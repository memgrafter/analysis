---
ver: rpa2
title: A Vlogger-augmented Graph Neural Network Model for Micro-video Recommendation
arxiv_id: '2405.18260'
source_url: https://arxiv.org/abs/2405.18260
tags:
- recommendation
- user
- micro-video
- vlogger
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of micro-video recommendation,
  focusing on the role of vloggers (video creators) in user preferences. Existing
  methods primarily focus on user-video interactions, neglecting the significant influence
  of vloggers.
---

# A Vlogger-augmented Graph Neural Network Model for Micro-video Recommendation

## Quick Facts
- arXiv ID: 2405.18260
- Source URL: https://arxiv.org/abs/2405.18260
- Authors: Weijiang Lai; Beihong Jin; Beibei Li; Yiyuan Zheng; Rui Zhao
- Reference count: 28
- Primary result: VA-GNN outperforms existing GNN-based models on micro-video recommendation by incorporating vlogger information and cross-view contrastive learning

## Executive Summary
This paper addresses micro-video recommendation by incorporating vlogger (video creator) information, which existing methods largely neglect. The authors propose VA-GNN, a tripartite graph neural network model that constructs embeddings from both user-video interactions (video-view) and user-vlogger interactions (vlogger-view). Cross-view contrastive learning ensures consistency between these two embedding perspectives, while multi-task learning with vlogger recommendation as an auxiliary task improves the main micro-video recommendation performance.

## Method Summary
VA-GNN constructs a tripartite graph with users, micro-videos, and vloggers as nodes, then learns node embeddings from two perspectives: video-view (based on user-video interactions) and vlogger-view (based on user-vlogger interactions). Cross-view contrastive learning is employed to ensure consistency between the embeddings from these two perspectives. The model predicts user-video interactions by combining user preferences for both the video itself and its vlogger. Experiments on WeChat-Channels and TakaTak datasets demonstrate significant improvements over existing GNN-based recommendation models.

## Key Results
- VA-GNN achieves 7.02% improvement in Recall@10 and 6.44% in NDCG@10 compared to SimGCL on WeChat-Channels dataset
- VA-GNN achieves 25.15% improvement in Recall@10 and 32.78% in NDCG@10 compared to SimGCL on TakaTak dataset
- The model consistently outperforms strong baselines including NGCF, LightGCN, GTN, SGL, and SimGCL

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-view contrastive learning aligns video-view and vlogger-view embeddings for the same entity, improving embedding quality.
- Mechanism: By treating embeddings from two views of the same user/video/vlogger as a positive pair and embeddings of different entities as negative pairs, the model learns to make the two views consistent.
- Core assumption: The two views capture complementary but related aspects of the same entity, so their embeddings should be similar.
- Break condition: If the two views capture unrelated or contradictory aspects of the entity, contrastive learning would force the model to merge incompatible information.

### Mechanism 2
- Claim: Incorporating vlogger information helps capture user preferences that are otherwise missed by user-video interactions alone.
- Mechanism: By constructing a tripartite graph with users, videos, and vloggers, the model can propagate information through vlogger nodes, capturing how user preferences for vloggers influence video interactions.
- Core assumption: Users' preferences for videos are significantly influenced by their preferences for the vloggers who create those videos.
- Break condition: If users interact with videos without regard to the vlogger (e.g., purely based on content), vlogger information would not add value.

### Mechanism 3
- Claim: Multi-task learning with vlogger recommendation as an auxiliary task improves the main micro-video recommendation task.
- Mechanism: By optimizing both user-video and user-vlogger interactions simultaneously, the model learns more accurate vlogger-view embeddings, which in turn improves the main task.
- Core assumption: User preferences for vloggers are indicative of their preferences for videos, and learning these preferences helps the main task.
- Break condition: If user preferences for vloggers and videos are unrelated, the auxiliary task would not help and might even hurt the main task.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) for recommendation
  - Why needed here: The paper uses GNNs to capture high-order collaborative signals between users, videos, and vloggers in a tripartite graph.
  - Quick check question: How does a GNN update node embeddings using information from neighboring nodes?

- Concept: Contrastive learning
  - Why needed here: The paper uses contrastive learning to align embeddings from two different views (video-view and vlogger-view) of the same entity.
  - Quick check question: What is the difference between instance-level and view-level contrastive learning?

- Concept: Multi-task learning
  - Why needed here: The paper uses multi-task learning to simultaneously optimize micro-video recommendation and vlogger recommendation tasks.
  - Quick check question: How can an auxiliary task help improve the performance of a main task in multi-task learning?

## Architecture Onboarding

- Component map: Heterogeneous graph construction -> Video-view and vlogger-view embedding propagation -> Cross-view contrastive learning -> Prediction layer -> Multi-task learning
- Critical path: Heterogeneous graph construction → Video-view and vlogger-view embedding propagation → Cross-view contrastive learning → Prediction layer
- Design tradeoffs:
  - Using a tripartite graph increases model complexity but allows capturing vlogger information
  - Cross-view contrastive learning adds computational overhead but improves embedding quality
  - Multi-task learning with vlogger recommendation as an auxiliary task might help or hurt the main task depending on the correlation between the two tasks
- Failure signatures:
  - If the model fails to capture the influence of vloggers on user preferences, the performance gain from the tripartite graph would be minimal
  - If the two views are not complementary, cross-view contrastive learning might force the model to merge incompatible information
  - If user preferences for vloggers and videos are unrelated, the auxiliary vlogger recommendation task might hurt the main task
- First 3 experiments:
  1. Ablation study: Remove cross-view contrastive learning and compare performance
  2. Ablation study: Remove the vlogger recommendation auxiliary task and compare performance
  3. Sensitivity analysis: Vary the weight of the vlogger loss (λ1) and observe its impact on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of VA-GNN compare to models that incorporate multimodal information from micro-videos (e.g., visual, acoustic, and textual features) while also considering vlogger information?
- Basis in paper: The paper mentions that some deep neural network models leverage multimodal information to achieve micro-video recommendation, but these models are costly in terms of time and computational power. The paper does not compare VA-GNN's performance against such models.
- Why unresolved: The paper focuses on comparing VA-GNN with GNN-based recommendation models and models that incorporate contrastive learning. It does not evaluate VA-GNN against models that leverage multimodal information.
- What evidence would resolve it: Conducting experiments comparing VA-GNN with multimodal models on the same datasets, reporting metrics such as Recall and NDCG, would provide insights into the trade-offs between incorporating multimodal information and vlogger information.

### Open Question 2
- Question: How sensitive is VA-GNN's performance to the quality and completeness of vlogger information, such as the number of videos published by a vlogger or the interactions between users and vloggers?
- Basis in paper: The paper mentions that VA-GNN constructs a tripartite graph with users, micro-videos, and vloggers as nodes, and that vlogger information is crucial for capturing user preferences. However, it does not explicitly discuss how the model's performance is affected by the quality and completeness of vlogger information.
- Why unresolved: The paper does not provide an analysis of how VA-GNN's performance varies with different levels of vlogger information quality and completeness.
- What evidence would resolve it: Conducting experiments with varying levels of vlogger information quality and completeness, such as removing some vlogger-video relationships or user-vlogger interactions, and observing the impact on VA-GNN's performance metrics, would provide insights into the model's sensitivity to vlogger information.

### Open Question 3
- Question: Can VA-GNN be extended to handle cold-start scenarios, where new users or new vloggers with limited interactions are introduced to the system?
- Basis in paper: The paper does not explicitly discuss cold-start scenarios. However, it mentions that VA-GNN captures user preferences for micro-videos and vloggers, which could be useful in recommending content to new users or promoting new vloggers.
- Why unresolved: The paper focuses on the performance of VA-GNN in scenarios with sufficient user and vlogger interaction data, but does not address how the model handles cold-start situations.
- What evidence would resolve it: Conducting experiments with simulated cold-start scenarios, such as introducing new users or new vloggers with limited interactions and evaluating VA-GNN's ability to recommend relevant content, would provide insights into the model's effectiveness in handling cold-start situations.

## Limitations
- The paper assumes vlogger influence is significant across all user-video interactions, though this may vary by platform and content type
- The contrastive learning mechanism's effectiveness depends on the quality of the two views, but the paper doesn't provide evidence that these views are truly complementary rather than redundant
- The multi-task learning setup assumes correlation between vlogger and video preferences, which may not hold universally

## Confidence
- Core claims: Medium
  - Empirical results show improvements over baselines, but ablation studies are limited
  - Proposed mechanisms, while plausible, lack rigorous validation
  - Improvements over strong baselines like SimGCL are substantial (7-25% gains)
  - Datasets and exact preprocessing steps are not fully specified, limiting reproducibility

## Next Checks
1. Conduct a more thorough ablation study by removing each major component (tripartite graph, contrastive learning, multi-task learning) individually to isolate their contributions
2. Test the model on a third dataset from a different platform to verify that vlogger influence is consistent across contexts
3. Perform a qualitative analysis of embedding similarity between video-view and vlogger-view to verify that contrastive learning is actually learning meaningful relationships rather than just forcing convergence