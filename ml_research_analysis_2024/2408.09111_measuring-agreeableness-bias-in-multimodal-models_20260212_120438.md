---
ver: rpa2
title: Measuring Agreeableness Bias in Multimodal Models
arxiv_id: '2408.09111'
source_url: https://arxiv.org/abs/2408.09111
tags:
- bias
- visual
- options
- multimodal
- pre-marked
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how visual cues in multiple-choice question
  images influence responses from multimodal language models, a phenomenon termed
  "agreeableness bias." The authors systematically tested this by presenting models
  with question images in neutral form and then with pre-marked answer options, measuring
  shifts in response distributions. Experiments covered two benchmarks (vMMLU for
  factual knowledge and vSocialIQa for social reasoning) and four models (Claude-haiku,
  Gemini-1.5-flash, GPT-4o-mini, and LLaVA).
---

# Measuring Agreeableness Bias in Multimodal Models

## Quick Facts
- arXiv ID: 2408.09111
- Source URL: https://arxiv.org/abs/2408.09111
- Reference count: 8
- Multimodal models shift responses toward pre-marked visual options in multiple-choice questions

## Executive Summary
This paper investigates how visual cues in multiple-choice question images influence responses from multimodal language models, a phenomenon termed "agreeableness bias." The authors systematically tested this by presenting models with question images in neutral form and then with pre-marked answer options, measuring shifts in response distributions. Experiments covered two benchmarks (vMMLU for factual knowledge and vSocialIQa for social reasoning) and four models (Claude-haiku, Gemini-1.5-flash, GPT-4o-mini, and LLaVA). Results showed consistent shifts toward pre-marked options across models, with Gemini-1.5-flash showing the strongest susceptibility (shifts up to 45 percentage points) and Claude-haiku showing moderate effects except in certain visual formats. The bias magnitude varied by task type and visual presentation, indicating that visual design significantly modulates model susceptibility. These findings highlight reliability concerns for multimodal models when processing images with pre-marked visual cues, especially in critical decision-making contexts.

## Method Summary
The study employed a systematic experimental design where multimodal models were presented with multiple-choice questions in two visual conditions: neutral (no answer markings) and pre-marked (with visual indicators on answer options). The authors used two benchmark datasets - vMMLU for factual knowledge assessment and vSocialIQa for social reasoning tasks. Four multimodal models were tested: Claude-haiku, Gemini-1.5-flash, GPT-4o-mini, and LLaVA. The primary measurement was the shift in response distributions between neutral and pre-marked conditions, quantified as the percentage point difference in model selections. Various visual manipulation techniques were employed, including highlighting, boxing, and color-coding of answer options, to understand how different visual presentations affected model susceptibility to the agreeableness bias.

## Key Results
- Multimodal models consistently shifted responses toward pre-marked answer options when visual cues were present
- Gemini-1.5-flash showed the highest susceptibility with shifts up to 45 percentage points
- Claude-haiku demonstrated moderate bias effects, with notable variations across different visual formats
- Bias magnitude varied significantly by task type, with stronger effects observed in social reasoning tasks versus factual knowledge questions

## Why This Works (Mechanism)
The agreeableness bias appears to stem from how multimodal models process and integrate visual information during inference. When models encounter images with pre-marked answer options, they may interpret these visual cues as implicit validation or recommendation signals. This suggests that models are not purely extracting visual content but are also sensitive to visual presentation patterns that might have been reinforced during training. The bias likely emerges from the interaction between the model's visual processing capabilities and its language understanding, where visual indicators are mapped to linguistic confidence or correctness signals. The varying susceptibility across models indicates differences in how individual architectures handle visual-linguistic alignment and the weight they assign to visual formatting cues during decision-making.

## Foundational Learning
- **Multimodal integration**: Understanding how models combine visual and textual information is essential because the bias emerges at this intersection. Quick check: Examine model attention maps to see if visual markers receive disproportionate weight.
- **Visual-linguistic alignment**: Critical for understanding why formatting cues affect responses, as models must map visual indicators to linguistic concepts. Quick check: Test models with abstract visual symbols versus concrete markings.
- **Inference-time processing**: The bias manifests during generation, not just encoding, highlighting the importance of understanding the complete inference pipeline. Quick check: Compare encoding representations between neutral and marked conditions.
- **Training data influence**: Likely contributes to bias as models may have learned associations between visual emphasis and correct answers. Quick check: Analyze training corpus for visual formatting patterns.
- **Cross-modal attention mechanisms**: Understanding how models attend across modalities helps explain why visual cues can override textual reasoning. Quick check: Measure attention weights on visual markers versus question content.

## Architecture Onboarding

**Component Map:** Image Encoder -> Cross-Modal Fusion -> Language Decoder -> Response Generator

**Critical Path:** Visual input → Feature extraction → Multimodal attention → Text generation → Response selection

**Design Tradeoffs:** Models must balance visual feature extraction quality against computational efficiency, and multimodal fusion depth against training stability. The architecture's ability to properly weight visual versus textual information directly impacts susceptibility to visual bias cues.

**Failure Signatures:** Consistent preference for visually marked options regardless of semantic correctness, with stronger effects when visual emphasis is more pronounced. Models may show different failure modes based on their visual encoder capabilities and fusion strategies.

**3 First Experiments:**
1. Compare model responses to neutral versus highlighted answer options across multiple visual emphasis levels
2. Test model behavior when visual markers are semantically meaningful versus arbitrary
3. Evaluate whether removing visual context before decision-making eliminates the bias effect

## Open Questions the Paper Calls Out
None

## Limitations
- Experiments focus specifically on multiple-choice formats, which may not generalize to all multimodal interaction scenarios
- Testing was limited to four models and two benchmark datasets, potentially missing variations across broader model families
- Visual manipulation techniques may not capture all real-world ways visual cues could influence model responses
- The study does not investigate underlying mechanisms causing the bias or its origins in training data patterns

## Confidence
- **High confidence**: The existence of agreeableness bias when models process images with pre-marked options (consistently observed across all models and benchmarks)
- **Medium confidence**: The relative susceptibility rankings between models (based on limited model samples and specific task types)
- **Medium confidence**: The task-specific variations in bias magnitude (requires broader task diversity for generalization)

## Next Checks
1. Test the same bias phenomenon across a wider range of multimodal models, including open-source variants with different architectural approaches
2. Evaluate whether similar biases emerge in non-multiple-choice contexts where visual cues might suggest preferred responses
3. Investigate whether fine-tuning or prompt engineering techniques can mitigate or eliminate the observed agreeableness bias