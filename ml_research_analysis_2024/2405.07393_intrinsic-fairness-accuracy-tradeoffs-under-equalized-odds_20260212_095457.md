---
ver: rpa2
title: Intrinsic Fairness-Accuracy Tradeoffs under Equalized Odds
arxiv_id: '2405.07393'
source_url: https://arxiv.org/abs/2405.07393
tags:
- fairness
- bound
- accuracy
- upper
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the intrinsic fairness-accuracy tradeoff under
  equalized odds constraints for binary classification. The authors present a new
  upper bound on accuracy as a function of the fairness budget, which depends on the
  underlying statistics of the data, labels, and sensitive group attributes.
---

# Intrinsic Fairness-Accuracy Tradeoffs under Equalized Odds

## Quick Facts
- arXiv ID: 2405.07393
- Source URL: https://arxiv.org/abs/2405.07393
- Reference count: 32
- This paper derives an upper bound on accuracy for binary classification under equalized odds constraints, showing that statistical disparities across sensitive subgroups fundamentally limit the fairness-accuracy tradeoff.

## Executive Summary
This paper investigates the intrinsic tradeoff between accuracy and fairness under equalized odds constraints for binary classification. The authors derive a new upper bound on achievable accuracy as a function of the fairness budget ϵEO, which depends on the total variation distances within sensitive subgroups and their relative proportions. Using a modified Le Cam's method, they show that statistical disparities across groups fundamentally limit how accurate a fair classifier can be, particularly when the fairness constraint is tight. Experimental results on three real-world datasets validate the theoretical bounds and demonstrate that achieving high accuracy under low-bias constraints is inherently limited by these statistical differences.

## Method Summary
The paper develops an upper bound on accuracy under equalized odds constraints using a modified Le Cam's method. The approach involves estimating total variation distances between class-conditional distributions within each sensitive subgroup, then combining these with the fairness budget and subgroup proportions to compute theoretical accuracy bounds. The authors use neural network-based variational estimators to compute TV distances, then validate their theoretical bounds by comparing them against empirical accuracy achieved by three different fair classifier implementations across three real-world datasets (COMPAS, Adult, and Law School).

## Key Results
- The derived upper bound is piecewise linear in the fairness budget ϵEO, with transition points determined by subgroup proportions
- The bound consistently outperforms the unconstrained Le Cam bound and closely approximates empirical accuracy achieved by various fair classifiers
- Statistical disparities across sensitive subgroups (captured by TV distances) fundamentally limit achievable accuracy under tight fairness constraints

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Accuracy under equalized odds is fundamentally bounded by the statistical disparity across sensitive subgroups.
- Mechanism: The theorem derives an upper bound on accuracy by combining subgroup-wise total variation distances (dT V (P a
1 , P a
0 ), dT V (P b
1 , P b
0 )) with the fairness budget ϵEO and subgroup proportions (β, 1−β). This captures how the intrinsic distributional differences between groups limit achievable fairness-accuracy tradeoffs.
- Core assumption: The classifier must satisfy ΔEO ≤ ϵEO, and the data follows the binary classification model with conditional PDFs P a
y (x), P b
y (x).
- Evidence anchors:
  - [abstract] states "achieving high accuracy subject to a low-bias could be fundamentally limited based on the statistical disparity across the groups."
  - [section III] proves Theorem 2, showing Acc(f) ≤ max(α, 1 − α) + min(T1, T2) where T1, T2 depend on subgroup TV distances and fairness budget.
  - [corpus] neighbors include "Kernel-based Equalized Odds" and "FairICP: Encouraging Equalized Odds" that also explore subgroup statistical disparities.
- Break condition: If the conditional distributions P a
y , P b
y are identical across subgroups (zero TV distance), the bound becomes tight to the unconstrained bound.

### Mechanism 2
- Claim: The relative subgroup sizes (β, 1−β) determine which subgroup's statistical distance dominates the accuracy bound as ϵEO increases.
- Mechanism: When β << 1−β (minority subgroup a), the bound transitions from being limited by dT V (P a
1 , P a
0 ) to being limited by dT V (P b
1 , P b
0 ) as the fairness budget grows, because the slope of T1 is β while the slope of T2 is (1−β).
- Core assumption: The classifier must satisfy the EO constraint, and subgroup proportions are known and fixed.
- Evidence anchors:
  - [section III] Remark 2 explains that "the slopes of these two lines are given by β = P(Z = a), and 1 − β = P(Z = b)".
  - [section IV] experiments on COMPAS, Adult, and Law School datasets show varying β values and corresponding bound behaviors.
  - [corpus] includes "A Stochastic Optimization Framework for Private and Fair Learning" which also studies subgroup size effects.
- Break condition: If β = 0.5 (equal subgroup sizes), both T1 and T2 contribute equally regardless of their TV distances.

### Mechanism 3
- Claim: The upper bound is piecewise linear in the fairness budget ϵEO, transitioning at a critical threshold determined by the relative subgroup proportions and TV distances.
- Mechanism: For small ϵEO, the bound is determined by the subgroup with smaller TV distance (worse accuracy), but as ϵEO increases, the minority subgroup's contribution grows linearly with its proportion until the majority subgroup's TV distance dominates.
- Core assumption: The TV distances and subgroup proportions are accurately estimated, and the fairness constraint is convex in the classifier parameters.
- Evidence anchors:
  - [section III] states "the upper bound is a piece-wise linear function of the fairness budget ϵEO, and obtained as a minimum over two expressions related to T1, T2".
  - [section IV] Figure 2 shows the empirical upper bounds for three real datasets matching the piecewise linear theoretical prediction.
  - [corpus] neighbors like "A Unified View of Group Fairness Tradeoffs" also discuss piecewise relationships between fairness notions.
- Break condition: If the two TV distances are equal, the piecewise structure collapses to a single linear function.

## Foundational Learning

- Concept: Total variation distance as a measure of distributional difference
  - Why needed here: The bound explicitly uses dT V (P a
1 , P a
0 ) and dT V (P b
1 , P b
0 ) to quantify how distinguishable the positive and negative classes are within each subgroup.
  - Quick check question: What is the TV distance between two distributions that assign probability 0.7 to outcome 1 and 0.3 to outcome 0 versus distributions assigning 0.3 to outcome 1 and 0.7 to outcome 0?

- Concept: Equalized odds fairness constraint and its relaxation
  - Why needed here: The entire bound derivation depends on the EO constraint ΔEO ≤ ϵEO, and understanding how relaxing this constraint (increasing ϵEO) affects the accuracy bound.
  - Quick check question: If a classifier has false positive rates of 0.1 for group a and 0.2 for group b when Y=0, and false negative rates of 0.3 for group a and 0.4 for group b when Y=1, what is ΔEO?

- Concept: Le Cam's method for binary classification bounds
  - Why needed here: The paper extends Le Cam's classical bound (which uses dT V (P1, P0)) to the EO-constrained setting by incorporating subgroup-wise TV distances.
  - Quick check question: According to Le Cam's bound, what is the maximum accuracy achievable when the TV distance between class-conditional distributions is 0.4?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Parameter estimation -> Bound computation -> Validation -> Visualization

- Critical path:
  1. Load and preprocess dataset (COMPAS/Adult/Law School)
  2. Estimate α, β, dT V (P0, P1), dT V (P a
0 , P a
1 ), dT V (P b
0 , P b
1 ) using variational TV distance estimators
  3. Compute theoretical upper bounds for range of ϵEO values
  4. Train multiple fair classifiers with different EO budgets
  5. Evaluate empirical accuracy and fairness metrics
  6. Compare empirical results with theoretical bounds
  7. Generate visualization of tradeoff curves

- Design tradeoffs:
  - Estimation accuracy vs computational cost: Using neural network estimators for TV distances provides better accuracy than histogram-based methods but requires training.
  - Bound tightness vs simplicity: The piecewise linear bound is simpler than the full optimization problem but may be conservative.
  - Dataset generality vs specificity: The bound works for any dataset but requires accurate estimation of underlying distributions.

- Failure signatures:
  - If estimated TV distances are negative, the estimator is broken or the sample size is too small
  - If empirical accuracy exceeds the theoretical bound, either the fairness constraint is violated or the bound computation is incorrect
  - If the piecewise structure doesn't appear in empirical results, the subgroup proportions or TV distances may be estimated incorrectly

- First 3 experiments:
  1. Compute the unconstrained bound (Theorem 1) for COMPAS dataset and verify it matches the Bayes optimal classifier accuracy
  2. For ϵEO = 0, compute the EO-constrained bound and verify it equals min(dT V (P a
1 , P a
0 ), dT V (P b
1 , P b
0 )) for balanced α
  3. Plot the piecewise linear bound for varying ϵEO and verify the transition point matches β/(β+(1-β)) = β

## Open Questions the Paper Calls Out
None

## Limitations
- The theoretical bounds assume accurate estimation of TV distances and subgroup proportions, but in practice these are estimated from finite samples and may contain significant error.
- The piecewise linear bound assumes the fairness constraint is convex in the classifier parameters, which may not hold for all fair classifier implementations.
- The analysis requires known and fixed subgroup proportions, which may not hold in dynamic or evolving datasets.

## Confidence
- **High confidence**: The mechanism by which TV distances limit accuracy under EO constraints (Mechanism 1) is well-supported by both theory and experiments across three real datasets.
- **Medium confidence**: The piecewise linear structure of the bound (Mechanism 3) is theoretically derived and matches empirical results, but the transition points depend sensitively on estimated subgroup proportions.
- **Medium confidence**: The claim about minority subgroup dominance in the bound (Mechanism 2) is supported by the theoretical analysis but would benefit from more extensive experimental validation across datasets with varying subgroup sizes.

## Next Checks
1. **Synthetic data validation**: Generate synthetic datasets with known TV distances and subgroup proportions to verify the theoretical bounds match empirical classifier performance across the full range of fairness budgets.
2. **Robustness to estimation error**: Test how estimation noise in TV distances and subgroup proportions affects bound tightness by adding controlled noise to the estimates and measuring bound degradation.
3. **Classifier implementation comparison**: Implement and compare the theoretical bounds against a broader range of fair classifiers (e.g., post-processing methods, adversarial debiasing) to verify the bounds are classifier-agnostic.