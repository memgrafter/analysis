---
ver: rpa2
title: 'Injecting Combinatorial Optimization into MCTS: Application to the Board Game
  boop'
arxiv_id: '2406.08766'
source_url: https://arxiv.org/abs/2406.08766
tags:
- mcts
- game
- combinatorial
- games
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper combines Monte Carlo Tree Search (MCTS) and Combinatorial
  Optimization to improve MCTS performance. The method injects Combinatorial Optimization
  into three MCTS steps: pre-selection of nodes, expansion, and playouts.'
---

# Injecting Combinatorial Optimization into MCTS: Application to the Board Game boop

## Quick Facts
- arXiv ID: 2406.08766
- Source URL: https://arxiv.org/abs/2406.08766
- Reference count: 20
- Combines MCTS with Combinatorial Optimization, achieving 96% win rate against vanilla MCTS

## Executive Summary
This paper introduces a novel approach to enhance Monte Carlo Tree Search (MCTS) by injecting Combinatorial Optimization techniques into three key steps: pre-selection of nodes, expansion, and playouts. The method is applied to the board game boop., where the AI agent demonstrates superior performance compared to traditional MCTS implementations. The approach leverages a Constraint Programming solver to find optimal moves based on a heuristic evaluation function, improving the quality of decision-making in MCTS.

## Method Summary
The method combines MCTS with Combinatorial Optimization by solving a Constraint Programming problem for move selection. The boop. game rules are implemented along with a heuristic evaluation function. The MCTS algorithm is modified to include three injections: pre-selection using the solver, expansion using the solver, and playouts using the solver to select moves. Key parameters include k=20 moves per playout, m=5 pre-selected nodes, discount factor d=0.9, and a timeout of 1 second for the solver.

## Key Results
- 96% win rate against vanilla MCTS baseline
- 80% win rate against a heuristics-based agent
- ELO rating of 373 after 51 games against human players, ranking 56th worldwide

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Injecting Combinatorial Optimization into MCTS Expansion improves move selection quality.
- Mechanism: The solver finds optimal moves under game constraints before MCTS expands the tree, ensuring better nodes are added.
- Core assumption: The heuristic used in the optimization objective function accurately captures move quality.
- Evidence anchors:
  - [abstract] "In particular, such combinations can be very profitable on devices with limited computing power, where only a few random playouts can be performed."
  - [section] "This issue can be tackled by replacing playouts with moves that are selected by solving the Combinatorial Optimization problem"
  - [corpus] Weak evidence; no directly related work on this specific combination.
- Break condition: If the heuristic function poorly represents actual game state value, the optimization becomes misleading.

### Mechanism 2
- Claim: Pre-selecting nodes using optimization improves MCTS Selection efficiency.
- Mechanism: The solver narrows the UCB selection space to top-m moves, reducing wasted exploration on poor branches.
- Core assumption: The top-m moves contain the actual best moves with high probability.
- Evidence anchors:
  - [section] "For the Selection step, the solver is called to pre-select the m best moves regarding the current game state"
  - [section] "This is analogical to invalid action masking in Reinforcement Learning"
  - [corpus] Weak evidence; related works focus on using MCTS to help optimization, not vice versa.
- Break condition: If m is too small, the best moves may be excluded; if too large, the benefit diminishes.

### Mechanism 3
- Claim: Replacing random playouts with optimization-guided moves improves value estimation.
- Mechanism: Each playout step selects optimal moves via solver, creating more realistic game trajectories for value estimation.
- Core assumption: Optimal moves in intermediate positions lead to better terminal state estimation.
- Evidence anchors:
  - [section] "We also inject the same Combinatorial Optimization problem into the MCTS process to bias the Selection and Expansion steps"
  - [section] "The playout reward is estimated by computing a discounted sum of the normalized scores"
  - [corpus] No direct evidence; this is the novel contribution.
- Break condition: If optimization becomes too slow, timeout constraints may force premature termination.

## Foundational Learning

- Concept: Monte Carlo Tree Search fundamentals
  - Why needed here: Understanding the four-step MCTS process is essential for knowing where and how to inject optimization.
  - Quick check question: What are the four steps of MCTS and their purposes?

- Concept: Constraint Programming and COP formulation
  - Why needed here: The optimization model must be correctly formulated to guide MCTS effectively.
  - Quick check question: What are the four components of a Constrained Optimization Problem (V, D, C, f)?

- Concept: Heuristics design for board games
  - Why needed here: The objective function relies on heuristics that evaluate game state quality.
  - Quick check question: What factors should a boop. heuristic consider for move evaluation?

## Architecture Onboarding

- Component map: Game state -> Solver -> MCTS node selection -> Simulation -> Backpropagation
- Critical path: Game state → Solver → MCTS node selection → Simulation → Backpropagation
- Design tradeoffs:
  - Solver timeout vs. MCTS depth
  - Heuristic complexity vs. solver speed
  - Pre-selection size m vs. exploration diversity
- Failure signatures:
  - Solver timeout causes MCTS fallback to random play
  - Poor heuristic leads to consistently suboptimal moves
  - Memory overflow from tree expansion with optimization
- First 3 experiments:
  1. Run vanilla MCTS vs. MCTS+Expansion to isolate Expansion impact
  2. Vary pre-selection size m to find optimal balance
  3. Test different heuristic weights to optimize solver objective function

## Open Questions the Paper Calls Out
None

## Limitations
- The heuristic function details are not fully specified, making exact replication challenging
- Limited testing against diverse baseline agents beyond vanilla MCTS and one heuristics-based agent
- No comparison with other state-of-the-art MCTS enhancements or deep learning approaches
- The solver timeout of 1 second may not be optimal across different game states

## Confidence
- High confidence in the general methodology and framework (MCTS + Combinatorial Optimization)
- Medium confidence in the specific implementation details and parameter choices
- Medium confidence in the win rate claims due to limited baseline comparisons
- Low confidence in the generalizability to other board games without further testing

## Next Checks
1. Implement the complete heuristic function and validate against the authors' reported performance metrics
2. Test the approach against additional baseline agents including AlphaZero-style methods and other MCTS variants
3. Conduct ablation studies varying the solver timeout parameter to find optimal balance between computation time and move quality