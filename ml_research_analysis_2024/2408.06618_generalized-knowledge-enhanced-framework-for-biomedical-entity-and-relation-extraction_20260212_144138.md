---
ver: rpa2
title: Generalized knowledge-enhanced framework for biomedical entity and relation
  extraction
arxiv_id: '2408.06618'
source_url: https://arxiv.org/abs/2408.06618
tags:
- biomedical
- relation
- knowledge
- entities
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a generalized knowledge-enhanced framework for
  biomedical entity and relation extraction. The core idea is to build a task-independent
  background knowledge graph (KG) that can be reused across different biomedical tasks,
  addressing the limitation of task-dependent KG models that require rebuilding for
  each new task.
---

# Generalized knowledge-enhanced framework for biomedical entity and relation extraction

## Quick Facts
- arXiv ID: 2408.06618
- Source URL: https://arxiv.org/abs/2408.06618
- Authors: Minh Nguyen; Phuong Le
- Reference count: 24
- Key outcome: F1 score of 83.22% on ADE for relation extraction and 63.21% on BioRelEx

## Executive Summary
This paper introduces a generalized knowledge-enhanced framework for biomedical entity and relation extraction that addresses the limitation of task-dependent knowledge graph models. The core innovation is a task-independent background knowledge graph that can be reused across different biomedical tasks, consisting of General-Knowledge (GK) and Specific-Knowledge (SK) components. The framework achieves competitive performance on two biomedical datasets (BioRelEx and ADE) by fusing general domain knowledge with task-specific information through graph neural networks.

## Method Summary
The framework builds a task-independent background knowledge graph (KG) from external sources like UMLS and Wikidata, separating it into General-Knowledge (GK) and Specific-Knowledge (SK) components. The GK component encodes reusable domain knowledge and is pre-built, while the SK component is derived from task-specific input documents. The framework uses BioBERT to extract relational information from external knowledge sources, creating weighted relational data through masked sentence constructions. These components are fused using an additional graph convolutional network (GCN) that connects task-specific entities to general knowledge entities, allowing effective learning transfer across biomedical tasks.

## Key Results
- Achieves F1 score of 83.22% on ADE dataset for relation extraction
- Achieves F1 score of 63.21% on BioRelEx dataset for relation extraction
- Demonstrates competitive performance against state-of-the-art methods while maintaining reusability of the knowledge base

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating the knowledge graph into General-Knowledge (GK) and Specific-Knowledge (SK) components allows reusable background knowledge to be shared across different biomedical tasks.
- Mechanism: GK component is built from external knowledge sources like UMLS and Wikidata and contains task-independent feature vectors for entities and relations. SK component is built from task-specific input documents and is task-dependent. These two components are then fused, allowing effective learning transfer.
- Core assumption: Domain knowledge is common across biomedical tasks and can be represented in a task-independent way.
- Evidence anchors:
  - [abstract] "The core idea is to build a task-independent background knowledge graph (KG) that can be reused across different biomedical tasks"
  - [section 1.2] "To address these shortcomings, we introduce a knowledge-enhanced model designed to leverage external general knowledge from various sources more efficiently. Our approach focuses on building a general knowledge graph (KG) that can truly serve as a public knowledge source and can be readily shared with any new domain-specific tasks."
  - [corpus] Weak - no direct evidence in corpus about the GK/SK separation, but related work mentions knowledge graphs and external knowledge sources.
- Break condition: If domain knowledge is highly task-specific rather than common across tasks, the GK component would not be reusable and the separation would provide no benefit.

### Mechanism 2
- Claim: Using BioBERT to extract relational information from external knowledge sources provides weighted relational data that can be used to train entity representations.
- Mechanism: The framework uses BioBERT to create masked sentences from (subject, relation, object) triples. By comparing the original sentence with the predicted sentence, cosine similarity is calculated as the weight indicating how well the relation matches the subject-object pair. These weights are then used to train a feed-forward neural network to encode relational information into entity representations.
- Core assumption: BioBERT can effectively extract relational information from biomedical text when given appropriate masked sentence constructions.
- Evidence anchors:
  - [section 2.2] "We apply BioBert embedding to get a set of associated weights that indicate how likely each relation rk will match the subject-object pair (si, oj)"
  - [section 2.2] "We then perform the geometric vector operation vE = vB + vC âˆ’ vA. Here E can be considered as the remaining vertex of the parallelogram with existing vertices A, B, C."
  - [corpus] Weak - corpus mentions knowledge graphs and BioBERT but doesn't specifically discuss this masked sentence approach for relation extraction.
- Break condition: If BioBERT fails to accurately predict the masked elements or if the geometric operations don't capture the relational information effectively, the extracted weights would be unreliable for training.

### Mechanism 3
- Claim: The fusion of GK and SK components through an additional GCN allows the model to combine general biomedical knowledge with task-specific information effectively.
- Mechanism: After building the SK component as a GCN on task-specific entities and the GK component with pre-trained entity embeddings, a fusion GCN connects nodes in the SK graph to those in the GK graph. This allows the model to leverage both the general knowledge encoded in GK and the specific patterns learned from the task data in SK.
- Core assumption: The connections between task-specific entities and general knowledge entities can be effectively learned through GCN architecture.
- Evidence anchors:
  - [section 2.3] "To perform the fusion, we train an additional GCN that connects the nodes in the specific task's graph to those in the graph from the GK component."
  - [section 3.3] "Moreover, our model outperforms all baselines for ADE data set (using both sources) and matches closely for BioRelEx."
  - [corpus] Weak - corpus doesn't discuss the fusion mechanism specifically, though it mentions GCNs and knowledge graphs in related contexts.
- Break condition: If the fusion GCN cannot effectively learn meaningful connections between GK and SK components, or if the GK component is too generic to be useful for specific tasks, the performance would degrade to using only the SK component.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and Graph Convolutional Networks (GCNs)
  - Why needed here: The framework uses GCNs to build both the SK component from task-specific documents and the fusion component connecting SK to GK. Understanding how GCNs aggregate information from neighboring nodes is crucial for understanding how the model learns entity representations.
  - Quick check question: How does a GCN update the representation of a node based on its neighbors, and what role does the adjacency matrix play in this process?

- Concept: Knowledge Graphs (KGs) and their construction
  - Why needed here: The framework builds a knowledge graph from external sources (UMLS, Wikidata) as the GK component. Understanding how entities and relations are represented in KGs, and how they can be used to provide background knowledge for downstream tasks, is fundamental to understanding this approach.
  - Quick check question: What are the key differences between a task-specific KG built from input documents versus a general KG built from external knowledge sources?

- Concept: Masked language modeling and relation extraction
  - Why needed here: The framework uses a masked sentence approach with BioBERT to extract relational weights between entities. Understanding how masked language models work and how they can be adapted for relation extraction tasks is important for grasping this mechanism.
  - Quick check question: How does masking different parts of a (subject, relation, object) triple help BioBERT learn to predict relations, and why use cosine similarity as the weighting metric?

## Architecture Onboarding

- Component map:
  - BioBERT model for initial entity embeddings and relation weight extraction
  - Feed-forward neural network for training entity representations with relational information
  - Task-specific GCN for SK component construction
  - Fusion GCN for connecting SK to GK
  - GK component (pre-built) containing entity embeddings from UMLS/Wikidata

- Critical path:
  1. Extract entity mentions and relations from input documents using BioBERT
  2. Build SK component GCN from task-specific entities
  3. Fuse SK with pre-built GK component using fusion GCN
  4. Train model on task-specific data using combined knowledge

- Design tradeoffs:
  - Pre-building GK component trades off some task-specific optimization for reusability across tasks
  - Using BioBERT for relation extraction trades computational efficiency for potentially less accurate relation weights compared to full training
  - Separating GK and SK allows for modular updates but adds complexity to the fusion process

- Failure signatures:
  - Poor performance on both tasks suggests issues with the fusion mechanism or BioBERT relation extraction
  - Good performance on one task but not the other suggests the GK component may not be equally useful across domains
  - Degradation in performance when GK is included suggests the fusion is not working correctly or GK is too generic

- First 3 experiments:
  1. Test the BioBERT relation extraction mechanism independently on a small set of triples to verify it produces reasonable weights
  2. Evaluate the GK component's coverage of frequent entities in the ADE dataset to understand how much knowledge is being reused
  3. Test the fusion GCN on a simplified task with known entity connections to verify it can learn meaningful relationships between SK and GK nodes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the framework's performance scale with increasing size of the General-Knowledge (GK) component, and what is the optimal balance between GK and Specific-Knowledge (SK) components for different biomedical tasks?
- Basis in paper: [explicit] The paper mentions that the GK component contributes more to frequent entities and that increasing the size of the GK component keeps results stable and close to KECI's performance. However, it doesn't provide a detailed analysis of performance scaling with GK size.
- Why unresolved: The paper does not provide quantitative data on how the framework's performance changes as the GK component grows larger or how it balances with the SK component for different tasks.
- What evidence would resolve it: Experiments showing performance metrics (e.g., F1 scores) for different sizes of the GK component and varying proportions of GK to SK for multiple biomedical tasks would provide insights into optimal component sizing and task-specific balances.

### Open Question 2
- Question: How can the framework be adapted to handle multi-label relations or nested entities in biomedical texts, and what impact would this have on performance?
- Basis in paper: [inferred] The paper focuses on single-label relations and non-nested entities. It does not address the complexities of multi-label relations or nested entities, which are common in biomedical texts.
- Why unresolved: The framework's current design and experiments do not explore scenarios involving multi-label relations or nested entities, leaving the impact on performance and necessary adaptations unclear.
- What evidence would resolve it: Experiments evaluating the framework's performance on datasets containing multi-label relations and nested entities, along with modifications to handle these cases, would demonstrate the framework's adaptability and potential performance impacts.

### Open Question 3
- Question: How does the framework's knowledge reuse capability compare to other knowledge-enhanced models in terms of efficiency and accuracy across diverse biomedical tasks beyond BioRelEx and ADE?
- Basis in paper: [explicit] The paper claims that the GK component is reusable across different biomedical tasks and shows competitive performance on BioRelEx and ADE datasets. However, it does not compare the framework's knowledge reuse capability directly with other models across a broader range of tasks.
- Why unresolved: The paper's experiments are limited to two datasets, and there is no direct comparison of the framework's knowledge reuse efficiency and accuracy with other models across diverse biomedical tasks.
- What evidence would resolve it: Comparative experiments evaluating the framework's knowledge reuse efficiency and accuracy against other knowledge-enhanced models on a wide range of biomedical tasks would provide a clearer understanding of its relative strengths and limitations.

## Limitations
- Performance depends on quality and coverage of external knowledge sources like UMLS and Wikidata
- BioBERT-based relation extraction may not capture complex biomedical relationships as accurately as fully supervised approaches
- Limited ablation studies provided to quantify individual contributions of GK and SK components

## Confidence
- High confidence: The core architectural design separating GK and SK components is clearly specified and logically sound
- Medium confidence: The reported performance metrics on BioRelEx and ADE datasets, though results are competitive with stated baselines
- Low confidence: The exact implementation details of the BioBERT relation weight extraction and fusion GCN mechanisms, which are described but not fully specified

## Next Checks
1. **Ablation study**: Systematically remove the GK component to quantify the performance drop and verify the claimed learning transfer benefits
2. **External knowledge coverage analysis**: Measure the proportion of entities in both datasets that have corresponding entries in the UMLS/Wikidata knowledge bases
3. **Relation extraction accuracy**: Independently validate the BioBERT-based relation weight extraction by manually checking predictions on a sample of triples