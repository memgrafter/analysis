---
ver: rpa2
title: 'Open3DTrack: Towards Open-Vocabulary 3D Multi-Object Tracking'
arxiv_id: '2410.01678'
source_url: https://arxiv.org/abs/2410.01678
tags:
- tracking
- open-vocabulary
- object
- objects
- novel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the limitations of traditional 3D multi-object
  tracking systems, which are constrained to predefined object categories and struggle
  to generalize to novel, unseen objects in dynamic environments. To overcome this,
  the authors introduce open-vocabulary 3D tracking, enabling systems to detect and
  track arbitrary object classes without relying on closed-set class labels during
  inference.
---

# Open3DTrack: Towards Open-Vocabulary 3D Multi-Object Tracking

## Quick Facts
- arXiv ID: 2410.01678
- Source URL: https://arxiv.org/abs/2410.01678
- Reference count: 27
- Key outcome: Open-vocabulary 3D tracking improves AMOTA by up to 14.3 points for novel object classes using class-agnostic tracking + 2D open-vocabulary label assignment

## Executive Summary
This work introduces open-vocabulary 3D multi-object tracking, enabling systems to track arbitrary object classes beyond predefined categories. The approach modifies an existing 3D tracking framework to operate class-agnostically and leverages 2D open-vocabulary detectors to assign semantic labels to 3D tracks. Evaluated on nuScenes with novel object splits, the method significantly improves tracking accuracy for unseen categories while maintaining strong performance on known classes.

## Method Summary
The method adapts 3DMOTFormer to track objects without class-specific labels by using only position and motion features. A confidence score prediction head estimates objectness for each track. Open-vocabulary classification is achieved by projecting 3D detections to multi-view images and using 2D open-vocabulary detections from a vision-language model (Grounding DINO) to assign class labels. A track consistency scoring module aggregates class predictions weighted by detection visibility to improve label accuracy across frames.

## Key Results
- Achieves 0.578 AMOTA overall on novel object classes, up to 14.3 points higher than baseline
- Strong generalization across different 3D detection backbones
- Demonstrates significant improvements on rare, urban, and diverse object splits in nuScenes

## Why This Works (Mechanism)
The method works by decoupling object tracking from object classification. By tracking objects class-agnostically using only geometric and motion features, the system can maintain consistent tracks regardless of whether objects belong to known or unknown categories. The 2D open-vocabulary detection provides semantic labels without requiring class-specific training data. The track consistency scoring module then refines these labels over time by weighting predictions based on detection visibility, reducing label noise from intermittent or partial observations.

## Foundational Learning

**3D Multi-Object Tracking (MOT)**
- *Why needed*: Core task of maintaining consistent object identities across frames in 3D space
- *Quick check*: Can you explain how data association works in 3D tracking?

**Vision-Language Models for Detection**
- *Why needed*: Enable detection of arbitrary objects without predefined categories
- *Quick check*: How do models like Grounding DINO differ from traditional object detectors?

**Track Consistency Scoring**
- *Why needed*: Improves label reliability by aggregating predictions over time
- *Quick check*: What factors should be considered when weighting predictions for track labeling?

**Multi-View Geometry**
- *Why needed*: Enables projection between 3D space and 2D image planes for cross-modal label assignment
- *Quick check*: How do you project a 3D bounding box to 2D image coordinates?

## Architecture Onboarding

**Component Map**
Preprocessing -> 3D Detection Backbone -> Class-Agnostic Tracker -> 2D Open-Vocabulary Detection -> Label Assignment -> Track Consistency Scoring -> Output Tracks

**Critical Path**
3D Detection Backbone -> Class-Agnostic Tracker -> Label Assignment -> Output Tracks

**Design Tradeoffs**
The approach trades off classification accuracy for tracking flexibility by using class-agnostic tracking followed by separate label assignment. This enables tracking novel objects but introduces dependency on 2D detection quality for label assignment. The track consistency module adds computational overhead but improves label accuracy.

**Failure Signatures**
- Poor 2D open-vocabulary detection leads to incorrect or missing class labels
- Track fragmentation when objects are occluded or small
- Label drift when track consistency scoring fails to correct noisy predictions

**First 3 Experiments**
1. Run class-agnostic tracking on a single scene to verify basic tracking functionality
2. Test 2D-to-3D projection accuracy on a few manually annotated objects
3. Evaluate label assignment quality on a small set of known objects before testing novel classes

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on 2D open-vocabulary detection quality for accurate 3D tracking
- Class-agnostic tracking head requires specialized training with objectness supervision
- Track consistency scoring depends on visibility estimates that may be inaccurate

## Confidence

**Major Claim Confidence:**
- **High confidence**: The overall methodology of class-agnostic 3D tracking followed by open-vocabulary label assignment is technically sound and well-implemented
- **Medium confidence**: The generalization to truly novel classes is demonstrated on nuScenes splits, but the diversity and realism of these splits could be questioned
- **Low confidence**: The scalability to very large vocabulary sizes is not demonstrated

## Next Checks
1. Test the full pipeline on a dataset with a much larger label vocabulary (e.g., 100+ classes) to evaluate scalability and label assignment accuracy degradation
2. Perform ablation studies isolating the impact of 2D detection quality on 3D tracking performance by varying detection confidence thresholds
3. Evaluate the system on a different autonomous driving dataset (e.g., Waymo Open Dataset) with different camera configurations and scene distributions to assess cross-dataset generalization