---
ver: rpa2
title: 'Federated Learning: A Stochastic Approximation Approach'
arxiv_id: '2402.12945'
source_url: https://arxiv.org/abs/2402.12945
tags:
- learning
- clients
- data
- federated
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies federated learning (FL) in a stochastic approximation
  (SA) framework, addressing the limitation of prior FL methods that assume constant
  step sizes and only achieve convergence in expectation. The key idea is to use client-specific
  tapering step sizes, enabling the global model to track an autonomous ODE whose
  forcing function is a weighted sum of individual client gradients.
---

# Federated Learning: A Stochastic Approximation Approach

## Quick Facts
- arXiv ID: 2402.12945
- Source URL: https://arxiv.org/abs/2402.12945
- Reference count: 21
- One-line primary result: Proposes SA-based FL with tapering step sizes achieving convergence with probability one, outperforming FedAvg and FedProx under non-IID conditions.

## Executive Summary
This paper introduces a federated learning framework based on stochastic approximation (SA) with client-specific tapering step sizes. Unlike prior FL methods that use constant step sizes and only achieve convergence in expectation, this approach enables the global model to track an autonomous ODE, ensuring convergence with probability one. The method uses decaying step sizes $a_n^{(i)} = C/n^\delta$ (with $3/4 < \delta \leq 1$) and shows that the limiting ratios of step sizes determine each client's influence on the global model. Experiments on F-MNIST, CIFAR-10, CIFAR-100, and STL-10 demonstrate improved accuracy, lower test loss, and greater robustness compared to FedAvg and FedProx, particularly under non-IID data splits.

## Method Summary
The method implements federated learning using stochastic approximation with client-specific tapering step sizes. Each client maintains a local model and performs mini-batch gradient updates using decaying step sizes $a_n^{(i)} = C_i/n^\delta$. The server aggregates weights at multiples of $N$ and redistributes the global model. The framework replaces expectation terms with mini-batch gradients, introducing Martingale difference sequences that vanish as step sizes decay. The analysis shows that the global model tracks an autonomous ODE whose forcing function is a weighted sum of individual client gradients, with weights determined by the limiting ratios of step sizes. The method achieves convergence with probability one under standard SA assumptions, unlike constant-step FL methods.

## Key Results
- SA-based FL achieves convergence with probability one, unlike constant-step methods that only converge in expectation
- The method outperforms FedAvg and FedProx on F-MNIST, CIFAR-10, CIFAR-100, and STL-10 datasets
- Under non-IID data splits, the proposed method shows better accuracy, lower test loss, and greater stability across training rounds
- The limiting ratios of step sizes determine each client's influence on the global model trajectory

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using tapering step sizes $a_n^{(i)} = C/n^\delta$ with $3/4 < \delta \leq 1$ makes the global model track an autonomous ODE with probability one.
- Mechanism: As step sizes decay, the stochastic gradient noise averages out, allowing the aggregate update to converge to the deterministic flow of the ODE $\dot{w} = \frac{1}{L}\sum_{i=1}^L h^{(i)}(w)$.
- Core assumption: Conditions A2 and A3 ensure the step-size sum diverges, the sum of squared steps converges, and iterates stay bounded.
- Evidence anchors:
  - [abstract]: "client-specific tapering step sizes $a^{(i)}_n$ are used. The global model is shown to track an ODE..."
  - [section]: A2 defines the step-size decay; A3 bounds iterates; C6 derives that $\|a_n M_n\| \to 0$.
  - [corpus]: No direct mention; evidence is internal.
- Break condition: If $\delta \leq 3/4$, the martingale sum $\sum a_n^2 E[\|M_n\|^2]$ may diverge, breaking almost-sure convergence.

### Mechanism 2
- Claim: The limiting ratios $p^{(i)} = \lim_{n\to\infty} a_n^{(i)}/a_n^{(1)}$ weight each client's influence on the global model.
- Mechanism: At convergence, the global model evolves according to a weighted average of client gradients, with weights given by $p^{(i)}$. Clients with larger $p^{(i)}$ steer the model more strongly.
- Core assumption: Step sizes taper but their ratios converge; A2 ensures $a_n^{(1)} \geq a_n^{(i)}$ for all $n$.
- Evidence anchors:
  - [abstract]: "The weights being the limiting ratios $p^{(i)} = \lim_{n\to\infty} \frac{a^{(i)}_n}{a^{(1)}_n}$..."
  - [section]: A2 and the definition of $p^{(i)}$ in the convergence analysis.
  - [corpus]: No external support; internal derivation only.
- Break condition: If step sizes do not taper uniformly (e.g., one client's step size plateaus), the ratio limit may not exist or may not reflect true influence.

### Mechanism 3
- Claim: Mini-batch gradients replace the expectation term, introducing zero-mean Martingale differences $M_n^{(i)}$ that vanish in the limit.
- Mechanism: The Martingale difference sequence has bounded second moment (C3) and satisfies $\sum a_n^2 E[\|M_n\|^2] < \infty$ (C5), ensuring $\lim a_n M_n = 0$ almost surely.
- Core assumption: IID data per client with finite variance (A4) and bounded gradient second moments (A5).
- Evidence anchors:
  - [abstract]: "replacing the expectation in (1) by (2) leads to..."
  - [section]: C3 and C5 formalize the Martingale bounds; C6 proves $a_n M_n \to 0$.
  - [corpus]: No external corroboration; theory is self-contained.
- Break condition: Violation of finite variance or independence breaks the zero-mean, square-integrable Martingale property, preventing noise cancellation.

## Foundational Learning

- Concept: Stochastic Approximation (SA) with tapering step sizes
  - Why needed here: SA theory provides the convergence proof with probability one, unlike constant-step FL methods that only converge in expectation.
  - Quick check question: If step sizes decay as $1/n^\delta$ with $\delta > 3/4$, will $\sum a_n^2 < \infty$ hold? (Yes.)

- Concept: Martingale convergence theorem
  - Why needed here: Justifies that the noise term $R_n^{(i)} = \sum_{p=0}^{n-1} a_p M_{p+1}^{(i)}$ converges almost surely, allowing noise to be ignored in the limit.
  - Quick check question: Given $E[M_n|M_{<n}]=0$ and $\sum a_n^2 E[\|M_n\|^2]<\infty$, does $R_n$ converge? (Yes.)

- Concept: ODE approximation for stochastic processes
  - Why needed here: Shows that the discrete update rule asymptotically follows the continuous flow of $\dot{w} = \frac{1}{L}\sum h^{(i)}(w)$, enabling use of stability analysis for convergence.
  - Quick check question: If the ODE has a globally asymptotically stable equilibrium, will the SA iterates converge to it? (Yes.)

## Architecture Onboarding

- Component map:
  - Clients: Each runs a local NN, computes mini-batch gradients, applies SA update $w_{n+1}^{(i)} = w_n^{(i)} + a_n^{(i)} h^{(i)}(w_n^{(i)}) + a_n^{(i)} M_{n+1}^{(i)}$.
  - Server: Aggregates $w_n = \frac{1}{L}\sum w_n^{(i)}$ at multiples of $N$, redistributes to clients.
  - Step-size scheduler: Enforces $a_n^{(i)} = C_i/n^\delta$ with $3/4<\delta\leq1$ and $a_n^{(1)} \geq a_n^{(i)}$ for all $i$.
- Critical path:
  1. Local training: compute mini-batch gradient, apply SA update.
  2. Aggregation: server collects and averages weights.
  3. Reinitialization: each client sets $w_n = \bar{w}_n$ at multiples of $N$.
  4. Convergence: monitor $\|\bar{w}_{n+1} - \bar{w}_n\|$ and test loss.
- Design tradeoffs:
  - Step-size decay rate ($\delta$) vs. convergence speed: smaller $\delta$ → slower decay → faster convergence but higher oscillation.
  - Batch size ($m$) vs. noise: larger $m$ → lower gradient variance → tighter martingale bounds but higher per-round cost.
  - Communication frequency ($N$) vs. stability: larger $N$ → fewer aggregations → more local drift but less communication.
- Failure signatures:
  - Divergence: step sizes not decaying or $\delta \leq 3/4$.
  - Persistent oscillation: step sizes too large, martingale noise dominates.
  - Slow progress: step sizes decay too fast ($\delta$ close to 1), or batch size too small.
  - Bias: data distribution shifts over time, breaking A4 assumptions.
- First 3 experiments:
  1. Run SA-based FL with $N=5$, $m=16$, $\delta=0.8$, compare test loss and accuracy to FedAvg under IID split.
  2. Vary $\delta$ (0.76, 0.85, 0.95) and observe stability/accuracy trade-off under non-IID DIR split.
  3. Fix $\delta=0.8$, increase $N$ (1, 5, 10) to measure impact on convergence and communication cost.

## Open Questions the Paper Calls Out

- Question: Can a convergence rate be established for the proposed stochastic approximation algorithm in federated learning?
  - Basis in paper: [explicit] The paper explicitly states in the conclusion that future work will involve coming up with a convergence rate for the proposed algorithm.
  - Why unresolved: The paper focuses on proving convergence with probability one but does not provide quantitative rates of convergence, which are important for practical deployment and comparison.
  - What evidence would resolve it: A rigorous proof establishing upper bounds on the number of iterations needed to achieve a desired accuracy, along with experimental validation comparing convergence speeds against FedAvg and FedProx.

- Question: How does the algorithm behave under varying client-specific step sizes (i.e., when $a_n^{(i)} \neq a_n^{(j)}$ for clients i and j)?
  - Basis in paper: [explicit] The paper mentions in the conclusion that future work will analyze the algorithm with varying step sizes across clients.
  - Why unresolved: The current analysis assumes a unified step size schedule for all clients, but in practice, clients may have different computational capabilities or data characteristics that could justify individualized step sizes.
  - What evidence would resolve it: Theoretical analysis showing how heterogeneity in step sizes affects convergence and stability, supported by experiments demonstrating improved performance or robustness under non-uniform step sizes.

- Question: What is the impact of client sampling strategies on the algorithm's performance in heterogeneous data settings?
  - Basis in paper: [inferred] While the paper compares performance under IID, DIR, and SC-DIR data splits, it does not explore how different client selection strategies (e.g., random, weighted, or importance-based sampling) affect convergence and accuracy.
  - Why unresolved: The paper assumes all clients participate in each round, but in real-world federated learning, only a subset of clients may be available or selected, which could influence the algorithm's robustness and efficiency.
  - What evidence would resolve it: Experiments comparing convergence and accuracy under various client sampling strategies, along with theoretical insights into how sampling affects the weighting of client gradients in the global model update.

## Limitations

- The convergence proof relies on strict SA conditions that may not hold in real federated settings, particularly the assumption of IID local data and bounded second moments.
- The paper does not address client heterogeneity in computational resources or the impact of client dropout on convergence.
- The influence weights $p^{(i)}$ depend on step-size ratios that may not converge in practice if clients have varying participation patterns or computational delays.

## Confidence

- **High Confidence**: The SA framework correctly establishes almost-sure convergence under stated assumptions; the ODE approximation mechanism is well-established theory.
- **Medium Confidence**: The experimental results demonstrating improved stability and performance under non-IID conditions; the practical impact of the tapering step-size strategy.
- **Low Confidence**: The exact influence weights $p^{(i)}$ in realistic federated settings with client heterogeneity and the practical implications of the theoretical convergence guarantees.

## Next Checks

1. Test the method under realistic client dropout scenarios and measure convergence degradation compared to the theoretical bounds.
2. Implement the SA-based FL with varying participation rates per client and verify whether the step-size ratios $p^{(i)}$ still determine influence as predicted.
3. Compare the sensitivity of SA-based FL to gradient clipping and gradient variance reduction techniques under highly skewed non-IID data distributions.