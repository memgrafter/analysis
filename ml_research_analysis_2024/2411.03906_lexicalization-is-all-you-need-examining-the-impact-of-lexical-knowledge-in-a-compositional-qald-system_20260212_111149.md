---
ver: rpa2
title: 'Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge
  in a Compositional QALD System'
arxiv_id: '2411.03906'
source_url: https://arxiv.org/abs/2411.03906
tags:
- question
- lexical
- knowledge
- language
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines the impact of explicit lexical knowledge on
  Question Answering over Linked Data (QALD) systems. The authors present a novel
  compositional approach that leverages lexical knowledge encoded in Lemon lexicons
  to improve the mapping of natural language questions to SPARQL queries.
---

# Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System

## Quick Facts
- arXiv ID: 2411.03906
- Source URL: https://arxiv.org/abs/2411.03906
- Reference count: 40
- Primary result: 35.8% improvement over state-of-the-art on QALD-9 with micro F1 of 0.72

## Executive Summary
This paper presents a compositional approach to Question Answering over Linked Data (QALD) that leverages explicit lexical knowledge encoded in Lemon lexicons to improve the mapping of natural language questions to SPARQL queries. The system uses dependency parsing, bottom-up semantic composition via Dependency-based Underspecified Discourse Representation Structures (DUDES), and a SPARQL selector to generate and select the best query from multiple candidates. Experiments on the QALD-9 benchmark demonstrate that this approach significantly outperforms state-of-the-art systems, achieving a micro F1 score of 0.72 compared to the previous best of 0.53.

## Method Summary
The compositional QALD system processes natural language questions through a pipeline that begins with dependency parsing using multiple frameworks (SpaCy and Stanza), followed by tree merging rules to create phrases that align with knowledge base elements. The system then matches nodes in the dependency tree to URIs representing entities and properties, creates DUDES for each node, and composes them bottom-up to build a representation of the entire question. This representation is translated into SPARQL queries, and an LLM-based selector chooses the best query from multiple candidates. The approach relies on a manually created Lemon lexicon with 599 entries that maps natural language terms to DBpedia properties, enabling precise disambiguation and reducing the lexical gap between questions and the knowledge base.

## Key Results
- Achieved micro F1 score of 0.72 on QALD-9 benchmark, outperforming state-of-the-art by 35.8%
- System correctly answers 33 additional questions compared to previous best results
- LLMs can benefit from lexical knowledge but lack the compositional reasoning abilities of the proposed approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Explicit lexical knowledge in Lemon lexicons enables precise mapping of natural language terms to knowledge base properties, reducing the lexical gap in QALD.
- Mechanism: The system uses a lexicon that explicitly defines how words in a question map to ontology elements (classes, properties). When a word is encountered, the lexicon provides a set of candidate interpretations, which are then disambiguated during DUDES composition.
- Core assumption: Lexical knowledge can be encoded declaratively in a Lemon lexicon format and will be sufficient to bridge the gap between natural language and SPARQL.
- Evidence anchors:
  - [abstract] "lexicalization, that is explicit knowledge about the potential interpretations of a word with respect to the given vocabulary, significantly eases the task and increases the performance of QA systems."
  - [section 2.1] "A necessary prerequisite for our approach is the availability of a Lemon lexicon [46] that describes by which lexical entries the elements (classes, properties) of a particular knowledge base (KB) can be verbalized in a particular language."
- Break condition: If the lexicon is incomplete or does not cover the vocabulary used in the questions, the mapping will fail and performance will degrade.

### Mechanism 2
- Claim: Dependency parsing combined with tree merging rules creates phrases that align with KB elements, improving entity and property matching.
- Mechanism: The system parses the input question into a dependency tree, then applies merging rules (generic, lexicon marker, entity merging) to combine nodes into phrases that better match KB elements. This reduces ambiguity and improves the chances of correct matching.
- Core assumption: Dependency parsing can generate a tree structure that, when merged appropriately, will yield phrases that correspond to KB elements.
- Evidence anchors:
  - [section 2.3] "we introduce a number of merging rules over the dependency tree to yield phrases that facilitate matching to KB elements."
  - [section 2.4] "Matching nodes in the dependency tree to URIs representing entities and properties (a.k.a. KB Linking ) is a central challenge in our approach."
- Break condition: If the dependency parser generates an incorrect tree, or the merging rules do not align with the actual phrasing in the KB, matching will fail.

### Mechanism 3
- Claim: Bottom-up semantic composition using DUDES allows the system to build complex SPARQL queries from simpler components, enabling handling of complex questions.
- Mechanism: The system represents KB elements as DUDES (Dependency-based Underspecified Discourse Representation Structures), which capture both the meaning of individual elements and their potential combinations. It then composes these DUDES bottom-up to build a representation of the entire question, which is then translated into SPARQL.
- Core assumption: DUDES can effectively represent the meaning of KB elements and their combinations, and that bottom-up composition will yield a correct representation of the question's meaning.
- Evidence anchors:
  - [abstract] "we present a compositional QA system that can leverage explicit lexical knowledge in a compositional manner to infer the meaning of a question in terms of a SPARQL query."
  - [section 2.6] "Now that we have a tree with KB elements (e.g., entities and properties) assigned to the nodes, the next task is to create Dependency-based Underspecified Discourse Representation Structures (DUDES) [10, 14], which are used to compose the atomic meanings of the tree nodes."
- Break condition: If the DUDES composition rules are not sufficient to capture the meaning of the question, or if there are ambiguities that cannot be resolved, the generated SPARQL query will be incorrect.

## Foundational Learning

- Concept: Dependency parsing and tree structures
  - Why needed here: The system relies on a dependency parse of the input question to identify the relationships between words, which are then used to guide the matching of words to KB elements and the composition of DUDES.
  - Quick check question: What is the head of the phrase "birth name of Angela Merkel" in a dependency tree?
- Concept: Lexical knowledge representation (Lemon lexicon)
  - Why needed here: The system uses a Lemon lexicon to encode the mapping between natural language words and KB elements, which is crucial for reducing the lexical gap.
  - Quick check question: What information is typically included in a Lemon lexical entry?
- Concept: Semantic composition and DUDES
  - Why needed here: The system uses DUDES to represent the meaning of KB elements and their combinations, which allows it to build complex SPARQL queries from simpler components.
  - Quick check question: How does the DUDES composition operation work?

## Architecture Onboarding

- Component map: Question -> Dependency parse -> Tree merge -> Ontology match -> Tree score -> DUDES creation -> DUDES composition -> SPARQL generation -> SPARQL selection
- Critical path: Question -> Dependency parse -> Tree merge -> Ontology match -> Tree score -> DUDES creation -> DUDES composition -> SPARQL generation -> SPARQL selection
- Design tradeoffs:
  - Using multiple dependency parsers increases the chance of getting a correct parse, but also increases complexity.
  - Creating a comprehensive Lemon lexicon is time-consuming, but improves performance.
  - Generating multiple candidate SPARQL queries allows for better selection, but increases computation time.
- Failure signatures:
  - Incorrect dependency parse leading to wrong tree structure.
  - Missing or incorrect lexical entries in the lexicon.
  - Ambiguity in DUDES composition that cannot be resolved.
  - LLM-based SPARQL selector failing to choose the correct query.
- First 3 experiments:
  1. Test the dependency parser on a set of simple questions to ensure it generates correct trees.
  2. Test the ontology matcher with a small set of questions and a limited lexicon to verify correct entity and property matching.
  3. Test the DUDES composer with a set of simple DUDES to ensure correct composition.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the manual creation of Lemon lexicons be automated to scale to larger knowledge bases?
- Basis in paper: [explicit] The paper notes that creating the lexicon took approximately 16 hours for 599 entries and suggests future work should focus on automating this process.
- Why unresolved: Manual lexicon creation is time-consuming and doesn't scale well to larger vocabularies or different domains.
- What evidence would resolve it: Successful automated approaches like LexExMachina or M-ATOLL that can generate comprehensive Lemon lexicons with comparable quality to manually created ones.

### Open Question 2
- Question: Can the combinatorial explosion problem be mitigated to improve response times without sacrificing accuracy?
- Basis in paper: [explicit] The paper mentions that combinatorial explosion significantly increases response times when multiple candidate DUDES exist across multiple nodes.
- Why unresolved: The current approach generates many candidate SPARQL queries, leading to long processing times that limit practical deployment.
- What evidence would resolve it: Techniques that reduce the search space while maintaining or improving accuracy, such as more intelligent pruning strategies or early stopping criteria.

### Open Question 3
- Question: How effective would a hybrid system be that combines compositional approaches with LLM generalization abilities?
- Basis in paper: [explicit] The paper suggests this as future work: "development of a hybrid system that combines the benefits of a compositional approach with the generalization abilities of large language models."
- Why unresolved: No empirical evaluation exists of hybrid approaches that leverage both symbolic compositionality and LLM pattern recognition.
- What evidence would resolve it: Comparative studies showing whether hybrid systems outperform either approach alone on complex QALD tasks, particularly for questions requiring both compositional reasoning and generalization.

## Limitations

- Manual lexicon creation is time-consuming and doesn't scale well to larger knowledge bases or different domains
- Combinatorial explosion during DUDES composition significantly increases response times and memory usage
- System performance may degrade if the lexicon is incomplete or doesn't cover the vocabulary used in questions
- Reliance on multiple candidate SPARQL queries and LLM-based selection adds computational overhead

## Confidence

- High confidence in experimental results showing 35.8% improvement over state-of-the-art on QALD-9 benchmark
- Medium confidence in generalizability of results to other datasets and domains due to single benchmark evaluation
- Medium confidence in claimed superiority of explicit lexical knowledge over LLM-based approaches for compositional reasoning, given limited comparison and lack of ablation studies

## Next Checks

1. Test the system on additional QALD benchmarks (QALD-10, QALD-11) to verify performance consistency across different question sets and knowledge bases
2. Conduct ablation studies removing the Lemon lexicon to quantify the exact contribution of explicit lexical knowledge versus compositional reasoning
3. Evaluate runtime efficiency and memory usage during DUDES composition with multiple candidate entities to assess practical deployment feasibility