---
ver: rpa2
title: 'ECLIPSE: Contrastive Dimension Importance Estimation with Pseudo-Irrelevance
  Feedback for Dense Retrieval'
arxiv_id: '2412.14967'
source_url: https://arxiv.org/abs/2412.14967
tags:
- documents
- relevant
- dimensions
- retrieval
- eclipse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ECLIPSE, a novel method for dense retrieval
  that leverages both relevant and irrelevant documents to improve dimension importance
  estimation. ECLIPSE addresses the limitation of existing DIME approaches that rely
  solely on relevant documents, which can introduce noise.
---

# ECLIPSE: Contrastive Dimension Importance Estimation with Pseudo-Irrelevance Feedback for Dense Retrieval

## Quick Facts
- **arXiv ID:** 2412.14967
- **Source URL:** https://arxiv.org/abs/2412.14967
- **Reference count:** 40
- **Key outcome:** ECLIPSE improves dense retrieval by up to 19.50% in mAP(AP) and 11.42% in nDCG@10 compared to DIME-based baselines by leveraging irrelevant documents for dimension importance estimation.

## Executive Summary
ECLIPSE addresses a key limitation in Dimension Importance Estimators (DIMEs) for dense retrieval: the exclusive reliance on relevant documents can introduce noise. The method introduces a contrastive approach by constructing a centroid of irrelevant document embeddings (the "moon") and subtracting it from the relevant document representation (the "sun"). This effectively suppresses non-relevant dimensions while preserving those important for retrieval. Extensive experiments across three in-domain and one out-of-domain benchmarks demonstrate significant improvements over both DIME-based and full-dimensionality baselines, with ECLIPSE achieving up to 22.35% improvement in AP and 13.10% in nDCG@10.

## Method Summary
ECLIPSE is a novel method for dense retrieval that leverages both relevant and irrelevant documents to improve dimension importance estimation. The method retrieves 1,000 documents per query, computes a centroid from the top-k+ relevant documents (sun) and a centroid from the bottom-k- irrelevant documents (moon), then applies a weighted subtraction (α·sun - β·moon) to identify and suppress non-relevant dimensions. The approach can be integrated with any standard DIME and demonstrates consistent performance improvements even when reducing dimensionality by 50%.

## Key Results
- ECLIPSE achieves up to 19.50% improvement in mAP(AP) and 11.42% in nDCG@10 compared to DIME-based baselines
- ECLIPSE outperforms the baseline using all dimensions by 22.35% in AP and 13.10% in nDCG@10
- Performance improvements are maintained even with 50% dimensionality reduction
- Random sampling of irrelevant documents shows no significant difference from exact bottom-k- selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Eclipse improves retrieval by suppressing irrelevant dimensions through contrastive learning with pseudo-irrelevance feedback.
- Mechanism: Constructs a centroid ("moon") from irrelevant document embeddings and subtracts it from the relevant document representation ("sun"), effectively suppressing non-relevant dimensions.
- Core assumption: Irrelevant documents can serve as negative examples that help identify and suppress non-relevant dimensions in the embedding space.
- Evidence anchors:
  - [abstract] "computes a centroid based on irrelevant documents as a reference to estimate noisy dimensions present in relevant ones"
  - [section] "We define a mean vector m, named moon, as an irrelevant representative embedding, aggregating the embeddings of the bottom k- documents"
  - [corpus] Weak evidence - only 2 out of 8 corpus papers explicitly mention pseudo-irrelevance or negative sampling
- Break condition: If irrelevant documents selected are not sufficiently different from relevant ones, the suppression effect diminishes and performance degrades.

### Mechanism 2
- Claim: Eclipse maintains retrieval effectiveness even with reduced dimensionality by preserving the most discriminative dimensions.
- Mechanism: By subtracting the irrelevant centroid, Eclipse creates a residual vector that emphasizes dimensions important for distinguishing relevant from irrelevant documents, allowing more aggressive dimension pruning.
- Core assumption: The contrast between relevant and irrelevant documents highlights dimensions that are truly discriminative for retrieval.
- Evidence anchors:
  - [section] "Table 2 we report the percentage of improvement that LLM Eclipse and PRF Eclipse using half of the embedding dimensions, achieve respectively to LLM DIME and PRF DIME"
  - [section] "Eclipse consistently outperforms the DIMEs baseline, even with reduced dimensionality"
  - [corpus] No direct corpus evidence for dimension importance estimation with irrelevance feedback
- Break condition: If too many dimensions are removed, the model loses sufficient information to distinguish relevant documents.

### Mechanism 3
- Claim: The semantic content of irrelevant documents is not critical; their low relevance scores are what matters.
- Mechanism: Random sampling of documents with low relevance scores from the retrieval results provides similar benefits to carefully selected irrelevant documents.
- Core assumption: The effectiveness comes from using documents that the model itself has determined to be low relevance, not from their semantic properties.
- Evidence anchors:
  - [section] "We designed our experiment as follows: (1) We fixed the collection Dq, with |Dq| = 1000; (2) Instead of selecting the exact bottom-k- documents, we randomly sampled k- documents from the last 30, 100, and 150 documents"
  - [section] "The results indicate no significant difference between randomly sampling irrelevant documents from the lower end of the ranked list and selecting the exact bottom-k- documents"
  - [corpus] No corpus evidence for this specific random sampling approach
- Break condition: If random sampling includes documents that are accidentally relevant or semantically similar to the query, the suppression effect may be weakened.

## Foundational Learning

- **Concept: Dense retrieval and embedding spaces**
  - Why needed here: Understanding how queries and documents are represented as vectors in high-dimensional space is fundamental to grasping why dimension selection matters
  - Quick check question: How does cosine similarity measure relevance between query and document embeddings?

- **Concept: Pseudo-relevance feedback**
  - Why needed here: PRF is the baseline method that Eclipse builds upon, so understanding how top-k documents are assumed relevant is crucial
  - Quick check question: What assumption does PRF make about the top-ranked documents in a retrieval result?

- **Concept: Contrastive learning principles**
  - Why needed here: Eclipse uses a contrastive approach by leveraging both relevant and irrelevant examples, similar to how contrastive learning works in representation learning
  - Quick check question: In contrastive learning, what role do negative examples play compared to positive examples?

## Architecture Onboarding

- **Component map:**
  - Dense retrieval model (ANCE/Contriever/TAS-B) → 768-dimensional embeddings
  - Retrieval step: get top-1000 documents for a query
  - PRF component: compute centroid of top-k+ relevant documents
  - Eclipse component: compute centroid of bottom-k- irrelevant documents
  - Dimension importance estimator: compute weighted difference (α·sun - β·moon)
  - Dimension selector: retain top dimensions based on importance scores
  - Final retrieval: re-rank using selected dimensions

- **Critical path:**
  1. Query → Dense retrieval → Top-1000 documents
  2. Top-k+ documents → PRF centroid (sun)
  3. Bottom-k- documents → Irrelevant centroid (moon)
  4. Compute Eclipse importance scores
  5. Select top dimensions
  6. Re-rank documents using reduced dimensions

- **Design tradeoffs:**
  - k+ vs k-: Higher k+ captures more relevant information but may include noise; higher k- provides better contrast but may include borderline documents
  - α vs β: Balance between emphasizing relevant signal vs suppressing irrelevant signal
  - Dimensionality reduction: More aggressive reduction saves computation but risks losing discriminative power

- **Failure signatures:**
  - Performance degrades when k- is too small (insufficient contrast)
  - Performance drops when α is too high (over-trusts relevant documents)
  - No improvement when k+ is too large (includes too much noise in sun vector)
  - Random sampling fails when irrelevant documents accidentally contain query-relevant content

- **First 3 experiments:**
  1. Run baseline PRF DIME with k+=1, measure AP and nDCG@10
  2. Implement Eclipse with k+=1, k-=5, α=0.5, β=0.5, measure improvement
  3. Test different k- values (2, 5, 10) to find optimal contrast strength

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the traditional sense, but it raises several interesting directions for future research implicitly through its findings and methodology.

## Limitations
- Eclipse requires retrieving 1,000 documents per query, increasing computational overhead compared to standard DIME approaches
- Performance depends critically on the quality of irrelevant document selection; if bottom-k- documents contain borderline relevant content, the suppression effect weakens
- The method's effectiveness on longer documents versus short passages has not been tested, limiting generalizability to document-level retrieval tasks

## Confidence
- **High Confidence**: ECLIPSE consistently outperforms DIME baselines across multiple benchmarks (MS MARCO DL'19/DL'20, DL-HARD, Robust'04) with statistically significant improvements in both AP and nDCG@10 metrics
- **Medium Confidence**: The random sampling experiment showing equivalent performance to exact bottom-k- selection, as this was only tested on two datasets and may be sensitive to dataset characteristics
- **Medium Confidence**: The claim that ECLIPSE can be applied to any standard DIME, as the paper only demonstrates this with PRF and LLM-based DIMEs

## Next Checks
1. Test ECLIPSE's robustness to different irrelevant document selection strategies, including random sampling from different portions of the retrieval list (top 500, middle 500, bottom 500)
2. Evaluate ECLIPSE's performance when the irrelevant document collection contains borderline documents (ranked 900-1000) that may be partially relevant
3. Measure the computational overhead of retrieving 1,000 documents per query and assess whether the performance gains justify the additional cost compared to 100-document retrieval with ECLIPSE