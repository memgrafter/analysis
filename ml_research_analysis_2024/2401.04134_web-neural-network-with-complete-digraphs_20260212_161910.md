---
ver: rpa2
title: Web Neural Network with Complete DiGraphs
arxiv_id: '2401.04134'
source_url: https://arxiv.org/abs/2401.04134
tags:
- neural
- network
- will
- output
- neurons
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a new neural network model, the Web Neural
  Network, which mimics biological brain structure more closely by organizing neurons
  as a complete directed graph with continuous input and output. This model allows
  for cyclical and recursive connections, preserving context across timesteps.
---

# Web Neural Network with Complete DiGraphs

## Quick Facts
- arXiv ID: 2401.04134
- Source URL: https://arxiv.org/abs/2401.04134
- Authors: Frank Li
- Reference count: 6
- Primary result: Novel neural network model with complete directed graph structure achieving 95% MNIST validation accuracy and high accuracy on Titanic dataset

## Executive Summary
This paper introduces the Web Neural Network, a novel neural network architecture that mimics biological brain structure through complete directed graph connectivity. The model processes continuous input and output over multiple timesteps, allowing cyclical and recursive connections that preserve context across time. The architecture is tested on Titanic and MNIST datasets, demonstrating its ability to learn classification processes rather than simply outputting final results.

## Method Summary
The Web Neural Network organizes neurons as a complete directed graph where each neuron connects to every other neuron, enabling cyclical connections that preserve intermediate states across timesteps. The model processes continuous input through vectorized batch operations, reducing computational complexity from O(TQ) to O(T). For MNIST, three convolutional layers preprocess the input before passing flattened features to the web layer. The network is trained using mini-batch SGD with AdamW optimizer and exponential learning rate scheduler.

## Key Results
- Achieved 95% validation accuracy and 94% test accuracy on MNIST dataset
- Demonstrated functional performance on Titanic binary classification task
- Showed incremental classification behavior through prediction history across timesteps
- Validated efficient training through vectorized implementation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuous propagation through a complete digraph allows the model to accumulate evidence over time rather than output a single decision.
- Mechanism: Each neuron at timestep t receives the mean of outputs from all neurons at t-1, propagates this through a linear transformation, and applies non-linearity. This forms a recurrent cycle where intermediate states persist and decay naturally as newer timesteps overwrite them.
- Core assumption: The mean aggregation across all neurons preserves sufficient context for learning classification processes.
- Evidence anchors:
  - [abstract] "continuous input and output, inspired by spiking neural networks, which allows the network to learn a process of classification, rather than simply returning the final result."
  - [section 3.1] "By allowing cyclic and recursive connections, the model can possess contexts of previous timesteps, because the intermediate results of the previous timesteps remain in the web of neurons, and as time passes, data from older timesteps will naturally be overwritten by newer data, hence simulating a decay of knowledge contexts."
  - [corpus] Weak; no direct citations of continuous aggregation in digraph models, but related spiking networks mention temporal state retention.
- Break condition: If the mean aggregation fails to distinguish important signals, the accumulation process degrades and the model reverts to simple feedforward behavior.

### Mechanism 2
- Claim: Vectorized batch multiplication reduces per-timestep complexity from O(TQ) to O(T), enabling practical training on larger webs.
- Mechanism: Instead of looping over each of the Q neurons, a single torch.matmul operation computes all Q outputs in parallel, leveraging GPU parallelism for the full state matrix update.
- Core assumption: The GPU memory can accommodate the (N, Q, Q) tensor required for batch multiplication without prohibitive overhead.
- Evidence anchors:
  - [section 4.2] "we can vectorize the state calculation so we don't have to iterate through the calculation for every node... This reduces the training complexity to O(ET), which showed a significant difference in training time compared to the naive solution when training on the MNIST dataset which used 500 nodes."
  - [corpus] No direct citations; the speedup claim is internal to the paper.
- Break condition: If Q is too large for available GPU memory, the vectorized approach fails and must fall back to the naive loop.

### Mechanism 3
- Claim: Using convolutional layers before the web layer improves MNIST accuracy by providing learned feature maps as continuous inputs.
- Mechanism: Three conv layers extract spatial features; their outputs are flattened and fed into the web layer, which then performs incremental classification over multiple timesteps.
- Core assumption: The web layer can process flattened conv outputs as continuous data without losing spatial relationships encoded by conv layers.
- Evidence anchors:
  - [section 5.2] "For the MNIST dataset, before the web layer, we first used three convolution layers... The model was also functional in this problem; over five epochs, the model was able to reach a validation accuracy of 95% and test accuracy of 94%."
  - [corpus] No citations of conv-to-web pipelines; this is a novel architectural choice.
- Break condition: If conv features are too abstract, the web layer cannot reconstruct class-relevant patterns from flattened input.

## Foundational Learning

- Concept: Complete directed graph connectivity
  - Why needed here: Ensures every neuron can influence every other, enabling cyclic context propagation.
  - Quick check question: What is the edge count in a complete digraph with Q neurons?
    - Answer: Q * (Q - 1) directed edges.

- Concept: Continuous time-series data representation
  - Why needed here: Allows the model to treat outputs as evolving sequences rather than static labels.
  - Quick check question: How does the output shape differ from a standard classifier?
    - Answer: (N, T, O) instead of (N, O), capturing predictions at each timestep.

- Concept: Vectorized batch operations in PyTorch
  - Why needed here: Enables efficient O(T) forward passes despite dense connectivity.
  - Quick check question: Which PyTorch function is used for the vectorized update?
    - Answer: torch.matmul.

## Architecture Onboarding

- Component map: Input preprocessing → Conv stack (optional) → Flatten → Web layer (complete digraph) → Output recording per timestep → Loss over final timestep or sequence
- Critical path: Input → Conv feature extraction (if used) → Flatten → Web state update loop (T steps) → Output neurons → Record predictions → Compute loss → Backprop
- Design tradeoffs: Dense connectivity gives rich context but requires O(Q²) parameters; convolution before web trades spatial structure for feature abstraction; vectorization trades memory for speed
- Failure signatures: Vanishing intermediate activations (network stops evolving), GPU OOM during matmul, training loss plateaus immediately (no learning dynamics), or validation accuracy jumps erratically across timesteps
- First 3 experiments:
  1. Train a minimal web (Q=10, T=5) on synthetic binary data to verify forward pass and loss decrease
  2. Add a single conv layer and test on MNIST digits 0/1 to confirm conv-to-web pipeline works
  3. Increase T and observe prediction history stability to confirm incremental classification behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model perform on continuous data inputs compared to constant inputs?
- Basis in paper: [inferred] The paper states that the model was tested on constant input data stretched over timesteps, but notes that more experiments could be done with actual continuous data like videos and stock data.
- Why unresolved: The current experiments only used constant inputs, not actual continuous data, so the model's effectiveness on real-world continuous data is unknown.
- What evidence would resolve it: Testing the model on datasets with inherently continuous data (e.g., video sequences, time-series financial data) and comparing performance metrics (accuracy, loss, convergence speed) to traditional models.

### Open Question 2
- Question: What is the impact of varying the number of neurons (Q) on model performance and computational efficiency?
- Basis in paper: [explicit] The paper mentions that the computational complexity is O(ETQ) with a large Q, and that Q must be at least I + O, but does not explore the trade-offs between model size and performance.
- Why unresolved: The experiments used fixed Q values (15 for Titanic, 500 for MNIST) without exploring how different sizes affect accuracy, training time, or resource usage.
- What evidence would resolve it: Systematic experiments varying Q across a wide range, measuring accuracy, training time, and GPU/CPU usage to identify optimal sizes for different tasks.

### Open Question 3
- Question: How does the Web Neural Network compare to existing models like LSTMs or transformers in terms of accuracy and training efficiency?
- Basis in paper: [inferred] The paper notes that the experiments could benefit from comparison with existing models but did not include such comparisons due to scope limitations.
- Why unresolved: The paper only compared the model to a vanilla fully-connected network implicitly and did not benchmark against state-of-the-art sequence models.
- What evidence would resolve it: Direct comparisons on the same datasets (Titanic, MNIST, and others) measuring accuracy, training time, number of parameters, and memory usage against LSTMs, transformers, and other competitive models.

## Limitations

- Major uncertainties remain around the efficiency claims without direct GPU memory benchmarks
- Model's scalability to larger Q values is unverified
- Lacks ablation studies isolating the contribution of complete digraph connectivity
- No statistical tests or confidence intervals provided for reported accuracies

## Confidence

- **High** for the architectural description and core forward-pass mechanics
- **Medium** for the vectorized O(T) complexity claim (speedup reported but not independently verified)
- **Low** for the biological plausibility assertion and absence of empirical comparisons to established RNN/CNN baselines

## Next Checks

1. Benchmark training time and memory usage of the vectorized solution against the naive loop for Q ∈ {50, 100, 200} on a fixed GPU
2. Run an ablation: train identical architectures with and without complete digraph connectivity to quantify the marginal benefit
3. Perform statistical significance testing on MNIST accuracy across 5 random seeds to confirm 95% validation accuracy is robust