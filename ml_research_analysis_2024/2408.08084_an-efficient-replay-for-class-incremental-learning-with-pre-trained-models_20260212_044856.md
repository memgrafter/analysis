---
ver: rpa2
title: An Efficient Replay for Class-Incremental Learning with Pre-trained Models
arxiv_id: '2408.08084'
source_url: https://arxiv.org/abs/2408.08084
tags:
- learning
- forgetting
- training
- methods
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in class-incremental
  learning with pre-trained models by observing that weight imbalances across tasks
  are a key cause. It proposes Weight Balancing Replay (WBR), which maintains a single
  memory vector per class and controls gradient updates to balance weight changes
  between old and new tasks during training.
---

# An Efficient Replay for Class-Incremental Learning with Pre-trained Models

## Quick Facts
- arXiv ID: 2408.08084
- Source URL: https://arxiv.org/abs/2408.08084
- Authors: Weimin Yin; Bin Chen; Chunzhao Xie; Zhenhao Tan
- Reference count: 9
- Primary result: WBR outperforms state-of-the-art methods in training efficiency while achieving competitive accuracy with minimal memory requirements

## Executive Summary
This paper addresses catastrophic forgetting in class-incremental learning with pre-trained models by observing that weight imbalances across tasks are a key cause. It proposes Weight Balancing Replay (WBR), which maintains a single memory vector per class and controls gradient updates to balance weight changes between old and new tasks during training. Experiments show WBR significantly outperforms state-of-the-art methods in training efficiency while achieving competitive accuracy, requiring far less memory than traditional sample buffers. Results confirm that balancing weights effectively mitigates forgetting, especially in pre-trained model settings. WBR's low computational cost and minimal memory requirements make it suitable for real-world scenarios with resource constraints.

## Method Summary
WBR is a replay-based method for class-incremental learning that uses pre-trained models. It maintains a single memory vector per class (sampled as class centers from embeddings) instead of storing sample buffers. During training on new tasks, WBR applies different gradient clipping constraints (controlled by α and β) to new task data and memory vectors to explicitly balance weight updates between old and new tasks. The method freezes the pre-trained encoder and only updates the classifier parameters, using cross-entropy loss for both new data and memory vectors.

## Key Results
- WBR achieves competitive accuracy compared to state-of-the-art methods while using significantly less memory
- Training efficiency is substantially improved through gradient balancing
- The weight balancing approach effectively mitigates catastrophic forgetting in pre-trained model settings
- Memory vectors of single sample size replace the need for large sample buffers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Catastrophic forgetting in class-incremental learning with pre-trained models is caused by imbalances in weight updates between old and new tasks.
- Mechanism: WBR maintains a single memory vector per class and uses gradient constraints to balance weight changes between old and new tasks during training.
- Core assumption: Weight imbalance across tasks is a key cause of catastrophic forgetting.
- Evidence anchors:
  - [abstract] "This paper addresses catastrophic forgetting in class-incremental learning with pre-trained models by observing that weight imbalances across tasks are a key cause."
  - [section] "We designed a balancing mechanism using two hyper-parameters to explicitly control the gradient update of new task data and memory vectors during training."

### Mechanism 2
- Claim: Using compressed memory vectors instead of sample buffers can effectively mitigate forgetting while significantly reducing memory requirements.
- Mechanism: WBR samples memory vectors from all samples within a task (similar to class centers) and uses these vectors to guide balanced fine-tuning during new task training.
- Core assumption: A single memory vector per class can adequately represent the class distribution for replay purposes.
- Evidence anchors:
  - [abstract] "WBR significantly outperforms state-of-the-art methods in training efficiency while achieving competitive accuracy, requiring far less memory than traditional sample buffers."
  - [section] "By controlling the gradient update size, WBR balances the changes in weights between new and old tasks during training, using a memory vector of a single sample size instead of a sample buffer."

### Mechanism 3
- Claim: Balancing weight updates during training can prevent overfitting to new tasks and maintain performance on old tasks.
- Mechanism: WBR uses gradient clipping with different constraints for new task data and memory vectors to explicitly control the magnitude of weight updates.
- Core assumption: Controlling the gradient update size can effectively balance learning new information while retaining old knowledge.
- Evidence anchors:
  - [abstract] "Results confirm that balancing weights effectively mitigates forgetting, especially in pre-trained model settings."
  - [section] "The weight balancing constraint the optimization, allowing new knowledge and old knowledge to integrate rather than experiencing catastrophic forgetting."

## Foundational Learning

- Concept: Class-incremental learning
  - Why needed here: WBR is specifically designed for class-incremental learning scenarios where models must learn new classes while retaining knowledge of old classes.
  - Quick check question: What is the difference between class-incremental learning and task-incremental learning?

- Concept: Catastrophic forgetting
  - Why needed here: Understanding catastrophic forgetting is crucial to grasp why WBR's weight balancing approach is effective.
  - Quick check question: What causes catastrophic forgetting in neural networks during continual learning?

- Concept: Gradient descent and backpropagation
  - Why needed here: WBR's mechanism relies on controlling gradient updates during training, so understanding how gradients work is essential.
  - Quick check question: How do gradient updates during backpropagation contribute to weight changes in neural networks?

## Architecture Onboarding

- Component map:
  - Pre-trained encoder (frozen) -> Classifier/Decoder (trainable) -> Memory vectors (non-trainable, one per class) -> Gradient clipping mechanism (α and β parameters)

- Critical path:
  1. Initialize WBR with pre-trained encoder and classifier
  2. For each new task: Sample memory vectors from current task data, update memory pool with new vectors, train classifier on new task data with gradient clipping, train classifier on memory vectors with different gradient clipping
  3. Store updated memory vectors after each task; repeat for all tasks; evaluate AB and Ā after each task

- Design tradeoffs:
  - Memory vs. performance: Using single vectors per class significantly reduces memory but may lose some information compared to full sample buffers
  - Training efficiency vs. accuracy: Gradient clipping speeds up training but requires careful tuning of α and β
  - Simplicity vs. effectiveness: WBR's simple approach works well but may not capture complex forgetting patterns

- Failure signatures:
  - Poor performance on old tasks: Indicates insufficient weight balancing or inadequate memory vector representation
  - Slow learning of new tasks: Suggests gradient constraints are too restrictive
  - Memory vector quality issues: If sampled vectors don't represent class distributions well

- First 3 experiments:
  1. Test WBR on a simple dataset (e.g., split MNIST) with varying α and β values to find optimal balance
  2. Compare WBR's performance with and without memory vectors on a small-scale class-incremental benchmark
  3. Measure the impact of different memory vector sampling strategies (e.g., class center vs. confidence-weighted) on final accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the weight balancing mechanism generalize to deeper networks beyond MLPs, such as CNNs and Transformers?
- Basis in paper: [inferred] The authors note that "with increasing network depth, the influence of the memory vector from the first layer on the subsequent layers weakens," suggesting limitations in deeper architectures.
- Why unresolved: The paper only demonstrates the effectiveness of WBR in MLP architectures and acknowledges the challenge of applying it to deeper models like CNNs and Transformers.
- What evidence would resolve it: Experimental results showing WBR's performance on deeper architectures like CNNs or Transformers in class-incremental learning tasks.

### Open Question 2
- Question: How does the choice of importance function affect the effectiveness of WBR in mitigating catastrophic forgetting?
- Basis in paper: [explicit] The authors compare average sampling with confidence-weighted sampling (herding strategy) and find only a 1% improvement with the latter, but suggest more exploration is needed.
- Why unresolved: While the authors tested two importance functions, they do not explore a wider range of options or analyze the sensitivity of WBR to different importance functions.
- What evidence would resolve it: Systematic experiments comparing WBR's performance using various importance functions and analyzing their impact on forgetting and learning efficiency.

### Open Question 3
- Question: Can WBR be integrated with other continual learning techniques, such as knowledge distillation or architectural expansion, to further improve performance?
- Basis in paper: [inferred] The authors discuss various continual learning methods (sample buffer-based, architecture-based, pretrained model-based) and suggest that WBR offers a unique approach by directly adjusting classifier weights without post-processing.
- Why unresolved: The paper focuses on WBR as a standalone method and does not explore its potential synergies with other continual learning techniques.
- What evidence would resolve it: Experiments combining WBR with other methods (e.g., knowledge distillation, architectural expansion) and evaluating the resulting performance improvements in class-incremental learning tasks.

## Limitations
- The weight imbalance hypothesis, while intuitively compelling, lacks direct empirical validation as the root cause of catastrophic forgetting.
- Single memory vector per class representation may be insufficient for complex, multimodal class distributions.
- Claims about WBR being state-of-the-art are based on comparisons with older methods and need updated benchmarks.

## Confidence
- **High Confidence**: WBR's computational efficiency and memory reduction claims are well-supported by the architecture and implementation details provided.
- **Medium Confidence**: The core mechanism of gradient balancing is sound, but the specific causal relationship between weight imbalance and catastrophic forgetting needs further validation.
- **Low Confidence**: Claims about WBR being state-of-the-art require updated comparisons with recent methods to be fully credible.

## Next Checks
1. Design an experiment to directly measure weight changes across tasks with and without gradient balancing to establish whether weight imbalance is indeed the primary driver of forgetting.
2. Evaluate different memory vector sampling strategies (e.g., confidence-weighted, k-means centroids, exemplar-based) on datasets with known complex class structures to determine if single vectors are sufficient.
3. Compare WBR against the most recent class-incremental learning methods that use advanced replay mechanisms, memory-efficient sampling, or generative approaches to validate the "state-of-the-art" claims.