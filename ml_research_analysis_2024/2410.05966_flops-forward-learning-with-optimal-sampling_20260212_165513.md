---
ver: rpa2
title: 'FLOPS: Forward Learning with OPtimal Sampling'
arxiv_id: '2410.05966'
source_url: https://arxiv.org/abs/2410.05966
tags:
- uni00000013
- uni00000011
- uni0000004c
- uni00000003
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the inefficiency of forward learning methods,
  which rely on perturbation-based gradient estimation and often allocate equal queries
  to all data points, leading to high computational costs. The authors propose FLOPS,
  a method that optimally allocates queries to different data points based on their
  gradient estimation difficulty, using a likelihood ratio-based approach with a reparameterized
  Gaussian allocator.
---

# FLOPS: Forward Learning with OPtimal Sampling

## Quick Facts
- arXiv ID: 2410.05966
- Source URL: https://arxiv.org/abs/2410.05966
- Reference count: 40
- Primary result: Achieves state-of-the-art forward learning performance with as few as 20 queries per data point

## Executive Summary
This paper addresses the computational inefficiency of forward learning methods, which rely on perturbation-based gradient estimation and often allocate equal queries to all data points. The authors propose FLOPS (Forward Learning with OPtimal Sampling), a method that optimally allocates queries to different data points based on their gradient estimation difficulty. By using a likelihood ratio-based approach with a reparameterized Gaussian allocator, FLOPS significantly reduces the required number of queries while maintaining accuracy. The method demonstrates substantial improvements in fine-tuning Vision Transformers on multiple datasets and shows promise in black-box applications like prompt tuning and multimodal model alignment.

## Method Summary
FLOPS improves forward learning efficiency by optimally allocating a limited query budget across data points based on their gradient estimation difficulty. The method uses a likelihood ratio approach to maximize a lower bound on performance improvement by minimizing the sum of gradient estimation variances weighted by allocated queries. The authors introduce a reparameterized Gaussian allocator with linear mean structure based on loss values and RBF covariance based on cosine similarity, reducing optimization dimensionality. Theoretical analysis guarantees the optimality of this allocation strategy, and experiments demonstrate significant improvements in both image classification tasks and black-box applications while maintaining scalability.

## Key Results
- Reduces required queries to 20 per data point while maintaining accuracy
- Achieves state-of-the-art performance in fine-tuning Vision Transformers
- Demonstrates effectiveness in black-box applications including prompt tuning and multimodal alignment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Allocating more queries to data points with higher gradient variance reduces overall training variance more efficiently than uniform allocation.
- Mechanism: Uses likelihood ratio method to maximize lower bound by minimizing sum of trace(Σ_j^t G / A_j) across data points.
- Core assumption: Gradient estimator for each data point approximately follows Gaussian distribution with estimable covariance.
- Evidence anchors:
  - [abstract]: "allocate the optimal number of queries over each data in one batch during training to achieve a good balance between estimation accuracy and computational efficiency"
  - [section 4.2]: "maximizing the lower bound LBt(λ) over λ ∈ Λ is equivalent to minimizing Jt(λ) ≜ EA∼P(·|λ) [Σj,tG / Aj]"
  - [corpus]: Weak - related papers focus on variance reduction in sampling but not on perturbation-based forward learning allocation
- Break condition: If gradient estimation distribution deviates significantly from Gaussian or covariance estimation becomes unreliable.

### Mechanism 2
- Claim: Reparameterizing Gaussian allocator with linear mean structure and RBF covariance improves scalability.
- Mechanism: Mean μ = β0 + β1Φ uses clean loss values as features, covariance Σ(i,j) = σ² exp(-dᵢ,ⱼ/2γ²) captures similarity through cosine similarity of embeddings.
- Core assumption: Similar data points have similar gradient estimation difficulties, and loss values are good proxies for this difficulty.
- Evidence anchors:
  - [section 4.3]: "the loss value serves as a strong indicator of the data point's characteristics" and "similar data may have similar influences on the training"
  - [section 5.4]: "the ablation on different transformer layers indicates that the variance of the gradient increases as the layer goes deeper"
  - [corpus]: Weak - no direct corpus evidence for loss-based allocator reparameterization in forward learning context
- Break condition: If data point similarities do not correlate with gradient estimation difficulty or loss values become poor indicators.

### Mechanism 3
- Claim: Optimal allocator provides theoretical guarantees through lower bound on cumulative performance improvement.
- Mechanism: Theorem 2 shows difference in lower bounds between optimal and equal allocation is at least Σt η²tL/2BA₀ Σj<k (√Tr(Σj,tG) - √Tr(Σk,tG))².
- Core assumption: L-smoothness of loss functions and convexity of parameter space allow derivation of this lower bound.
- Evidence anchors:
  - [section 4.2]: "Theorem 2 (Theoretical Improvement)" and derivation showing lower bound difference
  - [section 5.4]: "When the number of queries per data is small, the benefit from the allocation is still non-ignorable"
  - [corpus]: Weak - related papers on adaptive sampling don't provide similar theoretical guarantees for perturbation-based methods
- Break condition: If loss functions become non-smooth or optimization landscape changes dramatically during training.

## Foundational Learning

- Concept: Monte Carlo gradient estimation in high-dimensional spaces
  - Why needed here: Forward learning relies on estimating gradients through Monte Carlo sampling of perturbations, requiring understanding of how query allocation affects estimation variance
  - Quick check question: How does the variance of a Monte Carlo estimator scale with the number of samples, and what are the implications for query allocation?

- Concept: Likelihood ratio gradient estimation
  - Why needed here: The optimal allocator uses likelihood ratio methods to estimate gradients with respect to allocation parameters
  - Quick check question: What is the relationship between the likelihood ratio estimator and the score function in importance sampling?

- Concept: Gaussian process regression and kernel methods
  - Why needed here: The reparameterized covariance structure uses RBF kernels based on data similarity
  - Quick check question: How does the choice of kernel affect the smoothness and generalization properties of the resulting model?

## Architecture Onboarding

- Component map:
  - Target module φ(·; θ) -> Black-box modules ϕ₁(·) and ϕ₂(·) -> Allocator P(A|λ; Φ) -> Perturbation module -> Evaluation module

- Critical path:
  1. Compute clean losses Φ for the mini-batch
  2. Estimate gradient variances Tr(Σj,tG) using initial queries
  3. Optimize allocator parameters λ using likelihood ratio gradients
  4. Sample query allocation A ∼ P(A|λ, Φ)
  5. Perform perturbation-based gradient estimation with allocated queries
  6. Update network parameters θ using estimated gradients

- Design tradeoffs:
  - Query budget vs. estimation accuracy: More queries per data point reduce variance but increase computational cost
  - Allocator complexity vs. scalability: Gaussian allocator with full covariance captures data relationships but increases parameter count
  - Reparameterization vs. flexibility: Linear mean structure is efficient but may miss complex relationships
  - Initial variance estimation vs. allocation quality: Better variance estimates lead to better allocations but require more initial queries

- Failure signatures:
  - High variance in gradient estimates despite sufficient queries: Indicates poor allocator performance or violation of Gaussian assumption
  - Oscillating training loss: May indicate unstable allocator optimization or poor reparameterization
  - Slow convergence despite optimal allocation: Could indicate that the lower bound is not tight or that other factors dominate training dynamics
  - Memory overflow: Excessive query allocation or poor variance estimation leading to over-allocation

- First 3 experiments:
  1. Compare uniform allocation vs. optimal allocation on a simple MLP with synthetic data to verify variance reduction
  2. Test different allocator parameterizations (Gaussian vs. Bernoulli) on a small Vision Transformer to evaluate trade-offs
  3. Evaluate robustness of the allocator under different noise distributions and loss landscapes to test theoretical assumptions

## Open Questions the Paper Calls Out
The paper mentions that "While our method significantly improves scalability, closing the gap with backpropagation remains an open challenge for future research" regarding scaling to extremely large models with billions of parameters. The paper also notes that the perturbation-based framework can use different gradient estimators beyond the Gaussian and Bernoulli allocators evaluated, suggesting potential for exploring other noise distributions. Additionally, while specific hyperparameters are mentioned (learning rate of 1×10^-4, batch size of 128), the paper does not provide sensitivity analysis or guidelines for hyperparameter tuning across different tasks and datasets.

## Limitations
- Gaussian assumption for gradient estimation distributions may not hold in all scenarios
- Computational overhead of maintaining and optimizing allocator parameters could become prohibitive for very large batch sizes
- Focus on image classification and two specific black-box applications limits generalizability to other domains

## Confidence
- Core claims about query allocation optimality: High
- Scalability improvements in black-box applications: Medium
- Theoretical guarantees under all conditions: Low

## Next Checks
1. Verify variance reduction by comparing uniform vs. optimal allocation on synthetic data with known gradient distributions
2. Test allocator robustness across different noise distributions (uniform, Laplace) beyond Gaussian and Bernoulli
3. Measure computational overhead of allocator optimization on large batch sizes to validate scalability claims