---
ver: rpa2
title: 'Judgment-of-Thought Prompting: A Courtroom-Inspired Framework for Binary Logical
  Reasoning with Large Language Models'
arxiv_id: '2409.16635'
source_url: https://arxiv.org/abs/2409.16635
tags:
- reasoning
- logical
- tasks
- judge
- prompting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Judgment of Thought (JoT), a novel prompting\
  \ framework designed to enhance binary logical reasoning in large language models.\
  \ JoT uses a multi-agent approach with three specialized roles\u2014lawyer, prosecutor,\
  \ and judge\u2014where a higher-level model acts as judge and lower-level models\
  \ serve as lawyer and prosecutor."
---

# Judgment-of-Thought Prompting: A Courtroom-Inspired Framework for Binary Logical Reasoning with Large Language Models

## Quick Facts
- arXiv ID: 2409.16635
- Source URL: https://arxiv.org/abs/2409.16635
- Authors: Sungjune Park; Heehwan Kim; Haehyun Cho; Daeseon Choi
- Reference count: 20
- One-line primary result: Novel multi-agent prompting framework achieves 98% accuracy on Boolean expressions and 88% on Navigate benchmark

## Executive Summary
This paper introduces Judgment of Thought (JoT), a novel prompting framework designed to enhance binary logical reasoning in large language models. JoT uses a multi-agent approach with three specialized roles—lawyer, prosecutor, and judge—where a higher-level model acts as judge and lower-level models serve as lawyer and prosecutor. These roles engage in structured, iterative debates to evaluate arguments and deliver a final judgment. Evaluations on benchmarks like BigBenchHard and Winogrande show that JoT significantly outperforms existing methods, achieving 98% accuracy on Boolean expressions, 90% on Web of Lies, and 88% on Navigate. Ablation studies confirm that all components of JoT contribute to its strong performance, demonstrating its effectiveness in improving accuracy, reliability, and interpretability in binary reasoning tasks.

## Method Summary
The Judgment of Thought (JoT) framework employs a multi-agent approach where three specialized roles—lawyer, prosecutor, and judge—engage in structured, iterative debates to evaluate arguments and deliver a final judgment. The lawyer argues for the True position while the prosecutor argues for the False position, both using lower-level models. A higher-level model serves as the judge, evaluating arguments for logical coherence and providing structured feedback. This feedback loop allows lawyer and prosecutor to refine their arguments iteratively. The framework was evaluated on binary logical reasoning tasks using the BigBenchHard and Winogrande benchmarks, comparing performance against baseline methods including Zero-shot, Few-shot, Chain-of-Thought, Self-Consistency, and Debate approaches.

## Key Results
- Achieves 98% accuracy on Boolean expression evaluation, significantly outperforming baseline methods
- Demonstrates 90% accuracy on Web of Lies and 88% on Navigate benchmark tasks
- Ablation studies confirm all JoT components contribute to performance gains

## Why This Works (Mechanism)

### Mechanism 1: Adversarial Reasoning via Role Specialization
- Claim: Assigning distinct roles (lawyer, prosecutor, judge) reduces bias and ensures balanced consideration of both sides in binary tasks.
- Mechanism: Each role is explicitly instructed to advocate for a specific position (True/False), forcing the model to generate arguments from both perspectives rather than defaulting to a single viewpoint.
- Core assumption: Clear role definitions prevent overlap in argumentative responsibilities and promote structured, logical discourse.
- Evidence anchors: [abstract]: "JoT introduces a multi-agent approach with three specialized roles—lawyer, prosecutor, and judge—where a high-level model acts as the judge, and lower-level models serve as lawyer and prosecutor to systematically debate and evaluate arguments." [section 3]: "JoT mimics deliberative human reasoning (e.g., legal or debate settings) to support more intuitive, transparent, and trustworthy decision-making for end users."

### Mechanism 2: Iterative Refinement with Judge Feedback
- Claim: Multi-round feedback loops allow arguments to evolve and strengthen over time, improving reasoning quality.
- Mechanism: After initial arguments are presented, the judge evaluates and provides feedback highlighting strengths and weaknesses. Lawyer and prosecutor then refine their arguments based on this feedback and the opponent's reasoning.
- Core assumption: Models can incorporate feedback to correct logical gaps and improve argumentative depth.
- Evidence anchors: [abstract]: "Experimental evaluations on benchmarks such as BigBenchHard and Winogrande demonstrate JoT's superior performance compared to existing prompting approaches, achieving notable improvements..." [section 3]: "These refined arguments are again presented to the judge for further evaluation. This loop continues iteratively, allowing the judge to progressively identify the most logically robust arguments."

### Mechanism 3: Structured Logical Coherence Evaluation
- Claim: The judge critically evaluates arguments based on logical coherence and argumentation quality, ensuring decisions are based on reasoning strength.
- Mechanism: The judge analyzes input along with both sides' arguments, evaluates which is more logically convincing, and provides structured feedback explaining the decision.
- Core assumption: A higher-level model acting as judge can reliably assess logical validity and argumentation quality.
- Evidence anchors: [abstract]: "The judge then analyzes the logical coherence with the provided arguments and gives feedback highlighting their strengths and weaknesses." [section 3]: "The judge then analyzes the logical coherence with the provided arguments and gives feedback highlighting their strengths and weaknesses."

## Foundational Learning

- Concept: Role-based multi-agent prompting
  - Why needed here: To ensure balanced, adversarial reasoning where each agent has a clear responsibility for argumentation.
  - Quick check question: What are the three distinct roles in JoT, and what is each role's primary responsibility?

- Concept: Iterative feedback loops in reasoning
  - Why needed here: To allow arguments to evolve and improve through multiple rounds of evaluation and refinement.
  - Quick check question: How many opportunities does each role have to speak in JoT, and what is the purpose of each utterance?

- Concept: Logical coherence evaluation
  - Why needed here: To ensure the final decision is based on the strength of reasoning rather than persuasive language alone.
  - Quick check question: What must the judge do to maintain neutrality and objectivity when evaluating arguments?

## Architecture Onboarding

- Component map: Input -> Lawyer (True) + Prosecutor (False) -> Judge -> Feedback -> Refined Arguments -> Judge -> Final Decision

- Critical path:
  1. Input is presented to lawyer and prosecutor
  2. Both generate initial arguments
  3. Judge evaluates arguments and provides feedback
  4. Lawyer and prosecutor refine arguments based on feedback
  5. Judge evaluates refined arguments and delivers final decision

- Design tradeoffs:
  - Using lower-level models for lawyer/prosecutor reduces cost but may limit argument sophistication
  - Using higher-level model for judge improves evaluation quality but increases computational cost
  - Fixed number of iterations balances thoroughness with efficiency

- Failure signatures:
  - If roles overlap in argumentative responsibilities, arguments become redundant
  - If feedback is too generic, iterative refinement has minimal impact
  - If judge model is not sufficiently capable, it may favor persuasive but logically flawed arguments

- First 3 experiments:
  1. Test with symmetric role assignments (both lawyer and prosecutor using same model) to verify adversarial reasoning requirement
  2. Vary the number of iterations (1, 3, 5) to measure impact on performance across different task types
  3. Remove judge feedback to isolate the contribution of iterative refinement to overall performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does JoT perform on real-world tasks involving incomplete, noisy, or ambiguous data compared to controlled benchmark datasets?
- Basis in paper: [inferred] The paper explicitly acknowledges that real-world scenarios differ from controlled benchmarks and that JoT's effectiveness in such settings remains uncertain.
- Why unresolved: The evaluation was limited to controlled datasets (BigBenchHard and Winogrande), which do not fully represent the complexity and unpredictability of real-world data.
- What evidence would resolve it: Empirical studies testing JoT on real-world datasets with incomplete, noisy, or ambiguous inputs, along with performance comparisons to existing methods in such contexts.

### Open Question 2
- Question: How does JoT's computational efficiency compare to existing prompting methods when deployed at scale in real-time applications?
- Basis in paper: [inferred] The paper notes that JoT is computationally intensive due to its multi-agent approach with iterative loops, which could limit its applicability in resource-constrained environments.
- Why unresolved: The paper does not provide a detailed analysis of JoT's computational cost relative to other methods or its feasibility for real-time deployment.
- What evidence would resolve it: Comparative studies measuring JoT's runtime, resource usage, and scalability against other prompting methods in large-scale or real-time scenarios.

### Open Question 3
- Question: Can JoT's feedback mechanism be improved by incorporating adaptive or memory-augmented strategies to enhance reasoning quality?
- Basis in paper: [explicit] The paper discusses the potential for improving JoT's feedback mechanism by making it more adaptive or incorporating memory-augmented feedback to track inconsistencies across iterations.
- Why unresolved: The current feedback mechanism is rule-based and static, and the paper does not provide experimental validation of adaptive or memory-augmented feedback strategies.
- What evidence would resolve it: Experimental results comparing JoT's performance with and without adaptive or memory-augmented feedback mechanisms across various reasoning tasks.

## Limitations

- Limited role definition details create uncertainty about maintaining clear boundaries between lawyer, prosecutor, and judge responsibilities
- Assumes higher-level judge model can reliably distinguish between logically sound and merely persuasive arguments, without addressing potential model limitations
- Framework is specifically designed for binary reasoning tasks, with unclear generalization to multi-option or open-ended logical problems

## Confidence

- High Confidence: The framework's core concept of using role-based multi-agent prompting for adversarial reasoning is well-founded and the reported performance improvements on binary logical reasoning tasks are substantial and statistically significant across multiple benchmarks.
- Medium Confidence: The iterative refinement mechanism is supported by the results, but the extent to which the judge's feedback actually improves reasoning quality versus simply extending the prompt chain is not fully established.
- Low Confidence: The paper does not adequately address potential failure modes related to judge model limitations or how to ensure the judge maintains true logical objectivity rather than being influenced by rhetorical quality.

## Next Checks

1. **Judge Capability Validation**: Design an experiment where the judge model is tested on its ability to distinguish between logically sound and logically flawed arguments that are equally persuasive in presentation. This would verify whether the judge is actually evaluating logical coherence rather than argument quality.

2. **Role Overlap Assessment**: Implement a variant where lawyer and prosecutor roles use identical models and prompts (removing adversarial specialization) to quantify how much of JoT's performance gain comes specifically from role-based adversarial reasoning versus the general prompting approach.

3. **Iteration Efficiency Analysis**: Systematically vary the number of iterative rounds (1, 3, 5, 7) across different task types to determine the point of diminishing returns and identify which tasks benefit most from extended refinement versus those that reach optimal reasoning quality quickly.