---
ver: rpa2
title: 'Electrocardiogram-based diagnosis of liver diseases: an externally validated
  and explainable machine learning approach'
arxiv_id: '2412.03717'
source_url: https://arxiv.org/abs/2412.03717
tags:
- liver
- hepatic
- failure
- disease
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Liver diseases require costly, invasive diagnostics and are a major
  global health challenge. This study developed tree-based machine learning models
  using ECG features and demographics to detect liver diseases.
---

# Electrocardiogram-based diagnosis of liver diseases: an externally validated and explainable machine learning approach

## Quick Facts
- arXiv ID: 2412.03717
- Source URL: https://arxiv.org/abs/2412.03717
- Reference count: 40
- Key outcome: ECG-based ML models achieved AUROCs of 0.8025 (internal) and 0.7644 (external) for alcoholic liver disease detection, with age and QTc prolongation as key predictors

## Executive Summary
This study developed tree-based machine learning models using ECG features and demographics to detect liver diseases, addressing the need for non-invasive, cost-effective diagnostics. Models were trained on 467,729 patients from MIMIC-IV-ECG and externally validated on 775,535 patients from ECG-View II. Performance was evaluated using AUROC, with alcoholic liver disease (K70) achieving AUROCs of 0.8025 internally and 0.7644 externally, and hepatic failure (K72) achieving 0.7404 internally and 0.7498 externally. Explainability analysis consistently identified age and prolonged QTc intervals as key predictors, supporting the physiological connection between liver dysfunction and cardiac electrophysiology.

## Method Summary
Tree-based machine learning models (XGBoost) were trained to detect liver diseases using ECG features (RR, PR, QRS, QT, QTc intervals, P/QRS/T wave axes) and demographics (sex, age). The study used MIMIC-IV-ECG (467,729 patients, 2008–2019) for training and ECG-View II (775,535 patients, 1994–2013) for external validation. Models were trained per ICD-10 liver disease code with early stopping (patience of 10) and evaluated using AUROC, sensitivity, and specificity at a fixed threshold of 0.70. Shapley values provided interpretability by quantifying each feature's contribution to predictions.

## Key Results
- Alcoholic liver disease (K70): AUROC 0.8025 (internal), 0.7644 (external)
- Hepatic failure (K72): AUROC 0.7404 (internal), 0.7498 (external)
- Age and QTc prolongation consistently identified as top predictors across models
- External validation confirmed model generalizability with modest performance drop

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ECG-derived features can detect liver disease because shared cardiovascular-hepatic pathophysiology produces measurable cardiac electrical changes.
- Mechanism: Liver dysfunction disrupts systemic homeostasis through inflammation, electrolyte imbalance, and autonomic dysregulation, altering cardiac electrophysiology captured in ECG metrics like QTc prolongation.
- Core assumption: Cardiac manifestations of liver disease are consistent and detectable via standard ECG features without requiring raw waveform analysis.
- Evidence anchors:
  - "Features linked to autonomic regulation and electrical conduction abnormalities were also prominent, supporting known cardiovascular-liver connections and suggesting QTc as a potential biomarker."
  - "The interplay between liver and cardiovascular health is well-established. Liver diseases often manifest with cardiovascular complications such as cirrhosis-associated cardiomyopathy and portopulmonary hypertension [10]."
- Break condition: If liver disease effects on ECG are too variable across patient populations, or if confounding factors overwhelm the liver-specific signal.

### Mechanism 2
- Claim: Tree-based models with interpretable Shapley values provide both strong predictive performance and actionable clinical insights.
- Mechanism: Gradient boosting aggregates simple decision rules capturing non-linear relationships between ECG features and liver disease, while Shapley values quantify each feature's marginal contribution to predictions.
- Core assumption: Tree-based models can generalize across diverse populations when trained on large, representative datasets.
- Evidence anchors:
  - "The explainability analysis consistently identified age and prolonged QTc intervals (corrected QT, reflecting ventricular repolarization) as key predictors."
  - "We aim to go beyond a performance evaluation by providing insights into the trained models. To this end, we integrate Shapley values into our pipeline [27]."
- Break condition: If model performance degrades significantly in populations not well-represented in training data.

### Mechanism 3
- Claim: External validation on independent datasets ensures the model's robustness and clinical generalizability.
- Mechanism: Training on MIMIC-IV-ECG and validating on ECG-View II (different geography, timeframe) tests whether ECG-liver disease associations hold beyond a single institution or cohort.
- Core assumption: Both datasets use comparable ECG feature extraction and ICD coding standards, allowing fair comparison.
- Evidence anchors:
  - "We trained tree-based machine learning models on ECG features to detect liver diseases using two large datasets: MIMIC-IV-ECG (467,729 patients, 2008–2019) and ECG-View II (775,535 patients, 1994–2013)."
- Break condition: If the external dataset's population characteristics or measurement protocols differ enough to invalidate direct performance comparison.

## Foundational Learning

- Concept: ECG feature engineering (RR, PR, QRS, QT, QTc intervals; P/QRS/T wave axes)
  - Why needed here: The study uses pre-computed ECG metrics as inputs; understanding what each feature captures is critical for interpreting model decisions and physiological relevance.
  - Quick check question: What does QTc prolongation typically indicate in the context of liver disease, and why is it a key predictor here?

- Concept: Explainable AI with Shapley values
  - Why needed here: The study's novelty relies on interpretability; engineers must understand how Shapley values decompose feature contributions for clinical trust.
  - Quick check question: How does a Shapley value differ from simple feature importance, and why is it more suitable for tree-based models in healthcare?

- Concept: External validation and generalization
  - Why needed here: The model's real-world utility depends on performance beyond the training set; engineers must grasp how to design and interpret external validation.
  - Quick check question: What are the key risks when validating on an external dataset, and how can they be mitigated?

## Architecture Onboarding

- Component map: Data ingestion -> ECG feature extraction -> Dataset splitting (train/val/test + external) -> XGBoost training with early stopping -> Shapley value analysis -> Performance reporting
- Critical path:
  1. Load MIMIC-IV-ECG and ECG-View II datasets
  2. Align feature sets and ensure consistent QTc calculation (Bazett's formula)
  3. Train XGBoost models per ICD code with early stopping
  4. Generate predictions on internal and external test sets
  5. Compute AUROC, sensitivity, specificity
  6. Run Shapley analysis for interpretability
- Design tradeoffs:
  - Tree-based vs. deep learning: Better interpretability and robustness on tabular data vs. potential higher accuracy with raw waveforms
  - Combined features vs. ECG alone: Improved performance but added demographic confounders
  - Early stopping patience: Balances overfitting risk vs. model convergence
- Failure signatures:
  - AUROC drop >0.05 in external validation: Possible distribution shift or feature misalignment
  - Shapley values dominated by non-ECG features: Demographics may be confounding predictions
  - High variance in prediction intervals: Overfitting or insufficient data per condition
- First 3 experiments:
  1. Train XGBoost on MIMIC-IV-ECG ECG features only; compare AUROC to combined model
  2. Replicate Shapley analysis on a single condition (e.g., K70) and verify top features match paper
  3. Test model performance on a subset of ECG-View II stratified by age/gender to check demographic effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do ECG-derived features maintain diagnostic accuracy across diverse ethnic populations beyond the U.S. and South Korean cohorts studied?
- Basis in paper: The authors note that MIMIC-IV-ECG provides more ethnically diverse data than ECG-View II, but neither dataset includes race data, and the study's external validation was limited to a South Korean population.
- Why unresolved: The study lacks racial/ethnic diversity in its validation dataset, which is crucial for generalizability of the diagnostic tool across global populations.
- What evidence would resolve it: External validation studies using ECG datasets from diverse ethnic populations (e.g., African, European, South Asian, Latin American cohorts) would demonstrate whether the model maintains predictive performance across different racial and ethnic groups.

### Open Question 2
- Question: Can ECG-based liver disease detection be improved by incorporating raw ECG waveform data instead of extracted features?
- Basis in paper: The authors note that "recent findings on the superiority of raw ECG waveforms compared to ECG features for diagnostic tasks" suggest potential improvements in diagnostic accuracy using raw waveform data.
- Why unresolved: The study used extracted ECG features rather than raw waveforms, despite acknowledging potential benefits of the latter approach.
- What evidence would resolve it: Comparative studies applying the same methodology to raw ECG waveforms versus extracted features on the same datasets would demonstrate whether raw waveform analysis provides superior diagnostic accuracy for liver disease detection.

### Open Question 3
- Question: What are the underlying physiological mechanisms linking ECG abnormalities to specific liver disease pathophysiology?
- Basis in paper: The authors state that "the physiological mechanisms linking liver dysfunction to ECG abnormalities are not yet fully understood" and note this represents "an intriguing area for further research."
- Why unresolved: While the study identifies correlations between ECG patterns and liver diseases, it does not investigate the biological pathways connecting cardiac electrical changes to hepatic dysfunction.
- What evidence would resolve it: Mechanistic studies combining ECG analysis with hepatic biomarker measurements, cardiac imaging, and pathophysiological investigations could elucidate whether specific ECG changes reflect particular aspects of liver disease progression or complications.

## Limitations
- Reliance on pre-computed ECG features without validation of extraction consistency between datasets
- Potential confounding from medications (e.g., beta-blockers, antiarrhythmics) that affect ECG features but are common in liver disease populations
- External validation dataset's earlier timeframe (1994-2013 vs 2008-2019) raises concerns about changes in diagnostic coding practices or ECG technology over time

## Confidence
- ECG features can reliably detect liver diseases: Medium confidence
- Tree-based models with Shapley values provide clinically actionable interpretability: High confidence
- External validation confirms model generalizability: Medium confidence

## Next Checks
1. Compare ECG feature distributions (particularly QTc and RR intervals) between MIMIC-IV-ECG and ECG-View II populations to quantify potential measurement protocol differences
2. Analyze model predictions stratified by medication use (beta-blockers, QT-prolonging drugs) to assess confounding impact on liver disease detection
3. Train and validate models using only the subset of liver disease patients with complete medication histories to test robustness when controlling for cardiovascular drug effects