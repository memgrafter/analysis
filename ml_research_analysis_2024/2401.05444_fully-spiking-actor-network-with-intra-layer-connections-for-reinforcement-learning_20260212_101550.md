---
ver: rpa2
title: Fully Spiking Actor Network with Intra-layer Connections for Reinforcement
  Learning
arxiv_id: '2401.05444'
source_url: https://arxiv.org/abs/2401.05444
tags:
- spiking
- neurons
- which
- network
- ilc-san
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of deploying spiking neural networks
  (SNNs) for continuous control tasks on neuromorphic hardware by developing a fully
  spiking actor network that avoids floating-point matrix operations. The core method
  introduces a novel neural coding scheme using non-spiking neurons to represent continuous
  actions via membrane voltage, combined with intra-layer connections within output
  populations to enhance representation capacity.
---

# Fully Spiking Actor Network with Intra-layer Connections for Reinforcement Learning

## Quick Facts
- **arXiv ID**: 2401.05444
- **Source URL**: https://arxiv.org/abs/2401.05444
- **Authors**: Ding Chen; Peixi Peng; Tiejun Huang; Yonghong Tian
- **Reference count**: 40
- **Primary result**: ILC-SAN achieves state-of-the-art performance on OpenAI gym continuous control tasks while reducing energy consumption by 35.1% per inference compared to PopSAN and by over 71 times compared to traditional deep networks.

## Executive Summary
This paper addresses the challenge of deploying spiking neural networks for continuous control tasks on neuromorphic hardware by developing a fully spiking actor network that eliminates floating-point matrix operations. The proposed ILC-SAN introduces a novel membrane voltage coding scheme using non-spiking neurons to represent continuous actions, combined with intra-layer connections within output populations to enhance representation capacity. The method demonstrates superior performance across seven continuous control tasks from OpenAI Gym while offering significant energy efficiency advantages. By enabling direct deployment on neuromorphic chips, ILC-SAN provides a promising solution for real-time robot control applications requiring low power consumption.

## Method Summary
The method employs a hybrid framework where a deep critic network works alongside the proposed ILC-SAN, which is the core innovation. ILC-SAN uses population encoding with Gaussian receptive fields to map state dimensions to spike trains, processes these through a backbone SNN with current-based leaky integrate-and-fire neurons, and employs output populations with intra-layer connections. Each output population consists of multiple neurons encoding the same action dimension, with self and lateral connections allowing spatial-temporal integration. The final action values are read from the membrane voltage of non-spiking leaky integrate neurons using the Dlast statistic, eliminating the need for floating-point operations. Training uses the TD3 algorithm with specific hyperparameters for the SNN layers, population encoder/decoder, and learning rates.

## Key Results
- ILC-SAN achieves state-of-the-art performance on continuous control tasks from OpenAI Gym, outperforming existing methods including PopSAN and MDC-SAN
- The method reduces energy consumption by 35.1% per inference compared to PopSAN and by over 71 times compared to traditional deep networks
- ILC-SAN demonstrates superior performance with relative stability across tasks, showing the effectiveness of the proposed membrane voltage coding and intra-layer connections

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Membrane voltage coding with non-spiking neurons enables fully spike-based action decoding without floating-point matrix operations.
- Mechanism: Non-spiking neurons accumulate spike inputs over time to form a continuous membrane voltage, which is then read out as the action value using a statistic (Dlast, Dmax, or Dmean). This replaces firing rate → FC layer → action decoding.
- Core assumption: The membrane voltage of non-spiking neurons can accurately represent continuous control values for RL algorithms.
- Evidence anchors:
  - [abstract] "we draw inspiration from the non-spiking interneurons found in insects and employ the membrane voltage of the non-spiking neurons to represent the action."
  - [section III-C] "Inspired by the non-spiking interneurons found in insects, we propose to use non-spiking neurons as a bridge between perception and motion for decision-making."
  - [corpus] Weak - no direct corpus support found for this specific mechanism.
- Break condition: If the voltage readout does not correlate linearly with the desired action range or is too noisy for RL stability.

### Mechanism 2
- Claim: Intra-layer connections within output populations enhance action representation capacity through spatial-temporal integration.
- Mechanism: Neurons in each output population are interconnected (self + lateral connections), allowing each neuron to integrate both its own temporal dynamics and the spatial influence from peers. This improves encoding of continuous action dimensions.
- Core assumption: Neurons encoding the same action dimension benefit from lateral interactions and self connections to improve representation.
- Evidence anchors:
  - [abstract] "multiple population neurons are introduced to decode different dimensions of actions... we argue that the neurons in each population should be connected in time domain and space domain."
  - [section III-D5] "For continuous control tasks from OpenAI gym, actions in different dimensions vary greatly. Therefore, we apply intra-layer connections for each output population."
  - [section III-D5] "Since the intra-layer connection and the inter-layer connection both are connections between neurons, we model them in the same way as fully-connected layers."
  - [corpus] Weak - no direct corpus support found for this specific application.
- Break condition: If intra-layer connections cause instability or do not improve performance over disconnected populations.

### Mechanism 3
- Claim: Fully spiking architecture enables direct deployment on neuromorphic hardware, drastically reducing energy consumption.
- Mechanism: By avoiding floating-point operations in decoding and using spike-based computations throughout, all matrix operations can be completed on neuromorphic chips, leveraging their efficiency.
- Core assumption: Neuromorphic hardware can execute all required operations in ILC-SAN without external floating-point computation.
- Evidence anchors:
  - [abstract] "the proposed method outperforms the state-of-the-art performance on continuous control tasks from OpenAI gym... Moreover, we estimate the theoretical energy consumption when deploying ILC-SAN on neuromorphic chips to illustrate its high energy efficiency."
  - [section III-D] "By applying intra-layer connections in the output populations, the learned action representation could be better... which is a novel method based on hybrid framework."
  - [section IV-F] "Energy Consumption... The energy consumption of DAN is more than 71 times greater than the energy consumed by ILC-SAN across all four tasks."
  - [corpus] Weak - no direct corpus support found for this specific energy efficiency claim.
- Break condition: If neuromorphic hardware cannot efficiently implement the required operations or if external computation becomes necessary.

## Foundational Learning

- Concept: Spiking Neural Networks (SNNs) and their discrete dynamics.
  - Why needed here: ILC-SAN is built entirely on SNNs, so understanding how spiking neurons model membrane voltage, spikes, and reset dynamics is essential.
  - Quick check question: What is the difference between hard reset and soft reset in SNNs?
- Concept: Population encoding and decoding in neural systems.
  - Why needed here: The paper uses population encoders with Gaussian receptive fields and population decoders to map states to spike trains and spike trains to actions.
  - Quick check question: How does the population encoder transform a continuous state dimension into spike trains?
- Concept: Reinforcement learning with actor-critic frameworks.
  - Why needed here: ILC-SAN functions as the actor network in an actor-critic RL setup, learning policies from state inputs to continuous actions.
  - Quick check question: In TD3, what is the role of the critic network relative to the actor?

## Architecture Onboarding

- Component map: State → Population Encoder → Backbone SNN → Output Populations → Intra-layer Connections → Population Decoder → Membrane Voltage → Action
- Critical path: State → Population Encoder → Backbone SNN → Output Populations → Intra-layer Connections → Population Decoder → Membrane Voltage → Action
- Design tradeoffs:
  - Membrane voltage readout (Dlast vs Dmax vs Dmean): Dlast is simplest and performs best empirically.
  - Intra-layer connection weights: Need to balance self vs lateral connections; too much lateral can oversmooth.
  - Simulation time T: Longer T gives more integration time but increases latency.
- Failure signatures:
  - Vanishing gradients in deep SNN layers.
  - Output membrane voltages saturate or fail to span the action range.
  - Intra-layer connections cause oscillatory or unstable dynamics.
- First 3 experiments:
  1. Verify that membrane voltage coding works: compare Dlast, Dmax, Dmean decoding performance with and without intra-layer connections on a simple task.
  2. Test intra-layer connections ablation: run with only self connections, only lateral connections, and both, measuring performance impact.
  3. Energy consumption estimate: calculate SOPs/FLOPs and theoretical energy for DAN vs PopSAN vs ILC-SAN on a small benchmark.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the membrane voltage coding method compare to other decoding methods in terms of performance and energy efficiency across different RL tasks?
- Basis in paper: [explicit] The paper states that the membrane voltage coding method outperforms the mainstream decoding method based on firing rate and evaluates different decoding methods (Dlast, Dmax, Dmean) with different voltage decay factors.
- Why unresolved: The paper only compares the proposed method with a few specific decoding methods and tasks, leaving open the question of how it would perform against a broader range of decoding methods and tasks.
- What evidence would resolve it: A comprehensive comparison of the proposed method with various decoding methods across a wide range of RL tasks would provide evidence to resolve this question.

### Open Question 2
- Question: What is the impact of the number of hidden layers in the backbone SNN on the performance of the ILC-SAN?
- Basis in paper: [explicit] The paper mentions that the number of hidden layers in the backbone SNN affects the performance of the ILC-SAN, but only provides results for a specific number of hidden layers.
- Why unresolved: The paper does not provide a thorough analysis of how the number of hidden layers affects the performance of the ILC-SAN, leaving open the question of the optimal number of hidden layers for different tasks.
- What evidence would resolve it: A systematic study of the impact of the number of hidden layers on the performance of the ILC-SAN across various tasks would provide evidence to resolve this question.

### Open Question 3
- Question: How does the energy consumption of the ILC-SAN compare to other SNNs and deep networks across different tasks and hardware platforms?
- Basis in paper: [explicit] The paper estimates the energy consumption of the ILC-SAN and compares it to other SNNs and deep networks, but only for specific tasks and hardware platforms.
- Why unresolved: The paper does not provide a comprehensive analysis of the energy consumption of the ILC-SAN across a wide range of tasks and hardware platforms, leaving open the question of its energy efficiency compared to other methods.
- What evidence would resolve it: A thorough comparison of the energy consumption of the ILC-SAN with other SNNs and deep networks across various tasks and hardware platforms would provide evidence to resolve this question.

## Limitations

- The membrane voltage coding mechanism lacks direct corpus validation, making it difficult to assess whether this approach represents true innovation or simply an architectural choice
- Energy efficiency claims are based on theoretical calculations rather than measured values from actual neuromorphic hardware deployment
- The novelty of both the membrane voltage coding and intra-layer connections appears significant but remains unsubstantiated without corpus support

## Confidence

- **Mechanism 1 (Membrane voltage coding)**: Medium-Low - The concept is plausible but lacks direct empirical or corpus validation
- **Mechanism 2 (Intra-layer connections)**: Medium-Low - The benefit is demonstrated empirically but the theoretical justification is weak
- **Mechanism 3 (Energy efficiency)**: Medium - Theoretical calculations are provided but unverified on actual hardware
- **Overall performance claims**: Medium - Results show improvement but mechanisms driving success are not definitively established

## Next Checks

1. Conduct ablation studies comparing Dlast, Dmax, and Dmean decoding methods with and without intra-layer connections on multiple tasks to isolate the contribution of each mechanism
2. Measure actual energy consumption on real neuromorphic hardware (Loihi, SpiNNaker) rather than theoretical estimates to validate efficiency claims
3. Perform robustness testing across different random seeds and hyperparameter settings to establish whether performance gains are consistent or task-specific