---
ver: rpa2
title: Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors
  in Personas
arxiv_id: '2406.14462'
source_url: https://arxiv.org/abs/2406.14462
tags: []
core_contribution: The paper examines whether LLM-generated responses can capture
  human subjectivity and biases across demographic, ideological, and lived-experience
  dimensions. It compares explicit personas (given exact demographics) and implicit
  personas (via names) in annotation and belief-generation tasks.
---

# Modeling Human Subjectivity in LLMs Using Explicit and Implicit Human Factors in Personas

## Quick Facts
- arXiv ID: 2406.14462
- Source URL: https://arxiv.org/abs/2406.14462
- Reference count: 21
- Primary result: LLMs can partially capture human subjectivity using explicit personas but struggle with implicit bias modeling, with political ideology being the most influential factor

## Executive Summary
This paper investigates whether large language models can capture human subjectivity and biases across demographic, ideological, and lived-experience dimensions. The study compares explicit personas (with specific demographic information) and implicit personas (using names as proxies) in both annotation and belief-generation tasks. While explicit personas successfully replicate some known human biases, implicit personas show notably poor performance, suggesting limitations in LLM ability to model subtle human perceptions.

## Method Summary
The researchers conducted experiments using both explicit and implicit persona approaches across annotation and generation tasks. Explicit personas provided specific demographic information to LLMs, while implicit personas used names as proxies for demographic characteristics. The study measured correlations with known human patterns and compared explicit versus implicit persona performance. Multiple LLM architectures were tested, with particular attention to how political ideology, demographics, and lived experiences influenced responses.

## Key Results
- Explicit personas successfully replicated known human biases in annotation tasks
- Implicit personas using names showed poor correlation with both explicit personas and known human patterns
- Political ideology emerged as the most influential persona dimension across all tasks

## Why This Works (Mechanism)
The study reveals that LLMs can model certain aspects of human subjectivity when provided with explicit demographic information, but struggle to capture implicit biases that humans naturally exhibit. The mechanism appears to rely on pattern recognition from training data rather than genuine understanding of social contexts. Explicit persona information provides clear contextual signals that LLMs can use to adjust responses, while implicit cues like names lack sufficient semantic richness for the models to infer complex social biases.

## Foundational Learning

Bias modeling in LLMs: Understanding how LLMs process demographic information and implicit social cues
Why needed: Critical for evaluating model fairness and social impact
Quick check: Test model responses with varying demographic prompts

Persona engineering: Techniques for embedding human characteristics into AI systems
Why needed: Enables more nuanced and context-aware model behavior
Quick check: Compare explicit vs implicit persona performance

Annotation task design: Methods for measuring subjective judgment alignment
Why needed: Essential for validating model behavior against human patterns
Quick check: Use established human judgment datasets as benchmarks

## Architecture Onboarding

Component map: Persona input -> LLM processing -> Response generation -> Bias measurement
Critical path: Persona specification → Response generation → Correlation analysis
Design tradeoffs: Explicit personas provide clarity but lack natural human complexity; implicit approaches are more naturalistic but less reliable
Failure signatures: Poor correlation with human patterns, inconsistent persona influence across tasks
First experiments:
1. Test explicit persona approach with additional demographic dimensions
2. Implement more sophisticated implicit bias measurement techniques
3. Compare performance across different LLM architectures

## Open Questions the Paper Calls Out
None

## Limitations
- The study may underestimate the complexity of implicit bias modeling by using names as proxies
- Generation tasks show only moderate alignment with public opinion patterns even in successful cases
- Focus on English-language responses limits generalizability to other linguistic contexts

## Confidence

High: Political ideology is the most influential persona dimension across tasks
Medium: Claims about LLMs lacking intrinsic mechanisms to fully model human perceptions
Low: Assertions about implicit personas showing poor correlation with explicit ones and known human patterns

## Next Checks

1. Test the explicit and implicit persona approaches using multilingual datasets to determine if observed patterns hold across different language contexts
2. Implement more sophisticated implicit bias measurement techniques beyond name-based personas to assess whether LLMs can capture subtle implicit biases when using more nuanced prompts
3. Conduct a systematic comparison of different LLM architectures (GPT-4, Claude, LLaMA variants) to determine if model architecture influences the ability to model human subjectivity across persona dimensions