---
ver: rpa2
title: Subword Embedding from Bytes Gains Privacy without Sacrificing Accuracy and
  Complexity
arxiv_id: '2410.16410'
source_url: https://arxiv.org/abs/2410.16410
tags:
- subword
- embedding
- byte
- bytes
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Subword Embedding from Bytes (SEB), a novel
  method to protect privacy in federated learning by encoding subwords into byte sequences
  using deep neural networks. The approach makes it difficult to recover original
  text from embedding gradients while maintaining efficiency and accuracy.
---

# Subword Embedding from Bytes Gains Privacy without Sacrificing Accuracy and Complexity

## Quick Facts
- **arXiv ID:** 2410.16410
- **Source URL:** https://arxiv.org/abs/2410.16410
- **Reference count:** 40
- **Primary result:** SEB achieves strong privacy protection (ROUGE scores below 0.01) while maintaining or improving accuracy and reducing computational complexity

## Executive Summary
This paper introduces Subword Embedding from Bytes (SEB), a novel approach to protect privacy in federated learning scenarios by encoding subwords into byte sequences using deep neural networks. The method makes it significantly harder to recover original text from embedding gradients while maintaining efficiency and accuracy. SEB uses a small vocabulary of 256 bytes and preserves input sequence length, achieving comparable or better results than standard subword embedding methods across multiple NLP tasks including machine translation, sentiment analysis, and language modeling.

The approach addresses a critical challenge in federated learning where participants may be reluctant to share their data due to privacy concerns. By transforming subwords into byte sequences before embedding, SEB effectively obscures the original text content while still allowing the model to learn meaningful representations for downstream tasks. Experiments demonstrate that SEB successfully defends against embedding-based attacks while maintaining or improving BLEU scores, accuracy, and perplexity metrics with lower time and space complexity.

## Method Summary
SEB works by converting subword tokens into byte sequences before applying embedding layers. Instead of directly embedding subwords, the method first maps each character in a subword to its corresponding byte value, creating a sequence of byte representations. These byte sequences are then processed by a neural network (typically a transformer or LSTM) to generate the final embeddings. This intermediate byte-level representation makes it significantly harder for adversaries to reconstruct the original text from embedding gradients, as the mapping from bytes to meaningful words is non-trivial and requires substantial computational effort to reverse.

The architecture maintains the same input sequence length as traditional subword approaches, ensuring compatibility with existing model architectures. The byte vocabulary of 256 values is much smaller than typical subword vocabularies (often 30,000+), which contributes to the reduced computational complexity. During training, the byte-to-embedding network learns to produce representations that are semantically meaningful for the target task while simultaneously obscuring the original text content, creating a natural defense against privacy attacks without requiring additional encryption or differential privacy mechanisms.

## Key Results
- SEB reduced ROUGE-1/2/L scores from close to 1 to below 0.01, indicating effective protection against text reconstruction attacks
- Maintained or improved BLEU scores (35.44 vs 34.54) in machine translation tasks
- Achieved better accuracy (82.5% vs 81.2%) and lower perplexity (30.55 vs 30.84) compared to baseline methods
- Demonstrated lower time and space complexity due to the smaller 256-byte vocabulary

## Why This Works (Mechanism)
The core mechanism of SEB relies on introducing an intermediate representation layer between raw text and embeddings. By converting subwords to byte sequences before embedding, the method creates a many-to-many mapping that makes reverse engineering difficult. While bytes are semantically meaningless in isolation, the neural network learns to extract meaningful patterns from byte sequences that are useful for downstream tasks. This transformation effectively increases the computational cost for any adversary attempting to reconstruct original text from gradients, as they would need to first decode the byte sequences and then map them back to possible subwords or words. The byte-level representation acts as a form of obfuscation that preserves task utility while significantly degrading the quality of information that can be extracted through gradient-based attacks.

## Foundational Learning
- **Federated Learning:** A distributed machine learning paradigm where multiple parties train a model collaboratively without sharing raw data. Why needed: SEB specifically addresses privacy concerns in this setting where data remains on client devices.
- **Subword Tokenization:** Breaking text into smaller units (subwords) rather than individual characters or whole words to handle rare words and reduce vocabulary size. Why needed: SEB builds upon subword tokenization as its input representation.
- **Embedding Attacks:** Privacy attacks that attempt to reconstruct training data from model gradients, particularly embedding gradients. Why needed: SEB's primary goal is to defend against these specific privacy threats.
- **Byte Encoding:** Representing characters as numerical values (0-255) in a standardized format. Why needed: SEB uses byte encoding as an intermediate representation to obscure original text.
- **Sequence-to-Sequence Models:** Neural architectures that process sequential input and produce sequential output, commonly used in NLP tasks. Why needed: SEB employs these models to learn meaningful representations from byte sequences.
- **ROUGE Score:** A metric for evaluating text generation quality by comparing overlap of n-grams, word sequences, and word pairs. Why needed: Used to measure the effectiveness of privacy protection by assessing reconstruction quality.

## Architecture Onboarding

**Component Map:** Raw Text -> Subword Tokenizer -> Byte Encoder -> Byte Embedding Network -> Task-Specific Model

**Critical Path:** The byte embedding network is the critical component, as it transforms meaningless byte sequences into semantically meaningful representations while maintaining privacy. This network must balance two competing objectives: preserving task performance and obscuring original text content.

**Design Tradeoffs:** The method trades off between privacy protection and computational efficiency. Using a smaller byte vocabulary (256) reduces computational overhead compared to large subword vocabularies (30,000+), but may lose some semantic information that could be captured at the subword level. The architecture also must balance the depth of the byte embedding network - deeper networks provide better representations but increase computational cost and may create more opportunities for information leakage.

**Failure Signatures:** If privacy protection fails, ROUGE scores will remain high (close to 1), indicating successful text reconstruction. If task performance degrades significantly, BLEU scores, accuracy, or perplexity will drop well below baseline levels. If computational efficiency claims are invalid, time and space complexity measurements will show no improvement or degradation compared to baseline methods.

**First Experiments:**
1. Measure ROUGE-1/2/L scores on reconstructed text from embedding gradients to verify privacy protection effectiveness
2. Compare BLEU scores, accuracy, and perplexity on downstream tasks against baseline subword embedding methods
3. Benchmark time and space complexity during both training and inference phases to confirm efficiency improvements

## Open Questions the Paper Calls Out
None

## Limitations
- Performance evaluation focused primarily on embedding gradient attacks, with limited assessment against other privacy attack vectors
- Real-world federated learning scenarios with heterogeneous data distributions and device capabilities were not fully explored
- Results may not generalize to all language families or specialized NLP domains beyond the tested machine translation, sentiment analysis, and language modeling tasks

## Confidence
- Privacy claims: High - dramatic reduction in ROUGE scores from close to 1 to below 0.01 provides strong evidence of effective protection
- Performance improvements: Medium - results are promising but based on specific datasets and tasks that may not represent all NLP applications
- Computational efficiency: High - time and space complexity metrics show clear improvements, though real-world deployment may reveal additional bottlenecks

## Next Checks
1. Evaluate SEB's privacy and performance under different federated learning configurations, including non-IID data distributions and varying numbers of participating clients
2. Test SEB against a broader range of privacy attacks beyond embedding gradient reconstruction, such as membership inference and model inversion attacks
3. Conduct extensive ablation studies to determine the impact of byte sequence length and vocabulary size on both privacy protection and task performance across multiple language families