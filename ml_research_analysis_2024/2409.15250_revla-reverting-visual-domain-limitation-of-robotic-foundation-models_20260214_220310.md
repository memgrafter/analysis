---
ver: rpa2
title: 'ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models'
arxiv_id: '2409.15250'
source_url: https://arxiv.org/abs/2409.15250
tags:
- visual
- openvla
- vision
- revla
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the visual generalization problem in robotic
  foundation models, particularly the issue of catastrophic forgetting in vision encoders
  during training on limited robotic datasets. The authors propose ReVLA, a method
  that gradually reverts vision backbones (DINO-v2 and SigLIP) to their pretrained
  weights during training using a linear merging schedule.
---

# ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models

## Quick Facts
- **arXiv ID**: 2409.15250
- **Source URL**: https://arxiv.org/abs/2409.15250
- **Reference count**: 38
- **Primary result**: 77% and 66% improvements in grasping and lifting success rates for OOD tasks

## Executive Summary
Robotic foundation models struggle with visual out-of-domain generalization due to catastrophic forgetting in their vision encoders during training on limited robotic datasets. ReVLA addresses this by gradually reverting vision backbones (DINO-v2 and SigLIP) to their pretrained weights during training using a linear merging schedule. This approach enables the model to regain visual generalization capabilities while maintaining stable robot trajectories. Evaluated on the SIMPLER benchmark and extended OOD scenarios with objects from the YCB dataset, ReVLA significantly outperforms OpenVLA in visual out-of-domain tasks while maintaining strong in-domain performance.

## Method Summary
ReVLA implements a gradual backbone reversal approach where vision encoder weights are linearly interpolated between OpenVLA-trained weights and their original pretrained versions during training. The method uses a step-wise curriculum where the interpolation parameter α increases from 0 to 1 over training steps, effectively "reverting" the vision backbones to their generalizable pretrained states while still adapting the LLM components to robotic tasks. Both DINO-v2 and SigLIP encoders undergo this reversal process, with the former providing spatial understanding and the latter enabling semantic description of unseen objects.

## Key Results
- 77% improvement in grasping success rates for visual out-of-domain tasks
- 66% improvement in lifting success rates for visual out-of-domain tasks
- Maintains strong in-domain performance on the SIMPLER benchmark
- Demonstrates superior handling of novel objects and distractors compared to OpenVLA

## Why This Works (Mechanism)

### Mechanism 1
Gradual linear weight merging between catastrophic-forgotten vision backbones and their original pretrained versions restores generalization while maintaining task-specific performance. During training, ReVLA linearly interpolates between OpenVLA weights and pretrained DINO-v2/SigLIP weights using equation: Fθ = (1 - α)θOpenVLA + αθPretrained, where α increases from 0 to 1 over training steps. This schedule allows the model to gradually "revert" to generalizable visual representations while still adapting to robotic task requirements.

### Mechanism 2
Preserving pretrained vision encoder capabilities while fine-tuning LLM components enables better OOD generalization than fine-tuning entire architecture. ReVLA freezes vision backbones during training while only fine-tuning the LLM component, allowing the model to maintain strong visual feature extraction capabilities from pretraining while adapting language reasoning to robotic tasks.

### Mechanism 3
Combining DINO-v2 (spatial/3D reasoning) and SigLIP (semantic/linguistic) encoders with gradual reversal provides complementary generalization capabilities for OOD object manipulation. ReVLA reverses both vision backbones because DINO-v2 provides spatial understanding for novel object manipulation while SigLIP enables semantic description of unseen objects, creating a comprehensive visual representation system.

## Foundational Learning

- **Catastrophic forgetting in neural networks**: Understanding why vision backbones lose generalization capability during robotic training is essential for appreciating why ReVLA's reversal approach works.
  - *Quick check*: What happens to a neural network's ability to perform previously learned tasks when trained on new, different data?

- **Model merging and weight interpolation techniques**: ReVLA's core mechanism relies on gradually blending pretrained and fine-tuned weights, requiring understanding of how different weight combinations affect model behavior.
  - *Quick check*: How does linearly interpolating between two sets of model weights affect the resulting model's capabilities?

- **Vision-language-action (VLA) model architecture**: Understanding how OpenVLA processes visual inputs through multiple encoders before LLM reasoning is crucial for grasping why preserving vision backbone capabilities matters.
  - *Quick check*: In a VLA model with multiple vision encoders feeding into an LLM, which components are most critical for maintaining generalization?

## Architecture Onboarding

- **Component map**: RGB images → DINO-v2 → features → Tokenizer → LLM input; RGB images → SigLIP → features → Tokenizer → LLM input; LLM + language instruction → action predictions
- **Critical path**: Images → DINO-v2 → features → Tokenizer → LLM input; Images → SigLIP → features → Tokenizer → LLM input; LLM + language instruction → action predictions; Compare with ground truth trajectories → loss; Backpropagation with gradual weight merging schedule
- **Design tradeoffs**: Full model fine-tuning (OpenVLA) vs vision backbone freezing (ReVLA): Stability vs generalization; Gradual vs flip reversal schedule: Smooth transition vs computational efficiency; Single vs dual encoder reversal: Simplicity vs comprehensive capability
- **Failure signatures**: Vision encoders collapse to constant outputs (depth regression failure); Poor performance on novel objects despite strong in-domain results; Successful grasping but failed lifting (partial task completion); Inability to distinguish visually similar objects; Performance degradation when distractors are present
- **First 3 experiments**: Depth regression evaluation comparing DPT head outputs; In-domain SIMPLER benchmark Visual Matching protocol; OOD object manipulation testing grasping/lifting success rates on YCB objects

## Open Questions the Paper Calls Out

- **Optimal reversal schedule**: What is the optimal schedule for gradually reverting vision backbones during training? The authors propose gradual backbone reversal using linear merging schedule but only evaluate one specific configuration.
- **Reasoning capability emergence**: How does catastrophic forgetting in vision encoders impact the emergence of reasoning capabilities in robotic foundation models? The paper notes that OpenVLA requires fine-tuning both vision encoders and LLM simultaneously.
- **Visual domain diversity relationship**: What is the relationship between visual domain diversity in training data and the severity of catastrophic forgetting? The authors attribute catastrophic forgetting to "limited variations in the training data."

## Limitations
- Assumes catastrophic forgetting is entirely reversible through weight interpolation, which may not hold for all types of visual degradation
- Computational cost of maintaining and reverting two separate vision encoders could limit practical deployment
- Focuses primarily on grasping and lifting tasks, leaving open questions about generalization to other robotic manipulation primitives

## Confidence
- **High Confidence**: The core mechanism of gradual weight merging between pretrained and fine-tuned vision backbones is technically sound and well-supported by empirical results
- **Medium Confidence**: The assumption that pretrained DINO-v2 and SigLIP encoders contain sufficient visual generalization capabilities for novel object manipulation
- **Low Confidence**: The claim that vision backbone freezing is superior to full model fine-tuning for all robotic tasks

## Next Checks
1. **Cross-task Generalization**: Evaluate ReVLA on non-grasping manipulation tasks (e.g., pushing, pouring) to verify whether the vision backbone reversal approach generalizes beyond the tested task types
2. **Catastrophic Forgetting Reversibility**: Conduct ablation studies where different fractions of vision backbone weights are reverted to determine the minimum percentage needed for OOD generalization while maintaining task performance
3. **Real-World Deployment Feasibility**: Test ReVLA on physical robotic hardware with real-world objects and lighting conditions to assess whether simulation-to-reality transfer maintains the reported performance gains