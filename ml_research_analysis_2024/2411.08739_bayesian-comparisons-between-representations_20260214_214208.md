---
ver: rpa2
title: Bayesian Comparisons Between Representations
arxiv_id: '2411.08739'
source_url: https://arxiv.org/abs/2411.08739
tags:
- representations
- distance
- images
- metrics
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Bayesian framework for comparing neural
  network representations using linear readout models. The key innovation is computing
  prior predictive distributions analytically for Gaussian linear readouts with ridge
  regularization, then measuring distances between these distributions using Jensen-Shannon
  or total variation metrics.
---

# Bayesian Comparisons Between Representations

## Quick Facts
- arXiv ID: 2411.08739
- Source URL: https://arxiv.org/abs/2411.08739
- Authors: Heiko H. Schütt
- Reference count: 40
- Key outcome: Bayesian framework for comparing neural network representations using linear readout models with analytical prior predictive distributions

## Executive Summary
This paper introduces a Bayesian approach to compare neural network representations by measuring distances between prior predictive distributions of linear readouts. The key innovation is computing these distributions analytically for Gaussian linear readouts with ridge regularization, then quantifying distances using Jensen-Shannon or total variation metrics. The method provides principled uncertainty quantification while being invariant to scaling and rotation but sensitive to feature norms and offsets. Experiments show the new metrics are correlated with but distinct from existing approaches like CKA and RSA, varying less across image samples and providing more stringent comparisons.

## Method Summary
The method computes prior predictive distributions analytically for linear readouts with Gaussian priors and Gaussian noise, requiring only the kernel matrix XX^T of representations. Distances between these distributions are estimated using sampling approximations of total variation distance or Jensen-Shannon distance. The approach bridges linear readout methods and kernel-based metrics, connecting to existing literature while offering new statistical interpretations. Computationally, it requires O(n²) memory for the kernel matrix and O(n³) time for matrix operations, where n is the number of images.

## Key Results
- The Bayesian metrics are correlated with but distinct from CKA and RSA, varying less across different image samples
- The method is sensitive to feature norms and offsets but invariant to rotations and scaling of representations
- Computational efficiency allows reliable representation comparisons with full uncertainty quantification
- Experiments on ImageNet-1k models demonstrate practical utility across different architectures (AlexNet, ResNet-18, ViT-B-16)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bayesian linear readout with Gaussian priors enables analytical computation of prior predictive distributions.
- Mechanism: For linear readouts with isotropic Gaussian priors and Gaussian noise, the predictive distribution is analytically tractable as a normal distribution whose covariance depends only on the linear kernel matrix of the representations.
- Core assumption: The readout weights follow a zero-mean Gaussian prior and observations have independent Gaussian noise.
- Evidence anchors:
  - [abstract] "For a linear readout with a Gaussian prior on the read-out weights and Gaussian noise, we can analytically compute the (prior and posterior) predictive distributions without approximations."
  - [section 3.2] "As linear transformations of Gaussians are Gaussian, the distribution for y is then also a Gaussian with known parameters"
  - [corpus] Weak evidence - no directly related papers found on analytical Bayesian linear readout computation

### Mechanism 2
- Claim: Using metrics on predictive distributions induces pseudo-metrics on representations.
- Mechanism: Since Jensen-Shannon distance and total variation distance are proper metrics on probability distributions, applying them to predictive distributions creates a well-defined (pseudo-)metric structure on the space of representations.
- Core assumption: The mapping from representations to predictive distributions is well-defined and deterministic.
- Evidence anchors:
  - [abstract] "As Jensen-Shannon distance and total variation distance are metrics our dissimilarity measures are pseudo-metrics for representations"
  - [section 3.5] "Our new measures of similarity between representations are pseudo-metrics, because we use metrics to compute the dissimilarity of the predictive distributions"
  - [corpus] Weak evidence - no directly related papers found on metric-induced pseudo-metrics from predictive distributions

### Mechanism 3
- Claim: The method connects linear readout comparisons to kernel-based metrics while being sensitive to feature norms and offsets.
- Mechanism: The predictive distributions depend only on the linear kernel matrix, creating a bridge to kernel methods like CKA and RSA, but unlike those methods, the approach is sensitive to feature norms and offsets due to the non-centered nature of the distributions.
- Core assumption: The linear kernel matrix captures the essential structure of the representations for comparison purposes.
- Evidence anchors:
  - [abstract] "Thus, the Bayesian metrics connect to both linear read-out based comparisons and kernel based metrics like centered kernel alignment and representational similarity analysis"
  - [section 3.6] "Our new measure does not ignore the norms of the individual patterns or their distance to the origin... This is in contrast to representational similarity analysis"
  - [corpus] Weak evidence - no directly related papers found on connecting linear readout and kernel methods

## Foundational Learning

- Concept: Bayesian predictive distributions and their role in measuring inductive bias
  - Why needed here: The paper relies on using prior predictive distributions as a complete description of model inductive bias and generalization behavior
  - Quick check question: What is the key advantage of using prior predictive distributions over other comparison methods when analyzing high-dimensional representations?

- Concept: Gaussian process regression and its relationship to ridge regularization
- Why needed here: The linear readout with Gaussian prior is mathematically equivalent to ridge regression, providing the theoretical foundation for the analytical tractability
- Quick check question: How does the choice of Gaussian prior variance relate to the regularization strength in ridge regression?

- Concept: Kernel methods and their role in representation similarity analysis
- Why needed here: The paper explicitly connects to kernel-based metrics like centered kernel alignment and representational similarity analysis
- Quick check question: What is the key difference between how this method and traditional CKA treat the scaling and centering of representations?

## Architecture Onboarding

- Component map: Input images -> Representation extraction -> Kernel matrix computation (XX^T) -> Predictive distribution computation -> Distance computation -> Output dissimilarity matrix
- Critical path: Representation extraction → Kernel matrix computation → Predictive distribution computation → Distance computation → Output
- Design tradeoffs:
  - Memory vs. number of images: Kernel matrix requires O(n²) memory where n is number of images
  - Accuracy vs. computation time: Sampling-based distance approximation requires balancing sample count against speed
  - Sensitivity vs. invariance: Method is sensitive to feature norms and offsets but invariant to rotations and scaling
- Failure signatures:
  - Extremely small or large distances across all comparisons: May indicate issues with signal-to-noise ratio parameter a
  - High variance across image samples: May indicate insufficient test data or need for larger sample sizes in distance approximation
  - Computational memory errors: May indicate too many images for available RAM given O(n²) kernel matrix scaling
- First 3 experiments:
  1. Compute Jensen-Shannon distance between two simple synthetic representations with known differences (e.g., one with scaled features, one with rotated features)
  2. Compare a single convolutional layer to itself with different numbers of test images to observe stability properties
  3. Apply the method to two different layers within the same network (e.g., AlexNet conv1 vs conv2) and verify that nearby layers show smaller distances than distant layers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the Bayesian metrics compare to other representation comparison methods when applied to non-image data or different neural network architectures?
- Basis in paper: [inferred] The paper demonstrates results on ImageNet-1k trained models but explicitly states "We see no reason why our methods should be restricted to image processing models though."
- Why unresolved: The paper only evaluates the method on image classification models, leaving its generalizability to other domains and architectures untested.
- What evidence would resolve it: Empirical comparisons of the Bayesian metrics against existing methods on diverse datasets (text, audio, etc.) and network architectures (RNNs, transformers for NLP, etc.).

### Open Question 2
- Question: What is the optimal signal-to-noise ratio adjustment parameter (b) for different numbers of stimuli and representation dimensionalities?
- Basis in paper: [explicit] "Based on a few examples, we settled on b = 1/100" and "More fine-grained distinctions may profit from using lower noise levels and broader distinctions from even higher noise levels."
- Why unresolved: The paper uses a heuristic choice without rigorous justification or systematic exploration of the parameter space.
- What evidence would resolve it: Systematic analysis of how different b values affect metric performance across varying numbers of stimuli and representation dimensionalities.

### Open Question 3
- Question: How do the Bayesian metrics perform in detecting subtle architectural differences in neural networks with identical performance on classification tasks?
- Basis in paper: [inferred] The paper shows the metrics can distinguish between different layers and architectures but doesn't test their sensitivity to subtle architectural changes that preserve performance.
- Why unresolved: The experiments compare clearly different architectures (AlexNet, ResNet, ViT) but don't explore cases where networks have similar performance but different internal representations.
- What evidence would resolve it: Comparative analysis of networks with identical test accuracy but different architectural choices using the Bayesian metrics versus other similarity measures.

## Limitations
- Quadratic memory requirement for kernel matrices restricts the number of images that can be used
- Sensitivity to the signal-to-noise parameter a requires careful tuning for different applications
- Invariance to rotations and scaling may obscure meaningful representational differences in some cases

## Confidence
- **High confidence**: Claims about analytical tractability and metric properties are well-supported
- **Medium confidence**: Claims about practical utility have empirical support but limited domain testing
- **Low confidence**: Computational scalability claims may not hold for very large representation spaces

## Next Checks
1. Test the method's sensitivity to varying signal-to-noise ratios a across different representation scales and dimensions
2. Evaluate computational scaling on larger representation spaces (e.g., transformer models with 1M+ dimensions) to verify practical limits
3. Compare the method against established representation similarity metrics on non-vision domains (e.g., language models) to assess generality