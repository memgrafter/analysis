---
ver: rpa2
title: 'Savvy: Trustworthy Autonomous Vehicles Architecture'
arxiv_id: '2402.14580'
source_url: https://arxiv.org/abs/2402.14580
tags:
- time
- safety
- system
- architecture
- control
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Savvy, a new trustworthy autonomous vehicle
  architecture that aims to balance safety and performance by combining safe-operational
  control with Time-aware predictive quality degradation (TPQD). TPQD allows dynamic
  ML models to be tuned to provide either richer or faster outputs based on available
  safety time bounds, enabling the system to make timely decisions without compromising
  safety.
---

# Savvy: Trustworthy Autonomous Vehicles Architecture

## Quick Facts
- arXiv ID: 2402.14580
- Source URL: https://arxiv.org/abs/2402.14580
- Authors: Ali Shoker; Rehana Yasmin; Paulo Esteves-Verissimo
- Reference count: 40
- Key outcome: Proposed architecture balancing safety and performance through Time-aware predictive quality degradation (TPQD) in dynamic ML models

## Executive Summary
This paper introduces Savvy, a trustworthy autonomous vehicle architecture that addresses the fundamental tension between safety and performance in self-driving systems. The key innovation is Time-aware predictive quality degradation (TPQD), which allows dynamic ML models to trade recognition accuracy for faster inference times when safety time bounds are tight. By separating the control plane (Safety-Critical Control system) from the data plane (Time-Sensitive Intelligent Modules), Savvy ensures safety-first principles while maximizing AI capabilities within safety time constraints.

## Method Summary
The architecture implements a Safety-Critical Control (SCC) system that acts as a centralized supervisor, orchestrating Time-Sensitive Intelligent Modules (TSIMs) that contain both static safety submodules and dynamic AI submodules. The SCC uses Time to Event (TTE) and Time to Hazard (TTH) bounds to schedule tasks and determine when to switch between AI inference and hardcoded safety responses. Dynamic Neural Networks are tuned in real-time to meet time constraints, while Bounded AI models provide high-accuracy fallback predictions when time permits. The authors plan to implement a Proof of Concept and conduct empirical evaluation of TPQD effectiveness.

## Key Results
- Proposed TPQD mechanism enables AI models to provide lower-quality but faster outputs when safety time bounds are tight
- Clear separation between control plane (SCC) and data plane (TSIMs) ensures safety-first principles
- Bounded AI models provide high-accuracy fallback predictions when time permits, improving safety beyond conservative fail-operational modes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Time-aware predictive quality degradation (TPQD) enables safer autonomous driving by allowing AI models to provide lower-quality but faster outputs when safety time bounds are tight.
- Mechanism: Dynamic AI models are tuned in real-time to reduce computational depth or parameters, trading off recognition accuracy for faster inference times. The SCC uses TTE and TTH bounds to decide when to switch from AI inference to hardcoded safety responses.
- Core assumption: AI inference time is predictable enough that TTE and TTH can be reliably estimated and enforced without excessive overhead.
- Evidence anchors:
  - [abstract]: "using dynamic ML models that can be tuned to provide either richer or faster outputs based on the available safety time bounds"
  - [section]: "The SCC system plays the role of Pub/Sub broker where sensors push their readings to, and actuators take order from. Upon the receipt of input from that set of sensors, that triggers the event, the SCC system triggers the corresponding set of actuators before the safety-critical time TTH, if better opportunistic decisions are not expected within the TTE."
  - [corpus]: "The Use of the Simplex Architecture to Enhance Safety in Deep-Learning-Powered Autonomous Systems" discusses similar supervisory control but not dynamic quality degradation.

### Mechanism 2
- Claim: Clear separation between control plane (SCC) and data plane (TSIMs) ensures safety-first principles by centralizing decision authority.
- Mechanism: SCC retains full supervisory control over scheduling and safety timing, while TSIMs operate only within time bounds set by SCC. If a TSIM cannot deliver results before TTE, SCC immediately triggers safety responses from the Static submodule before TTH expires.
- Core assumption: A centralized SCC can reliably orchestrate multiple TSIMs and maintain timing guarantees across varying workloads.
- Evidence anchors:
  - [abstract]: "Savvy makes a clear separation between the control plane and the data plane to guarantee the safety-first principles. The former assume control to ensure safety using design-time defined rules, while launching the latter for optimising decisions as much as possible within safety time-bounds."
  - [section]: "The SCC system plays the role of Pub/Sub broker where sensors push their readings to, and actuators take order from... The SCC system employs a time-sensitive Task Scheduler that generates the time bounds for the driving related tasks, ensuring the safety-critical timeliness."
  - [corpus]: "HALO: Fault-Tolerant Safety Architecture For High-Speed Autonomous Racing" uses similar control-plane separation but focuses on fault tolerance rather than time-aware quality degradation.

### Mechanism 3
- Claim: Bounded AI (BAI) models provide high-accuracy fallback predictions when time permits, improving safety beyond conservative fail-operational modes.
- Mechanism: TSIMs use Bounded AI models that combine learned patterns with domain constraints to achieve near-100% accuracy in structured scenarios. SCC schedules these models when TTE is sufficient; otherwise, it falls back to faster but less accurate dynamic models.
- Core assumption: BAI models can be pre-trained to provide accurate predictions for known scenarios and can be evaluated quickly enough to fit within TTE when available.
- Evidence anchors:
  - [abstract]: "We are exploring Dynamic Neural Networks that allow for model deformation... or parameter (Weights, Space, or Channel) adjustments at inference time... For more accurate recognition and prediction to improve safety, our work encourages more research and use of what we call Bounded AI (BAI) prediction models that include factual pre-trained or symbolic models to guide the training of the main processing models."
  - [section]: "The TSIMs are self-contained modules that can be used in any architecture... Each TSIM is further composed of the Static submodule and the Dynamic submodule. DMod leverages the dynamic AI models capabilities... The TTE is the expected time by which all the DMods should deliver and execute in order to take advantage of the AI capabilities. In the event where the TSIM AI execution... hits the lower time bound, the SMod is triggered by firing the safety timer TTH."
  - [corpus]: "Physics-informed neural networks for time-dependent PDEs" provides evidence for BAI model accuracy in structured domains.

## Foundational Learning

- Concept: Time-critical system design and real-time scheduling
  - Why needed here: The architecture relies on precise timing bounds (TTE, TTH) to guarantee safety, requiring understanding of real-time scheduling, worst-case execution time estimation, and deadline enforcement.
  - Quick check question: What happens if a TSIM's actual execution time exceeds its assigned TTE, and how does the SCC detect and respond to this violation?

- Concept: Dynamic Neural Network architecture and inference-time tuning
  - Why needed here: TPQD depends on adjusting model depth, width, or parameters at inference time to meet time bounds, requiring knowledge of model architectures that support such dynamic behavior.
  - Quick check question: Which dynamic NN techniques (early exiting, pruning, NAS) are most suitable for automotive perception tasks where inference speed and accuracy trade-offs must be predictable?

- Concept: Safety-critical system design patterns (fail-safe, fail-operational)
  - Why needed here: The architecture must ensure that even when AI fails or is unavailable, the vehicle can enter a safe state, requiring understanding of safety integrity levels, redundancy, and fault tolerance.
  - Quick check question: How does the SCC determine when to trigger SMod responses versus allowing DMod to continue, and what are the safety consequences of each choice?

## Architecture Onboarding

- Component map: Sensors -> Preliminary-sensing -> SCC (Pub/Sub broker) -> TSIMs (SMod/DMod) -> Actuators

- Critical path:
  1. Preliminary-sensing detects event â†’ feeds initial time bounds to SCC
  2. SCC schedules TSIM tasks with TTE/TTH bounds
  3. TSIMs tune DMod models to meet TTE
  4. If DMod completes before TTE, use AI decision; else trigger SMod before TTH
  5. Actuators execute final decision

- Design tradeoffs:
  - Safety vs. performance: Conservative TTE/TTH bounds improve safety but reduce AI utilization
  - Model complexity vs. tuning flexibility: More complex models may offer better accuracy but be harder to tune dynamically
  - Centralization vs. modularity: SCC centralization simplifies safety guarantees but creates single point of failure

- Failure signatures:
  - SCC timing violations: Multiple TSIMs missing TTE deadlines indicates SCC scheduling problems
  - Excessive SMod activations: Frequent safety mode triggers suggest DMod models are consistently unable to meet TTE
  - Sensor fusion failures: Preliminary-sensing unable to provide timely initial bounds indicates sensor integration issues

- First 3 experiments:
  1. Implement SCC with fixed TTE/TTH bounds and verify timing guarantees using simulated sensor data
  2. Integrate a single TSIM with early-exiting CNN for obstacle detection, measuring accuracy vs. TTE trade-offs
  3. Add Bounded AI (PINN) model for structured scenarios (e.g., lane keeping) and compare performance against pure DNN approach under varying TTE constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we empirically evaluate the effectiveness of Time-aware predictive quality degradation (TPQD) in improving the balance between safety and performance in autonomous vehicles?
- Basis in paper: [explicit] The authors plan to implement a Proof of Concept of Savvy and evaluate TPQD empirically.
- Why unresolved: The paper does not provide details on the specific evaluation metrics, experimental setup, or results of the empirical evaluation.
- What evidence would resolve it: Empirical results demonstrating the effectiveness of TPQD in improving the balance between safety and performance in autonomous vehicles, along with the evaluation metrics and experimental setup used.

### Open Question 2
- Question: What are the specific design choices and implementation details of the Dynamic Neural Networks (DNNs) used in Savvy to enable time-aware predictive quality degradation?
- Basis in paper: [inferred] The paper mentions the use of Dynamic Neural Networks that can be tuned to deliver before the safety-critical time expires, but does not provide specific details on the design choices or implementation.
- Why unresolved: The paper does not provide details on the specific DNN architectures, tuning mechanisms, or inference-time adjustments used in Savvy.
- What evidence would resolve it: Detailed description of the DNN architectures, tuning mechanisms, and inference-time adjustments used in Savvy, along with their implementation details.

### Open Question 3
- Question: How can the Safety-Critical Control (SCC) system in Savvy effectively monitor and control the time safety bounds across processes, including the AI system, to ensure the safety-first principle?
- Basis in paper: [explicit] The paper mentions that the SCC system plays the role of Pub/Sub broker and employs a time-sensitive Task Scheduler to generate time bounds for driving-related tasks.
- Why unresolved: The paper does not provide details on the specific mechanisms, algorithms, or protocols used by the SCC system to monitor and control the time safety bounds.
- What evidence would resolve it: Detailed description of the mechanisms, algorithms, and protocols used by the SCC system to monitor and control the time safety bounds, along with their effectiveness in ensuring the safety-first principle.

## Limitations

- The proposed TPQD mechanism faces significant challenges in practical implementation due to unpredictable computational loads and environmental conditions that could make accurate time prediction difficult.
- The centralized SCC design creates a potential single point of failure that could compromise the entire safety guarantee, with no adequate redundancy mechanisms specified.
- The effectiveness of Bounded AI models in handling edge cases and the reliability of time prediction mechanisms for dynamic model tuning remain unproven in real-world scenarios.

## Confidence

- **High confidence**: The fundamental safety-first architectural separation between SCC and TSIMs is sound and aligns with established safety-critical system design principles
- **Medium confidence**: The TPQD concept of dynamically adjusting AI model quality based on available time is theoretically valid, but practical implementation challenges remain significant
- **Low confidence**: The effectiveness of Bounded AI models in real-world edge cases and the reliability of time prediction mechanisms for dynamic model tuning

## Next Checks

1. **Timing prediction validation**: Implement a simulation framework to test whether AI inference times can be accurately predicted across varying computational loads and input complexities, measuring prediction error rates and their impact on safety margins

2. **Edge case coverage testing**: Evaluate Bounded AI models on a comprehensive set of edge cases and failure scenarios to determine whether they can achieve near-100% accuracy while maintaining acceptable inference speeds, using real-world driving datasets

3. **SCC failure mode analysis**: Design and test SCC failure scenarios to assess the system's ability to maintain safety when the centralized controller experiences timing violations, computational bottlenecks, or complete failure