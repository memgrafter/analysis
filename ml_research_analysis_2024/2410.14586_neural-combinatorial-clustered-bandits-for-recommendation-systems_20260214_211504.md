---
ver: rpa2
title: Neural Combinatorial Clustered Bandits for Recommendation Systems
arxiv_id: '2410.14586'
source_url: https://arxiv.org/abs/2410.14586
tags:
- super
- neural
- reward
- which
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the contextual combinatorial bandit problem\
  \ for recommendation systems, where an agent must select subsets of items (arms)\
  \ to maximize cumulative reward. The authors propose Neural UCB Clustering (NeUClust),\
  \ a novel algorithm that uses two neural networks\u2014one for base arm rewards\
  \ and one for super arm rewards\u2014combined with clustering of the context space\
  \ to guide selections."
---

# Neural Combinatorial Clustered Bandits for Recommendation Systems

## Quick Facts
- arXiv ID: 2410.14586
- Source URL: https://arxiv.org/abs/2410.14586
- Reference count: 40
- Key outcome: NeUClust achieves O(ed√T) regret, outperforming state-of-the-art methods on MovieLens and Yelp datasets

## Executive Summary
This paper introduces Neural UCB Clustering (NeUClust), a novel algorithm for contextual combinatorial bandit problems in recommendation systems. Unlike prior methods requiring oracles, NeUClust uses two neural networks—one for base arm rewards and one for super arm rewards—combined with clustering of the context space to guide selections. The algorithm leverages monotonicity assumptions to eliminate the need for optimization oracles while achieving theoretical regret bounds matching prior neural combinatorial bandits. Experiments demonstrate superior performance on real-world MovieLens and Yelp datasets.

## Method Summary
NeUClust addresses the contextual combinatorial bandit problem by using two neural networks: a base arm network that estimates individual arm rewards and a monotonic super arm network that estimates the reward of selecting a subset of arms. The algorithm clusters the context space using k-means and selects arms from the cluster with the highest upper confidence bound (UCB). This approach eliminates the need for an optimization oracle while maintaining theoretical guarantees. The algorithm achieves O(ed√T) regret, where ed is the effective dimension of the neural tangent kernel matrix.

## Key Results
- NeUClust achieves eO(ed√T) regret, matching theoretical bounds of prior neural combinatorial bandits
- Outperforms state-of-the-art methods (CN-UCB, NeuralMAB, CCMAB, K-LinUCB) on MovieLens and Yelp datasets
- Demonstrates robustness to increasing context dimensions, with performance improving as context space grows

## Why This Works (Mechanism)

### Mechanism 1
The neural tangent kernel (NTK) effective dimension governs the algorithm's learning capacity and regret scaling. As the NTK effective dimension ed grows, the neural network can approximate more complex reward functions, but this also increases uncertainty in predictions, directly scaling the regret bound. The NTK matrix H must be positive semi-definite with bounded eigenvalues, and context vectors must be normalized and structured for meaningful clustering.

### Mechanism 2
Clustering the context space allows the algorithm to exploit similarity among arms, reducing super arm selection complexity. By grouping arms with similar contexts into clusters and selecting the top K arms from the best cluster, the algorithm avoids exhaustive search over all possible super arms while leveraging monotonicity to guarantee near-optimal selection. The context space must have an underlying clustered structure that matches ground-truth clusters over time.

### Mechanism 3
Using two neural networks—one for base arm rewards and one for super arm rewards—enables learning both reward functions without requiring an optimization oracle. The base arm network estimates individual arm rewards; its outputs (after ReLU) are fed to the monotonic super arm network, which respects the monotonicity assumption and outputs a super arm reward estimate used to guide cluster selection. The super arm reward function must be monotonic and Lipschitz continuous in base arm rewards.

## Foundational Learning

- **Neural Tangent Kernel (NTK) and its effective dimension**: The regret bound depends on the effective dimension ed of the NTK matrix, quantifying the model's capacity and generalization ability. Quick check: If the NTK matrix H has eigenvalues that decay rapidly, what happens to the effective dimension ed?

- **Semi-bandit feedback and combinatorial bandit structure**: The algorithm observes both individual base arm rewards and a total super arm reward each round, essential for training both neural networks and updating UCB estimates. Quick check: In a semi-bandit setting with K selected arms, how many individual reward observations are available per round?

- **Monotonic neural network architecture**: The super arm network must preserve the monotonicity assumption of the reward function to ensure theoretical guarantees and effective super arm selection. Quick check: What weight transformation is applied to each layer to guarantee monotonicity in the network output?

## Architecture Onboarding

- **Component map**: Context preprocessing -> k-means clustering -> Base arm network (ReLU) -> Super arm network (monotonic) -> UCB computation -> Cluster selection -> Reward observation -> Network updates

- **Critical path**: 1. Observe contexts → 2. Cluster arms → 3. Compute UCBs → 4. Select cluster and K arms → 5. Observe rewards → 6. Update networks → 7. Update confidence bounds

- **Design tradeoffs**: Using two networks avoids oracle dependency but increases computational cost and hyperparameter tuning complexity. Online clustering adapts to context drift but adds runtime overhead; offline clustering is faster but less flexible. Wider networks increase expressiveness but risk overfitting and higher regret if Condition 1 is not met.

- **Failure signatures**: Regret grows linearly (clustering accuracy degraded or context space lacks structure), high variance in performance (insufficient exploration or poor network initialization), slow convergence (learning rates too low or network width below Condition 1 threshold).

- **First 3 experiments**: 1) Run NeUClust with synthetic clustered contexts and known ground-truth clusters; verify that selected super arms match optimal arms within the best cluster. 2) Vary the number of clusters M and measure impact on regret and reward; confirm elbow plot behavior matches expectations. 3) Disable the monotonicity constraint in the super arm network and observe whether regret degrades, confirming the importance of the monotonicity assumption.

## Open Questions the Paper Calls Out

### Open Question 1
How does the clustering error bound in Lemma 3 depend on the number of clusters M relative to the number of arms N? The paper assumes N clusters exist but does not analyze the tradeoff between M and N in the regret bound. Evidence would require an explicit analysis showing how regret scales with M/N and under what conditions M should grow with N.

### Open Question 2
Can NeUClust achieve sublinear regret in the super arm size K without requiring an oracle? Lemma 3 shows a linear K term in Ut that the authors attribute to not using an oracle. Evidence would require a modified algorithm or theoretical proof showing sublinear K dependence is achievable without an oracle.

### Open Question 3
How sensitive is NeUClust's performance to the choice of clustering algorithm and initialization? The experiments use k-means with fixed iterations and number of clusters, but the theoretical regret bound assumes perfect clustering. Evidence would require empirical studies showing regret sensitivity to different clustering algorithms, initializations, and numbers of clusters across various datasets.

## Limitations
- Theoretical guarantees hinge on monotonicity assumption and clustering accuracy, neither empirically validated in experiments
- Neural network architectures and training procedures lack full specification, particularly for the monotonic super arm network
- Clustering approach may fail when context space lacks clear cluster structure, leading to linear regret growth

## Confidence
- **High confidence**: Dual-network architecture with UCB-based selection is clearly specified and implemented
- **Medium confidence**: Clustering-based super arm selection is theoretically justified but depends heavily on context space structure
- **Low confidence**: NTK-based regret bound and impact of effective dimension ed on practical performance not empirically validated

## Next Checks
1. Test clustering robustness by running ablation studies varying number of clusters M and context noise levels; measure impact on regret and reward
2. Validate monotonicity constraint by disabling it in the super arm network and observing whether regret degrades
3. Analyze NTK effective dimension by tracking ed during training and correlating with regret growth; test whether increasing network width beyond threshold improves or harms performance