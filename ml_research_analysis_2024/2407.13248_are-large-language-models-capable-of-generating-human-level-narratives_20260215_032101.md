---
ver: rpa2
title: Are Large Language Models Capable of Generating Human-Level Narratives?
arxiv_id: '2407.13248'
source_url: https://arxiv.org/abs/2407.13248
tags:
- story
- human
- turning
- narrative
- stories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a comprehensive framework for analyzing narratives
  through three discourse-level aspects: story arcs, turning points, and affective
  dimensions. The authors conduct an extensive study comparing human and AI-generated
  stories, finding that LLMs struggle with narrative pacing, suspense, and diversity
  compared to human writers.'
---

# Are Large Language Models Capable of Generating Human-Level Narratives?

## Quick Facts
- arXiv ID: 2407.13248
- Source URL: https://arxiv.org/abs/2407.13248
- Authors: Yufei Tian; Tenghao Huang; Miri Liu; Derek Jiang; Alexander Spangher; Muhao Chen; Jonathan May; Nanyun Peng
- Reference count: 40
- Primary result: LLMs struggle with narrative pacing, suspense, and diversity compared to human writers

## Executive Summary
This paper presents a comprehensive framework for analyzing narratives through three discourse-level aspects: story arcs, turning points, and affective dimensions. The authors conduct an extensive study comparing human and AI-generated stories, finding that LLMs struggle with narrative pacing, suspense, and diversity compared to human writers. They also benchmark LLM narrative comprehension abilities, showing that most models fall short of human performance in story arc and turning point identification. Finally, the paper demonstrates that incorporating discourse features into the generation process significantly improves LLM storytelling, achieving over 40% improvement in narrative diversity, suspense, and arousal.

## Method Summary
The paper employs a three-stage approach: first, collecting and annotating 819 movie synopses from Wikipedia, with 440 narratives annotated by humans for story arcs and turning points; second, benchmarking LLM performance on story arc and turning point identification tasks using multiple models including GPT-4, Llama3, and others; third, implementing discourse-aware generation approaches that incorporate story arcs and turning points into the generation process to improve narrative quality. The study uses both automated metrics and human evaluation to assess improvements in diversity, suspense, and emotional engagement.

## Key Results
- Most LLMs fall short of human abilities in discourse understanding, particularly in story arc and turning point identification
- Incorporating discourse-level features into the generation stage significantly improves LLM narrative construction, with over 40% improvement in diversity, suspense, and arousal
- LLMs show a bias toward positive story arcs (Rags to Riches, Cinderella) and struggle with narrative pacing and emotional development compared to human writers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating discourse-level features into the generation stage significantly improves LLM narrative construction, including reduced plot holes and enhanced suspense and emotion provocation.
- Mechanism: The explicit integration of story arcs and turning points during the generation process provides structural guidance that helps LLMs better pace the narrative, develop critical plot junctures, and create more engaging storylines with appropriate emotional dynamics.
- Core assumption: Narrative discourse structures (story arcs, turning points, affective dimensions) are fundamental building blocks that can be explicitly encoded and used as generative constraints to improve story quality.
- Evidence anchors:
  - [abstract] "explicit integration of aforementioned discourse features can enhance storytelling, as is demonstrated by over 40% improvement in neural storytelling in terms of diversity, suspense, and arousal"
  - [section 6] "Incorporating discourse reasoning in prompts can serve as important guidance towards better story generation" and "integrating awareness of story arcs enhances model diversity (outperforming vanilla prompting by 45%)"
- Break condition: If the discourse features are poorly defined, incorrectly extracted, or if the LLM's generation capacity cannot effectively utilize the additional structural constraints, the mechanism will fail to produce improvements.

### Mechanism 2
- Claim: Most LLMs fall short of human abilities in discourse understanding, which negatively impacts their narrative generation capabilities.
- Mechanism: LLMs struggle to comprehend and apply macro-level narrative structures (story arcs) and meso-level plot progressions (turning points), leading to unnatural pacing, lack of suspense, and limited narrative diversity in their generated stories.
- Core assumption: Narrative comprehension skills are prerequisites for narrative generation abilities, and deficits in comprehension directly manifest as deficits in generation quality.
- Evidence anchors:
  - [abstract] "most LLMs fall short of human abilities in discourse understanding" and "LLMs struggle with narrative pacing, suspense, and diversity compared to human writers"
  - [section 5] Benchmark results showing that LLMs achieve significantly lower accuracy than humans in story arc identification (GPT-4 only 27.3% vs human 59.6%) and turning point identification tasks
- Break condition: If the evaluation methodology for discourse understanding is flawed, or if the LLM architectures being tested have different capabilities than assumed, the mechanism linking comprehension deficits to generation quality may not hold.

### Mechanism 3
- Claim: Different discourse levels reinforce each other, with micro-level affective information improving macro-level narrative structure identification and vice versa.
- Mechanism: The integration of information across narrative discourse levels creates a synergistic effect where understanding finer-grained elements (like turning points) helps identify broader structures (like story arcs), and understanding the overall arc helps identify specific turning points.
- Core assumption: Narrative discourse elements are interconnected rather than independent, and models can leverage this interdependency to improve comprehension across levels.
- Evidence anchors:
  - [abstract] "we find that the different discourse-levels reinforce each other: we can improve turning point identification including story arc information in the input, and vice versa"
  - [section 5] Results showing that providing story arc information as prior improves turning point identification accuracy for some models (2% improvement for GPT-4 and Llama3), and providing turning point information significantly improves story arc identification across all models
- Break condition: If the discourse levels are more independent than assumed, or if the models cannot effectively integrate cross-level information, the reinforcement mechanism will not produce the observed improvements.

## Foundational Learning

- Concept: Narrative discourse structures (story arcs, turning points, affective dimensions)
  - Why needed here: These are the core analytical framework used throughout the paper to evaluate and improve LLM storytelling capabilities. Understanding these concepts is essential for interpreting the results and implementing the discourse-aware generation approaches.
  - Quick check question: Can you explain the difference between a story arc and a turning point, and give an example of each from a well-known story?

- Concept: Narrative comprehension vs. generation capabilities
  - Why needed here: The paper's central hypothesis is that poor narrative comprehension leads to poor narrative generation, so distinguishing between these abilities is crucial for understanding the research framework and interpreting the benchmark results.
  - Quick check question: If an LLM can identify story arcs with high accuracy but struggles to generate stories with appropriate arcs, what might this indicate about the relationship between comprehension and generation?

- Concept: Discourse-aware generation techniques
  - Why needed here: The paper proposes and evaluates methods for incorporating discourse features into the generation process, so understanding how to implement and evaluate these techniques is essential for building on this work.
  - Quick check question: How would you modify a standard LLM prompt to incorporate explicit story arc information, and what metrics would you use to evaluate whether this improves the generated narrative?

## Architecture Onboarding

- Component map: Data collection pipeline -> Annotation framework -> Evaluation benchmarks -> Generation enhancement modules -> Analysis tools
- Critical path: 1. Collect and preprocess narrative corpus, 2. Conduct expert annotations for ground truth, 3. Evaluate baseline LLM comprehension capabilities, 4. Implement discourse-aware generation approaches, 5. Evaluate improved generation quality, 6. Analyze results and draw conclusions
- Design tradeoffs: Annotation cost vs. dataset size (440 annotated narratives limited by expert annotation cost), Automation vs. accuracy (automated arousal/valence calculation using NRC-VAD vs. human annotation), Model size vs. performance (testing various model sizes to understand capabilities)
- Failure signatures: Flat narrative curves in arousal/valence analysis indicate lack of suspense and emotional engagement, Early positioning of major setback and climax turning points suggests poor pacing, Over-representation of positive story arcs indicates bias toward positive outcomes, Low accuracy on discourse comprehension benchmarks reveals fundamental limitations
- First 3 experiments: 1. Replicate the turning point identification benchmark using a different LLM (e.g., Claude 3) to verify the general trend of comprehension deficits, 2. Implement the self-generated TP approach and compare suspense scores against the outline-only baseline using human evaluation, 3. Test the arc-enhanced approach with a less common story arc (e.g., Oedipus) to evaluate the model's ability to follow complex narrative instructions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic features or narrative structures distinguish human-generated stories from LLM-generated stories in terms of pacing and emotional development?
- Basis in paper: [explicit] The paper identifies differences in pacing and emotional development between human and LLM-generated stories, noting that LLMs struggle with narrative pacing, suspense, and diversity.
- Why unresolved: The paper mentions these differences but does not provide a detailed linguistic or structural analysis of what specifically causes these discrepancies.
- What evidence would resolve it: A detailed linguistic analysis comparing human and LLM-generated stories, identifying specific features such as sentence length, vocabulary choice, and narrative structure that contribute to differences in pacing and emotional development.

### Open Question 2
- Question: How do different discourse features (story arcs, turning points, affective dimensions) interact and influence each other in narrative comprehension and generation?
- Basis in paper: [explicit] The paper discusses three discourse-level aspects (story arcs, turning points, and affective dimensions) and their impact on narrative comprehension and generation, noting that incorporating discourse features improves LLM storytelling.
- Why unresolved: While the paper shows that incorporating discourse features improves LLM storytelling, it does not explore the complex interactions between these features and how they might reinforce or contradict each other in narrative understanding and generation.
- What evidence would resolve it: A comprehensive study examining the interplay between story arcs, turning points, and affective dimensions in both human and LLM-generated narratives, using advanced modeling techniques to quantify their interactions and effects.

### Open Question 3
- Question: Can LLMs be trained or fine-tuned to generate narratives that are more diverse in story arcs and emotionally engaging, without explicit prompts for specific discourse features?
- Basis in paper: [explicit] The paper shows that LLMs have a bias towards certain story arcs and lack narrative diversity, but also demonstrates that incorporating discourse features can improve storytelling.
- Why unresolved: The paper focuses on improving LLM storytelling through explicit incorporation of discourse features, but does not explore whether LLMs can be trained to generate more diverse and emotionally engaging narratives without such explicit guidance.
- What evidence would resolve it: Experiments comparing the narrative output of LLMs trained with and without explicit discourse feature prompts, measuring diversity in story arcs and emotional engagement through human evaluations and automated metrics.

## Limitations
- Expert annotation shows moderate inter-annotator agreement (0.62 Cohen's Kappa), suggesting inherent subjectivity in narrative structure identification
- Study relies on movie synopses rather than full narratives, which may not capture the complexity of longer-form storytelling
- Automated arousal/valence calculations using NRC-VAD may miss context-dependent nuances that human evaluation would capture

## Confidence

**High Confidence**: The comparative results showing LLM underperformance in narrative comprehension tasks (story arc and turning point identification) are robust, supported by multiple models and clear statistical differences from human performance.

**Medium Confidence**: The claimed 40% improvement in narrative quality through discourse-aware generation is promising but based on limited human evaluation samples and specific evaluation metrics.

**Low Confidence**: The generalization of findings from movie synopses to broader narrative types (novels, short stories, etc.) requires additional validation.

## Next Checks

1. **Cross-domain validation**: Test the discourse-aware generation approach on different narrative domains (e.g., novels, news articles) to verify the generalizability of the 40% improvement claim.
2. **Long-term narrative coherence**: Evaluate whether discourse-aware generation maintains quality and coherence over longer narrative sequences (beyond typical synopsis length).
3. **Alternative annotation frameworks**: Replicate the comprehension benchmarks using alternative narrative structure frameworks (e.g., Labov's narrative structure) to test the robustness of the LLM comprehension deficit findings.