---
ver: rpa2
title: Oracle-Checker Scheme for Evaluating a Generative Large Language Model
arxiv_id: '2405.03170'
source_url: https://arxiv.org/abs/2405.03170
tags:
- entity
- gpt3
- checker
- sentence
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel approach called the oracle-checker
  scheme for evaluating the answers given by a generative large language model (LLM).
  The key idea is to use two types of checkers - one based on property testing and
  another based on program checking - to validate the LLM's outputs.
---

# Oracle-Checker Scheme for Evaluating a Generative Large Language Model

## Quick Facts
- **arXiv ID**: 2405.03170
- **Source URL**: https://arxiv.org/abs/2405.03170
- **Reference count**: 40
- **Primary result**: Novel oracle-checker scheme uses property testing and program checking to validate generative LLM outputs for entity extraction and paraphrase decision tasks

## Executive Summary
This paper introduces an oracle-checker scheme for evaluating answers from generative large language models (LLMs). The scheme employs two types of checkers - one based on property testing and another on program checking - to validate LLM outputs by articulating subjective trustworthiness views. Demonstrated on entity extraction and paraphrase decision tasks, the approach uses linearity tests for entity independence verification and compositional phrase alignment for semantic equivalence checking. The checkers can effectively assess trustworthiness and provide insights into LLM behavior, particularly useful when subjective trustworthiness views are difficult to articulate or for domain-specific inputs with unique data characteristics.

## Method Summary
The oracle-checker scheme uses GPT3.5 as an oracle for entity extraction and paraphrase decision tasks. For entity extraction, a linearity test verifies independence through synonym replacement and entity replacement functions. For paraphrase decision, compositional phrase alignment finds matching paths between syntactic trees to establish semantic equivalence, while a trust strategy checker uses GPT3.5's own paraphrases to verify "no" answers. The method is evaluated on DOCRED and RISC-V datasets for entity extraction, and MSR Paraphrase corpus for paraphrase decision, measuring acceptance rates and consistency between checker and oracle outputs.

## Key Results
- Linearity test successfully verifies entity extraction independence with probabilistic guarantees
- Compositional phrase alignment effectively identifies semantically equivalent sentence pairs
- Trust strategy checker identifies contradictions in GPT3.5's "no" answers about semantic equivalence
- Checker-based approach provides valuable insights into LLM behavior and trustworthiness assessment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The linearity checker verifies that GPT3.5's entity extraction is independent of other entities' presence.
- **Mechanism**: For a given sentence, the checker replaces entities with synonyms according to random characteristic vectors. If GPT3.5's extraction results are consistent under these transformations, the entities are considered linear (independent).
- **Core assumption**: Entities can be meaningfully replaced by synonyms without altering their core identity in the sentence context.
- **Evidence anchors**:
  - [abstract] "The first type of checker follows the idea of property testing."
  - [section] "Theorem 3.1...If f is a homomorphism from G1 to G2, the test passes with probability 1."
- **Break condition**: If synonym replacement changes the entity's core identity or if GPT3.5's entity extraction is context-dependent rather than independent.

### Mechanism 2
- **Claim**: The proof strategy checker finds compositional phrase alignments to verify semantic equivalence.
- **Mechanism**: The checker parses sentences into syntactic trees, finds matching paths between nodes, and verifies that all non-propositional words are covered by aligned phrases. If such an alignment exists, semantic equivalence is proven.
- **Core assumption**: Semantic equivalence can be established through compositional phrase alignment between sentences.
- **Evidence anchors**:
  - [abstract] "The second type of checker follows the idea of program checking."
  - [section] "Two sentences are said to be semantically equivalent if an alignment ρ can be established between them."
- **Break condition**: If semantic equivalence cannot be captured by compositional phrase alignment or if the parsing/alignment process fails.

### Mechanism 3
- **Claim**: The trust strategy checker uses GPT3.5's own paraphrases to verify its "no" answers on semantic equivalence.
- **Mechanism**: When GPT3.5 says two sentences are not semantically equivalent, the checker generates paraphrases of both sentences. If GPT3.5 claims the paraphrases are equivalent to both original sentences, this creates a contradiction that invalidates the "no" answer.
- **Core assumption**: GPT3.5's own paraphrase generation can be used to create contradictions that expose incorrect "no" answers.
- **Evidence anchors**:
  - [abstract] "Under the trust strategy, the person accepts an answer if the oracle passes a type of truthfulness test."
  - [section] "The checker needs the capability that it can 'pick a ρ-alignment randomly' and use it to transform a random choice of s1 and s2."
- **Break condition**: If GPT3.5's paraphrase generation is inconsistent or if the checker cannot find indifferentiable paraphrases to create contradictions.

## Foundational Learning

- **Property testing concepts**
  - Why needed here: Understanding how property testing can verify that GPT3.5's outputs satisfy certain mathematical properties (like linearity) without knowing the exact function.
  - Quick check question: If a function f is ϵ-far from being a homomorphism, what is the minimum probability that the linearity test will fail according to Theorem 3.1?

- **Graph isomorphism and program checking**
  - Why needed here: The proof strategy for semantic equivalence is inspired by graph isomorphism checking, where finding a permutation proves isomorphism.
  - Quick check question: How does the concept of finding a permutation in graph isomorphism translate to finding a ρ-alignment in semantic equivalence checking?

- **Compositional phrase alignment**
  - Why needed here: The proof strategy relies on finding phrase alignments between sentences to establish semantic equivalence.
  - Quick check question: What is the difference between a ρ-alignment and a ϕ-alignment in the context of semantic equivalence checking?

## Architecture Onboarding

- **Component map**: GPT3.5 (oracle) -> Linearity checker/Proof checker/Trust checker -> User
- **Critical path**:
  1. User provides input sentence(s) to GPT3.5
  2. GPT3.5 performs entity extraction or semantic equivalence decision
  3. Checker runs appropriate test (linearity, proof, or trust)
  4. Checker returns acceptance/rejection based on test results
- **Design tradeoffs**:
  - Property testing vs. exact verification: Linearity test provides probabilistic guarantees but not certainty
  - Computational complexity vs. accuracy: More sophisticated alignment methods may be more accurate but slower
  - Oracle dependence vs. checker capability: Checkers rely on GPT3.5's outputs but need to be simpler than GPT3.5
- **Failure signatures**:
  - Linearity test: High rejection rate indicates context-dependent entity extraction
  - Proof checker: Failure to find alignments suggests sentences are not semantically equivalent or checker limitations
  - Trust checker: Rejection of "no" answers indicates potential contradictions in GPT3.5's responses
- **First 3 experiments**:
  1. Run linearity test on DOCRED dataset to establish baseline acceptance rate
  2. Test proof checker on MSR Paraphrase corpus to verify semantic equivalence detection
  3. Run trust checker on GPT3.5-generated paraphrases to validate "no" answers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the checker's design be optimized to better handle weak entities and multi-form entities in entity extraction?
- Basis in paper: [explicit] The paper discusses the challenges posed by weak entities and multi-form entities, noting that these can lead to test failures and reduced consistency in entity extraction results.
- Why unresolved: The paper acknowledges the existence of these issues but does not provide specific strategies for optimizing the checker to handle them effectively.
- What evidence would resolve it: Developing and testing new algorithms or methods within the checker that specifically address the challenges of weak and multi-form entities, and demonstrating improved performance in handling these cases.

### Open Question 2
- Question: Can the oracle-checker scheme be extended to other natural language processing tasks beyond entity extraction and paraphrase decision?
- Basis in paper: [inferred] The paper introduces a novel approach for evaluating generative LLMs using the oracle-checker scheme, suggesting potential applicability to other NLP tasks.
- Why unresolved: The paper focuses on two specific tasks (entity extraction and paraphrase decision) and does not explore the broader applicability of the scheme to other NLP tasks.
- What evidence would resolve it: Implementing and evaluating the oracle-checker scheme on additional NLP tasks, such as sentiment analysis or machine translation, and assessing its effectiveness and adaptability.

### Open Question 3
- Question: How does the choice of synonym generation method impact the effectiveness of the linearity test in entity extraction?
- Basis in paper: [explicit] The paper discusses the reliance on a synonym generator (syn) and entity replacement function (R) for the linearity test, indicating that the test's effectiveness depends on these methods.
- Why unresolved: The paper does not explore the impact of different synonym generation methods on the linearity test's performance or provide guidance on optimizing this component.
- What evidence would resolve it: Conducting experiments with various synonym generation methods and comparing their impact on the linearity test's acceptance rates and accuracy in entity extraction.

## Limitations
- The linearity test assumes entities can be meaningfully replaced by synonyms without altering core identity
- Compositional phrase alignment may not capture all semantic relationships between sentences
- Trust strategy checker's effectiveness depends on consistency of GPT3.5's paraphrase generation

## Confidence

| Component | Confidence Level | Rationale |
|-----------|------------------|-----------|
| Entity extraction linearity testing | Medium | Theoretical foundation is sound but practical implementation details need more exploration |
| Semantic equivalence checking | Low-Medium | Shows promise but lacks extensive validation across diverse semantic phenomena |
| Trust strategy checker | Low | Most speculative mechanism requiring additional theoretical grounding |

## Next Checks
1. **Edge Case Analysis**: Systematically test the linearity checker on sentences with multi-word entities, nested entities, and context-dependent entities to identify failure patterns.
2. **Semantic Coverage Validation**: Evaluate the compositional alignment method on a benchmark dataset containing various types of semantic relationships (entailment, contradiction, paraphrase, similarity) to assess its coverage.
3. **Checker-Oracle Consistency**: Compare checker decisions with human judgments on a sample of outputs to establish the checker's reliability independent of the oracle's performance.