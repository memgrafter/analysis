---
ver: rpa2
title: 'Dynamic Depth Decoding: Faster Speculative Decoding for LLMs'
arxiv_id: '2409.00142'
source_url: https://arxiv.org/abs/2409.00142
tags:
- eagle-2
- draft
- decoding
- eagle
- dynamic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Dynamic Depth Decoding (DDD), an optimization
  of EAGLE-2's speculative decoding algorithm for large language models. DDD improves
  draft model efficiency by dynamically adjusting the beam search depth based on draft
  model confidence, rather than using a fixed depth.
---

# Dynamic Depth Decoding: Faster Speculative Decoding for LLMs

## Quick Facts
- arXiv ID: 2409.00142
- Source URL: https://arxiv.org/abs/2409.00142
- Reference count: 5
- Key outcome: Dynamic Depth Decoding (DDD) achieves 3.16x average speedup compared to vanilla autoregressive decoding, outperforming EAGLE-2's 3.07x by 44% on MT-bench with temperature 0.

## Executive Summary
This paper introduces Dynamic Depth Decoding (DDD), an optimization of EAGLE-2's speculative decoding algorithm that improves draft model efficiency by dynamically adjusting beam search depth based on draft model confidence. DDD employs a heuristic threshold on the sum of sequence probabilities to determine when to stop drafting, optimizing runtime by breaking lazy evaluation only when checking the heuristic. Experiments show DDD achieves an average speedup of 3.16x compared to vanilla autoregressive decoding, outperforming EAGLE-2's 3.07x by 44% on MT-bench with temperature 0. However, results differ from EAGLE-2's published benchmarks, likely due to hardware variations.

## Method Summary
DDD optimizes EAGLE-2's tree drafting method using a dynamic depth that adapts based on draft model confidence. The algorithm uses a heuristic threshold on the sum of sequence probabilities (logprobsum) to determine when to stop drafting, allowing the draft model to be called a variable number of times per target model call. The heuristic is checked at specific steps (S = {5, 7, 9}) with a threshold x = -0.3, and the maximum draft steps n = 11. The approach is tested on MT-bench with temperature 0 using Vicuna-7B, Vicuna-13B, LLaMA2-Chat 7B, and LLaMA2-Chat 13B models on a single NVIDIA A40 GPU.

## Key Results
- DDD achieves an average speedup of 3.16x compared to vanilla autoregressive decoding
- DDD outperforms EAGLE-2's 3.07x speedup by 44% on MT-bench with temperature 0
- On average, EAGLE-2 outperforms EAGLE by 8%, and DDD outperforms EAGLE-2 by 4%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DDD improves draft model efficiency by dynamically adjusting beam search depth based on draft model confidence
- Mechanism: DDD uses a heuristic threshold on the sum of sequence probabilities to determine when to stop drafting, allowing variable draft model calls per target model call
- Core assumption: EAGLE-2's draft model confidence approximates the acceptance rate of draft tokens, and this relationship holds for other draft models
- Evidence anchors: Abstract states DDD achieves 3.16x speedup, outperforming EAGLE-2 by 44%; section confirms EAGLE-2's confidence approximation holds for other draft models

### Mechanism 2
- Claim: DDD breaks lazy evaluation only when checking the heuristic, optimizing runtime
- Mechanism: While running the draft model, EAGLE-2 never uses data-dependent control flow, allowing lazy evaluation; DDD partially avoids this slowdown by not checking the heuristic every step
- Core assumption: Breaking lazy evaluation between every draft model call causes significant slowdown
- Evidence anchors: Section explains that heuristic checking requires immediate evaluation and causes slowdown; section notes DDD avoids checking heuristic every step

### Mechanism 3
- Claim: DDD achieves 3.16x average speedup compared to vanilla autoregressive decoding
- Mechanism: DDD's dynamic depth adjustment generates more tokens per forward pass of the target model, leading to higher speedup ratio
- Core assumption: Dynamic depth adjustment is more efficient than EAGLE-2's fixed depth approach
- Evidence anchors: Abstract states 3.16x speedup; section shows EAGLE-2 outperforms EAGLE by 8% and DDD outperforms EAGLE-2 by 4%

## Foundational Learning

- Concept: Beam search in language models
  - Why needed here: DDD uses beam search with dynamic depth, understanding beam search fundamentals is crucial
  - Quick check question: What is the main advantage of using beam search over greedy decoding in language models?

- Concept: Lazy evaluation in deep learning frameworks
  - Why needed here: DDD's runtime optimization relies on breaking lazy evaluation only when necessary
  - Quick check question: How does lazy evaluation improve the performance of deep learning computations?

- Concept: Speculative decoding in large language models
  - Why needed here: DDD is an optimization of EAGLE-2's speculative decoding algorithm
  - Quick check question: What is the main idea behind speculative decoding in large language models, and how does it help accelerate inference?

## Architecture Onboarding

- Component map: Prompt -> Draft model -> Beam search -> Target model -> Output

- Critical path:
  1. Run the draft model on the input prompt
  2. Postprocess draft model output to produce a beam using EAGLE-2's algorithm
  3. Calculate log probabilities of sequences in the beam
  4. Iteratively run draft model on the beam, postprocess output, and update log probabilities
  5. Check heuristic threshold at specified steps to determine whether to continue drafting
  6. Stop drafting if threshold is not met, otherwise continue until maximum steps reached

- Design tradeoffs:
  - Dynamic depth vs. fixed depth: DDD's dynamic adjustment allows more efficient drafting but requires additional computations for heuristic checking
  - Heuristic threshold frequency: Less frequent checking reduces overhead but may lead to suboptimal drafting decisions
  - Beam width: Wider beam search may lead to more accurate token sequences but increases computational cost

- Failure signatures:
  - Heuristic threshold set too high: drafting stops prematurely, leading to suboptimal token sequences
  - Heuristic threshold set too low: drafting continues unnecessarily, reducing speedup gains
  - Beam width too small: draft model may not explore enough token sequences, leading to suboptimal choices

- First 3 experiments:
  1. Implement DDD with fixed depth and compare performance to EAGLE-2 to isolate effect of dynamic depth adjustment
  2. Vary heuristic threshold and measure impact on speedup ratio and token acceptance rate to find optimal threshold value
  3. Compare performance of DDD with different beam widths to determine optimal balance between accuracy and computational cost

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DDD perform on different hardware compared to EAGLE-2's published benchmarks?
- Basis in paper: [explicit] The paper notes that their hardware causes different speedup results compared to EAGLE-2's published benchmarks
- Why unresolved: Experiments were conducted on a single NVIDIA A40 GPU, which may not be representative of other hardware configurations
- What evidence would resolve it: Running DDD and EAGLE-2 on the same hardware used in EAGLE-2's original publication would provide comparable results

### Open Question 2
- Question: What is the optimal heuristic checking frequency for DDD on different models and hardware?
- Basis in paper: [inferred] Authors empirically determined S = {5, 7, 9} for their experiments, but this may not be optimal for all scenarios
- Why unresolved: Optimal checking frequency likely depends on specific model architecture, hardware, and other factors not systematically explored
- What evidence would resolve it: Systematic study varying heuristic checking frequency across different models and hardware would identify optimal configurations

### Open Question 3
- Question: Can DDD be implemented without breaking lazy evaluation to avoid the associated slowdown?
- Basis in paper: [explicit] Paper acknowledges that heuristic check breaks lazy evaluation, causing slowdown, and suggests this as a limitation
- Why unresolved: Current implementation requires breaking lazy evaluation when checking heuristic, but authors suggest this could be improved
- What evidence would resolve it: Developing and demonstrating an implementation of DDD achieving same performance benefits without breaking lazy evaluation would resolve this question

## Limitations
- Hardware dependency: Results obtained on single NVIDIA A40 GPU, with different speedup results compared to EAGLE-2's published benchmarks due to hardware variations
- Limited benchmark scope: Experiments conducted only on MT-bench with temperature 0, generalizability to other benchmarks or temperature settings unclear
- Heuristic sensitivity: Dynamic depth adjustment relies on specific heuristic threshold (-0.3) checked at predetermined steps, paper doesn't thoroughly explore sensitivity to parameter variations

## Confidence

- Speedup claims (3.16x average, 44% improvement over EAGLE-2): Medium confidence - methodology is sound but hardware dependencies and limited benchmark scope create uncertainty
- Mechanism explanations (dynamic depth adjustment, lazy evaluation optimization): High confidence - mechanisms are clearly described and logically explained
- Generalization claims: Low confidence - paper doesn't provide evidence for how well DDD performs across different hardware, benchmarks, or parameter settings

## Next Checks
1. Reproduce experiments on multiple hardware configurations (different GPU models, potentially CPU-only) to assess hardware dependency and validate claimed speedup improvements across platforms

2. Test DDD on additional benchmarks beyond MT-bench, including different temperature settings and task types, to evaluate generalizability and robustness

3. Conduct systematic parameter sensitivity analysis by varying heuristic threshold values and checking frequencies to determine how robust speedup improvements are to parameter choices