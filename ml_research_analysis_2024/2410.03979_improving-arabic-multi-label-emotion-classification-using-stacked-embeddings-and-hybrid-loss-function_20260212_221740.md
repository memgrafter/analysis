---
ver: rpa2
title: Improving Arabic Multi-Label Emotion Classification using Stacked Embeddings
  and Hybrid Loss Function
arxiv_id: '2410.03979'
source_url: https://arxiv.org/abs/2410.03979
tags:
- loss
- arabic
- emotion
- classification
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel method for multi-label emotion classification
  in Arabic text, addressing challenges of class imbalance and label correlation.
  The approach combines stacked embeddings from three fine-tuned Arabic language models
  (ArabicBERT, MarBERT, and AraBERT), a meta-learner using Bi-LSTM, and a hybrid loss
  function incorporating class weighting, label correlation matrix, and contrastive
  learning.
---

# Improving Arabic Multi-Label Emotion Classification using Stacked Embeddings and Hybrid Loss Function

## Quick Facts
- arXiv ID: 2410.03979
- Source URL: https://arxiv.org/abs/2410.03979
- Reference count: 40
- Primary result: Proposed method achieves precision 0.82, recall 0.81, F1-score 0.81, Jaccard accuracy 0.67, and Hamming loss 0.15 on Arabic emotion classification

## Executive Summary
This paper addresses the challenges of multi-label emotion classification (MLEC) in Arabic text by proposing a novel framework that combines stacked embeddings from multiple fine-tuned language models with a hybrid loss function. The approach tackles two critical issues: class imbalance and label correlation, which are prevalent in emotion classification datasets. The method extracts contextual embeddings from ArabicBERT, MarBERT, and AraBERT, stacks them to create enriched representations, and processes them through a meta-learner (Bi-LSTM) trained with a hybrid loss incorporating class weighting, label correlation matrix, and contrastive learning. Experimental results on the SemEval-2018 Task 1-Ec-Ar dataset demonstrate significant improvements over state-of-the-art models, particularly in predicting minority emotion classes.

## Method Summary
The proposed method consists of three main components: (1) Stacked embeddings from three fine-tuned Arabic language models (ArabicBERT, MarBERT, AraBERT) that are concatenated to form enriched representations, (2) A meta-learner using Bi-LSTM architecture that processes these stacked embeddings to capture sequential dependencies, and (3) A hybrid loss function that combines class weighting to address imbalance, a label correlation matrix to capture emotional dependencies, and contrastive learning to improve discriminative power. The framework is evaluated on the SemEval-2018 Task 1-Ec-Ar dataset containing 4,381 Arabic tweets with 11 emotion labels.

## Key Results
- The proposed method achieves precision of 0.82, recall of 0.81, and F1-score of 0.81 on the SemEval-2018 Task 1-Ec-Ar dataset
- Jaccard accuracy of 0.67 and Hamming loss of 0.15 demonstrate effective multi-label classification performance
- Class-wise performance analysis shows significant improvements in predicting minority emotion classes compared to baseline models
- Ablation study confirms the effectiveness of each component, particularly highlighting the impact of the hybrid loss function

## Why This Works (Mechanism)

### Mechanism 1
Stacked embeddings from multiple fine-tuned Arabic models capture complementary linguistic features, improving overall representation quality. Each base model (ArabicBERT, MarBERT, AraBERT) is fine-tuned on the emotion dataset, learning task-specific features. Their embeddings are concatenated, allowing the meta-learner to benefit from diverse strengths of each model. This works because different models encode different aspects of Arabic language (MSA vs dialectal) and stacking them provides richer contextual information than any single model.

### Mechanism 2
The hybrid loss function effectively addresses class imbalance and label correlation, improving minority class performance. The loss combines class weighting (emphasizing minority classes), a label correlation matrix (capturing label dependencies), and contrastive learning (improving discriminative power). This integrated approach balances contributions from each component, addressing the main obstacles in Arabic MLEC: class imbalance, label correlation, and need for discriminative representations.

### Mechanism 3
The meta-learner (Bi-LSTM) trained on stacked embeddings performs effective sequence learning, improving final classification accuracy. The concatenated embeddings are passed through a Bi-LSTM to capture sequential dependencies, followed by dense layers for multi-label classification. This second-stage learner refines predictions based on richer input representations, effectively modeling temporal patterns in the embedding sequences for emotion classification.

## Foundational Learning

- **Multi-label classification with class imbalance**: Why needed here - Arabic emotion dataset has highly imbalanced classes; standard losses fail to handle this, leading to poor minority class performance. Quick check: What happens to model performance if you use standard BCE loss on an imbalanced multi-label dataset?

- **Contrastive learning in NLP**: Why needed here - Contrastive learning helps the model learn discriminative representations by pulling similar samples together and pushing dissimilar ones apart, crucial for distinguishing similar emotions. Quick check: How does contrastive loss differ from standard cross-entropy in terms of what it optimizes for?

- **Label correlation in multi-label tasks**: Why needed here - Emotions often co-occur (e.g., joy and optimism); capturing these dependencies improves prediction accuracy for related labels. Quick check: Why might ignoring label correlations hurt performance in multi-label emotion classification?

## Architecture Onboarding

- **Component map**: Data preprocessing → Three fine-tuned PLMs (ArabicBERT, MarBERT, AraBERT) → Stacked embeddings → Meta-learner (Bi-LSTM + Dense) → Hybrid loss (CW + LCM + CL) → Multi-label output
- **Critical path**: Stacked embeddings extraction → Meta-learner training → Hybrid loss optimization
- **Design tradeoffs**: Stacked embeddings increase model capacity and richness but also computational cost and risk of overfitting; hybrid loss balances multiple objectives but requires careful tuning of weighting coefficients; Bi-LSTM adds sequence modeling capability but may be unnecessary if embeddings are already highly contextual
- **Failure signatures**: Overfitting (high training performance but low validation/test performance); class imbalance not addressed (majority classes dominate predictions; minority class metrics remain low); label correlation issues (model fails to predict co-occurring emotions together)
- **First 3 experiments**: 1) Baseline: Use single PLM (e.g., ArabicBERT) with standard BCE loss to establish lower bound; 2) Ablation: Replace hybrid loss with only class weighting to assess its individual impact; 3) Full stack: Use all three PLMs with hybrid loss to confirm stacked embeddings + meta-learner benefit

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the proposed hybrid loss function perform when applied to other low-resource languages with different linguistic structures? The paper states the framework "can be adapted to other languages and domains," but performance on other languages remains untested. Empirical results from applying the approach to languages like Urdu, Swahili, or indigenous languages would resolve this.

- **Open Question 2**: What is the optimal combination of pre-trained language models for stacking in the embedding layer across different domains? The study uses ArabicBERT, MarBERT, and AraBERT based on Arabic language coverage but does not systematically explore whether this combination is optimal for other domains. Comparative experiments testing different combinations of pre-trained models across various classification tasks would resolve this.

- **Open Question 3**: How does the model scale with larger datasets, and what are the computational trade-offs of using stacked embeddings versus single model embeddings? The paper focuses on a relatively small dataset and does not discuss scalability or computational efficiency. Benchmarking the model's performance and training/inference time on larger datasets, comparing resource usage with single-model approaches, would resolve this.

- **Open Question 4**: Can the hybrid loss function be extended to handle multi-modal emotion classification tasks (e.g., text + audio or text + video)? The loss function addresses class imbalance and label correlation in text-based classification but does not consider multi-modal inputs. Implementation and evaluation of the hybrid loss in a multi-modal emotion classification framework would resolve this.

## Limitations

- The study uses only a single Arabic emotion dataset without validation on additional datasets or cross-domain testing, limiting generalizability
- Optimal weighting coefficients for the hybrid loss function components are not systematically explored, potentially leaving performance on the table
- Computational overhead of stacking three large language models is not explicitly discussed, raising concerns about practical deployment

## Confidence

**High Confidence**: The claim that stacked embeddings from multiple fine-tuned Arabic models improve performance is well-supported by the ablation study and aligns with established practices in representation learning.

**Medium Confidence**: The effectiveness of the hybrid loss function in addressing class imbalance and label correlation is demonstrated on the specific dataset, but optimal configuration remains uncertain.

**Low Confidence**: The generalizability of the framework to other low-resource languages or different emotion taxonomies is speculative and not empirically validated in the study.

## Next Checks

1. **Cross-Dataset Validation**: Test the complete framework (stacked embeddings + hybrid loss) on a different Arabic emotion dataset to verify whether performance gains transfer to new data distributions.

2. **Weighting Coefficient Optimization**: Conduct systematic grid search or Bayesian optimization over the hybrid loss weighting coefficients to determine if the current configuration represents a local optimum.

3. **Computational Efficiency Analysis**: Measure and compare the inference time and memory requirements of the stacked embedding approach versus single-model alternatives on the same hardware, quantifying practical tradeoffs.