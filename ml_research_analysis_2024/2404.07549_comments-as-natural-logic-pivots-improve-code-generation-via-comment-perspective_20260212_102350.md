---
ver: rpa2
title: 'Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective'
arxiv_id: '2404.07549'
source_url: https://arxiv.org/abs/2404.07549
tags:
- code
- comments
- pass
- comment
- power
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes that code comments serve as natural logic pivots
  between natural language and programming language, and suggests using comments to
  enhance the code generation ability of small and medium-sized code LLMs. The proposed
  method, MANGO, includes a comment contrastive training strategy and a corresponding
  logical comment decoding strategy.
---

# Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective

## Quick Facts
- arXiv ID: 2404.07549
- Source URL: https://arxiv.org/abs/2404.07549
- Authors: Yijie Chen; Yijin Liu; Fandong Meng; Yufeng Chen; Jinan Xu; Jie Zhou
- Reference count: 8
- Key outcome: MANGO improves code pass rates up to 7.52 pass@10 on HumanEval for StarCoder-7B and up to 4.17 pass@10 on MBPP for WizardCoder-7B

## Executive Summary
This paper proposes MANGO, a method that leverages code comments as natural logic pivots between natural language problem descriptions and programming language implementations. The approach includes a comment contrastive training strategy that strengthens the model's preference for generating code with comments, and a logical comment decoding strategy that guides the model to use comments as intermediate reasoning steps. Experiments demonstrate that MANGO significantly improves code generation performance for small and medium-sized code LLMs (3B-7B parameters) on HumanEval and MBPP benchmarks.

## Method Summary
MANGO (comMents As Natural loGic pivOts) is a two-phase method that first fine-tunes code models using standard supervised learning with an additional comment contrastive loss, then applies logical comment prompting during inference. The contrastive learning component creates negative samples by removing comments from code snippets and applies margin-based loss to encourage the model to prefer code with comments. During inference, the logical comment prompting strategy adds instructions to generate code with explanatory inline comments, effectively using comments as intermediate reasoning steps between problem descriptions and code implementation.

## Key Results
- MANGO achieves up to 7.52 pass@10 on HumanEval for StarCoder-7B and 4.17 pass@10 on MBPP for WizardCoder-7B
- The method shows particularly strong performance for smaller models, where the robustness of logical comment prompting exceeds Chain-of-thoughts prompting
- Ablation studies confirm that both the comment contrastive training and logical comment decoding strategies contribute to performance improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Code comments serve as natural logic pivots that bridge natural language problem descriptions and code implementation.
- Mechanism: Comments decompose complex problem descriptions into intermediate steps aligned with adjacent code lines, reducing the semantic gap between natural language and programming language.
- Core assumption: Code comments naturally interpret local code lines using natural language text, and this decomposition function of comments can be leveraged by LLMs to improve code generation.
- Evidence anchors:
  - [abstract] "code comments are the natural logic pivot between natural language and code language"
  - [section] "comments within the code are commonly integral to code corpus. Consequently, during the pre-training stage, training on code corpus endows the pre-trained code models with the respective capacities for understanding and generating code comments"
  - [corpus] Weak evidence - related works focus on comment generation and evaluation but don't directly support the pivot hypothesis
- Break condition: If comments in the training corpus are predominantly superficial or non-explanatory, the pivot function may not be learned effectively.

### Mechanism 2
- Claim: Comment contrastive learning strengthens the model's preference for generating code with comments.
- Mechanism: By creating negative samples without comments and applying contrastive loss, the model learns to prefer code snippets that include explanatory comments.
- Core assumption: The model can distinguish between code with and without comments and that this distinction improves code generation quality.
- Evidence anchors:
  - [section] "we adopt a contrastive learning approach to encourage the model to emphasize code comments more during the fine-tuning process"
  - [section] "For a code snippet ypos containing comments, we use an open-source code parsing tool to remove the comments and obtain the non-preferred contrastive sample yneg"
  - [corpus] Moderate evidence - contrastive learning is established in other domains but specific application to code comments is novel
- Break condition: If the margin hyperparameter is set too high or too low, the contrastive signal may be ineffective or counterproductive.

### Mechanism 3
- Claim: Logical comment prompting guides the model to intentionally use comments as intermediate steps during generation.
- Mechanism: Adding specific instructions to prompts that request code with comments explaining the logic causes the model to generate more interpretable and correct code.
- Core assumption: The model can follow instructions to include comments and that these comments improve the overall code generation process.
- Evidence anchors:
  - [section] "the logical comment decoding strategy is adopted to guide the model to explain the code logic via inline comments"
  - [section] "Adding a corresponding instruction in the prompt is the method with minimum cost"
  - [corpus] Weak evidence - while comment generation is studied, the specific use of comments as reasoning aids during generation is novel
- Break condition: If the prompt instructions are ambiguous or the model lacks sufficient comment generation capability, the strategy may fail.

## Foundational Learning

- Concept: Cross-entropy loss and its role in supervised fine-tuning
  - Why needed here: The paper builds contrastive learning on top of standard cross-entropy loss for code generation
  - Quick check question: What is the difference between standard cross-entropy loss and the contrastive loss proposed in MANGO?

- Concept: Contrastive learning and margin-based loss functions
  - Why needed here: The comment contrastive learning component uses a margin to create a preference for code with comments
  - Quick check question: How does the margin parameter affect the contrastive learning objective?

- Concept: Chain-of-thought prompting and its variants
  - Why needed here: The paper compares its approach against CoT prompting and analyzes when each strategy works best
  - Quick check question: What are the key differences between CoT prompting and the logical comment prompting strategy?

## Architecture Onboarding

- Component map:
  - Training phase: Standard SFT with comment contrastive loss (Llm + Lcl)
  - Inference phase: Logical comment prompting strategy
  - Evaluation: Pass@k metrics on HumanEval and MBPP datasets

- Critical path:
  1. Fine-tune model with standard SFT objective
  2. Apply comment contrastive learning with margin m
  3. During inference, use LCP prompt to generate code with comments
  4. Evaluate using pass@k metrics

- Design tradeoffs:
  - Comment quality vs. generation speed: More detailed comments may improve understanding but increase generation time
  - Margin hyperparameter tuning: Requires careful selection to balance contrastive signal strength
  - Prompt engineering vs. training complexity: LCP is low-cost compared to additional training components

- Failure signatures:
  - Low pass rates despite contrastive training: May indicate margin setting issues or insufficient comment quality in training data
  - High variance across prompt variants: Suggests model sensitivity to prompt phrasing or insufficient instruction following capability
  - Comments present but code incorrect: Indicates comments are not effectively serving as logic pivots

- First 3 experiments:
  1. Baseline comparison: Run SFT-only training and measure pass@k on HumanEval
  2. Ablation study: Test MANGO with and without contrastive loss component
  3. Robustness check: Evaluate performance across different margin values (0.03, 0.05, 0.10, 0.15)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of MANGO scale with model size beyond the tested range of 3B to 7B parameters?
- Basis in paper: The paper evaluates MANGO on models ranging from 3B to 7B parameters but does not explore its performance on larger models like GPT-4.
- Why unresolved: The study's scope is limited to small and medium-sized models, leaving the potential benefits and limitations of MANGO on larger models unexplored.
- What evidence would resolve it: Conducting experiments with larger models, such as those with 10B+ parameters, to compare the effectiveness of MANGO against baseline methods like CoT.

### Open Question 2
- Question: Can MANGO's comment contrastive learning approach be generalized to other programming languages beyond Python?
- Basis in paper: The experiments and training data are focused on Python, suggesting that the approach might be language-specific.
- Why unresolved: The paper does not investigate the applicability of MANGO to other programming languages, which could limit its generalizability.
- What evidence would resolve it: Applying MANGO to code generation tasks in other programming languages and evaluating its performance relative to baselines.

### Open Question 3
- Question: What is the impact of varying the margin parameter (m) in the comment contrastive learning loss on the model's performance?
- Basis in paper: The paper mentions that the margin parameter is set to 0.1 for all models but does not explore how different values affect the outcomes.
- Why unresolved: The sensitivity of the model's performance to the margin parameter is not thoroughly investigated, leaving its optimal value uncertain.
- What evidence would resolve it: Performing a detailed sensitivity analysis by testing different margin values and observing their effects on the model's pass rates.

## Limitations

- The method relies heavily on comment quality in the training corpus; if comments are predominantly superficial, the pivot function may not be learned effectively
- Effectiveness may be limited to problems where comments naturally decompose tasks into intermediate steps, providing less benefit for holistic reasoning problems
- The contrastive learning approach assumes code with comments is inherently better, which may not hold for all cases where well-written code without comments is more efficient

## Confidence

- **High confidence**: Experimental results showing improved pass@k metrics for MANGO compared to baselines on HumanEval and MBPP datasets
- **Medium confidence**: The claim that comments serve as natural logic pivots - plausible but not directly evidenced
- **Low confidence**: The assertion that logical comment prompting strategy is "notably higher" than CoT prompting in all cases - lacks comprehensive statistical analysis

## Next Checks

1. **Comment Quality Analysis**: Analyze the distribution of comment quality in the training corpus and evaluate whether MANGO's performance correlates with the proportion of high-quality explanatory comments.

2. **Problem-Type Specific Performance**: Conduct a detailed analysis of MANGO's performance across different problem types on HumanEval and MBPP, particularly focusing on problems where natural decomposition into comment-guided steps is less obvious versus problems requiring holistic reasoning.

3. **Generalization to Unseen Code Patterns**: Test MANGO's performance on code generation tasks involving patterns and constructs not well-represented in the training corpus to assess whether the comment-based reasoning generalizes beyond memorized patterns.