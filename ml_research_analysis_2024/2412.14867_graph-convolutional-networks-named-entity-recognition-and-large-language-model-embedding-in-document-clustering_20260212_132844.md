---
ver: rpa2
title: 'Graph-Convolutional Networks: Named Entity Recognition and Large Language
  Model Embedding in Document Clustering'
arxiv_id: '2412.14867'
source_url: https://arxiv.org/abs/2412.14867
tags:
- clustering
- graph
- named
- document
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a document clustering method that integrates
  Named Entity Recognition (NER) and Large Language Model (LLM) embeddings within
  a graph-convolutional network framework. The approach builds a graph where documents
  are nodes connected by edges weighted by named entity similarity, optimized using
  a GCN to improve semantic clustering.
---

# Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering

## Quick Facts
- arXiv ID: 2412.14867
- Source URL: https://arxiv.org/abs/2412.14867
- Authors: Imed Keraghel; Mohamed Nadif
- Reference count: 40
- Primary result: Proposed GCC* model achieved NMI scores of 95.12% on BBC News and 72.42% on MLSUM, significantly outperforming traditional methods

## Executive Summary
This paper introduces a novel document clustering method that integrates Named Entity Recognition (NER) and Large Language Model (LLM) embeddings within a graph-convolutional network framework. The approach constructs a graph where documents are nodes connected by edges weighted by named entity similarity, then optimizes clustering using a Graph Convolutional Network (GCN). Experiments on four datasets demonstrate significant improvements over traditional co-occurrence-based techniques, particularly for documents rich in named entities.

## Method Summary
The method builds a document graph where nodes represent documents and edges are weighted by named entity similarity. Named entities are extracted using NER models (CamemBERT-ner, DeBERTa, or GPT-4o depending on dataset), and Word2Vec is trained to capture entity similarity. Document links are established when named entity similarity exceeds threshold τ > 0.9 with at least three common entities. LLM embeddings (BERT-based) serve as node features X_ℓₗₘ, while the GCN jointly optimizes node embeddings and clustering assignments through an objective function combining reconstruction loss and clustering loss.

## Key Results
- GCC* achieved highest clustering performance across all datasets, with NMI reaching 95.12% on BBC News and 72.42% on MLSUM
- GCC* outperformed GCC(knn, ℓₗₘ) by up to 13% on BBC News, demonstrating the value of NER-based graph construction
- The method showed particular effectiveness on BBC News and MLSUM datasets, which contain rich named entity content
- Traditional co-occurrence-based approaches consistently underperformed compared to the NER-LLM-GCN framework

## Why This Works (Mechanism)

### Mechanism 1: Named Entity Recognition (NER) improves document clustering by capturing semantic relationships that co-occurrence methods miss.
NER identifies key entities (e.g., people, organizations, locations) in documents. These entities serve as semantic anchors, and documents sharing similar entities are more likely to be semantically related, even if their surface-level word overlap is low. Core assumption: Named entities are reliable indicators of document topic and semantic similarity.

### Mechanism 2: LLM embeddings provide richer contextual representations than traditional TF-IDF, improving semantic clustering.
LLM models like BERT generate embeddings that capture word meanings in context, not just frequency. These embeddings form the node feature matrix X_ℓₗₘ, encoding deeper semantic relationships between documents. Core assumption: LLM embeddings better represent semantic similarity than lexical features.

### Mechanism 3: Graph Convolutional Networks (GCNs) jointly optimize node embeddings and clustering, leading to better cluster assignments than separate steps.
The GCN framework simultaneously learns document embeddings and cluster assignments through a unified objective. This joint optimization ensures embeddings are shaped to be clustering-friendly. Core assumption: Joint optimization of embeddings and clustering yields better results than sequential approaches.

## Foundational Learning

- Concept: Graph representation learning
  - Why needed here: Documents are modeled as nodes in a graph, with edges representing semantic relationships. Understanding graph representations is crucial for implementing the NER-based graph construction and GCN optimization.
  - Quick check question: How does the adjacency matrix Aner encode relationships between documents based on named entity similarity?

- Concept: Named Entity Recognition (NER)
  - Why needed here: NER extracts key entities from documents, which form the basis for the graph edges. Without understanding NER, you cannot implement the entity similarity search or graph construction.
  - Quick check question: What types of named entities (e.g., PERSON, ORGANIZATION) are most relevant for document clustering in different domains?

- Concept: Large Language Model (LLM) embeddings
  - Why needed here: LLM embeddings replace traditional TF-IDF features as node representations. Understanding how to generate and use these embeddings is essential for the model.
  - Quick check question: How do you handle documents that exceed the token limits of your chosen LLM embedding model?

## Architecture Onboarding

- Component map: NER module → Word2Vec module → Graph construction module → LLM embedding module → GCC/GCC* module → Evaluation module
- Critical path: NER extraction → Word2Vec training → Entity similarity computation → Graph construction → LLM embedding generation → Joint optimization (GCC*) → Cluster assignment
- Design tradeoffs:
  - Entity similarity threshold τ: Higher thresholds produce sparser graphs but more reliable edges; lower thresholds create denser graphs but risk noise
  - Power parameter p in GCN: Controls neighborhood information aggregation; too low misses context, too high causes oversmoothing
  - Entity types: Including/excluding certain entity types (e.g., locations vs. organizations) affects graph quality and clustering performance
- Failure signatures:
  - Poor clustering performance: Check if entity similarity threshold is too high (sparse graph) or too low (noisy edges)
  - GCN convergence issues: Verify if the graph is too sparse or if the power parameter p is inappropriate
  - High computational cost: Consider reducing document length or using smaller LLM models
- First 3 experiments:
  1. Run GCC* with default parameters on BBC News dataset and verify it achieves NMI > 95%
  2. Test different entity similarity thresholds (τ = 0.8, 0.9, 0.95) and observe impact on clustering performance
  3. Compare GCC* with GCC(knn, ℓₗₘ) on the same dataset to verify the benefit of NER-based graph construction

## Open Questions the Paper Calls Out

### Open Question 1
How do different types of named entities (e.g., organizations, locations, events) contribute to clustering performance, and which entity types are most relevant for specific clustering tasks? The paper suggests future work exploring whether specific named entity types are more relevant than others for certain clustering tasks, which could lead to more refined document groupings and reveal thematic relationships.

### Open Question 2
What is the optimal threshold for named entity similarity that balances precision and recall in document clustering? The paper uses a fixed similarity threshold (τ > 0.9) and a minimum of three common named entities to establish document links, but does not explore the impact of varying these parameters.

### Open Question 3
How does the power parameter p in the graph convolution operation affect clustering performance, and what is the optimal value for different datasets? The paper mentions that p controls neighborhood information captured by the GCN and affects the smoothness of node embeddings, noting that p = 2 or 3 was optimal for their datasets, but this was determined empirically without systematic exploration.

## Limitations
- Word2Vec parameter configuration remains unspecified, which could significantly impact entity similarity calculations and subsequent graph construction
- Performance claims rely heavily on specific datasets (BBC News, MLSUM) with high named entity density, raising questions about effectiveness on domains with sparse named entity content
- The paper lacks direct comparison between LLM embeddings and traditional TF-IDF features, making it difficult to isolate the contribution of each component

## Confidence

- High confidence: The core mechanism of using NER for graph construction is well-supported by evidence showing that named entities capture semantic relationships missed by co-occurrence methods.
- Medium confidence: The claim that GCN joint optimization improves clustering performance is plausible but lacks direct ablation studies comparing it to sequential approaches.
- Medium confidence: The superiority of LLM embeddings over traditional methods is asserted but not empirically validated against TF-IDF baselines within the same experimental framework.

## Next Checks

1. Systematically vary the named entity similarity threshold τ (0.8, 0.85, 0.9, 0.95) and document length limits to determine their impact on clustering performance across different domains.

2. Conduct an ablation study comparing GCC* performance against variants using only NER-based graphs, only LLM embeddings, and only GCN optimization to quantify individual contribution of each component.

3. Test the model on datasets with varying named entity densities (e.g., scientific abstracts, news articles, social media) to assess generalizability beyond the current evaluation set.