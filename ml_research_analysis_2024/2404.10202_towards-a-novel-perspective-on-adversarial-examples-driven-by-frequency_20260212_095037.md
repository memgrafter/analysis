---
ver: rpa2
title: Towards a Novel Perspective on Adversarial Examples Driven by Frequency
arxiv_id: '2404.10202'
source_url: https://arxiv.org/abs/2404.10202
tags:
- adversarial
- frequency
- attack
- bands
- perturbations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the frequency characteristics of adversarial
  perturbations using wavelet packet decomposition to gain deeper insights into adversarial
  examples. The authors discover that significant adversarial perturbations are predominantly
  present in the high-frequency components of low-frequency bands, challenging the
  common view that adversarial perturbations are purely high-frequency signals.
---

# Towards a Novel Perspective on Adversarial Examples Driven by Frequency

## Quick Facts
- arXiv ID: 2404.10202
- Source URL: https://arxiv.org/abs/2404.10202
- Reference count: 15
- Primary result: Achieved 99% attack success rate using frequency-based black-box adversarial attack

## Executive Summary
This paper investigates the frequency characteristics of adversarial perturbations using wavelet packet decomposition, challenging the conventional view that adversarial perturbations are purely high-frequency signals. The authors discover that significant adversarial perturbations are predominantly present in the high-frequency components of low-frequency bands, providing new insights into the nature of adversarial examples. Based on this finding, they propose a black-box adversarial attack algorithm that combines low-frequency bands with high-frequency components of low-frequency bands, achieving an average attack success rate of 99% across multiple datasets and models. Additionally, the paper introduces the normalized disturbance visibility (NDV) index to address limitations of L2 norm in assessing continuous and discrete perturbations, offering a more accurate measure aligned with human visual perception.

## Method Summary
The paper employs wavelet packet decomposition (WPD) to analyze the frequency characteristics of adversarial examples generated using FGSM and PGD attacks. By decomposing both clean and adversarial images into multiple frequency bands, the authors identify that adversarial perturbations are not confined to high-frequency bands but are significantly present in high-frequency components of low-frequency bands. Based on this observation, they propose a black-box adversarial attack algorithm that selects specific frequency bands for perturbation, achieving high attack success rates. The method also introduces the normalized disturbance visibility (NDV) index as an alternative to L2 norm for evaluating perturbation visibility, particularly for discrete perturbations that L2 norm fails to accurately assess.

## Key Results
- Discovered that significant adversarial perturbations exist in high-frequency components of low-frequency bands, not just in high-frequency bands
- Achieved 99% average attack success rate across CIFAR-10, CIFAR-100, and ImageNet datasets using the proposed black-box attack algorithm
- Introduced NDV index that provides more accurate perturbation visibility assessment than L2 norm, particularly for discrete perturbations

## Why This Works (Mechanism)
The effectiveness of the proposed method stems from the discovery that adversarial perturbations, while inherently high-frequency, depend on low-frequency information from preceding levels in the wavelet decomposition hierarchy. This relationship allows the attack to leverage low-frequency bands while targeting high-frequency components within them, creating more effective perturbations that are harder to detect. The NDV index works by normalizing perturbation visibility against the original image content, providing a more perceptually accurate measure than absolute distance metrics like L2 norm.

## Foundational Learning
- **Wavelet Packet Decomposition**: Multi-resolution signal decomposition technique that separates signals into frequency sub-bands at multiple scales. Needed to analyze the frequency distribution of adversarial perturbations. Quick check: Verify that WPD correctly decomposes images into the expected number of frequency bands.

- **Adversarial Perturbation Characteristics**: Understanding how small, carefully crafted changes to input data can cause misclassification in deep learning models. Needed to contextualize the frequency analysis findings. Quick check: Confirm that generated adversarial examples successfully fool target models.

- **Frequency-Band Dependency**: The relationship between low and high-frequency components where high-frequency perturbations depend on low-frequency information. Needed to explain why combining bands improves attack effectiveness. Quick check: Test attack success rate when using only high-frequency bands versus combined bands.

## Architecture Onboarding

Component Map: Input Image -> WPD -> Frequency Band Selection -> Perturbation Generation -> Adversarial Example

Critical Path: The key process involves applying WPD to input images, selecting specific frequency bands (low-frequency bands and high-frequency components of low-frequency bands), generating perturbations in these bands, and combining them to create effective adversarial examples.

Design Tradeoffs: The method balances attack effectiveness against perturbation visibility by carefully selecting frequency bands that maximize success rate while minimizing perceptual changes. Using combined bands increases attack success but may slightly increase visibility compared to pure high-frequency attacks.

Failure Signatures: Poor frequency band selection leads to low attack success rates. Incorrect WPD implementation results in inaccurate frequency analysis. Inadequate perturbation generation in selected bands fails to create effective adversarial examples.

First Experiments:
1. Apply WPD to clean and adversarial images to verify frequency distribution patterns
2. Generate adversarial examples using only high-frequency bands versus combined bands to measure effectiveness difference
3. Compare NDV index values with L2 norm for various perturbation patterns to validate improved accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How can wavelet functions be designed to better separate adversarial perturbations from normal image components? The paper states that current wavelet functions are inadequate for the separation of adversarial perturbations and suggests designing new wavelet functions specifically for the characteristics of adversarial perturbations might facilitate a more complete separation. This remains unresolved because existing WPD does not fully isolate adversarial perturbations, as they are distributed across multiple frequency bands rather than confined to a single band. Development and testing of new wavelet functions that successfully isolate adversarial perturbations into distinct frequency bands, validated through improved detection or defense against adversarial attacks, would resolve this question.

### Open Question 2
What is the exact mechanism by which low-frequency information influences the effectiveness of high-frequency adversarial perturbations? The paper finds that adversarial perturbations, although inherently high-frequency, depend on the low-frequency information from their preceding levels, suggesting a dependency between low and high-frequency components. This relationship is identified but the underlying mechanism of how low-frequency information affects high-frequency perturbations is not explained. Detailed analysis or experiments showing how manipulating low-frequency components impacts the effectiveness of high-frequency adversarial perturbations, possibly through controlled ablation studies, would resolve this question.

### Open Question 3
How does the NDV index perform compared to L2 norm in real-world adversarial attack scenarios where perturbations are not uniformly distributed? The paper introduces the NDV index as a more accurate measure of perturbation visibility than L2 norm, especially for discrete perturbations, but does not extensively compare their performance in practical attack scenarios. The paper provides theoretical justification and some examples but lacks comprehensive empirical validation across diverse attack scenarios. Comparative studies of NDV and L2 norm performance in detecting or quantifying perturbations in various real-world adversarial attacks, including both continuous and discrete perturbations, would resolve this question.

## Limitations
- The paper does not specify exact wavelet functions and parameters used for WPD, which could significantly impact frequency analysis results
- Implementation details of the NDV index are not fully elaborated, potentially affecting reproducibility
- Focus on three specific datasets and models (CIFAR-10, CIFAR-100, ImageNet with ResNet-50, DenseNet-121, and InceptionV3) may limit generalizability to other domains or architectures

## Confidence

High confidence in the general findings about frequency characteristics of adversarial examples and the effectiveness of the proposed attack algorithm.

Medium confidence in the NDV index due to incomplete implementation details.

Low confidence in the generalizability of results to other datasets and models not tested in this study.

## Next Checks

1. Reproduce the wavelet packet decomposition with specified wavelet functions and parameters to verify frequency analysis results.

2. Implement and validate the normalized disturbance visibility (NDV) index to ensure it provides more accurate perturbation assessments than L2 norm.

3. Test the proposed black-box attack algorithm on additional datasets and models beyond CIFAR-10, CIFAR-100, and ImageNet to evaluate its generalizability.