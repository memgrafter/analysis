---
ver: rpa2
title: Identifying and interpreting non-aligned human conceptual representations using
  language modeling
arxiv_id: '2403.06204'
source_url: https://arxiv.org/abs/2403.06204
tags:
- features
- blind
- sighted
- similarity
- retained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a supervised representational-alignment method
  to determine whether two groups of individuals share the same basis of a certain
  category and to explain in what respects they differ. The method applies supervised
  feature-pruning to a language model (GloVe) to optimize prediction accuracy of human
  similarity judgments from word embeddings, separately for blind and sighted individuals.
---

# Identifying and interpreting non-aligned human conceptual representations using language modeling

## Quick Facts
- arXiv ID: 2403.06204
- Source URL: https://arxiv.org/abs/2403.06204
- Authors: Wanqian Bao; Uri Hasson
- Reference count: 21
- Key outcome: Introduces a supervised representational-alignment method to determine whether two groups share the same category basis and explain their differences, applied to study how blindness impacts conceptual representation of everyday verbs.

## Executive Summary
This study presents a novel approach to identify and interpret differences in how blind and sighted individuals conceptualize verbs. By applying supervised feature-pruning to GloVe word embeddings, the researchers optimized prediction accuracy of human similarity judgments separately for blind and sighted participants. A linear probing analysis then mapped retained features to interpretable semantic dimensions, revealing that blind individuals show stronger associations between motion verbs and social/cognitive meanings, while demonstrating sparser information for amodal verbs. This work provides both a methodological framework for studying interindividual differences in word meaning and empirical insights into how blindness shapes conceptual representations.

## Method Summary
The study employs supervised feature-pruning on GloVe word embeddings to identify subsets of features that optimally predict human similarity judgments for different verb categories and populations (blind vs. sighted). Pruning iteratively removes features contributing least to prediction accuracy, retaining between 20-30% of the original 300 features. A linear probing analysis using Partial Least Squares Regression (PLSR) then maps these retained features to 65 interpretable semantic dimensions from Binder et al. (2016). Cross-validation verifies generalization, and Dice coefficient analysis assesses overlap between pruning solutions across verb categories and groups.

## Key Results
- Pruning successfully identified feature subsets that maintained or exceeded baseline prediction accuracy while using only 20-30% of original features
- Blind individuals showed stronger associations between motion verbs and social/cognitive meanings compared to sighted individuals
- For amodal verbs, blind participants demonstrated significantly sparser information representation than sighted participants
- Different verb categories mapped to distinct embedding subspaces, with minimal feature overlap between categories

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pruning reduces feature space while preserving predictive accuracy for human similarity judgments
- Mechanism: Iterative feature removal that retains only those contributing most to predicting similarity matrices
- Core assumption: Pruned embeddings' cosine similarity correlates strongly with human similarity judgments
- Evidence anchors: Abstract states pruning optimizes prediction for both groups; section reports generalization success using 20-30% of features
- Break condition: If retained features fail to predict human similarity judgments better than chance or full feature set

### Mechanism 2
- Claim: PLSR probing reveals semantic differences between blind and sighted representations
- Mechanism: Mapping retained features to 65 interpretable semantic dimensions quantifies group differences
- Core assumption: Binder et al.'s 65 dimensions adequately capture relevant semantic space
- Evidence anchors: Abstract describes mapping to 65 dimensions; section reports prediction was "often very good" with five domains better predicted for blind in Perception-Touch verbs
- Break condition: If PLSR predictions show no correlation with ground truth ratings or differences aren't statistically significant

### Mechanism 3
- Claim: Different verb categories map to different embedding subspaces
- Mechanism: Low Dice coefficients between pruning solutions indicate category-specific semantic subspaces
- Core assumption: Non-overlapping features indicate fundamentally different semantic representations
- Evidence anchors: Abstract notes highest Dice coefficients found in diagonal (same verb type across groups); section states analysis "strongly suggests" different verb categories map to different dimensions
- Break condition: If high Dice coefficients found across all verb categories indicating shared features

## Foundational Learning

- Concept: Supervised pruning and feature selection
  - Why needed here: To identify minimal feature subsets that optimally predict human similarity judgments for different populations
  - Quick check question: How does the pruning algorithm determine which features to retain?

- Concept: Partial Least Squares Regression (PLSR) and probing tasks
  - Why needed here: To map retained features to interpretable semantic dimensions and compare blind vs. sighted representations
  - Quick check question: What is the relationship between prediction accuracy in probing task and semantic differences between groups?

- Concept: Representational Similarity Analysis (RSA) limitations
  - Why needed here: To understand why authors chose pruning+probing instead of directly comparing similarity matrices
  - Quick check question: What are key limitations of RSA that motivated current methodology?

## Architecture Onboarding

- Component map: Data preprocessing -> Supervised pruning -> Probing task (PLSR) -> Analysis (Dice coefficients, prediction accuracy comparison, clustering)
- Critical path: Data preprocessing → Supervised pruning → Probing task → Analysis
- Design tradeoffs:
  - GloVe vs. contextualized embeddings (GloVe chosen for established performance)
  - 65 dimensions vs. more/less (65 chosen as balance between granularity and interpretability)
  - Pruning vs. other feature selection methods (pruning chosen for ability to optimize prediction accuracy)
- Failure signatures:
  - Pruning fails to improve prediction accuracy over baseline
  - Probing task predictions show no correlation with ground truth ratings
  - No significant differences between blind and sighted in prediction accuracy
- First 3 experiments:
  1. Apply pruning to single verb category (e.g., Perception-Sight) and verify prediction accuracy improvement
  2. Run probing task on pruned features for one group (e.g., sighted) and check PLSR prediction quality
  3. Compare prediction accuracy between blind and sighted for single semantic domain (e.g., cognition) to identify potential differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do word embeddings trained on different corpora and architectures (GloVe vs. word2vec vs. BERT) compare in predicting human similarity judgments for blind and sighted individuals?
- Basis in paper: [explicit] Notes GloVe is competitive with other algorithms but differences appear minor; mentions using additional datasets could offer more comprehensive view
- Why unresolved: Study used only GloVe; comparing different models requires additional experiments
- What evidence would resolve it: Conducting same analyses with embeddings from different models and corpora and comparing prediction accuracy

### Open Question 2
- Question: How does age of onset of blindness affect conceptual representation of verbs? Would later-onset blind individuals show different patterns than congenitally blind?
- Basis in paper: [inferred] Study focuses on congenitally blind; mentions question of how blind and sighted differ is still open
- Why unresolved: Only congenitally blind participants included; different age groups would require different study design
- What evidence would resolve it: Conducting same analyses with blind individuals of different ages of onset and comparing to congenitally blind group

### Open Question 3
- Question: How do identified semantic dimensions relate to cognitive and neural processing differences between groups? Are there specific brain regions showing differential activation?
- Basis in paper: [inferred] Identifies specific dimensions differentially predicted; mentions methodological implications for understanding interindividual differences
- Why unresolved: Study is behavioral/computational; linking to neural processing requires neuroimaging studies
- What evidence would resolve it: Conducting fMRI/EEG studies with both groups processing verbs from different semantic domains and comparing neural activation patterns

## Limitations

- Reliance on single dataset (Bedny et al., 2019) limits generalizability of findings
- Semantic dimensions from Binder et al. (2016) may not fully capture all relevant aspects of verb meaning, particularly for blind individuals' unique experiences
- Pruning algorithm's generalization capability across different verb categories and populations not fully validated

## Confidence

- Supervised pruning mechanism: Medium
- Category-specific subspace claims: Low-Medium
- Semantic difference interpretations: Medium

## Next Checks

1. Replicate pruning algorithm with different random seeds and cross-validation folds to assess stability of retained feature sets
2. Apply same methodology to a different dataset of human similarity judgments to test generalizability
3. Conduct statistical power analysis on Dice coefficient results to determine whether category-specific subspaces are reliably detected