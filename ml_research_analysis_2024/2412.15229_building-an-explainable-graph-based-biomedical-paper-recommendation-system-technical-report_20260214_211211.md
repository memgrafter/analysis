---
ver: rpa2
title: Building an Explainable Graph-based Biomedical Paper Recommendation System
  (Technical Report)
arxiv_id: '2412.15229'
source_url: https://arxiv.org/abs/2412.15229
tags:
- document
- documents
- recommendation
- system
- bm25
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: XGPRec is an explainable paper recommendation system for biomedical
  digital libraries that addresses high computational costs and lack of transparency
  in current neural approaches. It represents documents as small knowledge graphs
  and uses graph-based similarity measures combined with BM25 for recommendation.
---

# Building an Explainable Graph-based Biomedical Paper Recommendation System (Technical Report)

## Quick Facts
- arXiv ID: 2412.15229
- Source URL: https://arxiv.org/abs/2412.15229
- Authors: Hermann Kroll; Christin K. Kreutz; Bill Matthias Thang; Philipp Schaer; Wolf-Tilo Balke
- Reference count: 40
- Primary result: XGPRec achieves 0.61 recall on PM2020 vs 0.29 for PubMed Recommender while providing interpretable graph-based explanations

## Executive Summary
XGPRec is an explainable paper recommendation system for biomedical digital libraries that addresses high computational costs and lack of transparency in current neural approaches. It represents documents as small knowledge graphs and uses graph-based similarity measures combined with BM25 for recommendation. The system performs a two-stage retrieval process: first identifying candidate documents based on concept overlap, then scoring them using graph core similarity and text similarity. Evaluated on three biomedical benchmarks with 37M MEDLINE documents, XGPRec achieves comparable or better performance than PubMed's recommender while providing interpretable graph-based explanations showing shared patterns between input and recommended papers.

## Method Summary
The system transforms biomedical documents into small knowledge graphs capturing concept interactions, then uses a two-stage retrieval approach. First stage applies cheap concept/edge matching to filter candidates (achieving ~0.6 recall on PM2020), then second stage uses expensive graph core overlap scoring only on filtered candidates. Final recommendation scores combine graph core overlap with BM25 text scoring (0.6:0.4 weighting). The approach is particularly effective for concept-centric information needs, offering domain experts immediate visual understanding of recommendations without requiring training data.

## Key Results
- XGPRec achieves 0.61 recall on PM2020 vs 0.29 for PubMed Recommender
- First-stage retrieval (FSConcept/FSCore) achieves 0.6-0.61 recall with 0.8-0.9s processing time per document
- System handles 37M MEDLINE documents while providing interpretable graph-based explanations
- Particularly effective for concept-centric information needs in biomedical literature

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based representations enable explainable recommendations while maintaining computational efficiency
- Mechanism: Documents are transformed into small knowledge graphs capturing concept interactions, allowing similarity to be computed through graph pattern matching rather than expensive neural embeddings
- Core assumption: Concept interactions extracted from biomedical literature can be effectively represented as graph patterns that capture the essential semantic content
- Evidence anchors:
  - [abstract] "It represents documents as small knowledge graphs and uses graph-based similarity measures combined with BM25 for recommendation"
  - [section 3] "We tackled the two issues of high costs (in terms of retrieval and training data collection) and missing explainability by building upon graph-based document representations"
  - [corpus] Weak - neighboring papers focus on narrative query graphs but don't directly address the explainability-cost tradeoff
- Break condition: If concept extraction fails to capture meaningful relationships between entities, or if graph pattern matching becomes too computationally expensive for larger graphs

### Mechanism 2
- Claim: Two-stage retrieval with concept-driven and edge-driven filtering reduces computational complexity while maintaining recall
- Mechanism: First stage uses cheap concept/edge matching to filter candidates (achieving ~0.6 recall on PM2020), then second stage uses expensive graph core overlap scoring only on filtered candidates
- Core assumption: A large proportion of relevant documents can be identified through simple concept/edge overlap before applying expensive graph matching
- Evidence anchors:
  - [section 5.2] "FSConcept and FSNode achieved the highest recall of 0.6-0.61 and the lowest retrieval time of 0.8-0.9s per input document"
  - [section 3.3] "Given the document collection D and some input document d, its graph dgraph and its graph core dcore, we propose the following first stages"
  - [corpus] Missing - no neighboring papers explicitly describe this two-stage approach
- Break condition: If concept/edge filtering fails to capture relevant documents, or if the candidate set remains too large for efficient second-stage processing

### Mechanism 3
- Claim: Combining graph core overlap with BM25 text scoring provides better performance than either approach alone
- Mechanism: Final recommendation score is weighted combination (0.6 graph, 0.4 text) where graph captures semantic relationships and BM25 captures lexical matches
- Core assumption: Graph-based semantic relationships and BM25-based lexical matching capture complementary aspects of document relevance
- Evidence anchors:
  - [section 3.3] "XGPRec(di, dc) = wgraph · core-overlap(di, dc) + wtext · BM25(di, dc)"
  - [section 5.3] "On PM2020 and Genomics, XGPRec achieved comparable nDCG and precision to the PubMed Recommender but nearly doubled recall (0.61 vs 0.29 and 0.29 vs 0.13)"
  - [corpus] Weak - neighboring papers use various combinations but don't specifically evaluate this weighted combination approach
- Break condition: If graph core overlap and BM25 scores are highly correlated, the combination provides little benefit over either method alone

## Foundational Learning

- Concept: Graph-based document representation and knowledge graphs
  - Why needed here: The entire recommendation system is built on transforming documents into graph structures for similarity computation
  - Quick check question: How does the system handle documents with no extracted statements (edges)?

- Concept: Information retrieval fundamentals (TF-IDF, BM25, precision/recall metrics)
  - Why needed here: The system combines traditional IR methods with graph-based approaches, requiring understanding of both paradigms
  - Quick check question: What's the difference between nDCG@10 and nDCG@20 in evaluating recommendation quality?

- Concept: Two-stage retrieval architecture
  - Why needed here: The system uses an initial cheap filtering stage followed by expensive scoring, a common pattern in large-scale retrieval
  - Quick check question: Why use a flexible cutoff instead of a fixed k value for candidate retrieval?

## Architecture Onboarding

- Component map:
  - Document processing pipeline: text → concepts + statements → document graph → graph core
  - First-stage retrieval: concept-driven (FSConcept), edge-driven (FSCore), node-driven (FSNode)
  - Second-stage scoring: graph core overlap + BM25 weighted combination
  - Explanation generation: shared pattern visualization with additional candidate information
  - UI components: input document display, recommendation list, explanation graphs, document graph viewer

- Critical path:
  1. User inputs document ID
  2. Retrieve document data and generate graph core
  3. First-stage retrieval (FSConcept with flexible cutoff, k=1000)
  4. Second-stage scoring with XGPRec (0.6 graph, 0.4 BM25)
  5. Generate explanations for top recommendations
  6. Display results with interactive graphs

- Design tradeoffs:
  - Graph complexity vs. extraction accuracy: More complex graphs provide better semantic representation but increase computational cost and extraction error
  - First-stage recall vs. computational efficiency: Larger candidate sets improve recall but increase second-stage processing time
  - Explanation detail vs. cognitive load: More detailed explanations help understanding but may overwhelm users

- Failure signatures:
  - Low recall: First-stage filtering too aggressive, or graph cores poorly representing document content
  - Poor explanations: Graph cores missing key concepts, or explanation algorithm not capturing meaningful patterns
  - Slow performance: Candidate set too large, or graph core overlap computation inefficient

- First 3 experiments:
  1. Benchmark first-stage retrieval on small document subset (100 documents) to verify FSConcept achieves ~0.6 recall
  2. Test graph core overlap computation on candidate pairs to measure processing time per document
  3. Validate explanation generation with user study on sample recommendations to confirm interpretability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design test collections that fairly evaluate graph-based recommendation systems when many relevant documents lack graph representations?
- Basis in paper: [explicit] The authors discuss that their graph-based approach retrieved many documents not judged in test collections, and that not all test collection documents can be represented by document graphs
- Why unresolved: Current test collections were built using term-based retrieval methods, inherently favoring traditional approaches and penalizing graph-based methods for retrieving unjudged but potentially relevant documents
- What evidence would resolve it: Development of test collection construction methods that incorporate graph-based retrieval strategies, or evaluation metrics that account for unjudged documents while still measuring relevance quality

### Open Question 2
- Question: What user interface design elements would best support exploration of recommended papers through chaining recommendations in a graph-based system?
- Basis in paper: [explicit] The user study revealed participants wanted to chain recommendations and navigate the content library, but the current interface lacked this functionality
- Why unresolved: While the study showed users wanted this capability, it didn't test specific interface designs for chaining recommendations or explore optimal visualization methods for multi-hop exploration
- What evidence would resolve it: User studies testing different interface prototypes with chaining functionality, measuring task completion time, user satisfaction, and effectiveness at finding relevant papers through multiple recommendation hops

### Open Question 3
- Question: How can we effectively combine graph-based explainable recommendations with traditional recommendation methods to improve both performance and explainability?
- Basis in paper: [inferred] The authors suggest combining graph-based explainable methods with traditional recommendation approaches as future work, and their evaluation showed BM25-based methods sometimes outperformed their core overlap approach
- Why unresolved: The paper only evaluates the methods separately and doesn't investigate hybrid approaches that might leverage the strengths of both graph-based explainability and term-based effectiveness
- What evidence would resolve it: Implementation and evaluation of hybrid recommendation algorithms that combine graph core overlap scores with BM25 or other traditional scores, measuring whether such combinations improve both recommendation quality and maintain explainability

## Limitations
- Evaluation relies on test collections with significant unjudged documents, particularly affecting precision and nDCG calculations for graph-based methods
- System effectiveness depends heavily on quality of biomedical concept extraction, which isn't fully characterized
- User study not conducted to validate that graph-based explanations actually improve user understanding of recommendations

## Confidence
- **High confidence**: Two-stage retrieval architecture effectiveness (Section 5.2 results show consistent 0.6 recall for FSConcept/FSCore)
- **Medium confidence**: Overall recommendation performance (comparative results with PubMed Recommender are promising but affected by unjudged document issues)
- **Medium confidence**: Explainability claims (user study not conducted, explanations rely on visual graph patterns without validation of user understanding)

## Next Checks
1. Conduct ablation study on the two-stage retrieval to quantify the contribution of first-stage filtering vs. second-stage scoring
2. Perform user study to validate that graph-based explanations actually improve user understanding of recommendations
3. Test system robustness on additional biomedical domains beyond the three evaluated collections to assess generalizability