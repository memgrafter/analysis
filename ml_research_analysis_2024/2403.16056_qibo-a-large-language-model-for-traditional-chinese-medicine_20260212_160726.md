---
ver: rpa2
title: 'Qibo: A Large Language Model for Traditional Chinese Medicine'
arxiv_id: '2403.16056'
source_url: https://arxiv.org/abs/2403.16056
tags:
- medical
- arxiv
- chinese
- data
- throat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Qibo, a large language model (LLM) specialized
  for Traditional Chinese Medicine (TCM). The authors address the challenge of developing
  an LLM for TCM by creating a two-stage training approach that combines continuous
  pre-training and supervised fine-tuning on a 2GB TCM-specific corpus.
---

# Qibo: A Large Language Model for Traditional Chinese Medicine

## Quick Facts
- arXiv ID: 2403.16056
- Source URL: https://arxiv.org/abs/2403.16056
- Reference count: 23
- Key outcome: A specialized LLM achieving 63% subjective win rate and 23-58% objective accuracy improvements on TCM tasks

## Executive Summary
Qibo addresses the challenge of developing specialized large language models for Traditional Chinese Medicine by introducing a two-stage training approach combining continuous pre-training on a 2GB TCM corpus with supervised fine-tuning. The authors create Qibo-Benchmark, a comprehensive evaluation tool assessing LLM performance across subjective, objective, and three TCM NLP task dimensions. The trained model demonstrates significant improvements over baselines, with Rouge-L scores of 0.72, 0.61, and 0.55 for entity recognition, reading comprehension, and syndrome differentiation tasks respectively. The paper also proposes a pipeline for applying Qibo to TCM consultation and syndrome differentiation, validated through case studies.

## Method Summary
Qibo employs a two-stage training methodology using Chinese-LLaMA as the base model. First, continuous pre-training is conducted on a 2GB TCM-specific corpus processed through character-level and paragraph-level cleaning rules to ensure high-quality training data. Second, supervised instruction fine-tuning is performed using diverse TCM instruction datasets including single-turn conversations, multi-turn dialogues, and NLP task instructions. The model is evaluated using Qibo-Benchmark, which assesses performance across subjective evaluation (professionalism, safety, fluency), objective evaluation (multiple-choice questions), and three TCM NLP tasks (entity recognition, reading comprehension, syndrome differentiation).

## Key Results
- Average subjective win rate of 63% against baseline models
- Objective accuracy improvements of 23% to 58% across evaluation tasks
- Rouge-L scores of 0.72, 0.61, and 0.55 for entity recognition, reading comprehension, and syndrome differentiation respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage training improves TCM-specific knowledge and instruction-following ability
- Mechanism: Continuous pre-training on large TCM corpus builds foundational domain knowledge, while supervised fine-tuning with diverse TCM instruction datasets refines instruction-following capabilities
- Core assumption: Model can effectively learn TCM knowledge from textual data and generalize to new instructions
- Evidence anchors: Strong evidence from explicit description of 2GB corpus construction and training methodology

### Mechanism 2
- Claim: Granularity-based data processing rules improve corpus quality
- Mechanism: Character-level and paragraph-level cleaning rules remove noise and ensure semantic coherence
- Core assumption: Processing rules effectively identify and correct errors without removing valuable information
- Evidence anchors: Moderate evidence; rules described but quantitative impact not provided

### Mechanism 3
- Claim: Qibo-Benchmark provides comprehensive evaluation across multiple dimensions
- Mechanism: Includes subjective, objective, and three TCM NLP task evaluations to assess overall capabilities
- Core assumption: Benchmark tasks are representative of skills required for effective TCM consultation
- Evidence anchors: Strong evidence from detailed description of benchmark components

## Foundational Learning

- Concept: Traditional Chinese Medicine theories and practices
  - Why needed here: Understanding TCM principles like syndrome differentiation and treatment approaches is crucial for developing effective TCM LLM
  - Quick check question: What are the key differences between TCM and modern medicine in terms of diagnosis and treatment approaches?

- Concept: Large Language Models and their training methodologies
  - Why needed here: Familiarity with LLM architectures, training objectives, and fine-tuning techniques is essential for understanding Qibo's design
  - Quick check question: What are the advantages and disadvantages of two-stage training for domain-specific LLMs?

- Concept: Natural Language Processing tasks and evaluation metrics
  - Why needed here: Knowledge of common NLP tasks and metrics is necessary for interpreting TCM NLP task evaluation results
  - Quick check question: How does Rouge-L score measure the quality of generated text summaries?

## Architecture Onboarding

- Component map: Data Processing -> Continuous Pre-training -> Supervised Fine-tuning -> Qibo-Benchmark -> TCM Consultation Pipeline
- Critical path: Data Processing → Continuous Pre-training → Supervised Fine-tuning → Qibo-Benchmark → TCM Consultation Pipeline
- Design tradeoffs: Pre-training corpus size vs. data quality; fine-tuning dataset diversity vs. task specificity; benchmark comprehensiveness vs. evaluation complexity
- Failure signatures: Poor TCM NLP task performance (insufficient domain knowledge); inconsistent responses (understanding issues); low benchmark scores (specific weaknesses)
- First 3 experiments: 1) Evaluate TCM NLP task subset performance, 2) Conduct ablation study on training stages, 3) Test multi-turn conversation handling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does Qibo's performance improve with larger TCM-specific training corpora beyond the 2GB used?
- Basis in paper: [explicit] Authors mention 2GB corpus but don't explore scaling effects
- Why unresolved: Paper doesn't investigate whether increasing corpus size would lead to better performance
- What evidence would resolve it: Training Qibo with progressively larger corpora (5GB, 10GB, 20GB) and comparing performance metrics

### Open Question 2
- Question: Can Qibo generalize to TCM domains not represented in training data, such as rare syndromes or modern integrative medicine?
- Basis in paper: [inferred] Demonstrates performance on standard tasks but not on out-of-distribution knowledge
- Why unresolved: Paper doesn't test ability to handle novel or underrepresented TCM concepts
- What evidence would resolve it: Testing on rare syndromes, integrative medicine cases, and emerging TCM practices

### Open Question 3
- Question: How does Qibo's consultation pipeline compare to actual TCM practitioners in diagnostic accuracy and patient outcomes?
- Basis in paper: [explicit] Proposes consultation pipeline with case studies but no practitioner comparison
- Why unresolved: Case studies lack direct comparison to experienced TCM practitioners
- What evidence would resolve it: Controlled study comparing Qibo and practitioners on same patient set

## Limitations

- Data Scale and Quality: 2GB corpus is smaller than typical LLM training data, with limited quantitative quality measures provided
- Model Architecture Details: Critical hyperparameters and architectural modifications are not specified
- Evaluation Scope: Focuses on Chinese-language capabilities without cross-linguistic validation or clinical safety assessment

## Confidence

- High Confidence: Two-stage training methodology is well-established with sufficient detail on corpus construction and evaluation
- Medium Confidence: Performance improvements based on internal benchmarks require external validation
- Low Confidence: Clinical utility and safety claims require extensive real-world testing not addressed in paper

## Next Checks

1. **Ablation Study**: Conduct controlled experiments removing pre-training or fine-tuning stages to quantify individual contributions
2. **External Benchmark Validation**: Evaluate Qibo on independent TCM datasets not used during training, including real-world clinical cases
3. **Longitudinal Conversation Testing**: Implement multi-turn conversation protocol testing context maintenance and clinical reasoning across extended consultations