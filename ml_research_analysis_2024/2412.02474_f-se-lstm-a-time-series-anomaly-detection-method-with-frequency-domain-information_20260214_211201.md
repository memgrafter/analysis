---
ver: rpa2
title: 'F-SE-LSTM: A Time Series Anomaly Detection Method with Frequency Domain Information'
arxiv_id: '2412.02474'
source_url: https://arxiv.org/abs/2412.02474
tags:
- time
- series
- detection
- anomaly
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes F-SE-LSTM, a time series anomaly detection
  method that leverages frequency domain information to identify hidden anomalies.
  The method constructs a frequency matrix by applying FFT to time series data segmented
  by sliding windows, then uses SENet and LSTM to extract frequency-related features
  within and between periods.
---

# F-SE-LSTM: A Time Series Anomaly Detection Method with Frequency Domain Information

## Quick Facts
- arXiv ID: 2412.02474
- Source URL: https://arxiv.org/abs/2412.02474
- Authors: Yi-Xiang Lu; Xiao-Bo Jin; Jian Chen; Dong-Jie Liu; Guang-Gang Geng
- Reference count: 40
- Primary result: F-SE-LSTM achieves F1 score of 0.9688 on Yahoo Webscope S5 dataset

## Executive Summary
This paper introduces F-SE-LSTM, a novel time series anomaly detection method that leverages frequency domain information to identify hidden anomalies that are difficult to detect in the time domain alone. The method constructs a frequency matrix by applying FFT to time series data segmented by sliding windows, then uses SENet and LSTM to extract frequency-related features within and between periods. Experiments on real-world datasets demonstrate that F-SE-LSTM outperforms existing state-of-the-art methods, achieving superior F1 scores and recall rates while also showing improved training efficiency.

## Method Summary
F-SE-LSTM combines Fast Fourier Transform, SENet, and LSTM to detect anomalies in time series data by transforming it into the frequency domain. The method uses two sliding windows to segment time series data, applies FFT to construct a frequency matrix, then employs SENet to extract channel-wise dependencies between frequencies within each time period, and LSTM to capture temporal dependencies between frequency patterns across different periods. The model outputs binary classification for anomaly detection and is trained on Yahoo Webscope S5 and Numenta Anomaly Benchmark datasets.

## Key Results
- F-SE-LSTM achieves an average F1 score of 0.9688 on Yahoo Webscope S5 dataset, outperforming C-LSTM's 0.9492
- The method demonstrates superior recall rates compared to baseline approaches
- F-SE-LSTM shows better training efficiency than competing methods
- Particularly effective at detecting anomalies hidden in frequency domain patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Frequency matrix construction preserves temporal correlation while exposing frequency differences
- Mechanism: Two-stage sliding window + FFT transforms local time windows into frequency bands, maintaining time ordering across windows
- Core assumption: Hidden anomalies manifest as frequency domain patterns not visible in raw time domain
- Evidence anchors:
  - [abstract]: "utilizes two sliding windows and fast Fourier transform (FFT) to construct a frequency matrix"
  - [section]: "we transform the time series matrix into other domains to construct relevant features"
  - [corpus]: Weak evidence - related papers mention frequency features but don't detail dual-window construction
- Break condition: If temporal correlation between windows is critical for anomaly detection and is lost in frequency transformation

### Mechanism 2
- Claim: SENet extracts channel-wise dependencies between frequencies within the same time period
- Mechanism: Convolutional filters learn local frequency relationships, followed by channel attention that weights important frequency bands
- Core assumption: Anomalies have characteristic frequency band combinations that can be learned through channel attention
- Evidence anchors:
  - [abstract]: "Squeeze-and-Excitation Networks (SENet) and Long Short-Term Memory (LSTM) are employed to extract frequency-related features within and between periods"
  - [section]: "SENet is a CNN with channel attention mechanism, which can improve accuracy by modeling the correlation between feature channels"
  - [corpus]: Weak evidence - corpus papers mention frequency-based features but don't detail SENet application to time series
- Break condition: If frequency relationships within a single time window don't capture the essential anomaly characteristics

### Mechanism 3
- Claim: LSTM captures temporal dependencies between frequency patterns across different time periods
- Mechanism: Sequential processing of frequency-transformed windows allows learning of evolving frequency patterns that indicate anomalies
- Core assumption: Anomalies exhibit temporal evolution in frequency domain that can be modeled as sequential dependencies
- Evidence anchors:
  - [abstract]: "LSTM... employed to extract frequency-related features within and between periods"
  - [section]: "LSTM, as a variant of RNN, can well model the temporal context dependencies of long and short sequences"
  - [corpus]: Moderate evidence - LSTM is commonly used in time series anomaly detection, but not specifically for frequency domain sequences
- Break condition: If frequency patterns don't evolve in meaningful ways over time, or if short-term dependencies are more important

## Foundational Learning

- Concept: Fast Fourier Transform (FFT)
  - Why needed here: Converts time-domain signals into frequency-domain representation while preserving information efficiently
  - Quick check question: What mathematical property allows FFT to be more efficient than direct DFT computation?

- Concept: Channel attention mechanisms
  - Why needed here: Allows the model to learn which frequency bands are most important for distinguishing anomalies
  - Quick check question: How does the squeeze operation in SENet reduce spatial dimensions while preserving channel information?

- Concept: Long Short-Term Memory (LSTM)
  - Why needed here: Models temporal dependencies between frequency-transformed windows, capturing evolving patterns
  - Quick check question: What problem in standard RNNs does LSTM specifically address through its gating mechanisms?

## Architecture Onboarding

- Component map: Raw time series → Sliding window 1 → Sliding window 2 → FFT → Frequency matrix (H×F) → SENet → Channel-attended features → LSTM → Sequential processing → DNN → Binary classification

- Critical path: Frequency matrix construction → SENet feature extraction → LSTM temporal modeling → DNN classification

- Design tradeoffs: Sliding window size T trades off between frequency resolution (smaller T) and temporal context (larger T); SENet complexity vs CNN simplicity

- Failure signatures: Poor F1 scores indicate either frequency matrix construction isn't capturing relevant features, SENet isn't learning useful channel relationships, or LSTM isn't modeling temporal dependencies effectively

- First 3 experiments:
  1. Test different sliding window sizes T (10, 20, 30, 40, 50) to find optimal balance between frequency and temporal information
  2. Compare SENet vs CNN for channel attention to verify the benefit of explicit channel weighting
  3. Test frequency matrix vs time matrix as input to validate the advantage of frequency domain representation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the F-SE-LSTM method perform when combining both time-domain and frequency-domain features simultaneously, rather than using them separately?
- Basis in paper: [inferred] The paper mentions that future work aims to integrate both time domain and frequency domain data to develop a more robust anomaly detection method.
- Why unresolved: The current F-SE-LSTM method only uses frequency domain information, and the paper explicitly states this as a direction for future work without providing experimental results for combined domain approaches.
- What evidence would resolve it: Comparative experiments showing F1 scores, recall, and precision metrics for a hybrid model using both time and frequency domain features against the current frequency-only approach on the same datasets.

### Open Question 2
- Question: What is the optimal sliding window size T for the frequency matrix construction across different types of time series data beyond those tested?
- Basis in paper: [explicit] The paper states that the sliding window size T was set to 30 to "balance time information and frequency information" and that "the total number of the highest F1 scores is far more than the total number of other values of T" when T=30.
- Why unresolved: The paper only tested T values of 10, 20, 30, 40, and 50, and while T=30 performed best overall, the paper doesn't explore whether this is universally optimal or if it varies by data type or anomaly characteristics.
- What evidence would resolve it: Systematic experiments varying T across a wider range of values and different types of time series data (e.g., financial, medical, environmental) to determine if a universal optimal value exists or if it should be data-specific.

### Open Question 3
- Question: How does the performance of F-SE-LSTM scale with increasing sequence length L beyond the 60 observations used in the experiments?
- Basis in paper: [explicit] The paper states "When constructing sample sequences, we follow the settings in the literature and set the sample sequence length N to 60" and describes the frequency matrix construction process based on this length.
- Why unresolved: The paper doesn't explore how the method performs with longer or shorter sequences, which could be important for real-world applications where different sampling rates or longer historical windows might be beneficial.
- What evidence would resolve it: Experiments comparing F-SE-LSTM performance across varying sequence lengths (e.g., 30, 60, 120, 240 observations) on the same datasets to determine if there's an optimal length or if performance improves with more data.

## Limitations

- Limited ablation studies to isolate the contribution of each component (SENet, LSTM, frequency transformation)
- No comparison with frequency-based methods that use simpler architectures
- The dual sliding window construction of the frequency matrix is not fully detailed, making exact replication challenging

## Confidence

- **High Confidence**: The overall methodology combining frequency domain information with deep learning is sound and well-supported by related work
- **Medium Confidence**: The specific F-SE-LSTM architecture details and implementation choices are reasonably clear but lack some specifics
- **Low Confidence**: The claimed superiority over all baseline methods is based on limited comparisons, particularly lacking frequency-specific baselines

## Next Checks

1. Conduct ablation studies to quantify the individual contributions of SENet, LSTM, and frequency domain transformation to overall performance
2. Compare F-SE-LSTM against frequency-based anomaly detection methods (not just time-domain baselines) to validate the claimed advantage of frequency domain information
3. Test the model's performance on additional datasets with different anomaly characteristics to assess generalizability beyond the Yahoo and NAB benchmarks