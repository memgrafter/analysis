---
ver: rpa2
title: Semantically Rich Local Dataset Generation for Explainable AI in Genomics
arxiv_id: '2407.02984'
source_url: https://arxiv.org/abs/2407.02984
tags:
- sequence
- sequences
- https
- archive
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of generating synthetic datasets
  for local explainability of black box deep learning models in genomics. The core
  method uses Grammar-Guided Genetic Programming (GGGP) to evolve perturbations of
  input sequences, maintaining syntactic similarity while maximizing semantic diversity
  in model predictions.
---

# Semantically Rich Local Dataset Generation for Explainable AI in Genomics

## Quick Facts
- arXiv ID: 2407.02984
- Source URL: https://arxiv.org/abs/2407.02984
- Reference count: 40
- Primary result: GGGP-based method achieves ~30% improvement in archive quality for local explainability of genomics models

## Executive Summary
This work introduces a novel approach to generating synthetic datasets for local explainability of black box deep learning models in genomics. The method employs Grammar-Guided Genetic Programming (GGGP) to evolve perturbations of input DNA sequences, creating semantically diverse datasets while maintaining syntactic similarity to the original sequences. Applied to RNA splicing prediction using the SpliceAI model, the approach significantly outperforms random sampling, demonstrating scalability to longer sequences and capturing richer biological information through increased motif disruption events.

## Method Summary
The method uses GGGP with a domain-specific grammar to generate synthetic datasets by evolving perturbations of input DNA sequences. Two fitness functions (BinFiller and Increased Archive Diversity) guide evolution toward creating diverse archives of sequences that span the prediction landscape. The approach maintains syntactic similarity through grammar constraints while maximizing semantic diversity in model predictions. Applied to RNA splicing with SpliceAI, the method significantly outperforms random sampling across 144 diverse input sequences.

## Key Results
- GGGP method achieves ~30% improvement in archive quality compared to random sampling
- Demonstrated scalability to longer sequences (up to 12kb) with consistent quality
- Generated datasets show increased motif disruption events, capturing richer biological information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using GGGP to evolve perturbations of input sequences enables generation of semantically diverse synthetic datasets while maintaining syntactic similarity.
- Mechanism: GGGP uses a domain-specific grammar to constrain perturbations to biologically plausible variations (SNVs, insertions, deletions) and applies genetic operators to explore the sequence space. The grammar ensures syntactic similarity by limiting perturbations and preventing overlapping changes.
- Core assumption: The complex sequence-to-function relationship of DNA can be effectively navigated using evolutionary algorithms guided by domain-specific grammars.
- Evidence anchors:
  - [abstract]: "We propose using Genetic Programming to generate datasets by evolving perturbations in sequences that contribute to their semantic diversity."
  - [section]: "Our custom, domain-guided individual representation effectively constrains syntactic similarity, and we provide two alternative fitness functions that promote diversity with no computational effort."
  - [corpus]: Found 25 related papers with average neighbor FMR=0.533, suggesting moderate relevance in the broader literature on genomics and synthetic data generation.

### Mechanism 2
- Claim: The BinFiller and IAD fitness functions effectively guide the evolutionary search toward generating diverse and evenly distributed synthetic datasets.
- Mechanism: BinFiller promotes survival of individuals in less populated prediction bins, encouraging exploration of underexplored areas of the semantic space. IAD measures how much adding an individual increases overall archive diversity, favoring sequences that deviate from local optima.
- Core assumption: The semantic space of the model predictions can be effectively explored by balancing exploration (BinFiller) and exploitation (IAD) strategies.
- Evidence anchors:
  - [abstract]: "Our custom, domain-guided individual representation effectively constrains syntactic similarity, and we provide two alternative fitness functions that promote diversity with no computational effort."
  - [section]: "It is designed to be less reliant on the current filling of each bin. Instead, it assigns higher fitness to a sequence if it positively contributes to the overall archive uniformity at that moment."
  - [corpus]: Weak evidence - corpus does not provide direct support for the effectiveness of these specific fitness functions.

### Mechanism 3
- Claim: The custom mutation operator that promotes locality in the sampled positions of perturbations is more effective at targeting functional motifs than standard GGGP mutation.
- Mechanism: The custom mutation operator replaces a randomly chosen DiffUnit with another one in proximity, determined by a normal distribution centered at the old DiffUnit's position. This enhances the search for functional local motifs, which is a known property of biological sequences.
- Core assumption: Exploring DiffUnits in a more localized manner is more effective at targeting functional motifs than mutating across the whole sequence.
- Evidence anchors:
  - [section]: "We also designed a custom mutation operator that replaces a randomly chosen DiffUnit with another one in proximity. This replacement is determined by a normal distribution centered at the position of the old DiffUnit."
  - [section]: "This outcome strongly suggests that exploring DiffUnits in a more localized manner is targeting functional motifs faster than when mutating across the whole sequence."
  - [corpus]: Weak evidence - corpus does not provide direct support for the effectiveness of this specific mutation operator.

## Foundational Learning

- Concept: Genetic Programming (GP) and its application in sequence generation
  - Why needed here: Understanding GP is crucial for grasping how the method evolves perturbations to generate diverse synthetic datasets while maintaining syntactic similarity.
  - Quick check question: What are the key components of a GP algorithm, and how do they contribute to the evolution of sequences in this method?

- Concept: Grammar-Guided Genetic Programming (GGGP) and domain-specific grammars
  - Why needed here: GGGP with domain-specific grammars is the core technique used to constrain perturbations to biologically plausible variations and ensure syntactic similarity.
  - Quick check question: How does the use of a domain-specific grammar in GGGP differ from standard GP, and what are the benefits for sequence generation in genomics?

- Concept: Fitness functions and their role in guiding evolutionary search
  - Why needed here: The BinFiller and IAD fitness functions are critical for guiding the evolutionary search toward generating diverse and evenly distributed synthetic datasets.
  - Quick check question: How do the BinFiller and IAD fitness functions work, and what are their respective strengths in guiding the evolutionary search?

## Architecture Onboarding

- Component map:
  - Grammar-Guided Genetic Programming (GGGP) algorithm
  - Domain-specific grammar for constraining perturbations
  - BinFiller and IAD fitness functions
  - Custom mutation operator
  - Archive for storing generated sequences
  - SpliceAI model for evaluating semantic diversity

- Critical path:
  1. Initialize population with random perturbations using the domain-specific grammar
  2. Evaluate individuals by applying perturbations to the original sequence and obtaining SpliceAI predictions
  3. Select individuals based on BinFiller and IAD fitness functions
  4. Apply genetic operators (mutation, crossover) to generate new individuals
  5. Add promising individuals to the archive
  6. Repeat steps 2-5 until archive reaches capacity or time budget is exhausted

- Design tradeoffs:
  - Balancing syntactic similarity and semantic diversity through grammar constraints and fitness functions
  - Exploring the sequence space efficiently while maintaining biological plausibility of perturbations
  - Computational cost of evaluating individuals using the SpliceAI model versus the quality of generated datasets

- Failure signatures:
  - Archive quality does not improve over random sampling
  - Archive contains sequences that are too similar to the original sequence or too far from the prediction landscape
  - Evolution gets stuck in local optima due to poorly tuned fitness functions or grammar constraints

- First 3 experiments:
  1. Implement the GGGP algorithm with the domain-specific grammar and BinFiller fitness function on a short, controlled sequence
  2. Compare the archive quality and diversity of the generated datasets against random sampling
  3. Evaluate the impact of the custom mutation operator on the archive quality and diversity by comparing it to standard GGGP mutation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the archive quality scale with sequence length beyond 10kb, and what is the computational limit of the method?
- Basis in paper: [inferred] The paper shows GGGP maintains consistent quality up to 12kb sequences but doesn't explore longer lengths or computational limits.
- Why unresolved: The experiments stopped at 12kb sequences, leaving uncertainty about scalability to much longer sequences (e.g., full genes) and computational feasibility.
- What evidence would resolve it: Experiments testing archive quality on sequences >12kb with varying time/computational budgets to identify practical limits.

### Open Question 2
- Question: What is the biological interpretability of motif disruption events in GGGP-generated sequences compared to known splicing regulatory mechanisms?
- Basis in paper: [explicit] The authors note GGGP datasets have higher motif disruption events but question whether these represent learned biological rules or spurious artifacts.
- Why unresolved: While motif disruption frequency is quantified, the biological significance and connection to established splicing regulatory mechanisms remains unclear.
- What evidence would resolve it: Functional validation experiments showing GGGP-generated sequences with specific motif disruptions actually alter splicing in predictable ways, or comparison with known splicing factor binding sites.

### Open Question 3
- Question: How would tissue-specific or cell-type-specific splicing models affect the quality and interpretability of generated datasets compared to the general SpliceAI model?
- Basis in paper: [explicit] The authors note SpliceAI lacks tissue specificity and mention attempting to use Pangolin but its inference time was prohibitive.
- Why unresolved: The study used a general model, but tissue-specific splicing regulation is crucial for biological interpretation and model explainability.
- What evidence would resolve it: Applying GGGP to tissue-specific models (like Pangolin or similar) and comparing archive quality and biological interpretability to the general model results.

## Limitations
- Domain specificity limits immediate applicability to other genomic tasks or model architectures
- Significant computational overhead from evaluating each individual with the SpliceAI model
- Incomplete specification of domain-specific grammar constraints affects reproducibility

## Confidence

**Confidence Levels:**
- **High Confidence**: The core methodology of using GGGP with domain-specific grammars is technically sound and well-established in evolutionary computation. The significant performance improvement over random sampling is empirically demonstrated.
- **Medium Confidence**: The specific fitness functions (BinFiller and IAD) and custom mutation operator show promise but require further validation across diverse genomic tasks beyond RNA splicing.
- **Low Confidence**: The generalizability of the approach to other deep learning models and biological problems remains unproven, as does the optimal tuning of grammar constraints for different genomic contexts.

## Next Checks

1. **Cross-Model Validation**: Apply the same methodology to a different genomics model (e.g., transcription factor binding prediction) to test generalizability
2. **Scalability Assessment**: Measure archive quality and generation time for sequences of varying lengths (beyond the tested range) to establish practical limits
3. **Biological Validation**: Perform motif analysis on generated sequences to confirm that semantic diversity captures functionally meaningful variations rather than random noise