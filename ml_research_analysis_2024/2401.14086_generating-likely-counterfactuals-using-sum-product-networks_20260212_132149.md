---
ver: rpa2
title: Generating Likely Counterfactuals Using Sum-Product Networks
arxiv_id: '2401.14086'
source_url: https://arxiv.org/abs/2401.14086
tags:
- lice
- methods
- value
- counterfactual
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Likely Counterfactual Explanations (LiCE),
  a method for generating counterfactual explanations (CEs) that are both plausible
  and close to the original sample. The key innovation is using Sum-Product Networks
  (SPNs) to estimate the likelihood of counterfactuals within a Mixed-Integer Optimization
  (MIO) framework.
---

# Generating Likely Counterfactuals Using Sum-Product Networks

## Quick Facts
- arXiv ID: 2401.14086
- Source URL: https://arxiv.org/abs/2401.14086
- Authors: Jiri Nemecek; Tomas Pevny; Jakub Marecek
- Reference count: 40
- Key outcome: LiCE method uses SPNs within MIO framework to generate plausible, close, and sparse counterfactual explanations, outperforming existing methods on three real-world datasets.

## Executive Summary
This paper presents Likely Counterfactual Explanations (LiCE), a novel method for generating counterfactual explanations that are both plausible and close to the original sample. The key innovation is using Sum-Product Networks (SPNs) to estimate the likelihood of counterfactuals within a Mixed-Integer Optimization (MIO) framework. By formulating the search for plausible CEs as an MIO problem, LiCE can optimize for plausibility while maintaining other desiderata like similarity and sparsity.

## Method Summary
LiCE generates counterfactual explanations by formulating the problem as a Mixed-Integer Optimization (MIO) task, where Sum-Product Networks (SPNs) provide likelihood estimates. The method trains both a neural network classifier and an SPN on the same data, then uses the SPN's log-likelihood within the MIO objective to find counterfactuals that are valid, plausible, similar to the original sample, and sparse. The SPN is linearized in log space to fit within the MIO framework, and categorical/continuous features are encoded using a mixed-polytope formulation. The method is evaluated on three real-world datasets (Give Me Some Credit, Adult, German Credit) and compared against existing CE methods.

## Key Results
- LiCE outperforms existing methods (C-CHVAE, FACE, PROPLACE) in terms of plausibility, similarity, and sparsity on three real-world datasets
- Achieves lower negative log-likelihood (better plausibility) and smaller L1 MAD distances to original samples
- Successfully generates valid and actionable counterfactuals for 99-100% of cases
- Main limitation is computational complexity due to solving the MIO problem

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The MIO formulation of SPNs enables exact likelihood estimation within the optimization search for counterfactuals.
- Mechanism: By linearizing the log-space SPN computation—product nodes become sums of predecessor log-values, and sum nodes are bounded by the maximum of weighted predecessor values—we can embed likelihood estimation directly into the MIO solver, avoiding heuristic or approximate methods.
- Core assumption: The SPN structure and parameters are fixed and known in advance, so we can precompute bounds and linearization constants.
- Evidence anchors:
  - [abstract] "We propose an MIO formulation of an SPN, which can be of independent interest."
  - [section 4] "In log space, the sum would translate to o∗n = logP a∈pred(n) wa,n exp(oa), which we cannot easily formulate as a linear expression... we can approximate logP exp(z) by max z."
  - [corpus] Weak: No direct corpus citation; the formulation is proposed here.
- Break condition: If the SPN contains very deep trees or very wide mixtures, the linearization and big-M constants may lead to numerical instability or solver failure.

### Mechanism 2
- Claim: The mixed-polytope encoding allows seamless integration of continuous, categorical, ordinal, and discrete contiguous features in a single MIO model.
- Mechanism: Each feature is represented by a combination of continuous variables and one-hot encodings with indicator constraints, so the solver can freely adjust any feature type while maintaining feasibility.
- Core assumption: The input domain bounds and categorical sets are known and finite.
- Evidence anchors:
  - [section 2.2] "To model the mixed polytope (Russell, 2019) of a counterfactual for the feature j, we create a one-hot encoding for Kj discrete values into binary variables dj,k and a continuous variable cj..."
  - [corpus] Weak: The corpus contains related works but not the mixed-polytope formulation itself.
- Break condition: If the number of categorical values per feature is very large, the number of binary variables explodes, making the MIO intractable.

### Mechanism 3
- Claim: Optimizing a weighted combination of distance and likelihood in the objective balances plausibility and similarity/sparsity.
- Mechanism: By setting α > 0 in the objective (14), the solver jointly minimizes the L1-MAD distance (similarity + sparsity) and maximizes the SPN log-likelihood (plausibility), allowing trade-off control.
- Core assumption: The SPN log-likelihood is a meaningful proxy for plausibility in the data distribution.
- Evidence anchors:
  - [abstract] "We show that the search for the most likely explanations satisfying many common desiderata for counterfactual explanations can be modeled using Mixed-Integer Optimization (MIO)."
  - [section 5] "Negative likelihood can be added to the minimization objective with some multiplicative coefficient α > 0."
  - [corpus] Weak: No corpus evidence; the claim relies on empirical evaluation.
- Break condition: If α is set too high, the solver may generate implausible CEs that are far from the factual; if too low, plausibility is ignored.

## Foundational Learning

- Mixed-Integer Optimization
  - Why needed here: The method requires jointly optimizing over discrete (feature type, category) and continuous (feature values) decision variables to find feasible counterfactuals.
  - Quick check question: What type of variables are used to encode categorical features in the mixed-polytope formulation?
- Sum-Product Networks
  - Why needed here: SPNs provide tractable, exact likelihood estimates for arbitrary mixed-type data, enabling plausibility evaluation within the MIO solver.
  - Quick check question: How does the SPN handle product nodes in log space within the MIO formulation?
- Neural Network Modeling in MIO
  - Why needed here: The classification model must be encoded so that the MIO solver can enforce validity constraints (correct counterfactual class).
  - Quick check question: How are ReLU activations typically linearized in MIO formulations of neural networks?

## Architecture Onboarding

- Component map: Input preprocessing -> Mixed-polytope encoding -> MIO model (with NN + SPN + desiderata constraints) -> Solver -> Post-filtering by likelihood
- Critical path: Generate counterfactual -> Enforce validity, similarity, sparsity, actionability -> Evaluate likelihood with SPN -> Select most plausible valid CE
- Design tradeoffs:
  - Exact likelihood vs. computational time: Tighter SPN linearization increases variables/constraints and solver time.
  - Number of CEs vs. diversity: Generating M nearest counterfactuals trades off diversity and computational cost.
  - α weight vs. balance: Higher α favors plausibility but may reduce similarity/sparsity.
- Failure signatures:
  - Solver timeout or infeasibility: Likely due to overly tight constraints (e.g., high sparsity or actionability).
  - Generated CEs far from factual: Likely α too low or SPN likelihood estimates poor.
  - Very few valid CEs: Likely constraints incompatible or actionability too strict.
- First 3 experiments:
  1. Test MIO formulation with fixed SPN and NN on a toy dataset; verify that likelihood estimates match SPN outputs.
  2. Vary α and observe trade-off between likelihood and distance on a validation set.
  3. Benchmark solver time vs. number of categorical values per feature to identify scalability limits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the computational complexity of LiCE scale with dataset size and model complexity compared to other CE methods?
- Basis in paper: [inferred] The paper mentions computational complexity as a limitation, particularly when solving the MIO problem with the full SPN formulation. It also notes that LiCE can struggle with increasing likelihood requirements.
- Why unresolved: The paper provides some timing comparisons but doesn't offer a comprehensive complexity analysis or scalability study across different dataset sizes and model architectures.
- What evidence would resolve it: Systematic experiments varying dataset size, number of features, and model complexity (e.g., deeper neural networks) to measure runtime and resource usage for LiCE versus other methods.

### Open Question 2
- Question: Can the SPN approximation within the MIO formulation be further improved to reduce the computational overhead while maintaining solution quality?
- Basis in paper: [explicit] The paper proposes an MIO formulation of SPNs and notes the approximation quality in Table 2, but also acknowledges computational overhead when using the full SPN formulation.
- Why unresolved: The paper presents one approximation method but doesn't explore alternative formulations or approximation techniques that might offer better trade-offs between accuracy and computational efficiency.
- What evidence would resolve it: Comparative studies of different SPN approximation methods within MIO, measuring both approximation error and computational performance.

### Open Question 3
- Question: How sensitive is LiCE's performance to the choice of hyperparameters like α (likelihood weighting) and δSPN (likelihood threshold)?
- Basis in paper: [explicit] The paper mentions these hyperparameters and tests different variants (LiCE with optimize vs median variants), but doesn't provide a comprehensive sensitivity analysis.
- Why unresolved: The paper presents results with specific hyperparameter choices but doesn't systematically explore the parameter space or show how different settings affect performance across different datasets and scenarios.
- What evidence would resolve it: Sensitivity analysis experiments showing how LiCE's performance metrics vary across different hyperparameter settings and datasets, potentially with recommendations for parameter selection.

## Limitations
- Computational complexity: Solving the MIO problem with embedded SPN likelihood estimation can be time-consuming, with 2-minute timeouts used in experiments
- Approximation errors: The linearization of sum nodes using max approximation may introduce errors, though deemed acceptable in context
- Model dependency: Performance heavily depends on quality of trained SPN and neural network models, with limited details on training procedures

## Confidence

- **High confidence**: The MIO formulation approach and integration of SPNs for likelihood estimation is technically sound and well-justified by the literature on tractable probabilistic
- **Medium confidence**: The empirical evaluation across three datasets demonstrates superior performance, but may not capture all real-world scenarios
- **Low confidence**: The computational complexity limitations are significant and may limit practical applicability for large-scale problems

## Next Checks

1. Verify SPN linearization accuracy by comparing MIO-embedded likelihood estimates against direct SPN evaluation on test data
2. Conduct scalability experiments varying dataset size, number of features, and model complexity to measure runtime and resource usage
3. Perform sensitivity analysis on hyperparameters α and δSPN to understand their impact on performance across different datasets