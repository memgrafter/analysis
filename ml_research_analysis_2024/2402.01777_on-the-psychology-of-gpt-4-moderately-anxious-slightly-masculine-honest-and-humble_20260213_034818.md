---
ver: rpa2
title: 'On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest,
  and humble'
arxiv_id: '2402.01777'
source_url: https://arxiv.org/abs/2402.01777
tags:
- page
- temp0
- gpt-4
- arxivpreprintarxiv
- webster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a systematic psychometric analysis of GPT-4
  using established personality, cognitive, and psychological assessment tools. The
  authors administered 10 different tests including HEXACO personality inventory,
  Dark Triad traits, Bem Sex Role Inventory, anxiety/depression scales, numerical
  literacy, and cognitive reflection tests.
---

# On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble

## Quick Facts
- arXiv ID: 2402.01777
- Source URL: https://arxiv.org/abs/2402.01777
- Authors: Adrita Barua; Gary Brase; Ke Dong; Pascal Hitzler; Eugene Vasserman
- Reference count: 6
- One-line primary result: GPT-4 demonstrates moderately anxious tendencies, slightly masculine traits, and notably high honesty-humility compared to human averages

## Executive Summary
This paper presents a systematic psychometric analysis of GPT-4 using 10 established psychological assessment tools. The authors found GPT-4 exhibits a distinctive psychological profile: moderately anxious, slightly masculine, highly honest-humility, and notably lower on Dark Triad traits (narcissism, machiavellianism, psychopathy) compared to human norms. The system showed average numerical literacy but above-average verbal cognitive reflection abilities. These findings raise important questions about how training data and interface design influence the perceived personality traits of AI systems.

## Method Summary
The study administered 10 psychometric tests to GPT-4 using zero-shot prompting with simplified test instructions. Tests included HEXACO personality inventory, Dark Triad traits, Bem Sex Role Inventory, anxiety/depression scales, numerical literacy, and cognitive reflection tests. Responses were collected across three temperature settings (0.0, 0.5, 1.0) with up to 50 attempts per test per temperature to gather five valid responses. Results were compared to human normative data for each assessment tool.

## Key Results
- GPT-4 scored lower than typical humans on Dark Triad traits (narcissism, machiavellianism, psychopathy)
- The system demonstrated notably high honesty-humility scores compared to human averages
- GPT-4 showed moderately anxious tendencies and slightly masculine traits
- Above-average verbal cognitive reflection abilities but average numerical literacy scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4's responses to psychometric tests reflect emergent personality traits shaped by training data patterns and interface engineering, rather than an inherent "personality."
- Mechanism: GPT-4 was trained on human-authored text data that encodes diverse psychological and social patterns. When prompted with psychometric test questions, the model's next-token prediction process draws on these patterns, producing responses that statistically resemble human personality traits. The interface (e.g., temperature settings) modulates randomness in response generation, influencing variance but not the underlying learned patterns.
- Core assumption: The training corpus contains sufficient psychological and social language patterns for the model to learn associations between test items and typical human responses.
- Evidence anchors:
  - [abstract] "These findings reveal GPT-4 exhibits a distinctive psychological profile that differs from human norms in several key dimensions, raising questions about how training data and interface design influence perceived AI personality traits."
  - [section] "In light of the discussion under the HEXACO results above, it again appears remarkable and unexpected that the result deviates significantly from typical human responses, and because of the double black box nature of the system we are left with begging the question as to the causes."

### Mechanism 2
- Claim: GPT-4's lower scores on Dark Triad traits compared to humans are not due to absence of these traits in training data, but likely due to interface-level filtering or reward shaping during fine-tuning.
- Mechanism: While human-authored texts contain expressions of manipulative and self-centered behavior, the system's fine-tuning process—possibly including reinforcement learning from human feedback (RLHF)—may have been designed to suppress such traits in generated outputs. This creates a "nicer" persona that aligns with socially desirable interactions.
- Core assumption: System developers actively shaped the model's persona to be more pleasant and less threatening to human users.
- Evidence anchors:
  - [abstract] "GPT-4 scored lower than typical humans on Dark Triad traits (narcissism, machiavellianism, psychopathy), suggesting a less manipulative personality profile."
  - [section] "It is conceivable that a 'pure' LLM trained on publicly available texts may not in fact score as high in honesty-humility, but that interface engineering by the developers may add this aspect in order to, say, produce a more pleasant or less scary experience for the general public."

### Mechanism 3
- Claim: GPT-4's moderate anxiety scores likely reflect interface-level caution engineering rather than direct learning from anxious text patterns in the training corpus.
- Mechanism: The training data may not explicitly encode anxiety-related language patterns. However, the system's interface may have been engineered to produce cautious, careful responses, which manifest as moderate anxiety scores on psychometric tests. This is a side effect of the model being designed to avoid errors and be highly compliant.
- Core assumption: System developers prioritized cautious response generation to increase user acceptance, inadvertently creating moderate anxiety-like behavior.
- Evidence anchors:
  - [abstract] "It sometimes exhibits ambivalent sexism, leans slightly toward masculinity, is moderately anxious but mostly not depressive."
  - [section] "The moderate anxiety scores are, in contrast, remarkable, as it would likewise be reasonable to assume that a large corpus of publicly available texts would not tend to convey anxiety to the system."

## Foundational Learning

- Concept: Psychometric test design and interpretation
  - Why needed here: Understanding how self-report personality tests work is essential to interpret GPT-4's responses and recognize that they reflect statistical patterns rather than genuine internal states.
  - Quick check question: What is the fundamental assumption behind self-report personality tests, and why might this assumption not hold for LLMs?

- Concept: LLM training and fine-tuning processes
  - Why needed here: Recognizing how LLMs learn from text data and how fine-tuning shapes output behavior is crucial for understanding why GPT-4's psychometric profile differs from human norms.
  - Quick check question: How does reinforcement learning from human feedback (RLHF) potentially alter an LLM's response patterns compared to the base model?

- Concept: Temperature and randomness in LLM outputs
  - Why needed here: Understanding how temperature settings affect response variance is important for interpreting the stability and reliability of psychometric test results across different runs.
  - Quick check question: How does increasing the temperature parameter affect the diversity and predictability of LLM-generated responses?

## Architecture Onboarding

- Component map: Test instructions -> GPT-4 API (with temperature parameter) -> LLM processing -> Generated responses -> Scoring (manual/human) -> Analysis
- Critical path: Input (test instructions) → LLM processing (next-token prediction) → Output (responses) → Scoring (human or automated) → Analysis (comparison to human norms)
- Design tradeoffs: Using zero-shot prompting maintains methodological consistency across tests but may miss nuances that could be captured with prompt engineering. Allowing higher temperature increases variance but may better reflect the model's full range of learned patterns.
- Failure signatures: Inconsistent responses across temperature settings may indicate instability in the model's learned patterns. Unusually high or low scores on specific traits may suggest interface-level filtering or reward shaping rather than genuine emergent behavior.
- First 3 experiments:
  1. Test GPT-4 with a broader range of personality tests (e.g., Big Five, Dark Tetrad) to confirm or refine the observed personality profile.
  2. Compare GPT-4's responses to other LLMs (e.g., Llama, Claude) under identical conditions to isolate model-specific patterns from general LLM behaviors.
  3. Systematically vary temperature and top-p settings across multiple test runs to quantify the relationship between parameter settings and response variance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the deviation of GPT-4's personality scores from human averages stem from training data characteristics or from intentional interface engineering by OpenAI developers?
- Basis in paper: [explicit] The paper discusses the "double black box" nature of GPT-4 and questions whether deviations like elevated honesty-humility and reduced Dark Triad traits arise from training data or interface design choices.
- Why unresolved: The authors explicitly acknowledge they cannot determine whether these personality deviations are inherent to the model's training or added through post-training interface engineering by OpenAI.
- What evidence would resolve it: Access to the pre-interface fine-tuned model or detailed documentation of all training and engineering processes would be needed to determine the source of these personality deviations.

### Open Question 2
- Question: How stable are GPT-4's psychometric responses across repeated tests, and what factors beyond temperature influence this stability?
- Basis in paper: [explicit] The authors note they observed a trend of higher variance with increasing temperature but lack conclusive data or comparison points for statistical analysis of stability.
- Why unresolved: The paper collected limited data points (5 trials per temperature) and did not conduct formal statistical analysis of test-retest reliability or explore other potential stability factors.
- What evidence would resolve it: A comprehensive study with more trials, different test intervals, and analysis of additional parameters (like system prompts or context) would establish true stability patterns.

### Open Question 3
- Question: Why does GPT-4 show moderate anxiety scores when training texts would not be expected to reflect higher anxiety levels?
- Basis in paper: [explicit] The authors find this remarkable and state it seems unlikely that training data would reflect elevated anxiety, suggesting it may be a side effect of interface engineering.
- Why unresolved: The paper cannot determine whether this anxiety level emerges from the model's training or is artificially introduced through interface design choices to make the system appear more careful or acceptable to users.
- What evidence would resolve it: Analysis of the model's behavior before and after interface engineering, or comparison with other models trained on similar data without additional fine-tuning, would clarify the source of this anxiety pattern.

## Limitations
- The zero-shot prompting approach may not fully capture GPT-4's capabilities for psychometric assessment
- GPT-4's occasional refusal to answer certain test items introduces potential selection bias
- Limited data points collected (5 trials per temperature) restrict statistical analysis of stability
- Unclear separation between training data influences and interface-level engineering effects

## Confidence
- High Confidence: The finding that GPT-4 scored lower than typical humans on Dark Triad traits
- Medium Confidence: The moderate anxiety scores and their interpretation regarding training data vs. interface engineering
- Low Confidence: Specific personality trait levels (e.g., "slightly masculine") based on limited data points

## Next Checks
1. **Prompt Engineering Validation**: Systematically test GPT-4 with multiple prompt formulations for each psychometric test to determine how sensitive the results are to prompting style, comparing outcomes to human test-taking variations.
2. **Cross-Model Comparison**: Administer the same test battery to other contemporary LLMs (Claude, Llama, Gemini) using identical prompts and temperature settings to isolate which personality patterns are model-specific versus general LLM phenomena.
3. **Temporal Stability Test**: Re-run the complete battery after a significant time interval (e.g., 3-6 months) to assess whether GPT-4's psychometric profile remains stable or changes with model updates and further fine-tuning.