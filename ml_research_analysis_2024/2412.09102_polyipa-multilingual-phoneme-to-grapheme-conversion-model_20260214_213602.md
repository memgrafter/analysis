---
ver: rpa2
title: PolyIPA -- Multilingual Phoneme-to-Grapheme Conversion Model
arxiv_id: '2412.09102'
source_url: https://arxiv.org/abs/2412.09102
tags:
- data
- languages
- training
- phonetic
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper presents PolyIPA, a multilingual phoneme-to-grapheme
  conversion model designed for transliteration, onomastic research, and information
  retrieval. The model employs data augmentation through two helper models: IPA2vec
  for finding soundalikes across languages and similarIPA for handling phonetic notation
  variations.'
---

# PolyIPA -- Multilingual Phoneme-to-Grapheme Conversion Model

## Quick Facts
- arXiv ID: 2412.09102
- Source URL: https://arxiv.org/abs/2412.09102
- Authors: Davor Lauc
- Reference count: 7
- Primary result: Achieves mean CER of 0.055 and BLEU score of 0.914 across 74 languages

## Executive Summary
PolyIPA is a multilingual phoneme-to-grapheme conversion model designed for transliteration, onomastic research, and information retrieval. The model employs innovative data augmentation techniques using two helper models - IPA2vec for finding soundalikes across languages and similarIPA for handling phonetic notation variations. Through these approaches, PolyIPA achieves strong performance across 74 languages, with particular effectiveness on languages with shallow orthographies. The implementation of beam search further improves practical utility, reducing effective error rate by 52.7% for top-3 candidates.

## Method Summary
The model uses ByT5-small architecture trained on 79.3 million augmented examples from multiple G2P datasets. Data augmentation employs two strategies: IPA2vec generates soundalike pairs using a Siamese neural network with cosine similarity loss and FAISS-based candidate retrieval, while similarIPA handles IPA notation variations through T5.1 sequence-to-sequence modeling. The model is trained for 3 epochs with specific hyperparameters (learning rate 4e-5, batch size 96) then fine-tuned with proper names data for 2 additional epochs. Evaluation uses CER, BLEU, and Top-N WER metrics with beam search analysis.

## Key Results
- Achieves mean CER of 0.055 and character-level BLEU score of 0.914 across 74 languages
- Top-3 beam search candidates reduce effective error rate by 52.7% (to CER: 0.026)
- Strong performance on shallow orthographies (Finnish CER: 0.002, Spanish CER: 0.006) vs. challenges with deep orthographies (English CER: 0.069, Chinese CER: 0.522)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IPA2vec improves cross-linguistic soundalike discovery through phonetic embeddings
- Mechanism: Siamese neural network with ByT5 encoder generates phonetic embeddings, enabling similarity-based retrieval via FAISS and edit distance refinement
- Core assumption: Phonetic similarity can be captured through learned embeddings and feature edit distance
- Evidence anchors: Generated 1.1 million phonetically similar pairs using two-stage similarity search approach
- Break condition: If feature edit distance threshold becomes too restrictive or permissive

### Mechanism 2
- Claim: similarIPA handles phonetic notation variations through learned IPA-to-IPA transformations
- Mechanism: T5.1 architecture trained on IPA-to-IPA pairs from multiple transcription conventions
- Core assumption: Multiple valid IPA transcriptions represent systematic variation learnable through sequence-to-sequence modeling
- Evidence anchors: Extracted all possible combinations from language-grapheme pairs with multiple valid IPA transcriptions
- Break condition: If model learns too many implausible variations

### Mechanism 3
- Claim: Beam search improves practical utility by providing multiple high-quality candidate outputs
- Mechanism: Generates N candidate outputs per input, selecting best based on character error rate
- Core assumption: Multiple valid transliterations exist for many phoneme sequences, especially in shallow orthographies
- Evidence anchors: Top-3 candidates reduce effective error rate by 52.7% (to CER: 0.026)
- Break condition: If beam search consistently places best candidate outside top-N

## Foundational Learning

- Concept: Phoneme-to-Grapheme Conversion
  - Why needed here: Core task being solved - converting phonetic representations (IPA) to written text across multiple languages
  - Quick check question: What is the difference between phoneme-to-grapheme and grapheme-to-phoneme conversion, and why is P2G considered more challenging?

- Concept: Orthographic Depth
  - Why needed here: Performance correlates with orthographic depth, showing shallow orthographies perform better
  - Quick check question: How does the orthographic depth hypothesis explain performance differences between Finnish (CER: 0.002) and Chinese (CER: 0.522)?

- Concept: Data Augmentation Techniques
  - Why needed here: Model's success relies on data augmentation through IPA2vec and similarIPA
  - Quick check question: What are the two main data augmentation strategies used in PolyIPA, and how do they address different types of data scarcity?

## Architecture Onboarding

- Component map: Data Collection -> Data Cleaning -> Augmentation (IPA2vec + similarIPA) -> Training (ByT5) -> Fine-tuning (proper names) -> Evaluation (beam search)

- Critical path: Data → Augmentation (IPA2vec + similarIPA) → Training (ByT5) → Fine-tuning (proper names) → Evaluation (beam search)

- Design tradeoffs:
  - ByT5 byte-level processing vs. character-level for multilingual support
  - Two-stage similarity search (FAISS + edit distance) for computational efficiency vs. single precise method
  - Generating multiple IPA variations vs. sticking to canonical transcriptions

- Failure signatures:
  - High CER on deep orthographies and logographic scripts
  - Model learning grapheme representations from other languages instead of target language phonetics
  - Beam search consistently placing best candidate outside top-N

- First 3 experiments:
  1. Test IPA2vec soundalike generation quality through human evaluation of retrieved pairs
  2. Validate similarIPA model by comparing generated variations against human-curated transcriptions
  3. Evaluate beam search effectiveness by measuring CER improvement with top-3 vs top-1 candidates across language families

## Open Questions the Paper Calls Out

- Question: What are the limitations of current phonetic similarity metrics and how could they be improved?
- Basis in paper: [explicit] Paper identifies need for better metrics for phonetic similarity, acknowledging subjective nature and suggesting language background consideration
- Why unresolved: Identifies as future research direction without providing specific improvements
- What evidence would resolve it: Development and testing of unified model generating IPA renderings of similar sounding words for typical speakers of given languages

- Question: How does model performance vary with training data size and quality for different languages?
- Basis in paper: [inferred] Mentions languages with limited training data show higher variance in performance
- Why unresolved: Does not provide detailed analysis of performance scaling with data quantity/quality
- What evidence would resolve it: Systematic experiments varying training data amount/quality and measuring performance changes

- Question: How effective would incorporating morphological analysis be in handling complex derivational and inflectional patterns?
- Basis in paper: [explicit] Suggests incorporating morphological analysis as future work for handling complex patterns
- Why unresolved: Does not test or implement morphological analysis
- What evidence would resolve it: Implementation of model variant with morphological analysis and comparative evaluation on languages with complex morphological structures

## Limitations
- Performance strongly correlates with orthographic depth, struggling with deep orthographies (English CER: 0.069) and logographic systems (Chinese CER: 0.522)
- Proper name adaptation limited to Latin-script languages with only 9.6K non-Latin names in fine-tuning dataset
- Data augmentation approach may propagate existing transcription inconsistencies across languages

## Confidence

- **High confidence**: CER and BLEU score measurements, beam search effectiveness, performance correlation with orthographic depth
- **Medium confidence**: IPA2vec soundalike generation quality, similarIPA model effectiveness for notation variations
- **Low confidence**: Proper name adaptation performance across non-Latin scripts, long-term stability of augmentation pipeline

## Next Checks

1. Conduct human evaluation of IPA2vec-generated soundalike pairs to verify phonetic similarity and assess whether retrieved pairs are truly phonetically equivalent
2. Test model's robustness to unseen proper names by evaluating cross-linguistic transliteration quality for names from languages not represented in training data
3. Measure performance degradation when removing augmentation layers to quantify contribution of IPA2vec and similarIPA to accuracy improvements