---
ver: rpa2
title: A Fashion Item Recommendation Model in Hyperbolic Space
arxiv_id: '2409.02599'
source_url: https://arxiv.org/abs/2409.02599
tags:
- hyperbolic
- space
- learning
- proceedings
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a fashion item recommendation model that incorporates
  hyperbolic geometry into user and item representations. The core method idea is
  to use hyperbolic space to capture implicit hierarchies among fashion items based
  on their visual data and users' purchase history.
---

# A Fashion Item Recommendation Model in Hyperbolic Space

## Quick Facts
- arXiv ID: 2409.02599
- Source URL: https://arxiv.org/abs/2409.02599
- Authors: Ryotaro Shimizu; Yu Wang; Masanari Kimura; Yuki Hirakawa; Takashi Wada; Yuki Saito; Julian McAuley
- Reference count: 40
- Primary result: Proposed hyperbolic model achieves AUC of 0.804 (Amazon Women), 0.830 (Amazon Men), and 0.810 (TOWN Women)

## Executive Summary
This paper introduces a fashion item recommendation model that leverages hyperbolic geometry to capture implicit hierarchies among fashion items based on visual data and purchase history. The model uses a multi-task learning framework combining hyperbolic and Euclidean distances, with hyperbolic space providing natural representation of hierarchical relationships. The approach incorporates visual features through a pre-trained image encoder and attention mechanism. Experiments on three datasets demonstrate that the proposed model outperforms previous Euclidean-only approaches, with ablation studies confirming the importance of the multi-task learning component.

## Method Summary
The HV ACF model uses Poincaré ball model for hyperbolic space with neighbor-attentive aggregation to combine user purchase history and visual features. The method employs a multi-task learning framework that optimizes both hyperbolic and Euclidean distances simultaneously, with an adjustment loss component for regularization. The model is trained using Riemannian Adam optimizer on three fashion datasets (Amazon Women, Amazon Men, and TOWN Women) with AUC as the primary evaluation metric. Key hyperparameters include embedding dimension D=50, batch size 512, and Inception V3 as frozen backbone image encoder.

## Key Results
- Achieves AUC of 0.804 on Amazon Women dataset, outperforming baseline models
- Achieves AUC of 0.830 on Amazon Men dataset, showing consistent performance across datasets
- Ablation studies demonstrate that removing Euclidean loss substantially deteriorates performance
- Analysis reveals items and users are separated in hyperbolic space, with popular items mapped near the origin

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hyperbolic space better captures implicit hierarchies among fashion items than Euclidean space
- Mechanism: Distance from origin increases exponentially in hyperbolic space, naturally representing hierarchical structures with root nodes near origin and leaf nodes near boundary
- Core assumption: Fashion item relationships exhibit implicit hierarchical structure
- Evidence anchors: [abstract] mentions capturing hierarchies via visual data and purchase history; [section] explains exponential distance property
- Break condition: If fashion item relationships are not hierarchical or hierarchy is too shallow

### Mechanism 2
- Claim: Multi-task learning combining hyperbolic and Euclidean distances is crucial for performance
- Mechanism: Model uses both distance measures in loss function with adjustment loss regularizing hyperbolic embeddings
- Core assumption: Hyperbolic and Euclidean distances provide complementary information
- Evidence anchors: [abstract] states multi-task learning considers both distances; [section] shows ablation removing Euclidean loss substantially degrades performance
- Break condition: If either distance measure becomes redundant or combination creates conflicting gradients

### Mechanism 3
- Claim: Visual features combined with hyperbolic geometry improve recommendation accuracy
- Mechanism: Incorporates visual features through pre-trained image encoder and attention mechanism
- Core assumption: Visual appearance is critical for fashion recommendations and can be combined with hyperbolic geometry
- Evidence anchors: [abstract] mentions visual data; [section] notes visual information's value for clothing recommendations
- Break condition: If visual features don't add meaningful information beyond purchase history

## Foundational Learning

- Concept: Hyperbolic geometry and Poincaré ball model
  - Why needed here: Understanding how distances are measured in hyperbolic space and how the model represents hierarchical relationships
  - Quick check question: What is the key difference between distance measurement in hyperbolic vs Euclidean space that makes hyperbolic suitable for hierarchies?

- Concept: Multi-task learning framework
  - Why needed here: Understanding how the model combines hyperbolic and Euclidean losses and why both are necessary
  - Quick check question: Why does removing the Euclidean loss component significantly degrade performance according to the ablation studies?

- Concept: Attention mechanisms for visual features
  - Why needed here: Understanding how the model weighs different visual features when computing user preferences
  - Quick check question: How does the attention mechanism in the neighbor-attentive aggregation component work to combine visual features with purchase history?

## Architecture Onboarding

- Component map: User embeddings (U) -> Item embeddings (V and P) -> Pre-trained image encoder (E) -> Neighbor-attentive aggregation module -> Hyperbolic distance computation -> Multi-task loss function (Lhyp + Ladj) -> Optimization with Riemannian Adam

- Critical path: User purchase history + Visual features → Neighbor-attentive aggregation → Hyperbolic embeddings → Distance computation → Loss calculation → Parameter updates

- Design tradeoffs:
  - Embedding dimension vs model complexity
  - Balance between hyperbolic and Euclidean losses (γ parameter)
  - Number of neighbors sampled (L parameter)
  - Choice of image encoder backbone

- Failure signatures:
  - Poor performance when c is too large (hyperbolic space becomes too constrained)
  - Worse performance than Euclidean-only models when Ladj is removed
  - Instability during training if γ is set too small

- First 3 experiments:
  1. Test different values of γ (balance between hyperbolic and Euclidean losses) to find optimal performance
  2. Test different values of c (curvature of hyperbolic space) to understand its impact on embeddings
  3. Compare performance with and without the neighbor-attentive aggregation component to validate its importance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the long-term performance implications of using hyperbolic vs. Euclidean space in fashion item recommendation systems?
- Basis in paper: [explicit] The paper demonstrates that hyperbolic space models outperform Euclidean models on current datasets, but does not explore long-term performance or scalability
- Why unresolved: The paper only evaluates short-term performance on static datasets without considering dynamic changes in user preferences or item trends over time
- What evidence would resolve it: Longitudinal studies comparing model performance over extended periods, with datasets that include temporal dynamics and evolving fashion trends

### Open Question 2
- Question: How do hyperbolic embeddings affect interpretability and explainability of fashion recommendations?
- Basis in paper: [inferred] The paper shows that hyperbolic space separates popular and unpopular items, but does not explore how this affects user understanding or trust in recommendations
- Why unresolved: While the paper demonstrates improved performance, it does not address whether users can understand or trust recommendations based on hyperbolic geometry
- What evidence would resolve it: User studies evaluating comprehension, trust, and satisfaction with hyperbolic-based recommendations compared to traditional methods

### Open Question 3
- Question: Can hyperbolic geometry be effectively combined with other non-Euclidean spaces for fashion recommendation?
- Basis in paper: [explicit] The paper focuses solely on hyperbolic space and does not explore combinations with other geometric representations like spherical or product spaces
- Why unresolved: The paper demonstrates the effectiveness of hyperbolic space in isolation but does not investigate potential synergies with other geometric approaches
- What evidence would resolve it: Comparative studies testing hybrid models that combine hyperbolic space with other geometric representations on the same recommendation tasks

## Limitations

- The ablation studies are limited in scope and don't explore all potential failure modes
- Implementation details of neighbor-attentive aggregation mechanism remain underspecified
- Analysis of why popular items map near origin could benefit from more rigorous statistical validation

## Confidence

- High confidence: Multi-task learning framework's effectiveness (clear ablation evidence showing performance degradation without Euclidean loss)
- Medium confidence: Hyperbolic space's superiority for capturing fashion hierarchies (supported by results but limited comparative analysis)
- Low confidence: Specific attention mechanism's contribution (implementation details unclear, making independent verification difficult)

## Next Checks

1. Replicate the ablation study with additional variants: Remove the adjustment loss, vary the γ parameter across a wider range, and test with different neighbor sampling strategies to validate the robustness of the multi-task learning claims

2. Conduct cross-dataset generalization tests: Train the model on one dataset (e.g., Amazon Women) and evaluate on another (e.g., Amazon Men) to assess whether the hyperbolic embeddings capture universal fashion hierarchies or dataset-specific patterns

3. Perform statistical analysis of embedding distributions: Systematically measure and compare the norm distributions of users vs items in both hyperbolic and Euclidean spaces across training epochs to verify the claimed separation pattern and its relationship to recommendation performance