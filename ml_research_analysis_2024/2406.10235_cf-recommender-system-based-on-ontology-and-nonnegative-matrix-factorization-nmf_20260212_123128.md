---
ver: rpa2
title: CF Recommender System Based on Ontology and Nonnegative Matrix Factorization
  (NMF)
arxiv_id: '2406.10235'
source_url: https://arxiv.org/abs/2406.10235
tags:
- matrix
- ontology
- recommender
- system
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses two major challenges in recommender systems\u2014\
  data sparsity and low prediction accuracy\u2014by combining ontology-based semantic\
  \ modeling with Nonnegative Matrix Factorization (NMF). The method first constructs\
  \ a hierarchical ontology from item data to compute semantic similarity, which is\
  \ used to impute missing ratings in the user-item matrix."
---

# CF Recommender System Based on Ontology and Nonnegative Matrix Factorization (NMF)

## Quick Facts
- arXiv ID: 2406.10235
- Source URL: https://arxiv.org/abs/2406.10235
- Authors: Sajida Mhammedi; Hakim El Massari; Noreddine Gherabi; Amnai Mohamed
- Reference count: 16
- Primary result: Hybrid ontology-NMF approach improves MAE and RMSE compared to CF, CB, and CF+NMF on BookCrossing dataset

## Executive Summary
This paper addresses two major challenges in recommender systems—data sparsity and low prediction accuracy—by combining ontology-based semantic modeling with Nonnegative Matrix Factorization (NMF). The method first constructs a hierarchical ontology from item data to compute semantic similarity, which is used to impute missing ratings in the user-item matrix. Then, NMF is applied to reduce dimensionality, enabling more efficient and accurate predictions. Experiments on the BookCrossing dataset show that the hybrid approach outperforms traditional collaborative filtering (CF), content-based (CB), and CF+NMF methods. Specifically, the proposed method achieves better performance in terms of MAE and RMSE, demonstrating that integrating semantic relationships with matrix factorization significantly improves recommendation quality.

## Method Summary
The method combines ontology-based semantic modeling with Nonnegative Matrix Factorization to address data sparsity and low prediction accuracy in recommender systems. First, a hierarchical ontology is constructed from item data, and semantic similarity between items is computed using their shared ancestors in the ontology tree. This similarity is used to impute missing ratings in the user-item matrix. Then, NMF is applied to the enriched matrix for dimensionality reduction, extracting latent features that capture underlying patterns and suppress noise. The hybrid approach leverages semantic structure to mitigate sparsity, while NMF denoises and compresses the data for better generalization. Experiments on the BookCrossing dataset demonstrate improved recommendation quality compared to traditional CF, CB, and CF+NMF methods.

## Key Results
- The hybrid ontology-NMF approach outperforms traditional CF, CB, and CF+NMF methods on the BookCrossing dataset
- The method achieves better MAE and RMSE scores, indicating improved recommendation accuracy
- Experiments show the approach efficiently reduces data sparsity and provides more relevant recommendations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic similarity based on hierarchical ontology structure reduces the impact of data sparsity in user-item matrices.
- Mechanism: The system computes semantic similarity between items using their shared ancestors in the ontology tree. Items with similar meanings are treated as semantically related, allowing the model to infer ratings for missing entries by leveraging the ratings of similar items.
- Core assumption: Hierarchical relationships in the ontology accurately reflect semantic similarity between items, such that items closer in the hierarchy are more likely to have correlated user preferences.
- Evidence anchors:
  - [section] "The similarity between two concepts, C1 and C2, is calculated using the ontology's hierarchical structure. Consequently, the resemblance of the two conceptions is comparable to the proximity of two relatives [15]."
  - [abstract] "Experiments on the BookCrossing dataset show that the hybrid approach outperforms traditional collaborative filtering (CF), content-based (CB), and CF+NMF methods."
  - [corpus] Weak anchor: no corpus neighbors discuss ontology-based semantic similarity for CF; stated explicitly.
- Break condition: If the ontology structure does not accurately capture semantic relationships, or if user preferences are not influenced by semantic similarity, the inferred ratings will be noisy and degrade recommendation quality.

### Mechanism 2
- Claim: Nonnegative Matrix Factorization (NMF) reduces dimensionality and improves prediction accuracy by extracting latent features.
- Mechanism: NMF factorizes the (possibly partially imputed) user-item matrix into two nonnegative matrices, representing latent features and their weights. This dimensionality reduction captures underlying patterns and suppresses noise, leading to more robust predictions.
- Core assumption: The user-item interaction data can be well-approximated by a low-rank nonnegative factorization, meaning latent features are additive and interpretable.
- Evidence anchors:
  - [section] "NMF can factor it into two non-negative matrices, W and H, having dimensions m x k, k x n respectively... using NMF makes it possible to obtain factorized matrices with dimensions significantly smaller than the product matrix."
  - [abstract] "Specifically, the proposed method achieves better performance in terms of MAE and RMSE, demonstrating that integrating semantic relationships with matrix factorization significantly improves recommendation quality."
  - [corpus] Weak anchor: corpus includes general NMF papers but none specifically on CF hybrid with ontology; stated explicitly.
- Break condition: If the true underlying data structure is not low-rank or nonnegative, NMF may not capture meaningful patterns, and predictions will be inaccurate.

### Mechanism 3
- Claim: The hybrid combination of ontology-based semantic imputation and NMF-based dimensionality reduction synergistically improves recommendation accuracy.
- Mechanism: First, semantic similarity is used to estimate missing ratings, filling in gaps based on item relatedness. Then NMF is applied to this enriched matrix, extracting latent features from both observed and imputed data. This two-stage process leverages semantic structure to mitigate sparsity, while NMF denoises and compresses the data for better generalization.
- Core assumption: The imputed values from semantic similarity are sufficiently accurate to guide NMF toward better factorization, and the two methods complement rather than interfere with each other.
- Evidence anchors:
  - [abstract] "The findings showed that the implemented approach efficiently reduces the sparsity of CF suggestions, improves their accuracy, and gives more relevant items as recommendations."
  - [section] "The objective of our work is to remedy these two problems. For this reason, we use the matrix factorization algorithm using one of its methods: the Nonnegative Matrix Factorization (NMF), which is one of the methods used to accelerate the search for content recommendations for users. We also use the conceptualization of items based on ontology."
  - [corpus] Weak anchor: no corpus neighbors discuss hybrid semantic+NMF for CF; stated explicitly.
- Break condition: If semantic imputation introduces systematic bias, or if NMF is misled by inaccurate imputed values, the hybrid approach may perform worse than either method alone.

## Foundational Learning

- Concept: Collaborative Filtering (CF) basics
  - Why needed here: The paper builds upon CF, so understanding how CF uses user-item interactions is essential to grasp why sparsity and accuracy are problems, and how the hybrid approach addresses them.
  - Quick check question: In CF, how are recommendations typically generated from the user-item matrix?

- Concept: Nonnegative Matrix Factorization (NMF) fundamentals
  - Why needed here: NMF is a core component of the hybrid method; knowing how it decomposes matrices into additive, nonnegative factors is key to understanding its role in dimensionality reduction and feature extraction.
  - Quick check question: What are the two matrices produced by NMF, and why must they be nonnegative?

- Concept: Ontology and semantic similarity
  - Why needed here: The paper uses ontology to compute semantic similarity between items; understanding hierarchical tree structures and how similarity is derived from shared ancestors is necessary to follow the imputation step.
  - Quick check question: How is semantic similarity calculated between two concepts in a hierarchical ontology?

## Architecture Onboarding

- Component map: Ontology Construction -> Semantic Similarity Computation -> Matrix Imputation -> NMF Factorization -> Prediction
- Critical path: Ontology → Semantic Similarity → Matrix Imputation → NMF → Prediction
- Design tradeoffs:
  - Tradeoff between imputation accuracy and noise: Higher semantic similarity thresholds may reduce noise but leave more sparsity; lower thresholds may introduce inaccurate imputations.
  - NMF rank (k) selection: Higher k may capture more nuance but risks overfitting; lower k may miss important patterns.
  - Ontology depth: Deeper hierarchies may allow finer semantic distinctions but increase computational cost and risk overfitting.
- Failure signatures:
  - High MAE/RMSE despite hybrid approach: Imputation or NMF may be introducing bias or noise.
  - Recommendations are irrelevant: Semantic similarity may not align with user preferences, or NMF factorization is poor.
  - System is slow: Ontology construction or similarity computation may be too costly; consider caching or approximation.
- First 3 experiments:
  1. Baseline CF: Implement standard CF on the BookCrossing dataset and record MAE/RMSE.
  2. CF + Semantic Imputation: Add semantic imputation before CF prediction and compare accuracy.
  3. CF + NMF: Apply NMF to the original user-item matrix and evaluate prediction accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of semantic similarity threshold impact recommendation quality and sparsity reduction?
- Basis in paper: [explicit] The paper states "the semantic similarity threshold was adjusted to improve the content of the matrix data while preserving the source matrix's fundamental attribute characteristics."
- Why unresolved: The paper does not provide specific threshold values tested or analyze the sensitivity of performance metrics to threshold variations.
- What evidence would resolve it: Systematic experiments varying threshold values and reporting corresponding MAE/RMSE scores.

### Open Question 2
- Question: How does the hybrid ontology-NMF approach scale with dataset size compared to baseline methods?
- Basis in paper: [inferred] The paper discusses data sparsity and scalability as challenges, and mentions matrix factorization reducing matrix size, but does not provide runtime or scalability analysis.
- Why unresolved: No performance metrics (execution time, memory usage) are reported for different dataset sizes.
- What evidence would resolve it: Scalability experiments comparing runtime and resource consumption across increasing dataset sizes.

### Open Question 3
- Question: What is the optimal low-rank approximation (k value) for NMF in this hybrid approach?
- Basis in paper: [explicit] The paper explains NMF requires choosing a lower dimension k, but does not report experiments testing different k values.
- Why unresolved: The paper does not specify which k value was used or analyze how different k values affect recommendation accuracy.
- What evidence would resolve it: Experiments testing multiple k values and their impact on MAE/RMSE performance.

## Limitations
- Lack of detailed implementation specifics for semantic similarity computation and NMF parameter tuning, which are critical for faithful reproduction
- No discussion of potential overfitting or robustness to noisy imputations
- Absence of ablation studies to isolate the contribution of each component (ontology, imputation, NMF)

## Confidence
- Medium: The paper presents a clear hybrid approach with supporting experiments, but lacks detailed implementation specifics and sensitivity analysis.

## Next Checks
1. Reproduce baseline CF and report MAE/RMSE for comparison
2. Conduct sensitivity analysis on NMF rank (k) and semantic similarity thresholds
3. Perform cross-dataset validation to assess generalizability