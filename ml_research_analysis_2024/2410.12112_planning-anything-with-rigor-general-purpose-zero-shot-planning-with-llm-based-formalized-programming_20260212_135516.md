---
ver: rpa2
title: 'Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based
  Formalized Programming'
arxiv_id: '2410.12112'
source_url: https://arxiv.org/abs/2410.12112
tags:
- coffee
- roastery
- variable
- cafe
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLMFP tackles the challenge of zero-shot planning for complex tasks
  by converting natural language planning problems into formal optimization problems,
  which are then solved by an SMT solver. The framework uses LLMs to define goals,
  variables, and constraints, formulate them into a structured JSON representation,
  generate executable optimization code, execute and format results, and self-assess
  for correctness.
---

# Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming

## Quick Facts
- **arXiv ID**: 2410.12112
- **Source URL**: https://arxiv.org/abs/2410.12112
- **Reference count**: 40
- **Primary result**: 83.7% optimal rate with GPT-4o and 86.8% with Claude 3.5 Sonnet, significantly outperforming direct planning baselines

## Executive Summary
LLMFP is a framework that enables zero-shot planning for complex tasks by converting natural language planning problems into formal optimization problems solved by SMT solvers. The approach leverages LLMs to define goals, variables, and constraints, formulate them into structured JSON representations, generate executable optimization code, execute and format results, and self-assess for correctness. Tested on 9 diverse planning tasks, LLMFP achieves 83.7% optimal rate with GPT-4o and 86.8% with Claude 3.5 Sonnet, significantly outperforming direct planning baselines. The system demonstrates robustness to obfuscated problem descriptions and requires no task-specific examples, enabling flexible, high-performance planning across domains.

## Method Summary
LLMFP tackles zero-shot planning by transforming natural language planning problems into constrained optimization problems that can be rigorously solved by external solvers. The framework operates through a five-step pipeline: first, LLMs extract goals, decision variables, and constraints from task descriptions; second, they create structured JSON representations of these elements; third, they generate executable optimization code (Python/Z3 or MILP); fourth, they format solver outputs into consistent plans; and finally, they perform self-assessment and automatic modification to fix errors in previous steps. This approach separates cognitive formulation from computational solving, allowing LLMs to focus on understanding problems while solvers handle finding optimal solutions within defined constraints.

## Key Results
- Achieves 83.7% optimal rate with GPT-4o and 86.8% with Claude 3.5 Sonnet
- Outperforms best baseline (direct planning with OpenAI o1-preview) by 37.6% and 40.7%
- Demonstrates 100% success rate on multi-step planning tasks with both models
- Shows effectiveness of each component through ablation experiments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMFP achieves strong performance by converting planning problems into formal optimization problems that can be rigorously solved by external solvers
- Mechanism: The framework uses LLMs to extract goals, decision variables, and constraints from natural language task descriptions, formulates them into structured JSON representations, generates executable optimization code, and solves with SMT solver
- Core assumption: LLMs can reliably parse natural language planning problems into formal optimization problem specifications when given appropriate prompts
- Evidence anchors:
  - [abstract]: "LLMFP takes in natural language domain description, natural language query under this domain, and available background information or APIs as inputs... solves the planning problem in five steps"
  - [section]: "we propose an pipeline that solves the planning problem by converting them into constrained optimization problems and then solving them using the SMT solver"
- Break condition: If LLM cannot reliably extract constraints from natural language descriptions, or if task descriptions are ambiguous, the formulation step fails and the entire framework breaks down

### Mechanism 2
- Claim: The self-assessment and modification component enables iterative refinement that improves plan quality
- Mechanism: After each step (definer, formulator, code generator), LLMFP performs self-assessment based on execution results and automatically modifies the first incorrect step, looping back to continue from there
- Core assumption: LLMs can accurately assess their own outputs and generate appropriate modifications when given execution feedback
- Evidence anchors:
  - [abstract]: "Finally, LLMFP performs overall self-assessment and automatic modification to fix the broken parts of the previous steps"
  - [section]: "LLMFP assesses each step based on the execution result, and modifies the first incorrect step... and LLMFP will loop back to continue the next steps from there again"
- Break condition: If LLM cannot accurately identify which step is incorrect or generate appropriate modifications, the iterative refinement process fails to improve plan quality

### Mechanism 3
- Claim: The separation of concerns between LLM-based formulation and solver-based execution enables handling complex planning problems that LLMs cannot solve directly
- Mechanism: LLMs handle the cognitive task of understanding and formulating the problem, while SMT solver handles the computational task of finding optimal solutions within the defined constraints
- Core assumption: Formal solvers can guarantee optimal solutions when given correct problem formulations, and this computational capability complements LLM's limitations in direct planning
- Evidence anchors:
  - [abstract]: "LLMFP notably achieves 83.7% and 86.8% optimal rates for GPT-4o and Claude 3.5 Sonnet, outperforming the best baseline (direct planning with OpenAI o1-preview) by 37.6% and 40.7%"
  - [section]: "Once a planning problem is formulated as the constrained optimization problem, it can be rigorously solved by solvers such as the SMT solver"
- Break condition: If the solver cannot handle the complexity of the formulated problem, or if the formulation contains errors that make the problem unsolvable, the framework fails to deliver valid plans

## Foundational Learning

- Concept: Constrained optimization problems
  - Why needed here: Planning problems are recast as constrained optimization problems where the goal is to find optimal solutions satisfying constraints
  - Quick check question: What are the three main components of a constrained optimization problem (P = {x, f(·), g(·), h(·)}) and what does each represent?

- Concept: Satisfiability Modulo Theory (SMT) solvers
  - Why needed here: SMT solvers are used to solve the formally encoded optimization problems generated by LLMFP
  - Quick check question: What is the key difference between SMT solvers and traditional SAT solvers, and why are SMT solvers more suitable for this planning framework?

- Concept: Chain-of-thought prompting
  - Why needed here: CoT prompting is used as one of the baseline methods to improve LLM planning performance
  - Quick check question: How does chain-of-thought prompting differ from direct prompting, and why might it be particularly useful for complex planning tasks?

## Architecture Onboarding

- Component map: Input → Definer → Formulator → Code Generator → Solver → Result Formatter → Self Assessor → Output
- Critical path: Input → Definer → Formulator → Code Generator → Solver → Result Formatter → Self Assessor → Output
- Design tradeoffs:
  - Flexibility vs. performance: Framework achieves zero-shot generalization but may be slower than task-specific solutions
  - LLM capability vs. solver capability: LLMs handle formulation while solvers handle computation
  - Iteration count vs. solution quality: More iterations enable better refinement but increase runtime
- Failure signatures:
  - Definer failure: Missing or incorrect goal/constraints, poor constraint reasoning
  - Formulator failure: Incorrect variable representation, missing variable attributes
  - Code Generator failure: Syntax errors, incorrect logic, missing constraints
  - Self Assessor failure: Incorrect assessment, inappropriate modifications
- First 3 experiments:
  1. Run Coffee task with all components enabled and verify optimal rate matches reported values
  2. Disable Formulator component and verify performance degradation matches ablation results
  3. Test with obfuscated predicate names (Mystery Blocksworld) to verify robustness to unclear naming

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LLMFP perform on planning problems that involve continuous variables or real-valued constraints, given that the current framework focuses on discrete optimization with SMT and MILP solvers?
- Basis in paper: [inferred] The paper mentions that the SMT solver is used for encoding optimization problems and that the framework can be adapted to any planner or solver by modifying the requirements in prompts. However, the experiments focus on discrete optimization problems.
- Why unresolved: The paper does not provide experimental results or analysis for continuous optimization problems, which are common in real-world planning scenarios such as resource allocation and scheduling.
- What evidence would resolve it: Testing LLMFP on a suite of continuous optimization problems (e.g., linear programming, nonlinear optimization) and comparing its performance with specialized continuous optimization solvers would provide evidence for its effectiveness in handling continuous variables.

### Open Question 2
- Question: What is the impact of task description quality on LLMFP's performance, and how does it handle ambiguous or incomplete task descriptions?
- Basis in paper: [explicit] The paper states that LLMFP needs clear and detailed task descriptions and queries, and it is hard for LLMFP to define the problems' goals and constraints if the task description is ambiguous or missing some important information.
- Why unresolved: While the paper mentions the importance of clear task descriptions, it does not provide a detailed analysis of how LLMFP handles ambiguous or incomplete task descriptions or the extent to which task description quality affects its performance.
- What evidence would resolve it: Conducting experiments with task descriptions of varying quality (e.g., clear, ambiguous, incomplete) and analyzing LLMFP's performance and ability to recover from ambiguous or incomplete information would provide insights into its robustness to task description quality.

### Open Question 3
- Question: How does LLMFP scale with problem size and complexity, and what are the computational limitations of the framework?
- Basis in paper: [inferred] The paper mentions that LLMFP uses external solvers (SMT and MILP) to solve optimization problems, and the performance of LLMFP depends on the strength of the solvers. It also mentions that for massive databases with numerous feasible plans, the speed for solvers to search for optimal plans is slow.
- Why unresolved: The paper does not provide a detailed analysis of LLMFP's scalability with problem size and complexity or the computational limitations of the framework. It also does not discuss potential strategies to mitigate the slow search speed for large-scale problems.
- What evidence would resolve it: Conducting experiments with problems of varying sizes and complexities, analyzing the computational time and resources required by LLMFP, and exploring strategies to improve scalability (e.g., heuristics, approximation algorithms) would provide insights into its computational limitations and potential solutions.

## Limitations

- **Prompt sensitivity**: The framework's performance depends heavily on LLM prompt engineering, but exact prompt templates are not provided, making reproduction challenging
- **Solver dependency**: Performance results are tied to specific SMT solvers (Z3), and generalizability to other solvers remains untested
- **Domain coverage**: While tested on 9 diverse tasks, the framework's effectiveness on more complex, real-world planning problems with extensive background knowledge is unverified

## Confidence

- **High confidence**: The core mechanism of converting planning problems to formal optimization problems is theoretically sound and well-supported by the empirical results
- **Medium confidence**: The iterative refinement through self-assessment is effective based on ablation results, but the robustness of this mechanism across diverse problem types requires further validation
- **Medium confidence**: The solver-agnostic claim is theoretically valid, but practical implementation may face challenges with different solver interfaces and capabilities

## Next Checks

1. **Prompt sensitivity analysis**: Systematically vary prompt templates for each LLMFP component to quantify the impact on optimal rate and identify critical prompt elements
2. **Solver portability test**: Implement LLMFP with an alternative SMT solver (e.g., CVC4) to verify solver-agnostic claims and measure performance differences
3. **Domain complexity stress test**: Evaluate LLMFP on planning tasks with significantly more constraints, variables, and background information than the 9 tested tasks to assess scalability limits