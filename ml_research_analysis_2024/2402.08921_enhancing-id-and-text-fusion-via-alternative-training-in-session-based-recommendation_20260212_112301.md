---
ver: rpa2
title: Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation
arxiv_id: '2402.08921'
source_url: https://arxiv.org/abs/2402.08921
tags:
- text
- information
- training
- alterrec
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies an imbalance issue in naive fusion frameworks
  for combining ID and text modalities in session-based recommendation, where ID information
  dominates and text modality is undertrained, leading to ineffective text integration.
  To address this, the authors propose AlterRec, an alternative training strategy
  that separately trains ID and text uni-modal networks and enables mutual learning
  through an alternating update mechanism using hard negative samples and augmented
  positive samples from each modality.
---

# Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation

## Quick Facts
- **arXiv ID**: 2402.08921
- **Source URL**: https://arxiv.org/abs/2402.08921
- **Reference count**: 40
- **Key outcome**: AlterRec achieves up to 19% improvement in Hits@10 and 3% improvement in NDCG@20 compared to best baseline, effectively integrating text information and improving long-tail item performance

## Executive Summary
This paper addresses a fundamental challenge in multi-modal session-based recommendation: the imbalance issue in naive fusion frameworks where ID information dominates training and text modality remains undertrained. The authors propose AlterRec, an alternative training strategy that separately trains ID and text uni-modal networks while enabling mutual learning through an alternating update mechanism. Using hard negative samples and augmented positive samples derived from each modality's predictions, AlterRec effectively integrates textual semantic information to improve recommendation performance, particularly for long-tail items. Experiments on real-world datasets demonstrate significant improvements over various baselines.

## Method Summary
AlterRec tackles the modality imbalance problem by implementing an alternative training strategy that separates the training of ID and text uni-modal networks. The method uses hard negative samples and augmented positive samples derived from each modality's predictions to enable mutual learning. The approach alternates between training the ID and text networks, using predictions from one network as training signals for the other. This design prevents the ID component from dominating the training process while effectively leveraging textual semantic information for recommendations. The final score combines both modalities using a weighted sum, with parameters optimized during training.

## Key Results
- AlterRec achieves up to 19% improvement in Hits@10 and 3% improvement in NDCG@20 compared to the best performing baseline
- The method effectively integrates text information while avoiding the imbalance issue seen in naive fusion frameworks
- AlterRec demonstrates superior performance on long-tail items, particularly in the [0,30] interaction count group
- Parameter analysis shows that increasing the number of hard negative samples (k2) generally improves performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The naive fusion framework fails to balance ID and text modalities, causing ID to dominate training and text to remain undertrained.
- Mechanism: When ID and text are fused using summation or concatenation and trained jointly, the gradient updates disproportionately favor the stronger ID modality. This leads to the text component receiving insufficient learning signals, preventing effective integration of textual information.
- Core assumption: The stronger modality (ID) has higher predictive power on the training objective, causing optimization to focus on it at the expense of the weaker modality (text).
- Evidence anchors:
  - [abstract]: "Further investigation reveals an potential imbalance issue in naive fusion, where the ID dominates and text modality is undertrained."
  - [section 3.2.2]: "Figure 3 reveals a significant imbalance issue in NFRec: the performance and loss of the ID component are almost overlapping with those of NFRec. This indicates a heavy reliance on the ID component in NFRec, where the ID dominates the overall performance and loss, and the text component has limited contributions."
  - [corpus]: Weak evidence - corpus lacks direct support for the specific claim about ID dominance in fusion frameworks.

### Mechanism 2
- Claim: Alternating training with hard negative samples enables mutual learning between ID and text modalities.
- Mechanism: By training ID and text uni-modal networks separately and using predictions from one network as training signals for the other, each modality learns from the patterns identified by the other. Hard negative samples derived from one modality's predictions provide more informative training signals than random negatives.
- Core assumption: The predictions from one modality contain useful information that can help the other modality learn complementary patterns.
- Evidence anchors:
  - [abstract]: "It separates the training of ID and text, thereby avoiding the imbalance issue seen in naive fusion. Additionally, AlterRec designs a novel strategy to facilitate the interaction between the two modalities, enabling them to mutually learn from each other."
  - [section 4.2]: "We leverage the predictions from one modality to the other in two aspects. First, we select top-ranked items as augmented positive training samples... Second, we choose other high-scored items as negative samples."
  - [corpus]: Weak evidence - corpus lacks direct support for the effectiveness of hard negative samples in multi-modal learning.

### Mechanism 3
- Claim: Text information provides complementary semantic information that improves performance on long-tail items.
- Mechanism: Textual data contains semantic information about items that is not captured by ID-based representations alone. This semantic information helps the model better understand and recommend items with sparse interactions (long-tail items).
- Core assumption: Long-tail items have distinctive textual features that can be leveraged for better recommendations.
- Evidence anchors:
  - [abstract]: "However, these methods often face challenges with long-tail items and overlook other rich forms of information, notably valuable textual semantic information."
  - [section 5.4]: "Textual data offers valuable semantic information that can be used to enhance long-tail items in session-based recommendation... AlterRec achieves the best performance in the [0,30] group on the Homedepot and Amazon-French."
  - [corpus]: Weak evidence - corpus lacks direct support for the specific claim about text improving long-tail item performance.

## Foundational Learning

- Concept: Multi-modal learning imbalance
  - Why needed here: Understanding why naive fusion fails is crucial for appreciating the alternative training approach. The imbalance phenomenon explains why simply combining modalities doesn't always improve performance.
  - Quick check question: What causes one modality to dominate training in naive fusion frameworks?

- Concept: Hard negative sampling in contrastive learning
  - Why needed here: The effectiveness of AlterRec relies on using informative negative samples derived from one modality's predictions to train the other. Understanding how hard negatives improve learning is essential.
  - Quick check question: How do hard negative samples differ from random negative samples in their impact on model training?

- Concept: Session-based recommendation objectives
  - Why needed here: The specific task of predicting the next item in a session influences the design of the model architecture and training strategy. Understanding the evaluation metrics and loss functions is important.
  - Quick check question: What is the difference between Hits@N and NDCG@N metrics in evaluating recommendation performance?

## Architecture Onboarding

- Component map:
  ID encoder -> ID network -> ID scores -> Final combiner
  Text encoder -> Text network -> Text scores -> Final combiner
  Alternating controller -> Hard negative selection -> Augmented positives

- Critical path:
  1. Initialize ID and text uni-modal networks
  2. Train both networks with random negatives for m_random epochs
  3. Alternate training between networks using hard negatives for m_gap epochs each
  4. Combine final scores using weighted combination of ID and text scores
  5. Evaluate on test set

- Design tradeoffs:
  - Separate vs. joint training: Separate training avoids imbalance but loses potential synergies
  - Hard vs. random negatives: Hard negatives provide better learning signals but require more computation
  - Text encoder choice: Pre-trained language models provide better semantic features but are fixed during training

- Failure signatures:
  - ID and text components show similar performance and loss curves (indicating imbalance)
  - Model performance matches or is worse than single-modality baselines
  - Training loss plateaus quickly without meaningful improvement

- First 3 experiments:
  1. Compare performance of ID-only, text-only, and naive fusion models on a small dataset to verify the imbalance phenomenon
  2. Implement basic alternating training without hard negatives to test if separation alone helps
  3. Add hard negative sampling to the alternating training and measure improvement over random negatives

## Open Questions the Paper Calls Out
The paper identifies several open questions for future research:
- What are the specific theoretical causes behind the imbalance issue observed in naive fusion frameworks where ID information dominates and text modality is undertrained?
- How does the performance of AlterRec compare to other potential alternative training strategies that might address the modality imbalance issue?
- What is the optimal strategy for selecting the parameters k1 and k2 for hard negative sampling in different types of recommendation datasets?

## Limitations
- The effectiveness of hard negative samples is asserted rather than empirically demonstrated through controlled experiments comparing random versus hard negatives
- The assumption that ID dominance is the primary failure mode in naive fusion is supported by loss curves but not through systematic ablation of different fusion strategies
- The paper lacks external validation through ablation studies on the hard negative sampling strategy specifically

## Confidence
- **High confidence**: The imbalance problem in naive fusion frameworks is well-documented through loss curves and performance metrics showing that ID and text components have similar performance when trained jointly.
- **Medium confidence**: The alternative training strategy with alternating updates improves performance over baselines, though the specific contribution of hard negative samples versus simple separation is not isolated.
- **Low confidence**: The claim that hard negative samples derived from one modality's predictions provide superior learning signals compared to random negatives lacks direct experimental validation.

## Next Checks
1. **Ablation study on negative sampling**: Run experiments comparing AlterRec with random negatives versus hard negatives to quantify the specific contribution of the hard negative strategy to overall performance improvements.

2. **External validation on additional datasets**: Test AlterRec on at least two additional session-based recommendation datasets (e.g., Yoochoose, Diginetica) to verify that the performance improvements generalize beyond the current datasets.

3. **Comparison with recent multi-modal methods**: Benchmark AlterRec against state-of-the-art transformer-based multi-modal approaches that also incorporate textual information to determine whether the alternative training strategy provides advantages over more recent fusion techniques.