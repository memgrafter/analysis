---
ver: rpa2
title: Where is the Truth? The Risk of Getting Confounded in a Continual World
arxiv_id: '2402.06434'
source_url: https://arxiv.org/abs/2402.06434
tags:
- dataset
- tasks
- data
- learning
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ConCon, the first continually confounded
  dataset, designed to study how machine learning models handle confounding factors
  in continual learning settings. The authors formalize continual confounding and
  create two dataset variants (disjoint and strict) where spurious correlations vary
  across sequential tasks.
---

# Where is the Truth? The Risk of Getting Confounded in a Continual World

## Quick Facts
- arXiv ID: 2402.06434
- Source URL: https://arxiv.org/abs/2402.06434
- Reference count: 40
- Primary result: Introduces ConCon, the first continually confounded dataset, demonstrating that standard continual learning methods fail to learn ground truth rules due to varying spurious correlations across tasks

## Executive Summary
This paper introduces ConCon, the first continually confounded dataset designed to study how machine learning models handle confounding factors in continual learning settings. The authors formalize continual confounding and create two dataset variants (disjoint and strict) where spurious correlations vary across sequential tasks. They demonstrate that standard continual learning methods fail to learn the underlying ground truth rule, instead focusing on task-specific confounders. Notably, they identify "insidious continual confounding" where joint training succeeds but continual cumulative training fails, challenging the assumption that knowledge accumulation is the optimal solution in continual learning.

## Method Summary
The authors formalize continual confounding by introducing a new dataset, ConCon, with two variants: disjoint and strict. In both variants, spurious correlations vary across sequential tasks, creating a scenario where models must learn to ignore confounding factors. The dataset consists of image classification tasks where certain features are confounded with class labels in different tasks. The authors evaluate standard continual learning methods on ConCon and compare their performance to joint training, demonstrating that continual learning methods fail to learn the underlying ground truth rule due to their focus on task-specific confounders.

## Key Results
- Standard continual learning methods fail to learn ground truth rules on ConCon dataset
- "Insidious continual confounding" identified where joint training succeeds but continual cumulative training fails
- Knowledge accumulation is not always optimal in continual learning settings
- Models focus on task-specific confounders rather than underlying patterns

## Why This Works (Mechanism)
The paper demonstrates that continual learning methods are susceptible to spurious correlations that vary across tasks. When models encounter new tasks with different confounding patterns, they tend to adapt to these new correlations rather than maintaining focus on the underlying ground truth features. This leads to catastrophic forgetting of previously learned ground truth patterns and an over-reliance on task-specific confounders. The joint training approach succeeds because it can see all data simultaneously and learn to ignore confounders, while sequential training cannot.

## Foundational Learning
- **Continual Learning**: Learning from sequential data without forgetting previous tasks - needed to understand the problem setting
- **Confounding in ML**: When spurious correlations between features and labels mislead models - needed to understand the core challenge
- **Ground Truth Rule**: The actual underlying pattern that should be learned - needed as the success metric
- **Spurious Correlations**: False relationships between features and labels - needed to understand confounders
- **Task-specific Adaptation**: Model's ability to adjust to new patterns - needed to understand why methods fail

## Architecture Onboarding
**Component Map**: Data Generator -> ConCon Dataset -> Continual Learning Algorithm -> Performance Evaluation -> Comparison with Joint Training

**Critical Path**: The evaluation pipeline follows: generate confounded data → apply continual learning algorithm → measure performance → compare with joint training baseline

**Design Tradeoffs**: The dataset design balances between realistic confounding scenarios and controlled experimental conditions. The disjoint vs strict variants represent different levels of confounding severity.

**Failure Signatures**: Models show high accuracy on individual tasks but fail to generalize across tasks, indicating reliance on task-specific confounders rather than ground truth features.

**First Experiments**:
1. Evaluate standard continual learning methods (EWC, MAS, etc.) on both ConCon variants
2. Compare continual learning performance with joint training on same data
3. Test model performance when confounding factors are removed from test data

## Open Questions the Paper Calls Out
None

## Limitations
- ConCon dataset may not fully capture real-world confounding complexity
- Evaluation limited to image classification tasks
- Analysis focused on specific set of continual learning algorithms
- Does not explore domain adaptation techniques for mitigating confounding

## Confidence

High:
- Identification of "insidious continual confounding" is well-supported
- Experimental results demonstrating continual learning failures are robust
- The core observation that joint training can succeed while continual training fails is significant

Medium:
- Dataset's ability to capture real-world confounding nuances is uncertain
- Generalization of findings to other domains requires further validation
- The claim about knowledge accumulation not being optimal needs more extensive studies

## Next Checks
1. Evaluate ConCon performance across wider range of continual learning algorithms including recent state-of-the-art methods
2. Apply domain adaptation techniques to mitigate confounding effects and compare with standard approaches
3. Conduct real-world case studies to validate practical relevance of insidious continual confounding phenomenon