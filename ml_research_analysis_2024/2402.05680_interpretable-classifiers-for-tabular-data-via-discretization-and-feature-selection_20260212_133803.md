---
ver: rpa2
title: Interpretable classifiers for tabular data via discretization and feature selection
arxiv_id: '2402.05680'
source_url: https://arxiv.org/abs/2402.05680
tags:
- median
- above
- classi
- data
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for producing interpretable classifiers
  for tabular data by first discretizing numerical features using medians and then
  applying feature selection to obtain short Boolean formulas (in DNF) that serve
  as classifiers. The method uses an efficient algorithm to compute the best possible
  classifier for a given set of features, and nested cross-validation to avoid overfitting.
---

# Interpretable classifiers for tabular data via discretization and feature selection

## Quick Facts
- arXiv ID: 2402.05680
- Source URL: https://arxiv.org/abs/2402.05680
- Reference count: 40
- Primary result: Produces highly interpretable classifiers using few features while achieving accuracy comparable to XGBoost and random forests

## Executive Summary
This paper presents a method for creating interpretable classifiers for tabular data by discretizing numerical features using medians and then applying feature selection to obtain short Boolean formulas in disjunctive normal form (DNF). The approach uses an efficient algorithm to compute the best possible classifier for a given set of features, combined with nested cross-validation to avoid overfitting. Experiments on 12 datasets demonstrate that the resulting classifiers are both highly interpretable (using very few features) and accurate, achieving results comparable to XGBoost and random forests. The method produces globally interpretable classifiers that use fewer than four features on average for most datasets.

## Method Summary
The method works by first discretizing numerical features at the median value, converting continuous values into binary features. Feature selection is then applied using standard methods (SelectKBest with F-test, mutual information, or chi2-test) to choose the most relevant attributes. For each selected set of features, an efficient O(|W||τ||T|) algorithm computes the best possible Boolean classifier in DNF form. Nested 70/30 cross-validation is used to find the most accurate formula while preventing overfitting, with a maximum of 10 features allowed. The final DNF formula is simplified using SymPy's simplify_logic function. The method is compared against XGBoost and random forests on 12 datasets, demonstrating both interpretability and competitive accuracy.

## Key Results
- Classifiers use fewer than four features on average for most datasets
- Accuracy comparable to XGBoost and random forests on 12 tested datasets
- Runtime remains under an hour even for the largest datasets tested
- Theoretical sample bound result provided showing when empirical classifier matches ideal one

## Why This Works (Mechanism)

### Mechanism 1
Discretizing numerical features at the median and using Booleanized attributes leads to simple, interpretable classifiers without large accuracy loss. Median-based discretization converts continuous values into binary features, reducing feature space complexity and enabling the use of fast Boolean formula algorithms that scale linearly with the number of selected features. The core assumption is that the median split preserves enough discriminative power for classification. Evidence shows this approach maintains competitive accuracy while dramatically improving interpretability. The break condition occurs if data distribution is heavily skewed or multimodal, where median discretization may collapse informative variance.

### Mechanism 2
Nested cross-validation with up to 10 features avoids overfitting while maintaining high interpretability. By limiting features and using validation sets to stop before overfitting, the method balances accuracy and simplicity, producing short DNF formulas that are globally interpretable. The core assumption is that overfitting typically happens after a small number of features, and a 1% accuracy tolerance is sufficient for model selection. Evidence demonstrates this approach produces accurate models without excessive complexity. The break condition is when the true decision boundary requires more than 10 features, leading to underfitting and accuracy degradation.

### Mechanism 3
The O(|W||τ||T|) algorithm for computing the empirical ideal classifier is fast enough for practical use and produces the best possible classifier given selected features. By scanning data once and counting type occurrences, the algorithm efficiently finds the DNF formula with minimal empirical error, approximating the theoretical ideal classifier. The core assumption is that the number of selected features τ is small, making the algorithm effectively linear in data points. Evidence shows the algorithm remains practical even for larger datasets. The break condition is if τ grows large (e.g., >20), where complexity degrades toward quadratic time.

## Foundational Learning

- Concept: Discretization and Booleanization of numerical features
  - Why needed here: Converts continuous attributes into binary features, enabling Boolean formula algorithms and simplifying interpretability
  - Quick check question: What threshold method is used to convert a numerical attribute into a Boolean feature in this paper?

- Concept: Nested cross-validation and hyperparameter selection
  - Why needed here: Prevents overfitting by validating model performance on held-out data while tuning number of features and other settings
  - Quick check question: How does the method decide when to stop adding features to avoid overfitting?

- Concept: DNF (disjunctive normal form) formulas and local/global interpretability
  - Why needed here: DNF formulas provide readable, rule-based representation of classifier, making it easy to explain predictions both locally and globally
  - Quick check question: What is the difference between local and global interpretability in context of DNF classifiers?

## Architecture Onboarding

- Component map: Data → Discretize → Feature select → Build DNF → Validate → Simplify → Output
- Critical path: Data preprocessing (median discretization, one-hot encoding) → Feature selection (SelectKBest methods) → Classifier construction (O(|W||τ||T|) algorithm) → Validation (nested 70/30 cross-validation) → Post-processing (SymPy simplify_logic) → Output DNF formula
- Design tradeoffs:
  - Simple discretization (median) vs. more nuanced binning: favors speed and interpretability over potential accuracy gains
  - Fixed max 10 features vs. adaptive: simplifies engineering but may underfit some datasets
  - Use of standard feature selectors vs. custom: ensures robustness and easy replacement
- Failure signatures:
  - Runtime much longer than expected: likely due to high |τ| or very large dataset
  - Accuracy drops sharply: may indicate median discretization lost critical variance
  - Validation accuracy keeps increasing with more features: possible overfitting or too lenient stopping criterion
- First 3 experiments:
  1. Run on small UCI dataset (e.g., BreastCancer) with default settings; verify median discretization and feature selection steps
  2. Test nested cross-validation on mid-sized dataset (e.g., GermanCredit); check accuracy plateau and formula length
  3. Compare runtime and accuracy against XGBoost on binary classification task; document any deviations from expected performance

## Open Questions the Paper Calls Out

### Open Question 1
Can the discretization step be improved beyond simple median-based Booleanization while maintaining interpretability and computational efficiency? The paper states "the discretization steps are performed very roughly, using simply the medians" and mentions considering "more custom-made procedures of discretization" in conclusions. This remains unresolved as the paper acknowledges this as future work without exploring alternatives in current experiments. Evidence to resolve this would be experiments comparing different discretization methods (entropy-based, clustering-based) while measuring both interpretability metrics and accuracy.

### Open Question 2
What is the theoretical relationship between maximum number of features allowed (currently set to 10) and achievable accuracy-interpretability tradeoff across different dataset characteristics? The paper mentions "This is a hyperparameter one could optimize for each dataset separately" and notes "For some datasets it could be necessary to go further before the accuracy stagnates." This remains unresolved as the paper uses fixed limit across all datasets without systematic exploration. Evidence to resolve this would be systematic study varying maximum feature limit across diverse datasets, measuring effects on both accuracy and interpretability.

### Open Question 3
How does the method's performance scale with dataset size and dimensionality, particularly for datasets with millions of rows or thousands of features? The paper mentions "Even for the two largest datasets, Covertype and RoadSafety, the runtime is still less than an hour" and tested up to 5997 Booleanized attributes, but doesn't systematically explore scalability limits. This remains unresolved as experiments cover reasonable range but don't push boundaries of very large datasets or high dimensionality. Evidence to resolve this would be systematic scaling experiments testing method on progressively larger datasets and higher dimensionalities.

## Limitations
- Median-based discretization may not preserve discriminative information for skewed or multimodal distributions
- Assumes Boolean formulas with up to 10 features are sufficient for most classification tasks
- Performance degrades for larger feature sets despite O(|W||τ||T|) complexity
- Comparison with XGBoost and random forests uses unspecified hyperparameters

## Confidence

- **High confidence**: Nested cross-validation approach effectively prevents overfitting and resulting classifiers are highly interpretable with few features
- **Medium confidence**: Median discretization method preserves sufficient discriminative power across most datasets
- **Medium confidence**: O(|W||τ||T|) algorithm provides best possible classifier for selected features within practical time constraints

## Next Checks
1. Test the method on datasets with known multimodal distributions to assess median discretization performance
2. Run experiments with varying maximum feature limits (5, 10, 15) to identify point of diminishing returns
3. Conduct ablation studies removing the SymPy simplification step to measure its impact on both interpretability and accuracy