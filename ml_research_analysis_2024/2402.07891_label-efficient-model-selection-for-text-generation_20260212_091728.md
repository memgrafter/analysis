---
ver: rpa2
title: Label-Efficient Model Selection for Text Generation
arxiv_id: '2402.07891'
source_url: https://arxiv.org/abs/2402.07891
tags:
- examples
- random
- diffuse
- number
- success
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DiffUse reduces annotation costs for model selection in text generation
  by clustering embedding differences between model outputs and selecting informative
  examples for oracle preference judgments. The method uses semantic embeddings of
  model outputs, computes difference vectors, clusters them hierarchically, and selects
  representatives to maximize diversity and informativeness.
---

# Label-Efficient Model Selection for Text Generation

## Quick Facts
- arXiv ID: 2402.07891
- Source URL: https://arxiv.org/abs/2402.07891
- Authors: Shir Ashury-Tahan; Ariel Gera; Benjamin Sznajder; Leshem Choshen; Liat Ein-Dor; Eyal Shnarch
- Reference count: 40
- Primary result: DiffUse reduces annotation costs for model selection by up to 75% while maintaining high success rates

## Executive Summary
DiffUse is a method for efficient model selection in text generation that reduces annotation costs by intelligently selecting examples for oracle preference judgments. The approach clusters semantic difference vectors between model outputs and selects representative examples that maximize diversity and informativeness. Experiments across 666 model pairs and 6 HELM tasks show DiffUse can identify the better model with significantly fewer annotations than random selection, achieving up to 75% cost reduction while maintaining high success rates.

## Method Summary
DiffUse operates by first generating embeddings for model outputs using Sentence-BERT, then computing difference vectors between paired model outputs. These difference vectors are clustered hierarchically using Ward linkage, and representatives closest to cluster centers are selected for oracle annotation. The method also includes an iterative variant that uses a hypergeometric distribution-based stopping criterion to determine when sufficient annotations have been collected to confidently identify the better model.

## Key Results
- DiffUse reduces required annotations by up to 75% compared to random selection
- Success rates in identifying the better model are maintained even with minimal annotation budgets
- Iterative selection dynamically determines optimal stopping points based on statistical thresholds
- Examples selected by DiffUse show larger output differences and better alignment with winning models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DiffUse reduces annotation costs by selecting examples that maximize information gain for distinguishing model preferences
- Mechanism: Difference vectors between model output embeddings are clustered, with one representative selected per cluster to ensure diversity and informativeness
- Core assumption: Semantic differences captured in embedding space correlate with oracle preference patterns
- Evidence anchors: Abstract and method section describe clustering approach; weak corpus support for clustering effectiveness in similar tasks
- Break condition: Semantic encoder fails to capture meaningful differences or oracle preferences don't correlate with embedding differences

### Mechanism 2
- Claim: Iterative selection dynamically determines when to stop annotating based on statistical thresholds
- Mechanism: Hypergeometric distribution calculates probability of observed preferences occurring by chance, enabling stopping when reliability threshold is met
- Core assumption: Hypergeometric distribution provides reasonable proxy for preference estimation reliability despite non-random selection
- Evidence anchors: Method section describes hypergeometric-based reliability threshold; weak corpus support for this approach in preference selection
- Break condition: Highly variable oracle preferences or small winning distances cause early/late stopping

### Mechanism 3
- Claim: DiffUse preferentially selects examples with larger output differences, improving selection accuracy
- Mechanism: Clustering difference vectors groups smaller-norm vectors together, leaving high-norm vectors as cluster centers that show clearer preference alignment
- Core assumption: Larger semantic differences correlate with clearer preference judgments and larger quality gaps
- Evidence anchors: Analysis shows clustering results in high-norm instances as representatives; preference labels more likely to align with winning model for high-norm instances; weak corpus support for this correlation
- Break condition: Oracle preferences not correlated with output differences or poor semantic encoding

## Foundational Learning

- Concept: Hierarchical Agglomerative Clustering with Ward linkage
  - Why needed here: Partitions difference vectors into meaningful groups representing different types of model output differences
  - Quick check question: How does Ward linkage minimize within-cluster variance when merging clusters?

- Concept: Semantic embeddings using Sentence-BERT
  - Why needed here: Converts model outputs into vectors capturing semantic meaning for difference computation
  - Quick check question: What distance metric (cosine vs Euclidean) is more appropriate for comparing Sentence-BERT embeddings?

- Concept: Hypergeometric distribution and survival function
  - Why needed here: Calculates probability that observed preferences could occur by chance, enabling stopping criterion
  - Quick check question: How does the hypergeometric survival function differ from a binomial distribution in this context?

## Architecture Onboarding

- Component map: Input models → Inference on test set → Embedding generation → Difference vector computation → Hierarchical clustering → Representative selection → Oracle annotation → Preference aggregation → Model selection
- Critical path: Embedding generation through representative selection to oracle annotation is most time-consuming and cost-critical
- Design tradeoffs: Higher clustering granularity increases diversity but may select less informative examples; lower granularity risks missing important differences
- Failure signatures: Poor performance on datasets with small winning distances; inconsistent results across different semantic encoders; stopping criterion met too early/late
- First 3 experiments:
  1. Run DiffUse on single model pair with small budget (N=10) and verify selected examples have higher difference norms than random selection
  2. Compare DiffUse with random selection on model pair with known large winning distance and measure success rate
  3. Test iterative algorithm on model pair and verify stopping criterion activates appropriately based on preference distribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DiffUse perform when selecting among more than two models simultaneously?
- Basis in paper: [inferred] Paper notes "we leave to future work the scenario of picking from a larger set of candidates"
- Why unresolved: Only evaluates on pairwise model comparisons, so multi-model selection effectiveness remains untested
- What evidence would resolve it: Experiments comparing DiffUse performance on selecting best model from 3+ candidates

### Open Question 2
- Question: Would DiffUse remain effective if semantic encoder was changed from Sentence-BERT to different model?
- Basis in paper: [explicit] Notes "opting for a different choice of clustering algorithm, or for a different approach of selecting examples given the clusters, does not dramatically affect the results"
- Why unresolved: Only tests with Sentence-BERT embeddings, no exploration of alternative semantic encoders
- What evidence would resolve it: Comparative experiments using different embedding models while keeping other components constant

### Open Question 3
- Question: How would DiffUse's performance change when applied to non-English text generation tasks?
- Basis in paper: [inferred] States DiffUse "is inherently generic and does not assume anything about the models, tasks, unlabeled test data, prompts, or model hyper-parameters"
- Why unresolved: All experiments on English text generation tasks, cross-lingual performance unknown
- What evidence would resolve it: Experiments applying DiffUse to text generation tasks in different languages

### Open Question 4
- Question: Would incorporating uncertainty estimation into clustering process improve DiffUse's ability to identify informative examples?
- Basis in paper: [explicit] Mentions related work on "iterative method that utilizes a surrogate model to estimate the metrics of interest over the unlabeled test set, and labels examples that lead to maximal uncertainty reduction"
- Why unresolved: DiffUse doesn't incorporate uncertainty estimation, relies solely on clustering difference vectors
- What evidence would resolve it: Experiments comparing DiffUse with variants incorporating uncertainty estimation into clustering or selection process

## Limitations

- **Semantic Encoder Dependence**: Effectiveness heavily relies on quality of semantic encoder to capture meaningful differences between model outputs
- **Oracle Preference Correlation**: Assumption that larger semantic differences correlate with clearer preference judgments may not hold universally
- **Stopping Criterion Validity**: Hypergeometric-based stopping criterion lacks strong empirical validation for non-random selection processes
- **Generalizability**: Performance on tasks outside HELM benchmark or with different model architectures remains untested

## Confidence

- Mechanism 1 (Clustering for Informative Selection): Medium confidence
- Mechanism 2 (Iterative Selection with Hypergeometric Stopping): Low confidence
- Mechanism 3 (Bias Toward High-Norm Instances): Medium confidence

## Next Checks

1. **Cluster Quality Assessment**: Evaluate cluster quality using silhouette score or Davies-Bouldin index, comparing against random selection to quantify informativeness of selected examples
2. **Oracle Preference Study**: Conduct user study where human oracles rate model outputs selected by DiffUse versus random selection, analyzing alignment with human preferences
3. **Cross-Task Generalization**: Apply DiffUse to text generation task outside HELM benchmark (e.g., summarization or dialogue generation) and measure success rates compared to original results