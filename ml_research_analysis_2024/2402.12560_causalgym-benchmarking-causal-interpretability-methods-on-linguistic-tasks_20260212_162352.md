---
ver: rpa2
title: 'CausalGym: Benchmarking causal interpretability methods on linguistic tasks'
arxiv_id: '2402.12560'
source_url: https://arxiv.org/abs/2402.12560
tags:
- filler
- garden
- subj-relc
- obj-relc
- subord
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CausalGym, a benchmark for evaluating interpretability
  methods on linguistic tasks using causal interventions. The authors adapt the SyntaxGym
  evaluation suite into a templated format that enables generation of large numbers
  of span-aligned minimal pairs.
---

# CausalGym: Benchmarking causal interpretability methods on linguistic tasks

## Quick Facts
- arXiv ID: 2402.12560
- Source URL: https://arxiv.org/abs/2402.12560
- Reference count: 40
- Primary result: DAS achieves highest causal efficacy on linguistic tasks but also performs well on arbitrary mappings, suggesting expressivity contributes to its advantage

## Executive Summary
This paper introduces CausalGym, a benchmark for evaluating interpretability methods on linguistic tasks using causal interventions. The authors adapt the SyntaxGym evaluation suite into a templated format that enables generation of large numbers of span-aligned minimal pairs. They then benchmark seven feature-finding methods—including DAS, linear probing, difference-in-means, LDA, PCA, k-means, and random baselines—on pythia models (14M–6.9B parameters). Results show DAS achieves the highest causal efficacy (odds-ratios up to 14.09) and is most selective, but also performs well on arbitrary mapping control tasks, suggesting expressivity contributes to its advantage. To control for this, the authors adapt the selectivity metric from the probing literature. Using DAS, they analyze two challenging linguistic phenomena in pythia-1b: NPI licensing and filler–gap dependencies, finding that the causal mechanisms emerge in discrete stages rather than gradually during training.

## Method Summary
The authors create CausalGym by converting SyntaxGym tasks into templated minimal pairs with span-aligned inputs. They benchmark seven interpretability methods (DAS, linear probing, diff-in-means, LDA, PCA, k-means, random) on pythia models (14M-6.9B parameters). Methods are trained on 400 examples and evaluated using 1D DII interventions that apply learned feature directions. Causal efficacy is measured by log odds-ratio changes, and selectivity is computed by comparing performance on original tasks versus control tasks with arbitrary token mappings. The framework also analyzes training dynamics across pythia-1b checkpoints to study how causal mechanisms emerge.

## Key Results
- DAS achieves highest causal efficacy with odds-ratios up to 14.09 on original tasks
- DAS also performs well on arbitrary mapping control tasks, suggesting expressivity advantage
- Selectivity metric reduces DAS's advantage by controlling for arbitrary mapping performance
- Causal mechanisms for NPI licensing and filler–gap dependencies emerge in discrete stages during training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DAS finds causally effective features by optimizing directly for model behavior change
- Mechanism: DAS learns a linear direction in activation space that, when applied via 1D DII, maximizes the probability of the counterfactual label output. This is achieved by freezing model weights and optimizing DAS parameters using a cross-entropy loss between the intervened model's output and the target label.
- Core assumption: The linear representation hypothesis holds—that relevant linguistic features are encoded in linear subspaces of neural activations.
- Evidence anchors:
  - [abstract]: "We study the pythia models (14M–6.9B) and assess the causal efficacy of a wide range of interpretability methods, including linear probing and distributed alignment search (DAS). We find that DAS outperforms the other methods..."
  - [section 4.2]: "DAS. Given a training set T, we learn the intervention direction... that maximizes the output probability of the counterfactual label. Formally, we first randomly initialise adas and intervene on the model p with it to get pf ←f ∗adas. We freeze the model weights and optimise adas such that we minimise the cross-entropy loss with the target output ys"
  - [corpus]: Weak. Only mentions DAS in one paper, but it's about automating mechanistic interpretability with hypernetworks rather than the core optimization mechanism described here.

- Break condition: If the linear representation hypothesis fails or if the optimization process does not converge to a direction that actually affects model behavior.

### Mechanism 2
- Claim: The control task adaptation from probing literature effectively controls for DAS expressivity
- Mechanism: The authors adapt Hewitt and Liang's (2019) control task idea to causal evaluation. They create control tasks where the next-token labels are mapped to arbitrary tokens while preserving class partitioning. Selectivity is computed as the difference between odds-ratios on the original task and the control task.
- Core assumption: A method that performs well on arbitrary input-output mappings is exploiting its expressivity rather than finding genuine causal mechanisms.
- Evidence anchors:
  - [abstract]: "To address this, we adapt the notion of control tasks from the probing literature (Hewitt and Liang, 2019), finding that adjusting for performance on the arbitrary mapping task reduces the gap between DAS and other methods."
  - [section 5.2]: "We adapt this notion to CausalGym, introducing control tasks where the next-token labels yb, ys are mapped to the arbitrary tokens ‘_dog’ and ‘_give’ while preserving the class partitioning... We define selectivity for each method by taking the difference between odds-ratios on the original task and the control task for each f"
  - [corpus]: Weak. The corpus only mentions one related paper about control tasks, but it's about differentiable autoaugmentation rather than the specific control task adaptation described here.

- Break condition: If the control task design does not adequately capture the notion of arbitrary input-output mappings, or if the selectivity metric does not properly isolate genuine causal mechanisms from expressivity.

### Mechanism 3
- Claim: Causal mechanisms for linguistic tasks emerge in discrete stages rather than gradually
- Mechanism: The authors analyze training dynamics by running the same causal experiments on checkpoints of pythia-1b at different training steps. They observe that causal effects first emerge at certain positions, then abruptly appear at intermediate positions, and finally stabilize.
- Core assumption: The emergence pattern of causal mechanisms reflects how the model learns to implement linguistic behaviors.
- Evidence anchors:
  - [abstract]: "Our analysis shows that the mechanism implementing both of these tasks is learned in discrete stages, not gradually."
  - [section 6.1]: "To study how the mechanisms emerge over the course of training, we run the exact same experiments on earlier checkpoints of pythia-1b... For both tasks, the model initially learns to move information directly from the alternating token to the output position. Later in training, intermediate steps are added in the middle layers."
  - [corpus]: Weak. The corpus only mentions one related paper about sparse autoencoders for factual knowledge, not about training dynamics of causal mechanisms.

- Break condition: If the observed discrete stages are an artifact of the specific tasks or models studied, or if the causal experiments do not accurately capture the emergence of linguistic mechanisms.

## Foundational Learning

- Concept: Linear representation hypothesis
  - Why needed here: The entire benchmarking approach relies on the assumption that linguistic features are encoded in linear subspaces of neural activations, which is necessary for methods like DAS and linear probing to work.
  - Quick check question: Why do we expect that a linear direction in activation space can control model behavior for binary linguistic features?

- Concept: Causal abstraction framework
  - Why needed here: The paper uses causal abstraction to formalize how interventions on model components can establish causal relationships between representations and behaviors.
  - Quick check question: How does the do-operator from causal inference translate to the intervention framework used in this paper?

- Concept: Interchange intervention
  - Why needed here: The paper uses interchange intervention as the mechanism for applying causal interventions, specifically 1D DII for linear subspaces.
  - Quick check question: What is the difference between vanilla interchange intervention and 1D DII, and why is 1D DII sufficient for binary features?

## Architecture Onboarding

- Component map: pythia models (14M-6.9B) -> templated SyntaxGym tasks -> feature-finding methods (DAS, linear probing, diff-in-means, LDA, PCA, k-means, random) -> 1D DII interventions -> odds-ratio evaluation -> selectivity metric -> training dynamics analysis

- Critical path: Generate templated minimal pairs → train feature-finding methods on base inputs → apply 1D DII interventions → measure odds-ratio change → compute overall and selectivity metrics → analyze results

- Design tradeoffs: The paper uses 1D DII for simplicity and because it's sufficient for binary features, but this limits the ability to study multi-dimensional features. The control task adaptation is a novel contribution but may not perfectly capture the notion of arbitrary mappings.

- Failure signatures: If feature-finding methods don't achieve significant odds-ratios, if selectivity metrics don't reduce DAS's advantage, or if training dynamics analysis doesn't show discrete stages.

- First 3 experiments:
  1. Run the full benchmarking pipeline on a small pythia model (14M) to verify the basic setup works.
  2. Compare DAS performance on a single task with and without the control task adaptation to verify the selectivity metric works.
  3. Run the training dynamics analysis on a single task and checkpoint to verify the discrete stages observation can be reproduced.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the causal efficacy of interpretability methods vary across different model architectures beyond the pythia series?
- Basis in paper: [explicit] The authors note that results may differ on other models, as pythia models were trained on the same data in a fixed order.
- Why unresolved: The study only examines the pythia model series, leaving uncertainty about generalizability to other architectures or training regimes.
- What evidence would resolve it: Benchmarking the same interpretability methods on diverse model families (e.g., GPT, BERT, T5) trained on different datasets.

### Open Question 2
- Question: Can non-linear interpretability methods outperform linear methods like DAS on linguistic tasks in CausalGym?
- Basis in paper: [explicit] The authors only benchmark methods operating on one-dimensional linear subspaces, leaving multi-dimensional linear and non-linear methods untested.
- Why unresolved: The study's focus on linear methods prevents comparison with potentially more expressive non-linear approaches.
- What evidence would resolve it: Implementing and benchmarking non-linear methods (e.g., neural probes, activation maximization) on the same tasks.

### Open Question 3
- Question: What is the relationship between probe selectivity and the model's actual use of linguistic features during inference?
- Basis in paper: [explicit] The authors adapt Hewitt and Liang's selectivity metric but note that high probe accuracy doesn't guarantee the model uses those features downstream.
- Why unresolved: The study measures selectivity but doesn't directly test whether high-selectivity probes correspond to features the model actively uses.
- What evidence would resolve it: Correlating probe selectivity scores with ablation studies showing feature importance for task performance.

## Limitations

- The templated minimal pairs from SyntaxGym may not fully capture natural language complexity
- Control task adaptation uses arbitrary token mappings that may not perfectly isolate genuine causal mechanisms
- Analysis focuses on binary linguistic features, limiting generalizability to more complex phenomena

## Confidence

- **High confidence**: The causal intervention framework implementation and odds-ratio metric are sound and well-established.
- **Medium confidence**: DAS outperforming other methods on the original task is robust, but the interpretation that this is primarily due to expressivity (rather than superior feature-finding) after applying selectivity controls is less certain.
- **Medium confidence**: The discrete-stage emergence pattern observed in training dynamics is supported by evidence but requires validation across more tasks and models.

## Next Checks

1. **Control task robustness**: Test the control task design with multiple arbitrary token mappings and verify that selectivity consistently reduces DAS's advantage across different task types.
2. **Generalization to non-binary features**: Extend the benchmarking framework to multi-dimensional features and verify whether the observed patterns hold when using full-dimensional interventions rather than 1D DII.
3. **Alternative causality metrics**: Compare odds-ratio with alternative causality measures (e.g., Shapley values or conditional independence tests) to verify that the observed effects are not artifacts of the specific metric used.