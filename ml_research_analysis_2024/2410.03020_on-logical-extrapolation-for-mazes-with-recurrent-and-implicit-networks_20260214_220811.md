---
ver: rpa2
title: On Logical Extrapolation for Mazes with Recurrent and Implicit Networks
arxiv_id: '2410.03020'
source_url: https://arxiv.org/abs/2410.03020
tags:
- maze
- mazes
- start
- size
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates logical extrapolation in recurrent and\
  \ implicit neural networks using maze-solving as a testbed. The authors examine\
  \ two models\u2014DT-Net (RNN) and PI-Net (INN)\u2014and their ability to generalize\
  \ to larger mazes and other distribution shifts beyond just maze size."
---

# On Logical Extrapolation for Mazes with Recurrent and Implicit Networks

## Quick Facts
- arXiv ID: 2410.03020
- Source URL: https://arxiv.org/abs/2410.03020
- Reference count: 29
- Primary result: Both DT-Net and PI-Net generalize well to larger mazes only when start positions are deadends and mazes are acyclic; performance drops significantly with distribution shifts.

## Executive Summary
This paper investigates logical extrapolation in recurrent and implicit neural networks using maze-solving as a testbed. The authors examine two models—DT-Net (RNN) and PI-Net (INN)—and their ability to generalize to larger mazes and other distribution shifts beyond just maze size. The key findings show that both models can extrapolate well to larger mazes when the start position is at a deadend and there are no cycles, but their performance drops significantly when the start position can have multiple neighbors or when the maze contains loops. This reveals that logical extrapolation is less robust than previously thought and depends on the specific axis of difficulty being tested. Additionally, the authors use topological data analysis to study the latent dynamics of these models, finding that while PI-Net consistently converges to fixed points, DT-Net exhibits more complex behaviors like two-point cycles and two-loop cycles in its latent space.

## Method Summary
The paper tests two neural network architectures on maze-solving tasks: DT-Net (a weight-tied RNN with progressive loss) and PI-Net (an implicit neural network with path-independence regularization). Models are trained on 9×9 mazes and tested on larger mazes (up to 99×99) as well as distribution shifts including non-deadend start positions and percolated mazes with loops. The authors use topological data analysis with a PyTorch wrapper for Ripser to study latent dynamics during inference, measuring accuracy as the percentage of correctly solved mazes and analyzing convergence behavior through persistent homology.

## Key Results
- Both models achieve perfect accuracy on larger mazes when start positions are deadends and mazes are acyclic
- Accuracy drops significantly when start position has multiple neighbors (from 1.00 to 0.72 for DT-Net, 1.00 to 0.94 for PI-Net)
- PI-Net consistently converges to fixed points while DT-Net exhibits two-point and two-loop cycles in latent space
- Models completely fail on percolated mazes with loops (p > 0), indicating learned deadend-filling algorithm limitations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Models generalize well to larger mazes when start positions are deadends and mazes are acyclic
- Mechanism: The learned iterative algorithm can reliably fill deadends and propagate solutions through acyclic graphs without ambiguity
- Core assumption: Deadend-filling algorithm scales with maze size and works correctly on acyclic structures
- Evidence anchors:
  - [abstract] "both models can extrapolate well to larger mazes when the start position is at a deadend and there are no cycles"
  - [section] "With this shift, accuracy on 9 × 9 mazes drops from 1.00 to 0.72 for DT-Net and from 1.00 to 0.94 for PI-Net"
  - [corpus] Weak evidence - corpus doesn't directly address deadend-filling mechanism
- Break condition: When start position has multiple neighbors or mazes contain loops, the algorithm encounters ambiguity and fails

### Mechanism 2
- Claim: PI-Net consistently converges to fixed points while DT-Net exhibits limit cycles
- Mechanism: PI-Net's path-independence property (contractivity) ensures unique fixed-point convergence, while DT-Net's lack of explicit path-independence constraints allows more complex limiting behaviors
- Core assumption: The training objective and architecture differences lead to fundamentally different convergence behaviors
- Evidence anchors:
  - [abstract] "while PI-Net consistently converges to fixed points, DT-Net exhibits more complex behaviors like two-point cycles and two-loop cycles"
  - [section] "We find that, while the INN we consider (Anil et al., 2022) consistently converges to a fixed point, regardless of maze size, the RNN we consider (Bansal et al., 2022) exhibits more complex limiting behaviour"
  - [corpus] Weak evidence - corpus doesn't directly address convergence behavior differences
- Break condition: When models encounter distribution shifts that require different solution strategies, convergence behavior may change unpredictably

### Mechanism 3
- Claim: Topological Data Analysis reveals hidden dynamical patterns in latent space
- Mechanism: Persistent homology can detect and classify limiting behaviors (fixed points, two-point cycles, two-loop cycles) that aren't visible through residual analysis alone
- Core assumption: The topology of latent iterates encodes meaningful information about model behavior
- Evidence anchors:
  - [abstract] "We use topological data analysis to study the latent dynamics of these models"
  - [section] "We quantify this phenomenon using tools from Topological Data Analysis (TDA)...we find that, while the INN we consider (Anil et al., 2022) consistently converges to a fixed point, the RNN we consider (Bansal et al., 2022) exhibits more complex limiting behaviour"
  - [corpus] Weak evidence - corpus doesn't discuss TDA application to neural networks
- Break condition: If latent space dimensionality or iterate patterns change significantly, TDA signatures may become less reliable

## Foundational Learning

- Concept: Topological Data Analysis and persistent homology
  - Why needed here: To quantify and classify complex limiting behaviors in high-dimensional latent spaces that aren't visible through simple residual analysis
  - Quick check question: What Betti numbers would you expect for a sequence oscillating between two well-separated points?

- Concept: Implicit Neural Networks and fixed-point iteration
  - Why needed here: Understanding how INNs solve problems through implicit conditions rather than explicit layer cascades is crucial for interpreting their extrapolation behavior
  - Quick check question: How does an INN's output differ fundamentally from a traditional RNN's output?

- Concept: Maze generation and percolation theory
  - Why needed here: Understanding how different maze parameters (size, start position constraints, percolation) affect problem difficulty and solution uniqueness
  - Quick check question: What happens to the uniqueness of maze solutions when percolation parameter p > 0?

## Architecture Onboarding

- Component map:
  Input: RGB maze images (9×9 to 99×99) -> DT-Net/PI-Net -> Output: Black and white solution path images -> TDA analysis

- Critical path:
  1. Load maze dataset with specified parameters
  2. Run model inference for specified iterations
  3. Store latent iterates for TDA analysis
  4. Compute persistent homology to classify limiting behavior
  5. Evaluate solution accuracy against ground truth

- Design tradeoffs:
  - DT-Net: Simpler architecture but exhibits more complex limiting behaviors; requires careful iteration count tuning
  - PI-Net: More stable convergence but higher memory costs due to Broyden's method Jacobian approximation
  - TDA: Provides deep insights but computationally expensive; requires dimensionality reduction for practical use

- Failure signatures:
  - Accuracy drops when start position has multiple neighbors (regardless of maze size)
  - Complete failure on percolated mazes (p > 0) due to non-unique solutions
  - DT-Net: Residuals converging to non-zero values indicating two-point or two-loop cycles
  - PI-Net: Always converges to fixed points but may miss optimal solutions

- First 3 experiments:
  1. Verify baseline extrapolation: Test both models on increasing maze sizes (9×9 to 99×99) with deadend start=True and p=0
  2. Test distribution shift sensitivity: Compare accuracy when toggling deadend start=False while keeping other parameters constant
  3. Analyze latent dynamics: Use TDA to classify limiting behaviors for both models across different maze sizes and configurations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the failure of DT-Net and PI-Net on mazes with non-deadend start positions indicate they have learned a specific algorithm (like deadend-filling) rather than a general maze-solving approach?
- Basis in paper: [explicit] The authors note that both models fail when start positions have multiple neighbors, and observe that DT-Net's behavior is "similar to that of the dead-end-filling algorithm" when encountering loops.
- Why unresolved: The paper shows correlation between failure modes and deadend-filling behavior but doesn't prove this is the learned algorithm versus a coincidental failure pattern.
- What evidence would resolve it: Testing the models on modified deadend-filling tasks, comparing latent dynamics during deadend-filling versus general maze solving, or training models to explicitly perform deadend-filling and comparing performance patterns.

### Open Question 2
- Question: Would explicitly training for path independence (convergence to fixed points) improve generalization across all axes of difficulty, not just maze size?
- Basis in paper: [explicit] The authors observe that PI-Net (trained for path independence) consistently converges to fixed points while DT-Net exhibits more complex behaviors like limit cycles, yet both generalize well to larger mazes.
- Why unresolved: The paper shows that path independence correlates with fixed-point convergence but doesn't test whether it improves generalization to other distribution shifts like non-deadend starts or percolated mazes.
- What evidence would resolve it: Training variants of DT-Net with explicit path independence constraints and testing their performance on all distribution shifts, or conducting an ablation study on the path independence training components.

### Open Question 3
- Question: How does the topological structure of latent dynamics change when models encounter out-of-distribution examples, and can this be used for OOD detection?
- Basis in paper: [inferred] The authors develop TDA tools to analyze latent dynamics and note their potential for studying how distribution shifts affect these dynamics, but don't actually perform this analysis.
- Why unresolved: The paper applies TDA to analyze in-distribution and extrapolation behavior but doesn't compare latent topology between in-distribution and OOD examples.
- What evidence would resolve it: Computing and comparing persistent Betti numbers for latent iterates from in-distribution versus OOD examples, testing whether topological features can distinguish OOD examples from in-distribution ones with high accuracy.

## Limitations
- Findings limited to maze-solving tasks; unclear if results generalize to other logical reasoning domains
- Only two specific model architectures tested (DT-Net and PI-Net)
- Topological analysis may not capture all relevant dynamical behaviors in higher-dimensional latent spaces

## Confidence
- High confidence: Models fail on mazes with non-deadend start positions and loops (percolation > 0)
- Medium confidence: PI-Net consistently converges to fixed points while DT-Net exhibits limit cycles
- Medium confidence: Deadend-filling algorithm explains extrapolation success on acyclic mazes

## Next Checks
1. Test both models on other logical reasoning tasks (e.g., Sudoku, graph coloring) to verify whether the identified failure modes generalize beyond maze-solving
2. Implement ablation studies varying latent dimension sizes to determine how dimensionality affects topological signatures and extrapolation performance
3. Compare the extrapolation behavior of DT-Net and PI-Net with standard LSTM/GRU architectures on the same maze distribution shifts