---
ver: rpa2
title: Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective
arxiv_id: '2405.16747'
source_url: https://arxiv.org/abs/2405.16747
tags:
- lp-ft
- lora
- training
- classifier
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the training dynamics of linear probing then
  fine-tuning (LP-FT) for classification tasks using neural tangent kernel (NTK) theory.
  The authors decompose the NTK matrix into pre-train-effective and FT-effective components,
  revealing that both accurate predictions and increased linear head norms after LP
  reduce feature changes during fine-tuning.
---

# Understanding Linear Probing then Fine-tuning Language Models from NTK Perspective

## Quick Facts
- arXiv ID: 2405.16747
- Source URL: https://arxiv.org/abs/2405.16747
- Reference count: 40
- Key outcome: LP-FT preserves pre-trained features while achieving high performance through increased linear head norms that reduce feature changes during fine-tuning

## Executive Summary
This paper analyzes the training dynamics of linear probing then fine-tuning (LP-FT) for classification tasks using neural tangent kernel (NTK) theory. The authors decompose the NTK matrix into pre-train-effective and FT-effective components, revealing that both accurate predictions and increased linear head norms after LP reduce feature changes during fine-tuning. They observe a significant increase in linear head norms during LP due to cross-entropy loss, which helps preserve pre-trained features but can negatively impact model calibration. The authors show this calibration issue can be corrected with temperature scaling and extend their NTK analysis to the low-rank adaptation (LoRA) method, providing theoretical validation of its effectiveness.

## Method Summary
The paper analyzes LP-FT training dynamics using NTK theory on a Transformer-based model (RoBERTa-base) across multiple NLP datasets. The method involves pre-training a feature extractor, performing linear probing to optimize only the classifier head, computing NTK matrices decomposed into pre-train-effective and FT-effective components, and then fine-tuning or applying LoRA. Temperature scaling is used for calibration correction. The NTK computation uses matrix-free trace estimation with forward-mode differentiation. Experiments compare feature changes, accuracy, and calibration metrics (ECE, MCE) between LP-FT and standard FT methods.

## Key Results
- Increased linear head norms during LP reduce feature changes during FT by making the FT-effective NTK component more dominant
- LP-FT achieves better feature preservation (higher cosine similarity, Fisher's discriminant ratio) compared to standard FT
- Temperature scaling effectively corrects calibration degradation caused by increased classifier weight norms during LP
- LoRA training approximates standard FT in the NTK regime with a scalar factor difference dependent on hyperparameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Increased linear head norms during LP reduce feature changes during FT
- Mechanism: Cross-entropy loss during LP causes classifier weight norms to grow significantly. These larger norms make the FT-effective NTK component more dominant relative to the pre-train-effective component, reducing feature update magnitude during fine-tuning.
- Core assumption: NTK regime accurately captures training dynamics where first-order Taylor expansion around initial parameters approximates actual training behavior
- Evidence anchors:
  - [abstract]: "We observe a significant increase in the linear head norm during LP, which stems from training with the cross-entropy (CE) loss. This increase in the linear head norm effectively reduces changes in learned features."
  - [section 4.2]: "This indicates that the classifier weight norm ∥V0∥F has a significant impact on the training dynamics of FT."
- Break condition: When operating outside NTK regime (linearized approximation breaks down) or when pre-trained features are poorly aligned with target task

### Mechanism 2
- Claim: Both accurate predictions and increased linear head norms after LP contribute to minimizing feature changes
- Mechanism: NTK decomposition shows feature updates depend on δi (difference between predicted probability and one-hot label) and classifier weight norm. After LP, both δi is smaller due to better predictions and ∥V0∥F is larger, both contributing to smaller feature changes during FT.
- Core assumption: NTK decomposition accurately captures distinct contributions to feature changes
- Evidence anchors:
  - [abstract]: "Our analysis decomposes the NTK matrix into two components. This decomposition highlights the importance of the linear head norm alongside the prediction accuracy at the start of the FT stage."
  - [section 4.2]: "The magnitude of changes in both features and logits... is proportional to δi, the difference between the predicted probability and the one-hot label."
- Break condition: When learning rate is too high or feature extractor has changed significantly during LP

### Mechanism 3
- Claim: LoRA approximates standard FT in NTK regime with scalar factor difference
- Mechanism: NTK matrix of LoRA and standard FT differ only by scalar factor in FT-effective component, with scalar depending on LoRA hyperparameters (rank r and initialization variance σ²).
- Core assumption: Linear model setting approximates behavior of complex Transformer models in NTK regime
- Evidence anchors:
  - [abstract]: "We extend our analysis with the NTK to the low-rank adaptation (LoRA) method and validate its effectiveness."
  - [section 4.5]: "This proposition suggests that with high probability, the only difference of the NTK matrix between LoRA and standard FT is a scalar factor of the FT-effective component in the NTK matrix"
- Break condition: When rank r is too small or variance σ² is too different from weight matrix scale

## Foundational Learning

- Concept: Neural Tangent Kernel (NTK)
  - Why needed here: NTK provides theoretical framework for analyzing how neural network parameters evolve during training, particularly for understanding feature changes during fine-tuning
  - Quick check question: In the NTK regime, what remains constant during training and governs the evolution of network outputs?

- Concept: Feature distortion theory
  - Why needed here: This theory explains why LP-FT preserves pre-trained features by starting FT with near-optimal linear head, which is validated and extended using NTK analysis
  - Quick check question: According to feature distortion theory, what is the main advantage of starting FT with parameters obtained from LP?

- Concept: Empirical NTK
  - Why needed here: Empirical NTK uses actual pre-trained parameters instead of random initialization, making it suitable for analyzing fine-tuning dynamics rather than just training from scratch
  - Quick check question: How does empirical NTK differ from theoretical infinite-width NTK in terms of parameter initialization?

## Architecture Onboarding

- Component map: Pre-trained model (RoBERTa-base) → Feature extractor (ϕ) → Linear head (V, b) → NTK computation → Temperature scaling → LoRA adapter
- Critical path: 1. Pre-train feature extractor 2. Linear probing (LP) to optimize classifier only 3. Compute NTK matrices (empirical, pre-train-effective, FT-effective components) 4. Fine-tuning (FT) or LoRA fine-tuning 5. Temperature scaling for calibration 6. Evaluate on ID and OOD datasets
- Design tradeoffs:
  - LP-FT vs FT: LP-FT preserves features better but may have calibration issues; FT is simpler but more prone to feature distortion
  - LoRA vs full FT: LoRA is parameter-efficient but may approximate rather than exactly match full FT behavior
  - Temperature scaling: Improves calibration but requires validation set for tuning
- Failure signatures:
  - Poor OOD performance: Indicates feature distortion despite LP
  - Calibration degradation: Suggests classifier weight norms grew too large during LP
  - NTK computation failure: Likely due to insufficient memory or incorrect parameter selection
  - LoRA instability: May occur with inappropriate rank or initialization variance
- First 3 experiments:
  1. Compare feature changes (cosine similarity, difference norms) between FT and LP-FT on a small dataset
  2. Test temperature scaling impact on calibration metrics (ECE, MCE) for LP-FT
  3. Verify LoRA NTK approximation by comparing FT-effective components between LoRA and standard FT

## Open Questions the Paper Calls Out

- Question: How does the increased linear head norm during LP affect model calibration across different types of downstream tasks (e.g., classification vs. regression)?
  - Basis in paper: [explicit] The paper observes that increased linear head norms can negatively affect model calibration and this can be corrected with temperature scaling.
  - Why unresolved: The study primarily focuses on classification tasks and does not explore how these effects manifest in regression tasks or other non-classification problems.
  - What evidence would resolve it: Empirical studies comparing calibration performance (e.g., ECE, MCE) across various task types when using LP-FT, with and without temperature scaling.

- Question: What is the optimal balance between linear head norm increase and feature preservation for maximizing both accuracy and calibration in LP-FT?
  - Basis in paper: [inferred] The paper suggests that increased linear head norms reduce feature changes but may harm calibration, implying a potential trade-off.
  - Why unresolved: The analysis shows effects in isolation but doesn't provide guidance on finding an optimal trade-off between competing objectives.
  - What evidence would resolve it: Systematic experiments varying LP duration and learning rates to identify Pareto-optimal points balancing accuracy and calibration metrics.

- Question: How do the NTK decomposition insights apply to more complex fine-tuning scenarios like continual learning or multi-task learning?
  - Basis in paper: [inferred] The NTK decomposition reveals insights about pre-train-effective and FT-effective components, but the analysis is limited to standard LP-FT scenarios.
  - Why unresolved: The theoretical framework could potentially extend to more complex scenarios, but the paper doesn't explore these extensions.
  - What evidence would resolve it: Empirical studies applying the NTK decomposition analysis to continual learning and multi-task learning scenarios, comparing feature changes and calibration effects.

## Limitations

- The NTK-based analysis relies on linearized regime approximation, which may break down for large learning rates or significant feature extractor changes during LP
- Empirical NTK computation using actual pre-trained parameters introduces approximation errors compared to theoretical infinite-width NTK
- LoRA analysis is based on simplified linear model setting rather than full Transformer architectures
- Temperature scaling calibration requires additional validation data and may not fully recover original pre-LP calibration quality

## Confidence

**High confidence**: The observation that classifier weight norms increase during LP and that this affects feature changes during FT is directly measurable and experimentally verified across multiple datasets.

**Medium confidence**: The NTK-based theoretical explanation for why increased linear head norms reduce feature changes during FT, while mathematically sound, relies on validity of NTK regime assumption.

**Low confidence**: The claim that specific decomposition of NTK into pre-train-effective and FT-effective components provides complete insight into training dynamics, as this may oversimplify complex interactions in real Transformer models.

## Next Checks

1. Validate NTK regime assumption by comparing actual training trajectories with NTK predictions on subset of parameters, varying learning rates to identify where approximation breaks down

2. Test calibration recovery limits by systematically varying magnitude of classifier weight norm growth during LP and measuring how much temperature scaling can recover original calibration quality

3. Extend LoRA analysis to full Transformers by implementing NTK analysis for LoRA in full Transformer architectures (not just simplified linear model) and verifying whether scalar factor approximation holds across different attention heads and layer types