---
ver: rpa2
title: Explainable AI for Comparative Analysis of Intrusion Detection Models
arxiv_id: '2406.09684'
source_url: https://arxiv.org/abs/2406.09684
tags:
- detection
- features
- intrusion
- learning
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper uses Occlusion Sensitivity to analyze how various machine
  learning models for network intrusion detection rely on different features in the
  UNSW-NB15 dataset. Most classifiers, including neural networks, depend heavily on
  only 1-2 critical features for achieving 90% accuracy, suggesting that effective
  feature engineering may be more important than model complexity.
---

# Explainable AI for Comparative Analysis of Intrusion Detection Models

## Quick Facts
- arXiv ID: 2406.09684
- Source URL: https://arxiv.org/abs/2406.09684
- Reference count: 21
- Most classifiers achieve 90% accuracy using only 1-2 critical features

## Executive Summary
This paper presents a comparative analysis of machine learning models for network intrusion detection using Occlusion Sensitivity to examine feature importance and model robustness. The study evaluates seven machine learning models on the UNSW-NB15 dataset, finding that most models rely heavily on only 1-2 critical features for achieving 90% accuracy. Random Forest emerges as the most robust and time-efficient model, treating all features more equally and maintaining performance when top features are masked. The research highlights that most models depend heavily on time-dependent features like TTL values, which could limit their generalizability across different network environments.

## Method Summary
The study trains seven machine learning models (Linear Regression, Logistic Regression, SVM, KNN, Random Forest, Decision Tree, and MLP) on the UNSW-NB15 dataset, aiming for 90% accuracy on binary and multi-class classification tasks. Feature selection is performed using correlation thresholds (>0.3), and data is preprocessed through cleaning, encoding, and scaling. Occlusion Sensitivity is then applied to systematically mask features and measure accuracy degradation, revealing feature importance rankings. Models are compared based on accuracy, time efficiency, and robustness to feature masking, with particular attention to their reliance on time-dependent features like TTL values.

## Key Results
- Most classifiers (including neural networks) achieve 90% accuracy using only 1-2 critical features
- Random Forest is the most robust model, maintaining performance when top features are masked and being the most time-efficient
- Models show high dependence on time-dependent features (like TTL values), suggesting potential generalizability limitations across different network environments

## Why This Works (Mechanism)

### Mechanism 1
Occlusion Sensitivity reveals feature importance by measuring accuracy degradation when specific features are masked. The method systematically occludes individual features or groups of features from input data, then measures how much the model's classification accuracy drops. Features whose occlusion causes the greatest accuracy loss are deemed most critical for the model's decision-making.

### Mechanism 2
Random Forest's robustness comes from its ensemble nature and equal treatment of features. Random Forest builds multiple decision trees using random subsets of features and data points. This averaging process reduces the impact of any single feature, making the model less sensitive to the removal of top features compared to single-model approaches like Decision Trees or Neural Networks.

### Mechanism 3
High dependence on time-dependent features (like TTL) indicates models may not generalize across different network environments. The Occlusion Sensitivity analysis reveals that models lose significant accuracy when time-dependent features are masked, suggesting these features are critical for current decision-making. This dependency means models are tuned to specific temporal patterns that may not exist in other network environments.

## Foundational Learning

- Concept: Occlusion Sensitivity method
  - Why needed here: This is the core technique used to analyze feature importance and model behavior. Understanding how it works is essential for interpreting the study's findings about feature dependence and model robustness.
  - Quick check question: How does Occlusion Sensitivity differ from other XAI methods like SHAP or LIME in terms of what it reveals about model behavior?

- Concept: Random Forest ensemble learning
  - Why needed here: The study identifies Random Forest as the most robust model, and understanding its ensemble nature is key to grasping why it treats features more equally than other models.
  - Quick check question: What specific mechanism in Random Forest's construction (bagging, feature randomness, averaging) contributes most to its robustness against feature removal?

- Concept: Feature correlation and selection
  - Why needed here: The study performs feature selection based on correlation thresholds, which affects which features models can use and how Occlusion Sensitivity results are interpreted.
  - Quick check question: How might the 0.3 correlation threshold for feature selection impact the Occlusion Sensitivity analysis and the models' apparent feature dependence?

## Architecture Onboarding

- Component map: Data preprocessing pipeline (cleaning, encoding, scaling, feature selection) -> ML model implementations (Linear Regression, Logistic Regression, SVM, KNN, Random Forest, Decision Tree, MLP) -> Occlusion Sensitivity analysis module -> Evaluation framework (accuracy, time, robustness)
- Critical path: Data preprocessing → Model training (with 90% accuracy target) → Occlusion Sensitivity feature importance analysis → Performance comparison (accuracy, time, robustness) → Feature masking experiments to test robustness
- Design tradeoffs: The study prioritizes interpretability and feature analysis over maximizing accuracy, using Occlusion Sensitivity which is computationally intensive but provides clear visual explanations. The 90% accuracy stopping criterion balances training time with model quality.
- Failure signatures: If models show inconsistent behavior across binary and multi-class tasks, if Occlusion Sensitivity results don't align with accuracy metrics, or if time-dependent feature reliance is inconsistent with domain knowledge about network traffic patterns.
- First 3 experiments:
  1. Run Occlusion Sensitivity on a simple model (e.g., Decision Tree) to verify it correctly identifies the most important features based on accuracy degradation.
  2. Compare Random Forest and Decision Tree behavior when masking the top-2 features to confirm the robustness difference described in the paper.
  3. Test model performance on a different network dataset (if available) to verify the time-dependent feature generalization concern.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the models perform when evaluated on a dataset with different TTL distributions than UNSW-NB15, particularly when the time-dependent features (sttl, dttl) are significantly altered?
- Basis in paper: The paper explicitly states that classifiers rely heavily on time-dependent features like TTL values and may face challenges when ported to different application scenarios.
- Why unresolved: The study only analyzed the UNSW-NB15 dataset and did not test the models on datasets with different network environments or TTL distributions to verify the generalizability of the findings.
- What evidence would resolve it: Testing the same models on multiple network intrusion detection datasets with varying TTL distributions and comparing their performance degradation would provide concrete evidence of their generalizability limitations.

### Open Question 2
- Question: What is the relationship between model complexity and feature dependency when feature selection is not applied, and how does this compare to when feature selection is performed?
- Basis in paper: The paper found that most models exploit only 1-2 critical features regardless of whether feature selection is applied, but did not deeply analyze the relationship between model complexity and feature dependency.
- Why unresolved: While the study compared feature sensitivity with and without feature selection, it did not explicitly analyze how model complexity (e.g., number of layers in MLP, depth of trees) affects the number of features used for decision-making.
- What evidence would resolve it: Conducting experiments with varying model complexities (e.g., different MLP architectures, deeper/shallower trees) and measuring feature dependency in both feature selection and non-selection scenarios would clarify this relationship.

### Open Question 3
- Question: How does the performance of Random Forest compare to more complex models like deep neural networks when trained on datasets with a higher proportion of less important features?
- Basis in paper: The paper found that Random Forest treats all features more equally and maintains robustness when top features are masked, suggesting it might perform better than complex models when critical features are less dominant.
- Why unresolved: The study focused on the UNSW-NB15 dataset and did not test scenarios where less important features might be more significant, nor did it compare Random Forest to more complex deep learning architectures beyond MLP.
- What evidence would resolve it: Training and evaluating Random Forest and deep neural networks on synthetic or real datasets where feature importance is more evenly distributed would reveal whether Random Forest maintains its advantage over complex models.

## Limitations

- The study relies on a single Occlusion Sensitivity method without comparison to other XAI techniques, limiting generalizability of findings about feature importance.
- Analysis is based solely on the UNSW-NB15 dataset, which contains synthetic attacks and may not fully represent real-world network traffic patterns.
- The comparison uses default scikit-learn configurations without hyperparameter tuning, which may not reflect optimized model performance.

## Confidence

- **High Confidence**: The finding that most models achieve 90% accuracy with only 1-2 critical features is well-supported by the occlusion sensitivity analysis and accuracy metrics presented.
- **Medium Confidence**: The claim about time-dependent feature dependence limiting generalizability requires external validation, as the study doesn't test models on different network environments or datasets.
- **Low Confidence**: The specific threshold values (0.3 correlation for feature selection, 90% accuracy stopping criterion) are somewhat arbitrary and may not generalize to other datasets or problem domains.

## Next Checks

1. **Cross-Dataset Validation**: Test the trained models on a different network intrusion detection dataset (e.g., CICIDS2017) to verify whether the time-dependent feature dependence is dataset-specific or a universal characteristic.

2. **XAI Method Comparison**: Implement SHAP or LIME alongside Occlusion Sensitivity to determine if the identified critical features are consistent across different XAI methods, validating the robustness of the feature importance rankings.

3. **Hyperparameter Sensitivity Analysis**: Conduct experiments with tuned hyperparameters for Random Forest and other models to determine if the observed robustness and performance advantages persist when models are optimized beyond default configurations.