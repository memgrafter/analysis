---
ver: rpa2
title: 'Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness'
arxiv_id: '2408.05446'
source_url: https://arxiv.org/abs/2408.05446
tags:
- adversarial
- image
- robustness
- attacks
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for improving adversarial robustness
  in image classifiers by leveraging multi-resolution inputs and dynamic self-ensembling
  of intermediate layer predictions. The authors propose CrossMax, a robust aggregation
  mechanism based on Vickrey auction, to dynamically ensemble predictions from multiple
  classifiers, checkpoints, and intermediate layers.
---

# Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness

## Quick Facts
- arXiv ID: 2408.05446
- Source URL: https://arxiv.org/abs/2408.05446
- Reference count: 27
- Primary result: ~72% adversarial accuracy on CIFAR-10 without adversarial training

## Executive Summary
This paper introduces a novel approach to improving adversarial robustness in image classifiers by leveraging multi-resolution inputs and dynamic self-ensembling of intermediate layer predictions. The authors propose CrossMax, a robust aggregation mechanism based on Vickrey auction principles, to dynamically ensemble predictions from multiple classifiers, checkpoints, and intermediate layers. By combining multi-resolution inputs and robust ensembling, they achieve significant adversarial robustness on CIFAR-10 and CIFAR-100 datasets without any adversarial training or extra data.

## Method Summary
The approach combines multi-resolution inputs with dynamic self-ensembling. Images are transformed into 3N-channel inputs by stacking downsampled versions (e.g., 32×32, 16×16, 8×8, 4×4) with random jitter, noise, and color shifts. A standard ResNet backbone is finetuned on these inputs. Intermediate heads (linear probes) are trained on activations from each layer. CrossMax aggregation, based on Vickrey auction principles, combines predictions from these intermediate heads and potentially other models. This creates a robust ensemble that can detect and correct adversarial perturbations affecting only the final layer.

## Key Results
- Achieves ~72% adversarial accuracy on CIFAR-10 without adversarial training
- Reaches ~48% adversarial accuracy on CIFAR-100 without adversarial training
- Adding simple adversarial training improves results to ~78% (CIFAR-10) and ~51% (CIFAR-100)
- Surpasses previous state-of-the-art non-adversarially trained models

## Why This Works (Mechanism)

### Mechanism 1: Multi-resolution Input Robustness
Multi-resolution input stacking creates robustness by forcing the classifier to operate on multiple scales simultaneously, mimicking human microsaccades and macrosaccades. The classifier is trained on a 3N-channel input formed by stacking downsampled versions of the same image. Each resolution receives random jitter, noise, and color shifts. This reduces the effective input space available to an attacker and increases invariance to spatial transformations.

### Mechanism 2: CrossMax Ensembling
CrossMax ensembling based on Vickrey auction principles aggregates predictions robustly by suppressing outlier predictions and encouraging consensus. For logits Z of shape [B, N, C], CrossMax normalizes by subtracting the per-predictor max and per-class max, then aggregates via median (or top-k for self-ensembles). This limits domination by a single model or class, as outliers are more likely to be incorrect predictions in adversarial settings.

### Mechanism 3: Intermediate Layer De-correlation
Intermediate layer de-correlation provides an active defense by allowing the model to detect and resist attacks that fool only the final layer. Linear probes trained on intermediate activations show that adversarial attacks on the final classifier do not significantly affect early/middle layer predictions. Self-ensembling via CrossMax aggregates these partially robust predictions, correcting errors when the final layer is compromised.

## Foundational Learning

- **Concept**: Adversarial examples and the adversarial robustness problem
  - Why needed: The paper builds a defense against targeted ℓ∞ perturbations; understanding attack objectives and metrics is essential
  - Quick check: What is the difference between clean accuracy and robust accuracy under AutoAttack?

- **Concept**: Ensemble methods and aggregation strategies
  - Why needed: CrossMax is a novel ensembling method; understanding standard ensembling (mean, median) is necessary to appreciate its advantages
  - Quick check: Why does taking the median over logits improve robustness compared to taking the mean?

- **Concept**: Multi-resolution image representations and scale invariance
  - Why needed: Multi-resolution inputs are the core architectural choice; knowing how pyramids and scale spaces work helps reason about design decisions
  - Quick check: How does adding noise and jitter at each resolution contribute to robustness?

## Architecture Onboarding

- **Component map**: Multi-resolution input -> ResNet backbone -> Intermediate heads (linear probes) -> CrossMax aggregation -> Final logits
- **Critical path**: 1. Preprocess image → multi-resolution stack with jitter/noise 2. Forward through backbone → intermediate activations 3. Linear probes → intermediate logits 4. CrossMax aggregation → final logits 5. Loss → cross-entropy on ground truth
- **Design tradeoffs**: Input dimensionality vs. computational cost (3N channels); Number of intermediate heads vs. robustness (more layers → better defense but higher cost); Top-k parameter in CrossMax vs. sensitivity to outliers; Fixed vs. learned aggregation weights
- **Failure signatures**: High clean accuracy but low robust accuracy → CrossMax not suppressing outliers; Robust accuracy degrades with stronger attacks → attacker finds universal perturbations; Training instability → learning rate too high for multi-resolution input space
- **First 3 experiments**: 1. Replace standard input with 2-resolution stack (32×32 + 16×16), train ResNet18, evaluate AutoAttack ℓ∞=8/255 2. Add intermediate heads to ResNet152, aggregate with median (no CrossMax normalization), compare to CrossMax 3. Ensemble three independent self-ensembles, measure robustness gain over single self-ensemble

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed multi-resolution approach scale to larger datasets like ImageNet compared to CIFAR-10/CIFAR-100? The authors mention scalability to larger datasets as future work, but empirical evidence on ImageNet or other large-scale datasets is lacking.

### Open Question 2
What is the theoretical foundation behind why multi-resolution inputs and CrossMax ensembling contribute to adversarial robustness? While the paper demonstrates empirical effectiveness, it does not provide a theoretical explanation for why these methods work.

### Open Question 3
How robust is the proposed method against adversarial attacks using norms other than L∞ (e.g., L2, L1, or semantic adversarial examples)? The current study only evaluates robustness against L∞ norm-bounded perturbations, leaving effectiveness against other attack types unknown.

## Limitations

- Effectiveness depends on attacker not being able to craft perturbations robust across all resolutions simultaneously
- CrossMax's Vickrey auction-based aggregation may be exploitable by adaptive attackers learning to push predictions toward target classes
- Intermediate layer de-correlation may fail against universal perturbations affecting all layers equally

## Confidence

- **High**: The multi-resolution input approach and its implementation details are well-specified and reproducible
- **Medium**: The CrossMax aggregation mechanism and its theoretical justification through Vickrey auctions
- **Low**: The intermediate layer de-correlation defense and its effectiveness against sophisticated adaptive attacks

## Next Checks

1. Implement an adaptive attack that crafts perturbations simultaneously robust across all resolutions to test the multi-resolution defense's limits
2. Design an attack that specifically targets the CrossMax aggregation mechanism by learning to push predictions toward a target class across all predictors
3. Evaluate the approach against universal perturbations that affect all intermediate layers to verify the de-correlation assumption