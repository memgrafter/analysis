---
ver: rpa2
title: 'More Victories, Less Cooperation: Assessing Cicero''s Diplomacy Play'
arxiv_id: '2406.04643'
source_url: https://arxiv.org/abs/2406.04643
tags:
- cicero
- diplomacy
- human
- players
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work rigorously evaluates Cicero\u2019s communication abilities\
  \ in the strategic board game Diplomacy. By annotating in-game messages with abstract\
  \ meaning representation (AMR), the study extracts player intents and detects deception\
  \ and persuasion."
---

# More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play

## Quick Facts
- arXiv ID: 2406.04643
- Source URL: https://arxiv.org/abs/2406.04643
- Reference count: 28
- Primary result: Cicero wins most matches but its communication is more transactional than cooperative

## Executive Summary
This study evaluates Cicero's communication abilities in the strategic board game Diplomacy by annotating in-game messages with abstract meaning representation (AMR) to extract player intents and detect deception and persuasion. In controlled games against humans, Cicero achieves strategic success but exhibits more transactional than cooperative communication patterns. Humans can reliably identify Cicero as an AI and perceive it as less trustworthy, despite the system breaking commitments less often than human players. The research concludes that while Cicero excels at strategy, it has not mastered the nuanced communication skills required for truly human-like cooperation in Diplomacy.

## Method Summary
The study employs AMR-based annotation to systematically analyze message intent in Diplomacy gameplay. Researchers conducted controlled matches between Cicero and human players, collecting communication data and player perceptions. The evaluation framework includes both quantitative metrics (win rates, commitment-breaking frequency) and qualitative assessments (trust ratings, AI identification accuracy). The approach combines automated message analysis with human participant feedback to provide a comprehensive evaluation of Cicero's diplomatic capabilities.

## Key Results
- Cicero wins most matches against human opponents but exhibits more transactional than cooperative communication
- Human players reliably identify Cicero as an AI and report lower trust levels compared to human opponents
- Cicero breaks commitments less often than humans but demonstrates reduced persuasive effectiveness

## Why This Works (Mechanism)
The study's systematic approach to analyzing diplomatic communication through AMR annotation provides objective metrics for evaluating AI performance in nuanced social interactions. By combining automated message analysis with human perception data, the research captures both the technical and experiential aspects of Cicero's performance. The controlled experimental design allows for direct comparison between AI and human players while maintaining ecological validity in the complex social dynamics of Diplomacy gameplay.

## Foundational Learning
- **Abstract Meaning Representation (AMR)**: A semantic formalism for representing sentence meaning as directed acyclic graphs, needed to systematically extract player intents from messages; quick check: can parse complex negotiation statements into structured semantic representations
- **Message intent classification**: The process of categorizing communication purposes (e.g., persuasion, deception, information sharing), required to understand strategic dialogue patterns; quick check: correctly labels messages with their primary communicative function
- **Deception detection**: Identifying when players make false or misleading statements, essential for modeling strategic manipulation in Diplomacy; quick check: distinguishes between genuine offers and deceptive tactics with reasonable accuracy
- **Persuasive communication metrics**: Quantitative measures of how effectively messages influence other players' decisions, needed to evaluate Cicero's ability to build alliances; quick check: correlates message features with alliance formation success
- **Human-AI interaction trust**: The psychological dimension of how humans perceive and respond to AI agents, critical for understanding social acceptance; quick check: measures trust levels through standardized survey instruments
- **Strategic commitment analysis**: Tracking and evaluating promise-keeping behavior in gameplay, important for assessing reliability and trustworthiness; quick check: accurately records and compares commitment adherence rates

## Architecture Onboarding

**Component Map**
AMR Annotation Pipeline -> Intent Classification Module -> Deception Detection System -> Persuasion Analysis Engine -> Human Perception Survey -> Strategic Outcome Metrics

**Critical Path**
Message collection → AMR annotation → Intent extraction → Deception/p persuasion analysis → Human evaluation → Strategic performance correlation

**Design Tradeoffs**
The study prioritizes systematic semantic analysis through AMR over more flexible but less standardized natural language processing approaches. This choice provides consistency and replicability but may miss subtle contextual cues that humans naturally detect during gameplay.

**Failure Signatures**
- Low agreement between AMR annotations and human interpretations suggests semantic representation limitations
- Inconsistent detection of deceptive messages indicates model sensitivity to contextual nuances
- Weak correlation between persuasion metrics and actual alliance formation reveals gaps in influence modeling
- High accuracy in AI identification by humans suggests detectable communication patterns
- Lower trust ratings despite commitment adherence indicate missing social cues

**3 First Experiments**
1. Test AMR annotation consistency by having multiple annotators label the same message corpus and measuring inter-annotator agreement
2. Validate deception detection accuracy by comparing system classifications against human judgments on known deceptive messages
3. Evaluate persuasion metric effectiveness by correlating message features with actual alliance formation outcomes in controlled gameplay

## Open Questions the Paper Calls Out
None

## Limitations
- AMR-based message annotation may miss subtle contextual cues that humans naturally detect during gameplay
- Binary classification of messages as deceptive or not may oversimplify complex strategic communication patterns
- Findings may not generalize to other strategic communication domains beyond Diplomacy's unique negotiation-betrayal dynamics

## Confidence
- **High**: Cicero's strategic performance metrics (win rates, commitment-breaking behavior, message effectiveness) are clearly measured and analyzed
- **Medium**: Comparative analysis of human versus AI communication styles relies on self-reported perceptions that may be influenced by experimental context
- **Low**: Generalizability of findings to other strategic communication domains, as Diplomacy's unique combination of negotiation and betrayal may not translate directly

## Next Checks
1. Replicate human perception study with larger, more diverse participant pools across different gaming platforms to verify consistency of results
2. Implement blinded trials where human players interact with both Cicero and human players without knowing which is which, to test whether identification is based on communication patterns alone
3. Conduct longitudinal studies tracking how human players adapt their strategies when repeatedly facing Cicero, to understand whether perceived trust deficits impact long-term strategic outcomes