---
ver: rpa2
title: 'The Best of Both Worlds: Bridging Quality and Diversity in Data Selection
  with Bipartite Graph'
arxiv_id: '2410.12458'
source_url: https://arxiv.org/abs/2410.12458
tags:
- filter
- data
- quality
- diversity
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of selecting high-quality and
  diverse data for supervised fine-tuning of large language models, where existing
  methods often prioritize either quality or diversity, leading to suboptimal model
  performance. To overcome this limitation, the authors propose GraphFilter, a novel
  data selection method that models the dataset as a bipartite graph connecting sentences
  to their constituent n-grams.
---

# The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph

## Quick Facts
- arXiv ID: 2410.12458
- Source URL: https://arxiv.org/abs/2410.12458
- Authors: Minghao Wu; Thuy-Trang Vu; Lizhen Qu; Gholamreza Haffari
- Reference count: 40
- Primary result: GraphFilter achieves up to +3.38 higher accuracy and 61× faster data selection than baselines

## Executive Summary
This paper addresses the challenge of selecting high-quality and diverse data for supervised fine-tuning of large language models. The authors propose GraphFilter, a novel data selection method that models the dataset as a bipartite graph connecting sentences to their constituent n-grams. By combining quality (measured by SUPER FILTER) and diversity (measured by TF-IDF scores of n-grams) in a multiplicative priority function, GraphFilter iteratively selects sentences while updating the graph to reflect n-gram coverage. Extensive experiments using three model backbones across six benchmarks demonstrate that GraphFilter outperforms nine existing baselines in both model performance and computational efficiency.

## Method Summary
GraphFilter constructs a bipartite graph where sentences are connected to their constituent n-grams (unigrams, bigrams, trigrams). It employs a priority function that combines quality (measured by SUPER FILTER - perplexity ratio) and diversity (measured by TF-IDF scores) multiplicatively. The algorithm iteratively selects high-priority sentences, removes covered n-grams from the graph, and recalculates priorities. This approach balances quality and diversity while approximating the NP-hard set cover problem. The method is evaluated by fine-tuning three different model backbones (GEMMA-2-2B, MISTRAL-7B-v0.3, LLAMA-3-8B) on selected subsets and evaluating performance across six benchmarks.

## Key Results
- GraphFilter achieves up to +3.38 higher accuracy compared to existing baselines
- Computational efficiency improves by up to 61× compared to competing methods
- Outperforms nine baselines including RANDOM, LONGEST, PERPLEXITY, ARMO RM, ALPAGASUS, DEITA, SUPER FILTER, KMEANS, and INSTAG
- Effectively balances quality and diversity, with instruction diversity being particularly important for model performance

## Why This Works (Mechanism)

### Mechanism 1
The bipartite graph structure enables efficient n-gram coverage maximization by iteratively selecting sentences that cover the most uncovered n-grams while maintaining quality priorities. The graph connects sentences to their constituent n-grams, and when a sentence is selected, its covered n-grams are removed from the graph with priorities recalculated based on remaining n-grams. This greedy approach approximates the set cover problem.

### Mechanism 2
The multiplicative priority function effectively balances quality and diversity by ensuring both metrics contribute proportionally to sentence selection. Priority is calculated as QUALITY(u) × DIVERSITY(u), where QUALITY uses SUPER FILTER (perplexity ratio) and DIVERSITY uses TF-IDF scores of n-grams in each sentence. This ensures high-quality sentences that also contribute to n-gram coverage are selected.

### Mechanism 3
The iterative graph update process maintains selection diversity by preventing redundant n-gram coverage. After each sentence selection, covered n-grams are removed from the graph and all edges connected to these n-grams are deleted. This prevents subsequent selections from covering the same n-grams, maintaining diversity.

## Foundational Learning

- **Concept**: Bipartite graphs and set cover problems
  - Why needed here: The method explicitly models data selection as a set cover problem using bipartite graphs, so understanding these concepts is crucial for grasping the approach.
  - Quick check question: What is the relationship between bipartite graphs and the set cover problem in the context of data selection?

- **Concept**: TF-IDF scoring and its role in diversity measurement
  - Why needed here: TF-IDF is used to quantify the diversity contribution of each n-gram, which is essential for understanding how the method balances quality and diversity.
  - Quick check question: How does TF-IDF scoring help in identifying diverse n-grams for data selection?

- **Concept**: Perplexity-based quality metrics (SUPER FILTER)
  - Why needed here: SUPER FILTER is the quality metric used in the priority function, so understanding how it measures instruction-following difficulty is important for understanding the quality component.
  - Quick check question: What does SUPER FILTER measure and why is it suitable for assessing data quality?

## Architecture Onboarding

- **Component map**: Data preprocessing -> N-gram extraction -> Graph construction -> Quality scoring -> Diversity scoring -> Priority calculation -> Selection loop -> Output
- **Critical path**: The selection loop is the critical path - each iteration depends on the previous graph state and priority calculations
- **Design tradeoffs**: 
  - Using n-grams vs. other linguistic units (words, phrases)
  - Multiplicative vs. additive priority function
  - Graph-based vs. embedding-based diversity measurement
  - SUPER FILTER vs. other quality metrics
- **Failure signatures**:
  - If selected data shows low diversity despite high quality scores
  - If computational efficiency degrades significantly with larger datasets
  - If the method consistently underperforms on specific benchmark types
- **First 3 experiments**:
  1. Run GraphFilter on a small subset (100-500 instances) with different n-gram combinations to verify the impact of n-gram choice
  2. Compare the quality-diversity balance by running with only quality or only diversity metrics
  3. Test the computational efficiency by scaling up to 10K instances and measuring runtime vs. baselines

## Open Questions the Paper Calls Out

### Open Question 1
How does the effectiveness of GraphFilter's quality-diversity balance vary across different dataset domains or task types? The paper demonstrates GraphFilter's effectiveness across multiple benchmarks and model backbones, but does not explicitly explore how performance varies across different dataset domains or task types.

### Open Question 2
How does GraphFilter's performance scale with larger dataset sizes and more complex language models? The paper experiments with datasets of up to 300K instances and models up to 8B parameters, but does not explore performance scaling with significantly larger datasets or more complex models.

### Open Question 3
How does GraphFilter's approach compare to other advanced data selection methods that incorporate more sophisticated quality and diversity metrics? The paper compares GraphFilter to nine baseline methods but does not explore more advanced data selection methods that might combine multiple quality metrics or use more sophisticated diversity measures.

## Limitations
- Effectiveness across different domains, languages, and instruction types remains unclear
- Relies on SUPER FILTER and TF-IDF metrics which may not capture all aspects of quality and diversity
- Claims about multiplicative priority function optimality difficult to verify without broader comparative studies

## Confidence
- **High Confidence**: Claims about basic algorithmic approach and computational efficiency improvements
- **Medium Confidence**: Performance improvements over baselines within experimental framework
- **Low Confidence**: Claims about specific multiplicative priority function being optimal and "best of both worlds" approach

## Next Checks
1. **Cross-dataset Validation**: Test GraphFilter on datasets from different domains (e.g., code generation, general knowledge) and languages to assess generalizability beyond instruction-following tasks.
2. **Metric Sensitivity Analysis**: Conduct controlled experiments varying the priority function (additive vs. multiplicative, different quality/diversity metrics) to quantify the impact of design choices on downstream performance.
3. **Long-tail Coverage Analysis**: Measure n-gram coverage across different frequency bands to verify that GraphFilter effectively captures both common and rare linguistic patterns, addressing potential bias toward high-frequency n-grams.