---
ver: rpa2
title: 'Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish:
  A Feasibility-Driven Transfer Learning Approach with Large Language Models'
arxiv_id: '2403.02121'
source_url: https://arxiv.org/abs/2403.02121
tags:
- classification
- few-shot
- learning
- zero-shot
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores zero-shot, one-shot, and few-shot learning for
  hate speech detection in code-mixed Hinglish YouTube comments. A dataset of 100
  comments was weakly annotated for misogyny detection at coarse and fine-grained
  levels.
---

# Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models

## Quick Facts
- arXiv ID: 2403.02121
- Source URL: https://arxiv.org/abs/2403.02121
- Reference count: 36
- Primary result: Zero-shot BART achieved 54% accuracy for binary misogyny classification, outperforming one-shot (34%) and few-shot (53%) approaches

## Executive Summary
This paper investigates zero-shot, one-shot, and few-shot learning approaches for hate speech detection in code-mixed Hinglish (Hindi+English) YouTube comments. The authors collected 100 comments and weakly annotated them for misogyny detection at both coarse (MGY/Not) and fine-grained (9 categories) levels. Their experiments demonstrate that zero-shot classification using BART large achieves better binary classification accuracy than one-shot approaches, while few-shot prompting with ChatGPT-3 shows promise. The study highlights the potential of transfer learning approaches for data annotation in low-resource languages, though results indicate room for improvement particularly in fine-grained classification tasks.

## Method Summary
The study employs transfer learning approaches including zero-shot, one-shot, and few-shot learning for misogyny detection in code-mixed Hinglish. The dataset consists of 100 YouTube comments from a video about marital rape law in India, weakly annotated at coarse level (MGY/Not) and fine-grained level (9 misogyny categories). Zero-shot classification uses BART-large-mnli by framing the task as Natural Language Inference. Few-shot learning employs SetFit with MPNet sentence transformer, fine-tuning on small labeled samples. One-shot/few-shot prompting uses ChatGPT-3 with in-context learning. The paper evaluates binary classification using accuracy, macro-F1, precision, recall, and MCC, while multi-label fine-grained classification is assessed using precision, recall, and F1 scores.

## Key Results
- Zero-shot BART classification achieved 54% accuracy for binary MGY/Not classification
- Few-shot prompting with ChatGPT-3 showed promising results for one-shot classification
- Multi-label fine-grained classification performance was low (precision 22-28%, F1 26-27%)
- Zero-shot approach outperformed one-shot (34%) but was comparable to few-shot (53%) for binary classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot classification can label Hinglish comments without fine-tuning when prompts are constructed as NLI premises
- Mechanism: The BART large model, pre-trained on MNLI, maps the input comment (premise) and constructed label hypothesis into an entailment decision, enabling zero-shot classification
- Core assumption: The NLI formulation generalizes to hate speech detection and the model's pre-training includes relevant linguistic patterns
- Evidence anchors:
  - [abstract] "Zero-shot classification using the Bidirectional Auto-Regressive Transformers (BART) large model"
  - [section] "we can consider the problem of zero-shot classification as an Natural Language Inference (NLI) problem"
  - [corpus] Weak, only general hate speech detection papers cited
- Break condition: If the comment contains slang or code-mixed structure outside the MNLI training distribution, the entailment mapping fails

### Mechanism 2
- Claim: Few-shot prompting with ChatGPT-3 can correctly label Hinglish comments by in-context learning
- Mechanism: Providing one or a few labeled examples in the prompt conditions ChatGPT-3 to generalize the labeling pattern to unseen comments
- Core assumption: The model's few-shot capabilities generalize across languages and informal mixing without fine-tuning
- Evidence anchors:
  - [abstract] "few-shot prompting using Generative Pre-trained Transformer- 3 (ChatGPT-3) achieve the best results"
  - [section] "the model correctly labels the statement as misogynistic and also provides reasoning"
  - [corpus] Weak, no direct comparison to Hindi-specific models
- Break condition: If the prompt format or label set is not clearly expressed, the model defaults to generic language patterns and mislabels

### Mechanism 3
- Claim: Transfer learning via SetFit can improve one-shot and few-shot classification by leveraging pre-trained sentence transformers
- Mechanism: SetFit fine-tunes the MPNet encoder on a small set of labeled samples, then trains a classification head on the resulting embeddings
- Core assumption: The pre-trained MPNet encoder captures relevant semantic features for Hinglish hate speech despite being trained on English
- Evidence anchors:
  - [section] "few-shot classification achieves the higher scores on all the metrics"
  - [section] "The one-shot promoting results obtained through ChatGPT-3 are promising"
  - [corpus] Weak, only general few-shot learning studies cited
- Break condition: If the dataset is too small or imbalanced, the fine-tuned embeddings overfit and performance degrades

## Foundational Learning

- Concept: Natural Language Inference (NLI) and entailment frameworks
  - Why needed here: Zero-shot classification is implemented by framing classification as NLI (premise + hypothesis → entailment)
  - Quick check question: In zero-shot BART classification, what role does the "premise" play relative to the labels?

- Concept: Prompt engineering and in-context learning
  - Why needed here: ChatGPT-3 relies on carefully structured prompts to perform one-shot/few-shot classification without fine-tuning
  - Quick check question: What two pieces of information must each example in a few-shot ChatGPT prompt contain?

- Concept: Sentence transformer fine-tuning and embedding spaces
  - Why needed here: SetFit leverages pre-trained sentence transformers (MPNet) and adapts them to the small Hinglish dataset
  - Quick check question: In SetFit, after fine-tuning the encoder, what component is trained on the embeddings to perform classification?

## Architecture Onboarding

- Component map: Data ingestion → Preprocessing (Romanized Hindi + English) → Weak annotation → BART zero-shot classifier (MNLI pre-trained) → SetFit fine-tuning (MPNet) → ChatGPT-3 few-shot prompting → Evaluation (accuracy, precision, recall, F1, MCC)
- Critical path: Data collection → Weak annotation → Model inference (zero/few-shot) → Evaluation → Iteration
- Design tradeoffs:
  - Zero-shot: No fine-tuning cost, but lower accuracy on imbalanced fine-grained labels
  - Few-shot: Higher accuracy but requires at least a handful of labeled examples
  - ChatGPT-3: Flexible prompting but API cost and context limits
- Failure signatures:
  - Low precision on multi-label classification → model struggles with label co-occurrence
  - Confusion between similar labels (e.g., "Derailing" vs "Shaming") → ambiguous label definitions
  - Poor performance on Romanized Hindi → vocabulary mismatch
- First 3 experiments:
  1. Run BART zero-shot with two labels ("MGY" vs "NOT") and compare to weak annotation
  2. Use SetFit with 4 samples per class and evaluate macro-F1
  3. Construct a ChatGPT-3 prompt with 1 example and test labeling on 10 new comments

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of zero-shot learning compare to fine-tuned models when using domain-specific pre-training data for code-mixed Hinglish?
- Basis in paper: [inferred] The paper notes that zero-shot models perform poorly due to lack of domain-specific pre-training, and suggests exploring domain-specific LLMs
- Why unresolved: The study only used general-purpose LLMs without domain adaptation, leaving the impact of domain-specific pre-training unexplored
- What evidence would resolve it: Experiments comparing zero-shot learning performance using general vs. Hinglish-specific pre-trained models on the same dataset

### Open Question 2
- Question: What is the inter-annotator agreement for the misogyny classification task, and how does it affect model performance?
- Basis in paper: [explicit] The paper mentions that only one annotator was used and that kappa coefficient calculation is planned for future work
- Why unresolved: Single-annotator bias is acknowledged but not quantified, and the impact on model evaluation remains unknown
- What evidence would resolve it: Kappa coefficient calculation with multiple annotators and performance comparison using gold-standard vs. single-annotator labels

### Open Question 3
- Question: How do different prompt engineering strategies affect one-shot prompting performance with ChatGPT-3?
- Basis in paper: [explicit] The paper tested two basic prompts and found promising results, suggesting potential for improvement through better prompt design
- Why unresolved: Only basic prompt structures were tested without systematic exploration of prompt engineering techniques
- What evidence would resolve it: Comparative experiments testing various prompt structures (chain-of-thought, few-shot examples, role-playing) on the same dataset

### Open Question 4
- Question: Would increasing the dataset size beyond 100 comments significantly improve the performance of zero-shot and few-shot learning approaches?
- Basis in paper: [inferred] The paper acknowledges the small dataset size as a limitation and suggests testing on larger datasets in future work
- Why unresolved: The study's findings are based on a limited sample size, leaving scalability questions unanswered
- What evidence would resolve it: Performance evaluation of the same approaches on progressively larger datasets (500, 1000, 5000+ samples) using consistent methodology

## Limitations
- The dataset size of 100 comments is extremely small for multi-label classification tasks, raising concerns about statistical significance
- Weak annotation process lacks detailed description of inter-annotator agreement and quality control procedures
- Romanized Hindi script may not be optimally handled by models pre-trained on standard scripts, potentially introducing vocabulary mismatches

## Confidence
**High Confidence**: The core observation that zero-shot classification using BART achieves better performance than one-shot approaches for binary classification is well-supported by the reported metrics (54% vs 34% accuracy).

**Medium Confidence**: The claim that few-shot learning with ChatGPT-3 shows "promising results" is supported but limited by lack of detailed prompt engineering specifications and comparison to baseline models.

**Low Confidence**: The multi-label classification results (precision 22-28%, F1 26-27%) are too low to draw definitive conclusions about model capability, especially given the small dataset and lack of ablation studies.

## Next Checks
1. **Dataset Validation**: Collect a larger, more diverse dataset of 500-1000 Hinglish comments from multiple YouTube videos and domains, with rigorous annotation protocols including inter-annotator agreement calculation (Krippendorff's alpha) and conflict resolution procedures.

2. **Prompt Engineering Study**: Systematically vary prompt formats for ChatGPT-3 few-shot learning, testing different example counts (1, 3, 5), prompt structures, and label descriptions to identify optimal configurations and quantify sensitivity to prompt design.

3. **Model Robustness Testing**: Evaluate model performance across different Hinglish variants including Devanagari script, varying levels of code-mixing, and different regional dialects to assess generalization beyond the specific dataset characteristics.