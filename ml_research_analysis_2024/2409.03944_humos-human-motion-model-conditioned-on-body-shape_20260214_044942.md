---
ver: rpa2
title: 'HUMOS: Human Motion Model Conditioned on Body Shape'
arxiv_id: '2409.03944'
source_url: https://arxiv.org/abs/2409.03944
tags:
- motion
- body
- human
- shape
- motions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating realistic human
  motion that accounts for body shape and size differences. Most existing motion models
  ignore these differences, resulting in uniform motion across different body types.
---

# HUMOS: Human Motion Model Conditioned on Body Shape

## Quick Facts
- arXiv ID: 2409.03944
- Source URL: https://arxiv.org/abs/2409.03944
- Reference count: 40
- Key outcome: HUMOS generates body-shape-aware human motion with 71.9% dynamic stability rate, outperforming state-of-the-art methods.

## Executive Summary
This paper introduces HUMOS, a generative motion model that conditions human motion generation on body shape using a conditional Variational Auto-Encoder (c-VAE). Unlike existing models that ignore body shape differences, HUMOS learns how people with different body shapes perform the same motion, enabling realistic motion retargeting between characters. The model is trained with cycle consistency, intuitive physics, and stability constraints, achieving significant improvements in physics-based metrics and perceptual realism compared to state-of-the-art methods.

## Method Summary
HUMOS is a conditional VAE using a Transformer-based encoder-decoder architecture that generates motion conditioned on body shape. The encoder maps motion features and identity to a latent space, while the decoder generates retargeted motion conditioned on the target identity. Training uses cycle consistency to enable unpaired data learning, intuitive physics terms to prevent artifacts like foot sliding and ground penetration, and dynamic stability constraints based on ZMP-CoP alignment. The model is trained on AMASS dataset (480 identities) with sequence length 200, subsampled to 20 fps, and augmented with mirroring.

## Key Results
- HUMOS achieves 71.9% dynamic stability rate compared to 55.92% for the closest baseline
- Significant improvements in physics metrics: 1.21 cm ground penetration vs 2.81 cm for baselines
- Perceptual study shows HUMOS-generated motions rated as more realistic than other methods by 25 participants per video
- Retargeted motions maintain original style while adapting to target body shape

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Cycle consistency allows training a shape-conditioned motion model without paired data by leveraging unpaired motion and identity samples.
- **Mechanism:** The model encodes a source motion into a latent representation that is identity-agnostic. It then decodes this latent code conditioned on a target identity to generate a retargeted motion. By reversing this process and ensuring the reconstructed motion matches the original, the model learns to disentangle motion style from identity.
- **Core assumption:** The latent space captures motion style independently of identity, and the cycle consistency loss forces the model to preserve motion semantics across identity transformations.
- **Evidence anchors:**
  - [abstract] "We demonstrate that it is possible to train this model from unpaired training data using cycle consistency, intuitive physics, and stability constraints"
  - [section 3.2] "we employ cycle-consistency by reversing the forward step, this time using ˆMA→B as the source motion andA as the target identity"
- **Break condition:** If the latent space fails to disentangle motion style from identity, cycle consistency cannot enforce meaningful retargeting.

### Mechanism 2
- **Claim:** Dynamic stability terms ensure generated motions are biomechanically plausible by enforcing ZMP-CoP alignment.
- **Mechanism:** The model computes the Zero Moment Point (ZMP) from the center of mass dynamics and minimizes its distance to the Center of Pressure (CoP), ensuring the motion remains dynamically stable during locomotion.
- **Core assumption:** Human motions in the dataset are dynamically stable, and enforcing ZMP-CoP alignment during training will produce realistic, balanced motions.
- **Evidence anchors:**
  - [abstract] "We propose differentiable physics terms that improve the realism of generated motions by addressing common issues like foot sliding, ground penetration, and unrealistic floating effects"
  - [section 3.4] "We follow the concept of zero-moment-point (ZMP)... If this point lies within the base of support, the ZMP is equivalent to the center of pressure and the motion is considered dynamically stable"
- **Break condition:** If the dataset contains many unstable motions or the ZMP computation is inaccurate, the stability term may enforce unrealistic constraints.

### Mechanism 3
- **Claim:** Intuitive physics losses prevent trivial solutions by penalizing physically implausible artifacts like foot sliding and ground penetration.
- **Mechanism:** Additional loss terms are applied to the generated target motion to minimize ground penetration, floating, and foot sliding, encouraging the model to adjust the motion appropriately for the target body shape.
- **Core assumption:** Without these physics constraints, the model could trivially copy the source motion to the target body, resulting in physically implausible artifacts.
- **Evidence anchors:**
  - [abstract] "To prevent this, our key insight is to incorporate our IP and dynamic stability terms as training losses on the generated target body motions"
  - [section 3.3] "We design IP terms to address penetration, float, and foot sliding individually... We collate them together as Lphysics = Lpenetrate + Lfloat + Lslide"
- **Break condition:** If the physics terms are too weak or the motion space is too constrained, the model may still produce implausible motions despite these losses.

## Foundational Learning

- **Concept:** Variational Autoencoder (VAE) and conditional VAE (c-VAE)
  - Why needed here: HUMOS uses a c-VAE architecture to learn a latent representation of motion conditioned on body shape, enabling generation of diverse, realistic motions for different identities.
  - Quick check question: How does a c-VAE differ from a standard VAE in terms of input and output?

- **Concept:** Zero Moment Point (ZMP) and dynamic stability in biomechanics
  - Why needed here: The dynamic stability term in HUMOS is based on ZMP theory, ensuring generated motions are biomechanically plausible by enforcing balance during locomotion.
  - Quick check question: What is the physical interpretation of the ZMP, and why is it important for dynamic stability?

- **Concept:** Cycle consistency in unpaired image-to-image translation
  - Why needed here: HUMOS leverages cycle consistency to train the shape-conditioned motion model without paired data, inspired by successful applications in unpaired image translation.
  - Quick check question: How does cycle consistency help enforce that the retargeted motion preserves the original motion style?

## Architecture Onboarding

- **Component map:** Encoder (Transformer) -> Latent space -> Decoder (Transformer) -> Physics & stability losses -> Retargeted motion
- **Critical path:** Encoder → Latent space → Decoder → Physics & stability losses → Retargeted motion
- **Design tradeoffs:**
  - Non-autoregressive vs. autoregressive generation: Chosen for better motion diversity but may sacrifice fine-grained temporal coherence
  - Mesh-based representation (SMPL) vs. skeleton-based: Chosen for accurate surface contact modeling but increases computational complexity
  - Transformer architecture vs. other sequence models: Chosen for strong spatial-temporal modeling but requires more data and compute
- **Failure signatures:**
  - Poor disentanglement of motion style and identity: Retargeted motions look similar regardless of target body shape
  - Inaccurate ZMP computation: Generated motions exhibit unrealistic floating or imbalance
  - Weak physics terms: Generated motions have ground penetration, foot sliding, or other physical artifacts
  - Mode collapse in latent space: Generated motions lack diversity and appear repetitive
- **First 3 experiments:**
  1. Train with only cycle consistency loss (Lcycle) and evaluate on physics metrics to confirm it learns basic retargeting
  2. Add physics losses (Lphysics) and measure improvement in penetration, float, and skate metrics
  3. Add dynamic stability term (Ldyn) and verify improvement in dynamic stability percentage and BoS distance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the diversity of body shapes in the training data affect the generalization capabilities of HUMOS?
- Basis in paper: [explicit] The paper mentions that HUMOS is trained on the AMASS dataset, which contains 480 unique gender identities with diverse body shapes and sizes. It also notes that the differences in motion style produced by characters of very different body shapes remain subtle, possibly due to the limited shape diversity in the training set.
- Why unresolved: The paper does not provide a detailed analysis of how varying the diversity of body shapes in the training data impacts the model's performance and generalization.
- What evidence would resolve it: Conducting experiments with datasets of varying body shape diversity and comparing HUMOS's performance on each would provide insights into the impact of training data diversity on the model's generalization capabilities.

### Open Question 2
- Question: How does HUMOS handle self-penetrations that may arise during shape-conditioned motion generation?
- Basis in paper: [inferred] The paper mentions that HUMOS generates physically plausible and dynamically stable human motions but does not explicitly address self-penetrations.
- Why unresolved: The paper does not discuss any mechanisms or losses in HUMOS specifically designed to prevent self-penetrations.
- What evidence would resolve it: Implementing and evaluating additional loss terms or constraints in HUMOS to prevent self-penetrations, and comparing the results with and without these additions, would clarify the model's handling of self-penetrations.

### Open Question 3
- Question: How would incorporating motion style as an additional conditioning signal affect HUMOS's performance?
- Basis in paper: [explicit] The paper acknowledges that human motion is influenced by both body shape and individual motion style, but only considers body shape as a conditioning signal. It suggests that with style-specific annotations, it would be useful to extend HUMOS to include style attributes as additional conditioning signals.
- Why unresolved: The paper does not explore the impact of including motion style as a conditioning signal on HUMOS's performance.
- What evidence would resolve it: Extending HUMOS to include motion style as an additional conditioning signal and evaluating its performance on motion generation tasks would provide insights into the benefits of incorporating motion style.

## Limitations

- SMPL-based representation constrains the model to clothed, articulated humans and may not generalize well to loose clothing or hair dynamics
- Dataset filtering process excludes important motion types like jumping or dancing by removing sequences with feet >20 cm above ground
- 29% of generated motions remain potentially unstable despite achieving 71.9% dynamic stability rate

## Confidence

- **High confidence**: The core mechanism of using cycle consistency for unpaired training and the physics-based stability terms are well-supported by quantitative metrics and ablation studies
- **Medium confidence**: The superiority over state-of-the-art methods is demonstrated, but comparisons are limited to specific baselines (TEMOS, TEI)
- **Medium confidence**: The perceptual study results are promising but based on a relatively small sample size (25 participants per video) and limited video duration (5 seconds)

## Next Checks

1. Test HUMOS on motions outside the training distribution (jumping, dancing, acrobatics) to evaluate generalization beyond ground-supported motions
2. Conduct a more extensive perceptual study with longer video sequences and diverse motion types to validate realism across different scenarios
3. Compare HUMOS against additional state-of-the-art motion generation methods (e.g., diffusion-based approaches) to establish broader performance claims