---
ver: rpa2
title: 'A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including
  RAG), Planning, and Feedback Learning'
arxiv_id: '2406.05804'
source_url: https://arxiv.org/abs/2406.05804
tags:
- workflows
- question
- language
- workflow
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a unified taxonomy to systematically review
  LLM-based agent frameworks across three prominent paradigms: tool use, planning,
  and feedback learning. The authors address the lack of coherent comparison by introducing
  task-agnostic LLM-profiled roles (policy models, evaluators, dynamic models) and
  universal workflows applicable across different environments.'
---

# A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning

## Quick Facts
- arXiv ID: 2406.05804
- Source URL: https://arxiv.org/abs/2406.05804
- Authors: Xinzhe Li
- Reference count: 31
- Primary result: Unified taxonomy for LLM-based agent frameworks across tool use, planning, and feedback learning paradigms

## Executive Summary
This paper addresses the fragmented nature of LLM-based agent research by presenting a comprehensive unified taxonomy that systematically categorizes frameworks across three major paradigms: tool use (including RAG), planning, and feedback learning. The authors introduce task-agnostic LLM-profiled roles and universal workflows to enable coherent comparison across diverse agent architectures. The survey covers both decision-making environments (games, embodied AI, web interaction) and natural language interaction settings, providing a structured framework for understanding how different paradigms interact and complement each other.

## Method Summary
The paper employs a systematic literature review methodology, analyzing existing LLM-based agent frameworks through a unified classification lens. The authors define three core LLM-profiled roles (policy models, evaluators, and dynamic models) and four universal workflow types (base, tool-use, search, and feedback-learning) that apply across different environmental contexts. The taxonomy organizes frameworks by their operational mechanisms and interaction patterns, enabling systematic comparison of approaches that were previously studied in isolation.

## Key Results
- Introduces a unified taxonomy that categorizes LLM-based agents across tool use, planning, and feedback learning paradigms
- Defines task-agnostic LLM-profiled roles (policy models, evaluators, dynamic models) applicable across different environments
- Identifies three key limitations: lack of unified solutions for base and autonomous tool-use workflows, absence of universal tool-use designs, and questionable task formulations
- Provides resources and categorization in a public GitHub repository for the research community

## Why This Works (Mechanism)
The unified taxonomy works by establishing a common vocabulary and structural framework that transcends the traditional boundaries between different LLM agent paradigms. By defining universal LLM-profiled roles and workflows, the paper creates a shared reference point that enables systematic comparison and integration of diverse approaches. This standardization allows researchers to identify patterns, commonalities, and gaps across previously siloed research areas, facilitating more coherent progress in the field.

## Foundational Learning
1. **LLM-Profiled Roles (LMRs)**: Why needed - To create standardized functional categories across different agent architectures; Quick check - Can the role be clearly mapped to one of three categories: policy model, evaluator, or dynamic model?
2. **Universal Workflows**: Why needed - To provide consistent operational patterns applicable across diverse environments; Quick check - Does the workflow apply to both decision-making and natural language interaction settings?
3. **Environment Classification**: Why needed - To systematically categorize the contexts in which agents operate; Quick check - Can the environment be classified as either decision-making (games, embodied, web) or natural language interaction?
4. **Paradigm Integration**: Why needed - To show how tool use, planning, and feedback learning complement each other; Quick check - Does the framework demonstrate interaction patterns between different paradigms?
5. **Workflow Types**: Why needed - To distinguish between base, tool-use, search, and feedback-learning operational modes; Quick check - Can the framework's workflow be categorized into one of the four defined types?

## Architecture Onboarding
**Component Map**: LLM Policy Model <-> Evaluator <-> Dynamic Model -> Environment Interface
**Critical Path**: Policy Model (Decision) -> Environment (Response) -> Evaluator (Feedback) -> Policy Model (Update)
**Design Tradeoffs**: Task-agnostic universality vs. domain-specific optimization, unified taxonomy vs. paradigm-specific nuances, comprehensive coverage vs. implementation practicality
**Failure Signatures**: Inconsistent tool selection in autonomous workflows, evaluator bias affecting policy learning, environment interface limitations preventing tool integration, framework incompatibility between paradigms
**3 First Experiments**:
1. Map an existing RAG system to the proposed taxonomy and identify which LLM-profiled roles and workflows it employs
2. Implement a simple decision-making environment and test how the universal workflows apply across different agent architectures
3. Analyze a feedback learning framework to determine how it integrates with the tool-use and planning paradigms in the taxonomy

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Focus on English-language publications may miss important developments in non-English research communities, particularly in Asian regions
- Rapid evolution of the field means some newer frameworks emerging after mid-2024 may not be included
- The claim about "questionable task formulations" appears somewhat subjective and could benefit from more empirical validation

## Confidence
- High: Classification framework and workflow taxonomy (draws from multiple established sources with clear logical structure)
- Medium: Identified limitations section (represents emerging consensus rather than universally agreed constraints)
- Low: "Questionable task formulations" claim (subjective assessment requiring empirical validation)

## Next Checks
1. Systematic review of non-English publications to ensure comprehensive coverage of the field
2. Empirical benchmarking of the proposed universal workflows against specific task domains to validate practical applicability
3. Follow-up survey in 12-18 months to assess how rapidly evolving frameworks address the identified limitations