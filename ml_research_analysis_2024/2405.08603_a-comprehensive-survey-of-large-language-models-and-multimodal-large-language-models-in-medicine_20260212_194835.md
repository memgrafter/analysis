---
ver: rpa2
title: A Comprehensive Survey of Large Language Models and Multimodal Large Language
  Models in Medicine
arxiv_id: '2405.08603'
source_url: https://arxiv.org/abs/2405.08603
tags:
- medical
- llms
- mllms
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive overview of large language
  models (LLMs) and multimodal large language models (MLLMs) in medicine, highlighting
  their transformative potential in clinical applications. It reviews the evolution
  from traditional models to LLMs and MLLMs, focusing on their architectures, training
  methods, and evaluation strategies.
---

# A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine

## Quick Facts
- **arXiv ID:** 2405.08603
- **Source URL:** https://arxiv.org/abs/2405.08603
- **Reference count:** 40
- **Key outcome:** This survey provides a comprehensive overview of large language models (LLMs) and multimodal large language models (MLLMs) in medicine, highlighting their transformative potential in clinical applications. It reviews the evolution from traditional models to LLMs and MLLMs, focusing on their architectures, training methods, and evaluation strategies. The survey explores five key applications—medical diagnosis, clinical report generation, medical education, mental health services, and surgical assistance—while addressing challenges such as hallucinations, privacy concerns, and bias. Future directions include edge deployment, medical agents, and general medical assistants. By bridging advanced AI technologies with clinical practice, this work aims to foster the development of intelligent healthcare systems.

## Executive Summary
This survey provides a comprehensive overview of large language models (LLMs) and multimodal large language models (MLLMs) in medicine, highlighting their transformative potential in clinical applications. It reviews the evolution from traditional models to LLMs and MLLMs, focusing on their architectures, training methods, and evaluation strategies. The survey explores five key applications—medical diagnosis, clinical report generation, medical education, mental health services, and surgical assistance—while addressing challenges such as hallucinations, privacy concerns, and bias. Future directions include edge deployment, medical agents, and general medical assistants. By bridging advanced AI technologies with clinical practice, this work aims to foster the development of intelligent healthcare systems.

## Method Summary
This survey comprehensively reviews the development and application of large language models (LLMs) and multimodal large language models (MLLMs) in medicine. The authors examine the evolution from traditional models to advanced LLMs and MLLMs, detailing their architectures, training methods, and evaluation strategies. They explore five key applications: medical diagnosis, clinical report generation, medical education, mental health services, and surgical assistance. The survey also addresses challenges such as hallucinations, privacy concerns, and bias, while proposing future directions including edge deployment, medical agents, and general medical assistants. The work aims to bridge advanced AI technologies with clinical practice to foster the development of intelligent healthcare systems.

## Key Results
- MLLMs integrate vision encoders and modality alignment modules to bridge text-only LLMs with medical image processing
- Instruction fine-tuning enhances zero-shot performance and instruction-following ability of medical LLMs and MLLMs
- Retrieval-augmented generation mitigates hallucinations by providing models with access to external knowledge during response generation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** MLLMs bridge the gap between text-only LLMs and medical image processing by integrating vision encoders and modality alignment modules.
- **Mechanism:** Vision encoders convert medical images into feature representations, which are then aligned into the semantic space of LLMs through modality alignment modules (e.g., projection-based or query-based methods).
- **Core assumption:** Vision encoders pre-trained on medical imaging datasets yield better performance than those trained on natural scenes.
- **Evidence anchors:**
  - [abstract] "they can integrate and analyze information from various modalities to enhance clinical decision support, disease diagnosis, and treatment planning."
  - [section] "vision encoders pre-trained on medical imaging datasets outperform those trained on natural scene datasets... Consequently, ViT models trained using contrastive learning represent the mainstream choice for vision encoders."
  - [corpus] Found 8 related papers, average FMR 0.503. Corpus provides supporting evidence but no direct citations to this specific claim.
- **Break Condition:** If the vision encoder fails to capture fine-grained medical image features (e.g., low resolution), the alignment step will propagate errors, leading to hallucinations or inaccurate diagnoses.

### Mechanism 2
- **Claim:** Instruction fine-tuning (IFT) enhances zero-shot performance and instruction-following ability of medical LLMs and MLLMs.
- **Mechanism:** Fine-tuning on instruction-following datasets teaches models to understand and execute user directives accurately, reducing reliance on task-specific fine-tuning.
- **Core assumption:** Instruction-following datasets are high-quality and diverse enough to generalize across clinical tasks.
- **Evidence anchors:**
  - [section] "Instruction fine-tuning (IFT) enables models to accurately understand and execute human directives, thereby significantly enhancing their zero-shot performance."
  - [section] "Enhanced instruction-following ability enable more accurate comprehension and execution of user directives, thereby improving downstream task performance."
  - [corpus] Weak evidence: corpus neighbors discuss instruction tuning but not specifically for medical domain.
- **Break Condition:** If the instruction-following dataset lacks medical specificity, the model may perform well on general tasks but fail in clinical contexts.

### Mechanism 3
- **Claim:** Retrieval-augmented generation (RAG) mitigates hallucinations by providing models with access to external knowledge during response generation.
- **Mechanism:** During inference, models retrieve relevant medical knowledge from external sources (e.g., knowledge bases) and incorporate it into their responses, grounding them in verified information.
- **Core assumption:** External knowledge sources are up-to-date and accurate.
- **Evidence anchors:**
  - [section] "retrieval-augmented generation has proven effective in reducing hallucinations... This approach allows the model to retrieve relevant knowledge from external webpages or knowledge bases during the response generation phase."
  - [section] "retrieval-augmented generation can be employed to update the knowledge of medical LLMs and MLLMs by linking the model to an information retrieval component."
  - [corpus] No direct corpus evidence; assumption based on general RAG literature.
- **Break Condition:** If the retrieval component returns outdated or irrelevant information, the model's responses may still contain hallucinations or inaccuracies.

## Foundational Learning

- **Concept:** Transformer architecture and its variants (encoder-only, decoder-only, encoder-decoder).
  - **Why needed here:** Understanding the underlying architecture is crucial for selecting the right base model for medical LLMs and MLLMs.
  - **Quick check question:** What are the key differences between encoder-only, decoder-only, and encoder-decoder transformer architectures, and which is best suited for medical text generation tasks?

- **Concept:** Vision encoders and modality alignment techniques.
  - **Why needed here:** Vision encoders process medical images, and modality alignment bridges the gap between visual and textual modalities.
  - **Quick check question:** What are the trade-offs between using ResNet, ViT, and CLIP-ViT as vision encoders for medical MLLMs?

- **Concept:** Fine-tuning methods (CPT, IFT, SFT, RLHF, RLAIF, DPO).
  - **Why needed here:** Different fine-tuning methods inject medical knowledge, improve instruction-following, and align models with human preferences.
  - **Quick check question:** When would you choose RLHF over DPO for aligning a medical LLM with human preferences?

## Architecture Onboarding

- **Component map:** Base LLM (e.g., LLaMA, PaLM) → Vision Encoder (e.g., CLIP-ViT, ViT) → Modality Alignment Module (e.g., projection-based, query-based) → Output Module (text generation)
- **Critical path:** Vision Encoder → Modality Alignment → LLM Backbone → Output
- **Design tradeoffs:**
  - Vision encoder choice: ResNet (faster but less scalable) vs. ViT (slower but more scalable and better for medical images).
  - Modality alignment: Projection-based (preserves more visual info but higher training cost) vs. Query-based (more efficient but may lose info).
  - Model size: Larger models (better performance) vs. smaller models (faster inference, lower cost).
- **Failure signatures:**
  - Hallucinations: Incorrect or fabricated information in responses.
  - Low accuracy: Poor performance on medical benchmarks.
  - Slow inference: Unacceptable latency in clinical settings.
- **First 3 experiments:**
  1. Evaluate different vision encoders (ResNet, ViT, CLIP-ViT) on a medical VQA dataset.
  2. Compare projection-based and query-based modality alignment methods on image-captioning tasks.
  3. Fine-tune a base LLM with CPT, IFT, and SFT on medical datasets and evaluate performance on downstream tasks.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can we develop standardized, clinically validated evaluation frameworks for medical LLMs and MLLMs that effectively measure both technical performance and real-world clinical utility?
- **Basis in paper:** [explicit] The paper emphasizes the need for comprehensive evaluation methods that go beyond automatic metrics to include human evaluation and AI evaluation, noting that current approaches have limitations in assessing clinical quality and alignment with human values.
- **Why unresolved:** The paper identifies multiple evaluation methods but acknowledges their individual limitations - automatic metrics lack clinical nuance, human evaluation is costly and subjective, and AI evaluation has biases. No clear solution for integrating these methods into a unified framework is provided.
- **What evidence would resolve it:** Development and validation of a standardized evaluation framework that combines quantitative metrics with qualitative clinical assessments, demonstrating improved correlation with actual clinical outcomes compared to existing methods.

### Open Question 2
- **Question:** What architectural innovations beyond the transformer-based approach could enable more efficient training and deployment of medical LLMs and MLLMs while maintaining or improving performance?
- **Basis in paper:** [explicit] The paper discusses the computational challenges of transformer-based models and mentions alternative architectures like RWKV and Mamba as potential solutions, but doesn't provide empirical comparisons in medical contexts.
- **Why unresolved:** While the paper identifies computational challenges and potential architectural alternatives, it doesn't explore how these new architectures perform specifically for medical applications or what trade-offs they might present.
- **What evidence would resolve it:** Comparative studies demonstrating the performance, efficiency, and clinical utility of alternative architectures versus transformers in real medical tasks, including training costs, inference speed, and diagnostic accuracy.

### Open Question 3
- **Question:** How can medical LLMs and MLLMs be effectively integrated into clinical workflows while maintaining appropriate human oversight and accountability?
- **Basis in paper:** [explicit] The paper discusses various clinical applications but emphasizes that these models should serve as auxiliary tools rather than replacements for human clinicians, highlighting concerns about hallucinations, privacy, and accountability.
- **Why unresolved:** The paper identifies the need for human oversight but doesn't provide concrete frameworks for how to structure the interaction between AI systems and healthcare professionals in real clinical settings.
- **What evidence would resolve it:** Development and implementation of clinical workflow protocols that demonstrate safe and effective integration of medical LLMs and MLLMs, with measurable improvements in patient outcomes while maintaining appropriate human control.

## Limitations

- Data privacy and security concerns remain inadequately addressed, particularly regarding the use of sensitive patient information in training datasets.
- The "black box" nature of these models raises significant explainability issues for clinical adoption.
- Most current models are evaluated primarily on benchmark datasets rather than real-world clinical settings, creating uncertainty about their practical utility.

## Confidence

- **High Confidence:** The foundational architecture descriptions and general survey methodology are well-established. The classification of fine-tuning approaches (CPT, IFT, SFT, RLHF) and their applications to medical domains is supported by multiple sources and standard practices in the field.
- **Medium Confidence:** The effectiveness claims for specific vision encoder choices (ViT vs ResNet) and modality alignment methods are based on general computer vision literature rather than extensive medical-specific validation. The survey presents these as current best practices but acknowledges limited direct evidence in medical contexts.
- **Low Confidence:** The survey's predictions about future directions (edge deployment, medical agents, general medical assistants) lack detailed technical specifications or feasibility analysis. These remain largely speculative given current computational and regulatory constraints.

## Next Checks

1. Conduct comparative experiments testing different vision encoder architectures (ResNet, ViT, CLIP-ViT) on standardized medical VQA datasets to empirically validate performance claims and identify optimal choices for specific medical imaging modalities.

2. Implement and evaluate multiple hallucination mitigation strategies (RAG, knowledge distillation, uncertainty quantification) on clinical text generation tasks, measuring both reduction in hallucinations and impact on overall model performance.

3. Design a longitudinal study comparing model performance on benchmark datasets versus real-world clinical deployment, tracking metrics like diagnostic accuracy, user satisfaction, and error rates across different healthcare settings.