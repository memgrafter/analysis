---
ver: rpa2
title: ID-centric Pre-training for Recommendation
arxiv_id: '2405.03562'
source_url: https://arxiv.org/abs/2405.03562
tags:
- recommendation
- sequential
- pre-trained
- information
- pre-training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of transferring knowledge from
  pre-trained ID embeddings to new domains in sequential recommendation. The core
  idea is to build an ID-centric pre-training framework (IDP) that leverages textual
  information as a bridge to connect multi-domain item IDs.
---

# ID-centric Pre-training for Recommendation

## Quick Facts
- arXiv ID: 2405.03562
- Source URL: https://arxiv.org/abs/2405.03562
- Authors: Yiqing Wu; Ruobing Xie; Zhao Zhang; Fuzhen Zhuang; Xu Zhang; Leyu Lin; Zhanhui Kang; Yongjun Xu
- Reference count: 40
- Key outcome: IDP significantly outperforms all baselines in both cold and warm settings for cross-domain sequential recommendation

## Executive Summary
This paper introduces ID-centric Pre-training (IDP), a framework for cross-domain sequential recommendation that addresses the challenge of transferring knowledge from pre-trained ID embeddings to new domains. IDP leverages textual information as a bridge to connect multi-domain item IDs, using a Cross-domain ID Matcher (CDIM) that considers both behavioral and textual correlations. The framework pre-trains an ID-based sequential model and uses CDIM to retrieve behaviorally and semantically similar items from pre-training domains, generating new item embeddings for the target domain. Extensive experiments demonstrate that IDP significantly outperforms existing methods in both cold-start and warm settings.

## Method Summary
IDP consists of two stages: pre-training and tuning. In the pre-training stage, an ID-based sequential model (SASRec) is trained on multi-domain data, while CDIM is trained with contrastive learning to align textual representations with behavioral patterns. CDIM uses a SimCSE backbone to encode textual information and incorporates both textual and behavior-involved contrastive learning. During tuning, CDIM retrieves top-m behaviorally and semantically similar items from pre-training domains for each target domain item, and their ID embeddings are aggregated to generate new item embeddings. The sequential model is then fine-tuned on the target domain using these generated embeddings. This approach preserves the behavioral information in ID embeddings while leveraging textual information to bridge domains.

## Key Results
- IDP achieves substantial improvements over baselines when downstream datasets are reduced in scale
- The model demonstrates significant performance gains in both cold and warm settings
- ID embeddings are shown to be more effective than modality-based embeddings for sequential recommendation tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-domain ID embeddings can be effectively generated by using textual information as a bridge to retrieve behaviorally and semantically similar items from pre-training domains.
- Mechanism: CDIM uses both textual similarity and behavioral similarity to find top-m similar items from pre-training domains, then aggregates their ID embeddings to form new item embeddings in the target domain.
- Core assumption: Items with similar textual descriptions and similar behavioral patterns will have useful ID embeddings that can be transferred across domains.
- Evidence anchors:
  - [abstract]: "We first leverage the textual information of downstream domain items to retrieve behaviorally and semantically similar items from pre-training domains using CDIM."
  - [section 3.4]: "With the help of CDIM, we can measure the similarity of items by textual information."
- Break condition: If textual similarity does not correlate with behavioral similarity in the target domain, the retrieved ID embeddings will be poor proxies for the new items.

### Mechanism 2
- Claim: Pre-trained ID embeddings contain more valuable behavioral information for sequential recommendation than modality-based embeddings alone.
- Mechanism: IDP directly transfers ID embeddings learned from user-item interactions rather than replacing them with textual embeddings, preserving the rich behavioral patterns.
- Core assumption: ID embeddings trained on large-scale user behavior data encode more relevant recommendation signals than general-purpose textual embeddings from PLMs.
- Evidence anchors:
  - [abstract]: "the behavioral information in ID embeddings is still verified to be dominating in PLM-based recommendation models compared to modality information"
- Break condition: If the pre-training domain lacks sufficient behavioral diversity or the downstream domain has fundamentally different user behavior patterns, transferred ID embeddings may be less useful.

### Mechanism 3
- Claim: Fine-tuning the pre-trained sequential model with generated ID embeddings significantly improves downstream recommendation performance, especially in data-scarce scenarios.
- Mechanism: The pre-trained ID embeddings provide a strong initialization for new items, allowing the model to learn faster and perform better with limited target domain data.
- Core assumption: Good initialization from pre-trained knowledge reduces the amount of target domain data needed for effective learning.
- Evidence anchors:
  - [abstract]: "Through extensive experiments on real-world datasets, both in cold and warm settings, we demonstrate that our proposed model significantly outperforms all baselines."
- Break condition: If the target domain data is sufficiently large, the benefit of pre-trained initialization may diminish or even cause negative transfer.

## Foundational Learning

- Concept: Contrastive learning for learning semantically meaningful representations
  - Why needed here: CDIM uses contrastive learning to align textual representations with behavioral patterns, ensuring that textual similarity reflects behavioral similarity in the recommendation context.
  - Quick check question: What is the difference between textual similarity and behavioral similarity in recommendation, and why must both be considered?

- Concept: Sequential recommendation modeling with attention mechanisms
  - Why needed here: The base sequential model (SASRec) uses self-attention to capture user preference patterns from behavior sequences, which is the foundation that IDP builds upon.
  - Quick check question: How does self-attention in SASRec differ from simple recurrent models for capturing sequential dependencies?

- Concept: Cross-domain recommendation and knowledge transfer
  - Why needed here: IDP addresses the challenge of transferring knowledge from pre-training domains to new domains without requiring overlapping users or items.
  - Quick check question: What are the main challenges in cross-domain recommendation, and how does using textual information as a bridge help overcome them?

## Architecture Onboarding

- Component map: Pre-train sequential model -> Train CDIM with contrastive learning -> Generate ID embeddings for target domain -> Fine-tune sequential model on target domain
- Critical path: Pre-train SASRec on multi-domain data → Train CDIM with SimCSE and behavior-involved contrastive learning → Generate new item embeddings using top-m similar pre-trained IDs → Fine-tune on downstream domain
- Design tradeoffs:
  - Using ID embeddings vs. modality embeddings: Preserves behavioral information but requires cross-domain bridging
  - CDIM complexity: Adding behavioral contrastive learning improves quality but increases training time
  - Model flexibility: Allowing different base and downstream models increases applicability but may reduce performance compared to specialized architectures
- Failure signatures:
  - Poor performance despite good pre-training: Likely indicates weak textual-behavioral correlation in CDIM
  - Negative transfer: May occur if pre-training domain is too dissimilar from target domain
  - High computational cost: Searching top-m similar items for all target items can be expensive
- First 3 experiments:
  1. Ablation test: Compare IDP with IDP w/o M (without CDIM) to verify CDIM's contribution
  2. Zero-shot test: Apply pre-trained model directly to target domain without fine-tuning
  3. Cross-platform test: Pre-train on one platform (e.g., Amazon) and test on another (e.g., MovieLens)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of IDP vary with different pre-training dataset sizes?
- Basis in paper: [inferred] The paper mentions using multi-domain datasets for pre-training but does not explore the impact of dataset size.
- Why unresolved: The paper does not provide ablation studies or experiments varying the size of the pre-training datasets.
- What evidence would resolve it: Experiments comparing IDP's performance using pre-training datasets of varying sizes (e.g., 25%, 50%, 75%, 100% of the full dataset) would show how sensitive IDP is to the amount of pre-training data.

### Open Question 2
- Question: Can IDP be extended to handle cross-domain recommendation where there are no overlapping items or users?
- Basis in paper: [explicit] The paper mentions that current cross-domain recommendation methods rely on overlapping users or items, which limits their universality.
- Why unresolved: The paper does not provide experiments or analysis on scenarios with no overlapping items or users between domains.
- What evidence would resolve it: Experiments demonstrating IDP's effectiveness in scenarios where there are no overlapping items or users between the pre-training and downstream domains would show its ability to handle this challenging case.

### Open Question 3
- Question: How does the performance of IDP compare to other cross-domain recommendation methods in terms of computational efficiency?
- Basis in paper: [inferred] The paper mentions that ID-based sequential modeling is more efficient than PLM-based models, but does not compare IDP's efficiency to other cross-domain recommendation methods.
- Why unresolved: The paper does not provide a detailed analysis of IDP's computational complexity or runtime compared to other methods.
- What evidence would resolve it: Experiments measuring the training and inference time of IDP compared to other cross-domain recommendation methods would provide insights into its computational efficiency.

## Limitations

- Cross-domain generalization gap: The effectiveness of CDIM's bridging mechanism depends heavily on the assumption that textual similarity correlates with behavioral similarity across domains.
- Hyperparameter sensitivity: Critical choices like the top-m value for similarity retrieval and the relative weights in the contrastive learning objectives are not thoroughly explored.
- Pre-training domain dependence: The method's success relies on having pre-training domains that are sufficiently similar to target domains.

## Confidence

- **High confidence**: The core architectural framework (IDP with pre-trained sequential model + CDIM for bridging) is well-defined and the experimental setup is reproducible.
- **Medium confidence**: The claims about ID embeddings being superior to modality-based embeddings are supported by ablation studies but lack direct comparative analysis with other embedding approaches.
- **Low confidence**: The generalization claims to zero-shot and few-shot settings need more extensive validation across diverse domain pairs and varying data scales.

## Next Checks

1. **Correlation analysis**: Measure and report the Spearman correlation between textual similarity and behavioral similarity scores in CDIM for each downstream domain to validate the bridging assumption.

2. **Hyperparameter sensitivity**: Conduct a grid search over top-m values (1-50) and report performance stability to identify optimal ranges and sensitivity to this critical parameter.

3. **Domain dissimilarity impact**: Systematically evaluate transfer performance when pre-training and target domains have varying degrees of overlap in item categories, measuring the degradation curve as dissimilarity increases.