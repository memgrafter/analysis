---
ver: rpa2
title: 'JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis'
arxiv_id: '2406.06111'
source_url: https://arxiv.org/abs/2406.06111
tags:
- jengan
- speech
- block
- vocoder
- signals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces JenGAN, a training strategy that applies
  stacked shifted low-pass filters to GAN-based vocoders to reduce aliasing and audible
  artifacts like tonal distortions. By enforcing shift-equivariance through time-domain
  shifting during training while preserving the original inference architecture, JenGAN
  effectively limits high-frequency signals and improves waveform quality.
---

# JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis

## Quick Facts
- arXiv ID: 2406.06111
- Source URL: https://arxiv.org/abs/2406.06111
- Reference count: 0
- Key outcome: JenGAN reduces aliasing and tonal artifacts in GAN-based vocoders by enforcing shift-equivariance through stacked shifted sinc filters during training, improving waveform quality across multiple metrics.

## Executive Summary
JenGAN introduces a training strategy for GAN-based neural vocoders that applies stacked shifted low-pass filters to reduce aliasing and audible artifacts like tonal distortions. By enforcing shift-equivariance through time-domain shifting during training while preserving the original inference architecture, JenGAN effectively limits high-frequency signals and improves waveform quality. Experiments on HiFi-GAN, Avocodo, and BigVGAN models show consistent performance gains across metrics such as MAE, M-STFT, PESQ, MCD, V/UV F1, periodicity, and pitch error. Mel-spectrogram visualizations confirm clearer harmonic patterns and more natural-sounding speech, with JenGAN outperforming PhaseAug on full datasets and delivering significant improvements especially on smaller training sets.

## Method Summary
JenGAN is an anti-aliasing training strategy for GAN-based neural vocoders that applies stacked shifted sinc filters during training to enforce shift-equivariance. The method wraps each generator and discriminator block with channel-wise 1D convolutions using sinc kernels, where the shift parameter δ is randomly sampled from a discrete distribution (e.g., {-2,-1,0,1,2}) at each training step. This process constrains high-frequency content and approximates continuous-domain behavior while preserving the original model architecture for fast inference. The approach is applied to HiFi-GAN, Avocodo, and BigVGAN models trained on the LJSpeech dataset.

## Key Results
- JenGAN consistently improves objective metrics (MAE, M-STFT, PESQ, MCD, V/UV F1, periodicity, pitch error) across HiFi-GAN, Avocodo, and BigVGAN models.
- Mel-spectrogram visualizations show clearer harmonic patterns and more natural-sounding speech compared to baselines.
- JenGAN outperforms PhaseAug on full datasets and delivers significant improvements especially on smaller training sets (1% LJSpeech).
- The method preserves inference speed by maintaining the original model architecture while modifying only the training process.

## Why This Works (Mechanism)

### Mechanism 1
Applying shifted sinc filters during training enforces shift-equivariance in discrete blocks, which reduces aliasing in generated waveforms. The sinc filter convolution convolves the input and output of each block with a shifted sinc kernel, where the shift is sampled from a distribution (uniform, normal, or discrete). This approximates continuous-domain behavior, constraining high-frequency content and preventing aliasing. The core assumption is that aliasing artifacts arise from non-shift-equivariant behavior in discrete-domain blocks; constraining frequency via shift-equivariance reduces these artifacts.

### Mechanism 2
Keeping the model architecture unchanged during inference ensures fast generation and simplifies fine-tuning. Training with shifted filters modifies block behavior in the forward pass but the model structure (weights, architecture) remains identical to baseline. During inference, δ=0 so the sinc filters are effectively bypassed. The core assumption is that the learned weights from shifted-filter training implicitly encode frequency constraints, so no architectural change is needed at inference.

### Mechanism 3
Random δ sampling during training improves generalization across different time shifts and prevents overfitting to a single shift value. Each training step samples a new δ from a distribution, causing the model to learn behavior consistent across multiple temporal shifts. This enforces robustness to phase shifts. The core assumption is that shift-equivariant behavior across a range of δ improves the model's ability to handle real-world input variations without artifacts.

## Foundational Learning

- Concept: Shift-equivariance in signal processing
  - Why needed here: Ensures that shifting input by δ and output by -δ leaves the system behavior unchanged, preventing aliasing artifacts in discrete convolutions.
  - Quick check question: If a system is shift-equivariant, what happens to the output when the input is shifted by δ and the output is shifted by -δ?

- Concept: Sinc function as ideal low-pass filter
  - Why needed here: The sinc kernel acts as a band-limiting filter in the frequency domain; using shifted sinc filters during training approximates continuous-domain behavior.
  - Quick check question: What is the frequency response of a sinc function in the ideal case?

- Concept: Aliasing and the Nyquist–Shannon sampling theorem
  - Why needed here: Downsampling without band-limiting causes high-frequency components to alias into lower frequencies, creating audible artifacts; the method aims to prevent this.
  - Quick check question: At what frequency must a signal be band-limited to avoid aliasing when downsampling by a factor of r?

## Architecture Onboarding

- Component map: Mel-spectrogram -> Generator (HiFi-GAN MRF blocks + ConvTranspose) -> Sinc filters -> Discriminator (MRF blocks) -> Sinc filters -> Loss computation
- Critical path: Training loop: Sample δ → apply sinc filter to input → run block → apply sinc filter to output → compute loss. Inference loop: Run block directly (δ=0).
- Design tradeoffs: Using sinc filters adds computation during training but preserves inference speed. Random δ sampling improves robustness but may slow convergence if too noisy. Only modifying training strategy avoids architectural complexity but may limit maximum artifact reduction.
- Failure signatures: Increased MAE/M-STFT if sinc filter length too short. Performance collapse if δ distribution too wide or poorly chosen. Training instability if sinc filters applied inconsistently across generator/discriminator.
- First 3 experiments: 1) Train HiFi-GAN baseline vs JenGAN with discrete δ sampling; compare MAE and mel-spectrogram quality. 2) Vary sinc filter length (e.g., ±12 vs ±24 samples) and observe effect on artifact reduction. 3) Test JenGAN on a smaller dataset (1%) to confirm improvement over PhaseAug in low-data regime.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of JenGAN vary when applied to different neural vocoder architectures beyond HiFi-GAN, Avocodo, and BigVGAN? The paper mentions that JenGAN enhances the performance of these three models but does not explore its effects on other vocoder architectures. Empirical results showing the performance of JenGAN when applied to a diverse set of neural vocoder architectures, including both GAN-based and non-GAN-based models, would resolve this question.

### Open Question 2
What is the impact of JenGAN on real-time inference speed and computational efficiency in resource-constrained environments? While the paper emphasizes that JenGAN preserves the model structure during inference, leading to fast inference speeds, it does not provide detailed analysis on computational efficiency or performance in resource-constrained settings. Comparative studies measuring inference speed and computational resource usage of JenGAN against other anti-aliasing methods in various hardware configurations would resolve this question.

### Open Question 3
How does the choice of shifting value sampling method affect the generalization and robustness of JenGAN across different datasets and speech conditions? The paper discusses three shifting value sampling methods (uniform, normal, and discrete distributions) and their impact on performance but does not explore their effects on generalization across diverse datasets or speech conditions. Experimental results demonstrating the performance of JenGAN with different sampling methods across multiple datasets and speech conditions, including varying speakers, accents, and noise levels, would resolve this question.

## Limitations

- The generalizability of the sinc-filter shifting method across different speech synthesis architectures and datasets beyond the tested models and LJSpeech data remains unclear.
- The ablation study on δ distributions shows discrete sampling performs best, but the theoretical justification for why continuous or asynchronous shifts fail is not fully explained.
- The paper does not provide a detailed analysis of computational overhead during training or investigate the impact of sinc filter length beyond the chosen ±12 samples.

## Confidence

**High Confidence:** The core claim that shift-equivariance enforced via sinc filtering reduces aliasing artifacts is well-supported by objective metrics (MAE, M-STFT, PESQ) and visual inspection of mel-spectrograms. The ablation on δ sampling distributions and the consistent improvements across three different GAN-based vocoders strengthen this claim.

**Medium Confidence:** The assertion that JenGAN outperforms PhaseAug on smaller datasets is supported by the 1% LJSpeech results, but the comparison is limited to one baseline and one dataset split. The claim about inference speed preservation is plausible given the architecture remains unchanged, but no explicit timing measurements are provided.

**Low Confidence:** The explanation of why asynchronous shifting between real and generated signals degrades performance is not empirically validated beyond a single ablation. The assumption that learned weights alone encode frequency constraints without architectural changes at inference is not directly tested.

## Next Checks

1. Apply JenGAN to a non-GAN vocoder (e.g., WaveGlow or WaveNet) and evaluate whether the shift-equivariance benefits transfer to likelihood-based models.

2. Train and evaluate JenGAN on a multi-speaker dataset (e.g., VCTK) and a noisy, real-world dataset (e.g., Librispeech) to test generalization beyond clean, single-speaker speech.

3. Systematically vary the sinc filter length (e.g., ±6, ±12, ±24 samples) and δ sampling distribution (continuous vs discrete) to identify the optimal configuration and confirm that the chosen parameters are not coincidentally good.