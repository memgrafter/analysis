---
ver: rpa2
title: Explainability of Deep Learning-Based Plant Disease Classifiers Through Automated
  Concept Identification
arxiv_id: '2412.07408'
source_url: https://arxiv.org/abs/2412.07408
tags:
- disease
- plant
- concepts
- learning
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study applies the Automated Concept-based Explanation (ACE)
  method to improve explainability in deep learning-based plant disease classification
  using the InceptionV3 model and PlantVillage dataset. ACE automatically identifies
  high-level visual concepts from images and quantifies their importance in model
  predictions.
---

# Explainability of Deep Learning-Based Plant Disease Classifiers Through Automated Concept Identification

## Quick Facts
- arXiv ID: 2412.07408
- Source URL: https://arxiv.org/abs/2412.07408
- Authors: Jihen Amara; Birgitta König-Ries; Sheeba Samuel
- Reference count: 33
- Primary result: ACE successfully identifies disease-specific visual concepts and reveals dataset biases in plant disease classification using InceptionV3 and PlantVillage dataset

## Executive Summary
This study applies the Automated Concept-based Explanation (ACE) method to improve explainability in deep learning-based plant disease classification using the InceptionV3 model and PlantVillage dataset. ACE automatically identifies high-level visual concepts from images and quantifies their importance in model predictions. The experiments revealed that ACE successfully captured disease-specific patterns and healthy leaf features, such as vein patterns. However, it also uncovered undesirable correlations with background and shadow elements, indicating dataset biases. These findings highlight ACE's potential to enhance model transparency, detect biases, and improve the reliability of plant disease classification, offering valuable insights for agricultural experts and model developers.

## Method Summary
The study fine-tunes an InceptionV3 model pretrained on ImageNet for plant disease classification using the PlantVillage dataset of 54,323 images across 14 crops and 38 diseases. The model architecture freezes the first 52 convolutional layers while fine-tuning subsequent layers with SGD optimizer (learning rate 0.0001, momentum 0.9). Data augmentation includes random rotations, zooms, translations, shears, and flips. ACE is then applied to extract visual concepts by segmenting images at multiple resolutions using SLIC, extracting CNN activations, clustering segments with k-means, and computing TCAV scores to quantify concept importance for model predictions.

## Key Results
- ACE successfully identified disease-specific visual concepts and healthy leaf features like vein patterns
- The method revealed undesirable correlations with background and shadow elements, indicating dataset biases
- Concept analysis showed consistent disease patterns across different plant species for some diseases while revealing plant-specific variations for others

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ACE identifies disease-specific visual concepts by clustering similar image segments using k-means on CNN activations.
- Mechanism: The method segments images at multiple resolutions with SLIC, extracts activations from a trained CNN, clusters segments by similarity, and ranks concepts by TCAV scores. This creates interpretable, concept-level explanations for model decisions.
- Core assumption: CNN activations at intermediate layers provide meaningful perceptual similarity space for plant disease image segments.
- Evidence anchors:
  - [section] "Using k-means clustering, concept patches are gathered into meaningful concept clusters" and "TCAV scores...for each concept is computed to retrieve the most significant ones"
  - [abstract] "ACE automatically identifies the visual concepts found in the image data and provides insights about the critical features influencing the model predictions"
- Break condition: If activations don't capture disease-relevant features or if segments are too heterogeneous for clustering to produce coherent concepts.

### Mechanism 2
- Claim: ACE reveals dataset biases by showing the model relies on non-disease features like background and shadows.
- Mechanism: By analyzing high-TCAV concepts across classes, researchers identify correlations between predictions and image elements that shouldn't influence classification, such as uniform backgrounds or leaf shadows.
- Core assumption: High-TCAV concepts reflect features the model actually uses for classification, not just correlation.
- Evidence anchors:
  - [section] "Another bias that was identified through the discovered concepts is the shadow of the leaves on the background" and "Background bias... the model mistakenly associates certain background colors or patterns with specific classes"
  - [abstract] "This approach reveals both effective disease-related patterns and incidental biases, such as those from background or lighting"
- Break condition: If TCAV scores don't accurately reflect feature importance or if background effects are already corrected in preprocessing.

### Mechanism 3
- Claim: ACE helps improve model generalization by identifying under-represented disease patterns across plant species.
- Mechanism: By comparing concepts for the same disease in different plants, ACE shows whether the model captures disease-specific patterns or is influenced by plant-specific features, guiding dataset improvement.
- Core assumption: Similar diseases should produce similar high-TCAV concepts regardless of plant species.
- Evidence anchors:
  - [section] "Another interesting thing is to investigate the concepts the model used when identifying the same type of disease but in different types of plants" and "Late blight in Tomato manifest more as pale green patches... while for Potato, symptoms are more dark brown patches"
  - [abstract] "This approach reveals both effective disease-related patterns... and incidental biases"
- Break condition: If disease manifestations vary too much between species for a single pattern to be useful, or if the model has learned to use species-specific cues.

## Foundational Learning

- Concept: Concept Activation Vectors (CAVs) and TCAV scores
  - Why needed here: Understanding how ACE quantifies concept importance through directional derivatives and statistical significance is crucial for interpreting results
  - Quick check question: How does a TCAV score of 1.0 differ from a score of 0.5 in terms of concept influence?

- Concept: Multi-resolution image segmentation with SLIC
  - Why needed here: ACE's effectiveness depends on creating meaningful segments at different scales to capture both fine details and broader patterns
  - Quick check question: Why does ACE use three levels of segmentation instead of just one?

- Concept: Transfer learning with fine-tuning
  - Why needed here: The study uses InceptionV3 pre-trained on ImageNet, and understanding this approach helps explain why certain concepts are found and how the model adapts to plant disease classification
  - Quick check question: Why freeze the first 52 convolutional layers when fine-tuning on plant disease images?

## Architecture Onboarding

- Component map: PlantVillage dataset → preprocessing → augmentation → InceptionV3 (fine-tuned) → ACE concept extraction → TCAV scoring → evaluation
- Critical path: Dataset → model training → ACE concept extraction → TCAV scoring → bias identification and interpretation
- Design tradeoffs:
  - ACE computational cost vs. interpretability gain
  - Segmentation resolution vs. concept coherence
  - TCAV statistical significance threshold vs. concept coverage
- Failure signatures:
  - Low concept coherence: k-means produces fragmented or nonsensical clusters
  - High background concept scores: model relies on non-disease features
  - Inconsistent concepts across species: model hasn't learned disease-specific patterns
- First 3 experiments:
  1. Run ACE on a single well-represented disease class to verify concept extraction works and produces meaningful disease-related patterns
  2. Compare TCAV scores for healthy vs. diseased leaves to ensure model distinguishes them correctly
  3. Test ACE on a disease affecting multiple plant species to see if consistent disease patterns are identified

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is ACE at identifying and mitigating dataset biases, such as background or shadow bias, in real-world agricultural applications beyond controlled datasets?
- Basis in paper: [explicit] The paper demonstrates ACE's ability to detect biases like background and shadow effects, but these findings are based on the PlantVillage dataset.
- Why unresolved: The paper does not test ACE's performance on datasets with more diverse or uncontrolled environments, such as those with varying lighting, backgrounds, or real-world noise.
- What evidence would resolve it: Testing ACE on larger, more diverse datasets with real-world conditions (e.g., field images with varying backgrounds, lighting, and weather) and evaluating its effectiveness in reducing biases and improving model accuracy.

### Open Question 2
- Question: Can ACE be effectively integrated into real-time tools for interactive exploration and validation of concept clusters by end-users, such as farmers or agricultural experts?
- Basis in paper: [explicit] The paper suggests future work on integrating ACE into a real-time tool for users to explore and validate concept clusters interactively.
- Why unresolved: The paper does not provide a prototype or evaluate the usability and effectiveness of such a tool in practical settings.
- What evidence would resolve it: Developing and testing an interactive ACE-based tool with end-users to assess its usability, interpretability, and impact on decision-making in agricultural practices.

### Open Question 3
- Question: How does ACE compare to other explainability methods, such as Grad-CAM or TCAV, in terms of interpretability and effectiveness for plant disease classification?
- Basis in paper: [inferred] The paper highlights ACE's advantages over visual-based methods like Grad-CAM but does not directly compare ACE to other concept-based methods like TCAV.
- Why unresolved: The paper does not provide a comparative analysis of ACE with other explainability methods, leaving its relative effectiveness unclear.
- What evidence would resolve it: Conducting a comparative study of ACE, Grad-CAM, and TCAV on the same dataset to evaluate their interpretability, accuracy in identifying key concepts, and ability to detect biases.

## Limitations
- The study relies on the controlled PlantVillage dataset, which may not reflect real-world agricultural conditions with diverse backgrounds and lighting
- ACE's assumption that CNN activations capture disease-relevant features isn't directly validated through perturbation studies
- The method identifies correlations between concepts and predictions but doesn't establish true causal relationships without additional experimentation

## Confidence

**High Confidence:**
- ACE successfully extracts interpretable visual concepts from plant disease images
- The method works technically as described
- Background and shadow biases exist in the PlantVillage dataset

**Medium Confidence:**
- ACE-identified concepts accurately represent what the model uses for classification
- Identified biases meaningfully impact real-world performance
- The approach generalizes to other agricultural datasets

## Next Checks
1. Systematically occlude high-TCAV concept regions in test images and measure changes in model predictions to establish causal relationships between identified concepts and classification decisions.

2. Apply ACE to plant disease datasets with more diverse backgrounds, lighting conditions, and image acquisition methods to verify whether identified biases are dataset-specific or generalizable.

3. Implement simple preprocessing techniques (background removal, shadow correction) and retrain models to measure whether ACE-identified biases can be effectively mitigated and how this affects concept extraction.