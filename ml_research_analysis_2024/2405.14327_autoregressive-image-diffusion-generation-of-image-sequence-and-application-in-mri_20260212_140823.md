---
ver: rpa2
title: 'Autoregressive Image Diffusion: Generation of Image Sequence and Application
  in MRI'
arxiv_id: '2405.14327'
source_url: https://arxiv.org/abs/2405.14327
tags:
- image
- images
- data
- should
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents the autoregressive image diffusion (AID) model
  for generating image sequences and applying it to accelerated MRI reconstruction.
  AID combines autoregressive modeling with diffusion models to capture inter-image
  dependencies in sequences.
---

# Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI

## Quick Facts
- arXiv ID: 2405.14327
- Source URL: https://arxiv.org/abs/2405.14327
- Reference count: 40
- Primary result: Autoregressive image diffusion (AID) improves sequential image generation and MRI reconstruction by capturing inter-image dependencies, reducing hallucinations and folding artifacts.

## Executive Summary
This paper introduces autoregressive image diffusion (AID), a novel model that extends diffusion models to sequential image generation and accelerated MRI reconstruction. AID combines autoregressive modeling with diffusion processes, conditioning each image generation on previously generated images through temporal-spatial conditioning blocks. The model is evaluated on fastMRI and cardiac datasets, demonstrating superior performance in generating sequentially coherent images and reconstructing undersampled MRI data compared to standard diffusion models.

## Method Summary
AID is an autoregressive diffusion model that factorizes joint image distributions into conditional probabilities using temporal-spatial conditioning blocks. The model is trained on MRI datasets with objectives based on negative log-likelihood, and during inference uses DDIM sampling combined with data fidelity steps for MRI reconstruction. The architecture incorporates causal attention to ensure autoregressive property, and can operate in both pixel and latent space (via VQ-VAE for cardiac data). Training uses Adam optimizer with learning rate 1e-4 for 440k iterations on 4 A100 GPUs.

## Key Results
- AID outperforms standard diffusion models in generating sequentially coherent image sequences
- The model reduces hallucinations in MRI reconstruction, achieving higher PSNR and lower NRMSE
- AID effectively reduces folding artifacts in single-coil unfolding experiments
- Performance gains are consistent across various sampling masks including random and equispaced patterns

## Why This Works (Mechanism)

### Mechanism 1
Autoregressive diffusion improves sequential coherence by conditioning each image generation on the full history of previously generated images, capturing inter-image dependencies that standard diffusion models ignore. The temporal conditioning is implemented via causal attention mask in DiTBlock, ensuring future images cannot influence current prediction. During training, the model learns to predict noise conditioned on the sequence, and during generation, it iteratively refines each image while appending it to the conditioning sequence.

### Mechanism 2
Sampling the posterior with AID reduces folding artifacts in undersampled MRI reconstruction by integrating k-space likelihood with learned image priors. The posterior is sampled using a two-step gradient update: first a DDIM reverse step guided by the diffusion prior, then a data fidelity step using the k-space likelihood. This joint sampling ensures reconstruction respects both undersampled data constraints and learned inter-image coherence.

### Mechanism 3
Training AID in latent space via VQ-VAE improves computational efficiency while preserving sequence coherence for cardiac MRI. Images are first compressed into discrete latent codes using VQ-VAE, which learns a codebook of visually meaningful components. AID then models the autoregressive dependencies in this lower-dimensional latent space, reducing parameter count and training time.

## Foundational Learning

- **Diffusion probabilistic models and score matching**: AID builds on diffusion models by extending them to sequential data; understanding the reverse diffusion process and noise prediction is essential for implementing the training objective. *Quick check*: In a standard DDPM, what is the role of the noise schedule β_t and how does it affect the quality of the reverse process?

- **Autoregressive modeling and causal attention**: AID's key innovation is autoregressive conditioning; causal attention ensures that each generated image only depends on previous ones, preserving temporal coherence. *Quick check*: How does the causal mask in the attention matrix enforce the autoregressive property during both training and generation?

- **Bayesian inverse problems and posterior sampling**: MRI reconstruction is formulated as sampling from the posterior p(x|y); understanding likelihood functions and posterior sampling algorithms (e.g., DDIM + data fidelity) is critical for applying AID to reconstruction tasks. *Quick check*: In the context of undersampled MRI, what is the mathematical form of the k-space likelihood function and how does it relate to the measurement noise model?

## Architecture Onboarding

- **Component map**: Images → Encoder blocks → TSC blocks (causal attention) → Noise prediction (training) or → Decoder blocks → TSC blocks → Clean images (generation)
- **Critical path**: During training, images flow from conditioning sequence → TSC blocks (causal attention) → Encoder blocks → Noise prediction. During generation, noisy latents → Decoder blocks → TSC blocks → Clean images appended to conditioning sequence.
- **Design tradeoffs**: Sequence length N vs. memory (longer sequences increase memory quadratically due to attention), Latent space vs. pixel space (latent space reduces computation but may lose fine details), Number of diffusion steps T vs. quality (more steps improve sample quality but increase generation time).
- **Failure signatures**: Mode collapse (generated sequences lack diversity, indicating poor training or insufficient data), Inconsistent conditioning (if causal mask is broken, future images influence current predictions), Poor reconstruction (high NRMSE/PSNR indicates mismatch between learned prior and target distribution).
- **First 3 experiments**: 1) Train AID on a small synthetic sequence dataset (e.g., moving MNIST) and verify that generated sequences show temporal coherence. 2) Implement the posterior sampling algorithm (Algorithm 1) and test on a simple undersampled MRI reconstruction task with known ground truth. 3) Compare AID reconstruction quality (PSNR, NRMSE) against standard diffusion model on fastMRI validation set using the same sampling masks.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of AID scale with increasing sequence length in both image generation and MRI reconstruction tasks? The paper mentions different sequence lengths used for brain (10) and cardiac (42) datasets but doesn't explore performance across varying lengths.

### Open Question 2
What is the impact of different sampling masks on AID's reconstruction quality compared to other generative models? While the paper shows AID outperforms Guide and CSGM, it doesn't break down performance by mask type or explore why certain masks perform better.

### Open Question 3
How does AID's computational efficiency compare to standard diffusion models when generating sequences of different lengths? While some speed metrics are provided, there's no systematic comparison of computational requirements between AID and standard diffusion models.

## Limitations
- The assumption that inter-image dependencies are statistically learnable and beneficial may not hold for all MRI sequences, particularly those with low temporal correlation
- The effectiveness of the VQ-VAE latent space for cardiac MRI is not empirically validated in the provided text
- The claim that AID reduces folding artifacts relies on the assumption that the learned prior accurately represents the true image distribution, which is not directly tested

## Confidence

- Mechanism 1 (Autoregressive conditioning for sequential coherence): **Medium**
- Mechanism 2 (Posterior sampling for artifact reduction): **Medium**
- Mechanism 3 (Latent space efficiency for cardiac MRI): **Low**

## Next Checks

1. Implement the exact TSC block architecture and verify that the causal attention mask prevents information flow from future images to current predictions during generation.
2. Conduct ablation studies comparing AID with and without autoregressive conditioning on datasets with varying levels of inter-image correlation to quantify the benefit of learned dependencies.
3. Test the model's performance on an out-of-distribution MRI dataset (e.g., different scanner parameters or anatomies) to assess the generalizability of the learned prior and identify potential bias in artifact reduction.