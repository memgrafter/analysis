---
ver: rpa2
title: Federated Unsupervised Domain Generalization using Global and Local Alignment
  of Gradients
arxiv_id: '2405.16304'
source_url: https://arxiv.org/abs/2405.16304
tags:
- domain
- learning
- federated
- local
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new problem called federated unsupervised
  domain generalization and proposes a novel method called FedGaLA. The core idea
  of FedGaLA is to align gradients at both the local and global levels to encourage
  clients to learn domain-invariant features and obtain a more generalized aggregated
  model.
---

# Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients

## Quick Facts
- arXiv ID: 2405.16304
- Source URL: https://arxiv.org/abs/2405.16304
- Reference count: 33
- Primary result: FedGaLA achieves 64.7% accuracy on PACS with 10% labeled data versus 64.2% for best baseline

## Executive Summary
This paper introduces a new problem called federated unsupervised domain generalization and proposes FedGaLA, a method that aligns gradients at both local and global levels. The approach aims to encourage clients to learn domain-invariant features by discarding gradients misaligned with the global learning direction and weighting client contributions during aggregation based on gradient alignment. The authors establish a theoretical connection between domain shift and gradient alignment in unsupervised federated learning. Experiments on four datasets demonstrate that FedGaLA outperforms comparable baselines, with the most notable improvement being 64.7% accuracy versus 64.2% for the best baseline on PACS with 10% labeled data.

## Method Summary
FedGaLA is a federated learning method for unsupervised domain generalization that uses SimCLR-based self-supervised learning. During local training, each client computes a reference gradient from the difference between current and previous global model parameters. Batch gradients with cosine similarity below threshold τ to this reference are discarded. At the server level, client updates are weighted by their cosine similarity to the average gradient, with weights computed as w_i = cos(g_i, g_+) + 1/2 and normalized across clients. The weighted updates are aggregated iteratively over 3 rounds. The method uses ResNet-18 encoder, Adam optimizer (lr=3e-3), batch size 128, 7 local epochs per communication round over 100 rounds.

## Key Results
- FedGaLA achieves 64.7% accuracy on PACS with 10% labeled data versus 64.2% for best baseline
- Outperforms comparable baselines on four datasets: PACS, OfficeHome, DomainNet, and TerraInc
- Local gradient alignment with τ=0 performs best; increasing τ degrades performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Discarding gradients misaligned with global learning direction encourages domain-invariant feature learning
- Core assumption: Global model updates represent domain-invariant learning direction clients should follow
- Evidence anchors: Abstract mentions discarding gradients not aligned with reference gradient; section explains preventing domain-specific feature learning
- Break condition: If global model is biased toward certain domains, discarding misaligned gradients could eliminate useful information

### Mechanism 2
- Claim: Weighting client contributions by gradient alignment during aggregation improves global model generalization
- Core assumption: Clients with gradients aligned with average gradient are learning more generalizable features
- Evidence anchors: Abstract mentions aggregation based on alignment; section details cosine similarity weighting formula
- Break condition: If all clients have similar domain shifts, gradient alignment weighting may not provide additional benefit

### Mechanism 3
- Claim: Theoretical connection between gradient alignment and domain shift provides method foundation
- Core assumption: Relationship between gradient covariance and domain shift holds across distributions and architectures
- Evidence anchors: Abstract mentions detailed theoretical framework; section states findings provide basis for effective updates
- Break condition: If relationship breaks down for certain data distributions or model architectures

## Foundational Learning

- Concept: Federated learning and data heterogeneity
  - Why needed: Method operates in federated setting with different client data distributions
  - Quick check: What is the primary challenge in federated learning when clients have different data distributions?

- Concept: Domain generalization and unsupervised learning
  - Why needed: Problem combines federated learning with unsupervised domain generalization
  - Quick check: How does unsupervised domain generalization differ from supervised domain generalization?

- Concept: Gradient-based optimization and alignment
  - Why needed: Method relies on gradient alignment at client and server levels
  - Quick check: What does it mean for two gradients to be "aligned" in optimization?

## Architecture Onboarding

- Component map: Client training with SSL → Gradient alignment against reference → Server aggregation with alignment weighting → Global update → Parameter distribution
- Critical path: Client training → Gradient alignment → Server aggregation → Global update → Parameter distribution
- Design tradeoffs:
  - Local threshold τ: Higher thresholds discard more gradients but may lose useful information
  - Global aggregation iterations: More iterations refine weights but increase computation
  - Communication frequency: More frequent communication improves alignment but increases communication cost
- Failure signatures:
  - Performance plateaus early: May indicate insufficient gradient discarding or poor threshold selection
  - Performance degrades with more communication rounds: Could suggest over-alignment or loss of domain diversity
  - Sensitivity to initialization: Might indicate instability in gradient alignment mechanism
- First 3 experiments:
  1. Baseline comparison: Implement FedSimCLR without alignment mechanisms
  2. Local alignment only: Implement FedGaLA with only local gradient alignment
  3. Global alignment only: Implement FedGaLA with only global gradient weighting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedGaLA perform under more extreme domain shifts where mutual information approaches zero between source domains?
- Basis: Paper establishes theoretical connection between domain shift and gradient alignment, noting decreased mutual information as domains shift apart
- Why unresolved: Experiments use moderate domain shifts from standard datasets; testing under extreme shifts would validate gradient alignment effectiveness
- What evidence would resolve it: Experiments comparing FedGaLA performance on datasets with progressively increasing domain shifts

### Open Question 2
- Question: Can theoretical framework be extended to federated supervised domain generalization beyond logistic regression?
- Basis: Paper states findings may apply to supervised domain generalization and provides proof for logistic regression
- Why unresolved: Proof only covers logistic regression; extending to deeper neural networks requires new theoretical development
- What evidence would resolve it: Formal proof demonstrating gradient alignment relationship for supervised learning with arbitrary neural networks

### Open Question 3
- Question: What is optimal threshold τ for local gradient alignment across different SSL methods and dataset characteristics?
- Basis: Paper shows τ=0 performs best for SimCLR-based FedGaLA but only tests τ=-0.1, 0, and 0.1
- Why unresolved: Optimal threshold may vary based on dataset characteristics, SSL method, and domain shift magnitude
- What evidence would resolve it: Systematic evaluation of local alignment threshold across multiple SSL methods and datasets

## Limitations

- Limited empirical validation of the theoretical connection between gradient covariance and domain shift
- Modest performance improvements (64.7% vs 64.2%) suggest limited practical impact
- Lack of ablation studies to isolate contributions of local versus global alignment mechanisms

## Confidence

- **Medium**: Core hypothesis that gradient alignment improves domain generalization, supported by theoretical framework but lacking direct empirical validation
- **Low**: Specific mechanism of discarding misaligned gradients, with no corpus evidence and unclear empirical validation
- **Medium**: Weighted aggregation mechanism, with some theoretical justification but no direct corpus evidence

## Next Checks

1. Conduct ablation studies to quantify individual contributions of local gradient discarding versus global weighted aggregation
2. Test method's sensitivity to gradient alignment threshold τ across different datasets and data distributions
3. Validate theoretical connection between gradient covariance and domain shift by measuring actual gradient covariance between clients