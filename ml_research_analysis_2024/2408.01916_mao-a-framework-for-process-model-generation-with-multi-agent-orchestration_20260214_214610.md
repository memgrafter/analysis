---
ver: rpa2
title: 'MAO: A Framework for Process Model Generation with Multi-Agent Orchestration'
arxiv_id: '2408.01916'
source_url: https://arxiv.org/abs/2408.01916
tags:
- process
- modeling
- bpmn
- language
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces MAO, a multi-agent framework that automatically\
  \ generates process models from textual requirements using large language models.\
  \ The framework employs four phases\u2014generation, refinement, reviewing, and\
  \ testing\u2014to collaboratively create BPMN models while addressing semantic and\
  \ format hallucinations."
---

# MAO: A Framework for Process Model Generation with Multi-Agent Orchestration

## Quick Facts
- arXiv ID: 2408.01916
- Source URL: https://arxiv.org/abs/2408.01916
- Reference count: 40
- Outperforms manual modeling by 89%, 61%, 52%, and 75% on four different datasets

## Executive Summary
MAO is a multi-agent framework that automatically generates BPMN process models from textual requirements using large language models. The framework employs four phases—generation, refinement, reviewing, and testing—to collaboratively create process models while addressing semantic and format hallucinations. Through specialized agent roles and structured collaboration, MAO demonstrates significant improvements over existing methods and manual modeling approaches.

## Method Summary
MAO uses a multi-agent orchestration approach with specialized agents (team leader, process reviewer, process design expert) working in four phases to generate BPMN models from textual requirements. The framework incorporates knowledge injection, few-shot learning, and Chain of Thought prompting to enhance agent performance. Semantic hallucinations are resolved through agent dialogue, while format hallucinations are detected using external tools. The system focuses on common BPMN elements including sequence flows, activities, and gateways.

## Key Results
- Outperforms existing methods on four different datasets
- Surpasses manual modeling by 89%, 61%, 52%, and 75% respectively
- Successfully handles both semantic and format hallucinations
- Demonstrates effectiveness across fine-grained and coarse-grained process descriptions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-agent orchestration improves process model quality by handling semantic and format hallucinations
- Mechanism: Specialized agents in four phases iteratively refine and validate BPMN models
- Core assumption: Structured multi-agent collaboration produces more accurate models than single-agent approaches
- Evidence anchors: Experiments show MAO outperforms existing methods and manual modeling by significant margins

### Mechanism 2
- Claim: Categorizing hallucinations enables targeted resolution without manual intervention
- Mechanism: Semantic hallucinations resolved through agent interactions, format hallucinations handled by external tools
- Core assumption: Categorization allows for automated resolution
- Evidence anchors: Agents autonomously repair process without manual intervention

### Mechanism 3
- Claim: Knowledge injection and few-shot learning enhance agent performance
- Mechanism: Agents receive BPMN knowledge, examples, and step-by-step prompting
- Core assumption: Domain-specific knowledge and examples improve LLM performance
- Evidence anchors: Integration of few-shot learning and Chain of Thought mechanisms

## Foundational Learning

- Concept: BPMN (Business Process Model and Notation)
  - Why needed here: Essential for designing and interpreting process models
  - Quick check question: What are the main BPMN elements used in the MAO framework?

- Concept: Large Language Models (LLMs) and Prompt Engineering
  - Why needed here: Core technology behind MAO's agents
  - Quick check question: How does Chain of Thought prompting improve LLM performance in MAO?

- Concept: Multi-Agent Systems
  - Why needed here: MAO relies on multiple agents with specialized roles
  - Quick check question: What are the roles of the agents in the MAO framework, and how do they interact?

## Architecture Onboarding

- Component map:
  Team Leader Agent -> Process Design Expert Agent -> Process Reviewer Agent -> External Tools

- Critical path: User requirements → Team Leader instruction → Process Design Expert generation → Refinement → Process Reviewer semantic review → External tools format check → Final BPMN model

- Design tradeoffs:
  - Multiple agents add complexity but improve quality through specialization
  - External tools are necessary for format checking but introduce dependencies
  - Focus on subset of BPMN elements simplifies task but limits applicability

- Failure signatures:
  - Poor model quality from ineffective agent coordination
  - Persistent hallucinations from incomplete categorization or tool failures
  - Performance degradation from LLM issues or inefficient orchestration

- First 3 experiments:
  1. Test MAO on simple BPMN model with sequential activities to validate basic functionality
  2. Introduce semantic hallucination and verify Process Reviewer can detect and suggest fix
  3. Introduce format hallucination and verify external tools can detect and report error

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do multi-agent systems handle the tradeoff between semantic and format hallucinations during process model generation?
- Basis in paper: Paper discusses different approaches for semantic (agent dialogue) versus format (external tools) hallucinations
- Why unresolved: No quantitative data on frequency, impact, or resolution effectiveness
- What evidence would resolve it: Comparative metrics showing hallucination frequency and resolution effectiveness

### Open Question 2
- Question: What is the optimal team composition and role distribution for multi-agent process modeling in different domains?
- Basis in paper: Paper uses fixed three-agent structure without exploring alternatives
- Why unresolved: Only uses one team structure, doesn't investigate variations
- What evidence would resolve it: Comparative studies testing different agent configurations

### Open Question 3
- Question: How do multi-agent systems scale when generating process models with more complex BPMN elements?
- Basis in paper: Paper acknowledges LLM limitations for complex BPMN elements
- Why unresolved: Paper deliberately limits to basic elements
- What evidence would resolve it: Performance metrics with advanced BPMN elements

## Limitations

- Reliance on GPT-4 and external tools introduces dependencies that may limit reproducibility
- Specific prompt templates and examples are not provided, making exact replication difficult
- Framework focuses on subset of BPMN elements and doesn't address complex features like subprocesses or message flows

## Confidence

High: Overall effectiveness of multi-agent framework in generating BPMN models from textual requirements
Medium: Mechanisms for hallucination detection and repair, though specific tools are not detailed
Low: Reproducibility of exact prompt strategies due to missing specific templates and examples

## Next Checks

1. Reproduce the basic framework: Set up multi-agent environment with three roles using GPT-4 and implement four-phase workflow to validate core functionality

2. Test hallucination handling: Introduce controlled semantic and format hallucinations into sample models and verify detection and repair mechanisms

3. Evaluate on additional datasets: Test MAO on datasets with more complex process structures and elements not covered in original datasets to assess generalizability and limitations