---
ver: rpa2
title: Improving Generalization in Semantic Parsing by Increasing Natural Language
  Variation
arxiv_id: '2402.08666'
source_url: https://arxiv.org/abs/2402.08666
tags:
- questions
- spider
- type
- original
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of limited linguistic variation
  in the Spider text-to-SQL dataset, which leads to poor generalization of semantic
  parsing models. To improve robustness, the authors augment Spider with more diverse
  and natural questions using large language models like ChatGPT.
---

# Improving Generalization in Semantic Parsing by Increasing Natural Language Variation

## Quick Facts
- **arXiv ID**: 2402.08666
- **Source URL**: https://arxiv.org/abs/2402.08666
- **Reference count**: 40
- **Primary result**: ChatGPT-generated question reformulations improve text-to-SQL model robustness and cross-domain generalization

## Executive Summary
This paper addresses the limited linguistic variation in the Spider text-to-SQL dataset, which constrains model generalization. The authors propose augmenting Spider with diverse, natural questions generated by large language models like ChatGPT. Using various reformulation instructions (deletions, substitutions, rewritings, paraphrases), they create more realistic and varied training data. Experiments with state-of-the-art text-to-SQL models show substantial improvements in robustness to question perturbations and generalization to out-of-domain datasets, demonstrating that increased natural language variation enhances semantic parsing performance.

## Method Summary
The authors augment the Spider dataset with ChatGPT-generated question reformulations using seven different instruction types: simplify, simplify by hiding details, simplify using synonyms, simplify using substitutions, express in a different way, paraphrase, and examples-based rewriting. These augmentations are filtered and combined with the original Spider training data. State-of-the-art text-to-SQL models (T5-3B, PICARD, RESDSQL) are fine-tuned on this augmented dataset and evaluated on robustness benchmarks (Dr.Spider NLQ) and out-of-domain datasets (GeoQuery, KaggleDBQA) using execution accuracy as the primary metric.

## Key Results
- Absolute robustness (accuracy on post-perturbed sets) improves by more than 3% for augmented models
- Relative robustness (pre-post difference) shows similar gains across perturbation types
- Combined augmentations outperform specialized methods (Spider-Syn, MT-TEQL) on multiple evaluation datasets
- Improvements transfer to out-of-domain generalization on GeoQuery and KaggleDBQA

## Why This Works (Mechanism)

### Mechanism 1
ChatGPT rewrites questions using diverse instructions to expand the linguistic distribution of training data. The assumption is that ChatGPT-generated paraphrases preserve semantic equivalence while introducing realistic variation not present in the original Spider dataset.

### Mechanism 2
Training on diverse reformulations exposes models to perturbations in question phrasing, enabling better generalization to unseen linguistic forms. The key assumption is that perturbations in evaluation sets are sufficiently similar to augmentations to transfer robustness gains.

### Mechanism 3
Diverse rewrite operations expose models to broader linguistic variation, enabling better adaptation to unseen domains. The assumption is that no single augmentation type captures all necessary variation, so combining types yields complementary benefits.

## Foundational Learning

- **Concept**: Semantic parsing maps natural language to formal meaning representations (SQL queries)
  - Why needed here: Core task; understanding this clarifies why linguistic variation impacts performance
  - Quick check question: What is the difference between text-to-SQL and general semantic parsing?

- **Concept**: Cross-domain generalization requires models to parse questions for arbitrary databases, not just seen ones
  - Why needed here: Spider's benchmark design; augmentation aims to improve this capability
  - Quick check question: How does Spider's cross-domain setup differ from single-domain datasets like GeoQuery?

- **Concept**: Robustness to perturbations measures model resilience to small changes in input (e.g., synonyms, paraphrasing)
  - Why needed here: Primary evaluation metric; augmentation directly targets this
  - Quick check question: What is the difference between absolute and relative robustness?

## Architecture Onboarding

- **Component map**: Spider training data + ChatGPT augmentations → T5-3B/PICARD/RESDSQL models → Evaluation on Dr.Spider NLQ, GeoQuery, KaggleDBQA → Execution accuracy metrics

- **Critical path**:
  1. Generate augmentations using ChatGPT with diverse rewrite instructions
  2. Filter and combine with original Spider training data
  3. Train model (T5-3B/PICARD/RESDSQL) on augmented data
  4. Evaluate zero-shot on perturbation and out-of-domain benchmarks
  5. Analyze robustness and generalization gains

- **Design tradeoffs**:
  - Augmentation diversity vs. semantic fidelity: More diverse rewrites risk semantic drift
  - Training size increase vs. computational cost: 2x data size increases training time
  - Model-agnostic vs. specialized architectures: Approach works across models but doesn't optimize for any single one

- **Failure signatures**:
  - Decreased performance on original Spider dev set despite augmentation gains
  - Model confusion between synonyms and distinct SQL entities
  - Overfitting to augmentation style rather than generalizing variation

- **First 3 experiments**:
  1. Compare execution accuracy on Spider dev set before/after augmentation to detect overfitting
  2. Ablation study: Train with only one augmentation type (e.g., deletion) to measure contribution
  3. Evaluate on Spider-Realistic and Spider-Syn to compare against specialized augmentation methods

## Open Questions the Paper Calls Out

- **Open Question 1**: How do the augmentations affect the distribution of parsing errors in semantic parsers?
  - Basis in paper: The authors conducted an error analysis showing that the majority of errors are similar in nature to those made by models without augmentations, with only a small percentage potentially due to augmentations affecting values
  - Why unresolved: The analysis was based on a sample of 60 instances, which may not be representative of the entire dataset
  - What evidence would resolve it: A larger-scale error analysis comparing the error distributions of models trained with and without augmentations on a significant portion of the Spider development set

- **Open Question 2**: What is the impact of different types of question reformulations on model robustness and generalization?
  - Basis in paper: The authors conducted an ablation study showing that different types of augmentations (deletions, substitutions, rewriting, paraphrasing) are helpful for different datasets, but a combination of augmentations performs best overall
  - Why unresolved: The study did not explore the impact of varying the number of augmentations per type or the effect of different weighting schemes for combining augmentations
  - What evidence would resolve it: Experiments varying the number of augmentations per type and testing different weighting schemes for combining them, followed by evaluation on robustness and generalization benchmarks

- **Open Question 3**: Can the proposed approach be extended to multilingual semantic parsing?
  - Basis in paper: The authors mention this as a potential future direction, noting that their approach could be adapted for multilingual semantic parsing
  - Why unresolved: The paper does not provide any evidence or experiments related to multilingual semantic parsing
  - What evidence would resolve it: Experiments applying the approach to multilingual datasets and evaluating model performance on robustness and generalization tasks in multiple languages

## Limitations

- The semantic fidelity of ChatGPT-generated augmentations lacks rigorous validation beyond spot-checking
- The evaluation relies heavily on execution accuracy without deeper analysis of error types or false positives
- Weak external validation signal (avg citations=0.0) suggests limited testing in the broader research community

## Confidence

- **High confidence**: The empirical results showing improved robustness on Dr.Spider NLQ sets are well-supported by the experimental design and control comparisons
- **Medium confidence**: The claim that combined augmentations outperform specialized methods (Spider-Syn, MT-TEQL) is supported but could benefit from more systematic ablation studies
- **Low confidence**: The assumption that ChatGPT-generated variations are semantically equivalent to originals lacks rigorous validation

## Next Checks

1. **Semantic Fidelity Audit**: Systematically sample 100 ChatGPT augmentations and have human annotators verify whether each maps to the same SQL query as its original. Calculate precision and recall of semantic preservation.

2. **Ablation of Conservative Generation**: Test whether increasing ChatGPT's temperature or using alternative prompt strategies produces more diverse variations without semantic drift. Compare robustness gains against the original conservative approach.

3. **Error Analysis on False Positives**: Analyze cases where augmented models achieve higher accuracy than baseline but execute incorrect SQL queries. Determine whether this represents true robustness gains or simply different failure modes.