---
ver: rpa2
title: 'Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived
  features by means of radiomics'
arxiv_id: '2405.02334'
source_url: https://arxiv.org/abs/2405.02334
tags:
- features
- radiomic
- deep
- explanation
- rad4xcnn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Rad4XCNN, a novel method that provides global
  explainability for deep features extracted from CNNs by correlating them with radiomic
  features, aiming to address the explainability-accuracy trade-off dilemma. The authors
  evaluate their method on breast cancer classification using ultrasound imaging datasets,
  including an online dataset and two in-house datasets for internal and external
  validation.
---

# Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics

## Quick Facts
- arXiv ID: 2405.02334
- Source URL: https://arxiv.org/abs/2405.02334
- Reference count: 20
- CNN-derived features achieve superior accuracy compared to ViT-derived and radiomic features while maintaining explainability

## Executive Summary
Rad4XCNN is a novel post-hoc explanation method that provides global explainability for deep features extracted from CNNs by correlating them with radiomic features. The method addresses the explainability-accuracy trade-off dilemma by preserving model performance while offering interpretable explanations based on the intrinsic meaning of radiomic features. Evaluated on breast cancer classification using ultrasound imaging datasets, Rad4XCNN demonstrates that CNN-derived features outperform both radiomic and ViT-derived features in accuracy, while conventional visualization map methods present significant limitations. The method enables physicians to extract meaningful insights without sacrificing model accuracy.

## Method Summary
Rad4XCNN works by computing Spearman correlation coefficients between deep features extracted from pre-trained CNN models (ResNet50, DenseNet121, ViT-B32) and radiomic features extracted from the same images. Features with correlation coefficients above a threshold M are considered correlated, and their radiomic meaning provides interpretable explanations for the deep features. The method processes breast ultrasound images from multiple datasets (BUSI, Palermo, Cefalù), extracts patches, and computes 474 radiomic features using PyRadiomics. Deep features are extracted from CNN models trained on the BUSI dataset and fine-tuned on the Palermo training set. Shallow classifiers (RF, XGB, SVM) are then trained on both deep and radiomic features for classification tasks.

## Key Results
- CNN-derived features achieved higher accuracy than both ViT-derived and radiomic features for breast cancer classification
- Rad4XCNN provides global explanations that enable physicians to analyze model outputs and findings
- Conventional visualization map methods (Grad-CAM, EigenCAM, ScoreCAM) present conflicting results and several pitfalls
- The method maintains model accuracy by not modifying the deep learning architecture or training process

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Rad4XCNN correlates CNN-derived features with radiomic features to create global explainability without altering model performance
- Mechanism: The method computes Spearman correlation coefficients between deep features (fd) and radiomic features (fr). Features above a threshold M are considered correlated, and their radiomic meaning provides interpretable explanations for the deep features
- Core assumption: Radiomic features have well-defined, meaningful interpretations that can explain abstract deep features
- Evidence anchors: [abstract], [section 3.4], [corpus] with moderate relevance (FMR=0.512)
- Break condition: Correlation threshold M is set too high or too low, resulting in either no correlations found or too many spurious correlations

### Mechanism 2
- Claim: Rad4XCNN achieves better explainability than saliency map methods by providing global rather than local explanations
- Mechanism: Unlike Grad-CAM, EigenCAM, and ScoreCAM which create class-specific saliency maps for individual predictions, Rad4XCNN analyzes correlations across the entire dataset to identify global patterns in feature relationships
- Core assumption: Global explanations are more useful for clinical validation than local explanations that vary by individual case
- Evidence anchors: [abstract], [section 4.2], [corpus] with moderate relevance
- Break condition: If physicians require local explanations for specific patient cases, the global approach may be insufficient

### Mechanism 3
- Claim: Rad4XCNN maintains model accuracy by not modifying the deep learning architecture or training process
- Mechanism: The method extracts features after model training and computes correlations separately, leaving the original CNN architecture untouched
- Core assumption: Post-hoc explanations that don't interfere with training will preserve the original model's predictive performance
- Evidence anchors: [abstract], [section 3.4], [section 4.1], [corpus] with weak evidence
- Break condition: If correlation computation or feature extraction adds computational overhead that affects model deployment

## Foundational Learning

- Concept: Radiomics feature extraction and meaning
  - Why needed here: Understanding radiomic features is essential to interpret what Rad4XCNN correlates with deep features
  - Quick check question: What is the difference between first-order radiomic features and texture-based features like GLCM?

- Concept: Spearman correlation and its interpretation
  - Why needed here: Rad4XCNN uses Spearman correlation to identify relationships between feature sets
  - Quick check question: When would you use Spearman correlation instead of Pearson correlation for feature analysis?

- Concept: CNN feature extraction and architecture
  - Why needed here: Understanding what CNN-derived features represent helps interpret the correlation results
  - Quick check question: How do convolutional layers extract hierarchical features from images?

## Architecture Onboarding

- Component map: Data preprocessing pipeline -> Deep learning models (ResNet50, DenseNet121, ViT-B32) -> Radiomic feature extraction pipeline -> Correlation computation module -> Visualization component
- Critical path: Feature extraction → Correlation computation → Interpretation
- Design tradeoffs: Balance between correlation threshold (M) and number of meaningful correlations; choice of radiomic features to extract
- Failure signatures: No correlations found (threshold too high); too many spurious correlations (threshold too low); computational bottlenecks in feature extraction
- First 3 experiments:
  1. Run Rad4XCNN on a small dataset with known feature relationships to verify correlation detection works
  2. Compare correlation results with different threshold values (M) to find optimal balance
  3. Validate that Rad4XCNN explanations align with clinical literature for a subset of features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Rad4XCNN method provide clinically meaningful explanations that improve physician trust and diagnostic accuracy in breast cancer detection?
- Basis in paper: [explicit] The paper states that Rad4XCNN provides global explanations enabling physicians to extract insights and findings
- Why unresolved: The paper presents the methodology and some initial results, but does not provide a formal clinical validation study or user study
- What evidence would resolve it: A clinical study where radiologists use Rad4XCNN explanations to interpret CNN-derived features, measuring their diagnostic accuracy, confidence, and perceived trustworthiness

### Open Question 2
- Question: How does the choice of threshold M in Rad4XCNN affect the quality and interpretability of the explanations provided?
- Basis in paper: [explicit] The paper describes M as a hyperparameter to be determined according to the specific case study
- Why unresolved: The paper presents results for several threshold values but does not analyze how the choice of M affects the explanations
- What evidence would resolve it: A systematic analysis of how different M values affect the number and type of correlated features identified

### Open Question 3
- Question: Can Rad4XCNN be effectively applied to other medical imaging modalities and classification tasks beyond breast cancer detection in ultrasound?
- Basis in paper: [inferred] The paper presents Rad4XCNN as an agnostic method applicable to any CNN-based architecture
- Why unresolved: The paper only demonstrates Rad4XCNN on breast cancer classification in ultrasound
- What evidence would resolve it: Application and validation of Rad4XCNN on multiple medical imaging datasets from different modalities and classification tasks

## Limitations

- Correlation threshold (M) selection process is not fully specified, which could impact explanation quality
- The method relies on the assumption that radiomic features have well-defined clinical interpretations
- Comparison with saliency map methods focuses on visualization quality rather than clinical utility

## Confidence

- Medium confidence in global explanation claims due to moderate corpus relevance (FMR=0.512) and lack of direct validation studies
- Medium confidence in accuracy preservation claims due to primarily indirect evidence
- Low confidence in clinical utility claims due to absence of formal user studies

## Next Checks

1. Verify correlation detection works by testing Rad4XCNN on a small dataset with known feature relationships
2. Analyze the impact of different correlation threshold (M) values on the number and type of correlated features identified
3. Validate that Rad4XCNN explanations align with clinical literature for a subset of features through expert review