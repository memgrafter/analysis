---
ver: rpa2
title: 'Ingest-And-Ground: Dispelling Hallucinations from Continually-Pretrained LLMs
  with RAG'
arxiv_id: '2410.02825'
source_url: https://arxiv.org/abs/2410.02825
tags:
- privacy
- knowledge
- which
- base
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a system that combines continual pre-training
  of a large language model with a semantic retrieval-augmented generation layer to
  reduce hallucinations in privacy-related queries. The approach trains Llama-3.1
  on a domain-specific privacy knowledge base, then uses semantic chunking with a
  text embedding model to retrieve relevant context for queries.
---

# Ingest-And-Ground: Dispelling Hallucinations from Continually-Pretrained LLMs with RAG

## Quick Facts
- arXiv ID: 2410.02825
- Source URL: https://arxiv.org/abs/2410.02825
- Reference count: 17
- Primary result: RAG layer improves accuracy by 40% on privacy queries compared to raw Llama-3.1

## Executive Summary
This work introduces a system that combines continual pre-training of a large language model with a semantic retrieval-augmented generation layer to reduce hallucinations in privacy-related queries. The approach trains Llama-3.1 on a domain-specific privacy knowledge base, then uses semantic chunking with a text embedding model to retrieve relevant context for queries. Evaluations show that this method significantly improves accuracy, with pass rates for quality metrics doubling compared to the baseline model, and a 40% improvement over raw Llama-3.1 in handling privacy-related questions.

## Method Summary
The method involves continual pre-training of Llama-3.1-70b-instruct on a privacy knowledge base containing 20,000 documents (~2M tokens) using Causal Token Masking. A semantic RAG layer is then built using Dragon-Plus text embeddings for context retrieval. When processing queries, the system retrieves relevant document chunks from the knowledge base and augments the original prompt with this context before passing it to the LLM for response generation.

## Key Results
- Pass rates for quality metrics doubled compared to the baseline model
- 40% improvement over raw Llama-3.1 in handling privacy-related questions
- Effective reduction in hallucinations when answering privacy queries

## Why This Works (Mechanism)

### Mechanism 1
Continual pre-training with domain-specific data improves model's ability to understand and reason about privacy-related concepts. The additional pre-training updates model weights on privacy-specific documents, enhancing the base model's domain knowledge without alignment tuning. Core assumption: The privacy knowledge base contains sufficient and accurate information to meaningfully improve the model's understanding of privacy concepts.

### Mechanism 2
Semantic chunking improves retrieval quality by creating contextually coherent document segments. Instead of uniform chunking by characters or paragraphs, semantic chunking uses text embeddings to group text segments with similar meanings, ensuring each chunk is contextually coherent. Core assumption: Document content has natural semantic boundaries that can be identified through embedding similarity.

### Mechanism 3
RAG layer reduces hallucinations by providing factual grounding from the knowledge base. When presented with a query, the RAG layer retrieves relevant documents from the knowledge base and uses both the original prompt and retrieved information to generate responses. Core assumption: The retrieved context is relevant and sufficient to ground the response factually.

## Foundational Learning

- **Continual Pre-training**
  - Why needed here: To adapt a general-purpose LLM to the specialized domain of privacy regulations without starting from scratch
  - Quick check question: What is the key difference between continual pre-training and fine-tuning in terms of how they update model weights?

- **Retrieval-Augmented Generation (RAG)**
  - Why needed here: To provide factual grounding from external knowledge sources to reduce hallucinations in domain-specific queries
  - Quick check question: How does RAG differ from traditional retrieval-based QA systems in terms of how information is integrated into the response generation process?

- **Semantic Chunking**
  - Why needed here: To create document segments that preserve contextual coherence for more effective retrieval
  - Quick check question: What is the primary advantage of semantic chunking over traditional fixed-size chunking methods in the context of RAG systems?

## Architecture Onboarding

- **Component map**: Privacy knowledge base (20,000 documents, ~2M tokens) -> Continual pre-training module (Llama-3.1-70b-instruct) -> Semantic RAG layer (Dragon-Plus text embeddings) -> Online inference pipeline (query → RAG → LLM → response)

- **Critical path**: Query processing → Semantic chunking → Document retrieval → Context augmentation → LLM generation → Response delivery

- **Design tradeoffs**:
  - Model size vs. latency: Llama-3.1-70b provides strong performance but requires significant compute resources
  - Chunk size vs. retrieval accuracy: Smaller chunks improve precision but may lose context; larger chunks preserve context but may reduce recall
  - Embedding model quality vs. computational cost: Dragon-Plus offers state-of-the-art performance but at higher computational expense

- **Failure signatures**:
  - Low retrieval recall: System returns irrelevant or no documents for queries
  - High hallucination rate: Generated responses contain factual errors despite RAG layer
  - Slow inference: Response times exceed acceptable thresholds due to computational overhead

- **First 3 experiments**:
  1. Evaluate baseline Llama-3.1 performance on privacy queries without any enhancements
  2. Measure the impact of continual pre-training alone on query accuracy metrics
  3. Test semantic RAG integration with the pre-trained model to assess combined improvement

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of PrivacyBrain scale with different knowledge base sizes and document diversity beyond the 20,000 documents tested? The paper mentions using 20,000 documents (~2 million tokens) but does not explore performance variations with different knowledge base sizes or document diversity.

### Open Question 2
How does PrivacyBrain's hallucination reduction performance compare to other state-of-the-art hallucination mitigation techniques beyond simple raw Llama baselines? The paper only compares against three variants of Llama-3.1 but does not benchmark against other hallucination reduction techniques.

### Open Question 3
What is the computational overhead and latency impact of the semantic chunking approach compared to simpler chunking methods in production environments? The paper describes implementing a sophisticated semantic chunking method using Dragon-Plus embeddings but does not report on computational costs or latency implications.

## Limitations

- Knowledge base quality dependency: The effectiveness critically depends on the quality and comprehensiveness of the 20,000-document privacy knowledge base
- Evaluation scope: Limited to 50 privacy-related queries with GPT-4 as judge, potentially missing edge cases
- Generalizability: Approach is specifically designed for privacy queries without evidence of cross-domain effectiveness

## Confidence

- **High Confidence**: The architectural framework combining continual pre-training with RAG is technically sound and follows established best practices
- **Medium Confidence**: The quantitative results showing improved pass rates and keyword matching are credible but limited by the small evaluation dataset
- **Low Confidence**: The long-term effectiveness of the system for maintaining up-to-date privacy knowledge and handling evolving regulatory landscapes is not demonstrated

## Next Checks

1. **Cross-Domain Evaluation**: Test the Ingest-And-Ground approach on at least two other specialized domains (e.g., healthcare regulations, financial compliance) using the same evaluation methodology to assess generalizability beyond privacy queries

2. **Knowledge Base Dynamics**: Implement a longitudinal study where the knowledge base is updated with new privacy regulations over a 6-month period, measuring how quickly and effectively the system adapts to changes in the regulatory landscape

3. **Adversarial Testing**: Design a battery of adversarial queries specifically crafted to trigger hallucinations or exploit potential weaknesses in the retrieval-augmented generation pipeline, measuring failure rates under these stress conditions