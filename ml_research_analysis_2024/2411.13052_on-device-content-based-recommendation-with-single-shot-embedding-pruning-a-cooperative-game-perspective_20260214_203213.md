---
ver: rpa2
title: 'On-device Content-based Recommendation with Single-shot Embedding Pruning:
  A Cooperative Game Perspective'
arxiv_id: '2411.13052'
source_url: https://arxiv.org/abs/2411.13052
tags:
- embedding
- shapley
- value
- pruning
- parameter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Shaver, a single-shot embedding pruning method
  for on-device content-based recommender systems (CRSs) based on Shapley values.
  The method addresses the storage bottleneck of large embedding tables in CRSs, which
  is particularly problematic for resource-constrained devices.
---

# On-device Content-based Recommendation with Single-shot Embedding Pruning: A Cooperative Game Perspective

## Quick Facts
- arXiv ID: 2411.13052
- Source URL: https://arxiv.org/abs/2411.13052
- Authors: Hung Vinh Tran; Tong Chen; Guanhua Ye; Quoc Viet Hung Nguyen; Kai Zheng; Hongzhi Yin
- Reference count: 40
- Key outcome: Single-shot embedding pruning method for on-device content-based recommendation systems using Shapley values, achieving competitive performance without retraining

## Executive Summary
This paper addresses the critical challenge of large embedding tables in content-based recommender systems, which pose significant storage constraints for on-device deployment. The authors propose Shaver, a novel single-shot embedding pruning method that leverages Shapley values from cooperative game theory to quantify parameter importance and prune embeddings in one pass. Unlike traditional iterative pruning approaches, Shaver eliminates the need for expensive retraining cycles by making pruning decisions based on a single importance evaluation. The method also introduces a field-aware codebook to replace conventional zero-padding, mitigating information loss during the pruning process.

The proposed approach demonstrates substantial computational efficiency improvements, reducing complexity from factorial to linear in the number of feature fields. Experiments across three real-world datasets show that Shaver achieves competitive performance with lightweight recommendation models across various parameter budgets, even without post-pruning fine-tuning. This makes it particularly suitable for resource-constrained devices where both storage and computational efficiency are paramount concerns.

## Method Summary
Shaver employs a single-shot embedding pruning strategy based on Shapley values, which measure each embedding parameter's marginal contribution to the overall recommendation performance. The method calculates these values in one pass through the data, eliminating the need for iterative pruning and retraining cycles typical of traditional approaches. To address the information loss problem associated with zero-padding in pruned embeddings, the authors introduce a field-aware codebook that dynamically replaces padded positions with learned representations. This codebook is trained alongside the pruning process to ensure that removed parameters' information is preserved in a compressed form. The combination of Shapley value-based importance scoring and field-aware codebook replacement enables effective pruning while maintaining recommendation quality, making it particularly suitable for on-device deployment where storage constraints are critical.

## Key Results
- Achieves competitive performance with lightweight recommendation models across three real-world datasets
- Eliminates need for expensive retraining cycles through single-shot pruning approach
- Reduces computational complexity from O((nd)! × |D|) to O(md × |D|)

## Why This Works (Mechanism)
The method works by leveraging cooperative game theory principles, specifically Shapley values, to quantify the marginal contribution of each embedding parameter to the recommendation system's performance. By calculating these values in a single pass through the data, the approach can identify and remove truly redundant parameters without iterative refinement. The field-aware codebook addresses the inherent information loss in traditional zero-padding by learning compact representations that preserve the semantic information of removed parameters, ensuring that pruning doesn't degrade recommendation quality.

## Foundational Learning

**Shapley Values in Recommendation Systems**
*Why needed:* Provides a theoretically grounded way to measure individual parameter importance in collaborative settings
*Quick check:* Verify that Shapley value calculations align with empirical parameter importance across different recommendation tasks

**Cooperative Game Theory Applications**
*Why needed:* Enables fair attribution of contribution among embedding parameters
*Quick check:* Test whether cooperative game assumptions hold for different embedding architectures

**Field-aware Codebook Design**
*Why needed:* Addresses information loss from zero-padding in pruned embeddings
*Quick check:* Compare information retention against traditional padding strategies

## Architecture Onboarding

**Component Map**
User Features -> Embedding Tables -> Shapley Value Calculator -> Pruning Decision Module -> Field-aware Codebook -> Pruned Model

**Critical Path**
Feature extraction → Embedding lookup → Shapley value computation → Parameter pruning → Codebook replacement → Inference

**Design Tradeoffs**
Single-shot pruning trades potential optimality for computational efficiency; field-aware codebook adds complexity but preserves information; no fine-tuning requirement limits final performance but enables faster deployment

**Failure Signatures**
Poor Shapley value estimates leading to over-pruning critical parameters; codebook learning instability causing information loss; mismatch between pruning budget and actual parameter redundancy

**First 3 Experiments**
1. Ablation study comparing Shapley-based pruning against random and magnitude-based pruning
2. Codebook effectiveness evaluation with varying pruning ratios
3. Cross-dataset generalization test with different embedding table dimensions

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations

The assumption that Shapley value-based importance estimation reliably identifies redundant parameters across diverse datasets may not hold universally. The lack of post-pruning fine-tuning raises concerns about whether pruned models are truly optimal or merely adequate. The field-aware codebook introduces additional complexity that may not generalize well to all embedding architectures.

## Confidence

**Major Limitations and Uncertainties**
The primary limitation lies in the assumption that Shapley value-based importance estimation can reliably identify truly redundant parameters across diverse recommendation datasets. While the method demonstrates competitive performance with lightweight models, the lack of post-pruning fine-tuning raises questions about whether the pruned models are truly optimal or merely adequate. The field-aware codebook, while addressing padding information loss, introduces additional complexity that may not generalize well to all embedding architectures. The computational complexity improvement, though significant in theory, may not translate equally across different hardware constraints and embedding table sizes.

**Confidence Assessment**
The core claim that Shaver achieves competitive performance without retraining carries **Medium** confidence due to the limited scope of datasets tested (only three real-world datasets) and the absence of comparison against state-of-the-art on-device recommendation methods. The theoretical complexity reduction from O((nd)! × |D|) to O(md × |D|) has **High** confidence as it follows directly from the single-shot pruning approach. The effectiveness of the field-aware codebook in mitigating padding information loss has **Medium** confidence, as the paper demonstrates improvement but does not provide ablation studies comparing it against alternative padding strategies.

## Next Checks

1. Test Shaver on diverse recommendation domains beyond the three provided datasets, including cases with highly sparse features and varying embedding table dimensions, to validate generalizability.

2. Conduct a comprehensive ablation study comparing the field-aware codebook against other padding strategies and evaluate its impact on different embedding architectures and recommendation tasks.

3. Perform long-term stability analysis of pruned models across multiple epochs of inference to ensure that the single-shot pruning approach does not introduce performance degradation over time.