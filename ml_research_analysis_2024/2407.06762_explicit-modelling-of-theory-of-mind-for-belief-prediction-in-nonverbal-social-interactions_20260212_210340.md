---
ver: rpa2
title: Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social
  Interactions
arxiv_id: '2407.06762'
source_url: https://arxiv.org/abs/2407.06762
tags:
- mtomnet
- belief
- beliefs
- boss
- cues
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces MToMnet, a neural network that explicitly\
  \ models Theory of Mind for predicting beliefs and belief dynamics from multimodal\
  \ nonverbal cues. The method encodes contextual and person-specific cues through\
  \ two independent MindNets, one per person, and explores three variants\u2014Decision-Based,\
  \ Implicit Communication, and Common Ground\u2014for integrating these cues."
---

# Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions

## Quick Facts
- arXiv ID: 2407.06762
- Source URL: https://arxiv.org/abs/2407.06762
- Reference count: 40
- Primary result: MToMnet achieves 0.729 accuracy on BOSS and 0.488 macro F1 on TBD with ~460k parameters vs. 21M baseline parameters

## Executive Summary
This paper introduces MToMnet, a neural network that explicitly models Theory of Mind for predicting beliefs and belief dynamics from multimodal nonverbal cues. The method encodes contextual and person-specific cues through two independent MindNets, one per person, and explores three variants—Decision-Based, Implicit Communication, and Common Ground—for integrating these cues. Evaluated on BOSS and TBD datasets, MToMnet significantly outperforms prior approaches while using far fewer parameters. It also excels at predicting false belief dynamics.

## Method Summary
MToMnet processes multimodal nonverbal cues through two parallel MindNets (bidirectional LSTMs) that encode person-specific information, while shared feature extractors handle contextual cues. The model supports three explicit Theory of Mind variants: Decision-Based (τ-weighted fusion), Implicit Communication (cross-attention), and Common Ground (concatenated cell states). For BOSS, it predicts belief states; for TBD, it predicts belief dynamics across multiple mental agents. The architecture uses CNNs for RGB frames, GNNs for pose/OCR matrices, and FC layers for bounding boxes, with cross-entropy loss and Adam optimizer.

## Key Results
- MToMnet achieves 0.729 accuracy on BOSS belief prediction (30% improvement over baselines)
- TBD macro F1 score of 0.488 with 0.412 for false belief detection
- Parameter efficiency: ~460k parameters vs. 21M baseline parameters
- Common Ground variant (CG-MToMnet) shows superior performance for false belief dynamics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: MToMnet's independent MindNets encode person-specific cues effectively, leading to disentangled latent representations.
- **Mechanism**: Two separate bidirectional LSTMs (MindNets) process gaze and body language for each person independently. This allows each MindNet to learn distinct feature spaces tailored to individual behavior patterns.
- **Core assumption**: Person-specific nonverbal cues contain distinct information that benefits from separate modeling.
- **Evidence anchors**:
  - [abstract] "Our results emphasize the importance of explicit Theory of Mind (ToM) modelling for achieving these performance improvements. Moreover, analyses of MToMnet's latent representations underline the effectiveness of encoding person-specific cues with independent MindNets."
  - [section] "To assess the efficacy of encoding individual cues and predicting individuals' beliefs using independent MindNets, we compared the feature representations from the two LSTMs, h1 and h2, by employing Principal Component Analysis (PCA). As the examples in Figure 6 show, the LSTMs hidden states h1 and h2 from CG∥-MToMnet show a clear disentanglement of principal components both on BOSS and TBD."
  - [corpus] Weak anchor: related papers focus on ToM benchmarking but do not explicitly discuss disentangled latent representations in multimodal settings.
- **Break condition**: If nonverbal cues are highly correlated across persons (e.g., synchronized gestures in duets), separate encoding may not provide additional benefit and could increase model complexity unnecessarily.

### Mechanism 2
- **Claim**: Explicit ToM modeling variants (CG, IC, DB) outperform base MToMnet by incorporating structured interpersonal reasoning.
- **Mechanism**: Variants fuse latent states using operations like concatenation (CG∥), element-wise multiplication (CG⊗), or cross-attention (CG⊙). These operations create structured communication channels mimicking social cognition mechanisms.
- **Core assumption**: Human social reasoning involves explicit integration of mental state predictions between agents, not just parallel processing.
- **Evidence anchors**:
  - [abstract] "Our results demonstrate that MToMnet surpasses existing methods by a large margin while at the same time requiring a significantly smaller number of parameters."
  - [section] "Adding explicit ToM modelling leads to further performance gains for all three variants, up to 30% on HGM. Considering the average performance across different aggregation types, the best model is again the one inspired by social cognition, CG-MToMnet."
  - [corpus] Weak anchor: no corpus evidence directly supports superiority of CG variants over DB or IC for false belief prediction.
- **Break condition**: If interpersonal communication is minimal or irrelevant to the task, explicit ToM fusion may add noise rather than signal.

### Mechanism 3
- **Claim**: Common ground representation (CG-MToMnet) enables superior belief dynamics prediction, especially for false beliefs.
- **Mechanism**: CG-MToMnet concatenates LSTM cell states from both MindNets to form a shared common ground representation, then fuses it with each MindNet's hidden state. This mimics the human cognitive process of forming shared situational understanding.
- **Core assumption**: Effective human communication requires forming a shared context (common ground) that both parties contribute to and reference.
- **Evidence anchors**:
  - [abstract] "Moreover, analyses of MToMnet's latent representations underline the effectiveness of encoding person-specific cues with independent MindNets."
  - [section] "In contrast, our MToMnet variants, especially CG-MToMnet, can overcome this bias." (referring to bias toward predicting "update" class in false belief scenarios)
  - [corpus] Weak anchor: no direct corpus evidence for common ground modeling improving false belief prediction specifically.
- **Break condition**: If the task requires purely individual reasoning without shared context, common ground fusion may be unnecessary overhead.

## Foundational Learning

- **Concept**: Multimodal feature extraction and fusion
  - **Why needed here**: MToMnet must process diverse inputs (video frames, gaze, pose, bounding boxes) and integrate them meaningfully for belief prediction.
  - **Quick check question**: How does the CNN feature extractor differ from the graph convolutional network used for OCR matrices?

- **Concept**: Recurrent modeling of temporal dynamics
  - **Why needed here**: Belief prediction requires understanding how nonverbal cues evolve over time to infer mental states.
  - **Quick check question**: Why use bidirectional LSTMs instead of unidirectional ones in MindNets?

- **Concept**: Classification head design for multi-mind prediction
  - **Why needed here**: TBD requires predicting belief dynamics for multiple mental agents (self, other, common ground).
  - **Quick check question**: How does the model architecture differ between BOSS (belief prediction) and TBD (belief dynamics prediction)?

## Architecture Onboarding

- **Component map**: Input -> Shared feature extractors (CNN, GNN, FC) -> MindNets (2 parallel BiLSTMs) -> ToM fusion (DB, IC, or CG) -> Classification heads -> Output

- **Critical path**: Input → Shared feature extractors → MindNets → ToM fusion → Classification heads → Output

- **Design tradeoffs**:
  - Separate MindNets vs. shared encoder: Separate encoders capture individual differences but increase parameters; shared encoder reduces parameters but may miss person-specific patterns.
  - CG fusion vs. IC fusion: CG creates explicit common ground but requires careful aggregation; IC enables implicit communication but may be harder to interpret.

- **Failure signatures**:
  - Poor performance on BOSS but good on TBD: Likely issue with object-context relation modeling (OCR matrix)
  - All variants perform similarly: ToM modeling may not be necessary for the task
  - CG variant underperforms: Common ground representation may not be beneficial for the specific interaction patterns

- **First 3 experiments**:
  1. Ablation study: Remove bounding boxes and observe accuracy drop on BOSS
  2. Parameter efficiency: Compare parameter counts between MToMnet and baselines
  3. False belief detection: Evaluate CG-MToMnet on TBD false belief subsets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MToMnet's performance scale when modeling more than two interacting agents, and what architectural modifications would be necessary?
- Basis in paper: [explicit] The paper notes that CG-MToMnet can be easily adapted to interactions involving more than two agents due to its shared common ground representation, while DB- and IC-MToMnet variants would require modifications.
- Why unresolved: The paper only evaluates MToMnet on dyadic interactions and does not test multi-agent scenarios or propose concrete architectural changes for scaling beyond two agents.
- What evidence would resolve it: Experimental results comparing MToMnet variants on datasets with three or more agents, along with architectural designs that demonstrate how to extend the common ground representation and aggregation mechanisms.

### Open Question 2
- Question: What is the relative contribution of each input modality (gaze, pose, video frames, bounding boxes, OCR) to belief prediction accuracy, and how do these contributions vary across different social contexts?
- Basis in paper: [explicit] The paper includes modality ablation studies showing that bounding boxes significantly impact BOSS performance and that combining gaze, pose, and third-person RGB frames improves TBD results.
- Why unresolved: While the ablation studies show overall trends, they don't provide fine-grained analysis of individual modality contributions or how these contributions change across different social interaction types and contexts.
- What evidence would resolve it: Detailed ablation studies across multiple datasets with varying social contexts, including quantitative measures of each modality's contribution to final accuracy and analysis of how these contributions shift between collaborative and non-collaborative scenarios.

### Open Question 3
- Question: How robust is MToMnet to imperfect or noisy input data, particularly for gaze estimation and bounding box annotations, and what error correction mechanisms could improve performance?
- Basis in paper: [inferred] The paper mentions inaccuracies in original BOSS bounding box annotations and re-extraction improving performance, and notes that participant faces were obscured for privacy reasons, making gaze data correction unfeasible.
- Why unresolved: The paper doesn't systematically evaluate MToMnet's performance under various levels of input noise or propose mechanisms to handle imperfect data beyond re-extraction of bounding boxes.
- What evidence would resolve it: Experiments introducing controlled noise to different input modalities, performance degradation curves showing MToMnet's robustness thresholds, and proposed error correction or data augmentation techniques to improve performance under imperfect conditions.

## Limitations
- Limited generalization: Performance improvements only demonstrated on two specific datasets (BOSS and TBD) with limited diversity in interaction types
- Parameter efficiency claims: Limited ablation studies on parameter efficiency despite compelling comparisons
- Lack of systematic noise analysis: No evaluation of model robustness to imperfect or noisy input data

## Confidence
- **High confidence**: MToMnet's ability to predict beliefs from multimodal cues (supported by significant accuracy improvements on BOSS)
- **Medium confidence**: The effectiveness of independent MindNets for capturing person-specific information (supported by PCA analysis but limited to qualitative visualization)
- **Medium confidence**: The superiority of CG variants for false belief prediction (supported by performance gains but lacking ablations)
- **Low confidence**: Claims about explicit ToM modeling being essential (lacks comparisons with purely implicit models)

## Next Checks
1. **Parameter efficiency analysis**: Conduct detailed ablation studies comparing parameter counts across all MToMnet variants and baselines, including breakdown of contributions from each modality.

2. **Ablation of ToM components**: Remove the explicit ToM fusion mechanisms while keeping the rest of the architecture intact to isolate the contribution of CG, IC, and DB variants.

3. **Cross-dataset validation**: Test MToMnet on additional datasets with different interaction types (e.g., MPIIGaze, VLOG) to assess generalization beyond BOSS and TBD.