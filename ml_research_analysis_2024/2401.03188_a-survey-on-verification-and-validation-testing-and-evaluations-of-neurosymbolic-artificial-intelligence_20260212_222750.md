---
ver: rpa2
title: A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic
  Artificial Intelligence
arxiv_id: '2401.03188'
source_url: https://arxiv.org/abs/2401.03188
tags:
- symbolic
- neurosymbolic
- learning
- sub-symbolic
- part
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey examines the verification and validation (V&V) challenges
  in neurosymbolic artificial intelligence (AI), which combines symbolic AI's explainability
  with sub-symbolic AI's learning capabilities. The paper analyzes two taxonomies
  of neurosymbolic systems and surveys current V&V methods for both symbolic and sub-symbolic
  components.
---

# A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic Artificial Intelligence

## Quick Facts
- arXiv ID: 2401.03188
- Source URL: https://arxiv.org/abs/2401.03188
- Reference count: 40
- Key outcome: Neurosymbolic AI combines symbolic AI's explainability with sub-symbolic AI's learning capabilities, with verification methods existing for symbolic components but requiring adaptation for neurosymbolic systems

## Executive Summary
This survey examines the verification and validation challenges in neurosymbolic artificial intelligence, which integrates symbolic AI's explainability with sub-symbolic AI's learning capabilities. The paper analyzes two taxonomies of neurosymbolic systems and surveys current V&V methods for both symbolic and sub-symbolic components. For symbolic AI, logical systems like propositional and first-order logic are decidable or semi-decidable, with established verification methods. Knowledge graphs can be validated using multiple techniques. For sub-symbolic AI, V&V remains challenging due to its "black box" nature, though testing frameworks exist for properties like correctness, robustness, and interpretability. The survey finds that neurosymbolic architectures can leverage symbolic components to improve V&V of sub-symbolic models, particularly in applications like safe reinforcement learning.

## Method Summary
The survey systematically maps V&V concepts to symbolic and sub-symbolic AI components, surveys existing V&V approaches for each, and analyzes their applicability to neurosymbolic applications. The methodology involves examining two taxonomies of neurosymbolic systems, reviewing verification methods for propositional and first-order logic, knowledge graph validation techniques, and sub-symbolic testing frameworks. The authors propose that symbolic components can act as "safety shields" or decision verifiers to constrain and validate sub-symbolic outputs. The paper identifies gaps where dedicated testing frameworks are needed for neurosymbolic configurations, particularly when combining knowledge graphs with CNNs or applying symbolic verification to complex sub-symbolic decision boundaries.

## Key Results
- Symbolic AI components (propositional logic, first-order logic, knowledge graphs) have established verification methods including truth tables, theorem provers, and KG validation tools
- Sub-symbolic AI components (neural networks) can be tested for correctness, robustness, and interpretability using frameworks like DeepXplore, neuron coverage metrics, and adversarial testing
- Neurosymbolic architectures can leverage symbolic components to improve V&V of sub-symbolic models through constraints, guidelines, and verification shields
- Current V&V methods are only partially sufficient for neurosymbolic systems and require adaptation for specific configurations
- Knowledge graphs combined with CNNs represent a frequent neurosymbolic configuration that would benefit from dedicated testing frameworks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neurosymbolic systems can improve V&V of sub-symbolic models by using symbolic components to constrain, guide, or verify sub-symbolic decisions.
- Mechanism: The symbolic part provides interpretable rules, knowledge graphs, or formal specifications that act as a "safety shield" or decision verifier, ensuring correctness and robustness of sub-symbolic outputs.
- Core assumption: Symbolic AI can effectively model the decision space and constraints of sub-symbolic models in a way that is both decidable and verifiable.
- Evidence anchors:
  - [abstract]: "neurosymbolic AI combines the advantages of both symbolic and sub-symbolic AI" and "neurosymbolic applications can ease the V&V process"
  - [section VI-A]: "In 'Reasoning for Learning', the symbolic part can support the sub-symbolic AI by providing guidelines and constraints through e.g. logic rules"
  - [corpus]: Weak - corpus neighbors focus on neurosymbolic systems but don't directly address V&V mechanisms.
- Break condition: If symbolic rules cannot accurately capture the complexity of sub-symbolic decision boundaries, verification becomes incomplete or computationally intractable.

### Mechanism 2
- Claim: Decidable symbolic components enable formal verification of neurosymbolic systems.
- Mechanism: Propositional logic and first-order logic components within neurosymbolic systems are decidable or semi-decidable, allowing for truth tables, semantic tableau, or automated theorem provers to verify logical correctness.
- Core assumption: The symbolic sub-component's logical structure remains tractable even when integrated with complex sub-symbolic learning.
- Evidence anchors:
  - [section IV-A]: "Propositional logic is decidable. The validity of a statement can be determined by a truth table"
  - [section IV-B]: "Even though first-order logic is not decidable, tools like [41], can be used to verify it in many cases"
  - [corpus]: Weak - corpus doesn't specifically address decidability in neurosymbolic verification contexts.
- Break condition: When symbolic components grow in complexity or integrate uncertain knowledge, decidability may be lost, requiring approximation methods.

### Mechanism 3
- Claim: Knowledge graphs within neurosymbolic systems can be validated using established knowledge graph validation techniques.
- Mechanism: Knowledge graphs used as symbolic components can leverage existing validation methods like COPAAL, DeFacto, or TISCO to ensure factual accuracy and temporal consistency.
- Core assumption: Knowledge graph validation techniques scale to the knowledge representation needs of neurosymbolic systems.
- Evidence anchors:
  - [section IV-C]: "KGs are an increasingly important component of current applications. Accordingly, there are numerous methods for validating these graphs"
  - [section IV-C]: "COPAAL computes a so-called mutual information (MI) score" and "DeFacto is an algorithm that tries to find supporting information about a given fact"
  - [corpus]: Weak - corpus focuses on neurosymbolic architectures but doesn't specifically address KG validation.
- Break condition: If knowledge graphs become too large or interconnected, validation methods may become computationally prohibitive or lose accuracy.

## Foundational Learning

- Concept: Decidability in formal logic systems
  - Why needed here: Understanding which logical components can be formally verified is critical for designing verifiable neurosymbolic systems
  - Quick check question: What's the difference between propositional and first-order logic decidability?

- Concept: Knowledge graph validation techniques
  - Why needed here: Knowledge graphs are commonly used symbolic components that require validation to ensure reliability of neurosymbolic systems
  - Quick check question: How does COPAAL validate knowledge graph facts differently from DeFacto?

- Concept: Adversarial testing for neural networks
  - Why needed here: Sub-symbolic components need robustness validation, and adversarial testing is a primary method for this
  - Quick check question: What's the relationship between neuron coverage and robustness in neural network testing?

## Architecture Onboarding

- Component map:
  - Symbolic component: Logic rules, knowledge graphs, formal specifications
  - Sub-symbolic component: Neural networks, CNNs, RNNs, GCNs
  - Interface layer: Embeddings, symbolic representations, verification shields
  - Validation layer: Truth tables, theorem provers, adversarial testing frameworks

- Critical path: Input → Sub-symbolic processing → Symbolic verification/constraint → Output
  - Alternative path: Input → Symbolic transformation → Symbolic reasoning → Output

- Design tradeoffs:
  - Precision vs. computational cost: More thorough verification increases accuracy but may slow real-time performance
  - Expressiveness vs. decidability: More complex symbolic representations may capture richer semantics but lose formal verification capabilities
  - Integration tightness: Tighter coupling between symbolic and sub-symbolic parts enables better verification but may reduce modularity

- Failure signatures:
  - Symbolic component: Logical contradictions, undecidable statements, knowledge graph inconsistencies
  - Sub-symbolic component: Adversarial vulnerability, poor generalization, incorrect feature extraction
  - Integration failures: Mismatched representations, conflicting constraints, verification bottlenecks

- First 3 experiments:
  1. Implement a simple neurosymbolic system with propositional logic verification using truth tables on a small dataset
  2. Add knowledge graph validation using COPAAL to verify symbolic facts extracted from sub-symbolic predictions
  3. Test robustness of the sub-symbolic component using DeepXplore while measuring symbolic verification effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can current V&V methods be effectively applied to neurosymbolic AI applications that combine knowledge graphs with convolutional neural networks?
- Basis in paper: [explicit] The paper identifies that knowledge graphs combined with CNNs is a frequent configuration in neurosymbolic AI applications, and suggests this combination could benefit from dedicated testing frameworks
- Why unresolved: While individual V&V methods exist for KGs and CNNs separately, the paper notes that their integration in neurosymbolic systems creates new challenges that current frameworks don't fully address
- What evidence would resolve it: A systematic study testing existing V&V frameworks on neurosymbolic KG-CNN applications, documenting which methods work, which fail, and identifying specific gaps

### Open Question 2
- Question: How can neurosymbolic AI architectures improve the efficiency of training deep learning models while maintaining or improving accuracy?
- Basis in paper: [inferred] The paper mentions that neurosymbolic AI could potentially make training more efficient through symbolic guidance, and notes that energy-efficient training is an important research direction
- Why unresolved: The paper identifies this as an open challenge but doesn't provide concrete evidence or comparisons between neurosymbolic and conventional deep learning approaches
- What evidence would resolve it: Empirical studies comparing training efficiency (time, energy consumption) and accuracy between neurosymbolic systems and comparable deep learning models across multiple tasks

### Open Question 3
- Question: What are the minimal verification requirements for symbolic components in neurosymbolic AI systems when the sub-symbolic component can handle noisy data?
- Basis in paper: [explicit] The paper discusses that neural networks can handle noise well, suggesting that complete verification of symbolic components might not always be necessary
- Why unresolved: The paper raises this as an open challenge but doesn't provide guidelines or metrics for determining when partial verification is sufficient
- What evidence would resolve it: Research establishing error bounds and tolerance levels for symbolic components in neurosymbolic systems, with case studies showing the relationship between verification thoroughness and system reliability

## Limitations
- Symbolic verification methods may become computationally intractable for large-scale problems, requiring approximation techniques that reduce verification completeness
- Current V&V frameworks for sub-symbolic components don't directly apply to neurosymbolic configurations without significant adaptation and modification
- The paper acknowledges that dedicated testing frameworks are needed for neurosymbolic systems, particularly for knowledge graph and CNN combinations

## Confidence
- High confidence in fundamental decidability of propositional logic and semi-decidability of first-order logic for symbolic verification
- Medium confidence in scalability and practical effectiveness of V&V methods in complex real-world neurosymbolic systems
- Medium confidence in existing sub-symbolic V&V methods' direct applicability to neurosymbolic architectures without modification

## Next Checks
1. **Performance Benchmarking**: Measure the computational overhead of symbolic verification layers when integrated with sub-symbolic components across different neurosymbolic architectures, comparing execution time and resource usage against pure sub-symbolic systems.

2. **Cross-Domain Robustness Testing**: Implement the same neurosymbolic V&V framework across multiple application domains (e.g., healthcare, autonomous driving, finance) to assess whether symbolic verification effectiveness generalizes beyond the survey's case studies.

3. **Scalability Analysis**: Evaluate how knowledge graph validation techniques (COPAAL, DeFacto) perform as the symbolic component's knowledge base grows from small-scale examples to real-world complexity levels, measuring both accuracy degradation and computational scaling.