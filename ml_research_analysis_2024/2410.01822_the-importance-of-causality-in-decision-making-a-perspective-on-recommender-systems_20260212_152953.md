---
ver: rpa2
title: 'The Importance of Causality in Decision Making: A Perspective on Recommender
  Systems'
arxiv_id: '2410.01822'
source_url: https://arxiv.org/abs/2410.01822
tags:
- causal
- causality
- systems
- item
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a causal decision-making framework for recommender
  systems (RSs) to address the fundamental issue that recommendation algorithms often
  produce biased estimates due to unmet assumptions of unbiasedness in real-world
  scenarios. The authors formulate the RS problem using potential outcomes and structural
  causal models, providing formal definitions of causal quantities to be estimated
  and a general causal graph as a reference for future research.
---

# The Importance of Causality in Decision Making: A Perspective on Recommender Systems

## Quick Facts
- **arXiv ID:** 2410.01822
- **Source URL:** https://arxiv.org/abs/2410.01822
- **Reference count:** 24
- **Primary result:** Presents a causal decision-making framework for recommender systems to address biased estimates due to unmet assumptions of unbiasedness

## Executive Summary
This paper addresses a fundamental issue in recommender systems: algorithms often produce biased estimates due to unmet assumptions of unbiasedness in real-world scenarios. The authors propose a causal decision-making framework that formulates the recommendation problem using potential outcomes and structural causal models. By providing formal definitions of causal quantities to be estimated and a general causal graph as a reference, the framework aims to bridge the gap between prediction and decision-making in recommender systems, enabling researchers to holistically define and address problems in the RS community.

## Method Summary
The proposed framework consists of four steps: (1) causal discovery using observational data and expert knowledge to construct a causal graph representing the data-generating process, (2) causal estimand identification using the adjustment formula estimator and identification criteria like backdoor criterion to transform interventional quantities into estimable statistical quantities, (3) estimation of causal effects using statistical models compatible with outcome variables (linear regression for continuous outcomes, neural networks for non-linear relations), and (4) making decisions using greedy, epsilon-greedy, or more sophisticated policies based on the estimated causal effects.

## Key Results
- Formalizes recommender systems as a causal inference problem using potential outcomes and structural causal models
- Provides a four-step framework for causal decision-making in RS: causal discovery, estimand identification, effect estimation, and decision-making
- Introduces a reference causal graph for RS as a foundation for future research
- Addresses the fundamental issue of biased estimates due to unmet assumptions of unbiasedness in real-world RS scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causality transforms biased RS predictions into unbiased causal estimands
- Mechanism: By modeling the recommendation process as a causal graph, the framework identifies confounding variables and uses adjustment formulas to isolate the true causal effect of a recommendation on user feedback
- Core assumption: The causal graph correctly captures the data-generating process, and all relevant confounders are identified and measured
- Evidence anchors:
  - [abstract] The authors formulate the RS problem using potential outcomes and structural causal models to address biased estimates due to unmet assumptions of unbiasedness
  - [section] The adjustment formula estimator removes do-terms to obtain equivalent statistical estimands using observational data
  - [corpus] Weak evidence - related papers discuss causal discovery and debiasing, but specific mechanism details are sparse
- Break condition: If key confounders are unmeasured or the causal graph is misspecified, the adjustment will fail to remove bias, leading to biased estimates

### Mechanism 2
- Claim: Causal discovery enables learning of accurate data-generating processes
- Mechanism: The framework combines observational data with expert knowledge through causal discovery algorithms to construct a causal graph that represents the RS domain
- Core assumption: Observational data contains sufficient information about causal relationships, and expert knowledge is accurate
- Evidence anchors:
  - [section] The first step is to have a causal graph that describes the data-generating process, which can be learned by combining observational data with experts' knowledge through causal discovery
  - [section] The authors provide a reference causal graph for RSs to guide construction of domain-specific graphs
  - [corpus] Moderate evidence - related papers discuss causal discovery in RSs, suggesting this is an active research area
- Break condition: If the causal discovery process fails to identify true causal relationships or relies on incorrect expert knowledge, the resulting graph will be invalid

### Mechanism 3
- Claim: The do-operator enables proper framing of decision-making problems
- Mechanism: By using the do-operator in causal estimands, the framework distinguishes between observational and interventional quantities, allowing proper decision-making based on causal effects rather than correlations
- Core assumption: The do-calculus and identification criteria (like backdoor criterion) can successfully remove do-terms from estimands
- Evidence anchors:
  - [section] The causal estimand uses the do-operator to define the intervention of fixing recommendation values, distinguishing it from conditioning on observed values
  - [section] Identification criteria like the backdoor criterion are used to identify variables that must be included in adjustment sets
  - [corpus] Moderate evidence - related papers discuss counterfactual inference and causal learning, suggesting active research in this area
- Break condition: If identification criteria cannot be satisfied, the causal effect is guaranteed to be unidentifiable, making causal estimation impossible

## Foundational Learning

- Potential Outcomes Framework
  - Why needed here: Provides the mathematical foundation for defining causal effects and estimands in the RS context
  - Quick check question: What is the difference between P(Y|X=x) and E[Y|do(X=x)] in terms of causal inference?

- Structural Causal Models
  - Why needed here: Represents the causal relationships between variables in the recommendation process using directed graphs
  - Quick check question: How does a structural causal model differ from a traditional statistical model in terms of assumptions about variable relationships?

- Do-calculus and Identification Criteria
  - Why needed here: Provides the mathematical tools to transform interventional quantities into estimable statistical quantities using observational data
  - Quick check question: What are the three rules of do-calculus, and how do they enable the removal of do-operators from causal estimands?

## Architecture Onboarding

- Component map: Causal Discovery Module -> Estimand Identification Module -> Effect Estimation Module -> Decision Policy Module
- Critical path: Data → Causal Discovery → Estimand Identification → Effect Estimation → Decision Making
- Design tradeoffs:
  - Complexity vs. accuracy: More sophisticated causal discovery methods may improve accuracy but increase computational cost
  - Model assumptions vs. flexibility: Parametric models may be more interpretable but less flexible than non-parametric approaches
  - Intervention scope vs. identifiability: Wider interventions may capture more causal effects but may be harder to identify from observational data
- Failure signatures:
  - High variance in estimated effects may indicate unmeasured confounding
  - Non-convergence of identification criteria may suggest unidentifiable causal effects
  - Poor decision performance despite good predictions may indicate model misspecification
- First 3 experiments:
  1. Validate causal discovery on synthetic data with known ground truth causal structure
  2. Compare adjustment formula estimates with randomized experiment results on a subset of the data
  3. Test different decision policies (greedy vs. epsilon-greedy) on a real-world RS dataset and measure recommendation quality metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively integrate expert knowledge with observational data to construct accurate causal graphs for recommender systems?
- Basis in paper: [explicit] The paper emphasizes the need for causal discovery algorithms that combine observational data with experts' knowledge, but does not provide specific methods for this integration.
- Why unresolved: The paper presents a general framework but does not detail how to practically implement the causal discovery step, especially in complex RS domains.
- What evidence would resolve it: A case study or experimental evaluation showing the effectiveness of different causal discovery methods in RS contexts, comparing expert-driven vs data-driven approaches.

### Open Question 2
- Question: Under what conditions are the assumptions of ignorability and unconfoundedness likely to be satisfied in real-world recommender systems?
- Basis in paper: [explicit] The authors stress that causality makes explicit assumptions like ignorability and unconfoundedness, and that these must be carefully evaluated for each context.
- Why unresolved: The paper acknowledges the importance of these assumptions but does not provide guidance on how to assess their validity in practice.
- What evidence would resolve it: Empirical studies across different RS domains demonstrating when and why these assumptions hold or fail, along with methods to test them.

### Open Question 3
- Question: How can we design recommendation policies that effectively balance exploration and exploitation while accounting for causal effects?
- Basis in paper: [explicit] The authors mention epsilon-greedy and more sophisticated policies but do not elaborate on their design in the context of causal RS.
- Why unresolved: The paper introduces the concept but lacks detailed discussion on policy design that incorporates causal estimates.
- What evidence would resolve it: Comparative studies of different policy designs in simulated or real RS environments, showing their performance in terms of both causal effect estimation and recommendation quality.

## Limitations

- The framework's effectiveness critically depends on the validity of causal discovery and the assumption of no unmeasured confounding, which are active research areas without guaranteed solutions
- The paper lacks empirical validation on real-world RS datasets, making practical performance claims uncertain
- The complexity of real recommendation scenarios may limit the practical applicability of the proposed approach due to the difficulty of satisfying identification criteria and modeling assumptions

## Confidence

- **High confidence**: The theoretical foundation linking causal inference to RS decision-making is sound and well-established in the causal inference literature
- **Medium confidence**: The four-step framework is methodologically coherent, but practical implementation challenges remain unaddressed
- **Low confidence**: The framework's performance claims lack empirical validation on real RS datasets

## Next Checks

1. Validate the causal discovery component on a synthetic RS dataset with known ground truth causal structure to assess its ability to recover true causal relationships
2. Compare the framework's causal estimates against ground truth from a randomized controlled trial on a real RS platform to measure bias reduction
3. Evaluate decision quality improvements by implementing the framework's recommendations in a live A/B test against standard RS algorithms