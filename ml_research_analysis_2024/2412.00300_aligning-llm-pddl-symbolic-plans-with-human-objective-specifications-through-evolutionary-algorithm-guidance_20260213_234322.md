---
ver: rpa2
title: Aligning LLM+PDDL Symbolic Plans with Human Objective Specifications through
  Evolutionary Algorithm Guidance
arxiv_id: '2412.00300'
source_url: https://arxiv.org/abs/2412.00300
tags:
- plan
- language
- feedback
- planning
- pddl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of generating accurate PDDL plans
  from natural language feedback using LLMs, which often produce imprecise translations.
  The authors propose a neurosymbolic framework that uses a genetic algorithm to search
  for improved symbolic plan specifications based on an initial LLM translation, guided
  by a trained LSTM-based adherence model.
---

# Aligning LLM+PDDL Symbolic Plans with Human Objective Specifications through Evolutionary Algorithm Guidance

## Quick Facts
- **arXiv ID:** 2412.00300
- **Source URL:** https://arxiv.org/abs/2412.00300
- **Reference count:** 21
- **Primary result:** Neurosymbolic framework improves plan adherence to user feedback from 32.49% (LLM-only) to 47.65% using genetic algorithm optimization

## Executive Summary
This paper addresses the challenge of generating accurate PDDL plans from natural language feedback using LLMs, which often produce imprecise translations. The authors propose a neurosymbolic framework that uses a genetic algorithm to search for improved symbolic plan specifications based on an initial LLM translation, guided by a trained LSTM-based adherence model. Evaluated on a naval disaster recovery scenario, the system improved plan adherence to user feedback from 32.49% (LLM-only) to 47.65%, successfully generating valid plans in 40% of cases where the LLM translation was incorrect. The approach demonstrates effectiveness in catching LLM errors but faces challenges with constraints requiring extended plan horizons or semantically similar actions.

## Method Summary
The system uses a genetic algorithm-based optimizer to search the space of symbolic plan specifications, starting from an initial specification provided by a possibly erroneous LLM translation. An LSTM-based adherence model quantifies how well generated plans align with user feedback by processing sequences of plan steps and feedback statements. The framework operates on a naval disaster recovery domain where users provide natural language feedback on plans, which is translated to PDDL constraints through a two-stage process (natural language → mid-level constraint → PDDL). The genetic algorithm iteratively modifies the specification, evaluating candidates using the adherence model until convergence or a generation limit is reached.

## Key Results
- Improved plan adherence from 32.49% (LLM-only) to 47.65% (LLM+GA) on naval disaster recovery scenarios
- Successfully generated valid plans in 40% of cases where the LLM translation was incorrect
- Achieved perfect adherence (100%) on constraints like "all assets start at ship dock" requiring minimal plan modification
- Faced challenges with constraints requiring extended plan horizons, showing 43% non-convergence rate for "all assets end at ship dock"

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The genetic algorithm improves plan adherence by exploring variations of the LLM-generated plan specification.
- Mechanism: The system starts with an LLM-generated plan specification that may contain mistranslations. A genetic algorithm generates a population of modified specifications through mutation and crossover operations. Each specification is evaluated using a trained LSTM adherence model that predicts whether plans generated from the specification align with user feedback. The genetic algorithm iteratively improves the population by selecting specifications that produce more adherent plans.
- Core assumption: The space of valid plan specifications contains solutions that better match user intent than the initial LLM translation.
- Evidence anchors:
  - [abstract] "Our system uses a genetic algorithm-based optimizer to search the space of symbolic plan specifications, based on an initial specification provided by a possibly erroneous LLM translation."
  - [section IV-D] "In order to generate a plan with improved adherence to the user's feedback, the system uses a genetic algorithm to search for plan specifications which produce adherent plans."

### Mechanism 2
- Claim: The LSTM-based adherence model enables automated evaluation of plan specification quality without requiring manual validation.
- Mechanism: The adherence model takes a plan and user feedback as input, embedding both using text embeddings. It processes the sequence of plan steps and feedback through LSTM layers to predict whether the plan adheres to the feedback. This automated evaluation allows the genetic algorithm to quickly assess many candidate specifications without human intervention.
- Core assumption: The LSTM model can learn to accurately predict plan adherence from embeddings of plans and feedback.
- Evidence anchors:
  - [section IV-C] "Our system utilizes a Specification Adherence Model as a means to quantify the extent to which a generated plan adheres to a set of user feedback statements."
  - [section IV-C] "To evaluate the adherence of the plan to a feedback statement, each step of the plan and the feedback statement are embedded using OpenAI's text-embedding-3-small model."

### Mechanism 3
- Claim: The two-stage translation process (natural language → mid-level constraint → PDDL) improves translation accuracy compared to direct translation.
- Mechanism: User feedback is first translated to mid-level constraints, which are natural language constraints grounded in the symbolic objects of the problem description. These mid-level constraints are then translated to atomic PDDL constraints. This intermediate representation helps maintain semantic alignment with user intent during the translation process.
- Core assumption: Breaking the translation into two stages preserves more semantic information than a single direct translation.
- Evidence anchors:
  - [section IV-A] "The system utilizes an LLM to initially translate each feedback statement, f i, into an atomic PDDL constraint, c i... The LLM first translates the feedback statement into a mid-level constraint, which is a natural language constraint that is grounded in the symbolic objects in the PDDL problem description."

## Foundational Learning

- Concept: PDDL syntax and semantics
  - Why needed here: The system manipulates PDDL constraints and generates plans from PDDL specifications. Understanding the grammar and semantics of PDDL constraints is essential for modifying specifications and interpreting results.
  - Quick check question: What are the key differences between state-trajectory constraints like "always" and "at end" in PDDL3?

- Concept: Genetic algorithm fundamentals
  - Why needed here: The system uses a genetic algorithm to search the space of plan specifications. Understanding selection, crossover, mutation, and fitness evaluation is crucial for tuning and debugging the algorithm.
  - Quick check question: How does the mutation operation in this system differ from standard genetic algorithm mutation, and why is this design choice important?

- Concept: LSTM and sequence modeling
  - Why needed here: The adherence model uses LSTM layers to process sequences of plan steps and feedback. Understanding LSTM architecture and training is important for model improvement and debugging.
  - Quick check question: What role does the dropout layer play in the LSTM adherence model, and how might changing the dropout rate affect model performance?

## Architecture Onboarding

- Component map: User Interface -> LLM Translator -> Symbolic Planner -> Adherence Model -> Genetic Algorithm -> PDDL Constraint Optimizer
- Critical path:
  1. User provides natural language feedback
  2. LLM translates feedback to initial PDDL specification
  3. Symbolic planner generates initial plan
  4. Adherence model evaluates plan quality
  5. Genetic algorithm searches for improved specifications
  6. Best specification is selected and used to generate final plan
- Design tradeoffs:
  - Population size vs. computation time: Larger populations may find better solutions but increase computation time
  - Adherence model accuracy vs. training data: More training data improves accuracy but requires more effort to collect
  - Number of GA generations vs. convergence quality: More generations may find better solutions but increase latency
- Failure signatures:
  - Non-convergence: GA fails to find valid plan within generation limit (43% for "all assets end at ship dock")
  - False positives: Adherence model incorrectly predicts adherence (100% for certain archetypes)
  - LLM mistranslation: Initial specification is fundamentally incorrect despite GA search
- First 3 experiments:
  1. Test LLM-only translation accuracy on simple feedback statements to establish baseline performance
  2. Validate adherence model accuracy on a small dataset with manual verification
  3. Run GA with a single constraint archetype to verify the complete pipeline works before scaling up

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the genetic algorithm's convergence rate be improved for constraints requiring extended plan horizons?
- Basis in paper: [explicit] The paper notes that constraints like "all assets end at the ship dock" require at least three additional actions and result in a 43% non-convergence rate.
- Why unresolved: The paper identifies this as a limitation but does not propose specific solutions for improving convergence on such constraints.
- What evidence would resolve it: Experiments comparing different GA configurations (population size, mutation rates, generation limits) on constraints requiring extended horizons, showing improved convergence rates.

### Open Question 2
- Question: Would using a smaller LLM for initial translation affect the overall performance of the neurosymbolic framework?
- Basis in paper: [explicit] The paper mentions this as future work but does not explore it experimentally.
- Why unresolved: The paper only tested with GPT-4 and did not compare against smaller models for the initial translation step.
- What evidence would resolve it: Comparative experiments using different LLM sizes (GPT-3.5, GPT-4) for initial translation while keeping the GA and adherence model constant.

### Open Question 3
- Question: How can the specification adherence model be improved to better handle semantically similar but disjoint actions?
- Basis in paper: [explicit] The paper found that constraints like "all underwater debris is removed" caused 100% false-positive rates due to semantic similarity issues.
- Why unresolved: The paper identifies this failure mode but does not propose architectural changes or training strategies to address it.
- What evidence would resolve it: Experiments showing improved performance after augmenting the training dataset with multiple constraints or using alternative model architectures (e.g., transformers instead of LSTM).

## Limitations
- The system shows 43% non-convergence rates for constraints requiring extended plan horizons, such as "all assets end at the ship dock"
- The adherence model demonstrates 100% false-positive rates on semantically similar constraints like "all underwater debris is removed"
- The approach requires ground-truth PDDL specifications for validation, limiting its applicability to scenarios where such specifications exist

## Confidence
- **High confidence:** The mechanism of using genetic algorithms to search plan specification space is well-established and the reported adherence improvements (32.49% → 47.65%) are statistically significant
- **Medium confidence:** The LSTM adherence model provides useful guidance for the GA search, though its limitations with semantically similar constraints suggest room for improvement
- **Medium confidence:** The two-stage translation process (natural language → mid-level constraint → PDDL) provides benefits, though the exact contribution of each stage is unclear

## Next Checks
1. Test the system's robustness on constraints requiring plan horizons beyond 20 steps to identify scalability limits
2. Conduct ablation studies removing the adherence model to quantify its contribution to GA effectiveness
3. Evaluate the system's performance on semantically ambiguous feedback statements to better characterize false-positive rates