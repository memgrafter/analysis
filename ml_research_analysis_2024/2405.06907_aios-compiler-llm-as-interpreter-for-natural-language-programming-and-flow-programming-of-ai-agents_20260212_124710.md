---
ver: rpa2
title: 'AIOS Compiler: LLM as Interpreter for Natural Language Programming and Flow
  Programming of AI Agents'
arxiv_id: '2405.06907'
source_url: https://arxiv.org/abs/2405.06907
tags:
- language
- step
- programming
- natural
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the CoRE system, which uses LLMs as interpreters
  to execute natural language programs (NLPg). It addresses the challenges of ambiguity
  and vagueness in natural language by defining a CoRE language that unifies natural
  language programming, pseudo-code programming, and flow programming.
---

# AIOS Compiler: LLM as Interpreter for Natural Language Programming and Flow Programming of AI Agents

## Quick Facts
- arXiv ID: 2405.06907
- Source URL: https://arxiv.org/abs/2405.06907
- Reference count: 40
- Key outcome: CoRE system achieves average score of 0.5744 on OpenAGI benchmark using GPT-4 as interpreter

## Executive Summary
This paper introduces the CoRE system, which uses large language models as interpreters to execute natural language programs (NLPg). The system addresses challenges of ambiguity and vagueness in natural language by defining a structured CoRE language that unifies natural language programming, pseudo-code programming, and flow programming. The LLM interpreter executes programs step-by-step while leveraging external memory for context and external tools for specialized tasks. The approach is evaluated on the OpenAGI benchmark, demonstrating improved performance compared to traditional zero-shot, chain-of-thought, and few-shot learning approaches.

## Method Summary
The CoRE system implements an LLM-based interpreter that executes structured natural language programs through a step-by-step approach. The method involves parsing natural language instructions into a structured CoRE language format with step names, types (Process/Decision/Terminal), instructions, and connections. The interpreter retrieves relevant information from external memory, constructs detailed prompts with task descriptions and current progress, executes each step while analyzing output for tool usage, and determines the next step through branching analysis. The system is evaluated on the OpenAGI benchmark across three task types using CLIP, BERT, and ViT scores as metrics.

## Key Results
- CoRE system achieves average score of 0.5744 on OpenAGI benchmark using GPT-4 as interpreter
- Outperforms zero-shot, chain-of-thought, and few-shot learning approaches across all task types
- Demonstrates improved performance particularly on Task 2 and average score when using Mixtral as interpreter

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CoRE unifies natural language programming, pseudo-code programming, and flow programming under a single syntax representation.
- Mechanism: The CoRE language defines a structured format using step name, step type (Process/Decision/Terminal), step instruction, and step connection. This structure logically organizes natural language instructions into a form that inherently mirrors pseudo-code logic and can be visualized as a workflow.
- Core assumption: Natural language instructions can be systematically structured to represent algorithmic logic without losing readability.
- Evidence anchors:
  - [abstract] "The proposed system unifies natural language programming, pseudo-code programming, and flow programming under the same representation"
  - [section] "Natural language programming offers a method where instructions are formulated in everyday language, making the code intuitive and accessible. When we structure all natural language instructions in a logical way, it inherently mirrors the essence of pseudo-code programming."
  - [corpus] Weak evidence - no direct corpus support found for this specific unification claim.
- Break condition: If natural language instructions contain excessive ambiguity that cannot be resolved through structured formatting, the unification would fail.

### Mechanism 2
- Claim: LLM interpreters execute natural language programs step-by-step while leveraging external memory and tools.
- Mechanism: The interpreter retrieves relevant information from memory, constructs a detailed prompt with task description, current progress, observation, and current instruction, analyzes output for tool usage, and determines the next step through branching analysis.
- Core assumption: LLMs can maintain coherent execution context across multiple steps when provided with structured information retrieval and tool invocation capabilities.
- Evidence anchors:
  - [abstract] "we develop a novel system for Code Representation and Execution (CoRE), which employs LLM as interpreter to interpret and execute natural language instructions"
  - [section] "In the CoRE system, the interpreter determines the useful information to execute the current step. Then the interpreter will integrate all relevant information to construct the prompt."
  - [corpus] Weak evidence - while related work exists on LLMs as interpreters, specific evidence for this exact step-by-step execution mechanism with memory and tools is limited.
- Break condition: If the context window size becomes insufficient to maintain coherence across steps, or if tool invocation fails to provide necessary specialized capabilities.

### Mechanism 3
- Claim: CoRE improves performance on OpenAGI benchmark compared to zero-shot, chain-of-thought, and few-shot learning approaches.
- Mechanism: By structuring programs in CoRE language and using LLM as interpreter with memory and tools, the system achieves better task completion rates and higher metric scores across different task types.
- Core assumption: Structured natural language programming with LLM interpretation provides better task-solving capability than direct prompting approaches.
- Evidence anchors:
  - [abstract] "The CoRE system is evaluated on the OpenAGI benchmark, demonstrating improved performance compared to zero-shot, chain-of-thought, and few-shot learning approaches, achieving an average score of 0.5744 using GPT-4 as the interpreter."
  - [section] "From the results, we can see that our CoRE planning schema is better on average performance than any baseline under both Mixtral and GPT-4 as the interpreters."
  - [corpus] No direct corpus support found for this specific benchmark performance comparison.
- Break condition: If the LLM's reasoning capabilities are insufficient to interpret the structured instructions correctly, or if external tools become unreliable.

## Foundational Learning

- Concept: Control structures (sequence, selection, iteration)
  - Why needed here: These fundamental programming constructs are directly mapped to CoRE language syntax through Process, Decision, and Terminal step types
  - Quick check question: How would you represent a "for loop" in CoRE language?

- Concept: Prompt engineering and context management
  - Why needed here: The LLM interpreter requires carefully constructed prompts with task description, progress tracking, observations, and instructions to maintain coherent execution
  - Quick check question: What are the four key elements that must be included in each interpreter prompt?

- Concept: Tool use and function calling in LLMs
  - Why needed here: The interpreter needs to invoke external tools when tasks exceed LLM capabilities, requiring proper tool name and argument specification
  - Quick check question: When should the interpreter decide to use external tools versus attempting to solve within the LLM?

## Architecture Onboarding

- Component map:
  - CoRE Language Parser -> LLM Interpreter Engine -> Memory Management System -> Tool Execution Module -> Progress Tracker

- Critical path:
  1. Parse CoRE program into structured format
  2. Initialize execution context with task description
  3. For each step: retrieve observations, construct prompt, execute, analyze output
  4. Determine next step based on step type and conditions
  5. Continue until terminal step reached

- Design tradeoffs:
  - Structured vs. unstructured natural language: More structure improves execution reliability but reduces natural language flexibility
  - Memory size vs. context window: Larger memory improves context but may exceed LLM input limits
  - Tool invocation vs. LLM reasoning: Tools provide specialized capabilities but add latency and complexity

- Failure signatures:
  - Infinite loops: Decision steps failing to progress due to incorrect branching
  - Memory overflow: Storing too many intermediate results for the LLM to process
  - Tool invocation failures: External tools not responding or returning invalid data
  - Context loss: LLM forgetting previous steps despite memory retrieval

- First 3 experiments:
  1. Implement a simple arithmetic program (e.g., "add two numbers, then multiply by 3") and verify step-by-step execution
  2. Create a conditional program (e.g., "if input > 10, return double, else return triple") and test branching logic
  3. Build a multi-step workflow that requires tool invocation (e.g., "get current time, then format it as string")

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CoRE system perform compared to other methods when using open-source LLMs as interpreters?
- Basis in paper: [explicit] The paper mentions that CoRE outperforms Zero-shot and CoT under each type of task when using Mixtral as the interpreter, and is better than Few-shot learning on Task 2 and average score.
- Why unresolved: While the paper provides some results for Mixtral, a comprehensive comparison with other open-source LLMs is not provided.
- What evidence would resolve it: Conduct experiments using a wider range of open-source LLMs and compare their performance with CoRE.

### Open Question 2
- Question: How does the performance of the CoRE system change when using different natural language programming instructions?
- Basis in paper: [inferred] The paper mentions that even for the same CoRE program, the system may perform differently when using different LLM as interpreters, implying that the performance might also vary with different instructions.
- Why unresolved: The paper does not explore the impact of different natural language programming instructions on the system's performance.
- What evidence would resolve it: Conduct experiments using different sets of natural language programming instructions and analyze the system's performance.

### Open Question 3
- Question: Can the CoRE system be extended to support real-time debugging features?
- Basis in paper: [explicit] The paper mentions that a future direction is to implement real-time debugging features to aid in education and assist novice programmers.
- Why unresolved: The paper does not provide any implementation details or results for real-time debugging features.
- What evidence would resolve it: Develop and implement real-time debugging features in the CoRE system and evaluate their effectiveness in improving the system's usability and accessibility.

## Limitations

- Evaluation is limited to a single benchmark (OpenAGI) without comparison to established programming benchmarks or real-world applications
- Claims about unification of programming paradigms lack empirical validation of programmer comprehension and maintainability benefits
- Performance metrics are domain-specific to OpenAGI tasks and may not generalize to broader programming applications

## Confidence

- **High Confidence**: The basic feasibility of using LLMs as interpreters for structured natural language instructions is well-supported by the mechanism description and implementation details.
- **Medium Confidence**: The claim of improved performance on OpenAGI benchmark is supported by reported results but limited by single benchmark evaluation and lack of comparison to other LLM-based programming approaches.
- **Low Confidence**: The broader claims about unification of programming paradigms and generalizability to real-world programming tasks are not adequately supported by the evidence presented.

## Next Checks

1. **Cross-Benchmark Validation**: Test the CoRE system on established programming benchmarks (e.g., HumanEval, MBPP) to verify if performance improvements generalize beyond the OpenAGI domain.

2. **Ablation Study on CoRE Language**: Conduct controlled experiments removing the CoRE language structure while keeping the LLM interpreter to quantify the specific contribution of the unified syntax representation to performance gains.

3. **Programmer Comprehension Study**: Evaluate whether programs written in CoRE language are actually more comprehensible and maintainable than equivalent pseudo-code or natural language descriptions through human subject testing with software developers.