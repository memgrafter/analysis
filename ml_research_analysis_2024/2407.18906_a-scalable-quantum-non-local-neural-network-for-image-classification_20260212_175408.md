---
ver: rpa2
title: A Scalable Quantum Non-local Neural Network for Image Classification
arxiv_id: '2407.18906'
source_url: https://arxiv.org/abs/2407.18906
tags:
- quantum
- neural
- qnl-net
- classical
- classi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a scalable Quantum Non-local Neural Network
  (QNL-Net) that leverages quantum entanglement and quantum-enhanced feature space
  to capture long-range dependencies for image classification. The hybrid quantum-classical
  model employs variational quantum circuits with three distinct ansatzes to replicate
  classical non-local operations, achieving 99.96% accuracy on MNIST and 93.98% on
  CIFAR-10 binary classification using only 4 qubits.
---

# A Scalable Quantum Non-local Neural Network for Image Classification

## Quick Facts
- **arXiv ID**: 2407.18906
- **Source URL**: https://arxiv.org/abs/2407.18906
- **Authors**: Sparsh Gupta; Debanjan Konar; Vaneet Aggarwal
- **Reference count**: 26
- **Primary result**: 99.96% accuracy on MNIST and 93.98% on CIFAR-10 binary classification using only 4 qubits

## Executive Summary
This work introduces a scalable Quantum Non-local Neural Network (QNL-Net) that leverages quantum entanglement and quantum-enhanced feature space to capture long-range dependencies for image classification. The hybrid quantum-classical model employs variational quantum circuits with three distinct ansatzes to replicate classical non-local operations, achieving 99.96% accuracy on MNIST and 93.98% on CIFAR-10 binary classification using only 4 qubits. The proposed architecture integrates classical dimensionality reduction techniques (CNN or PCA) to preprocess data before quantum processing, demonstrating superior performance compared to existing quantum classifiers while using significantly fewer qubits.

## Method Summary
The QNL-Net architecture combines classical preprocessing with quantum processing, where classical dimensionality reduction (CNN or PCA) reduces image features to 4 components, followed by quantum encoding, variational quantum circuit processing, and measurement. The quantum circuit uses parameterized rotations and CX entanglements in three different patterns (cyclic, reverse linear, mixed) to capture pairwise relationships in feature space. The model is trained end-to-end using classical optimization (Adam) with NLL loss, achieving 99.96% accuracy on MNIST and 93.98% on CIFAR-10 binary classification using only 4 qubits.

## Key Results
- Achieves 99.96% accuracy on MNIST binary classification using only 4 qubits
- Demonstrates 93.98% accuracy on CIFAR-10 binary classification (birds vs ships) with the same 4-qubit setup
- Outperforms existing quantum classifiers like QTN-VQC (98.6% accuracy) and Hybrid TTN-MERA (99.87% accuracy) while using significantly fewer qubits
- Shows that quantum entanglement and parallelism can capture long-range dependencies more efficiently than classical approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Quantum entanglement in QNL-Net enables simultaneous processing of multiple features, capturing long-range dependencies more efficiently than classical non-local operations.
- **Mechanism**: Entanglement creates strong correlations between all qubits through CX gates, allowing the quantum state to encode pairwise relationships without explicitly computing them, which reduces computational complexity from quadratic to linear in circuit depth.
- **Core assumption**: The entanglement structure (cyclic, reverse linear, or mixed pattern) sufficiently captures all pairwise dependencies needed for non-local operations.
- **Evidence anchors**:
  - [abstract]: "involving pairwise relationships through quantum entanglement"
  - [section]: "The proposed QNL-Net utilizes CX entanglements to replicate variable dependencies present in classical non-local mechanisms"
  - [corpus]: Weak evidence - only one paper mentions non-local observables, no direct comparison to entanglement-based approaches
- **Break condition**: If entanglement patterns fail to capture essential feature correlations, or if quantum noise destroys the entanglement before measurement, the model performance degrades to classical levels.

### Mechanism 2
- **Claim**: Quantum parallelism allows QNL-Net to process exponentially many feature combinations simultaneously, providing computational advantage for non-local operations.
- **Mechanism**: Superposition states created by Hadamard gates and rotation gates enable the quantum circuit to explore multiple feature configurations in parallel during the variational quantum circuit execution, reducing the number of required evaluations.
- **Core assumption**: The variational quantum circuit ansatz is sufficiently expressive to represent the optimal non-local relationships in the feature space.
- **Evidence anchors**:
  - [abstract]: "inherent quantum parallelism to allow the simultaneous processing of a large number of input features"
  - [section]: "Quantum parallelism allows for the simultaneous processing of a large number of states, enabling more efficient computations in tasks involving pairwise relationships"
  - [corpus]: Moderate evidence - multiple papers discuss quantum parallelism in feature space but limited empirical validation for non-local operations
- **Break condition**: If the ansatz cannot represent the optimal solution, or if the number of qubits becomes too small to capture the feature space dimensionality, the parallelism advantage disappears.

### Mechanism 3
- **Claim**: Quantum-enhanced feature mapping transforms classical data into high-dimensional spaces where patterns become more separable and interpretable for non-local operations.
- **Mechanism**: The measurement encoder maps classical pixel values into quantum amplitudes through parameterized rotations, creating interference patterns that highlight relevant feature relationships for classification.
- **Core assumption**: The feature mapping preserves the essential information needed for classification while creating beneficial interference patterns.
- **Evidence anchors**:
  - [abstract]: "quantum feature mapping in the proposed QNL-Net transforms classical data into high-dimensional quantum spaces where patterns become more interpretable"
  - [section]: "To encode classical data X = [y0,y 1,···,y n− 1]∈ Rn into the quantum space, we first write |X⟩ as the quantum version of X"
  - [corpus]: Weak evidence - limited discussion of feature mapping in related works, mostly focused on other quantum neural network approaches
- **Break condition**: If the mapping loses critical information during encoding, or if the measurement basis doesn't capture the relevant features, classification accuracy degrades significantly.

## Foundational Learning

- **Concept**: Quantum superposition and entanglement
  - Why needed here: Understanding how qubits can represent multiple states simultaneously and how entanglement creates correlations is fundamental to grasping why QNL-Net can capture non-local dependencies efficiently
  - Quick check question: If you have two entangled qubits in state |ψ⟩ = (|00⟩ + |11⟩)/√2, what happens to the state of the second qubit when you measure the first qubit in the |0⟩ state?

- **Concept**: Variational quantum circuits and parameterized gates
  - Why needed here: The QNL-Net relies on trainable quantum circuits where rotation angles are optimized through classical gradient descent, so understanding how these circuits work and how they're trained is essential
  - Quick check question: In a variational quantum circuit with rotation gates Rx(θ), Ry(φ), Rz(λ), how many independent parameters are there for a single qubit layer?

- **Concept**: Quantum measurement and Born rule
  - Why needed here: The final classification decision in QNL-Net comes from measuring qubits in the Pauli-Z basis, so understanding how measurement probabilities relate to the quantum state is crucial
  - Quick check question: If a qubit is in state |ψ⟩ = α|0⟩ + β|1⟩, what is the probability of measuring |0⟩ and what observable are you measuring?

## Architecture Onboarding

- **Component map**: Classical preprocessing (CNN or PCA) → Feature vector reduction (4×1) → Quantum encoding layer (Hadamard + parameterized rotations) → Variational quantum circuit (3 ansatzes with rotation + entanglement layers) → Measurement layer (Pauli-Z basis at qubit 0) → Classical post-processing (fully connected layer) → Classification output

- **Critical path**: Classical preprocessing → Quantum encoding → VQC execution → Measurement → Classical post-processing → Classification output

- **Design tradeoffs**:
  - Ansatz complexity vs. qubit count: More complex ansatzes could capture better relationships but require more qubits
  - Classical preprocessing vs. quantum processing: More sophisticated classical preprocessing could reduce quantum circuit requirements
  - Measurement basis selection: Measuring at different qubits or using different bases could capture different feature relationships

- **Failure signatures**:
  - Training loss plateaus early: Could indicate the ansatz is too simple or the learning rate is inappropriate
  - Test accuracy much lower than training accuracy: Suggests overfitting or that quantum noise is affecting generalization
  - Very slow convergence: Might indicate the learning rate is too low or the circuit depth is insufficient

- **First 3 experiments**:
  1. **Baseline verification**: Run QNL-Net with all parameters frozen except the measurement basis to verify the quantum circuit is functioning correctly
  2. **Learning rate sweep**: Test different learning rates (0.0001 to 0.001) with fixed ansatz to find optimal training convergence
  3. **Ansatz comparison**: Test all three ansatzes (cyclic, reverse linear, mixed) with the same hyperparameters to identify which entanglement pattern works best for the dataset

## Open Questions the Paper Calls Out

- **Question**: How does the performance of QNL-Net scale when increasing the number of qubits beyond 4, particularly for multi-class classification tasks?
  - **Basis in paper**: [explicit] The paper notes that multi-class classification performed poorly with the current 4-qubit setup, and limitations in fault-tolerance and quantum scalability are acknowledged as challenges.
  - **Why unresolved**: The current implementation only uses 4 qubits, and the paper explicitly states that scaling to larger datasets and more complex models presents computational challenges.
  - **What evidence would resolve it**: Experimental results demonstrating QNL-Net's performance with 8-16 qubits on multi-class datasets (e.g., full MNIST with 10 classes) would clarify scalability limits and performance improvements.

- **Question**: What is the impact of different quantum encoding strategies (e.g., amplitude encoding, tensor product encoding) on QNL-Net's classification accuracy and efficiency?
  - **Basis in paper**: [inferred] The paper uses a specific Pauli-Z measurement at one qubit and mentions that the choice of encoding could be explored further, but doesn't systematically compare encoding methods.
  - **Why unresolved**: Only one encoding method (MeasurementEncoder with Pauli-Z basis) is tested, and the paper suggests that exploring different quantum encodings could be valuable.
  - **What evidence would resolve it**: Comparative experiments using various encoding strategies (amplitude, tensor product, or other feature maps) with identical ansatzes and datasets would reveal optimal encoding approaches.

- **Question**: How does QNL-Net's performance compare to classical non-local networks on the same datasets when accounting for qubit count and training complexity?
  - **Basis in paper**: [explicit] The paper compares QNL-Net to other quantum classifiers but doesn't directly benchmark against classical non-local networks using equivalent computational resources.
  - **Why unresolved**: The paper focuses on quantum-classical hybrid advantages but lacks direct comparison to classical non-local operations with similar parameter counts and computational budgets.
  - **What evidence would resolve it**: Head-to-head experiments matching parameter counts and computational complexity between QNL-Net and classical non-local networks on identical datasets would quantify the quantum advantage.

## Limitations

- The scalability of the 4-qubit architecture to more complex multi-class classification tasks remains unproven, with explicit acknowledgment of limitations in fault-tolerance and quantum scalability
- The theoretical advantages of quantum parallelism and entanglement for non-local operations lack rigorous empirical validation against classical non-local methods
- The relationship between specific entanglement patterns and their effectiveness in capturing non-local dependencies is underspecified with limited direct evidence

## Confidence

**High Confidence**: The experimental results showing 99.96% accuracy on MNIST and 93.98% on CIFAR-10 are well-documented with specific metrics and comparison to baseline methods. The hybrid architecture combining classical preprocessing with quantum processing is clearly specified.

**Medium Confidence**: The claims about quantum entanglement enabling efficient capture of long-range dependencies are supported by the mathematical framework but lack direct empirical validation against classical non-local methods. The superiority over existing quantum classifiers is demonstrated but could benefit from more comprehensive benchmarking.

**Low Confidence**: The theoretical advantages of quantum parallelism and quantum-enhanced feature mapping are described but not rigorously proven through ablation studies or theoretical analysis. The mechanism by which entanglement patterns replicate classical non-local operations needs more detailed explanation.

## Next Checks

1. **Ablation study on entanglement patterns**: Test the QNL-Net with systematically reduced entanglement complexity to quantify the contribution of quantum entanglement to performance gains versus classical processing.

2. **Classical non-local comparison**: Implement a classical non-local neural network with similar architecture (including the same preprocessing) and compare performance to isolate the quantum advantage.

3. **Scalability analysis**: Test the QNL-Net on incrementally more complex datasets (e.g., adding more classes to CIFAR-10 or using higher resolution images) to evaluate how performance scales with problem complexity and whether the 4-qubit architecture remains sufficient.