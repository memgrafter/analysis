---
ver: rpa2
title: The Impact of Element Ordering on LM Agent Performance
arxiv_id: '2409.12089'
source_url: https://arxiv.org/abs/2409.12089
tags:
- ordering
- elements
- element
- text
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study finds that the ordering of elements in an LM agent\u2019\
  s state representation has a major impact on performance\u2014randomizing the order\
  \ degrades performance as much as removing all text. This is especially true for\
  \ more challenging tasks and advanced models."
---

# The Impact of Element Ordering on LM Agent Performance

## Quick Facts
- arXiv ID: 2409.12089
- Source URL: https://arxiv.org/abs/2409.12089
- Reference count: 40
- One-line primary result: Randomizing element order degrades LM agent performance as much as removing all text

## Executive Summary
This paper investigates how the ordering of UI elements in an LM agent's state representation affects task performance. The authors find that randomizing element order degrades performance as severely as removing all visible text, particularly for challenging tasks and advanced models. They address pixel-only environments by training a UI element detection model on Common Crawl data and using t-SNE-based dimensionality reduction to order elements effectively, achieving more than double the task completion rate on OmniACT compared to previous state-of-the-art.

## Method Summary
The authors train a Faster-RCNN model on CommonCrawl data to detect interactable UI elements from pixel screenshots, then use EasyOCR to extract text from these elements. They apply t-SNE dimensionality reduction to element coordinates to generate an effective ordering sequence, which is combined with extracted text. This representation is evaluated with LM agents (GPT-4V, Gemini 1.5, Llama3) using high-level action spaces on VisualWebArena and OmniACT benchmarks. The approach compares t-SNE ordering against random and raster orderings to demonstrate the importance of element ordering for LM agent performance.

## Key Results
- Randomizing element ordering degrades LM agent performance as severely as removing all visible text
- t-SNE-based ordering more than doubles task completion rate on OmniACT compared to previous state-of-the-art
- Element detection from pixels combined with effective ordering enables strong performance in pixel-only environments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Randomizing element ordering degrades LM agent performance as severely as removing all visible text.
- Mechanism: Language models process information sequentially; when element order is randomized, the model cannot rely on spatial or logical grouping of related UI elements, leading to degraded reasoning and task completion.
- Core assumption: The model uses element ordering as implicit context to understand functional relationships between UI elements.
- Evidence anchors:
  - [abstract]: "randomizing element ordering in a webpage degrades agent performance comparably to removing all visible text from an agent's state representation"
  - [section]: "Randomizing element ordering in a webpage degrades agent performance comparably to removing all visible text from an agent's state representation"
- Break condition: If the LM model develops non-sequential reasoning capabilities or uses attention mechanisms that bypass element ordering dependencies.

### Mechanism 2
- Claim: t-SNE-based dimensionality reduction provides effective element ordering for pixel-only environments by preserving local spatial relationships.
- Mechanism: t-SNE reduces 2D pixel coordinates to 1D while retaining local structure, ensuring visually proximate elements (often functionally related) remain adjacent in the sequence presented to the LM.
- Core assumption: Visually close UI elements are more likely to be functionally associated, and LMs benefit from such adjacency in sequential input.
- Evidence anchors:
  - [abstract]: "dimensionality reduction provides a viable ordering for pixel-only environments"
  - [section]: "t-SNE's ability to retain local structure allows it to generate an effective ordering"
- Break condition: If the visual proximity-to-functionality correlation weakens in certain UI designs or if the LM becomes context-aware beyond sequential dependencies.

### Mechanism 3
- Claim: Training a UI element detection model on Common Crawl data enables effective element extraction from pixels, improving performance over generic segmentation approaches.
- Mechanism: A Faster-RCNN model trained specifically on interactable UI elements from webpages learns to detect elements relevant to agent tasks, rather than generic objects, providing higher quality inputs for ordering and action selection.
- Core assumption: UI elements relevant to agents differ from generic image objects, and specialized training improves detection accuracy in agent contexts.
- Evidence anchors:
  - [abstract]: "We train a UI element detection model to derive elements from pixels"
  - [section]: "We train an object detection model [16] to detect interactable UI elements specifically for agents"
- Break condition: If the domain gap between webpages and target environments (e.g., desktop apps) becomes too large for the trained model to generalize effectively.

## Foundational Learning

- Concept: Document Object Model (DOM) hierarchy and pre-order traversal
  - Why needed here: Understanding DOM structure explains why webpages have natural element ordering, while pixel-only environments lack this, motivating the need for learned ordering methods.
  - Quick check question: How does pre-order traversal of a DOM tree differ from raster scanning in terms of element ordering logic?

- Concept: t-SNE dimensionality reduction and local structure preservation
  - Why needed here: t-SNE is used to convert 2D spatial coordinates into 1D sequences while maintaining local relationships, which is crucial for effective element ordering.
  - Quick check question: What property of t-SNE makes it more suitable than PCA for preserving local spatial relationships in element ordering?

- Concept: Object detection model training and domain adaptation
  - Why needed here: Training a Faster-RCNN on Common Crawl data for UI element detection requires understanding how to adapt models from one domain (webpages) to another (pixel-only environments).
  - Quick check question: Why might a UI element detection model trained on webpages still perform reasonably on desktop application screenshots despite domain shift?

## Architecture Onboarding

- Component map: Pixel input → UI element detection model (Faster-RCNN) → Bounding boxes with IDs → OCR for text extraction → t-SNE ordering → Sequential element list → LM agent → Action output
- Critical path: UI element detection → t-SNE ordering → LM input sequence formation
- Design tradeoffs:
  - Using t-SNE vs. raster ordering: t-SNE better preserves functional relationships but adds computational overhead
  - Specialized UI detection vs. generic segmentation: Higher accuracy for agent-relevant elements but requires training data and domain adaptation
  - Multimodal vs. text-only representation: Multimodal helps but text remains essential for web/desktop navigation
- Failure signatures:
  - Random ordering consistently yields lowest performance across experiments
  - Removing text representation causes dramatic performance drops even with visual input
  - Element detection failures lead to missing critical UI elements, breaking task completion
- First 3 experiments:
  1. Compare random, raster, and t-SNE ordering on a small set of OmniACT tasks using a pre-trained UI detection model
  2. Ablation study: Remove text vs. randomize ordering to confirm relative impact on performance
  3. Domain adaptation test: Evaluate UI detection model trained on webpages on desktop application screenshots

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does element ordering impact agent performance in purely image-based representations without any accompanying text?
- Basis in paper: [inferred] The paper states "The impact of element ordering may or may not generalize to an image only representation" and "our results indicated that a visual representation alone was insufficient for web and desktop environments which prevents us from conducting this experiment."
- Why unresolved: The authors were unable to test image-only representations due to poor performance of visual-only approaches in web and desktop environments, though they note that mobile environments showed comparable performance with and without text.
- What evidence would resolve it: Experiments comparing different ordering methods (random, raster, t-SNE) on image-only representations in mobile or other visual-only environments would provide empirical evidence of ordering's impact.

### Open Question 2
- Question: Would training the UI element detection model on a more diverse dataset beyond Common Crawl webpages improve performance on desktop applications?
- Basis in paper: [explicit] The authors state "We gather a dataset by finding 67,530 interactable elements over 1468 Common Crawl webpages" and note "Despite the domain shift from webpages to desktop applications, we found that our object detection model worked reasonably well on the OmniACT benchmark."
- Why unresolved: The authors acknowledge a domain shift between webpages and desktop applications but don't explore whether training on a more diverse or application-specific dataset would yield better results.
- What evidence would resolve it: Training and evaluating the UI detection model on datasets specifically containing desktop application screenshots would show whether domain-specific training improves performance.

### Open Question 3
- Question: How would different dimensionality reduction techniques compare to t-SNE for ordering elements in pixel-only environments?
- Basis in paper: [explicit] The authors state "We provided two simple methods to apply ordering when a default ordering is not given" (random and raster) and "We provided a method of ordering elements through dimensionality reduction and showed that it performed best in realistic environments" (t-SNE), but acknowledge this could be improved.
- Why unresolved: The authors only tested t-SNE among dimensionality reduction techniques and found it effective, but suggest future research could introduce "more sophisticated methods to find ordering with only pixel information."
- What evidence would resolve it: Direct comparisons of t-SNE against other dimensionality reduction methods (UMAP, PCA, etc.) applied to the same UI element ordering task would show which technique performs best.

## Limitations

- Domain Generalization: The UI element detection model is trained on CommonCrawl webpage data but evaluated on desktop application screenshots, raising questions about cross-domain robustness.
- Temporal Dynamics: The study doesn't address how element ordering affects agents dealing with dynamic content that changes during interaction.
- Alternative Ordering Methods: While t-SNE is shown to outperform random ordering, the paper doesn't extensively compare against other dimensionality reduction techniques.

## Confidence

- **High Confidence**: The core finding that element ordering significantly impacts LM agent performance, and that randomizing order degrades performance comparably to removing text.
- **Medium Confidence**: The effectiveness of t-SNE-based ordering for pixel-only environments.
- **Medium Confidence**: The generalizability of the UI element detection model across different UI domains.

## Next Checks

1. **Cross-Domain Detection Robustness**: Evaluate the UI element detection model's performance on a held-out set of desktop applications not seen during training, measuring detection accuracy and false positive rates to quantify domain shift effects.

2. **Alternative Ordering Baselines**: Implement and compare t-SNE ordering against UMAP and Isomap dimensionality reduction methods, as well as a learned ordering approach using a small MLP trained to predict element adjacency based on visual and functional features.

3. **Dynamic Content Handling**: Design a synthetic benchmark with dynamic UI elements (loading states, pop-ups, disappearing elements) to test whether the current element ordering approach degrades under temporal changes, and if so, develop a simple heuristic to re-order elements based on visibility or interaction recency.