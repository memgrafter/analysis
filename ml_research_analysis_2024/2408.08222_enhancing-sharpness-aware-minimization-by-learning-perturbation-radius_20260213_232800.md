---
ver: rpa2
title: Enhancing Sharpness-Aware Minimization by Learning Perturbation Radius
arxiv_id: '2408.08222'
source_url: https://arxiv.org/abs/2408.08222
tags:
- uni00000013
- learning
- uni00000036
- uni00000024
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method called LETS to learn the perturbation
  radius for sharpness-aware minimization (SAM) algorithms. The core idea is to formulate
  the problem of learning the perturbation radius as a bilevel optimization problem,
  where the upper-level problem aims to minimize the squared generalization gap between
  training and validation losses, while the lower-level problem is the SAM optimization.
---

# Enhancing Sharpness-Aware Minimization by Learning Perturbation Radius

## Quick Facts
- arXiv ID: 2408.08222
- Source URL: https://arxiv.org/abs/2408.08222
- Authors: Xuehao Wang; Weisen Jiang; Shuai Fu; Yu Zhang
- Reference count: 40
- One-line primary result: A gradient-based method to learn the perturbation radius in SAM, improving generalization across vision and NLP tasks.

## Executive Summary
This paper introduces LETS (Learning to Enhance Sharpness-aware minimization), a method that learns the perturbation radius for SAM algorithms via bilevel optimization. By minimizing the squared generalization gap between validation and training losses, LETS adaptively tunes the radius during training. Experimental results demonstrate improved performance over standard SAM and its variants across multiple benchmark datasets in both computer vision and natural language processing.

## Method Summary
LETS formulates the problem of learning the perturbation radius as a bilevel optimization problem. The lower-level problem optimizes model parameters using SAM or ASAM with a fixed radius, while the upper-level problem minimizes the squared generalization gap by updating the radius via gradient descent. The method maintains SAM's convergence properties while adaptively tuning the radius to improve generalization. LETS is tested with both SAM and ASAM, referred to as LETS-SAM and LETS-ASAM respectively.

## Key Results
- LETS-SAM and LETS-ASAM outperform standard SAM and ASAM on CIFAR-10, CIFAR-100, ImageNet, GLUE benchmark, and IWSLT'14 DE-EN datasets
- The learned perturbation radius adapts dynamically during training, showing improved generalization compared to fixed or grid-searched values
- Theoretical analysis shows LETS preserves SAM's O(1/√T) convergence rate under similar conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LETS learns an optimal perturbation radius by minimizing the squared generalization gap between validation and training losses.
- Mechanism: The bilevel optimization structure ensures that the lower-level SAM training is constrained by the upper-level objective of minimizing generalization gap, effectively tuning ρ to regions that improve validation performance.
- Core assumption: The generalization gap is a reliable proxy for model generalization quality and is differentiable with respect to ρ through the training process.
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If the generalization gap does not correlate with actual generalization (e.g., in overparameterized regimes), the learned ρ may not improve performance.

### Mechanism 2
- Claim: LETS improves SAM's effectiveness by adaptively scaling the perturbation radius rather than using a fixed or grid-searched value.
- Mechanism: By treating ρ as a learnable parameter and updating it via gradient descent on the upper-level objective, LETS can adjust ρ dynamically during training to match the evolving loss landscape.
- Core assumption: The perturbation radius affects generalization in a smooth and differentiable manner through the training dynamics.
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If the gradient-based update for ρ is unstable or if ρ changes too rapidly, training could diverge or become inefficient.

### Mechanism 3
- Claim: LETS maintains SAM's convergence rate while improving generalization by learning ρ.
- Mechanism: The theoretical analysis shows that the O(1/√T) convergence rate is preserved because the additional gradient computation for ρ does not affect the dominant terms in the convergence bound.
- Core assumption: The smoothness and bounded variance assumptions on the loss hold and the additional update steps for ρ do not introduce harmful noise.
- Evidence anchors: [section], [section], [corpus]
- Break condition: If the additional hyperparameter tuning for ρ destabilizes training or if the Hessian approximation becomes inaccurate, the convergence guarantee may not hold in practice.

## Foundational Learning

- Concept: Bilevel optimization
  - Why needed here: The problem of learning the perturbation radius is naturally formulated as a bilevel problem, where the lower level optimizes the model parameters given ρ, and the upper level optimizes ρ given the model.
  - Quick check question: What is the difference between a single-level and a bilevel optimization problem?

- Concept: Sharpness-aware minimization (SAM)
  - Why needed here: LETS is built on top of SAM and aims to improve its performance by learning the perturbation radius; understanding SAM's min-max formulation and gradient updates is essential.
  - Quick check question: How does SAM's perturbation step relate to finding flat minima?

- Concept: Gradient-based hyperparameter optimization
  - Why needed here: LETS uses gradient descent to update the perturbation radius; understanding techniques like implicit differentiation or iterative differentiation is necessary.
  - Quick check question: What are the main challenges of computing gradients for hyperparameters in deep learning?

## Architecture Onboarding

- Component map: Validation set -> Upper-level optimizer (ρ) -> Squared generalization gap -> Lower-level optimizer (θ) -> Training set

- Critical path:
  1. Sample mini-batches from training and validation sets.
  2. Compute SAM/ASAM perturbation and model update (lower level).
  3. Compute gradients of validation and training losses at updated model.
  4. Compute gradient of squared generalization gap w.r.t. ρ (upper level).
  5. Update ρ using upper-level optimizer.
  6. Repeat for next iteration.

- Design tradeoffs:
  - Memory vs. speed: Approximating the Hessian (via diagonal of squared gradients) saves memory and computation but may be less accurate.
  - Hyperparameter tuning: LETS introduces additional hyperparameters (e.g., learning rate for ρ) that must be tuned.
  - Stability: The bilevel update can be unstable if the gradient of the upper-level objective is noisy or if ρ is updated too aggressively.

- Failure signatures:
  - If ρ becomes too large or too small, SAM updates may become ineffective or unstable.
  - If the generalization gap does not decrease, the upper-level objective may not be well-aligned with true generalization.
  - If the approximation of the Hessian is poor, the update for ρ may be inaccurate.

- First 3 experiments:
  1. Run SAM and LETS-SAM with the same base optimizer on a small vision dataset (e.g., CIFAR-10) and compare final validation accuracy and learned ρ trajectories.
  2. Perform a sensitivity analysis: initialize ρ at different values and observe convergence and final performance.
  3. Visualize the loss landscape before and after LETS training to verify that the learned radius leads to flatter minima.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LETS vary when using different generalization metrics beyond the squared generalization gap, such as the absolute generalization gap or a weighted combination of training and validation losses?
- Basis in paper: [explicit] The paper mentions that different generalization metrics (e.g., validation loss, generalization gap, or its square) can be used in the upper-level problem, and empirical results show that the squared generalization gap achieves the best performance.
- Why unresolved: The paper only tests a limited set of generalization metrics, leaving the potential of other metrics unexplored.
- What evidence would resolve it: Experiments comparing LETS with various generalization metrics on multiple datasets and architectures, quantifying performance differences and identifying the most effective metric for different scenarios.

### Open Question 2
- Question: What is the theoretical justification for the convergence rate of LETS, and can tighter bounds be derived under specific assumptions about the loss landscape?
- Basis in paper: [explicit] The paper provides a theoretical analysis of LETS-SAM's convergence rate, showing it is O(1/√T), which matches the rate of SAM and its variants.
- Why unresolved: The convergence analysis relies on general assumptions about smoothness and bounded variance, and tighter bounds may be possible under more specific conditions.
- What evidence would resolve it: A more detailed theoretical analysis of LETS under specific assumptions about the loss landscape (e.g., strong convexity, Lipschitz gradients), deriving tighter convergence bounds and comparing them to empirical results.

### Open Question 3
- Question: How does the choice of the perturbation radius affect the computational efficiency of LETS, and can the learning process be optimized to reduce the overhead introduced by updating the radius?
- Basis in paper: [inferred] The paper mentions that LETS involves additional computations for updating the perturbation radius, but does not provide a detailed analysis of its impact on efficiency.
- Why unresolved: The paper focuses on the effectiveness of LETS but does not thoroughly investigate its computational overhead and potential optimizations.
- What evidence would resolve it: Experiments comparing the runtime and memory usage of LETS with different perturbation radius update strategies (e.g., different learning rates, update frequencies), identifying the most efficient approach while maintaining performance.

## Limitations
- Effectiveness depends on the generalization gap being a reliable proxy for true generalization, which may not hold in overparameterized regimes
- Additional computational overhead from updating the perturbation radius during training
- Theoretical convergence guarantees rely on standard assumptions that may not hold for all deep learning tasks

## Confidence

- Mechanism 1 (bilevel optimization for radius): Medium - The formulation is sound, but the assumption about generalization gap as a proxy is unverified
- Mechanism 2 (adaptive radius scaling): Medium - The approach is novel, but sensitivity to hyperparameters and update stability are concerns
- Mechanism 3 (preserved convergence rate): Medium - The theoretical analysis appears correct, but practical convergence may be affected by approximation errors

## Next Checks
1. **Correlation analysis**: Test whether the learned radius correlates with actual test set performance across different datasets and architectures.
2. **Ablation study**: Compare LETS with random radius search and fixed optimal radius to isolate the benefit of adaptive learning.
3. **Robustness test**: Evaluate LETS on datasets with varying noise levels to verify that the learned radius adapts appropriately to different generalization challenges.