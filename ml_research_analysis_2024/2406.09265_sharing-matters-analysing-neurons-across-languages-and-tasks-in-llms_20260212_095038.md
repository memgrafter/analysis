---
ver: rpa2
title: 'Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs'
arxiv_id: '2406.09265'
source_url: https://arxiv.org/abs/2406.09265
tags:
- neurons
- neuron
- across
- languages
- activation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explores neuron activation patterns across languages
  and tasks in multilingual large language models (LLMs). Researchers classify neurons
  into four categories: all-shared (activated across all languages), partial-shared
  (activated in some languages), specific (activated in only one language), and non-activated
  (never activated).'
---

# Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs

## Quick Facts
- arXiv ID: 2406.09265
- Source URL: https://arxiv.org/abs/2406.09265
- Reference count: 40
- Primary result: Deactivating all-shared neurons causes up to 87.39% accuracy drops in multilingual LLMs

## Executive Summary
This study investigates neuron activation patterns across languages and tasks in multilingual large language models (LLMs). Researchers classify neurons into four categories: all-shared (activated across all languages), partial-shared (activated in some languages), specific (activated in only one language), and non-activated (never activated). Experiments on three tasks across nine languages using BLOOMZ-7B and other LLMs reveal that all-shared neurons are crucial for model performance, with their deactivation causing significant accuracy drops. The study finds that neuron activation patterns vary across tasks and models, with all-shared and partial-shared neurons peaking in mid-layers. Interestingly, language similarity does not always correlate with neuron sharing. These findings shed light on the internal workings of multilingual LLMs and highlight the importance of shared neurons in cross-lingual processing.

## Method Summary
The study analyzes neuron activation patterns in BLOOMZ-7B and other LLMs across nine languages (English, German, Spanish, French, Russian, Thai, Turkish, Vietnamese, Chinese) on three tasks (XNLI, Fact Probing, Cross-lingual Knowledge Editing). Neurons are classified into four categories based on their activation across languages. Deactivation experiments systematically disable specific neuron types to measure performance impact. Generation Impact Score and Correctness Impact Score quantify neuron contributions to model output. The analysis examines neuron importance across layers, tasks, and language similarities.

## Key Results
- All-shared neurons account for only 8.71% of total neurons but cause 87.39% accuracy decrease when deactivated
- All-shared and partial-shared neurons show peak activation in mid-layers (5-10)
- Instruction-finetuned BLOOMZ-7B has higher percentage of all-shared neurons compared to BLOOM-7B
- Language similarity does not always correlate with neuron sharing patterns

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** All-shared neurons are crucial for model performance across languages and tasks.
- **Mechanism:** All-shared neurons are activated by inputs in all languages, carrying universal linguistic representations critical for cross-lingual processing. Deactivating these neurons leads to significant accuracy drops (up to 87.39%) because the model loses access to shared linguistic features necessary for task completion.
- **Core assumption:** Neuron activation patterns reflect functional importance, and deactivation experiments reveal causal impact.
- **Evidence anchors:**
  - [abstract] "deactivating the all-shared neurons significantly decreases performance; (ii) the shared neurons play a vital role in generating responses, especially for the all-shared neurons"
  - [section 5] "All-shared neurons play a crucial role in model performance across different tasks... deactivating the all-shared neurons, which account for only 8.71% of the total neurons, results in an 87.39% decrease in accuracy"
  - [corpus] Weak evidence - corpus papers discuss language-specific neurons but don't directly support the all-shared claim.

### Mechanism 2
- **Claim:** Neuron activation patterns vary across tasks, LLMs, and languages, and don't always align with language similarity.
- **Mechanism:** Different tasks require different linguistic features, causing neurons to specialize or generalize accordingly. LLMs have different architectures and training data, leading to different activation patterns. Language similarity doesn't guarantee neuron sharing because language families share structural features but may differ in lexical or phonetic aspects that affect neuron activation.
- **Core assumption:** Neuron activation reflects the model's internal representation of linguistic features, which varies based on task requirements and language characteristics.
- **Evidence anchors:**
  - [abstract] "neuron activation patterns are highly sensitive and vary across tasks, LLMs, and languages"
  - [section 7.4] "Our empirical results show that languages from the same language family do not always exhibit a higher degree of neuron sharing compared with languages from distinct language families"
  - [corpus] Weak evidence - corpus papers discuss neuron overlap but don't specifically address the lack of correlation with language similarity.

### Mechanism 3
- **Claim:** Instruction-finetuned LLMs exhibit larger proportion of all-shared neurons compared to foundation models.
- **Mechanism:** Instruction finetuning encourages the model to develop more generalized, cross-lingual representations by optimizing for instruction-following across multiple languages. This process likely promotes sharing of neurons that capture universal linguistic features, as opposed to language-specific features.
- **Core assumption:** Instruction finetuning changes the internal representations in a way that promotes cross-lingual generalization.
- **Evidence anchors:**
  - [section 7.3] "the instruction-finetuned BLOOMZ-7B demonstrates a higher percentage of all-shared neurons compared to BLOOM-7B"
  - [abstract] "instruction finetuned LLMs exhibit larger proportion of the all-shared neurons"
  - [corpus] Weak evidence - corpus papers discuss instruction finetuning but don't specifically address its impact on neuron sharing patterns.

## Foundational Learning

- **Concept:** Neuron activation in FFN blocks
  - **Why needed here:** Understanding how neurons work in transformer models is fundamental to interpreting the results about neuron sharing and deactivation experiments.
  - **Quick check question:** How is a neuron defined as "activated" in this study, and what mathematical operation determines this?

- **Concept:** Cross-lingual transfer and language similarity
  - **Why needed here:** The study's findings about neuron sharing not correlating with language similarity require understanding of what cross-lingual transfer is and how language similarity is typically measured.
  - **Quick check question:** What are the typical language families mentioned in the study, and why would one expect neuron sharing to correlate with language family membership?

- **Concept:** Impact metrics for neuron importance
  - **Why needed here:** The study uses Generation Impact Score and Correctness Impact Score to quantify neuron contributions, so understanding these metrics is crucial for interpreting the results.
  - **Quick check question:** How do Generation Impact Score and Correctness Impact Score differ in what they measure about neuron contributions?

## Architecture Onboarding

- **Component map:** Input embeddings → Transformer layers → Feed-Forward Network (FFN) blocks → Neuron activation → Output generation
- **Critical path:**
  1. Input token embeddings flow through transformer layers
  2. At each layer, FFN blocks process the hidden state
  3. Neurons activate based on input content and language
  4. Activated neurons contribute to output through weighted sum
  5. Residual connections preserve information across layers
- **Design tradeoffs:**
  - Sparsity vs. coverage: More non-activated neurons mean sparsity but may indicate specialization
  - Sharing vs. specificity: More shared neurons enable cross-lingual transfer but may reduce language-specific performance
  - Layer depth: Earlier layers capture more universal features, later layers more task-specific features
- **Failure signatures:**
  - Performance degradation when all-shared neurons are deactivated
  - Inconsistent neuron activation patterns across similar languages
  - Unexpected performance improvements when certain neuron types are deactivated
- **First 3 experiments:**
  1. Replicate the neuron deactivation experiments on a simple multilingual task to verify the importance of all-shared neurons
  2. Analyze neuron activation patterns across different tasks on the same LLM to confirm task-related variations
  3. Compare neuron activation patterns between a foundation model and its instruction-finetuned version to verify the sharing difference

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the functional specialization of all-shared neurons vary across different layers in multilingual LLMs, and what specific linguistic features do they encode at each layer?
- **Basis in paper:** [inferred] The paper mentions that all-shared neurons have the highest Generation Impact Score and Correctness Impact Score across tasks and layers, with a decrease in influence between layers 5-10 due to lower layers focusing on input understanding. However, it does not specify what linguistic features these neurons encode at each layer.
- **Why unresolved:** The study identifies the importance of all-shared neurons but does not provide a detailed analysis of their functional specialization or the specific linguistic features they encode at different layers.
- **What evidence would resolve it:** Detailed analysis of the activation patterns of all-shared neurons across different layers, combined with linguistic feature analysis (e.g., syntax, semantics, morphology) to determine what features are encoded at each layer.

### Open Question 2
- **Question:** Does the proportion of shared neurons (all-shared, partial-shared) correlate with the multilingual proficiency of an LLM, and can this be used to predict model performance on cross-lingual tasks?
- **Basis in paper:** [explicit] The paper observes that instruction-finetuned LLMs (BLOOMZ-7B) have a higher percentage of all-shared neurons compared to foundation models (BLOOM-7B), and suggests this may encourage neuron sharing across languages. However, it does not establish a direct correlation between shared neuron proportion and multilingual proficiency or task performance.
- **Why unresolved:** While the paper suggests a potential relationship between neuron sharing and multilingual proficiency, it does not provide empirical evidence to support this claim or explore its predictive value for cross-lingual task performance.
- **What evidence would resolve it:** Correlation analysis between the proportion of shared neurons and performance metrics on various multilingual tasks, along with predictive modeling to assess if shared neuron proportion can forecast cross-lingual task success.

### Open Question 3
- **Question:** How do knowledge conflicts encoded in LLMs contribute to performance improvements when deactivating certain neuron types, and can this phenomenon be leveraged for targeted model optimization?
- **Basis in paper:** [explicit] The paper observes that deactivating partial-shared or specific neurons can occasionally improve performance for certain languages, hypothesizing this is due to mitigating knowledge conflicts. However, it does not explore the nature of these conflicts or how they can be systematically addressed.
- **Why unresolved:** The study identifies the phenomenon of performance improvements through neuron deactivation but does not investigate the underlying mechanisms of knowledge conflicts or how this insight can be applied for model optimization.
- **What evidence would resolve it:** Detailed analysis of the knowledge encoded in deactivated neurons, identification of conflict patterns, and experimental validation of targeted neuron deactivation strategies for performance enhancement.

## Limitations
- Study focuses on nine languages, potentially limiting generalizability to global linguistic diversity
- Simple activation threshold (Al_i > 0) may not capture nuanced activation patterns
- Limited testing across different LLM architectures beyond BLOOMZ-7B and BLOOM-7B

## Confidence

**High Confidence:** The claim that all-shared neurons are crucial for model performance is well-supported by the deactivation experiments showing up to 87.39% accuracy drops. The methodology for identifying and deactivating these neurons is clearly specified.

**Medium Confidence:** The finding that instruction-finetuned models have more all-shared neurons compared to foundation models is supported by the BLOOMZ vs BLOOM comparison, but would benefit from testing on a broader range of models.

**Medium Confidence:** The observation that language similarity doesn't correlate with neuron sharing is interesting but based on limited language pairs and requires validation across more diverse language combinations.

## Next Checks
1. **Replicate across diverse language families:** Test the neuron sharing patterns on a broader set of languages including underrepresented families (African, Indigenous American languages) to verify if the lack of correlation with language similarity holds across more diverse linguistic structures.

2. **Cross-architecture validation:** Apply the same neuron analysis methodology to other prominent multilingual LLMs (GPT-4, PaLM, LLaMA) to determine if the all-shared neuron importance and sharing patterns are consistent across different model architectures.

3. **Ablation study on activation thresholds:** Conduct sensitivity analysis by varying the neuron activation threshold (Al_i > 0) to determine how robust the neuron classification is to different threshold values and whether more nuanced activation patterns emerge with alternative thresholding approaches.