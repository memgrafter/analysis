---
ver: rpa2
title: Verified Training for Counterfactual Explanation Robustness under Data Shift
arxiv_id: '2403.03773'
source_url: https://arxiv.org/abs/2403.03773
tags:
- robust
- robustness
- training
- loss
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes VeriTraCER, a method to train models and counterfactual
  explanation (CE) generators that are robust to small model shifts. It jointly trains
  a classifier and CE generator using a loss function that promotes CE validity, quality,
  and robustness to a multiplicity set of similar models.
---

# Verified Training for Counterfactual Explanation Robustness under Data Shift

## Quick Facts
- arXiv ID: 2403.03773
- Source URL: https://arxiv.org/abs/2403.03773
- Authors: Anna P. Meyer; Yuhao Zhang; Aws Albarghouthi; Loris D'Antoni
- Reference count: 33
- Key outcome: VeriTraCER achieves 70-97% δ-robustness rates for counterfactual explanations while maintaining competitive model accuracy and CE quality

## Executive Summary
This paper addresses the vulnerability of counterfactual explanations (CEs) to small model shifts caused by data distribution changes. The authors propose VeriTraCER, a training method that jointly optimizes a classifier and CE generator to produce explanations robust to lp-bounded model updates. By employing a novel verified training algorithm called Simul-CROWN, VeriTraCER computes sound overapproximations of worst-case loss over a multiplicity set of similar models, enabling formal robustness guarantees. Empirical evaluation on five real-world datasets demonstrates significant improvements in CE robustness compared to state-of-the-art methods.

## Method Summary
VeriTraCER jointly trains a classifier and counterfactual explanation generator using a custom loss function that promotes validity, quality, and robustness. The method employs Simul-CROWN, a verified training algorithm that efficiently computes sound overapproximations of the worst-case RobustCE loss over a multiplicity set of models. During training, CEs are first generated with the current model, then the classifier is updated to minimize classification loss, and finally the CE generator is updated to minimize the RobustCE loss. The approach uses layer-specific robustness bounds (δi values) dynamically determined based on each layer's parameter norm to enable more effective training.

## Key Results
- Achieves δ-robustness rates of 70-97% across five real-world datasets (CTG, WHO, HELOC, TC, OULA)
- Outperforms state-of-the-art methods in cross-model validity under various data shifts
- Maintains competitive model accuracy while providing formal robustness guarantees for CEs
- Generates CEs with slightly higher proximity to original inputs but offers fast, deterministic generation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** VeriTraCER jointly trains the classifier and CE generator so the CEs are optimized for both accuracy and robustness simultaneously.
- **Mechanism:** The loss function has two parts: one for classifier accuracy (Lf) and one for CE validity, quality, and robustness (Lg). During each training epoch, CEs are first generated with the current model, then the classifier is updated to minimize Lf, and finally the CE generator is updated to minimize Lg.
- **Core assumption:** Optimizing over a multiplicity set of models during training will yield CEs that are robust to small model shifts in practice.
- **Evidence anchors:**
  - [abstract] "VeriTraCER optimizes over a carefully designed loss function that ensures the verifiable robustness of CEs to local model updates"
  - [section 4.1] "We define Lf and Lg as follows: ... Our approach, VeriTraCER, is a training algorithm that takes a training set D as input and outputs a model f and a CE generator g such that the CEs generated by g have a high rate of Mf,x-robustness."
- **Break condition:** If the multiplicity set Mf,x does not capture the actual distribution shift the model will encounter, the robustness guarantees may not hold.

### Mechanism 2
- **Claim:** Simul-CROWN provides a tighter over-approximation of the worst-case RobustCE loss than IBP or CROWN-IBP, enabling more effective training.
- **Mechanism:** Simul-CROWN reasons about the over-approximation of both f(x) and f(x') simultaneously, using a greedy algorithm to solve the resulting optimization problem efficiently while preserving gradient information.
- **Core assumption:** The tighter bound from Simul-CROWN leads to better model accuracy, CE validity, and CE quality without sacrificing CE robustness.
- **Evidence anchors:**
  - [section 4.2.2] "Simul-CROWN addresses this challenge to achieve a more precise overapproximation of the RobustCE loss."
  - [section 4.2.2] "We can use a solver to address each case in Equation (3) by encoding it into a linear programming (LP) problem. However, solving an LP for each training batch is time-consuming and breaks the gradient information required to optimize the RobustCE loss."
- **Break condition:** If the greedy algorithm in Simul-CROWN fails to find the optimal solution, the bound may not be as tight as claimed.

### Mechanism 3
- **Claim:** The layer-specific δi values, dynamically determined based on the lp norm of each layer, allow for more effective training and better robustness.
- **Mechanism:** By scaling δi with the norm of each layer's parameters, VeriTraCER can enforce more appropriate constraints on each layer, avoiding overly restrictive or lenient bounds.
- **Core assumption:** The norm of each layer's parameters is a good indicator of how much the layer can change during model updates.
- **Evidence anchors:**
  - [section 5.1] "We dynamically determine a distinct δi value for the i-th layer with parameter θi based on its lp norm, denoted as δi = κ∥θi∥p, where κ ∈ [0, 1] is the ratio of δi to the layer norm."
  - [section 5.1] "This design is motivated by two considerations. Firstly, parameters across different layers have different lp norms due to layer size and depth differences. Consequently, a fixed δ may be overly restrictive for some layers and lenient for others."
- **Break condition:** If the relationship between parameter norm and layer changeability does not hold, the layer-specific δi values may not improve training.

## Foundational Learning

- **Concept:** Interval bound propagation (IBP)
  - **Why needed here:** IBP is used as a baseline technique for over-approximating the worst-case loss over the multiplicity set of models.
  - **Quick check question:** What is the main limitation of using IBP to over-approximate the RobustCE loss?

- **Concept:** Counterfactual explanations (CEs)
  - **Why needed here:** CEs are the core output of VeriTraCER, and understanding their definition and properties is crucial for understanding the problem and solution.
  - **Quick check question:** What are the key properties that a CE should have according to the paper?

- **Concept:** Model multiplicity
  - **Why needed here:** The paper relies on the assumption that there are multiple models with similar performance on the training data, which is the basis for the multiplicity set Mf,x.
  - **Quick check question:** What is the multiplicity set Mf,x, and why is it important for VeriTraCER?

## Architecture Onboarding

- **Component map:** Classifier f -> CE Generator g -> Loss function (Lf + Lg) -> Simul-CROWN
- **Critical path:** Generate CEs with g, update f to minimize Lf, update g to minimize Lg
- **Design tradeoffs:** The main tradeoff is between the tightness of the over-approximation of the RobustCE loss and the computational efficiency of the training process.
- **Failure signatures:** If the CEs generated by VeriTraCER are not robust to model shifts, it could indicate that the multiplicity set Mf,x does not capture the actual distribution shift, or that the over-approximation of the RobustCE loss is too loose.
- **First 3 experiments:**
  1. Train VeriTraCER on a simple dataset (e.g., HELOC) and evaluate the δ-robustness rate.
  2. Compare the performance of VeriTraCER with IBP and CROWN-IBP on a more complex dataset (e.g., OULA).
  3. Evaluate the cross-model validity of CEs generated by VeriTraCER under different types of model updates (e.g., random initialization, leave-one-out, distribution shift).

## Open Questions the Paper Calls Out

- **Question:** How does the choice of δ value (the robustness bound) impact the trade-off between CE quality and robustness guarantees?
- **Question:** How does the proposed approach handle counterfactual explanations for models with continuous output spaces (e.g., regression models)?
- **Question:** How does the proposed approach compare to existing methods in terms of computational efficiency, especially when dealing with high-dimensional data or complex models?

## Limitations

- The effectiveness of VeriTraCER depends on the assumption that the multiplicity set Mf,x adequately captures real-world data shifts
- The greedy algorithm in Simul-CROWN isn't formally proven to find optimal solutions, though empirically validated
- The relationship between parameter norm and layer changeability during updates is intuitive rather than rigorously justified

## Confidence

**High Confidence:** The mechanism of jointly training classifier and CE generator (Mechanism 1) is well-supported by the loss function design and training procedure described. The empirical results showing 70-97% δ-robustness rates provide strong evidence for this claim.

**Medium Confidence:** The superiority of Simul-CROWN over IBP and CROWN-IBP (Mechanism 2) is supported by theoretical arguments and experimental comparisons, but the greedy algorithm's optimality isn't formally proven. The paper demonstrates improved performance but doesn't provide worst-case guarantees for the approximation quality.

**Medium Confidence:** The layer-specific δi values (Mechanism 3) show empirical benefits, but the assumption that parameter norm correlates with layer changeability during updates is intuitive rather than rigorously justified. The design choice appears reasonable but could benefit from deeper theoretical analysis.

## Next Checks

1. **Robustness to Real Distribution Shifts:** Test VeriTraCER's CEs against actual distribution shifts in the wild (e.g., temporal drift, domain adaptation scenarios) rather than synthetic lp-bounded perturbations to validate whether the multiplicity set assumption holds in practice.

2. **Simul-CROWN Optimality Verification:** Implement an exact solver for the LP formulation in Equation (3) on small networks to quantify how often the greedy algorithm finds suboptimal solutions and measure the actual gap between greedy and optimal bounds.

3. **Cross-Dataset Generalization:** Evaluate VeriTraCER on additional datasets with different characteristics (e.g., tabular vs. image data, different sparsity patterns) to determine whether the layer-specific δi scaling generalizes beyond the five datasets tested.