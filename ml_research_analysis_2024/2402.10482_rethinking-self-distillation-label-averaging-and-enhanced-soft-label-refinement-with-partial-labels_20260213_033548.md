---
ver: rpa2
title: 'Rethinking Self-Distillation: Label Averaging and Enhanced Soft Label Refinement
  with Partial Labels'
arxiv_id: '2402.10482'
source_url: https://arxiv.org/abs/2402.10482
tags:
- label
- distillation
- corruption
- class
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes self-distillation in linear probing settings,
  where feature extractors are fixed and traditional feature-learning explanations
  do not apply. The authors show that multi-round self-distillation performs label
  averaging among instances with high feature correlations, governed by eigenvectors
  of the Gram matrix.
---

# Rethinking Self-Distillation: Label Averaging and Enhanced Soft Label Refinement with Partial Labels

## Quick Facts
- arXiv ID: 2402.10482
- Source URL: https://arxiv.org/abs/2402.10482
- Authors: Hyeonsu Jeong; Hye Won Chung
- Reference count: 40
- One-line primary result: Novel single-round PLL student model achieves multi-round distillation benefits with significantly reduced computational cost

## Executive Summary
This paper analyzes self-distillation in linear probing settings where feature extractors are fixed. The authors show that multi-round self-distillation performs label averaging among instances with high feature correlations, governed by eigenvectors of the Gram matrix. This averaging leads to clustered predictions and improved generalization, particularly mitigating label noise. They introduce a novel single-round method using refined partial labels from the teacher's top two softmax outputs (PLL student model) that achieves comparable or superior performance to multi-round distillation while significantly reducing computational cost.

## Method Summary
The paper analyzes self-distillation in linear probing settings where a linear classifier is trained on top of a fixed pre-trained feature extractor. The authors prove that multi-round self-distillation performs label averaging among instances with high feature correlations, governed by eigenvectors of the Gram matrix. They introduce a novel single-round PLL (Partial Label Learning) student model that uses refined partial labels from the teacher's top two softmax outputs, achieving multi-round distillation benefits in a single training round.

## Key Results
- Multi-round self-distillation performs label averaging among instances with high feature correlations, governed by eigenvectors of the Gram matrix
- The PLL student model achieves comparable or superior performance to multi-round distillation with significantly reduced computational cost
- Label averaging mitigates label noise by reducing reliance on potentially corrupted labels, achieving 100% population accuracy under mild conditions
- Experiments on six datasets show the PLL student is particularly effective in high-noise scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-round self-distillation performs label averaging among instances with high feature correlations, governed by eigenvectors of the Gram matrix.
- Mechanism: As distillation progresses, the top-K eigenvectors dominate, causing predictions for instances from the same ground-truth class to become increasingly similar through iterative averaging.
- Core assumption: Feature correlations exhibit a block-wise structure where instances from the same class have higher correlations than those from different classes.
- Evidence anchors:
  - [abstract] "Our theoretical analysis reveals that multi-round self-distillation effectively performs label averaging among instances with high feature correlations, governed by the eigenvectors of the Gram matrix derived from input features."
  - [section] "The Gram matrix Φ, defined as [Φ]ij := ⟨ϕ(xi), ϕ(xj)⟩, captures the pairwise feature correlations among the training instances."
  - [corpus] No direct evidence found in corpus neighbors about Gram matrix eigenvector dynamics.
- Break condition: If feature correlations do not exhibit the assumed block structure, or if the eigen-gap between top-K and remaining eigenvectors is insufficient.

### Mechanism 2
- Claim: Label averaging mitigates label noise by reducing reliance on potentially corrupted labels.
- Mechanism: The averaging process incorporates information from other instances with high feature correlation, diluting the impact of individual noisy labels.
- Core assumption: The proportion of correctly labeled instances exceeds mislabeled instances for each class.
- Evidence anchors:
  - [abstract] "This process leads to clustered predictions and improved generalization, mitigating the impact of label noise by reducing the model's reliance on potentially corrupted labels."
  - [section] "As the latter signal strengthens with more distillation rounds, the student model can correctly classify samples with noisy labels after a few iterations."
  - [corpus] Weak evidence - corpus neighbors discuss pseudo-label refinement but not the specific averaging mechanism described.
- Break condition: When label corruption rates are too high such that incorrectly labeled instances dominate the averaging process.

### Mechanism 3
- Claim: Single-round PLL student achieves multi-round benefits through refined partial labels from top two softmax outputs.
- Mechanism: By assigning equal weights (1/2) to top two predictions, the method boosts confidence in the true label for noisy samples while reducing overconfidence in clean samples.
- Core assumption: The true label consistently ranks among the top two predictions in the teacher's output.
- Evidence anchors:
  - [abstract] "We introduce a novel, efficient single-round self-distillation method using refined partial labels from the teacher's top two softmax outputs, referred to as the PLL student model."
  - [section] "The key insight stems from the observation that, under mild conditions on the label corruption rates, the teacher's softmax output at the true label consistently ranks at least second-highest."
  - [corpus] No direct evidence in corpus neighbors about top-two partial label refinement strategy.
- Break condition: When the true label frequently falls outside the top two predictions in the teacher's output.

## Foundational Learning

- Concept: Eigenvalue decomposition and Gram matrix properties
  - Why needed here: The analysis relies on understanding how feature correlations (captured in the Gram matrix) decompose into eigenvectors that govern the averaging process.
  - Quick check question: What property of the Gram matrix ensures that the label averaging process preserves the eigenvector structure across distillation rounds?

- Concept: Linear probing in neural networks
  - Why needed here: The setting involves training a linear classifier on top of a fixed feature extractor, which is a specific and common scenario in transfer learning.
  - Quick check question: How does the linear probing setting differ from full neural network training in terms of feature learning dynamics?

- Concept: Label noise robustness and partial label learning
  - Why needed here: The method explicitly addresses scenarios with noisy labels and uses partial label learning techniques.
  - Quick check question: Under what condition does the PLL student model guarantee the true label is included in the partial label set?

## Architecture Onboarding

- Component map:
  - Feature extractor (fixed, pre-trained) -> Linear classifier layer (trainable) -> Softmax output layer -> Gram matrix computation module -> Partial label refinement module (for PLL student)

- Critical path:
  1. Extract features using pre-trained model
  2. Compute Gram matrix of features
  3. For multi-round: iteratively update linear classifier using self-distillation
  4. For PLL: compute top-two predictions, create refined labels, train once

- Design tradeoffs:
  - Multi-round vs single-round: computational cost vs performance
  - Top-K selection: balancing inclusion probability vs confidence dilution
  - Temperature scaling: affects softmax sharpness but doesn't change optimal solution

- Failure signatures:
  - Poor performance despite multiple rounds: feature correlations may not exhibit expected block structure
  - PLL student instability: candidate set may include too many incorrect labels
  - Slow convergence: weight decay λ may be too high or too low

- First 3 experiments:
  1. Verify Gram matrix block structure on a small dataset using hierarchical clustering
  2. Test multi-round distillation on synthetic data with controlled label noise
  3. Compare PLL student performance against multi-round baseline under various noise rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do self-distillation dynamics change when the feature extractor is not fixed but allowed to evolve across distillation rounds?
- Basis in paper: [explicit] The authors acknowledge this limitation and propose a theoretical extension in Corollary C.1, suggesting that allowing feature correlation to evolve could amplify gains, but they do not provide empirical validation.
- Why unresolved: The paper focuses on fixed feature extractors for theoretical tractability. Testing this requires tracking feature evolution across distillation rounds and measuring how intra-class feature correlations change.
- What evidence would resolve it: Experiments comparing distillation performance on fixed vs. evolving feature extractors, with quantitative tracking of feature correlation changes across rounds.

### Open Question 2
- Question: Can the PLL student model's performance be further improved by incorporating information from more than two candidate labels?
- Basis in paper: [inferred] The authors conduct ablation studies showing that using top-2 labels performs best, but they don't explore methods to retain the confidence benefits of multi-round distillation while using more candidates.
- Why unresolved: The current PLL method balances label inclusion and confidence, but doesn't explore adaptive weighting schemes or confidence-aware label selection.
- What evidence would resolve it: Experiments testing adaptive weight schemes for candidate labels, or methods to dynamically select the optimal number of candidates based on model confidence.

### Open Question 3
- Question: How robust is the label averaging effect to different types of feature correlation structures beyond the block-diagonal model used in the paper?
- Basis in paper: [explicit] The authors test five different feature correlation models but acknowledge that their main analysis relies on the class-wise correlation structure, and generalizing to arbitrary correlation functions remains future work.
- Why unresolved: The theoretical analysis and experiments focus on specific correlation patterns. Real-world feature spaces may have more complex correlation structures.
- What evidence would resolve it: Experiments testing distillation performance on datasets with known non-block correlation structures, or theoretical analysis of how different correlation patterns affect the eigenvalue decay rates.

## Limitations
- Theoretical analysis relies heavily on assumptions about feature correlation structure and eigen-gap properties that may not hold in practice
- PLL student method's performance depends critically on the assumption that true labels consistently rank in the top two predictions
- Analysis focuses on linear probing settings, limiting generalizability to full network training scenarios

## Confidence

- **High confidence**: The Gram matrix-based analysis of multi-round self-distillation averaging mechanism and its relationship to eigenvectors.
- **Medium confidence**: The theoretical conditions for achieving 100% accuracy under label noise, as these depend on specific noise rate thresholds.
- **Medium confidence**: The PLL student method's effectiveness, as experimental validation is strong but theoretical guarantees have narrow applicability conditions.

## Next Checks

1. **Verify eigen-structure hypothesis**: Apply hierarchical clustering to feature representations from multiple datasets to empirically test whether the assumed block-wise correlation structure exists.

2. **Test PLL student limits**: Systematically evaluate PLL student performance across varying noise rates and corruption patterns to identify failure thresholds where the true label no longer ranks in top-two predictions.

3. **Generalization beyond linear probing**: Conduct preliminary experiments using the PLL student method with fine-tuning (rather than linear probing) to assess performance in more general neural network training scenarios.