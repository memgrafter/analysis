---
ver: rpa2
title: View-based Explanations for Graph Neural Networks
arxiv_id: '2401.02086'
source_url: https://arxiv.org/abs/2401.02086
tags:
- graph
- explanation
- node
- patterns
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes GVEX, a novel approach to generate explanation
  views for graph neural networks (GNNs) that provides both explainable and queryable
  structures. The method designs a two-tier explanation structure called explanation
  views, consisting of a set of graph patterns and a set of induced explanation subgraphs.
---

# View-based Explanations for Graph Neural Networks

## Quick Facts
- arXiv ID: 2401.02086
- Source URL: https://arxiv.org/abs/2401.02086
- Authors: Tingyang Chen; Dazhuo Qiu; Yinghui Wu; Arijit Khan; Xiangyu Ke; Yunjun Gao
- Reference count: 40
- Key outcome: Proposes GVEX, a method generating explanation views for GNNs with both explainability and queryability, achieving 1/2 and 1/4 approximation ratios for static and streaming settings respectively

## Executive Summary
This paper introduces GVEX, a novel approach for generating explanation views for graph neural networks that provides both explainable and queryable structures. The method designs a two-tier explanation structure consisting of graph patterns and induced explanation subgraphs to concisely describe why a GNN classifier assigns specific class labels. The authors formulate the problem as submodular maximization with coverage constraints and prove it is Œ£2 P-hard, presenting two approximation algorithms with provable guarantees.

## Method Summary
GVEX generates explanation views for GNN-based classification by optimizing a two-tier structure: explanation subgraphs (lower-tier) that provide counterfactual explanations, and graph patterns (higher-tier) that summarize these subgraphs for queryability. The method uses a monotone submodular explainability function based on feature influence and neighborhood diversity, enabling greedy algorithms with approximation guarantees. Two algorithms are presented: ApproxGVEX for static settings with 1/2 approximation ratio, and StreamGVEX for streaming settings with 1/4 approximation ratio and anytime quality guarantees.

## Key Results
- The explainability function is proven monotone submodular, enabling approximation algorithms with 1/2 and 1/4 guarantees
- ApproxGVEX achieves high Fidelity+ scores on MUTAGENICITY, REDDIT-BINARY, and ENZYMES datasets
- StreamGVEX demonstrates scalability on large graphs like PRODUCTS (10M nodes, 40M edges) while maintaining quality
- The method outperforms competitors in terms of explanation quality, conciseness, and compression metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The two-tier explanation view structure (patterns + subgraphs) enables both explainability and queryability for GNN-based classification.
- **Mechanism**: The "lower-tier" explanation subgraphs provide counterfactual explanations for why a specific class label is assigned, while the "higher-tier" patterns summarize these subgraphs into queryable graph patterns. This two-level structure allows domain experts to inspect explanations at different levels of abstraction.
- **Core assumption**: Graph patterns can effectively summarize subgraphs while preserving the structural information needed for queryability and inspection.
- **Evidence anchors**:
  - [abstract]: "An explanation view consists of a set of graph patterns and a set of induced explanation subgraphs."
  - [section]: "The upper left corner of the figure shows two graph patterns {ùëÉ11, ùëÉ12} and corresponding subgraphs that explain 'why' the compounds ùê∫1 and ùê∫2 have mutagenicity."
- **Break condition**: If the patterns fail to capture the essential structural differences between class labels, the queryability property breaks down and the approach loses its advantage over existing methods.

### Mechanism 2
- **Claim**: The monotone submodular maximization framework with coverage constraints enables approximation algorithms with provable guarantees.
- **Mechanism**: The explainability function ùëì(GùëôV) is shown to be monotone submodular, allowing the use of greedy algorithms that provide 1/2-approximation guarantees for static settings and 1/4-approximation for streaming settings.
- **Core assumption**: The explainability function based on feature influence and neighborhood diversity satisfies the properties required for submodular maximization.
- **Evidence anchors**:
  - [section]: "LEMMA 3.3. Given G, ≈Å, C, and a fixed GNN M, ùëì(G V) is a monotone submodular function."
  - [section]: "This allows us to reduce EVG to a fair submodular maximization problem [14]."
- **Break condition**: If the explainability function fails to be monotone submodular (e.g., due to complex feature interactions), the approximation guarantees break down and the greedy algorithms may perform poorly.

### Mechanism 3
- **Claim**: The incremental streaming algorithm maintains explanation views with anytime quality guarantees while processing graphs as node streams.
- **Mechanism**: The algorithm processes nodes incrementally, maintaining a candidate set and using greedy swapping strategies to update explanation subgraphs and patterns without requiring full recomputation.
- **Core assumption**: The streaming setting allows for weaker but still useful approximation guarantees while maintaining efficiency on large graphs.
- **Evidence anchors**:
  - [abstract]: "Our second algorithm performs a single-pass to an input node stream in batches to incrementally maintain explanation views, having an anytime quality guarantee of 1/4-approximation."
  - [section]: "StreamGVEX offers the advantage of not requiring a comparison of information from all nodes each time, allowing anytime access of explanation views."
- **Break condition**: If the node stream order significantly affects the discovered patterns beyond what the greedy replacement strategy can handle, the quality of the explanation views may degrade substantially.

## Foundational Learning

- **Concept**: Graph pattern matching and subgraph isomorphism
  - Why needed here: The algorithm needs to verify that patterns cover the nodes in explanation subgraphs and that subgraphs are valid explanations
  - Quick check question: How does node-induced subgraph isomorphism differ from edge-induced subgraph isomorphism in the context of explanation views?

- **Concept**: Submodular optimization and approximation algorithms
  - Why needed here: The core optimization problem is reduced to submodular maximization under coverage constraints, enabling approximation guarantees
  - Quick check question: Why does the monotonicity of the explainability function matter for the greedy algorithm's approximation ratio?

- **Concept**: GNN feature propagation and influence maximization
  - Why needed here: The explainability metric is based on feature influence via the GNN's message-passing mechanism, which determines which nodes are important for classification
  - Quick check question: How does the Jacobian matrix relate to feature influence in GNNs, and why is it used in the explainability metric?

## Architecture Onboarding

- **Component map**: Input (Graph database G, GNN model M, configuration C) -> Core (ApproxGVEX/StreamGVEX algorithms) -> Verification (EVerify, PMatch, PGen) -> Output (Set of explanation views GV)

- **Critical path**:
  1. Precompute Jacobian matrix for feature influence calculation
  2. Greedily select nodes to maximize explainability while satisfying coverage constraints
  3. Generate patterns from explanation subgraphs using constrained pattern mining
  4. Verify constraints and return explanation view

- **Design tradeoffs**:
  - Static vs. streaming: ApproxGVEX provides better approximation (1/2) but requires full graph access; StreamGVEX provides weaker approximation (1/4) but handles large graphs efficiently
  - Pattern vs. subgraph focus: Patterns provide queryability but may miss edge-level details; subgraphs provide completeness but lack abstraction
  - Coverage strictness: Tighter coverage constraints ensure comprehensive explanations but increase computational cost

- **Failure signatures**:
  - Poor Fidelity+ scores: Explanation subgraphs fail to provide counterfactual explanations (removing them doesn't change predictions)
  - High edge loss: Patterns fail to capture structural details in explanation subgraphs
  - Slow performance on large graphs: Static algorithm struggles with scalability, indicating need for streaming approach

- **First 3 experiments**:
  1. Run ApproxGVEX on MUTAGENICITY dataset with varying ùë¢ùëô parameters to observe trade-off between explanation quality and conciseness
  2. Compare Fidelity+ and Fidelity- scores of ApproxGVEX vs. competitors on REDDIT-BINARY dataset
  3. Test StreamGVEX on PRODUCTS dataset to verify scalability and anytime quality guarantees with different node processing orders

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GVEX handle edge features in addition to node features for generating explanations?
- Basis in paper: [explicit] The paper mentions future work to consider the impact of edge features but does not currently address them.
- Why unresolved: Edge features are not considered in the current formulation of the explainability measure and algorithms.
- What evidence would resolve it: Experiments showing the impact of incorporating edge features on the quality and conciseness of explanations compared to the current node-feature-only approach.

### Open Question 2
- Question: What is the impact of node ordering on the quality of explanation views generated by StreamGVEX?
- Basis in paper: [inferred] The paper mentions that StreamGVEX does not require a predefined node order and provides an anytime quality guarantee, but does not extensively analyze the impact of different node orderings.
- Why unresolved: The paper does not provide a detailed analysis of how different node arrival sequences affect the quality and diversity of the generated patterns and explanation subgraphs.
- What evidence would resolve it: A systematic study comparing the quality of explanation views generated under different node orderings, including worst-case and best-case scenarios.

### Open Question 3
- Question: How does GVEX scale to extremely large graph datasets that cannot fit into memory?
- Basis in paper: [explicit] The paper mentions the efficiency and scalability of GVEX, but does not specifically address scenarios where the graph database is too large to fit into memory.
- Why unresolved: The paper does not discuss strategies for handling graph databases that exceed available memory, such as disk-based or distributed approaches.
- What evidence would resolve it: Experiments demonstrating the performance of GVEX on extremely large graph datasets using memory-efficient techniques or distributed computing frameworks.

## Limitations

- The streaming algorithm's 1/4 approximation guarantee is significantly weaker than the 1/2 guarantee for the static algorithm, potentially limiting its effectiveness for highly sensitive applications
- The pattern generation process uses a fixed threshold (Œ∏=0.8) that may not be optimal across different domains and could affect the queryability of generated patterns
- The method does not currently handle edge features, limiting its applicability to graphs where edge attributes are crucial for classification

## Confidence

- **High**: The theoretical foundation of submodular maximization and the approximation guarantees for both algorithms
- **Medium**: The practical effectiveness of the two-tier explanation structure in real-world applications
- **Low**: The robustness of the streaming algorithm across different node arrival orders and its generalization to unseen graph types

## Next Checks

1. Test the approximation ratio empirically by comparing greedy solutions to optimal solutions on small synthetic graphs where exhaustive search is feasible
2. Evaluate the sensitivity of explanation quality to different Œ∏ thresholds across multiple datasets to identify optimal parameter settings
3. Measure the impact of node stream ordering on StreamGVEX performance by running experiments with randomized and adversarial arrival sequences