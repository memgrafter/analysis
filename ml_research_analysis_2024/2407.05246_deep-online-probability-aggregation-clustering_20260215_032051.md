---
ver: rpa2
title: Deep Online Probability Aggregation Clustering
arxiv_id: '2407.05246'
source_url: https://arxiv.org/abs/2407.05246
tags:
- clustering
- deep
- online
- cluster
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel clustering method called Probability
  Aggregation Clustering (PAC), which addresses the limitations of traditional center-based
  clustering algorithms in online deep clustering. PAC circumvents the need for cluster
  centers by formulating clustering as an optimization problem that aligns the probability
  space and distribution space.
---

# Deep Online Probability Aggregation Clustering

## Quick Facts
- arXiv ID: 2407.05246
- Source URL: https://arxiv.org/abs/2407.05246
- Reference count: 40
- Key outcome: DPAC achieves state-of-the-art clustering accuracy on five image benchmarks by integrating PAC-based OPA with weighted contrastive loss

## Executive Summary
This paper introduces Probability Aggregation Clustering (PAC), a novel clustering method that eliminates the need for cluster centers by aligning probability and distribution spaces through optimization. The authors develop an Online Probability Aggregation (OPA) module that enables stable, flexible clustering over mini-batches, allowing the model to be trained in a supervised manner without additional clustering steps. The Deep PAC (DPAC) framework integrates OPA with a weighted contrastive loss, achieving superior performance on five challenging image benchmarks compared to state-of-the-art deep clustering methods.

## Method Summary
The method introduces PAC, which reformulates clustering as an optimization problem that aligns probability and distribution spaces without requiring cluster centers. PAC uses sample probability aggregation instead of nearest-center assignment, computing cluster probabilities by aggregating distances and probabilities of all samples. The Online Probability Aggregation (OPA) module enables mini-batch clustering by computing clustering scores from distance and probability matrices, normalizing them to obtain target codes, and training via KL divergence. DPAC combines OPA with a weighted contrastive loss (WCL) that masks negative samples likely from the same class, integrating the entire clustering process within the forward pass for online training.

## Key Results
- DPAC achieves state-of-the-art clustering accuracy on five challenging image benchmarks
- The method demonstrates significant improvements in clustering robustness compared to traditional center-based algorithms
- Online PAC eliminates stability issues from cluster center initialization while maintaining computational efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PAC avoids instability from cluster center initialization by using sample probability aggregation instead of nearest-center assignment
- Mechanism: Computes cluster assignment probabilities by aggregating distances and probabilities across all samples rather than using a single center
- Core assumption: Joint probability computation across all samples improves assignment quality
- Evidence anchors: Abstract states PAC "circumvents the cluster center and aligns the probability space and distribution space"; section notes PAC "directly outputs probabilities which is more stable"

### Mechanism 2
- Claim: OPA enables online clustering by computing pseudo-labels from mini-batches without full-dataset recomputation
- Mechanism: Computes clustering scores using mini-batch distance and probability matrices, normalizes to obtain target codes, trains via KL divergence
- Core assumption: Mini-batch computation is representative enough to approximate full-data clustering for online training
- Evidence anchors: Abstract states OPA "seamlessly combines the computation process of PAC with loss computation, allowing the model to be trained in a supervised manner"

### Mechanism 3
- Claim: DPAC achieves superior clustering by integrating PAC-based OPA with weighted contrastive loss that masks semantically similar negative samples
- Mechanism: Weighted contrastive loss uses cluster probability consistency to reduce semantic distortion from negative samples while OPA handles clustering in the same forward pass
- Core assumption: Masking semantically similar negative samples improves representation learning without sacrificing discriminative power
- Evidence anchors: Section states WCL is used to "mitigate the semantic distortion caused by negative samples"

## Foundational Learning

- **Concept**: Fuzzy C-Means (FCM) clustering and its objective function with fuzzy weighting exponent m
  - Why needed here: PAC extends FCM by replacing cluster-center term with probability-aggregation term; understanding FCM is essential to grasp PAC derivation
  - Quick check question: What role does the weighting exponent m play in FCM objective, and how is it adapted in PAC?

- **Concept**: Online vs. offline clustering trade-offs
  - Why needed here: DPAC's design hinges on performing clustering within each mini-batch rather than on full dataset; engineers must understand stability vs. computational efficiency
  - Quick check question: What are main stability and error-accumulation risks when clustering is performed offline after each epoch?

- **Concept**: KL divergence as self-supervised loss
  - Why needed here: OPA uses KL divergence between computed target codes and network output probabilities; familiarity with its properties is needed to tune or debug training
  - Quick check question: How does KL divergence differ from cross-entropy in context of clustering?

## Architecture Onboarding

- **Component map**: Backbone (ResNet-34) → Feature extractor f → Projector g (MLP) → Contrastive space → Classifier h → K-way probability output → OPA module → Computes Q from D and P → Weighted contrastive loss (WCL) with masking → Loss (KL + WCL) → Backward → Parameter update

- **Critical path**: Forward pass → f → g/h → OPA computes Q → Loss (KL + WCL) → Backward → Parameter update

- **Design tradeoffs**:
  - Online PAC vs. offline KM: Speed and stability vs. possible lower precision
  - Fixed m = 1.03 vs. per-dataset tuning: Simplicity vs. marginal accuracy gains
  - Contrastive masking vs. full negatives: Semantic clarity vs. possible loss of diversity

- **Failure signatures**:
  - All samples assigned to one cluster → likely m too small or batch too small
  - Very slow convergence or oscillation → OPA scores not well-scaled
  - Poor performance on fine-grained classes → masking coefficient may be too high

- **First 3 experiments**:
  1. Replace OPA with standard K-means on full data each epoch and measure runtime vs. accuracy
  2. Sweep m in [1.01, 1.1] and record cluster collapse rates and final accuracy
  3. Disable masking in contrastive loss and observe changes in class collision rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does choice of distance metric in PAC affect clustering performance compared to other clustering algorithms?
- Basis in paper: Explicit statement that "edi,j can be replaced by many other distance measurement. We use L2 distance as the default distance measure"
- Why unresolved: Paper only experiments with L2 distance without exploring impact of other metrics or comparing to other algorithms using different metrics
- What evidence would resolve it: Experimental results comparing PAC's performance using different distance metrics against other clustering algorithms using same metrics

### Open Question 2
- Question: What is impact of weighting exponent m on PAC's performance for different types of data distributions?
- Basis in paper: Explicit mention of parameter sensitivity evaluation of m for both FCM and PAC on Pendigits
- Why unresolved: While paper provides some sensitivity analysis for m, it doesn't explore how different data distributions affect optimal choice of m for PAC
- What evidence would resolve it: Experiments varying m across datasets with different characteristics to determine optimal m values and their impact on clustering performance

### Open Question 3
- Question: How does computational complexity of OPA scale with increasing batch sizes and number of clusters?
- Basis in paper: Inferred from paper mentioning OPA has "high extensibility" and "computes clustering codes with the batches of data"
- Why unresolved: While paper discusses time complexity of PAC, it doesn't provide detailed analysis of how OPA's computational requirements scale with different batch sizes and cluster numbers
- What evidence would resolve it: Experiments measuring OPA's runtime and memory usage across varying batch sizes and cluster numbers, along with theoretical analysis of computational complexity

## Limitations
- Online PAC formulation relies heavily on mini-batch representativeness without systematic validation that batch size 240 is sufficient for most challenging datasets
- Weighting exponent m=1.03 is fixed across all datasets without justification for why this value generalizes
- Masked contrastive loss mechanism lacks ablation studies showing impact of different masking coefficients

## Confidence

**High confidence**: PAC algorithm derivation from FCM principles, mathematical formulation of OPA, and two-stage training procedure are clearly specified and reproducible. Performance improvements on standard benchmarks are measurable and significant.

**Medium confidence**: Claimed stability advantages over K-means-based methods are supported by paper's analysis but would benefit from direct runtime comparisons with identical architectures. Online computation claims assume batch size sufficiency without systematic validation.

**Low confidence**: Exact impact of masked contrastive loss on semantic preservation is difficult to assess without access to specific masking implementation details and hyperparameter sensitivity analysis.

## Next Checks

1. Systematically vary batch size from 64 to 480 on CIFAR-10 to determine minimum batch size where OPA performance matches full-data PAC accuracy within 2%
2. Perform m parameter sweep (1.01 to 1.2) on all five datasets to quantify stability-accuracy tradeoff and identify dataset-specific optimal values
3. Conduct ablation studies on masking coefficient in WCL, measuring class collision rates and contrastive loss values with masking disabled versus various masking strengths