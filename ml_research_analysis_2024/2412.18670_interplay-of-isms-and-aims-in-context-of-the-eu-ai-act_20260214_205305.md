---
ver: rpa2
title: Interplay of ISMS and AIMS in context of the EU AI Act
arxiv_id: '2412.18670'
source_url: https://arxiv.org/abs/2412.18670
tags:
- security
- requirements
- standards
- management
- european
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of implementing the EU AI Act''s
  cybersecurity requirements by clarifying the interface between Information Security
  Management Systems (ISMS) and AI Management Systems (AIMS). The author proposes
  integrating AI-specific security controls into existing ISMS frameworks, specifically
  the German BSI IT Grundschutz, by introducing four new AI modules: AI Cyber Governance,
  Data, AI Model, and AI Platform.'
---

# Interplay of ISMS and AIMS in context of the EU AI Act
## Quick Facts
- arXiv ID: 2412.18670
- Source URL: https://arxiv.org/abs/2412.18670
- Reference count: 0
- This paper proposes integrating AI-specific security controls into existing ISMS frameworks to implement EU AI Act cybersecurity requirements.

## Executive Summary
This paper addresses the challenge of implementing the EU AI Act's cybersecurity requirements by clarifying the interface between Information Security Management Systems (ISMS) and AI Management Systems (AIMS). The author proposes integrating AI-specific security controls into existing ISMS frameworks, specifically the German BSI IT Grundschutz, by introducing four new AI modules: AI Cyber Governance, Data, AI Model, and AI Platform. The study demonstrates that these modules, combined with existing Grundschutz controls, provide a comprehensive basis for implementing Article 15 of the AIA. Additionally, the paper suggests introducing a national standard BSI 200-5 based on ISO/IEC 42001 to create a certification framework for AIMS in Germany, which could be adapted by other EU countries.

## Method Summary
The paper presents a systematic approach to bridging ISMS and AIMS frameworks for implementing EU AI Act cybersecurity requirements. The methodology involves analyzing the gap between existing ISMS frameworks and AIA requirements, then proposing extensions through new AI-specific security modules. The approach focuses on extending the German BSI IT Grundschutz standard with four new AI modules while maintaining compatibility with international standards like ISO/IEC 42001.

## Key Results
- Proposed four AI-specific security modules (AI Cyber Governance, Data, AI Model, AI Platform) that can be integrated into existing ISMS frameworks
- Demonstrated that combining new AI modules with existing Grundschutz controls provides comprehensive coverage of Article 15 AIA requirements
- Suggested BSI 200-5 standard as national certification framework for AIMS, adaptable by other EU countries

## Why This Works (Mechanism)
The approach works by leveraging existing, proven ISMS frameworks rather than creating entirely new systems. By extending established standards like BSI IT Grundschutz with AI-specific modules, organizations can build on existing security practices while addressing new AI-specific risks. The modular approach allows for incremental implementation and maintains compatibility with international standards.

## Foundational Learning
- **ISMS Fundamentals**: Understanding of established information security management principles - needed to recognize existing security practices that can be extended for AI systems
- **AI Security Requirements**: Knowledge of AI-specific security risks and controls - needed to identify gaps in traditional ISMS for AI systems
- **Regulatory Framework**: Understanding of EU AI Act requirements - needed to ensure compliance with specific legal obligations
- **Standard Integration**: Methods for combining multiple standards - needed to create interoperable security frameworks
- **Risk Assessment**: Techniques for evaluating AI-specific risks - needed to prioritize security controls
- **Certification Processes**: Understanding of how standards become certifiable - needed to create practical implementation pathways

## Architecture Onboarding
The proposed architecture follows a modular extension pattern where existing ISMS components (A) are enhanced with new AI-specific modules (B), creating an integrated AIMS framework (C). The critical path involves first implementing governance controls, then data and model security, and finally platform security. Design tradeoffs include choosing between comprehensive upfront implementation versus phased rollout. Failure signatures include incomplete risk assessments and insufficient stakeholder buy-in. First experiments should: 1) Map existing controls to AI requirements, 2) Test AI module integration in a controlled environment, 3) Validate compliance with Article 15 requirements.

## Open Questions the Paper Calls Out
None

## Limitations
- Does not provide empirical evidence from real-world deployments or case studies demonstrating successful integration in operational environments
- Uncertainties remain regarding scalability and adaptability across different EU member states with varying regulatory contexts
- Limited detail on interaction between proposed AIMS framework and other AIA provisions beyond Article 15 cybersecurity requirements

## Confidence
High confidence in technical feasibility of proposed integration approach
Medium confidence in practical implementation success without empirical validation
Medium confidence in cross-EU adaptability of German BSI 200-5 approach

## Next Checks
1. Conduct pilot implementations of the proposed AI modules within existing ISMS frameworks across multiple organizations with different scales and sectors to validate practical feasibility and identify implementation challenges
2. Perform cross-EU validation studies comparing the proposed BSI 200-5 approach with existing national AI governance frameworks in other member states to assess adaptability and identify necessary modifications
3. Execute formal gap analysis between the proposed AI modules and emerging international standards (beyond ISO/IEC 42001) to ensure comprehensive coverage of AI security requirements and regulatory compliance