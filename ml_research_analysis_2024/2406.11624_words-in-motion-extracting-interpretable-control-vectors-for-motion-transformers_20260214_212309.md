---
ver: rpa2
title: 'Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers'
arxiv_id: '2406.11624'
source_url: https://arxiv.org/abs/2406.11624
tags:
- motion
- features
- control
- language
- hidden
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of interpreting and controlling
  hidden states in transformer-based motion forecasting models. The authors propose
  a novel method that uses natural language to quantize motion features into discrete,
  interpretable sets.
---

# Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers

## Quick Facts
- arXiv ID: 2406.11624
- Source URL: https://arxiv.org/abs/2406.11624
- Authors: Omer Sahin Tas; Royden Wagner
- Reference count: 40
- Key outcome: Natural language-based quantization of motion features enables interpretable control vectors for motion transformers without fine-tuning

## Executive Summary
This paper addresses the challenge of interpreting and controlling hidden states in transformer-based motion forecasting models. The authors propose a novel method that uses natural language to quantize motion features into discrete, interpretable sets. They then use linear probing to measure the degree to which these features are embedded in hidden states, demonstrating that the hidden states exhibit neural collapse towards human-interpretable motion features. Building on this insight, the authors fit control vectors to opposing motion features, allowing for controlling motion forecasts at inference without fine-tuning or prompt engineering.

## Method Summary
The method involves classifying motion features using natural language descriptions, then measuring their embedding in hidden states through linear probing during training. Control vectors are computed as differences between hidden states of opposing motion features, which can then be added to modify predictions at inference. The approach is evaluated on two motion forecasting models (Wayformer and RedMotion) using the Argoverse 2 and Waymo datasets, demonstrating high linear probing accuracy and effective zero-shot control of motion forecasts.

## Key Results
- Linear probing accuracy exceeds 80% for direction and 92% for motion classes, indicating strong alignment between hidden states and interpretable motion features
- Control vectors effectively modify motion forecasts at inference without fine-tuning
- Method demonstrates zero-shot generalization to unseen dataset characteristics
- Hidden states show neural collapse toward human-interpretable motion feature clusters

## Why This Works (Mechanism)

### Mechanism 1
- Motion forecasting transformers exhibit neural collapse toward interpretable motion feature clusters during training, with samples of similar motion features clustering together. This clustering is reinforced by the loss function and regularization, with linear probing accuracy >80% indicating alignment with human-interpretable features.

### Mechanism 2
- Control vectors modify motion forecasts by adding the difference between hidden states of opposing motion features. The temperature scaling parameter τ controls modification strength, working because the hidden states are arranged in a well-structured latent space with opposing features at opposite ends.

### Mechanism 3
- Natural language descriptions effectively quantize motion features into interpretable classes by capturing essential characteristics of motion patterns. These classes enable discrete labeling for linear probing and control vector fitting, aligning with human perception of motion categorization.

## Foundational Learning

- **Neural collapse**: Why needed - Understanding neural collapse explains why hidden states cluster around interpretable motion features and enables control vector methods. Quick check - What is the key characteristic of neural collapse that makes it desirable for classification tasks?

- **Linear probing**: Why needed - Linear probing measures how well interpretable motion features are embedded in hidden states, providing evidence for neural collapse. Quick check - How does linear probing differ from standard supervised learning in terms of its effect on the underlying model?

- **Control vectors**: Why needed - Control vectors are the mechanism for modifying motion forecasts at inference time without fine-tuning. Quick check - What is the mathematical relationship between a control vector and the hidden states it's derived from?

## Architecture Onboarding

- **Component map**: Motion encoder (3 modules) → Linear probes for motion features → Control vector fitting module; Environment context encoder → Motion decoder → Output layer; Datasets (Argoverse 2, Waymo) → Training loop with combined loss

- **Critical path**: 1. Encode past motion and environment context; 2. Hidden states processed through motion encoder modules; 3. Linear probes measure embedding of motion features; 4. Control vectors computed from opposing feature hidden states; 5. Control vectors added to hidden states at inference; 6. Modified hidden states decoded to motion forecasts

- **Design tradeoffs**: Linear probes vs. end-to-end training (measure without affecting representation learning vs. missing complex relationships); PCA reduction for computational efficiency vs. potential information loss; Temperature scaling for fine-grained control vs. requiring tuning

- **Failure signatures**: Low linear probing accuracy (<80%) indicating poor alignment; Control vectors producing unrealistic forecasts suggesting poorly-structured hidden space; High representation collapse (low std-ℓ2-norm) indicating redundant representations

- **First 3 experiments**: 1. Train models and measure linear probing accuracy for direction, speed, and acceleration features; 2. Fit control vectors for one feature pair (e.g., high vs. low speed) and test effects at different temperatures; 3. Combine multiple control vectors and evaluate zero-shot generalization to unseen dataset characteristics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the natural language-based motion feature quantization be extended to include more granular or diverse motion descriptors, such as combinations of speed, direction, and acceleration, or even dynamic scene elements like surrounding vehicles and pedestrians?
- Basis in paper: [inferred] The paper mentions that future work can explore detailed text descriptions by incorporating both static and dynamic scene elements.
- Why unresolved: Current method focuses on coarse-grained direction, speed, and acceleration classes without specific methods for more detailed descriptions.
- What evidence would resolve it: Experiments demonstrating effectiveness of more granular descriptors in improving linear probing accuracy and control vector performance.

### Open Question 2
- Question: How do multiple motion decoders affect the embeddings learned by motion forecasting models, and can the natural language-based quantization and control vector methods be adapted to work with models that use multiple decoders?
- Basis in paper: [inferred] The paper mentions investigating the impact of multiple motion decoders on embeddings as promising future research.
- Why unresolved: Current study focuses on models with single motion decoder; effect of multiple decoders on embeddings and method applicability remains unclear.
- What evidence would resolve it: Comparative studies showing method performance on models with different numbers of motion decoders and analysis of embedding changes.

### Open Question 3
- Question: Can natural language-based motion classes be effectively used for voice control in self-driving vehicles, and what are the potential challenges and benefits of implementing such a system?
- Basis in paper: [explicit] The paper suggests natural language-based motion classes could enable voice control and discusses potential benefits.
- Why unresolved: Paper mentions possibility but doesn't provide specific methods or results for implementing voice control systems.
- What evidence would resolve it: Demonstrations of working voice control system for self-driving vehicles using natural language-based motion classes, with performance analysis and challenge assessment.

## Limitations
- Linear probing accuracy alone cannot fully capture hidden state organization complexity and may miss nonlinear feature relationships
- Control vector method assumes linear separability of motion features, with uncertainty about generalization to subtle or overlapping features
- Natural language quantization introduces potential ambiguity in feature thresholds and edge case handling

## Confidence

**High Confidence (Experimental Evidence Strong):**
- Linear probing can measure embedding of interpretable motion features in hidden states
- Control vectors can modify motion forecasts at inference when applied to well-structured hidden states
- The method works on both Wayformer and RedMotion models with the tested datasets

**Medium Confidence (Methodologically Sound but Limited Evidence):**
- Hidden states exhibit neural collapse toward human-interpretable motion features
- Natural language descriptions effectively quantize motion features for this application
- Temperature scaling provides predictable control over modification strength

**Low Confidence (Theoretical Claims with Limited Validation):**
- The observed neural collapse is solely due to the transformer architecture and training process
- Control vectors will generalize to unseen dataset characteristics with the same effectiveness
- The method's performance will scale to more complex motion forecasting scenarios

## Next Checks
1. Apply non-linear probing methods (e.g., small neural networks) to measure motion feature embedding beyond linear separability and compare results with linear probing accuracy

2. Systematically vary the temperature parameter τ across a wider range and test on edge cases to establish limits of predictable control, measuring frequency of physically implausible motion forecasts

3. Train control vectors on one dataset (e.g., Argoverse 2) and evaluate effectiveness on motion forecasts from the other dataset (Waymo) without fine-tuning, measuring accuracy degradation and systematic biases