---
ver: rpa2
title: 'Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation"'
arxiv_id: '2407.19996'
source_url: https://arxiv.org/abs/2407.19996
tags:
- images
- attributes
- iti-gen
- prompt
- attribute
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study aimed to reproduce and extend the results of the ITI-GEN
  paper, which introduces a method to improve inclusiveness in text-to-image generation.
  The authors claim that ITI-GEN improves diversity and quality of generated images,
  is scalable to different domains, has plug-and-play capabilities, and is efficient
  from a computational point of view.
---

# Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation"

## Quick Facts
- **arXiv ID**: 2407.19996
- **Source URL**: https://arxiv.org/abs/2407.19996
- **Reference count**: 11
- **Primary result**: Study confirmed most claims about ITI-GEN's inclusiveness improvements but found limitations with multi-attribute generation and proxy feature learning

## Executive Summary
This reproducibility study evaluated the ITI-GEN method for improving inclusiveness in text-to-image generation. The study confirmed that ITI-GEN successfully generates diverse and high-quality images for single attributes, works across different domains, and integrates well with other models like ControlNet. However, the study also identified significant limitations: ITI-GEN struggles with multiple attributes, sometimes uses undesired attributes as proxy features, and has scalability issues as attribute count increases. To address these limitations, the study proposed Hard Prompt Search with negative prompting (HPSn) as an alternative approach that better handles negation without requiring training.

## Method Summary
The study reproduced ITI-GEN's core approach of learning fair tokens through directional alignment loss and semantic consistency loss on reference images. The reproduction used datasets including CelebA, FAIR, FairFace, and Landscapes HQ, evaluating fairness via KL divergence and image quality via FID scores. The study extended the original work by investigating the impact of reference image diversity, exploring the combination of ITI-GEN with HPSn for negation handling, and testing plug-and-play capabilities with ControlNet. Minor modifications were made to the provided GitHub repository to adapt it for the extended experiments.

## Key Results
- ITI-GEN successfully generates diverse and high-quality images for single attributes while maintaining good image quality
- The method demonstrates plug-and-play capabilities and works well across different domains
- ITI-GEN struggles with multi-attribute generation and exhibits proxy feature learning issues
- HPSn outperforms vanilla HPS in handling negations and can be combined with ITI-GEN for improved performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ITI-GEN improves diversity and quality of generated images while preserving image quality using a small number of reference images.
- Mechanism: ITI-GEN learns fair tokens by aligning reference images with inclusive prompts using directional alignment loss and semantic consistency loss. This creates a mapping between attribute categories and image features that guides the generator.
- Core assumption: Reference images are diverse and representative enough to capture the desired attribute distribution without introducing unwanted correlations.
- Evidence anchors:
  - [abstract] "ITI-GEN improves diversity and quality of generated images"
  - [section 3.1] "ITI-Gen learns a set of fair tokens that represent each attribute category"
  - [corpus] Weak - no direct evidence in related papers about this specific mechanism
- Break condition: If reference images contain strong correlations between attributes (e.g., most bald people are men), the model will learn these as proxy features rather than the intended attributes.

### Mechanism 2
- Claim: ITI-GEN has plug-and-play capabilities and can be used with other text-to-image models.
- Mechanism: The learned fair tokens can be appended to any text prompt, and the method integrates with different generators by modifying the conditioning vector while keeping the original model architecture unchanged.
- Core assumption: The conditioning mechanism of the target model accepts additional token embeddings that can influence generation without breaking the model.
- Evidence anchors:
  - [abstract] "Trained fair tokens can be used with other similar text prompts in a plug-and-play manner"
  - [section 3.1] "sampling over a uniform distribution over all combinations leads to fair generation"
  - [corpus] Weak - no direct evidence in related papers about plug-and-play with different models
- Break condition: If the target model's conditioning space doesn't align with CLIP embeddings or if the model architecture doesn't support token concatenation.

### Mechanism 3
- Claim: Hard Prompt Search with negative prompting (HPSn) handles negation better than vanilla HPS.
- Mechanism: HPSn uses two conditioning vectors - one for desired features and one for undesired features (negative prompt). The generator computes λ(f(x,t,c)−f(x,t,c̄)) + f(x,t,c̄) where c̄ represents negative features.
- Core assumption: The generator's denoising process can effectively subtract the influence of negative features when provided as separate conditioning.
- Evidence anchors:
  - [abstract] "we propose using Hard Prompt Search with negative prompting, a method that does not require training and that handles negation better than vanilla Hard Prompt Search"
  - [section 3.1] "By providing the features that are not wanted we can prevent them from appearing in the generated images"
  - [corpus] Moderate - related papers mention prompt engineering but not this specific negative conditioning approach
- Break condition: If the generator doesn't properly implement the negative conditioning or if λ scaling is inappropriate for the model.

## Foundational Learning

- Concept: Directional alignment loss and cosine similarity loss for image-text embedding alignment
  - Why needed here: These losses create the mapping between attribute categories and visual features that enables fair generation
  - Quick check question: What happens to the loss when image embeddings for different categories are too similar to distinguish?

- Concept: Kullback-Leibler divergence for measuring distribution fairness
  - Why needed here: KL divergence quantifies how close the generated attribute distribution is to the uniform (fair) distribution
  - Quick check question: If KL divergence equals zero, what does that tell us about the generated images' attribute distribution?

- Concept: Fréchet Inception Distance (FID) for image quality assessment
  - Why needed here: FID provides a quantitative measure of how realistic the generated images are compared to real images
  - Quick check question: What does a lower FID score indicate about the quality of generated images?

## Architecture Onboarding

- Component map:
  Reference image dataset → CLIP encoders (Eimg, Etext) → Directional alignment loss → Fair token learner → Inclusive prompt generator → Text-to-image model → Generated images
  HPSn: Text prompt → Negative prompt → Dual conditioning → Stable Diffusion → Generated images
  Combined approach: HPSn text + ITI-GEN fair tokens → Dual conditioning → Stable Diffusion → Generated images

- Critical path:
  1. Prepare reference images for each attribute category
  2. Train ITI-GEN to learn fair tokens using directional alignment and semantic consistency losses
  3. Generate images using the inclusive prompts with fair tokens
  4. Evaluate diversity (KL divergence) and quality (FID score)

- Design tradeoffs:
  - Training time vs. number of attributes (exponential growth)
  - Reference image diversity vs. proxy feature learning
  - Quality of negative prompting vs. complexity of specifying negative attributes

- Failure signatures:
  - High KL divergence indicates poor diversity (model not generating all attribute combinations)
  - Proxy feature learning (e.g., using gender as proxy for baldness) shows in joint attribute distributions
  - Poor FID scores indicate quality issues with generated images

- First 3 experiments:
  1. Train ITI-GEN on single attribute (e.g., eyeglasses) and measure KL divergence and FID score
  2. Test plug-and-play capability by applying learned tokens to different prompts
  3. Compare HPSn vs ITI-GEN on multi-attribute generation (e.g., gender × eyeglasses) for diversity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we systematically detect when ITI-GEN is using proxy features for attributes that are correlated with other attributes?
- Basis in paper: [explicit] The paper demonstrates that ITI-GEN sometimes uses undesired attributes as proxy features, particularly for attributes like "Bald," "Mustache," and "Beard," which seem to use "Gender" as a proxy.
- Why unresolved: The paper identifies the issue but does not provide a systematic method to detect proxy feature usage across different attributes and datasets.
- What evidence would resolve it: Developing a framework or set of metrics to identify proxy feature usage would be helpful. This could involve analyzing the distribution of generated images and comparing it with the expected distribution if no proxy features were used.

### Open Question 2
- Question: What are the specific limitations of Hard Prompt Search with negative prompting (HPSn) in handling continuous attributes, and how can these be addressed?
- Basis in paper: [explicit] The paper states that HPSn cannot be used for continuous attributes that are hard to express in natural language, an area where ITI-GEN excels as it is guided by images during training.
- Why unresolved: The paper identifies the limitation but does not explore potential solutions or modifications to HPSn to handle continuous attributes better.
- What evidence would resolve it: Investigating methods to extend HPSn's capabilities to continuous attributes, such as incorporating image guidance or developing hybrid approaches, would be valuable.

### Open Question 3
- Question: How does the choice of reference images affect the performance of ITI-GEN in terms of fairness and diversity, and what guidelines can be established for selecting appropriate reference images?
- Basis in paper: [explicit] The paper shows that ITI-GEN's performance can be affected by the diversity and entanglement of attributes in the reference image datasets, as demonstrated in the experiments with the "Eyeglasses" dataset.
- Why unresolved: The paper provides examples of how reference image choice impacts performance but does not offer comprehensive guidelines for selecting reference images to ensure fairness and diversity.
- What evidence would resolve it: Conducting a thorough study on the impact of reference image selection on ITI-GEN's performance and developing best practices for choosing reference images would be beneficial.

## Limitations
- Incomplete specification of experimental parameters (exact text prompts and evaluation settings) affects reproducibility
- ITI-GEN struggles with multi-attribute generation and exhibits proxy feature learning issues
- Classification-based evaluation using CLIP embeddings may introduce noise in diversity measurements

## Confidence
- **High Confidence**: Claims about ITI-GEN's effectiveness for single-attribute generation and its compatibility with ControlNet for plug-and-play functionality
- **Medium Confidence**: Claims about ITI-GEN's limitations with multiple attributes and proxy feature learning
- **Low Confidence**: Claims about the superiority of HPSn over vanilla HPS for handling negation

## Next Checks
1. **Systematic multi-attribute scalability test**: Conduct controlled experiments varying the number of attributes from 2 to 6, measuring KL divergence, FID scores, and proxy feature detection rates to quantify scalability limitations.

2. **Manual validation of classification accuracy**: Manually label a stratified sample of 500-1000 generated images across different attribute combinations to assess the reliability of CLIP-based classification for KL divergence calculations.

3. **Cross-domain generalization study**: Test ITI-GEN's performance on entirely different domains (e.g., animals, vehicles, or indoor scenes) beyond the tested CelebA, FairFace, and LHQ datasets to evaluate the generality of its plug-and-play capabilities and identify domain-specific failure modes.