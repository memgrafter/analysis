---
ver: rpa2
title: Modelling Political Coalition Negotiations Using LLM-based Agents
arxiv_id: '2402.11712'
source_url: https://arxiv.org/abs/2402.11712
tags:
- coalition
- statement
- political
- negotiation
- party
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces POLCA, a multilingual dataset for simulating
  coalition negotiations, and models the process as a hierarchical Markov decision
  process with LLM-based agents. The dataset comprises political party manifestos
  and coalition agreements from six European countries, enabling the analysis of negotiation
  dynamics.
---

# Modelling Political Coalition Negotiations Using LLM-based Agents

## Quick Facts
- arXiv ID: 2402.11712
- Source URL: https://arxiv.org/abs/2402.11712
- Reference count: 12
- The proposed model uses two levels of policies—one for selecting statements and another for negotiating actions—to simulate the coalition formation process

## Executive Summary
This paper introduces POLCA, a multilingual dataset for simulating coalition negotiations, and models the process as a hierarchical Markov decision process with LLM-based agents. The dataset comprises political party manifestos and coalition agreements from six European countries, enabling the analysis of negotiation dynamics. The proposed model uses two levels of policies—one for selecting statements and another for negotiating actions—to simulate the coalition formation process. Experiments with state-of-the-art LLMs show that while predicting negotiation outcomes is challenging, the model achieves reasonable performance, with gpt-3.5-turbo outperforming other models.

## Method Summary
The paper models coalition negotiations as a two-level hierarchical Markov decision process (HMDP). At the higher level, an agent selects which statement to negotiate from a set of manifesto statements. At the lower level, the agent chooses negotiation actions (support, oppose, refine, compromise) for the selected statement. The approach uses pre-trained LLMs (gpt-3.5-turbo, LLaMa-7b-chat, LLaMa-13b-chat) as negotiation agents, with reward functions guiding policy updates at each level. The POLCA dataset provides the foundation, containing manifestos and coalition agreements from six European countries. The model is evaluated using macro F1 score to account for imbalanced class distributions.

## Key Results
- The hierarchical policy approach improves results compared to simpler baselines, highlighting the importance of strategic reasoning in political negotiations
- gpt-3.5-turbo outperforms both LLaMa-13b-chat and LLaMa-7b-chat models, with performance correlating to parameter count
- While predicting negotiation outcomes remains challenging, the model achieves reasonable performance in simulating coalition formation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hierarchical Markov decision process (HMDP) improves coalition negotiation prediction by separating strategic statement selection from tactical action execution.
- Mechanism: The HMDP divides the negotiation into two levels: the higher level chooses which statement to negotiate, while the lower level decides the action (support, oppose, refine, compromise) for that statement. This separation allows the model to learn distinct policies for high-level strategy and low-level negotiation tactics.
- Core assumption: Coalition negotiations benefit from a hierarchical decision-making structure where strategy and tactics can be optimized independently.
- Evidence anchors:
  - [abstract] "The proposed model uses two levels of policies—one for selecting statements and another for negotiating actions—to simulate the coalition formation process."
  - [section] "We model the coalition negotiation as a two-level hierarchical Markov decision process. At the higher (HI) level, an agent p chooses statement mi from M = {m1, ..., mn}. At the lower (LO) level, the agent chooses action ak from A = {a1, ..., at} to negotiate the chosen statement at the higher level."
  - [corpus] Weak evidence; no direct corpus citations for HMDP effectiveness.
- Break condition: If the interaction between high-level strategy and low-level tactics becomes too complex for the model to capture, or if the statement selection becomes irrelevant to successful negotiation.

### Mechanism 2
- Claim: Large language models with higher parameter counts (like gpt-3.5-turbo) outperform smaller models in coalition negotiation simulation due to better understanding of political nuance and reasoning capabilities.
- Mechanism: LLMs with more parameters have been trained on more diverse data and can capture more complex relationships and nuances in political language, leading to more realistic negotiation simulations.
- Core assumption: Model size correlates with the ability to understand and simulate complex political negotiations.
- Evidence anchors:
  - [abstract] "Experiments with state-of-the-art LLMs show that while predicting negotiation outcomes is challenging, the model achieves reasonable performance, with gpt-3.5-turbo outperforming other models."
  - [section] "gpt-3.5-turbo consistently outperforms both LLaMa-13b-chat and LLaMa-7b-chat models. This superiority in performance can be attributed to the correlation between the number of parameters in these models and their respective abilities to accurately simulate the coalition negotiation process."
  - [corpus] Weak evidence; no direct corpus citations for parameter size effectiveness.
- Break condition: If political nuance requires domain-specific knowledge that general LLMs cannot acquire, regardless of size.

### Mechanism 3
- Claim: The POLCA dataset enables realistic coalition negotiation simulation by providing real-world manifestos and coalition agreements from multiple countries and parties.
- Mechanism: By grounding the negotiation simulation in actual political statements and their outcomes, the model can learn patterns of successful negotiation strategies and outcomes that reflect real-world dynamics.
- Core assumption: Historical coalition negotiation data contains patterns that can be learned and generalized to new negotiation scenarios.
- Evidence anchors:
  - [abstract] "We introduce a multilingual dataset, POLCA, comprising manifestos of European political parties and coalition agreements over a number of elections in these countries."
  - [section] "In order to address the data scarcity problem in this area, we introduce a new dataset, POLCA, which is compiled by analysing and annotating the content of two existing datasets in political science."
  - [corpus] Weak evidence; no direct corpus citations for dataset effectiveness.
- Break condition: If the historical patterns in the dataset are too specific to individual countries or time periods to generalize, or if political contexts change significantly over time.

## Foundational Learning

- Concept: Hierarchical decision-making structures
  - Why needed here: Understanding how to decompose complex decision processes into multiple levels of abstraction is crucial for implementing the HMDP approach.
  - Quick check question: Can you explain why separating strategy (what to negotiate) from tactics (how to negotiate) might improve model performance in complex scenarios?

- Concept: Large language model capabilities and limitations
  - Why needed here: Understanding the strengths and weaknesses of different LLMs is essential for selecting appropriate models and interpreting their performance in negotiation tasks.
  - Quick check question: What factors should be considered when choosing between different LLMs for a complex reasoning task like coalition negotiation?

- Concept: Political negotiation dynamics
  - Why needed here: Understanding the basic principles of political coalition formation and negotiation helps in designing appropriate reward functions and evaluation metrics.
  - Quick check question: What are the key elements that make coalition negotiations different from other types of negotiations?

## Architecture Onboarding

- Component map:
  Data pipeline: Manifesto and coalition agreement processing -> Annotation generation -> Dataset creation
  Model architecture: Hierarchical MDP with two-level policies -> LLM-based agents -> Reward functions
  Training loop: State observation -> Policy selection -> Action execution -> Reward calculation -> Policy update
  Evaluation: Macro F1 score calculation -> Performance comparison across models and settings

- Critical path:
  1. Load and preprocess manifesto and coalition agreement data
  2. Generate annotations using GPT-4 with retrieval module
  3. Initialize HMDP with LLM agents and predefined actions
  4. Run negotiation simulation with policy updates
  5. Calculate performance metrics and compare results

- Design tradeoffs:
  - Model complexity vs. interpretability: HMDP adds complexity but may improve performance
  - Dataset size vs. quality: More countries/parties would improve generalization but increase annotation costs
  - LLM choice vs. performance: Larger models perform better but are more expensive to run
  - Negotiation rounds vs. computational cost: More rounds may improve outcomes but increase training time

- Failure signatures:
  - Low performance across all models: Indicates fundamental issues with approach or dataset quality
  - Performance gap between gpt-3.5-turbo and other models: Suggests parameter count is crucial for this task
  - HMDP-LO outperforming full HMDP: Indicates the hierarchical structure may be unnecessary or poorly implemented
  - Inconsistent results across countries: Suggests model struggles with language or political context differences

- First 3 experiments:
  1. Compare HMDP with simple classifier baseline on the same dataset to validate the need for negotiation simulation
  2. Test different LLM sizes (gpt-3.5-turbo, LLaMa-13b-chat, LLaMa-7b-chat) in the HMDP to quantify performance differences
  3. Run ablation study removing either the high-level or low-level policy to measure the contribution of each component to overall performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of POLCA vary when applied to coalition negotiations involving more than two parties?
- Basis in paper: [inferred] The paper mentions that the hierarchical MDP framework can be extended to multi-party negotiations, but only tests two-party scenarios.
- Why unresolved: The paper focuses on two-party negotiations, leaving the scalability and effectiveness of the model for multi-party scenarios unexplored.
- What evidence would resolve it: Experiments testing the model's performance with three or more parties in coalition negotiations.

### Open Question 2
- Question: To what extent does the hierarchical MDP framework capture the dynamic and iterative nature of real-world coalition negotiations?
- Basis in paper: [explicit] The paper highlights that coalition negotiations are complex and iterative, but the model's ability to fully represent these dynamics is not thoroughly evaluated.
- Why unresolved: While the hierarchical MDP is designed to simulate negotiations, its effectiveness in capturing the full complexity of real-world negotiations is not fully demonstrated.
- What evidence would resolve it: Comparative analysis of the model's predictions against real-world negotiation outcomes in diverse political contexts.

### Open Question 3
- Question: How does the choice of backbone LLM affect the model's ability to handle negotiations in languages other than those tested in the paper?
- Basis in paper: [explicit] The paper tests the model with English and other European languages but does not explore its performance in non-European or less-resourced languages.
- Why unresolved: The paper does not address the generalizability of the model to languages beyond the tested set.
- What evidence would resolve it: Performance evaluations of the model using coalition negotiation data in non-European languages.

## Limitations

- The effectiveness of the hierarchical structure relies heavily on the assumption that strategy and tactics can be optimized independently, which may not hold in complex real-world negotiations
- The dataset covers only six European countries, limiting generalizability to other political systems
- The evaluation focuses primarily on prediction accuracy rather than the realism or strategic depth of the negotiations

## Confidence

- High confidence in the HMDP framework design and implementation
- Medium confidence in the POLCA dataset quality and coverage
- Medium confidence in the claimed performance benefits of larger LLMs
- Low confidence in the generalizability to non-European political contexts

## Next Checks

1. Conduct ablation studies to isolate the contribution of each policy level in the HMDP and test whether the hierarchical structure truly improves performance over simpler approaches
2. Evaluate model performance on out-of-sample countries and time periods to assess generalization capabilities
3. Implement human evaluation studies to assess the realism and strategic quality of simulated negotiations beyond prediction accuracy metrics