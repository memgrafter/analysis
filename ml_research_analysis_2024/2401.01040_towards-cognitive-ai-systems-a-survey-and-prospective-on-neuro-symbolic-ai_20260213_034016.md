---
ver: rpa2
title: 'Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI'
arxiv_id: '2401.01040'
source_url: https://arxiv.org/abs/2401.01040
tags:
- symbolic
- nsai
- systems
- neural
- neuro
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey paper systematically reviews neuro-symbolic AI (NSAI)
  algorithms and characterizes their system performance. NSAI combines neural, symbolic,
  and probabilistic approaches to create more interpretable, robust, and data-efficient
  AI systems compared to pure neural networks.
---

# Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI

## Quick Facts
- **arXiv ID:** 2401.01040
- **Source URL:** https://arxiv.org/abs/2401.01040
- **Reference count:** 11
- **Primary result:** NSAI workloads exhibit greater heterogeneity and memory intensity than traditional neural networks, with symbolic reasoning dominating runtime and requiring novel hardware architectures.

## Executive Summary
This survey systematically reviews neuro-symbolic AI (NSAI) algorithms and characterizes their system performance, revealing that NSAI systems combine neural, symbolic, and probabilistic approaches to create more interpretable, robust, and data-efficient AI systems. The paper categorizes NSAI algorithms into five paradigms based on how neural and symbolic components are integrated, and profiles three representative models finding that symbolic workloads can dominate runtime (up to 92.1%) due to sequential reasoning and data movement bottlenecks. The analysis reveals NSAI workloads exhibit greater heterogeneity and memory intensity than traditional neural networks, requiring novel architectures to address the computational challenges of integrating these diverse components.

## Method Summary
The study profiles three representative NSAI models (LNN, LTN, NVSA) on Intel Xeon Silver 4114 CPU and Nvidia RTX 2080 Ti GPU using PyTorch Profiler. The profiling workflow measures runtime breakdown by workload type (neural vs symbolic), scalability with test set size, and compute operator analysis across six categories: convolution, MatMul, vector/element-wise, data transformation, data movement, and others. The experiments aim to characterize the computational characteristics of NSAI systems and identify performance bottlenecks in integrating neural and symbolic components.

## Key Results
- Symbolic workloads can dominate runtime (up to 92.1%) in NSAI systems, predominantly due to sequential and computationally intensive rule detection during reasoning procedures
- NSAI workloads exhibit greater heterogeneity and memory intensity than traditional DNN workloads, requiring novel hardware architectures with dedicated processing units and memory hierarchies
- Current hardware roadmaps focused on matrix multiplication are not well-suited for NSAI's diverse computational patterns including irregular memory access and complex control flows

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neuro-symbolic AI systems achieve better data efficiency and interpretability by combining neural learning with symbolic reasoning.
- Mechanism: The neural component handles feature extraction and pattern recognition from complex data, while the symbolic component provides explicit reasoning and domain knowledge, reducing reliance on large training datasets.
- Core assumption: Symbolic reasoning can be effectively integrated with neural networks without compromising either component's strengths.
- Evidence anchors:
  - [abstract]: "Neuro-symbolic AI (NSAI) emerges as a promising paradigm, fusing neural, symbolic, and probabilistic approaches to enhance interpretability, robustness, and trustworthiness while facilitating learning from much less data."
  - [section]: "Symbolic methods enhance explainability and reduce the dependence on extensive training data by incorporating established models of the physical world"

### Mechanism 2
- Claim: Symbolic workloads can become the bottleneck in NSAI systems, dominating runtime despite being computationally less intensive than neural components.
- Mechanism: Symbolic reasoning often involves sequential operations and complex data movement that don't parallelize well, while neural components benefit from GPU acceleration.
- Core assumption: The sequential nature of symbolic reasoning inherently limits parallelization opportunities.
- Evidence anchors:
  - [section]: "symbolic workloads can dominate runtime (up to 92.1%) and are bottlenecked by sequential reasoning and data movement"
  - [section]: "symbolic workload dominates the NVSA's runtime, predominately due to the sequential and computational-intensive rule detection during the involved reasoning procedure"

### Mechanism 3
- Claim: NSAI systems require novel hardware architectures due to their heterogeneous workload characteristics that differ significantly from pure neural networks.
- Mechanism: The combination of neural, symbolic, and probabilistic components creates diverse computational patterns including irregular memory access, complex control flows, and varied data types that don't map well to existing DNN accelerators.
- Core assumption: Current hardware architectures optimized for matrix multiplication cannot efficiently handle the diverse computational patterns in NSAI.
- Evidence anchors:
  - [abstract]: "The analysis reveals NSAI workloads exhibit greater heterogeneity and memory intensity than traditional neural networks, requiring novel architectures"
  - [section]: "NSAI workloads that combine neural, symbolic, and probabilistic methods feature much greater heterogeneity in compute kernels, sparsity, irregularity in access patterns, and higher memory intensity than current DNN workloads"

## Foundational Learning

- **Concept:** Neural network fundamentals (CNNs, MLPs, activation functions)
  - Why needed here: Understanding the neural component of NSAI systems is essential for analyzing their performance characteristics
  - Quick check question: What is the primary computational operation in a convolutional neural network layer?

- **Concept:** Symbolic reasoning and logic programming
  - Why needed here: Symbolic components are central to NSAI and understanding their computational characteristics is crucial
  - Quick check question: What is the difference between propositional and first-order logic in symbolic reasoning systems?

- **Concept:** Hardware architecture concepts (memory hierarchy, parallelism, data movement)
  - Why needed here: Analyzing NSAI performance requires understanding how different computational patterns map to hardware
  - Quick check question: How does data movement between CPU and GPU affect overall system performance?

## Architecture Onboarding

- **Component map:** Perception layers (CNNs) -> Feature extraction -> Symbolic reasoning engines -> Probabilistic components -> Decision output
- **Critical path:** The symbolic reasoning component often forms the critical path due to its sequential nature and data dependencies, particularly in systems like NVSA where reasoning follows perception
- **Design tradeoffs:** Balancing neural network depth for feature extraction against symbolic reasoning complexity; choosing between integrated vs. pipeline architectures; determining optimal data movement strategies
- **Failure signatures:** Performance bottlenecks from sequential symbolic reasoning; memory bandwidth limitations from irregular access patterns; underutilization of parallel hardware for symbolic workloads
- **First 3 experiments:**
  1. Profile runtime breakdown between neural and symbolic components on representative tasks
  2. Measure memory bandwidth utilization during symbolic reasoning phases
  3. Test different architectural configurations (integrated vs. pipeline) for latency vs. throughput tradeoffs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental principles and methods for integrating neural, symbolic, and probabilistic approaches in a unified framework for neuro-symbolic AI?
- Basis in paper: [explicit] The paper discusses the need for a unified framework to design algorithms that combine neural, symbolic, and probabilistic components, and for quantifying scaling laws for neuro-probabilistic-symbolic inference versus large neural models.
- Why unresolved: The integration of neural, symbolic, and probabilistic approaches in a principled manner remains a fundamental and open challenge, as mentioned in the paper.
- What evidence would resolve it: Research papers and case studies that demonstrate successful integration of these approaches in a unified framework, along with quantitative analysis of their performance and scalability.

### Open Question 2
- Question: How can efficient software frameworks be developed to support the diverse computational needs of neuro-symbolic AI systems, including logic operations, neural network computations, and probabilistic reasoning?
- Basis in paper: [explicit] The paper highlights the need for new software frameworks that can encompass a broad set of reasoning logical capabilities and provide practical syntactic and semantic extensions while being fast and memory-efficient.
- Why unresolved: The current software frameworks for neuro-symbolic AI are limited in modularity and extensibility, as mentioned in the paper.
- What evidence would resolve it: Development and evaluation of software frameworks that demonstrate improved performance, modularity, and extensibility for neuro-symbolic AI systems.

### Open Question 3
- Question: What are the key architectural considerations and design principles for cognitive hardware architectures that can efficiently support the diverse computational needs of neuro-symbolic AI workloads?
- Basis in paper: [explicit] The paper discusses the need for novel architectures with dedicated processing units, memory hierarchies, and on-chip interconnects that can handle the additional complexities in computations and communications for neuro-symbolic AI workloads.
- Why unresolved: The current hardware roadmap focuses on matrix multiplication or nearest neighbor search, which is not well-suited for the heterogeneity and memory intensity of neuro-symbolic AI workloads, as mentioned in the paper.
- What evidence would resolve it: Architectural designs and performance evaluations of hardware platforms that demonstrate improved efficiency and flexibility for neuro-symbolic AI workloads.

## Limitations

- The survey relies heavily on profiling only three specific NSAI models (LNN, LTN, NVSA) without broader empirical validation across diverse implementations
- The characterization of symbolic workloads as universally sequential may not generalize to all symbolic reasoning approaches, particularly those employing parallel algorithms
- Performance bottlenecks identified are specific to the hardware platforms (Intel Xeon Silver 4114 CPU and Nvidia RTX 2080 Ti GPU) used in the study and may differ on alternative architectures

## Confidence

- **High Confidence:** The fundamental observation that NSAI systems combine neural and symbolic components creating heterogeneous workloads is well-established
- **Medium Confidence:** The specific runtime breakdown percentages are likely accurate for the profiled models but may not generalize across all NSAI implementations
- **Low Confidence:** Predictions about the necessity for entirely new cognitive hardware architectures remain speculative without broader empirical evidence

## Next Checks

1. Profile additional NSAI implementations beyond the three models studied to assess generalizability of the workload characterization findings
2. Test the same NSAI workloads on specialized hardware accelerators (e.g., Graphcore IPUs, Cerebras WSE) to determine if current hardware limitations are fundamental or platform-specific
3. Implement parallel symbolic reasoning algorithms to empirically test whether sequential reasoning is an inherent limitation or can be overcome through algorithmic improvements