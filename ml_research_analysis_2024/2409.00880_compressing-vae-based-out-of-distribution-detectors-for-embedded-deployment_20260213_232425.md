---
ver: rpa2
title: Compressing VAE-Based Out-of-Distribution Detectors for Embedded Deployment
arxiv_id: '2409.00880'
source_url: https://arxiv.org/abs/2409.00880
tags:
- quantization
- detection
- loss
- pruning
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of deploying variational autoencoder
  (VAE)-based out-of-distribution (OOD) detectors on resource-constrained embedded
  systems. The core method combines quantization, pruning, and knowledge distillation
  into a systematic design methodology that reduces model size and inference time
  while maintaining detection accuracy.
---

# Compressing VAE-Based Out-of-Distribution Detectors for Embedded Deployment

## Quick Facts
- arXiv ID: 2409.00880
- Source URL: https://arxiv.org/abs/2409.00880
- Reference count: 29
- This work addresses the challenge of deploying variational autoencoder (VAE)-based out-of-distribution (OOD) detectors on resource-constrained embedded systems.

## Executive Summary
This paper presents a systematic methodology for compressing VAE-based OOD detectors while maintaining detection accuracy for deployment on embedded systems. The approach combines quantization, pruning, and knowledge distillation to reduce model size and inference time. The key insight is that OOD detection relies on relative latent space divergence rather than absolute reconstruction quality, allowing for more aggressive compression than traditional classification tasks. Evaluated on a Jetson Nano platform, the methodology achieves significant performance improvements while keeping detection accuracy within acceptable bounds.

## Method Summary
The methodology employs a three-stage compression pipeline: first applying quantization (8-bit for CPU, fp16 for GPU), then pruning-aware knowledge distillation where layers with highest sparsity are removed, and finally a final pruning stage. The approach exploits the fact that VAE-based OOD detection depends on KL divergence between latent encodings and the prior distribution, allowing compression techniques to degrade both ID and OOD samples proportionally in latent space while preserving their relative separation. This enables aggressive compression without proportional loss in detection performance.

## Key Results
- Achieved 20% GPU and 28% CPU inference time reductions while maintaining AUROC within 5% of baseline for optical flow OOD detection
- Demonstrated 38% execution time reduction with only 1% AUROC loss for β-VAE detection
- Successfully deployed compressed models on Jetson Nano embedded platform with minimal accuracy degradation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The VAE-based OOD detector maintains detection accuracy even under aggressive compression because the detection relies on relative latent space divergence rather than absolute reconstruction quality.
- Mechanism: OOD detection performance depends on KL divergence between latent encodings and the prior distribution. Compression techniques degrade both ID and OOD samples proportionally in latent space, preserving their relative separation.
- Core assumption: The KL divergence-based decision boundary remains effective even when the VAE's reconstruction capability is degraded.
- Evidence anchors:
  - [abstract] "While these techniques increase the VAE's test loss, this does not correspond to a proportional decrease in OOD detection performance"
  - [section] "we observe that low training loss in the VAE does not necessarily translate to high OOD detection accuracy, and vice-versa"
  - [corpus] Weak evidence - no direct citations about KL divergence-based detection under compression found in corpus
- Break condition: If compression disproportionately affects ID vs OOD samples in latent space, breaking the relative divergence pattern.

### Mechanism 2
- Claim: Knowledge distillation with pruning-aware architecture search finds efficient student models by removing layers with highest sparsity, reducing computational load while maintaining accuracy.
- Mechanism: The methodology identifies and removes convolutional or fully-connected layers with the highest percentage of zero weights after pruning, assuming these contribute least to the network's output.
- Core assumption: Layer sparsity correlates with its contribution to the network's output and removing such layers preserves essential functionality.
- Evidence anchors:
  - [section] "We take a layer's sparsity after pruning as a heuristic for its contribution to the network's output"
  - [section] "We take a layer with the highest percentage of zero weights is removed"
  - [corpus] No direct corpus evidence about pruning-aware knowledge distillation for VAE-based OOD detection
- Break condition: If the sparsity-heuristic fails and critical layers are removed, causing accuracy collapse.

### Mechanism 3
- Claim: Quantization reduces memory footprint and execution time by converting 32-bit float weights to 8-bit integers while maintaining detection accuracy through hardware-aware optimization.
- Mechanism: The methodology generates separate models for CPU (quantized 8-bit) and GPU (fp16) targets, exploiting hardware-specific efficiency gains without sacrificing accuracy.
- Core assumption: Different hardware platforms can efficiently execute models with precision levels matching their native computational capabilities.
- Evidence anchors:
  - [section] "our methodology generates two models: a floating point version tailored to GPU inference and a quantized version tailored to CPU inference"
  - [section] "Dynamic quantization incurs the longest execution time, which could be attributed to the additional overhead of computing the scaling factors during runtime"
  - [corpus] No direct corpus evidence about quantized VAE-based OOD detection
- Break condition: If quantization causes numerical instability or loss of precision critical for detection.

## Foundational Learning

- Concept: KL divergence in latent space
  - Why needed here: OOD detection relies on measuring how far samples deviate from the prior distribution in latent space
  - Quick check question: What happens to KL divergence when a sample is truly OOD versus ID?

- Concept: Knowledge distillation and pruning
  - Why needed here: The methodology combines these to create efficient student models while preserving detection capability
  - Quick check question: How does removing a layer with high sparsity affect the model's representational capacity?

- Concept: Quantization and hardware optimization
  - Why needed here: Different embedded platforms require different precision levels for optimal performance
  - Quick check question: Why does dynamic quantization have higher runtime overhead than static quantization?

## Architecture Onboarding

- Component map: Encoder-only VAE architecture → KL divergence computation → ICP confidence scoring → martingale smoothing → OOD classification
- Critical path: Input → Encoder → Latent space → KL divergence → Confidence score → Decision
- Design tradeoffs: Precision vs performance (quantization), model size vs accuracy (pruning), complexity vs execution time (knowledge distillation)
- Failure signatures: AUROC drop below threshold, execution time exceeding limits, memory usage exceeding constraints
- First 3 experiments:
  1. Run baseline VAE model on Jetson Nano to establish performance metrics
  2. Apply dynamic quantization and measure impact on AUROC and execution time
  3. Perform pruning-aware knowledge distillation and evaluate accuracy vs efficiency tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of OOD detectors degrade when compression techniques are applied to datasets with different generating distributions than those used in the case studies?
- Basis in paper: [explicit] The paper notes that their methodology requires access to OOD samples at design time for cross-validation, but acknowledges that OOD samples may not follow a particular generating distribution in general applications.
- Why unresolved: The case studies used controlled datasets with known OOD distributions (brightness changes for β-VAE, precipitation for optical flow), but real-world applications may have more complex and unknown OOD distributions.
- What evidence would resolve it: Testing the compression methodology on diverse real-world datasets with various types of OOD samples and comparing detection performance across different distribution characteristics.

### Open Question 2
- Question: What is the theoretical relationship between VAE reconstruction loss and OOD detection performance, and why does high compression sometimes maintain or improve detection accuracy despite increased loss?
- Basis in paper: [explicit] The paper observes that low training loss in the VAE does not necessarily translate to high OOD detection accuracy, and that compression techniques can maintain detection performance even when loss increases.
- Why unresolved: The paper provides empirical observations but does not explain the underlying mechanism that allows OOD detection to remain effective despite degraded reconstruction quality.
- What evidence would resolve it: Developing a theoretical framework that connects latent space divergence, reconstruction loss, and OOD detection accuracy, and validating this framework across multiple VAE architectures and datasets.

### Open Question 3
- Question: How can the design methodology be extended to guarantee finding the globally optimal architecture rather than relying on greedy search through pruning-aware knowledge distillation?
- Basis in paper: [explicit] The paper states that their methodology "only guides the search for a faster architecture, but does not guarantee the optimum result."
- Why unresolved: The current approach uses heuristic-based greedy search and binary search, which may miss better architectures that require non-greedy exploration of the design space.
- What evidence would resolve it: Developing and testing alternative search strategies (such as reinforcement learning-based architecture search or genetic algorithms) and comparing their results against the greedy approach across multiple OOD detection tasks.

## Limitations
- Limited generalizability to VAE architectures beyond the two presented cases (β-VAE and optical flow VAE)
- Methodology validated only on Jetson Nano platform, may not generalize to other embedded hardware
- Requires access to OOD samples at design time for cross-validation, which may not be available in all applications

## Confidence
- High confidence: The empirical results showing 20-38% execution time reductions while maintaining AUROC within 5% of baseline
- Medium confidence: The mechanism explanations for why compression preserves detection accuracy through relative latent space divergence
- Low confidence: The general applicability of the sparsity-heuristic for pruning-aware knowledge distillation across diverse VAE architectures

## Next Checks
1. Test the methodology on additional VAE architectures and datasets to validate generalizability beyond the two presented cases
2. Conduct ablation studies to isolate the contribution of each compression technique (quantization, pruning, knowledge distillation) to overall performance
3. Evaluate detection performance on edge devices with different hardware constraints (e.g., ARM Cortex-M, RISC-V) to assess platform independence