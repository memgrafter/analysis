---
ver: rpa2
title: ChatGPT as speechwriter for the French presidents
arxiv_id: '2411.18382'
source_url: https://arxiv.org/abs/2411.18382
tags:
- chatgpt
- words
- presidents
- texts
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study compared ChatGPT-generated French presidential speeches
  with authentic ones, revealing distinct stylistic differences. ChatGPT overused
  nouns, possessive determiners, and numbers while underusing verbs (especially complex
  tenses), pronouns, and adverbs.
---

# ChatGPT as speechwriter for the French presidents

## Quick Facts
- arXiv ID: 2411.18382
- Source URL: https://arxiv.org/abs/2411.18382
- Authors: Dominique Labbé; Cyril Labbé; Jacques Savoy
- Reference count: 0
- Key outcome: ChatGPT-generated French presidential speeches showed distinct stylistic differences including overuse of nouns, numbers, and generic themes while underusing verbs and pronouns

## Executive Summary
This study compares ChatGPT-generated French presidential speeches with authentic ones from 2002-2021, revealing significant stylistic differences that could potentially be used for authorship attribution. The research demonstrates that ChatGPT tends to overuse nouns, possessive determiners, and numbers while underusing verbs (especially complex tenses), pronouns, and adverbs. The analysis shows more uniform sentence length distributions in generated texts compared to natural presidential speeches.

The study also evaluates the effectiveness of intertextual distance analysis for detecting AI-generated content, finding that this traditional plagiarism detection method becomes ineffective when given a single ChatGPT-generated text as reference. This suggests limitations in current attribution tools when dealing with AI-generated political speech content.

## Method Summary
The researchers collected 20 authentic French presidential speeches (5 each from Chirac, Sarkozy, Hollande, and Macron) and generated corresponding ChatGPT versions using identical prompts. They performed lemmatization and POS tagging on both corpora to analyze grammatical category frequencies. The study examined sentence length distributions, vocabulary usage patterns, and calculated intertextual distances for hierarchical clustering-based author attribution. The analysis focused on identifying stylistic markers that distinguish human-written presidential speeches from AI-generated content.

## Key Results
- ChatGPT overuses nouns, possessive determiners, and numbers while underusing verbs (especially complex tenses), pronouns, and adverbs
- Generated texts show more uniform and less diverse sentence length distributions compared to authentic speeches
- Intertextual distance analysis fails to reliably distinguish ChatGPT outputs when given a single model text as reference

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT's overuse of nouns and numbers creates distinctive stylistic fingerprints that differ from human-written political speech patterns
- Evidence: POS distribution analysis showing systematic deviations in grammatical category frequencies between authentic and generated texts

### Mechanism 2
- Claim: Sentence length uniformity in ChatGPT outputs reflects the model's tendency to optimize for coherence rather than natural variation
- Evidence: Statistical comparison of sentence length distributions showing narrower variance in generated texts

### Mechanism 3
- Claim: Generic theme insertion (e.g., "wishes for the new year") reveals ChatGPT's prompt-following behavior overriding context-appropriate content
- Evidence: Frequency analysis of vocabulary showing disproportionate occurrence of generic phrases

## Foundational Learning

### POS tagging
- Why needed: Essential for analyzing grammatical patterns and stylistic differences between human and AI-generated text
- Quick check: Verify French POS tagger accuracy on test corpus with known categories

### Lemmatization
- Why needed: Reduces words to base forms for accurate frequency analysis across inflected forms
- Quick check: Ensure lemmatizer correctly handles French verb conjugations and noun genders

### Intertextual distance
- Why needed: Traditional plagiarism detection method for author attribution analysis
- Quick check: Validate distance metric on known author pairs before applying to AI detection

## Architecture Onboarding

### Component Map
Raw Speeches -> Lemmatization/POS Tagging -> Frequency Analysis -> Intertextual Distance Calculation -> Hierarchical Clustering

### Critical Path
Speech Generation -> POS Analysis -> Pattern Detection -> Attribution Testing

### Design Tradeoffs
- Simple prompt vs. context-rich generation: Single generic prompt maximizes stylistic consistency but may not reflect real speechwriting complexity
- Automated vs. manual validation: Computational analysis enables large-scale comparison but may miss nuanced stylistic elements

### Failure Signatures
- Intertextual distance failure: Single ChatGPT text cannot be distinguished from human authors using traditional methods
- POS distribution anomalies: Systematic overuse/underuse patterns indicate AI generation
- Sentence length uniformity: Narrower distribution than natural text suggests automated generation

### First Experiments
1. Test POS tagging accuracy on mixed human-AI corpus with French linguistic benchmarks
2. Compare sentence length distributions using statistical tests (Kolmogorov-Smirnov) on larger datasets
3. Evaluate alternative attribution methods (neural embeddings) on same corpus to validate intertextual distance limitations

## Open Questions the Paper Calls Out
None

## Limitations
- Small corpus size (20 authentic speeches) may not capture full range of presidential speechwriting styles
- Single prompt approach may not represent diversity of actual presidential speech contexts
- Intertextual distance methodology shows limitations for AI-generated content detection

## Confidence
- POS distribution findings: Medium confidence
- Sentence length analysis: Medium confidence
- Intertextual distance limitations: High confidence

## Next Checks
1. Test with larger corpora and multiple generation prompts to assess generalizability of stylistic differences
2. Apply alternative attribution methods (e.g., neural embedding approaches) to validate the limitations of intertextual distance for ChatGPT detection
3. Conduct human evaluation studies to assess whether linguistic patterns identified by automated analysis align with human perception of authenticity