---
ver: rpa2
title: Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models
arxiv_id: '2405.19561'
source_url: https://arxiv.org/abs/2405.19561
tags:
- language
- engineering
- such
- llms
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper highlights the limitations of large language models (LLMs)
  in scientific domains like chemical engineering, where first-principles knowledge
  and deep domain expertise are essential. While LLMs excel in natural language processing
  and creative tasks, they struggle with reasoning, planning, and explaining due to
  their lack of mechanistic understanding.
---

# Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models

## Quick Facts
- **arXiv ID**: 2405.19561
- **Source URL**: https://arxiv.org/abs/2405.19561
- **Reference count**: 40
- **Primary result**: Proposes Large Knowledge Models (LKMs) as hybrid AI systems combining symbolic knowledge with LLMs for scientific domains

## Executive Summary
The paper addresses the limitations of large language models (LLMs) in scientific domains like chemical engineering, where first-principles knowledge and deep domain expertise are essential. While LLMs excel in natural language processing and creative tasks, they struggle with reasoning, planning, and explaining due to their lack of mechanistic understanding. The authors propose Large Knowledge Models (LKMs) as a solution—hybrid AI systems that integrate symbolic knowledge (e.g., ontologies, first principles) with data-driven techniques. This approach enables accurate explanations, causal reasoning, and domain-specific applications such as drug discovery and process optimization.

## Method Summary
The paper proposes developing hybrid AI systems (LKMs) that combine symbolic knowledge representations with data-driven LLM capabilities. The method involves integrating domain-specific ontologies, causal graphs, and first-principles knowledge with language models, enabling reasoning about cause and effect in scientific domains. The approach aims to reduce data requirements by leveraging mechanistic understanding and provides focused expertise in specialized areas rather than broad but shallow knowledge.

## Key Results
- LLMs cannot reason, plan, or explain in scientific domains due to lack of mechanistic understanding
- LKMs combine symbolic knowledge with data-driven techniques for accurate explanations and causal reasoning
- Future AI success in scientific domains depends on integrating symbolic and statistical methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Symbolic AI and first-principles knowledge integration enables domain-specific reasoning that LLMs lack.
- Mechanism: LKMs combine structured knowledge representations (ontologies, causal graphs) with data-driven LLM capabilities, providing explicit relationships between cause and effect, which pure LLMs cannot derive from pattern matching alone.
- Core assumption: Chemical engineering domains require mechanistic understanding beyond probabilistic associations.
- Evidence anchors:
  - [abstract] "They cannot yet reason, plan, or explain due to their lack of in-depth domain knowledge"
  - [section 3] "reasoning about cause and effect in a process plant is central to fault diagnosis, risk analysis, alarm management, and supervisory control"
  - [corpus] Weak - no direct citations in corpus, but related papers discuss LLM limitations in domain-specific reasoning
- Break condition: When the symbolic knowledge base is incomplete or inconsistent, leading to incorrect reasoning despite the LLM's language capabilities.

### Mechanism 2
- Claim: Hybrid AI models reduce data requirements by leveraging first-principles knowledge.
- Mechanism: By incorporating conservation laws, constitutive relations, and technical knowledge, LKMs can generate synthetic data and constrain learning, reducing dependence on massive datasets that are unavailable in many chemical engineering applications.
- Core assumption: Chemical engineering applications are not "big data" domains compared to NLP or vision.
- Evidence anchors:
  - [abstract] "many chemical engineering applications are not 'big data'"
  - [section 3] "our first-principles knowledge can be leveraged and exploited to reduce the need for large amounts of data"
  - [corpus] Weak - no direct citations in corpus, but related papers discuss LLM data requirements
- Break condition: When the first-principles knowledge is insufficient to compensate for data scarcity, leading to poor model performance.

### Mechanism 3
- Claim: Domain-specific LLMs provide focused expertise rather than broad but shallow knowledge.
- Mechanism: Custom LKMs trained on domain-specific ontologies and knowledge bases achieve deeper understanding in specialized areas (e.g., pharmaceutical chemistry) compared to general LLMs that may hallucinate or provide inaccurate information.
- Core assumption: Specialized domains require depth over breadth in AI capabilities.
- Evidence anchors:
  - [abstract] "a custom LLM in pharmaceutical engineering might not compose poems like Shakespeare, but it will not hallucinate on pharmaceutical chemistry"
  - [section 5] "We classify AI applications into three categories – 'easy,' 'hard,' and 'harder' problems"
  - [corpus] Weak - no direct citations in corpus, but related papers discuss LLM specialization
- Break condition: When the domain knowledge becomes too narrow, limiting the system's ability to handle novel or cross-domain problems.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Understanding how LLMs process sequential data and context is crucial for appreciating their limitations and how LKMs augment them
  - Quick check question: How does the self-attention mechanism in transformers differ from recurrent neural networks in handling long-range dependencies?

- Concept: Symbolic AI and knowledge representation
  - Why needed here: The paper advocates for integrating symbolic AI methods with data-driven approaches, so understanding knowledge graphs, ontologies, and rule-based systems is essential
  - Quick check question: What are the key differences between symbolic AI and statistical machine learning approaches in terms of knowledge representation?

- Concept: First-principles modeling in chemical engineering
  - Why needed here: The paper emphasizes the importance of conservation laws, constitutive relations, and fundamental principles in chemical engineering applications
  - Quick check question: How do differential and algebraic equations (DAEs) represent first-principles knowledge in chemical engineering systems?

## Architecture Onboarding

- Component map:
  LLM core (for language understanding and generation) -> Knowledge graph/RDF store (for structured domain knowledge) -> Reasoning engine (for causal and logical inference) -> Retrieval module (for accessing relevant knowledge) -> Fine-tuning interface (for domain adaptation)

- Critical path:
  1. User query → LLM for initial understanding
  2. Knowledge retrieval → knowledge graph lookup
  3. Reasoning → symbolic inference engine
  4. Generation → LLM augmented with retrieved knowledge
  5. Output → coherent, domain-accurate response

- Design tradeoffs:
  - Expressiveness vs. computational efficiency (rich knowledge representation vs. fast inference)
  - Generalizability vs. domain expertise (broad vs. deep knowledge)
  - Transparency vs. performance (interpretable reasoning vs. black-box accuracy)

- Failure signatures:
  - Hallucinations when knowledge retrieval fails
  - Inconsistent reasoning when knowledge base is incomplete
  - Slow response times due to complex reasoning processes
  - Domain drift when knowledge becomes outdated

- First 3 experiments:
  1. Implement a simple LKM for explaining chemical equations using a small knowledge graph and test with various reaction kinetics problems
  2. Compare performance of general LLM vs. LKM on a pharmaceutical chemistry QA task using benchmark datasets
  3. Test knowledge retrieval accuracy by measuring precision/recall of relevant facts retrieved from the knowledge graph for different query types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can symbolic AI methodologies be effectively integrated with LLMs to create hybrid AI systems capable of reasoning and planning in chemical engineering domains?
- Basis in paper: [explicit] The paper discusses the limitations of LLMs in reasoning, planning, and explaining due to their lack of in-depth domain knowledge, and proposes the development of hybrid AI systems (LKMs) that combine symbolic knowledge with data-driven techniques.
- Why unresolved: While the concept of LKMs is proposed, the specific methods and architectures for integrating symbolic AI with LLMs are not detailed.
- What evidence would resolve it: Successful case studies or prototypes demonstrating the integration of symbolic AI methodologies (e.g., graph-theoretical models, ontologies) with LLMs in chemical engineering applications.

### Open Question 2
- Question: What are the specific challenges and opportunities in developing domain-specific LLMs for highly technical fields like pharmaceutical engineering and materials discovery?
- Basis in paper: [explicit] The paper highlights the need for domain-specific LLMs that are deep in domain knowledge but narrow in scope, and discusses applications in chemistry and pharmaceuticals.
- Why unresolved: The paper identifies the need but does not explore the detailed challenges and opportunities in developing such models.
- What evidence would resolve it: Research outlining the technical, ethical, and practical challenges in developing domain-specific LLMs, along with potential solutions and successful implementations.

### Open Question 3
- Question: How can knowledge graphs be effectively incorporated into LLM frameworks to enhance interpretability and reduce hallucinations in scientific domains?
- Basis in paper: [explicit] The paper suggests the inclusion of knowledge graphs (KGs) in LLM frameworks to circumvent hallucinations and augment domain-specific knowledge.
- Why unresolved: While the potential of KGs is mentioned, the paper does not provide detailed methodologies for their integration or evidence of their effectiveness.
- What evidence would resolve it: Empirical studies demonstrating the integration of KGs with LLMs and their impact on reducing hallucinations and improving interpretability in scientific applications.

## Limitations
- Integration mechanism between symbolic knowledge and LLM components is not clearly specified
- No empirical validation presented; claims about LKM superiority are theoretical
- Scalability challenges of maintaining comprehensive knowledge bases for specialized domains are not addressed

## Confidence
- **High confidence**: The identification of LLM limitations in scientific domains requiring mechanistic understanding
- **Medium confidence**: The proposed LKM architecture and its potential benefits
- **Low confidence**: Specific claims about LKM performance advantages over existing approaches

## Next Checks
1. **Implementation feasibility test**: Build a minimal LKM prototype integrating a knowledge graph with an LLM using a specific chemical engineering domain (e.g., reaction kinetics) and evaluate the integration complexity and computational overhead.

2. **Knowledge base quality assessment**: Measure the completeness and accuracy of domain-specific ontologies required for effective LKM operation by having domain experts evaluate knowledge graph coverage for key chemical engineering concepts.

3. **Performance comparison study**: Conduct controlled experiments comparing general LLMs, domain-specific fine-tuned LLMs, and LKMs on standardized chemical engineering reasoning tasks, measuring accuracy, hallucination rates, and explanation quality.