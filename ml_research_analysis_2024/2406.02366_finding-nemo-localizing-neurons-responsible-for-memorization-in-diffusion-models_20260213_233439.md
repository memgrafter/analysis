---
ver: rpa2
title: 'Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion
  Models'
arxiv_id: '2406.02366'
source_url: https://arxiv.org/abs/2406.02366
tags:
- neurons
- memorization
- prompts
- memorized
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NeMo, the first method to localize memorization
  in diffusion models (DMs) down to individual neurons. The approach identifies neurons
  in cross-attention layers that trigger memorization of specific training samples
  by detecting out-of-distribution activation patterns.
---

# Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models

## Quick Facts
- **arXiv ID:** 2406.02366
- **Source URL:** https://arxiv.org/abs/2406.02366
- **Reference count:** 40
- **Primary result:** Introduces NeMo, the first method to localize memorization in diffusion models down to individual neurons, successfully mitigating training data replication without additional model training

## Executive Summary
This paper introduces NeMo, a novel approach for identifying and deactivating neurons responsible for memorization in diffusion models. By detecting out-of-distribution activation patterns in cross-attention layers, NeMo localizes memorization to individual neurons, allowing for permanent mitigation of training data replication. The method demonstrates that single neurons can be responsible for memorizing specific training samples, and deactivating these neurons increases output diversity while maintaining image quality.

## Method Summary
NeMo employs a two-step process to identify memorization neurons: first, it detects neurons with out-of-distribution activation patterns when processing memorized prompts using statistical methods; second, it refines this candidate set through systematic deactivation testing. The approach focuses on value layers in cross-attention mechanisms, measuring memorization strength through SSIM-based comparisons of noise differences in initial denoising steps. By permanently deactivating identified neurons, NeMo provides a training-free solution for mitigating memorization in publicly released diffusion models.

## Key Results
- Successfully localizes memorization neurons in Stable Diffusion v1.4, with many training samples memorized by just a few or single neurons
- Deactivating memorization neurons effectively mitigates training data replication while maintaining image quality and increasing output diversity
- Demonstrates permanent memorization mitigation without requiring additional model training or runtime safeguards

## Why This Works (Mechanism)

### Mechanism 1
Single neurons in cross-attention value layers exhibit distinct activation patterns for memorized versus non-memorized prompts, enabling reliable identification through out-of-distribution detection. This localization enables targeted deactivation without disrupting general model functionality.

### Mechanism 2
Deactivating identified memorization neurons blocks the information flow from text embeddings that triggers memorization, preventing replication of training data while preserving the model's ability to generate diverse, high-quality images for non-memorized prompts.

### Mechanism 3
The structural similarity between noise differences in the first denoising step serves as an effective proxy for quantifying memorization strength, as memorized prompts show more consistent denoising trajectories across different initial seeds.

## Foundational Learning

- **Cross-attention mechanism in diffusion models**: Understanding how text embeddings are incorporated into the denoising process is crucial for identifying where memorization occurs
- **Out-of-distribution (OOD) detection**: Essential for identifying neurons with unusual activation patterns that indicate memorization
- **Structural Similarity Index Measure (SSIM)**: Used to quantify memorization strength by comparing noise differences across different seeds

## Architecture Onboarding

- **Component map**: Stable Diffusion v1.4 U-Net with cross-attention layers â†’ NeMo focuses on value layers in down- and mid-blocks
- **Critical path**: (1) Identify memorized prompts using SSIM-based memorization score, (2) Detect OOD neurons in cross-attention value layers, (3) Refine neuron set through deactivation testing, (4) Evaluate memorization mitigation and image quality
- **Design tradeoffs**: Focusing on value layers prioritizes direct text embedding processing but may miss memorization mechanisms in other parts of the model
- **Failure signatures**: (1) No neurons identified for memorized prompts, (2) Identified neurons fail to mitigate memorization when deactivated, (3) Deactivating neurons significantly degrades image quality or prompt alignment
- **First 3 experiments**:
  1. Verify SSIM-based memorization detection on known memorized and non-memorized prompts
  2. Implement OOD detection on cross-attention value layers and visualize activation patterns
  3. Test deactivation of identified neurons on memorized prompts and measure changes in memorization metrics and diversity

## Open Questions the Paper Calls Out

### Open Question 1
How do memorization neurons identified by NeMo behave during fine-tuning of diffusion models? The paper mentions the method works without additional training but doesn't investigate whether fine-tuning would reactivate memorization or change the distribution of memorization neurons.

### Open Question 2
Are there potential interactions between memorization neurons across different layers that could affect mitigation strategies? While the paper identifies memorization neurons in specific layers, it doesn't explore potential synergistic or antagonistic relationships between neurons across layers.

### Open Question 3
How does the effectiveness of NeMo change when applied to diffusion models with different architectures or training datasets? The paper focuses exclusively on Stable Diffusion v1.4 trained on LAION dataset without systematic testing across different architectures or datasets.

## Limitations

- The method's reliance on identifying distinct activation patterns may not capture all forms of memorization, particularly distributed or complex interaction-based mechanisms
- The claim that single neurons can memorize entire training samples requires further validation across diverse model architectures and datasets
- The permanent nature of neuron deactivation lacks the flexibility of runtime safeguards that could be adapted based on use case requirements

## Confidence

- **High Confidence**: Effectiveness of SSIM-based memorization detection and general framework for neuron deactivation are well-supported by experimental results
- **Medium Confidence**: Claim about single neurons being responsible for memorization is intriguing but requires further validation
- **Low Confidence**: Assertion that this is the first method to localize memorization down to individual neurons may be premature given rapidly evolving field

## Next Checks

1. Test NeMo's effectiveness on different diffusion model architectures (e.g., Stable Diffusion v2, DALL-E 2) to assess generalizability
2. Evaluate the method's performance on datasets with varying types of memorization (exact copies vs. near-duplicates vs. stylized variations)
3. Conduct ablation studies to determine the minimum number of neurons required for effective memorization and assess whether identified neurons are truly unique to specific training samples