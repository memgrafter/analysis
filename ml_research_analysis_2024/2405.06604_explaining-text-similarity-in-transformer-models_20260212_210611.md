---
ver: rpa2
title: Explaining Text Similarity in Transformer Models
arxiv_id: '2405.06604'
source_url: https://arxiv.org/abs/2405.06604
tags:
- similarity
- interactions
- explanations
- relevance
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces BiLRP, a method to explain interactions between
  tokens in Transformer-based similarity models. It computes second-order attributions
  using layer-wise relevance propagation, allowing detailed analysis of which token
  interactions drive similarity predictions.
---

# Explaining Text Similarity in Transformer Models

## Quick Facts
- arXiv ID: 2405.06604
- Source URL: https://arxiv.org/abs/2405.06604
- Reference count: 23
- Key outcome: BiLRP method computes second-order attributions to explain token interactions in Transformer similarity models, showing better identification of relevant interactions than baselines on synthetic and real semantic similarity tasks.

## Executive Summary
This paper introduces BiLRP, a method for explaining interactions between tokens in Transformer-based similarity models. BiLRP extends layer-wise relevance propagation to compute second-order attributions, allowing detailed analysis of which token interactions drive similarity predictions. The approach is evaluated on a synthetic task with ground truth interactions and real semantic similarity datasets, demonstrating that it better identifies relevant interactions than baselines like Hessian×Product or raw embeddings. Corpus-level analyses reveal how different models prioritize specific parts-of-speech and how multilingual models handle cross-lingual matching.

## Method Summary
BiLRP is an extension of layer-wise relevance propagation designed for bilinear similarity models that computes second-order explanations by analyzing feature interactions between tokens. The method adapts LRP rules for Transformer architectures, including specialized handling for attention mechanisms, residual connections, and layer normalization to preserve relevance during backward propagation. Explanations are factorized into token-token interaction scores, which can be aggregated at the corpus level to analyze patterns across POS tags. The approach is implemented for multiple Transformer variants including BERT, mBERT, SGPT, and SBERT, with code available at https://github.com/alevas/xai_similarity_transformers.

## Key Results
- BiLRP outperforms raw embeddings and Hessian×Product baselines on a synthetic noun-matching task with ground truth interactions
- Perturbation analysis shows BiLRP explanations are more faithful to model behavior than first-order methods on STSb dataset
- Corpus-level POS analysis reveals different models use distinct interaction strategies, with multilingual models showing different patterns than monolingual counterparts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Second-order relevance scores (BiLRP) better capture token interactions than raw embeddings or first-order gradients.
- Mechanism: BiLRP aggregates relevance through factorized propagation over intermediate layers, weighting feature interactions by their actual contribution to the similarity score rather than raw co-occurrence or linear approximations.
- Core assumption: Relevance is conserved during backward propagation; the similarity score can be decomposed into meaningful interaction terms.
- Evidence anchors: Abstract statement about investigating feature interactions; section on LRP propagation robustness; corpus analysis showing interaction patterns.

### Mechanism 2
- Claim: Conservation of relevance during backpropagation yields more faithful explanations.
- Mechanism: Modified LRP rules for Transformers (e.g., treating attention scores as detached weights, normalizing residuals) prevent relevance from leaking or being created, preserving the mapping from input interactions to output similarity.
- Core assumption: The Transformer's computational structure can be linearized or approximated without losing critical relevance flow.
- Evidence anchors: Section on LRP rules for Transformers with specific implementation details; discussion of relevance conservation challenges; empirical validation of conservation properties.

### Mechanism 3
- Claim: Corpus-level aggregation of POS-tag interactions reveals model-specific strategies and shortcut learning.
- Mechanism: By summing relevance across many sentence pairs and normalizing by interaction frequency, rare but high-impact POS interactions become visible, exposing whether models rely on token-matching shortcuts versus deeper semantic composition.
- Core assumption: POS tags are a sufficient proxy for grammatical roles; aggregating over a large corpus smooths out noise and highlights systematic biases.
- Evidence anchors: Corpus-level analysis methodology; comparison of POS interaction patterns across models and languages; discussion of implications for model understanding.

## Foundational Learning

- Concept: Layer-wise Relevance Propagation (LRP)
  - Why needed here: Provides the base framework for computing feature attributions that conserve relevance during backward passes.
  - Quick check question: Can you derive the LRP-0 rule for a fully connected layer and explain how relevance is redistributed?

- Concept: Bilinear similarity models and second-order interactions
  - Why needed here: Similarity between sentences is computed as a dot product of embeddings, so interactions between token pairs are central to the prediction.
  - Quick check question: How does the Hessian of the similarity score encode pairwise feature interactions?

- Concept: Transformer attention and normalization mechanisms
  - Why needed here: These layers introduce non-linearities and normalization terms that break standard relevance conservation; specialized propagation rules are required.
  - Quick check question: What happens to relevance flow if you ignore the detach() operation on attention weights?

## Architecture Onboarding

- Component map: Input sentences -> Transformer encoder -> Pooling layer -> Bilinear similarity head -> BiLRP explanation computation
- Critical path:
  1. Forward pass to get embeddings and similarity score
  2. Backward pass with LRP rules to compute per-layer relevance
  3. Factorize relevance into token-token interaction scores
  4. Aggregate interactions for corpus-level analysis
- Design tradeoffs:
  - Speed vs. fidelity: BiLRP requires one backward pass per embedding dimension; using fewer dimensions or batching speeds up but coarsens explanations
  - POS abstraction vs. granularity: Aggregating by POS tags simplifies analysis but loses word-specific nuances
  - Model generality vs. specificity: BiLRP rules work for multiple Transformer variants but may need tuning for custom architectures
- Failure signatures:
  - Relevance sums don't match the similarity score (poor conservation)
  - Explanations highlight rare or irrelevant POS pairs
  - High computational cost with diminishing explanatory gains
- First 3 experiments:
  1. Run BiLRP on a toy similarity task with known ground-truth interactions; verify that top-ranked interactions match the ground truth
  2. Compare AUPC (area under perturbation curve) between BiLRP, H×P, and raw embeddings on a small semantic similarity dataset
  3. Aggregate POS interactions on a held-out corpus and check if the most relevant POS pairs align with human intuition about similarity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic patterns or phenomena in POS tags contribute most to semantic similarity predictions across different languages?
- Basis in paper: The paper analyzes POS interactions across multilingual settings (English, German) and observes differences in relevant POS interactions between monolingual and multilingual contexts.
- Why unresolved: The paper identifies some patterns (e.g., determiner-determiner interactions in German) but does not provide a comprehensive linguistic explanation for why certain POS interactions are more relevant in specific languages.
- What evidence would resolve it: Detailed linguistic analysis of POS interactions in multiple languages, combined with model explanations, to identify language-specific patterns and their impact on semantic similarity predictions.

### Open Question 2
- Question: How do different pooling strategies affect the identification of relevant feature interactions in similarity models?
- Basis in paper: The paper compares CLS-Pooling and Mean-Pooling strategies and observes differences in the distribution of relevance across POS interactions.
- Why unresolved: The paper shows that pooling strategies impact model performance and relevance attribution but does not provide a detailed analysis of how specific pooling methods influence the identification of relevant feature interactions.
- What evidence would resolve it: Systematic evaluation of various pooling strategies on their ability to identify relevant feature interactions, using both quantitative metrics and qualitative analysis of the resulting explanations.

### Open Question 3
- Question: What are the potential risks and limitations of relying on token matching strategies for semantic similarity in high-risk domains?
- Basis in paper: The paper discusses how similarity models often rely on token matching, which can lead to inaccurate predictions, especially in biomedical text retrieval.
- Why unresolved: While the paper highlights the limitations of token matching, it does not provide a comprehensive assessment of the risks and potential consequences of these strategies in high-risk domains.
- What evidence would resolve it: Case studies and empirical evaluations of similarity models in high-risk domains (e.g., medical diagnosis, legal document analysis) to quantify the impact of token matching errors and identify potential mitigation strategies.

## Limitations

- Computational scalability: BiLRP requires computing explanations for each embedding dimension separately, leading to high computational overhead that may limit practical deployment.
- Ground truth validation: Real-world semantic similarity lacks definitive interaction-level rationales, making it difficult to validate whether BiLRP identifies the "correct" interactions.
- Generalization across tasks: While BiLRP is tested on semantic similarity tasks, its effectiveness for other tasks involving bilinear similarity remains untested.

## Confidence

**High confidence**: BiLRP computes second-order attributions and can be applied to Transformer-based similarity models. The mathematical framework is sound, and the method produces explanations with reasonable computational properties.

**Medium confidence**: BiLRP provides more faithful explanations than first-order methods like H×P or raw embeddings, as measured by perturbation analysis. While experimental results support this claim, evaluation relies on faithfulness metrics rather than ground-truth correctness.

**Medium confidence**: Corpus-level analysis reveals meaningful patterns in how different models approach semantic similarity. The POS interaction analysis demonstrates that models exhibit distinct strategies, but interpretation requires further validation.

## Next Checks

1. Create additional synthetic tasks with known ground-truth interactions beyond noun matching and systematically evaluate whether BiLRP consistently identifies these ground truth interactions better than baselines.

2. Conduct a systematic ablation study measuring explanation quality versus computational cost across different numbers of embedding dimensions, model sizes, and sequence lengths to quantify the tradeoff between fidelity and scalability.

3. Design controlled experiments where models are known to use specific shortcuts (e.g., keyword matching, lexical overlap) and verify whether BiLRP successfully identifies these shortcut strategies compared to models using genuine semantic understanding.