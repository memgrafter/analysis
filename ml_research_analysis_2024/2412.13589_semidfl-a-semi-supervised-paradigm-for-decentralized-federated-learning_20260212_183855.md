---
ver: rpa2
title: 'SemiDFL: A Semi-Supervised Paradigm for Decentralized Federated Learning'
arxiv_id: '2412.13589'
source_url: https://arxiv.org/abs/2412.13589
tags:
- data
- learning
- client
- labeled
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SemiDFL introduces the first semi-supervised decentralized federated
  learning framework that addresses the challenge of limited labeled data across diverse
  client types (labeled-only, unlabeled-only, and mixed). The method employs neighborhood
  pseudo-labeling to enhance pseudo-label quality using local and neighbor classifiers,
  and an adaptive filtering threshold based on neighborhood performance.
---

# SemiDFL: A Semi-Supervised Paradigm for Decentralized Federated Learning

## Quick Facts
- arXiv ID: 2412.13589
- Source URL: https://arxiv.org/abs/2412.13589
- Authors: Xinyang Liu; Pengchao Han; Xuan Li; Bo Liu
- Reference count: 40
- Primary result: First semi-supervised decentralized federated learning framework achieving up to 94.46% accuracy on MNIST with robust performance across varying non-IID degrees and labeled data ratios

## Executive Summary
SemiDFL introduces a novel semi-supervised decentralized federated learning framework that addresses the challenge of limited labeled data across diverse client types in DFL settings. The method employs neighborhood pseudo-labeling to enhance pseudo-label quality using local and neighbor classifiers, and an adaptive filtering threshold based on neighborhood performance. It introduces consensus-based diffusion models to generate synthesized data, forming a consensus data space that mitigates non-IID distribution issues. An adaptive aggregation mechanism dynamically weights model contributions based on classifier accuracy on generated data. Experiments across MNIST, Fashion-MNIST, and CIFAR-10 datasets demonstrate significant performance improvements over state-of-the-art baselines.

## Method Summary
SemiDFL operates in decentralized federated learning settings with three client types (labeled-only, unlabeled-only, and mixed) facing non-IID data distributions. The method combines neighborhood pseudo-labeling with consensus-based diffusion models and adaptive aggregation. Each client trains local classifier and diffusion models, generates pseudo-labels using neighborhood information, creates synthesized data through consensus diffusion models, and applies MixUp operations. Model aggregation is performed adaptively based on classifier accuracy evaluated on generated data. The framework addresses both the semi-supervised learning challenge and the decentralized communication constraints without requiring a central server.

## Key Results
- Achieves up to 94.46% accuracy on MNIST dataset
- Maintains robust performance across varying non-IID degrees (α from 100 to 0.01)
- Demonstrates effectiveness across different labeled data ratios (r from 0.1% to 5%)
- Outperforms state-of-the-art baselines in semi-supervised decentralized settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neighborhood pseudo-labeling improves pseudo-label quality by combining client and neighbor classifier predictions.
- Mechanism: Client aggregates predictions from its own classifier and randomly selected neighbor classifiers for each data variant, then applies adaptive filtering based on neighborhood performance.
- Core assumption: Neighbor classifiers provide complementary information that reduces local model bias in non-IID settings.
- Evidence anchors: [abstract] "we utilize neighborhood information to improve the quality of pseudo-labeling"; [section] "we introduce neighborhood classifiers to predict the label of a sample un_i's variant in client i"
- Break condition: If neighborhood classifiers are too divergent or noisy, the aggregation could degrade rather than improve pseudo-label quality.

### Mechanism 2
- Claim: Consensus-based diffusion models generate synthesized data following a similar distribution across clients.
- Mechanism: Each client trains a diffusion model that is globally updated through consensus aggregation, ensuring all generated datasets follow similar distributions for MixUp.
- Core assumption: Consensus aggregation of diffusion models leads to convergence toward a shared data distribution.
- Evidence anchors: [abstract] "We then design a consensus-based diffusion model to generate synthesized data"; [section] "all diffusion models ψi,i∈N are aggregated based on a consensus mechanism, leading to a unified diffusion model"
- Break condition: If consensus aggregation fails to converge or if client data distributions are too heterogeneous, synthesized data may not be sufficiently similar across clients.

### Mechanism 3
- Claim: Adaptive aggregation weights based on model accuracy on generated data improve consensus model quality.
- Mechanism: Each client evaluates its classifier on a small validation set sampled from its generated data, using these accuracies to compute adaptive weights for model aggregation.
- Core assumption: Classifier accuracy on generated data is a reliable proxy for model quality without requiring access to labeled test data.
- Evidence anchors: [abstract] "adaptive aggregation method that leverages the model accuracy of synthesized data"; [section] "we design an adaptive aggregation method based on each classifier's accuracy on synthesized data"
- Break condition: If generated data is not representative of true data distribution, accuracy evaluations may lead to incorrect weight assignments.

## Foundational Learning

- Concept: Decentralized Federated Learning (DFL)
  - Why needed here: The paper operates in DFL setting where clients communicate directly without central server
  - Quick check question: How does DFL differ from traditional FL in terms of model aggregation and failure points?

- Concept: Semi-Supervised Learning (SSL)
  - Why needed here: The method addresses scenarios where clients have varying amounts of labeled data
  - Quick check question: What are the three client types considered in this semi-supervised DFL scenario?

- Concept: Pseudo-labeling
  - Why needed here: Unlabeled data is leveraged through pseudo-label estimation to enhance model training
  - Quick check question: How does the neighborhood pseudo-labeling method differ from vanilla pseudo-labeling?

## Architecture Onboarding

- Component map: Client nodes with local data (labeled, unlabeled, or both) -> Communication topology defining neighbor relationships -> Local classifier models (ϕi) -> Local diffusion models (ψi) -> Consensus aggregation mechanisms -> Neighborhood pseudo-labeling module -> Consensus MixUp module

- Critical path:
  1. Local training of classifier and diffusion models
  2. Neighborhood pseudo-labeling to generate pseudo-labels
  3. Consensus-based diffusion model training
  4. Data generation and MixUp operations
  5. Adaptive aggregation based on generated data evaluation
  6. Consensus model space formation through weighted aggregation

- Design tradeoffs:
  - Local computation vs communication overhead in consensus aggregation
  - Quality of pseudo-labels vs computational cost of neighborhood information
  - Representative generated data vs privacy preservation

- Failure signatures:
  - High variance in client accuracies indicating poor consensus
  - Degradation in pseudo-label quality over rounds
  - Non-convergence of diffusion models across clients

- First 3 experiments:
  1. Run SemiDFL on MNIST with topology 1 (one L-client, six U-clients, three M-clients) and α=100, r=0.5%
  2. Evaluate robustness by varying non-IID degree α from 100 to 0.01 on Fashion-MNIST
  3. Test labeled data ratio sensitivity by varying r from 0.1% to 5% on CIFAR-10 with α=100

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SemiDFL's performance scale when the number of clients increases beyond the tested topologies?
- Basis in paper: [inferred] The paper evaluates three specific topologies but does not explore scalability with larger client numbers or different network structures.
- Why unresolved: The experimental section only tests three predefined communication topologies without exploring scalability or performance under varying network sizes.
- What evidence would resolve it: Experimental results comparing SemiDFL performance across topologies with varying numbers of clients and different network connectivity patterns.

### Open Question 2
- Question: What is the impact of using different diffusion model architectures on SemiDFL's performance and computational efficiency?
- Basis in paper: [explicit] The paper mentions using UNet architecture for diffusion models but doesn't explore alternatives or their impact on performance.
- Why unresolved: The implementation details only describe using UNet architecture without comparing against other potential diffusion model architectures.
- What evidence would resolve it: Comparative experiments using different diffusion model architectures (e.g., DDPM, DDIM) showing performance and efficiency trade-offs.

### Open Question 3
- Question: How does SemiDFL handle label noise in the pseudo-labeling process, and what is the impact of different noise levels on final performance?
- Basis in paper: [inferred] The paper describes neighborhood pseudo-labeling and filtering mechanisms but doesn't explicitly address label noise robustness or quantify its impact.
- Why unresolved: While the paper discusses pseudo-label filtering, it doesn't systematically evaluate how different levels of label noise affect the overall performance.
- What evidence would resolve it: Experiments introducing controlled amounts of label noise in the pseudo-labeling process and measuring the corresponding impact on final model accuracy.

## Limitations
- Unknown exact decentralized topology structure beyond the example in Fig 1a
- Specific diffusion model architecture details not fully specified
- Neighborhood selection mechanism for pseudo-labeling unclear
- No systematic evaluation of hyperparameter sensitivity

## Confidence

**Medium**: The three mechanism clusters (neighborhood pseudo-labeling, consensus diffusion models, adaptive aggregation) are theoretically sound and supported by experimental results showing performance improvements. However, the lack of ablation studies isolating each mechanism's contribution reduces confidence in attributing specific performance gains. The experimental results demonstrate robustness across datasets, but the sample sizes and hyperparameter sensitivity are not fully explored.

## Next Checks

1. Implement the three client types (L, U, M) with varying non-IID degrees to verify the method's robustness claims
2. Conduct ablation studies to isolate the contribution of neighborhood pseudo-labeling versus consensus diffusion models
3. Test the consensus aggregation mechanism with extreme non-IID settings (α approaching 0) to identify failure thresholds