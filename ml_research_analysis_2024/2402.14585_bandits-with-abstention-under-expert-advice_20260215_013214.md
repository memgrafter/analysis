---
ver: rpa2
title: Bandits with Abstention under Expert Advice
arxiv_id: '2402.14585'
source_url: https://arxiv.org/abs/2402.14585
tags:
- have
- each
- graph
- which
- abstention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses online prediction with expert advice under
  bandit feedback where abstention is allowed, treating abstention as a special action
  with zero reward. The CBA algorithm is proposed, which improves upon EXP4 by exploiting
  the abstention option to achieve better reward bounds.
---

# Bandits with Abstention under Expert Advice

## Quick Facts
- arXiv ID: 2402.14585
- Source URL: https://arxiv.org/abs/2402.14585
- Reference count: 22
- One-line primary result: CBA algorithm improves EXP4 by exploiting abstention, achieving novel reward bounds for confidence-rated predictors with O(KE) per-trial complexity

## Executive Summary
This paper introduces the CBA algorithm for online prediction with expert advice under bandit feedback where abstention is allowed. The key insight is treating abstention as a special action with zero reward, allowing the algorithm to avoid penalties from uncertain predictions. CBA significantly improves upon EXP4 by exploiting this abstention option, achieving novel reward bounds for general confidence-rated predictors and dramatically improving performance for specialist experts. The algorithm maintains O(KE) per-trial time complexity and includes an efficient implementation for learning unions of balls in metric spaces, reducing runtime from quadratic to nearly linear in the number of contexts.

## Method Summary
CBA is a bandit algorithm that maintains weight vectors for experts and projects them into valid policy sets at each trial. It uses unbiased reward estimators and a modified mirror descent update rule, treating abstention as an algorithmic choice rather than just another action. The algorithm achieves O(KE) per-trial time complexity through an efficient implementation based on balanced binary trees for metric ball queries. For metric spaces, CBA can learn unions of balls in nearly linear time by maintaining implicit functions and computing QUERY and UPDATE operations in O(ln(N)) time per context-action pair.

## Key Results
- CBA achieves novel reward bounds for general confidence-rated predictors, outperforming EXP4 in scenarios with specialist experts
- The algorithm has O(KE) per-trial time complexity and can be efficiently implemented for metric spaces
- Preliminary experiments on synthetic and real-world graphs demonstrate CBA's superiority over existing bandit algorithms when using appropriate basis functions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: CBA exploits the abstention action to achieve reward bounds that can be dramatically higher than EXP4 by aggregating confidence-rated predictors.
- **Mechanism**: The algorithm maintains weight vectors for experts and projects them into a valid policy set at each trial, using unbiased reward estimators and a modified mirror descent update rule.
- **Core assumption**: One action always has zero reward (abstention), allowing the algorithm to avoid penalties from uncertain predictions.
- **Evidence anchors**:
  - [abstract]: "We propose the CBA algorithm, which exploits this assumption to obtain reward bounds that can significantly improve those of the classical EXP4 algorithm."
  - [section]: "Our modification of mirror descent is based on the following mathematical objects... CBA maintains, on each trial t ∈ [T], a weight vector wt ∈ RE+."
- **Break condition**: If the abstention action does not have zero reward on every trial, the algorithm's reward bounds would match EXP4 and lose its advantage.

### Mechanism 2
- **Claim**: CBA achieves novel reward bounds for general confidence-rated predictors and significantly improves bounds for specialists.
- **Mechanism**: The algorithm treats abstention as an algorithmic choice rather than just another action, allowing it to accumulate confidence from multiple specialists without partitioning the context space.
- **Core assumption**: Experts can be viewed as confidence-rated predictors where low confidence means either all actions are bad or the expert is uncertain.
- **Evidence anchors**:
  - [abstract]: "Importantly, we are the first to achieve bounds on the expected cumulative reward for general confidence-rated predictors."
  - [section]: "Our problem can also be seen as that of aggregating confidence-rated predictors... When the problem is phrased in this way, at the start of each trial, each predictor recommends a probability distribution over the actions... but with a confidence rating."
- **Break condition**: If experts must be awake on exactly one specialist per trial (as in SPECIALIST EXP), CBA loses its advantage as it would need to partition the context space.

### Mechanism 3
- **Claim**: CBA has O(KE) per-trial time complexity and can be efficiently implemented for learning unions of balls in metric spaces.
- **Mechanism**: The algorithm uses data structures based on balanced binary trees to maintain implicit functions and compute QUERY and UPDATE operations in O(ln(N)) time per context-action pair.
- **Core assumption**: The distance function d satisfies d(q,x) ≠ d(q,z) for x ≠ z, allowing consistent tie-breaking and ball duplication.
- **Evidence anchors**:
  - [section]: "We now show how to implement these subroutines implicitly in a time of O(ln(N)) as required... Our data structure is based on a balanced binary tree D whose leaves are the elements of X in order of increasing distance from x."
  - [corpus]: Weak evidence - corpus neighbors discuss related bandit problems but don't directly address the efficient implementation mechanism.
- **Break condition**: If the distance function has many ties or the space is not finite, the binary tree structure may not be applicable and the O(ln(N)) complexity guarantee may not hold.

## Foundational Learning

- **Concept**: Mirror descent algorithm
  - Why needed here: CBA is derived as a modification of mirror descent, maintaining weight vectors and projecting them into valid policy sets
  - Quick check question: How does mirror descent differ from standard gradient descent in terms of the update rule and projection step?

- **Concept**: Confidence-rated predictors
  - Why needed here: Experts in CBA can be interpreted as confidence-rated predictors where the confidence rating determines the weight given to their recommendations
  - Quick check question: What is the difference between treating abstention as an algorithmic choice versus treating it as just another action in terms of reward bounds?

- **Concept**: Metric spaces and balls
  - Why needed here: The efficient implementation for learning unions of balls relies on the properties of metric spaces and the ability to define balls as sets of points within a certain distance from a center
  - Quick check question: Why does the efficient implementation require that for all q, x, z ∈ X with x ≠ z we have d(q, x) ≠ d(q, z)?

## Architecture Onboarding

- **Component map**: Input context and expert recommendations -> Compute confidence ratings -> Project weight vectors -> Select stochastic actions -> Receive rewards -> Update weights -> Efficient ball queries via binary tree

- **Critical path**: 
  1. Receive expert recommendations
  2. Compute ct confidence vector
  3. Project wt to ˜wt using interval bisection
  4. Compute st and select at
  5. Receive rt,at and compute ˆrt
  6. Update wt+1 using Equation (2)

- **Design tradeoffs**:
  - Time vs. space: O(KE) complexity is achieved by maintaining implicit functions rather than explicit representations
  - Accuracy vs. efficiency: The binary tree implementation trades some accuracy for O(ln(N)) query time
  - Generality vs. specialization: CBA works for general confidence-rated predictors but achieves best results with specialist experts

- **Failure signatures**:
  - Poor performance when experts are not well-calibrated (confidence ratings don't match actual accuracy)
  - Slow convergence when there are many experts with similar performance
  - Memory issues when N (number of contexts) is very large despite efficient implementation

- **First 3 experiments**:
  1. Compare CBA against EXP4 on a synthetic problem with known specialist structure to verify the theoretical advantage
  2. Test CBA with different basis functions (p-seminorm balls, communities, intervals) on Cora dataset to understand inductive bias effects
  3. Vary the abstention action reward (not zero) to test the break condition of Mechanism 1

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of basis functions affect the performance of CBA in practical applications beyond the specific cases tested?
- Basis in paper: [inferred] ...
- Why unresolved: The paper provides preliminary experiments on synthetic and real-world graphs using specific basis functions, but does not explore a wide range of basis functions or other types of data structures.
- What evidence would resolve it: Conducting experiments with a broader variety of basis functions on different types of data, such as time series or text data, would provide insights into the generalizability of CBA's performance.

### Open Question 2
- Question: What is the theoretical limit on the improvement CBA can achieve over EXP4 in the worst-case scenario?
- Basis in paper: [explicit] ...
- Why unresolved: The paper claims that CBA can dramatically outperform EXP4 in certain scenarios, but it does not provide a precise theoretical bound on the worst-case improvement.
- What evidence would resolve it: Deriving a formal worst-case analysis comparing CBA's performance to EXP4's, potentially involving the relationship between the number of experts and the structure of the problem, would clarify the limits of CBA's advantage.

### Open Question 3
- Question: How does CBA handle non-stationary environments where the underlying reward structure changes over time?
- Basis in paper: [inferred] ...
- Why unresolved: The paper does not discuss the behavior of CBA in non-stationary environments, which are common in real-world applications.
- What evidence would resolve it: Analyzing CBA's performance in scenarios where the reward structure changes, such as through simulations or theoretical analysis, would provide insights into its robustness and adaptability.

### Open Question 4
- Question: Can CBA be extended to handle partial information settings where the learner does not observe the full reward vector but only a noisy version?
- Basis in paper: [explicit] ...
- Why unresolved: The paper focuses on the bandit feedback setting where the learner observes the reward of the chosen action, but does not address partial information scenarios.
- What evidence would resolve it: Developing and analyzing an extension of CBA for partial information settings, such as through theoretical analysis or experiments, would demonstrate its applicability to a wider range of problems.

## Limitations

- Theoretical analysis assumes abstention action has zero reward on every trial, which may not hold in practical scenarios
- Efficiency gains depend on having finite metric spaces with no distance ties, limiting generalization to all domains
- Empirical validation is limited to specific graph datasets and synthetic problems with relatively small-scale experiments

## Confidence

- Mechanism 1 (CBA exploiting abstention): Medium - Strong theoretical derivation but limited empirical validation across diverse domains
- Mechanism 2 (Reward bounds for confidence-rated predictors): High - Novel theoretical contribution with rigorous proof structure
- Mechanism 3 (O(KE) complexity and efficient implementation): Medium - Clear algorithmic description but dependency on specific metric space properties

## Next Checks

1. Test CBA performance when abstention action reward deviates from zero to verify the break condition identified in Mechanism 1
2. Evaluate CBA on non-graph datasets with different metric structures to assess the generality of the efficient implementation
3. Compare CBA against modern contextual bandit algorithms like LinUCB and Thompson Sampling in domains where expert advice is available