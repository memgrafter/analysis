---
ver: rpa2
title: Song Emotion Classification of Lyrics with Out-of-Domain Data under Label Scarcity
arxiv_id: '2410.05778'
source_url: https://arxiv.org/abs/2410.05778
tags:
- emotions
- lyrics
- classification
- song
- emotion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of emotion classification in song
  lyrics under label scarcity by leveraging large out-of-domain data. The authors
  propose using Reddit comments as an alternative training source when high-quality
  in-domain datasets are limited.
---

# Song Emotion Classification of Lyrics with Out-of-Domain Data under Label Scarcity

## Quick Facts
- arXiv ID: 2410.05778
- Source URL: https://arxiv.org/abs/2410.05778
- Reference count: 5
- 88% accuracy on Billboard songs using Reddit-trained model

## Executive Summary
This work addresses the challenge of emotion classification in song lyrics when labeled in-domain data is scarce. The authors propose leveraging large out-of-domain datasets, specifically Reddit comments, as an alternative training source. They implement a CNN-based sequential neural network model that achieves 88% accuracy on 100 Billboard songs, demonstrating that publicly available conversational text data can effectively supplement limited song emotion datasets.

## Method Summary
The approach uses a CNN-based sequential neural network with word embeddings, two 1D convolutional layers (100 filters, kernel size 4), max-pooling, dense layers (64 and 32 units with softplus activation), and a sigmoid output layer for 8 emotions. The model is trained on 58,000 Reddit comments from the GoEmotions dataset, then applied to classify emotions in 100 Billboard songs. Training uses binary cross-entropy loss with ADAM optimizer.

## Key Results
- CNN model trained on 58,000 Reddit comments achieves 88% accuracy on 100 Billboard songs
- Model successfully classifies 8 emotions: anger, confusion, desire, fear, grief, excitement, love, sadness
- Out-of-domain data can effectively supplement scarce in-domain data for emotion classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large out-of-domain Reddit comment data can transfer emotional patterns to song lyrics classification due to shared emotional expression modes in conversational and lyrical text.
- Mechanism: The model leverages distributional similarity between conversational emotional expressions in Reddit comments and emotional content in song lyrics.
- Core assumption: Emotional expression patterns are sufficiently similar between Reddit comments and song lyrics.
- Evidence anchors: Reddit comments present one-person perspective similar to lyrics; humans interpret lyrics based on conversational language familiarity.
- Break condition: If emotional expression patterns diverge significantly between domains.

### Mechanism 2
- Claim: Convolutional neural networks can effectively extract emotional features from sequential text data regardless of domain when trained on large datasets.
- Mechanism: CNN architecture with embedding layers and convolutional filters identifies local patterns and emotional markers in text sequences.
- Core assumption: CNN architectures are flexible enough to learn transferable emotional features.
- Evidence anchors: Model grasps local patterns and potential emotional markers present in word combinations.
- Break condition: If emotional features require longer-range dependencies than CNN filters can capture.

### Mechanism 3
- Claim: Large dataset size compensates for domain mismatch in emotion classification tasks.
- Mechanism: 58,000 Reddit comments provide robust emotional representations that generalize despite domain shift.
- Core assumption: Dataset size can overcome domain differences when target domain has limited labeled data.
- Evidence anchors: Model achieves 88% accuracy after training on large Reddit dataset.
- Break condition: If domain difference is too large relative to dataset size.

## Foundational Learning

- Concept: Transfer learning across domains
  - Why needed here: Model must learn from Reddit comments and apply to song lyrics
  - Quick check question: What are key differences between conversational text and song lyrics that might affect feature transferability?

- Concept: Convolutional neural networks for text classification
  - Why needed here: CNN extracts emotional features from text sequences
  - Quick check question: How do 1D convolutional layers with different kernel sizes capture different aspects of text patterns?

- Concept: Multi-label classification with sigmoid activation
  - Why needed here: Model classifies songs into multiple emotions simultaneously
  - Quick check question: Why is sigmoid activation more appropriate than softmax for multi-label emotion classification?

## Architecture Onboarding

- Component map: Input text → Flattening layer → Word embedding layer (learned) → Dropout (20%) → 2x 1D Conv layers (100 filters, kernel size 4) → Max pooling → Global max pooling → Dense layer (64 units, softplus) → Dropout (20%) → Dense layer (32 units, softplus) → Output layer (8 units, sigmoid)

- Critical path: Input text → Embedding → Convolutional feature extraction → Pooling → Dense classification → Output emotions

- Design tradeoffs:
  - Pros: Simple architecture works well with limited in-domain data, learned embeddings adapt to task, CNN captures local patterns effectively
  - Cons: No recurrent layers for long-range dependencies, limited to word-level patterns, may miss complex lyrical structures

- Failure signatures:
  - Low accuracy on certain emotions (especially "surprise" and "disgust")
  - Poor performance on metaphorical or figurative language common in lyrics
  - Overfitting to Reddit-style emotional expressions

- First 3 experiments:
  1. Test model on Reddit validation set to establish baseline performance
  2. Evaluate performance on individual emotions to identify poorly transferring categories
  3. Compare performance with baseline model trained only on available in-domain data

## Open Questions the Paper Calls Out

1. How does performance of Reddit-trained model compare to models trained on in-domain song lyrics datasets?
2. What is optimal balance between in-domain and out-of-domain data for song emotion classification?
3. How well does Reddit-trained model generalize to song genres and languages beyond Billboard Popular Chart?

## Limitations
- Limited evaluation on only 100 songs from Billboard chart
- No comparison with in-domain trained models
- Model tested only on English-language popular music

## Confidence

**High Confidence**
- Using large out-of-domain datasets mitigates label scarcity in emotion classification
- CNN architectures extract local patterns from sequential text data effectively
- Proposed methodology of using Reddit comments is feasible and implementable

**Medium Confidence**
- Reddit comments transfer emotional patterns effectively to song lyrics classification
- 88% accuracy represents robust performance on emotion classification task
- CNN architecture is optimal for cross-domain emotion classification

**Low Confidence**
- Dataset size alone compensates for domain mismatch in emotion classification
- Model handles metaphorical and poetic language as effectively as literal Reddit expressions
- Selected 8 emotions are most appropriate for song lyrics classification

## Next Checks
1. Conduct systematic comparison of emotional expression patterns between Reddit comments and song lyrics using vocabulary overlap and n-gram distributions
2. Test model on multiple song datasets of varying sizes (100, 500, 1000 songs) to determine if 88% accuracy is robust
3. Compare CNN-based approach against Transformer-based models and linear classifiers on same task