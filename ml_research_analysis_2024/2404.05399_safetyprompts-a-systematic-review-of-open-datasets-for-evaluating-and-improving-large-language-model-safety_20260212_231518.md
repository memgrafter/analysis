---
ver: rpa2
title: 'SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving
  Large Language Model Safety'
arxiv_id: '2404.05399'
source_url: https://arxiv.org/abs/2404.05399
tags:
- datasets
- safety
- language
- association
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper systematically reviews 144 open datasets for evaluating\
  \ and improving large language model (LLM) safety published between June 2018 and\
  \ December 2024. The authors find that while safety dataset creation has rapidly\
  \ accelerated since 2023, with growing diversity in purposes and formats, significant\
  \ gaps remain\u2014especially for non-English languages and naturalistic evaluation\
  \ data."
---

# SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety

## Quick Facts
- arXiv ID: 2404.05399
- Source URL: https://arxiv.org/abs/2404.05399
- Authors: Paul Röttger; Fabio Pernisi; Bertie Vidgen; Dirk Hovy
- Reference count: 40
- Key outcome: Systematic review of 144 open datasets for LLM safety evaluation, identifying significant gaps especially for non-English languages and naturalistic evaluation data, with a living catalogue at SafetyPrompts.com

## Executive Summary
This paper presents a systematic review of 144 open datasets for evaluating and improving large language model safety published between June 2018 and December 2024. The authors find that while safety dataset creation has rapidly accelerated since 2023 with growing diversity in purposes and formats, significant gaps remain—especially for non-English languages and naturalistic evaluation data. They observe that current evaluation practices in model releases and benchmarks are highly idiosyncratic and underutilize available datasets. Their contributions include a structured codebook, a comprehensive living catalogue (SafetyPrompts.com), and recommendations for standardization and leveraging newer dataset types to improve LLM safety evaluation.

## Method Summary
The authors conducted an iterative and community-driven dataset identification process, identifying 144 open datasets through keyword searches and community feedback via social media and Reddit. They recorded 23 pieces of structured information for each dataset using a comprehensive codebook, then analyzed dataset characteristics, purposes, and usage patterns in practice. The review focused on datasets published between June 2018 and December 2024, with findings documented in a living catalogue at SafetyPrompts.com.

## Key Results
- Dataset creation for LLM safety has rapidly accelerated since 2023, with significant diversification in purposes and formats
- Major gaps remain in non-English safety datasets and naturalistic evaluation data
- Current evaluation practices in model releases and benchmarks are highly idiosyncratic, leveraging only a small fraction of available datasets
- The SafetyPrompts.com catalogue provides comprehensive coverage with structured categorization by purpose, format, and licensing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Community-driven iterative search captures emerging datasets that keyword search misses
- Mechanism: By releasing an early version of the catalogue and soliciting feedback from the LLM safety community via social media and Reddit, the authors gather datasets that might not use standard safety terminology but are highly relevant
- Core assumption: The LLM safety community is active, collaborative, and responsive to public calls for dataset contributions
- Evidence anchors: [abstract] "Over the next months, we marketed the website to the LLM safety community on Twitter and Reddit, to solicit feedback and further dataset suggestions." [section 2.2] "Over the next months, we marketed the website to the LLM safety community on Twitter and Reddit, to solicit feedback and further dataset suggestions."

### Mechanism 2
- Claim: Distinguishing dataset purposes (broad safety, narrow safety, bias, value alignment, other) enables targeted selection for specific safety evaluations
- Mechanism: The codebook explicitly categorizes each dataset by its primary purpose, allowing researchers to quickly identify which datasets align with their evaluation goals
- Core assumption: Safety is multi-faceted and different evaluation needs require different dataset types
- Evidence anchors: [abstract] "This makes it difficult for researchers and practitioners to find the most relevant datasets for their use case, and to identify gaps in dataset coverage that future work may fill." [section 3.2] "In our review, we differentiate between five distinct dataset purposes: Broad safety, Narrow safety, Value alignment, Bias, and Other."

### Mechanism 3
- Claim: Examining real-world usage of datasets in model releases and benchmarks highlights gaps and standardization opportunities
- Mechanism: By analyzing which datasets are actually used in practice, the authors identify underutilized resources and opportunities for more standardized safety evaluation
- Core assumption: Practical usage data reflects the needs and priorities of the LLM safety community
- Evidence anchors: [abstract] "We also examine how LLM safety datasets are used in practice – in LLM release publications ( §4) and popular LLM benchmarks (§5) – finding that current evaluation practices are highly idiosyncratic and leverage only a small fraction of available datasets." [section 4.2] "Around half of state-of-the-art LLMs are evaluated for safety ahead of their release, with substantial variation in the extent and nature of safety evaluations."

## Foundational Learning

- Concept: Systematic review methodology
  - Why needed here: Ensures comprehensive and unbiased dataset identification, unlike ad-hoc keyword searches
  - Quick check question: What are the key steps in a systematic review process, and how do they apply to dataset identification?

- Concept: Safety in the context of LLMs
  - Why needed here: Provides a framework for understanding the diverse aspects of LLM safety and the corresponding datasets
  - Quick check question: What are the main categories of LLM safety risks, and how do they relate to dataset purposes?

- Concept: Dataset licensing and access
  - Why needed here: Determines the usability and distribution rights of the datasets for research and commercial purposes
  - Quick check question: What are the common open-source licenses for datasets, and what are their implications for usage?

## Architecture Onboarding

- Component map: The SafetyPrompts.com website serves as the central catalogue, with the codebook spreadsheet as the underlying data structure. The website is updated continuously based on community feedback and new dataset releases

- Critical path: Dataset identification (community-driven search) → Data collection (codebook entries) → Website publication (SafetyPrompts.com) → Community feedback and updates

- Design tradeoffs: Comprehensive coverage vs. manageable review scope. Detailed categorization vs. simplicity. Community-driven vs. expert-curated

- Failure signatures: Outdated datasets, missing relevant datasets, inconsistent categorization, broken links to datasets

- First 3 experiments:
  1. Verify dataset access by downloading a sample of datasets from different sources (GitHub, Hugging Face) and checking licenses
  2. Test the website's search and filtering functionality with various queries related to dataset purposes and formats
  3. Assess the clarity and usefulness of the dataset categorization by asking a sample of LLM safety researchers to find relevant datasets for specific evaluation needs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective methods for creating naturalistic safety evaluation datasets that accurately reflect real-world LLM usage patterns?
- Basis in paper: [inferred] from the paper's discussion of the lack of naturalistic safety evaluations and the dominance of template-based and synthetic approaches
- Why unresolved: The paper identifies this as a major gap but doesn't propose specific solutions or evaluate different methods for creating more naturalistic data
- What evidence would resolve it: Comparative studies showing different methods for collecting real-world interaction data and their effectiveness in capturing realistic safety risks

### Open Question 2
- Question: How can we standardize safety evaluation practices across the industry to enable meaningful model comparisons and incentivize safer LLM development?
- Basis in paper: [explicit] from the paper's discussion of idiosyncratic evaluation practices and the small fraction of available datasets being used
- Why unresolved: While the paper suggests three directions (better leveraging recent datasets, unified quality standards, and standardized protocols), it doesn't provide concrete frameworks or demonstrate their effectiveness
- What evidence would resolve it: Adoption rates and effectiveness metrics of standardized evaluation frameworks across multiple organizations

### Open Question 3
- Question: What are the most effective strategies for creating multilingual safety evaluation datasets that account for cultural differences in safety interpretations?
- Basis in paper: [explicit] from the paper's identification of the clear lack of non-English safety datasets as a major challenge
- Why unresolved: The paper mentions this gap and suggests involving local stakeholders, but doesn't provide evidence on which approaches work best for different language contexts
- What evidence would resolve it: Comparative studies of different multilingual dataset creation approaches and their effectiveness in capturing culturally-relevant safety concerns

## Limitations
- Reliance on community-driven search may miss datasets that don't use standard safety terminology
- Difficulty in categorizing datasets that serve multiple purposes or have complex entry formats
- Focus on dataset characteristics and usage rather than actual safety evaluation effectiveness outcomes

## Confidence
- High: Claims about dataset volume growth and diversification since 2023
- Medium: Observations about usage patterns in model releases and benchmarks
- Low: Conclusions about actual safety evaluation effectiveness

## Next Checks
1. Verify dataset accessibility and license compliance for a random sample of 20 datasets from different sources
2. Test the SafetyPrompts.com search functionality with specific safety evaluation scenarios to assess practical utility
3. Conduct a validation study with LLM safety researchers to evaluate the usefulness and clarity of the dataset categorization system for identifying appropriate datasets for specific evaluation needs