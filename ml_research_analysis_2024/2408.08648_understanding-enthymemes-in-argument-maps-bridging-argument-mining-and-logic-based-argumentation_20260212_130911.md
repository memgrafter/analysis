---
ver: rpa2
title: 'Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based
  Argumentation'
arxiv_id: '2408.08648'
source_url: https://arxiv.org/abs/2408.08648
tags:
- argument
- default
- claim
- arguments
- explicit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel framework to bridge argument mining
  and logic-based argumentation by representing argument maps using default logic.
  The key idea is to use classical logic for explicit information (premises and claims)
  and default logic for implicit information (common-sense knowledge).
---

# Understanding Enthymemes in Argument Maps: Bridging Argument Mining and Logic-based Argumentation

## Quick Facts
- arXiv ID: 2408.08648
- Source URL: https://arxiv.org/abs/2408.08648
- Reference count: 22
- Primary result: Novel framework using default logic to bridge argument mining and logic-based argumentation by representing argument maps with explicit premises/claims in classical logic and implicit knowledge in default rules.

## Executive Summary
This paper addresses the challenge of connecting natural language argument maps (from argument mining) with logic-based argumentation frameworks. The authors propose a novel approach that uses classical logic to represent explicit argument components while employing default logic to encode implicit enthymemes - common-sense knowledge typically left unstated in arguments. Each argument map node is transformed into a default argument containing both explicit premises/claims and implicit default rules, enabling automated reasoning about argument validity, consistency, and relationships. The framework systematically supports various support and attack relations between arguments, providing a bridge between natural language representations and formal logical analysis.

## Method Summary
The framework translates argument maps into default logic representations by assigning explicit premises and claims to classical formulas, while encoding implicit knowledge as default rules. Each argument map node becomes a default argument tuple ⟨W_p, D_p, W_c, D_c⟩ where W sets contain classical logic formulas and D sets contain default rules. Support and attack relations between arguments are determined through interactions of their default extensions. The approach assumes a logical translation function mapping text to formulas, and provides formal definitions for different types of support and attack relations, enabling systematic analysis of instantiated argument maps.

## Key Results
- Framework successfully bridges argument mining outputs with logic-based argumentation using default logic
- Supports multiple types of support and attack relations between arguments
- Enables automated reasoning about argument validity, consistency, and logical relationships
- Provides formal definitions for different interaction types between arguments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Classical logic captures explicit argument structure while default logic handles implicit enthymemes.
- Mechanism: The paper assigns explicit premises/claims to classical formulas, then uses default rules to encode implicit knowledge needed to derive conclusions.
- Core assumption: Each argument map node can be faithfully represented as a tuple ⟨W_p, D_p, W_c, D_c⟩ where W sets are classical and D sets are default rules.
- Evidence anchors:
  - [abstract] "use classical logic for representing the explicit information in the text, and using default logic for representing the implicit information"
  - [section 4] Formal definition of default arguments with explicit premises/claims and implicit default rules
- Break condition: If implicit premises cannot be encoded as default rules without generating inconsistent extensions.

### Mechanism 2
- Claim: Support/attack relations between arguments can be expressed through interactions of default extensions.
- Mechanism: An argument A supports B if C*(A) ∩ S*(B) ≠ ∅; attacks occur when C(A) ∪ S(B) ∪ J_p(B) ⊢ ⊥.
- Core assumption: The default extension of premises (S(A)) and claims (C(A)) capture the logical strength of arguments.
- Evidence anchors:
  - [section 5] Definitions of support types including "inferentially supports" and "support attacks"
  - [section 6] Example showing how n2's claim ¬s1 attacks n0's conclusion s1
- Break condition: If default extensions become inconsistent or too large to compute.

### Mechanism 3
- Claim: Translation functions bridge natural language and logical formulas, enabling automated reasoning.
- Mechanism: Each text string is mapped to a formula via T: T ∪ {Null} → ℘(L), with Null → ∅.
- Core assumption: The translation preserves enough semantic content to maintain argument validity under logical instantiation.
- Evidence anchors:
  - [section 2.2] Definition of logical translation function and atomic/propositional/first-order options
  - [section 6] Example mapping argument map nodes to logical formulas like {s0}, {s1}
- Break condition: If translation loses critical semantic distinctions or generates ambiguous formulas.

## Foundational Learning

- Concept: Default logic and extensions
  - Why needed here: Core representation mechanism for implicit enthymemes
  - Quick check question: What makes a default theory singular, and why is this important for default arguments?

- Concept: Argument mining output structure
  - Why needed here: Defines the input format for the bridging framework
  - Quick check question: How does an argument map differ from an argument graph in this paper's framework?

- Concept: Types of support and attack relations
  - Why needed here: Determines how arguments interact in the instantiated map
  - Quick check question: What is the difference between "justification support" and "explicit support"?

## Architecture Onboarding

- Component map: Translation module → Default argument constructor → Relation checker → Consistency validator
- Critical path: Parse text → Apply T function → Build default arguments → Check supports/attacks → Validate extensions
- Design tradeoffs: Atomic vs first-order translation balances expressiveness and tractability
- Failure signatures: Inconsistent extensions, vacuous arguments, unsupported claims
- First 3 experiments:
  1. Implement atomic translation and instantiate a simple enthymeme (bird/Tweety example)
  2. Add support relations and verify direct support detection
  3. Introduce attack relations and test consequence attack detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we automatically translate natural language argument maps into logical representations that preserve the implicit information?
- Basis in paper: explicit - The paper proposes using classical logic for explicit information and default logic for implicit information, but leaves the mechanism for automated translation to future work.
- Why unresolved: The paper provides the theoretical framework but does not develop specific algorithms for the translation process from natural language to logical representations.
- What evidence would resolve it: A working prototype that can take argument maps from argument mining and automatically translate them into default logic representations with comparable accuracy to human translation.

### Open Question 2
- Question: How can we systematically acquire and represent common-sense knowledge in default logic for use in argument instantiation?
- Basis in paper: explicit - The paper acknowledges the need for common-sense knowledge to instantiate implicit premises but leaves this as future work, noting it's difficult to acquire and often gaps exist.
- Why unresolved: The paper identifies the problem but doesn't provide a methodology for automatically acquiring and representing common-sense knowledge in a form suitable for default logic.
- What evidence would resolve it: A scalable system that can automatically extract common-sense knowledge from text and represent it as default rules that can be used to instantiate enthymemes in argument maps.

### Open Question 3
- Question: How can we measure and compare the robustness of different instantiations of the same argument map?
- Basis in paper: explicit - The paper discusses comparing different instantiations but doesn't provide specific metrics or methods for measuring robustness.
- Why unresolved: The paper proposes the framework for instantiation but doesn't develop evaluation criteria for comparing the quality or robustness of different instantiations.
- What evidence would resolve it: A set of quantitative metrics that can measure how robust an instantiation is, and how these metrics correlate with human judgments of argument quality and validity.

## Limitations

- The framework assumes default logic can adequately capture all forms of implicit knowledge, which may not hold for complex common-sense reasoning.
- No empirical validation is provided on real-world argument mining outputs, limiting assessment of practical scalability.
- The logical translation function T is assumed to exist but not specified, making implementation challenging.

## Confidence

**Medium** - The approach assumes default logic can adequately capture all forms of implicit knowledge (enthymemes) in argument maps. While the framework is theoretically sound, there may be cases where common-sense knowledge is too complex to encode as default rules without generating unintended consequences or inconsistent extensions.

**Low** - The paper does not provide empirical validation of the framework on real-world argument mining outputs. The examples are illustrative but limited in scope, leaving questions about scalability and practical implementation challenges unanswered.

**High** - The paper assumes the existence of a reliable logical translation function T, but does not specify how this function should be implemented or evaluated for accuracy. This is a critical component that could significantly impact the framework's effectiveness.

## Next Checks

1. **Consistency Validation**: Implement the framework on a diverse set of argument maps and systematically check for inconsistent default extensions, particularly when combining multiple arguments with complex support/attack relationships.

2. **Translation Evaluation**: Develop and test multiple logical translation functions (atomic, propositional, first-order) on the same argument maps to assess how translation choices affect the logical validity and consistency of the instantiated arguments.

3. **Scalability Assessment**: Apply the framework to argument maps with increasing complexity (number of nodes, types of relations) to identify performance bottlenecks and potential limitations in the default logic representation approach.