---
ver: rpa2
title: 'DeLLMa: Decision Making Under Uncertainty with Large Language Models'
arxiv_id: '2402.02392'
source_url: https://arxiv.org/abs/2402.02392
tags:
- dellma
- decision
- price
- yield
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models (LLMs) are increasingly being used as decision
  support tools in domains such as business, engineering, and medicine, which often
  face challenges of decision-making under uncertainty. This paper shows that directly
  prompting LLMs on these types of decision-making problems can yield poor results,
  especially as problem complexity increases.
---

# DeLLMa: Decision Making Under Uncertainty with Large Language Models

## Quick Facts
- arXiv ID: 2402.02392
- Source URL: https://arxiv.org/abs/2402.02392
- Reference count: 40
- Primary result: DeLLMa achieves up to 40% increase in decision-making accuracy over competing methods

## Executive Summary
Large language models are increasingly used as decision support tools in uncertain environments, but direct prompting often yields poor results, especially as problem complexity increases. DeLLMa (Decision-making Large Language Model assistant) addresses this by integrating classical decision theory with inference-time reasoning to create a structured framework for decision-making under uncertainty. The method demonstrates significant accuracy improvements across multiple realistic decision-making environments while maintaining human-auditability.

## Method Summary
DeLLMa implements a three-step reasoning process based on classical decision theory: state enumeration to identify relevant latent factors, state forecasting to produce probability distributions over these factors, and utility elicitation through pairwise ranking of state-action pairs. The framework uses batching and variance reduction techniques to improve utility elicitation accuracy, and converts LLM verbal probability assessments to numerical distributions. Expected utility maximization is then performed by an external program to select optimal actions. The method was validated on agriculture and stock decision-making tasks using datasets from USDA reports and historical stock prices.

## Key Results
- Up to 40% increase in decision-making accuracy over competing methods
- Linear performance improvements when scaling compute at test time through increased batch overlap and sample size
- All tested models achieved reasonable calibration performance that correlated with overall prediction accuracy
- Demonstrated consistent enhancement of decision-making performance across leading language models

## Why This Works (Mechanism)

### Mechanism 1
LLM decision-making improves when structured reasoning follows classical decision theory. DeLLMa constrains LLMs to follow a three-step reasoning process (state enumeration → state forecasting → utility elicitation → expected utility maximization) that mimics rational decision theory. Core assumption: Decision theory principles that work for human reasoning also improve LLM decision quality.

### Mechanism 2
Batching and variance reduction improve utility elicitation accuracy. DeLLMa uses overlapping batches of state-action pairs and duplicates states across actions to reduce variance in preference comparisons. Core assumption: LLM pairwise ranking quality improves with better exposure to preference patterns across batches.

### Mechanism 3
Verbalized probability scores from LLMs can be calibrated to numerical distributions. DeLLMa converts LLM verbal probability assessments ("very likely", "somewhat unlikely", etc.) to numerical values and normalizes them into approximate posterior distributions. Core assumption: LLMs can produce well-calibrated verbal probability assessments that map reliably to numerical distributions.

## Foundational Learning

- **Expected utility maximization**
  - Why needed here: Forms the mathematical foundation for optimal decision-making under uncertainty
  - Quick check question: If utility function U(θ,a) = θ × a and θ ∈ {1,2} with P(θ=1)=0.6, P(θ=2)=0.4, which action a ∈ {3,4} maximizes expected utility?

- **Bayesian inference and posterior distributions**
  - Why needed here: Required for state forecasting given context information
  - Quick check question: If LLM verbalizes P(θ) as "very likely" for high values and "unlikely" for low values, what distribution shape would you expect?

- **Bradley-Terry model for pairwise comparisons**
  - Why needed here: Converts LLM rankings into utility function parameters
  - Quick check question: If LLM ranks (θ1,a1) > (θ2,a2) and (θ2,a2) > (θ3,a3), what constraints does this place on the utility function?

## Architecture Onboarding

- **Component map**: Prompt → State enumeration → State forecasting → Utility elicitation → Expected utility calculation → Decision output

- **Critical path**: Prompt → State enumeration → State forecasting → Utility elicitation → Expected utility calculation → Decision output

- **Design tradeoffs**:
  - Batch size vs. computational cost: Larger batches improve preference quality but increase API costs
  - Sample size vs. variance: More samples reduce variance but increase latency
  - Verbal vs. numerical probabilities: Verbal is more LLM-friendly but requires calibration

- **Failure signatures**:
  - Poor state enumeration: Irrelevant or missing latent factors in decision context
  - Misaligned utility function: LLM preferences don't match human preferences
  - Calibration issues: Verbal probability mapping produces distorted distributions

- **First 3 experiments**:
  1. Vary overlap percentage (0%, 25%, 50%) while keeping sample size constant to find optimal batching
  2. Test different verbal-to-numerical mappings to verify calibration stability
  3. Compare DeLLMa with and without variance reduction to quantify its impact on accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of DeLLMa vary with different state enumeration strategies beyond the simple latent factor approach described in the paper? The paper mentions that the current state enumeration method is simple and can be extended or made more sophisticated.

### Open Question 2
How sensitive is DeLLMa's performance to the choice of utility elicitation method (Rank2Pairs vs. One-vs-All)? The paper mentions that DeLLMa has variants using both Rank2Pairs and One-vs-All for utility elicitation, and that One-vs-All may be desirable when accurate comparisons of certain suboptimal state-actions is challenging.

### Open Question 3
Can DeLLMa be extended to handle sequential decision-making problems, where the decision maker must make multiple decisions over time? The paper focuses on single-step decision-making problems, and the authors mention that constructing a weighted combination of actions (i.e., a portfolio) is left for future work.

## Limitations

- Empirical validation relies heavily on synthetic decision-making environments with limited testing on real-world, high-stakes applications
- Calibration mechanism for verbal-to-numerical probability mapping may not generalize well across different LLM models and domains
- Computational scaling claims don't fully address economic constraints and cost-benefit tradeoffs for practical deployment

## Confidence

- **High confidence** in the core decision-theoretic framework: The integration of classical decision theory with LLM inference-time reasoning is well-grounded and theoretically robust
- **Medium confidence** in the batching and variance reduction mechanism: Performance improvements shown but optimal parameters likely domain-dependent
- **Medium confidence** in the verbal probability calibration: Promising results but based on limited verbal categories and may require more nuanced probability expressions in real-world applications

## Next Checks

1. **Cross-domain generalization test**: Apply DeLLMa to a high-stakes, real-world decision-making scenario (e.g., medical triage or engineering failure diagnosis) and compare performance against domain experts and traditional decision support systems.

2. **Cost-performance tradeoff analysis**: Systematically vary batch sizes, sample counts, and overlap percentages across multiple domains to identify optimal parameter settings that balance accuracy gains against computational costs and latency constraints.

3. **Alternative probability calibration validation**: Replace the current verbal-to-numerical mapping with alternative calibration methods (e.g., direct numerical elicitation or external calibration models) and compare performance, particularly in domains requiring fine-grained probability distinctions.