---
ver: rpa2
title: A deep graph model for the signed interaction prediction in biological network
arxiv_id: '2407.07357'
source_url: https://arxiv.org/abs/2407.07357
tags:
- graph
- network
- drug
- edges
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces RGCNTD, a deep graph model integrating graph
  convolutional networks and tensor decomposition, designed to predict signed chemical-gene
  interactions in biological networks. RGCNTD addresses limitations of existing unsigned
  models by distinguishing polar (activation/inhibition) from non-polar (binding)
  relations.
---

# A deep graph model for the signed interaction prediction in biological network

## Quick Facts
- arXiv ID: 2407.07357
- Source URL: https://arxiv.org/abs/2407.07357
- Reference count: 32
- Primary result: RGCNTD achieves 0.966 AUC and 0.961 AUPRC on chemical-gene interaction prediction with improved polarity discrimination

## Executive Summary
This paper introduces RGCNTD, a deep graph model that integrates graph convolutional networks and tensor decomposition to predict signed chemical-gene interactions in biological networks. The model addresses limitations of existing unsigned approaches by distinguishing polar (activation/inhibition) from non-polar (binding) relations. A novel conflict-aware sampling strategy mitigates polarity ambiguities, and new metrics evaluate polarity discrimination. Experiments demonstrate superior predictive performance with AUC of 0.966 and improved handling of polarity through CL sampling.

## Method Summary
RGCNTD combines a two-layer GCN encoder with a RGCNTDDecoder that uses RGCN layers and tensor decomposition. The model processes a heterogeneous Chemical-Gene graph from STITCH database with 12,537 compounds, 28,432 genes, and 1.8M interactions across four relation types. Training employs a conflict-aware sampling strategy (CL) that enforces mutual exclusivity between increase and decrease predictions. The model averages predictions from chemical-to-gene and gene-to-chemical directions for improved robustness. Evaluation uses both traditional metrics (AUROC, AUPRC) and polarity-specific metrics (AUCpolarity, CP@500).

## Key Results
- RGCNTD achieves 0.966 AUC and 0.961 AUPRC on average predictions
- CL sampling strategy improves polarity discrimination with AUCpolarity of 0.977
- Subgraph structures do not enhance accuracy, demonstrating model efficiency
- CP@500 precision metric shows strong performance on top confident predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conflict-aware sampling resolves polarity ambiguities by enforcing mutual exclusivity between increase and decrease predictions
- Mechanism: The model uses a Cannot-Link (CL) sampling strategy that explicitly samples edges with opposite polarity (increase vs decrease) and penalizes the model for predicting both directions simultaneously. This is implemented through a custom loss function that maximizes the score difference between ML and CL pairs.
- Core assumption: Polar relations like activation and inhibition are mutually exclusive and cannot coexist for the same chemical-gene pair
- Evidence anchors:
  - [abstract]: "incorporates a conflict-aware sampling strategy to resolve polarity ambiguities"
  - [section]: "In our study, 'edge conflicts' specifically refer to the conflicts during polarity predictions by the model, such as the same sample being predicted as both 'activation' and 'inhibition'"
- Break condition: If the biological data contains cases where chemicals can simultaneously increase and decrease gene expression through different mechanisms, the mutual exclusivity assumption would fail.

### Mechanism 2
- Claim: Tensor decomposition enhances feature representation by capturing higher-order interactions between chemical and gene embeddings
- Mechanism: The RGCNTDDecoder combines Relational Graph Convolutional Network layers with tensor decomposition to parse global and local interactions. The tensor decomposition layer uses Hadamard products of entity embeddings and relation-specific tensors to generate interaction predictions.
- Core assumption: Complex chemical-gene interactions can be decomposed into interpretable tensor components that capture both local neighborhood information and global interaction patterns
- Evidence anchors:
  - [section]: "The RGCNTDDecoder combines Relational Graph Convolutional Network (RGCN) layers with the DEDICOM tensor decomposition layer, where the former is responsible for aggregating information according to different relation types, and the latter for parsing global and local interactions"
  - [section]: "P redij = σ( K∑k=1 aijk ·(Ei ⊙ Ej ⊙ Rk) )"
- Break condition: If the tensor decomposition introduces too many parameters relative to the available training data, it could lead to overfitting rather than improved representation.

### Mechanism 3
- Claim: Average prediction fusion improves robustness by combining chemical-to-gene and gene-to-chemical predictions
- Mechanism: The model separately predicts Pchem-gene and Pgene-chem interactions and combines them through simple averaging. This approach overcomes biases from single-direction predictions and enhances robustness against dataset imbalances.
- Core assumption: Chemical-to-gene and gene-to-chemical prediction directions capture complementary information that, when combined, provides more robust predictions than either direction alone
- Evidence anchors:
  - [section]: "By integrating predictions of chemical-gene and gene-chemical interactions, we aim to overcome biases that single-direction predictions might introduce and to enhance robustness against potential imbalances in the dataset"
  - [section]: "Paverage = Pchem-gene + Pgene-chem / 2"
- Break condition: If one prediction direction consistently outperforms the other, simple averaging might dilute the better predictions rather than improve overall performance.

## Foundational Learning

- Concept: Signed network representation
  - Why needed here: The model must distinguish between positive (activation/increase), negative (inhibition/decrease), and neutral (binding) interactions, which requires explicit edge sign representation rather than treating all interactions as unsigned
  - Quick check question: What are the three types of relations handled by this model, and which ones are considered polar vs non-polar?

- Concept: Graph convolutional networks
  - Why needed here: GCNs are essential for capturing local neighborhood information in the chemical-gene interaction graph, allowing the model to learn how a chemical's effects propagate through connected genes
  - Quick check question: How does the GCN update equation incorporate information from neighbors of different relation types?

- Concept: Tensor decomposition in graph settings
  - Why needed here: Tensor decomposition provides a way to model complex multi-relational interactions that go beyond simple pairwise relationships, capturing higher-order interaction patterns between chemicals and genes
  - Quick check question: What is the role of the Hadamard product in the tensor decomposition layer, and how does it combine entity embeddings with relation-specific components?

## Architecture Onboarding

- Component map: Input -> GCNEncoder (2-layer) -> RGCNTDDecoder (RGCN layers + tensor decomposition) -> Output predictions; CL sampling strategy modifies training data selection
- Critical path: Graph construction -> GCN feature extraction -> Tensor decomposition decoding -> CL sampling during training -> Evaluation with polarity-aware metrics
- Design tradeoffs: Simpler GCN-only approaches would be faster but miss higher-order interactions; full tensor decomposition adds complexity but captures richer patterns; CL sampling improves polarity discrimination but may slightly reduce traditional metric performance
- Failure signatures: High polarity conflict error rates indicate CL sampling issues; poor performance on signed relations suggests tensor decomposition problems; overfitting on small datasets points to GCN complexity issues
- First 3 experiments:
  1. Compare single-direction predictions (Pchem-gene vs Pgene-chem) to verify complementarity assumption
  2. Test model with and without CL sampling to measure polarity discrimination improvement
  3. Evaluate performance with different hidden dimension configurations to find optimal complexity-accuracy tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the RGCNTD model perform on predicting signed interactions in biological networks compared to other state-of-the-art models?
- Basis in paper: [explicit] The paper introduces the RGCNTD model and compares its performance to baseline models, showing superior classification accuracy and improved discrimination of polar edges.
- Why unresolved: The paper only compares the RGCNTD model to a few baseline models and does not provide a comprehensive comparison to all state-of-the-art models for signed interaction prediction in biological networks.
- What evidence would resolve it: A comprehensive comparison of the RGCNTD model to all relevant state-of-the-art models on a standardized dataset would provide a clear answer to this question.

### Open Question 2
- Question: How does the conflict-aware sampling strategy affect the model's ability to predict signed interactions in biological networks?
- Basis in paper: [explicit] The paper introduces a conflict-aware sampling strategy to resolve polarity ambiguities and evaluates its impact on the model's performance, showing improved discrimination of polar edges.
- Why unresolved: The paper only provides a limited analysis of the conflict-aware sampling strategy and does not explore its impact on different types of signed interactions or its performance on different datasets.
- What evidence would resolve it: A more comprehensive analysis of the conflict-aware sampling strategy, including its impact on different types of signed interactions and its performance on different datasets, would provide a clear answer to this question.

### Open Question 3
- Question: How does the RGCNTD model handle the challenge of label noise in biological interaction data?
- Basis in paper: [inferred] The paper mentions that the RGCNTD model is robust to label noise, but does not provide a detailed analysis of how it handles this challenge.
- Why unresolved: The paper does not provide a detailed analysis of how the RGCNTD model handles label noise in biological interaction data, and does not compare its performance to other models in this regard.
- What evidence would resolve it: A detailed analysis of how the RGCNTD model handles label noise in biological interaction data, including a comparison to other models, would provide a clear answer to this question.

## Limitations
- Performance claims rely heavily on specific dataset construction choices and effectiveness of conflict-aware sampling strategy
- Mutual exclusivity assumption for polar relations may not hold universally across all biological contexts
- Tensor decomposition layer's parameter sensitivity and overfitting potential not thoroughly explored
- Model generalization to datasets beyond STITCH and scalability to larger networks remain unverified

## Confidence

- High Confidence: The overall predictive performance metrics (AUC, AUPRC) are well-supported by experimental results and standard evaluation practices.
- Medium Confidence: The superiority of the CL sampling strategy for polarity discrimination is demonstrated but could benefit from additional ablation studies.
- Low Confidence: Claims about the tensor decomposition's interpretability and the model's biological interpretability are not fully substantiated with case studies or expert validation.

## Next Checks
1. **Dataset Generalization Test**: Evaluate RGCNTD on independent chemical-gene interaction datasets from sources like BioGRID or STRING to verify performance consistency across different data sources.
2. **Biological Interpretability Analysis**: Conduct a case study where model predictions are validated against known biological mechanisms, particularly focusing on cases where the model correctly identifies complex polarity interactions.
3. **Scalability Assessment**: Test the model's performance and computational efficiency on a larger, more diverse biological network (e.g., incorporating additional interaction types or organisms) to evaluate its practical scalability.