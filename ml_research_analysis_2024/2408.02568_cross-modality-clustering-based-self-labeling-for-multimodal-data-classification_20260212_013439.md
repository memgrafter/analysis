---
ver: rpa2
title: Cross-Modality Clustering-based Self-Labeling for Multimodal Data Classification
arxiv_id: '2408.02568'
source_url: https://arxiv.org/abs/2408.02568
tags:
- modalities
- data
- cmcsl
- visual
- modality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel Cross-Modality Clustering-based Self-Labeling
  (CMCSL) algorithm for semi-supervised multimodal data classification. The key idea
  is to leverage complementary information from multiple modalities to improve label
  propagation and classifier performance when only limited labeled data is available.
---

# Cross-Modality Clustering-based Self-Labeling for Multimodal Data Classification

## Quick Facts
- arXiv ID: 2408.02568
- Source URL: https://arxiv.org/abs/2408.02568
- Reference count: 40
- Primary result: Cross-Modal Clustering-based Self-Labeling (CMCSL) improves semi-supervised multimodal classification by propagating labels across modalities using cluster consistency

## Executive Summary
This paper introduces Cross-Modality Clustering-based Self-Labeling (CMCSL), a novel approach for semi-supervised multimodal data classification. The method leverages complementary information from multiple modalities to improve label propagation when only limited labeled data is available. CMCSL performs k-means clustering in each modality's feature space using pre-labeled samples as initial centroids, then propagates labels to all instances within clusters. When label disagreements occur between modalities, the method resolves conflicts by selecting the label from the modality where the instance is closest to its cluster centroid. Extensive experiments on 20 datasets derived from MM-IMDb demonstrate statistically significant improvements in balanced accuracy compared to reference approaches, particularly when pre-labeled samples are scarce.

## Method Summary
CMCSL works by first extracting deep features from each modality using pre-trained networks. It then performs k-means clustering in each modality's feature space using a small set of pre-labeled samples as initial centroids. Known labels are propagated to all instances within each cluster. In case of label disagreement between modalities for a given instance, the label from the modality where the instance is closer to its cluster centroid (based on Euclidean distance) is selected. This cross-modal label propagation is shown to improve classification accuracy compared to standard unimodal clustering-based self-labeling approaches.

## Key Results
- CMCSL achieves statistically significantly better balanced accuracy compared to early fusion, late fusion, and unimodal clustering-based self-labeling approaches
- Improvement is most pronounced when the number of pre-labeled samples is small
- The method demonstrates the benefit of cross-modal label propagation in semi-supervised scenarios

## Why This Works (Mechanism)
The effectiveness of CMCSL stems from leveraging complementary information across multiple modalities to improve label propagation. By performing clustering independently in each modality's feature space and then resolving conflicts through proximity to cluster centroids, the method can identify consistent patterns that may be obscured when considering modalities individually. This cross-modal consistency check helps filter out noise and improves the reliability of self-labeled data, particularly valuable when labeled data is scarce.

## Foundational Learning
- **Multimodal Feature Extraction**: Using pre-trained deep networks to extract meaningful representations from different data modalities
  - Why needed: Deep features capture semantic information that improves clustering and classification performance
  - Quick check: Verify feature extraction quality using t-SNE visualizations and classification accuracy on labeled subsets

- **Cross-Modal Consistency**: Ensuring label assignments are consistent across different modality representations
  - Why needed: Different modalities may capture complementary or conflicting information about the same instances
  - Quick check: Measure agreement rates between modality-specific label assignments on validation sets

- **Semi-Supervised Learning**: Leveraging limited labeled data with abundant unlabeled data for improved classification
  - Why needed: Labeled data is often expensive or difficult to obtain, especially in multimodal scenarios
  - Quick check: Compare performance across different ratios of labeled to unlabeled data

## Architecture Onboarding

**Component Map:**
Feature Extraction -> Modality-specific Clustering -> Label Propagation -> Cross-Modal Conflict Resolution -> Final Classification

**Critical Path:**
1. Extract deep features from each modality
2. Perform k-means clustering using labeled samples as centroids
3. Propagate labels within clusters
4. Resolve conflicts using Euclidean distance to centroids
5. Train classifier on self-labeled data

**Design Tradeoffs:**
- Using pre-trained networks provides good feature representations but may not be optimal for specific datasets
- K-means clustering is computationally efficient but assumes spherical cluster shapes
- Euclidean distance for conflict resolution is simple but may not capture complex relationships

**Failure Signatures:**
- Poor performance when modalities capture fundamentally different aspects of data
- Suboptimal results when feature spaces have different scales or distributions
- Degradation when cluster assumptions (spherical, equal-sized) are violated

**First Experiments:**
1. Test performance with different pre-trained feature extractors on a subset of datasets
2. Evaluate the impact of varying the number of initial labeled samples
3. Compare CMCSL against simple late fusion baseline on balanced accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability beyond MM-IMDb dataset and specific deep feature extractors remains uncertain
- Performance depends heavily on the assumption that cross-modal clustering produces consistent label assignments
- The Euclidean distance heuristic for conflict resolution may not always produce optimal results

## Confidence

**High confidence** in the experimental methodology and statistical analysis on the tested datasets
**Medium confidence** in the general effectiveness of cross-modal label propagation as a semi-supervised learning strategy
**Low confidence** in the scalability and performance guarantees when applied to different types of multimodal data or with different pre-trained feature extractors

## Next Checks
1. Evaluate CMCSL on diverse multimodal datasets beyond MM-IMDb, including different domains (medical imaging, remote sensing, etc.) to test generalizability
2. Test the impact of using different pre-trained networks and feature extraction methods to assess robustness to feature representation choices
3. Compare CMCSL's label conflict resolution strategy against alternative approaches (e.g., weighted voting, ensemble methods) to determine optimal conflict handling