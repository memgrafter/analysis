---
ver: rpa2
title: Image Based Character Recognition, Documentation System To Decode Inscription
  From Temple
arxiv_id: '2405.17449'
source_url: https://arxiv.org/abs/2405.17449
tags:
- image
- tamil
- inscriptions
- pixel
- tesseract
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of digitizing 10th-century Tamil
  inscriptions from temple walls using OCR technology. The research combines modern
  preprocessing techniques, including image enhancement and noise reduction, with
  a custom-trained Tesseract OCR model tailored for ancient Tamil script.
---

# Image Based Character Recognition, Documentation System To Decode Inscription From Temple

## Quick Facts
- arXiv ID: 2405.17449
- Source URL: https://arxiv.org/abs/2405.17449
- Reference count: 15
- System digitizes 10th-century Tamil inscriptions from temple walls using OCR technology

## Executive Summary
This study presents a comprehensive system for digitizing ancient Tamil inscriptions from temple walls using Optical Character Recognition (OCR) technology. The research addresses the challenge of preserving historical records by developing a specialized pipeline that combines modern image preprocessing techniques with custom-trained OCR models tailored for ancient Tamil script. The system achieves an overall accuracy of 80.8% in character recognition, demonstrating the feasibility of automated inscription decoding while providing a web application for public access to the tool.

## Method Summary
The research employs a multi-stage approach to digitize Tamil inscriptions. The process begins with innovative data collection using limestone powder to enhance image contrast, followed by preprocessing techniques including image enhancement and noise reduction. A custom-trained Tesseract OCR model is developed specifically for ancient Tamil script, with manual bounding box refinement to ensure accurate character recognition. The system is validated on a test dataset of 500 images, achieving an 80.8% overall accuracy. A web application is also developed to facilitate public access to the digitization tool.

## Key Results
- Achieved 80.8% overall accuracy in character recognition across test images
- Successfully handled unique morphological characteristics of ancient Tamil script
- Developed functional web application for public access to the digitization tool

## Why This Works (Mechanism)
The system's effectiveness stems from combining specialized preprocessing techniques with a custom-trained OCR model. The limestone powder application improves image contrast by creating a uniform background, making characters more distinguishable for OCR processing. The custom Tesseract training specifically addresses the morphological characteristics of ancient Tamil script, which differs significantly from modern text. Manual bounding box refinement ensures precise character segmentation, a critical factor in OCR accuracy for complex scripts.

## Foundational Learning
- **Image preprocessing importance**: Why needed - Clean, enhanced images significantly improve OCR accuracy; Quick check - Compare OCR results with and without preprocessing steps
- **Custom model training**: Why needed - Generic OCR models struggle with ancient scripts; Quick check - Test model performance on modern vs. ancient Tamil text
- **Bounding box refinement**: Why needed - Accurate character segmentation is crucial for complex scripts; Quick check - Measure OCR accuracy with automatic vs. manual segmentation

## Architecture Onboarding

Component map: Image Capture -> Preprocessing -> OCR Processing -> Post-processing -> Web Interface

Critical path: Limestone powder application → Image enhancement → Character segmentation → OCR recognition → Accuracy validation

Design tradeoffs: Custom model training vs. generic OCR (accuracy vs. generalization), manual vs. automatic segmentation (precision vs. scalability)

Failure signatures: Poor contrast conditions → decreased OCR accuracy; Complex character morphology → segmentation errors; Insufficient training data → model underperformance

First experiments:
1. Test OCR accuracy on images with varying contrast levels
2. Compare manual vs. automatic character segmentation performance
3. Evaluate model performance with different training dataset sizes

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Small test dataset of 500 images may not represent full variability of inscriptions
- Focus on single temple site limits generalizability to other locations or scripts
- Long-term preservation and accessibility of digital dataset not addressed

## Confidence

High confidence:
- Methodology for image preprocessing and custom Tesseract training is well-documented
- Overall accuracy metric of 80.8% is clearly stated and reproducible

Medium confidence:
- Effectiveness of limestone powder technique across diverse inscription conditions requires further validation
- Manual bounding box refinement process may not be scalable for larger projects

Low confidence:
- Long-term preservation and accessibility of digital dataset not addressed
- Potential for model degradation over time or with increased data diversity not discussed

## Next Checks
1. Test the OCR system on a larger, more diverse dataset of Tamil inscriptions from multiple temple sites and time periods to assess generalizability
2. Conduct a detailed error analysis to identify specific character types or morphological features that consistently challenge the OCR model, guiding targeted improvements
3. Evaluate the web application's performance with concurrent users and large datasets to ensure scalability and real-world usability