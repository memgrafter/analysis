---
ver: rpa2
title: 'VCC-INFUSE: Towards Accurate and Efficient Selection of Unlabeled Examples
  in Semi-supervised Learning'
arxiv_id: '2404.11947'
source_url: https://arxiv.org/abs/2404.11947
tags:
- learning
- confidence
- unlabeled
- examples
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses challenges in semi-supervised learning (SSL)
  where existing pseudo-label-based methods struggle with inaccurate confidence scores
  and inefficient use of unlabeled data. To solve these, the authors propose two methods:
  Variational Confidence Calibration (VCC) and Influence-Function-based Unlabeled
  Sample Elimination (INFUSE).'
---

# VCC-INFUSE: Towards Accurate and Efficient Selection of Unlabeled Examples in Semi-supervised Learning

## Quick Facts
- arXiv ID: 2404.11947
- Source URL: https://arxiv.org/abs/2404.11947
- Reference count: 20
- Primary result: Reduces CIFAR-100 error rate by 1.08% while saving nearly half the training time compared to FlexMatch

## Executive Summary
This paper addresses two key challenges in semi-supervised learning (SSL): inaccurate pseudo-label confidence scores and inefficient use of unlabeled data. The authors propose VCC-INFUSE, a two-component framework that improves both accuracy and efficiency. VCC (Variational Confidence Calibration) enhances pseudo-label selection using three types of consistency scores combined with a variational autoencoder, while INFUSE (Influence-Function-based Unlabeled Sample Elimination) accelerates training by dynamically pruning unimportant unlabeled examples. Together, these methods improve classification accuracy and reduce training time on standard SSL benchmarks.

## Method Summary
VCC-INFUSE combines two novel techniques to enhance semi-supervised learning. VCC improves pseudo-label confidence calibration by computing three types of consistency scores (ensemble, temporal, and view consistency) and using a variational autoencoder to reconstruct these into more stable confidence scores. INFUSE accelerates training by using influence functions to identify and prune unimportant unlabeled examples, maintaining only a core subset for training. The framework is designed as a plugin that can be integrated with existing SSL methods like FixMatch, FlexMatch, and SimMatch.

## Key Results
- Reduces CIFAR-100 error rate by 1.08% compared to FlexMatch baseline
- Saves nearly half the training time while maintaining accuracy
- Outperforms state-of-the-art methods on CIFAR-10, CIFAR-100, SVHN, and STL-10
- Demonstrates effective calibration with improved ECE, MCE, and ACE metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VCC improves pseudo-label accuracy by using multiple consistency scores to approximate calibrated confidence
- Mechanism: Combines ensemble consistency (Monte Carlo dropout), temporal consistency (KL divergence over time), and view consistency (KL divergence between EMA views with cross-feature trick) to produce a stability-weighted confidence score
- Core assumption: Combining stability metrics from different perspectives provides a more robust approximation of calibration than any single metric
- Evidence anchors: Abstract states VCC uses "three types of consistency scores" for pseudo-label selection; Section 3.3 describes EMA construction and cross-feature trick

### Mechanism 2
- Claim: INFUSE reduces training time by dynamically pruning unimportant unlabeled examples using influence functions
- Mechanism: Computes importance scores based on how validation loss changes if example weights increase, keeping only top-scoring examples
- Core assumption: Influence functions provide good approximation of example importance for pruning without expensive retraining
- Evidence anchors: Abstract describes INFUSE as "data pruning method that constructs a core dataset"; Section 4 provides influence score formula with Hessian approximation

### Mechanism 3
- Claim: The variational autoencoder in VCC reconstructs statistical approximations into learned confidence scores to reduce instability
- Mechanism: VAE learns to map three consistency scores to more stable confidence scores through reconstruction, using statistical approximations as "ground truth"
- Core assumption: Reconstruction process can smooth out noise and instability in statistical approximation
- Evidence anchors: Section 3.5 describes VAE learning jointly with classifier where consistency scores serve as "ground-truth" for reconstruction loss

## Foundational Learning

- Concept: Semi-supervised learning with pseudo-labeling
  - Why needed here: Builds on pseudo-labeling approaches like FixMatch that generate labels for unlabeled data based on model confidence
  - Quick check question: What is the main challenge with pseudo-labeling in SSL that VCC addresses?

- Concept: Confidence calibration in deep learning
  - Why needed here: Modern neural networks are often overconfident, and VCC aims to produce better-calibrated confidence scores for pseudo-label selection
  - Quick check question: How does temperature scaling work for confidence calibration, and why might it not be directly applicable to SSL?

- Concept: Influence functions and core set selection
  - Why needed here: INFUSE uses influence functions to identify and keep only the most informative unlabeled examples, reducing training cost
  - Quick check question: What is the key computational challenge with exact influence functions, and how does INFUSE address it?

## Architecture Onboarding

- Component map:
  - Base SSL model (e.g., FixMatch/FlexMatch/SimMatch)
  - VCC plugin:
    - Ensemble consistency module (Monte Carlo dropout)
    - Temporal consistency module (EMA tracking)
    - View consistency module (cross-feature EMA)
    - VAE reconstruction module
  - INFUSE module:
    - Influence score computation
    - Core set selection and update logic
  - Training loop coordination

- Critical path: SSL model training → VCC confidence calibration → INFUSE core set pruning → repeat

- Design tradeoffs:
  - VCC adds computational overhead for consistency score computation and VAE training, but improves accuracy
  - INFUSE reduces training iterations by pruning data, but requires influence score computation
  - The VAE in VCC could be seen as over-engineering vs simpler calibration methods

- Failure signatures:
  - VCC fails if consistency scores become correlated or unreliable
  - INFUSE fails if influence scores are poorly estimated due to Hessian approximation
  - Both methods may underperform if the base SSL method is already well-calibrated or data is already informative

- First 3 experiments:
  1. Run baseline SSL method (e.g., FixMatch) on CIFAR-100 with 2500 labels to establish performance baseline
  2. Add VCC to the baseline and measure improvement in accuracy and calibration error
  3. Add INFUSE to the baseline with various keep ratios to find the optimal trade-off between accuracy and training time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed VCC-INFUSE framework perform when applied to semi-supervised learning tasks beyond image classification, such as object detection or semantic segmentation?
- Basis in paper: The authors mention that future work will involve extending VCC-INFUSE to various SSL tasks, such as object detection and segmentation, to assess its generalization.
- Why unresolved: The paper primarily focuses on evaluating the method on image classification datasets (CIFAR-10/100, SVHN, STL-10). The authors acknowledge that extending the method to other SSL tasks is a direction for future work, but no experiments or analysis are provided in the paper.
- What evidence would resolve it: Conducting experiments applying VCC-INFUSE to object detection and semantic segmentation tasks, and comparing the results with state-of-the-art methods in those domains.

### Open Question 2
- Question: What is the impact of using different types of consistency scores in the VCC method, and how do they contribute to the overall performance?
- Basis in paper: The authors mention that they use three types of consistency scores (sens, stem, and sview) to approximate calibrated confidence scores. They also conduct an ablation study to analyze the contributions of each consistency score.
- Why unresolved: While the authors provide an ablation study showing that each consistency score contributes to the estimation of a more accurate calibrated confidence, they do not provide a detailed analysis of the individual impact of each consistency score or explore alternative consistency scores that could potentially improve performance.
- What evidence would resolve it: Conducting a more comprehensive analysis of the individual impact of each consistency score, including exploring alternative consistency scores and their effects on performance.

### Open Question 3
- Question: How does the proposed INFUSE method compare to other core set selection methods in terms of computational efficiency and memory usage, especially when dealing with large-scale datasets?
- Basis in paper: The authors mention that INFUSE is designed to reduce computation costs during training by dynamically pruning unimportant unlabeled examples. They also compare INFUSE with other core set selection methods (e.g., RETRIEVE, GradMatch, EL2N) in terms of error rate.
- Why unresolved: While the authors compare INFUSE with other core set selection methods in terms of error rate, they do not provide a detailed analysis of the computational efficiency and memory usage of INFUSE, especially when dealing with large-scale datasets. The authors mention that INFUSE uses the identity matrix to approximate the inverse Hessian for efficiency, but the impact of this approximation on performance is not explored.
- What evidence would resolve it: Conducting a detailed analysis of the computational efficiency and memory usage of INFUSE, including comparing it with other core set selection methods on large-scale datasets and exploring the impact of different approximations on performance.

## Limitations

- The VAE reconstruction step in VCC lacks empirical justification for why it improves over simpler calibration methods
- The influence function approximation using an identity matrix for the Hessian is a significant simplification that could lead to inaccurate importance scores
- Computational overhead of VCC (Monte Carlo dropout, multiple consistency scores, VAE training) is not fully characterized

## Confidence

- **High confidence**: The core problem identification (inaccurate pseudo-label confidence and inefficient data usage in SSL) and the general approach of combining calibration with pruning are well-founded
- **Medium confidence**: The influence function-based pruning mechanism has theoretical grounding, though the specific approximation methods used are not fully validated
- **Low confidence**: The VAE reconstruction step in VCC lacks theoretical or empirical justification for why it improves over simpler calibration methods

## Next Checks

1. **Ablation study on VAE**: Remove the VAE reconstruction from VCC and compare performance to isolate whether the VAE adds value beyond the three consistency scores
2. **Sensitivity analysis on keep ratio**: Systematically vary the INFUSE keep ratio parameter to determine the optimal trade-off between accuracy and training time across different datasets
3. **Computation time profiling**: Measure the exact computational overhead added by VCC (consistency score computation, VAE training) to validate the claimed efficiency improvements when combined with INFUSE