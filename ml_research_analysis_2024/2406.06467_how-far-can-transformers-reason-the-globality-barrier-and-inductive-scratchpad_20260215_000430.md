---
ver: rpa2
title: How Far Can Transformers Reason? The Globality Barrier and Inductive Scratchpad
arxiv_id: '2406.06467'
source_url: https://arxiv.org/abs/2406.06467
tags:
- scratchpad
- learning
- task
- distribution
- inductive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies the learning capabilities of Transformers, focusing
  on their ability to perform global reasoning tasks that require composing multiple
  steps of information. The authors introduce the notion of "distribution locality"
  to quantify the difficulty of learning a target distribution from scratch, where
  high locality indicates that many input tokens are required to correlate with the
  target.
---

# How Far Can Transformers Reason? The Globality Barrier and Inductive Scratchpad

## Quick Facts
- arXiv ID: 2406.06467
- Source URL: https://arxiv.org/abs/2406.06467
- Authors: Emmanuel Abbe; Samy Bengio; Aryo Lotfi; Colin Sandon; Omid Saremi
- Reference count: 40
- One-line primary result: Transformers struggle with global reasoning tasks requiring composition of multiple information steps, but inductive scratchpads can overcome this locality barrier and enable length generalization up to 6x.

## Executive Summary
This paper investigates Transformers' limitations in performing global reasoning tasks that require composing multiple steps of information. The authors introduce "distribution locality" as a measure of learning difficulty, showing that tasks requiring many input tokens to correlate with targets are hard for Transformers to learn efficiently. They propose scratchpads as intermediate reasoning steps and introduce an "inductive scratchpad" that exploits the inductive structure of reasoning tasks, enabling better out-of-distribution generalization. Experiments demonstrate significant improvements in length generalization for arithmetic tasks.

## Method Summary
The method involves training GPT2-style decoder-only Transformers with 6 layers, 6 heads, and embedding dimension 384 on reasoning tasks with varying locality levels. The approach uses population gradient descent with polynomial hyperparameters and employs scratchpads to provide intermediate steps for reasoning. The inductive scratchpad mechanism uses attention masking and reindexing to enforce inductive behavior, allowing the model to learn state transition functions rather than memorizing proof steps. The locality measure quantifies task difficulty by measuring the minimum number of tokens needed to correlate with the target when combined with the histogram.

## Key Results
- Tasks with high locality (requiring many input tokens to correlate with targets) are difficult for Transformers to learn efficiently
- Scratchpads can reduce locality by decomposing targets into simpler subtasks, enabling learning of otherwise difficult tasks
- Inductive scratchpads improve out-of-distribution generalization by learning induction functions rather than memorizing proof steps
- Length generalization improves up to 6x for arithmetic tasks using inductive scratchpads

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformers struggle to learn global reasoning tasks when the locality measure is high.
- Mechanism: Locality quantifies the minimum number of tokens needed to correlate with the target when combined with the histogram. High locality implies the target requires global composition, which Transformers cannot efficiently learn from scratch.
- Core assumption: The data distribution is well-behaved and symmetric under permutations of inputs.
- Evidence anchors:
  - [abstract] "distributions with high locality cannot be learned efficiently"
  - [section 2.2] "Transformers require low locality: formal results"
  - [corpus] weak - no direct mention of locality or learning barriers
- Break condition: If the data distribution is not well-behaved or if positional embeddings allow focusing on relevant subsets.

### Mechanism 2
- Claim: Educated scratchpads can break the locality barrier if they decompose the target into subtasks of lower locality.
- Mechanism: Intermediate steps (scratchpad) reduce the locality of each step, making the overall target learnable. The autoregressive locality measures how well a scratchpad breaks down the task.
- Core assumption: The target can be decomposed into subtasks with lower locality, and each step can be learned efficiently.
- Evidence anchors:
  - [section 3.1] "educated scratchpad can help if it breaks the locality at each step"
  - [section 3.1] "parity task with cumulative product scratchpad has locality of 2"
  - [corpus] weak - no direct mention of scratchpads or locality decomposition
- Break condition: If the subtasks still have high locality or if the scratchpad steps cannot be learned efficiently.

### Mechanism 3
- Claim: Inductive scratchpads improve out-of-distribution generalization by learning the induction function rather than memorizing proof steps.
- Mechanism: Inductive scratchpads exploit the inductive structure of reasoning tasks, promoting generalization to inputs requiring different numbers of reasoning steps. Attention masking and reindexing enforce the inductive behavior.
- Core assumption: The task can be solved inductively with a state transition function, and the model can learn this function.
- Evidence anchors:
  - [section 3.2.2] "inductive scratchpad can generalize to more reasoning steps than seen during training"
  - [section 3.2.2] "inductive scratchpad for cycle task generalizes to more reasoning steps"
  - [corpus] weak - no direct mention of inductive scratchpads or generalization
- Break condition: If the task cannot be decomposed into inductive steps or if the model cannot learn the induction function.

## Foundational Learning

- Concept: Locality measure
  - Why needed here: Locality quantifies the difficulty of learning a target distribution from scratch, explaining why Transformers struggle with global reasoning tasks.
  - Quick check question: Can you explain why the cycle task has high locality and why this makes it hard for Transformers to learn?

- Concept: Scratchpad methodologies
  - Why needed here: Scratchpads provide intermediate steps that break down the target into simpler subtasks, potentially overcoming the locality barrier.
  - Quick check question: How does the cumulative product scratchpad reduce the locality of the parity task from k to 2?

- Concept: Inductive reasoning
  - Why needed here: Inductive reasoning tasks have a state transition function that can be learned, allowing models to generalize to inputs requiring different numbers of reasoning steps.
  - Quick check question: Can you describe how the inductive scratchpad for the addition task works and why it enables length generalization?

## Architecture Onboarding

- Component map: Input sequence → Transformer layers with attention → Output distribution over next token
- Critical path: Input sequence → Transformer layers with attention → Output distribution over next token
- Design tradeoffs: Larger models (25M, 85M parameters) can learn harder tasks but require more data and computation. Relative positional embeddings may improve length generalization.
- Failure signatures: Model fails to learn when locality is high (e.g., cycle task with 24 nodes/edges). Model overfits when using fully educated scratchpads (e.g., DFS scratchpad for cycle task).
- First 3 experiments:
  1. Train on cycle task with 24 nodes/edges and assess accuracy on connected vs. disconnected nodes.
  2. Implement cumulative product scratchpad for parity task and evaluate learning efficiency for different numbers of bits.
  3. Create inductive scratchpad for addition task using random spaces and assess length generalization from 10 to 20 digits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Transformers efficiently learn tasks with high locality if given sufficient training data and computational resources?
- Basis in paper: [explicit] The paper introduces the concept of distribution locality to quantify the difficulty of learning a target distribution from scratch, where high locality indicates that many input tokens are required to correlate with the target.
- Why unresolved: While the paper provides theoretical and experimental evidence that tasks with high locality are hard for Transformers to learn efficiently, it does not definitively rule out the possibility that with enough data and computational power, Transformers might still be able to learn such tasks.
- What evidence would resolve it: Extensive experiments with varying amounts of training data and model sizes on tasks with high locality, such as the cycle task, could provide insights into whether there is a threshold beyond which Transformers can learn these tasks efficiently.

### Open Question 2
- Question: Can Transformers learn tasks with high locality using unsupervised pretraining on large datasets?
- Basis in paper: [inferred] The paper focuses on learning tasks from scratch, but does not explore the potential benefits of unsupervised pretraining on large datasets, which is a common practice in modern machine learning.
- Why unresolved: The paper does not investigate whether pretraining on large datasets can help Transformers learn tasks with high locality by providing useful representations or inductive biases.
- What evidence would resolve it: Experiments comparing the performance of Transformers with and without unsupervised pretraining on large datasets for tasks with high locality could shed light on the potential benefits of pretraining.

### Open Question 3
- Question: Are there alternative architectures or modifications to Transformers that can efficiently learn tasks with high locality?
- Basis in paper: [inferred] The paper primarily focuses on regular Transformers and does not explore alternative architectures or modifications that might be better suited for learning tasks with high locality.
- Why unresolved: The paper does not investigate whether other architectures, such as recurrent neural networks or models with different attention mechanisms, can efficiently learn tasks with high locality.
- What evidence would resolve it: Comparative experiments between regular Transformers and alternative architectures on tasks with high locality could reveal whether there are more suitable architectures for these tasks.

## Limitations
- The locality measure may not fully capture all aspects of reasoning difficulty and assumes well-behaved distributions symmetric under permutations
- The effectiveness of scratchpads relies on the assumption that complex reasoning tasks can be decomposed into simpler subtasks
- The inductive scratchpad's ability to scale beyond arithmetic and graph tasks remains unproven
- The approach may not generalize well to real-world reasoning tasks with complex dependencies

## Confidence

**High Confidence**: The theoretical framework around locality as a measure of reasoning difficulty is well-developed and mathematically rigorous. The experimental results showing that high-locality tasks (like the cycle task) are indeed difficult for Transformers to learn are consistent and reproducible.

**Medium Confidence**: The effectiveness of educated scratchpads in reducing locality and enabling learning of otherwise difficult tasks. While the experiments with parity tasks are convincing, the general applicability to diverse reasoning tasks needs further validation.

**Low Confidence**: The inductive scratchpad's ability to generalize to out-of-distribution samples and its practical utility in real-world reasoning tasks. The improvements in length generalization are promising but limited to specific arithmetic tasks, and the scalability to more complex reasoning remains unproven.

## Next Checks

1. **Cross-domain locality testing**: Apply the locality framework to non-arithmetic reasoning tasks (such as logical inference, spatial reasoning, or multi-step planning) to validate whether the measure generalizes beyond the specific tasks tested. This would involve designing tasks with controlled locality values across different reasoning domains and measuring Transformer performance.

2. **Scratchpad decomposition analysis**: Systematically vary the granularity and structure of scratchpads for a single task to determine the optimal decomposition strategy. This includes testing whether different scratchpad designs (cumulative product, step-by-step breakdowns, hierarchical decompositions) affect learning efficiency differently for the same underlying task.

3. **Inductive scratchpad scalability evaluation**: Test the inductive scratchpad approach on increasingly complex tasks that require chaining more reasoning steps than seen during training. This should include tasks where the number of required reasoning steps varies significantly between training and test samples, measuring both performance and generalization gaps.