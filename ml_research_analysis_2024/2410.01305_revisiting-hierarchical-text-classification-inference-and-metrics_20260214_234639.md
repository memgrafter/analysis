---
ver: rpa2
title: 'Revisiting Hierarchical Text Classification: Inference and Metrics'
arxiv_id: '2410.01305'
source_url: https://arxiv.org/abs/2410.01305
tags:
- hierarchical
- which
- classification
- text
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper revisits hierarchical text classification (HTC) by proposing
  a new evaluation methodology that accounts for hierarchical structure using specific
  hierarchical metrics. The authors introduce a new challenging dataset, Hierarchical
  Wikivitals (HWV), which has a deeper and more complex hierarchy compared to existing
  benchmarks.
---

# Revisiting Hierarchical Text Classification: Inference and Metrics

## Quick Facts
- arXiv ID: 2410.01305
- Source URL: https://arxiv.org/abs/2410.01305
- Reference count: 40
- One-line primary result: Simple HTC methods with conditional softmax and logit adjustment outperform recent sophisticated models on a new challenging HWV dataset

## Executive Summary
This paper critically revisits hierarchical text classification (HTC) by questioning commonly used evaluation practices and proposing a new challenging benchmark. The authors introduce the Hierarchical Wikivitals (HWV) dataset, which features deeper and more complex hierarchies than existing benchmarks. Through comprehensive experiments, they demonstrate that recent sophisticated HTC models do not necessarily outperform simpler baselines when evaluated with appropriate hierarchical metrics. The paper introduces a theoretically motivated conditional softmax loss function and shows that simpler methods often achieve better performance on HWV. Additionally, the authors highlight the limitations of using fixed 0.5 thresholds for inference and advocate for threshold-independent evaluation using precision-recall curves and AUC.

## Method Summary
The paper proposes a conditional softmax loss function for HTC that enforces hierarchy coherence by normalizing probabilities within parent-child groups. For multi-path hierarchies, a conditional sigmoid variant is introduced. To address label imbalance, a logit-adjusted version incorporates prior label probabilities. The evaluation methodology emphasizes hierarchical metrics (hF1-score, hF1 AUC) and threshold-independent assessment. The authors evaluate these approaches on four datasets: HWV (new), WOS, RCV1-V2, and BGC, using BERT-base-uncased as the text encoder. Training employs 20 epochs with AdamW optimizer, and inference uses precision-recall curves at all thresholds rather than a fixed 0.5 cutoff.

## Key Results
- Simple baselines with conditional softmax and logit adjustment outperform recent sophisticated HTC models on the new HWV dataset
- The commonly used 0.5 threshold for inference is suboptimal; threshold-independent evaluation using AUC is more robust
- The HWV dataset presents a more challenging benchmark for HTC with deeper hierarchies (depth 2-6) compared to existing datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conditional softmax loss improves hierarchical text classification by enforcing hierarchy coherence in probability distributions.
- Mechanism: The conditional softmax applies softmax normalization within each parent-child group, ensuring that the predicted probabilities respect the tree structure (i.e., probabilities of children sum to the probability of their parent).
- Core assumption: The hierarchy structure can be captured by modeling conditional probabilities at each node given its parent.
- Evidence anchors:
  - [abstract]: "simple theoretically motivated loss function based on conditional softmax"
  - [section 4.1]: Describes the conditional softmax formulation and its hierarchical properties
  - [corpus]: No direct corpus evidence found for this specific mechanism
- Break condition: If the hierarchy structure is not a tree or if parent-child relationships are not meaningful for the classification task.

### Mechanism 2
- Claim: Logit-adjusted conditional softmax addresses label imbalance by incorporating prior label probabilities.
- Mechanism: Adds a term τ log ν(y|π(y)) to the logits, where ν(y|π(y)) estimates P(y|π(y)), which adjusts the predicted probabilities based on the frequency of labels in the training data.
- Core assumption: Label imbalance affects model performance and can be mitigated by incorporating prior label probabilities.
- Evidence anchors:
  - [section 4.2]: Introduces the logit-adjusted conditional softmax and explains its motivation
  - [section 6]: Shows improved performance on HWV dataset, which has significant label imbalance
  - [corpus]: No direct corpus evidence found for this specific mechanism
- Break condition: If label frequencies in the training data do not reflect the true underlying distribution or if the adjustment hyperparameter τ is not properly tuned.

### Mechanism 3
- Claim: Threshold-independent evaluation using AUC is more robust than fixed threshold metrics like F1-score.
- Mechanism: Instead of choosing a single threshold (e.g., 0.5), the evaluation considers all possible thresholds and computes the area under the precision-recall curve, which captures model performance across different operating points.
- Core assumption: The optimal threshold for classification depends on the specific metric and may vary across different instances.
- Evidence anchors:
  - [abstract]: "commonly used 0.5 threshold for inference is suboptimal and proposes using precision-recall curves and AUC"
  - [section 3.3]: Provides theoretical justification for why 0.5 threshold is suboptimal
  - [corpus]: No direct corpus evidence found for this specific mechanism
- Break condition: If the precision-recall curve is flat or if the metric of interest is not well-represented by the area under the curve.

## Foundational Learning

- Concept: Hierarchical text classification as a structured prediction problem
  - Why needed here: The paper deals with assigning labels that follow a hierarchical structure, which is different from flat multi-label classification
  - Quick check question: How does hierarchical text classification differ from standard multi-label text classification?

- Concept: Conditional probability modeling
  - Why needed here: The proposed loss functions rely on modeling conditional probabilities of labels given their parent labels
  - Quick check question: What is the difference between modeling P(y|x) and P(y|x, π(y))?

- Concept: Evaluation metrics for hierarchical classification
  - Why needed here: The paper introduces specific hierarchical metrics like hF1-score and argues for their use over standard multi-label metrics
  - Quick check question: How does the hierarchical F1-score differ from the standard F1-score?

## Architecture Onboarding

- Component map: BERT encoding -> Conditional probability estimation -> Loss computation -> Parameter updates
- Critical path: Input text → BERT encoding → Conditional probability estimation → Loss computation → Parameter updates
- Design tradeoffs:
  - Conditional softmax enforces hierarchy coherence but may be computationally more expensive than standard BCE
  - Logit adjustment helps with label imbalance but requires estimating prior label probabilities
  - Threshold-independent evaluation is more robust but may be less interpretable than fixed threshold metrics
- Failure signatures:
  - Poor performance on deep hierarchy nodes: May indicate that the conditional softmax is not effectively capturing hierarchical relationships
  - Inconsistent predictions (child predicted without parent): May indicate issues with the conditional probability modeling
  - Large discrepancy between micro and macro F1-scores: May indicate label imbalance issues
- First 3 experiments:
  1. Compare conditional softmax vs. standard BCE on a simple hierarchy to verify hierarchy coherence enforcement
  2. Evaluate the effect of logit adjustment on label imbalance by training on an imbalanced dataset with and without the adjustment
  3. Compare threshold-independent AUC evaluation vs. fixed threshold F1-score on a dataset with varying optimal thresholds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the conditional softmax loss effectively handle multi-path hierarchies in HTC tasks?
- Basis in paper: [explicit] The authors mention that the conditional softmax is not designed for multi-path labels and propose a conditional sigmoid loss for such cases.
- Why unresolved: The paper does not provide experimental results comparing the performance of conditional softmax and conditional sigmoid on multi-path datasets.
- What evidence would resolve it: Experimental results comparing the performance of conditional softmax and conditional sigmoid on multi-path datasets.

### Open Question 2
- Question: How does the logit-adjusted conditional softmax loss perform on datasets with varying degrees of label imbalance?
- Basis in paper: [explicit] The authors introduce the logit-adjusted conditional softmax loss to improve robustness to data imbalance, particularly for the HWV dataset.
- Why unresolved: The paper does not provide a comprehensive analysis of the logit-adjusted conditional softmax loss performance across datasets with different levels of label imbalance.
- What evidence would resolve it: Experiments comparing the performance of logit-adjusted conditional softmax on datasets with varying degrees of label imbalance.

### Open Question 3
- Question: Is there an optimal inference rule for hierarchical metrics that outperforms the threshold-based approach?
- Basis in paper: [inferred] The authors discuss the limitations of using a 0.5 threshold and propose using precision-recall curves and AUC for a more robust evaluation.
- Why unresolved: The paper does not explore alternative inference rules that might be optimal for hierarchical metrics.
- What evidence would resolve it: Experiments comparing the performance of different inference rules on hierarchical metrics.

## Limitations

- The HWV dataset, while deeper than existing benchmarks, is derived from Wikipedia and may not represent the complexity of naturally occurring hierarchical text classification problems in domains like biomedical literature or legal documents.
- The proposed conditional softmax loss assumes tree-structured hierarchies, limiting its applicability to multi-path datasets like RCV1-V2 and BGC.
- The paper's evaluation relies heavily on synthetic experiments and controlled benchmarks, which may not fully capture real-world hierarchical classification challenges.

## Confidence

- **High Confidence**: The assertion that 0.5 threshold is suboptimal and that threshold-independent evaluation (AUC) provides more robust assessment of model performance.
- **Medium Confidence**: The claim that simple baselines with conditional softmax outperform recent sophisticated HTC models on HWV.
- **Medium Confidence**: The effectiveness of logit-adjusted conditional softmax in addressing label imbalance.

## Next Checks

1. **Cross-Domain Validation**: Evaluate the proposed methods on naturally occurring hierarchical text classification datasets from different domains (e.g., biomedical, legal, or scientific literature) to assess generalizability beyond Wikipedia-derived HWV.

2. **Ablation Study on Conditional Components**: Systematically test the contribution of each component in the conditional softmax framework (hierarchy coherence enforcement vs. label imbalance adjustment) by training models with individual components disabled.

3. **Threshold Behavior Analysis**: Conduct a detailed analysis of how optimal classification thresholds vary across different hierarchy levels and label frequencies, comparing the proposed AUC-based evaluation against traditional threshold-based metrics in terms of practical utility for real-world deployment.