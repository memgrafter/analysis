---
ver: rpa2
title: On the Maximal Local Disparity of Fairness-Aware Classifiers
arxiv_id: '2406.03255'
source_url: https://arxiv.org/abs/2406.03255
tags:
- mcdp
- fairness
- disparity
- local
- maximal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a new fairness metric, MCDP(\u03F5), to\
  \ measure the maximal local disparity of model predictions across demographic groups.\
  \ It addresses the limitation of existing metrics like \u2206DP and ABCC, which\
  \ average out extreme local disparities, potentially masking unfairness."
---

# On the Maximal Local Disparity of Fairness-Aware Classifiers

## Quick Facts
- arXiv ID: 2406.03255
- Source URL: https://arxiv.org/abs/2406.03255
- Authors: Jinqiu Jin; Haoxuan Li; Fuli Feng
- Reference count: 40
- Key outcome: Introduces MCDP(ϵ) metric to measure maximal local disparity in fairness-aware classifiers, addressing limitations of existing metrics by capturing worst-case local unfairness

## Executive Summary
This paper addresses a critical limitation in fairness-aware classification by introducing a new metric, MCDP(ϵ), that captures maximal local disparity between demographic groups. Unlike existing metrics that average out extreme disparities, MCDP(ϵ) focuses on the worst-case unfairness within local prediction neighborhoods. The authors develop both exact and approximate algorithms for efficient computation and propose a bi-level optimization framework (DiffMCDP) to train classifiers that minimize this metric while maintaining accuracy.

## Method Summary
The paper proposes MCDP(ϵ) as a fairness metric that measures the maximal cumulative ratio disparity within an ϵ-neighborhood around each prediction point, addressing the limitation of existing metrics that average out extreme local disparities. The authors develop two algorithms for MCDP(ϵ) calculation: an exact O(N²) algorithm and an approximate O(K²/ϵ) algorithm that significantly reduces computational complexity while maintaining accuracy. For training fair classifiers, they propose DiffMCDP, a bi-level optimization algorithm that uses a differentiable approximation of MCDP(0) based on temperature-scaled sigmoid functions. Experiments on tabular (Adult, Bank) and image (CelebA-A, CelebA-W) datasets demonstrate that DiffMCDP achieves superior fairness-accuracy trade-offs compared to existing methods.

## Key Results
- MCDP(ϵ) effectively captures maximal local disparity that existing metrics like ∆DP and ABCC miss by averaging out extreme values
- Approximate MCDP(ϵ) algorithm reduces computational complexity from O(N²) to O(K²/ϵ) while maintaining low estimation error
- DiffMCDP training algorithm achieves consistently better fairness-accuracy trade-offs across all tested datasets compared to baselines (ERM, AdvDebias, DiffDP, FairMixup, DRAlign, DiffABCC)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** MCDP(ϵ) captures maximal local disparity by measuring the minimal CDF difference within an ϵ-neighborhood around each prediction point.
- **Mechanism:** Instead of using exact CDF differences at each prediction, MCDP(ϵ) replaces it with the minimum disparity in a small neighborhood [y₀ - ϵ, y₀ + ϵ]. This smooths sharp distribution changes and focuses on the worst-case local unfairness.
- **Core assumption:** Sharp prediction clusters can cause misleadingly high disparity values; smoothing them reveals true fairness violations.
- **Evidence anchors:**
  - [abstract] "we propose a novel fairness metric called Maximal Cumulative ratio Disparity along varying Predictions' neighborhood (MCDP), for measuring the maximal local disparity"
  - [section] "we take the minimal disparity within its ϵ-neighborhood [y₀ - ϵ, y₀ + ϵ] as the maximal local disparity instead of the exact disparity ∆F(y₀)"
- **Break condition:** If the prediction distribution is uniform across all neighborhoods, MCDP(ϵ) will be small even if global distributions differ.

### Mechanism 2
- **Claim:** The proposed DiffMCDP training algorithm effectively minimizes maximal local disparity by regularizing a differentiable approximation of MCDP(0).
- **Mechanism:** DiffMCDP uses a temperature-scaled sigmoid function to approximate the step-like empirical CDF difference, making the fairness regularization term differentiable. It then performs bi-level optimization to minimize this approximation.
- **Core assumption:** A differentiable approximation of MCDP(0) can be optimized effectively to reduce local disparity while maintaining accuracy.
- **Evidence anchors:**
  - [abstract] "We further propose a bi-level optimization algorithm using differentiable approximation of MCDP(0) to train a fair classifier"
  - [section] "we adopt a differentiable approximation of CDF disparity based on temperature sigmoid function... and then minimize the maximal estimated CDF disparity using the bi-level optimization approach"
- **Break condition:** If the temperature is too low, the approximation becomes too sharp to differentiate; if too high, gradients vanish.

### Mechanism 3
- **Claim:** The approximate MCDP(ϵ) calculation algorithm significantly reduces computational complexity while maintaining estimation accuracy.
- **Mechanism:** Instead of traversing all possible prediction points, the algorithm samples K equally-spaced points and finds the minimum CDF disparity within each 2K-point window, reducing complexity from O(N²) to O(K²/ϵ).
- **Core assumption:** Sampling prediction points at frequency ϵ/K captures the essential structure of the CDF disparity without exhaustive search.
- **Evidence anchors:**
  - [abstract] "we develop a provably exact and an approximate calculation algorithm that greatly reduces the computational complexity with low estimation error"
  - [section] "the approximate algorithm firstly samples prediction points that are equally spaced by ϵ/K on [0,1]"
- **Break condition:** If K is too small relative to the density of prediction clusters, important local disparities may be missed.

## Foundational Learning

- **Concept:** Empirical Distribution Function (EDF)
  - **Why needed here:** MCDP(ϵ) is defined in terms of CDFs of model predictions across demographic groups, which must be estimated from finite samples using EDFs.
  - **Quick check question:** How does the EDF differ from the theoretical CDF, and why does the Glivenko-Cantelli theorem matter for MCDP(ϵ) estimation?

- **Concept:** Lipschitz Continuity
  - **Why needed here:** The theoretical analysis of MCDP(ϵ) bounds its relationship to ABCC using the Lipschitz constant of the CDF difference function.
  - **Quick check question:** What does it mean for a function to be Lipschitz continuous, and how does this property enable the upper bound relationship between MCDP(ϵ) and ABCC?

- **Concept:** Bi-level Optimization
  - **Why needed here:** The DiffMCDP training algorithm uses bi-level optimization to first find the prediction with maximal CDF disparity, then optimize model parameters to minimize this disparity.
  - **Quick check question:** What distinguishes bi-level optimization from standard optimization, and why is this approach necessary for training with MCDP(0) as a regularization term?

## Architecture Onboarding

- **Component map:** Data → Model Predictions → EDF Calculation → MCDP(ϵ) Metric → Differentiable Approximation → Bi-level Optimization → Fair Model
- **Critical path:** Data → Model Predictions → EDF Calculation → MCDP(ϵ) Metric → Differentiable Approximation → Bi-level Optimization → Fair Model
- **Design tradeoffs:**
  - Exact vs Approximate MCDP(ϵ) calculation: accuracy vs computational efficiency
  - Temperature τ in DiffMCDP: estimation accuracy vs gradient magnitude
  - Neighborhood size ϵ: sensitivity to local disparities vs robustness to noise
- **Failure signatures:**
  - MCDP(ϵ) values near zero despite obvious unfairness: may indicate uniform prediction distributions
  - Training instability in DiffMCDP: likely temperature τ is improperly set
  - Excessive computation time: may need to switch from exact to approximate MCDP(ϵ) calculation
- **First 3 experiments:**
  1. Implement MCDP(ϵ) calculation on synthetic data with known local disparities to verify it captures extreme local differences better than ∆DP and ABCC
  2. Compare computational runtime of exact vs approximate MCDP(ϵ) algorithms across varying K and ϵ values
  3. Train DiffMCDP on Adult dataset with different temperature τ values to find optimal trade-off between fairness and accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- The DiffMCDP algorithm shows high sensitivity to the temperature parameter τ, with optimal values varying significantly between datasets
- While the approximate MCDP(ϵ) algorithm shows computational efficiency gains, the theoretical error bounds could be tighter
- The trade-off between estimation accuracy and computational savings in the approximate algorithm is not fully characterized

## Confidence

- **High confidence:** The theoretical foundations of MCDP(ϵ) as a metric capturing maximal local disparity, including its relationship to ABCC and ∆DP through Lipschitz continuity arguments.
- **Medium confidence:** The effectiveness of the approximate MCDP(ϵ) algorithm, as the theoretical error analysis is sound but practical performance depends heavily on the sampling parameter K.
- **Medium confidence:** The DiffMCDP training algorithm's ability to minimize maximal local disparity, though results show sensitivity to temperature τ and bi-level optimization stability.

## Next Checks

1. **Hyperparameter sensitivity analysis:** Systematically vary the temperature τ parameter in DiffMCDP across all datasets to map the full fairness-accuracy trade-off landscape and identify regions of stable performance.

2. **Robustness to prediction distribution:** Test MCDP(ϵ) on synthetic datasets where prediction distributions are deliberately manipulated (uniform, bimodal, skewed) to verify it captures true local disparities rather than being confounded by global distribution differences.

3. **Comparison with alternative smoothing approaches:** Implement and compare DiffMCDP against other differentiable fairness regularizers (e.g., using different smoothing functions or optimization strategies) to isolate the contribution of the MCDP(ϵ) metric itself versus the training methodology.