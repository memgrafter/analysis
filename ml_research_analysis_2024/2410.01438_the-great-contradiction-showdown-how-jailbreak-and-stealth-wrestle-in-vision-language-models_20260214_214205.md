---
ver: rpa2
title: 'The Great Contradiction Showdown: How Jailbreak and Stealth Wrestle in Vision-Language
  Models?'
arxiv_id: '2410.01438'
source_url: https://arxiv.org/abs/2410.01438
tags:
- jailbreak
- image
- attacks
- e-02
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the trade-off between jailbreak attack
  effectiveness and stealthiness in Vision-Language Models (VLMs) through an information-theoretic
  lens. The authors introduce algorithms to detect non-stealthy jailbreak attacks
  using entropy and perplexity gaps, and propose a stealthiness-aware attack method
  leveraging diffusion models.
---

# The Great Contradiction Showdown: How Jailbreak and Stealth Wrestle in Vision-Language Models?

## Quick Facts
- arXiv ID: 2410.01438
- Source URL: https://arxiv.org/abs/2410.01438
- Authors: Ching-Chia Kao; Chia-Mu Yu; Chun-Sien Lu; Chu-Song Chen
- Reference count: 40
- Primary result: Jailbreak effectiveness is inversely related to stealthiness in VLMs, with typography playing a critical role in bypassing safety detection

## Executive Summary
This paper investigates the fundamental trade-off between jailbreak attack effectiveness and stealthiness in Vision-Language Models (VLMs) through an information-theoretic lens. The authors establish that successful jailbreak attacks inherently become more detectable, quantified through Fano's inequality, and demonstrate that typographic content is particularly effective at bypassing safety mechanisms. They propose a detection framework using entropy and perplexity gaps, along with a stealthiness-aware attack method leveraging diffusion models. Experiments across multiple VLMs show their detection method significantly outperforms prior approaches while their attack maintains reasonable success rates with improved stealthiness.

## Method Summary
The method employs an information-theoretic framework using Fano's inequality to quantify the relationship between jailbreak success rates and stealthiness scores. The detection algorithm calculates entropy and perplexity gaps between attack and natural content, rejecting samples that exceed thresholds. For attacks, the system uses keyword extraction (RAKE or LLM-based), story generation, typography design, and diffusion model synthesis to create jailbreak content that passes entropy gap checks. The approach is evaluated on VLMs including LLaVA, MiniGPT-4, and InstructBLIP using SafeBench and Li et al. datasets, measuring Attack Success Rate (ASR), AUROC, F1 scores, and toxicity metrics.

## Key Results
- Detection method achieves AUROC of 0.45-0.96 and F1 scores of 0.52-0.93 across different scenarios
- Stealthiness-aware attack maintains ASR of 0.17-0.39 on LLaVA while being more difficult to detect than competing methods
- Typography proves critical for jailbreak effectiveness, creating a perceptual gap between human and model understanding
- Entropy gap detection successfully identifies non-stealthy jailbreak attempts across both text and image domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Jailbreak effectiveness is inversely related to stealthiness due to information-theoretic constraints captured by Fano's inequality
- Mechanism: Fano's inequality establishes a lower bound on error probability that increases as the mutual information between attack content and jailbreak target decreases
- Core assumption: Attack success probability depends on the model's ability to distinguish between natural and jailbroken content based on information-theoretic measures
- Evidence anchors: Theoretical framework demonstrates how success probability is intrinsically linked to stealthiness through entropy gaps

### Mechanism 2
- Claim: Typography serves as a critical jailbreak vector that bypasses OCR-based safety detection while remaining perceptible to the model
- Mechanism: Typographic text triggers the model's OCR capability in ways that can bypass text-based safety filters while the visual presentation remains effective for jailbreaking
- Core assumption: VLMs process visual text content differently than natural text, creating a perceptual gap exploitable for jailbreaking
- Evidence anchors: Experiments show typographic content plays a crucial role in jailbreak effectiveness across multiple VLM architectures

### Mechanism 3
- Claim: Diffusion model-generated content can evade entropy-based detection while maintaining jailbreak effectiveness
- Mechanism: Diffusion models produce images with controlled entropy characteristics that match natural content patterns, making detection difficult while preserving jailbreak capability through typographic overlay
- Core assumption: The entropy gap between attack and natural content is a reliable indicator of stealthiness
- Evidence anchors: Proposed stealthiness-aware attack method leverages diffusion models to generate content that passes entropy gap checks while maintaining jailbreak capability

## Foundational Learning

- Concept: Information Theory and Fano's Inequality
  - Why needed here: Provides the theoretical framework for understanding the fundamental trade-off between attack effectiveness and stealthiness
  - Quick check question: How does Fano's inequality relate the error probability to conditional entropy in classification problems?

- Concept: Vision-Language Model Architecture
  - Why needed here: Understanding how VLMs process multimodal inputs is crucial for designing effective jailbreak attacks and detection methods
  - Quick check question: What are the key components in typical VLM architectures that make them vulnerable to jailbreak attacks?

- Concept: Entropy and Perplexity Measures
  - Why needed here: These metrics serve as the basis for detecting non-stealthy jailbreak attacks in both text and image domains
  - Quick check question: How do entropy and perplexity differ in their application to image vs. text content analysis?

## Architecture Onboarding

- Component map: Keyword extraction (RAKE/LLM) -> Story generation (text-to-text) -> Typography design (text-to-image overlay) -> Diffusion synthesis (image generation) -> Entropy gap checker (detection) -> VLM interface (attack target)

- Critical path: Keyword extraction → Story generation → Typography design → Diffusion synthesis → Entropy gap validation → VLM attack

- Design tradeoffs:
  - Speed vs. stealth: RAKE keyword extraction is faster but potentially less effective than LLM-based extraction
  - Image quality vs. detectability: Higher-quality images may be more detectable through entropy analysis
  - Typography opacity vs. effectiveness: More visible typography may be more effective but also more detectable

- Failure signatures:
  - High entropy gap values trigger rejection
  - Low CLIP scores between keywords and generated content
  - LLM-as-judge scores below threshold indicate unsuccessful jailbreak

- First 3 experiments:
  1. Test entropy gap detection on known jailbreak vs. natural images to validate Algorithm 1
  2. Compare RAKE vs. LLM keyword extraction effectiveness on sample prompts
  3. Evaluate typography overlay methods (diffusion vs. blending) for jailbreak success rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the perceptual gap between human and model understanding of visual content extend beyond typography to other visual elements like texture, color, or composition?
- Basis in paper: The paper raises this question in the discussion section, noting that VLMs successfully jailbreak regardless of whether they use OCR or image understanding, suggesting a potential perceptual gap.
- Why unresolved: The paper only tested typography-based attacks and didn't systematically investigate other visual elements that might create similar perceptual gaps.
- What evidence would resolve it: A systematic study testing jailbreak effectiveness using various visual elements (texture patterns, color schemes, compositional arrangements) while measuring human and model detection rates.

### Open Question 2
- Question: How does the stealthiness of jailbreak attacks scale with the number of modalities (e.g., text, image, audio, video) beyond the two-modality case studied?
- Basis in paper: The remark section mentions that "as the number of modalities increases (more Yi), the likelihood of jailbreak success rises," suggesting a relationship that wasn't fully explored.
- Why unresolved: The theoretical framework and experiments focused only on text and image modalities, leaving open questions about multi-modal extensions.
- What evidence would resolve it: Empirical studies testing jailbreak effectiveness across increasing numbers of modalities (e.g., text+image, text+image+audio) while measuring both success rates and detectability.

### Open Question 3
- Question: What is the relationship between the specific vocabulary size of prohibited content and the theoretical bounds on jailbreak success rates?
- Basis in paper: The remark section notes that "the denominator depends on the cardinality of the possible jailbreaking alphabet sets," indicating this relationship is theoretically understood but not empirically validated.
- Why unresolved: While the paper establishes a theoretical relationship, it doesn't empirically test how different vocabulary sizes affect actual jailbreak success rates in practice.
- What evidence would resolve it: Controlled experiments varying the size of prohibited keyword lists while measuring corresponding changes in jailbreak success rates and detection difficulty.

## Limitations

- The theoretical framework based on Fano's inequality may oversimplify the complex decision processes in modern VLMs
- Empirical validation relies on specific datasets that may not represent the full diversity of real-world harmful prompts
- Diffusion model-based attack generation process has significant hyperparameters that could affect results but are not fully specified

## Confidence

**High Confidence**: The detection framework using entropy and perplexity gaps is well-grounded in established information theory principles. The experimental methodology for measuring AUROC and F1 scores follows standard practices in the field.

**Medium Confidence**: The theoretical connection between Fano's inequality and jailbreak effectiveness is mathematically sound but may oversimplify the complex multimodal processing in VLMs. The practical effectiveness of the proposed stealth-aware attack method depends heavily on implementation details not fully specified.

**Low Confidence**: The claim about typography being a "critical" jailbreak vector is supported by experimental results but lacks a mechanistic explanation for why typographic content specifically bypasses safety mechanisms more effectively than other visual patterns.

## Next Checks

1. **Robustness Testing**: Evaluate the detection algorithm across a broader range of VLM architectures and datasets beyond LLaVA, MiniGPT-4, and InstructBLIP to assess generalizability.

2. **Parameter Sensitivity Analysis**: Systematically vary key hyperparameters in the diffusion model-based attack generation (e.g., guidance scale, number of denoising steps) to understand their impact on the stealthiness-effectiveness trade-off.

3. **Human Evaluation Study**: Conduct a human perception study comparing