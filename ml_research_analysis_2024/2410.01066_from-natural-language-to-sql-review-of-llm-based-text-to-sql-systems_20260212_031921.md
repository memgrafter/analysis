---
ver: rpa2
title: 'From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems'
arxiv_id: '2410.01066'
source_url: https://arxiv.org/abs/2410.01066
tags:
- text-to-sql
- systems
- arxiv
- query
- schema
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive review of LLM-based text-to-SQL
  systems, tracing their evolution from rule-based methods to advanced LLM approaches
  with Retrieval Augmented Generation (RAG). The paper introduces a taxonomy classifying
  methods into in-context learning, fine-tuning, and RAG-based systems, with detailed
  categorization of techniques within each approach.
---

# From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems

## Quick Facts
- arXiv ID: 2410.01066
- Source URL: https://arxiv.org/abs/2410.01066
- Reference count: 40
- Primary result: Comprehensive review of LLM-based Text-to-SQL systems, introducing taxonomy and exploring RAG and Graph RAG approaches

## Executive Summary
This survey provides a comprehensive review of LLM-based Text-to-SQL systems, tracing their evolution from rule-based methods to advanced approaches using Retrieval Augmented Generation (RAG). The paper introduces a taxonomy classifying methods into in-context learning, fine-tuning, and RAG-based systems, with detailed categorization of techniques within each approach. Key findings include RAG's effectiveness in addressing limitations like schema understanding, linguistic ambiguity, and domain generalization through dynamic knowledge retrieval.

## Method Summary
The survey analyzes existing Text-to-SQL literature through systematic review and taxonomy construction. The authors classify approaches into three main categories: in-context learning (prompt-based), fine-tuning (parameter updates), and RAG-based systems. They examine each category's mechanisms, advantages, and limitations, with particular focus on RAG and Graph RAG implementations. The study evaluates these approaches using established benchmarks (Spider, BIRD, WikiSQL) and metrics (EM, EX, VES), synthesizing findings from multiple sources to provide comprehensive coverage of the field.

## Key Results
- RAG systems significantly improve Text-to-SQL accuracy by dynamically retrieving schema-specific information during query processing
- Graph RAG enhances schema understanding through knowledge graph construction from database schemas
- Fine-tuning LLM parameters with task-specific datasets improves SQL generation accuracy by adapting models to domain-specific patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retrieval-Augmented Generation (RAG) improves Text-to-SQL accuracy by dynamically fetching schema-specific information during query processing.
- Mechanism: RAG combines a retrieval module that fetches relevant schema metadata, table relationships, and query examples from external sources with a generative module that produces SQL queries. This allows the system to use real-time context rather than relying solely on the LLM's pre-trained knowledge.
- Core assumption: Schema information and query examples retrieved dynamically will be relevant and accurately integrated into the generation process to improve SQL accuracy.
- Evidence anchors:
  - [abstract]: "LLMs when used with Retrieval Augmented Generation (RAG), are greatly improving the SOTA of translating natural language queries to structured and correct SQL."
  - [section]: "RAG systems combine two key components: A Retrieval Module that dynamically fetches relevant schema details, SQL query template, or domain-specific knowledge from structured and/or unstructured sources like documents [6]."
  - [corpus]: Weak evidence - the corpus mentions related works but does not directly support the specific mechanism of RAG improving accuracy through dynamic schema retrieval.
- Break condition: If retrieved information is irrelevant, outdated, or incorrectly integrated into the SQL generation process, the system's accuracy will degrade.

### Mechanism 2
- Claim: Graph RAG enhances Text-to-SQL systems by constructing a knowledge graph from database schemas, improving schema understanding and query accuracy.
- Mechanism: Graph RAG builds a structured knowledge graph from raw data, organizing schema elements into a hierarchical structure. It uses graph-based relationships between tables, columns, and entities to improve schema linking and retrieval accuracy for SQL generation.
- Core assumption: Graph-based representation of schema information provides more accurate and complete relationships than flat schema descriptions, leading to better SQL generation.
- Evidence anchors:
  - [abstract]: "Also, we uniquely study the use of Graph RAGs for better contextual accuracy and schema linking in these systems."
  - [section]: "Graph RAG [33] offers a structured and hierarchical approach to Retrieval-Augmented Generation (RAG), making it a promising solution for Text-to-SQL tasks. Unlike traditional semantic search methods that rely solely on text-based retrieval, Graph RAG constructs a knowledge graph from raw data..."
  - [corpus]: Weak evidence - the corpus does not directly support the specific mechanism of Graph RAG improving accuracy through knowledge graph construction.
- Break condition: If the graph construction process fails to capture important schema relationships or becomes too computationally expensive, the benefits of Graph RAG will be diminished.

### Mechanism 3
- Claim: Fine-tuning LLM parameters with task-specific datasets improves SQL generation accuracy by adapting the model to domain-specific patterns.
- Mechanism: Fine-tuning updates the model's internal parameters using task-specific datasets containing pairs of natural language questions and SQL queries. This allows the model to learn patterns specific to SQL generation, such as understanding database schema and query syntax.
- Core assumption: The task-specific dataset contains high-quality examples that represent the target domain well, and the fine-tuning process effectively updates the model's parameters to capture these patterns.
- Evidence anchors:
  - [section]: "Fine-tuning involves refining the model's internal parameters, θ, using task-specific datasets. Unlike in-context learning methods, where the model's parameters remain fixed and prompts are the primary mechanism of control, fine-tuning updates the model's parameters based on examples from the target task."
  - [section]: "Mathematically, the outcome of this process is represented as a function g: θ′ = g(θ, D) (2) where θ is the pre-trained model's parameters, D is the task-specific dataset (pair of questions and SQL queries) and θ′ represents the updated parameters after fine-tuning [79]."
  - [corpus]: Weak evidence - the corpus mentions related works but does not directly support the specific mechanism of fine-tuning improving accuracy through parameter updates.
- Break condition: If the task-specific dataset is too small, biased, or not representative of the target domain, the fine-tuning process may not improve accuracy or could even degrade performance.

## Foundational Learning

- Concept: Natural Language Processing (NLP)
  - Why needed here: Text-to-SQL systems must understand and process natural language queries to translate them into SQL, requiring NLP techniques for parsing, semantic understanding, and context extraction.
  - Quick check question: What are the main challenges in processing natural language queries for database applications, and how do these differ from general NLP tasks?

- Concept: Database Schema Understanding
  - Why needed here: Text-to-SQL systems must map natural language queries to the correct database schema elements (tables, columns, relationships) to generate accurate SQL queries, requiring deep understanding of schema structure and semantics.
  - Quick check question: How do Text-to-SQL systems handle schema variations across different databases, and what techniques are used to map natural language entities to schema elements?

- Concept: Large Language Models (LLMs)
  - Why needed here: Modern Text-to-SQL systems rely on LLMs for their ability to understand complex natural language queries and generate SQL code, requiring knowledge of LLM architectures, training processes, and fine-tuning techniques.
  - Quick check question: What are the key differences between traditional NLP models and LLMs in the context of Text-to-SQL tasks, and how do these differences impact system performance?

## Architecture Onboarding

- Component map: Input Processing -> Schema Mapping -> SQL Generation -> Execution -> RAG Integration -> Graph Construction

- Critical path:
  1. Receive natural language query
  2. Parse query for entities, conditions, and relationships
  3. Map query components to database schema using schema linking
  4. Generate SQL query using LLM with or without RAG augmentation
  5. Execute SQL query on database
  6. Return results to user

- Design tradeoffs:
  - Accuracy vs. speed: RAG systems provide better accuracy but introduce retrieval latency
  - Static vs. dynamic schemas: Fine-tuned models work well for static schemas but struggle with dynamic changes
  - Complexity vs. maintainability: Graph RAG offers better accuracy but increases system complexity
  - General vs. domain-specific: Zero-shot learning is more general but less accurate than fine-tuned approaches

- Failure signatures:
  - Incorrect schema mapping: Generated SQL references wrong tables or columns
  - Ambiguous query interpretation: System cannot resolve multiple possible meanings
  - Performance degradation: Query execution takes too long or times out
  - Hallucination: System generates SQL for non-existent schema elements
  - Context loss: System fails to maintain conversational context in multi-turn interactions

- First 3 experiments:
  1. Test zero-shot SQL generation on simple queries using a pre-trained LLM without any fine-tuning or RAG augmentation
  2. Evaluate RAG-enhanced SQL generation on complex queries requiring dynamic schema retrieval and context
  3. Compare performance of fine-tuned LLM vs. RAG-based approach on domain-specific queries with complex schemas

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Graph RAG systems be optimized for real-time schema adaptation as databases evolve?
- Basis in paper: [inferred] The paper mentions that current systems are inefficient in adapting to dynamic, evolving databases without full retraining, which is a limitation for realistic databases that frequently experience schema changes.
- Why unresolved: Real-time schema adaptation requires efficient incremental learning and flexible architectures that can seamlessly update LLMs and Knowledge Graphs (KGs) without losing accuracy.
- What evidence would resolve it: Empirical studies demonstrating Graph RAG systems that can maintain high accuracy in SQL query generation while dynamically updating their graph structures in response to schema changes, particularly in environments with frequent updates.

### Open Question 2
- Question: What are the most effective strategies for balancing Retrieval-Augmented Generation (RAG) and fine-tuning in text-to-SQL systems?
- Basis in paper: [explicit] The paper discusses the balance between RAG and fine-tuning as an area to be explored, with potential future systems leveraging the strengths of both approaches to minimize training time while maintaining context-sensitive query generation.
- Why unresolved: Determining the optimal balance between RAG and fine-tuning involves understanding the trade-offs between computational efficiency, context sensitivity, and training requirements.
- What evidence would resolve it: Comparative studies evaluating the performance of text-to-SQL systems using different combinations of RAG and fine-tuning, with metrics on accuracy, efficiency, and adaptability across various domains and query complexities.

### Open Question 3
- Question: How can Graph RAG systems be extended to support multi-lingual or cross-lingual text-to-SQL queries effectively?
- Basis in paper: [explicit] The paper suggests extending Graph RAG to support multi-lingual or cross-lingual queries, making it effective for use in a wide number of global use cases.
- Why unresolved: Implementing multi-lingual support requires incorporating language-specific knowledge and translation mechanisms into the graph, which is complex and context-dependent.
- What evidence would resolve it: Development and evaluation of Graph RAG systems that can accurately generate SQL queries from natural language queries in multiple languages, with benchmarks demonstrating performance across diverse linguistic contexts and database schemas.

## Limitations
- The review relies heavily on synthesizing existing literature rather than providing original empirical validation
- Effectiveness of Graph RAG and specific RAG implementations remains largely theoretical with limited quantitative comparisons
- The survey does not address real-world deployment challenges such as handling schema changes in production environments

## Confidence
- High confidence: The taxonomy classification of Text-to-SQL approaches (in-context learning, fine-tuning, RAG) is well-supported by existing literature
- Medium confidence: Claims about RAG improving accuracy through dynamic schema retrieval are supported by general RAG literature but lack direct experimental evidence
- Low confidence: The unique contribution regarding Graph RAG's superiority for schema linking and contextual accuracy is based on theoretical reasoning rather than empirical validation

## Next Checks
1. **Empirical Comparison Study**: Conduct controlled experiments comparing zero-shot, fine-tuned, and RAG-based Text-to-SQL systems on standardized benchmarks (Spider, BIRD) to quantify the actual performance gains from each approach, including execution time and accuracy metrics.

2. **Graph RAG Implementation Validation**: Implement a Graph RAG system for Text-to-SQL and evaluate its performance against traditional RAG approaches on complex schema understanding tasks, measuring improvements in schema linking accuracy and SQL generation quality.

3. **Real-World Deployment Assessment**: Deploy representative Text-to-SQL systems (fine-tuned vs. RAG-based) in a production environment with dynamic schemas to evaluate practical challenges including schema adaptation, query latency, and maintenance overhead over time.