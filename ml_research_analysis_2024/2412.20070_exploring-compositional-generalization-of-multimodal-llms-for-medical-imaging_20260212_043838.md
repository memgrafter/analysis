---
ver: rpa2
title: Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging
arxiv_id: '2412.20070'
source_url: https://arxiv.org/abs/2412.20070
tags:
- classification
- diseases
- data
- x-ray
- lung
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates compositional generalization (CG) in multimodal
  large language models (MLLMs) for medical imaging. It introduces Med-MAT, a dataset
  of 106 medical datasets structured by modality, anatomical area, and task, enabling
  exploration of CG through novel element recombination.
---

# Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging

## Quick Facts
- arXiv ID: 2412.20070
- Source URL: https://arxiv.org/abs/2412.20070
- Authors: Zhenyang Cai; Junying Chen; Rongsheng Wang; Weihong Wang; Yonglin Deng; Dingjie Song; Yize Chen; Zixu Zhang; Benyou Wang
- Reference count: 40
- Primary result: MLLMs leverage compositional generalization to understand unseen medical images by recombining learned elements across modality, anatomical area, and task

## Executive Summary
This paper investigates compositional generalization (CG) in multimodal large language models (MLLMs) for medical imaging through the introduction of Med-MAT, a dataset of 106 medical datasets structured by modality, anatomical area, and task. The authors demonstrate that MLLMs can leverage CG to understand unseen medical images by recombining learned elements, with CG identified as a key driver of generalization in multi-task training rather than simply data volume. The research shows that CG improves performance on limited data and extends across both classification and detection tasks, enabling data-efficient training and broader generalization in medical MLLM applications.

## Method Summary
The study constructs the Med-MAT dataset by categorizing 106 medical datasets into MAT-Triplets (Modality, Anatomical area, Task) and converting them to Visual Question Answering (VQA) format. MLLMs are fine-tuned on subsets of Med-MAT, with experiments designed to evaluate CG through training on related versus unrelated data combinations. The evaluation framework tests model performance on target subsets to assess generalization capabilities, with direction types (fixed modality, fixed area, fixed task, modality-area pairs) defining experimental conditions that test different aspects of compositional reasoning.

## Key Results
- MLLMs achieve compositional generalization by recombining learned elements across MAT-Triplets to understand unseen medical images
- CG is identified as a key driver of generalization in multi-task training, outperforming approaches based solely on data volume
- CG enables data-efficient training, improving performance when target data is limited across both classification and detection tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MLLMs leverage compositional generalization to understand unseen medical images by recombining learned elements (Modality, Anatomical area, Task).
- Mechanism: The model learns fundamental visual and semantic elements across multiple datasets and generalizes to novel combinations by reassembling these elements in new ways.
- Core assumption: Medical images can be decomposed into distinct, reusable elements that map to the MAT-Triplet structure.
- Evidence anchors:
  - [abstract] "MLLMs can use CG to understand unseen medical images"
  - [section 3.2] "almost all CG combinations are able to generalize to downstream tasks"
  - [corpus] Weak - no direct discussion of compositional generalization mechanisms in cited papers
- Break condition: If MAT-Triplet elements cannot be meaningfully separated or if visual similarities across different triplets create spurious correlations.

### Mechanism 2
- Claim: CG is a key driver of generalization in multi-task training, not just data volume.
- Mechanism: Multi-task training exposes the model to diverse combinations of MAT-Triplet elements, enabling it to learn transferable patterns rather than memorizing specific dataset combinations.
- Core assumption: Generalization improvements from multi-task training stem from compositional reasoning rather than simple task diversity.
- Evidence anchors:
  - [abstract] "identified CG as one of the main drivers of the generalization observed in multi-task training"
  - [section 4.2] "All Related achieves a performance level comparable to All Data" showing CG's central role
  - [corpus] Weak - related papers focus on benchmarks rather than underlying generalization mechanisms
- Break condition: If task-specific features dominate over compositional elements, or if the model learns to ignore MAT-Triplet structure entirely.

### Mechanism 3
- Claim: CG enables data-efficient training by allowing models to leverage related datasets for tasks with limited data.
- Mechanism: When target data is scarce, related datasets sharing MAT-Triplet elements provide compositional building blocks that accelerate learning on the target task.
- Core assumption: Related datasets provide meaningful compositional elements rather than redundant information.
- Evidence anchors:
  - [abstract] "CG effectively supports datasets with limited data"
  - [section 5.2] "CG helps data efficiency for MLLM training" by accelerating performance with limited target data
  - [corpus] Weak - no direct evidence about data efficiency in cited papers
- Break condition: If related datasets provide conflicting or noisy compositional signals that confuse rather than help the model.

## Foundational Learning

- Concept: MAT-Triplet structure (Modality, Anatomical area, Task)
  - Why needed here: Provides the compositional framework that enables CG by defining how medical images can be decomposed into reusable elements
  - Quick check question: Can you explain why CT images of lungs for cancer detection and X-ray images of bones for fracture detection share compositional elements?

- Concept: Visual Question Answering (VQA) format conversion
  - Why needed here: Transforms diverse medical image-label datasets into a unified format compatible with MLLM training pipelines
  - Quick check question: How does converting classification datasets to multiple-choice VQA format enable compositional generalization experiments?

- Concept: Direction Types in CG experiments
  - Why needed here: Defines the experimental conditions (fixed modality, fixed area, fixed task, modality-area pairs) that test different aspects of compositional reasoning
  - Quick check question: What would be the difference between fixing only modality versus fixing modality-area pairs in CG experiments?

## Architecture Onboarding

- Component map: Raw datasets → MAT-Triplet annotation → VQA conversion → training subsets → MLLM training → evaluation framework
- Critical path: MAT-Triplet annotation → subset creation → CG experiment design → training → generalization evaluation
- Design tradeoffs: Dataset coverage vs. annotation quality, VQA complexity vs. model capability, training data volume vs. compositional diversity
- Failure signatures: Poor MAT-Triplet separation, inconsistent label clustering, VQA format errors, CG not improving over baseline
- First 3 experiments:
  1. Verify MAT-Triplet annotation consistency by manually checking 10 random samples from each modality
  2. Test VQA conversion by training a small model on a single subset and verifying it answers correctly
  3. Run a simple CG experiment with one fixed element (e.g., fixed modality) to confirm the basic mechanism works

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does compositional generalization interact with domain shift in medical imaging datasets, particularly when MAT-Triplet elements originate from different sources or distributions?
- Basis in paper: Explicit - The paper mentions controlled experiments where MAT-Triplet elements came from different datasets (Section A.4), but doesn't systematically explore domain shift effects.
- Why unresolved: The experiments focus on compositional generalization success rates but don't analyze how dataset characteristics (domain shift, distribution differences) affect generalization performance.
- What evidence would resolve it: Systematic experiments varying dataset characteristics (domain shift, distribution differences) while holding compositional structure constant, measuring generalization performance changes.

### Open Question 2
- Question: Can compositional generalization be effectively applied to rare disease detection in medical imaging, and what are the limitations when training data for individual compositional elements is scarce?
- Basis in paper: Inferred - Section 5.2 discusses generalization with limited target data, but doesn't specifically address rare diseases or element scarcity.
- Why unresolved: The paper shows CG helps with limited data but doesn't explore extreme scarcity scenarios or provide guidelines for when CG breaks down.
- What evidence would resolve it: Experiments systematically varying element scarcity levels, measuring CG effectiveness and identifying failure thresholds.

### Open Question 3
- Question: How does compositional generalization scale with increasing task complexity and multi-label classification in medical imaging, beyond the binary/multi-class scenarios explored?
- Basis in paper: Explicit - The paper mentions "Multiple Classification" tasks but focuses primarily on binary/multi-class scenarios (Section B.1).
- Why unresolved: The experiments don't explore complex multi-label scenarios where multiple compositional elements must be identified simultaneously.
- What evidence would resolve it: Experiments with complex multi-label datasets requiring simultaneous identification of multiple compositional elements, measuring CG performance degradation.

## Limitations
- Dataset Composition Uncertainty: The core premise depends on MAT-Triplet annotation quality across 106 datasets, but lacks details on inter-annotator agreement or validation procedures.
- Transfer Mechanism Ambiguity: The specific compositional elements that transfer between tasks remain underspecified, with the mechanism not empirically demonstrated at the feature level.
- Evaluation Scope Limitation: Experiments focus on held-out test sets from the same domain as training data, with claims about broad generalization extending beyond empirical evidence.

## Confidence
- **High Confidence**: MLLMs can achieve compositional generalization when trained on diverse medical datasets with clear MAT-Triplet structure. The empirical results show consistent improvements across multiple experimental conditions.
- **Medium Confidence**: CG is a key driver of multi-task training generalization (not just data volume). While results show Related > Unrelated training improves performance, the relative contribution of CG versus other factors like task diversity remains unclear.
- **Low Confidence**: CG enables broad generalization to truly unseen medical imaging tasks outside the Med-MAT framework. The paper provides limited evidence for generalization beyond the specific MAT-Triplet structure it defines.

## Next Checks
1. **MAT-Triplet Validation**: Conduct ablation studies removing CG-related datasets to quantify the specific contribution of compositional generalization versus general multi-task learning effects. Compare performance degradation when removing CG elements versus removing random elements.

2. **Cross-Domain Transfer**: Test model generalization on medical imaging datasets that don't fit the MAT-Triplet structure (e.g., ultrasound, pathology slides) to validate claims about broad applicability beyond the curated Med-MAT ecosystem.

3. **Feature-Level Analysis**: Perform feature attribution studies to identify which specific compositional elements (modality features, anatomical features, task features) drive generalization improvements, rather than treating CG as a monolithic phenomenon.