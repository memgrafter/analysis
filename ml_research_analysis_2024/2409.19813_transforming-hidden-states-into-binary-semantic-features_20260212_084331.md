---
ver: rpa2
title: Transforming Hidden States into Binary Semantic Features
arxiv_id: '2409.19813'
source_url: https://arxiv.org/abs/2409.19813
tags:
- component
- components
- words
- word
- hidden
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to interpret the hidden states of
  large language models using Independent Component Analysis (ICA) to transform them
  into binary semantic features. The authors apply ICA to hidden states from Llama
  3 models, binarize the resulting components, and show that these binary vectors
  represent interpretable semantic features.
---

# Transforming Hidden States into Binary Semantic Features

## Quick Facts
- arXiv ID: 2409.19813
- Source URL: https://arxiv.org/abs/2409.19813
- Authors: Tomáš Musil; David Mareček
- Reference count: 40
- This paper proposes a method to interpret the hidden states of large language models using Independent Component Analysis (ICA) to transform them into binary semantic features.

## Executive Summary
This paper presents a novel approach to interpreting large language model (LLM) hidden states by applying Independent Component Analysis (ICA) to transform them into interpretable binary semantic features. The authors extract hidden states from Llama 3 models for 250,000 vocabulary words, apply ICA followed by binarization, and demonstrate that the resulting components represent meaningful semantic concepts. The method reveals diverse semantic domains ranging from music and instruments to pharmaceuticals and pregnancy, showing that ICA can uncover interpretable structure in LLM representations.

## Method Summary
The authors extract hidden states from Llama 3 8B and 70B models for 250,000 vocabulary words generated using a specific sampling prompt. They apply PCA for dimension reduction (512 or 1024 dimensions), then run FastICA on the reduced vectors. The ICA components are normalized and binarized using a threshold parameter t, producing binary semantic features. The method demonstrates that these binary vectors are compositional and interpretable, with component graphs showing semantic relationships. The approach successfully reveals semantic structure present in the training data through a transformation that separates independent components from the mixed hidden state representations.

## Key Results
- ICA successfully transforms LLM hidden states into binary semantic features representing interpretable concepts
- Components capture diverse semantic domains including "Music," "Instruments," "Pharmaceuticals," and "Pregnancy"
- Binary features demonstrate compositional properties, allowing meaningful combinations of semantic concepts
- Component graphs reveal semantic relationships between different concepts in the LLM's learned representations

## Why This Works (Mechanism)
The method works by leveraging Independent Component Analysis to separate mixed hidden state representations into independent, interpretable semantic components. ICA is particularly suited for this task because it can identify statistically independent features in high-dimensional data, effectively "unmixing" the complex representations learned by LLMs into distinct semantic dimensions. The binarization step then creates clear on/off states for each semantic feature, making the interpretation more accessible while preserving the underlying semantic structure. This approach succeeds because LLM hidden states, despite their complexity, contain independent semantic information that can be isolated through proper statistical separation techniques.

## Foundational Learning
- Independent Component Analysis (ICA): A statistical technique for separating mixed signals into independent components, needed to disentangle semantic features from mixed hidden states; quick check: verify components are statistically independent
- FastICA algorithm: An efficient implementation of ICA that maximizes non-Gaussianity to find independent components; needed for computational tractability on large datasets; quick check: monitor convergence of the algorithm
- Principal Component Analysis (PCA): A dimensionality reduction technique used before ICA to reduce computational complexity; needed to handle the high dimensionality of LLM hidden states; quick check: ensure explained variance ratio is acceptable
- Binarization threshold selection: The process of converting continuous ICA components to binary values using a threshold; needed to create interpretable on/off semantic features; quick check: analyze distribution of component values to choose appropriate threshold
- Compositionality analysis: The evaluation of whether semantic features can be meaningfully combined; needed to demonstrate that binary features capture coherent semantic concepts; quick check: test feature combinations on word similarity tasks

## Architecture Onboarding

Component Map:
Hidden States -> PCA -> FastICA -> Binarization -> Interpretable Components

Critical Path:
Vocabulary generation -> Hidden state extraction (Llama 3 layer 8) -> PCA dimension reduction -> FastICA transformation -> Normalization -> Binarization -> Component analysis

Design Tradeoffs:
- PCA dimension choice (512 vs 1024) balances computational efficiency with information retention
- Binarization threshold affects interpretability vs. information preservation tradeoff
- Layer selection for hidden state extraction impacts semantic vs. syntactic feature capture

Failure Signatures:
- Non-interpretable components suggest poor ICA convergence or inappropriate dimension reduction
- Too few non-zero entries after binarization indicates threshold is too high
- Components dominated by single words suggest ICA is not properly separating independent features

First Experiments:
1. Test different PCA dimensions (256, 512, 1024) to find optimal balance for ICA performance
2. Vary binarization thresholds to observe impact on interpretability and component sparsity
3. Apply method to different layers of Llama 3 to compare semantic feature emergence across depths

## Open Questions the Paper Calls Out
- How does the interpretability of ICA components vary across different layers of LLM hidden states? The paper mentions that future work could analyze differences between layers in a single model, but only extracted hidden states from layer 8 of Llama 3 models and did not compare across layers.
- How sensitive are the ICA components to the vocabulary selection method? While the authors used a vocabulary generated from the model itself, they state "Experiments with various corpora showed us that the choice of vocabulary affects the results" but did not systematically test different vocabulary selection methods.
- How transferable are ICA components across different LLM architectures? The paper only tested Llama 3 models and showed similar components from different Llama models in Appendix B, but did not test models from other architectures (e.g., BERT, GPT, Claude) to see if ICA reveals similar semantic features.

## Limitations
- The binarization threshold parameter t is not explicitly specified, which could affect reproducibility of results
- The compositionality claim is supported but could benefit from more quantitative validation measures
- The method was only tested on Llama 3 models, limiting generalizability to other LLM architectures

## Confidence
- Core finding (ICA reveals interpretable semantic features): High
- Precise binarization methodology: Medium (due to unspecified threshold)
- Compositionality claims: Medium (given limited quantitative support)

## Next Checks
1. Reproduce the binarization results using different threshold values to determine sensitivity and optimal parameter settings
2. Quantify compositionality by measuring correlation patterns between component activations across different word sets
3. Validate interpretability through additional human evaluation on a held-out set of components