---
ver: rpa2
title: What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic
  Regular Languages
arxiv_id: '2406.04289'
source_url: https://arxiv.org/abs/2406.04289
tags:
- neural
- dpfsa
- language
- rank
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper empirically investigates what types of distributions
  neural language models can learn by testing their ability to learn distributions
  induced by probabilistic finite-state automata (PFSAs). The key method involves
  sampling 2,100 random PFSAs with varying complexity parameters (number of states,
  alphabet size, and rank of the transition matrix) and training 15,000 RNN and Transformer
  language models on strings generated from these PFSAs.
---

# What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages

## Quick Facts
- arXiv ID: 2406.04289
- Source URL: https://arxiv.org/abs/2406.04289
- Reference count: 40
- Primary result: RNNs outperform Transformers on learning probabilistic regular languages, with learnability strongly predicted by PFSA rank and expected string length

## Executive Summary
This paper empirically investigates what types of distributions neural language models can learn by testing their ability to learn distributions induced by probabilistic finite-state automata (PFSAs). The key method involves sampling 2,100 random PFSAs with varying complexity parameters and training 15,000 RNN and Transformer language models on strings generated from these PFSAs. The learnability is measured using KL divergence between the neural model and the target PFSA distribution. The study finds that both the rank of the PFSA's emission matrix and the expected length of sampled strings are strong predictors of learnability for both RNNs and Transformers, with RNNs generally outperforming Transformers on this task.

## Method Summary
The authors generated 2,100 random probabilistic finite-state automata with systematically varied parameters: number of states (10, 20, or 30), alphabet size (2, 4, or 8), and rank of the transition matrix (2, 4, or 8). From each PFSA, they sampled 100,000 strings with lengths between 1 and 20 tokens. They then trained 15,000 language models (7,500 RNNs and 7,500 Transformers) with varying hidden state sizes on these datasets. Learnability was evaluated using KL divergence between the neural model's distribution and the true PFSA distribution. The study systematically varied model architecture, hidden state size, and PFSA complexity to identify which factors most strongly influence learnability.

## Key Results
- RNNs consistently outperform Transformers on learning PFSA distributions across all tested configurations
- The rank of the PFSA's emission matrix is a strong predictor of learnability for both RNNs and Transformers
- Expected string length is the second strongest predictor of learnability
- Surprisingly, higher entropy in the PFSA distribution correlates negatively with learnability

## Why This Works (Mechanism)
The learnability of PFSA distributions depends on the representational capacity of neural networks relative to the structural complexity of the target distribution. PFSAs generate regular languages with finite memory requirements, making them theoretically learnable by both RNNs and Transformers. The rank of the PFSA's emission matrix determines the minimum hidden state size required for exact representation - neural models need hidden states at least as large as this rank to capture the distribution's structure. The expected string length affects the sample complexity needed to learn the distribution accurately. The negative entropy correlation suggests neural models learn structured distributions more easily than random ones, possibly because structured distributions have more predictable patterns that are easier to capture with limited data.

## Foundational Learning
- **Probabilistic Finite-State Automata**: Weighted finite-state machines that generate probability distributions over strings; needed because they provide a controlled way to study learnability of regular languages; quick check: verify the PFSA's transition and emission matrices sum to 1 for each state
- **KL Divergence**: Measure of difference between two probability distributions; needed as the evaluation metric to quantify how well neural models learn the target distribution; quick check: KL divergence should be 0 when distributions match exactly
- **Rank of Transition Matrix**: The dimension of the column space of the transition matrix; needed because it determines the minimum representational capacity required to model the PFSA; quick check: verify rank calculation using singular value decomposition
- **Expected String Length**: The average length of strings generated by the PFSA; needed because it affects sample complexity and the difficulty of learning long-range dependencies; quick check: calculate from the PFSA's transition structure
- **Hidden State Size**: The dimensionality of the neural network's internal representation; needed because it determines the model's capacity to represent complex distributions; quick check: ensure hidden size is large enough to potentially represent the target PFSA's rank
- **Regular vs. Context-Free Languages**: Regular languages require only finite memory while context-free languages require stack-like memory; needed as theoretical background for understanding PFSA limitations; quick check: verify that the generated languages are indeed regular

## Architecture Onboarding
- **Component Map**: Data Generator -> Neural Model Trainer -> KL Divergence Evaluator -> Analysis Pipeline
- **Critical Path**: PFSA Generation → String Sampling → Model Training → Distribution Evaluation → Statistical Analysis
- **Design Tradeoffs**: Random PFSA generation provides controlled experiments but may not reflect natural language structure; large-scale training enables statistical significance but requires substantial compute resources
- **Failure Signatures**: High KL divergence indicates poor learnability; negative entropy correlation may indicate dataset size effects rather than fundamental learnability properties
- **First Experiments**: 1) Train a small RNN on a low-rank PFSA with short strings; 2) Train a large Transformer on a high-rank PFSA with long strings; 3) Compare learnability across matched entropy distributions with different structural properties

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Focus on PFSAs may not generalize to natural language phenomena involving hierarchical structure or long-range dependencies
- Randomly generated PFSAs may not represent the distributional properties of real-world languages
- Evaluation metric assumes access to true distributions, which is unrealistic for natural language modeling
- Finding that RNNs outperform Transformers requires context as PFSAs lack long-range dependencies where Transformers typically excel

## Confidence
- **High confidence**: RNNs outperform Transformers on PFSA learnability; rank and expected string length are strong predictors
- **Medium confidence**: The negative correlation between entropy and learnability; the rank-based representational bounds
- **Low confidence**: Generalization to natural language learnability; the causal mechanisms behind entropy effects

## Next Checks
1. Test learnability on context-free grammars and mildly context-sensitive languages to assess generalization beyond regular languages
2. Vary dataset sizes systematically to disentangle entropy effects from sample complexity issues
3. Implement control experiments with structured vs. random distributions matched for entropy to isolate the role of structure in learnability