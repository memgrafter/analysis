---
ver: rpa2
title: Solving Epistemic Logic Programs using Generate-and-Test with Propagation
arxiv_id: '2410.22130'
source_url: https://arxiv.org/abs/2410.22130
tags:
- program
- generator
- stable
- epistemic
- programs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a general framework for generate-and-test-based
  solvers for epistemic logic programs, instantiated with different generator and
  tester programs. The framework proves sufficient conditions for correctness and
  introduces a new generator program incorporating epistemic consequence propagation,
  reducing the number of candidates exponentially while incurring only linear overhead.
---

# Solving Epistemic Logic Programs using Generate-and-Test with Propagation

## Quick Facts
- arXiv ID: 2410.22130
- Source URL: https://arxiv.org/abs/2410.22130
- Authors: Jorge Fandinno; Lute Lillo
- Reference count: 13
- Key outcome: New solver achieves ~3.3x speed-up and solves 91% more instances on well-known benchmarks

## Executive Summary
This paper introduces a general framework for generate-and-test-based solvers for epistemic logic programs, instantiated with different generator and tester programs. The framework proves sufficient conditions for correctness and introduces a new generator program incorporating epistemic consequence propagation, reducing the number of candidates exponentially while incurring only linear overhead. A new solver is implemented and experimentally shown to outperform existing solvers by achieving a ~3.3x speed-up and solving 91% more instances on well-known benchmarks.

## Method Summary
The paper presents a general framework for generate-and-test-based solvers for epistemic logic programs. The framework consists of a generator program that produces candidate stable models and a tester program that verifies if these candidates are worldviews. The key innovation is a new generator program (G1) that incorporates epistemic consequence propagation, exponentially reducing the number of candidates while only incurring linear overhead. The framework also introduces a normal form transformation to simplify the handling of subjective literals. The solver is implemented using ASP metaprogramming techniques and the clingo solver.

## Key Results
- New generator program G1 with epistemic propagation reduces candidates exponentially while adding only linear overhead
- Solver achieves ~3.3x speed-up and solves 91% more instances compared to existing solvers
- Sufficient conditions proven for correctness of the generate-and-test framework

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating epistemic consequence propagation in the generator program exponentially reduces the number of candidates to test.
- Mechanism: The generator program (G1) infers epistemic literals (Ka, K¬a) and adds rules to propagate their consequences. These inferred literals eliminate stable models that cannot correspond to any worldview, drastically reducing the search space.
- Core assumption: The epistemic consequences can be computed during generation and correctly constrain the search space.
- Evidence anchors:
  - [abstract] "exponentially reduce the number of candidates that need to be tested while only incurring a linear overhead"
  - [section] "we introduce a new generator program that can exponentially reduce the number of candidates by propagating the consequences of epistemic literals in the generator program"
- Break condition: If the propagation rules are incomplete or incorrect, false negatives (valid worldviews eliminated) will occur, causing the solver to miss solutions.

### Mechanism 2
- Claim: Using the normal form transformation ensures the correctness of the generate-and-test framework for programs with subjective literals.
- Mechanism: The normal form replaces complex subjective literals (K¬a, K¬¬a) with new atoms (na, nna) and corresponding rules, simplifying the solver's logic and enabling uniform treatment of subjective literals.
- Core assumption: The normal form transformation preserves the set of worldviews one-to-one with the original program.
- Evidence anchors:
  - [section] "We can transform any epistemic program Π into a corresponding program in normal form... Theorem 1 shows a one-to-one correspondence between the worldviews of Π and NF(Π)"
  - [section] "This definition of worldview is a rephrasing of the original definition by Gelfond (1994), usually denoted G94"
- Break condition: If the transformation introduces bugs or fails to preserve all epistemic information, the solver will produce incorrect results.

### Mechanism 3
- Claim: The generator and tester programs satisfy sufficient conditions for correctness, ensuring Algorithm 1 finds all worldviews.
- Mechanism: The generator program ensures every worldview has a corresponding stable model, and the tester program verifies candidates are worldviews by checking epistemic consequences. The framework proves these conditions are sufficient.
- Core assumption: The sufficient conditions on generator and tester programs are correctly formulated and implementable.
- Evidence anchors:
  - [abstract] "we prove sufficient conditions on those programs for the correctness of the solvers built using this framework"
  - [section] "Theorem 2 shows the correspondence between the worldviews of Π and members of wv(G(Π), T(Π))"
- Break condition: If the conditions are not truly sufficient (e.g., missing edge cases), some worldviews may be missed or false positives included.

## Foundational Learning

- Concept: Epistemic logic programs and worldviews
  - Why needed here: The solver's correctness depends on correctly identifying worldviews, which are sets of interpretations satisfying epistemic constraints.
  - Quick check question: What is the difference between a stable model and a worldview in epistemic logic programs?

- Concept: Answer Set Programming (ASP) and stable models
  - Why needed here: The generator and tester programs are ASP programs, and the solver relies on computing stable models of these programs.
  - Quick check question: How does the reduct operation in ASP relate to the subjective reduct in epistemic programs?

- Concept: Polynomial hierarchy and computational complexity
  - Why needed here: Epistemic logic programs are ΣP₃-complete, explaining why solver optimization is crucial and why naive approaches are infeasible.
  - Quick check question: Why is determining whether an epistemic program has a worldview ΣP₃-complete, and what does this imply for solver design?

## Architecture Onboarding

- Component map: Normal form transformer -> Generator program (G1) -> Stable model generation -> Tester program (T0) -> Worldview validation -> Return valid worldviews
- Critical path: Normal form transformation → Generate stable models of G1 → For each stable model, check if it satisfies the tester conditions → Build worldview if valid → Return all valid worldviews.
- Design tradeoffs: Using G1 vs G0 involves a linear overhead in grounding but potentially exponential reduction in the number of candidates, making it beneficial for larger instances.
- Failure signatures: If the solver times out frequently, it may indicate insufficient propagation rules or an inefficient tester program. If it returns no solutions for solvable instances, there may be bugs in the normal form transformation or the generator/tester conditions.
- First 3 experiments:
  1. Run Algorithm 1 with generator G0 and tester T0 on a small benchmark (e.g., Eligibility problem) to verify basic functionality.
  2. Replace G0 with G1 and compare the number of candidates generated and the runtime to confirm the propagation's effectiveness.
  3. Test the solver on a known hard instance (e.g., large Bomb problem) to evaluate scalability and identify performance bottlenecks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the exponential reduction in candidates achieved by G1 be maintained when extending ELPs with second-order epistemic operators?
- Basis in paper: [explicit] The paper states that second-order epistemic operators are not necessary from a solving perspective because they can be replaced by ¬ K¬, but does not explore whether this replacement affects the efficiency gains of G1.
- Why unresolved: The paper focuses on programs with only the K operator and does not investigate the computational impact of adding second-order operators.
- What evidence would resolve it: Experimental comparison of G1's performance on ELPs with and without second-order operators, measuring candidate reduction and solving time.

### Open Question 2
- Question: Does the linear-time computation of stable models in G1 hold when extending the framework to handle non-disjunctive rules or more complex rule types?
- Basis in paper: [explicit] The paper proves that stable models of G1 can be computed from G0 in linear time, but this is demonstrated only for programs in normal form with disjunctive rules.
- Why unresolved: The paper does not explore whether the linear-time property extends to more complex rule types or non-disjunctive programs.
- What evidence would resolve it: Theoretical analysis or experimental results showing the computational complexity of G1 when handling non-disjunctive rules or other rule extensions.

### Open Question 3
- Question: How does the performance of G1 compare to translational-based solvers on problems beyond conformant planning, such as reasoning about attack trees and graphs?
- Basis in paper: [explicit] The paper mentions that existing generate-and-test solvers outperform translational-based solvers on benchmarks, but does not provide a detailed comparison on specific problem domains like attack trees.
- Why unresolved: The experimental evaluation focuses on conformant planning benchmarks and does not explore other domains mentioned in the introduction.
- What evidence would resolve it: Experimental results comparing G1's performance on reasoning about attack trees and graphs against both generate-and-test and translational-based solvers.

## Limitations

- The performance claims depend on the specific benchmarks used and may not generalize to all types of epistemic logic programs.
- The paper does not provide detailed experimental results or runtime comparisons across different problem sizes and characteristics.
- The implementation details of the ASP metaprogramming approach and the clingo solver configuration are not fully specified.

## Confidence

- **High Confidence**: The general framework for generate-and-test-based solvers and the sufficient conditions for correctness, as these are proven theoretically and follow standard ASP solver design principles.
- **Medium Confidence**: The effectiveness of the epistemic propagation in the generator program, as the exponential reduction in candidates is supported by the paper's arguments but may depend on the specific problem structure.
- **Low Confidence**: The absolute performance improvement over existing solvers, as the paper does not provide detailed runtime data or comparisons on a diverse set of benchmarks.

## Next Checks

1. **Correctness Validation**: Implement a reference implementation of the normal form transformation and epistemic propagation rules, and verify that it produces the expected results on small, hand-crafted epistemic logic programs with known worldviews.

2. **Performance Benchmarking**: Run the solver on a comprehensive set of benchmarks, including both the problems mentioned in the paper (Eligibility, Yale, Bomb) and additional instances of varying sizes and complexities. Measure the runtime and compare it to existing solvers, analyzing the performance across different problem characteristics.

3. **Scalability Testing**: Identify the largest solvable instance for the solver and the baseline solvers on a given benchmark suite. Analyze the scaling behavior as the problem size increases, and determine the point at which the solver's performance advantage diminishes or disappears.