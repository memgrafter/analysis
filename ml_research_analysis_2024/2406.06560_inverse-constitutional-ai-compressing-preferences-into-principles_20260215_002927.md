---
ver: rpa2
title: 'Inverse Constitutional AI: Compressing Preferences into Principles'
arxiv_id: '2406.06560'
source_url: https://arxiv.org/abs/2406.06560
tags:
- select
- data
- response
- principles
- constitution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Inverse Constitutional AI (ICAI), a novel
  approach to interpreting pairwise text preference datasets by compressing them into
  natural language principles (constitutions). The method works by generating candidate
  principles from feedback data, clustering and filtering them, then validating their
  ability to reconstruct original annotations using an LLM.
---

# Inverse Constitutional AI: Compressing Preferences into Principles

## Quick Facts
- arXiv ID: 2406.06560
- Source URL: https://arxiv.org/abs/2406.06560
- Reference count: 40
- Primary result: Extracts interpretable principles from pairwise preference data using Inverse Constitutional AI

## Executive Summary
This paper introduces Inverse Constitutional AI (ICAI), a novel approach to interpreting pairwise text preference datasets by compressing them into natural language principles (constitutions). The method works by generating candidate principles from feedback data, clustering and filtering them, then validating their ability to reconstruct original annotations using an LLM. Experiments on synthetic, human-annotated (AlpacaEval), and crowdsourced (Chatbot Arena) datasets show that ICAI successfully extracts interpretable principles that explain preferences. The approach enables identifying biases, creating interpretable reward models, scaling evaluation to new models, and adapting models to individual preferences. Constitutions transfer well across model families (e.g., from GPT-4o to Claude models).

## Method Summary
ICAI addresses the challenge of interpreting pairwise text preference datasets by framing the problem as a compression task. The method generates candidate principles from preference pairs using an LLM, clusters similar principles using K-means, and filters them based on their ability to reconstruct original annotations. The five-step algorithm includes principle generation, clustering, sub-sampling, testing, and filtering to create interpretable constitutions. These constitutions can then be used to explain preferences, identify biases, create interpretable reward models, scale evaluation to new models, and adapt models to individual preferences.

## Key Results
- ICAI successfully extracts interpretable principles from synthetic, human-annotated, and crowdsourced preference datasets
- Constitutions transfer well across model families (e.g., from GPT-4o to Claude models)
- The method can identify biases in preference datasets by revealing underlying rules
- Generated principles achieve reasonable reconstruction accuracy of original annotations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ICAI extracts interpretable principles from pairwise preference data by framing the problem as a compression task.
- Mechanism: The algorithm generates candidate principles, clusters similar ones, tests their ability to reconstruct original annotations using an LLM, and filters based on performance.
- Core assumption: A small set of natural language principles can sufficiently capture the underlying preferences in pairwise text data.
- Evidence anchors:
  - [abstract] "given a feedback dataset, we aim to extract a constitution that best enables a large language model (LLM) to reconstruct the original annotations"
  - [section 2] "we consider the following optimization problem: argmax_c { agreement(po, p(c)) s.t. |c| â‰¤ n}"
  - [corpus] Weak - related work focuses on RLHF and DPO but doesn't specifically address principle extraction from preferences

### Mechanism 2
- Claim: Constitutions generated by ICAI can transfer across different model families.
- Mechanism: A constitution generated using one model (e.g., GPT-4o) can be used to annotate data with a different model (e.g., Claude-3-Opus) with reasonable accuracy.
- Core assumption: Different LLMs share enough common understanding of natural language principles to apply them consistently.
- Evidence anchors:
  - [abstract] "Constitutions transfer well across model families (e.g., from GPT-4o to Claude models)"
  - [section 4.2] "both are able to use GPT-4o's generated constitution to reconstruct the test set annotations effectively, albeit to a lower standard than GPT-4o"
  - [corpus] Weak - limited evidence of cross-model constitution transfer in related work

### Mechanism 3
- Claim: ICAI can identify biases in preference datasets by generating constitutions that reveal underlying rules.
- Mechanism: By analyzing the generated constitutions, researchers can identify principles that may represent unintended biases in the original annotations.
- Core assumption: The generated principles will reveal the actual reasoning used by annotators, even if those reasons were not consciously articulated.
- Evidence anchors:
  - [abstract] "help identify undesirable annotator biases"
  - [section 1] "it is valuable to understand the implicit rules and biases guiding annotators of feedback data"
  - [corpus] Moderate - related work documents biases in human feedback but doesn't propose a method for extracting them from existing data

## Foundational Learning

- Concept: Reinforcement Learning from Human Feedback (RLHF)
  - Why needed here: Understanding how preference data is typically used in LLM training provides context for why interpreting this data is valuable
  - Quick check question: What is the primary goal of RLHF in the context of LLM development?

- Concept: Pairwise preference annotation
  - Why needed here: The entire method is built around interpreting pairwise preference data, so understanding this annotation format is crucial
  - Quick check question: How does pairwise preference annotation differ from rating-based annotation?

- Concept: Constitutional AI
  - Why needed here: ICAI inverts the Constitutional AI process, so understanding the original process is essential for grasping the inverse approach
  - Quick check question: What is the main difference between Constitutional AI and traditional RLHF?

## Architecture Onboarding

- Component map:
  Principle generation -> Principle clustering -> Principle sub-sampling -> Principle testing -> Principle filtering -> Final constitution

- Critical path:
  1. Generate candidate principles
  2. Cluster and de-duplicate principles
  3. Test principles on training data
  4. Filter and order principles
  5. Return final constitution

- Design tradeoffs:
  - More principles (larger n) allows finer-grained capture of preferences but risks overfitting
  - Fewer principles improves generalization but may miss important nuances
  - Using multiple generation prompts increases diversity but also computational cost

- Failure signatures:
  - Low reconstruction accuracy indicates principles don't capture preferences well
  - Very high accuracy on training but low on test data suggests overfitting
  - Constitutions that are too generic or too specific indicate problems with clustering or filtering

- First 3 experiments:
  1. Run ICAI on synthetic data with known principles to verify basic functionality
  2. Apply to a small human-annotated dataset to test real-world applicability
  3. Generate constitutions for different annotators to test individual preference capture

## Open Questions the Paper Calls Out
The paper mentions future work exploring new applications and extensions to the approach, but does not explicitly call out specific open questions.

## Limitations
- Limited evidence of constitution transferability across diverse model families
- Uncertainty about whether extracted principles truly capture annotator reasoning versus surface-level patterns
- Computational cost increases with the number of generation prompts and candidate principles

## Confidence
- Core claims about ICAI's ability to extract interpretable principles and achieve reasonable reconstruction accuracy: High
- Cross-model transferability claim: Medium
- Claim about identifying biases: Low

## Next Checks
1. Test constitution transferability across a wider range of model families (e.g., open-source models) to validate the generalizability claim.
2. Apply ICAI to preference datasets with known biases to verify its ability to detect them.
3. Measure reconstruction accuracy when constitutions are applied to models fine-tuned on different domains to assess robustness.