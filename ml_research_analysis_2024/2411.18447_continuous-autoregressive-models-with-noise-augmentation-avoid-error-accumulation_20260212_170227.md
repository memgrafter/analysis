---
ver: rpa2
title: Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation
arxiv_id: '2411.18447'
source_url: https://arxiv.org/abs/2411.18447
tags:
- autoregressive
- noise
- audio
- embeddings
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CAM (Continuous Autoregressive Models), a
  method to train autoregressive models directly on continuous embeddings without
  error accumulation. The key innovation is training with random noise augmentation
  in the input embeddings, forcing the model to learn robust representations resilient
  to prediction errors.
---

# Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation

## Quick Facts
- arXiv ID: 2411.18447
- Source URL: https://arxiv.org/abs/2411.18447
- Reference count: 24
- Primary result: Introduces CAM (Continuous Autoregressive Models) achieving lowest FAD (0.405) vs baselines for musical audio generation without error accumulation

## Executive Summary
This paper introduces CAM (Continuous Autoregressive Models), a method to train autoregressive models directly on continuous embeddings without error accumulation. The key innovation is training with random noise augmentation in the input embeddings, forcing the model to learn robust representations resilient to prediction errors. An additional low-level noise injection during inference further improves generation quality. Experiments on musical audio generation show CAM achieves the lowest FAD (0.405) compared to baselines and maintains consistent quality for extended sequences.

## Method Summary
CAM trains a transformer-based autoregressive model with random noise augmentation in input embeddings, forcing the model to learn robust representations that handle prediction errors. The model uses Rectified Flow for denoising corrupted embeddings conditioned on backbone outputs. During inference, a small constant amount of Gaussian noise is added to generated embeddings before feeding them back to the Backbone. The system operates on continuous latent embeddings extracted from audio using an internal Music2Latent autoencoder.

## Key Results
- CAM achieves FAD of 0.405 on musical audio generation, lowest among baselines
- Maintains consistent quality for extended sequences unlike other autoregressive models
- Low-level inference noise (k_inf=0.02) further reduces error accumulation
- Enables efficient, real-time interactive generative applications without discrete tokenization

## Why This Works (Mechanism)

### Mechanism 1
- Noise augmentation during training simulates error accumulation, forcing the model to learn robust representations
- By adding random noise to continuous embeddings during training, the model learns to distinguish and denoise, preparing it for real error propagation at inference
- Core assumption: The error distribution during inference can be approximated by the linear combination of real embeddings and Gaussian noise with varying weights k_t
- Evidence: Abstract states "we encourage the model to learn to distinguish between real and 'erroneous' signals, making it robust to error propagation during inference"

### Mechanism 2
- Rectified Flow combined with autoregressive modeling improves sample quality and stability
- RF models a deterministic mapping from noise to data via straight-line trajectories in latent space
- Core assumption: Straight-line interpolation in latent space is a good approximation of the true data manifold between noisy and clean embeddings
- Evidence: Abstract mentions "we use the RF framework...in tandem with AMs for continuous embeddings"

### Mechanism 3
- Low-level inference noise (k_inf) reduces mismatch between training and inference error distributions
- Adding constant Gaussian noise to generated embeddings smooths the transition between predicted and real embeddings
- Core assumption: The error introduced by the Sampler is more Gaussian-like than the actual prediction error
- Evidence: Abstract states "adding a small constant amount of Gaussian noise...can yield higher quality when generating long sequences"

## Foundational Learning

- **Diffusion models and score matching**: Why needed - The Sampler uses diffusion principles to denoise embeddings conditioned on the Backbone output. Quick check - How does the noise level parameter σ_t in diffusion models relate to the error level k_t used in noise augmentation?

- **Autoregressive sequence modeling**: Why needed - The Backbone predicts embeddings sequentially, conditioning on previously generated embeddings. Quick check - What is the difference between causal and masked attention in autoregressive models, and why does CAM use causal attention?

- **Vector quantization and continuous embeddings**: Why needed - CAM operates directly on continuous embeddings, bypassing tokenization. Quick check - How does working with continuous embeddings instead of discrete tokens affect model architecture and loss functions?

## Architecture Onboarding

- **Component map**: Input embeddings -> Backbone (Transformer) -> z_t conditioning -> Sampler (MLP with AdaLN) -> denoised embeddings -> (k_inf noise) -> Backbone

- **Critical path**: Generate z_t from Backbone → Denoise y_t with Sampler → Feed back to Backbone with k_inf noise

- **Design tradeoffs**: 
  - Noise augmentation increases training robustness but may slow convergence if too aggressive
  - Rectified Flow simplifies training vs. traditional diffusion but assumes linear latent manifold
  - k_inf tuning is crucial: too low → error accumulation; too high → quality degradation

- **Failure signatures**:
  - Degradation in FAD for longer sequences → insufficient noise augmentation or k_inf tuning
  - High training loss with noise augmentation → Backbone cannot distinguish real vs. noisy signals
  - Poor FAD at inference → Sampler underfits or overfitting to training noise distribution

- **First 3 experiments**:
  1. Train Backbone with noise augmentation (k_t ∈ [0, 0.5]) and measure FAD vs. baseline without noise
  2. Vary k_inf ∈ [0, 0.05] and evaluate FAD/FAD_acc to find optimal inference noise
  3. Compare Rectified Flow vs. linear noise prediction in Sampler for same Backbone configuration

## Open Questions the Paper Calls Out

- **How does CAM's performance vary across different musical instruments and genres?** The paper evaluates only overall FAD scores without breaking down performance by instrument type, genre, or musical feature.

- **What is the exact mechanism by which low-level noise injection during inference improves generation quality?** The paper provides only a hypothesis about the mechanism without empirical validation.

- **How does CAM's performance scale to sequences much longer than the 20-second maximum context used in training?** The evaluation only covers 20-second sequences, leaving uncertainty about CAM's performance on significantly longer sequences.

## Limitations
- Experiments confined to single domain (instrumental music); effectiveness on other continuous autoregressive tasks untested
- Backbone is a relatively standard transformer; unclear how CAM scales to larger models
- Relies on internal dataset of ~20,000 single-instrument recordings; generalization to polyphonic music untested
- FAD is primary metric but may not fully capture perceptual quality or long-term coherence

## Confidence
- **High Confidence**: Noise augmentation improves robustness to error propagation; Low-level inference noise reduces mismatch between training and inference error distributions; CAM achieves lower FAD than baseline models
- **Medium Confidence**: Rectified Flow combined with autoregressive modeling improves sample quality; The error distribution during inference can be approximated by noise-perturbed embeddings during training
- **Low Confidence**: CAM generalizes effectively to other continuous autoregressive tasks beyond musical audio; The optimal noise injection strategy is robust across different model scales and datasets

## Next Checks
1. Evaluate CAM on non-musical continuous autoregressive tasks (e.g., video frame prediction or text continuation) to assess cross-domain generalization of noise augmentation
2. Conduct systematic ablation study varying k_t and k_inf to identify optimal ranges and test their stability across different model scales
3. Supplement FAD with human perceptual studies or alternative metrics to validate that noise injection strategies improve perceptual quality of generated sequences