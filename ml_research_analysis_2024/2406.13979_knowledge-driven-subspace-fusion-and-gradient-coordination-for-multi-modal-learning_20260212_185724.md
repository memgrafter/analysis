---
ver: rpa2
title: Knowledge-driven Subspace Fusion and Gradient Coordination for Multi-modal
  Learning
arxiv_id: '2406.13979'
source_url: https://arxiv.org/abs/2406.13979
tags:
- multi-modal
- learning
- genomics
- subspace
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of integrating multi-modal data,
  specifically histology images and genomics, for cancer diagnosis and prognosis.
  The proposed method, Knowledge-driven Subspace Fusion and Gradient Coordination
  (KS-Fusion and CG-Coord), decomposes the feature subspace of histology images and
  genomics, reflecting distinct tumor and microenvironment features.
---

# Knowledge-driven Subspace Fusion and Gradient Coordination for Multi-modal Learning

## Quick Facts
- arXiv ID: 2406.13979
- Source URL: https://arxiv.org/abs/2406.13979
- Authors: Yupei Zhang; Xiaofei Wang; Fangliangzi Meng; Jin Tang; Chao Li
- Reference count: 24
- Primary result: Achieves 95.28% AUC for glioma diagnosis, 91.53% for tumor grading, and 79.78% for survival analysis on merged TCGA GBM-LGG and IvyGAP datasets

## Executive Summary
This paper presents a novel multi-modal learning framework for integrating histology images and genomics in cancer diagnosis and prognosis. The method, Knowledge-driven Subspace Fusion and Gradient Coordination (KS-Fusion and CG-Coord), decomposes genomic data into tumor- and microenvironment-related genes, processes them separately with histology features, and employs cross-modal deformable attention with gene-guided consistency. A unique gradient coordination strategy dynamically resolves conflicts between the two subspaces during training. The approach demonstrates superior performance on glioma datasets, achieving state-of-the-art results across three downstream tasks.

## Method Summary
The method integrates whole-slide images (WSIs) and genomic profiles through a biologically interpretable framework. It first partitions genomic data into tumor-related (59 genes) and TME-related (361 genes) subsets, then processes each through separate neural networks. A multi-modal teacher guides deformable attention offsets for each gene subset, while a gene-guided consistency strategy (Gram matrix similarity) enforces alignment between deformed histology features and genomics. The model employs confidence-guided gradient coordination to dynamically resolve conflicts between tumor- and TME-subspace gradients during training, optimizing for glioma diagnosis, tumor grading, and survival analysis.

## Key Results
- Achieves 95.28% AUC for glioma diagnosis, outperforming state-of-the-art methods
- Obtains 91.53% accuracy for tumor grading across three grades
- Delivers 79.78% C-Index for survival analysis prediction
- Demonstrates robust performance across multiple downstream tasks on merged TCGA GBM-LGG and IvyGAP datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing genomics into tumor- and microenvironment-related genes allows separate modeling of their distinct morphological features
- Mechanism: The model splits genomic profiles into two groups—tumor-related (59 genes) and TME-related (361 genes)—and processes them in parallel with WSIs to capture niche-specific features before fusion
- Core assumption: Tumor and TME genes contribute distinct morphological patterns in histology that benefit from separate feature extraction
- Evidence anchors:
  - [abstract]: "We propose a biologically interpretative and robust multi-modal learning framework to efficiently integrate histology images and genomics by decomposing the feature subspace of histology images and genomics, reflecting distinct tumour and microenvironment features."
  - [section]: "To enhance the biological guidance from niche-specific genomic profiles, we propose a KS-Fusion scheme to capture subspace informative features from both tumour- and TME-related gene profiles."
  - [corpus]: Weak—corpus neighbors mention "disentangled" or "multi-modal learning" but not this specific gene decomposition mechanism
- Break condition: If tumor and TME gene sets are not biologically separable or do not map to distinct histological patterns, the decomposition will not improve fusion

### Mechanism 2
- Claim: Cross-modal deformable attention with gene-guided consistency aligns histological patches to gene-driven deformation offsets
- Mechanism: A two-stream neural network uses a multi-modal teacher to guide deformable offsets for each gene subset, then applies a gene-guided consistency strategy (Gram matrix similarity) to enforce alignment between deformed histology features and genomics
- Core assumption: Deformable attention can be effectively guided by gene-derived features, and Gram matrix similarity meaningfully constrains deformation
- Evidence anchors:
  - [abstract]: "To enhance cross-modal interactions, we design a knowledge-driven subspace fusion scheme, consisting of a cross-modal deformable attention module and a gene-guided consistency strategy."
  - [section]: "The informative morphological features are dominated by the multi-modal features, enhancing the correlations and interactions between subspace genomic and histology embeddings."
  - [corpus]: Weak—corpus neighbors discuss cross-modal attention but not the specific deformable-attention-plus-consistency combination
- Break condition: If the deformation offsets become unstable or the Gram matrix constraint is too restrictive, the attention may fail to capture useful interactions

### Mechanism 3
- Claim: Confidence-guided gradient coordination dynamically resolves conflicts between tumor- and TME-subspace gradients during training
- Mechanism: When gradients from the two subspaces are opposing (cosine < 0), the model projects the lower-confidence gradient toward the higher-confidence one, enabling harmonious joint optimization
- Core assumption: Conflicts between tumor- and TME-subspace gradients are common and can be resolved by confidence-weighted modulation
- Evidence anchors:
  - [abstract]: "Additionally, in pursuit of dynamically optimizing the subspace knowledge, we further propose a novel gradient coordination learning strategy."
  - [section]: "To boost the downstream task by combining these two types of domain knowledge, we design the CG-Coord scheme to obtain the global training optimum via dynamic gradient regulation."
  - [corpus]: Weak—corpus neighbors mention multi-modal fusion but not confidence-guided gradient coordination
- Break condition: If confidence scores are unreliable or the projection causes vanishing gradients, coordination may degrade performance

## Foundational Learning

- Concept: Gene selection and partitioning based on biological relevance
  - Why needed here: The method depends on distinguishing tumor- from TME-related genes to drive separate feature extraction; incorrect partitioning would corrupt the entire pipeline
  - Quick check question: How many tumor- and TME-related genes are used, and on what biological criteria are they selected?

- Concept: Cross-modal attention and deformable convolution mechanics
  - Why needed here: The deformable attention module is central to aligning histology patches to gene-driven deformations; misunderstanding offsets or sampling would break feature fusion
  - Quick check question: What is the shape of the reference grid and how are offsets generated from the multi-modal teacher?

- Concept: Gradient coordination and projection for conflicting updates
  - Why needed here: The CG-Coord scheme modifies gradients based on prediction confidence; incorrect implementation could stall training or cause instability
  - Quick check question: How is the confidence score computed for survival tasks versus classification tasks?

## Architecture Onboarding

- Component map: Genomics → SNN → tumor/TME streams → teacher → deformable attention → consistency → classifier → gradient coordination → loss
- Critical path: Genomics encoder produces tumor- and TME-gene embeddings, which flow through separate streams guided by multi-modal teacher, then undergo deformable attention with gene-guided consistency before classifier update with gradient coordination
- Design tradeoffs:
  - Gene decomposition vs. monolithic fusion: Separate streams improve interpretability but increase model complexity
  - Gram matrix similarity vs. direct feature matching: Similarity is computationally cheaper but may miss fine-grained alignment
  - Confidence-based projection vs. uniform gradient scaling: Projection preserves gradient direction from dominant task but can suppress minority-task learning
- Failure signatures:
  - Training instability or vanishing gradients: Likely from aggressive gradient projection or misaligned attention offsets
  - Poor histology-genomics alignment: Check Gram matrix loss and attention maps; inconsistent deformation suggests gene guidance is weak
  - Suboptimal task performance: Verify gene partitions match biology; re-check confidence score calculation
- First 3 experiments:
  1. Train with gene decomposition disabled (concatenate tumor/TME genes) and compare AUC
  2. Remove gene-guided consistency and measure attention offset stability and classification accuracy
  3. Disable gradient coordination and observe training loss curves for tumor vs. TME branches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed KS-Fusion and CG-Coord method perform on datasets with different types of cancer beyond gliomas?
- Basis in paper: [explicit] The authors mention that their method is specifically tested on glioma datasets (TCGA GBM-LGG and IvyGAP) and show superior performance compared to state-of-the-art methods. However, they do not provide evidence of the method's effectiveness on other cancer types
- Why unresolved: The paper focuses solely on glioma datasets, and there is no discussion or testing of the method's generalizability to other cancer types. This limits the understanding of the method's broader applicability in cancer diagnosis and prognosis
- What evidence would resolve it: Testing the KS-Fusion and CG-Coord method on multiple cancer types, such as breast cancer, lung cancer, or prostate cancer, and comparing its performance to state-of-the-art methods for each cancer type would provide evidence of its generalizability and effectiveness across different cancers

### Open Question 2
- Question: How does the proposed method handle the potential imbalance in the number of tumour-related and TME-related genes?
- Basis in paper: [inferred] The method decomposes genomics data into tumour- and TME-related genes for integration with histological features. However, the paper does not discuss how it addresses the potential imbalance in the number of genes in these two categories
- Why unresolved: The imbalance in the number of tumour-related and TME-related genes could potentially affect the performance of the method. Without addressing this issue, it is unclear how the method ensures that the contributions from both types of genes are appropriately balanced and utilized
- What evidence would resolve it: Providing a detailed analysis of the distribution of tumour-related and TME-related genes in the datasets and demonstrating how the method handles this imbalance, possibly through normalization or weighting strategies, would clarify its approach to addressing this issue

### Open Question 3
- Question: What is the impact of the hyper-parameter α on the performance of the method, and how is it optimized?
- Basis in paper: [explicit] The paper mentions that the hyper-parameter α is used to balance the contributions of tumour- and TME-related gene features in the KS-Fusion scheme. It also mentions that α is tuned to achieve optimal performance on the validation set
- Why unresolved: While the paper states that α is tuned for optimal performance, it does not provide detailed information on the impact of different values of α on the method's performance or the specific optimization process used
- What evidence would resolve it: Conducting a thorough sensitivity analysis of the hyper-parameter α, including its impact on different tasks (diagnosis, grading, survival analysis) and providing a clear optimization strategy, would help understand its role in the method's performance and how it is optimized

## Limitations
- Limited validation to glioma datasets only, with no evidence of generalizability to other cancer types
- Assumes clear biological separation between tumor- and microenvironment-related genes that may not hold across different cancer contexts
- Depends on specific gene partitioning that requires biological validation for different cancer types

## Confidence

- Mechanism 1 (gene decomposition): Medium - biologically plausible but limited empirical validation of gene groupings
- Mechanism 2 (deformable attention + consistency): Low - novel combination without established precedent in the corpus
- Mechanism 3 (gradient coordination): Medium - theoretically sound but untested outside this specific framework

## Next Checks

1. Perform ablation studies to quantify performance degradation when removing gene decomposition, testing whether tumor/TME separation is truly necessary
2. Validate the biological relevance of the 59 tumor and 361 TME genes by checking their correlation with known histological patterns
3. Test gradient coordination on synthetic multi-modal datasets with controlled gradient conflicts to verify the projection mechanism works as intended