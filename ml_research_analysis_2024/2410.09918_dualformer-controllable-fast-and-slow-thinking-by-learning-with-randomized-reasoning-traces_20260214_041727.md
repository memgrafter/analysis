---
ver: rpa2
title: 'Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized
  Reasoning Traces'
arxiv_id: '2410.09918'
source_url: https://arxiv.org/abs/2410.09918
tags:
- wall
- dualformer
- mode
- reasoning
- maze
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Dualformer, a Transformer model that integrates
  fast and slow reasoning modes by training on randomized reasoning traces with strategic
  trace dropping. During training, different parts of the reasoning traces are selectively
  dropped to mimic human shortcuts in thinking, enabling the model to operate in fast,
  slow, or auto modes at inference.
---

# Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces

## Quick Facts
- arXiv ID: 2410.09918
- Source URL: https://arxiv.org/abs/2410.09918
- Reference count: 40
- Dualformer outperforms baselines across fast, slow, and auto modes in maze navigation and Sokoban tasks

## Executive Summary
Dualformer is a Transformer model that integrates fast and slow reasoning modes by training on randomized reasoning traces with strategic trace dropping. The model can operate in fast, slow, or auto modes at inference, controlled by simple tokens. Experiments on maze navigation and Sokoban tasks show Dualformer achieves 97.6% optimal rate in slow mode with 45.5% fewer reasoning steps than Searchformer, and 80% optimal rate in fast mode versus 30% for solution-only models. The approach also improves diversity of generated plans and generalizes to fine-tuning LLMs for math reasoning.

## Method Summary
Dualformer is an encoder-decoder Transformer trained on randomized reasoning traces where different parts of A* search traces are selectively dropped during training. The model learns to generate solutions with or without reasoning steps based on control tokens (plan/create). Four levels of trace dropping progressively remove reasoning components: close clauses, cost tokens, create clauses, or entire traces. During inference, the model switches between fast, slow, or auto modes based on the presence or absence of control tokens. The auto mode samples from learned distributions to engage slower thinking for more complex problems.

## Key Results
- Dualformer achieves 97.6% optimal rate in slow mode with 45.5% fewer reasoning steps than Searchformer
- Fast mode reaches 80% optimal rate versus 30% for solution-only models
- Generates 9.05-25.77 unique feasible paths versus 1.52-7.60 for baselines across maze sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured trace dropping during training enables Dualformer to learn both fast and slow reasoning modes in a single model
- Core assumption: The structure of A* search traces is hierarchical and predictable, allowing systematic removal of reasoning components without losing task semantics
- Evidence: [abstract] describes randomized reasoning traces with strategic dropping; [section 3] details four levels of trace dropping (D1-D4) that progressively remove reasoning components

### Mechanism 2
- Claim: Randomized trace dropping strategies improve plan diversity by preventing memorization of single optimal paths
- Core assumption: The non-deterministic A* implementation in training data provides sufficient diversity that the model can exploit when trace dropping creates varied training examples
- Evidence: [abstract] states Dualformer produces more diverse reasoning traces than Searchformer; [section 4.1.1] shows Dualformer generates 9.05-25.77 unique feasible paths vs 1.52-7.60 for baselines

### Mechanism 3
- Claim: Auto mode enables context-aware switching between fast and slow thinking based on problem difficulty
- Core assumption: The model can implicitly learn to associate problem complexity with appropriate reasoning mode through the randomized training objective
- Evidence: [section 4.1.3] shows increased slow-mode usage with higher wall density and maze size; [figure 4.1] demonstrates auto mode adapts to maze difficulty

## Foundational Learning

- **Concept**: Tokenization and sequence modeling in encoder-decoder transformers
  - Why needed here: Dualformer operates on tokenized sequences representing maze problems, A* traces, and solutions
  - Quick check question: How does the model distinguish between prompt, trace, and solution tokens in the input sequence?

- **Concept**: A* search algorithm and heuristic search
  - Why needed here: The training data consists of A* search traces, and understanding the algorithm's structure is crucial for designing effective trace dropping strategies
  - Quick check question: What information is contained in create vs close clauses of A* search traces?

- **Concept**: Randomization techniques in training (dropout, masking)
  - Why needed here: The core innovation involves randomized trace dropping, which builds on understanding of how random masking affects model learning
  - Quick check question: How does trace dropping differ from standard token masking in terms of what is dropped and why?

## Architecture Onboarding

- **Component map**: Input tokenization → encoder processing → decoder autoregressive generation → output parsing for path extraction
- **Critical path**: Maze problem → tokenized input → encoder → decoder → generated trace/solution → path extraction
- **Design tradeoffs**: Smaller model size (15M/46M) vs performance; randomized training vs standard supervised learning; single model vs separate fast/slow models
- **Failure signatures**: Model generates invalid paths (through walls); reasoning traces are too long/short; poor performance in either fast or slow mode
- **First 3 experiments**:
  1. Verify tokenization correctly represents maze problems and solutions
  2. Test basic generation with complete traces to ensure model learns from full data
  3. Evaluate fast mode performance with plan control token to confirm mode switching works

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Dualformer's performance scale when trained on larger datasets and more complex environments beyond maze navigation and Sokoban?
- Basis: The paper mentions future work could investigate whether the approach helps models scale to more complex tasks
- Why unresolved: Experiments were limited to specific grid-based navigation and planning tasks with fixed model sizes (15M and 46M parameters)
- What evidence would resolve it: Systematic experiments scaling Dualformer to larger model sizes and testing on more complex planning domains

### Open Question 2
- Question: What is the theoretical explanation for why structured trace dropping strategies improve both reasoning accuracy and efficiency in Dualformer?
- Basis: The paper demonstrates empirically that trace dropping works but lacks formal theoretical analysis
- Why unresolved: The paper relies on empirical observations and analogies to human System 1/System 2 thinking but lacks formal mathematical justification
- What evidence would resolve it: Theoretical analysis showing how trace dropping affects gradient updates and information entropy changes during training

### Open Question 3
- Question: How does Dualformer's auto mode determine when to switch between fast and slow thinking, and can this decision-making process be made more interpretable?
- Basis: The paper shows auto mode engages more slow thinking as task difficulty increases but doesn't explain the internal mechanism
- Why unresolved: While demonstrating auto mode selection, the paper doesn't analyze internal attention patterns or decision criteria
- What evidence would resolve it: Analysis of attention weights during auto mode generation and visualization of decision boundaries

## Limitations

- Limited generalizability beyond maze navigation and structured math problems
- Lack of theoretical explanation for why trace dropping strategies work effectively
- Potential overfitting to specific A* search implementation used in training data

## Confidence

**High Confidence**: Experimental results demonstrating Dualformer's performance advantages over baselines in maze navigation and Sokoban tasks with clearly defined comparison metrics.

**Medium Confidence**: Claims about Dualformer's ability to generate more diverse reasoning traces than baselines, though the diversity metric may not fully capture quality or usefulness.

**Low Confidence**: Generalizability of Dualformer's approach to domains beyond maze navigation and structured math problems where optimal solutions aren't as clearly defined.

## Next Checks

1. **Trace Dependency Analysis**: Conduct ablation studies systematically removing different components of A* traces to determine the minimum information required for optimal performance.

2. **Cross-Domain Generalization**: Test Dualformer on reasoning tasks with less structured traces, such as open-ended problem solving or domains where optimal solutions aren't easily verifiable.

3. **Mode Switching Robustness**: Evaluate auto-mode switching performance across a wider range of problem complexities and different types of reasoning tasks to verify reliable difficulty-to-mode association.