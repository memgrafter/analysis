---
ver: rpa2
title: 'Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent
  Systems'
arxiv_id: '2410.02506'
source_url: https://arxiv.org/abs/2410.02506
tags:
- agentprune
- graph
- agent
- communication
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the high token consumption and economic cost
  of multi-agent systems using large language models (LLMs), which limits their large-scale
  deployment. The authors propose AgentPrune, a framework that identifies and prunes
  redundant or malicious communication messages in LLM-based multi-agent systems by
  performing one-shot pruning on the spatial-temporal message-passing graph.
---

# Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems

## Quick Facts
- **arXiv ID**: 2410.02506
- **Source URL**: https://arxiv.org/abs/2410.02506
- **Reference count**: 40
- **One-line primary result**: AgentPrune achieves comparable results to state-of-the-art topologies at a significantly lower cost (approximately $5.6 vs. $43.7), reduces token consumption by 28.1% to 72.8%, and enhances robustness against adversarial attacks with a 3.5% to 10.8% performance boost.

## Executive Summary
This paper addresses the high token consumption and economic cost of multi-agent systems using large language models (LLMs), which limits their large-scale deployment. The authors propose AgentPrune, a framework that identifies and prunes redundant or malicious communication messages in LLM-based multi-agent systems by performing one-shot pruning on the spatial-temporal message-passing graph. AgentPrune leverages a trainable communication graph mask optimized using a low-rank principle to guide training, resulting in a sparse yet informative communication topology. Experiments on six benchmarks demonstrate that AgentPrune achieves comparable results to state-of-the-art topologies at a significantly lower cost (approximately $5.6 vs. $43.7), reduces token consumption by 28.1% to 72.8%, and enhances robustness against adversarial attacks with a 3.5% to 10.8% performance boost.

## Method Summary
AgentPrune treats the entire LLM-based multi-agent system as a spatial-temporal communication graph, where agents are nodes and communication edges represent message passing. The framework trains a differentiable graph mask (SS for spatial, ST for temporal) to approximate edge importance, regularized with a nuclear norm to encourage low-rank and sparse structure. After K′ rounds of optimization using policy gradient, one-shot magnitude pruning retains only the top (1-p%) edges, producing a fixed sparse topology Gsub for subsequent rounds. This approach reduces redundant and malicious communication while maintaining task performance and improving robustness.

## Key Results
- Token consumption reduced by 28.1% to 72.8% across six benchmarks
- Cost savings from approximately $43.7 to $5.6 compared to state-of-the-art topologies
- Robustness enhancement against adversarial attacks with 3.5% to 10.8% performance boost

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: AgentPrune identifies and removes communication redundancy by optimizing a low-rank spatial-temporal graph mask, leading to sparse yet effective communication topologies.
- **Mechanism**: The framework treats the multi-agent system as a spatial-temporal graph where each agent is a node and edges represent communication. AgentPrune trains a differentiable graph mask (SS, ST) to approximate the importance of each edge. The masks are regularized with a nuclear norm to encourage sparsity and low-rank structure. After K′ rounds of optimization, one-shot magnitude pruning retains only the top (1-p%) edges, producing a fixed sparse topology Gsub for subsequent rounds.
- **Core assumption**: The low-rank principle effectively separates important from redundant communication edges, and that a one-shot pruning after limited training suffices for high performance.
- **Evidence anchors**:
  - [abstract] “AgentPrune leverages a trainable communication graph mask optimized using a low-rank principle to guide training, resulting in a sparse yet informative communication topology.”
  - [section 3.2] “The second term in Equation (8) promotes the graph masks {SS, ST} to be low-rank… which not only filters out informative agent communications but also aids in removing redundant, noisy, and even malicious messages.”
  - [corpus] Weak evidence. Related works (e.g., “Adaptive Graph Pruning for Multi-Agent Communication”) focus on adaptive pruning but do not explicitly use low-rank regularization or one-shot pruning as AgentPrune does.
- **Break condition**: If the low-rank assumption fails to capture essential communication structure, or if the pruned graph loses critical information for solving tasks, performance will degrade.

### Mechanism 2
- **Claim**: AgentPrune enhances robustness against adversarial attacks by removing malicious communication messages through low-rank graph optimization.
- **Mechanism**: The low-rank regularization in the graph mask training implicitly identifies and downweights edges carrying malicious or noisy information. During pruning, edges associated with adversarial messages are removed, leaving a cleaner communication graph. This makes the system less susceptible to attacks that exploit communication channels.
- **Core assumption**: Malicious or noisy messages are structurally redundant and thus penalized by the low-rank constraint.
- **Evidence anchors**:
  - [abstract] “AgentPrune employs a low-rank principle to guide the graph mask training, successfully robus-tifying LLM-MA systems against various agent-targeted adversarial attacks.”
  - [section 3.2] “Low-rank Sparsity… not only filters out informative agent communications but also aids in removing redundant, noisy, and even malicious messages… that low-rank graphs are more robust to network attacks.”
  - [corpus] No explicit supporting evidence found in the corpus; claim relies on internal experimental results.
- **Break condition**: If adversarial messages are not structurally redundant or if the low-rank regularization fails to distinguish them, robustness gains will be minimal.

### Mechanism 3
- **Claim**: AgentPrune achieves token efficiency by pruning redundant intra- and inter-dialogue communication, significantly reducing token consumption while maintaining task performance.
- **Mechanism**: By removing unnecessary spatial (intra-dialogue) and temporal (inter-dialogue) edges, AgentPrune reduces the number of messages exchanged in each round. This directly lowers the total token count without sacrificing solution quality, as redundant messages do not contribute meaningfully to task completion.
- **Core assumption**: A substantial portion of agent-agent communication is redundant and can be removed without harming performance.
- **Evidence anchors**:
  - [abstract] “AgentPrune… prunes redundant or even malicious communication messages… yielding a token-economic and high-performing communication topology.”
  - [section 2] “we for the first time identify a significant phenomenon of Communication Redundancy… wherein a significant portion of spatial and temporal edges, i.e., communication, does not contribute to collaborative intelligence.”
  - [section 3.4] Provides cost analysis showing token savings (Equation 13).
  - [corpus] Weak evidence. The corpus contains related works on graph pruning but none with the specific token-saving focus or quantitative savings reported by AgentPrune.
- **Break condition**: If the pruned communication graph loses essential information for solving tasks, performance will drop despite token savings.

## Foundational Learning

- **Concept**: Graph sparsification and low-rank regularization
  - Why needed here: AgentPrune relies on graph sparsification to reduce communication edges while preserving essential connectivity. Low-rank regularization ensures the resulting graph is both sparse and robust.
  - Quick check question: How does nuclear norm regularization promote low-rank structure in graph masks?

- **Concept**: Policy gradient optimization for non-differentiable utility functions
  - Why needed here: The utility function ϕ(·) depends on external APIs or compilers, making it non-differentiable. Policy gradient is used to optimize the graph masks with respect to this utility.
  - Quick check question: Why can’t standard gradient descent be used directly on the utility function in AgentPrune?

- **Concept**: Multi-agent communication topologies (chain, tree, complete graph, etc.)
  - Why needed here: Understanding these topologies is essential to grasp how AgentPrune modifies them and to interpret experimental comparisons.
  - Quick check question: What distinguishes spatial communication from temporal communication in multi-agent systems?

## Architecture Onboarding

- **Component map**:
  - Nodes: Each agent with base LLM, role, state, and plugins
  - Edges: Spatial (intra-dialogue) and temporal (inter-dialogue) message-passing channels
  - Graph mask (SS, ST): Trainable matrices indicating edge importance
  - DAGSampling: Function ensuring spatial communication graph remains a DAG
  - Pruning module: One-shot magnitude pruning retaining top (1-p%) edges
  - AggregateSolution: Mechanism to combine agent outputs into final answer

- **Critical path**:
  1. Initialize spatial-temporal graph and masks
  2. Optimize masks for K′ rounds using policy gradient + low-rank regularization
  3. Apply one-shot pruning to derive sparse topology Gsub
  4. Use Gsub for remaining (K-K′) rounds of multi-agent reasoning
  5. Aggregate final solution

- **Design tradeoffs**:
  - Early stopping (K′ << K) vs. full optimization: balances training cost and mask quality
  - Pruning ratio p% vs. performance: higher pruning saves more tokens but risks losing critical communication
  - Single-query vs. multi-query training: single-query optimizes per task, multi-query amortizes cost across dataset
  - Low-rank regularization strength vs. expressiveness: stronger regularization increases robustness but may oversimplify

- **Failure signatures**:
  - Performance drops after pruning: indicates essential communication edges were removed
  - No token savings: pruning ratio too low or masks not properly optimized
  - Model instability or divergence: policy gradient step size too large or masks not regularized
  - DAG violation: DAGSampling failing to enforce acyclicity

- **First 3 experiments**:
  1. Validate on a small benchmark (e.g., MMLU with 3 agents) comparing AgentPrune vs. vanilla complete graph: check performance retention and token reduction.
  2. Test adversarial robustness: apply agent prompt attack, measure performance drop with/without AgentPrune.
  3. Sensitivity analysis: vary pruning ratio p% and early stopping rounds K′, plot performance and token savings to find sweet spot.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the performance of AgentPrune vary across different task domains (e.g., code generation vs. mathematical reasoning) when the number of agents increases beyond five?
- **Basis in paper**: [explicit] The paper notes that performance gains from increasing the number of agents become marginal after five agents.
- **Why unresolved**: The paper only tests up to nine agents, and the performance trends beyond five agents are not fully explored.
- **What evidence would resolve it**: Conducting experiments with a larger number of agents (e.g., 10-20) across diverse task domains would provide insights into the scalability and effectiveness of AgentPrune.

### Open Question 2
- **Question**: What is the impact of varying the pruning ratio (p%) on the performance and token efficiency of AgentPrune?
- **Basis in paper**: [inferred] The paper mentions that AgentPrune uses a one-shot pruning approach based on a pruning ratio, but does not extensively explore the effects of different pruning ratios.
- **Why unresolved**: The optimal pruning ratio may vary depending on the task complexity and the communication topology, and its impact on performance and token efficiency is not fully characterized.
- **What evidence would resolve it**: Conducting experiments with different pruning ratios (e.g., 10%, 20%, 30%, etc.) and analyzing the resulting performance and token efficiency metrics would provide insights into the sensitivity of AgentPrune to the pruning ratio.

### Open Question 3
- **Question**: How does the low-rank principle guide the graph mask training in AgentPrune, and what are the specific benefits of this approach compared to other regularization techniques?
- **Basis in paper**: [explicit] The paper states that AgentPrune employs a low-rank principle to guide the graph mask training, which promotes a sparse and robust communication structure.
- **Why unresolved**: The paper does not provide a detailed explanation of how the low-rank principle is implemented or compare its effectiveness to other regularization techniques.
- **What evidence would resolve it**: Providing a detailed explanation of the low-rank regularization mechanism and conducting experiments comparing AgentPrune with other regularization techniques (e.g., L1 regularization) would clarify the benefits of the low-rank principle.

### Open Question 4
- **Question**: How does AgentPrune perform in scenarios with a large number of queries (e.g., 10,000+ queries) where the initial Q' queries used for training the topology may not be representative of the entire dataset?
- **Basis in paper**: [inferred] The paper mentions a multi-query training paradigm where the initial Q' queries are used to optimize the topology, but does not explore the scenario with a large number of queries.
- **Why unresolved**: The effectiveness of AgentPrune may depend on the representativeness of the initial Q' queries, and its performance in scenarios with a large number of queries is not fully characterized.
- **What evidence would resolve it**: Conducting experiments with a large number of queries and analyzing the performance of AgentPrune with different values of Q' would provide insights into its scalability and robustness in real-world scenarios.

## Limitations

- The paper's analysis of communication patterns and redundancy detection could be more detailed, with limited ablation studies on different aspects of the low-rank regularization.
- Evaluation focuses primarily on cost reduction and performance metrics, with limited discussion of potential negative impacts on collaborative reasoning quality or long-term system behavior.
- Claims about inherent robustness of low-rank graphs to network attacks are supported mainly by experimental results rather than theoretical analysis.

## Confidence

**High Confidence Claims:**
- AgentPrune successfully reduces token consumption by 28.1% to 72.8% across benchmarks
- The framework achieves comparable performance to state-of-the-art topologies while significantly reducing costs
- The low-rank principle effectively promotes sparsity in the communication graph

**Medium Confidence Claims:**
- The robustness enhancement against adversarial attacks is primarily based on experimental results without extensive theoretical justification
- The one-shot pruning approach after K′ rounds is sufficient for optimal performance, though the sensitivity to K′ is not thoroughly explored

**Low Confidence Claims:**
- The paper claims that low-rank graphs are inherently more robust to network attacks, but this is supported mainly by the experimental results rather than theoretical analysis
- The generalization capability across diverse benchmarks is demonstrated but not extensively analyzed for potential failure modes

## Next Checks

1. **Ablation Study on Low-Rank Regularization**: Conduct experiments varying the strength of low-rank regularization and its components (spatial vs. temporal) to determine their individual contributions to performance and token savings.

2. **Adversarial Attack Analysis**: Systematically test AgentPrune against a wider range of adversarial attacks, including adaptive attacks that target the pruning mechanism itself, to better understand the limits of robustness claims.

3. **Communication Pattern Analysis**: Perform detailed analysis of the pruned communication graphs to verify that removed edges are truly redundant and to identify any patterns in preserved communications that correlate with task success.