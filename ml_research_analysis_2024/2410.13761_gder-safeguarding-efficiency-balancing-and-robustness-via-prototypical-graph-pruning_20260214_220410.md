---
ver: rpa2
title: 'GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical
  Graph Pruning'
arxiv_id: '2410.13761'
source_url: https://arxiv.org/abs/2410.13761
tags:
- graph
- gder
- data
- pruning
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GDeR introduces a dynamic soft-pruning method for graph-level training
  that maintains efficiency while ensuring balance and robustness. It projects graph
  embeddings onto a hyperspherical space, regularizes with trainable prototypes, and
  samples representative, unbiased subsets using a probability distribution based
  on familiarity, outlier risk, and balancing scores.
---

# GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning

## Quick Facts
- arXiv ID: 2410.13761
- Source URL: https://arxiv.org/abs/2410.13761
- Authors: Guibin Zhang; Haonan Dong; Yuchen Zhang; Zhixun Li; Dingshuo Chen; Kai Wang; Tianlong Chen; Yuxuan Liang; Dawei Cheng; Kun Wang
- Reference count: 40
- One-line primary result: Achieves or surpasses full-dataset performance with 30%–50% fewer training samples, attains up to 2.81× lossless speedup, and improves robustness in imbalanced and noisy settings by 0.3%–7.8%.

## Executive Summary
GDeR introduces a dynamic soft-pruning method for graph-level training that maintains efficiency while ensuring balance and robustness. It projects graph embeddings onto a hyperspherical space, regularizes with trainable prototypes, and samples representative, unbiased subsets using a probability distribution based on familiarity, outlier risk, and balancing scores. On five datasets across three GNN backbones, GDeR achieves performance comparable to full datasets with 30%–50% fewer training samples, attains up to 2.81× lossless speedup, and improves robustness in imbalanced and noisy settings by 0.3%–7.8%.

## Method Summary
GDeR dynamically maintains a balanced training subset by sampling based on outlier risk, familiarity, and balancing scores. The method computes three metrics for each graph embedding: outlier risk (ωr) via Mahalanobis distance to prototype clusters, familiarity (ωe) via angular distance to own vs. other prototypes, and balancing score (ωb) via cluster size weighting. These are combined into a sampling probability distribution that favors under-learned, minority-class, low-outlier-risk samples. At each epoch, GDeR samples a subset using the probability distribution for the current epoch and re-uses the previous epoch's distribution for pruned samples, ensuring the subset remains representative while reducing training time per epoch.

## Key Results
- Achieves or surpasses full-dataset performance with 30%–50% fewer training samples
- Attains up to 2.81× lossless training speedup
- Improves robustness in imbalanced and noisy settings by 0.3%–7.8%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GDeR dynamically maintains a balanced training subset by sampling based on outlier risk, familiarity, and balancing scores.
- Mechanism: The method computes three metrics for each graph embedding: outlier risk (ωr) via Mahalanobis distance to prototype clusters, familiarity (ωe) via angular distance to own vs. other prototypes, and balancing score (ωb) via cluster size weighting. These are combined into a sampling probability distribution that favors under-learned, minority-class, low-outlier-risk samples.
- Core assumption: Prototype clusters accurately reflect the underlying class structure and can serve as reliable anchors for outlier and balance detection.
- Evidence anchors:
  - [abstract] "samples representative, balanced, and unbiased subsets"
  - [section 3.4] "We propose using a prototype-based Mahalanobis distance to estimate the outlier risk of each graph sample" and "formulate the balancing score for each sample zi as follows"
  - [corpus] Weak - no direct corpus evidence for prototype-based balancing in graph pruning
- Break condition: If prototype clusters are poorly initialized or the data distribution shifts significantly during training, the metrics will no longer reflect true representativeness and balance.

### Mechanism 2
- Claim: GDeR improves robustness by excluding high-outlier-risk samples from training.
- Mechanism: The outlier risk score ωr uses the maximum Mahalanobis distance of a sample to its own class prototypes. Samples with high values are down-weighted in the sampling distribution, reducing their influence on training.
- Core assumption: Outlier samples have larger Mahalanobis distances to their class prototypes than inliers.
- Evidence anchors:
  - [section 3.4] "we propose using a prototype-based Mahalanobis distance to estimate the outlier risk of each graph sample" and "Equation (8) calculates the maximum distance of zi to all prototypes within its class, which serves as a robust outlier detection metric"
  - [abstract] "improve robustness in imbalanced and noisy settings by 0.3%–7.8%"
  - [corpus] Weak - no corpus evidence for Mahalanobis-based outlier filtering in graph pruning
- Break condition: If the data contains label noise or adversarial perturbations that create subtle but not extreme outliers, Mahalanobis distance may not effectively distinguish them from clean samples.

### Mechanism 3
- Claim: GDeR maintains efficiency by dynamically pruning the dataset to 30%-50% of its original size without sacrificing performance.
- Mechanism: At each epoch, GDeR samples a subset Xt using the probability distribution P(t)(z) for the current epoch and P(t-1)(z) for the pruned samples. This ensures the subset remains representative while reducing training time per epoch.
- Core assumption: The sampling distribution P(t)(z) accurately reflects the current training needs and can be approximated by re-using P(t-1)(z) for pruned samples.
- Evidence anchors:
  - [abstract] "achieves or surpasses the performance of the full dataset with 30%–50% fewer training samples" and "attains up to a 2.81× lossless training speedup"
  - [section 3.4] "we obtain the final sampling probability distribution P(t)(z)" and "For ˜Xt, we use the probability distribution P(t-1)(z) from the (t-1)-th epoch"
  - [corpus] Moderate - dynamic pruning literature supports efficiency gains but not specifically for hyperspherical embedding spaces
- Break condition: If the model's learning dynamics change rapidly or the data distribution shifts, the fixed budget s% and reuse of P(t-1)(z) may lead to stale or unrepresentative subsets.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and message-passing mechanism
  - Why needed here: GDeR is designed to work with GNNs and relies on their ability to produce graph-level embeddings for prototype clustering.
  - Quick check question: Can you explain how a 3-layer GCN produces a graph-level embedding from node features and adjacency matrix?

- Concept: Hyperspherical embeddings and von Mises-Fisher (vMF) distribution
  - Why needed here: GDeR projects graph embeddings onto a unit hypersphere and models them with vMF distributions to enable prototype clustering and distance-based sampling.
  - Quick check question: What property of the unit hypersphere makes it suitable for modeling class clusters with vMF distributions?

- Concept: Prototype learning and contrastive objectives
  - Why needed here: GDeR uses trainable prototypes and compactness/separation losses to shape the embedding space before sampling.
  - Quick check question: How do compactness loss and separation loss differ in their effect on prototype arrangement?

## Architecture Onboarding

- Component map:
  - GNN encoder (fθ) -> Graph embeddings
  - Projector (gϕ) -> Hyperspherical embeddings
  - Prototype clusters (Pc) -> Regularized embedding space
  - Scoring functions (ωr, ωe, ωb) -> Sampling probabilities
  - Scheduler (Ψ(t), ˜Ψ(t)) -> Dynamic subset selection
  - Training loop -> Model updates with Ltask + λ1·Lcomp + λ2·Lsepa

- Critical path:
  1. Forward pass through GNN and projector to get embeddings
  2. Assign embeddings to prototype clusters
  3. Compute outlier, familiarity, and balancing scores
  4. Form sampling distribution and select next epoch's subset
  5. Train model on selected subset with full objective

- Design tradeoffs:
  - K (prototype count) vs. embedding space granularity: Higher K gives finer-grained clusters but increases computation.
  - λ1, λ2 (loss coefficients) vs. embedding quality: Too high causes overfitting to prototypes; too low loses regularization benefits.
  - s% (pruning ratio) vs. efficiency vs. performance: Lower s% gives higher speedup but risks under-representing data.

- Failure signatures:
  - Performance degradation despite pruning: Prototype clusters poorly reflect data distribution.
  - Training instability: Loss coefficients λ1, λ2 not well-tuned.
  - No speedup: GNN encoder too lightweight or projector too expensive relative to savings.

- First 3 experiments:
  1. Train GDeR on MUTAG with GCN, K=2, λ1=λ2=0.1, s=0.3; verify 30% speedup and comparable accuracy.
  2. Repeat with s=0.5 and s=0.7; observe performance vs. efficiency tradeoff.
  3. Introduce 5% label noise; confirm GDeR's robustness improvement over baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GDeR perform on extremely large-scale graphs beyond the datasets tested in the paper?
- Basis in paper: [inferred] The paper mentions the challenge of large-scale, imbalanced, and noisy datasets but only tests on five datasets across three GNN backbones.
- Why unresolved: The scalability of GDeR to massive graphs with millions of nodes and edges is not explored.
- What evidence would resolve it: Empirical results on large-scale graph datasets such as OGB-LSC or social network graphs.

### Open Question 2
- Question: Can GDeR be adapted to handle node-level or edge-level graph pruning tasks?
- Basis in paper: [inferred] The paper focuses on graph-level pruning but mentions the lack of solutions for node-level imbalance.
- Why unresolved: The methodology is designed for graph-level embeddings and may not directly extend to node or edge pruning.
- What evidence would resolve it: Demonstrations of GDeR applied to node classification or link prediction tasks with comparable efficiency gains.

### Open Question 3
- Question: How sensitive is GDeR to hyperparameter choices like the number of prototypes (K) or the concentration parameter (κ) in different domains?
- Basis in paper: [explicit] The paper includes a sensitivity analysis on K but does not explore κ or other hyperparameters in depth.
- Why unresolved: The impact of these parameters on performance across diverse graph domains and tasks is not fully characterized.
- What evidence would resolve it: Comprehensive ablation studies varying K, κ, and other hyperparameters across multiple graph datasets and tasks.

## Limitations
- Prototype cluster quality is critical for balancing and outlier detection; poor initialization or distribution shifts can degrade performance.
- The method assumes hyperspherical embeddings and vMF modeling, which may not hold for all graph embedding distributions.
- Hyperparameter sensitivity (K, λ1, λ2) requires careful tuning and may not generalize across diverse graph domains.

## Confidence

- Efficiency gains: High
- Robustness improvements: High
- Balancing claims: Medium
- Universal applicability of prototype-based metrics: Low

## Next Checks

1. **Prototype Sensitivity Analysis**: Systematically vary K (e.g., K ∈ {2, 4, 8}) and measure impact on balancing, efficiency, and robustness across all five datasets. This will reveal whether the method's performance is robust to prototype granularity.

2. **Extreme Imbalance Stress Test**: Create a synthetic dataset with severe class imbalance (e.g., 1:100 ratio) and evaluate whether GDeR's balancing score effectively prioritizes minority samples or if the sampling distribution collapses to majority classes.

3. **Adversarial Noise Robustness**: Inject adversarial edge perturbations into training graphs and measure GDeR's outlier detection efficacy versus Mahalanobis distance. This will test whether the method can distinguish adversarial from natural outliers.