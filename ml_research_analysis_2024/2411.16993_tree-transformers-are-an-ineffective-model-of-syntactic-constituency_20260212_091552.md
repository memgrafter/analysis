---
ver: rpa2
title: Tree Transformers are an Ineffective Model of Syntactic Constituency
arxiv_id: '2411.16993'
source_url: https://arxiv.org/abs/2411.16993
tags:
- tree
- transformer
- sentences
- language
- hierarchical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether Tree Transformers effectively model
  syntactic constituency by examining both learned representations and performance
  on syntactic tasks. The author pretrains a Tree Transformer on masked language modeling
  using the BERT architecture and analyzes the induced tree structures, finding that
  while the model follows some linguistic patterns like merging determiners with nouns,
  it often produces unexpected structures that diverge from linguistic theory.
---

# Tree Transformers are an Ineffective Model of Syntactic Constituency

## Quick Facts
- **arXiv ID**: 2411.16993
- **Source URL**: https://arxiv.org/abs/2411.16993
- **Reference count**: 19
- **Primary result**: Tree Transformers produce unexpected constituent structures and show minimal performance gains over standard transformers on syntactic tasks

## Executive Summary
This paper investigates whether Tree Transformers effectively model syntactic constituency by examining both learned representations and performance on syntactic tasks. The author pretrains a Tree Transformer on masked language modeling using the BERT architecture and analyzes the induced tree structures, finding that while the model follows some linguistic patterns like merging determiners with nouns, it often produces unexpected structures that diverge from linguistic theory. For example, it tends to merge determiners with adjectives rather than adjectives with nouns, and rarely forms constituents for relative clauses. In experiments testing agreement violation detection across three settings (in-distribution, hierarchical generalization, and recursive generalization), Tree Transformers show minimal improvements over standard BERT models, with only a 1.3-2.8% performance gain in the most challenging setting. The results suggest that Tree Transformers do not effectively learn meaningful constituent structures and provide limited benefit for syntactic tasks compared to standard transformers.

## Method Summary
The author pretrains a Tree Transformer model using the BERT architecture on masked language modeling, modifying the attention mechanism to enforce constituent structure. The model calculates constituent probabilities between tokens and constrains standard attention so tokens can only attend to others in the same constituent. At each layer, tokens merge into larger constituents following these probabilities. The learned tree structures are analyzed through breakpoint probabilities and qualitative examination of constituent formation. The model is then evaluated on agreement violation detection tasks across three settings: in-distribution sentences, hierarchical generalization with embedded clauses, and recursive generalization with deeper structures. Performance is compared against a standard BERT model trained on the same data.

## Key Results
- Tree Transformers often merge determiners with adjectives rather than adjectives with nouns, contrary to linguistic theory
- The model rarely forms constituents for relative clauses, instead merging determiners with verbs in relative clauses
- Tree Transformers show only 1.3-2.8% improvement over standard BERT on agreement violation detection in recursive generalization tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tree Transformer uses a modified attention mechanism to enforce constituent structure
- Mechanism: The model calculates constituent probabilities between tokens and constrains standard attention so tokens can only attend to others in the same constituent. At each layer, tokens merge into larger constituents following these probabilities.
- Core assumption: Hierarchical structure can be learned through probabilistic merging of adjacent tokens
- Evidence anchors:
  - [section 3]: "Constituent attention learns which tokens should form constituents, and constrains standard attention so that tokens can only attend to other tokens in the same constituent"
  - [abstract]: "which utilizes a modified attention mechanism to organize tokens into constituents"
- Break condition: When constituent probabilities become too uniform across all possible merges, losing the ability to distinguish meaningful structure

### Mechanism 2
- Claim: Tree Transformer creates hierarchical representations by progressively merging tokens
- Mechanism: The model starts with individual tokens and iteratively merges adjacent pairs based on learned probabilities. Each layer produces larger constituents until all tokens form a single unit.
- Core assumption: Progressive merging captures the hierarchical nature of syntax
- Evidence anchors:
  - [section 3]: "This process is repeated at each level, inducing a tree-like representation where constituents grow larger and larger"
  - [section 4.3]: "breakpoint probabilities tend to be very close to 50% at all tokens in the lowest layer, 75% in the second layer, 87.5% in the third, and so on"
- Break condition: When merging becomes random or follows non-linguistic patterns (e.g., always merging first two words)

### Mechanism 3
- Claim: Tree Transformer's hierarchical bias should improve syntactic generalization
- Mechanism: By explicitly modeling constituent structure, the model should better capture long-distance dependencies and hierarchical patterns in language.
- Core assumption: Explicit constituency modeling provides meaningful inductive bias for syntactic tasks
- Evidence anchors:
  - [abstract]: "Tree Transformer, which utilizes a modified attention mechanism to organize tokens into constituents"
  - [section 5.6.2]: "the main effect of the Tree Transformer modification seems to be to reduce long-distance attention at the lowest layers"
- Break condition: When improvements over standard transformers are minimal or non-existent, as found in the experiments

## Foundational Learning

- Concept: Attention mechanisms in transformers
  - Why needed here: Understanding how Tree Transformer modifies standard attention is crucial for grasping its hierarchical approach
  - Quick check question: How does the constituent attention mechanism constrain standard attention in Tree Transformer?

- Concept: Hierarchical syntax and constituent structure
  - Why needed here: The paper evaluates whether Tree Transformer learns linguistically meaningful structures
  - Quick check question: What is the difference between a determiner-noun constituent and an adjective-noun constituent in standard syntactic theory?

- Concept: Subject-verb agreement and hierarchical generalization
  - Why needed here: The paper uses agreement violation detection to test syntactic capabilities
  - Quick check question: Why does the sentence "the dogs that chase the cat runs" violate agreement rules, while "the dogs that chase the cat run" is correct?

## Architecture Onboarding

- Component map:
  - Standard transformer layers with modified attention mechanism
  - Constituent attention module that calculates merge probabilities
  - Token merging logic that creates hierarchical structure
  - Tree parsing algorithm for extracting learned structures

- Critical path:
  1. Token embedding and positional encoding
  2. Constituent attention calculation at each layer
  3. Constrained attention application
  4. Progressive token merging across layers
  5. Tree structure extraction and analysis

- Design tradeoffs:
  - Explicit constituency modeling vs. standard transformer flexibility
  - Hierarchical bias vs. ability to learn long-distance dependencies
  - Discrete structure representation vs. continuous embeddings

- Failure signatures:
  - Uniform breakpoint probabilities across all positions
  - Constituent structures that don't match linguistic expectations
  - Minimal performance improvements on syntactic tasks

- First 3 experiments:
  1. Train a Tree Transformer on masked language modeling and analyze the learned constituent structures on simple sentences
  2. Compare Tree Transformer and standard transformer performance on subject-verb agreement detection
  3. Test generalization to deeper sentences with embedded clauses to evaluate recursive capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would Tree Transformers perform on languages with more complex syntactic structures than English, such as languages with rich case systems or free word order?
- Basis in paper: [explicit] The paper focuses exclusively on English data and agreement rules, noting this as a limitation in the discussion section.
- Why unresolved: The paper only tests on English data, leaving open the question of whether Tree Transformers would show different performance patterns on languages with different syntactic properties.
- What evidence would resolve it: Testing Tree Transformer models on multiple languages with varying syntactic complexity and comparing performance across these languages.

### Open Question 2
- Question: Would modifying the Tree Transformer architecture to allow tokens to attend across constituent boundaries in higher layers improve its ability to learn hierarchical and recursive generalizations?
- Basis in paper: [inferred] The discussion section identifies a key limitation that Tree Transformer enforces a single constituent structure and limits cross-constituent attention, which may interfere with learning long-distance dependencies.
- Why unresolved: The current Tree Transformer architecture enforces strict constituent boundaries at all levels, and the paper suggests this may be a fundamental limitation that prevents it from matching the flexibility of standard transformers.
- What evidence would resolve it: Implementing and testing a modified Tree Transformer that allows cross-constituent attention in higher layers and comparing its performance to both standard Tree Transformers and standard transformers.

### Open Question 3
- Question: Would Tree Transformers show greater improvements if pretrained on larger datasets or with curriculum learning approaches that gradually introduce more complex structures?
- Basis in paper: [explicit] The paper notes that their pretrained Tree Transformer used an order of magnitude less data than BERT and suggests that full pretraining might demonstrate greater improvements.
- Why unresolved: The paper's pretrained Tree Transformer was trained on significantly less data than standard BERT, making it unclear whether the limited performance improvements were due to the architecture itself or insufficient pretraining.
- What evidence would resolve it: Training Tree Transformers with full-scale pretraining datasets and comparing their performance to BERT models with equivalent pretraining, or testing curriculum learning approaches that start with simpler structures and gradually increase complexity.

## Limitations

- Results are based on a single Tree Transformer variant and one pretraining approach, limiting generalizability to other implementations
- Analysis focuses exclusively on English data, making it unclear whether findings apply to languages with different syntactic properties
- The paper doesn't explore whether different training objectives, architectural modifications, or hyperparameter settings could yield better constituent learning

## Confidence

**High confidence**: The finding that Tree Transformers produce unexpected constituent structures that diverge from linguistic theory is well-supported by the qualitative analysis and breakpoint probability data. The minimal performance improvements over standard transformers are also clearly demonstrated across multiple experimental settings.

**Medium confidence**: The claim that Tree Transformers are "ineffective" at modeling syntactic constituency may be overstated. While the specific implementation studied shows limited success, other variants or training approaches might perform differently. The conclusion that explicit constituency modeling provides little benefit assumes that syntactic competence should manifest primarily through improved agreement detection performance.

**Low confidence**: The paper doesn't provide strong evidence about why Tree Transformers fail to learn meaningful structures. Alternative explanations, such as insufficient training data, suboptimal hyperparameters, or the specific choice of BERT architecture, are not thoroughly explored.

## Next Checks

1. **Architecture Ablation Study**: Systematically test different Tree Transformer variants with varying constituent attention mechanisms, merge strategies, and training objectives to determine which architectural components are responsible for the poor performance. Compare results against standard transformers with equivalent parameter counts.

2. **Cross-linguistic Generalization**: Evaluate the same Tree Transformer implementation on languages with richer morphological case systems (e.g., German, Russian) where syntactic dependencies are more explicitly marked. This would test whether the model's limitations are specific to English syntax or represent more fundamental issues with hierarchical learning.

3. **Extended Syntactic Evaluation**: Design targeted syntactic evaluation tasks beyond agreement detection, including long-distance dependency resolution, filler-gap dependencies, and recursive structure parsing. Compare performance against strong syntactic baselines to determine if Tree Transformers show advantages in any specific syntactic domains.