---
ver: rpa2
title: Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech
  Conversational LLM
arxiv_id: '2409.17353'
source_url: https://arxiv.org/abs/2409.17353
tags:
- audio
- response
- speech
- icot
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes internalizing the ASR (Automatic Speech Recognition)
  chain of thought into a speech-based LLM to enable more efficient and natural speech-to-speech
  conversations. The key idea is to train the model to bypass explicit ASR transcription
  during inference while maintaining speech conversation capabilities, thereby reducing
  latency.
---

# Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM

## Quick Facts
- arXiv ID: 2409.17353
- Source URL: https://arxiv.org/abs/2409.17353
- Reference count: 18
- Key outcome: 20.2% latency reduction while maintaining competitive conversational quality (42.3% win rate vs A-T-T-A)

## Executive Summary
This paper introduces ICoT (Implicit Chain of Thought) reasoning to internalize ASR (Automatic Speech Recognition) processing within a speech-based LLM, enabling more efficient speech-to-speech conversations. The method progressively removes explicit ASR transcription tokens during training, allowing the model to generate speech responses directly from audio input while maintaining conversational quality. The approach achieves significant latency improvements over traditional cascaded systems and demonstrates the potential for more natural, real-time speech interactions.

## Method Summary
The method uses a two-stage training process: first fine-tuning the AnyGPT model with standard CoT prompting, then applying LoRA-based ICoT training to internalize ASR reasoning. During ICoT training, the model progressively removes audio transcript tokens from the generation template, forcing it to learn direct speech-to-speech mapping. The approach leverages curriculum learning principles, gradually increasing the difficulty of token removal to maintain training stability while achieving internalization.

## Key Results
- 20.2% latency reduction compared to A-T-T-A baseline while maintaining conversational quality
- 42.3% win rate against A-T-T-A finetuned model in LLM evaluations
- Significantly outperforms models without ASR CoT or ICoT internalization
- ICoT successfully internalizes ASR but not TTS, highlighting modality-specific challenges

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Internalizing ASR CoT tokens via ICoT reduces inference latency while preserving conversational quality
- **Mechanism**: Progressive removal of audio transcript tokens during training forces the model to learn direct speech-to-speech generation, eliminating the need for explicit transcription
- **Core assumption**: The model can implicitly learn intermediate reasoning steps that were previously explicit
- **Evidence anchors**: 20.2% latency reduction while maintaining competitive conversational quality; two-stage training with progressive token removal
- **Break condition**: Model fails to maintain quality when all ASR CoT tokens are removed

### Mechanism 2
- **Claim**: ICoT training enables zero-shot reasoning without explicit intermediate steps
- **Mechanism**: Model learns to generate both text response and audio output directly from audio input by internalizing ASR reasoning process
- **Core assumption**: Model can implicitly perform the same reasoning that was previously explicit in CoT
- **Evidence anchors**: Direct speech-to-speech generation capability; elimination of audio transcript generation during inference
- **Break condition**: Model generates incoherent responses when ASR CoT tokens are removed

### Mechanism 3
- **Claim**: LoRA fine-tuning enables efficient adaptation of the base model for ICoT
- **Mechanism**: Low-Rank Adaptation modifies only a small subset of model parameters in attention mechanisms rather than full fine-tuning
- **Core assumption**: LoRA can effectively capture changes needed for internalizing ASR CoT without requiring full fine-tuning
- **Evidence anchors**: LoRA with rank=32 and alpha=32 used for ICoT training; efficient parameter modification
- **Break condition**: Model fails to internalize ASR CoT when using LoRA, requiring full fine-tuning instead

## Foundational Learning

- **Concept**: Chain-of-Thought (CoT) prompting
  - Why needed here: ICoT builds on CoT as foundation for understanding how explicit intermediate reasoning improves performance
  - Quick check question: What is the key difference between standard prompting and Chain-of-Thought prompting in terms of how the model generates responses?

- **Concept**: Curriculum learning
  - Why needed here: ICoT uses curriculum learning approach where difficulty increases gradually during training
  - Quick check question: How does curriculum learning differ from standard fine-tuning in terms of training process and objectives?

- **Concept**: Discrete speech tokenization
  - Why needed here: Model operates on discrete speech tokens rather than raw audio
  - Quick check question: What are the advantages and disadvantages of using discrete speech tokens compared to continuous audio representations?

## Architecture Onboarding

- **Component map**: Audio input → SpeechTokenizer → Model (with internalized ASR) → Discrete audio tokens → Audio output
- **Critical path**: The critical optimization is removing the audio transcript generation step from the pipeline
- **Design tradeoffs**:
  - Latency vs. quality: Removing ASR CoT reduces latency but may slightly impact quality (42.3% win rate)
  - Training complexity: Two-stage training with LoRA adds complexity but reduces parameter changes
  - Generalization: ICoT works for ASR but not TTS, suggesting different mechanisms needed for different modalities
- **Failure signatures**:
  - Grammatically incoherent responses (seen in A-T-A No ASR ICoT baseline)
  - Loss of contextual relevance (seen in A-A ICoT baseline)
  - No latency improvement (if ICoT fails to internalize properly)
  - Overfitting to training data (if curriculum progression is too aggressive)
- **First 3 experiments**:
  1. Baseline comparison: Train A-T-T-A finetuned model and measure latency and quality to establish baseline metrics
  2. ICoT ablation: Train with ICoT but with minimal token removal (T=2000) to verify mechanism works before full implementation
  3. Curriculum progression: Test different values of T (500, 1000, 2000) to find optimal balance between training stability and internalization effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance change when applying internalized ASR model to languages other than English, particularly low-resource languages?
- Basis in paper: Paper uses English conversational dataset and doesn't explore multilingual capabilities
- Why unresolved: Current evaluation limited to English; no insights into cross-lingual generalization
- What evidence would resolve it: Evaluating on multilingual datasets and low-resource languages with comparative performance metrics

### Open Question 2
- Question: What is the impact of varying the number of CoT tokens removed per step (T) on model performance and latency?
- Basis in paper: Paper mentions T=500 but doesn't explore effects of different T values
- Why unresolved: Choice of T=500 based on stability, but effects of different values on performance-latency balance unexplored
- What evidence would resolve it: Experiments with varying T values and analysis of their impact on conversational quality and latency

### Open Question 3
- Question: How does model performance change when internalizing TTS CoT with different curriculum learning strategies or parameter adjustments?
- Basis in paper: TTS ICoT attempt with different T value (T=2000) and smaller learning rate found ineffective
- Why unresolved: Paper doesn't explore alternative curriculum strategies or parameter adjustments for TTS ICoT
- What evidence would resolve it: Experimenting with various curriculum learning strategies and parameter adjustments for TTS ICoT

## Limitations

- ICoT successfully internalizes ASR but not TTS, indicating modality-specific challenges that require different approaches
- Evaluation methodology relies on LLM-based judgments which may not fully capture human perception of conversational quality
- Synthetic dataset, while large, may not fully represent diversity of real conversational speech

## Confidence

- High confidence: Basic premise that removing intermediate ASR transcription steps can reduce latency is well-supported by experimental results
- Medium confidence: Claim that ICoT maintains competitive conversational quality is supported but LLM evaluation methodology introduces uncertainty
- Low confidence: Assertion that LoRA is sufficient for effective ICoT training, as paper doesn't provide ablation studies comparing LoRA vs full fine-tuning

## Next Checks

1. Conduct human evaluation studies to validate LLM-based evaluation results, particularly for conversational naturalness and coherence metrics
2. Compare performance of LoRA-based ICoT against full fine-tuning to verify efficiency claims through ablation studies
3. Evaluate trained model on naturalistic conversational datasets beyond synthetic SODA-based corpus to assess real-world generalization