---
ver: rpa2
title: 'GASP: Gaussian Avatars with Synthetic Priors'
arxiv_id: '2412.07739'
source_url: https://arxiv.org/abs/2412.07739
tags:
- gaussian
- prior
- data
- avatar
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GASP, a method for creating high-quality,
  real-time, animatable 3D avatars from limited data such as a single image or short
  video. The key innovation is using a synthetic dataset to train a Gaussian Avatar
  prior, which helps fill in unseen regions when fitting to real data.
---

# GASP: Gaussian Avatars with Synthetic Priors

## Quick Facts
- arXiv ID: 2412.07739
- Source URL: https://arxiv.org/abs/2412.07739
- Reference count: 40
- Key outcome: Achieves PSNR of 21.34 in monocular training, significantly outperforming DiffusionRig (19.67) and FlashAvatar (17.25)

## Executive Summary
GASP introduces a novel approach to creating high-quality, real-time, animatable 3D avatars from limited data. The key innovation is using a synthetic dataset to train a Gaussian Avatar prior, which helps fill in unseen regions when fitting to real data. The method employs a three-stage fitting process and learned per-Gaussian features to overcome the domain gap between synthetic and real data. Results show GASP significantly outperforms state-of-the-art methods in both monocular and single-image settings, achieving 70fps rendering on commercial hardware.

## Method Summary
GASP addresses the challenge of creating high-quality 3D avatars from limited data by training a Gaussian Avatar prior on a synthetic dataset. The method uses a three-stage fitting process: inversion (optimizing identity code), MLP fine-tuning, and Gaussian Splatting refinement. The synthetic prior is trained using an auto-decoder architecture with identity codes and per-Gaussian features, which helps fill in unseen regions when fitting to real data. The approach employs mesh-attached Gaussians with learned offsets and combines synthetic and real data during optimization to reduce the domain gap. The method achieves real-time performance at 70fps on commercial hardware while maintaining high quality across multiple evaluation metrics.

## Key Results
- In monocular training, GASP achieves PSNR of 21.34 compared to 19.67 for DiffusionRig and 17.25 for FlashAvatar
- The method runs at 70fps on commercial hardware, demonstrating real-time performance
- GASP significantly outperforms state-of-the-art methods across multiple metrics including SSIM, LPIPS, FID, and ID-SIM

## Why This Works (Mechanism)
GASP works by leveraging a synthetic dataset to train a Gaussian Avatar prior that captures common facial features and structures. This prior helps the model generalize better when fitting to real data, particularly in unseen regions. The three-stage fitting process allows for efficient optimization: first establishing a reasonable starting point through identity code optimization, then fine-tuning the MLP for better feature extraction, and finally refining the Gaussian Splatting representation. The learned per-Gaussian features enable the model to distinguish between different semantic regions and apply appropriate regularization during fitting.

## Foundational Learning
- Gaussian Splatting: 2D Gaussian primitives for efficient 3D representation - needed for real-time rendering performance
- Auto-decoder architectures: Learning without explicit supervision through latent code optimization - needed for identity-specific avatar generation
- Domain adaptation: Techniques to reduce differences between synthetic and real data distributions - needed to bridge the synthetic-to-real gap
- Multi-view geometry: Understanding 3D structure from multiple camera views - needed for accurate avatar reconstruction
- Learned feature representations: Neural networks that extract meaningful features from data - needed for semantic understanding of Gaussian attributes

## Architecture Onboarding

Component map: Synthetic dataset -> Gaussian Avatar Prior -> Three-stage fitting -> Real-time rendering

Critical path: Identity code optimization -> MLP fine-tuning -> Gaussian Splatting refinement

Design tradeoffs:
- Synthetic vs real data: Using synthetic data enables perfect annotations but introduces domain gap
- Three-stage vs single-stage fitting: More stages provide better optimization but increase complexity
- Per-Gaussian features vs global features: More granular features improve quality but require more parameters

Failure signatures:
- Poor quality in unseen regions indicates insufficient prior regularization
- Overfitting to training view suggests inadequate identity code optimization
- Slow convergence points to improper learning rate scheduling

First experiments:
1. Test identity code optimization stage on a simple synthetic dataset
2. Evaluate per-Gaussian feature learning on synthetic data with known semantic labels
3. Benchmark three-stage fitting against single-stage on a small real dataset

## Open Questions the Paper Calls Out

Open Question 1: What is the optimal number of subjects to include in the synthetic dataset for training the Gaussian Avatar prior?
- Basis in paper: The paper shows an ablation study varying the number of prior subjects from 1 to 1000, with performance improving as more subjects are added.
- Why unresolved: The study only tests up to 1000 subjects. The relationship between prior size and performance is not characterized to determine if there's a point of diminishing returns.
- What evidence would resolve it: A systematic study varying the number of subjects well beyond 1000 (e.g., 1k, 5k, 10k, 50k, 100k) to identify the saturation point where additional subjects provide negligible improvement.

Open Question 2: How can the synthetic-to-real domain gap be further reduced to improve quality in unseen regions?
- Basis in paper: The authors acknowledge that synthetic data introduces a domain gap problem and that their method still produces synthetic-looking results in some regions like the back of the head.
- Why unresolved: The paper proposes learned semantic Gaussian features and a three-stage fitting process to address this, but doesn't explore other potential solutions or quantify the remaining domain gap.
- What evidence would resolve it: Comparative studies of different domain adaptation techniques (e.g., adversarial training, style transfer, meta-learning) applied to the Gaussian Avatar prior, measuring improvement in unseen region quality.

Open Question 3: How does the proposed method perform on subjects with significant variations in appearance (e.g., different skin tones, hair types, accessories)?
- Basis in paper: The paper mentions the synthetic dataset is "highly diverse" but doesn't provide detailed quantitative analysis of performance across different demographic groups or appearance variations.
- Why unresolved: The evaluation focuses on overall metrics without breaking down performance by demographic factors, which is important for fairness and generalizability.
- What evidence would resolve it: A comprehensive analysis evaluating the method's performance across different demographic groups, skin tones, hair types, and appearance variations, with quantitative metrics for each subgroup.

## Limitations
- Dependence on synthetic dataset for prior training raises questions about generalizability to diverse real-world scenarios
- The method still produces synthetic-looking results in some regions like the back of the head
- User study validation has limited sample size (20 participants)

## Confidence
High: Quantitative comparisons on NeRSemble dataset showing clear PSNR improvements over DiffusionRig and FlashAvatar
Medium: 70fps rendering claim without comparison with other real-time methods on identical hardware
Low: Limited evaluation of performance across different demographic groups and appearance variations

## Next Checks
1. Test GASP's performance on diverse real-world datasets beyond NeRSemble to assess generalizability from synthetic priors
2. Conduct a detailed ablation study isolating the contribution of each component in the three-stage fitting process
3. Benchmark rendering performance against other real-time Gaussian avatar methods on identical hardware configurations