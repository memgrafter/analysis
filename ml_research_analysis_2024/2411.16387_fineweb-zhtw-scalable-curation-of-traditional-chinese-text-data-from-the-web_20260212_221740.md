---
ver: rpa2
title: 'FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the
  Web'
arxiv_id: '2411.16387'
source_url: https://arxiv.org/abs/2411.16387
tags:
- dataset
- language
- chinese
- content
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FineWeb-zhtw addresses the lack of large-scale, high-quality Traditional
  Chinese text datasets for training large language models. The authors extended the
  FineWeb pipeline to handle Traditional Chinese linguistic nuances, implementing
  multiple stages of filtering including basic text extraction, custom language identification,
  and adapted versions of Gopher, C4, and FineWeb quality filters.
---

# FineWeb-zhtw: Scalable Curation of Traditional Chinese Text Data from the Web

## Quick Facts
- arXiv ID: 2411.16387
- Source URL: https://arxiv.org/abs/2411.16387
- Reference count: 13
- One-line primary result: FineWeb-zhtw achieves mean evaluation scores of 2.42 (Traditional Chinese naturalness), 2.04 (educational value), and 4.72 (sensitive content handling) across 1,000 samples

## Executive Summary
FineWeb-zhtw addresses the critical shortage of large-scale, high-quality Traditional Chinese text datasets for training large language models. The authors extended the existing FineWeb pipeline to handle Traditional Chinese linguistic nuances through a comprehensive multi-stage filtering approach. By implementing custom language identification, adapted quality filters, and minhash deduplication, they created a dataset of over 13 million documents with a 99.5% screening rate. The dataset was rigorously evaluated using GPT-3.5 across three quality dimensions, demonstrating significant improvements over baseline filtering approaches.

## Method Summary
The authors implemented a comprehensive pipeline to process Common Crawl data, utilizing various filtering techniques at each stage. The process begins with extracting documents from WARC files using trafilatura, followed by basic filtering, custom language identification for Traditional Chinese, and sequential application of Gopher, C4, and FineWeb quality filters. The pipeline concludes with minhash deduplication to remove redundant content. A custom Traditional Chinese language identification filter was designed to differentiate between Traditional and Simplified Chinese using character and word-phrase filtering with fuzzy Traditional Chinese tokens defined by Unicode ranges.

## Key Results
- Achieved total mean evaluation score of 9.17 across 1,000 samples using GPT-3.5
- Significant improvements over basic filtering and language identification only pipelines (t-statistic of 5.36, p-value = 9.14e-08)
- Final dataset contains over 13 million documents with 99.5% screening rate
- Mean scores: Traditional Chinese naturalness (2.42), Educational value (2.04), Sensitive content handling (4.72)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-stage filtering pipeline effectively removes low-quality and irrelevant Traditional Chinese text while preserving high-quality educational content.
- Mechanism: Sequential application of basic filtering, language identification, Gopher filters, C4 filters, FineWeb quality filters, and minhash deduplication progressively removes unwanted content while maintaining content quality through strict criteria at each stage.
- Core assumption: Each filtering stage independently improves dataset quality without introducing bias that would eliminate valuable content.
- Evidence anchors:
  - [abstract] "We came up with multiple stages of meticulously designed filters to cater to the linguistic difference between English and Traditional Chinese"
  - [section 2.7] "Figure 1 illustrates the global removal rate and the relative retention rates of documents at each stage"
  - [section 3.2] "Results show that the FineWeb-zhtw dataset has consistent improvements across all categories compared to the datasets after basic filtering and language identification"
- Break condition: If any single filter stage removes too much content (over-filtering), or if the filters are too lenient (under-filtering), the final dataset quality would degrade.

### Mechanism 2
- Claim: The custom Traditional Chinese language identification filter effectively distinguishes between Traditional and Simplified Chinese content.
- Mechanism: The filter uses a combination of character and word-phrase filtering with fuzzy Traditional Chinese tokens defined by Unicode ranges, blocking documents that don't meet the criteria.
- Core assumption: The custom filter can accurately identify Traditional Chinese text without false positives or negatives that would compromise dataset composition.
- Evidence anchors:
  - [section 2.2] "Most language identifiers, such as fasttext, do not differentiate between Traditional Chinese and Simplified Chinese"
  - [section 2.2] "we designed a custom filter in addition to fasttext, with character and word-phrase filtering"
  - [section 3.2] "Significant improvements with FineWeb-zhtw are supported by a t-statistic of 5.36 (p-value = 9.14e-08)"
- Break condition: If the custom filter cannot maintain high precision/recall in distinguishing character variants, the dataset would contain inappropriate language variants.

### Mechanism 3
- Claim: GPT-3.5 evaluation provides reliable quality assessment of the dataset across multiple dimensions.
- Mechanism: Automated scoring using a large language model with detailed prompts covering Traditional Chinese naturalness, educational value, and sensitive content detection.
- Core assumption: The LLM scoring agent can consistently and accurately evaluate text quality across the three specified criteria.
- Evidence anchors:
  - [section 3.1] "We utilized 'language model as a scoring agent' to automate and streamline this evaluation"
  - [section 3.2] "Figure 2 presents the evaluation results for the different datasets, highlighting the distribution of scores and mean values"
  - [section 3.2] "T-tests confirm significant differences between all pairings"
- Break condition: If the LLM scoring criteria don't align with human judgment or the prompt isn't specific enough, evaluation results could be unreliable.

## Foundational Learning

- Concept: Traditional Chinese vs Simplified Chinese character sets and linguistic differences
  - Why needed here: The dataset specifically targets Traditional Chinese users, requiring filters that can distinguish between the two character variants
  - Quick check question: Can you identify which Unicode ranges correspond to Traditional Chinese characters versus Simplified Chinese characters?

- Concept: Web data extraction and W ARC format processing
  - Why needed here: The dataset is built from Common Crawl W ARC files, requiring understanding of how to extract text from HTML content
  - Quick check question: What are the key steps in processing W ARC files to extract usable text content?

- Concept: Minhash algorithms for document deduplication
  - Why needed here: The pipeline uses minhash deduplication to remove repetitive content from the dataset
  - Quick check question: How does minhash compare documents for similarity, and what parameters affect its effectiveness?

## Architecture Onboarding

- Component map: Data ingestion (W ARC files) → Basic filtering → Language identification → Gopher filters → C4 filters → FineWeb filters → Minhash deduplication → GPT-3.5 evaluation
- Critical path: Language identification → Quality filters → Evaluation, as these directly determine dataset composition and quality metrics
- Design tradeoffs: Strict filtering improves quality but reduces dataset size; custom Traditional Chinese filters increase accuracy but require maintenance
- Failure signatures: Low retention rates after filtering indicate over-aggressive filters; poor evaluation scores suggest inadequate filtering
- First 3 experiments:
  1. Run the pipeline on a small subset of Common Crawl and verify the language identification filter's precision/recall
  2. Test the evaluation pipeline with known good/bad samples to validate GPT-3.5 scoring consistency
  3. Measure the impact of each filter stage individually to identify potential over-filtering issues

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific Traditional Chinese linguistic features were identified as most challenging for the filtering pipeline, and how were these addressed?
- Basis in paper: [explicit] The paper mentions that "the unique linguistic and cultural nuances of Traditional Chinese, such as lack of spacing, hinder the direct projection of current pipelines, which necessitates a specialized refinement approach."
- Why unresolved: The paper states that specialized refinement was needed but does not detail which specific linguistic features posed the greatest challenges or how they were specifically addressed in the filtering pipeline.
- What evidence would resolve it: Detailed analysis of the linguistic challenges encountered during pipeline development, including specific examples of Traditional Chinese features that required special handling and the corresponding technical solutions implemented.

### Open Question 2
- Question: How does the performance of models trained on FineWeb-zhtw compare to those trained on other Traditional Chinese datasets in downstream tasks?
- Basis in paper: [inferred] The paper focuses on dataset curation and quality evaluation but does not provide empirical comparisons of model performance using FineWeb-zhtw versus other Traditional Chinese datasets.
- Why unresolved: While the paper establishes the quality of FineWeb-zhtw through manual evaluation, it does not conduct experiments to demonstrate how models trained on this dataset perform relative to those trained on existing Traditional Chinese datasets.
- What evidence would resolve it: Empirical studies comparing model performance on various downstream tasks (e.g., text classification, question answering) when trained on FineWeb-zhtw versus other established Traditional Chinese datasets.

### Open Question 3
- Question: What are the long-term implications of the 40x data size gap between English and Traditional Chinese datasets for the development of Traditional Chinese language models?
- Basis in paper: [explicit] The paper states "At the language identification stage, the gap between the data size of English and Traditional Chinese is already around 40x."
- Why unresolved: The paper identifies the data gap but does not explore its potential long-term consequences for the development of Traditional Chinese language models or strategies to address this disparity.
- What evidence would resolve it: Analysis of how the data gap affects model capabilities, research on strategies to bridge the gap (e.g., data augmentation, cross-lingual transfer learning), and projections of the impact on the future development of Traditional Chinese language models.

## Limitations

- The evaluation methodology relies heavily on GPT-3.5 as a scoring agent, which may not perfectly align with human judgment of Traditional Chinese quality
- The custom Traditional Chinese language identification filter's performance metrics (precision/recall) are not explicitly reported
- The paper does not address potential cultural or regional variations within Traditional Chinese usage across different regions

## Confidence

**High Confidence Claims:**
- The multi-stage filtering pipeline structure and its sequential application
- The dataset's availability through Hugging Face
- The basic statistical outcomes (total documents, screening rate of 99.5%)

**Medium Confidence Claims:**
- The relative improvement of FineWeb-zhtw over baseline filtering methods
- The effectiveness of the custom Traditional Chinese language identification filter
- The quality scores achieved in GPT-3.5 evaluation

**Low Confidence Claims:**
- The absolute quality of the dataset for specific downstream tasks
- The generalizability of the filtering approach to other languages or character sets
- The long-term stability of the evaluation criteria across different GPT model versions

## Next Checks

1. **Language Filter Validation**: Manually examine 100 randomly selected documents from the filtered dataset to verify the custom Traditional Chinese language identification filter's accuracy in distinguishing between Traditional and Simplified Chinese, and identify any systematic errors in character variant classification.

2. **Evaluation Consistency Test**: Run the same 1,000 evaluation samples through multiple GPT model versions (including GPT-4) and compare consistency of scoring across different model iterations to assess the stability of the quality evaluation methodology.

3. **Downstream Task Performance**: Train a small-scale Traditional Chinese language model using FineWeb-zhtw and evaluate its performance on established Traditional Chinese benchmarks (such as CLUE or ChineseGLUE) to validate that the quality improvements translate to practical utility.