---
ver: rpa2
title: 'SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time
  Dynamic Graphs'
arxiv_id: '2405.19062'
source_url: https://arxiv.org/abs/2405.19062
tags:
- graph
- causal
- temporal
- dynamic
- subgraph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SIG, the first self-interpretable graph neural
  network designed for continuous-time dynamic graphs (CTDGs). The key innovation
  is the Independent and Confounded Causal Model (ICCM), which addresses both independent
  and identically distributed (IID) and out-of-distribution (OOD) data by separating
  causal subgraphs from confounding factors.
---

# SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs

## Quick Facts
- arXiv ID: 2405.19062
- Source URL: https://arxiv.org/abs/2405.19062
- Reference count: 40
- Primary result: First self-interpretable GNN for CTDGs achieving 99.99% average AUC/AP

## Executive Summary
This paper introduces SIG, the first self-interpretable graph neural network designed for continuous-time dynamic graphs (CTDGs). The key innovation is the Independent and Confounded Causal Model (ICCM), which addresses both IID and out-of-distribution (OOD) data by separating causal subgraphs from confounding factors. SIG efficiently generates causal subgraphs and representations using normalized weighted geometric mean (NWGM) approximation to avoid computationally expensive pairwise interventions. Experiments on five real-world datasets show that SIG significantly outperforms state-of-the-art methods, achieving 99.99% AUC and 99.99% AP on average, while also providing interpretable explanations with 42.09% fidelity.

## Method Summary
SIG is a self-interpretable GNN that processes continuous-time dynamic graphs through an Independent and Confounded Causal Model (ICCM). The model extracts temporal and structural subgraphs using recent edge sequences and n-hop neighborhoods, then encodes these using temporal and structural encoders. To handle confounders efficiently, SIG employs NWGM approximation to avoid pairwise interventions, using deep learning clustering to generate a confounder dictionary. The model predicts links through a combination of IID classifiers and intervention-based classifiers that account for both temporal and structural information.

## Key Results
- Achieves 99.99% average AUC and AP across five datasets, surpassing best baseline by 1.25% in AP and 0.92% in AUC
- Provides interpretable explanations with 42.09% fidelity at 0.6 sparsity, outperforming baselines by 17.10%
- Demonstrates strong robustness to distribution shifts, maintaining high performance across varying levels of synthetic bias injection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SIG's ICCM separates causal subgraphs from confounding factors, enabling both IID and OOD data handling.
- Mechanism: ICCM combines Independent Causal Model (ICM) for IID data and Confounded Causal Model (CCM) for OOD data, using do-operations to block backdoor paths created by confounders.
- Core assumption: The causal subgraph is the unique exogenous variable influencing the prediction label in IID data, while confounders act as shortcut features in OOD data.
- Evidence anchors:
  - [abstract] "ICCM, which addresses both independent and identically distributed (IID) and out-of-distribution (OOD) data by separating causal subgraphs from confounding factors."
  - [section] "The ICM is designed for IID data, where the causal subgraph is the unique exogenous variable influencing the predictive label. In contrast, the CCM is tailored for OOD data, where shortcut features act as confounding factors..."
- Break condition: If the separation between causal subgraphs and confounders is not maintained, spurious correlations will persist, degrading performance on OOD data.

### Mechanism 2
- Claim: NWGM approximation enables efficient intervention optimization by avoiding computationally expensive pairwise interventions.
- Mechanism: Instead of directly pairing causal subgraphs with each confounder, NWGM approximates the expectation of confounders, reducing computational complexity from O(|D|) to constant time.
- Core assumption: The confounder dictionary D can be approximated by a representation matrix generated through deep learning clustering.
- Evidence anchors:
  - [abstract] "SIG efficiently generates causal subgraphs and representations using normalized weighted geometric mean (NWGM) approximation to avoid computationally expensive pairwise interventions."
  - [section] "To address this, we leverage the Normalized Weighted Geometric Mean (NWGM) approximation [41], i.e., Ed∼D[σ[W c ∗ f s y(H S) + W c ∗ f u y (d)]] ≈ σ[Ed∼D[W c ∗ f s y(H S) + W c ∗ f u y (d)]]."
- Break condition: If the NWGM approximation fails to accurately represent the expectation of confounders, the model's performance on OOD data will degrade.

### Mechanism 3
- Claim: Temporal and structural subgraph extraction captures invariant patterns across both IID and OOD data.
- Mechanism: SIG extracts temporal subgraphs using edge sequences and structural subgraphs using n-hop neighborhoods, encoding them into representations H T and H S that are used for prediction.
- Core assumption: The top-k most recent temporal edges and n-hop structural neighbors contain the most relevant causal information for link prediction.
- Evidence anchors:
  - [section] "SIG employs two causal subgraph extractors to extract structural and temporal subgraphs ˆCs and ˆCt from the input data. These extracted subgraphs are then used to approximate Cs and Ct."
  - [section] "The node mask matrices are computed through the equations: M n v = Softmax[z T u Zv√ d], M n u = Softmax[z T v Zu√ d], ˆCs = TOPk(M n u , M n v)."
- Break condition: If the extracted subgraphs do not contain the relevant causal information, the model will fail to capture invariant patterns, leading to poor performance on both IID and OOD data.

## Foundational Learning

- Concept: Causal inference and do-operations
  - Why needed here: To handle confounding factors and remove spurious correlations in OOD data
  - Quick check question: What is the difference between P(Y|X) and P(Y|do(X)) in the presence of confounders?

- Concept: Graph neural networks and representation learning
  - Why needed here: To encode temporal and structural information from the extracted causal subgraphs
  - Quick check question: How do temporal GNNs differ from static GNNs in handling dynamic graph data?

- Concept: Mutual information and variational bounds
  - Why needed here: To formulate the learning objective as maximizing mutual information between causal subgraphs and prediction labels
  - Quick check question: Why is maximizing mutual information equivalent to minimizing a variational upper bound of the risk functions?

## Architecture Onboarding

- Component map: Input graph -> Causal subgraph extraction -> Encoding -> Confounder generation -> Prediction (IID + interventions)
- Critical path: Input graph → Causal subgraph extraction → Encoding → Confounder generation → Prediction (IID + interventions)
- Design tradeoffs:
  - Computational efficiency vs. accuracy: NWGM approximation reduces complexity but may introduce approximation errors
  - Sparsity of explanations vs. fidelity: Higher sparsity leads to more interpretable explanations but may reduce fidelity
- Failure signatures:
  - Poor performance on OOD data: Indicates issues with confounding factor handling or NWGM approximation
  - Low fidelity of explanations: Suggests problems with causal subgraph extraction or encoding
  - High computational cost: May indicate inefficient implementation of NWGM or subgraph extraction
- First 3 experiments:
  1. Verify causal subgraph extraction by visualizing extracted subgraphs and checking if they contain relevant causal information
  2. Test NWGM approximation by comparing its output with direct pairwise intervention results on small graphs
  3. Evaluate performance on OOD data by injecting synthetic biases and measuring degradation in AP and AUC metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SIG compare when applied to graphs with varying levels of dynamic complexity, such as those with frequent structural changes versus those with stable structures over time?
- Basis in paper: [inferred] The paper demonstrates SIG's effectiveness on real-world datasets but does not explore performance across graphs with different dynamic complexities.
- Why unresolved: The paper does not provide experiments or analysis comparing SIG's performance on graphs with varying degrees of dynamic complexity.
- What evidence would resolve it: Experiments comparing SIG's performance on datasets with different levels of structural change over time, such as graphs with high-frequency edge additions/removals versus stable graphs.

### Open Question 2
- Question: What are the specific limitations of the Normalized Weighted Geometric Mean (NWGM) approximation in handling large-scale graphs, and how does it impact the model's scalability?
- Basis in paper: [explicit] The paper mentions using NWGM to avoid computationally expensive pairwise interventions but does not discuss its limitations or scalability issues.
- Why unresolved: The paper does not provide a detailed analysis of NWGM's limitations or its impact on scalability in large-scale graphs.
- What evidence would resolve it: A thorough analysis of NWGM's computational complexity and its performance degradation with increasing graph size, along with potential alternative approximations.

### Open Question 3
- Question: How does the choice of hyperparameters, such as the number of recent edges (N) and the number of hops (n), affect the model's interpretability and performance in different scenarios?
- Basis in paper: [explicit] The paper mentions setting N=50 and 1-hop neighbors for causal subgraph extraction but does not explore the impact of varying these hyperparameters.
- Why unresolved: The paper does not provide experiments or insights into how different hyperparameter settings influence SIG's performance and interpretability.
- What evidence would resolve it: Experiments varying N and n across different datasets to assess their impact on performance metrics like fidelity, sparsity, and prediction accuracy.

## Limitations
- The paper's performance claims are based on only five datasets, which may not be representative of all CTDG scenarios
- The exact implementation details of the causal subgraph extraction algorithm and VaDE clustering parameters are not fully specified
- The computational efficiency gains from NWGM approximation need validation against larger-scale graphs where pairwise interventions become prohibitively expensive

## Confidence

- High confidence: The ICCM framework's ability to handle both IID and OOD data through causal subgraph separation
- Medium confidence: The NWGM approximation's effectiveness in reducing computational complexity while maintaining accuracy
- Medium confidence: The reported performance improvements over baselines (1.25% AP, 0.92% AUC gains)

## Next Checks

1. **Causal Subgraph Validation**: Implement the causal subgraph extraction and visualize the extracted subgraphs for a small test case. Verify that the top-k temporal edges and n-hop structural neighbors contain the relevant causal information by checking if removing these edges significantly impacts prediction accuracy.

2. **NWGM Approximation Accuracy**: For a small graph where pairwise interventions are computationally feasible, compare the NWGM approximation output with direct pairwise intervention results. Calculate the approximation error and determine if it's within acceptable bounds for maintaining model performance.

3. **OOD Robustness Testing**: Implement synthetic bias injection by creating a controlled OOD dataset where specific edge features are systematically altered. Measure the degradation in AP and AUC metrics compared to the IID performance to validate the model's robustness claims.