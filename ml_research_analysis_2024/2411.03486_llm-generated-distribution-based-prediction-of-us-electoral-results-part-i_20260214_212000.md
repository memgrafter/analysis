---
ver: rpa2
title: LLM Generated Distribution-Based Prediction of US Electoral Results, Part I
arxiv_id: '2411.03486'
source_url: https://arxiv.org/abs/2411.03486
tags:
- election
- electoral
- state
- prediction
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a distribution-based prediction method that
  interprets LLM output token probabilities as predictive distributions representing
  the model's learned representation of the world. The approach bypasses demographic-based
  persona simulation by directly prompting models to forecast electoral outcomes and
  analyzing the resulting probability distributions.
---

# LLM Generated Distribution-Based Prediction of US Electoral Results, Part I

## Quick Facts
- arXiv ID: 2411.03486
- Source URL: https://arxiv.org/abs/2411.03486
- Authors: Caleb Bradshaw; Caelen Miller; Sean Warnick
- Reference count: 25
- Primary result: Distribution-based LLM prediction achieved 0.45 percentage point average error for 2020 election, predicting Harris 303 vs Trump 235 electoral votes for 2024

## Executive Summary
This paper introduces a novel distribution-based prediction method that interprets LLM output token probabilities as predictive distributions representing the model's learned representation of the world. The approach bypasses traditional demographic-based persona simulation by directly prompting models to forecast electoral outcomes and analyzing the resulting probability distributions. Tested on U.S. presidential election prediction, the method achieved an average prediction error of 0.45 percentage points for both Joe Biden and Donald Trump when "predicting" the 2020 election results across all states.

The method enables assessment of task-specific bias, prompt noise sensitivity, and algorithmic fidelity through distributional analysis. Testing revealed left-leaning biases in LLM predictions, with consistent Democratic favoritism in swing states except when recalling Donald Trump's actual 2016 victory. The approach's effectiveness was demonstrated across different model sizes, with larger models (90B parameters) producing more nuanced and realistic distributions that better captured actual voting patterns. For the 2024 election, the model predicted Kamala Harris would win with 303 electoral votes over Donald Trump's 235 votes (95% win probability).

## Method Summary
The distribution-based prediction method works by prompting LLMs to forecast vote shares for specific candidates in each state, then interpreting the output token probability distributions as predictive distributions. The approach uses system prompts with demographic information and user prompts asking for specific vote share percentages. These distributions are then processed to extract predictions and run through an electoral college simulation. The method was tested using Llama 3.2 models of different sizes (1B, 3B, 11B, 90B parameters) and validated against historical 2020 election data.

## Key Results
- Achieved 0.45 percentage point average prediction error for 2020 election across all states
- Predicted Kamala Harris would win 2024 election with 303 electoral votes vs Trump's 235 (95% win probability)
- Larger models (90B parameters) produced more nuanced distributions that better captured actual voting patterns
- Revealed systematic left-leaning bias in LLM predictions, with Democratic favoritism in swing states

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM output token probabilities can be interpreted as predictive distributions representing the model's learned representation of the world
- Mechanism: The model's training on vast amounts of text data creates internal representations that capture real-world patterns and distributions. When prompted to predict vote shares, the probability distribution over possible outputs reflects the model's learned understanding of electoral dynamics.
- Core assumption: LLMs encode coherent world models that accurately reflect real-world distributions in their probability outputs
- Evidence anchors:
  - [abstract] "interpreting output token probabilities as distributions representing the models' learned representation of the world"
  - [section] "research indicates that LLMs contain coherent and grounded representations that reflect real world distributions"
  - [corpus] Weak - no direct corpus evidence found
- Break condition: The model's training data is biased or unrepresentative of the target domain, or the model fails to capture the underlying distributions accurately

### Mechanism 2
- Claim: Distribution-based prediction enables assessment of task-specific bias through distributional analysis
- Mechanism: By comparing the model's predicted distributions against actual election results, systematic deviations can be identified as bias. The distributional approach provides a richer signal than point predictions alone.
- Core assumption: Systematic differences between predicted and actual distributions indicate bias in the model's world representation
- Evidence anchors:
  - [abstract] "This distribution-based nature offers an alternative perspective for analyzing algorithmic fidelity"
  - [section] "Using direct prediction, extracted distributions can be compared to actual results as a means of assessing an LLMs world model bias for a given task"
  - [corpus] Weak - limited corpus evidence on bias detection through distributional methods
- Break condition: The comparison methodology is flawed, or the actual distributions are unknown or unreliable

### Mechanism 3
- Claim: Larger models produce more nuanced and realistic distributions that better capture actual voting patterns
- Mechanism: As model size increases, the model's capacity to represent complex distributions and subtle patterns in the data improves, leading to more accurate predictions.
- Core assumption: Model capacity correlates with the quality and realism of predicted distributions
- Evidence anchors:
  - [section] "Testing revealed left-leaning biases in LLM predictions" and "larger models (90B parameters) producing more nuanced and realistic distributions that better captured actual voting patterns"
  - [appendix] Figure 9 shows increasing model size leads to more differentiated and logical distributions
  - [corpus] Weak - limited corpus evidence on model size effects on distribution quality
- Break condition: Model size increases without corresponding improvement in distribution quality, or other factors (like training data quality) become limiting

## Foundational Learning

- Concept: Probability distributions and their interpretation
  - Why needed here: The core methodology relies on interpreting token probabilities as distributions representing the model's world knowledge
  - Quick check question: If a model outputs probabilities [0.1, 0.2, 0.3, 0.4] for vote shares 40%, 45%, 50%, 55%, what is the most likely predicted vote share?

- Concept: Electoral college mechanics and state-level voting patterns
  - Why needed here: The method applies distribution-based prediction specifically to U.S. presidential elections, requiring understanding of how electoral votes are allocated and how state voting patterns work
  - Quick check question: How many electoral votes does a candidate need to win the U.S. presidential election?

- Concept: Statistical error analysis and comparison methods
  - Why needed here: The paper evaluates model performance by comparing predicted distributions against actual results, requiring understanding of error metrics and comparison techniques
  - Quick check question: What does an average prediction error of 0.45 percentage points mean in practical terms?

## Architecture Onboarding

- Component map:
  Prompt generation system (system prompt + user prompt) -> LLM inference engine (various model sizes) -> Distribution processing pipeline (probability extraction and analysis) -> Electoral college simulation module -> Comparison and bias detection system

- Critical path:
  1. Generate prompt for each state-candidate combination
  2. Run LLM inference to get token probability distribution
  3. Process distribution to extract predictions
  4. Run electoral college simulation
  5. Compare results to ground truth (for historical data)

- Design tradeoffs:
  - Model size vs. computational cost: Larger models produce better distributions but require more resources
  - Prompt specificity vs. generality: More specific prompts may reduce bias but limit generalizability
  - Distribution granularity vs. simplicity: Finer-grained distributions provide more information but are harder to analyze

- Failure signatures:
  - Uniform distributions across all states (model not capturing regional differences)
  - Extreme concentrations at boundary values (0% or 100%)
  - Systematic bias favoring one party across all states
  - High variance between runs with same prompt

- First 3 experiments:
  1. Run distribution-based prediction on historical election data (2020) to establish baseline performance and identify any systematic biases
  2. Test sensitivity to prompt variations by changing wording and structure while keeping the same target prediction task
  3. Compare predictions across different model sizes (1B, 3B, 11B, 90B parameters) to quantify the relationship between model capacity and prediction quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is distribution-based prediction against variations in prompt design and phrasing?
- Basis in paper: [explicit] The paper identifies prompt noise as a key challenge, noting that different wordings can significantly alter output distributions
- Why unresolved: The authors acknowledge this limitation but do not provide systematic testing across multiple prompt variations to quantify the impact on prediction accuracy
- What evidence would resolve it: Empirical testing showing prediction accuracy and distribution stability across a range of semantically equivalent prompts, with quantitative measures of sensitivity to specific prompt modifications

### Open Question 2
- Question: What is the relationship between model size and prediction accuracy in distribution-based prediction?
- Basis in paper: [explicit] Figure 9 shows how distributions change with increasing model size from 1B to 90B parameters, but only for two states
- Why unresolved: The paper demonstrates visual differences but does not provide quantitative analysis of how prediction accuracy scales with model size across multiple states or domains
- What evidence would resolve it: Systematic testing of prediction accuracy across multiple model sizes and states, with statistical analysis of the correlation between parameter count and error rates

### Open Question 3
- Question: How well does distribution-based prediction generalize to domains beyond electoral forecasting?
- Basis in paper: [explicit] The authors suggest potential applications in sports, weather, and stock market prediction, but only test the method on elections
- Why unresolved: The paper focuses exclusively on electoral predictions without validating the approach on other prediction domains that might have different data characteristics
- What evidence would resolve it: Testing the distribution-based prediction method on multiple prediction tasks with known ground truth data, comparing accuracy to traditional prediction methods

## Limitations

- The method relies on LLMs' internal representations of electoral dynamics, which may not capture all relevant factors affecting voting behavior
- The systematic left-leaning bias observed in predictions raises concerns about political neutrality and underlying training data representation
- The approach assumes token probability distributions meaningfully represent predictive distributions, which requires further validation across different domains

## Confidence

- High confidence: Technical feasibility of using LLM-generated probability distributions for electoral prediction is well-supported, with 0.45 percentage point average error demonstrating practical accuracy
- Medium confidence: Relationship between model size and prediction quality shows clear trend with larger models producing more nuanced distributions, though exact scaling relationships remain uncertain
- Low confidence: The claim that LLM output token probabilities directly represent predictive distributions encoding the model's world knowledge is most speculative and relies on unverified assumptions about how LLMs encode information

## Next Checks

1. **Cross-domain validation**: Apply the distribution-based prediction method to non-electoral forecasting tasks (e.g., sports outcomes, weather prediction, or financial market movements) to test whether the approach generalizes beyond political prediction and whether observed biases persist across different domains.

2. **Bias characterization study**: Conduct a systematic investigation of the left-leaning bias by testing the model's predictions across different demographic groups, geographic regions, and historical election contexts. This should include analysis of how prompt structure and content affect bias magnitude and direction.

3. **Model architecture ablation**: Compare the distribution-based prediction approach across different LLM architectures (not just different sizes of the same family) to determine whether the observed relationships between model capacity and prediction quality are architecture-dependent or more general phenomena.