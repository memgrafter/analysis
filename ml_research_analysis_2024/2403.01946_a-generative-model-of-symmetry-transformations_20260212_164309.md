---
ver: rpa2
title: A Generative Model of Symmetry Transformations
arxiv_id: '2403.01946'
source_url: https://arxiv.org/abs/2403.01946
tags:
- learning
- data
- transformations
- figure
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces a Symmetry-aware Generative Model (SGM) that
  learns to model the distribution of symmetry transformations present in a dataset.
  The SGM separates the latent representation into an invariant component (prototype)
  and an equivariant component (symmetry parameters), using a two-stage algorithm:
  first learning prototypes via self-supervised learning, then learning symmetry parameters
  via maximum likelihood.'
---

# A Generative Model of Symmetry Transformations

## Quick Facts
- arXiv ID: 2403.01946
- Source URL: https://arxiv.org/abs/2403.01946
- Reference count: 40
- Key outcome: Symmetry-aware Generative Model (SGM) improves data efficiency and robustness by learning symmetry transformations through prototype-parameter decomposition

## Executive Summary
This paper introduces a Symmetry-aware Generative Model (SGM) that learns to model the distribution of symmetry transformations present in a dataset. The model decomposes observations into an invariant component (prototype) and an equivariant component (symmetry parameters), using a two-stage algorithm: first learning prototypes via self-supervised learning, then learning symmetry parameters via maximum likelihood. The approach enables generative models to produce realistic samples that respect learned symmetries and improves performance when combined with standard generative models, particularly in data-scarce scenarios.

## Method Summary
The method employs a two-stage algorithm to learn symmetry transformations. First, an invariant prototype inference function is trained using self-supervised learning to map observations to transformation-invariant prototypes. Second, a generative network models the distribution over symmetry parameters given these prototypes using normalizing flows for flexibility. The model assumes transformations form a group, partitioning data space into disjoint orbits. This allows the model to learn p(η|ˆx), the distribution of naturally occurring transformations for each prototype, without explicitly modeling the prototype distribution p(ˆx).

## Key Results
- SGM improves marginal test-log-likelihoods on MNIST, dSprites, and GalaxyMNIST datasets compared to standard VAE baselines
- The model demonstrates increased robustness to reduced training data, maintaining performance better than standard models under data scarcity
- Resampled examples generated by SGM are visually similar to original observations while varying along learned symmetry dimensions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model learns the distribution of symmetry transformations by decomposing observations into prototypes and symmetry parameters
- Mechanism: Each observation x is modeled as a transformed prototype (x = Tη(ˆx)) where ˆx contains no symmetry information, allowing learning of pψ(η|ˆx)
- Core assumption: Transformations form a group, creating disjoint orbits where each element can be transformed into any other element in the same orbit
- Evidence anchors:
  - [abstract]: "Our model can be seen as a generative process for data augmentation."
  - [section]: "Having the transformations {Tη} be a group simplifies things, since {Tη} will then naturally partition the space X into (disjoint) orbits."
- Break condition: If transformations don't form a group, the orbit structure breaks down and the model cannot uniquely assign prototypes

### Mechanism 2
- Claim: Two-stage learning enables tractable learning without modeling prototype distribution p(ˆx)
- Mechanism: First learn invariant prototype inference fω(x) via self-supervised learning, then learn pψ(η|ˆx) via maximum likelihood on generated pairs
- Core assumption: Prototype inference function can be learned to be approximately invariant to specified transformations
- Evidence anchors:
  - [abstract]: "We provide a simple algorithm for learning our generative model."
  - [section]: "We propose a two-stage algorithm for learning our SGM: first learning ˆx using a self-supervised approach and then learning η via maximum likelihood."
- Break condition: If prototype inference cannot achieve sufficient invariance, the model cannot correctly learn pψ(η|ˆx)

### Mechanism 3
- Claim: Normalizing flows provide flexibility to capture complex, multimodal distributions over symmetry parameters
- Mechanism: Using normalizing flows for pψ(η|ˆx) allows representation of distributions with multiple modes, different ranges for different prototypes, and parameter dependencies
- Core assumption: Normalizing flows are sufficiently flexible to approximate true conditional distributions
- Evidence anchors:
  - [section]: "We solve this problem by modeling pψ(η|ˆx) with normalizing flows, which can match a wide range of distributions."
  - [section]: "Here, the simple uni-modal distribution is clearly worse than the bi-modal distribution due to the large amount of probability mass being wasted on angles with low density."
- Break condition: If normalizing flow architecture is too limited, it cannot capture true complexity of transformation distributions

## Foundational Learning

- Concept: Group theory and symmetry transformations
  - Why needed here: Model's foundation relies on understanding how symmetry transformations form groups and create orbits in data space
  - Quick check question: What properties must a set of transformations have to form a mathematical group?

- Concept: Self-supervised learning for invariance
  - Why needed here: First stage requires teaching model to map observations to invariant prototypes without labels
  - Quick check question: How does comparing randomly transformed versions of the same image help learn an invariant representation?

- Concept: Normalizing flows for flexible density estimation
  - Why needed here: Second stage requires learning complex conditional distributions over transformation parameters
  - Quick check question: Why would a simple Gaussian distribution be insufficient for modeling symmetry parameters?

## Architecture Onboarding

- Component map:
  Prototype inference network (fω) -> Prototype (ˆx) -> Generative network (pψ) -> Transformation parameters (η) -> Resampled observation (Tη(ˆx))

- Critical path: Observation → Prototype inference (fω) → Prototype (ˆx) → Generative model (pψ) → Transformation parameters (η) → Resampled observation (Tη(ˆx))

- Design tradeoffs:
  - Specifying transformation types vs. model flexibility: More specified transformations require less model capacity but less discovery
  - Flow complexity vs. training stability: More complex flows capture distributions better but may be harder to train
  - Batch size vs. SSL effectiveness: Larger batches provide better augmentation diversity but require more memory

- Failure signatures:
  - Blurry or empty prototypes indicate invertibility problems or overly lossy transformations
  - Uniform or incorrect distributions over parameters suggest insufficient model flexibility or poor invariance learning
  - High variance in transformation parameters across same-orbit examples indicates poor prototype inference

- First 3 experiments:
  1. Train on MNIST with only rotation transformations; verify prototypes are consistent across rotations and distributions are centered around 0°
  2. Test on heart sprites from dSprites without rotation; confirm model learns to ignore rotation transformation
  3. Apply to GalaxyMNIST with affine and color transformations; check that resampled examples are visually similar to originals

## Open Questions the Paper Calls Out

- Question: How robust is SGM to larger sets of potential symmetries than those tested in experiments?
  - Basis in paper: [explicit] Authors state main limitation is requiring specification of super-set of possible symmetries, suggesting this as future work
  - Why unresolved: Experiments only tested affine and color transformations; performance with more diverse or complex symmetry sets is unknown
  - What evidence would resolve it: Experiments testing SGM with broader range of symmetry transformations (e.g., non-linear, 3D, or learned symmetry groups) and evaluating performance and stability

- Question: Can SGM handle transformations that are not perfectly invertible?
  - Basis in paper: [explicit] Authors discuss partial invertibility issue, noting affine transformations can cause information loss
  - Why unresolved: Current SGM assumes invertibility for prototype inference; impact of non-invertible transformations unexplored
  - What evidence would resolve it: Experiments modifying SGM to handle non-invertible transformations through approximate inversion or learning distribution over prototypes

- Question: How does SGM-based data augmentation compare to other methods in discriminative settings?
  - Basis in paper: [explicit] Authors mention it would be interesting to apply SGM to data augmentation in discriminative settings and compare with methods like Benton et al. [2020], Miao et al. [2023]
  - Why unresolved: Paper only demonstrates SGM benefits in generative models (VAEs); effectiveness in improving discriminative model performance unexplored
  - What evidence would resolve it: Experiments applying SGM-based augmentation to train discriminative models (e.g., classifiers) and comparing performance to standard data augmentation or no augmentation

## Limitations
- Model performance heavily depends on correctly specifying transformation group; incorrect specifications degrade effectiveness
- Two-stage training may create training-inference mismatch as model trained on generated pairs but handles real observations during inference
- Scalability to more complex symmetry discovery remains an open question, only demonstrated on simple cases

## Confidence
- High confidence: Basic mechanism of separating invariant prototypes from equivariant parameters works as described, supported by clear mathematical foundations and multiple experimental demonstrations
- Medium confidence: Claim that SGM improves data efficiency and robustness is supported by experiments but would benefit from additional ablation studies isolating learned symmetries' contribution
- Medium confidence: Assertion that SGM can discover symmetries when not fully specified is promising but only demonstrated on simple cases; scalability to more complex symmetry discovery remains open

## Next Checks
1. Test model robustness by systematically removing or adding transformations to specified set and measuring performance degradation or improvement
2. Conduct ablation studies comparing SGM with standard generative models while controlling for architectural differences (number of parameters, flow complexity, etc.)
3. Evaluate model performance on datasets with known but more complex symmetry structures (e.g., protein structures, molecular conformations) to assess scalability of the approach