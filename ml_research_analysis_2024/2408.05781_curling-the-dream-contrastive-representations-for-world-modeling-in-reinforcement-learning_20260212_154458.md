---
ver: rpa2
title: 'CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement
  Learning'
arxiv_id: '2408.05781'
source_url: https://arxiv.org/abs/2408.05781
tags:
- learning
- contrastive
- loss
- reinforcement
- curled-dreamer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Curled-Dreamer, which integrates contrastive
  learning from CURL and reconstruction loss into the DreamerV3 framework to improve
  visual representation learning in reinforcement learning tasks. It uses data augmentation
  and InfoNCE loss to enhance the encoder's ability to capture discriminative features
  from visual inputs.
---

# CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement Learning

## Quick Facts
- arXiv ID: 2408.05781
- Source URL: https://arxiv.org/abs/2408.05781
- Reference count: 27
- Key outcome: Curled-Dreamer achieves mean score of 863 and median score of 805 on 20 DeepMind Control Suite tasks at 1M environment steps, outperforming baselines including DreamerV3 (229→328 on Acrobot Swingup, 867 on Cheetah Run, 894 on Quadruped Walk).

## Executive Summary
Curled-Dreamer integrates contrastive learning from CURL and reconstruction loss into the DreamerV3 framework to improve visual representation learning in reinforcement learning tasks. By combining InfoNCE contrastive loss with autoencoder reconstruction, the method enhances the encoder's ability to capture discriminative features from visual inputs while preserving detailed information. The approach demonstrates significant performance improvements across 20 DeepMind Control Suite tasks, achieving state-of-the-art results in challenging visual control problems while maintaining the efficiency of model-based reinforcement learning.

## Method Summary
Curled-Dreamer extends DreamerV3 by incorporating contrastive learning and reconstruction objectives into the training framework. The method uses data augmentation to create positive pairs for contrastive learning, computes InfoNCE loss to encourage similar representations for different views of the same state, and adds reconstruction loss to preserve visual details. The encoder is trained jointly with the dynamics model, policy, and decoder using a combined loss function that balances policy performance, state prediction accuracy, discriminative feature learning, and reconstruction capability. Standard hyperparameters from DreamerV3 are used with InfoNCE temperature set to 0.1 and all loss weights equal to 1.0.

## Key Results
- Mean score of 863 and median score of 805 across 20 DeepMind Control Suite tasks at 1M environment steps
- Significant improvements over DreamerV3 baseline: Acrobot Swingup (328 vs 229), Cheetah Run (867), Quadruped Walk (894)
- Outperforms PPO, SAC, CURL, DrQ-v2, and previous DreamerV3 versions on visual control tasks
- Demonstrates enhanced learning efficiency and policy robustness in high-dimensional visual observation spaces

## Why This Works (Mechanism)

### Mechanism 1
- Claim: InfoNCE contrastive loss improves encoder representations by forcing consistency across data augmentations while discriminating between different states.
- Mechanism: The InfoNCE loss maximizes similarity between positive pairs (different augmentations of the same state) and minimizes similarity between negative pairs (augmentations of different states), creating a representation space where visually similar states cluster together while distinct states are separated.
- Core assumption: Augmented views of the same state contain sufficient shared information while being sufficiently different to provide meaningful contrastive signal.
- Evidence anchors: [abstract] "By incorporating the contrastive loss from the CURL algorithm and a reconstruction loss from autoencoder, Curled-Dreamer achieves significant improvements"; [section] "The contrastive loss is computed using the InfoNCE loss... This contrastive loss encourages the encoder to produce similar representations for different augmentations of the same state and dissimilar representations for different states."
- Break condition: If augmentations destroy critical task-relevant information or if the temperature parameter τ is poorly tuned, the contrastive signal becomes either too weak or too dominant relative to the RL objectives.

### Mechanism 2
- Claim: Reconstruction loss provides additional supervisory signal that encourages the encoder to preserve detailed visual information needed for accurate state reconstruction.
- Mechanism: The reconstruction loss directly optimizes the encoder-decoder pair to minimize reconstruction error, forcing the latent representation to contain sufficient information to reconstruct the original observation.
- Core assumption: Preserving reconstruction capability doesn't conflict with learning compressed, policy-relevant representations, and the decoder architecture is capable of reconstructing from the latent space produced by the contrastive-augmented encoder.
- Evidence anchors: [abstract] "By incorporating the contrastive loss from the CURL algorithm and a reconstruction loss from autoencoder"; [section] "The encoder's output is also fed into a decoder to reconstruct the original input, promoting the learning of more detailed and accurate representations."
- Break condition: If the reconstruction objective dominates the training, it may encourage the encoder to preserve too much task-irrelevant visual detail, reducing the efficiency of the latent representation for policy learning.

### Mechanism 3
- Claim: The combined loss function effectively balances multiple learning objectives, allowing Curled-Dreamer to leverage both predictive world modeling and contrastive representation learning.
- Mechanism: By combining policy loss, dynamics loss, contrastive loss, and reconstruction loss with tunable weights, the algorithm can simultaneously optimize for task completion, accurate state prediction, discriminative feature learning, and reconstruction capability.
- Core assumption: The linear combination of losses with fixed weights is sufficient to balance these potentially competing objectives throughout training, and the learning rates are appropriately scaled for each component.
- Evidence anchors: [abstract] "Our extensive experiments demonstrate that Curled-Dreamer consistently outperforms state-of-the-art algorithms"; [section] "The overall training objective for Curled-Dreamer is a combination of the contrastive loss, the dynamics model loss, the policy loss, and the reconstruction loss."
- Break condition: If one loss component dominates early in training, it may prevent other components from learning effectively, leading to suboptimal representations or unstable policy learning.

## Foundational Learning

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: Understanding how contrastive learning creates meaningful representation spaces through similarity/dissimilarity maximization is crucial for implementing and debugging the encoder training
  - Quick check question: What is the difference between a positive pair and a negative pair in InfoNCE loss, and why does this distinction matter for representation quality?

- Concept: World models and latent dynamics prediction
  - Why needed here: Curled-Dreamer builds on DreamerV3's world model approach, so understanding how latent states predict future observations and rewards is essential for grasping the overall algorithm architecture
  - Quick check question: How does the latent dynamics model use the encoded representations to predict future states, and what role does the reward predictor play in this process?

- Concept: Data augmentation strategies for visual observations
  - Why needed here: The effectiveness of the contrastive learning component depends heavily on appropriate augmentation choices that preserve task-relevant information while providing sufficient variation
  - Quick check question: What types of data augmentations are most effective for control tasks, and how might aggressive augmentation hurt performance?

## Architecture Onboarding

- Component map: Observation → Data Augmentation → Encoder → Latent Representation → (Decoder for reconstruction, Dynamics Model for prediction, Policy for action selection)
- Critical path: Observation → Data Augmentation → Encoder → Latent Representation → (Decoder for reconstruction, Dynamics Model for prediction, Policy for action selection)
- Design tradeoffs:
  - Augmentation strength vs. information preservation: Stronger augmentations provide better contrastive signals but may remove task-relevant details
  - Loss weight balancing: The λ parameters control the relative importance of each objective, requiring careful tuning
  - Model capacity: Adding reconstruction and contrastive components increases model complexity and training time
- Failure signatures:
  - Poor policy performance despite good reconstruction: Contrastive loss may be too weak or augmentations too aggressive
  - Unstable training: Loss components may be imbalanced; check individual loss magnitudes
  - Representations not improving: Contrastive signal may be too weak; check augmentation quality and temperature parameter
- First 3 experiments:
  1. Implement and test the encoder with only contrastive loss (no reconstruction, no DreamerV3 components) on a simple classification task to verify InfoNCE implementation
  2. Add the decoder and reconstruction loss to the encoder, train end-to-end on observation reconstruction only, verify that representations capture visual details
  3. Integrate with DreamerV3 dynamics model and policy, start with only contrastive loss (no reconstruction), test on a simple control task to verify compatibility with world modeling framework

## Open Questions the Paper Calls Out

- Question: How does the performance of Curled-Dreamer scale with increased model capacity (e.g., larger encoder and decoder networks)?
  - Basis in paper: [explicit] The paper mentions that "the addition of parameters, such as the use of two encoders and the matrix W, likely contributed to the improved results by allowing the model to capture more complex features and relationships within the data."
  - Why unresolved: The paper does not provide empirical results on how varying the model size affects performance.
  - What evidence would resolve it: Comparative experiments showing performance of Curled-Dreamer with different encoder/decoder sizes on the same set of tasks.

- Question: What is the impact of removing the decoder from the Curled-Dreamer architecture on its performance and robustness?
  - Basis in paper: [explicit] The paper states "Future work will explore... remove the decoder from the model to make the algorithm more robust."
  - Why unresolved: This is explicitly identified as future work, indicating it hasn't been tested yet.
  - What evidence would resolve it: Experimental results comparing Curled-Dreamer with and without the decoder component across various tasks.

- Question: How does Curled-Dreamer perform on tasks with partial observability or partially observable Markov decision processes (POMDPs)?
  - Basis in paper: [inferred] The paper focuses on fully observable visual inputs in DeepMind Control Suite tasks but doesn't test on partially observable environments.
  - Why unresolved: The experiments were limited to fully observable tasks, leaving the algorithm's behavior in POMDPs unexplored.
  - What evidence would resolve it: Testing Curled-Dreamer on standard partially observable benchmark tasks and comparing performance to fully observable counterparts.

## Limitations

- Limited ablation studies: The paper doesn't provide experiments isolating the contributions of contrastive learning versus reconstruction loss to the performance gains.
- Fixed loss weights: The choice of λ₁=λ₂=λ₃=1.0 appears arbitrary without sensitivity analysis or justification.
- Implementation details unclear: Specific data augmentation schemes and positive/negative pair sampling strategies are not detailed, making exact reproduction difficult.

## Confidence

- **High**: The general framework combining contrastive learning with world models is sound and builds on established methods (CURL, DreamerV3)
- **Medium**: The reported performance improvements on DeepMind Control Suite tasks are plausible but lack rigorous statistical validation
- **Low**: The relative contribution of each component (contrastive loss vs reconstruction vs baseline DreamerV3) remains unclear due to absent ablation studies

## Next Checks

1. **Ablation study**: Implement and compare Curled-Dreamer variants with only contrastive loss, only reconstruction loss, and the combined approach to quantify individual contributions to performance gains.

2. **Loss weight sensitivity**: Systematically vary λ₂ (contrastive) and λ₃ (reconstruction) weights across multiple tasks to identify optimal configurations and verify the chosen values (all set to 1.0) are reasonable.

3. **Augmentation impact analysis**: Test different augmentation strengths and types to determine the optimal balance between contrastive signal quality and preservation of task-relevant information.