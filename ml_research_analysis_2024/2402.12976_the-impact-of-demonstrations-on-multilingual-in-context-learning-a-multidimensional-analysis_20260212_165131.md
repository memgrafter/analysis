---
ver: rpa2
title: 'The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional
  Analysis'
arxiv_id: '2402.12976'
source_url: https://arxiv.org/abs/2402.12976
tags:
- demonstrations
- learning
- language
- llama
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines how multilingual in-context learning (ICL)
  performance is affected by the number and quality of demonstrations, as well as
  the formatting of prompts. The authors evaluate five models across nine multilingual
  datasets spanning 56 languages, including both classification and generation tasks.
---

# The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis

## Quick Facts
- arXiv ID: 2402.12976
- Source URL: https://arxiv.org/abs/2402.12976
- Authors: Miaoran Zhang; Vagrant Gautam; Mingyang Wang; Jesujoba O. Alabi; Xiaoyu Shen; Dietrich Klakow; Marius Mosbach
- Reference count: 40
- Primary result: ICL effectiveness varies significantly across models, tasks, and languages; chat models are less sensitive to demonstration quality than base models

## Executive Summary
This study systematically evaluates how multilingual in-context learning (ICL) performance is affected by demonstration number, quality, and prompt formatting across five models and nine multilingual datasets spanning 56 languages. The authors find that ICL does not consistently outperform zero-shot learning, and that chat models like GPT-3.5 and GPT-4 show remarkable insensitivity to demonstration quality. A key finding is that carefully crafted templates can eliminate the need for demonstrations altogether, particularly for chat models. These results suggest that the benefits of ICL may be overestimated and that future work should carefully compare results with zero-shot learning and multiple templates.

## Method Summary
The study evaluates five models (XGLM, Llama 2, Llama 2-Chat, GPT-3.5, GPT-4) across nine multilingual datasets using classification and generation tasks. Demonstrations are varied in number (0, 2, 4, 8), quality (random selection, top-k similarity, corrupted labels), and language match. Templates are tested in original and formatting-focused variants. Performance is measured using classification accuracy, F1 scores, and ChrF++ metrics, with comparisons between ICL and zero-shot learning to assess demonstration effectiveness.

## Key Results
- ICL does not consistently outperform zero-shot learning across all models, tasks, and languages
- Chat models (GPT-3.5, GPT-4, Llama 2-Chat) are largely insensitive to demonstration quality, unlike base models
- Carefully crafted formatting-focused templates can eliminate the need for demonstrations with chat models
- Performance improvements from demonstrations saturate quickly, typically after 2-4 examples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual ICL effectiveness varies significantly across models, tasks, and languages
- Mechanism: Different LLMs have varying capabilities in multilingual understanding and task-solving, which interact with task complexity and language representation in training data
- Core assumption: The variation is due to differences in model architecture, training data composition, and inherent language capabilities rather than random noise
- Evidence anchors:
  - [abstract] "Our results reveal that the effectiveness of demonstrations varies significantly across models, tasks, and languages."
  - [section 4] "We see that improvements saturate quickly with 2 to 4 demonstrations. This aligns with Chen et al. (2023), who found that reducing the number of demonstrations to one does not significantly deteriorate chain-of-thought reasoning."
  - [corpus] Weak - only citation count available, no specific evidence provided
- Break condition: If models are tested on languages equally represented in training data, or if tasks are uniformly simple across all languages

### Mechanism 2
- Claim: Chat models are less sensitive to demonstration quality than base models
- Mechanism: Instruction-tuned chat models have learned to follow instructions and understand task formats, making them less dependent on specific demonstrations for task comprehension
- Core assumption: Chat models have developed stronger instruction-following capabilities through fine-tuning, reducing their reliance on demonstration examples
- Evidence anchors:
  - [abstract] "We also find that strong instruction-following models including Llama 2-Chat, GPT-3.5, and GPT-4 are largely insensitive to the quality of demonstrations."
  - [section 5] "XGLM and Llama 2 perform significantly worse with corrupted labels, especially on the machine translation task, whereas chat models do not rely as much on correct labels."
  - [corpus] Weak - only citation count available, no specific evidence provided
- Break condition: If chat models are tested on tasks requiring extensive domain-specific knowledge not captured in instruction tuning

### Mechanism 3
- Claim: Carefully crafted templates can eliminate the benefits of demonstrations for chat models
- Mechanism: Templates that focus on output formatting provide clear instructions for response structure, reducing the need for demonstrations to convey task format
- Core assumption: Chat models can understand and follow formatting instructions directly, making demonstrations redundant for format guidance
- Evidence anchors:
  - [abstract] "Instead, a carefully crafted template often eliminates the benefits of demonstrations for some tasks and languages altogether."
  - [section 6] "Using a formatting-focused template can even eliminate the need for demonstrations with chat models."
  - [corpus] Weak - only citation count available, no specific evidence provided
- Break condition: If templates are poorly designed or if chat models have not learned to follow complex formatting instructions

## Foundational Learning

- Concept: In-context learning (ICL)
  - Why needed here: The paper is fundamentally about how ICL works differently across multilingual contexts
  - Quick check question: What distinguishes ICL from fine-tuning in terms of parameter updates and task adaptation?

- Concept: Demonstration selection methods
  - Why needed here: The paper compares different methods (random, top-k, corrupted labels) to understand their impact on ICL performance
  - Quick check question: How does semantic similarity between demonstrations and test samples theoretically affect ICL performance?

- Concept: Template design and prompt engineering
  - Why needed here: The paper shows that template quality can be as important as demonstration quality, especially for chat models
  - Quick check question: What elements should a template contain to effectively guide LLM responses without demonstrations?

## Architecture Onboarding

- Component map: Model selection (Base models: XGLM, Llama 2; Chat models: Llama 2-Chat, GPT-3.5, GPT-4) -> Task categorization (Classification tasks vs generation tasks) -> Language coverage (High-resource vs low-resource languages) -> Demonstration variables (Number: 0, 2, 4, 8; Quality: random, top-k, corrupted; Language match) -> Template variables (Original vs formatting-focused templates)

- Critical path: 1. Select model and task type -> 2. Choose demonstration parameters (number and quality) -> 3. Design appropriate template -> 4. Evaluate performance across languages -> 5. Compare ICL vs zero-shot performance

- Design tradeoffs: Model choice (Base models are more sensitive to demonstrations but cheaper to run; Chat models are more robust but expensive) -> Demonstration selection (Top-k selection is computationally expensive but may improve performance; Random selection is cheaper but less reliable) -> Template complexity (More detailed templates may reduce demonstration needs but increase prompt engineering effort)

- Failure signatures: Performance worse than zero-shot indicates poor demonstration selection or template design -> Inconsistent performance across languages suggests language representation issues -> Chat models performing poorly with demonstrations may indicate template problems

- First 3 experiments:
  1. Test XGLM with 4 random demonstrations vs zero-shot on XNLI across 10 languages
  2. Test GPT-3.5 with corrupted labels vs ground truth labels on XQuAD
  3. Test Llama 2-Chat with original vs formatting-focused templates on AfriSenti

## Open Questions the Paper Calls Out

- Open Question 1: Does the observed variance in ICL performance across languages and models stem from differences in the pre-training data distribution for different languages?
- Open Question 2: How does data contamination (test data appearing in pre-training data) affect the validity of ICL evaluations across different model families?
- Open Question 3: What is the relative contribution of demonstration selection versus template engineering in optimizing ICL performance across different model families?
- Open Question 4: Does the format of chain-of-thought reasoning demonstrations affect ICL performance differently than standard input-output demonstrations, particularly for multilingual tasks?
- Open Question 5: How does the effectiveness of ICL demonstrations scale with model size and capability across different languages?

## Limitations
- The study focuses on a fixed set of nine datasets and 56 languages, which may not capture the full diversity of real-world multilingual applications
- The analysis of chat model behavior is based on only three chat models, which may not represent the full spectrum of instruction-tuned LLMs
- The study does not explore how model size variations within model families might influence ICL sensitivity to demonstrations and templates
- The paper does not investigate more sophisticated demonstration selection approaches beyond random, top-k, and corrupted label methods

## Confidence

**High Confidence**: The finding that ICL does not consistently outperform zero-shot learning across all models, tasks, and languages. This conclusion is supported by extensive empirical testing across 56 languages and multiple model families, with clear performance patterns observed.

**Medium Confidence**: The claim that chat models are largely insensitive to demonstration quality. While the evidence strongly supports this for the tested models, the mechanism behind this insensitivity is not fully explored, and results may vary with different chat model architectures or training approaches.

**Medium Confidence**: The assertion that carefully crafted templates can eliminate the need for demonstrations with chat models. The evidence is compelling for the tested scenarios, but the template design space is vast, and results may not generalize to all task types or poorly designed templates.

## Next Checks

1. **Zero-shot vs ICL Robustness Test**: Systematically test whether the zero-shot performance advantage holds when varying template quality across all models and tasks to determine if results are robust to template design.

2. **Cross-linguistic Demonstration Transfer**: Evaluate whether demonstrations from high-resource languages can effectively substitute for demonstrations in low-resource languages across different model types to test universality of demonstration benefits.

3. **Semantic Similarity Demonstration Selection**: Implement and test a semantic similarity-based demonstration selection method to determine if this approach can outperform random selection, particularly for base models where demonstration quality appears to matter more.