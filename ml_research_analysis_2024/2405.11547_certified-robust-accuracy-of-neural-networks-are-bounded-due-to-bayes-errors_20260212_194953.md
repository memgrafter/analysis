---
ver: rpa2
title: Certified Robust Accuracy of Neural Networks Are Bounded due to Bayes Errors
arxiv_id: '2405.11547'
source_url: https://arxiv.org/abs/2405.11547
tags:
- robustness
- certified
- error
- bayes
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the fundamental limits of certified robust
  accuracy in neural networks through the lens of Bayes errors. The authors prove
  that the pursuit of robustness inherently increases the Bayes error due to label
  assignment to neighboring inputs in the perturbation vicinity.
---

# Certified Robust Accuracy of Neural Networks Are Bounded due to Bayes Errors

## Quick Facts
- arXiv ID: 2405.11547
- Source URL: https://arxiv.org/abs/2405.11547
- Authors: Ruihan Zhang; Jun Sun
- Reference count: 40
- This paper establishes theoretical upper bounds on certified robust accuracy based on Bayes errors and proves that the pursuit of robustness inherently increases Bayes error.

## Executive Summary
This paper investigates the fundamental limits of certified robust accuracy in neural networks through the lens of Bayes errors. The authors prove that achieving robustness inherently increases the Bayes error due to label assignment to neighboring inputs in the perturbation vicinity. They establish theoretical upper bounds on certified robust accuracy based on the original data distribution and perturbation size. Empirical results on benchmark datasets show that the computed upper bounds consistently exceed state-of-the-art certified robust accuracy by 1.5-7.1%, and that the upper bound decreases monotonically as perturbation size increases.

## Method Summary
The paper uses theoretical analysis to establish bounds on certified robust accuracy, combining concepts from Bayes decision theory with robustness requirements. The approach involves computing the original Bayes error, calculating the convolved distribution after applying vicinity functions, and deriving irreducible robustness error bounds. Empirical validation uses standard ERM training and state-of-the-art certified training methods on benchmark datasets including Moons, Chan, FashionMNIST, and CIFAR-10.

## Key Results
- The computed upper bounds on certified robust accuracy exceed state-of-the-art methods by 1.5-7.1% on benchmark datasets
- Upper bounds on certified robust accuracy decrease monotonically as perturbation size increases
- The paper proves that convolution with vicinity functions increases Bayes error, establishing a fundamental trade-off between robustness and accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bayes error fundamentally limits certified robust accuracy
- Mechanism: When robustness is required, each input's label is extended to its vicinity, causing convolution between the original distribution and the vicinity function. This convolution increases overlap between class distributions, raising the Bayes error.
- Core assumption: The original distribution contains inherent uncertainty (label ambiguity for some inputs)
- Evidence anchors:
  - [abstract] "We first show that the accuracy inevitably decreases in the pursuit of robustness due to changed Bayes error in the altered data distribution."
  - [section 3.1] "We hypothesise that the altered distribution worsens Bayes error."
  - [corpus] Weak - corpus papers focus on certified training techniques rather than fundamental Bayes error limits
- Break condition: If the original distribution has zero Bayes error (perfectly separable classes with deterministic labels)

### Mechanism 2
- Claim: Convolving with vicinity function increases Bayes error monotonically
- Mechanism: Theorem 2 proves that ((maxk(pk)) * v)(x) ≥ maxk((pk * v)(x)), meaning convolution smooths and spreads distributions, increasing overlap between classes
- Core assumption: Vicinity function v(x) is a probability density function
- Evidence anchors:
  - [section 3.1] "Theorem 2. Given a distribution D for classification, its convolved distribution D′ has an equal or larger Bayes error, i.e., βD ≤ βD′."
  - [section 3.1] Proof showing that left side of inequality is greater than or equal to right side
  - [corpus] Weak - corpus focuses on training techniques, not theoretical convolution properties
- Break condition: If vicinity function is not a valid PDF or if the original distributions are already maximally overlapping

### Mechanism 3
- Claim: Irreducible robustness error is bounded below by Bayes error
- Mechanism: Theorem 3 shows that robustness can only be achieved at inputs with deterministic labels (no uncertainty). The proportion of inputs with uncertain labels provides a lower bound on irreducible robustness error.
- Core assumption: Robustness requires both correct center prediction AND consistent predictions for all neighbors in vicinity
- Evidence anchors:
  - [section 3.2] "Theorem 3. Given a distribution D over X × Y, the irreducible robustness error is greater than or equal to the probability that an input is in KD."
  - [section 3.2] "ζD = ∫KD q(x)dx + ∫X\KD† (1 − maxk q(y = k|x = x))q(x)dx"
  - [corpus] Weak - corpus papers don't discuss irreducible error from Bayes error perspective
- Break condition: If all inputs in the distribution have deterministic labels (zero Bayes error)

## Foundational Learning

- Concept: Bayes error and optimal classification
  - Why needed here: The paper's core argument relies on understanding that Bayes error represents the fundamental limit of classification accuracy due to inherent data uncertainty
  - Quick check question: What is the Bayes error for a perfectly separable two-class problem with no overlap between class distributions?

- Concept: Convolution of probability distributions
  - Why needed here: The paper shows that achieving robustness requires convolving the original distribution with a vicinity function, which increases uncertainty
  - Quick check question: If we convolve a narrow Gaussian distribution with a rectangular vicinity function, what happens to the resulting distribution's shape and overlap with neighboring classes?

- Concept: Certified robust accuracy and its relationship to standard accuracy
  - Why needed here: The paper contrasts certified robust accuracy (which requires consistency across vicinities) with standard accuracy, showing the trade-off imposed by Bayes errors
  - Quick check question: How does certified robust accuracy differ from standard accuracy in terms of what it measures and guarantees?

## Architecture Onboarding

- Component map: Theoretical analysis -> Numerical computation -> Empirical validation
- Critical path: (1) Compute original Bayes error, (2) Calculate convolved distribution and new Bayes error, (3) Compute irreducible robustness error bounds, (4) Compare with state-of-the-art certified training results
- Design tradeoffs: The theoretical bounds are distribution-dependent and require knowledge of the true distribution, while practical evaluation uses finite samples which introduces approximation errors
- Failure signatures: If computed bounds are lower than state-of-the-art certified accuracy, the theoretical assumptions may be violated; if experimental results don't show monotonic decrease with vicinity size, implementation may have errors
- First 3 experiments:
  1. Compute Bayes error bounds for Moons dataset with varying vicinity sizes to verify Theorem 2
  2. Compare theoretical upper bound (1 - ζD) with certified training results on FashionMNIST
  3. Test the effect of high-frequency features on Bayes error growth by comparing Chan vs Moons datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the convolution-based analysis of Bayes error apply to non-uniform vicinity functions, or is the rectangular function assumption necessary for the theoretical results?
- Basis in paper: [explicit] The paper uses a uniform rectangular vicinity function (Equation 5) and proves Theorem 1 and 2 based on this assumption.
- Why unresolved: The theoretical bounds and analysis are developed specifically for rectangular vicinity functions. It's unclear if the same relationship between Bayes error and robustness holds for more complex vicinity shapes.
- What evidence would resolve it: Experimental comparison of Bayes error changes and upper bounds of certified robust accuracy across different vicinity function shapes (e.g., Gaussian, elliptical) would demonstrate the generality of the results.

### Open Question 2
- Question: How does the irreducible robustness error ζD scale with input dimensionality in high-dimensional spaces, particularly for datasets like CIFAR-10?
- Basis in paper: [explicit] Corollary 2 provides a bound that depends on dimensionality through the term (dim X-1)/(dim X), but this is an asymptotic result.
- Why unresolved: The paper only provides empirical results for 2D datasets (Moons, Chan) and moderately high-dimensional datasets (FashionMNIST, CIFAR-10). The theoretical scaling behavior in very high dimensions remains unexplored.
- What evidence would resolve it: Theoretical analysis or empirical experiments with synthetic high-dimensional datasets showing how ζD grows with dimension would clarify this scaling behavior.

### Open Question 3
- Question: Can the upper bound of certified robust accuracy be tightened by incorporating information about the classifier's decision boundary geometry rather than just the data distribution?
- Basis in paper: [inferred] The current bounds depend only on the data distribution and vicinity function, but the classifier's decision boundary could provide additional constraints on achievable robustness.
- Why unresolved: The paper establishes distribution-based bounds but doesn't explore whether classifier-specific information could yield tighter bounds. This would require analyzing the relationship between decision boundaries and the K*D marginal domain.
- What evidence would resolve it: Development of a method that incorporates decision boundary information into the bound calculation, followed by empirical comparison showing tighter bounds on the same datasets, would demonstrate the potential improvement.

## Limitations
- The theoretical bounds rely on assumptions about the true data distribution being known, which is rarely the case in practice
- Empirical validation uses finite samples and specific neural network architectures, potentially limiting generalizability
- The theoretical framework focuses on isotropic vicinities, while real-world perturbations may have more complex structures

## Confidence
- Mechanism 1 (Bayes error limiting certified accuracy): **High** - The mathematical derivation is sound and directly follows from Bayes decision theory
- Mechanism 2 (Convolution increasing Bayes error): **Medium** - The theorem is mathematically proven, but practical validation is limited to specific datasets
- Mechanism 3 (Irreducible robustness error bounds): **Medium** - The theoretical framework is rigorous, but depends on accurate estimation of distribution properties

## Next Checks
1. **Distribution Sensitivity Test**: Evaluate the bounds on additional synthetic distributions with varying overlap characteristics to assess robustness to distribution assumptions
2. **Architecture Independence Verification**: Test whether the bounds hold across different neural network architectures (CNNs, transformers, etc.) on the same datasets
3. **Perturbation Structure Analysis**: Extend the theoretical framework to anisotropic perturbations and compare bounds with isotropic assumptions to quantify the impact of perturbation structure assumptions