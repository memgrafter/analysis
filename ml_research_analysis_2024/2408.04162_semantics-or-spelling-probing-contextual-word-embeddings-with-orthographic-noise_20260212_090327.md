---
ver: rpa2
title: Semantics or spelling? Probing contextual word embeddings with orthographic
  noise
arxiv_id: '2408.04162'
source_url: https://arxiv.org/abs/2408.04162
tags:
- word
- words
- cwes
- noise
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the reliability of contextual word embeddings
  (CWEs) from pretrained language models (PLMs) as semantic proxies by probing their
  sensitivity to minor orthographic noise. The authors hypothesize that if CWEs primarily
  encode semantic information, a single character swap in an input word should not
  drastically affect the resulting representation, given sufficient linguistic context.
---

# Semantics or spelling? Probing contextual word embeddings with orthographic noise

## Quick Facts
- arXiv ID: 2408.04162
- Source URL: https://arxiv.org/abs/2408.04162
- Authors: Jacob A. Matthews; John R. Starr; Marten van Schijndel
- Reference count: 15
- This paper investigates the reliability of contextual word embeddings (CWEs) from pretrained language models (PLMs) as semantic proxies by probing their sensitivity to minor orthographic noise.

## Executive Summary
This study investigates whether contextual word embeddings (CWEs) from pretrained language models (PLMs) primarily encode semantic information by probing their sensitivity to minor orthographic noise. The authors hypothesize that if CWEs are robust semantic proxies, a single character swap in an input word should not drastically affect the resulting representation, given sufficient linguistic context. Surprisingly, the results show that CWEs are highly sensitive to such noise, with this effect being most pronounced for single-token words, which constitute over a third of English words in the test data. This sensitivity is related to subword tokenization: words represented by fewer tokens are more susceptible to noise-induced changes in token-level representation, leading to drastically different CWEs. The study concludes that PLM-derived CWEs may not be reliable semantic proxies and that caution is warranted when interpreting representational similarity, especially when dealing with noisy data.

## Method Summary
The authors investigate the reliability of contextual word embeddings (CWEs) as semantic proxies by probing their sensitivity to minor orthographic noise. They hypothesize that if CWEs primarily encode semantic information, a single character swap in an input word should not drastically affect the resulting representation, given sufficient linguistic context. To test this, they create a vocabulary of 68,725 alphabetic words with more than 3 characters from the Wikitext-2-raw-v1 training set and generate edited versions of each word by randomly replacing a single character with another of the same case. They then generate CWEs for each word and its edited counterpart using versions of GPT-2, BERT, RoBERTa, XLNet, and BLOOM, both with and without context from Wikitext. The CWEs are compared using cosine similarity and Spearman correlation to assess noise robustness, and the results are analyzed across different token lengths and model families.

## Key Results
- CWEs from PLMs are highly sensitive to minor orthographic noise, challenging the assumption that they primarily encode semantic information.
- The sensitivity to noise is most pronounced for single-token words, which constitute over a third of English words in the test data.
- The relationship between subword tokenization and CWE noise robustness suggests that caution is warranted when interpreting representational similarity, especially when dealing with noisy data.

## Why This Works (Mechanism)
The study investigates the relationship between subword tokenization and the noise robustness of contextual word embeddings (CWEs) from pretrained language models (PLMs). By analyzing how CWEs change when a single character in a word is swapped, the authors aim to understand whether CWEs primarily encode semantic information or are sensitive to minor orthographic variations. The key insight is that words represented by fewer tokens (e.g., single-token words) are more susceptible to noise-induced changes in token-level representation, leading to drastically different CWEs. This finding challenges the assumption that CWEs are reliable semantic proxies and highlights the importance of considering subword tokenization when interpreting representational similarity.

## Foundational Learning
1. Contextual Word Embeddings (CWEs): Vector representations of words that take into account the surrounding context in which the word appears. CWEs are generated by pretrained language models (PLMs) and are used in various natural language processing tasks. [Why needed: Understanding CWEs is crucial for interpreting the study's findings on their sensitivity to orthographic noise.] [Quick check: Familiarize yourself with the concept of CWEs and how they are generated by PLMs.]

2. Subword Tokenization: A technique used in PLMs to break down words into smaller subword units (e.g., characters, character n-grams, or word pieces) to handle out-of-vocabulary words and improve efficiency. [Why needed: The study's findings on CWE noise robustness are closely related to subword tokenization.] [Quick check: Understand the different subword tokenization methods (e.g., BPE, WordPiece) and their impact on CWEs.]

3. Orthographic Noise: Minor variations or errors in the spelling or representation of words, such as typos, misspellings, or character swaps. [Why needed: The study investigates the sensitivity of CWEs to orthographic noise to assess their reliability as semantic proxies.] [Quick check: Consider examples of orthographic noise and how they might affect word representations in PLMs.]

## Architecture Onboarding
Component map: Input words -> Subword tokenization -> PLM -> CWEs -> Similarity analysis
Critical path: Subword tokenization -> PLM -> CWEs
Design tradeoffs: The study uses single-character swaps as a form of orthographic noise, which may not represent all types of noise encountered in practice. Additionally, the focus on English words limits the generalizability of the findings to other languages and scripts.
Failure signatures: If the similarity scores do not show a clear pattern of sensitivity to orthographic noise, it may indicate issues with the preprocessing of the data or the generation of CWEs. If the results differ significantly from the reported findings, it could be due to differences in the PLM implementations or tokenization methods.
First experiments: 1) Verify the correctness of the vocabulary extraction and the edited word creation process. 2) Ensure that the correct versions of the models are used and that the tokenization is consistent with the study's approach. 3) Analyze the similarity scores to determine the noise robustness of CWEs and observe patterns in sensitivity to orthographic noise across different token lengths and model families.

## Open Questions the Paper Calls Out
1. How do different types of orthographic noise (e.g., character swaps, insertions, deletions) affect the robustness of contextual word embeddings?
2. To what extent do part-of-speech and other word-level characteristics influence the noise robustness of contextual word embeddings?
3. How do different subword tokenization methods compare in terms of their impact on the noise robustness of contextual word embeddings?

## Limitations
- The study focuses on English words and may not generalize to other languages or scripts.
- The analysis is based on a specific dataset (Wikitext-2-raw-v1) and may not capture the full diversity of real-world text.
- The study only considers single-character swaps as noise, which may not represent all types of orthographic variations encountered in practice.

## Confidence
High confidence in the finding that CWEs are sensitive to orthographic noise, as demonstrated by the consistent results across multiple PLMs and evaluation metrics. Medium confidence in the conclusion that CWEs may not be reliable semantic proxies, as this interpretation relies on the assumption that semantic information should be robust to minor orthographic changes. Low confidence in the generalizability of the results to other languages, scripts, or types of orthographic noise.

## Next Checks
1. Evaluate the sensitivity of CWEs to orthographic noise in other languages and scripts to assess the generalizability of the findings.
2. Investigate the impact of different types of orthographic noise (e.g., transpositions, insertions, deletions) on CWEs to determine if the observed sensitivity is specific to single-character swaps.
3. Explore the relationship between CWEs and subword tokenization more closely by analyzing how different tokenization strategies (e.g., BPE, WordPiece) affect the noise robustness of CWEs.