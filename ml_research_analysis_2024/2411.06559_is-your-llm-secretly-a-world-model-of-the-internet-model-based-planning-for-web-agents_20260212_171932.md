---
ver: rpa2
title: Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for
  Web Agents
arxiv_id: '2411.06559'
source_url: https://arxiv.org/abs/2411.06559
tags:
- action
- world
- planning
- actions
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WEBDREAMER, a model-based planning framework
  for web agents that leverages large language models (LLMs) as world models to simulate
  and score future states before executing actions. By predicting the outcomes of
  candidate actions, WEBDREAMER enables informed decision-making in complex web environments
  where backtracking is often infeasible due to irreversible actions.
---

# Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents

## Quick Facts
- arXiv ID: 2411.06559
- Source URL: https://arxiv.org/abs/2411.06559
- Reference count: 28
- Primary result: Introduces WEBDREAMER, a model-based planning framework using LLMs as world models for web agents, achieving 4–5× efficiency gains over tree search while maintaining competitive performance

## Executive Summary
This paper introduces WEBDREAMER, a model-based planning framework for web agents that leverages large language models (LLMs) as world models to simulate and score future states before executing actions. By predicting the outcomes of candidate actions, WEBDREAMER enables informed decision-making in complex web environments where backtracking is often infeasible due to irreversible actions. The framework uses LLMs to implement both the simulation function (sim) and the scoring function (score), iteratively selecting the best action based on simulated trajectories. Additionally, the authors train a specialized world model, Dreamer-7B, using over 3.1 million interaction instances synthesized by a scalable data pipeline. Empirically, WEBDREAMER achieves substantial performance improvements over reactive baselines across three benchmarks, including real-world websites (Online-Mind2Web and Mind2Web-Live) and sandbox environments (VisualWebArena). It is competitive with tree search methods while being 4–5 times more efficient. Dreamer-7B performs comparably to GPT-4o on online benchmarks, and domain-specific fine-tuning further enhances its effectiveness, surpassing GPT-4o in certain environments. These results highlight the potential of specialized world models for efficient and effective planning in complex web environments.

## Method Summary
The paper introduces WEBDREAMER, a model-based planning framework for web agents that uses LLMs as world models to simulate and score future states before executing actions. The framework implements a simulation function (sim) that predicts state transitions and a scoring function (score) that evaluates trajectories, selecting the action with the highest expected reward. To improve performance, the authors train a specialized world model, Dreamer-7B, on over 3.1 million synthetic interaction instances generated through a scalable data pipeline. Dreamer-7B is fine-tuned to predict the next state as a natural language description after performing an action. The framework is evaluated across three benchmarks: VisualWebArena, Online-Mind2Web, and Mind2Web-Live, demonstrating substantial improvements over reactive baselines and competitive performance with tree search methods while being 4–5 times more efficient.

## Key Results
- WEBDREAMER achieves substantial performance improvements over reactive baselines across three benchmarks (Online-Mind2Web, Mind2Web-Live, VisualWebArena)
- Dreamer-7B performs comparably to GPT-4o on online benchmarks while being 4–5 times more efficient than tree search methods
- Domain-specific fine-tuning of Dreamer-7B further enhances effectiveness, surpassing GPT-4o in certain environments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using LLMs as world models enables informed decision-making by predicting the outcomes of candidate actions before execution.
- Mechanism: LLMs simulate state transitions and score potential trajectories, allowing the agent to choose the action with the highest expected reward without actually executing it.
- Core assumption: LLMs pretrained on web-scale data have implicitly learned both structural knowledge of websites and common sense needed to predict the outcomes of proposed actions.
- Evidence anchors:
  - [abstract] "WEBDREAMER, a model-based planning framework that uses LLMs to simulate and score possible future states before executing actions"
  - [section] "We propose building world models for the Internet by leveraging large language models (LLMs) as the foundation. Pretrained on web-scale data, LLMs have implicitly acquired both structural knowledge of websites and common sense needed to predict the outcomes of proposed actions"
  - [corpus] Weak - no direct corpus evidence found for LLM world models in web planning
- Break condition: If the LLM lacks sufficient web knowledge or the action space becomes too complex for accurate simulation.

### Mechanism 2
- Claim: Training specialized world models on synthesized web interaction data improves planning performance compared to using general-purpose LLMs.
- Mechanism: A dedicated world model trained on 3.1 million interaction instances learns domain-specific patterns and transitions, providing more accurate simulations for web planning.
- Core assumption: The synthesized data captures rich causal relationships between user actions and web state transitions that can be learned by a smaller model.
- Evidence anchors:
  - [abstract] "Furthermore, our trained world model, Dreamer-7B, performs comparable to GPT-4o"
  - [section] "Empirically, WEBDREAMER achieves substantial performance improvements over reactive baselines across three benchmarks"
  - [corpus] Weak - corpus mentions related work but no direct evidence for this specific training approach
- Break condition: If the synthesized data doesn't capture sufficient diversity or the training process doesn't generalize to unseen websites.

### Mechanism 3
- Claim: Model-based planning is more efficient than tree search with real interactions because it avoids backtracking and reduces the number of actual web interactions.
- Mechanism: By simulating outcomes before execution, the agent only interacts with the actual website when it's confident about the action, avoiding the exploration and backtracking costs of tree search.
- Core assumption: The simulation accuracy is sufficient to make good decisions without extensive exploration.
- Evidence anchors:
  - [abstract] "It is competitive, while being 4–5 times more efficient, with tree search in sandbox environments"
  - [section] "Tree search-based planning with real interactions is costly and risks irreversible actions. Model-based planning through simulation mitigates this by using a learned simulation function"
  - [corpus] Moderate - related work mentions efficiency concerns but no direct comparison evidence
- Break condition: If the simulation function becomes too inaccurate, leading to poor decisions despite fewer interactions.

## Foundational Learning

- Concept: Partially Observable Markov Decision Process (POMDP)
  - Why needed here: Web agents operate in environments where they can only observe partial states of the webpage, requiring decision-making under uncertainty.
  - Quick check question: How does a POMDP differ from a regular MDP in terms of observability?

- Concept: Model Predictive Control (MPC)
  - Why needed here: The planning framework uses MPC to simulate possible future states for each action over a finite horizon and execute the action with the highest score.
  - Quick check question: What are the key components of an MPC framework in the context of web planning?

- Concept: Data synthesis for world model training
  - Why needed here: Real web interaction data is scarce and expensive, so synthesizing data through random web walking and automated state change description is crucial.
  - Quick check question: What are the main challenges in creating synthetic data that accurately represents real web interactions?

## Architecture Onboarding

- Component map: Candidate action generation (top-k sampling + LLM refinement) -> Simulation function (state transition prediction + action proposal) -> Scoring function (trajectory evaluation) -> Execution engine (actual web interaction) -> World model training pipeline (data synthesis + model fine-tuning)

- Critical path: Action proposal → Simulation → Scoring → Execution → Observation

- Design tradeoffs:
  - Planning horizon vs. simulation accuracy (longer horizons accumulate more errors)
  - Model size vs. inference cost (smaller models faster but potentially less accurate)
  - Data diversity vs. domain specificity (broader data more general, specialized data more accurate for specific sites)

- Failure signatures:
  - Poor action selection despite high simulation scores (simulation accuracy issues)
  - Excessive simulation time compared to execution (inefficient implementation)
  - Degraded performance on unseen websites (overfitting to training data)

- First 3 experiments:
  1. Compare success rates of reactive vs. model-based planning on a simple benchmark
  2. Measure simulation accuracy by comparing predicted vs. actual state changes
  3. Test efficiency gains by measuring steps and time for both approaches on the same tasks

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several important questions arise from the work:

### Open Question 1
- Question: How does the performance of WebDreamer change when the planning horizon H is increased beyond 1, given that longer horizons introduce action proposal hallucinations?
- Basis in paper: [explicit] The paper notes that planning horizon H=1 is empirically most effective and efficient, but investigates horizons of 1, 2, and 3 on Online-Mind2Web, observing diminishing returns due to hallucinations.
- Why unresolved: While the paper identifies the issue, it does not explore alternative strategies to mitigate hallucinations in longer-horizon planning or test whether architectural modifications could enable effective multi-step planning.
- What evidence would resolve it: Experiments testing WebDreamer with H>1 after applying hallucination mitigation techniques (e.g., filtering irrelevant actions during simulation) would show whether longer horizons can be made effective.

### Open Question 2
- Question: Can the intrinsic evaluation dataset be expanded to cover a more diverse set of web tasks and interaction types to better predict real-world performance?
- Basis in paper: [explicit] The intrinsic evaluation is constructed from 44 tasks, 141 states, and 279 deviation actions, and shows a Pearson correlation of 0.8455 with downstream task success.
- Why unresolved: The current dataset is limited in size and diversity, potentially missing edge cases or rare interaction patterns that could significantly impact model selection and performance.
- What evidence would resolve it: Expanding the intrinsic dataset to include hundreds of tasks across more diverse domains and interaction types, then measuring the correlation with downstream performance, would validate its predictive power.

### Open Question 3
- Question: How would scaling the synthetic training data beyond the current 3.1M instances affect the performance of Dreamer-7B on real-world benchmarks?
- Basis in paper: [explicit] The paper shows a scaling trend where performance improves with larger training datasets but tapers off at higher scales, suggesting diminishing returns.
- Why unresolved: The paper does not explore whether further scaling could yield continued improvements or if a saturation point has been reached, leaving the optimal data size unclear.
- What evidence would resolve it: Training Dreamer-7B on datasets of 5M, 10M, and 20M interactions and evaluating on Online-Mind2Web and Mind2Web-Live would reveal whether continued scaling provides meaningful gains.

### Open Question 4
- Question: What is the impact of using Dreamer-7B versus GPT-4o on task completion time and cost in real-world deployments?
- Basis in paper: [explicit] Dreamer-7B performs comparably to GPT-4o on two online benchmarks, and WebDreamer is 4–5 times more efficient than tree search, but no direct comparison of inference cost and latency between Dreamer-7B and GPT-4o is provided.
- Why unresolved: While Dreamer-7B is cheaper to run than GPT-4o, the paper does not quantify the exact cost savings or latency improvements in practical deployments.
- What evidence would resolve it: Measuring task completion time and inference cost per task for both models on the same benchmark would provide concrete metrics for deployment decisions.

### Open Question 5
- Question: How does the performance of WebDreamer vary across different types of web domains (e.g., e-commerce, social media, forums) when using domain-specific fine-tuned world models?
- Basis in paper: [explicit] The paper fine-tunes Dreamer-7B on in-domain data for Classifieds, Reddit, and Shopping, showing improvements in Classifieds and Shopping but not Reddit, likely due to dense layouts and limited interactions.
- Why unresolved: The analysis is limited to three domains, and the paper does not explore why Reddit underperforms or whether additional fine-tuning strategies could improve performance in such environments.
- What evidence would resolve it: Testing WebDreamer with domain-specific models on a broader set of domains (e.g., banking, travel, education) and analyzing failure modes would clarify the framework's generalizability and limitations.

## Limitations
- The framework's performance on highly dynamic or personalized websites remains untested, as benchmarks focus on relatively static web content
- Simulation accuracy depends heavily on the quality of synthesized training data, with no detailed error analysis of prediction failures provided
- The efficiency claims assume simulation runs faster than actual web interactions, which may not hold for all environments or LLM configurations

## Confidence

- **High confidence** in the core claim that LLM-based world models can improve planning efficiency over reactive approaches, supported by empirical results across multiple benchmarks
- **Medium confidence** in the efficiency claims relative to tree search, as the comparison methodology isn't fully detailed and the 4-5× improvement may vary with implementation specifics
- **Medium confidence** in the superiority of specialized world models over general LLMs, though the comparison with GPT-4o shows promising results that need broader validation

## Next Checks

1. **Simulation accuracy analysis**: Measure the percentage of correctly predicted state transitions across different website types and action categories to identify failure patterns and limitations of the world model.

2. **Cross-domain generalization test**: Evaluate WEBDREAMER on websites with significantly different structures and interaction patterns than those in the training data to assess true generalization capabilities.

3. **Efficiency benchmarking**: Conduct head-to-head comparisons measuring both computation time and actual web interaction time across different planning approaches under varying network conditions and website complexities.