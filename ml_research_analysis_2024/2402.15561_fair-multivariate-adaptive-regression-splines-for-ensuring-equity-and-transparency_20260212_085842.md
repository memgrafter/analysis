---
ver: rpa2
title: Fair Multivariate Adaptive Regression Splines for Ensuring Equity and Transparency
arxiv_id: '2402.15561'
source_url: https://arxiv.org/abs/2402.15561
tags:
- mars
- fairness
- basis
- knot
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces fairMARS, a transparent and interpretable
  regression model based on Multivariate Adaptive Regression Splines (MARS) that incorporates
  fairness measures in the learning process. Unlike existing fair regression models,
  fairMARS does not require parametric assumptions, handles non-linear relationships,
  and generates interpretable decision rules.
---

# Fair Multivariate Adaptive Regression Splines for Ensuring Equity and Transparency

## Quick Facts
- arXiv ID: 2402.15561
- Source URL: https://arxiv.org/abs/2402.15561
- Authors: Parian Haghighat; Denisa G'andara; Lulu Kang; Hadis Anahideh
- Reference count: 13
- Primary result: fairMARS achieves comparable accuracy to MARS while significantly reducing disparity across sensitive subgroups.

## Executive Summary
This paper introduces fairMARS, a transparent and interpretable regression model based on Multivariate Adaptive Regression Splines (MARS) that incorporates fairness measures in the learning process. Unlike existing fair regression models, fairMARS does not require parametric assumptions, handles non-linear relationships, and generates interpretable decision rules. The key innovation is integrating fairness into the knot optimization algorithm and coefficient estimation, ensuring that predictor variables and their knots do not introduce or exacerbate bias against any group. Experimental results on real-world datasets demonstrate that fairMARS achieves comparable accuracy to MARS while significantly reducing disparity across sensitive subgroups.

## Method Summary
fairMARS extends standard MARS by modifying the knot optimization process to include fairness constraints and adjusting coefficient estimation through weighted least squares based on subgroup proportions. The algorithm integrates fairness into the knot selection objective by adding a penalty term proportional to absolute error differences between subgroups, and uses weighted least squares where weights reflect subgroup observation proportions. This approach preserves the interpretability of MARS while ensuring equity across sensitive subgroups.

## Key Results
- fairMARS reduces absolute error difference for Black subgroup from 0.016 to 0.012 compared to MARS on ELS dataset
- Maintains comparable overall MSE (0.020 vs 0.021) while improving fairness
- Outperforms fair decision trees in terms of accuracy, flexibility, and interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: fairMARS achieves fairness by integrating fairness constraints into the knot optimization step, balancing accuracy and subgroup disparity.
- Mechanism: The knot optimization objective is modified to include a penalty term proportional to the absolute error difference between subgroups, guiding the selection of knots that reduce both RSS and disparity.
- Core assumption: The objective function modification preserves the convergence properties of the original MARS algorithm while improving fairness.
- Evidence anchors:
  - [abstract] "Specifically, we integrate fairness into the knot optimization algorithm and provide theoretical and empirical evidence of how it results in a fair knot placement."
  - [section] "By minimizing the absolute error difference within the knot search objective function, we aim to ensure that the selection of predictor variables and their knots does not introduce or exacerbate bias or discrimination against any group."
  - [corpus] Weak: corpus contains related papers on regression and fairness but lacks direct discussion of knot-level fairness integration in MARS.
- Break condition: If the λ parameter is not tuned properly, fairness improvements may come at the cost of unacceptable accuracy loss, or the optimization may fail to converge.

### Mechanism 2
- Claim: fairMARS ensures fairness in coefficient estimation by using weighted least squares that reflect subgroup observation proportions.
- Mechanism: The linear least-squares loss is converted into a weighted least-squares loss, where weights are proportional to the inverse variance of each subgroup's observations.
- Core assumption: Weighted least squares with subgroup-specific weights leads to coefficients that produce fairer predictions across subgroups.
- Evidence anchors:
  - [section] "For faircoef estimation, we extend the loss function by assigning weights to observations based on wi = 1/σi, reflecting the proportion of each subgroup in the training data."
  - [abstract] "Experimental results on real-world datasets demonstrate that fairMARS achieves comparable accuracy to MARS while significantly reducing disparity across sensitive subgroups."
  - [corpus] Weak: corpus includes papers on fairness in regression but not specifically on weighted least squares for subgroup fairness in MARS.
- Break condition: If subgroup sizes are very imbalanced or if variance estimates are unreliable, the weighting scheme may introduce new biases or fail to improve fairness.

### Mechanism 3
- Claim: fairMARS preserves interpretability by maintaining the MARS framework and decision rule structure while enforcing fairness.
- Mechanism: The algorithm retains the original MARS basis function generation and pruning steps, but biases the selection toward knots that are fair across subgroups, thus preserving transparency.
- Core assumption: The interpretability of MARS is not compromised by the integration of fairness constraints at the knot selection level.
- Evidence anchors:
  - [abstract] "fairMARS stands out compared to the fair decision tree regression model... in terms of accuracy, flexibility, and interpretability."
  - [section] "fairMARS can produce smooth and flexible curves that accurately represent the underlying relationships between predictor and outcome variables across different sensitive subgroups."
  - [corpus] Weak: corpus does not provide direct evidence on the interpretability of fairMARS versus MARS.
- Break condition: If fairness constraints force the model to select knots that are too complex or numerous, interpretability could degrade due to increased basis function count.

## Foundational Learning

- Concept: Multivariate Adaptive Regression Splines (MARS)
  - Why needed here: MARS is the base model upon which fairMARS builds; understanding its mechanics is crucial for grasping fairness integration.
  - Quick check question: What are the two main phases of MARS, and what is the purpose of each?
- Concept: Fairness metrics in regression (e.g., absolute error difference)
  - Why needed here: The paper uses absolute error difference to quantify disparity; engineers must understand how it differs from classification fairness measures.
  - Quick check question: How is the absolute error difference computed for subgroups in a regression setting?
- Concept: Generalized Cross-Validation (GCV)
  - Why needed here: GCV is used in both MARS and fairMARS to select the optimal subset of basis functions, balancing model complexity and fit.
  - Quick check question: Why is GCV preferred over standard cross-validation in MARS?

## Architecture Onboarding

- Component map: Knot Optimization Module -> Basis Function Generation -> Coefficient Estimation -> Backward Elimination
- Critical path:
  1. Initialize MARS basis functions (intercept).
  2. Iteratively select knots using modified objective (RSS + λ*Disparity).
  3. Fit coefficients using weighted least squares.
  4. Prune basis functions using backward elimination with fairness consideration.
  5. Output final fairMARS model.
- Design tradeoffs:
  - Accuracy vs. Fairness: λ parameter tunes the trade-off; higher λ favors fairness, lower λ favors accuracy.
  - Interpretability vs. Fairness: Too many knots for fairness can reduce model simplicity.
  - Computational cost: Additional fairness calculations slightly increase runtime, but remain efficient compared to alternatives like fairDT.
- Failure signatures:
  - High λ leading to poor fit (large RSS).
  - Very small or imbalanced subgroups causing unstable variance estimates.
  - Overfitting due to excessive knots introduced to satisfy fairness.
- First 3 experiments:
  1. Compare fairMARS vs. MARS on a balanced dataset; verify subgroup error differences decrease with λ tuned.
  2. Test fairMARS on a dataset with known subgroup bias; confirm fairness improvements without significant accuracy loss.
  3. Perform sensitivity analysis on λ; plot fairness vs. accuracy trade-off curve.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal value of the fairness regularization parameter λ that balances fairness and accuracy in fairMARS?
- Basis in paper: [explicit] The paper mentions λ ∈ {0.2, 0.4, 0.6, 0.8} was explored and notes there may be a trade-off between accuracy and disparity that can be adjusted using λ.
- Why unresolved: The paper does not provide a definitive optimal λ value, only that it can be adjusted based on preferences or constraints.
- What evidence would resolve it: Systematic experimentation across multiple datasets with different λ values and quantitative metrics showing the trade-off curve between fairness (e.g., disparity reduction) and accuracy (e.g., MSE).

### Open Question 2
- Question: How does fairMARS perform on datasets with more than two sensitive attribute categories?
- Basis in paper: [explicit] The paper only considers scenarios with 2 or 5 sensitive attribute categories in the experiments (race with 5 categories, gender with 2 categories).
- Why unresolved: The methodology is presented generally but experimental validation is limited to binary or small categorical sensitive attributes.
- What evidence would resolve it: Testing fairMARS on datasets with high-cardinality sensitive attributes (e.g., multiple racial/ethnic categories, combinations of sensitive attributes) and measuring fairness metrics across all subgroups.

### Open Question 3
- Question: How does fairMARS compare to post-hoc fairness methods that explain black-box models?
- Basis in paper: [inferred] The paper positions fairMARS as an intrinsic interpretable method, contrasting it with post-hoc methods in the introduction, but does not empirically compare to such approaches.
- Why unresolved: The paper only compares fairMARS to other intrinsic fair regression methods, not to post-hoc explainability methods applied to fair black-box models.
- What evidence would resolve it: Direct comparison between fairMARS and a pipeline combining a fair black-box model (e.g., fair random forest) with post-hoc interpretability methods (e.g., SHAP values) on the same datasets.

## Limitations
- Implementation details for fairness-aware knot selection and weighted least squares coefficient estimation are underspecified
- Experimental validation limited to three datasets, which may not generalize to all regression contexts
- Claims about interpretability preservation lack direct evidence and user studies

## Confidence
- **High Confidence**: Claims about fairMARS reducing subgroup error disparity while maintaining MSE comparable to MARS are well-supported by the experimental results presented.
- **Medium Confidence**: The mechanism of fairness integration through modified knot optimization and weighted least squares is theoretically sound, but implementation specifics are underspecified.
- **Low Confidence**: Claims about interpretability preservation lack direct evidence and require further validation.

## Next Checks
1. Implement and test fairMARS on additional regression datasets with known subgroup biases to verify generalizability of fairness improvements.
2. Conduct ablation studies varying the λ parameter to quantify the accuracy-fairness trade-off and identify optimal settings for different data scenarios.
3. Perform interpretability analysis comparing the number and complexity of basis functions generated by fairMARS versus standard MARS across multiple datasets.