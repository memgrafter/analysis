---
ver: rpa2
title: 'Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous
  Tokens'
arxiv_id: '2410.13863'
source_url: https://arxiv.org/abs/2410.13863
tags:
- tokens
- continuous
- autoregressive
- scaling
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work studies how to improve scaling for autoregressive text-to-image
  models. It tests four model variants combining two design choices: discrete vs.'
---

# Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens

## Quick Facts
- arXiv ID: 2410.13863
- Source URL: https://arxiv.org/abs/2410.13863
- Reference count: 39
- Key outcome: Autoregressive text-to-image models with continuous tokens and random-order generation achieve state-of-the-art zero-shot FID of 6.16 on MS-COCO

## Executive Summary
This work investigates how to improve scaling for autoregressive text-to-image models by testing four design variants: discrete vs. continuous tokens, and raster vs. random token generation order. Experiments with models from 150M to 3B parameters show that continuous tokens significantly outperform discrete tokens in visual quality, while random-order models with bidirectional attention achieve much better text-image alignment scores. The authors scale up the best-performing variant to 10.5B parameters, achieving state-of-the-art results with zero-shot FID of 6.16 on MS-COCO and GenEval overall score of 0.69.

## Method Summary
The authors train four autoregressive model variants combining discrete/continuous tokens with raster/random generation order. Models range from 150M to 10.5B parameters and use a T5-XXL text encoder with a transformer decoder. Discrete tokens use cross-entropy loss while continuous tokens employ a diffusion head with diffusion loss. All models are trained on WebLI dataset and evaluated on MS-COCO 2014 for zero-shot FID and GenEval benchmark scores. The training uses AdamW optimizer with batch size 2048 and 1M steps, with validation loss tracking showing power-law scaling across all variants.

## Key Results
- Continuous token models achieve significantly better visual quality than discrete token models
- Random-order models with bidirectional attention achieve notably better GenEval scores than raster-order models
- Validation loss scales as a power-law with model size across all variants, but FID and GenEval do not follow strict power-law trends
- The 10.5B parameter Fluid model achieves state-of-the-art zero-shot FID of 6.16 on MS-COCO and GenEval score of 0.69

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuous tokens preserve more information than discrete tokens, leading to better visual quality
- Mechanism: Vector quantization introduces information loss by mapping continuous pixel values to finite discrete codes. Continuous tokens avoid this quantization step, allowing more accurate representation of fine-grained visual details
- Core assumption: The continuous tokenizer can approximate the true image distribution better than the discrete tokenizer
- Evidence anchors: Continuous token models achieve significantly better visual quality; raster-order discrete token models plateau around 1B parameters
- Break condition: If continuous tokenizer's approximation introduces more noise than information preserved, or training becomes unstable

### Mechanism 2
- Claim: Random-order generation with bidirectional attention allows better global structure editing
- Mechanism: Raster-order generation constrains the model to predict each token based only on previously generated tokens (causal attention). Random-order generation enables bidirectional attention to consider all known tokens when predicting any masked token, enabling iterative refinement of global structure
- Core assumption: Global structure is more important for text-image alignment than local details
- Evidence anchors: Random-order models achieve notably better GenEval scores; random-order models with bidirectional attention significantly outperform raster-order models
- Break condition: If random token selection becomes inefficient or model struggles to maintain coherence without fixed generation order

### Mechanism 3
- Claim: Scaling autoregressive models with continuous tokens follows power-law relationship for validation loss but not necessarily for evaluation metrics
- Mechanism: Autoregressive model's ability to fit training data improves predictably with model size (power-law scaling for validation loss). The gap between validation loss and evaluation metrics arises because these metrics measure different aspects of image quality and text-image alignment not directly optimized during training
- Core assumption: Validation loss is good proxy for overall learning capacity but not necessarily for generating high-quality, text-aligned images
- Evidence anchors: All models scale effectively in validation loss but evaluation performance follows different trends; validation loss scales as power-law with model size
- Break condition: If relationship between validation loss and evaluation metrics becomes non-monotonic at very large model sizes

## Foundational Learning

- Concept: Autoregressive modeling
  - Why needed here: The paper builds autoregressive models for text-to-image generation
  - Quick check question: In an autoregressive model, how is the probability of a sequence decomposed?

- Concept: Vector quantization and its impact on information loss
  - Why needed here: The paper contrasts discrete tokens (which use VQ) with continuous tokens
  - Quick check question: What is the main drawback of using vector quantization in image generation?

- Concept: Attention mechanisms (causal vs. bidirectional)
  - Why needed here: The paper compares raster-order models with causal attention to random-order models with bidirectional attention
  - Quick check question: What is the key difference between causal attention and bidirectional attention?

## Architecture Onboarding

- Component map: Image tokenizer (discrete/continuous) -> Text encoder (T5-XXL) -> Text aligner (trainable transformer blocks) -> Main transformer (decoder-only) -> Output head (softmax/diffusion head)
- Critical path: Text embedding → cross-attention → token prediction → (diffusion steps for continuous tokens)
- Design tradeoffs:
  - Discrete vs. continuous tokens: Discrete tokens are faster to train and sample but lose information. Continuous tokens preserve more information but require diffusion head and more compute
  - Raster vs. random order: Raster order allows kv-caching and faster inference but may struggle with global structure. Random order allows better global editing but is slower and cannot use kv-caching
- Failure signatures:
  - Poor visual quality with discrete tokens: Indicates information loss from VQ
  - Gray artifacts in raster-order continuous tokens: Suggests issues with positional embeddings
  - Bright spots in random-order continuous tokens: May indicate instability in diffusion process
- First 3 experiments:
  1. Train small raster-order model with discrete tokens to verify baseline implementation
  2. Switch to continuous tokens and compare visual quality and validation loss
  3. Switch to random order and compare GenEval scores and generation speed

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the fundamental reason that autoregressive models with continuous tokens and random order generation outperform raster-order models with discrete tokens?
- Basis in paper: [explicit] The authors observe that continuous token models produce significantly better visual quality than discrete token models, and random-order models achieve notably better GenEval scores compared to raster-order models. They hypothesize that vector quantization in discrete token models introduces information loss, and that random order generation with bidirectional attention allows better global structure adjustment.
- Why unresolved: The paper provides empirical observations but does not conduct rigorous theoretical analysis of why these architectural choices lead to better performance. The exact mechanisms by which continuous tokens and random order generation improve visual quality and text-image alignment remain unclear.
- What evidence would resolve it: Detailed ablation studies comparing information retention in discrete vs. continuous tokenization, analysis of attention patterns in random vs. raster order generation, and controlled experiments isolating the effects of token continuity and generation order would help clarify underlying reasons for performance differences.

### Open Question 2
- Question: Is there a strict power-law relationship between model size and evaluation metrics (FID and GenEval) for autoregressive text-to-image models, similar to what has been observed in language models?
- Basis in paper: [explicit] The authors note that while validation loss scales as a power-law with model size, FID and GenEval scores do not follow strict power-law trend. They observe that improvements in validation loss do not always translate linearly to better evaluation metrics.
- Why unresolved: The paper provides empirical evidence showing that evaluation metrics improve with model size but do not strictly follow power-law scaling. However, it does not determine whether this is due to inherent limitations of autoregressive models for vision tasks or if power-law scaling might emerge with further scaling.
- What evidence would resolve it: Training autoregressive models with continuous tokens and random order generation to much larger scales (e.g., 100B+ parameters) and measuring evaluation metrics would determine if power-law scaling emerges at larger scales, or if deviation from power-law scaling is fundamental to autoregressive vision models.

### Open Question 3
- Question: What are the fundamental limits of autoregressive text-to-image models in terms of visual quality and text-image alignment, and how close are current models to these limits?
- Basis in paper: [explicit] The authors achieve state-of-the-art results with their 10.5B parameter Fluid model, achieving zero-shot FID of 6.16 on MS-COCO and GenEval overall score of 0.69. They note that GenEval scores plateau for 10.5B model compared to 3.1B model, though visual quality continues to improve.
- Why unresolved: The paper demonstrates significant improvements in autoregressive models but does not establish what ultimate achievable performance limits are. The plateau in GenEval scores for larger models suggests potential limitations, but it's unclear whether these are fundamental or can be overcome with architectural innovations.
- What evidence would resolve it: Systematic scaling experiments beyond 10.5B parameters, comprehensive benchmarking against human preferences for visual quality and text-image alignment, and comparisons with theoretical bounds on autoregressive model performance would help establish fundamental limits of these models.

## Limitations

- The empirical analysis shows inconsistent scaling patterns for downstream evaluation metrics (FID, GenEval) despite clear scaling trends for validation loss
- The claim that continuous tokens inherently preserve more information than discrete tokens rests on theoretical assumptions about VQ information loss rather than direct quantitative comparison
- The mechanism explaining random-order generation's advantage through global structure editing is supported by benchmark scores but lacks supporting qualitative analysis of generated samples

## Confidence

- **High confidence**: Validation loss scales as a power-law with model size across all four model variants
- **Medium confidence**: Continuous tokens produce better visual quality than discrete tokens
- **Medium confidence**: Random-order models with bidirectional attention achieve better text-image alignment than raster-order models
- **Low confidence**: The 10.5B parameter Fluid model achieves state-of-the-art zero-shot FID of 6.16 on MS-COCO

## Next Checks

1. **Quantitative VQ information loss analysis**: Measure and compare the reconstruction error of discrete vs. continuous tokenizers on held-out image dataset, and correlate this with downstream generation quality to directly validate information preservation mechanism

2. **Attention pattern ablation study**: Generate and visualize attention maps for both raster-order and random-order models during generation to empirically demonstrate how bidirectional attention enables global structure refinement versus local constraints of causal attention

3. **Scaling extrapolation validation**: Train additional intermediate model sizes (e.g., 500M, 1.5B parameters) to verify whether power-law scaling relationship for validation loss continues to hold and whether evaluation metrics follow predictable trends beyond tested range