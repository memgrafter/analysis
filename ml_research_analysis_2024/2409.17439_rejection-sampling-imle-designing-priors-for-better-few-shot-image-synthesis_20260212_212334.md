---
ver: rpa2
title: 'Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis'
arxiv_id: '2409.17439'
source_url: https://arxiv.org/abs/2409.17439
tags:
- data
- imle
- training
- samples
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the misalignment between latent codes used
  during training and testing in implicit generative models like IMLE when trained
  on limited data. The core method, RS-IMLE, uses rejection sampling to modify the
  prior distribution used for training, ensuring better alignment between training
  and testing latent distributions.
---

# Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis

## Quick Facts
- arXiv ID: 2409.17439
- Source URL: https://arxiv.org/abs/2409.17439
- Authors: Chirag Vashist; Shichong Peng; Ke Li
- Reference count: 40
- Key outcome: RS-IMLE achieves 45.9% decrease in FID compared to best baseline method on nine few-shot image datasets

## Executive Summary
This paper addresses the misalignment between latent codes used during training and testing in implicit generative models like IMLE when trained on limited data. The core method, RS-IMLE, uses rejection sampling to modify the prior distribution used for training, ensuring better alignment between training and testing latent distributions. This leads to higher quality image generation during inference. Experiments on nine few-shot image datasets show that RS-IMLE achieves a 45.9% decrease in FID compared to the best baseline method.

## Method Summary
RS-IMLE modifies the implicit maximum likelihood estimation (IMLE) framework by introducing rejection sampling during training. For each data point, instead of drawing m samples from a standard normal prior and selecting the closest one, RS-IMLE first filters out samples within a radius ε of any data point using rejection sampling. This modified selection process ensures that the distribution of samples used for training better aligns with the standard normal prior used at test time, addressing the fundamental misalignment issue in vanilla IMLE. The method employs fast k-nearest neighbor search (DCI) for efficient computation and uses a generator network with decoder modules from VDVAE combined with a fully-connected mapping network.

## Key Results
- Achieves 45.9% decrease in FID compared to best baseline method across nine few-shot image datasets
- Produces sharper and more diverse images with near-perfect precision and significantly higher recall than baselines
- Demonstrates superior performance in visual recall tests, where generated samples closely resemble query images while maintaining diversity
- Effective even with reduced model parameters, outperforming baselines in challenging datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The misalignment between training and testing latent distributions in IMLE is caused by the selection bias inherent in the min operation during training.
- Mechanism: During IMLE training, for each data point, the algorithm selects the closest sample among m draws from a standard normal prior. This creates a biased latent distribution that systematically prefers samples closer to data points. At test time, when sampling from the same standard normal prior without the selection bias, the latent distribution differs, causing poor sample quality in regions rarely visited during training.
- Core assumption: The selected samples during training follow a different distribution than the prior, and this discrepancy directly causes the quality gap at test time.
- Evidence anchors:
  - [abstract] states "current IMLE-based approaches encounter challenges due to inadequate correspondence between the latent codes selected for training and those drawn during inference."
  - [section 3.3 Analysis of the Misalignment Issue] derives the CDF relationship showing that the distribution of selected samples differs from random samples, and notes that "there are large gaps between these bands, indicating that these segments of the latent space are consistently overlooked during training."
  - [corpus] has no direct evidence about this mechanism; the closest neighbor is PRISM: Performer RS-IMLE, which mentions IMLE but focuses on robotics.
- Break condition: If the min operation's selection bias is somehow neutralized (e.g., through uniform sampling or different objective), the misalignment would disappear.

### Mechanism 2
- Claim: RS-IMLE fixes the misalignment by using rejection sampling to modify the prior distribution during training.
- Mechanism: RS-IMLE defines a target prior distribution that, when used with rejection sampling, ensures the selected samples during training have a distribution closer to the standard normal prior used at test time. By rejecting samples within a radius ε of any data point, the method avoids the selection bias that caused the misalignment in vanilla IMLE.
- Core assumption: The target prior can be constructed such that the distribution of samples selected during training (after rejection) matches the standard normal distribution encountered at test time.
- Evidence anchors:
  - [abstract] states RS-IMLE "changes the prior distribution used for training" to "substantially higher quality image generation."
  - [section 3.4 Solving the Misalignment Issue] derives the target prior distribution and explains the rejection sampling procedure, showing how the selected samples follow the desired distribution.
  - [corpus] has no direct evidence about this rejection sampling mechanism; the closest neighbor is MoFlow, which mentions IMLE but in a different context.
- Break condition: If the rejection sampling introduces too much bias (e.g., very high rejection rate), the effective sample size becomes too small to learn meaningful representations.

### Mechanism 3
- Claim: The hyperparameter ε in RS-IMLE controls the trade-off between sample quality and diversity.
- Mechanism: A larger ε rejects more samples, forcing the generator to learn from more challenging samples that are farther from data points. This improves sample diversity but may reduce quality if ε is too large. The optimal ε balances these competing objectives.
- Core assumption: There exists an optimal ε that maximizes both sample quality and diversity.
- Evidence anchors:
  - [section 4.3 Ablation Study] shows FID scores for different ε values, with the best performance around ε=0.15.
  - [section 3.6 Implementation Details] mentions that ε is selected through cross-validation.
  - [corpus] has no direct evidence about this hyperparameter tuning; the closest neighbor is CTS, which mentions consistency but not hyperparameter selection.
- Break condition: If ε is set too low, the method reverts to vanilla IMLE with misalignment; if too high, the rejection rate becomes excessive and learning stalls.

## Foundational Learning

- Concept: Implicit Maximum Likelihood Estimation (IMLE)
  - Why needed here: RS-IMLE builds directly on IMLE, modifying its prior distribution. Understanding IMLE's objective and how it selects samples is crucial for grasping why the misalignment occurs and how RS-IMLE addresses it.
  - Quick check question: In IMLE, for each data point, how many samples are drawn from the prior, and what determines which sample is selected for training?

- Concept: Rejection Sampling
  - Why needed here: RS-IMLE uses rejection sampling to modify the prior distribution. Understanding how rejection sampling works and how it can be used to sample from complex distributions is essential for understanding the method's implementation.
  - Quick check question: In rejection sampling, what is the acceptance probability for a sample, and how does it relate to the target and proposal distributions?

- Concept: Fréchet Inception Distance (FID)
  - Why needed here: FID is the primary quantitative metric used to evaluate generated image quality. Understanding how FID is computed and what it measures is important for interpreting the experimental results.
  - Quick check question: FID measures the distance between two distributions in feature space. What are these two distributions, and how are they estimated from real and generated images?

## Architecture Onboarding

- Component map:
  Generator network (VDVAE decoder + mapping network) -> Rejection sampling module -> Fast k-nearest neighbor search (DCI) -> Distance metric (L2 in image space)

- Critical path:
  1. Sample m latent codes from standard normal prior
  2. Apply rejection sampling to filter out samples within ε of any data point
  3. For each data point, find the nearest remaining sample using fast nearest neighbor search
  4. Compute loss and update generator parameters

- Design tradeoffs:
  - Sample efficiency vs. computational cost: Larger m improves sample quality but increases nearest neighbor search cost
  - Rejection rate vs. learning signal: Larger ε improves alignment but may reduce effective sample size
  - Dimensionality of projected space vs. accuracy: Lower dimensionality speeds up nearest neighbor search but may reduce distance accuracy

- Failure signatures:
  - High rejection rate (>90%): ε is too large, effective sample size is too small
  - Poor FID scores despite training: Nearest neighbor search is inaccurate, or generator architecture is insufficient
  - Mode collapse: ε is too small, or generator lacks capacity to model diverse modes

- First 3 experiments:
  1. Implement vanilla IMLE with different values of m (e.g., 10×, 20×, 50× number of data points) and observe how FID changes
  2. Implement RS-IMLE with ε=0 and compare to vanilla IMLE to verify that it reproduces the misalignment issue
  3. Implement RS-IMLE with different values of ε (e.g., 0.1, 0.15, 0.2) and observe the trade-off between FID and rejection rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of the distance function $d(\cdot, \cdot)$ affect the performance of RS-IMLE compared to other distance metrics?
- Basis in paper: [explicit] The paper mentions that $d(\cdot, \cdot)$ is a distance metric but does not explore different distance functions.
- Why unresolved: The paper does not provide an ablation study or theoretical analysis on how different distance metrics impact the performance of RS-IMLE.
- What evidence would resolve it: Experimental results comparing RS-IMLE with various distance metrics (e.g., L1, L2, cosine distance) on the same datasets would clarify the impact of the choice of distance function.

### Open Question 2
- Question: What is the computational complexity of RS-IMLE compared to the baseline IMLE, especially in high-dimensional spaces?
- Basis in paper: [inferred] The paper mentions using fast k-nearest neighbor search methods to reduce computational complexity but does not provide a detailed analysis of the overall computational cost.
- Why unresolved: The paper does not provide a comprehensive analysis of the computational efficiency of RS-IMLE compared to IMLE, especially in high-dimensional settings.
- What evidence would resolve it: A detailed analysis of the time and space complexity of RS-IMLE compared to IMLE, including experiments on high-dimensional datasets, would clarify the computational trade-offs.

### Open Question 3
- Question: How does the hyperparameter $\epsilon$ in the rejection sampling step affect the quality of generated images, and what is the optimal range for $\epsilon$?
- Basis in paper: [explicit] The paper provides an ablation study on different values of $\epsilon$ but does not discuss the optimal range or the theoretical justification for choosing $\epsilon$.
- Why unresolved: The paper only tests a few values of $\epsilon$ and does not provide a comprehensive analysis of how $\epsilon$ affects the performance across different datasets.
- What evidence would resolve it: A systematic study of the impact of $\epsilon$ on image quality across a wider range of values and datasets would help identify the optimal range for $\epsilon$.

## Limitations
- The method's performance on larger datasets (beyond few-shot scenarios) is not evaluated, leaving questions about scalability
- Computational overhead of rejection sampling and nearest neighbor search is not thoroughly discussed, particularly for higher-resolution images or larger datasets
- The method fundamentally changes how samples are selected during training, which may introduce new biases or limitations not fully explored

## Confidence

**High confidence** in the mechanism explanation: The mathematical derivation of the misalignment issue is rigorous and the rejection sampling solution is well-justified theoretically.

**Medium confidence** in the empirical results: While the 45.9% FID improvement is impressive and consistent across nine datasets, the evaluation is limited to few-shot scenarios with relatively small image counts.

**Medium confidence** in the generalization claims: The method shows strong performance on diverse datasets, but the evaluation lacks comparison to state-of-the-art few-shot methods beyond IMLE variants.

## Next Checks

1. Test RS-IMLE on datasets with larger sample sizes (e.g., 1000+ images) to evaluate scalability beyond few-shot scenarios and assess whether the rejection sampling mechanism remains effective.

2. Implement an ablation study that varies the rejection sampling threshold ε across a wider range (e.g., 0.05 to 0.3) to better understand the trade-off between sample quality and diversity, and identify the precise point where rejection rates become detrimental to learning.

3. Compare RS-IMLE against recent few-shot image synthesis methods (e.g., DINO, StyleGAN-ADA) on standard benchmarks to establish relative performance in the broader context of few-shot generation research.