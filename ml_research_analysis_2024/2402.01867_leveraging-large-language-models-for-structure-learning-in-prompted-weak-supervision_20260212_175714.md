---
ver: rpa2
title: Leveraging Large Language Models for Structure Learning in Prompted Weak Supervision
arxiv_id: '2402.01867'
source_url: https://arxiv.org/abs/2402.01867
tags:
- structure
- weak
- supervision
- prompted
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a Structure Refining Module to address the
  challenge of learning dependency structures among prompted labeling functions (LFs)
  in weak supervision. The key idea is to leverage similarities in the embedding space
  of prompted LFs, computed using a large language model (LLM), to detect redundant
  LFs and estimate their dependency structures.
---

# Leveraging Large Language Models for Structure Learning in Prompted Weak Supervision

## Quick Facts
- **arXiv ID**: 2402.01867
- **Source URL**: https://arxiv.org/abs/2402.01867
- **Reference count**: 12
- **Key outcome**: Structure Refining Module improves prompted weak supervision performance by up to 12.7 points on benchmark tasks

## Executive Summary
This paper addresses the challenge of learning dependency structures among prompted labeling functions (LFs) in weak supervision. The authors introduce a Structure Refining Module that leverages LLM embedding similarities to detect redundant LFs and estimate their dependency structures. The module consists of two components: Labeling Function Removal (LaRe) which removes redundant LFs based on embedding similarities, and Correlation Structure Generation (CosGen) which estimates dependency structures among the remaining LFs. This approach improves performance by up to 12.7 points compared to previous methods while offering efficiency gains through reduced LLM queries and computational time.

## Method Summary
The proposed Structure Refining Module operates on prompted LFs in weak supervision. First, it computes pairwise cosine similarities between LLM embeddings of the LFs. LaRe then removes redundant LFs by selecting pairs with high similarity and keeping only one (the one with lower index). CosGen constructs a dependency structure by assuming the two least similar LFs are independent, then adding edges between highly similar LFs up to a specified limit. The resulting structure is used in label modeling with FlyingSquid, and probabilistic labels are used to train an end model like RoBERTa. The method claims to find dependencies intrinsic to LFs rather than data-dependent ones, making it more efficient than data-based approaches.

## Key Results
- Structure Refining Module improves prompted weak supervision performance by up to 12.7 points on benchmark tasks
- Method offers efficiency gains by reducing LLM query costs and computational time for label modeling
- Outperforms previous methods that learn dependencies from weak labels by finding LF-intrinsic dependencies

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The Structure Refining Module improves PromptedWS by detecting and removing redundant LFs based on LLM embedding similarities.
- **Mechanism**: The module computes pairwise cosine similarities between LLM embeddings of prompted LFs. High similarity indicates potential redundancy, allowing automatic removal of the more redundant LF (higher index) to reduce LLM queries and model bias.
- **Core assumption**: LFs with high embedding similarity are likely to be correlated and produce redundant votes.
- **Evidence anchors**: 
  - [abstract] "We find that the similarity of the representations of the prompted LFs is predictive of harmful correlations."
  - [section] "We find that the similarity of the representations of the prompted LFs is predictive of harmful correlations. Further, they can be computed much more quickly than executing the prompted LFs on many examples."
- **Break condition**: If LLM embeddings do not capture task-relevant features distinguishing LFs, similarity scores become unreliable indicators of correlation.

### Mechanism 2
- **Claim**: CosGen efficiently learns dependency structures among LFs using only embedding similarities without labeled data.
- **Mechanism**: After removing redundant LFs, CosGen uses the similarity matrix of remaining LFs to construct a dependency graph. It first assumes the two least similar LFs are independent, then adds edges between highly similar LFs up to a specified edge limit.
- **Core assumption**: Embedding similarities reflect true task dependencies, and assuming two least similar LFs are independent guarantees identifiability of the structure.
- **Evidence anchors**:
  - [abstract] "CosGen is specifically designed to efficiently learn the dependency structures among prompted LFs, utilizing only the vector embeddings of the prompted LFs themselves, without relying on any labels or unlabeled data."
  - [section] "One key intuition is to construct dependency for highly correlated LFs indicated by Mâ€². However, the structure directly estimated from this method may be non-identifiable and can not be used for label modeling. In order to guarantee the structure to be identifiable, we first find two LFs that have the smallest correlation and assume these two to be mutually independent while at the same time, also to be independent with all the other LFs."
- **Break condition**: If the least similar LF pair is not truly independent in practice, the structure becomes misspecified and harms label modeling.

### Mechanism 3
- **Claim**: The Structure Refining Module achieves better performance than learning dependency structures from weak labels (data-based methods).
- **Mechanism**: By finding dependencies intrinsic to LFs rather than from data, the method avoids spurious correlations that arise from specific data distributions, leading to more robust label modeling.
- **Core assumption**: LF-intrinsic dependencies are more stable and generalizable than data-dependent ones.
- **Evidence anchors**:
  - [abstract] "Compared to previous methods that learn the dependencies from weak labels, our method finds the dependencies which are intrinsic to the LFs and less dependent on the data."
  - [section] "Previous studies have also explored how to automatically discover the structure with only unlabeled data (Bach et al., 2017; Varma et al., 2017). However, existing methods are not designed to handle correlations in Prompted weak supervision setup. In prompted weak supervision, weak labels are solely based on querying prompted LFs via the Large Language Models and the model responses alone may not fully represent the correlations among the prompted LFs."
- **Break condition**: If LF-intrinsic dependencies do not capture important data-dependent correlations, the method may miss relevant structure and underperform.

## Foundational Learning

- **Concept**: Programmatic Weak Supervision (PWS)
  - **Why needed here**: Understanding PWS is essential to grasp how prompted LFs vote for labels and why dependency structures matter for label modeling.
  - **Quick check question**: In PWS, how does the label model aggregate votes from multiple noisy LFs to estimate true labels?

- **Concept**: Embedding Similarity and Cosine Distance
  - **Why needed here**: The method relies on computing pairwise cosine similarities between LLM embeddings to detect redundant LFs and estimate dependencies.
  - **Quick check question**: What does a cosine similarity of 1.0 between two LF embeddings indicate about their representations?

- **Concept**: Markov Random Fields and Dependency Structures
  - **Why needed here**: The CosGen component constructs a dependency graph that can be incorporated into probabilistic label models like FlyingSquid or factor graph methods.
  - **Quick check question**: Why is assuming two LFs are independent (the least similar pair) necessary for ensuring the dependency structure is identifiable?

## Architecture Onboarding

- **Component map**: Unlabeled dataset D -> Prompted LFs SLF -> LLM A -> Structure Refining Module (LaRe -> CosGen) -> Refined LFs S'LF + Dependency structure E -> Label model (FlyingSquid) -> End model (RoBERTa) -> Probabilistic labels

- **Critical path**:
  1. Compute LLM embeddings for each prompted LF
  2. Build similarity matrix M
  3. LaRe removes redundant LFs based on M
  4. CosGen constructs dependency structure from refined M'
  5. Pass structure to label model for label aggregation
  6. Train end model on probabilistic labels

- **Design tradeoffs**:
  - LaRe vs. no removal: Removing LFs reduces computation and potential bias but may lose information if LFs are not truly redundant
  - CosGen vs. data-based WSSL: CosGen is faster and data-independent but may miss data-specific correlations that WSSL captures
  - Edge limit in CosGen: More edges capture more dependencies but increase label model complexity and runtime

- **Failure signatures**:
  - Performance drops after LF removal: Indicates LFs removed were not redundant or contained unique information
  - Label model runtime spikes after adding structure: Suggests too many edges or dense dependency graph
  - No improvement over PromptedWS: Could mean embeddings do not capture meaningful LF similarities or dependencies are already well-handled

- **First 3 experiments**:
  1. Run LaRe with mr=0 (no removal) on a small dataset to verify embeddings are computed and similarity matrix built correctly
  2. Apply LaRe with mr=1 on a dataset with known redundant LFs to confirm removal reduces LLM queries and improves efficiency
  3. Use CosGen with me=1 (one edge) to ensure dependency structure is generated and can be passed to a label model without errors

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How robust is the proposed Structure Refining Module to biases and spurious correlations in the LLM's internal representations?
- **Basis in paper**: [explicit] The paper mentions the potential for unfair labeling due to spurious and sensitive feedback from LLMs and the need for careful moderation.
- **Why unresolved**: The paper does not provide empirical evidence or a detailed analysis of the robustness of the proposed method to LLM biases.
- **What evidence would resolve it**: Experiments evaluating the performance of the proposed method on datasets with known biases or conducting sensitivity analysis to assess the impact of LLM biases on the method's performance.

### Open Question 2
- **Question**: Can the proposed method be extended to handle multi-label classification tasks or tasks with more complex label structures?
- **Basis in paper**: [inferred] The paper focuses on binary classification tasks and does not discuss extensions to more complex label structures.
- **Why unresolved**: The paper does not provide any analysis or experiments on the applicability of the proposed method to multi-label or structured prediction tasks.
- **What evidence would resolve it**: Experiments evaluating the performance of the proposed method on multi-label or structured prediction tasks and comparing it to existing methods for those tasks.

### Open Question 3
- **Question**: How does the proposed method compare to other approaches for learning dependency structures in weak supervision, such as those based on graphical models or probabilistic inference?
- **Basis in paper**: [explicit] The paper compares the proposed method to a state-of-the-art structure learning method (WSSL) but does not discuss other approaches in detail.
- **Why unresolved**: The paper does not provide a comprehensive comparison of the proposed method to other existing approaches for learning dependency structures in weak supervision.
- **What evidence would resolve it**: Experiments comparing the performance and efficiency of the proposed method to other existing approaches for learning dependency structures in weak supervision on a diverse set of benchmark tasks.

## Limitations
- Limited direct empirical evidence confirming that LLM embedding similarities reliably predict LF correlations
- Assumption that two least similar LFs are independent may not hold in practice, potentially causing misspecified structures
- No comparison to human-designed dependency structures or gold-standard LF correlations to validate the approach

## Confidence
- **Mechanism 1 (LaRe redundancy detection)**: Medium - reasonable approach but unverified whether embeddings capture LF distinctions
- **Mechanism 2 (CosGen dependency estimation)**: Medium - theoretical guarantee for identifiability but unverified practical assumption about least similar LF pair
- **Mechanism 3 (Intrinsic vs data-based dependencies)**: Low - performance comparison shows parity but doesn't prove intrinsic dependencies are more stable

## Next Checks
1. Create synthetic LF sets with known correlations and test whether CosGen recovers the true dependency structure
2. Run ablation studies removing LaRe to measure the actual impact of redundancy removal on LLM query costs vs performance
3. Compare CosGen structures against those learned from labeled data to quantify trade-offs between efficiency and correlation capture