---
ver: rpa2
title: 'Rematch: Robust and Efficient Matching of Local Knowledge Graphs to Improve
  Structural and Semantic Similarity'
arxiv_id: '2404.02126'
source_url: https://arxiv.org/abs/2404.02126
tags:
- similarity
- amrs
- rematch
- semantic
- structural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces rematch, a novel AMR similarity metric that
  uses semantic motifs to improve both structural and semantic consistency compared
  to existing methods. The authors also develop RARE, a new benchmark for evaluating
  structural similarity between AMRs.
---

# Rematch: Robust and Efficient Matching of Local Knowledge Graphs to Improve Structural and Semantic Similarity

## Quick Facts
- arXiv ID: 2404.02126
- Source URL: https://arxiv.org/abs/2404.02126
- Authors: Zoher Kachwala; Jisun An; Haewoon Kwak; Filippo Menczer
- Reference count: 18
- Primary result: Novel AMR similarity metric using semantic motifs achieves state-of-the-art semantic consistency while being 5x faster than alternatives.

## Executive Summary
This paper introduces rematch, a novel AMR similarity metric that uses semantic motifs to improve both structural and semantic consistency compared to existing methods. The authors also develop RARE, a new benchmark for evaluating structural similarity between AMRs. On RARE, rematch achieves 95.32% structural consistency, trailing only smatch (96.57%). On semantic benchmarks STS-B and SICK-R, rematch outperforms existing methods by 1-5 percentage points, achieving the highest semantic consistency. Rematch is also five times faster than the next most efficient metric.

## Method Summary
Rematch computes similarity between two AMRs by analyzing the overlap of semantically rich features called motifs. Each AMR is represented by the union of its instance, relation, and attribute motifs. The rematch score is determined by calculating the Jaccard similarity between their respective motif sets. The approach leverages Penman for parsing, extracts three types of motifs (attribute, instance, relation), and optionally uses Verbatlas to generalize PropBank frames for improved semantic consistency.

## Key Results
- Achieves 95.32% structural consistency on RARE benchmark, second only to smatch (96.57%)
- Outperforms existing methods by 1-5 percentage points on semantic benchmarks STS-B and SICK-R
- Five times faster than the next most efficient AMR similarity metric
- Highest semantic consistency among all evaluated AMR metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using motif-based unordered graph partitions instead of node labels reduces the search space for graph similarity matching.
- Mechanism: AMR motifs combine instance, attribute, and relation information into compact features. This clustering reduces the number of unique features compared to raw node labels, shrinking the search space from exponential in the number of nodes to polynomial in the number of motifs.
- Core assumption: Motif sets capture enough semantic information to preserve meaningful graph similarity while drastically reducing combinatorial complexity.
- Evidence anchors:
  - [abstract] "rematch computes the similarity between two AMRs by analyzing the overlap of semantically rich features, which we call motifs."
  - [section] "Graph features constructed using an ordered concatenation of edge-node bi-grams are utilized in both isomorphism tests... This approach is effective: it consistently produces smaller node groups compared to those based solely on node labels."
  - [corpus] Weak: no direct evidence in neighbors about motif efficiency; only general graph matching papers.

### Mechanism 2
- Claim: Jaccard similarity on motif sets provides both structural and semantic consistency in AMR comparison.
- Mechanism: Structural consistency is achieved because motif overlap directly reflects edge/node correspondence. Semantic consistency is preserved because motifs encode verb frames, arguments, and attributes, so similar meaning yields overlapping motifs.
- Core assumption: The motif set union captures both the graph topology and the linguistic semantics encoded in AMR.
- Evidence anchors:
  - [abstract] "The rematch score between two AMRs is determined by calculating the Jaccard similarity between their respective motif sets."
  - [section] "Each AMR is represented by the union of its instance, relation, and attribute motifs. The rematch score between two AMRs is determined by calculating the Jaccard similarity between their respective motif sets."
  - [corpus] No direct evidence; only general Jaccard similarity usage.

### Mechanism 3
- Claim: Replacing PropBank frames with Verbatlas generalizations improves semantic consistency by grouping semantically similar verbs.
- Mechanism: Instance motifs are built from either the original PropBank frame or its Verbatlas generalization. This abstraction allows semantically related verbs to share the same motif, increasing similarity scores for paraphrased sentences.
- Core assumption: Verbatlas frame mappings are accurate and cover enough of the AMR lexicon to be useful.
- Evidence anchors:
  - [section] "Instance motifs leverage Verbatlas, a resource that maps PropBank frames to more generalized frames (Di Fabio et al., 2019). If an instance in the AMR corresponds to a Verbatlas frame, the latter is used instead."
  - [corpus] Weak: no neighbor papers reference Verbatlas; assumption based on cited paper.

## Foundational Learning

- Concept: Abstract Meaning Representation (AMR) graph structure
  - Why needed here: Rematch operates directly on AMR graphs; understanding nodes, edges, instances, attributes, relations is essential.
  - Quick check question: In an AMR, what distinguishes an instance node from an attribute node?

- Concept: Graph isomorphism and subgraph isomorphism
  - Why needed here: The paper contrasts exact isomorphism with approximate similarity; knowing the difference clarifies why motif-based similarity is needed.
  - Quick check question: Why can't we use exact graph isomorphism to compare AMRs of different sizes?

- Concept: Jaccard similarity
  - Why needed here: Rematch's final similarity score is a Jaccard coefficient over motif sets; knowing how it works is critical to interpret results.
  - Quick check question: If two AMRs share 8 of 10 motifs, what is their Jaccard similarity?

## Architecture Onboarding

- Component map: AMR parsing (Penman) -> Motif extraction (attribute/instance/relation) -> Motif set aggregation -> Jaccard similarity calculation
- Critical path: 1. Parse source AMR(s) -> 2. Extract motifs -> 3. Build motif sets -> 4. Compute Jaccard similarity -> 5. Return score
- Design tradeoffs:
  - Motif granularity vs. efficiency: Finer motifs increase accuracy but also computational cost.
  - Verbatlas vs. PropBank: Generalization improves semantic consistency but may lose verb-specific nuances.
  - Jaccard vs. weighted similarity: Simpler but ignores motif importance differences.
- Failure signatures:
  - Extremely low similarity scores on paraphrases: May indicate missing Verbatlas mappings or motif granularity too coarse.
  - Runtime spikes on large AMRs: Likely motif extraction inefficiency or memory blow-up in motif set storage.
  - Inconsistent results across parsers: Parser differences in AMR output may cause motif mismatch.
- First 3 experiments:
  1. Run rematch on STS-B sentence pairs with spring parser; compare to human similarity scores.
  2. Generate a small RARE-like test set by rewiring edges; verify structural consistency drops as expected.
  3. Perform ablation: run rematch without Verbatlas; measure semantic consistency loss.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several natural extensions emerge from the work:

1. Can rematch be adapted to handle longer documents by considering motifs of longer paths, and what would be the impact on its efficiency and accuracy?
2. How does rematch compare to non-AMR similarity methods like SimCSE in terms of efficiency and accuracy for semantic textual similarity tasks?
3. Can rematch be extended to handle multilingual AMRs and what challenges would arise in capturing semantic similarity across languages?

## Limitations

- Evaluation focuses exclusively on English AMR graphs, limiting generalizability to other languages
- RARE benchmark is synthetically constructed and may not fully capture real-world structural variation
- Relies on Verbatlas coverage which is not validated in the paper
- Effectiveness on other graph-based meaning representations (UCCA, DRS) remains untested

## Confidence

- Structural consistency improvements: High - directly measurable and consistently demonstrated
- Runtime efficiency: High - clear quantitative improvement over alternatives
- Semantic consistency gains: Medium - strong STS-B/SICK-R results but potential sensitivity to Verbatlas coverage gaps
- General applicability of motif approach: Low - cross-lingual and cross-representation tests are absent

## Next Checks

1. Test rematch on AMR graphs from multiple languages to assess cross-lingual robustness
2. Perform an ablation study removing Verbatlas mappings to quantify their contribution to semantic consistency
3. Evaluate rematch on a non-AMR graph-based semantic representation (e.g., UCCA) to test the motif approach's generality