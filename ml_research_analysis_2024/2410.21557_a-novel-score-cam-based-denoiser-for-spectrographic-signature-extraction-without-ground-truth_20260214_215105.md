---
ver: rpa2
title: A Novel Score-CAM based Denoiser for Spectrographic Signature Extraction without
  Ground Truth
arxiv_id: '2410.21557'
source_url: https://arxiv.org/abs/2410.21557
tags:
- data
- image
- class
- mask
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel Score-CAM-based denoising framework
  to extract spectrographic signatures from underwater audio signals without requiring
  ground truth data. The approach uses a Wasserstein GAN to generate additional training
  samples, followed by clustering and class activation mapping to create class-specific
  saliency masks.
---

# A Novel Score-CAM based Denoiser for Spectrographic Signature Extraction without Ground Truth

## Quick Facts
- arXiv ID: 2410.21557
- Source URL: https://arxiv.org/abs/2410.21557
- Reference count: 11
- Primary result: 86% noise removal with 8% false negatives and 2% intersecting tonal regions using 0.75 threshold

## Executive Summary
This paper presents a novel denoising framework for extracting spectrographic signatures from underwater audio signals without requiring ground truth data. The approach leverages a Wasserstein GAN to generate synthetic training samples, KMeans clustering to identify representative spectrograms, and Score-CAM to create class-specific saliency masks for noise removal. Experimental results demonstrate that a threshold of 0.75 effectively removes approximately 86% of noise while preserving target signal features with minimal false negatives (~8%) and few intersecting tonal regions (~2). The method outperforms baseline auto-encoder and reverse mask approaches while eliminating the need for labeled clean data.

## Method Summary
The framework operates through a multi-stage pipeline: first, a Wasserstein GAN generates additional spectrographic samples matching the distribution of limited input data, enabling training without ground truth labels. A CNN-based classifier is trained on both real and generated data, with embeddings from the dense layer used for KMeans++ clustering to identify representative spectrograms for each class. Score-CAM then generates class-specific saliency masks by measuring confidence changes when activation maps are applied, and these masks are thresholded (typically at 0.75) to isolate tonal regions corresponding to target classes. The final denoised output is obtained by multiplying the thresholded mask with the input spectrogram, effectively removing noise while preserving the target signature.

## Key Results
- Threshold of 0.75 removes ~86% of noise while maintaining target signal integrity
- False negative rate remains low at approximately 8% with this threshold
- Intersecting tonal regions are minimal (~2%) in the denoised output
- Outperforms baseline auto-encoder and reverse mask methods in both noise removal and signal preservation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Wasserstein GAN generates spectrographic samples with noise distributions that match the target class without needing labeled clean data.
- Mechanism: The WGAN minimizes Earth Mover's distance between real and generated distributions using gradient penalties, producing synthetic spectrograms that preserve tonal structure while adding realistic noise.
- Core assumption: The low-feature spectrogram space has sufficient variation to allow the GAN to learn meaningful class-conditional distributions.
- Evidence anchors:
  - [abstract] "proposes a novel generative adversarial network architecture for learning and producing spectrographic training data in similar distributions to low-feature spectrogram inputs"
  - [section] "WGAN model involving the discriminator and the generator models was trained and then extracted to be able to generate new data samples from random seed values"
  - [corpus] No direct corpus evidence of GAN-based spectrogram generation; this appears novel.
- Break condition: If the spectrogram space lacks sufficient variation or the GAN overfits to limited training samples, generated data may not represent true class distributions.

### Mechanism 2
- Claim: KMeans++ clustering on CNN embedding space identifies the most representative spectrograms for each class.
- Mechanism: Embeddings from the second dense layer of Spec-CNN capture discriminative features, and KMeans++ finds centroids that represent the densest regions of the embedding space, selecting nearest actual spectrograms.
- Core assumption: The CNN embedding space preserves semantic similarity between spectrograms such that clustering reveals representative samples.
- Evidence anchors:
  - [abstract] "This paper also a generalizable class activation mapping based denoiser for different distributions of acoustic data"
  - [section] "The KMeans clustering model utilized all the embeddings of known images of that target class to cluster the data. Once this model was finished clustering the data, the centroids were extracted from the data set."
  - [corpus] No corpus evidence of using CNN embeddings for clustering spectrograms.
- Break condition: If the embedding space does not preserve semantic similarity or the number of clusters is poorly chosen, centroids may not represent the true class distribution.

### Mechanism 3
- Claim: Score-CAM generates saliency masks that highlight class-specific tonal regions by measuring the increase in confidence when activation maps are applied.
- Mechanism: Score-CAM uses forward passes to compute confidence scores for each activation map, then applies ReLU to the weighted sum of activation maps to create a class-specific saliency map.
- Core assumption: The CNN's confidence changes when activation maps are applied reflect the importance of those regions for class prediction.
- Evidence anchors:
  - [abstract] "this paper also a generalizable class activation mapping based denoiser for different distributions of acoustic data"
  - [section] "Score-CAM does not rely on back-propagating of the dense layer of a CNN to create a rough localization of the class activation, but instead utilizes a perturbation-based approach"
  - [corpus] No corpus evidence of Score-CAM for spectrogram denoising; this appears novel.
- Break condition: If the CNN is not well-trained or the activation maps do not correlate with class-specific features, the saliency masks will not accurately identify tonal regions.

## Foundational Learning

- Concept: Wasserstein GAN loss and Earth Mover's distance
  - Why needed here: Provides stable training and meaningful gradient signals for generating realistic spectrogram samples without labeled clean data
  - Quick check question: What is the key difference between Wasserstein loss and traditional GAN minimax loss?

- Concept: KMeans++ initialization and elbow method for optimal cluster determination
  - Why needed here: Ensures centroids are well-distributed and representative of the class embedding space, critical for selecting representative spectrograms
  - Quick check question: How does KMeans++ differ from standard KMeans initialization?

- Concept: Score-CAM saliency map generation and perturbation-based approaches
  - Why needed here: Provides class-specific localization without relying on gradient backpropagation, which can be noisy in spectrogram domains
  - Quick check question: What is the key advantage of Score-CAM over Grad-CAM for this application?

## Architecture Onboarding

- Component map: Input spectrogram → Spec-CNN classification → KMeans clustering on embeddings → Score-CAM saliency maps → Thresholding → Binary mask → Output denoised spectrogram
- Critical path: The denoising pipeline requires accurate classification first, then clustering to find representative samples, then Score-CAM to generate masks, and finally thresholding for extraction
- Design tradeoffs: Using generated data vs limited real data, choosing cluster count vs representation accuracy, threshold selection vs noise removal vs feature preservation
- Failure signatures: Poor classification accuracy leads to wrong class selection, inadequate clustering produces unrepresentative masks, incorrect thresholds either leave too much noise or remove too many features
- First 3 experiments:
  1. Train WGAN on limited spectrogram data and evaluate generated sample quality visually and through discriminator accuracy
  2. Apply KMeans++ clustering to CNN embeddings and verify that selected centroids are representative samples
  3. Generate Score-CAM masks for representative samples and test different threshold values for optimal noise removal

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well does the proposed Score-CAM based denoiser generalize to audio data from other domains (e.g., speech, music, industrial sounds) outside of underwater sonar applications?
- Basis in paper: [inferred] The paper states the approach "generalizes to other noisy image domains" but does not provide experimental validation beyond underwater sonar spectrograms.
- Why unresolved: The experiments only validate performance on underwater sonar spectrograms, leaving uncertainty about effectiveness on other audio domains with different noise characteristics and tonal structures.
- What evidence would resolve it: Systematic experiments applying the framework to diverse audio datasets (speech, music, industrial) with quantitative comparisons to domain-specific denoising methods.

### Open Question 2
- Question: What is the optimal threshold range for different types of noise distributions and audio signal characteristics?
- Basis in paper: [explicit] The paper tests three thresholds (0.65, 0.75, 0.85) but notes "the proposed approach with a threshold of around 0.7-0.75 seems to extract the most amount of unwanted noise" without establishing systematic criteria for threshold selection.
- Why unresolved: The paper only tests a limited range of thresholds on one dataset, and the optimal threshold likely varies with noise characteristics, signal-to-noise ratio, and the specific target class.
- What evidence would resolve it: A comprehensive study mapping threshold performance across different noise levels, signal types, and SNR conditions to develop guidelines for threshold selection.

### Open Question 3
- Question: How does the performance of the Score-CAM based denoiser compare to supervised deep learning approaches when ground truth data becomes available?
- Basis in paper: [explicit] The paper emphasizes its advantage of not requiring ground truth data, but does not compare performance against supervised methods that could use labeled clean data.
- Why unresolved: The paper positions itself as an alternative when ground truth is unavailable, but does not quantify the performance gap compared to supervised approaches when such data exists.
- What evidence would resolve it: Direct comparative experiments between the proposed method and supervised CNN-based denoisers trained on labeled clean data, measuring both noise removal and preservation of target signal features.

## Limitations
- The framework lacks validation on diverse spectrogram datasets beyond underwater audio signals, limiting generalizability claims.
- Critical hyperparameters (WGAN architecture, cluster count selection method, Score-CAM threshold determination) are underspecified, making exact reproduction challenging.
- The claim of 86% noise removal with minimal false negatives is based on single threshold experiments without sensitivity analysis or statistical significance testing.

## Confidence
- **High Confidence**: The overall pipeline concept (GAN generation → clustering → Score-CAM → thresholding) is mechanistically sound and follows established deep learning principles.
- **Medium Confidence**: The specific implementation details and parameter choices appear reasonable but lack rigorous justification or ablation studies.
- **Low Confidence**: Claims about generalization to "other noisy image domains" are speculative without empirical validation beyond the described underwater audio case.

## Next Checks
1. **Cross-domain testing**: Apply the complete pipeline to at least two different noisy image domains (e.g., medical imaging or astronomical data) to validate generalization claims beyond underwater spectrograms.
2. **Ablation study**: Systematically remove or replace each component (WGAN, KMeans clustering, Score-CAM) to quantify individual contributions to the final denoising performance.
3. **Statistical validation**: Conduct multiple runs with different random seeds and perform significance testing to establish confidence intervals for the reported metrics (86% noise removal, 8% false negatives, 2% intersecting tonal regions).