---
ver: rpa2
title: 'IG2: Integrated Gradient on Iterative Gradient Path for Feature Attribution'
arxiv_id: '2406.10852'
source_url: https://arxiv.org/abs/2406.10852
tags:
- path
- explicand
- attributions
- attribution
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IG2 introduces an improved path method for feature attribution
  that integrates both explicand and counterfactual gradients along a novel path (GradPath)
  to a new baseline (GradCF). The GradPath iteratively minimizes the representation
  distance to a counterfactual reference, avoiding saturation effects by aligning
  with counterfactual gradients, while GradCF provides a model- and explicand-specific
  baseline that highlights critical distinguishing features.
---

# IG2: Integrated Gradient on Iterative Gradient Path for Feature Attribution

## Quick Facts
- arXiv ID: 2406.10852
- Source URL: https://arxiv.org/abs/2406.10852
- Reference count: 40
- Primary result: IG2 outperforms state-of-the-art attribution methods across multiple datasets and metrics

## Executive Summary
IG2 introduces an improved path method for feature attribution that integrates both explicand and counterfactual gradients along a novel path (GradPath) to a new baseline (GradCF). The method addresses saturation effects by aligning with counterfactual gradients while maintaining theoretical guarantees including Completeness, Dummy, Implementation Invariance, and Symmetry axioms. Extensive experiments on synthetic, image, text, and structured data demonstrate IG2's superior performance in both qualitative and quantitative metrics compared to existing methods.

## Method Summary
IG2 computes feature attributions by integrating gradients along an iterative path from the explicand to a counterfactual baseline (GradCF). The GradPath is constructed by iteratively minimizing the representation distance to a counterfactual reference using normalized gradients. GradCF serves as the baseline, generated through gradient descent optimization that satisfies validity, data manifold closeness, and explicand relevance properties. The final attribution is computed by integrating the product of explicand and counterfactual gradients along GradPath, with normalization applied to prevent gradient saturation effects.

## Key Results
- IG2 outperforms state-of-the-art methods on XAI benchmark, ImageNet, MNIST, TREC, wafer maps, and CelebA datasets
- Theoretical analysis confirms satisfaction of Completeness, Dummy, Implementation Invariance, and Symmetry axioms
- Ablation studies validate the individual effectiveness of GradPath and GradCF components
- GradCF provides model- and explicand-specific baseline that highlights critical distinguishing features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IG2 integrates both explicand and counterfactual gradients along GradPath to reduce attribution noise and saturation effects
- Mechanism: GradPath iteratively minimizes representation distance to counterfactual reference, aligning with counterfactual gradients to quickly decrease model prediction and filter noise from explicand's gradient
- Core assumption: The representation distance minimization objective implicitly reduces explicand's prediction while staying on counterfactual data manifold
- Evidence anchors:
  - [abstract] "IG2 incorporates the counterfactual gradient iteratively into the integration path, generating a novel path (GradPath) and a novel baseline (GradCF)"
  - [section] "GradPath effectively mitigates saturation effects [23], [18] (in Definition 3). This is achieved by its alignment with the counterfactual gradients, leading to a rapid decrease in the model's prediction of the explicand"
  - [corpus] Weak - related papers discuss path-weighted or manifold-constrained approaches but not the specific counterfactual gradient integration

### Mechanism 2
- Claim: GradCF provides a model- and explicand-specific baseline that highlights critical distinguishing features
- Mechanism: GradCF is generated by iterative gradient descent on representation distance, creating a counterfactual example that satisfies validity, data manifold closeness, and explicand relevance properties
- Core assumption: The iterative optimization simultaneously ensures closeness to both explicand and counterfactual data distributions while maintaining realistic feature combinations
- Evidence anchors:
  - [abstract] "IG2 incorporates the counterfactual gradient iteratively into the integration path, generating a novel path (GradPath) and a novel baseline (GradCF)"
  - [section] "Distinctively, GradCF satisfies all three describable properties, which correlates with the explicand and stays on the manifold of counterfactual data"
  - [corpus] Missing - no corpus evidence found for model- and explicand-specific baselines in path methods

### Mechanism 3
- Claim: The multiplication of explicand and counterfactual gradients in IG2 attribution weights features by their importance in distinguishing classes
- Mechanism: The Riemann summation weight of counterfactual gradient (∂∥f(γG(α)) - f(xr)∥²/∂xi) highlights features that contribute most to representation difference
- Core assumption: Features with larger counterfactual gradients are more important for distinguishing explicand from reference
- Evidence anchors:
  - [abstract] "IG2 incorporates the counterfactual gradient iteratively into the integration path, generating a novel path (GradPath) and a novel baseline (GradCF)"
  - [section] "Eq. 3 explicitly reveals the nature of IG2: the multiplication of two gradients. Compared to Vanilla IG in Eq. 2, the major distinction is the Riemann summation weight of explicand's gradients"
  - [corpus] Weak - related papers discuss weighted integrated gradients but not the specific multiplication with counterfactual gradients

## Foundational Learning

- Concept: Path methods and Aumann-Shapley theory
  - Why needed here: IG2 is a path method that must satisfy desirable axioms like Completeness, Dummy, Implementation Invariance, and Symmetry
  - Quick check question: What are the four axioms that path methods must satisfy, and how does IG2 ensure each one?

- Concept: Counterfactual explanation and representation distance
  - Why needed here: GradCF and GradPath are built on counterfactual explanation principles and use representation distance to find meaningful baselines
  - Quick check question: What are the three desirable properties of a good counterfactual baseline, and how does GradCF satisfy each one?

- Concept: Gradient descent optimization and normalization
  - Why needed here: GradCF is found through iterative gradient descent on representation distance with normalization, and GradPath uses normalized gradients
  - Quick check question: Why is normalization important in the iterative optimization for GradCF, and what are the trade-offs between ℓ1 and ℓ2 normalization?

## Architecture Onboarding

- Component map:
  Input preprocessing -> Counterfactual reference sampling -> Representation layer selection -> GradCF optimization (iterative gradient descent) -> GradPath construction -> IG2 attribution calculation (gradient integration) -> Post-processing

- Critical path:
  GradCF optimization (most computationally expensive, ~10-20× more than IG)
  IG2 attribution calculation (requires multiple references, ~20× more than single-baseline methods)
  Reference selection (critical for attribution quality, affects denoising vs completeness tradeoff)

- Design tradeoffs:
  Step size: Small → less noise, incomplete attribution; Large → complete, noisy attribution
  Reference choice: Relevant → denoising, less complete; Irrelevant → complete, more noise
  Normalization: ℓ1 → sparse, may miss relevant features; ℓ2 → balanced, computationally simpler
  Representation layer: Shallow → more stable, less meaningful; Deep → more meaningful, potentially unstable

- Failure signatures:
  Noisy attributions → check GradPath optimization convergence, step size too large, or poor reference choice
  Incomplete attributions → check step size too small, references too similar to explicand, or GradPath stuck in local minima
  Numerical instability → check gradient multiplication, normalization parameters, or representation distance calculation

- First 3 experiments:
  1. MNIST digit classification with simple CNN: Compare IG2 to Vanilla IG and Guided IG on digit 5 vs reference 3,6,9 to validate critical area highlighting
  2. ImageNet animal classification: Test IG2 on images with interference objects (dog playing basketball) to validate denoising with relevant references
  3. TREC question classification: Apply IG2 to word-level attributions for questions with different interrogative words to validate weak word de-emphasis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise impact of GradCF on feature attributions for high-dimensional data (e.g., ImageNet) when using relevant vs. irrelevant reference categories?
- Basis in paper: [explicit] The paper states that relevant references reduce noise in attributions but at the cost of completeness, while irrelevant references ensure completeness but introduce more noise. However, it does not provide a quantitative analysis of this trade-off specifically for high-dimensional data.
- Why unresolved: The paper only provides qualitative examples and general observations without a rigorous quantitative evaluation of the trade-off between noise reduction and completeness for high-dimensional data.
- What evidence would resolve it: A detailed study comparing the attribution quality (e.g., faithfulness, monotonicity, and ground truth metrics) of IG2 using relevant and irrelevant references on a high-dimensional dataset like ImageNet, with a large number of samples and diverse classes.

### Open Question 2
- Question: How does the choice of representation layer affect the performance of IG2 in terms of attribution quality and computational efficiency?
- Basis in paper: [explicit] The paper mentions that IG2 is slightly affected by the choice of representation layer, but does not provide a detailed analysis of this impact.
- Why unresolved: The paper only provides a qualitative comparison of IG2 with different representation layers on the wafer map dataset, without a comprehensive evaluation of the impact on attribution quality and computational efficiency across multiple datasets.
- What evidence would resolve it: A systematic study comparing the attribution quality (e.g., faithfulness, monotonicity, and ground truth metrics) and computational cost of IG2 using different representation layers (e.g., early, middle, and late layers) on multiple datasets with varying input dimensions and model architectures.

### Open Question 3
- Question: What is the optimal step size and number for IG2 to balance the trade-off between attribution noise and completeness?
- Basis in paper: [explicit] The paper mentions that there is a trade-off between attribution noise and completeness for step size, and that step number is not a critical hyperparameter. However, it does not provide a detailed analysis of the optimal values for these hyperparameters.
- Why unresolved: The paper only provides a qualitative illustration of the effect of step size and number on IG2 attribution for a single example, without a comprehensive evaluation of the optimal values across multiple datasets and models.
- What evidence would resolve it: A systematic study investigating the impact of step size and number on IG2 attribution quality (e.g., faithfulness, monotonicity, and ground truth metrics) across multiple datasets and models, with a focus on finding the optimal values that balance the trade-off between noise and completeness.

## Limitations
- Computational complexity is approximately 20× slower than baseline methods, limiting real-time applications
- Performance depends critically on representation layer choice and distance metric selection
- Interactions between GradPath and GradCF in high-dimensional spaces remain incompletely characterized

## Confidence

**High confidence**: Theoretical satisfaction of key axioms (Completeness, Dummy, Implementation Invariance, Symmetry) and basic functionality of GradCF and GradPath

**Medium confidence**: Generalization across diverse datasets and model types, with performance gains over state-of-the-art methods

**Low confidence**: Computational efficiency claims and scalability to extremely large models or datasets

## Next Checks

1. Benchmark IG2 against real-time attribution requirements on mobile/embedded devices to quantify practical deployment constraints
2. Conduct systematic ablation studies varying representation layer depth and distance metrics across different model families to identify optimal configurations
3. Test IG2 on adversarial examples and out-of-distribution inputs to evaluate robustness and identify potential failure modes in security-critical applications