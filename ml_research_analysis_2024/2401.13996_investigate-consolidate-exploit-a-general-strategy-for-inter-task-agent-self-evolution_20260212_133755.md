---
ver: rpa2
title: 'Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution'
arxiv_id: '2401.13996'
source_url: https://arxiv.org/abs/2401.13996
tags:
- tool
- execution
- node
- plan
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Investigate-Consolidate-Exploit (ICE)
  strategy for enabling inter-task self-evolution in AI agents. Unlike existing methods
  that focus on intra-task learning, ICE promotes knowledge transfer between tasks,
  mimicking human experiential learning.
---

# Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution

## Quick Facts
- arXiv ID: 2401.13996
- Source URL: https://arxiv.org/abs/2401.13996
- Reference count: 25
- Primary result: ICE strategy reduces API calls by up to 80% while matching GPT-4 performance with GPT-3.5

## Executive Summary
This paper introduces the Investigate-Consolidate-Exploit (ICE) strategy for enabling inter-task self-evolution in AI agents. Unlike existing methods that focus on intra-task learning, ICE promotes knowledge transfer between tasks, mimicking human experiential learning. The strategy dynamically investigates planning and execution trajectories, consolidates them into simplified workflows and pipelines, and exploits them for improved task execution. Experiments on the XAgent framework demonstrate ICE's effectiveness, reducing API calls by up to 80% and significantly decreasing the demand for the model's capability. When combined with GPT-3.5, ICE's performance matches that of raw GPT-4 across various agent tasks. The self-evolution approach represents a paradigm shift in agent design, contributing to a more robust AI ecosystem and moving closer to full autonomy.

## Method Summary
The ICE strategy operates through three phases: Investigate, Consolidate, and Exploit. During the Investigate phase, agents dynamically analyze their planning and execution trajectories across different tasks to identify patterns and reusable components. The Consolidate phase transforms these insights into simplified workflows and pipelines that capture transferable knowledge. Finally, the Exploit phase applies these consolidated patterns to improve task execution efficiency. This approach differs from traditional intra-task learning methods by explicitly facilitating knowledge transfer between tasks, allowing agents to build upon past experiences rather than starting from scratch for each new task. The strategy is implemented within the XAgent framework and evaluated through comprehensive experiments demonstrating significant improvements in efficiency and capability.

## Key Results
- ICE reduces API calls by up to 80% compared to baseline approaches
- GPT-3.5 with ICE achieves performance comparable to raw GPT-4
- The strategy demonstrates significant reduction in demand for model capability
- Knowledge transfer between tasks leads to more efficient execution across diverse agent tasks

## Why This Works (Mechanism)
The ICE strategy works by breaking down the agent learning process into three interconnected phases that mirror human experiential learning. The Investigate phase allows agents to actively explore and understand the patterns in their own behavior across different tasks, creating a rich dataset of trajectories and decision points. The Consolidate phase then applies abstraction techniques to distill this complex data into simplified, transferable representations that capture the essence of successful strategies. Finally, the Exploit phase leverages these distilled patterns to guide future task execution, enabling rapid adaptation without requiring extensive new learning. This cyclical process creates a feedback loop where each completed task enhances the agent's ability to handle future tasks, particularly those that share underlying structural similarities.

## Foundational Learning

**Trajectory Analysis**: Understanding agent decision paths across tasks - why needed: to identify reusable patterns; quick check: verify trajectory data captures meaningful decision points

**Workflow Abstraction**: Converting complex behaviors into simplified representations - why needed: to enable knowledge transfer; quick check: ensure abstraction preserves critical decision logic

**Pattern Recognition**: Identifying common structures across different task types - why needed: to enable generalization; quick check: validate patterns apply across task domains

**Knowledge Transfer Mechanisms**: Methods for applying learned patterns to new tasks - why needed: to achieve inter-task learning; quick check: test transfer effectiveness across task boundaries

**Pipeline Optimization**: Streamlining execution paths based on consolidated knowledge - why needed: to improve efficiency; quick check: measure reduction in computational steps

## Architecture Onboarding

**Component Map**: Task Executor -> ICE Module -> Knowledge Base -> Optimizer -> Task Executor (cyclical flow)

**Critical Path**: The Investigate phase is most critical as it generates the raw data for consolidation and exploitation phases

**Design Tradeoffs**: The paper trades some model capability requirements for increased efficiency through knowledge consolidation

**Failure Signatures**: Poor trajectory analysis leads to ineffective consolidation, which results in suboptimal exploitation

**First Experiments**:
1. Test ICE's effectiveness across multiple agent frameworks beyond XAgent
2. Conduct ablation studies to determine which phase of ICE contributes most to performance gains
3. Implement long-term stability tests to evaluate whether consolidated workflows maintain effectiveness over extended periods

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Evaluation primarily within XAgent framework limits generalizability
- Claims about mimicking human learning remain somewhat abstract without detailed empirical connections
- Consolidation phase may lead to loss of nuanced behaviors in simplified representations

## Confidence

**High confidence**: The technical description of ICE's three-phase structure and its implementation details

**Medium confidence**: The reported performance improvements and API call reductions

**Low confidence**: The broader claims about paradigm shift in agent design and implications for full autonomy

## Next Checks

1. Test ICE across multiple agent frameworks beyond XAgent to assess generalizability
2. Conduct ablation studies to determine which phase of ICE contributes most to performance gains
3. Implement long-term stability tests to evaluate whether consolidated workflows maintain effectiveness over extended periods and across evolving task distributions