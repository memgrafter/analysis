---
ver: rpa2
title: 'HDRGS: High Dynamic Range Gaussian Splatting'
arxiv_id: '2408.06543'
source_url: https://arxiv.org/abs/2408.06543
tags:
- images
- exposure
- radiance
- image
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents HDRGS, a method for reconstructing 3D high
  dynamic range (HDR) radiance fields from multi-exposure low dynamic range (LDR)
  images. The core approach redefines Gaussian point colors as radiance and introduces
  an asymmetric grid-based tone mapper to convert pixel irradiance to color.
---

# HDRGS: High Dynamic Range Gaussian Splatting

## Quick Facts
- **arXiv ID**: 2408.06543
- **Source URL**: https://arxiv.org/abs/2408.06543
- **Reference count**: 40
- **Key outcome**: Achieves state-of-the-art HDR reconstruction with 6-8 minute training vs 9+ hours for HDR-NeRF, reaching PSNR 39.16 on synthetic data and 33.34 on real data

## Executive Summary
HDRGS introduces a method for reconstructing 3D high dynamic range radiance fields from multi-exposure low dynamic range images using Gaussian splatting. The core innovation redefines Gaussian point colors as radiance rather than standard RGB, enabling reconstruction of the full dynamic range of real-world scenes. An asymmetric grid-based tone mapper efficiently converts pixel irradiance to color while remaining differentiable. The method achieves state-of-the-art performance on both synthetic and real datasets with dramatically faster training times and real-time rendering capabilities at over 210 FPS.

## Method Summary
HDRGS reconstructs HDR radiance fields by redefining Gaussian point colors as radiance values instead of standard RGB colors. The method uses an asymmetric grid-based tone mapper to convert pixel irradiance to LDR colors, with more grid nodes allocated to regions of dense irradiance distribution. A novel coarse-to-fine training strategy separates tone mapping from Gaussian point attribute learning, first using a simple sigmoid function in the coarse phase, then transitioning to the asymmetric grid in the fine phase. This approach prevents local optima and accelerates convergence while maintaining reconstruction quality. The method is trained on multi-exposure LDR images and achieves real-time rendering performance.

## Key Results
- PSNR values reaching 39.16 on synthetic data and 33.34 on real data
- Training time reduced to 6-8 minutes compared to 9+ hours for HDR-NeRF
- Real-time rendering at 210+ FPS with superior quality metrics
- Outperforms NeRF, NeRF-W, HDR-NeRF, HDR-Plenoxel, and 3DGS baselines

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: HDRGS redefines Gaussian point colors as radiance rather than color, enabling reconstruction of HDR radiance fields.
- **Mechanism**: By modeling each Gaussian point as emitting radiance (which can be any non-negative value) instead of standard RGB color, the method can represent the full dynamic range of real-world scenes. The splatting process then produces irradiance values on the HDR image plane rather than limited LDR colors.
- **Core assumption**: Radiance is additive and can be represented by positive real numbers, while standard color representations are bounded.
- **Evidence anchors**:
  - [abstract] states "This method enhances color dimensionality by including luminance and uses an asymmetric grid for tone-mapping"
  - [section] explains "we redefine the color of Gaussian points as radiance L, which results in the pixel values of the image formed by Gaussian points splatting onto the HDR plane no longer representing color C, but irradiance E"
- **Break condition**: If radiance values become negative or if the additive property of radiance doesn't hold for the scenes being reconstructed.

### Mechanism 2
- **Claim**: The asymmetric grid-based tone mapper efficiently maps irradiance to LDR colors while remaining differentiable.
- **Mechanism**: The asymmetric grid allocates more nodes to regions with dense irradiance distribution and fewer nodes to sparse regions. This targeted allocation improves mapping accuracy where it matters most while reducing overfitting in low-density regions. The grid is differentiable, allowing gradients to flow during training.
- **Core assumption**: Irradiance distributions in HDR scenes are non-uniform, with most values clustered in specific ranges.
- **Evidence anchors**:
  - [abstract] mentions "uses an asymmetric grid for tone-mapping, swiftly and precisely converting pixel irradiance to color"
  - [section] states "we empirically found that in some scenarios, the distribution of irradiance values is highly uneven"
- **Break condition**: If irradiance distribution is actually uniform across scenes, or if the grid becomes too sparse to capture necessary detail.

### Mechanism 3
- **Claim**: The coarse-to-fine strategy prevents local optima and accelerates convergence by separating tone mapping from Gaussian point attribute learning.
- **Mechanism**: During the coarse phase, a simple sigmoid function serves as the tone mapper while only Gaussian point attributes are trained. This establishes a reasonable initial state. In the fine phase, the asymmetric grid replaces the sigmoid and is jointly optimized with Gaussian points, building on the established foundation to achieve better results.
- **Core assumption**: Jointly training the grid with Gaussian points from scratch leads to severe coupling and overfitting.
- **Evidence anchors**:
  - [abstract] describes "integrates a novel coarse-to-fine strategy to speed up model convergence, enhancing robustness against sparse viewpoints and exposure extremes, and preventing local optima"
  - [section] explains "directly using a grid as the tonemapping function and jointly training it with the attributes of Gaussian points leads to severe coupling and overfitting"
- **Break condition**: If the initial sigmoid-based training doesn't provide a useful starting point, or if the two-phase approach introduces unnecessary complexity for certain scene types.

## Foundational Learning

- **Concept**: Camera Response Function (CRF) and its invertibility
  - **Why needed here**: The method relies on modeling the complete physical imaging process, including the CRF that maps irradiance to pixel values. Understanding CRF invertibility is crucial for reconstructing HDR from LDR images.
  - **Quick check question**: Why must the CRF be monotonic and invertible for this method to work?

- **Concept**: Tone mapping and inverse tone mapping (ITM)
  - **Why needed here**: The core challenge is inverse tone mapping - recovering HDR from LDR images. The asymmetric grid serves as the ITM function.
  - **Quick check question**: How does the asymmetric grid differ from traditional symmetric grids in tone mapping applications?

- **Concept**: Gaussian splatting and 3D reconstruction
  - **Why needed here**: HDRGS builds upon 3D Gaussian splatting as its reconstruction framework. Understanding how 3D Gaussians are projected to 2D and combined is essential.
  - **Quick check question**: What mathematical property of Gaussians makes them suitable for splatting-based rendering?

## Architecture Onboarding

- **Component map**: Multi-exposure LDR images -> 3D Gaussian points with radiance attributes -> Asymmetric grid-based tone mapper -> Differentiable loss computation -> Parameter updates

- **Critical path**: Input images → 3D Gaussian splatting (radiance-based) → Asymmetric grid tone mapping → Differentiable loss computation → Parameter updates

- **Design tradeoffs**:
  - Asymmetric vs. symmetric grid: Better expressiveness vs. increased complexity
  - Coarse-to-fine vs. direct training: Faster convergence and stability vs. longer total training time
  - Radiance-based vs. color-based Gaussians: Full HDR representation vs. simpler implementation

- **Failure signatures**:
  - Poor LDR reconstruction quality: Likely issues with tone mapper or Gaussian attributes
  - HDR images dominated by white or with floating-point issues: Insufficient expressiveness of tone mapper
  - Slow convergence or local optima: Missing coarse-to-fine strategy or improper learning rates
  - Memory issues: Too many Gaussian points or overly dense asymmetric grid

- **First 3 experiments**:
  1. **Sanity check with synthetic data**: Use Blender-rendered scenes with known HDR ground truth to verify the complete pipeline works end-to-end
  2. **Ablation on grid symmetry**: Compare asymmetric vs. symmetric grid performance on a scene with known irradiance distribution
  3. **Coarse-to-fine impact**: Train the same scene with and without the coarse phase to measure convergence speed and final quality difference

## Open Questions the Paper Calls Out
No open questions were explicitly called out in the paper.

## Limitations
- Performance degrades for scenes with transparent objects due to the crude simulation of the physical imaging process
- Method depends on precise exposure time measurements and assumes linear CRF invertibility
- Asymmetric grid requires careful calibration of node distribution based on scene-specific irradiance characteristics
- Coarse-to-fine strategy adds training complexity and may not benefit all scene types equally

## Confidence

*High confidence*: The core radiance redefinition mechanism and its mathematical foundation are well-established. The asymmetric grid's ability to map HDR irradiance to LDR colors is theoretically sound and supported by experimental results.

*Medium confidence*: The coarse-to-fine training strategy's effectiveness may be scene-dependent. While it prevents local optima in tested scenarios, its benefits for scenes with different exposure distributions or geometric complexity remain to be validated.

*Low confidence*: The exact implementation details of the time scaling function and its interaction with the asymmetric grid during training versus inference are not fully specified, creating potential reproducibility challenges.

## Next Checks

1. **Cross-dataset generalization test**: Apply HDRGS to a dataset with significantly different exposure distributions (e.g., predominantly low-light scenes) to verify that the asymmetric grid allocation strategy and time scaling function remain effective.

2. **CRF non-linearity analysis**: Systematically test the method's robustness to CRF non-linearity by introducing controlled distortions to the exposure time measurements and measuring the degradation in reconstruction quality.

3. **Grid parameter sensitivity**: Conduct a grid resolution ablation study varying the asymmetric node distribution ratios (128 vs 64 nodes) across scenes with different irradiance distributions to determine optimal configurations and identify failure modes.