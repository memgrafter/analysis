---
ver: rpa2
title: 'LiGNN: Graph Neural Networks at LinkedIn'
arxiv_id: '2402.11139'
source_url: https://arxiv.org/abs/2402.11139
tags:
- graph
- training
- sampling
- data
- linkedin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LiGNN is a large-scale Graph Neural Networks (GNNs) framework deployed
  at LinkedIn, addressing challenges in training GNNs on massive graphs with diverse
  entities and cold start problems. The framework introduces innovations such as temporal
  graph architectures with long-term losses, graph densification for cold start, and
  multi-hop neighbor sampling.
---

# LiGNN: Graph Neural Networks at LinkedIn

## Quick Facts
- arXiv ID: 2402.11139
- Source URL: https://arxiv.org/abs/2402.11139
- Reference count: 33
- LiGNN achieves 1% increase in job application hearing back rate, 2% lift in ads CTR, 0.5% increase in feed-engaged daily active users, 0.2% session lift, and 0.1% weekly active user lift

## Executive Summary
LiGNN is a large-scale Graph Neural Networks framework deployed at LinkedIn to address the challenges of training GNNs on massive graphs with diverse entities and cold start problems. The framework introduces innovations such as temporal graph architectures with long-term losses, graph densification for cold start, and multi-hop neighbor sampling. Training is accelerated by 7x using adaptive neighbor sampling, grouping and slicing of training batches, and specialized shared-memory queues. Deployed across multiple LinkedIn applications, LiGNN achieves significant improvements in key metrics including job applications, ads CTR, and user engagement.

## Method Summary
LiGNN is a large-scale GNN framework that trains models on heterogeneous graphs with up to a hundred billion nodes and several hundred billion edges. The framework uses a GraphSAGE encoder with temporal graph architecture, multi-hop neighbor sampling using Personalized PageRank, and graph densification for cold start problems. Training optimizations include adaptive neighbor sampling, grouping and slicing of training batches, and specialized shared-memory queues to achieve 7x speedup. The system is deployed on a Kubernetes cluster with a Graph Engine for real-time graph sampling and GNN Trainer for model training, serving near-line inference for fresh embeddings.

## Key Results
- 1% increase in job application hearing back rate
- 2% lift in ads CTR
- 0.5% increase in feed-engaged daily active users
- 7x training speedup achieved through optimization techniques

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-hop Personalized PageRank (PPR) sampling significantly improves GNN performance compared to random/weighted sampling by focusing on topologically important neighbors.
- **Mechanism:** PPR computes a probability distribution over the graph, identifying neighbors with the highest likelihood of being relevant based on the graph structure and edge weights. This prioritizes important nodes in the sampling process.
- **Core assumption:** The topological importance of neighbors correlates with their usefulness for representation learning in the GNN.
- **Evidence anchors:**
  - [abstract]: "We found Personalized PageRank (PPR) [2, 7, 30, 31] sampling to be more effective than random sampling."
  - [section 3.6]: "In experiments in Follow Feed and People recommendations, 2-hop PPR sampling contributes around 90% of gains and accelerate the sampling speed by 3 times, therefore we choose 2-hop PPR sampling as the default sampling strategy."
  - [corpus]: No direct evidence in corpus.

### Mechanism 2
- **Claim:** Graph densification using artificial edges based on content embeddings mitigates cold start problems by connecting low-degree nodes to relevant high-degree nodes.
- **Mechanism:** By leveraging external content embeddings (e.g., profile LLM embeddings for members, content embeddings for items), nodes with similar characteristics are identified. Artificial edges are added between low-out-degree nodes and their top-k similar high-out-degree counterparts, facilitating information flow.
- **Core assumption:** Nodes with similar content embeddings are likely to have similar interaction patterns or relevance in the graph.
- **Evidence anchors:**
  - [abstract]: "To improve the experience for less active members, we propose methods for graph densification (ยง3.5) and share our experience on speeding up multi-hop graph sampling (ยง3.6)."
  - [section 3.5]: "We utilize different external embeddings for varying node types, such as profile LLM embeddings for member nodes, derived from member profile data, and content embeddings for item nodes, based on text and image content."
  - [corpus]: No direct evidence in corpus.

### Mechanism 3
- **Claim:** Temporal modeling using transformer-based architectures with long-term losses improves GNN performance by capturing time-sensitive dynamics in professional social networks.
- **Mechanism:** The model expands the SAGE encoder output to a multi-head dimension, encodes the last N activities of a member using a node encoding module, and feeds this sequence to a transformer encoder. Positional encoding and prefix causal masking are used to model the temporal order. Long-term losses extend predictions to future events.
- **Core assumption:** Interactions in professional social networks are time-sensitive, and modeling the temporal sequence of activities improves the model's ability to capture user preferences and predict future interactions.
- **Evidence anchors:**
  - [abstract]: "To keep up with LinkedIn's dynamic ecosystem, we integrated Temporal Graphs with long-term optimization (ยง3.4) and implemented near-line graph serving (ยง5)."
  - [section 3.4]: "Our design modifies the neighbor sampling method of a SAGE [32] encoder by adding time-based node sampling to capture the last N (e.g. 100) activities of member before a certain time."
  - [corpus]: No direct evidence in corpus.

## Foundational Learning

- **Concept:** Graph Neural Networks (GNNs) and their training challenges at scale.
  - **Why needed here:** Understanding the unique challenges of GNN training, such as graph hosting requirements and scalability issues, is crucial for grasping the innovations presented in the paper.
  - **Quick check question:** What are the main differences between traditional DNN training and GNN training, particularly in terms of scalability?

- **Concept:** Graph sampling strategies, including random sampling, weighted sampling, and Personalized PageRank (PPR) sampling.
  - **Why needed here:** The choice of graph sampling strategy significantly impacts GNN performance, and understanding the trade-offs between different approaches is essential for effective model design.
  - **Quick check question:** How does PPR sampling differ from random sampling, and why is it more effective in certain scenarios?

- **Concept:** Cold start problem in recommendation systems and graph-based solutions.
  - **Why needed here:** The cold start problem is a common challenge in recommender systems, and understanding how graph densification using artificial edges can mitigate this issue is key to appreciating the paper's contributions.
  - **Quick check question:** What are the main approaches to address the cold start problem, and how does graph densification using artificial edges based on content embeddings compare to other methods?

## Architecture Onboarding

- **Component map:** Graph Construction -> Graph Engine (GE) -> GNN Trainer -> Model Inference -> Near-line Embedding Generation

- **Critical path:** The critical path for training a GNN model using LiGNN involves:
  1. Constructing the heterogeneous graph with appropriate node and edge types.
  2. Deploying the Graph Engine and GNN Trainer on the Kubernetes cluster.
  3. Implementing the chosen GNN architecture (e.g., SAGE encoder with temporal modeling).
  4. Applying graph densification techniques if necessary.
  5. Configuring the multi-hop graph sampling strategy (e.g., 2-hop PPR sampling).
  6. Implementing training speedup techniques to optimize performance.
  7. Training the GNN model using the prepared data and sampling strategy.
  8. Deploying the trained model for near-line inference to generate fresh embeddings.

- **Design tradeoffs:**
  - Model complexity vs. training speed: More complex models (e.g., with temporal modeling) may require more training time and computational resources.
  - Sampling strategy: PPR sampling is more effective but computationally more expensive than random sampling.
  - Graph densification: Adding artificial edges can mitigate cold start but may introduce noise if not done carefully.
  - Training speedup techniques: Techniques like adaptive neighbor sampling and grouping and slicing can significantly reduce training time but may require careful parameter tuning.

- **Failure signatures:**
  - Training instability: If the training process fails frequently or produces unstable results, it may indicate issues with the Graph Engine, network connectivity, or memory management.
  - Poor model performance: If the trained model doesn't show significant improvements over baseline models, it may suggest problems with the graph construction, sampling strategy, or model architecture.
  - Slow training speed: If the training process is excessively slow, it may indicate the need for optimization techniques like mixed precision training or gradient accumulation.

- **First 3 experiments:**
  1. **Baseline GNN training:** Train a simple GNN model using random sampling on a small subset of the graph to establish a performance baseline.
  2. **PPR sampling evaluation:** Compare the performance of PPR sampling against random sampling on the same subset of the graph to assess the impact of the sampling strategy.
  3. **Graph densification impact:** Apply graph densification techniques to the graph and evaluate the performance improvement on a cold start scenario.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the impact of temporal graph modeling on long-term user engagement metrics beyond immediate short-term gains?
- **Basis in paper:** [explicit] The paper discusses temporal graph modeling and long-term losses, but only reports short-term metric improvements (e.g., 0.1% weekly active user lift).
- **Why unresolved:** The paper focuses on immediate metric improvements but does not explore long-term engagement impacts of temporal modeling.
- **What evidence would resolve it:** Longitudinal A/B tests measuring user engagement metrics (e.g., retention, lifetime value) over extended periods (e.g., months) would clarify the long-term impact of temporal graph modeling.

### Open Question 2
- **Question:** How does the performance of LiGNN's graph densification approach compare to other cold start solutions like meta-learning or self-supervised pre-training?
- **Basis in paper:** [inferred] The paper presents graph densification as a cold start solution but does not compare its effectiveness to other established methods.
- **Why unresolved:** The paper only demonstrates the effectiveness of graph densification within LiGNN's context, lacking comparative analysis with alternative cold start approaches.
- **What evidence would resolve it:** Benchmarking experiments comparing graph densification to meta-learning, self-supervised pre-training, and other cold start techniques on the same datasets would provide a clear performance comparison.

### Open Question 3
- **Question:** What are the trade-offs between model accuracy and training time when using adaptive neighbor sampling with different initial neighbor counts and stride values?
- **Basis in paper:** [explicit] The paper introduces adaptive neighbor sampling as a technique to reduce training time but does not explore the trade-offs with model accuracy.
- **Why unresolved:** While the paper demonstrates the effectiveness of adaptive neighbor sampling in reducing training time, it does not investigate how different parameter settings affect model accuracy.
- **What evidence would resolve it:** Systematic experiments varying initial neighbor counts and stride values while monitoring both training time and model accuracy would reveal the trade-offs involved in adaptive neighbor sampling.

## Limitations

- Many technical details about LinkedIn's specific implementation (Graph Engine, in-house solutions) are proprietary and not fully disclosed, limiting complete reproducibility.
- The heterogeneous graph schema with specific edge types (engagement, affinity, attribute) is complex and likely tuned to LinkedIn's specific use case.
- Performance metrics are relative improvements compared to baselines, but absolute baseline performance values are not provided.

## Confidence

**High Confidence:**
- The effectiveness of 2-hop PPR sampling compared to random/weighted sampling (supported by specific experimental results in Follow Feed and People recommendations)
- The 7x training speedup from the optimization techniques (explicitly stated result)
- The overall framework architecture and its components

**Medium Confidence:**
- The impact of temporal modeling on performance (mechanism described but specific experimental comparisons not provided)
- The effectiveness of graph densification for cold start (mechanism described but quantitative results limited to general claims)

**Low Confidence:**
- The exact implementation details of the in-house approximate nearest neighbor search for graph densification
- The specific hyperparameter configurations that led to optimal performance

## Next Checks

1. **Sampling Strategy Validation:** Conduct controlled experiments comparing 2-hop PPR sampling against random and weighted sampling on a representative graph dataset, measuring both performance impact and computational efficiency.

2. **Cold Start Mitigation Testing:** Implement graph densification using external embeddings on a cold start scenario and measure the performance improvement against a baseline model without densification, ensuring the embeddings are truly independent of the graph structure.

3. **Temporal Modeling Impact:** Perform ablation studies by training models with and without temporal components on time-sensitive graph data to quantify the actual contribution of temporal modeling to the overall performance improvements.