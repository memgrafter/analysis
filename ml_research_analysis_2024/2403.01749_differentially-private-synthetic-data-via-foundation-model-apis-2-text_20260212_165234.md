---
ver: rpa2
title: 'Differentially Private Synthetic Data via Foundation Model APIs 2: Text'
arxiv_id: '2403.01749'
source_url: https://arxiv.org/abs/2403.01749
tags:
- synthetic
- aug-pe
- data
- text
- private
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes AUG-PE, a novel method for generating differentially
  private (DP) synthetic text using only API access to large language models (LLMs),
  without any model training. AUG-PE addresses the challenge of creating high-quality
  DP synthetic text, which is crucial for privacy-preserving applications.
---

# Differentially Private Synthetic Data via Foundation Model APIs 2: Text

## Quick Facts
- arXiv ID: 2403.01749
- Source URL: https://arxiv.org/abs/2403.01749
- Reference count: 40
- Key outcome: AUG-PE generates DP synthetic text via LLM APIs without model training, achieving competitive utility vs DP fine-tuning baselines

## Executive Summary
This paper proposes AUG-PE, a novel method for generating differentially private (DP) synthetic text using only API access to large language models (LLMs), without any model training. AUG-PE addresses the challenge of creating high-quality DP synthetic text, which is crucial for privacy-preserving applications. The method employs a private evolution algorithm with new generation and selection techniques, including adaptive text lengths, paraphrasing, and fill-in-the-blanks. Experiments on three benchmark datasets (Yelp, OpenReview, PubMed) demonstrate that AUG-PE produces DP synthetic text with competitive utility compared to state-of-the-art DP fine-tuning baselines, even when using more powerful open-source or API-based LLMs. The results show improved downstream task accuracy and embedding distribution similarity, highlighting the feasibility of relying solely on LLM APIs for privacy-preserving text generation.

## Method Summary
AUG-PE generates DP synthetic text by iteratively improving synthetic samples through LLM API calls, without any model training. The method starts with random samples from the LLM, calculates embeddings and DP histograms for privacy, then selects and generates high-quality synthetic samples using variation techniques like paraphrasing and fill-in-the-blanks. The algorithm uses adaptive text lengths, rank-based sampling, and powerful LLMs (GPT-2, GPT-3.5, etc.) as data generators. AUG-PE achieves competitive utility with DP finetuning baselines by leveraging effective sample selection and generation techniques while maintaining formal DP guarantees.

## Key Results
- AUG-PE produces DP synthetic text with competitive utility compared to state-of-the-art DP fine-tuning baselines
- The method works across three benchmark datasets (Yelp, OpenReview, PubMed) with improved downstream task accuracy
- AUG-PE achieves better performance as data size increases, scaling well with the number of synthetic samples
- Using more powerful LLMs and embedding models further improves AUG-PE's performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AUG-PE uses API access to LLMs to generate DP synthetic text without model training.
- Mechanism: Instead of finetuning LLMs with DP-SGD on private data, AUG-PE iteratively improves synthetic samples by selecting the most similar ones to private data and generating new samples via API calls.
- Core assumption: LLM APIs can generate diverse and high-quality text samples that approximate the private data distribution.
- Evidence anchors:
  - [abstract]: "We propose an augmented PE algorithm, named AUG-PE, that applies to the complex setting of text. We use API access to an LLM and generate DP synthetic text without any model training."
  - [section]: "Unlike image diffusion models used in Lin et al. (2024), text models usually do not provide off-the-shelf variation APIs. Again, we leverage the instruction-following capability of LLMs to implement this via prompting."
- Break condition: If LLM APIs cannot generate sufficiently diverse or high-quality text samples, or if the private data distribution is too complex for the LLM to approximate.

### Mechanism 2
- Claim: AUG-PE improves text generation quality by using adaptive text lengths and diverse generation techniques.
- Mechanism: AUG-PE adjusts per-sample max_token adaptively based on the desired word count in the generation and uses paraphrasing and fill-in-the-blanks for variation.
- Core assumption: LLMs can follow instructions for adaptive text lengths and diverse generation techniques.
- Evidence anchors:
  - [section]: "To address the challenge, we leverage PE to learn text lengths automatically by adjusting per-sample max_token adaptively."
  - [section]: "We propose two variation methods: paraphrasing and fill-in-the-blanks."
- Break condition: If LLMs fail to follow instructions for adaptive text lengths or diverse generation techniques, or if the generated texts are of poor quality.

### Mechanism 3
- Claim: AUG-PE achieves competitive utility with DP finetuning baselines by leveraging powerful LLMs and effective sample selection.
- Mechanism: AUG-PE uses GPT-3.5 and other powerful LLMs as data generators and employs rank-based sampling and embedding models for effective sample selection.
- Core assumption: More powerful LLMs can generate higher-quality synthetic texts, and effective sample selection can improve utility.
- Evidence anchors:
  - [abstract]: "Experiments on three benchmark datasets (Yelp, OpenReview, PubMed) demonstrate that AUG-PE produces DP synthetic text with competitive utility compared to state-of-the-art DP finetuning baselines."
  - [section]: "We use off-the-shelf text embedding models Φ to calculate the embedding of private/synthetic samples."
- Break condition: If powerful LLMs fail to generate higher-quality synthetic texts, or if the sample selection process does not improve utility.

## Foundational Learning

- Concept: Differential Privacy (DP)
  - Why needed here: DP is the formal privacy guarantee that ensures the output of a mechanism is close regardless of whether an individual data record is included in the input or not.
  - Quick check question: What is the formal definition of (ε, δ)-DP, and how does it ensure privacy?

- Concept: Large Language Models (LLMs)
  - Why needed here: LLMs are used as data generators in AUG-PE to generate synthetic text samples via API access.
  - Quick check question: What are the key differences between GPT-2-series models and GPT-3.5 in terms of generation capabilities?

- Concept: Text Embeddings
  - Why needed here: Text embeddings are used to calculate the similarity between private and synthetic samples for effective sample selection in AUG-PE.
  - Quick check question: How do text embedding models like sentence-transformer capture the nuances of texts in the embedding space?

## Architecture Onboarding

- Component map:
  RANDOM_API -> VARIATION_API -> DP_NN_HISTOGRAM -> Sample selection and generation

- Critical path:
  Generate initial synthetic samples via RANDOM_API -> Calculate embeddings and DP histogram -> Select and generate high-quality synthetic samples -> Repeat until convergence

- Design tradeoffs:
  Adaptive text lengths vs. fixed max_token for text generation
  Paraphrasing vs. fill-in-the-blanks for variation
  Rank-based sampling vs. probability-based random sampling for sample selection

- Failure signatures:
  Poor quality synthetic samples
  High embedding distribution distance between real and synthetic data
  Low downstream task accuracy on synthetic data

- First 3 experiments:
  1. Generate initial synthetic samples with RANDOM_API and evaluate their quality
  2. Calculate embeddings and DP histogram, and evaluate the sample selection process
  3. Generate high-quality synthetic samples with VARIATION_API and evaluate their utility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of AUG-PE scale with increasing dataset size beyond the tested ranges?
- Basis in paper: [explicit] The paper notes that "under ϵ = 1, 2, 4, ∞, AUG-PE in general achieves better performance across all datasets as the data size increases, suggesting that AUG-PE scales well with the number of synthetic samples."
- Why unresolved: The paper's experiments are limited to specific dataset sizes (e.g., 5k, 10k, 100k for Yelp). The scalability beyond these ranges is not explored.
- What evidence would resolve it: Experiments testing AUG-PE on datasets with sizes significantly larger than 100k samples, measuring downstream task accuracy and embedding distribution similarity.

### Open Question 2
- Question: How does the quality of synthetic text generated by AUG-PE compare to that of other non-DP text generation methods?
- Basis in paper: [inferred] The paper focuses on DP synthetic text generation and compares AUG-PE to DP finetuning baselines, but does not compare it to non-DP methods.
- Why unresolved: The paper's primary focus is on privacy-preserving methods, leaving the comparison to non-DP methods unexplored.
- What evidence would resolve it: A direct comparison of AUG-PE's synthetic text quality (e.g., downstream task accuracy, embedding distribution similarity) to that of non-DP text generation methods like standard GPT-2 or GPT-3.5 finetuning.

### Open Question 3
- Question: How does the choice of embedding model affect the performance of AUG-PE, and can more powerful embedding models further improve results?
- Basis in paper: [explicit] The paper states, "Tb. 7 shows that larger embedding models such as 'sentence-t5-xl' can more accurately capture the nuances of texts in the embedding space, leading to higher utility for GPT-2 generated texts."
- Why unresolved: While the paper shows that larger embedding models improve performance, it does not explore the upper limits of this improvement or test the most advanced embedding models available.
- What evidence would resolve it: Experiments using state-of-the-art embedding models (e.g., large language models like GPT-4 or Claude) to generate embeddings for AUG-PE, measuring the impact on downstream task accuracy and embedding distribution similarity.

## Limitations
- The approach relies heavily on LLM APIs generating diverse, high-quality samples that approximate private data distributions
- Privacy budget calculation follows standard DP-SGD accounting without exploring adaptive privacy budgets or tighter composition theorems
- Experiments are limited to three benchmark datasets with relatively standard downstream tasks

## Confidence
- High Confidence: The core mechanism of using LLM APIs for DP synthetic text generation without training is sound and well-demonstrated
- Medium Confidence: The specific implementation details (prompt engineering, temperature settings, variation techniques) may require tuning for different LLMs or domains
- Low Confidence: The long-term robustness of this approach against evolving privacy attacks and its scalability to extremely large datasets or real-time generation scenarios

## Next Checks
1. **Cross-LLM Generalization Test**: Validate AUG-PE's performance using the same hyperparameter settings across at least five different LLM architectures (including both commercial and open-source models) to establish robustness beyond GPT-2 and GPT-3.5.

2. **Domain Adaptation Evaluation**: Apply AUG-PE to domain-specific text datasets (e.g., medical records, legal documents, code repositories) to assess performance on specialized vocabularies and writing styles not represented in the benchmark datasets.

3. **Privacy Budget Optimization Study**: Conduct experiments with adaptive privacy budgets and tighter composition theorems to determine if utility can be improved without compromising the formal DP guarantees, particularly for high-dimensional text data.