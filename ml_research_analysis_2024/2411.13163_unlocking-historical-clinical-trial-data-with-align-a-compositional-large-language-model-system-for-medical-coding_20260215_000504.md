---
ver: rpa2
title: 'Unlocking Historical Clinical Trial Data with ALIGN: A Compositional Large
  Language Model System for Medical Coding'
arxiv_id: '2411.13163'
source_url: https://arxiv.org/abs/2411.13163
tags:
- align
- codes
- coding
- medical
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'ALIGN is a compositional LLM-based system for automated zero-shot
  medical coding that addresses interoperability challenges in historical clinical
  trial data. It employs a three-step process: diverse candidate code generation using
  dense retrieval, BM25 retrieval, and LLM reasoning; self-evaluation of codes via
  entailment verification; and confidence scoring with uncertainty estimation for
  human deferral.'
---

# Unlocking Historical Clinical Trial Data with ALIGN: A Compositional Large Language Model System for Medical Coding

## Quick Facts
- arXiv ID: 2411.13163
- Source URL: https://arxiv.org/abs/2411.13163
- Reference count: 40
- One-line primary result: ALIGN achieves 72-73% overall accuracy for ATC Level 4 codes and 86-90% for common medications, outperforming baselines by 7-22%.

## Executive Summary
ALIGN is a compositional LLM-based system for automated zero-shot medical coding that addresses interoperability challenges in historical clinical trial data. It employs a three-step process: diverse candidate code generation using dense retrieval, BM25 retrieval, and LLM reasoning; self-evaluation of codes via entailment verification; and confidence scoring with uncertainty estimation for human deferral. Evaluated on 22 immunology trials for ATC (medication) and MedDRA (medical history) coding, ALIGN achieved 72-73% overall accuracy for ATC Level 4 codes and 86-90% for common medications, outperforming baselines by 7-22%. For MedDRA, ALIGN matched RAG performance at 87-90% accuracy for HLGT codes. Its uncertainty-based deferral improved accuracy by 17% to 90% with 30% deferral, particularly benefiting uncommon medications. ALIGN is cost-efficient at $0.0007-$0.02 per code, making it practical for large-scale clinical deployment.

## Method Summary
ALIGN is a compositional LLM system that automates zero-shot medical coding for historical clinical trial data. It addresses missing standardized medical codes (ATC for medications, MedDRA for medical history) through three stages: (1) diverse candidate generation via dense retrieval, BM25, and LLM reasoning; (2) self-evaluation via entailment verification against ATC/MedDRA descriptions; (3) confidence scoring with entropy-based uncertainty for human deferral. The system uses OpenAI embeddings for dense retrieval, BM25 for sparse retrieval, and LLM contextualization and reasoning to generate candidate codes. Entailment verification filters invalid codes, and MCQ reformulation with entropy estimates uncertainty for deferral. Evaluated on 22 immunology trials, ALIGN achieves 72-73% accuracy for ATC Level 4 codes and 86-90% for common medications, outperforming baselines while maintaining cost-efficiency.

## Key Results
- ALIGN achieves 72-73% overall accuracy for ATC Level 4 codes and 86-90% for common medications, outperforming baselines by 7-22%.
- For MedDRA coding, ALIGN matches RAG performance at 87-90% accuracy for HLGT codes.
- Uncertainty-based deferral improves accuracy by 17% to 90% with 30% deferral, particularly benefiting uncommon medications.
- ALIGN is cost-efficient at $0.0007-$0.02 per code, making it practical for large-scale clinical deployment.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ALIGN improves medical coding accuracy by combining multiple retrieval and reasoning strategies to generate diverse candidate codes.
- Mechanism: Dense retrieval, BM25 retrieval, and LLM reasoning are used to propose candidate codes, ensuring coverage of different semantic and syntactic matches.
- Core assumption: Different retrieval methods capture complementary aspects of the query, and LLM reasoning can fill gaps that retrieval alone cannot.
- Evidence anchors:
  - [abstract] "diverse candidate code generation using dense retrieval, BM25 retrieval, and LLM reasoning"
  - [section] "ALIGN employs three complementary approaches to generate diverse candidate codes: dense retrieval, BM25 retrieval, and LLM reasoning."
  - [corpus] No direct corpus evidence for retrieval diversity; inferred from method description.
- Break condition: If all retrieval methods fail to propose the correct code, or if the LLM reasoning consistently misses the correct code due to insufficient training data.

### Mechanism 2
- Claim: Self-evaluation via entailment verification reduces spurious code assignments.
- Mechanism: ALIGN uses an LLM to perform natural language inference, checking if the query is logically entailed by the code descriptions from authoritative sources.
- Core assumption: Entailment verification is a reliable proxy for code validity, and authoritative sources provide accurate grounding.
- Evidence anchors:
  - [abstract] "self-evaluation of codes via entailment verification"
  - [section] "ALIGN employs a separate LLM to perform a natural language inference (NLI) task...to evaluate whether the medication query or medical condition is logically entailed by or consistent with the retrieved context (code descriptions)."
  - [corpus] No direct corpus evidence for entailment filtering; inferred from method description.
- Break condition: If the entailment model is poorly calibrated, or if authoritative sources are incomplete or outdated.

### Mechanism 3
- Claim: Uncertainty quantification enables selective human deferral, improving accuracy while reducing expert burden.
- Mechanism: ALIGN reformulates coding as a multiple-choice question, extracts logit probabilities, applies temperature scaling, and computes entropy to estimate uncertainty. Codes with high entropy are deferred to humans.
- Core assumption: LLM token-level probabilities are well-calibrated for uncertainty estimation in MCQ format.
- Evidence anchors:
  - [abstract] "confidence scoring with uncertainty estimation for human deferral"
  - [section] "We reformulate the code prediction task as a multiple choice question (MCQ)...extract the log-probabilities for each as confidence scores...estimate uncertainty by computing the predictive entropy"
  - [corpus] No direct corpus evidence for MCQ reformulation; inferred from method description.
- Break condition: If the MCQ reformulation introduces bias, or if entropy thresholds are poorly calibrated.

## Foundational Learning

- Concept: Medical coding systems (ATC, MedDRA)
  - Why needed here: Understanding the structure and granularity of ATC and MedDRA is essential to interpret results and design experiments.
  - Quick check question: What are the four levels of the ATC hierarchy, and what does each represent?

- Concept: Natural language inference (entailment)
  - Why needed here: Entailment verification is the core of ALIGN's self-evaluation step; understanding NLI helps debug failures.
  - Quick check question: In entailment verification, what does it mean if the hypothesis is "entailed" by the premise?

- Concept: Conformal prediction
  - Why needed here: ALIGN can be extended with conformal prediction for frequentist guarantees; knowing the framework aids future extensions.
  - Quick check question: In conformal prediction, what is the role of the calibration set?

## Architecture Onboarding

- Component map: Query input → Dense retrieval (ChromaDB + embeddings) → BM25 retrieval (bm25s) → LLM reasoning (contextualizer + alternative names + code generation) → Entailment verifier (LLM) → Confidence scorer (MCQ reformulation + entropy) → Output or deferral
- Critical path: Query → Candidate generation (dense, BM25, LLM) → Self-evaluation (entailment) → Confidence scoring → Output/deferral
- Design tradeoffs:
  - Retrieval diversity vs. latency: Using three methods increases coverage but adds latency.
  - Self-evaluation filtering vs. recall: Strict entailment filtering improves precision but may drop correct but rare codes.
  - Entropy threshold vs. deferral rate: Lower threshold increases deferral (higher accuracy) but increases human workload.
- Failure signatures:
  - Low diversity in candidate codes: Retrieval indices may be outdated or queries too narrow.
  - High false positives in self-evaluation: Entailment model may be overconfident or grounding sources incomplete.
  - Poor uncertainty calibration: MCQ reformulation or temperature scaling may be misconfigured.
- First 3 experiments:
  1. Ablation: Run ALIGN with only one retrieval method (dense, BM25, or LLM) to quantify diversity gain.
  2. Entailment filtering analysis: Manually inspect codes filtered by entailment to check for false positives.
  3. Uncertainty calibration: Vary entropy threshold and plot accuracy vs. deferral rate to find optimal balance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ALIGN's performance scale with larger and more diverse datasets, particularly for uncommon medications and codes?
- Basis in paper: [inferred] The paper notes that ALIGN's performance on uncommon medications is lower and suggests this is due to limited contextual information in the LLM's training corpus. It also mentions the potential for future work to expand evaluations to more medical indications and coding systems.
- Why unresolved: The paper only evaluated ALIGN on 22 immunology trials, which may not be representative of the full diversity of medical conditions and medications. Scaling to larger, more diverse datasets could reveal new challenges or opportunities for improvement.
- What evidence would resolve it: Evaluating ALIGN on a much larger and more diverse set of clinical trials across multiple therapeutic areas and coding systems would provide evidence of how well it scales and where it might struggle.

### Open Question 2
- Question: What is the impact of using different LLM backbones (e.g., GPT-4o-mini vs. GPT-4o) on ALIGN's performance and cost-effectiveness?
- Basis in paper: [explicit] The paper compares the performance and cost of using GPT-4o-mini and GPT-4o as LLM backbones for ALIGN. It notes that GPT-4o-mini is more cost-effective but does not provide a detailed analysis of how the choice of backbone affects performance.
- Why unresolved: The paper only provides a high-level comparison of cost and performance for two specific LLM models. A more comprehensive analysis of different LLM backbones could reveal insights into the trade-offs between performance and cost.
- What evidence would resolve it: Evaluating ALIGN with a wider range of LLM backbones and conducting a detailed cost-benefit analysis would provide evidence of the impact of different backbones on performance and cost-effectiveness.

### Open Question 3
- Question: How does ALIGN's uncertainty quantification and human-in-the-loop integration affect its performance and reliability in real-world clinical settings?
- Basis in paper: [explicit] The paper highlights ALIGN's uncertainty quantification capability and its ability to flag cases for human review. It also mentions the potential for future work to improve performance in areas where human oversight is needed.
- Why unresolved: The paper only provides simulated results for the impact of human-in-the-loop integration. Real-world deployment would involve more complex and varied scenarios that could affect ALIGN's performance and reliability.
- What evidence would resolve it: Conducting a real-world deployment of ALIGN in a clinical setting and evaluating its performance and reliability with human-in-the-loop integration would provide evidence of its effectiveness in practice.

## Limitations
- Retrieval diversity and coverage are not empirically quantified; the complementarity between methods and completeness of metadata are not assessed.
- Entailment verification reliability is not validated; calibration, false positive/negative rates, and reliance on authoritative sources are not evaluated.
- Uncertainty calibration and deferral strategy lack rigorous validation; optimal thresholds and alternative uncertainty measures are not explored.
- Evaluation scope is limited to 22 immunology trials and specific code levels; performance on rare medications, other coding systems, and label reliability are not assessed.

## Confidence
- **High Confidence**: Overall accuracy improvements (72-73% ATC Level 4, 86-90% common medications), cost-efficiency ($0.0007-$0.02 per code), and comparison with RAG baselines for MedDRA coding.
- **Medium Confidence**: Performance gains from uncertainty-based deferral (17% accuracy increase at 30% deferral), but calibration and optimal thresholds are not validated.
- **Low Confidence**: Claims about retrieval diversity, entailment filtering reliability, and generalizability to other medical domains or coding systems.

## Next Checks
1. Ablation Study for Retrieval Diversity: Run ALIGN with each retrieval method (dense, BM25, LLM) separately and in pairs to quantify the marginal contribution of each to overall accuracy and coverage, especially for rare medications.
2. Entailment Filtering Analysis: Manually inspect a sample of codes filtered by the entailment verifier to assess false positive/negative rates and identify patterns where the model fails (e.g., incomplete code descriptions, ambiguous queries).
3. Uncertainty Calibration and Deferral Optimization: Vary the entropy threshold for deferral and plot accuracy vs. deferral rate to find the optimal balance; compare entropy-based uncertainty with conformal prediction for frequentist guarantees.