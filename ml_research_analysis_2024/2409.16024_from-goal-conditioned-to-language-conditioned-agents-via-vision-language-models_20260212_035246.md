---
ver: rpa2
title: From Goal-Conditioned to Language-Conditioned Agents via Vision-Language Models
arxiv_id: '2409.16024'
source_url: https://arxiv.org/abs/2409.16024
tags:
- task
- configurations
- mtrl
- tasks
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a novel decomposition of the problem of
  building language-conditioned agents (LCAs): first find an environment configuration
  that has a high vision-language model (VLM) score for text describing a task; then
  use a pretrained goal-conditioned policy to reach that configuration. The method
  employs precomputed configuration embeddings for rapid retrieval, optionally followed
  by finetuning using a distilled model, and leverages multiview evaluation to resolve
  ambiguities inherent in single 2D views.'
---

# From Goal-Conditioned to Language-Conditioned Agents via Vision-Language Models

## Quick Facts
- arXiv ID: 2409.16024
- Source URL: https://arxiv.org/abs/2409.16024
- Authors: Theo Cachet; Christopher R. Dance; Olivier Sigaud
- Reference count: 40
- Primary result: LCA outperforms multi-task RL baselines in zero-shot generalization (205/256 tasks) on Humanoid environment

## Executive Summary
This paper presents a novel decomposition of language-conditioned agent training by first finding high-scoring configurations using vision-language models (VLMs) and then using pretrained goal-conditioned policies to reach those configurations. The method employs precomputed configuration embeddings for rapid retrieval, optionally followed by finetuning using a distilled model, and leverages multiview evaluation to resolve ambiguities inherent in single 2D views. Experiments on a Humanoid environment with 256 diverse tasks show the proposed LCA outperforms multi-task RL baselines in zero-shot generalization, achieves better viewpoint robustness, and reduces computation time by up to 40,000x using the distilled model.

## Method Summary
The approach decomposes language-conditioned agent training into two stages: (1) configuration generation using VLMs to find environment states that match task descriptions, and (2) goal-conditioned policy execution to reach those configurations. Configurations are represented as a 31-dimensional subset of the state space that affects visual rendering. The method uses precomputed configuration embeddings from diverse datasets (random policy, uniform sampling, and embedding-diversity), enabling fast retrieval via cosine similarity. Multiview evaluation (averaging scores across three camera views) mitigates single-view ambiguities. A distilled model provides 40,000x speedup for finetuning configurations via projected gradient ascent, with final VLM evaluation selecting the best configurations.

## Key Results
- Zero-shot generalization to 205/256 tasks on Humanoid environment
- 40,000x computation time reduction using distilled model for configuration embeddings
- Multiview evaluation improves configuration robustness compared to single-view retrieval
- LCA outperforms multi-task RL baselines across diverse task sets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VLM score-based goal generation avoids the slow per-task training bottleneck of STRL.
- Mechanism: Precomputing configuration embeddings and retrieving high-scoring configurations reduces per-task configuration search to fast dot products rather than iterative RL training.
- Core assumption: The configuration space can be sampled and embedded such that high-scoring configurations exist for diverse tasks.
- Evidence anchors:
  - [abstract] "the cost and time required to train a policy for each new task"
  - [section 3.2.1] "one may retrieve a configuration with a high configuration-text similarity score, simply by taking dot products"
  - [corpus] weak - corpus neighbors focus on goal-conditioned imitation and hierarchical planning, not VLM-based retrieval
- Break condition: If the configuration space is too sparse or embeddings poorly capture task alignment, retrieval will fail.

### Mechanism 2
- Claim: Multiview evaluation mitigates ambiguities in single-view configuration assessment.
- Mechanism: Averaging VLM scores over multiple camera views smooths out occlusion and distance ambiguities that cause misleading single-view evaluations.
- Core assumption: Configuration embeddings from different views capture complementary information about the task.
- Evidence anchors:
  - [section 4.3] "evaluate configurations using multiple views mitigates some of the problems arising from the lack of information of single 2D images"
  - [section 4.3] Table 2 shows configurations retrieved with three views maintain high scores across viewpoints, unlike single-view retrievals
  - [corpus] weak - corpus papers do not discuss viewpoint robustness
- Break condition: If views are too similar or camera placement does not capture task-relevant aspects, multiview averaging provides no benefit.

### Mechanism 3
- Claim: Distilled model-based finetuning improves configuration alignment without full VLM evaluation cost.
- Mechanism: The distilled model approximates the configuration embedding, allowing gradient-based optimization to refine retrieved configurations, then exact VLM evaluation selects the best.
- Core assumption: The distilled model is smooth enough for effective gradient-based optimization yet accurate enough to improve true VLM scores.
- Evidence anchors:
  - [section 4.4] "the distilled model reduces the computation time of configuration embeddings by 40 000×"
  - [section 3.2.2] "the gradient of this surrogate score is ∇q ˆSqt(q, x) = ∇q ˆf config(q) · f text(x)"
  - [section 4.4] Table 3 shows finetuning increases scores even when evaluated by other VLMs
  - [corpus] weak - corpus neighbors focus on RL fine-tuning but not VLM-distilled optimization
- Break condition: If the distilled model is inaccurate or too smooth, finetuning may not improve true VLM scores.

## Foundational Learning

- Concept: Cosine similarity in embedding space as proxy for semantic alignment
  - Why needed here: VLM-based methods rely on embedding similarity to score how well a configuration matches a text description
  - Quick check question: If two embeddings have cosine similarity 0.8, are they semantically closer than embeddings with similarity 0.6?

- Concept: Projected gradient ascent with admissible constraints
  - Why needed here: Finetuning configurations must stay within feasible configuration space (no object interpenetration, stability)
  - Quick check question: What happens if gradient steps push a configuration into an inadmissible state before projection?

- Concept: Configuration as state subspace relevant to rendering
  - Why needed here: The approach only optimizes configuration dimensions that affect visual appearance, ignoring velocities or past states
  - Quick check question: Why might including velocities in the configuration space complicate optimization?

## Architecture Onboarding

- Component map:
  - Text description → VLM text encoder → embedding → cosine similarity search → top-k configurations
  - Retrieved configuration → distilled model → gradient ascent → projection → VLM evaluation → final goal
  - Goal → goal-conditioned policy → action sequence → environment
  - Environment → renderer → multiple camera views → VLM image encoder

- Critical path: Text → embedding → retrieval → (finetuning) → goal → GCRL → action sequence → environment
- Design tradeoffs:
  - More views → better robustness but higher embedding computation cost
  - Larger retrieval dataset → better coverage but more memory and slower retrieval
  - More finetuning steps → potentially better scores but diminishing returns and risk of overfitting to distilled model
- Failure signatures:
  - Low retrieval scores across all methods → configuration space sampling insufficient or VLM poorly aligned with tasks
  - High finetuning scores but low final scores → distilled model inaccurate or finetuning overfitting
  - GCRL fails to reach goals → training insufficient or goals intrinsically hard to reach
- First 3 experiments:
  1. Retrieve top-10 configurations for a simple task ("standing up") from embedding-diversity dataset and visualize them
  2. Compare single-view vs multiview retrieval scores for a task where occlusion is likely (e.g., "box on top of humanoid")
  3. Finetune a retrieved configuration for a task and verify score improvement using both distilled model and exact VLM

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed approach be extended to handle tasks involving compositional relationships between multiple diverse objects?
- Basis in paper: [explicit] The paper discusses limitations in current VLMs' ability to assess relationships between objects, mentioning this as a future direction.
- Why unresolved: The paper identifies this as a limitation of current VLMs and states that a new generation of VLMs is needed to enable such work.
- What evidence would resolve it: Demonstrating the approach's effectiveness on tasks involving multiple objects and complex relationships, or showing improvements with newer VLMs that better handle compositionality.

### Open Question 2
- Question: What is the impact of using more than three viewpoints for configuration evaluation, and how does it affect the trade-off between robustness and computational cost?
- Basis in paper: [inferred] The paper uses three viewpoints and discusses the linear increase in computational cost with multiple views, but doesn't explore the impact of using more views.
- Why unresolved: The paper only experiments with three viewpoints and doesn't investigate the effects of using additional views on configuration robustness and computational efficiency.
- What evidence would resolve it: Comparative experiments showing the benefits and drawbacks of using more than three viewpoints in terms of configuration quality and computational resources.

### Open Question 3
- Question: How can the approach be adapted to handle dynamic tasks that require continuous motion rather than static configurations?
- Basis in paper: [explicit] The paper explicitly states that the current approach is limited to static configurations and suggests extending it to dynamic tasks as future work.
- Why unresolved: The paper focuses on static configurations and doesn't provide a method for handling tasks that require continuous motion or temporal sequences.
- What evidence would resolve it: Developing and demonstrating a method that can generate goals for dynamic tasks and successfully control the agent to perform these tasks.

## Limitations
- Method's performance fundamentally limited by quality and coverage of precomputed configuration embeddings
- Assumption that VLM scores directly correlate with task feasibility may not hold universally
- 31-dimensional configuration space selection may exclude important state dimensions affecting task completion

## Confidence

- High confidence: Computational efficiency gains (40,000× speedup) from distilled models are well-supported
- Medium confidence: Zero-shot generalization claim (205/256 tasks) is supported by experimental data but needs scrutiny
- Medium confidence: Multiview evaluation effectiveness is demonstrated but robustness to extreme viewpoints untested

## Next Checks

1. **Generalization test**: Evaluate the LCA approach on a completely held-out set of 50 tasks not seen during any training phase, measuring both VLM scores and actual task completion rates.

2. **Viewpoint robustness**: Systematically vary camera positions (elevation, azimuth, distance) for retrieved configurations to quantify the breakdown point of multiview averaging.

3. **Configuration space completeness**: Measure the coverage of the embedding dataset by attempting to retrieve configurations for a comprehensive set of text descriptions spanning the full semantic space of possible tasks.