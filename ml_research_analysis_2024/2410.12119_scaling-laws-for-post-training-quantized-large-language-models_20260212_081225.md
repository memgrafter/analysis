---
ver: rpa2
title: Scaling Laws for Post Training Quantized Large Language Models
arxiv_id: '2410.12119'
source_url: https://arxiv.org/abs/2410.12119
tags:
- loss
- quantization
- scaling
- data
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the unpredictability of post-training quantization
  (PTQ) quality for large language models (LLMs), where scaling laws exist for pre-training
  but not for PTQ optimization. The authors conduct a systematic empirical study of
  multiple LLM families quantized to numerous low-precision tensor data types using
  popular PTQ techniques.
---

# Scaling Laws for Post Training Quantized Large Language Models

## Quick Facts
- arXiv ID: 2410.12119
- Source URL: https://arxiv.org/abs/2410.12119
- Reference count: 17
- Key outcome: Identifies scaling laws for post-training quantization quality across multiple LLM families using random forest regression

## Executive Summary
This work addresses the unpredictability of post-training quantization (PTQ) quality for large language models (LLMs), where scaling laws exist for pre-training but not for PTQ optimization. The authors conduct a systematic empirical study of multiple LLM families quantized to numerous low-precision tensor data types using popular PTQ techniques. They identify key scaling factors related to local loss landscape characteristics and build a statistical model based on random forest regression that predicts PTQ outcomes with reasonable accuracy.

The study establishes underlying scaling laws for quantized LLMs, transforming PTQ from a trial-and-error process to one guided by predictable scaling relationships. The predictive model achieves accurate results on held-out models from unseen families, suggesting generalizability across both different model sizes and LLM families. This represents a significant advancement in understanding how quantization quality scales with model size and architecture.

## Method Summary
The authors conducted an extensive empirical study across multiple LLM families including LLaMA, Mistral, and others, systematically applying various post-training quantization techniques including GPTQ and AWQ. They measured local loss landscape characteristics as key features and employed random forest regression to build predictive models. The study involved quantizing models to various precision levels from 8-bit down to lower precision formats, measuring performance degradation in terms of negative log-likelihood loss. The approach involved collecting empirical measurements as input features and training the model to predict quantization quality outcomes for unseen LLMs across different model sizes and families.

## Key Results
- Identified key scaling factors related to local loss landscape characteristics that govern PTQ quality
- Built a random forest regression model that predicts NLL loss after GPTQ with reasonable accuracy
- Demonstrated generalizability of the predictive model across different model families and sizes
- Transformed PTQ from a trial-and-error process to one guided by predictable scaling relationships

## Why This Works (Mechanism)
The mechanism underlying the scaling laws relates to the local loss landscape characteristics around the quantized models. The study found that certain geometric properties of the loss surface, such as curvature and flatness in parameter space, correlate strongly with quantization quality. These characteristics capture how the model's parameters interact with the quantization error introduced during the process. Models with certain loss landscape properties are more amenable to low-precision representation without significant performance degradation. The random forest model learns these relationships by mapping measured landscape features to expected quantization outcomes, effectively capturing the non-linear relationships between model geometry and quantization robustness.

## Foundational Learning

1. **Post-training quantization (PTQ)** - Why needed: Essential for deploying LLMs on resource-constrained hardware by reducing memory and computational requirements. Quick check: Can the model maintain performance after converting weights to lower precision without retraining.

2. **Loss landscape characteristics** - Why needed: Geometric properties of the optimization surface determine model robustness to perturbations like quantization. Quick check: Measure curvature and flatness metrics around parameter space to assess quantization sensitivity.

3. **Random forest regression** - Why needed: Ensemble method that can capture complex non-linear relationships between model features and quantization outcomes. Quick check: Evaluate feature importance and prediction accuracy on held-out data.

4. **GPTQ quantization technique** - Why needed: Popular PTQ method that uses differentiable approximation for optimal weight clustering. Quick check: Compare quantization quality against other methods like AWQ.

5. **NLL loss as quality metric** - Why needed: Negative log-likelihood provides a principled measure of language model performance degradation. Quick check: Measure degradation relative to full-precision baseline.

6. **Model family generalization** - Why needed: Ensures scaling laws apply across diverse architectural designs, not just specific implementations. Quick check: Test predictions on held-out families not used in training.

## Architecture Onboarding

**Component Map**: LLM Architecture -> Loss Landscape Analysis -> Feature Extraction -> Random Forest Model -> PTQ Quality Prediction

**Critical Path**: The critical path involves measuring loss landscape characteristics, extracting relevant features, and feeding them through the random forest model to obtain PTQ quality predictions. This process must be completed before deployment decisions can be made.

**Design Tradeoffs**: The study balances between model complexity (using random forests for accuracy) and interpretability (identifying key scaling factors). The choice of GPTQ as the primary quantization method trades comprehensiveness for depth of analysis on a single well-understood technique.

**Failure Signatures**: Poor predictions occur when models have atypical loss landscape characteristics not well-represented in the training data. This manifests as high prediction errors for novel architectures or when extrapolating beyond the parameter range of studied models.

**First Experiments**:
1. Measure loss landscape characteristics (curvature, flatness) for a new LLM architecture
2. Extract the same feature set used in the original study and input to the random forest model
3. Compare predicted NLL loss against actual measured performance after GPTQ quantization

## Open Questions the Paper Calls Out
None

## Limitations
- Focus primarily on 8-bit and lower precision formats, potentially missing higher precision performance characteristics
- Prediction accuracy shows variability across different model families and sizes
- Reliance on GPTQ as primary method limits generalizability to other PTQ techniques
- Empirical measurements required as input features may present practical deployment challenges

## Confidence

| Claim | Confidence |
|-------|------------|
| Scaling laws hold across multiple model families | Medium |
| Predictive model accuracy is reasonable | Medium |
| Model generalizes to held-out families | Medium |
| Transformation of PTQ from trial-and-error to predictable process | Medium |

## Next Checks
1. Evaluate predictive model performance on models trained with novel architectural innovations not represented in current dataset
2. Test scaling laws and predictions across wider range of quantization granularities, particularly 4-bit to 8-bit range
3. Conduct ablation studies to determine relative importance of each input feature and assess if simpler models achieve comparable accuracy