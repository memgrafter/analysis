---
ver: rpa2
title: Task-Oriented Dialogue with In-Context Learning
arxiv_id: '2402.12234'
source_url: https://arxiv.org/abs/2402.12234
tags:
- dialogue
- system
- transfer
- logic
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a system for building task-oriented dialogue
  systems using large language models (LLMs) for dialogue understanding and business
  logic execution. The system translates user messages into commands via LLMs, which
  are then processed by a deterministic dialogue manager.
---

# Task-Oriented Dialogue with In-Context Learning
## Quick Facts
- arXiv ID: 2402.12234
- Source URL: https://arxiv.org/abs/2402.12234
- Reference count: 7
- Key outcome: LLM-based dialogue system achieves 95.8% pass rate vs 47.9% for intent-based NLU, with less development effort

## Executive Summary
This paper introduces a novel approach to building task-oriented dialogue systems that leverages large language models (LLMs) for dialogue understanding while maintaining deterministic execution of business logic. The system translates user messages into structured commands using LLMs, which are then processed by a deterministic dialogue manager. This hybrid approach combines the flexibility of LLMs in understanding natural language with the reliability of rule-based systems for task execution. The method demonstrates significant improvements in handling complex dialogue phenomena while requiring less development effort than traditional intent-based systems.

## Method Summary
The proposed system uses LLMs to translate user messages into structured commands that represent user intent and extracted entities. These commands are then processed by a deterministic dialogue manager that executes business logic and maintains conversation state. The system is evaluated on the WOZ 2.0 dataset using a restaurant reservation scenario. Evaluation involves running 71 test conversations through the system and measuring whether the correct restaurant is suggested based on the user's preferences. The approach contrasts with traditional intent-based NLU systems by using few-shot prompting to handle dialogue understanding rather than training separate intent and entity recognition models.

## Key Results
- LLM-based system achieves 95.8% pass rate on 71 test conversations
- Traditional intent-based NLU approach achieves only 47.9% pass rate
- System requires significantly less development effort (1169 lines vs 1713 lines of code and data)

## Why This Works (Mechanism)
The system works by leveraging LLMs' natural language understanding capabilities through few-shot prompting, which allows the model to learn the mapping from user utterances to structured commands without explicit training. The deterministic dialogue manager ensures reliable execution of business logic and maintains conversation state, avoiding the potential inconsistencies that could arise from using LLMs for both understanding and execution. This separation of concerns allows the system to handle complex dialogue phenomena like corrections, digressions, and disambiguation more effectively than traditional intent-based approaches.

## Foundational Learning
- **Few-shot prompting**: Teaching LLMs new tasks with just a few examples in the prompt; needed to adapt LLMs to dialogue understanding without fine-tuning; quick check: verify the prompt format and example quality
- **Task-oriented dialogue**: Systems designed to help users complete specific tasks; needed to define the evaluation scope and success criteria; quick check: confirm the business logic aligns with user goals
- **Dialogue state tracking**: Maintaining conversation context across turns; needed to handle multi-turn dialogues and corrections; quick check: verify state transitions match expected dialogue flows
- **Pass rate evaluation**: Measuring task completion success; needed to quantify system performance; quick check: ensure test cases cover edge cases and complex scenarios
- **Deterministic dialogue management**: Rule-based execution of business logic; needed to ensure reliable task completion; quick check: verify the business logic handles all required scenarios

## Architecture Onboarding
- **Component map**: User Message -> LLM Prompt Generator -> LLM -> Command Parser -> Dialogue Manager -> Business Logic -> Response Generator -> User
- **Critical path**: User message flows through LLM-based understanding to command parsing, then through deterministic dialogue management for state tracking and business logic execution
- **Design tradeoffs**: Uses LLM for flexible understanding while keeping execution deterministic to balance natural language capabilities with reliability; trades potential LLM inference costs for reduced development complexity
- **Failure signatures**: Incorrect command parsing from LLM, business logic not handling edge cases, state tracking errors in dialogue manager, prompt examples not covering diverse utterance patterns
- **First experiments**: 1) Test LLM understanding with diverse utterance variations, 2) Verify dialogue manager correctly handles state transitions, 3) Validate business logic produces correct responses for all test scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single dataset (WOZ 2.0) and restaurant reservation scenario, limiting generalizability
- Performance depends on LLM choice and prompt engineering, though specific configurations not detailed
- Lacks statistical significance testing or confidence intervals for reported performance metrics

## Confidence
- LLM-based dialogue understanding superiority (High): Well-supported by 95.8% vs 47.9% pass rate comparison
- Development efficiency benefits (Medium): Line count metric provided but doesn't capture full development complexity
- Handling of complex dialogue phenomena (Medium): Demonstrated but limited to test set scope

## Next Checks
1. Evaluate system across multiple diverse task-oriented dialogue datasets to assess domain generalization
2. Conduct ablation studies varying LLM model size, prompt engineering, and temperature settings
3. Perform user studies with real human users to validate high pass rate translates to genuine satisfaction and task completion