---
ver: rpa2
title: Two-way Deconfounder for Off-policy Evaluation in Causal Reinforcement Learning
arxiv_id: '2412.05783'
source_url: https://arxiv.org/abs/2412.05783
tags:
- uni00000013
- unmeasured
- policy
- confounders
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses off-policy evaluation (OPE) in reinforcement
  learning when unmeasured confounders are present. The authors propose a two-way
  unmeasured confounding assumption that categorizes latent confounders into trajectory-specific
  and time-specific groups, relaxing the restrictive one-way assumption while maintaining
  estimability.
---

# Two-way Deconfounder for Off-policy Evaluation in Causal Reinforcement Learning

## Quick Facts
- arXiv ID: 2412.05783
- Source URL: https://arxiv.org/abs/2412.05783
- Reference count: 40
- Authors: Shuguang Yu; Shuxing Fang; Ruixin Peng; Zhengling Qi; Fan Zhou; Chengchun Shi
- Primary result: Proposes two-way unmeasured confounding assumption for off-policy evaluation in RL with superior performance over existing methods

## Executive Summary
This paper addresses the challenge of off-policy evaluation (OPE) in reinforcement learning when unmeasured confounders are present. The authors introduce a novel two-way unmeasured confounding assumption that categorizes latent confounders into trajectory-specific and time-specific components, relaxing the restrictive one-way assumption while maintaining estimability. They develop a two-way deconfounder algorithm that uses a neural tensor network to jointly learn the unmeasured confounders and system dynamics, enabling consistent policy value estimation. The method is theoretically grounded with finite-sample error bounds and demonstrates superior performance on both simulated and real-world datasets, particularly in medical applications using the MIMIC-III dataset.

## Method Summary
The proposed method introduces a two-way unmeasured confounding assumption that decomposes latent confounders into trajectory-specific and time-specific components. The authors develop a two-way deconfounder algorithm that uses a neural tensor network to jointly learn the unmeasured confounders and system dynamics. This enables construction of a model-based estimator for consistent policy value estimation in off-policy evaluation settings. The approach relaxes the restrictive one-way unmeasured confounding assumption while maintaining theoretical guarantees through finite-sample error bounds that establish consistency under appropriate conditions.

## Key Results
- The two-way deconfounder algorithm achieves lower mean squared errors compared to existing methods in off-policy value estimation
- Experiments demonstrate reduced bias in policy value estimation across both simulated and real-world datasets
- The method shows particular effectiveness in medical applications using the MIMIC-III dataset, with consistent improvements over baseline approaches

## Why This Works (Mechanism)
The two-way deconfounding approach works by relaxing the restrictive one-way unmeasured confounding assumption through decomposition of latent confounders into trajectory-specific and time-specific components. This separation allows for more flexible modeling of the underlying confounding structure while maintaining estimability. The neural tensor network architecture enables joint learning of both the unmeasured confounders and system dynamics, capturing complex interactions between observed and latent variables. By constructing a model-based estimator from this joint learning process, the method achieves consistent policy value estimation even in the presence of unmeasured confounding, with theoretical guarantees provided through finite-sample error bounds.

## Foundational Learning
- **Off-policy evaluation (OPE)**: Evaluating a policy using data collected from a different policy; needed to assess policy performance without running expensive or risky interventions; quick check: verify policy evaluation differs from policy optimization
- **Unmeasured confounding**: Hidden variables affecting both treatment and outcome; breaks standard causal inference assumptions; quick check: identify variables that could influence both state transitions and rewards
- **Trajectory-specific vs time-specific confounders**: Different temporal structures of confounding effects; trajectory confounders affect entire sequences while time confounders affect individual timesteps; quick check: map which confounders persist across time steps vs change within trajectories
- **Neural tensor networks**: Deep learning architecture for capturing multi-way interactions; enables joint learning of confounders and dynamics; quick check: verify tensor factorization captures appropriate interaction terms
- **Model-based OPE**: Using learned dynamics models for policy evaluation; allows counterfactual reasoning; quick check: confirm model can simulate alternative trajectories under different policies
- **Finite-sample error bounds**: Theoretical guarantees on estimation accuracy with limited data; provides confidence in method's practical applicability; quick check: verify conditions for consistency are satisfied in implementation

## Architecture Onboarding

Component map: Observed data -> Neural tensor network -> Learned confounders & dynamics -> Model-based estimator -> Policy value estimation

Critical path: Data preprocessing → Neural tensor network training → Confounder and dynamics learning → Model-based policy evaluation → Value estimation

Design tradeoffs: The method balances model complexity against estimation accuracy by using a neural tensor network that can capture complex interactions while maintaining theoretical guarantees. The two-way confounding assumption provides more flexibility than one-way approaches but requires careful specification of confounder structure. The model-based approach enables counterfactual reasoning but introduces potential model misspecification risks.

Failure signatures: Performance degradation when the trajectory-specific/time-specific confounder separation assumption is violated, overfitting when the neural tensor network is too complex relative to available data, and bias amplification when model misspecification occurs in the learned dynamics.

First experiments to run:
1. Validate the learned confounders by checking their predictive power for observed state-action patterns
2. Compare policy value estimates across different network architectures to assess sensitivity
3. Test the method on synthetic data with known confounding structure to verify theoretical guarantees

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- The method relies on strong assumptions about the structure of unmeasured confounders being separable into trajectory-specific and time-specific components
- The neural tensor network introduces additional complexity and potential overfitting risks, particularly with limited data
- Theoretical finite-sample error bounds depend on specific conditions that may be challenging to verify in practice

## Confidence
- **High confidence** in the mathematical formulation and theoretical framework of the two-way deconfounder algorithm
- **Medium confidence** in the practical applicability across diverse real-world scenarios
- **Low confidence** in the scalability and robustness when dealing with extremely high-dimensional state-action spaces

## Next Checks
1. Test the algorithm's performance on multiple diverse real-world datasets beyond the medical domain to assess generalizability
2. Conduct ablation studies to evaluate the impact of different network architectures and hyperparameters on estimation accuracy
3. Design experiments specifically targeting scenarios where the trajectory-specific and time-specific confounder separation assumption is violated to test method robustness