---
ver: rpa2
title: Relation-based Counterfactual Data Augmentation and Contrastive Learning for
  Robustifying Natural Language Inference Models
arxiv_id: '2410.20710'
source_url: https://arxiv.org/abs/2410.20710
tags:
- data
- learning
- sentence
- contrastive
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes relation-based counterfactual data augmentation
  and contrastive learning to improve the robustness of natural language inference
  models. The method generates counterfactual sentence pairs using token-level and
  sentence-level augmentation, then applies contrastive learning to explicitly learn
  the semantic differences between sentence pairs of different classes with similar
  contexts.
---

# Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models

## Quick Facts
- **arXiv ID**: 2410.20710
- **Source URL**: https://arxiv.org/abs/2410.20710
- **Authors**: Heerin Yang; Sseung-won Hwang; Jungmin So
- **Reference count**: 0
- **Primary result**: Relation-based counterfactual data augmentation and contrastive learning significantly improve NLI model robustness on counterfactually-revised datasets

## Executive Summary
This paper addresses the robustness limitations of natural language inference (NLI) models by proposing a novel approach that combines counterfactual data augmentation with relation-based contrastive learning. The method generates challenging training examples through token-level and sentence-level augmentation, then applies contrastive learning to explicitly teach models to distinguish semantic differences between sentence pairs of different classes with similar contexts. Experiments on counterfactually-revised and general NLI datasets demonstrate significant improvements in both model performance and robustness compared to baseline models and other robust text classification methods.

## Method Summary
The proposed method employs an iterative process where a generator model creates counterfactual premise/hypothesis sentences conditioned on original sentences and target labels, while a classifier evaluates these generated pairs and assigns confidence scores. Token-level augmentation substitutes nouns in premise/hypothesis sentences with synonyms, hyponyms, hypernyms, antonyms, or co-hyponyms using WordNet to generate entailment, neutral, or contradiction pairs. Sentence-level augmentation uses T5 to generate counterfactual sentences conditioned on original sentence and label, with confidence-based filtering (threshold τ=0.9) to ensure quality. Relation-based contrastive learning minimizes the distance between embeddings of original and same-label augmented pairs while maximizing distances to pairs of different classes, creating a more discriminative feature space for NLI classification.

## Key Results
- Significant improvement in accuracy on counterfactually-revised CF-SNLI test sets (Original, RP, RH, RP & RH) compared to baseline models
- Enhanced performance on general NLI datasets (SNLI test, MNLI dev-m, dev-mm) demonstrating broad applicability
- Outperforms other robust text classification methods while maintaining efficiency through iterative training of classifier and generator models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Relation-based contrastive learning explicitly teaches the model to distinguish semantic differences between sentence pairs of different classes that share similar contexts.
- Mechanism: The model learns to minimize the distance between embeddings of original sentence pairs and their counterfactual counterparts of the same class, while maximizing the distance to pairs of different classes. This creates a more discriminative feature space.
- Core assumption: The semantic difference between classes can be effectively captured by contrasting pairs with similar contexts but different labels.
- Evidence anchors:
  - [abstract] "apply contrastive learning to help the model learn the difference between sentence pairs of different classes with similar contexts"
  - [section] "the distance between the embedding vectors of the original and entailment pair is minimized, while the distances between the embedding vectors of the original and other pairs are maximized"
  - [corpus] Weak - most corpus papers focus on contrastive learning for images or general text, not specifically NLI with relation-based pairs
- Break condition: If the generated counterfactual pairs do not preserve semantic coherence or if the augmentation creates pairs that are too dissimilar from the original context.

### Mechanism 2
- Claim: Counterfactual data augmentation exposes the model to non-causal features that it might otherwise rely on, forcing it to learn more robust semantic patterns.
- Mechanism: By generating sentence pairs that have different labels but similar contexts through token substitution and conditional generation, the model is trained to focus on the actual semantic differences rather than spurious correlations like lexical overlap.
- Core assumption: The original model relies on non-causal features (e.g., lexical overlap) that do not generalize to counterfactually revised data.
- Evidence anchors:
  - [abstract] "although pre-trained language models show good performance on various natural language processing tasks, they often rely on non-causal features and patterns to determine the outcome"
  - [section] "NLI classifiers may learn that a sentence pair having significant lexical overlap is a sign that they are in an entailment relationship, which is not necessarily true"
  - [corpus] Assumption: Related work on robustness through data augmentation supports this general approach, though specific NLI relation-based methods are limited
- Break condition: If the augmentation methods generate sentence pairs that do not maintain the intended semantic relationship or if the model still relies on spurious features despite augmentation.

### Mechanism 3
- Claim: Iterative training of classifier and generator models creates high-quality counterfactual data that improves model robustness.
- Mechanism: The generator model creates hypothesis sentences conditioned on premise sentences and labels, while the classifier evaluates the generated pairs. Through multiple iterations, both models improve, leading to better quality counterfactual data for training.
- Core assumption: The quality of generated counterfactual data directly impacts the effectiveness of the contrastive learning approach.
- Evidence anchors:
  - [section] "We go through an iterative process where the augmented set becomes the train set which is used to train the classifier and the generator"
  - [section] "the generator model generates three sentences for each sentence pair in the original set. For the generated sentence pairs, we apply confidence-based filtering and drop samples with model confidence lower than a threshold τ"
  - [corpus] Assumption: Iterative self-training approaches are effective in other domains, but specific evidence for NLI relation-based generation is limited
- Break condition: If the iterative process does not converge or if the generated data quality degrades over iterations, leading to poor training signals.

## Foundational Learning

- Concept: Contrastive Learning
  - Why needed here: To explicitly teach the model to distinguish between semantic relationships by pulling together same-class pairs and pushing apart different-class pairs with similar contexts
  - Quick check question: What is the mathematical formulation of the contrastive loss used in this method, and how does it differ from standard supervised contrastive learning?

- Concept: Counterfactual Data Generation
  - Why needed here: To create challenging training examples that expose the model to non-causal features and force it to learn robust semantic patterns
  - Quick check question: How do token-level and sentence-level augmentation methods differ in their approach to generating counterfactual NLI pairs, and what are the trade-offs?

- Concept: Natural Language Inference (NLI)
  - Why needed here: Understanding the unique challenge of NLI where the relation between premise and hypothesis sentences is the target label, not just individual sentence semantics
  - Quick check question: What makes NLI different from standard text classification tasks, and why does this require special consideration for data augmentation and contrastive learning?

## Architecture Onboarding

- Component map: Pre-trained Language Model (BERT/RoBERTa) -> Token-level Augmentation Module -> Sentence-level Augmentation Module -> Classifier Model -> Generator Model -> Contrastive Learning Module -> Training Pipeline
- Critical path: Generator → Classifier → Augmentation → Contrastive Learning → Final Training
- Design tradeoffs: Token-level augmentation is more controlled but limited in diversity; sentence-level generation is more diverse but requires filtering for quality. The choice of augmentation method affects the quality of contrastive learning signals.
- Failure signatures: Poor performance on counterfactually revised datasets indicates the model still relies on spurious features; failure to improve on general NLI datasets suggests the contrastive learning signals are not effective.
- First 3 experiments:
  1. Implement token-level augmentation only and evaluate on CF-SNLI RP set to verify basic counterfactual generation works
  2. Add sentence-level augmentation with confidence filtering and compare performance to token-level only
  3. Implement relation-based contrastive learning with both augmentation methods and measure improvement over data augmentation alone

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed method vary with different threshold values (τ) in the confidence-based filtering step during sentence-level augmentation?
- Basis in paper: [explicit] The paper mentions that the results were not sensitive to τ unless a very low number was chosen, but does not provide a detailed analysis of performance across different τ values.
- Why unresolved: The paper only mentions that τ was empirically tuned to 0.9 without exploring the impact of different threshold values on model performance.
- What evidence would resolve it: Conducting experiments with varying τ values and analyzing the resulting model performance would provide insights into the optimal threshold for confidence-based filtering.

### Open Question 2
- Question: How would extending token-level augmentation to include word types other than nouns affect the quality and diversity of generated counterfactual data?
- Basis in paper: [inferred] The paper acknowledges that substituting words other than nouns for counterfactual data generation is left for future work, indicating that this aspect has not been explored.
- Why unresolved: The current method only substitutes nouns in the sentence, which may limit the diversity and quality of generated counterfactual data.
- What evidence would resolve it: Implementing token-level augmentation for various word types (e.g., verbs, adjectives) and evaluating the resulting model performance would determine the impact of extending augmentation beyond nouns.

### Open Question 3
- Question: Can the proposed method be effectively applied to create large-scale NLI datasets using inputs outside the original train set?
- Basis in paper: [explicit] The paper suggests that a possible future work could use the proposed methods to create a large number of NLI sentence pairs using inputs outside the train set.
- Why unresolved: The paper does not explore the feasibility or effectiveness of applying the method to external data sources for large-scale dataset creation.
- What evidence would resolve it: Conducting experiments to generate and evaluate NLI sentence pairs using external data sources, followed by assessing the model performance on these newly created datasets, would determine the method's applicability to large-scale dataset creation.

## Limitations

- Lack of ablation studies to isolate the individual contributions of token-level augmentation, sentence-level augmentation, and relation-based contrastive learning
- Limited evaluation scope focused primarily on CF-SNLI dataset variants without broader testing on diverse NLI datasets or other text classification tasks
- Absence of qualitative analysis of generated counterfactual pairs to verify semantic coherence and label correctness

## Confidence

- **High confidence**: The general approach of combining counterfactual data augmentation with contrastive learning is well-supported by existing literature on model robustness and has been successfully applied in other domains. The evaluation methodology using counterfactually-revised datasets is appropriate for testing robustness.

- **Medium confidence**: The specific implementation details for token-level and sentence-level augmentation are described adequately, but the lack of hyperparameter sensitivity analysis and the limited discussion of failure modes reduce confidence in the reproducibility and robustness of the approach.

- **Low confidence**: The claim that relation-based contrastive learning is specifically more effective than standard supervised contrastive learning for NLI is not well-supported. The paper does not provide comparisons to standard contrastive learning baselines or demonstrate why the relation-based approach is superior.

## Next Checks

1. **Ablation study**: Implement and evaluate each component (token-level augmentation, sentence-level augmentation, and relation-based contrastive learning) independently to quantify their individual contributions to model performance and robustness.

2. **Quality analysis of generated data**: Conduct a systematic evaluation of the generated counterfactual pairs, including human evaluation of semantic coherence, label correctness, and diversity. Analyze how the quality of generated data correlates with model performance.

3. **Comparison with standard contrastive learning**: Implement a standard supervised contrastive learning baseline using the same augmented data to determine whether the relation-based approach provides specific benefits for NLI beyond what standard contrastive learning achieves.