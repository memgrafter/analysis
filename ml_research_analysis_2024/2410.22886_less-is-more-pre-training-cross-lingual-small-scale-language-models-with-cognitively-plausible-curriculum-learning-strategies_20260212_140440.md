---
ver: rpa2
title: 'Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with
  Cognitively-Plausible Curriculum Learning Strategies'
arxiv_id: '2410.22886'
source_url: https://arxiv.org/abs/2410.22886
tags:
- language
- acquisition
- curricula
- curriculum
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether language acquisition theories can
  guide the development of better curriculum learning strategies for pre-training
  small-scale language models (SSLMs). The authors create age-ordered corpora of child-directed
  speech for four typologically distant languages and train SSLMs using three new
  objective curricula (GROWING, INWARDS, and MMM) that precisely replicate developmental
  sequences predicted by contemporary acquisition theories.
---

# Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies

## Quick Facts
- arXiv ID: 2410.22886
- Source URL: https://arxiv.org/abs/2410.22886
- Authors: Suchir Salhan; Richard Diehl Martinez; ZÃ©bulon Goriely; Paula Buttery
- Reference count: 14
- Primary result: SSLMs achieve comparable performance to LLMs despite using 25x fewer parameters and 6,000x fewer words

## Executive Summary
This paper investigates whether language acquisition theories can guide the development of better curriculum learning strategies for pre-training small-scale language models (SSLMs). The authors create age-ordered corpora of child-directed speech for four typologically distant languages and train SSLMs using three new objective curricula (GROWING, INWARDS, and MMM) that precisely replicate developmental sequences predicted by contemporary acquisition theories. Results show that fine-grained, language-specific curricula can outperform non-curriculum baselines, with the MMM (SEM) curriculum achieving statistically significant improvements in English and Chinese. Different strategies show varying effectiveness across languages, with MMM (UPOS) performing best in Japanese and Chinese, while INWARDS nearly matches non-curriculum performance in French.

## Method Summary
The study implements three acquisition-inspired objective curricula (GROWING, INWARDS, MMM) by modifying the masked language modeling objective to progressively introduce POS tag subsets according to developmental sequences predicted by acquisition theories. SSLMs with 8M parameters are trained on age-ordered Child-Directed Speech (CDS) corpora called MAO-CHILDES for four languages: French, German, Japanese, and Chinese. The curricula vary the order and sequence of masking using different tagsets, starting with high-frequency, semantically basic categories before introducing more complex syntactic structures. Performance is evaluated on minimal pair datasets specific to each language family.

## Key Results
- SSLMs achieve comparable performance to LLMs despite using approximately 25x fewer parameters and 6,000x fewer words
- MMM (SEM) curriculum achieves statistically significant improvements in English and Chinese over non-curriculum baselines
- Different curriculum strategies show varying effectiveness across languages, with MMM (UPOS) performing best in Japanese and Chinese while INWARDS nearly matches non-curriculum performance in French

## Why This Works (Mechanism)

### Mechanism 1
Fine-grained, language-specific curriculum learning outperforms non-curriculum baselines by aligning pre-training with developmental acquisition sequences. The study implements three objective curricula that precisely replicate developmental sequences predicted by acquisition theories. By varying the order and sequence of masking using different tagsets, the model progressively exposes learners to linguistic categories in the order they naturally acquire them, starting with high-frequency, semantically basic categories before introducing more complex syntactic structures.

### Mechanism 2
Semantic tagging enables more effective language-specific curricula than part-of-speech tagging alone. The MMM (SEM) curriculum adds semantic tags to the universal POS tagsets, creating more granular curriculum units that capture language-specific acquisition patterns. This allows the model to attend to semantic distinctions (like tense, aspect, and modality) that vary across languages and are acquired at different stages.

### Mechanism 3
Pre-training on child-directed speech (CDS) rather than general text enables better grammatical generalization despite using vastly less data. The SSLMs are trained on MAO-CHILDES, an age-ordered corpus of child-directed speech that approximates the volume and nature of input that first-language learners receive. This focused, developmentally appropriate data allows the models to develop grammatical capabilities comparable to much larger models trained on web-scale data.

## Foundational Learning

- **Concept: Curriculum Learning**
  - Why needed here: The paper investigates whether ordering training data according to linguistic difficulty, as predicted by acquisition theories, can improve SSLM performance compared to random ordering.
  - Quick check question: What is the key difference between static curriculum learning (like sorting by sentence length) and the dynamic, acquisition-inspired curricula implemented in this study?

- **Concept: Masked Language Modeling (MLM)**
  - Why needed here: All SSLMs use MLM as their primary training objective, and the curriculum strategies modify which tokens are masked and when, based on developmental stages.
  - Quick check question: How does the masking ratio change across curriculum stages, and why is this important for the acquisition-inspired objectives?

- **Concept: Cross-linguistic variation in acquisition**
  - Why needed here: The study trains and evaluates SSLMs on four typologically distant languages, finding that different curriculum strategies work better for different languages, suggesting language-specific rather than universal acquisition patterns.
  - Quick check question: Why might the MMM (UPOS) curriculum work well for Japanese and Chinese but not English, according to the acquisition theories?

## Architecture Onboarding

- **Component map**: Data preprocessing -> semantic tagging -> curriculum unit definition -> SSLM training with modified MLM objective -> evaluation on minimal pair datasets
- **Critical path**: The model processes age-ordered CDS data through progressive curriculum stages, with masking patterns determined by developmental sequences in POS/semantic tagsets, culminating in evaluation on language-specific minimal pair datasets
- **Design tradeoffs**: Smaller models with carefully ordered data vs. larger models with random data; language-specific curricula complexity vs. universal approaches; semantic tagging accuracy vs. simpler POS-based curricula
- **Failure signatures**: No improvement over non-curriculum baselines; curriculum strategy performs worse than random ordering; semantic tagging errors propagate through curriculum units
- **First 3 experiments**:
  1. Train a vanilla SSLM on MAO-CHILDES without curriculum to establish baseline performance
  2. Implement and test the MMM (UPOS) curriculum on English to verify the basic curriculum learning framework works
  3. Compare MMM (UPOS) vs. MMM (SEM) on Chinese to evaluate the benefit of semantic tagging for language-specific curricula

## Open Questions the Paper Calls Out

### Open Question 1
Does the MMM (SEM) curriculum's superior performance in English and Chinese indicate that semantic tag-based curricula are universally more effective than POS-only curricula across languages? The study only implements MMM (SEM) for English and Chinese, limiting cross-linguistic comparisons. Implementing MMM (SEM)-style curricula for French, German, Japanese, and other languages would resolve this question.

### Open Question 2
Why do acquisition-inspired curricula show inconsistent improvements across languages despite being based on universal acquisition theories? The authors observe that GROWING and INWARDS strategies improve performance in Chinese and Japanese but not in French, German, or English. Detailed linguistic analysis of CDS corpora across languages to identify structural differences would help explain this variation.

### Open Question 3
Does the superior performance of acquisition-inspired curricula in Japanese compared to LLMs indicate fundamental limitations in LLM training data or architecture for certain languages? The authors note that acquisition-inspired CL strategies in Japanese significantly outperform GPT-2 baselines. Comparative analysis of Japanese CDS versus Japanese web text characteristics would address this question.

## Limitations

- The MAO-CHILDES corpus represents only a limited sample of available child-directed speech across the four languages, with significant variation in corpus size and quality
- Semantic tagging accuracy varies across languages (91.4% for Chinese, 94.6% for English) and errors could propagate through curriculum units
- The study assumes acquisition theories accurately predict optimal developmental sequences for neural models without empirical validation of whether these particular sequences are superior to other possible orderings

## Confidence

- **High Confidence**: SSLMs can achieve comparable performance to LLMs using 25x fewer parameters and 6,000x fewer words (well-supported by empirical results across multiple languages)
- **Medium Confidence**: Acquisition-inspired curriculum learning outperforms non-curriculum baselines (supported by data but with varying effect sizes across languages and strategies)
- **Low Confidence**: The specific developmental sequences predicted by acquisition theories are the optimal ordering for neural language model training (relies on theoretical alignment rather than empirical validation)

## Next Checks

1. **Cross-linguistic curriculum transfer**: Train SSLMs on one language's CDS corpus using curriculum strategies developed for another language to test whether curriculum benefits are language-specific or if certain strategies generalize across typologically similar languages.

2. **Curriculum ablation study**: Systematically remove or randomize the developmental ordering within each curriculum strategy while keeping all other factors constant to determine whether the specific ordering or simply the progressive introduction of linguistic complexity drives the observed improvements.

3. **Scaling experiment**: Train larger SSLMs (e.g., 50M parameters) using the same curriculum strategies to determine whether the data efficiency gains scale with model size, or if the curriculum benefits are specific to the small-scale regime.