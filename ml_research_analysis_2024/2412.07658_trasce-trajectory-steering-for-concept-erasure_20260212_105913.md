---
ver: rpa2
title: 'TraSCE: Trajectory Steering for Concept Erasure'
arxiv_id: '2412.07658'
source_url: https://arxiv.org/abs/2412.07658
tags:
- concept
- diffusion
- prompts
- negative
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TraSCE, a training-free approach to concept
  erasure in diffusion models that guides the denoising trajectory away from generating
  unwanted content. The method uses a modified negative prompting formulation (Equation
  6) and localized loss-based guidance to steer the diffusion process, addressing
  the limitation of widely used negative prompting strategies.
---

# TraSCE: Trajectory Steering for Concept Erasure

## Quick Facts
- arXiv ID: 2412.07658
- Source URL: https://arxiv.org/abs/2412.07658
- Authors: Anubhav Jain; Yuya Kobayashi; Takashi Shibuya; Yuhta Takida; Nasir Memon; Julian Togelius; Yuki Mitsufuji
- Reference count: 40
- One-line primary result: TraSCE achieves training-free concept erasure in diffusion models, reducing attack success rates by up to 15% while maintaining image quality

## Executive Summary
This paper introduces TraSCE, a training-free approach to concept erasure in diffusion models that guides the denoising trajectory away from generating unwanted content. The method uses a modified negative prompting formulation and localized loss-based guidance to steer the diffusion process, addressing limitations of widely used negative prompting strategies. TraSCE achieves state-of-the-art results in removing harmful content while maintaining general image generation capabilities, with minimal impact on FID scores (17.41 vs 16.71 for standard generation).

## Method Summary
TraSCE is a training-free concept erasure method that operates entirely in the inference stage by modifying the diffusion sampling process. It combines a modified negative prompting formulation that uses unconditional guidance as a baseline instead of negative concept guidance, with a localized loss-based guidance that reduces semantic similarity between adversarial prompts and the negative concept. The approach requires no training, weight updates, or training data, making it practical for model owners to remove concepts. It successfully generalizes to erasing artistic styles and objects while maintaining general image generation capabilities.

## Key Results
- Reduces attack success rates by up to 15% on adversarial prompts designed to bypass safety measures
- Maintains minimal impact on FID scores (17.41 vs 16.71 for standard generation)
- Successfully erases artistic styles and objects while preserving general image quality
- Achieves training-free concept erasure without requiring weight updates or training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The modified negative prompting formulation (Equation 6) prevents trajectory guidance toward the concept being erased when input prompt matches the negative concept
- Mechanism: By using unconditional guidance (e∅) as baseline instead of the negative concept guidance (enp), the formulation ensures that when the input prompt equals the negative concept, the difference term becomes zero, leaving only unconditional guidance to steer toward training distribution
- Core assumption: Unconditional guidance approximates the training distribution and doesn't generate the erased concept
- Evidence anchors:
  - [abstract]: "we propose using a specific formulation of negative prompting instead of the widely used one"
  - [section 4]: "When ep is the same as enp, the trajectory will be guided towards enp, which is the concept we want to avoid. To fix this issue, we adopt the following formulation introduced by [19]"
  - [corpus]: No direct corpus evidence for this specific formulation, weak connection to related work
- Break condition: If unconditional guidance itself has learned to generate the erased concept, or if unconditional distribution doesn't adequately represent "safe" content

### Mechanism 2
- Claim: The localized loss-based guidance (Equation 7-8) reduces semantic similarity between adversarial prompts and the negative concept, making it harder for adversarial prompts to bypass defenses
- Mechanism: The Gaussian loss function Lt makes noise predictions for adversarial prompts (ep) and negative concepts (enp) converge when they are semantically similar, while having minimal effect when they are semantically distant
- Core assumption: Adversarial prompts tend to be semantically close to the concept being erased, and making their noise predictions similar will neutralize their effect
- Evidence anchors:
  - [abstract]: "we introduce a localized loss-based guidance that enhances the modified negative prompting technique by steering the diffusion trajectory"
  - [section 4]: "To address this issue, we introduce a localized loss-based guidance that further steers the trajectory to alleviate this issue"
  - [corpus]: No direct corpus evidence for this specific loss-based guidance approach
- Break condition: If adversarial prompts can find semantically distant but still effective prompts that bypass both the negative prompting and loss-based guidance

### Mechanism 3
- Claim: The combined approach achieves training-free concept erasure without requiring weight updates or training data
- Mechanism: By operating entirely in the inference stage through modified guidance strategies, the method can erase concepts without modifying model parameters or requiring concept-specific training data
- Core assumption: The diffusion model's learned representations contain sufficient information to guide away from concepts through appropriate conditioning alone
- Evidence anchors:
  - [abstract]: "Our proposed approach does not require any training, weight modifications, or training data"
  - [section 1]: "model owners are interested in quick fixes that (a) require little to no training; (b) allow easy removal of new concepts; and (c) do not impact the overall model performance"
  - [corpus]: No direct corpus evidence for training-free erasure without weight updates
- Break condition: If the concept being erased is too deeply embedded in the model's representations to be effectively steered away from through guidance alone

## Foundational Learning

- Concept: Diffusion model denoising process and classifier-free guidance
  - Why needed here: Understanding how diffusion models generate images and how guidance modifies the denoising trajectory is fundamental to grasping TraSCE's approach
  - Quick check question: How does the classifier-free guidance formula (Equation 4) modify the denoising trajectory compared to unconditional sampling?

- Concept: Adversarial prompting and jailbreaking in diffusion models
  - Why needed here: The paper's motivation centers on defending against adversarial prompts that bypass concept erasure methods
  - Quick check question: What distinguishes white-box from black-box adversarial attacks on diffusion models?

- Concept: Negative prompting in diffusion models
  - Why needed here: TraSCE builds upon and modifies negative prompting techniques for concept erasure
  - Quick check question: How does standard negative prompting differ from the modified formulation proposed in TraSCE?

## Architecture Onboarding

- Component map: Text prompt embedding (ep) and negative concept embedding (enp) -> Noise prediction network (ϵθ) with three forward passes -> Gaussian loss function for localized guidance -> Modified denoising trajectory avoiding the negative concept

- Critical path: Text prompt → embeddings → noise predictions (3 passes) → localized loss computation → trajectory modification → image generation

- Design tradeoffs:
  - Training-free vs. weight-update methods: Training-free approach is more practical but potentially less effective
  - Computational overhead: Additional noise prediction and gradient computation per timestep
  - Semantic flexibility: Can erase arbitrary concepts defined through text without requiring training data

- Failure signatures:
  - If adversarial prompts still succeed despite TraSCE, likely indicates the loss function isn't sufficiently penalizing semantic similarity
  - If general image quality degrades significantly, suggests the guidance is too aggressive
  - If certain concepts remain unerasable, may indicate those concepts are too fundamental to the model's representations

- First 3 experiments:
  1. Reproduce the baseline comparison on Ring-A-Bell dataset to verify the 15% reduction in attack success rate
  2. Test the ablation study by removing either the modified negative prompting or the localized loss-based guidance to quantify their individual contributions
  3. Evaluate the impact on COCO-30K dataset to verify minimal degradation in FID score (should be close to 16.71)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the localized loss-based guidance (Lt) specifically affect the quality of generated images for unrelated concepts?
- Basis in paper: [explicit] The paper mentions that the localized loss-based guidance is designed to minimize the distance between the noise predictions for the prompt and negative prompt when they are semantically close, but it should not affect the noise prediction when the prompt is not related to the negative prompt. It also states that directly minimizing the MSE loss function can negatively impact the perceptual quality on unrelated concepts.
- Why unresolved: While the paper shows visual examples of the impact of the MSE loss function on unrelated concepts, it does not provide a quantitative analysis of how the localized loss-based guidance affects the quality of generated images for unrelated concepts.
- What evidence would resolve it: A quantitative analysis of the impact of the localized loss-based guidance on the quality of generated images for unrelated concepts, such as measuring the FID score or other image quality metrics, would help to understand the trade-off between concept erasure and image quality.

### Open Question 2
- Question: How does the performance of TraSCE compare to other concept erasure methods when dealing with adversarial prompts that are designed to generate specific artistic styles or objects?
- Basis in paper: [inferred] The paper focuses on the performance of TraSCE in avoiding the generation of NSFW content and violence, and erasing artistic styles and objects. However, it does not provide a direct comparison of TraSCE with other concept erasure methods when dealing with adversarial prompts that are designed to generate specific artistic styles or objects.
- Why unresolved: While the paper shows that TraSCE outperforms other methods in avoiding the generation of NSFW content and violence, it does not provide a direct comparison of its performance with other methods when dealing with adversarial prompts that are designed to generate specific artistic styles or objects.
- What evidence would resolve it: A direct comparison of TraSCE with other concept erasure methods when dealing with adversarial prompts that are designed to generate specific artistic styles or objects, such as measuring the attack success rate or other relevant metrics, would help to understand the relative performance of TraSCE in this scenario.

### Open Question 3
- Question: How does the performance of TraSCE change when dealing with concepts that are more abstract or have a broader semantic meaning?
- Basis in paper: [inferred] The paper focuses on the performance of TraSCE in avoiding the generation of NSFW content and violence, and erasing artistic styles and objects. However, it does not provide any analysis of how the performance of TraSCE changes when dealing with concepts that are more abstract or have a broader semantic meaning.
- Why unresolved: While the paper shows that TraSCE is effective in erasing specific concepts, such as artistic styles and objects, it does not provide any analysis of how its performance changes when dealing with more abstract or broadly defined concepts.
- What evidence would resolve it: An analysis of the performance of TraSCE when dealing with more abstract or broadly defined concepts, such as measuring the attack success rate or other relevant metrics, would help to understand the limitations and potential of TraSCE in this scenario.

## Limitations
- Effectiveness against evolving adversarial prompt techniques remains uncertain as new bypass strategies may emerge
- Performance with abstract or broadly defined concepts has not been thoroughly evaluated
- Long-term stability of concept erasure across model updates and fine-tuning is unknown

## Confidence
- High Confidence: The training-free nature of TraSCE and its practical implementation without requiring model modifications or training data
- Medium Confidence: The effectiveness of the combined approach against current adversarial prompts, based on demonstrated attack success rate reductions
- Medium Confidence: The generalizability of the approach to artistic styles and object erasure, though this may be more limited than NSFW/violence concept erasure

## Next Checks
1. Design and test novel adversarial prompt strategies that attempt to bypass TraSCE's defenses, particularly focusing on semantically distant prompts that might evade the localized loss function

2. Apply TraSCE to diffusion models beyond Stable Diffusion v1.4 (e.g., SDXL, Midjourney) to verify the approach's effectiveness across different architectures and training datasets

3. Conduct extended testing over multiple generations of diffusion models to assess whether concepts remain effectively erased as models are updated or fine-tuned with new data