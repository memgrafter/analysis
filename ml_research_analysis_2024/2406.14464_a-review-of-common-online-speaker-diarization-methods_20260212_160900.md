---
ver: rpa2
title: A Review of Common Online Speaker Diarization Methods
arxiv_id: '2406.14464'
source_url: https://arxiv.org/abs/2406.14464
tags:
- speaker
- online
- diarization
- audio
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reviews online speaker diarization methods, which answer
  the question "who spoke when?" for streaming audio with low latency. The authors
  categorize methods into modular systems (which process subtasks separately) and
  end-to-end systems (which use a single neural network).
---

# A Review of Common Online Speaker Diarization Methods

## Quick Facts
- **arXiv ID**: 2406.14464
- **Source URL**: https://arxiv.org/abs/2406.14464
- **Reference count**: 40
- **Primary result**: Categorizes online speaker diarization methods into modular systems and end-to-end systems, identifying ongoing research challenges in balancing accuracy and latency.

## Executive Summary
This paper reviews online speaker diarization methods, which answer the question "who spoke when?" for streaming audio with low latency. The authors categorize methods into modular systems (which process subtasks separately) and end-to-end systems (which use a single neural network). Modular systems often use GMMs, i-vectors, or supervised clustering (e.g., UIS RNN), while end-to-end systems include frame-wise streaming approaches and online learning systems. Key metrics include DER (Diarization Error Rate) and JER (Jaccard Error Rate). Challenges include balancing accuracy and latency, limited training data, and handling multispeaker scenarios in EEND systems. The paper concludes that online speaker diarization is a growing field with ongoing research opportunities.

## Method Summary
The review systematically examines online speaker diarization approaches by categorizing them into modular systems and end-to-end systems. Modular systems process subtasks (SAD, segmentation, clustering) separately using techniques like GMMs, i-vectors, or supervised clustering algorithms. End-to-end systems employ single neural networks with frame-wise streaming or online learning capabilities. The review evaluates these methods based on key metrics including DER and JER, while identifying challenges such as the accuracy-latency tradeoff, training data scarcity, and multispeaker handling in streaming scenarios.

## Key Results
- Modular systems process subtasks separately, allowing independent optimization for latency and accuracy trade-offs
- Self-attention mechanisms in end-to-end systems improve speaker consistency over time compared to recurrent models
- Active window strategies effectively balance accuracy and latency by limiting historical context processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modular systems outperform end-to-end systems in early online diarization due to better handling of latency and flexibility in sub-task optimization.
- Mechanism: Modular systems process sub-tasks (SAD, segmentation, clustering) separately, allowing each component to be optimized independently for latency and accuracy trade-offs. This separation enables the use of lightweight, streaming-friendly algorithms for each stage.
- Core assumption: Latency can be effectively managed by optimizing individual sub-tasks rather than treating diarization as a monolithic problem.
- Evidence anchors:
  - [section] "Modular systems often use GMMs, i-vectors, or supervised clustering (e.g., UIS RNN), while end-to-end systems include frame-wise streaming approaches and online learning systems."
  - [section] "Dimitriadis et al. [15] have developed an online diarization system that uses i-vectors, among other things. The system consists of a SAD, a segmentation and a clustering component."
  - [corpus] Weak evidence - corpus does not directly compare modular vs. end-to-end performance in terms of latency.
- Break condition: If a single end-to-end model can be designed with low-latency streaming capabilities that outperform modular systems in both accuracy and latency.

### Mechanism 2
- Claim: Self-attention mechanisms in end-to-end systems improve speaker consistency over time compared to recurrent models.
- Mechanism: Self-attention allows the model to maintain long-range dependencies and speaker identity consistency without the vanishing gradient problems of RNNs, leading to more stable speaker assignments in streaming scenarios.
- Core assumption: The ability to attend to previous frames without sequential processing provides a memory advantage for maintaining speaker identity.
- Evidence anchors:
  - [section] "The decoder is implemented with non-autoregressive self-attention. On the one hand, self-attention ensures that the speaker labels remain consistent over time."
  - [section] "Self-attention based systems have a longer memory than, for example, an LSTM-based system."
  - [corpus] Weak evidence - corpus neighbors do not discuss self-attention mechanisms.
- Break condition: If the computational overhead of self-attention negates its benefits in low-latency streaming scenarios, or if alternative architectures achieve similar consistency with lower latency.

### Mechanism 3
- Claim: Active window strategies effectively balance accuracy and latency by limiting historical context processing.
- Mechanism: By constraining the amount of historical audio data processed at any given time, systems can maintain lower latency while still achieving reasonable accuracy through periodic reconciliation of speaker labels.
- Core assumption: Most speaker diarization errors occur within short time windows, making it unnecessary to process the entire audio history continuously.
- Evidence anchors:
  - [section] "However, in order to ensure online diarization, long audio files cannot be clustered on the entire history. Therefore, Dimitriadis et al. introduce an active window to limit the history."
  - [section] "Coria et al. [18] use an active window that is controlled by the parameter λ. The larger λ is selected, the higher the latency and the lower the DER."
  - [corpus] Weak evidence - corpus does not provide specific examples of active window implementations.
- Break condition: If the active window size becomes too restrictive, causing speaker label inconsistencies across window boundaries that cannot be reconciled effectively.

## Foundational Learning

- Concept: Gaussian Mixture Models (GMMs) for speaker representation
  - Why needed here: Understanding GMMs is crucial because they were the foundational approach for online speaker diarization and are still referenced in modular systems.
  - Quick check question: What is the primary advantage of using GMMs for speaker modeling in diarization systems?

- Concept: i-vectors and d-vectors for speaker embeddings
  - Why needed here: These vector representations replaced GMMs in many systems and are essential for understanding modern diarization approaches.
  - Quick check question: How do i-vectors address the intersession variability problem that affects GMM-based systems?

- Concept: Spectral clustering and its online variants
  - Why needed here: Clustering is a critical component in modular systems, and understanding both traditional and online variants is necessary for system design.
  - Quick check question: What is the main challenge when adapting spectral clustering for online speaker diarization?

## Architecture Onboarding

- Component map: SAD → Segmentation → Clustering → (Optional) Reconciliation
- Critical path: The clustering component typically determines the overall system latency, as it must process all available segments while maintaining streaming capabilities.
- Design tradeoffs: Accuracy vs. latency tradeoff requires careful selection of window sizes, model complexity, and whether to use modular or end-to-end approaches.
- Failure signatures: High DER with low latency suggests insufficient context; high latency with moderate DER indicates inefficient processing or reconciliation overhead.
- First 3 experiments:
  1. Implement a basic modular system with energy-based SAD and GMM clustering to establish baseline performance
  2. Add an active window mechanism to the baseline and measure the impact on latency and DER
  3. Replace GMM clustering with a simple online variant of spectral clustering and compare results against the baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can online speaker diarization systems effectively decouple accuracy from latency?
- Basis in paper: [explicit] The paper states that "there is a need for further research to decouple latency from accuracy" and provides examples of systems that improve DER with increased latency.
- Why unresolved: Current systems show improved performance with increased latency, but a specific latency threshold is reached where DER no longer significantly decreases. This indicates a fundamental tradeoff that hasn't been overcome.
- What evidence would resolve it: Development and demonstration of an online speaker diarization system that maintains high accuracy across a wide range of latency values, showing no significant performance degradation as latency is reduced.

### Open Question 2
- Question: What approaches can effectively address the training data scarcity problem for online speaker diarization?
- Basis in paper: [explicit] The paper identifies "missing training data" as a challenge and notes that current supervised systems need "a lot of high quality training data" which is limited in availability and expensive to annotate.
- Why unresolved: While some approaches like Turn to Diarize (which simplifies annotation) and online learning systems are mentioned, these are described as "good approaches" but not comprehensive solutions to the data scarcity problem.
- What evidence would resolve it: A novel approach that significantly reduces the dependency on large amounts of labeled training data while maintaining or improving performance, demonstrated through extensive experiments on multiple datasets.

### Open Question 3
- Question: How can end-to-end online speaker diarization systems handle a flexible number of speakers without prior knowledge of the maximum number?
- Basis in paper: [explicit] The paper identifies "problems with multispeaker in EEND systems" as a challenge, noting that "the maximum number of speakers in online speaker diarization cannot be determined in advance, as the audio file arrives as a stream and additional speakers may be added at a later point in time."
- Why unresolved: Current EEND systems either limit the number of speakers based on training data or require additional mechanisms like blockwise clustering, which move away from the core end-to-end concept.
- What evidence would resolve it: An EEND system that can dynamically handle any number of speakers in a streaming fashion without performance degradation, demonstrated through experiments with varying numbers of speakers beyond the training set.

## Limitations

- The review synthesizes existing literature but does not provide experimental validation of the claimed performance differences between modular and end-to-end systems.
- The mechanisms described are theoretical rather than empirically verified within this paper.
- The review focuses primarily on technical approaches without addressing real-world deployment constraints such as computational resource requirements, scalability, or robustness to environmental noise in streaming scenarios.

## Confidence

- **High confidence**: The categorization of online speaker diarization methods into modular and end-to-end systems is well-established in the literature and accurately reflected in the review.
- **Medium confidence**: The claimed advantages of self-attention mechanisms for maintaining speaker consistency over time are supported by citations but lack direct experimental validation in the review.
- **Low confidence**: The specific performance claims regarding latency-accuracy tradeoffs for different active window strategies are not quantified or validated in the review.

## Next Checks

1. **Empirical validation of modular vs. end-to-end latency tradeoffs**: Implement representative systems from both categories on identical hardware and measure actual latency-accuracy curves across varying window sizes and streaming conditions.

2. **Self-attention mechanism benchmarking**: Compare self-attention-based diarization systems against recurrent alternatives in controlled experiments measuring both speaker consistency metrics and computational overhead under realistic streaming constraints.

3. **Active window strategy optimization**: Conduct systematic ablation studies on active window parameters (λ) to quantify the precise relationship between window size, latency, and DER across different types of audio content (broadcast news, meetings, conversational speech).