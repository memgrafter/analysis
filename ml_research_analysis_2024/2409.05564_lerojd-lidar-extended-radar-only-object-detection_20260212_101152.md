---
ver: rpa2
title: 'LEROjD: Lidar Extended Radar-Only Object Detection'
arxiv_id: '2409.05564'
source_url: https://arxiv.org/abs/2409.05564
tags:
- point
- lidar
- object
- radar
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes two methods to transfer knowledge from lidar
  to radar for improving radar-only 3D object detection. First, a multi-stage training
  approach that progressively thins lidar point clouds and fine-tunes on radar.
---

# LEROjD: Lidar Extended Radar-Only Object Detection

## Quick Facts
- arXiv ID: 2409.05564
- Source URL: https://arxiv.org/abs/2409.05564
- Reference count: 40
- Primary result: Multi-stage training with progressive lidar point cloud thinning improves radar-only 3D object detection mAP by up to 4.2 percentage points

## Executive Summary
This paper addresses the challenge of improving radar-only 3D object detection by transferring knowledge from lidar data. The authors propose two complementary approaches: a multi-stage training method that progressively thins lidar point clouds and fine-tunes on radar data, and a knowledge distillation method that transfers learning from a lidar-trained teacher to a radar-trained student. Both methods are evaluated on the View-of-Delft dataset using PointPillars and DSVT-P architectures, demonstrating significant performance improvements for radar-only detection.

## Method Summary
The paper proposes two methods to transfer knowledge from lidar to radar for improving radar-only 3D object detection. The first approach uses multi-stage training with progressive lidar point cloud thinning, where the network is first trained on dense lidar data, then iteratively fine-tuned on increasingly sparse lidar point clouds mixed with radar data, and finally on radar-only data. The second approach employs knowledge distillation, where a teacher network trained on lidar data transfers its knowledge to a student network trained on radar data through distillation losses (logit, feature, and label-based). Both methods are demonstrated on PointPillars and DSVT-P architectures.

## Key Results
- Multi-stage training with voxel-based thinning improves mAP by up to 4.2 percentage points
- Knowledge distillation improves mAP by up to 3.9 percentage points
- Both methods are applicable to different object detector architectures without architectural modifications
- Voxel-based thinning strategy outperforms random and k-nearest neighbor approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-stage training with progressive lidar point cloud thinning improves radar-only object detection performance.
- Mechanism: The network is first trained on dense lidar point clouds, then iteratively fine-tuned on increasingly sparse lidar point clouds, and finally on radar-only data. This curriculum learning approach helps the network adapt to the sparsity of radar data.
- Core assumption: Knowledge learned from dense lidar point clouds can be transferred to sparse radar point clouds through progressive thinning.
- Evidence anchors:
  - [abstract] "Our results show significant performance gains of up to 4.2 percentage points in mean Average Precision with multi-stage training"
  - [section] "The main benefit of these approaches is their applicability to other 3D object detection networks without altering their architecture"
- Break condition: If the thinning process removes too much information too quickly, or if the radar data distribution is too different from the thinned lidar data, the transfer may fail.

### Mechanism 2
- Claim: Knowledge distillation from lidar to radar improves radar-only object detection.
- Mechanism: A teacher network trained on lidar data transfers its knowledge to a student network trained on radar data through distillation losses (logit, feature, and label-based).
- Core assumption: The teacher's predictions on radar data are meaningful and can guide the student's learning.
- Evidence anchors:
  - [abstract] "up to 3.9 percentage points with knowledge distillation by initializing the student with the teacher's weights"
  - [section] "We investigate two approaches to transfer knowledge from lidar-based to radar-based object detectors: a KD-based and a multi-stage training approach"
- Break condition: If the teacher's predictions on radar data are not accurate or meaningful, the distillation process may not be effective.

### Mechanism 3
- Claim: Mixing radar and lidar point clouds during training helps the network learn features relevant to radar-only detection.
- Mechanism: In the multi-stage training, lidar and radar point clouds are mixed in the early stages to condition the network on radar data while still benefiting from the density of lidar.
- Core assumption: Features learned from mixed lidar and radar data are useful for radar-only detection.
- Evidence anchors:
  - [section] "The thin-out of the lidar points remains the same and is mixed with the radar point cloud in each step"
  - [section] "This conditions the model on radar from the first step in order to prioritize features in the lidar point cloud that relate to a good object detection on radar-only data"
- Break condition: If the mixed data introduces too much noise or the radar and lidar features are too dissimilar, the network may not learn effectively.

## Foundational Learning

- Concept: Knowledge Distillation
  - Why needed here: To transfer knowledge from lidar to radar object detectors.
  - Quick check question: What are the three types of distillation losses used in this work?

- Concept: Curriculum Learning
  - Why needed here: To progressively adapt the network to the sparsity of radar data through multi-stage training.
  - Quick check question: How does the thin-out strategy affect the performance of the multi-stage training?

- Concept: Point Cloud Representation
  - Why needed here: Lidar and radar data are represented as point clouds, and understanding their structure is crucial for designing effective detection methods.
  - Quick check question: What are the challenges of using radar point clouds compared to lidar point clouds?

## Architecture Onboarding

- Component map: PointPillars/DSVT-P -> Multi-stage training/Knowledge distillation -> Radar-only detection
- Critical path: Train teacher on lidar data → Initialize student with teacher weights → Apply distillation losses → Fine-tune on radar data
- Design tradeoffs: Balancing point cloud density with sparsity simulation, choosing optimal thin-out strategy, configuring distillation loss weights
- Failure signatures: Poor performance on radar data, especially for small objects like pedestrians and cyclists
- First 3 experiments:
  1. Train the teacher on full lidar data and evaluate its performance
  2. Initialize the student with the teacher's weights and fine-tune on radar data (baseline)
  3. Apply knowledge distillation with logit loss and compare performance to the baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of cross-modal knowledge distillation vary with different teacher architectures or model families?
- Basis in paper: [inferred] The paper only tests knowledge distillation on PointPillars and DSVT-P, but does not explore whether certain teacher architectures perform better for transferring knowledge to radar detectors.
- Why unresolved: The study only uses two detector architectures, limiting the generalizability of the knowledge distillation findings.
- What evidence would resolve it: Systematic experiments comparing knowledge distillation performance using multiple teacher architectures (e.g., transformer-based, voxel-based, point-based) and analyzing which types yield the best student performance on radar data.

### Open Question 2
- Question: What is the optimal point cloud thinning strategy for radar object detection in different driving scenarios (e.g., urban, highway, parking lots)?
- Basis in paper: [explicit] The paper tests three thinning strategies (random, k-nearest neighbor, voxel-based) but does not analyze their performance in different driving scenarios or environments.
- Why unresolved: The evaluation focuses on overall dataset performance without considering scenario-specific effects of thinning strategies.
- What evidence would resolve it: Scenario-based analysis comparing the three thinning methods across different driving environments, measuring detection performance for each vehicle class and range bin in each scenario.

### Open Question 3
- Question: Can learnable point cloud thinning methods outperform the fixed strategies tested in this paper?
- Basis in paper: [explicit] The paper mentions in the conclusion that learnable point cloud thinning methods could be investigated in future work as they might overcome limitations of choosing a strict thinning strategy.
- Why unresolved: The paper only tests fixed thinning strategies and does not explore adaptive or learnable approaches.
- What evidence would resolve it: Comparative experiments between the tested fixed thinning strategies and learnable thinning methods, measuring detection performance improvements and computational efficiency trade-offs.

## Limitations

- Effectiveness is evaluated on a single dataset (View-of-Delft), limiting generalizability to other datasets and real-world scenarios
- No detailed analysis of computational overhead or inference time impact of the proposed methods
- Limited ablation studies on different thin-out strategies and distillation loss combinations

## Confidence

- **High confidence**: Multi-stage training with voxel-based thinning improves radar-only object detection performance (supported by experimental results showing up to 4.2 percentage points improvement in mAP)
- **Medium confidence**: Knowledge distillation from lidar to radar improves performance (supported by results showing up to 3.9 percentage points improvement, but effectiveness may depend on specific configurations)
- **Low confidence**: Mixing radar and lidar point clouds during training helps learn features relevant to radar-only detection (mechanism and impact not fully explained or validated)

## Next Checks

1. Evaluate the proposed methods on additional datasets with different radar and lidar sensor configurations to assess generalizability
2. Conduct an ablation study to determine the optimal combination of thin-out strategies and distillation loss configurations for maximum performance gain
3. Analyze the computational overhead and inference time impact of the multi-stage training and knowledge distillation approaches to assess their practical applicability in real-world scenarios