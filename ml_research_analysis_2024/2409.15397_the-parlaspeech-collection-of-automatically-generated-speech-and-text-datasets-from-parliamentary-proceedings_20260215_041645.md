---
ver: rpa2
title: The ParlaSpeech Collection of Automatically Generated Speech and Text Datasets
  from Parliamentary Proceedings
arxiv_id: '2409.15397'
source_url: https://arxiv.org/abs/2409.15397
tags:
- speech
- text
- data
- datasets
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ParlaSpeech, a novel approach for building
  large-scale speech-and-text-aligned datasets for less-resourced languages using
  parliamentary recordings and transcripts. The core challenge addressed is the lack
  of global alignment between long audio recordings and corresponding text transcripts,
  often complicated by incomplete data and differing orders.
---

# The ParlaSpeech Collection of Automatically Generated Speech and Text Datasets from Parliamentary Proceedings

## Quick Facts
- arXiv ID: 2409.15397
- Source URL: https://arxiv.org/abs/2409.15397
- Reference count: 29
- Primary result: Novel approach to build large-scale speech-and-text-aligned datasets from parliamentary recordings and transcripts for less-resourced languages

## Executive Summary
This paper presents ParlaSpeech, a method for building large-scale speech-and-text-aligned datasets for less-resourced languages using parliamentary recordings and transcripts. The core challenge addressed is the lack of global alignment between long audio recordings and corresponding text transcripts, often complicated by incomplete data and differing orders. The proposed method leverages modern end-to-end speech recognition systems and a refined text-to-text matching routine to align sequences effectively. Applied to Croatian, Polish, and Serbian, the approach yielded over 5,000 hours of aligned speech and text data. The datasets were released in three formats: FAIR repository entries, HuggingFace datasets, and linguistically annotated corpora, enabling diverse downstream applications such as ASR training and linguistic research.

## Method Summary
The ParlaSpeech method involves a pipeline of audio processing, text pre-processing, language modeling, speech recognition, matching of automatic to reference text, and post-processing. Audio is processed using a Wav2Vec2-XLS-R model to extract logits, followed by voice activity detection (VAD). Text transcripts are normalized and chunked for matching. A Kneser-Ney discounted 3-gram language model is trained on the transcripts and used to decode ASR outputs via pyctcdecode. The matching procedure employs sliding window histogram-based comparison with Levenshtein distance refinement to align ASR output to reference text. Post-processing includes filtering based on character error rates and yield rate optimization.

## Key Results
- Over 5,000 hours of aligned speech and text data generated for Croatian, Polish, and Serbian.
- Datasets released in FAIR repository entries, HuggingFace datasets, and linguistically annotated corpora.
- High yield rates achieved: Croatian data showed 74% yield rate for speeches and 80% for sentences.

## Why This Works (Mechanism)

### Mechanism 1
- Leveraging parliamentary proceedings provides high-quality, legally mandated transcripts paired with public recordings, enabling scalable multilingual dataset creation.
- Parliaments worldwide generate consistent, high-volume speech data under public domain mandates, offering rich metadata and speaker attributes.
- Core assumption: Parliaments maintain accessible recordings and transcripts in aligned formats for multiple languages.
- Evidence anchors:
  - [abstract] Mentions use of "parliamentary recordings and transcripts" as the data source.
  - [section 1.1] Describes parliaments as "a convenient source of speech and the corresponding text data for official languages" due to public domain availability.
- Break condition: Parliaments cease public release of recordings, or metadata becomes inconsistent or unavailable.

### Mechanism 2
- End-to-end speech recognition with n-gram language models bridges gaps between imperfectly transcribed speech and reference text.
- Wav2Vec2-XLS-R model outputs logits, which are decoded using a 3-gram language model trained on aligned transcripts, enabling robust matching despite transcription deviations.
- Core assumption: ASR models pre-trained on diverse data can generalize to parliamentary speech domains with limited adaptation.
- Evidence anchors:
  - [section 3.3] Describes training a "Knesser-Ney discounted 3-gram model with interpolation" for ASR decoding.
  - [section 2.2] Highlights use of "more modern end-to-end speech recognition system" to improve alignment accuracy.
- Break condition: ASR model fails to generalize to parliamentary speech characteristics or language-specific nuances.

### Mechanism 3
- Sliding window histogram-based matching with Levenshtein distance refinement aligns long speech and text sequences in large search spaces.
- Reference text is chunked with overlap, histograms of word frequencies are compared to ASR output, and best matches are selected via Levenshtein distance, iteratively refining gaps.
- Core assumption: Audio and text chunks can be reliably matched using statistical word frequency overlaps even when order varies.
- Evidence anchors:
  - [section 3.4] Details the matching procedure using "sliding window" and "Levenshtein distance."
  - [section 2.2] Explains adaptation of older methods to suit "data and the purpose of the final product."
- Break condition: Speech-text misalignment exceeds statistical matching thresholds or order discrepancies prevent convergence.

## Foundational Learning

- Concept: Forced alignment and Viterbi decoding
  - Why needed here: To map ASR-generated text back to audio timestamps with word-level precision.
  - Quick check question: What algorithm is used to align character sequences to Wav2Vec2 model outputs?

- Concept: Language modeling for ASR adaptation
  - Why needed here: To improve ASR decoding accuracy by incorporating domain-specific n-gram statistics from parliamentary transcripts.
  - Quick check question: Which smoothing technique is applied to the 3-gram model for robustness?

- Concept: Corpus query language and linguistic annotation
  - Why needed here: To enable advanced search and linguistic analysis of the final spoken corpora.
  - Quick check question: Which tool is used for morphological annotation of Croatian and Serbian sentences?

## Architecture Onboarding

- Component map: Wav2Vec2-XLS-R model → VAD → ASR decoding (pyctcdecode) → sliding window histogram matching → Levenshtein refinement → Viterbi forced alignment → JSONL output
- Critical path: Audio preprocessing → ASR decoding → Text matching → Alignment refinement → Dataset packaging
- Design tradeoffs: High ASR accuracy vs. computational cost; completeness vs. filtering strictness; metadata richness vs. release complexity
- Failure signatures: Low yield rates in alignment; high character error rates in matched segments; mismatched speaker metadata
- First 3 experiments:
  1. Test ASR decoding on a small sample of parliamentary audio with different n-gram orders.
  2. Validate sliding window matching thresholds using known aligned audio-text pairs.
  3. Measure character error rate impact of different text normalization rules.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the yield rate of the matching and filtering procedure for Serbian data, given that only 1000 out of 4500 audio files have been processed?
- Basis in paper: [explicit] The paper states that only 1000 audio files out of almost 4500 files have been processed for Serbian, and expresses hope to expand the dataset in future releases.
- Why unresolved: The paper does not provide yield rate statistics for the Serbian data, as processing is incomplete.
- What evidence would resolve it: Completion of the Serbian dataset processing and reporting of the yield rate similar to the Croatian data (74%).

### Open Question 2
- Question: How does the performance of the ASR systems trained on ParlaSpeech data compare to existing ASR systems for the same languages?
- Basis in paper: [inferred] The paper mentions ASR systems were trained on a subset of Croatian data in the initial run, but does not provide performance comparisons.
- Why unresolved: The paper focuses on dataset creation methodology rather than ASR system evaluation and benchmarking.
- What evidence would resolve it: Publication of ASR system evaluations using ParlaSpeech data compared to state-of-the-art systems for Croatian, Polish, and Serbian.

### Open Question 3
- Question: What is the impact of the filtering thresholds (60% CER for speeches, 10% CER for sentences, and 0.2 ratio) on the final dataset coverage and quality?
- Basis in paper: [explicit] The paper describes these specific filtering thresholds and mentions they were defined by manual inspection of data samples.
- Why unresolved: The paper does not provide quantitative analysis of how these thresholds affect dataset size, coverage, or downstream task performance.
- What evidence would resolve it: Sensitivity analysis showing dataset characteristics under different threshold values and their impact on downstream tasks.

### Open Question 4
- Question: How scalable is the ParlaSpeech approach to languages with significantly different parliamentary transcript structures or recording qualities?
- Basis in paper: [inferred] The paper emphasizes scalability and potential for many languages, but only demonstrates on three Slavic languages with similar structures.
- Why unresolved: The methodology's effectiveness for non-European languages or languages with different parliamentary traditions remains untested.
- What evidence would resolve it: Successful application of the method to diverse languages with different transcript formats and audio qualities, demonstrating consistent yield rates.

## Limitations
- Relies heavily on quality and completeness of parliamentary recordings and transcripts, which may vary significantly across languages and time periods.
- Alignment mechanism depends on effectiveness of Wav2Vec2-XLS-R model and n-gram language model, but lacks detailed error analysis across diverse linguistic phenomena.
- Scalability to languages with very limited parliamentary resources or to non-parliamentary domains remains uncertain.

## Confidence
- Dataset quality and yield (Medium): While the paper claims over 5,000 hours of aligned data, the evaluation focuses on yield rates rather than direct assessment of alignment accuracy or downstream task performance.
- Scalability and language coverage (Medium): The approach is demonstrated on three Slavic languages, but generalization to unrelated languages or low-resource settings is not empirically validated.
- Technical novelty of the alignment pipeline (High): The combination of modern ASR, refined matching, and forced alignment is well-justified and technically sound, though incremental in the broader literature.

## Next Checks
1. Conduct a systematic error analysis on a held-out subset of the aligned data, focusing on false positives, false negatives, and cases where alignment failed due to order discrepancies or transcript-audio mismatches.
2. Test the alignment pipeline on a non-parliamentary speech corpus (e.g., broadcast news or lectures) to assess domain robustness and identify potential failure modes.
3. Evaluate the utility of the aligned datasets for downstream ASR training by measuring word error rate improvements on a held-out test set for each target language.