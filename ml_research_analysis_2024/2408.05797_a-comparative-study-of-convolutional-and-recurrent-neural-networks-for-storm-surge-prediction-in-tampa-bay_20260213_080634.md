---
ver: rpa2
title: A Comparative Study of Convolutional and Recurrent Neural Networks for Storm
  Surge Prediction in Tampa Bay
arxiv_id: '2408.05797'
source_url: https://arxiv.org/abs/2408.05797
tags:
- data
- storm
- lstm
- surge
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compared three deep learning architectures (CNN-LSTM,
  LSTM, and 3D-CNN) for storm surge prediction in Tampa Bay using atmospheric data
  and historical water levels. The CNN-LSTM model achieved the best test performance
  with a loss of 0.010 and R2 score of 0.84, while the LSTM model showed the lowest
  training loss (0.007) but poorer generalization (test loss 0.014, R2 0.77).
---

# A Comparative Study of Convolutional and Recurrent Neural Networks for Storm Surge Prediction in Tampa Bay

## Quick Facts
- arXiv ID: 2408.05797
- Source URL: https://arxiv.org/abs/2408.05797
- Reference count: 28
- Primary result: CNN-LSTM model achieved test loss of 0.010 and R2 score of 0.84 for storm surge prediction in Tampa Bay

## Executive Summary
This study compares three deep learning architectures (CNN-LSTM, LSTM, and 3D-CNN) for storm surge prediction in Tampa Bay using atmospheric data and historical water levels. The CNN-LSTM model outperformed the other architectures, achieving a test loss of 0.010 and an R-squared score of 0.84. While the LSTM model achieved the lowest training loss (0.007), it exhibited poorer generalization with a test loss of 0.014 and R2 of 0.77. The 3D-CNN model showed reasonable performance but displayed instability under extreme conditions. A case study on Hurricane Ian demonstrated the CNN-LSTM model's superior robustness and accuracy in extreme scenarios.

## Method Summary
The study used CFSv2 atmospheric reanalysis data (wind components and surface pressure) at 0.25° resolution over a 3x3 degree area covering Tampa Bay, combined with NOAA tide gauge data from St. Petersburg station. Three deep learning models were developed: CNN-LSTM, LSTM, and 3D-CNN. Models were trained on data from 2011-2021, validated on 2021 data, and tested on the remainder. All models used Adam optimizer (learning rate 0.001), batch size 64, and were trained for 15 epochs. The CNN-LSTM architecture combined convolutional feature extraction with LSTM temporal modeling, while the 3D-CNN jointly modeled spatial and temporal dimensions.

## Key Results
- CNN-LSTM achieved the best test performance with loss of 0.010 and R2 score of 0.84
- LSTM showed lowest training loss (0.007) but poorer generalization (test loss 0.014, R2 0.77)
- 3D-CNN performed reasonably (test loss 0.011, R2 0.82) but displayed instability during extreme conditions
- CNN-LSTM demonstrated superior robustness in Hurricane Ian case study with -1.5 meter negative surge

## Why This Works (Mechanism)

### Mechanism 1
CNN-LSTM outperforms pure LSTM because CNNs extract spatial patterns from atmospheric data before temporal modeling. CNNs capture local spatial dependencies in wind/pressure grids, transforming them into feature maps that LSTMs can process sequentially, enabling better generalization. This works when storm surge is driven by spatial patterns in atmospheric forcing that are best captured by convolutional feature extraction before temporal modeling.

### Mechanism 2
3D-CNN shows instability during extreme conditions because spatiotemporal convolutions may overfit to normal patterns. 3D convolutions jointly model spatial and temporal dimensions, but may create unstable feature representations when encountering rare extreme events outside training distribution. This occurs when extreme surge events represent low-probability regions in the spatiotemporal feature space that 3D-CNNs cannot robustly represent.

### Mechanism 3
LSTM achieves lowest training loss but poor generalization due to overfitting to training patterns without spatial feature extraction. LSTM processes flattened atmospheric data directly, capturing temporal patterns but missing spatial structure that could improve generalization to unseen scenarios. This happens when spatial patterns in atmospheric forcing contain information that, when extracted by CNNs, improves model generalization to extreme events.

## Foundational Learning

- Concept: Spatial feature extraction with convolutional layers
  - Why needed here: Storm surge is driven by spatially distributed atmospheric forcing (wind and pressure fields) that contain patterns CNNs can extract
  - Quick check question: How would a 3x3 convolution kernel with stride 1 and padding 'same' transform a 15x15 input feature map?

- Concept: Temporal sequence modeling with LSTM layers
  - Why needed here: Storm surge prediction requires modeling how atmospheric conditions evolve over time to produce water level changes
  - Quick check question: What is the role of the forget gate in an LSTM cell when processing a time series?

- Concept: Feature fusion and concatenation
  - Why needed here: The model combines atmospheric data features with tidal predictions, requiring proper alignment and merging of different input streams
  - Quick check question: What dimensionality should the concatenated tensor have if tidal data has shape (36,1) and atmospheric features have shape (36,64)?

## Architecture Onboarding

- Component map: Input (36,15,15,3) → Conv2D(32) → Conv2D(16) → Dense(16) → LSTM(128) → Concat with tidal (36,1) → Dense reduction → Output (36,1)

- Critical path: Input → CNN feature extraction → LSTM temporal modeling → Concat with tidal data → Dense layers → Output

- Design tradeoffs:
  - CNN-LSTM vs LSTM: Spatial feature extraction improves generalization but adds computational cost
  - CNN-LSTM vs 3D-CNN: Separate spatial/temporal processing provides more control but may miss joint patterns
  - Dropout rates: Balance between preventing overfitting and maintaining learning capacity

- Failure signatures:
  - High training loss: Model capacity insufficient or learning rate too low
  - Low training loss but high validation loss: Overfitting, increase regularization
  - Unstable predictions during extremes: Model not robust to distribution shift, consider data augmentation
  - Poor temporal alignment: Check LSTM sequence length and input preprocessing

- First 3 experiments:
  1. Train LSTM-only baseline with identical hyperparameters to establish performance floor
  2. Add single Conv2D layer before LSTM to test spatial feature extraction benefit
  3. Compare 3D-CNN with CNN-LSTM on extreme event subset to isolate stability differences

## Open Questions the Paper Calls Out

### Open Question 1
How would a CNN-seq2seq architecture compare to the CNN-LSTM, LSTM, and 3D-CNN models tested in this study for storm surge prediction? The authors mention "Future research should consider exploring more advanced architectures such as CNN-seq2seq models to enhance the performance" in the conclusion, but did not evaluate these models.

### Open Question 2
Would incorporating additional atmospheric parameters beyond wind components and pressure improve model performance for extreme surge events? The models struggled with extreme events like Hurricane Ian, suggesting potential limitations in the input feature set, but only used u/v wind components and surface air pressure from CFSv2 data.

### Open Question 3
How sensitive are the model performances to the geographical extent and resolution of the input atmospheric data? The study used a specific 3x3 degree area (15x15 grid cells) at 0.25 degree resolution but did not explore sensitivity to different extents or resolutions.

## Limitations
- Architectural details for each model (layer configurations, filter sizes, activation functions) are not fully specified
- Preprocessing pipeline for tidal data fusion is not detailed
- Limited evaluation of extreme event robustness beyond single Hurricane Ian case study

## Confidence
- High Confidence: Comparative performance ranking between CNN-LSTM, LSTM, and 3D-CNN models under normal conditions
- Medium Confidence: Mechanisms explaining why CNN-LSTM outperforms other architectures
- Low Confidence: Stability analysis of 3D-CNN during extreme conditions

## Next Checks
1. Conduct ablation study by training CNN-only and LSTM-only variants to quantify individual contributions of spatial feature extraction and temporal modeling
2. Systematically evaluate all three models on multiple extreme surge events using metrics like prediction variance, error distribution, and correlation coefficients
3. Perform hyperparameter sensitivity analysis for each model, varying dropout rates, filter sizes, and layer depths to determine robustness of observed performance differences