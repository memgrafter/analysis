---
ver: rpa2
title: 'Diffusion Tuning: Transferring Diffusion Models via Chain of Forgetting'
arxiv_id: '2406.00773'
source_url: https://arxiv.org/abs/2406.00773
tags:
- diff-tuning
- diffusion
- knowledge
- forgetting
- pre-trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Diff-Tuning is a fine-tuning approach for diffusion models that
  addresses their fundamental transfer characteristics. It leverages the "chain of
  forgetting" phenomenon observed in diffusion models' reverse denoising process,
  where early denoising steps are more transferable than later ones.
---

# Diffusion Tuning: Transferring Diffusion Models via Chain of Forgetting

## Quick Facts
- arXiv ID: 2406.00773
- Source URL: https://arxiv.org/abs/2406.00773
- Authors: Jincheng Zhong; Xingzhuo Guo; Jiaxiang Dong; Mingsheng Long
- Reference count: 40
- Primary result: 26% improvement over standard fine-tuning on eight conditional generation tasks

## Executive Summary
Diff-Tuning is a fine-tuning approach for diffusion models that addresses their fundamental transfer characteristics by leveraging the "chain of forgetting" phenomenon observed in diffusion models' reverse denoising process. The method recognizes that early denoising steps are more transferable than later ones, and balances knowledge retention for general denoising with knowledge reconsolidation for domain-specific adaptation. Diff-Tuning achieves significant performance improvements over standard fine-tuning and accelerates convergence of ControlNet, while maintaining compatibility with existing parameter-efficient fine-tuning methods.

## Method Summary
Diff-Tuning addresses diffusion model transfer learning by exploiting the monotonic "chain of forgetting" trend where earlier denoising steps retain more general knowledge while later steps are more domain-specific. The method uses two complementary objectives: knowledge retention for early timesteps (preserving general denoising capabilities) and knowledge reconsolidation for later timesteps (adapting to domain-specific characteristics). It constructs a pre-sampled dataset from the pre-trained model to serve as a repository of retained knowledge, and applies timestep-weighted sampling and loss calculation using retention and reconsolidation coefficients that vary with timestep t.

## Key Results
- 26% improvement over standard fine-tuning on eight conditional generation tasks
- 24% acceleration of ControlNet convergence across five control conditions
- Compatible with parameter-efficient fine-tuning methods while maintaining consistent performance gains
- Pre-sampled datasets outperform using original training data for knowledge retention

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The "chain of forgetting" phenomenon indicates that early denoising steps in diffusion models are more transferable than later steps.
- **Mechanism:** The reverse denoising process has a monotonic property where noise at early timesteps (small t) is more uniformly distributed and less domain-specific, while later timesteps (large t) correspond to higher-level, domain-specific features that are more prone to forgetting during fine-tuning.
- **Core assumption:** The transferability of denoising steps follows a monotonic pattern where earlier steps retain more general knowledge while later steps are more task-specific.
- **Evidence anchors:** 
  - [abstract]: "monotonous chain of forgetting trend of transferability along the reverse process"
  - [section]: "we investigate the transferability within the reverse process of diffusion models" and "a monotonous chain of forgetting trend of transferability along the reverse process"
- **Break condition:** If the noise schedule or model architecture fundamentally changes the relationship between timestep and feature abstraction level, this monotonic pattern may not hold.

### Mechanism 2
- **Claim:** Knowledge retention for early denoising steps and knowledge reconsolidation for later steps improves transfer learning.
- **Mechanism:** Diff-Tuning uses two complementary objectives: retention coefficient ξ(t) decreases with t to preserve general denoising knowledge at early steps, while reconsolidation coefficient ψ(t) increases with t to emphasize domain-specific adaptation at later steps.
- **Core assumption:** The optimal transfer strategy requires different treatment of early versus late denoising steps based on their transfer characteristics.
- **Evidence anchors:**
  - [abstract]: "Diff-Tuning encourages the fine-tuned model to retain the pre-trained knowledge at the end of the denoising chain close to the generated data while discarding the other noise side"
  - [section]: "knowledge retention, which retains general denoising knowledge" and "knowledge reconsolidation, which tailors high-level shaping characteristics to specific downstream domains"
- **Break condition:** If the downstream task requires uniform adaptation across all timesteps, or if the domain mismatch is minimal, this differentiated approach may not provide benefits.

### Mechanism 3
- **Claim:** Pre-sampling from the pre-trained model creates a more effective knowledge retention dataset than using the original training data.
- **Mechanism:** The pre-sampled dataset captures the distilled knowledge of the pre-trained model's denoising capabilities, providing a more precise representation of what should be retained during fine-tuning.
- **Core assumption:** Generated samples from the pre-trained model better represent the knowledge that needs to be preserved than the original training distribution.
- **Evidence anchors:**
  - [section]: "Diff-Tuning constructs an augmented dataset bX s, pre-sampled from the pre-trained model. This dataset acts as a repository of the retained knowledge"
  - [section]: "Using the entire source dataset, which comprises 1.2M ImageNet images, results in suboptimal outcomes. This observation underscores that pre-sampled data serve as a more precise distillation of pre-trained knowledge"
- **Break condition:** If the pre-trained model's knowledge is not representative of the downstream task, or if the pre-sampling process introduces bias, this approach may be less effective.

## Foundational Learning

- **Concept:** Diffusion models reverse a noising process to generate data from random noise.
  - **Why needed here:** Understanding the reverse process is fundamental to grasping why different timesteps have different transfer characteristics.
  - **Quick check question:** What is the relationship between timestep t and the noise level in a diffusion model?

- **Concept:** Catastrophic forgetting in neural networks when fine-tuning on new tasks.
  - **Why needed here:** The paper addresses how Diff-Tuning mitigates forgetting specific to diffusion models' reverse process structure.
  - **Quick check question:** How does catastrophic forgetting typically manifest in neural network fine-tuning?

- **Concept:** Parameter-efficient fine-tuning (PEFT) methods for large models.
  - **Why needed here:** The paper demonstrates compatibility with existing PEFT approaches and discusses how Diff-Tuning enhances their transfer capability.
  - **Quick check question:** What is the primary goal of parameter-efficient fine-tuning methods?

## Architecture Onboarding

- **Component map:**
  - Pre-trained diffusion model (base architecture)
  - Knowledge retention dataset (pre-sampled from pre-trained model)
  - Two loss components: Lretention(θ) and Ladapation(θ)
  - Weighting functions ξ(t) and ψ(t) for timestep-dependent loss balancing
  - Optional integration with PEFT adapters

- **Critical path:**
  1. Pre-sample knowledge retention dataset from pre-trained model
  2. Initialize fine-tuning with pre-trained weights
  3. For each batch, compute both retention and adaptation losses
  4. Apply timestep-weighted sampling and loss calculation
  5. Update model parameters
  6. Monitor convergence and downstream task performance

- **Design tradeoffs:**
  - Memory overhead for storing pre-sampled knowledge retention dataset
  - Additional hyperparameters (ξ(t), ψ(t) functions and their parameters)
  - Potential complexity in integrating with existing PEFT methods
  - Computational cost of generating pre-sampled data

- **Failure signatures:**
  - Poor performance on early timesteps indicates inadequate knowledge retention
  - Poor performance on later timesteps indicates insufficient domain adaptation
  - Instability during training suggests improper weighting function design
  - Slow convergence may indicate suboptimal hyperparameter choices

- **First 3 experiments:**
  1. Compare standard fine-tuning vs Diff-Tuning on a simple downstream task with pre-sampled data size variation
  2. Test different weighting function forms (linear, polynomial, SNR-based) on representative dataset
  3. Evaluate compatibility with LoRA adapter by applying Diff-Tuning to LoRA-fine-tuned model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Diff-Tuning perform when applied to non-diffusion generative models like GANs or VAEs?
- Basis in paper: [inferred] The paper focuses exclusively on diffusion models and doesn't explore applicability to other generative model architectures
- Why unresolved: The theoretical framework and empirical validation are specific to diffusion models' unique reverse denoising process
- What evidence would resolve it: Direct experimental comparison of Diff-Tuning applied to GANs/VAEs versus their standard fine-tuning approaches on equivalent transfer learning tasks

### Open Question 2
- Question: What is the optimal size and composition of the pre-sampled dataset for knowledge retention across different downstream tasks?
- Basis in paper: [explicit] The paper shows that using the entire source dataset (ImageNet) performs suboptimally compared to smaller pre-sampled sets
- Why unresolved: The experiments only explore a limited range of sample sizes (5K to 200K) and don't systematically investigate optimal composition strategies
- What evidence would resolve it: Systematic ablation studies varying sample size, diversity metrics, and domain similarity between pre-sampled and target datasets

### Open Question 3
- Question: How does the choice of t-weighting function (τ in ψ(t) = t^τ) affect performance across different types of downstream tasks?
- Basis in paper: [explicit] The paper tests τ values from {0, 0.3, 0.5, 0.7, 1, 1.5} but doesn't analyze which tasks benefit from which settings
- Why unresolved: The analysis treats τ as a general hyperparameter without task-specific optimization or analysis of which tasks require more/less emphasis on later denoising steps
- What evidence would resolve it: Task-specific hyperparameter tuning across diverse downstream datasets with analysis of correlation between task characteristics and optimal τ values

### Open Question 4
- Question: Does Diff-Tuning's advantage persist when evaluated on more challenging or out-of-distribution transfer tasks?
- Basis in paper: [inferred] All experiments use datasets with varying similarity to ImageNet, but don't test extreme domain shifts
- Why unresolved: The paper doesn't include transfer tasks with significant domain mismatch (e.g., artistic styles, medical imaging, scientific data)
- What evidence would resolve it: Experiments transferring diffusion models to domains with minimal overlap in visual characteristics, semantics, or distribution to the pre-training data

### Open Question 5
- Question: How does Diff-Tuning scale with model size and complexity, particularly for the largest diffusion models?
- Basis in paper: [inferred] Experiments use moderate-sized models (DiT-XL-2-256x256) but don't test scaling behavior
- Why unresolved: The paper doesn't investigate whether the chain of forgetting phenomenon and Diff-Tuning's benefits hold for much larger models with more complex architectures
- What evidence would resolve it: Direct comparison of Diff-Tuning versus standard fine-tuning on increasingly large diffusion models (SD 1.5, SD XL, etc.) across the same set of downstream tasks

## Limitations
- The specific "chain of forgetting" mechanism lacks direct corpus evidence and validation across diverse diffusion model architectures
- The pre-sampling approach for knowledge retention, while showing improved results, lacks comparison with alternative knowledge distillation methods
- The analysis of how Diff-Tuning enhances PEFT methods' transfer capability is limited in scope and depth

## Confidence
- **High confidence**: The empirical results showing 26% improvement over standard fine-tuning on eight conditional generation tasks and 24% acceleration of ControlNet convergence are directly measured and reproducible with the provided methodology.
- **Medium confidence**: The theoretical framework of "chain of forgetting" and its relationship to timestep-dependent transferability is logically sound but relies on the assumption that noise level correlates with feature abstraction in a monotonic way across all diffusion model variants.
- **Medium confidence**: The claim that pre-sampled datasets better represent pre-trained knowledge than original training data is supported by experimental comparison but the underlying mechanism and generalizability require further investigation.

## Next Checks
1. **Cross-architecture validation**: Test Diff-Tuning on different diffusion model architectures (e.g., DDPM, DDIM, Score-based models) to verify the universality of the "chain of forgetting" phenomenon across varying noise schedules and model structures.

2. **Alternative weighting function evaluation**: Systematically compare the proposed SNR-based weighting functions against other candidate functions (polynomial, exponential, learned) to determine if the performance gains are specifically due to the SNR formulation or the general concept of timestep-dependent weighting.

3. **Knowledge retention dataset ablation**: Conduct controlled experiments comparing pre-sampled knowledge retention datasets against: (a) original training data, (b) knowledge distillation from the pre-trained model, and (c) synthetic data generated by the pre-trained model to isolate the contribution of the pre-sampling approach.