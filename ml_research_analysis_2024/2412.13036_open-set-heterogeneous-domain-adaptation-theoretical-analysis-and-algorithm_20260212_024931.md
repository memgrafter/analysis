---
ver: rpa2
title: 'Open-Set Heterogeneous Domain Adaptation: Theoretical Analysis and Algorithm'
arxiv_id: '2412.13036'
source_url: https://arxiv.org/abs/2412.13036
tags:
- target
- domain
- data
- vgg-19
- reset-50
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces open-set heterogeneous domain adaptation
  (OSHeDA), a challenging learning scenario where models must handle both feature
  space heterogeneity and novel classes in the target domain. The authors develop
  theoretical learning bounds that emphasize the importance of minimizing domain distances
  for known classes while maximizing separation from unknown classes.
---

# Open-Set Heterogeneous Domain Adaptation: Theoretical Analysis and Algorithm

## Quick Facts
- arXiv ID: 2412.13036
- Source URL: https://arxiv.org/abs/2412.13036
- Authors: Thai-Hoang Pham; Yuanlong Wang; Changchang Yin; Xueru Zhang; Ping Zhang
- Reference count: 40
- Primary result: Introduces RL-OSHeDA, a method that significantly outperforms existing approaches in OSHeDA scenarios across clinical, computer vision, and NLP datasets

## Executive Summary
This paper introduces open-set heterogeneous domain adaptation (OSHeDA), a challenging learning scenario where models must handle both feature space heterogeneity and novel classes in the target domain. The authors develop theoretical learning bounds that emphasize the importance of minimizing domain distances for known classes while maximizing separation from unknown classes. Based on this framework, they propose RL-OSHeDA, a representation learning method that simultaneously transfers knowledge between heterogeneous data sources and identifies novel classes. The method employs adversarial learning, pseudo-labeling with a two-stage training approach, and non-negative risk estimation.

## Method Summary
RL-OSHeDA addresses OSHeDA through a two-stage learning process. Stage 1 trains with classification loss on source and labeled target data to partially align domains. Stage 2 optimizes a full objective combining classification loss, domain alignment via MMD, unknown-class segregation, and open-set detection with non-negative risk estimation. The method uses pseudo-labeling to identify unknown samples in the target domain, treating the 1-λ fraction with smallest class probabilities as unknown. For clinical ECG data, ResNet-based architectures are employed, while feed-forward networks are used for non-ECG datasets.

## Key Results
- RL-OSHeDA achieves superior HOS scores compared to baselines (SSAN, STN, SCT, KPG, OPDA, PL, SL, DS3L) across diverse datasets
- The method demonstrates robust performance in clinical, computer vision, and NLP scenarios with varying feature dimensionalities
- Two-stage training with pseudo-labeling significantly improves open-set detection while maintaining known-class accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Minimizing JS divergence between known-class representations from source and target domains improves transfer performance.
- Mechanism: Adversarial learning using MMD aligns the marginal and label-conditional distributions of known classes across domains.
- Core assumption: Known-class distributions are similar enough across domains that alignment improves generalization without harming unknown-class separation.
- Evidence anchors:
  - [abstract]: "RL-OSHeDA transfer knowledge from source to target domains by aligning representations between source and target domains for known classes..."
  - [section 4.1]: "the model need to optimize three terms: (i) the source error, (ii) the open-set difference, and (iii) the distances of marginal and joint distributions between source domain and target domain conditioned on known labels"
  - [corpus]: Weak - corpus papers focus on source-free or open-set adaptation but don't directly address heterogeneous feature spaces with known-class alignment.
- Break condition: If unknown classes are too close to known classes in representation space, alignment may cause negative transfer.

### Mechanism 2
- Claim: Segregating unknown-class representations from known-class representations prevents misclassification of unknown samples.
- Mechanism: MMD-based distance maximization between centroids of known and unknown representations in target space.
- Core assumption: Unknown samples form a distinct cluster that can be separated from known classes in the shared representation space.
- Evidence anchors:
  - [abstract]: "RL-OSHeDA transfer knowledge from source to target domains by aligning representations between source and target domains for known classes while also enforcing the representations of novel class in target domains to move apart from the known classes"
  - [section 4.1]: "to avoid the large lower bound for the target error...we should increase the distance of the marginal distribution between the source domain and the unknown data in target domain"
  - [corpus]: Weak - corpus papers focus on open-set adaptation but don't explicitly address segregation in heterogeneous feature spaces.
- Break condition: If unknown samples are distributed throughout the representation space rather than forming a distinct cluster.

### Mechanism 3
- Claim: Non-negative risk estimation for open-set loss prevents excessively negative open-set difference during training.
- Mechanism: Losd is implemented as max(0, empirical open-set difference) to prevent the model from pushing known-class representations too far from unknown-class representations.
- Core assumption: The optimal open-set difference is 0, but deep networks may make it excessively negative without constraint.
- Evidence anchors:
  - [abstract]: "RL-OSHeDA optimizes a non-negative risk estimator for open-set and employs pseudo labeling to enrich the labeled data"
  - [section 5.1]: "Due to the flexibility of deep neural networks, this term can become excessively negative during training and adversely affect model performance. To address this issue, we implement Losd as a non-negative risk estimator"
  - [corpus]: Weak - corpus papers don't mention non-negative risk estimation in the context of heterogeneous domain adaptation.
- Break condition: If the constraint is too restrictive and prevents necessary separation between known and unknown classes.

## Foundational Learning

- Concept: Jensen-Shannon divergence
  - Why needed here: JS divergence is used as the statistical distance measure between source and target domains in the theoretical analysis and adversarial learning objectives.
  - Quick check question: What is the relationship between JS divergence and KL divergence, and why is JS divergence symmetric?

- Concept: Maximum Mean Discrepancy (MMD)
  - Why needed here: MMD is used as an alternative to JS divergence for aligning distributions in the practical implementation, avoiding the need for discriminators that scale with class count.
  - Quick check question: How does MMD measure the distance between distributions, and what kernel is typically used in practice?

- Concept: Natarajan dimension
  - Why needed here: Natarajan dimension appears in the finite-sample learning bounds to characterize the complexity of the hypothesis class with multiple labels.
  - Quick check question: How does Natarajan dimension generalize VC dimension to multi-class classification, and what's its relationship to Rademacher complexity?

## Architecture Onboarding

- Component map: fs (source→shared) -> ft (target→shared) -> h (shared→output)
- Critical path:
  1. Stage 1: Optimize Lcls to partially align source and target
  2. Stage 2: Optimize full objective L with pseudo-labels
  3. Inference: Use argmax across all classes (including unknown)

- Design tradeoffs:
  - MMD vs adversarial JS divergence: MMD avoids discriminator scaling issues but may be less precise
  - Pseudo-label quality vs quantity: Higher thresholds improve quality but reduce quantity
  - Known vs unknown separation: Too much separation may hurt known-class performance

- Failure signatures:
  - Known-class accuracy drops significantly: Possible over-separation of unknown class
  - Unknown-class recall remains low: Possible insufficient separation or poor pseudo-labeling
  - Training instability: Possible learning rate or stage transition issues

- First 3 experiments:
  1. Ablation: Remove Lseg and observe known-class performance vs unknown detection
  2. Hyperparameter sweep: Vary pseudo-label threshold and observe trade-off
  3. Visualization: t-SNE of representations to verify known-class alignment and unknown-class segregation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RL-OSHeDA scale with the number of unknown classes in the target domain?
- Basis in paper: [explicit] The paper notes that in experiments, 4-6 out of 8-12 shared classes were designated as unknown classes across datasets.
- Why unresolved: The paper only tested with a fixed proportion of unknown classes and did not systematically vary this parameter.
- What evidence would resolve it: Experiments varying the percentage of unknown classes from 10% to 90% while measuring HOS scores.

### Open Question 2
- Question: What is the impact of different pseudo-labeling strategies on the performance of RL-OSHeDA?
- Basis in paper: [explicit] The paper describes their specific pseudo-labeling approach in Section 5.2 but does not compare it to alternatives.
- Why unresolved: Only one pseudo-labeling strategy was tested, leaving questions about optimal methods.
- What evidence would resolve it: Comparison of multiple pseudo-labeling strategies (e.g., entropy-based, distance-based, uncertainty-based) on the same datasets.

### Open Question 3
- Question: How does RL-OSHeDA perform when the feature space heterogeneity is extreme (e.g., completely different feature dimensions)?
- Basis in paper: [inferred] The paper uses datasets with different feature dimensions but doesn't test extreme cases of heterogeneity.
- Why unresolved: All tested datasets had relatively similar feature dimensionalities (ranging from 64 to 4096).
- What evidence would resolve it: Experiments with feature spaces having vastly different dimensions (e.g., 10 vs 10000) or completely different feature types.

## Limitations
- Theoretical analysis assumes bounded feature spaces and may not fully capture real-world heterogeneous domain adaptation complexity
- Empirical evaluation relies on synthetic unknown classes created by withholding known source classes rather than truly novel categories
- Two-stage training introduces hyperparameters (pseudo-label threshold λ, stage transition timing) that significantly impact performance but are not thoroughly explored

## Confidence
- Known-class alignment (Mechanism 1): Medium-High
- Unknown-class segregation (Mechanism 2): Low-Medium
- Non-negative risk estimation (Mechanism 3): Low-Medium

## Next Checks
1. **Ablation study**: Remove Lseg and evaluate the trade-off between known-class accuracy and unknown-class detection to verify the necessity of explicit segregation.
2. **Robustness analysis**: Test performance with varying proportions of unknown samples and different unknown class distributions to assess real-world applicability.
3. **Theoretical bounds**: Investigate whether the learning bounds tighten under more realistic assumptions about feature space heterogeneity and unknown class distributions.