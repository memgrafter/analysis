---
ver: rpa2
title: A Framework for Evaluating LLMs Under Task Indeterminacy
arxiv_id: '2411.13760'
source_url: https://arxiv.org/abs/2411.13760
tags:
- evaluation
- human
- arxiv
- task
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the issue of task indeterminacy in LLM evaluations,
  where ambiguous or vague instructions lead to multiple correct responses. The authors
  develop a framework using a causal directed acyclic graph to disentangle the relationships
  between task specification, human ratings, and LLM responses.
---

# A Framework for Evaluating LLMs Under Task Indeterminacy

## Quick Facts
- arXiv ID: 2411.13760
- Source URL: https://arxiv.org/abs/2411.13760
- Authors: Luke Guerdan; Hanna Wallach; Solon Barocas; Alexandra Chouldechova
- Reference count: 40
- Key outcome: This paper addresses the issue of task indeterminacy in LLM evaluations, where ambiguous or vague instructions lead to multiple correct responses. The authors develop a framework using a causal directed acyclic graph to disentangle the relationships between task specification, human ratings, and LLM responses. They propose a method for estimating an error-adjusted performance interval given partial knowledge about indeterminate items in the evaluation corpus. A synthetic experiment shows that evaluations using the "gold label" assumption underestimate true LLM performance under indeterminacy.

## Executive Summary
This paper introduces a novel framework for evaluating large language models (LLMs) under task indeterminacy, addressing a critical gap in current evaluation practices. When evaluation tasks are ambiguous or vague, multiple correct responses may exist, but standard evaluation methods using aggregated "gold labels" fail to account for this indeterminacy and systematically underestimate LLM performance. The authors propose a causal directed acyclic graph (DAG) approach to model the evaluation pipeline, explicitly representing the relationships between task specifications, human ratings, and LLM responses. They demonstrate through synthetic experiments that the gold label assumption leads to performance underestimation, and propose practical methods for estimating error-adjusted performance bounds using partial knowledge about indeterminate items.

## Method Summary
The authors develop a framework using a causal directed acyclic graph (DAG) to model the LLM evaluation pipeline, disentangling the relationships between task specification, human ratings, and LLM responses. The core methodology involves generating synthetic data consistent with the DAG structure, implementing gold label evaluation approaches, and proposing error-adjusted bounds (prevalence and partition bounds) that account for task indeterminacy. The framework requires characterizing indeterminate items through valid response sets and estimating performance intervals based on partial knowledge about indeterminacy prevalence. The synthetic experiment compares gold label evaluation against true performance, demonstrating systematic underestimation when indeterminacy is present.

## Key Results
- The gold label assumption underestimates true LLM performance when tasks have multiple valid responses
- Performance underestimation increases with the proportion of indeterminate items in the evaluation corpus
- Prevalence bounds and partition bounds provide methods for estimating error-adjusted performance intervals using partial knowledge about indeterminacy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using a directed acyclic graph (DAG) to model the LLM evaluation pipeline enables explicit disentanglement of sources of variation in human ratings.
- Mechanism: The DAG maps causal relationships between task specification (T), human ratings (YR), LLM responses (YL), and performance metrics (M), allowing researchers to identify how ambiguity and vagueness propagate through the evaluation system.
- Core assumption: The evaluation pipeline can be accurately represented as a causal DAG where nodes represent observable variables and latent factors.
- Evidence anchors:
  - [abstract] "Our framework disentangles the relationships between task specification, human ratings, and LLM responses in the LLM evaluation pipeline."
  - [section] "Our framework, shown in Figure 1, uses a DAG to describe how task specification, human ratings, and LLM responses affect model performance."
  - [corpus] Weak - no direct corpus evidence for DAG approach; this appears to be novel methodology.
- Break condition: If the causal relationships between components are non-linear or involve feedback loops that cannot be captured in a DAG structure.

### Mechanism 2
- Claim: The gold label assumption underestimates true LLM performance when tasks are indeterminate.
- Mechanism: When items have multiple correct responses (indeterminate), comparing LLM outputs to a single aggregated gold label creates a systematic bias by ignoring valid alternative responses.
- Core assumption: Task indeterminacy exists and can be characterized by multiple valid response sets (VRS) for some items.
- Evidence anchors:
  - [abstract] "Using our framework, we conduct a synthetic experiment showing that evaluations that use the 'gold label' assumption underestimate the true performance."
  - [section] "Figure 2 shows that evaluations that use the gold label assumption underestimate the true performance. Furthermore, the magnitude of the evaluation bias increases as the proportion of indeterminate items in the evaluation corpus increases."
  - [corpus] Weak - no direct corpus evidence for this specific underestimation claim; based on synthetic experiment.
- Break condition: If task indeterminacy is rare or if the VRS can be accurately estimated without significant additional cost.

### Mechanism 3
- Claim: Performance intervals can be estimated using partial knowledge about indeterminate items through prevalence bounds and partition bounds.
- Mechanism: By estimating the proportion of indeterminate items (prevalence bound) or partitioning the corpus into determinate and indeterminate subsets (partition bound), researchers can bound true performance without needing complete VRS information.
- Core assumption: Partial information about indeterminacy is easier to obtain than complete VRS information for all items.
- Evidence anchors:
  - [abstract] "We also provide a method for estimating an error-adjusted performance interval given partial knowledge about indeterminate items in the evaluation corpus."
  - [section] "The prevalence bound uses an estimate of the proportion of indeterminate items to construct a performance interval... The partition bound is obtained by splitting the evaluation corpus into two subsets: determinate and indeterminate."
  - [corpus] Weak - no direct corpus evidence for these specific bounding methods; appears to be proposed methodology.
- Break condition: If partial knowledge about indeterminacy cannot be reliably obtained or if the bounds are too wide to be practically useful.

## Foundational Learning

- Concept: Causal Directed Acyclic Graphs (DAGs)
  - Why needed here: The framework relies on DAGs to model the evaluation pipeline and disentangle sources of variation. Understanding DAG structure and causal inference is essential for implementing and extending this framework.
  - Quick check question: What are the key assumptions required for a causal DAG to validly represent a system, and how might these assumptions be violated in LLM evaluation contexts?

- Concept: Task Indeterminacy and Valid Response Sets
  - Why needed here: The framework centers on task indeterminacy - when items have multiple correct responses. Understanding how to characterize and measure indeterminacy is crucial for applying the framework.
  - Quick check question: How would you distinguish between ambiguity (multiple interpretations) and vagueness (unclear boundaries) in a given task specification, and why does this distinction matter for evaluation?

- Concept: Performance Interval Estimation
  - Why needed here: The framework proposes bounding true performance using partial information. Understanding interval estimation and uncertainty quantification is necessary for implementing these methods.
  - Quick check question: What are the tradeoffs between prevalence bounds and partition bounds in terms of required information and precision of the resulting performance intervals?

## Architecture Onboarding

- Component map: Task specifications (T) -> Indeterminacy assessment -> Performance calculation -> Bound estimation
- Critical path: Task specification → Indeterminacy assessment → Performance calculation → Bound estimation
- Design tradeoffs: Complete VRS estimation (accurate but expensive) vs. partial knowledge bounds (approximate but practical)
- Failure signatures: Overestimation of performance bounds, failure to detect indeterminacy, computational inefficiency with large corpora
- First 3 experiments:
  1. Implement the synthetic experiment from Figure 2 to reproduce the underestimation result
  2. Apply the framework to a small evaluation corpus with known indeterminacy to test bound accuracy
  3. Compare prevalence bounds vs. partition bounds on a corpus with varying levels of indeterminacy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively measure and quantify the prevalence of task indeterminacy in real-world LLM evaluation datasets?
- Basis in paper: [explicit] The authors propose using crowdsourcing techniques to estimate the proportion of indeterminate items in an evaluation corpus, but do not provide a detailed methodology for implementation.
- Why unresolved: The paper identifies the need for this measurement but does not provide concrete implementation details or validation of this approach.
- What evidence would resolve it: A detailed methodology for using crowdsourcing to measure indeterminacy prevalence, including validation studies showing accuracy and reliability compared to ground truth.

### Open Question 2
- Question: How does task indeterminacy affect the reliability and validity of LLM evaluations beyond the performance metrics discussed in this paper?
- Basis in paper: [inferred] The authors mention that their framework is limited to forced-choice NLP tasks and does not comprehensively assess evaluation reliability and validity.
- Why unresolved: The paper focuses on performance metrics but does not explore broader implications for evaluation design and interpretation.
- What evidence would resolve it: Empirical studies showing how indeterminacy affects different aspects of evaluation quality (e.g., construct validity, test-retest reliability) across various task types.

### Open Question 3
- Question: Can the proposed framework be extended to handle more complex task types beyond forced-choice questions, such as open-ended tasks or multi-step reasoning problems?
- Basis in paper: [explicit] The authors acknowledge that their framework is limited to forced-choice NLP tasks and does not cover more open-ended tasks.
- Why unresolved: The paper provides a clear framework for one type of task but does not address how to generalize it to other task types.
- What evidence would resolve it: A modified framework that can handle different task types, with case studies demonstrating its application and effectiveness.

## Limitations
- The framework's effectiveness depends heavily on the ability to accurately characterize task indeterminacy and valid response sets, which remains challenging in practice.
- The synthetic experiment demonstrates theoretical advantages but lacks real-world validation on actual evaluation corpora.
- The proposed bounds (prevalence and partition) require partial knowledge about indeterminacy that may itself be difficult to obtain reliably.

## Confidence
- **High confidence**: The core insight that task indeterminacy affects evaluation accuracy and that the gold label assumption can underestimate performance. This is supported by both theoretical reasoning and synthetic experiment results.
- **Medium confidence**: The proposed framework structure using causal DAGs for modeling the evaluation pipeline. While methodologically sound, practical implementation challenges and real-world validation are needed.
- **Low confidence**: The specific implementation details for prevalence and partition bounds, as well as their practical utility across different types of evaluation tasks and corpora.

## Next Checks
1. **Real-world corpus validation**: Apply the framework to a diverse set of actual LLM evaluation corpora with varying levels of task ambiguity to verify that the gold label underestimation effect holds beyond synthetic data.

2. **Bound precision assessment**: Systematically evaluate the precision and reliability of prevalence vs. partition bounds across different scenarios, measuring how often bounds contain true performance and how wide they need to be for practical utility.

3. **Alternative modeling approaches**: Compare the causal DAG framework against alternative modeling approaches (e.g., Bayesian networks, probabilistic graphical models) to assess whether the DAG structure provides unique advantages or if simpler models could achieve similar results.