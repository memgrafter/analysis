---
ver: rpa2
title: Graph Neural Network Based Action Ranking for Planning
arxiv_id: '2412.04752'
source_url: https://arxiv.org/abs/2412.04752
tags:
- action
- gabar
- graph
- problems
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GABAR, a graph neural network approach for
  learning relational policies in classical planning through action ranking. The key
  innovation is an action-centric graph representation that explicitly encodes relationships
  between actions, objects, and predicates, combined with a GRU-based decoder that
  sequentially constructs grounded actions.
---

# Graph Neural Network Based Action Ranking for Planning

## Quick Facts
- arXiv ID: 2412.04752
- Source URL: https://arxiv.org/abs/2412.04752
- Authors: Rajesh Mangannavar; Stefan Lee; Alan Fern; Prasad Tadepalli
- Reference count: 40
- One-line primary result: Achieves 95.5% coverage on easy problems and 89.2% on hard problems using graph neural networks for action ranking in planning

## Executive Summary
This paper introduces GABAR, a graph neural network approach for learning relational policies in classical planning through action ranking. The key innovation is an action-centric graph representation that explicitly encodes relationships between actions, objects, and predicates, combined with a GRU-based decoder that sequentially constructs grounded actions. Unlike value-function approaches that must learn globally consistent estimates, GABAR only needs to learn locally consistent action rankings.

Experiments across eight standard planning domains demonstrate that GABAR achieves 95.5% coverage on easy problems and maintains 89.2% coverage even on hard problems that are up to 8 times larger than training instances. This significantly outperforms value-function baselines (79.1% coverage on easy problems, 6.5% on hard) and other action ranking methods (43.5% on easy, 22.1% on hard). Plan quality ratio remains high at 0.99 across all difficulty levels, indicating that GABAR not only solves more problems but also generates efficient solutions.

## Method Summary
GABAR learns relational policies through action ranking using a graph neural network architecture. The method uses an action-centric graph representation that explicitly captures action information and relationships between actions and objects. A GNN encoder processes this graph through multiple rounds of edge and node updates, followed by a GRU-based decoder that sequentially constructs grounded actions by selecting action schemas and their parameters. The model is trained using data from small problem instances and evaluated on problems of varying difficulty levels, demonstrating strong generalization to larger problems.

## Key Results
- Achieves 95.5% coverage on easy problems and 89.2% coverage on hard problems (8x larger than training)
- Maintains high plan quality ratio of 0.99 across all difficulty levels
- Outperforms value-function baselines (79.1% easy, 6.5% hard) and other action ranking methods (43.5% easy, 22.1% hard)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The action-centric graph representation enables effective generalization by explicitly encoding relationships between actions and objects.
- Mechanism: The graph structure captures how objects participate in actions through action-object edges, while predicate-object edges encode state information. This explicit representation allows the GNN to learn patterns that transfer from small training problems to larger test instances.
- Core assumption: The relationships between actions and objects are the key structural features that generalize across problem sizes.
- Evidence anchors:
  - [abstract] "We introduce a new graph representation that explicitly captures action information"
  - [section 3.2] "Our representation G= (V, E, X, R) consists of a set of nodes V, edgesE, node featuresXand edge featuresR"
  - [corpus] Weak evidence - related papers focus on general graph neural networks but not specifically on action-centric representations for planning
- Break condition: If the action-object relationships don't capture the essential structure needed for planning, or if the graph becomes too large to process effectively.

### Mechanism 2
- Claim: The GRU-based conditional decoder captures dependencies between action parameters, enabling coherent action construction.
- Mechanism: The decoder sequentially selects action parameters, conditioning each choice on previously selected objects through the GRU hidden state. This autoregressive approach ensures parameter selections are coherent and reflect real dependencies in the domain.
- Core assumption: Action parameters are not independent and their dependencies matter for generating valid, effective actions.
- Evidence anchors:
  - [abstract] "a GRU-based decoder that sequentially constructs grounded actions"
  - [section 3.3.2] "This autoregressive approach ensures that each parameter selection is conditioned on the graph structure, the selected action schema, and all previously selected parameters"
  - [corpus] Weak evidence - related papers don't specifically address conditional decoding for action parameter selection
- Break condition: If parameter dependencies are weak or non-existent in certain domains, making the sequential approach unnecessary overhead.

### Mechanism 3
- Claim: Action ranking is more effective than value function learning for generalized planning because it only requires learning local consistency rather than global consistency.
- Mechanism: Instead of learning a complex value function that must be globally consistent across all states, the model only needs to learn which actions are better in each local state. This simpler learning problem generalizes better to larger problems.
- Core assumption: Local action rankings are easier to learn and more generalizable than global value functions.
- Evidence anchors:
  - [abstract] "Unlike value-function based approaches that must learn a globally consistent function, our action ranking method only needs to learn locally consistent ranking"
  - [section 5.1] "The dramatic performance drop from GABAR to GABAR-RANK (replacing action ranking with value function learning) confirms that directly ranking local actions is a more robust and generalizable strategy"
  - [corpus] Weak evidence - related papers focus on value function approaches rather than action ranking
- Break condition: If global consistency becomes crucial for certain domains, making the local ranking approach insufficient.

## Foundational Learning

- Graph Neural Networks
  - Why needed here: GNNs can process variable-sized relational structures while maintaining permutation invariance, making them ideal for planning states with different numbers of objects
  - Quick check question: Why can't we just use standard neural networks instead of GNNs for processing the planning state graphs?

- Message Passing
  - Why needed here: Message passing allows information to propagate between related nodes (objects, predicates, actions) in the graph, capturing complex relationships that inform action selection
  - Quick check question: How many rounds of message passing are typically needed to capture all relevant information in a planning problem graph?

- Autoregressive Decoding
  - Why needed here: The sequential selection of action parameters allows the model to capture dependencies between parameters, ensuring generated actions are valid and coherent
  - Quick check question: What happens if we select all action parameters independently instead of sequentially?

## Architecture Onboarding

- Component map: Graph representation → GNN encoder (edge update → node update → global update) → GRU decoder (action selection → parameter selection) → Beam search
- Critical path: The flow from input graph through GNN processing to action selection determines the model's effectiveness
- Design tradeoffs: Explicit action representation vs. compact encoding, sequential vs. parallel parameter selection, local ranking vs. global value functions
- Failure signatures: Poor coverage indicates generalization issues, low plan quality ratio suggests inefficient action selection, ablation performance drops pinpoint which components are critical
- First 3 experiments:
  1. Test coverage on easy problems to verify basic functionality
  2. Compare plan quality ratio against Fast Downward on solved instances
  3. Run ablation studies (GABAR-ACT, GABAR-CD, GABAR-RANK) to validate component contributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GABAR's performance change when trained on a mix of problem sizes versus only small problems?
- Basis in paper: [explicit] The paper states GABAR is "trained on data generated from small problem instances" but doesn't compare this to training on mixed-size datasets
- Why unresolved: The authors assume training only on small problems is optimal for generalization but don't empirically test whether including medium or hard problems in training improves or degrades performance on larger test instances
- What evidence would resolve it: Experiments comparing GABAR trained on small-only vs mixed-size training sets, measuring coverage and plan quality on hard test instances

### Open Question 2
- Question: What is the impact of beam search width on GABAR's coverage and plan quality across different domains?
- Basis in paper: [explicit] The paper mentions using beam width k=2 but states "Setting a larger beam width provides better results theoretically"
- Why unresolved: The paper only reports results for k=2 without exploring the trade-off between computational cost and performance gains from larger beam widths
- What evidence would resolve it: Systematic experiments varying beam width (k=1, 2, 4, 8) across all domains, measuring both coverage and plan quality metrics

### Open Question 3
- Question: How does GABAR scale with problem size in terms of computational resources (memory and inference time)?
- Basis in paper: [inferred] The paper demonstrates excellent coverage on problems up to 8x larger than training instances but doesn't report resource usage scaling
- Why unresolved: The paper focuses on solution quality metrics but doesn't characterize the computational complexity or practical limitations of applying GABAR to extremely large planning problems
- What evidence would resolve it: Experiments measuring memory usage, inference time, and GPU requirements as problem size increases, establishing practical scalability limits

### Open Question 4
- Question: Would incorporating domain-specific knowledge (like action preconditions) into the graph representation improve GABAR's performance?
- Basis in paper: [explicit] The authors note that "domains with high-arity actions or predicates" present challenges for their graph representation
- Why unresolved: The current graph structure is domain-agnostic, and the authors suggest this could be limiting in complex domains, but don't test whether encoding domain-specific constraints would help
- What evidence would resolve it: Experiments augmenting the graph with precondition information and measuring changes in coverage and plan quality, particularly in complex domains like Logistics and Rovers

## Limitations
- Evaluation focuses exclusively on classical planning domains, limiting generalizability to real-world applications
- Computational complexity of processing action-centric graphs with large numbers of objects is not analyzed
- Training data generation relies on a single planner (Fast Downward), potentially biasing learned policies

## Confidence

**High confidence** in the action ranking mechanism effectiveness, supported by substantial performance gap between GABAR and value-function baselines across all difficulty levels.

**Medium confidence** in the generalization claims, as results show strong performance on larger problems but don't investigate whether learned policies transfer to structurally different domains.

**Low confidence** in the computational efficiency claims, as the paper provides no analysis of training time, inference latency, or memory requirements for processing the graph representations.

## Next Checks

1. **Generalization to Novel Domains**: Test GABAR on planning domains structurally different from the training domains (e.g., hierarchical planning or temporal planning problems) to verify if the action ranking approach generalizes beyond size scaling to structural generalization.

2. **Noise Robustness Evaluation**: Introduce controlled noise to the graph representations (corrupted predicate values, missing action-object edges) and measure the degradation in coverage and plan quality to assess the model's robustness to imperfect state representations.

3. **Computational Complexity Analysis**: Measure and report training time, inference latency, and memory usage for GABAR across different problem sizes and graph densities to understand the practical scalability limitations of the action-centric graph representation approach.