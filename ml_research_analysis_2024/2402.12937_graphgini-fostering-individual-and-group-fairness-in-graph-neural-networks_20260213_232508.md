---
ver: rpa2
title: 'GRAPHGINI: Fostering Individual and Group Fairness in Graph Neural Networks'
arxiv_id: '2402.12937'
source_url: https://arxiv.org/abs/2402.12937
tags:
- fairness
- gini
- group
- individual
- graphgini
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GraphGini tackles individual and group fairness in Graph Neural
  Networks by replacing the Lipschitz constant with the Gini coefficient, enabling
  a more expressive measure of fairness across the entire outcome distribution. It
  uses a differentiable upper bound of the Gini to integrate it into the loss function
  and employs Nash Social Welfare to achieve Pareto-optimal group fairness.
---

# GRAPHGINI: Fostering Individual and Group Fairness in Graph Neural Networks

## Quick Facts
- arXiv ID: 2402.12937
- Source URL: https://arxiv.org/abs/2402.12937
- Authors: Anuj Kumar Sirohi; Anjali Gupta; Sandeep Kumar; Amitabha Bagchi; Sayan Ranu
- Reference count: 40
- Primary result: Replaces Lipschitz constant with Gini coefficient for fairness, achieving up to 88% improvement in individual fairness while maintaining utility

## Executive Summary
GraphGini introduces a novel approach to fairness in Graph Neural Networks by replacing the Lipschitz constant with the Gini coefficient, enabling a more expressive measure of fairness across the entire outcome distribution. The method uses a differentiable upper bound of the Gini coefficient to enable gradient-based optimization, Nash Social Welfare to achieve Pareto-optimal group fairness, and automatic gradient normalization to balance competing objectives. Across three real-world datasets and three GNN architectures, GraphGini significantly outperforms 11 state-of-the-art baselines in both fairness metrics while maintaining utility.

## Method Summary
GraphGini addresses fairness in GNNs by optimizing three competing objectives: utility, individual fairness, and group fairness. The method constructs a differentiable upper bound for the Gini coefficient (Tr(ZT LZ)) to enable gradient-based optimization of individual fairness, uses Nash Social Welfare Program to achieve Pareto-optimal group fairness across sensitive groups, and employs gradient normalization (GradNorm) to automatically balance the competing objectives. The model is trained on three real-world datasets (Credit, Income, Pokec-n) using GCN, GIN, and JK backbones with attention mechanisms weighted by similarity matrices.

## Key Results
- Achieves up to 88% improvement in individual fairness compared to state-of-the-art methods
- Maintains utility (AUCROC/F1-score) while significantly improving fairness metrics
- Ensures Pareto-optimal group fairness across multiple sensitive groups
- Outperforms 11 state-of-the-art baselines across three real-world datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GraphGini uses a differentiable upper bound of the Gini coefficient to enable gradient-based optimization of individual fairness.
- Mechanism: Instead of directly optimizing the non-differentiable Gini coefficient, GraphGini minimizes Tr(ZT LZ), which serves as a convex upper bound. This bound is derived by replacing the ℓ1-norm with the ℓ2-norm scaled by √c, making the loss function amenable to gradient descent.
- Core assumption: The ℓ2-norm scaled by √c is a valid upper bound for the ℓ1-norm in the context of fairness, and minimizing this upper bound leads to meaningful improvements in the true Gini metric.
- Evidence anchors:
  - [abstract]: "We address this by proving an upper bound that is differentiable, allowing its seamless incorporation as a loss regularizer."
  - [section]: "Proposition 1. Given node embeddings Z ∈ Rn×c of graph G = (V,E, X) with node similarity matrix S and corresponding Laplacian L ... Gini(V) ≤ Tr(ZT LZ)"
  - [corpus]: Weak. No direct corpus evidence on the tightness or empirical effectiveness of the upper bound.
- Break condition: If the upper bound is not tight enough, minimizing it may not translate to significant improvements in the actual Gini coefficient, leading to misleading optimization behavior.

### Mechanism 2
- Claim: Nash Social Welfare Program (NSWP) is used to achieve Pareto-optimal group fairness across multiple sensitive groups.
- Mechanism: NSWP converts the group fairness objective into a product of normalized disparities, ensuring that no group's fairness can be improved without harming another. This formulation avoids the non-differentiability of max operations in group disparity calculations.
- Core assumption: The product formulation in NSWP leads to a Pareto-optimal solution that fairly balances group disparities.
- Evidence anchors:
  - [abstract]: "Additionally, we employ the Nash social welfare program to ensure our solution yields a Pareto optimal distribution of group fairness."
  - [section]: "Proposition 3. Minimizing Eq. 9 produces Pareto optimal solutions for group fairness over all groups."
  - [corpus]: Weak. No corpus evidence on the specific NSWP formulation or its empirical impact on fairness outcomes.
- Break condition: If the product formulation does not capture the true trade-offs between groups, the solution may not be truly Pareto-optimal or may unfairly prioritize certain groups.

### Mechanism 3
- Claim: Gradient normalization (GradNorm) automatically balances the competing objectives of utility, individual fairness, and group fairness without manual hyperparameter tuning.
- Mechanism: GradNorm adjusts the weights βi(t) for each loss term based on the ratio of current to initial training rates, encouraging all objectives to progress at similar rates. This dynamic balancing avoids the pitfalls of static weighting.
- Core assumption: Balancing training rates across loss terms leads to a better overall trade-off between utility and fairness objectives.
- Evidence anchors:
  - [abstract]: "Automatic gradient normalization balances the competing objectives of utility individual fairness, and group fairness."
  - [section]: "We perform gradient normalization to automatically learn the weights (Chen et al., 2018)."
  - [corpus]: Weak. No corpus evidence on the specific implementation or effectiveness of GradNorm in the GraphGini context.
- Break condition: If the training rates are not well-correlated with the importance of each objective, GradNorm may lead to suboptimal balancing, potentially sacrificing one objective for another inappropriately.

## Foundational Learning

- Concept: Convex optimization and upper bounds.
  - Why needed here: Understanding how to replace a non-convex, non-differentiable fairness metric with a convex, differentiable upper bound is crucial for implementing GraphGini.
  - Quick check question: Why is Tr(ZT LZ) a valid upper bound for the Gini coefficient, and how does its convexity help in optimization?

- Concept: Pareto optimality and multi-objective optimization.
  - Why needed here: Grasping the concept of Pareto optimality and how NSWP achieves it is essential for understanding the group fairness mechanism in GraphGini.
  - Quick check question: How does the product formulation in NSWP ensure that no group's fairness can be improved without harming another?

- Concept: Gradient-based optimization and automatic weight adjustment.
  - Why needed here: Understanding how GradNorm dynamically adjusts loss weights based on training rates is key to implementing the balanced optimization in GraphGini.
  - Quick check question: How does GradNorm use the ratio of current to initial training rates to balance the objectives, and why is this approach effective?

## Architecture Onboarding

- Component map:
  Input Graph -> Base GNN Embeddings -> GAT with Similarity Attention -> Loss Computation (L1, L2, L3) -> GradNorm Weight Adjustment -> Updated Embeddings

- Critical path:
  1. Initialize embeddings Z using base GNN and utility loss L1
  2. Apply GAT with attention scores based on similarity matrix S
  3. Compute losses L1, L2, and L3
  4. Use GradNorm to adjust weights β1, β2, β3 based on training rates
  5. Update model parameters and embeddings Z
  6. Repeat until convergence

- Design tradeoffs:
  - Using a differentiable upper bound vs. directly optimizing the Gini coefficient: The upper bound is easier to optimize but may not perfectly capture the Gini metric
  - NSWP vs. other group fairness formulations: NSWP ensures Pareto optimality but may be more complex to implement
  - GradNorm vs. manual hyperparameter tuning: GradNorm automates the balancing process but may not always find the optimal weights

- Failure signatures:
  - Poor convergence or unstable training: May indicate issues with the upper bound tightness or GradNorm implementation
  - Significant drop in utility while improving fairness: May suggest that the balancing is too aggressive
  - Persistent group disparities despite optimization: May indicate that the NSWP formulation is not effectively addressing the specific group imbalances

- First 3 experiments:
  1. Verify the convexity and tightness of the upper bound Tr(ZT LZ) compared to the true Gini coefficient on a small synthetic dataset
  2. Test the Pareto optimality of the NSWP formulation by checking if improving one group's fairness harms another on a dataset with known group disparities
  3. Validate the GradNorm balancing by comparing the training rates and final performance of GraphGini with manually tuned weights on a benchmark dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GraphGini's performance scale with graph size and density in real-world scenarios?
- Basis in paper: [inferred] The paper mentions running time comparisons but doesn't extensively test scalability on larger graphs or varying densities.
- Why unresolved: The experiments use three datasets of moderate size. Scaling behavior to larger, denser graphs remains unexplored.
- What evidence would resolve it: Experiments on graphs with 100K+ nodes and varying edge densities showing runtime and fairness degradation patterns.

### Open Question 2
- Question: Can the differentiable upper bound for the Gini coefficient be further tightened to reduce approximation error?
- Basis in paper: [explicit] Proposition 1 provides a differentiable upper bound, but the paper notes it may be loose in certain cases.
- Why unresolved: The paper uses this bound for optimization but doesn't explore tighter approximations or their impact on fairness.
- What evidence would resolve it: Comparison of tighter bounds (e.g., using ℓ1-norm directly) with the current upper bound on fairness metrics.

### Open Question 3
- Question: How does GraphGini perform under dynamic graph settings where edges/nodes are added or removed over time?
- Basis in paper: [inferred] The paper focuses on static graphs but doesn't address temporal dynamics or incremental updates.
- Why unresolved: Graph Neural Networks are often used in dynamic environments (e.g., social networks), and fairness maintenance over time is critical.
- What evidence would resolve it: Experiments on temporal graph datasets showing fairness and utility stability across time steps.

## Limitations
- The paper lacks direct empirical evidence validating the tightness of the Gini coefficient upper bound
- Specific implementation details of the gradient normalization (GradNorm) mechanism are not fully specified
- No ablation studies are provided to isolate the individual contributions of the three mechanisms

## Confidence

**High confidence:**
- Mathematical formulation of the differentiable upper bound for individual fairness

**Medium confidence:**
- Effectiveness of the NSWP formulation for group fairness due to limited empirical validation

**Low confidence:**
- Automatic balancing mechanism without detailed implementation specifications

## Next Checks

1. Conduct empirical validation comparing the Gini coefficient upper bound (Tr(ZT LZ)) against the true Gini metric across multiple datasets to quantify the approximation error

2. Implement ablation studies isolating each component (Gini regularization, NSWP, GradNorm) to measure their individual contributions to fairness improvements

3. Test the model's sensitivity to similarity matrix construction by varying the similarity threshold and measuring its impact on both utility and fairness metrics