---
ver: rpa2
title: A scalable generative model for dynamical system reconstruction from neuroimaging
  data
arxiv_id: '2411.02949'
source_url: https://arxiv.org/abs/2411.02949
tags: []
core_contribution: This work addresses the challenge of training state space models
  (SSMs) for dynamical systems reconstruction when observations depend on histories
  of latent states, as in BOLD signals from fMRI. The authors introduce a novel approach
  that combines generalized teacher forcing with Wiener deconvolution to handle convolved
  observations.
---

# A scalable generative model for dynamical system reconstruction from neuroimaging data

## Quick Facts
- arXiv ID: 2411.02949
- Source URL: https://arxiv.org/abs/2411.02949
- Reference count: 40
- Authors: Eric Volkmann; Alena Brändle; Daniel Durstewitz; Georgia Koppe
- Primary result: ConvSSM outperforms existing methods in recovering attractor geometry and long-term temporal properties on benchmark datasets, and successfully reconstructs individual subject dynamics from fMRI data

## Executive Summary
This paper introduces convSSM, a novel approach for training state space models on data where observations depend on histories of latent states, specifically addressing the challenge of hemodynamic convolution in BOLD signals. The method combines generalized teacher forcing with Wiener deconvolution to handle convolved observations while maintaining efficient scaling with model dimensionality. When applied to both benchmark dynamical systems (Lorenz63, ALN cascade) and empirical fMRI data, convSSM demonstrates superior performance in reconstructing attractor geometry and temporal properties compared to existing methods.

## Method Summary
ConvSSM addresses the challenge of training state space models when observations are convolved with a known kernel (like the HRF in fMRI). The approach uses Wiener deconvolution to pre-process observations, separating the deconvolution step from learnable parameters to achieve linear scaling. During training, generalized teacher forcing stabilizes gradient propagation in chaotic systems by interpolating between model-generated and data-inferred states. The latent model uses a clipped shallow PLRNN structure, while the observation model explicitly handles the convolution and nuisance artifacts.

## Key Results
- On Lorenz63 system with TR=0.2s, convSSM achieves Dstsp=0.14±0.01 compared to Dstsp=0.23±0.01 for standard SSM
- Scales efficiently with model size, enabling M=100 latent dimensions and L=1000 filter length in practical training times
- Applied to empirical fMRI data, successfully reconstructs individual subject dynamics with positive maximum Lyapunov exponents indicating chaotic behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Wiener deconvolution efficiently inverts the hemodynamic response function (HRF) to obtain clean latent state estimates from BOLD observations
- Mechanism: Wiener deconvolution uses frequency-domain filtering to separate the true latent signal from noise, assuming known convolution kernel (HRF) and noise spectrum. The filter combines spectral density estimates of the signal and noise to compute an optimal estimate in least-MSE sense.
- Core assumption: The HRF is known and stationary; noise follows approximately Gaussian statistics allowing spectral density estimation via median estimator on wavelet coefficients
- Evidence anchors:
  - [abstract]: "we use a Wiener filter [75] to invert Equation 5" and "scales exceptionally well with model dimensionality and filter length"
  - [section]: "The Wiener deconvolution provides the estimate ˆzt of the unknown signal zt through least-MSE estimation" with explicit filter formula Wk = HRF* k Sk / (|HRF k|2Sk + Nk)
  - [corpus]: Weak evidence - no direct mention of Wiener deconvolution in related papers, but "physics-guided time series embedding" and "dynamical systems reconstruction" are related concepts
- Break condition: If HRF varies across subjects or brain regions, or if noise is non-Gaussian or has time-varying spectrum, the Wiener filter performance degrades significantly

### Mechanism 2
- Claim: Generalized Teacher Forcing (GTF) stabilizes training by preventing gradient explosion in chaotic systems through controlled trajectory synchronization
- Mechanism: GTF interpolates between model-generated state zt and data-inferred state dt at each time step: ˜zt = (1-α)·zt + α·dt. This keeps trajectories close to observed data during training while allowing autonomous evolution during inference
- Core assumption: The decoder model is (pseudo-)invertible to obtain control signals dt from observations; chaotic divergence is the primary cause of exploding gradients
- Evidence anchors:
  - [abstract]: "These techniques are based on control-theoretic ideas, like modern variants of teacher forcing (TF), to ensure stable loss gradient propagation while training"
  - [section]: "Recent breakthroughs in data-driven DSR build on insights from the field of chaos control and synchronization... by guiding the training process through optimally chosen control signals – modern variations of classical teacher forcing (TF)"
  - [corpus]: "True Zero-Shot Inference of Dynamical Systems Preserving Long-Term Statistics" mentions similar TF-based approaches for chaotic systems
- Break condition: If the decoder model cannot be inverted (non-invertible convolutions) or if system exhibits non-chaotic but still unstable dynamics, GTF may not prevent gradient issues

### Mechanism 3
- Claim: The convolutional observation model with decoupled deconvolution scales linearly with model size and convolution length due to linearity of convolution operation
- Mechanism: By exploiting linearity, deconvolution is performed once before training to obtain xdeconv and rdeconv, then during training only matrix operations B+ and J are applied. This separates expensive convolution inversion from per-epoch parameter updates
- Core assumption: Convolution is linear operation allowing separation of deconvolution step from learnable parameters; observation model structure permits this decomposition
- Evidence anchors:
  - [abstract]: "Our method, convSSM, scales efficiently with model dimensionality and filter length, making it practical for large-scale applications"
  - [section]: "We therefore make use of the linearity of convolutions and separate the deconvolution step from the learnable parameters" with mathematical derivation showing B(hrf * z)t = (hrf * (Bz))t
  - [corpus]: "Optimal Recurrent Network Topologies for Dynamical Systems Reconstruction" mentions scaling considerations for DSR models
- Break condition: If observation model includes nonlinear operations combined with convolution, or if HRF varies with state, the linearity assumption breaks and scaling benefits are lost

## Foundational Learning

- Concept: State Space Models (SSMs) and their role in dynamical systems reconstruction
  - Why needed here: The convSSM is fundamentally an SSM with convolutional observation model; understanding SSM architecture and training is essential for grasping the innovation
  - Quick check question: What distinguishes an SSM from a standard RNN in terms of modeling assumptions about observation process?

- Concept: Hemodynamic Response Function (HRF) and its effect on BOLD signal
  - Why needed here: The HRF convolution is the core challenge addressed; understanding its temporal smoothing effect is crucial for appreciating the deconvolution approach
  - Quick check question: How does the HRF convolution affect the temporal resolution and information content of BOLD signals compared to underlying neural activity?

- Concept: Chaos theory and Lyapunov exponents in dynamical systems
  - Why needed here: The paper focuses on chaotic systems (positive Lyapunov exponents); understanding why chaotic systems are challenging for gradient-based learning is key to appreciating GTF
  - Quick check question: Why do chaotic systems with positive Lyapunov exponents pose particular challenges for standard RNN training approaches?

## Architecture Onboarding

- Component map:
  Latent model (cshPLRNN) -> Observation model (convolutional) -> Deconvolution layer -> Control signal generator -> GTF interpolator -> Loss computation

- Critical path:
  1. Pre-training: Wiener deconvolution of training data (xdeconv, rdeconv)
  2. Training loop: For each batch
     - Compute model states zt via cshPLRNN
     - Generate control signals dt from deconvolved data
     - Apply GTF interpolation to get ˜zt
     - Compute predictions ˆxt = B(hrf * zt) + Jrt
     - Calculate loss and backpropagate gradients

- Design tradeoffs:
  - Pre-computation vs. online deconvolution: Pre-computation enables linear scaling but assumes stationary HRF
  - Latent dimension vs. expressivity: Higher M enables better reconstruction but increases computational cost
  - α parameter in GTF: Higher α provides more stability but may reduce model autonomy; lower α allows more learning but risks instability

- Failure signatures:
  - Training divergence despite GTF: Likely indicates non-invertible observation model or inappropriate α
  - Poor reconstruction quality (high Dstsp): May indicate insufficient latent dimension or inappropriate deconvolution parameters
  - Slow convergence: Could indicate suboptimal learning rate or batch size

- First 3 experiments:
  1. Train convSSM on Lorenz63 data with TR=0.2s, σ=0.01; verify Dstsp < 0.3 and compare with standard SSM
  2. Scale convSSM to M=100, L=1000 on same data; measure epoch time scaling
  3. Train on ALN data with TR=0.5s; evaluate whether performance measures computed on short time series predict long-term properties

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the convSSM framework be extended to handle non-stationary data effectively?
- Basis in paper: [explicit] The paper mentions that non-stationarity in data poses challenges for DSR methods and notes this as an open question
- Why unresolved: Current implementations assume stationary dynamics, but real-world data often exhibits non-stationary behavior that could degrade model performance
- What evidence would resolve it: Demonstrating the convSSM's performance on benchmark datasets with controlled non-stationarity, comparing approaches like sliding window training, adaptive hyperparameters, or explicit non-stationary modeling

### Open Question 2
- Question: What is the optimal strategy for combining data from multiple subjects in convSSM training?
- Basis in paper: [explicit] The paper identifies this as an open question regarding how to efficiently combine data from many subjects
- Why unresolved: While the paper shows convSSM can distinguish between individuals, it doesn't address whether joint training on multiple subjects improves reconstruction quality or generalization
- What evidence would resolve it: Empirical comparisons of single-subject vs. multi-subject training on benchmark datasets, measuring both reconstruction accuracy and cross-subject generalization performance

### Open Question 3
- Question: How well do convSSM models generalize to out-of-domain data or experimental conditions?
- Basis in paper: [explicit] The paper identifies generalization to out-of-domain data as an open question
- Why unresolved: The current validation focuses on in-domain performance, but real-world applications may require models to handle different experimental paradigms, scanner types, or population characteristics
- What evidence would resolve it: Testing convSSM on datasets with different acquisition parameters, subject demographics, or task conditions, measuring performance degradation and identifying factors that influence robustness

## Limitations
- Performance critically depends on accurate HRF knowledge and stationarity assumptions, which may not hold in real fMRI data
- Method's effectiveness for systems with nonlinear observation models remains unverified
- While scaling well for convolution length, quadratic dependence on latent dimension M could limit very large models

## Confidence
- High confidence: Scaling efficiency claims and Lorenz63 reconstruction performance (strong quantitative evidence)
- Medium confidence: ALN model results and fMRI empirical validation (limited sample size, cross-validation needed)
- Low confidence: Generalization claims for Lyapunov exponent estimation from short windows

## Next Checks
1. Test convSSM performance when HRF parameters are imperfectly known or vary across brain regions to assess robustness to deconvolution errors
2. Evaluate model performance on systems with nonlinear observation models (e.g., quadratic observation terms) to test generality beyond convolutional cases
3. Conduct ablation studies varying the GTF interpolation parameter α to determine optimal stability-learning tradeoff and identify failure modes