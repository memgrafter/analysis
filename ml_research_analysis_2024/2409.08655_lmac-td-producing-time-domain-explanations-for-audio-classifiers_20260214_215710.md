---
ver: rpa2
title: 'LMAC-TD: Producing Time Domain Explanations for Audio Classifiers'
arxiv_id: '2409.08655'
source_url: https://arxiv.org/abs/2409.08655
tags:
- lmac-td
- explanations
- audio
- l-mac
- classifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LMAC-TD, a post-hoc explanation method for
  audio classifiers that generates time-domain interpretations directly, bypassing
  the limitations of magnitude-STFT domain approaches. LMAC-TD enhances the L-MAC
  framework by incorporating the SepFormer architecture, which allows for high-quality
  audio separation and reconstruction in the time domain.
---

# LMAC-TD: Producing Time Domain Explanations for Audio Classifiers

## Quick Facts
- **arXiv ID**: 2409.08655
- **Source URL**: https://arxiv.org/abs/2409.08655
- **Reference count**: 35
- **Primary result**: LMAC-TD achieves comparable faithfulness metrics to L-MAC while significantly improving audio quality through time-domain interpretation generation

## Executive Summary
This paper introduces LMAC-TD, a post-hoc explanation method for audio classifiers that generates time-domain interpretations directly, bypassing the limitations of magnitude-STFT domain approaches. LMAC-TD enhances the L-MAC framework by incorporating the SepFormer architecture, which allows for high-quality audio separation and reconstruction in the time domain. The method combines classifier representations with encoded audio input using a UNet decoder and a SepFormer MaskNet, producing interpretations that are faithful to the classifier's decisions. Experimental results demonstrate that LMAC-TD achieves comparable faithfulness metrics to existing methods, such as L-MAC, while significantly improving audio quality as validated by a user study. Specifically, LMAC-TD with α = 0.75 outperforms other methods in terms of perceived audio quality without compromising faithfulness.

## Method Summary
LMAC-TD generates time-domain explanations for audio classifiers by combining classifier representations with encoded audio input through a UNet decoder and SepFormer MaskNet. The method uses a pre-trained CNN14 classifier to extract representations, which are combined with SepFormer encoder outputs via a convex combination controlled by parameter α. This combined signal passes through a MaskNet to generate a mask, which is applied to the input audio through a SepFormer decoder to produce the final time-domain interpretation. The model is trained using a loss function that ensures both faithfulness to the classifier and high audio quality, combining classification similarity, classification dissimilarity, and regularization terms.

## Key Results
- LMAC-TD achieves comparable faithfulness metrics (Average Increase, Average Decrease, Average Gain, Faithfulness, Fidelity-In) to L-MAC
- User study validates significantly improved audio quality for LMAC-TD interpretations compared to L-MAC
- LMAC-TD with α = 0.75 demonstrates the best trade-off between faithfulness and audio quality
- The method eliminates the need for fine-tuning while maintaining or enhancing interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LMAC-TD improves audio quality by bypassing the phase reconstruction step required in L-MAC.
- Mechanism: L-MAC operates in the magnitude-STFT domain and reconstructs waveforms using the input signal's phase, which introduces artifacts. LMAC-TD uses SepFormer to generate interpretations directly in the time domain, eliminating the need for phase reconstruction and thus reducing artifacts.
- Core assumption: Time-domain interpretation generation is inherently less prone to reconstruction artifacts than magnitude-STFT-based methods.
- Evidence anchors:
  - [abstract] "This paper proposes LMAC-TD, a post-hoc explanation method that trains a decoder to produce explanations directly in the time domain."
  - [section] "In this paper, we propose enhancing the quality of L-MAC's explanations by incorporating the SepFormer's MaskNet in the interpreter. That is, we generate explanations directly in the time domain, bypassing the need to use the input signal's phase as required by L-MAC's magnitude-STFT approach."
  - [corpus] Weak - related papers don't directly address the phase reconstruction issue in audio explanation methods.

### Mechanism 2
- Claim: The convex combination of classifier representations and encoded audio input (controlled by α) enables a better faithfulness-audio quality trade-off.
- Mechanism: The α parameter balances the influence of classifier representations (Hd) and encoded audio input (He) on the final interpretation. This allows the model to adjust the relative importance of faithfulness to the classifier versus audio quality preservation.
- Core assumption: The optimal balance between classifier influence and input preservation varies depending on the specific audio content and classification task.
- Evidence anchors:
  - [section] "In order to take into account contributions from both classifier representations and the encoded input audio directly, we combine Hd with the output of the SepFormer encoder He. The convex combination of He and Hd is then fed into the SepFormer MaskNet to obtain the mask M."
  - [section] "We observe that calculating this combination through alpha allows the model to reach better faithfulness-audio quality trade-off."
  - [corpus] Missing - related papers don't discuss the specific role of α in balancing faithfulness and audio quality.

### Mechanism 3
- Claim: The masking loss function ensures that interpretations are both interpretable and of high audio quality.
- Mechanism: The loss function combines classification similarity between input and interpretation (λin term), classification dissimilarity between input and masked-out interpretation (λout term), and a regularization term (λreg) to avoid trivial solutions. This multi-objective approach encourages interpretations that are both faithful to the classifier and acoustically meaningful.
- Core assumption: The combination of classification-based and audio quality-based loss terms effectively guides the model toward producing useful explanations.
- Evidence anchors:
  - [section] "The loss function is then calculated by comparing the classification results for the input signal x, the interpretation i, and the mask out version of the interpretation signal iout, which is defined as..."
  - [section] "All in all, the training loss function is calculated following the L-MAC approach, min θ λind(f (InputTf(x))∥f (InputTf(i))) − λoutd(f (InputTf(x))∥f (InputTf(iout))) + λregR(i),"
  - [corpus] Missing - related papers don't detail the specific loss function formulation for audio explanation methods.

## Foundational Learning

- Concept: Time-domain vs. frequency-domain audio processing
  - Why needed here: Understanding the difference between time-domain and STFT-based approaches is crucial for grasping why LMAC-TD improves audio quality.
  - Quick check question: What are the potential artifacts introduced by reconstructing audio from magnitude-STFT representations using the original signal's phase?

- Concept: Post-hoc explanation methods in deep learning
  - Why needed here: LMAC-TD is a post-hoc explanation method, so understanding the general principles of post-hoc interpretability is important.
  - Quick check question: How do post-hoc explanation methods differ from inherently interpretable model architectures?

- Concept: Source separation architectures (e.g., SepFormer)
  - Why needed here: SepFormer is a key component of LMAC-TD, so understanding its role in audio source separation is important.
  - Quick check question: What are the key components of the SepFormer architecture, and how do they contribute to high-quality audio separation?

## Architecture Onboarding

- Component map: Input signal (time domain) -> Input transformation (Mel-spectrogram extraction) -> Pre-trained classifier (CNN14 encoder + classification head) -> UNet decoder -> SepFormer encoder and MaskNet -> SepFormer decoder (time-domain interpretation output) -> Loss calculation (classification-based and regularization terms)

- Critical path: The critical path for LMAC-TD involves the flow of information from the input signal through the pre-trained classifier, the UNet decoder, the SepFormer encoder and MaskNet, and finally the SepFormer decoder to produce the time-domain interpretation.

- Design tradeoffs:
  - The choice between time-domain and STFT-based interpretation generation (favoring time-domain for better audio quality)
  - The balance between classifier faithfulness and audio quality (controlled by α)
  - The complexity of the explanation generation pipeline (increased by adding SepFormer components)

- Failure signatures:
  - Poor audio quality: may indicate issues with the SepFormer components or the α parameter setting
  - Low faithfulness: may indicate issues with the UNet decoder or the loss function hyperparameters
  - Overfitting to the training data: may indicate the need for stronger regularization or data augmentation

- First 3 experiments:
  1. Verify that LMAC-TD produces time-domain interpretations by checking the output waveform characteristics.
  2. Test the effect of different α values on the faithfulness-audio quality trade-off by training models with α = 0, 0.5, and 1.0.
  3. Compare the audio quality of LMAC-TD interpretations to L-MAC interpretations using a subjective listening test.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of alpha value (α) affect the trade-off between faithfulness and audio quality in LMAC-TD?
- Basis in paper: [explicit] The paper states that "We observe that calculating this combination through alpha allows the model to reach better faithfulness-audio quality trade-off" and benchmarks LMAC-TD with different α values to assess their impact.
- Why unresolved: The paper mentions that α = 0.75 achieves the best results, but does not provide a detailed analysis of how different α values specifically impact the trade-off between faithfulness and audio quality.
- What evidence would resolve it: A comprehensive study varying α across its entire range and analyzing the resulting faithfulness and audio quality metrics would provide a clearer understanding of the optimal α value for different applications.

### Open Question 2
- Question: Can LMAC-TD be extended to work with other types of classifiers beyond CNN14 and zero-shot classifiers?
- Basis in paper: [inferred] The paper demonstrates LMAC-TD's effectiveness with CNN14 and zero-shot classifiers, but does not explore its applicability to other classifier architectures.
- Why unresolved: The paper focuses on specific classifiers and does not investigate the generalizability of LMAC-TD to other architectures or domains.
- What evidence would resolve it: Experiments applying LMAC-TD to a variety of classifiers, such as transformers or recurrent neural networks, and evaluating its performance across different domains would determine its broader applicability.

### Open Question 3
- Question: How does LMAC-TD perform on audio data with varying levels of noise and complexity compared to other explanation methods?
- Basis in paper: [explicit] The paper evaluates LMAC-TD on audio mixtures with noise and speech contamination, showing improved faithfulness scores compared to L-MAC.
- Why unresolved: While the paper demonstrates LMAC-TD's effectiveness on specific noise and complexity levels, it does not provide a comprehensive analysis across a wide range of conditions.
- What evidence would resolve it: A systematic evaluation of LMAC-TD's performance on audio data with varying noise levels, signal-to-noise ratios, and complexity would provide insights into its robustness and limitations in real-world scenarios.

## Limitations
- The optimal α parameter appears dataset-specific, raising questions about generalization across different audio classification tasks
- The loss function hyperparameters are presented as fixed values without sensitivity analysis or justification for their specific values
- The user study methodology for audio quality assessment lacks detailed protocol information including sample size, participant selection criteria, and presentation order

## Confidence

**High Confidence**: The core claim that time-domain interpretation generation improves audio quality compared to STFT-based methods is well-supported by the mechanism description and experimental results.

**Medium Confidence**: The claim that LMAC-TD achieves comparable faithfulness to L-MAC while improving audio quality is supported by metrics but relies on specific hyperparameter settings that may not generalize.

**Medium Confidence**: The effectiveness of the α parameter in balancing faithfulness and audio quality is demonstrated empirically but lacks theoretical justification for why the specific values work.

## Next Checks
1. Conduct ablation studies varying α across a wider range (0.1 to 0.9) to verify the robustness of the faithfulness-audio quality trade-off and identify potential overfitting to the specific ESC-50 dataset.
2. Test LMAC-TD on out-of-domain audio classification tasks (different datasets or domains) to evaluate generalization and determine if the time-domain advantage persists across diverse audio characteristics.
3. Perform a controlled user study with standardized protocols (multiple presentation orders, sufficient sample size, demographic diversity) to validate the subjective audio quality assessments and ensure results are not influenced by presentation bias.