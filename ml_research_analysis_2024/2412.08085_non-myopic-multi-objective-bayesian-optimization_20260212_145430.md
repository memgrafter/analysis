---
ver: rpa2
title: Non-Myopic Multi-Objective Bayesian Optimization
arxiv_id: '2412.08085'
source_url: https://arxiv.org/abs/2412.08085
tags:
- optimization
- non-myopic
- hypervolume
- function
- acquisition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first non-myopic Bayesian optimization
  methods for multi-objective problems. The key challenge addressed is that the Bellman
  optimality principle, which underpins non-myopic single-objective BO, does not directly
  apply to MOO problems due to scalarization, monotonicity, and additivity requirements.
---

# Non-Myopic Multi-Objective Bayesian Optimization

## Quick Facts
- arXiv ID: 2412.08085
- Source URL: https://arxiv.org/abs/2412.08085
- Reference count: 31
- Non-myopic multi-objective Bayesian optimization methods that outperform myopic approaches by 10-30% in hypervolume on 6 real-world problems

## Executive Summary
This paper addresses the challenge of extending non-myopic Bayesian optimization to multi-objective problems, where the standard Bellman optimality principle cannot be directly applied. The authors solve this by using hypervolume improvement (HVI) as a scalarization approach that satisfies the required conditions of monotonicity, additivity, and scalar variables. They develop three acquisition functions: NMMO-Nested (exact but intractable), NMMO-Joint (scalable lower bound), and BINOM (fast batch approximation). Experiments on six real-world multi-objective optimization problems demonstrate that these non-myopic methods significantly outperform state-of-the-art myopic approaches in small-budget settings.

## Method Summary
The paper develops non-myopic Bayesian optimization for multi-objective problems by addressing the fundamental challenge that the Bellman optimality principle doesn't directly apply to MOO. The key innovation is using hypervolume improvement (HVI) as a scalarization approach that satisfies the necessary conditions for Bellman optimality (scalar rewards, monotonicity, additivity). Three acquisition functions are derived: NMMO-Nested (exact Bellman recursion), NMMO-Joint (scalable lower bound via joint batch optimization), and BINOM (fast batch-based approximation using posterior sampling). The methods use independent GP models for each objective and incorporate one-step lookahead approximations to improve computational efficiency.

## Key Results
- Non-myopic methods outperform myopic baselines by 10-30% in hypervolume on real-world problems
- Performance improvements are most pronounced in small-budget settings (early iterations)
- NMMO-Joint provides the best trade-off between performance and computational complexity
- BINOM offers fast computation but with approximation errors from batch selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hypervolume improvement (HVI) enables the Bellman optimality principle to hold for multi-objective optimization by providing a scalarization that satisfies monotonicity, additivity, and scalar variable requirements.
- Mechanism: HVI transforms multi-objective rewards into a single scalar value representing the volume of objective space newly dominated by adding a point to the Pareto front. This scalar measure preserves the monotonic property (better actions lead to higher rewards) and satisfies additivity because total improvement can be decomposed into sum of intermediate improvements.
- Core assumption: Pareto optimality with respect to hypervolume improvement rather than individual objectives is the appropriate optimization target for multi-objective Bayesian optimization.
- Evidence anchors:
  - [abstract]: "We address this challenge by using hypervolume improvement (HVI) as our scalarization approach, which allows us to use a lower-bound on the Bellman equation"
  - [section 4.2.1]: "HVI provides a suitable scalarization because it naturally satisfies all of the reward requirements... Second, it preserves the monotonicity by reflecting the Pareto quality of a new input"
  - [corpus]: Weak - corpus neighbors discuss related multi-objective optimization but don't specifically address HVI's role in enabling Bellman optimality
- Break condition: If the scalarization approach fails to capture true Pareto dominance quality or if additivity doesn't hold due to interaction effects between objectives

### Mechanism 2
- Claim: The nested acquisition function structure allows lookahead reasoning by balancing immediate EHVI gains with future expected improvements through batch selection.
- Mechanism: The NMMO-Nested acquisition function combines immediate exploitation (EHVI of current input) with exploration (maximum of expected BEHVI over lookahead horizon). This structure approximates the Bellman recursion by replacing the nested maximization with a joint batch optimization.
- Core assumption: The lower bound on Bellman equation provided by the joint batch utility is sufficiently tight to approximate optimal sequential decision-making.
- Evidence anchors:
  - [section 4.2.2]: "By defining the marginal gain in utility as the HVI, we rewrite the acquisition function as: αNested(x|Dt) = EHVI(x|Dt) + maxX′:|X′|=T−t−1 Ey[BEHVI(X′|Dt∪(x, y))]"
  - [section 4.2.2]: "The lower bound on the Bellman equation (Equation 10) provides an efficient alternative for optimizing the sequential decision-making process"
  - [corpus]: Weak - corpus neighbors discuss multi-objective optimization but don't specifically address nested acquisition function structures for lookahead
- Break condition: If the gap between the lower bound and true optimal policy becomes too large, or if computational approximations in the nested optimization degrade performance

### Mechanism 3
- Claim: Posterior sampling approximation replaces expensive expectation computation with one-step lookahead GP models, improving computational efficiency while maintaining accuracy.
- Mechanism: Instead of sampling multiple realizations from the posterior to compute expectations over BEHVI, the method uses a one-step lookahead GP model where the mean function remains unchanged but variance is updated based on posterior conditioning on the new input.
- Core assumption: The one-step lookahead approximation provides sufficiently accurate estimates of the expected utility without requiring extensive sampling.
- Evidence anchors:
  - [section 4.2.2]: "To mitigate the former issues, we propose to substitute the expectation by the use of a one-step lookahead GP model"
  - [section 4.2.2]: "In this approach, the mean function of the GP remains unchanged, while the variance is updated based on the posterior conditioning on the newly added input"
  - [corpus]: Weak - corpus neighbors don't specifically discuss one-step lookahead GP approximations for multi-objective Bayesian optimization
- Break condition: If the approximation error from using one-step lookahead becomes too large compared to full posterior sampling, or if model uncertainty compounds excessively

## Foundational Learning

- Concept: Bellman optimality principle and its requirements for scalar rewards, monotonicity, and additivity
  - Why needed here: Understanding why the standard Bellman principle doesn't directly apply to multi-objective problems and how HVI addresses these limitations
  - Quick check question: What are the three key conditions a reward function must satisfy for the Bellman optimality principle to hold?

- Concept: Hypervolume improvement as a scalarization method for multi-objective optimization
  - Why needed here: HVI is the core mechanism that enables non-myopic reasoning in multi-objective settings by providing a scalar measure that satisfies all Bellman requirements
  - Quick check question: How does hypervolume improvement differ from standard hypervolume in terms of additivity properties?

- Concept: Gaussian process modeling for multi-objective optimization with independent GP models per objective
  - Why needed here: The surrogate modeling approach underpins all acquisition function calculations and posterior sampling approximations
  - Quick check question: Why do we typically use independent GP models for each objective function in multi-objective Bayesian optimization?

## Architecture Onboarding

- Component map: GP surrogate models (K independent models, one per objective) -> Acquisition function module (three variants) -> Hypervolume calculation engine -> Batch selection optimization component -> One-step lookahead GP approximation module
- Critical path: 1. Evaluate candidate inputs using GP models, 2. Compute EHVI for immediate gains, 3. Approximate future gains using BEHVI with one-step lookahead, 4. Optimize acquisition function to select next input, 5. Update GP models with new observations
- Design tradeoffs:
  - NMMO-Nested offers highest theoretical accuracy but is computationally intractable
  - NMMO-Joint provides scalable approximation with joint optimization
  - BINOM offers fastest computation but with approximation errors from batch selection
  - One-step lookahead GP approximation trades accuracy for computational efficiency
- Failure signatures:
  - Degraded performance with increasing horizon length due to compounding uncertainty
  - Computational bottlenecks in nested optimization for NMMO-Nested
  - Unstable optimization behavior with insufficient posterior samples
  - Poor exploration-exploitation balance when HVI scalarization fails to capture true Pareto quality
- First 3 experiments:
  1. Implement NMMO-Joint with H=2 on a simple 2-objective synthetic problem (e.g., ZDT3) to validate basic functionality
  2. Compare NMMO-Joint vs EHVI on a real-world problem (e.g., Reinforced Concrete Beam Design) to demonstrate performance improvement
  3. Test BINOM with varying horizons (H=2,4,6) on a combinatorial problem to understand horizon sensitivity and computational tradeoffs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How tight is the lower bound on the Bellman equation when using hypervolume improvement (HVI) as the reward function in multi-objective Bayesian optimization?
- Basis in paper: [inferred] The paper states that the lower-bound connection between the Bellman equation and batch utility functions provides an efficient alternative for non-myopic single-objective BO, and extends this to MOBO using HVI, but does not explicitly quantify the tightness of this bound in the multi-objective setting.
- Why unresolved: The paper does not provide theoretical analysis or empirical evidence quantifying how closely the lower bound approximates the true optimal policy in multi-objective settings. This is particularly important given the complex trade-offs in MOO problems.
- What evidence would resolve it: Theoretical bounds on the adaptivity gap for HVI-based scalarization, or empirical studies comparing the performance of the lower-bound approach against an oracle method that could solve the full Bellman equation exactly.

### Open Question 2
- Question: How does the performance of non-myopic methods degrade as the number of objectives (K) increases beyond the 2-3 objectives tested in the experiments?
- Basis in paper: [inferred] The experiments focus on problems with 2-3 objectives, and the paper mentions applying BINOM to DTLZ problems with up to 5 objectives, but does not provide comprehensive results or analysis of scalability with respect to the number of objectives.
- Why unresolved: The paper does not investigate the scaling behavior of the non-myopic methods as the dimensionality of the objective space increases, which is critical for understanding their applicability to high-dimensional MOO problems.
- What evidence would resolve it: Systematic experiments varying the number of objectives on synthetic benchmarks, along with analysis of computational complexity and performance degradation as K increases.

### Open Question 3
- Question: What is the optimal lookahead horizon length for non-myopic methods in practice, and how does this depend on problem characteristics?
- Basis in paper: [explicit] The paper mentions that "longer horizons can hinder the optimization process by including suboptimal or misleading inputs" and observes that performance sometimes decreases with increasing horizon values, but does not provide guidance on how to select optimal horizon lengths.
- Why unresolved: The paper demonstrates that horizon length affects performance but does not develop methodology for determining appropriate horizon lengths for different problem types or provide theoretical justification for the observed trade-offs.
- What evidence would resolve it: Empirical studies correlating horizon length performance with problem characteristics (e.g., Pareto front geometry, objective function complexity), along with theoretical analysis of the exploration-exploitation trade-off as a function of horizon length.

## Limitations

- Computational complexity of NMMO-Nested acquisition function makes exact implementation challenging for high-dimensional problems
- Empirical validation limited to relatively small problem instances (2-4 objectives, 65 iterations)
- The effectiveness of HVI as a scalarization approach for complex Pareto fronts with disconnected regions remains unproven
- One-step lookahead GP approximation accuracy compared to full posterior sampling not thoroughly validated

## Confidence

- **High confidence**: The theoretical framework connecting HVI to Bellman optimality is sound and well-established
- **Medium confidence**: Experimental results showing performance improvements over myopic baselines are promising but limited in scope
- **Low confidence**: Computational scalability claims for NMMO-Joint method need more extensive validation on larger problems

## Next Checks

1. Implement a systematic scalability study testing the NMMO methods on problems with increasing dimensionality (more objectives and variables) to identify computational bottlenecks
2. Conduct ablation studies isolating the impact of the one-step lookahead approximation by comparing against exact posterior sampling on smaller problems
3. Validate the method on problems with known disconnected Pareto fronts to test HVI's effectiveness in capturing complex trade-offs