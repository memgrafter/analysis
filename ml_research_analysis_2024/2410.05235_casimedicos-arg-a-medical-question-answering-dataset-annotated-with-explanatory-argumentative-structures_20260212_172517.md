---
ver: rpa2
title: 'CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory
  Argumentative Structures'
arxiv_id: '2410.05235'
source_url: https://arxiv.org/abs/2410.05235
tags:
- medical
- explanations
- dataset
- language
- argument
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces CasiMedicos-Arg, a multilingual dataset for
  medical question answering with manually annotated argumentative structures. The
  dataset includes 558 clinical cases in English, Spanish, French, and Italian, enriched
  with explanations written by doctors and annotated with argument components (5021
  claims, 2313 premises) and relations (2431 supports, 1106 attacks).
---

# CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures

## Quick Facts
- arXiv ID: 2410.05235
- Source URL: https://arxiv.org/abs/2410.05235
- Authors: Ekaterina Sviridova; Anar Yeginbergen; Ainara Estarrona; Elena Cabrio; Serena Villata; Rodrigo Agerri
- Reference count: 25
- Key outcome: Introduces a multilingual medical QA dataset with manually annotated argumentative structures, including 558 clinical cases in four languages with 5021 claims and 2313 premises, demonstrating multilingual data transfer benefits for argument component detection

## Executive Summary
This paper introduces CasiMedicos-Arg, a multilingual dataset for medical question answering enriched with manually annotated argumentative structures. The dataset contains 558 clinical cases in English, Spanish, French, and Italian, each accompanied by doctor-written explanations and annotated with argument components (claims and premises) and relations (support and attack). To validate the annotations, the authors establish competitive baselines using encoder, encoder-decoder, and decoder-only models, demonstrating that multilingual data transfer outperforms cross-lingual model transfer for argument component detection.

## Method Summary
The dataset construction involved translating the original Spanish CasiMedicos corpus into English, French, and Italian, then projecting English argument annotations to other languages using word alignment tools (AWESOME and Easy Label Projection). Manual corrections were applied to address alignment errors. For baseline evaluation, multiple LLM architectures were fine-tuned on the multilingual data: encoder models (mBERT, mDeBERTa), encoder-decoder models (Medical mT5), and decoder-only models (LLaMa2, Mistral). The models were trained on pooled multilingual data and evaluated separately on each language test set using F1-macro scores for argument component detection.

## Key Results
- Multilingual data transfer (pooling all languages) outperforms cross-lingual model transfer (training on English, testing on other languages) for argument component detection
- Decoder-only generative models (Mistral-0.1-7B) achieve the highest F1 scores, with medical mT5 models performing nearly as well
- The dataset includes 5021 claims and 2313 premises across 558 clinical cases, with 2431 support and 1106 attack relations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual data transfer outperforms cross-lingual model transfer for argument component detection in medical QA.
- Mechanism: Training models on pooled multilingual data from all four languages and evaluating on each language separately yields higher F1 scores than fine-tuning on English only and evaluating on other languages.
- Core assumption: Medical domain knowledge and argumentative structures are transferable across languages when jointly trained.
- Evidence anchors:
  - [abstract] "multilingual data transfer for argument component detection"
  - [section] "multilingual method of pooling all languages into a single dataset proves to be beneficial for every model"
  - [corpus] Weak - related papers focus on argument mining but not specifically medical multilingual transfer
- Break condition: If language-specific medical terminology or argumentation patterns differ significantly across languages, the pooled approach may introduce noise that outweighs benefits.

### Mechanism 2
- Claim: Decoder-only LLMs outperform encoder-only and encoder-decoder models for sequence labeling in medical argument mining.
- Mechanism: Large decoder-only models like Mistral-0.1-7B achieve higher F1 scores due to their pre-training on diverse text and ability to capture complex argumentative relationships.
- Core assumption: Decoder-only architectures possess sufficient linguistic knowledge to perform well on sequence labeling without specialized medical pre-training.
- Evidence anchors:
  - [abstract] "competitive baselines using encoder, encoder-decoder, and decoder-only models"
  - [section] "decoder-only generative models outperform the rest, though the Medical mT5 models are nearly as effective"
  - [corpus] Weak - related papers discuss argument mining but not specific architectural comparisons
- Break condition: If the sequence labeling task requires precise token-level classification that benefits from encoder-specific attention mechanisms, decoder-only models may hallucinate or misclassify.

### Mechanism 3
- Claim: Medical domain knowledge improves argument component detection in medical QA datasets.
- Mechanism: Medical mT5 models trained on multilingual medical texts achieve near state-of-the-art performance by leveraging domain-specific terminology and relationships.
- Core assumption: Domain adaptation provides meaningful improvement over general-purpose language models for specialized tasks.
- Evidence anchors:
  - [abstract] "Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain"
  - [section] "Medical mT5 models are nearly as effective" and "Medical mT5 models, which may be due to this model being trained on multilingual medical data"
  - [corpus] Weak - related papers focus on argument mining but not medical domain adaptation
- Break condition: If the argumentative structures in medical QA are sufficiently general that domain knowledge provides minimal advantage, the performance gain may not justify the additional training complexity.

## Foundational Learning

- Concept: Argumentative structure annotation (claims, premises, support, attack relations)
  - Why needed here: The dataset requires manual annotation of argumentative components to train and evaluate argument mining models
  - Quick check question: Can you distinguish between a claim (conclusion) and a premise (supporting evidence) in a medical explanation?

- Concept: Cross-lingual transfer learning
  - Why needed here: The dataset includes four languages, requiring techniques to project annotations and evaluate model performance across languages
  - Quick check question: What is the difference between data-transfer (training on multiple languages) and model-transfer (training on English, testing on other languages)?

- Concept: Sequence labeling with LLMs
  - Why needed here: Argument component detection is a sequence labeling task that can be performed using various LLM architectures
  - Quick check question: How would you format the input and output for a generative LLM to perform sequence labeling?

## Architecture Onboarding

- Component map: Data ingestion → Annotation projection → Model training → Evaluation → Baseline comparison
- Critical path: Clean and structure original Spanish data → Translate and revise to English, French, Italian → Project English annotations → Post-process projected data → Manual correction by native speakers → Train and evaluate models
- Design tradeoffs: Using projected annotations vs. manual annotation for non-English languages saves time but may introduce alignment errors; pooling multilingual data improves transfer but may add noise
- Failure signatures: Low inter-annotator agreement indicates unclear guidelines; poor cross-lingual performance suggests inadequate projection quality; model overfitting indicates insufficient training data
- First 3 experiments:
  1. Fine-tune mBERT on English gold annotations and evaluate on held-out English test set to establish baseline
  2. Project English annotations to Spanish and fine-tune mBERT on projected Spanish data, evaluating on Spanish test set
  3. Pool English, Spanish, French, and Italian training data and fine-tune mBERT, evaluating separately on each language test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the quality and reliability of explanations generated by LLMs in medical domains be systematically evaluated and validated?
- Basis in paper: [explicit] The paper discusses the need for better evaluation of explanations in medical domains, noting that current methods lack transparency and verified medical knowledge at their core. It mentions that quality assessment of medical explanations remains challenging because the decision-making process is not transparent.
- Why unresolved: The paper identifies this as a significant challenge but does not provide a solution or framework for systematically evaluating LLM-generated medical explanations. While it mentions that explanations need verified medical knowledge and that the decision-making process is not transparent, it does not detail how to ensure explanations meet these criteria.
- What evidence would resolve it: A comprehensive framework or set of metrics specifically designed for evaluating the quality, accuracy, and reliability of medical explanations generated by LLMs, along with empirical validation demonstrating their effectiveness.

### Open Question 2
- Question: What are the most effective methods for projecting argument component annotations across languages while maintaining semantic accuracy and contextual relevance?
- Basis in paper: [explicit] The paper describes using word alignments calculated by AWESOME and Easy Label Projection to project annotations from English to other languages, but notes that a post-processing step was necessary to correct misalignments, particularly with articles at the beginning of argument components and sequences labeled only partially.
- Why unresolved: While the paper presents a projection method, it acknowledges that post-processing corrections were needed and does not fully address how to ensure semantic accuracy and contextual relevance during the projection process, especially for languages with different grammatical structures.
- What evidence would resolve it: Comparative studies showing the effectiveness of different projection methods in maintaining semantic accuracy and contextual relevance, along with detailed analysis of error types and their frequency across different language pairs.

### Open Question 3
- Question: How can multilingual data augmentation strategies be optimized for medical domain-specific tasks while balancing resource constraints and performance gains?
- Basis in paper: [explicit] The paper demonstrates that multilingual data pooling improves performance over monolingual training for argument component detection, but does not explore optimization strategies or analyze the trade-offs between resource usage and performance improvements.
- Why unresolved: The paper shows that multilingual training is beneficial but does not investigate how to optimize the process, such as determining the ideal mix of languages, identifying which language combinations yield the best results, or establishing resource-efficient approaches for different use cases.
- What evidence would resolve it: Empirical studies comparing different multilingual data augmentation strategies, including analyses of optimal language combinations, resource efficiency metrics, and performance trade-offs across various medical domain tasks.

## Limitations
- The dataset size (558 clinical cases) is relatively small for robust model training, particularly in multilingual settings where data sparsity across languages may limit generalization
- The annotation projection approach from English to other languages introduces potential alignment errors that could affect model performance and may not capture language-specific argumentative nuances
- The evaluation focuses primarily on argument component detection rather than end-to-end argumentative structure prediction, leaving uncertainty about how well models would perform on complete argumentative reasoning tasks in medical contexts

## Confidence
- **High Confidence**: The dataset construction methodology (translation, projection, manual correction) is clearly described and follows established practices in cross-lingual annotation transfer. The competitive baseline results demonstrating multilingual data transfer advantages are well-supported by the experimental design and metrics.
- **Medium Confidence**: The architectural comparison between encoder, encoder-decoder, and decoder-only models shows clear performance differences, though the specific conditions under which each architecture excels remain partially explored. The domain adaptation benefits of medical mT5 models are observed but could benefit from more systematic ablation studies.
- **Low Confidence**: The generalizability of these findings to other medical QA datasets or different argumentative structures beyond the CasiMedicos domain. The impact of annotation quality variations across languages on downstream model performance is not fully characterized.

## Next Checks
1. **Cross-Dataset Transfer Validation**: Evaluate the trained models on an independent medical QA dataset with argumentative annotations to assess whether the multilingual transfer learning benefits generalize beyond the CasiMedicos corpus.
2. **Annotation Quality Assessment**: Conduct inter-annotator agreement studies specifically for the projected annotations in non-English languages to quantify the impact of projection errors on model training and performance.
3. **End-to-End Structure Prediction**: Extend the evaluation to include complete argumentative structure prediction (claims, premises, and relations together) rather than just argument component detection, measuring how well models can reconstruct the full argumentative reasoning chain in medical explanations.