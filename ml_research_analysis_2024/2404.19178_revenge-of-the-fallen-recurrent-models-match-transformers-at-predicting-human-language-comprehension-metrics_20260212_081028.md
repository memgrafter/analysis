---
ver: rpa2
title: Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human
  Language Comprehension Metrics
arxiv_id: '2404.19178'
source_url: https://arxiv.org/abs/2404.19178
tags:
- language
- https
- mamba
- reading
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares transformers and two new recurrent architectures
  (RWKV and Mamba) for modeling human language comprehension using neural metrics
  (N400) and reading times. All models are trained on the same data and matched in
  scale.
---

# Revenge of the Fallen? Recurrent Models Match Transformers at Predicting Human Language Comprehension Metrics

## Quick Facts
- arXiv ID: 2404.19178
- Source URL: https://arxiv.org/abs/2404.19178
- Authors: James A. Michaelov; Catherine Arnett; Benjamin K. Bergen
- Reference count: 40
- Key outcome: Recurrent models (RWKV, Mamba) match or exceed transformers at predicting human language comprehension metrics, with Mamba typically outperforming

## Executive Summary
This paper challenges the assumption that transformers are uniquely suited for modeling human language comprehension by comparing them with two newer recurrent architectures (RWKV and Mamba). All models were trained on the same data and matched in scale, revealing that recurrent models often perform comparably or better at predicting N400 amplitude (a neural metric of language comprehension). The study found that transformers excel at predicting eye-tracking metrics, while recurrents perform better on self-paced reading tasks. Crucially, model scaling effects are consistent across architectures—larger models fit positively scaling datasets better, and vice versa. These findings suggest transformers are not uniquely suited to modeling human language comprehension, opening new avenues for cognitive modeling.

## Method Summary
The researchers compared transformers with two recurrent architectures (RWKV and Mamba) using neural metrics (N400) and reading times. All models were trained on identical datasets and scaled to comparable sizes. They evaluated model performance on predicting human language comprehension through multiple behavioral and neural measures, including eye-tracking and self-paced reading metrics. The systematic comparison controlled for architectural differences while examining how different model families capture human language processing patterns.

## Key Results
- Recurrent models (particularly Mamba) often match or exceed transformers at predicting N400 amplitude
- Transformers better predict eye-tracking metrics, while recurrents excel at self-paced reading prediction
- Model scaling effects are consistent across architectures—larger models fit positively scaling datasets better, and vice versa
- These results challenge the assumption that transformers are uniquely suited for modeling human language comprehension

## Why This Works (Mechanism)
The paper suggests that transformers may not be uniquely suited for modeling human language comprehension, as recurrent models can match or exceed their performance on certain metrics. The findings indicate that different architectural approaches may capture different aspects of human language processing, with transformers excelling at some comprehension measures while recurrents perform better on others. The consistent scaling relationships across architectures suggest that model size and dataset characteristics interact predictably regardless of architectural family.

## Foundational Learning
- **N400 amplitude**: A neural response measured through EEG that reflects semantic processing difficulty; needed to understand how well models predict human neural responses to language
- **Eye-tracking metrics**: Behavioral measures of reading patterns that capture real-time comprehension processes; needed to evaluate models' ability to predict human reading behavior
- **Self-paced reading**: A comprehension task where participants control reading speed, revealing processing difficulty; needed to assess models' predictions of incremental language understanding
- **Model scaling relationships**: How model size affects performance on different types of datasets; needed to understand the interaction between architecture capacity and data characteristics
- **Architectural tradeoffs**: The balance between different design choices (attention vs. recurrence) and their impact on modeling human comprehension; needed to inform future cognitive modeling approaches

## Architecture Onboarding

**Component Map:**
Input sequence -> Embedding layer -> Recurrent layers (RWKV/Mamba) OR Transformer layers -> Output layer

**Critical Path:**
Input embedding → Core architecture (recurrent or transformer blocks) → Prediction head → Comprehension metric output

**Design Tradeoffs:**
- Attention mechanisms vs. recurrence for capturing long-range dependencies
- Parameter efficiency vs. modeling capacity
- Training stability vs. performance on specific comprehension metrics
- Generalization across different types of comprehension measures

**Failure Signatures:**
- Poor performance on negatively scaling datasets with small models
- Inconsistent predictions across different comprehension measures
- Inability to capture fine-grained temporal patterns in reading behavior
- Overfitting to specific dataset characteristics rather than general comprehension patterns

**First 3 Experiments:**
1. Train all architectures on positively scaling datasets to verify larger models perform better
2. Compare predictions on self-paced reading vs. eye-tracking to identify architectural strengths
3. Test additional recurrent architectures (LSTMs, GRUs) to determine if findings generalize beyond RWKV and Mamba

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Testing limited to only two recurrent architectures and one transformer architecture
- Findings may not generalize to the broader space of available models
- The theoretical mechanisms underlying scaling relationships warrant further investigation
- Transformers remain dominant in general language modeling tasks outside comprehension modeling

## Confidence

**High confidence:**
- Mamba outperforming other architectures on N400 prediction
- Consistent scaling relationships between model size and dataset characteristics

**Medium confidence:**
- General claim that transformers are not uniquely suited to modeling human language comprehension
- Mixed results on reading time predictions

**Low confidence:**
- Claims about why recurrent models perform well on certain tasks
- Broader implications for cognitive modeling architecture selection

## Next Checks
1. Test additional transformer and recurrent architectures (including LSTMs and GRUs) to determine if findings generalize beyond the specific models studied
2. Conduct ablation studies to identify which architectural features (attention mechanisms, recurrence, etc.) drive performance differences on comprehension metrics
3. Evaluate models on additional comprehension measures beyond N400 and reading times to establish comprehensive performance profiles across the space of human language processing phenomena