---
ver: rpa2
title: Self-supervised denoising of visual field data improves detection of glaucoma
  progression
arxiv_id: '2411.12146'
source_url: https://arxiv.org/abs/2411.12146
tags:
- progression
- data
- visual
- field
- glaucoma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of noisy visual field data in glaucoma
  detection, which exhibits high variance especially with increasing damage. The authors
  propose a self-supervised deep learning approach to denoise visual field data from
  over 4,000 patients, aiming to enhance signal-to-noise ratio and improve detection
  of true glaucoma progression.
---

# Self-supervised denoising of visual field data improves detection of glaucoma progression

## Quick Facts
- arXiv ID: 2411.12146
- Source URL: https://arxiv.org/abs/2411.12146
- Reference count: 28
- Primary result: 4.7% increase in detection of progressing eyes and 2.3 months earlier prediction of glaucoma progression

## Executive Summary
This paper addresses the challenge of noisy visual field data in glaucoma detection by proposing a self-supervised deep learning approach for denoising. The method processes visual field data from over 4,000 patients to enhance signal-to-noise ratio and improve detection of true glaucoma progression. By comparing variational autoencoders and masked autoencoders, the authors demonstrate that the masked autoencoder approach, particularly when incorporating categorical p-values at each visual field location, leads to cleaner denoised data and more effective progression detection.

## Method Summary
The core approach uses two neural network architectures - a variational autoencoder (VAE) and a masked autoencoder - to denoise visual field data while reconstructing salient features. Both models are trained on data from 4,232 patients (16,924 exams) using Humphrey Field Analyzer II 24-2 VF tests with 52 locations. The masked autoencoder masks ten random visual field locations during training and has been found more effective than VAEs. The authors incorporate categorical p-values at each location to improve denoising quality. Training parameters include batch size 32, Adam optimizer with learning rate 0.0001, and a 5-layer architecture with PyTorch seed 42.

## Key Results
- Masked autoencoder with p-values led to cleaner denoised data than previous methods
- 4.7% increase in detection of progressing eyes using pointwise linear regression (PLR)
- Predicted glaucoma progression 2.3 months earlier compared to when p-values were not included

## Why This Works (Mechanism)
The masked autoencoder improves glaucoma progression detection by leveraging self-supervised learning to smooth noisy visual field data while preserving important diagnostic features. By masking random visual field locations during training, the model learns to reconstruct missing information based on surrounding context, effectively denoising the data. The incorporation of categorical p-values at each location provides additional statistical information that helps distinguish true progression from noise, resulting in more reliable detection of visual field changes.

## Foundational Learning
- Variational Autoencoders (VAEs): Generative models that learn probability distributions of input data - needed for understanding the baseline comparison method; quick check: VAEs should reconstruct input data while learning latent representations
- Masked Autoencoders: Self-supervised models that mask random input locations during training - needed for understanding the core denoising approach; quick check: masked autoencoders should effectively reconstruct masked elements
- Pointwise Linear Regression (PLR): Statistical method for detecting visual field progression - needed for evaluating model performance; quick check: PLR should identify statistically significant deterioration over time
- Humphrey Field Analyzer 24-2 VF: Standard visual field test with 52 test locations - needed for understanding input data format; quick check: data should exclude blind spots and be normalized
- Categorical p-values: Statistical significance indicators for each visual field location - needed for understanding the p-value incorporation method; quick check: p-values should be properly encoded as input features

## Architecture Onboarding

Component map:
Visual Field Data -> Masked Autoencoder with P-values -> Denoised Output -> PLR Progression Analysis

Critical path: The critical path flows from raw visual field data through the masked autoencoder (with p-value incorporation) to PLR analysis, as this sequence directly enables the improved progression detection.

Design tradeoffs: The authors chose masked autoencoders over VAEs for better denoising performance, and incorporated p-values to enhance statistical reliability. The tradeoff is increased model complexity and potential overfitting risk versus improved progression detection accuracy.

Failure signatures: Poor progression detection rates indicate architectural mismatches or hyperparameter issues. Overfitting manifests as excellent performance on training data but poor generalization to new patients.

First experiments:
1. Implement basic masked autoencoder without p-values to establish baseline performance
2. Add p-value incorporation to compare with baseline and validate the 4.7% improvement claim
3. Test different numbers of masked locations (e.g., 5, 10, 15) to find optimal masking strategy

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Would incorporating recurrent neural networks, specifically Long Short-Term Memory (LSTM) networks, into the denoising architecture further improve the detection of glaucoma progression compared to the current masked autoencoder approach?
- Basis in paper: The authors suggest that utilizing recurrent neural networks like LSTM could leverage past and future visual field data to better smooth current data based on learned patient input patterns.
- Why unresolved: The paper only mentions this as a potential area for future research and does not test or validate the effectiveness of LSTMs in this context.
- What evidence would resolve it: Comparative studies demonstrating whether LSTM-based models outperform the current masked autoencoder approach in terms of progression detection rates and time to progression predictions.

### Open Question 2
- Question: How does the performance of masked autoencoders compare to Convolutional Neural Networks (CNNs) when applied to the grayscale representation of 24-2 central visual field tests?
- Basis in paper: The authors propose utilizing CNNs on the grayscale representation of 24-2 central visual field tests as a potential area for improvement, suggesting it may contribute to more effective diagnosis of glaucoma progression compared to the numerical format.
- Why unresolved: The paper does not test or validate the effectiveness of CNNs on grayscale representations, leaving this comparison unexplored.
- What evidence would resolve it: Empirical studies comparing the performance of masked autoencoders and CNNs on grayscale visual field data in terms of denoising quality and progression detection accuracy.

### Open Question 3
- Question: What is the optimal number and distribution of masked visual field locations during training to maximize the denoising performance of the masked autoencoder?
- Basis in paper: The authors use a fixed approach of masking ten random visual field locations during training, but do not explore the impact of varying the number or distribution of masked locations.
- Why unresolved: The paper does not investigate the sensitivity of the model's performance to different masking strategies, leaving the optimal configuration unknown.
- What evidence would resolve it: Systematic experiments varying the number and distribution of masked locations to determine the configuration that yields the best denoising performance and progression detection accuracy.

## Limitations
- Exact architecture details of the 5-layer neural networks remain unspecified, making precise replication difficult
- Specific p-value encoding method is not detailed, which could impact denoising effectiveness
- The study focuses on 24-2 VF tests and may not generalize to other visual field testing formats

## Confidence
- Method reproducibility: Medium - general approach is clear but specific implementation details are missing
- Performance claims: Medium - results are promising but exact architecture and hyperparameters are unspecified
- Clinical applicability: High - the approach addresses a well-documented problem in glaucoma diagnosis

## Next Checks
1. Implement and test multiple network architectures (varying layer sizes and activation functions) to identify the configuration that best reproduces the reported progression detection improvements
2. Experiment with different p-value encoding schemes to determine which method most effectively enhances denoising performance
3. Conduct ablation studies removing p-values to quantify their exact contribution to the 4.7% improvement in progression detection