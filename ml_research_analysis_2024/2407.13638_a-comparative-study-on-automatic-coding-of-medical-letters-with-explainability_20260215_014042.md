---
ver: rpa2
title: A Comparative Study on Automatic Coding of Medical Letters with Explainability
arxiv_id: '2407.13638'
source_url: https://arxiv.org/abs/2407.13638
tags:
- codes
- coding
- each
- which
- snomed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores automating medical letter coding using NLP
  and ML with explainable AI. The HAN/HLAN models were applied to MIMIC-III for ICD
  prediction, with ICD-SNOMED mappings implemented.
---

# A Comparative Study on Automatic Coding of Medical Letters with Explainability

## Quick Facts
- arXiv ID: 2407.13638
- Source URL: https://arxiv.org/abs/2407.13638
- Reference count: 21
- Key outcome: HAN model applied to MIMIC-III for ICD prediction with 97.98% SNOMED mapping success

## Executive Summary
This study explores automating medical letter coding using NLP and ML with explainability. The HAN/HLAN models were applied to MIMIC-III for ICD prediction, with ICD-SNOMED mappings implemented. The system successfully mapped 97.98% of codes, providing either direct SNOMED codes or relevant descriptions. While model performance on full MIMIC-III was modest (macro F1: 0.041, micro F1: 0.403, precision@15: 0.599), the explainability feature proved valuable for verification. Results suggest potential for real-world implementation with dataset improvements targeting more diverse clinical scenarios beyond discharge summaries.

## Method Summary
The study employed Hierarchical Attention Networks (HAN/HLAN) trained on MIMIC-III discharge summaries for ICD-9 code prediction. Text was preprocessed and converted to word embeddings, then processed through bidirectional GRUs with label-wise attention mechanisms. The model outputs predicted ICD codes with attention visualizations highlighting relevant text regions. ICD codes were mapped to SNOMED CT using UMLS mapping files, providing standardized medical terminology for predicted codes.

## Key Results
- HAN model achieved macro F1: 0.041, micro F1: 0.403, precision@15: 0.599 on full MIMIC-III
- ICD-SNOMED mapping success rate of 97.98% of codes
- Attention visualization provided interpretable explanations for code predictions
- Stakeholder evaluation revealed poor performance on non-discharge summary clinical letters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical label-wise attention enables model to selectively focus on document regions most relevant to each ICD code, improving interpretability and precision.
- Mechanism: The model processes text through bidirectional GRUs, generating hidden states for each token. For each label, it computes attention scores using a label-specific context vector. These scores weight the hidden states to form sentence and document representations, which are then used for code prediction.
- Core assumption: Different parts of a medical document are relevant to different codes, and the model can learn to identify these parts via attention.
- Evidence anchors:
  - [abstract] "we explore the function of explainability for transparency of AI models"
  - [section 3.3] "The label wise word-level attention mechanism, which contains a context matrix (Vw) where each row Vwl, is the context vector to the corresponding label yl. The attention score is calculated as a SoftMax function of the dot product similarity between the vector representation of the hidden layers from the Bi-GRU and the context vector for the same label."
- Break condition: If the context vectors are not well-aligned with the semantic meaning of codes, or if the attention mechanism fails to capture long-range dependencies, the model's precision and explainability will degrade.

### Mechanism 2
- Claim: Mapping ICD codes to SNOMED CT via one-to-one and one-to-many relationships allows the system to provide richer, standardized medical terminology for the predicted codes.
- Mechanism: The system loads ICD-SNOMED mapping files, creates dictionaries for one-to-one and one-to-many mappings, and looks up each predicted ICD code. For one-to-one matches, it outputs the SNOMED code and fully specified name (FSN). For one-to-many, it outputs all relevant SNOMED codes. If no mapping exists, it returns the ICD code description.
- Core assumption: ICD codes can be meaningfully linked to SNOMED CT concepts, and these mappings cover most clinically relevant codes.
- Evidence anchors:
  - [abstract] "We also experimented with the mapping between ICD and SNOMED CT knowledge bases. In our experiments, the models provided useful information for 97.98% of codes."
  - [section 4.2] "The map was originally created for the Unified Medical Language System (UMLS) to facilitate the translation of legacy data still coded in ICD-9 to SNOMED CT codes."
- Break condition: If ICD and SNOMED terminologies diverge (e.g., due to different versions or scopes), many codes will have no mapping, reducing the system's utility.

### Mechanism 3
- Claim: Using pre-trained word embeddings and fine-tuning on MIMIC-III data allows the model to leverage semantic knowledge and adapt to the specific language of clinical notes.
- Mechanism: The model starts with word2vec embeddings trained on a large corpus, capturing semantic relationships between tokens. During training on MIMIC-III, these embeddings are fine-tuned to the domain-specific language of medical notes, improving the model's ability to map text to relevant ICD codes.
- Core assumption: The semantic relationships captured by pre-trained embeddings are transferable to the clinical domain, and fine-tuning on MIMIC-III data adapts these embeddings to the specific language of medical notes.
- Evidence anchors:
  - [section 2.2] "Each embedding is a semantically meaningful mathematical representation, usually a vector, of the token designed so that tokens with similar meanings have similar vectors"
  - [section 3.4] "It then adopts the general domain pre-trained XLNet... which is further trained on MIMIC, and then applied to every chunk."
- Break condition: If the pre-trained embeddings are not representative of the clinical domain, or if the MIMIC-III data is not diverse enough, the fine-tuning process may not effectively adapt the embeddings to the task.

## Foundational Learning

- Concept: Attention mechanisms in neural networks
  - Why needed here: Attention allows the model to focus on the most relevant parts of the input text for each ICD code prediction, improving both performance and interpretability.
  - Quick check question: How does the attention score for a token relate to its importance for a particular code?

- Concept: Multi-label classification
  - Why needed here: Medical notes often contain multiple diagnoses and procedures, so the model must be able to assign multiple ICD codes to a single document.
  - Quick check question: What is the difference between multi-class and multi-label classification, and why is multi-label more appropriate for this task?

- Concept: Word embeddings and transfer learning
  - Why needed here: Pre-trained word embeddings capture semantic relationships between tokens, which can be fine-tuned on the clinical domain to improve the model's understanding of medical language.
  - Quick check question: How do word embeddings enable the model to understand the semantic meaning of words, and why is transfer learning beneficial in this context?

## Architecture Onboarding

- Component map:
  - Clinical notes (discharge summaries) -> Text preprocessing and tokenization -> Word embedding lookup -> HAN model with bidirectional GRUs and label-wise attention -> ICD code predictions with attention visualizations -> ICD to SNOMED mapping -> Output results

- Critical path:
  - Preprocess clinical notes -> Run through HAN model -> Generate ICD code predictions and attention maps -> Map ICD codes to SNOMED CT -> Output results

- Design tradeoffs:
  - HAN vs. CNN: HAN provides better interpretability through attention mechanisms but may be less computationally efficient than CNN-based models like CAML.
  - Full MIMIC-III vs. MIMIC-III-50: Full MIMIC-III provides more diverse training data but requires more computational resources and may have a long-tail distribution of codes.
  - ICD-9 vs. ICD-10: ICD-9 is used in this study due to MIMIC-III's coding, but ICD-10 is more recent and comprehensive.

- Failure signatures:
  - Low macro F1 score: Model struggles with rare or diverse codes, possibly due to insufficient training data or model capacity.
  - High number of "no map" results: ICD-SNOMED mappings are incomplete or mismatched, reducing the system's utility.
  - Attention maps not highlighting relevant text: Attention mechanism fails to capture important information, possibly due to poor context vectors or inadequate training.

- First 3 experiments:
  1. Train HAN model on MIMIC-III-50 and evaluate performance on MIMIC-III Full to assess generalization to diverse codes.
  2. Compare HAN model with and without label embedding initialization to quantify the impact of leveraging ICD code semantics.
  3. Implement and evaluate ICD-SNOMED mapping on a subset of MIMIC-III codes to identify gaps and potential improvements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the HAN model perform significantly worse on real-world clinical letters compared to MIMIC-III discharge summaries?
- Basis in paper: [explicit] The stakeholder evaluation showed poor performance on non-discharge summary letters, with only one correct prediction out of six test cases.
- Why unresolved: The paper attributes this to overfitting on MIMIC-III discharge summaries but doesn't investigate whether domain adaptation or fine-tuning on diverse clinical letter types could resolve this gap.
- What evidence would resolve it: Comparative experiments showing HAN performance on a dataset containing diverse clinical letter types (referral letters, prescription requests, etc.) after fine-tuning or domain adaptation training.

### Open Question 2
- Question: How would the system perform if trained on a dataset that includes non-hospitalization cases and represents the full range of SNOMED terminology hierarchies?
- Basis in paper: [explicit] The authors note that MIMIC-III only contains hospitalization-related diagnoses and procedures, missing common conditions like ear infections and psoriasis that appear in regular clinical practice.
- Why unresolved: The study uses only MIMIC-III data and doesn't explore whether expanding the training corpus to include outpatient and general practice scenarios would improve performance.
- What evidence would resolve it: Training and testing the model on a newly created dataset containing diverse clinical scenarios from primary care settings and measuring performance improvements.

### Open Question 3
- Question: Would transformer-based models like MHLAT outperform HAN when applied to real-world clinical letters, despite their computational complexity?
- Basis in paper: [explicit] MHLAT showed state-of-the-art results on MIMIC-III-50 but wasn't evaluated on full MIMIC-III or real clinical letters due to computational constraints.
- Why unresolved: The paper doesn't explore whether the superior performance of transformer models on limited datasets translates to better generalization on diverse real-world clinical text.
- What evidence would resolve it: Comparative experiments training MHLAT or similar transformer models on diverse clinical letter datasets and evaluating their performance against HAN on both discharge summaries and general clinical correspondence.

## Limitations
- Model performance on full MIMIC-III is modest (macro F1: 0.041), indicating significant room for improvement.
- Reliance on discharge summaries only limits generalizability to other clinical document types.
- ICD-SNOMED mapping success depends on external mapping files whose quality and coverage are not independently verified.

## Confidence
- **High Confidence**: The hierarchical attention mechanism implementation and SNOMED mapping procedure are well-documented and reproducible. The explainability features function as described.
- **Medium Confidence**: The model architecture and training procedures are clearly specified, but the exact hyperparameters and pretrained model versions are not provided, which could affect replication fidelity.
- **Low Confidence**: The generalizability claim from discharge summaries to "real-world" clinical letters lacks empirical validation beyond stakeholder consultation.

## Next Checks
1. **Generalization Testing**: Evaluate the trained HAN model on actual clinical letters from the stakeholder's system to verify the claimed transferability from MIMIC discharge summaries.
2. **Mapping Coverage Audit**: Conduct a systematic audit of ICD-SNOMED mappings for the predicted codes to identify gaps or mismatches, particularly for rare codes where the model underperforms.
3. **Architecture Ablation Study**: Implement and compare the HAN model with the CNN-based CAML model to empirically validate the claimed tradeoff between interpretability and performance.