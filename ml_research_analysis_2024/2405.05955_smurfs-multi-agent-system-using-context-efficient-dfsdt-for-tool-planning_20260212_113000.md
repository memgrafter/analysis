---
ver: rpa2
title: 'Smurfs: Multi-Agent System using Context-Efficient DFSDT for Tool Planning'
arxiv_id: '2405.05955'
source_url: https://arxiv.org/abs/2405.05955
tags:
- tool
- agent
- smurfs
- planning
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of enabling large language models
  to use external tools for solving complex tasks, focusing on improving the context
  efficiency and stability of multi-tool planning systems. It introduces "Smurfs,"
  a novel multi-agent system (MAS) that enhances the Deep First Search Decision Tree
  (DFSDT) with a modular, context-efficient, and training-free design.
---

# Smurfs: Multi-Agent System using Context-Efficient DFSDT for Tool Planning

## Quick Facts
- arXiv ID: 2405.05955
- Source URL: https://arxiv.org/abs/2405.05955
- Authors: Junzhi Chen; Juhao Liang; Benyou Wang
- Reference count: 27
- One-line primary result: Smurfs achieves state-of-the-art performance on both open-ended (StableToolBench) and closed-ended (HotpotQA) benchmarks, reducing token usage by 60.9% compared to DFSDT.

## Executive Summary
This paper introduces Smurfs, a novel multi-agent system (MAS) that enhances the Deep First Search Decision Tree (DFSDT) with a modular, context-efficient, and training-free design. Smurfs addresses the limitations of DFSDT, including rollback instability, redundant context, and premature termination, by decomposing tasks into sub-tasks and using specialized agents (Planning, Executor, Answer, Verifier) with a rule-based rollback mechanism and context compression. The system achieves state-of-the-art performance on both open-ended (StableToolBench) and closed-ended (HotpotQA) benchmarks, significantly reducing token usage and enabling weaker models like Mistral-7b to perform on par with GPT-4-DFSDT.

## Method Summary
Smurfs is a multi-agent system that improves upon the Deep First Search Decision Tree (DFSDT) by introducing a modular, context-efficient, and training-free design. It decomposes complex tasks into simpler sub-tasks using a Planning Agent, which are then solved by Executor Agents with localized context to prevent interference from irrelevant historical data. The system implements a rule-based rollback mechanism for stability and uses an Answer Agent to compress context, mitigating the 'lost-in-the-middle' problem. Smurfs is evaluated on StableToolBench and HotpotQA benchmarks, demonstrating superior performance and context efficiency compared to baseline methods like ReAct and DFSDT.

## Key Results
- Smurfs achieves state-of-the-art performance on both StableToolBench (open-ended) and HotpotQA (closed-ended) benchmarks.
- Smurfs reduces token usage by 60.9% compared to DFSDT.
- Mistral-7b using Smurfs performs on par with GPT-4-DFSDT.
- Extensive ablation studies confirm the effectiveness of Smurfs' core components.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-agent decomposition reduces cognitive load on individual agents, enabling more reliable tool use.
- Mechanism: The Planning Agent breaks the complex task into simpler sub-tasks, each solvable with a single tool. Executor Agents operate on localized context (local memory + current tool list), preventing interference from irrelevant historical data.
- Core assumption: Smaller, focused reasoning contexts improve model performance compared to processing entire conversation history.
- Evidence anchors:
  - [abstract] "By dividing tasks among different agents, each agent can focus on a specific part of the task, accessing only the necessary history as context during task execution, which effectively addresses the issue of redundant context."
  - [section 3.4] "Each inference process only uses the relevant part from the local memory and tool list to reduce the context redundancy."
- Break condition: If the sub-task decomposition is too coarse, the Executor Agent may still need to handle complex reasoning beyond its capability.

### Mechanism 2
- Claim: The rule-based rollback mechanism improves stability compared to model-driven rollback.
- Mechanism: When a tool fails, it is removed from the tool list and the step is retried. If the tool list becomes empty, the system backtracks to the previous step and removes the failed tool from that step's tool list. This deterministic process avoids incorrect rollback decisions by the base model.
- Core assumption: A simple, deterministic rollback strategy is more reliable than relying on the model to decide rollback depth and tool selection.
- Evidence anchors:
  - [section 3.4] "This rule-based rollback mechanism, compared to the original model-based rollback mechanism of DFSDT, is less flexible and might reduce rollback efficiency. However, it is more stable, ensuring the correctness of deep first search and enabling models with weaker capabilities to utilize DFSDT on tool planning."
  - [section 2] "The rollback mechanism in DFSDT is determined by the model... When the model's capability is insufficient, it will fail to execute the correct rollback mechanism."
- Break condition: If the task requires revisiting a tool that was incorrectly removed from the tool list, the system cannot recover.

### Mechanism 3
- Claim: The Answer Agent compresses context, mitigating the 'lost-in-the-middle' problem and improving performance.
- Mechanism: After each tool execution, the Answer Agent summarizes the relevant findings into concise natural language, which is stored in memory. This prevents the memory from being filled with verbose tool responses that could distract the model.
- Core assumption: Retaining only essential information in memory improves model reasoning compared to storing full tool responses.
- Evidence anchors:
  - [abstract] "The Answer Agent compiles the findings into a cohesive response, which is subsequently verified by the Verifier Agent to ensure accuracy and relevance."
  - [section 3.4] "To mitigate the performance degradation caused by lengthy contexts, we introduce the Answer Agent role, designed to extract crucial content for each step and sub-problem."
- Break condition: If the Answer Agent's summary is too lossy, the model may lose critical information needed for subsequent reasoning steps.

## Foundational Learning

- Concept: Deep First Search Decision Tree (DFSDT)
  - Why needed here: DFSDT is the baseline method that Smurfs enhances. Understanding its limitations (rollback instability, redundant context, premature termination) is crucial to appreciating Smurfs' contributions.
  - Quick check question: What are the three main limitations of DFSDT identified in the paper?
- Concept: Context Efficiency
  - Why needed here: Smurfs achieves context efficiency through memory segmentation (local vs. global) and the Answer Agent. This is key to its performance advantage.
  - Quick check question: How does Smurfs reduce context redundancy compared to DFSDT?
- Concept: Multi-Agent Systems (MAS)
  - Why needed here: Smurfs is a MAS framework. Understanding the benefits of task decomposition and specialized agent roles is essential for grasping its design.
  - Quick check question: What are the four main agents in Smurfs and their primary responsibilities?

## Architecture Onboarding

- Component map:
  - Planning Agent -> Executor Agent -> Answer Agent -> Verifier Agent -> (repeat or finish)
- Critical path: Planning Agent → Executor Agent → Answer Agent → Verifier Agent → (repeat or finish).
- Design tradeoffs:
  - Flexibility vs. Stability: Smurfs sacrifices some rollback flexibility for greater stability.
  - Context Richness vs. Efficiency: Smurfs compresses context to improve efficiency, but risks losing information.
  - Model Capability vs. Agent Complexity: Weaker models benefit more from complex MAS, while stronger models may prefer simpler workflows.
- Failure signatures:
  - Executor Agent repeatedly fails to generate valid tool arguments → indicates the base model's tool use capability is insufficient.
  - Verifier Agent frequently requests retries → suggests the task decomposition is too complex or the hints are ineffective.
  - Answer Agent's summaries are too brief → may lead to loss of critical information.
- First 3 experiments:
  1. Run Smurfs on a simple StableToolBench task and verify that the Planning Agent correctly decomposes the task.
  2. Test the Executor Agent's ability to select and execute a single tool on a sub-task.
  3. Verify that the Answer Agent correctly summarizes a tool response and that the Verifier Agent accurately assesses task completion.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of agents and workflow for multi-tool planning systems across different model capabilities?
- Basis in paper: [inferred] The ablation study suggests that weaker models benefit more from complex multi-agent systems and context segmentation, while stronger models perform better with comprehensive context and simpler agent systems.
- Why unresolved: The paper only provides initial observations and a hypothesis. More extensive ablation studies are needed under a wider range of models and constraints to explore the influence of different context structures and reasoning workflows.
- What evidence would resolve it: Conducting comprehensive ablation studies with a wider range of models (varying sizes and capabilities) and systematically testing different agent configurations and workflows would provide concrete evidence to support or refute the hypothesis.

### Open Question 2
- Question: How can the Smurfs framework be adapted to new domains beyond tool planning, such as facilitating the synthesis of high-quality multi-tool planning data?
- Basis in paper: [inferred] The conclusion mentions that future research could focus on exploring Smurfs' use in new domains, including facilitating the synthesis of high-quality multi-tool planning data and enhancing the base model's reasoning and tool-use abilities.
- Why unresolved: The paper does not explore or test the framework's applicability to other domains. It only mentions potential future directions without providing concrete evidence or methodologies.
- What evidence would resolve it: Implementing the Smurfs framework in a new domain (e.g., data synthesis) and evaluating its effectiveness compared to existing methods would demonstrate its adaptability and potential for broader applications.

### Open Question 3
- Question: What are the limitations of the current memory system in Smurfs, and how can it be improved for better context efficiency?
- Basis in paper: [explicit] The paper describes the local-global combined memory system in Smurfs but acknowledges that it ensures context efficiency during the task-solving process without explicitly stating its limitations.
- Why unresolved: The paper does not discuss potential limitations or areas for improvement in the memory system. It only describes the current implementation without evaluating its efficiency or scalability.
- What evidence would resolve it: Analyzing the memory usage and context efficiency of the Smurfs framework in various tasks and comparing it to alternative memory architectures would highlight its strengths and weaknesses, providing insights for potential improvements.

## Limitations
- The rule-based rollback mechanism, while more stable, might not be as flexible or efficient as a model-driven approach in certain scenarios.
- The performance of Smurfs is dependent on the quality of the tool list and API cache, which may not be comprehensive or up-to-date for all domains.
- The scalability of the multi-agent approach is uncertain for very complex tasks due to the computational expense of managing multiple agents and their interactions.

## Confidence
- **High Confidence:** The core claims about Smurfs' context efficiency and stability improvements over DFSDT are well-supported by the experimental results on both StableToolBench and HotpotQA.
- **Medium Confidence:** The claim that Smurfs enables weaker models (like Mistral-7b) to perform on par with stronger models (like GPT-4) is supported by the results, but the generalizability of this finding to other domains or tasks is uncertain.
- **Low Confidence:** The assertion that Smurfs is universally superior to single-agent approaches like ReAct is not fully substantiated, as the paper does not provide a comprehensive comparison across all relevant benchmarks or task types.

## Next Checks
1. **Scalability Test:** Evaluate Smurfs on a more complex task or dataset to assess its performance and computational efficiency as the task complexity increases.
2. **Generalizability Assessment:** Test Smurfs on a diverse set of domains or tasks to determine its effectiveness beyond the StableToolBench and HotpotQA benchmarks.
3. **Comparison with Advanced Single-Agent Methods:** Compare Smurfs with the latest single-agent approaches that incorporate advanced techniques like tool learning or parallel tool invocation to determine if the multi-agent approach still provides a significant advantage.