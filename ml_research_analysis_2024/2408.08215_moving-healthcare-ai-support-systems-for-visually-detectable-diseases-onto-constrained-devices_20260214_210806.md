---
ver: rpa2
title: Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto
  Constrained Devices
arxiv_id: '2408.08215'
source_url: https://arxiv.org/abs/2408.08215
tags:
- cloud
- devices
- classification
- system
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This pilot study explores using tinyML to provide healthcare support
  with low-spec devices in low-connectivity environments, focusing on diagnosing skin
  diseases and the ethical use of AI assistants in healthcare. To investigate this,
  10,000 images of skin lesions were used to train a model for classifying visually
  detectable diseases (VDDs).
---

# Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices

## Quick Facts
- **arXiv ID**: 2408.08215
- **Source URL**: https://arxiv.org/abs/2408.08215
- **Reference count**: 40
- **Primary result**: 78% test accuracy achieved for skin lesion classification using tinyML on Raspberry Pi without internet access

## Executive Summary
This pilot study demonstrates the feasibility of deploying healthcare AI systems for visually detectable diseases on constrained devices in low-connectivity environments. Using 10,000 skin lesion images, researchers trained a model to classify visually detectable diseases and deployed it on a Raspberry Pi with webcam for offline operation. The prototype achieved 78% test accuracy with a test loss of 1.08, suggesting potential for medical support in resource-limited settings. The work addresses the critical challenge of bringing AI diagnostic tools to areas with limited internet connectivity while maintaining ethical considerations for healthcare applications.

## Method Summary
The study utilized 10,000 images of skin lesions to train a classification model for visually detectable diseases. After training, the model weights were offloaded to a Raspberry Pi equipped with a webcam for local inference without requiring internet connectivity. The approach focused on tinyML deployment, enabling the system to operate in low-connectivity environments. The training process and specific model architecture details were not fully disclosed in the available information.

## Key Results
- Achieved 78% test accuracy on skin lesion classification task
- Test loss measured at 1.08, indicating moderate model performance
- Successfully deployed model on Raspberry Pi for offline operation
- Demonstrated feasibility of tinyML approach for healthcare diagnostics

## Why This Works (Mechanism)
The system works by leveraging compressed neural network models optimized for resource-constrained devices. The Raspberry Pi processes image inputs from the webcam through the pre-trained model, which has been specifically designed to operate within the memory and computational limitations of the device. The offline capability is enabled by storing the model weights locally, eliminating the need for cloud connectivity while maintaining diagnostic functionality.

## Foundational Learning
- **tinyML deployment principles**: Essential for understanding how to compress and optimize models for edge devices with limited resources
  - Why needed: Enables AI functionality on devices with restricted computational power
  - Quick check: Verify model size and inference time on target hardware
- **Skin lesion classification**: Critical for medical AI applications in dermatology
  - Why needed: Provides the clinical context for evaluating diagnostic accuracy
  - Quick check: Compare model performance against medical expert benchmarks
- **Edge computing constraints**: Fundamental for designing systems that operate without cloud connectivity
  - Why needed: Determines the feasibility of deployment in low-connectivity environments
  - Quick check: Measure memory usage and processing latency under real conditions
- **Medical AI ethics**: Important for responsible deployment of diagnostic tools
  - Why needed: Ensures patient safety and appropriate use of AI in healthcare
  - Quick check: Review ethical framework and validation protocols

## Architecture Onboarding

**Component Map**: Image Capture -> Preprocessing -> Inference Engine -> Classification Output

**Critical Path**: The system's performance is limited by the inference engine's ability to process images quickly enough for practical use. The Raspberry Pi's CPU/GPU capabilities determine the classification speed, which directly impacts clinical utility. Model size and memory constraints on the device create the primary bottleneck for accuracy versus performance tradeoffs.

**Design Tradeoffs**: Accuracy (78%) versus computational efficiency - higher accuracy models may exceed Raspberry Pi's processing capabilities. Memory usage versus model complexity - larger models provide better classification but may not fit within device constraints. Real-time performance versus thorough analysis - faster inference may sacrifice diagnostic detail.

**Failure Signatures**: Poor lighting conditions causing classification errors, network connectivity issues (though designed for offline use), model drift over time requiring retraining, hardware failures on Raspberry Pi affecting inference reliability, and false positives/negatives in critical medical diagnoses.

**3 First Experiments**:
1. Measure inference latency with live webcam feed versus static images to assess real-world usability
2. Test model performance across different skin tones and lighting conditions to evaluate robustness
3. Compare classification accuracy against medical expert diagnosis on a validation set

## Open Questions the Paper Calls Out
None

## Limitations
- Missing implementation details including model architecture and compression techniques
- No validation of real-world clinical utility or user studies with healthcare providers
- Lack of comparison to baseline models or state-of-the-art approaches in medical imaging

## Confidence
- **Model Performance Claims**: Low confidence - insufficient architectural and validation details provided
- **Deployment Feasibility**: Low confidence - missing critical metrics on inference speed and memory usage
- **Ethical Considerations**: Medium confidence - mentions ethics but lacks detailed framework or analysis

## Next Checks
1. Replicate the classification pipeline using the same dataset with published model architecture and hyperparameters to verify the 78% accuracy claim
2. Measure inference latency and memory usage on the Raspberry Pi under realistic conditions (live video feed vs static images)
3. Conduct user studies with healthcare providers to assess the system's clinical utility and identify potential ethical concerns in real deployment scenarios