---
ver: rpa2
title: On Few-Shot Prompting for Controllable Question-Answer Generation in Narrative
  Comprehension
arxiv_id: '2404.02800'
source_url: https://arxiv.org/abs/2404.02800
tags:
- question
- questions
- answer
- narrative
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study proposes a few-shot prompting strategy for controllable
  question-answer generation in narrative comprehension. The method uses prompt engineering
  to control two attributes: question explicitness and underlying narrative elements.'
---

# On Few-Shot Prompting for Controllable Question-Answer Generation in Narrative Comprehension

## Quick Facts
- arXiv ID: 2404.02800
- Source URL: https://arxiv.org/abs/2404.02800
- Authors: Bernardo Leite; Henrique Lopes Cardoso
- Reference count: 10
- Key outcome: Few-shot prompting strategy controls question explicitness and narrative elements in narrative comprehension, improving semantic closeness to ground truth and outperforming a reference fine-tuned model in some scenarios.

## Executive Summary
This study proposes a few-shot prompting strategy for controllable question-answer generation in narrative comprehension. The method uses prompt engineering to control two attributes: question explicitness and underlying narrative elements. Evaluation shows the few-shot approach can generate questions semantically closer to ground truth, especially for controlling narrative elements. It also outperforms a reference fine-tuned model in some scenarios regarding question diversity and answer coherence. While improvements are not always statistically significant, the results demonstrate the potential of few-shot prompting for controllable educational question generation.

## Method Summary
The study uses few-shot prompting with GPT-3.5 to generate controllable question-answer pairs for narrative comprehension. Prompts are constructed with 5 examples and control attributes for narrative elements (e.g., character, setting) and explicitness (explicit/implicit). A reference model (T5-large) is fine-tuned for comparison. Evaluation uses semantic similarity metrics (BLEU, ROUGE, BLEURT), QA system performance, and linguistic quality measures.

## Key Results
- Few-shot prompting generates questions semantically closer to ground truth, especially when controlling narrative elements.
- The few-shot approach outperforms the reference fine-tuned model in some scenarios regarding question diversity and answer coherence.
- Increasing the number of prompt examples improves controllability for both narrative and explicitness attributes.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Few-shot prompting improves semantic closeness to ground truth by aligning generated questions with the desired narrative element.
- Mechanism: Conditioning the prompt with specific narrative element labels ("character", "setting", etc.) biases the model to generate questions that semantically match the target element.
- Core assumption: The language model can recognize and replicate the semantic patterns associated with each narrative element when prompted.
- Evidence anchors:
  - [abstract]: "Evaluation shows the few-shot approach can generate questions semantically closer to ground truth, especially for controlling narrative elements."
  - [section]: "Hypothesis (1) is that generated questions will be closer to the ground truth when control attributes are incorporated."
  - [corpus]: Weak - no direct mention of narrative alignment in neighbors.
- Break condition: If the prompt examples do not cover the full range of narrative element variations, the model may default to generic question forms.

### Mechanism 2
- Claim: Adding explicitness control attributes leads to better question-answer alignment as measured by a QA system.
- Mechanism: By explicitly stating whether questions should be "explicit" or "implicit", the generated answers are more likely to match the expected type, allowing a QA system to correctly match them.
- Core assumption: The QA system (QAsys) can reliably distinguish between explicit and implicit answers and that the generated questions are answerable in the correct style.
- Evidence anchors:
  - [abstract]: "Evaluation shows the few-shot approach can generate questions semantically closer to ground truth, especially for controlling narrative elements."
  - [section]: "Hypothesis (2) is that QAsys will perform significantly better on explicit than implicit generated questions, as previously supported by FairytaleQA’s authors."
  - [corpus]: Weak - no direct mention of QA system performance in neighbors.
- Break condition: If the QA system is not well-calibrated for the specific narrative comprehension domain, it may misclassify answers regardless of explicitness control.

### Mechanism 3
- Claim: Increasing the number of prompt examples improves controllability for both narrative and explicitness attributes.
- Mechanism: More examples provide richer context for the model to infer the desired output style, especially when the task involves nuanced distinctions like implicit vs. explicit answers.
- Core assumption: The model generalizes better from more diverse examples within the same attribute category.
- Evidence anchors:
  - [abstract]: "Our experiments highlight instances where the few-shot strategy surpasses the reference model, particularly in scenarios such as semantic closeness evaluation and the diversity and coherency of question-answer pairs."
  - [section]: "As the number of prompt examples increases, QAsys consistently improves for explicit questions and consistently underperforms for implicit questions."
  - [corpus]: Weak - no direct mention of example count effects in neighbors.
- Break condition: If examples are too similar or do not span the full range of possible outputs, additional examples may not help and could even confuse the model.

## Foundational Learning

- Concept: Controllable Question Generation
  - Why needed here: The study aims to generate questions with specific attributes (narrative element, explicitness) rather than generic questions.
  - Quick check question: What are the two main attributes controlled in this study?

- Concept: Few-shot Prompting
  - Why needed here: It allows the model to perform a task with only a few examples, avoiding the need for extensive fine-tuning.
  - Quick check question: How many examples are used per prompt in this study?

- Concept: Narrative Comprehension
  - Why needed here: The dataset and task are grounded in narrative comprehension, requiring understanding of story elements and their relationships.
  - Quick check question: What are the seven narrative elements targeted in this study?

## Architecture Onboarding

- Component map: Input (text passage + control attributes) -> Prompt (query + 5 examples) -> Model (GPT-3.5) -> Output (generated question-answer pair) -> Evaluation (semantic similarity, QA system, linguistic quality)

- Critical path: Prepare input → Format prompt with examples → Generate output → Evaluate against ground truth or QA system

- Design tradeoffs:
  - Few-shot vs. fine-tuning: Few-shot is faster and requires no model training, but may be less precise.
  - Example count: More examples can improve control but increase prompt length and cost.
  - Evaluation metrics: Multiple metrics are needed to capture different aspects of quality and control.

- Failure signatures:
  - Low BLEU/ROUGE but high BLEURT: Model captures meaning but not exact wording.
  - High perplexity: Generated text is incoherent or unnatural.
  - Low diversity: Model produces repetitive or formulaic questions.

- First 3 experiments:
  1. Test few-shot prompting with only narrative control on a small subset of the test set; measure semantic closeness.
  2. Add explicitness control and evaluate with the QA system; compare explicit vs. implicit performance.
  3. Vary the number of prompt examples (1, 3, 5, 7) and measure impact on both narrative and explicitness control.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of few-shot prompting for controllable question generation vary across different narrative comprehension datasets and domains?
- Basis in paper: Explicit
- Why unresolved: The study focuses on a specific dataset (FairytaleQA) and domain (children's narrative texts), limiting generalizability.
- What evidence would resolve it: Conducting experiments with diverse datasets covering various narrative comprehension domains and age groups.

### Open Question 2
- Question: What is the impact of increasing the number of prompt examples on the performance of few-shot prompting for controlling question explicitness?
- Basis in paper: Explicit
- Why unresolved: While the study explores varying the number of examples for narrative control, it only uses 5 examples for explicitness control.
- What evidence would resolve it: Experimenting with different numbers of prompt examples (e.g., 1, 3, 7, 10) for controlling question explicitness and analyzing the results.

### Open Question 3
- Question: How does the linguistic quality of questions generated by few-shot prompting compare to those generated by fine-tuned models when controlling for narrative elements and explicitness?
- Basis in paper: Explicit
- Why unresolved: The study compares the two approaches based on similarity to ground truth and question-answering performance, but does not directly assess linguistic quality.
- What evidence would resolve it: Conducting human evaluations or using automated linguistic quality metrics (e.g., fluency, grammaticality) to compare the generated questions from both approaches.

### Open Question 4
- Question: What are the most effective strategies for ensuring alignment between generated questions and the specified control attributes (narrative elements and explicitness) in few-shot prompting?
- Basis in paper: Inferred
- Why unresolved: The study identifies instances of narrative misalignment in the generated questions, suggesting a need for improved alignment strategies.
- What evidence would resolve it: Investigating and evaluating different post-processing techniques or prompt engineering strategies to enhance the alignment between generated questions and control attributes.

## Limitations
- The evaluation of narrative control relies heavily on text similarity metrics, which may not fully capture semantic alignment with target narrative elements.
- The QA system-based evaluation of explicitness control assumes the QAsys model is well-calibrated for narrative comprehension, which is not independently verified.
- The selection criteria for prompt examples are not explicitly defined, which could impact reproducibility and performance consistency.

## Confidence

- **High confidence**: Few-shot prompting improves semantic closeness to ground truth when controlling narrative elements, supported by multiple similarity metrics.
- **Medium confidence**: Explicitness control leads to better QA system performance, though the evaluation depends on QAsys calibration.
- **Medium confidence**: Increasing prompt examples improves controllability, but the relationship is not linear and depends on example quality.

## Next Checks

1. **Validate QAsys calibration**: Test the QAsys model on a held-out set of manually labeled explicit/implicit questions to ensure it can reliably distinguish between the two types before using it to evaluate generated questions.

2. **Test example selection sensitivity**: Systematically vary the criteria for selecting prompt examples (e.g., random vs. most similar vs. most diverse) and measure the impact on both narrative and explicitness control performance.

3. **Evaluate semantic alignment directly**: Conduct a human evaluation study where annotators rate the semantic alignment of generated questions with target narrative elements, independent of text similarity metrics, to validate the automated evaluation.