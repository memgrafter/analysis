---
ver: rpa2
title: 'AcME-AD: Accelerated Model Explanations for Anomaly Detection'
arxiv_id: '2403.01245'
source_url: https://arxiv.org/abs/2403.01245
tags:
- feature
- anomaly
- acme-ad
- detection
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AcME-AD is a model-agnostic framework for explaining anomaly detection
  (AD) predictions in tabular data. It addresses the lack of interpretability in AD
  models by providing local feature importance scores and a what-if analysis tool.
---

# AcME-AD: Accelerated Model Explanations for Anomaly Detection

## Quick Facts
- arXiv ID: 2403.01245
- Source URL: https://arxiv.org/abs/2403.01245
- Reference count: 33
- AcME-AD provides model-agnostic explanations for anomaly detection predictions that are 3 orders of magnitude faster than KernelSHAP

## Executive Summary
AcME-AD is a model-agnostic framework that provides interpretable explanations for anomaly detection predictions in tabular data. The method addresses the interpretability gap in AD models by computing local feature importance scores and offering what-if analysis tools. It achieves this through a perturbation-based approach that evaluates how changes to feature values affect both anomaly scores and classification outcomes, while being significantly faster than existing model-agnostic methods like KernelSHAP.

## Method Summary
AcME-AD computes feature importance by perturbing each feature using quantile values and evaluating the impact on anomaly scores through four novel sub-scores (Delta, Ratio, Change of predicted class, Distance to change). These sub-scores are combined using customizable weights to produce a single importance score for each feature. The method can provide both local explanations for individual anomalies and global feature importance by aggregating across all anomalies. The framework is model-agnostic, requiring only access to anomaly scores and classification thresholds, and demonstrates computational efficiency by being three orders of magnitude faster than KernelSHAP.

## Key Results
- AcME-AD provides comparable feature rankings to KernelSHAP and DIFFI while being over 100x faster
- On the Glass dataset, identified Al and Ba as most important features for headlamp glass anomaly detection
- Feature selection experiments show higher F1-scores than random feature selection using global importance scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local importance scores are computed by perturbing each feature using quantiles and evaluating the effect on both anomaly score and classification outcome.
- Mechanism: For each feature, AcME-AD constructs a variable-quantile matrix Zj with Q perturbed versions of the baseline observation. It computes four scores (Delta, Ratio, Change of predicted class, Distance to change) from the mapped anomaly scores, then combines them into a single importance score using weighted sum.
- Core assumption: Perturbing features along quantiles captures their influence on model behavior, and the four sub-scores together provide a complete picture of local feature importance.
- Evidence anchors:
  - [abstract]: "It offers local feature importance scores and a what-if analysis tool, shedding light on the factors contributing to each anomaly"
  - [section]: "To calculate the local importance score of each feature j ∈ 1, ..., p in the prediction of x, we perturb it based on its quantile values computed within the dataset"
- Break condition: If the feature distributions are highly skewed or contain outliers, quantile-based perturbations may not capture meaningful variations in feature importance.

### Mechanism 2
- Claim: The four sub-scores capture different aspects of feature influence - magnitude of anomaly score change, relative position in the score distribution, ability to flip the predicted class, and proximity to class change boundary.
- Mechanism: Delta measures the range of anomaly scores from perturbations; Ratio measures how far the original score is from the minimum; Change captures if perturbations can flip the classification; Distance quantifies how close to the class boundary the feature can push the observation.
- Core assumption: These four aspects together provide a comprehensive understanding of how each feature affects both the anomaly score and the predicted class.
- Evidence anchors:
  - [abstract]: "computing four novel sub-scores (Delta, Ratio, Change of predicted class, Distance to change) that capture how feature modifications affect both the anomaly score and classification"
  - [section]: "Starting from these values, we define four novel metrics as follows: Delta, Ratio, Change of predicted class, Distance to change"
- Break condition: If the anomaly detection model is not well-calibrated or the threshold is not meaningful, the Change and Distance sub-scores may not reflect actual classification behavior.

### Mechanism 3
- Claim: Global importance scores are derived by aggregating local scores across all predicted anomalies, providing a model-wide view of feature relevance.
- Mechanism: For each feature j, the global score Tj is computed as the sum of local importance scores Ij(x) for all anomalies x in the dataset. This aggregation weights features by their consistent impact across multiple anomalies.
- Core assumption: Summing local scores across anomalies provides a meaningful measure of overall feature importance for the model.
- Evidence anchors:
  - [abstract]: "It additionally offers a global evaluation of feature importance derived from these local explanations"
  - [section]: "Let S be the set of interest, we defined the global importance score of feature j as the sum local importance scores Ij for the points in S predicted as anomalous"
- Break condition: If the set of anomalies is not representative of the model's behavior or is too small, the global scores may not reflect true feature importance.

## Foundational Learning

- Concept: Quantile-based perturbation
  - Why needed here: Allows systematic exploration of feature values across their empirical distribution to assess impact on model predictions
  - Quick check question: How would you construct a variable-quantile matrix for a feature with 5 quantiles?

- Concept: Convex combination of multiple importance metrics
  - Why needed here: Different aspects of feature influence (score change, classification change, etc.) need to be combined into a single interpretable score
  - Quick check question: If you have four sub-scores and want equal weighting, what should each weight be?

- Concept: Model-agnostic explanation framework
  - Why needed here: Allows applying the same interpretability method to any anomaly detection model without requiring model-specific modifications
  - Quick check question: What are the minimal requirements a model must satisfy to be compatible with AcME-AD?

## Architecture Onboarding

- Component map: Data preprocessing -> Perturbation engine -> Scoring module -> Aggregation layer -> Global synthesis -> Visualization tools
- Critical path: Perturbation → Scoring → Aggregation → Visualization
- Design tradeoffs: Pre-computed statistics vs. runtime computation; number of quantiles vs. computational cost; flexibility of weight parameters vs. simplicity
- Failure signatures: Inconsistent feature rankings across similar anomalies; extreme sensitivity to weight parameters; high computational time for large datasets
- First 3 experiments:
  1. Run AcME-AD on a simple synthetic dataset with known feature importance to verify correct behavior
  2. Compare local explanations with ground truth on a small dataset where feature relevance is known
  3. Test computational efficiency by measuring time for different numbers of quantiles and features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does AcME-AD perform on high-dimensional datasets with more than 100 features?
- Basis in paper: [inferred] The paper mentions evaluating on a dataset with 36 features but does not explore higher dimensions.
- Why unresolved: The paper does not provide experiments or analysis for datasets with more than 36 features.
- What evidence would resolve it: Experimental results on datasets with varying numbers of features, particularly those exceeding 100, would demonstrate AcME-AD's scalability and performance in high-dimensional settings.

### Open Question 2
- Question: How sensitive are AcME-AD's explanations to the choice of weights (wD, wC, wQ, wR) for the sub-scores?
- Basis in paper: [explicit] The paper mentions that the weights are customizable by the user and provides default values, but does not explore the sensitivity to different weight configurations.
- Why unresolved: The paper does not provide experiments or analysis on how changing the weights affects the explanations and their quality.
- What evidence would resolve it: Experiments varying the weights and comparing the resulting explanations and their quality metrics (e.g., feature rankings, computational time) would demonstrate the sensitivity and guide optimal weight selection.

### Open Question 3
- Question: How does AcME-AD compare to other model-agnostic explainability methods, such as LIME or SHAP with different background dataset sizes?
- Basis in paper: [inferred] The paper compares AcME-AD to KernelSHAP but does not explore other model-agnostic methods or variations of SHAP.
- Why unresolved: The paper does not provide experiments or analysis comparing AcME-AD to a broader range of model-agnostic explainability methods.
- What evidence would resolve it: Experimental results comparing AcME-AD to other model-agnostic methods (e.g., LIME, SHAP with different background sizes) in terms of explanation quality, computational time, and robustness would demonstrate AcME-AD's relative strengths and weaknesses.

## Limitations
- Primarily validated on tabular data; extension to other data types needs verification
- Performance depends on choice of quantile values and number of perturbations
- Global importance scores may be sensitive to the distribution of anomalies in the dataset

## Confidence

**Confidence: Medium** for local importance scores and what-if analysis - While the method is well-defined, validation is primarily on synthetic data and limited real datasets. The claim of providing "comparable feature rankings" to KernelSHAP needs broader validation across diverse AD models and datasets.

**Confidence: High** for computational efficiency - The 3 orders of magnitude speedup over KernelSHAP is explicitly demonstrated and the computational advantage of the perturbation-based approach is theoretically sound.

**Confidence: Low** for global importance scores - The aggregation method (summing local scores) is simple and may not capture nuanced global feature relationships. The feature selection experiments provide limited validation of global scores' quality.

## Next Checks
1. Test AcME-AD on a diverse set of real-world anomaly detection tasks (fraud detection, network intrusion, industrial monitoring) to validate generalizability
2. Compare global importance scores with alternative aggregation methods (weighted sums, rank-based methods) to assess robustness
3. Evaluate sensitivity of local importance scores to the number of quantiles and choice of weight parameters across different anomaly detection models