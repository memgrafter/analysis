---
ver: rpa2
title: 'Learning from others'' mistakes: Finetuning machine translation models with
  span-level error annotations'
arxiv_id: '2410.16509'
source_url: https://arxiv.org/abs/2410.16509
tags:
- error
- data
- tokens
- annotations
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores the potential of utilizing fine-grained span-level
  error annotations from offline datasets to improve machine translation models. It
  introduces a new finetuning algorithm called Training with Annotations (TWA) that
  directly trains machine translation models on such annotated data.
---

# Learning from others' mistakes: Finetuning machine translation models with span-level error annotations

## Quick Facts
- **arXiv ID**: 2410.16509
- **Source URL**: https://arxiv.org/abs/2410.16509
- **Reference count**: 11
- **Key outcome**: TWA significantly outperforms SFT and DPO baselines on En→De and Zh→En machine translation using span-level error annotations

## Executive Summary
This paper introduces Training with Annotations (TWA), a finetuning algorithm that leverages span-level error annotations from MQM data to improve machine translation models. Unlike traditional approaches that use only sequence-level supervision, TWA treats error and non-error spans differently using a combination of unlikelihood loss for error spans and cross-entropy loss for non-error spans. The method significantly outperforms baselines including SFT and DPO on WMT'23 benchmarks, demonstrating the effectiveness of incorporating detailed error information for model improvement.

## Method Summary
TWA finetunes machine translation models using span-level error annotations by applying different loss functions to different types of spans. For error spans, it uses span-level unlikelihood loss to penalize specific tokens while preserving reasonable ones, with severity weights scaling the loss magnitude. For non-error spans, it applies standard cross-entropy loss. Off-trajectory tokens after the first error span are ignored to avoid noisy signal. The method uses a 602M parameter Transformer encoder-decoder trained with batch size 8192, learning rate 2e-6, and greedy decoding for evaluation.

## Key Results
- TWA achieves significantly better Metric-X-23 and COMET-20 scores than SFT and DPO baselines on WMT'23 En→De and Zh→En test sets
- Span-level unlikelihood loss effectively learns which tokens to penalize within error spans
- Ignoring off-trajectory tokens after the first error span prevents propagation of noisy signal
- The approach generalizes to both English-German and Chinese-English translation directions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TWA improves translation quality by using span-level unlikelihood loss to penalize specific tokens within error spans, rather than the entire span.
- Mechanism: The model learns to identify which tokens within an error span are most responsible for the error by minimizing the span-level unlikelihood loss. This allows for targeted corrections while preserving tokens that are reasonable given their context.
- Core assumption: The span-level unlikelihood loss can effectively guide the model to learn which tokens within an error span to penalize without requiring explicit heuristics or token-level annotations.
- Evidence anchors:
  - [abstract]: "TWA uses span-level error information to treat error and non-error spans differently, allowing the model to learn what to penalize within error spans"
  - [section 4.1]: "the span-level unlikelihood loss allows the model to learn which tokens to penalize in order to decrease the overall probability of the span"
  - [corpus]: Weak - The corpus neighbors do not directly support this specific mechanism, but they discuss related error span detection methods.
- Break condition: If the model fails to learn meaningful patterns of which tokens to penalize, or if the span-level loss becomes too noisy due to complex error spans.

### Mechanism 2
- Claim: TWA leverages the quality spectrum within translations by treating non-error spans with cross-entropy loss and ignoring off-trajectory tokens after the first error.
- Mechanism: By only applying cross-entropy loss to non-error tokens before the first error span, TWA prevents the model from being trained on potentially noisy or irrelevant off-trajectory tokens. This focuses learning on high-quality signal while avoiding propagation of errors.
- Core assumption: Non-error tokens before the first error span are more likely to be high-quality signal that the model should learn from, while off-trajectory tokens are either irrelevant or potentially harmful.
- Evidence anchors:
  - [abstract]: "TWA considers the overall trajectory of a sequence when deciding which non-error spans to utilize as positive signals"
  - [section 4.2]: "off-trajectory tokens at best are irrelevant to the model distribution and at worst could provide noisy signal"
  - [corpus]: Weak - Corpus neighbors discuss error span detection but don't specifically address the off-trajectory token handling strategy.
- Break condition: If ignoring off-trajectory tokens removes valuable signal, or if the first error span doesn't accurately represent the beginning of significant quality degradation.

### Mechanism 3
- Claim: TWA's effectiveness comes from its ability to utilize fine-grained annotations that provide more detailed information than sequence-level labels, enabling more precise model improvements.
- Mechanism: The span-level annotations allow TWA to distinguish between different types of errors and their severity, enabling the model to learn nuanced corrections rather than just treating all errors equally.
- Core assumption: Fine-grained annotations contain information that is both available and useful for improving translation quality beyond what sequence-level annotations can provide.
- Evidence anchors:
  - [abstract]: "Unlike sequence-level annotations, span-level annotations provide information about specific segments within a sequence, offering more detailed information for model learning"
  - [section 1]: "most efforts consider only sequence-level labels, usually in the form of a scalar score assigned to the entire output"
  - [section 4.1]: "we take into account the severity of the error by scaling the loss by the absolute value of the severity weight w assigned to the span"
  - [corpus]: Weak - While corpus neighbors discuss error span detection, they don't specifically address the comparative advantage of span-level vs sequence-level annotations.
- Break condition: If the additional complexity of span-level annotations doesn't translate to meaningful quality improvements, or if the annotation process becomes prohibitively expensive relative to the gains.

## Foundational Learning

- Concept: Cross-entropy loss for sequence-to-sequence models
  - Why needed here: TWA uses cross-entropy loss for non-error tokens, so understanding how it works is fundamental to grasping the overall approach
  - Quick check question: How does cross-entropy loss encourage the model to generate the correct token distribution?

- Concept: Unlikelihood training and negative log-likelihood
  - Why needed here: TWA employs span-level unlikelihood loss for error spans, which is a key distinguishing feature from standard approaches
  - Quick check question: What's the difference between cross-entropy loss and unlikelihood loss, and when would you use each?

- Concept: Span-level vs token-level supervision
  - Why needed here: TWA operates at the span level for error handling, which requires understanding the tradeoffs between different granularities of supervision
  - Quick check question: What are the advantages and disadvantages of providing supervision at the token level versus the span level?

## Architecture Onboarding

- Component map:
  Base translation model (602M parameter Transformer encoder-decoder) -> Tokenization layer (32k subword units) -> Span-level annotation processor (converts error spans to token weights) -> TWA loss computation module (handles error spans with unlikelihood loss, non-error spans with cross-entropy) -> Training loop (batch size 8192, learning rate 2e-6, no label smoothing)

- Critical path:
  1. Tokenize input text and annotations
  2. Convert annotations to token weights (negative for error spans, zero for off-trajectory, positive for non-error)
  3. Group tokens into spans based on weights
  4. Compute TWA loss for each span type
  5. Backpropagate and update model parameters

- Design tradeoffs:
  - Span-level vs token-level error handling: Span-level allows learning what to penalize but is less precise
  - Off-trajectory token handling: Ignoring them simplifies training but may discard useful signal
  - Severity weighting: Incorporating severity provides more nuanced learning but adds complexity

- Failure signatures:
  - Performance worse than SFT alone: Likely issues with span-level loss computation or annotation processing
  - Model becomes unstable: Check learning rate and unlikelihood loss implementation
  - No improvement over baselines: Verify annotation data quality and span grouping logic

- First 3 experiments:
  1. Run TWA on a small subset of data with manual verification of span grouping and loss computation
  2. Compare performance of unlikelihood vs negative likelihood on error spans using validation data
  3. Test the impact of ignoring off-trajectory tokens by running with and without this feature on a validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would Training with Annotations (TWA) perform on online data where the base model's quality is significantly lower than the annotated data?
- Basis in paper: [inferred] The paper mentions "assessing TWA on online data" as a future work direction and notes that "the quality of the generations and annotations on resulting model performance" is an open question.
- Why unresolved: The current experiments use pretraining data where the base model quality is already close to or better than the submissions, making it difficult to isolate TWA's performance in lower quality scenarios.
- What evidence would resolve it: Running TWA on online data where the base model quality is substantially lower than the annotations, comparing results to standard finetuning, and measuring the difference in improvement.

### Open Question 2
- Question: Would incorporating the fine-grained annotation information directly into the model (e.g., as additional features or constraints) yield better results than the current span-level unlikelihood approach?
- Basis in paper: [inferred] The paper mentions "exploring the impact of the quality of the generations and annotations on resulting model performance" and "exploring the repeated use of TWA for iterative refinement of a model" as future work directions.
- Why unresolved: The current TWA approach only uses span-level error information for the unlikelihood loss, not incorporating other potential ways to leverage the fine-grained annotations.
- What evidence would resolve it: Implementing alternative methods that directly incorporate the fine-grained annotations (e.g., as additional features or constraints) and comparing their performance to TWA.

### Open Question 3
- Question: How would TWA perform on other tasks beyond machine translation, such as text summarization or question answering, where span-level annotations might be available?
- Basis in paper: [explicit] The paper concludes by stating "While the experiments focus on MQM data for the task of machine translation, TWA can be used for span-level annotations broadly, paving the way for other applications of fine-grained annotations."
- Why unresolved: The current experiments only evaluate TWA on machine translation tasks, so its effectiveness on other tasks with span-level annotations is unknown.
- What evidence would resolve it: Applying TWA to other tasks with span-level annotations (e.g., text summarization, question answering) and comparing its performance to standard finetuning and other baselines.

## Limitations

- **Annotation Quality and Coverage**: The approach relies heavily on the quality and comprehensiveness of span-level MQM annotations, with only ~6,000 annotated source texts available.
- **Span-level Granularity**: While the paper claims span-level annotations provide more detailed information, the actual granularity achieved may be coarser than implied, applying the same weight to all tokens within a span.
- **Limited Language Pair Evaluation**: Experiments only evaluate on two language pairs (En→De and Zh→En), limiting generalizability to other language pairs or multilingual settings.

## Confidence

**High Confidence (9/10)**:
- TWA significantly outperforms SFT and DPO baselines on the tested language pairs
- The span-level unlikelihood loss mechanism works as described for penalizing error spans
- The validation methodology (average of Metric-X-23 and COMET-20) is sound

**Medium Confidence (6/10)**:
- The superiority of span-level annotations over sequence-level annotations for translation quality improvement
- The assumption that ignoring off-trajectory tokens is beneficial
- The generalizability of results to other language pairs and domains

**Low Confidence (3/10)**:
- The cost-effectiveness of the annotation process relative to the quality gains
- The scalability of the approach to much larger models or more diverse error types
- The robustness of TWA when annotation quality varies

## Next Checks

1. **Annotation Quality Validation**: Manually verify a random sample of 50-100 annotated examples to assess annotation consistency, error span accuracy, and severity weighting. Calculate inter-annotator agreement if multiple annotations are available.

2. **Ablation Study on Off-trajectory Handling**: Run experiments comparing TWA with three variants: (a) current implementation ignoring off-trajectory tokens, (b) treating off-trajectory tokens with standard cross-entropy loss, and (c) treating them with unlikelihood loss. Measure impact on both translation quality and training stability.

3. **Cross-domain Transferability Test**: Apply the TWA-finetuned models to a different domain (e.g., news domain if trained on WMT data) and measure performance degradation. Compare this degradation against SFT and DPO baselines to assess domain robustness.