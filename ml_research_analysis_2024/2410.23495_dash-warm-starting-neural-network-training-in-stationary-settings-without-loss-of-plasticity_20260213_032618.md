---
ver: rpa2
title: 'DASH: Warm-Starting Neural Network Training in Stationary Settings without
  Loss of Plasticity'
arxiv_id: '2410.23495'
source_url: https://arxiv.org/abs/2410.23495
tags:
- data
- training
- experiments
- number
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses plasticity loss in neural network training,
  where warm-starting with previously learned weights leads to worse generalization
  than training from scratch, even under stationary data distributions. The authors
  develop a theoretical framework that combines feature learning and discrete learning
  processes to show that noise memorization is the primary cause of plasticity loss
  in warm-starting.
---

# DASH: Warm-Starting Neural Network Training in Stationary Settings without Loss of Plasticity

## Quick Facts
- **arXiv ID:** 2410.23495
- **Source URL:** https://arxiv.org/abs/2410.23495
- **Reference count:** 40
- **Primary result:** DASH improves warm-starting by selectively forgetting memorized noise while preserving learned features, achieving higher test accuracy than both cold-starting and Shrink & Perturb baseline

## Executive Summary
This paper addresses the plasticity loss problem in neural network warm-starting, where models initialized with previously learned weights perform worse than training from scratch, even under stationary data distributions. The authors develop a theoretical framework that identifies noise memorization during training as the primary cause of this degradation. Based on this insight, they propose DASH (Direction-Aware SHrinking), a method that selectively shrinks weights based on their alignment with the negative gradient, effectively forgetting memorized noise while preserving useful features. Experiments across various vision tasks demonstrate that DASH eliminates plasticity loss, improves test accuracy, and requires fewer training steps compared to standard warm-starting approaches.

## Method Summary
DASH operates by selectively shrinking weights that are aligned with the negative gradient direction, which the authors show corresponds to weights that have memorized noise during training. The method computes the angle between each weight vector and the negative gradient, then applies a shrinking operation to weights whose alignment exceeds a threshold. This selective forgetting mechanism preserves weights that encode meaningful features while discarding noise memorization. The shrinking factor and threshold are hyperparameters that control the degree of forgetting. DASH can be applied at the start of warm-starting and requires minimal additional computation compared to standard training, making it practical for deployment across different architectures and optimizers.

## Key Results
- DASH eliminates plasticity loss in warm-starting scenarios, achieving higher test accuracy than both cold-starting and Shrink & Perturb baseline
- The method reduces training steps required to reach optimal performance by 20-30% across various vision tasks
- DASH demonstrates consistent improvements across multiple datasets (CIFAR, ImageNet), model architectures (ResNet, VGG), and optimizers (SGD, Adam)

## Why This Works (Mechanism)
The mechanism behind DASH is rooted in the observation that plasticity loss occurs because warm-starting initializes models with weights that have memorized noise from previous training runs. When the same data distribution is encountered again, these noise patterns interfere with learning new features or refining existing ones. DASH addresses this by computing the alignment between each weight and the negative gradient direction - weights highly aligned with the negative gradient are those that have been adjusted to fit noise in the previous training. By selectively shrinking these weights, DASH effectively "forgets" the memorized noise while preserving weights that encode meaningful features. This selective forgetting restores the model's ability to learn effectively from the data, eliminating the performance gap between warm-starting and cold-starting.

## Foundational Learning
- **Plasticity loss:** The degradation in test accuracy when warm-starting with previously learned weights compared to training from scratch. Why needed: Understanding this phenomenon is crucial as warm-starting is commonly used in practice but often leads to suboptimal performance. Quick check: Verify that warm-starting indeed shows worse performance than cold-starting on a simple dataset.
- **Feature learning vs. discrete learning:** The two phases of neural network training where early epochs focus on learning features and later epochs on fine-tuning discrete patterns. Why needed: The paper's theoretical framework distinguishes between these phases to explain how noise memorization occurs. Quick check: Plot training loss curves to identify distinct phases in learning.
- **Gradient alignment:** The angle between weight vectors and gradient directions, used to identify noise-memorized weights. Why needed: This metric is the core mechanism by which DASH identifies which weights to shrink. Quick check: Compute cosine similarity between weights and gradients across training epochs.
- **Noise memorization:** The phenomenon where neural networks fit to random noise in the training data, which persists in the learned weights. Why needed: Understanding this concept is essential to grasp why warm-starting leads to plasticity loss. Quick check: Train on corrupted data with random labels and observe overfitting patterns.
- **Selective forgetting:** The ability to retain useful learned features while discarding memorized noise. Why needed: This is the fundamental principle behind DASH's approach to solving plasticity loss. Quick check: Compare performance when forgetting all weights vs. selective forgetting based on gradient alignment.

## Architecture Onboarding

**Component Map:** Input data -> Model (with pre-trained weights) -> Forward pass -> Compute loss -> Backward pass -> Compute gradient alignment -> DASH shrinking operation -> Update weights -> Output predictions

**Critical Path:** The critical path involves computing the angle between each weight and the negative gradient, applying the shrinking operation to weights exceeding the threshold, and then proceeding with standard backpropagation. This adds minimal computational overhead compared to standard training.

**Design Tradeoffs:** The method trades off between complete preservation of learned features and aggressive noise removal. Too much shrinking may erase useful features, while too little may not sufficiently address plasticity loss. The hyperparameters (shrink factor and threshold) provide control over this tradeoff.

**Failure Signatures:** If the shrink factor is too high, the model may lose important features and converge slowly. If the threshold is too low, noise may not be adequately removed, leading to persistent plasticity loss. If the threshold is too high, excessive weights may be shrunk, degrading performance.

**First Experiments:**
1. Verify plasticity loss exists by comparing warm-starting vs cold-starting on a simple CNN with CIFAR-10
2. Test DASH with different shrink factors (0.1, 0.5, 0.9) to find optimal performance
3. Evaluate DASH's computational overhead by measuring training time per epoch compared to standard warm-starting

## Open Questions the Paper Calls Out
The paper acknowledges that while DASH effectively addresses plasticity loss in stationary settings, its performance in non-stationary environments (where data distributions change over time) requires further investigation. The authors briefly discuss potential extensions to continual learning scenarios but note that the current theoretical framework and empirical validation are limited to stationary distributions. Additionally, the paper suggests that exploring DASH's effectiveness on non-vision tasks, such as natural language processing or reinforcement learning, could provide insights into its broader applicability.

## Limitations
- The theoretical framework relies on simplifying assumptions about the interaction between feature learning and discrete learning phases, which may not fully capture complex dynamics in deep networks with batch normalization and skip connections
- Evaluation focuses primarily on standard vision tasks, with limited exploration of performance on other domains like NLP or reinforcement learning
- The claim of "eliminating plasticity loss" is somewhat overstated, as DASH shows improvements but doesn't completely prevent performance degradation in all warm-starting scenarios

## Confidence

| Claim | Confidence |
|-------|------------|
| Theoretical framework linking noise memorization to plasticity loss | Medium |
| Empirical performance improvements on vision tasks | High |
| Generalization to non-vision domains | Low |
| Computational efficiency claims | Medium |

## Next Checks
1. Test DASH on non-vision tasks (e.g., language modeling or reinforcement learning) to assess domain generalization
2. Conduct ablation studies on DASH hyperparameters (shrink factor and threshold) across different model architectures
3. Compare DASH against recent continual learning methods like MAS or EWC under identical experimental conditions