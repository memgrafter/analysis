---
ver: rpa2
title: 'Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding
  Units'
arxiv_id: '2403.16609'
source_url: https://arxiv.org/abs/2403.16609
tags:
- grounding
- cgus
- dialog
- traum
- acts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an annotation of two dialogue corpora using
  Grounding Acts and Common Grounding Units, along with a measure of grounding degree.
  The authors annotate the Meetup and Spot the Difference datasets, identifying challenges
  in distinguishing between different grounding acts.
---

# Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding Units

## Quick Facts
- arXiv ID: 2403.16609
- Source URL: https://arxiv.org/abs/2403.16609
- Reference count: 0
- Authors annotate two dialogue corpora using Grounding Acts and Common Grounding Units, propose new grounding categories, and establish baseline T5 model performance

## Executive Summary
This paper presents a comprehensive annotation of two dialogue corpora using Grounding Acts and Common Grounding Units, along with a measure of grounding degree. The authors annotate the Meetup and Spot the Difference datasets, identifying challenges in distinguishing between different grounding acts. They propose new grounding categories and sub-categories, and provide a coding manual for future research. The paper also evaluates the performance of a T5 model in categorizing utterances into grounding acts, establishing a baseline for future studies. The annotated datasets and model results serve as valuable resources for advancing research in conversational grounding.

## Method Summary
The authors employed a hierarchical approach to conversational grounding, using Traum's framework of Grounding Acts (GA) and Common Grounding Units (CGU). They annotated two dialogue corpora - Meetup (spoken) and Spot the Difference (written) - with GA labels, CGU formation, and grounding degrees. A T5 model was trained to classify utterances into GA categories using weighted loss to handle class imbalance. The annotation process involved defining new categories (Repeat and None) to address challenges in distinguishing between existing acts. The CGUs were formed by grouping GAs and assigned degree levels (High, Medium, Low, Ambiguous) based on their grounding state and potential for future alteration.

## Key Results
- The annotated datasets (Meetup and Spot the Difference) provide new resources for conversational grounding research
- The T5 model achieved 51.9% overall accuracy in categorizing utterances into grounding acts
- Introduction of Repeat and None categories improved grounding annotation coverage and accuracy
- The degree-of-grounding metric provides actionable signals for dialog system behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hierarchical grounding structure (GA → CGU) enables systematic representation of dialog context.
- Mechanism: Grounding Acts provide atomic units that are combined into Common Grounding Units, allowing precise tracking of what information has been established versus what is pending.
- Core assumption: Dialog can be discretized into discrete acts that correspond to clear shifts in grounding state.
- Evidence anchors:
  - [abstract] "Traum (Traum, 1995) provided a framework for conversational grounding introducing Grounding Acts and Grounding Units"
  - [section] "A CGU is composed of several individual utterances. Each individual utterance has a corresponding GA."
- Break condition: When dialog contains overlapping or multi-intent utterances that cannot be cleanly assigned to a single GA.

### Mechanism 2
- Claim: Introducing Repeat and None categories improves grounding accuracy for non-standard dialog patterns.
- Mechanism: The Repeat category captures information reiteration, while the None handles utterances that don't advance grounding, preventing misclassification of non-informative turns.
- Core assumption: Not all utterances contribute equally to grounding state, and distinguishing these cases improves model performance.
- Evidence anchors:
  - [section] "we propose the inclusion of two additional categories: Repeat and None"
  - [section] "The Repeat category encompasses instances where the speaker reiterates previously mentioned information, while the None category was necessary to account for many utterances that did not significantly contribute to the grounding process."
- Break condition: If too many utterances are labeled as None, potentially losing information that could be useful for downstream tasks.

### Mechanism 3
- Claim: The degree-of-grounding metric provides actionable signals for dialog system behavior.
- Mechanism: By assigning High/Medium/Low/Ambiguous degrees to grounded CGUs, the system can prioritize responses and determine when clarification is needed.
- Core assumption: Different levels of certainty in grounding require different system responses.
- Evidence anchors:
  - [section] "we also assessed the level of grounding for each Common Grounding Unit (CGU) upon its grounding, categorizing them into four levels: High, Medium, Low, and Ambiguous"
  - [section] "When a CGU is grounded due to a 'Move on' act, it's assigned a low degree, indicating a higher likelihood of alteration in future discussions."
- Break condition: If degree assignments become inconsistent or don't correlate with actual dialog success.

## Foundational Learning

- Concept: Grounding Acts taxonomy (Initiate, Continue, Acknowledge, Repair, Request-Repair, Request-Acknowledge, Cancel)
  - Why needed here: Provides the vocabulary for labeling dialog utterances and determining when information has been successfully grounded.
  - Quick check question: What GA would you assign to an utterance that asks "Do you mean the blue one?" in response to a previous statement?

- Concept: CGU formation and lifecycle (initiation → acknowledgment → potential reopening)
  - Why needed here: Understanding how CGUs are created, closed, and potentially reopened is essential for implementing the annotation scheme.
  - Quick check question: If a CGU is acknowledged but then reopened with a Repair, what happens to its grounding state?

- Concept: Degree of grounding levels (High, Medium, Low, Ambiguous)
  - Why needed here: Enables nuanced handling of uncertainty in the grounding process, which affects how dialog systems should respond.
  - Quick check question: When would a grounded CGU be assigned an "Ambiguous" degree?

## Architecture Onboarding

- Component map: Data layer (annotated dialogs) -> Annotation engine (T5 model) -> CGU builder (grouping logic) -> Degree calculator (level assignment) -> Storage layer (indexed representation)

- Critical path: GA annotation → CGU formation → Degree assignment → System response

- Design tradeoffs:
  - Granularity vs. simplicity: More GA categories provide better nuance but increase annotation complexity
  - Real-time vs. post-hoc: Annotation is post-hoc, but systems must operate in real-time
  - Accuracy vs. coverage: Weighted loss helps with rare categories but may introduce bias

- Failure signatures:
  - High proportion of "None" labels suggests overly strict GA definitions
  - Frequent CGU reopening indicates ambiguous acknowledgment handling
  - Low model accuracy on certain GAs points to category overlap or insufficient training data

- First 3 experiments:
  1. Train T5 model on Meetup dataset and evaluate per-GA accuracy
  2. Implement CGU builder and verify against annotated examples
  3. Test degree-of-grounding assignment logic with ambiguous cases from the corpus

## Open Questions the Paper Calls Out

- How to best handle multi-intent utterances that could be assigned to multiple grounding acts
- Whether the grounding act annotation scheme generalizes across different dialog types and modalities
- The practical utility of the degree-of-grounding metric for improving dialog system performance beyond the annotation task

## Limitations

- Difficulty distinguishing between certain Grounding Acts (e.g., Acknowledge and Continue) indicates inherent ambiguity in the annotation scheme
- The T5 model achieves only 51.9% overall accuracy, suggesting significant room for improvement in automated grounding act classification
- The paper does not report kappa values for all proposed categories, particularly the new Repeat and None categories, leaving uncertainty about their reliability

## Confidence

**High confidence**: The hierarchical structure of Grounding Acts forming Common Grounding Units is well-established in the literature (Traum, 1995) and provides a systematic framework for representing dialog context. The core mechanism of using degree-of-grounding levels to signal uncertainty in grounding state is logically sound and supported by the annotation process.

**Medium confidence**: The introduction of Repeat and None categories addresses real annotation challenges, but their reliability and necessity require further validation. The effectiveness of the weighted loss function in handling imbalanced categories is theoretically justified but not empirically validated against alternative approaches.

**Low confidence**: The generalizability of the annotation scheme across different dialog types and modalities remains unproven. The practical utility of the degree-of-grounding metric for improving dialog system performance has not been demonstrated beyond the annotation task itself.

## Next Checks

1. **Reliability testing across annotators and datasets**: Conduct a comprehensive inter-annotator reliability study on the new Repeat and None categories across both Meetup and Spot the Difference datasets, measuring kappa values and identifying systematic disagreements to refine the coding manual.

2. **Ablation study on grounding degree utility**: Implement a dialog system that uses the degree-of-grounding metric to make response decisions, comparing its performance against a baseline system without this information across multiple success metrics (task completion, user satisfaction, grounding accuracy).

3. **Cross-modal validation**: Test whether the grounding act annotation scheme transfers effectively from spoken (Meetup) to written (Spot the Difference) dialogs by having annotators label a subset of each other's data and measuring category-specific performance degradation.