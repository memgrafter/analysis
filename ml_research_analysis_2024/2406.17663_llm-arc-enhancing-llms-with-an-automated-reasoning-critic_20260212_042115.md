---
ver: rpa2
title: 'LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic'
arxiv_id: '2406.17663'
source_url: https://arxiv.org/abs/2406.17663
tags:
- tests
- actor
- building
- critic
- logic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLM-ARC is a neuro-symbolic framework that combines a large language
  model (LLM) with an automated reasoning engine to improve logical reasoning capabilities.
  The system uses an Actor-Critic method where the LLM generates declarative logic
  programs and tests, while the reasoning engine evaluates the code, runs the tests,
  and provides feedback for iterative refinement.
---

# LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic

## Quick Facts
- arXiv ID: 2406.17663
- Source URL: https://arxiv.org/abs/2406.17663
- Reference count: 40
- Primary result: Achieves 88.32% accuracy on FOLIO benchmark using neuro-symbolic Actor-Critic framework

## Executive Summary
LLM-ARC is a neuro-symbolic framework that combines a large language model with an automated reasoning engine to improve logical reasoning capabilities. The system uses an Actor-Critic method where the LLM generates declarative logic programs and tests, while the reasoning engine evaluates the code, runs the tests, and provides feedback for iterative refinement. Implemented using Answer Set Programming, LLM-ARC achieves state-of-the-art accuracy of 88.32% on the FOLIO benchmark, which tests complex logical reasoning. The framework demonstrates significant improvements over LLM-only baselines by incorporating test generation and iterative self-refinement.

## Method Summary
LLM-ARC uses an Actor-Critic architecture where the LLM (Actor) generates ASP code and semantic tests from natural language problem descriptions, and an automated reasoning engine (Critic, specifically Clingo) evaluates the code, runs the tests, and provides detailed feedback on failures. The system iteratively refines the code and tests until all pass or a maximum iteration limit is reached. A self-supervised training loop further enhances performance by fine-tuning the LLM on dialog traces collected during the self-correction process, where the model learns to generate high-quality ASP programs and tests directly from end-to-end examples.

## Key Results
- Achieves 88.32% accuracy on FOLIO benchmark, state-of-the-art performance
- Iterative self-correction loop with up to 4 iterations improves accuracy by 3.36% over non-iterative version
- Test generation capability improves accuracy by 6.6% compared to code-only generation
- Self-supervised training on dialog traces further enhances performance over few-shot baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The LLM generates declarative logic programs with semantic tests, allowing the automated reasoning engine to verify both syntax and logical correctness.
- Mechanism: The Actor-Critic architecture enables iterative refinement where the LLM writes ASP code and tests, the Critic (Clingo solver) executes the code and evaluates tests, then provides detailed feedback on failures for the Actor to improve.
- Core assumption: The reasoning engine can provide detailed, actionable explanations for test failures that the LLM can use to correct both code and tests.
- Evidence anchors:
  - [abstract] "The Automated Reasoning Critic evaluates the code, runs the tests and provides feedback on test failures for iterative refinement."
  - [section 3.1.2] "Each test has optional facts that need to be added to the program to test the rules/constraints, and the test conditions are either..."
  - [corpus] Weak evidence - the paper does not provide concrete examples of the explanation quality from Clingo.
- Break condition: If the reasoning engine cannot provide meaningful explanations for test failures, the iterative refinement loop breaks down.

### Mechanism 2
- Claim: Test generation with specific guidelines improves logical reasoning accuracy by 6.6% compared to code-only generation.
- Mechanism: The LLM is prompted with logic stratification guidelines that map FOLIO statement types to appropriate test patterns, ensuring comprehensive semantic coverage.
- Core assumption: The logic stratification analysis accurately captures the diversity of logical structures in FOLIO, and the test guidelines are sufficient for all cases.
- Evidence anchors:
  - [section 3.1.2] "We designed a simple general schema for specifying logic tests" and "To improve test generation quality, we asked the LLM to add two additional fields..."
  - [section 4.3.2] "The results for this ablation are shown in the table below for the two LLM-ARC few-shot systems, and indicate a big drop in performance"
  - [corpus] Moderate evidence - the ablation study shows improvement but doesn't quantify the specific contribution of each guideline.
- Break condition: If the logic stratification misses important statement types or the guidelines are insufficient for certain logical patterns, test quality degrades.

### Mechanism 3
- Claim: Training the LLM Actor on end-to-end dialog traces with Critic feedback creates a self-supervised loop that achieves state-of-the-art accuracy of 88.32%.
- Mechanism: The Actor is fine-tuned on dialog traces showing the progression from incorrect code/tests to correct ones, learning to generate high-quality ASP programs and tests directly.
- Core assumption: The dialog traces captured in the training process are representative of the failure modes the Actor will encounter in validation.
- Evidence anchors:
  - [section 4.1] "We ran the un-trained 8-shot version of the LLM-ARC system (with the TestGen capability) on the entire training set and collected dialog trace data"
  - [section 4.2] "Our best performing system is the LLM-ARC version that was trained in a self-supervised manner on end-to-end dialog traces with the Critic feedback"
  - [corpus] Moderate evidence - the paper describes the training procedure but doesn't provide error analysis on the trained model's failure modes.
- Break condition: If the training data doesn't cover certain logical patterns or failure modes, the trained Actor may fail on those cases.

## Foundational Learning

- Concept: Logic stratification and classification of natural language statements
  - Why needed here: To create effective in-context examples and test generation guidelines that cover the diversity of FOLIO problems
  - Quick check question: How many logical classes were identified in FOLIO through LLM analysis?

- Concept: Answer Set Programming (ASP) syntax and semantics
  - Why needed here: The Actor must generate syntactically correct ASP code and understand how to represent logical relationships
  - Quick check question: What are the three main components of an ASP program (rules, facts, and queries)?

- Concept: Automated reasoning and proof-by-refutation
  - Why needed here: The Critic must evaluate logical entailment and generate explanations for why queries follow from or contradict the program
  - Quick check question: How does Clingo determine that a query is entailed by an ASP program?

## Architecture Onboarding

- Component map:
  - LLM Actor (GPT4-Turbo/GPT4) -> ASP Code Generator -> Test Generator -> Clingo Solver (Critic) -> Self-correction Loop -> LLM Actor

- Critical path:
  1. Natural language problem description → LLM Actor
  2. ASP code + tests generation → Clingo Solver
  3. Test evaluation and failure analysis → LLM Actor
  4. Code/test refinement → Repeat until convergence

- Design tradeoffs:
  - ASP vs FOL: ASP chosen for enterprise application experience but lacks existential quantification
  - Few-shot vs fine-tuned: Few-shot works surprisingly well but fine-tuning on dialog traces achieves SOTA
  - Test generation: Adds complexity but provides semantic validation and improvement signals

- Failure signatures:
  - Compilation errors: Syntax issues in ASP code
  - Test failures: Semantic issues where rules don't capture intended meaning
  - Query misinterpretation: Incorrect translation of conclusion statements
  - Iterative stagnation: Actor makes no changes across iterations

- First 3 experiments:
  1. Run 8-shot LLM-ARC without test generation to establish baseline
  2. Add test generation to 8-shot system to measure improvement
  3. Implement self-correction loop with 4 iterations and measure accuracy gain

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the analysis, several important unresolved questions emerge regarding the framework's performance and generalizability.

## Limitations

- The framework relies heavily on the quality of explanations generated by the automated reasoning engine, which is not thoroughly evaluated in the paper
- The system's performance on logical problems beyond the FOLIO benchmark remains untested, raising questions about generalizability
- The specific test generation guidelines and their completeness across all FOLIO statement types are not detailed, making faithful reproduction challenging

## Confidence

- Mechanism 1 (Iterative refinement with automated reasoning): High confidence - supported by systematic ablation studies and SOTA results
- Mechanism 2 (Test generation with guidelines): Medium confidence - ablation study shows improvement but lacks detailed analysis of guideline effectiveness
- Mechanism 3 (Self-supervised training on dialog traces): Medium confidence - achieves SOTA but training process and failure mode analysis are limited

## Next Checks

1. Perform error analysis on the 11.68% of FOLIO cases where LLM-ARC fails, categorizing failures by type (syntax errors, semantic mismatches, query misinterpretation) to identify patterns.
2. Test the trained Actor model on a held-out set of FOLIO problems that were not used in the dialog trace collection to assess generalization and identify any overfitting to specific failure modes.
3. Compare the quality of explanations generated by Clingo when tests fail versus when they pass, to verify that the Critic provides actionable feedback that the Actor can use for meaningful refinement.