---
ver: rpa2
title: 'UniSAR: Modeling User Transition Behaviors between Search and Recommendation'
arxiv_id: '2404.09520'
source_url: https://arxiv.org/abs/2404.09520
tags:
- search
- recommendation
- user
- transitions
- unisar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces UniSAR, a unified framework that explicitly
  models fine-grained user transitions between search and recommendation behaviors.
  UniSAR addresses the challenge of understanding complex user behavior patterns in
  platforms offering both services by extracting, aligning, and fusing different types
  of transitions (s2s, r2r, r2s, s2r) using transformers, contrastive learning, and
  cross-attention mechanisms.
---

# UniSAR: Modeling User Transition Behaviors between Search and Recommendation

## Quick Facts
- arXiv ID: 2404.09520
- Source URL: https://arxiv.org/abs/2404.09520
- Reference count: 40
- Primary result: Achieves SOTA performance on joint search and recommendation tasks, with 0.1990 HR@1 for recommendation and 0.5282 HR@1 for search on KuaiSAR dataset

## Executive Summary
UniSAR is a unified framework that explicitly models fine-grained user transitions between search and recommendation behaviors. It addresses the challenge of understanding complex user behavior patterns in platforms offering both services by extracting, aligning, and fusing different types of transitions using transformers, contrastive learning, and cross-attention mechanisms. The model is jointly trained on both search and recommendation data using MMoE to handle multi-task learning, achieving state-of-the-art performance on two public datasets.

## Method Summary
UniSAR introduces a three-step process for modeling user transitions: extraction, alignment, and fusion. It employs transformers with mask mechanisms to extract four types of transitions (s2s, r2r, r2s, s2r), uses contrastive learning to align transitions from same and different scenarios, and applies cross-attention to fuse transitions into unified representations. The model is jointly trained on search and recommendation data using MMoE to handle multi-task learning and address the seesaw phenomenon. Training involves a combined loss function incorporating click losses and contrastive losses, optimized using Adam with early stopping.

## Key Results
- UniSAR achieves 0.1990 HR@1 for recommendation and 0.5282 HR@1 for search on KuaiSAR dataset
- Significantly outperforms existing joint search and recommendation models and traditional sequential recommendation and personalized search models
- Ablation study validates the effectiveness of each component in UniSAR

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UniSAR explicitly models fine-grained user transitions between search and recommendation behaviors, which existing approaches overlook.
- Mechanism: UniSAR uses a three-step process: extraction, alignment, and fusion. It employs transformers with mask mechanisms to extract four types of transitions (s2s, r2r, r2s, s2r), contrastive learning to align transitions from same and different scenarios, and cross-attention to fuse transitions into unified representations.
- Core assumption: Modeling transitions explicitly captures more nuanced user behavior patterns than implicit or separate modeling approaches.
- Evidence anchors:
  - [abstract] "Existing approaches either model user search and recommendation behaviors separately or overlook the different transitions between user search and recommendation behaviors."
  - [section 4.2.1] "To disentangle different transitions and enable the model to better capture different transitions separately, we introduce a mask matrix M"
  - [corpus] Weak evidence - corpus neighbors focus on domain transitions, not search/recommendation transitions specifically
- Break condition: If user behavior transitions between search and recommendation are not significant or predictable enough to improve recommendation performance, explicit modeling may not provide benefit over simpler approaches.

### Mechanism 2
- Claim: Contrastive learning aligns transitions from same and different scenarios to learn relationships between them, improving fusion effectiveness.
- Mechanism: UniSAR applies contrastive learning to align Hs2s with Hr2s (both involve search history) and Hr2r with Hs2r (both involve recommendation history), treating them as positive samples while using in-batch negatives. This enables the model to learn semantic similarities between transitions from different behavioral contexts.
- Core assumption: Transitions from same scenarios (regardless of originating behavior type) share semantic similarities that can be learned through contrastive alignment.
- Evidence anchors:
  - [section 4.2.2] "We utilize contrastive learning to align transitions from the same scenarios with those from different scenarios, enabling the model to learn the correlations between them."
  - [section 4.2.3] "After extracting and learning the relationships between different transitions, we fuse them to get the overall user representation."
  - [corpus] Weak evidence - corpus neighbors mention contrastive learning but not specifically for transition alignment
- Break condition: If contrastive learning fails to create meaningful alignment between transitions, or if the semantic relationships are too complex for simple contrastive approaches to capture.

### Mechanism 3
- Claim: Multi-gate Mixture of Experts (MMoE) addresses the seesaw phenomenon in multi-task learning, enabling simultaneous optimization of search and recommendation tasks.
- Mechanism: UniSAR uses MMoE with shared and task-specific expert networks, along with gating networks that learn task-specific weights for each expert. This allows the model to balance learning between search and recommendation while sharing relevant knowledge.
- Core assumption: Search and recommendation tasks have both shared and task-specific information that can be effectively captured through MMoE architecture.
- Evidence anchors:
  - [section 4.3.2] "UniSAR employs a single model to predict both S&R tasks... we employ a multi-task approach to separately predict the two tasks, incorporating behavior-shared and behavior-specific modules."
  - [section 4.3.3] "There is a trade-off between two tasks... Incorporating MMoE helps us overcome this issue."
  - [corpus] Moderate evidence - corpus includes papers on multi-task learning and MMoE applications
- Break condition: If search and recommendation tasks are too dissimilar or have conflicting optimization objectives, MMoE may not effectively balance the seesaw phenomenon.

## Foundational Learning

- Concept: Transformer architectures with attention mechanisms
  - Why needed here: UniSAR relies heavily on transformer encoders with multi-head self-attention and cross-attention for transition extraction, alignment, and fusion
  - Quick check question: Can you explain how the mask matrix M in MSAₘ ensures attention is computed exclusively between different behaviors?

- Concept: Contrastive learning and its application to representation alignment
  - Why needed here: UniSAR uses contrastive learning to align transitions from same and different scenarios, requiring understanding of positive/negative sampling and temperature parameters
  - Quick check question: How does the contrastive loss in Eq. (5) encourage the model to learn similarities between Hs2s and Hr2s?

- Concept: Multi-task learning and the seesaw phenomenon
  - Why needed here: UniSAR jointly trains on search and recommendation tasks using MMoE to address potential conflicts between objectives
  - Quick check question: What is the seesaw phenomenon in multi-task learning, and how does MMoE help mitigate it?

## Architecture Onboarding

- Component map:
  - Embedding Module -> Transition Extraction (three transformers) -> Contrastive Alignment -> Cross-Attention Fusion -> History Aggregation -> MMoE Prediction -> Joint Training Loss

- Critical path:
  1. Input data → Embedding layer (with query-item contrastive learning)
  2. Embeddings → Transition extraction (three transformers)
  3. Extracted transitions → Contrastive alignment
  4. Aligned transitions → Cross-attention fusion
  5. Fused representations → History aggregation → MMoE prediction
  6. Predictions → Joint training loss optimization

- Design tradeoffs:
  - Separate vs. unified modeling: UniSAR chose unified modeling with MMoE over separate models to share parameters and knowledge
  - Explicit vs. implicit transition modeling: Explicit modeling with masks and separate transformers vs. implicit modeling through sequence mixing
  - Contrastive alignment: Additional computational cost for potential performance gains in transition understanding

- Failure signatures:
  - Poor performance on both tasks: May indicate MMoE parameters need tuning or tasks are too dissimilar
  - Good performance on one task, poor on other: Classic seesaw phenomenon, MMoE gating may need adjustment
  - No improvement over baselines: Transition extraction or alignment may not be capturing useful patterns

- First 3 experiments:
  1. Ablation study removing each transition type (s2s, r2r, r2s, s2r) to validate their individual contributions
  2. Compare performance with and without contrastive alignment (LAlign) to measure its impact on transition understanding
  3. Test different MMoE configurations (number of experts, gating network complexity) to optimize multi-task balance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would UniSAR perform on datasets with different user transition patterns, such as platforms where users rarely switch between search and recommendation?
- Basis in paper: [inferred] The paper demonstrates UniSAR's effectiveness on datasets with high transition rates (KuaiSAR, Amazon), but doesn't test its performance on platforms with minimal S&R transitions.
- Why unresolved: The paper focuses on demonstrating UniSAR's effectiveness in scenarios with high transition rates, but doesn't explore its performance in low-transition environments.
- What evidence would resolve it: Experiments on datasets from platforms with different transition patterns (e.g., news websites, e-commerce sites with less integrated search/recommendation) would clarify UniSAR's versatility across various user behavior patterns.

### Open Question 2
- Question: How does the performance of UniSAR change with different sequence lengths for user history, and what is the optimal length for different types of platforms?
- Basis in paper: [inferred] The paper uses a fixed sequence length of 30 for both datasets, but doesn't explore the impact of varying sequence lengths on performance.
- Why unresolved: The paper doesn't investigate how different sequence lengths affect UniSAR's ability to capture meaningful user transitions and interests.
- What evidence would resolve it: Experiments varying the sequence length parameter across a range of values (e.g., 10-100) on multiple datasets would identify optimal sequence lengths for different types of platforms and user behavior patterns.

### Open Question 3
- Question: How would incorporating additional contextual information (e.g., time of day, device type, user demographics) impact UniSAR's performance in modeling user transitions?
- Basis in paper: [inferred] The paper focuses on modeling transitions between search and recommendation behaviors, but doesn't explore how external contextual factors might influence these transitions.
- Why unresolved: The current model doesn't account for potential contextual factors that might affect user behavior transitions between search and recommendation.
- What evidence would resolve it: Experiments incorporating various contextual features into UniSAR's architecture and comparing performance with and without these features would reveal the importance of contextual information in modeling user transitions.

## Limitations
- Relatively small scale of evaluation datasets, particularly the query-item contrastive learning dataset with only 2,097 samples
- Lack of computational complexity analysis and real-time inference performance evaluation
- Absence of scalability analysis and real-world deployment considerations

## Confidence
- **High**: The overall framework design and the need to model transitions between search and recommendation behaviors is well-supported by the literature and experimental results.
- **Medium**: The specific architectural choices (mask matrices, contrastive alignment, MMoE configuration) are reasonable but could benefit from more ablation studies on alternative designs.
- **Low**: The scalability analysis and real-world deployment considerations are largely absent from the paper.

## Next Checks
1. **Scalability test**: Evaluate UniSAR on a larger dataset (e.g., 10x the size of KuaiSAR) to verify that the transition modeling approach maintains its effectiveness with increased data complexity and volume.

2. **Ablation of contrastive components**: Remove the contrastive learning alignment (LAlign) and compare performance to assess whether the computational overhead is justified by the gains in transition understanding.

3. **Real-time inference benchmarking**: Measure the inference latency and memory requirements of UniSAR compared to baseline models under realistic serving conditions to evaluate production feasibility.