---
ver: rpa2
title: Exploiting XAI maps to improve MS lesion segmentation and detection in MRI
arxiv_id: '2409.03772'
source_url: https://arxiv.org/abs/2409.03772
tags:
- maps
- saliency
- segmentation
- https
- lesion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores using radiomic features extracted from XAI (saliency)
  maps to improve the performance of a deep learning model for MS lesion segmentation.
  The core idea is that TP and FP predictions produce distinct saliency maps, and
  these differences can be captured by radiomic features to refine the model's output.
---

# Exploiting XAI maps to improve MS lesion segmentation and detection in MRI

## Quick Facts
- arXiv ID: 2409.03772
- Source URL: https://arxiv.org/abs/2409.03772
- Reference count: 35
- Primary result: Using radiomic features from XAI saliency maps improves MS lesion segmentation F1 score from 0.7006 to 0.7450

## Executive Summary
This paper presents a novel approach to improve MS lesion segmentation in MRI by leveraging radiomic features extracted from XAI (saliency) maps. The core insight is that true positive (TP) and false positive (FP) predictions produce distinct saliency maps, and these differences can be captured by radiomic features to refine the model's output. By training a logistic regression model to classify TP vs FP predictions based on radiomic features from saliency maps, the authors demonstrate significant performance improvements over a standard U-Net architecture.

## Method Summary
The method involves generating saliency maps for TP and FP predictions from an initial U-Net model, extracting 93 radiomic features from these maps, and training a logistic regression model to classify TP vs FP predictions. The most important features for distinguishing TP from FP were mean absolute deviation, inverse difference normalized, and root mean squared. The refined model achieves an F1 score of 0.7450 and PPV of 0.7817, compared to 0.7006 and 0.6265 for the original U-Net model.

## Key Results
- Improved F1 score from 0.7006 to 0.7450 using radiomic features from XAI maps
- Increased PPV from 0.6265 to 0.7817
- Mean absolute deviation, inverse difference normalized, and root mean squared were the most important features for distinguishing TP from FP

## Why This Works (Mechanism)
The method works by capturing the spatial and intensity characteristics of saliency maps that differ between TP and FP predictions. True positive predictions tend to have saliency maps with higher contrast and more focused attention on actual lesion regions, while false positive predictions often show diffuse or misplaced saliency patterns. Radiomic features effectively quantify these differences, allowing a secondary classifier to distinguish between reliable and unreliable predictions.

## Foundational Learning
- **Radiomic features**: Quantitative descriptors of image texture and intensity patterns; needed to capture subtle differences in saliency maps; quick check: extract Haralick features and test separability between TP/FP maps
- **XAI saliency maps**: Heatmaps showing which image regions influence model predictions; needed to understand model decision-making; quick check: visualize saliency maps for TP vs FP cases
- **Logistic regression for binary classification**: Simple yet effective method for TP/FP discrimination; needed for post-processing refinement; quick check: compare with SVM or random forest classifiers

## Architecture Onboarding

**Component Map**: U-Net -> Saliency Map Generator -> Radiomic Feature Extractor -> Logistic Regression Classifier

**Critical Path**: Input MRI -> U-Net segmentation -> Saliency map generation -> Radiomic feature extraction (93 features) -> Logistic regression classification -> Refined segmentation output

**Design Tradeoffs**: The approach trades increased computational complexity (generating saliency maps and extracting 93 features per prediction) for improved segmentation accuracy. The choice of 93 radiomic features was not justified through feature selection, potentially including redundant features.

**Failure Signatures**: Poor performance on datasets with different acquisition protocols or scanner types; overfitting to the specific training dataset; failure when ground truth labels are noisy or incomplete.

**3 First Experiments**:
1. Generate saliency maps for a subset of predictions and visualize differences between TP and FP cases
2. Extract radiomic features from saliency maps and perform feature importance analysis
3. Train and evaluate logistic regression classifier on a small validation set to assess separability

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset size (30 cases) limits generalizability
- No external validation raises concerns about overfitting
- Computational cost of generating and processing radiomic features not discussed
- Binary classification approach assumes perfect ground truth labeling

## Confidence

**High**: The core methodology (using radiomic features from XAI maps to distinguish TP from FP predictions) is sound and well-executed.

**Medium**: The reported performance improvements are likely real but may be dataset-specific.

**Low**: Generalizability to other datasets, segmentation tasks, or clinical settings.

## Next Checks
1. Validate the method on an independent external dataset with different acquisition protocols and scanners.
2. Compare the computational efficiency and inference time with the original U-Net model.
3. Conduct ablation studies to determine the optimal number of radiomic features and assess feature redundancy.