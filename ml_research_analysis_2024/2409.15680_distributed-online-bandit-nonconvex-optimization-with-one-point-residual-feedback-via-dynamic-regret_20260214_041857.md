---
ver: rpa2
title: Distributed Online Bandit Nonconvex Optimization with One-Point Residual Feedback
  via Dynamic Regret
arxiv_id: '2409.15680'
source_url: https://arxiv.org/abs/2409.15680
tags:
- optimization
- online
- distributed
- regret
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel distributed online bandit optimization
  algorithm for nonconvex loss functions over time-varying digraphs. The algorithm,
  called OP-DOPGD, estimates gradients using residuals from two points, effectively
  reducing regret bounds while maintaining O(1) sampling complexity per iteration.
---

# Distributed Online Bandit Nonconvex Optimization with One-Point Residual Feedback via Dynamic Regret

## Quick Facts
- arXiv ID: 2409.15680
- Source URL: https://arxiv.org/abs/2409.15680
- Reference count: 40
- One-line primary result: Achieves O(T^(1/2+δ)) dynamic regret for nonconvex losses and O(T^(1/2)) for convex losses using one-point residual feedback with O(1) sampling complexity

## Executive Summary
This paper proposes OP-DOPGD, a novel distributed online bandit optimization algorithm that achieves dynamic regret bounds comparable to two-point feedback methods while maintaining single-query complexity. The algorithm leverages one-point residual feedback to estimate gradients using consecutive function evaluations, reducing estimation variance while preserving the O(1) sampling complexity advantage of one-point methods. The approach is validated theoretically and empirically for both convex and nonconvex loss functions over time-varying digraphs, demonstrating that the expected dynamic regret scales sublinearly with time under mild assumptions about the objective function sequence and optimal solution path length.

## Method Summary
The algorithm operates in a distributed online bandit optimization setting where agents must optimize time-varying loss functions using only function value observations. Each agent maintains a decision vector and updates it using a gradient estimator based on residuals between consecutive function evaluations at perturbed points. The update consists of three stages: local gradient estimation using one-point residual feedback, local optimization via projected gradient descent, and consensus-based communication with neighbors to maintain network-wide agreement. The algorithm uses a carefully designed step size and smoothing parameter schedule to balance exploration and exploitation while ensuring convergence to stationary points of the nonconvex optimization problem.

## Key Results
- Achieves O(T^(1/2+δ)) dynamic regret for nonconvex losses and O(T^(1/2)) for convex losses
- Maintains O(1) sampling complexity per iteration despite using two-point-like gradient estimates
- Numerical simulations validate performance on both convex sensor network tracking and nonconvex polynomial optimization problems
- Regret bounds comparable to existing two-point feedback algorithms under sublinear deviation and path length assumptions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: One-point residual feedback reduces gradient estimation variance compared to traditional one-point methods by leveraging consecutive function evaluations.
- Mechanism: The gradient estimator uses the difference between the current loss at a perturbed point and the previous loss at a different perturbed point. This residual structure cancels out noise components that vary independently between iterations, leading to a lower variance estimate.
- Core assumption: The noise in function evaluations at consecutive perturbed points is independent and identically distributed.
- Evidence anchors:
  - [abstract]: "estimates the gradient using residuals from two points, effectively reducing the regret bound while maintaining O(1) sampling complexity per iteration"
  - [section]: "The gradient estimate in (16) evaluates the loss value at only one perturbed point xi,k + µkui,k at each iteration, while the other loss evaluation fi,k−1 (xi,k−1 + µk−1ui,k−1) is inherited from the previous iteration"
- Break condition: If the noise structure between consecutive evaluations is correlated or the environment changes significantly between iterations, the variance reduction benefit diminishes.

### Mechanism 2
- Claim: The algorithm achieves dynamic regret bounds comparable to two-point feedback methods while maintaining single-query complexity.
- Mechanism: By combining the residual feedback gradient estimator with distributed consensus updates, the algorithm maintains low estimation error while allowing agents to track time-varying optimal solutions. The dynamic regret metric benchmarks against the optimal decision at each time step rather than a fixed optimal, making it more stringent but also more realistic for non-stationary problems.
- Core assumption: The deviation in objective function sequence (ΘT) and path length of consecutive optimal solutions (ωT) grow sublinearly.
- Evidence anchors:
  - [abstract]: "achieves a dynamic regret bound of O(T^(1/2+δ)) for nonconvex losses and O(T^(1/2)) for convex losses"
  - [section]: "By appropriately selecting the step size and smoothing parameters, we demonstrate that the expected dynamic regret of our algorithm is comparable to existing algorithms that use two-point feedback, provided the deviation in the objective function sequence and the path length of the minimization grows sublinearly"
- Break condition: If ΘT or ωT grow linearly with time, the regret bound degrades and may become linear in T.

### Mechanism 3
- Claim: The distributed consensus update structure enables agents to converge to a common solution while tracking time-varying objectives.
- Mechanism: Each agent performs local gradient descent using the residual feedback estimate, then applies a weighted average of neighboring agents' intermediate values. This combination allows agents to maintain individual optimization progress while ensuring network-wide agreement on the solution trajectory.
- Core assumption: The time-varying communication graph is uniformly strongly connected over time with bounded mixing time.
- Evidence anchors:
  - [section]: "Using the information received from these neighbors, player i applies the projected consensus-based algorithm to update its decision to xi,k+1"
  - [section]: "By taking average of both sides of (29) and applying the double stochasticity of the transition matrices, we obtain"
- Break condition: If the communication graph becomes disconnected for extended periods or the mixing time becomes unbounded, consensus may fail and agents may diverge.

## Foundational Learning

- Concept: Gaussian smoothing for gradient estimation
  - Why needed here: Enables gradient estimation using only function values, which is essential for bandit feedback where gradients are unavailable
  - Quick check question: How does the smoothing parameter µ affect the bias-variance tradeoff in gradient estimation?

- Concept: Dynamic regret vs static regret
  - Why needed here: Dynamic regret benchmarks against time-varying optimal solutions, making it more appropriate for non-stationary optimization problems
  - Quick check question: What additional assumptions are needed to achieve sublinear dynamic regret compared to static regret?

- Concept: Consensus-based distributed optimization
  - Why needed here: Allows multiple agents to collaboratively optimize a global objective while only communicating with neighbors
  - Quick check question: How does the mixing time of the communication graph affect the convergence rate of consensus-based methods?

## Architecture Onboarding

- Component map: Local gradient estimation -> Local optimization -> Consensus communication -> Projection -> Next iteration

- Critical path: Gradient estimation → Local optimization → Consensus communication → Projection → Next iteration

- Design tradeoffs:
  - Sampling complexity vs estimation accuracy: One-point residual feedback trades slightly higher variance for O(1) sampling complexity
  - Communication frequency vs consensus speed: More frequent communication accelerates consensus but increases overhead
  - Smoothing parameter vs bias: Larger smoothing reduces variance but increases bias in gradient estimation

- Failure signatures:
  - High variance in gradient estimates → Poor convergence, oscillatory behavior
  - Poor mixing in communication graph → Agent disagreement, failure to reach consensus
  - Sublinear growth of ΘT or ωT → Linear regret bounds, algorithm failure to track optimal solutions

- First 3 experiments:
  1. Implement the one-point residual feedback gradient estimator and compare variance to traditional one-point estimator on a simple quadratic function
  2. Test consensus convergence on a fixed communication graph with varying graph connectivity and mixing times
  3. Evaluate dynamic regret on a time-varying convex optimization problem with known optimal trajectory to validate tracking performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the algorithm's performance scale with the dimension d in very high-dimensional spaces, particularly beyond the O(d^2) complexity observed in the simulations?
- Basis in paper: [inferred] The paper mentions O(d^2) dimensional dependence is common for distributed zeroth-order algorithms and consistent with results in [33], [35], [36], [43], but doesn't explore scaling beyond these dimensions or provide explicit analysis for very high-dimensional cases.
- Why unresolved: The paper only provides simulations for 2-dimensional problems and theoretical analysis doesn't explicitly address high-dimensional scaling. The O(d^2) complexity suggests potential computational challenges in very high-dimensional spaces.
- What evidence would resolve it: Extended simulations showing performance degradation rates as dimension increases, or theoretical analysis providing bounds on regret scaling with very large d values.

### Open Question 2
- Question: Can the algorithm be extended to handle dynamic constraint sets where the feasible region Ω changes over time, rather than being fixed as assumed in the paper?
- Basis in paper: [explicit] The paper explicitly states "In this paper, only simple ensemble constraints are considered. Exploring online optimization on dynamic constraint sets would be an interesting and challenging future direction."
- Why unresolved: The algorithm relies on a fixed projection operator P_Ω that would need modification for time-varying constraints. The theoretical analysis assumes fixed Ω throughout.
- What evidence would resolve it: Development and analysis of an extended algorithm that handles time-varying constraints, with corresponding regret bounds and simulation validation.

### Open Question 3
- Question: What is the impact of communication delays or packet drops on the algorithm's convergence and regret bounds in practical implementations?
- Basis in paper: [inferred] The paper assumes ideal communication conditions where each agent can communicate with its neighbors through the time-varying graph Gk, but doesn't consider real-world communication imperfections.
- Why unresolved: The theoretical analysis and simulations assume perfect, instantaneous communication. Real-world distributed systems typically face delays and packet losses that could affect performance.
- What evidence would resolve it: Analysis of algorithm robustness under communication delays/packet drops, modified regret bounds accounting for communication imperfections, and simulation results comparing ideal vs. imperfect communication scenarios.

## Limitations
- Sublinear growth assumptions for ΘT and ωT may not hold in many real-world scenarios with abrupt changes
- Requires uniformly strongly connected time-varying graphs, which may not be realistic in all network scenarios
- One-point residual feedback mechanism may be sensitive to noise correlation between consecutive evaluations

## Confidence
- Theoretical regret bounds: High for convex case (O(T^(1/2))), Medium for nonconvex case (O(T^(1/2+δ)))
- Consensus mechanism: Medium, heavily dependent on graph properties
- One-point residual feedback: Medium, pending empirical validation under realistic noise conditions

## Next Checks
1. Test the algorithm on a time-varying optimization problem where ΘT grows linearly with time to verify if the regret bounds degrade as predicted by theory when the sublinear growth assumption is violated.

2. Implement the algorithm on a communication graph with intermittent connectivity to assess the impact of non-uniform graph connectivity on consensus performance and overall regret bounds.

3. Compare the performance of the one-point residual feedback estimator against traditional one-point and two-point feedback methods on problems with correlated noise to validate the claimed variance reduction benefits.