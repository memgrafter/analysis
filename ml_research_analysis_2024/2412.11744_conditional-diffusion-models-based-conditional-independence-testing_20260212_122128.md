---
ver: rpa2
title: Conditional Diffusion Models Based Conditional Independence Testing
arxiv_id: '2412.11744'
source_url: https://arxiv.org/abs/2412.11744
tags:
- conditional
- test
- distribution
- samples
- testing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel conditional independence testing
  method using conditional diffusion models (CDMs) to approximate the conditional
  distribution of X given Z. The method is compared against seven state-of-the-art
  approaches on synthetic datasets and real-world applications, including breast cancer
  genomics and flow cytometry data.
---

# Conditional Diffusion Models Based Conditional Independence Testing

## Quick Facts
- arXiv ID: 2412.11744
- Source URL: https://arxiv.org/abs/2412.11744
- Reference count: 40
- Key outcome: Novel CI testing method using conditional diffusion models outperforms 7 state-of-the-art approaches on synthetic and real datasets with superior type I error control and computational efficiency.

## Executive Summary
This paper introduces a conditional independence testing method based on conditional diffusion models (CDMs) to approximate the conditional distribution of X given Z. The method uses a classifier-based conditional mutual information (CMI) estimator and the conditional randomization test framework to test whether X and Y are independent given Z. The proposed method demonstrates superior performance compared to seven state-of-the-art approaches on both synthetic and real-world datasets, including breast cancer genomics and flow cytometry data. Theoretical analysis shows that the method asymptotically controls type I error at the specified significance level.

## Method Summary
The method learns a conditional diffusion model to approximate P(X|Z) from unlabelled data, then uses this model to generate pseudo-samples for the conditional randomization test. A classifier-based CMI estimator serves as the test statistic, which captures complex dependence structures without requiring specific distributional assumptions. The algorithm consists of three main components: training the conditional diffusion model using score matching, generating pseudo-samples from the learned conditional distribution, and estimating CMI using a binary classifier. The method is evaluated against seven state-of-the-art CI testing methods across synthetic datasets with known ground truth and real-world applications.

## Key Results
- Controls both type I and type II errors effectively, even in high-dimensional scenarios and mixed-type conditioning sets
- Achieves highest recall and F-score on flow cytometry data among all tested methods
- Demonstrates lowest prediction MSE for tumor size in breast cancer datasets
- Shows superior computational efficiency compared to competing methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed method accurately approximates the conditional distribution of X given Z using conditional diffusion models, leading to more accurate conditional independence testing.
- Mechanism: CDMs are trained to approximate p(X|Z) by learning the score function ∇ log p(X(t)|Z) through score matching, then used to generate pseudo-samples for the conditional randomization test.
- Core assumption: The true conditional distribution p(X|Z) can be well-approximated by a CDM trained on the data.
- Evidence anchors: Theoretical and empirical evidence shows CDMs closely approximate the true conditional distribution and offer more accurate approximation compared to GANs.
- Break condition: If the CDM fails to accurately learn the score function, generated samples will not closely approximate the true conditional distribution, leading to inflated type I errors.

### Mechanism 2
- Claim: The classifier-based CMI estimator effectively captures intricate dependence structures without requiring specific distributional assumptions.
- Mechanism: Uses a binary classifier trained to distinguish between samples from p(X,Y,Z) and p(X,Z)p(Y|Z), with CMI estimated via KL divergence computed from classifier probabilities.
- Core assumption: The classifier can effectively learn to distinguish between joint and product distributions, and estimated CMI accurately reflects true conditional dependence.
- Evidence anchors: CMI provides strong theoretical guarantees for conditional dependence relations and doesn't require specific distributional assumptions.
- Break condition: If the classifier fails to distinguish distributions, estimated CMI will not accurately reflect true conditional dependence, leading to incorrect CI test results.

### Mechanism 3
- Claim: The proposed test asymptotically controls the type I error at the specified significance level α.
- Mechanism: Theoretical analysis shows type I error is bounded by α plus total variation distance between true and approximated conditional distributions, which converges to zero as sample size increases.
- Core assumption: Total variation distance converges to zero as sample size increases, and classifier-based CMI estimator is consistent.
- Evidence anchors: Theoretical analysis demonstrates valid asymptotic control of type I error.
- Break condition: If total variation distance does not converge to zero or CMI estimator is not consistent, type I error will not be asymptotically controlled at level α.

## Foundational Learning

- Concept: Conditional independence (CI)
  - Why needed here: CI is the fundamental concept being tested; understanding CI is crucial for grasping the problem, solution, and evaluation.
  - Quick check question: What does it mean for two random variables X and Y to be conditionally independent given a third random variable Z?

- Concept: Conditional randomization test (CRT)
  - Why needed here: CRT is the framework used for testing conditional independence; understanding CRT is essential for how the method generates pseudo-samples and calculates p-values.
  - Quick check question: How does the CRT framework work for testing conditional independence, and what is the role of the conditional distribution p(X|Z) in this framework?

- Concept: Diffusion models
  - Why needed here: Diffusion models are the core component for approximating the conditional distribution p(X|Z); understanding them is crucial for how the method generates pseudo-samples.
  - Quick check question: How do diffusion models work, and how are they adapted in this paper to model the conditional distribution p(X|Z)?

## Architecture Onboarding

- Component map: Input dataset -> Conditional diffusion model training -> Sample generation -> Classifier-based CMI estimation -> p-value calculation

- Critical path: 1. Train conditional diffusion model on unlabelled data 2. Generate pseudo-samples using trained model 3. Estimate CMI using classifier-based estimator 4. Calculate p-value based on CMI estimates

- Design tradeoffs: Accuracy vs. computational efficiency (more complex models may improve approximation but increase training time); sample size vs. type I error control (larger training sets improve approximation but require more resources)

- Failure signatures: High type I error (indicates poor conditional distribution approximation); low power (indicates CMI estimator not sensitive enough); slow convergence (indicates ineffective score function learning)

- First 3 experiments: 1. Synthetic data experiment evaluating type I error and power compared to baselines 2. Real data application to breast cancer genomic data identifying conditionally dependent genes 3. Ablation study evaluating impact of different components (diffusion model architecture, CMI estimator) on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method scale with extremely high-dimensional conditioning sets (e.g., dz > 1000)?
- Basis in paper: Explicit statement that LPCIT and DGCIT are impractical for high-dimensional Z due to long execution times, while the proposed method shows computational efficiency.
- Why unresolved: Paper demonstrates good performance for dz up to 100 but doesn't test or discuss performance for dz > 1000.
- What evidence would resolve it: Empirical results showing performance metrics for dz > 1000, or theoretical analysis of computational complexity as dz grows.

### Open Question 2
- Question: What is the impact of choosing different neural network architectures for the score network bs(x, z, t) on performance?
- Basis in paper: Explicit mention of using ReLU neural networks with specific architecture details but no exploration of sensitivity to these choices.
- Why unresolved: Paper uses specific architectures without investigating how variations in depth, width, and activation functions affect performance.
- What evidence would resolve it: Systematic experiments comparing performance across different architectures including ablation studies on depth, width, and activation functions.

### Open Question 3
- Question: How robust is the proposed method to violations of the smoothness assumptions on the conditional density p(x|z)?
- Basis in paper: Explicit smoothness assumption (Hölder norm) required for theoretical guarantees but no discussion of robustness to violations.
- Why unresolved: Paper relies on this assumption for theoretical guarantees but doesn't empirically test performance with non-smooth conditional distributions.
- What evidence would resolve it: Experiments using synthetic data with non-smooth conditional distributions to assess performance degradation and type I error control.

### Open Question 4
- Question: What is the optimal number of repetitions B for the conditional randomization test, and how sensitive is the method to this choice?
- Basis in paper: Explicit setting of B=100 with statement that influence is minimal, but no systematic analysis of this parameter.
- Why unresolved: While mentioning minimal influence, paper doesn't provide rigorous analysis of the trade-off between computational cost and statistical power as B varies.
- What evidence would resolve it: Experiments systematically varying B and measuring impact on type I error, power, and computational time to determine optimal choice.

## Limitations

- Asymptotic type I error control may not hold in practical finite-sample regimes common in real-world applications.
- Method requires substantial unlabelled data (N=500) for training the conditional sampler, which may not be available in many applications.
- Performance depends heavily on the quality of the diffusion model approximation with no explicit verification mechanism beyond aggregate metrics.

## Confidence

**High Confidence:** Empirical demonstration of CDM effectiveness in synthetic settings and validity of CRT framework; type I error control mechanism is theoretically sound given assumptions.

**Medium Confidence:** Claim that CDMs provide more accurate approximation compared to GANs - theoretically plausible but comparative evidence limited to specific experimental conditions.

**Low Confidence:** Assertion of asymptotic type I error control at arbitrary significance levels without specifying convergence rate or sample size requirements; practical implications for finite samples unclear.

## Next Checks

1. **Finite-sample behavior analysis:** Conduct experiments with varying sample sizes (n < 500) to quantify deviation from nominal α levels and establish practical guidelines for required sample sizes.

2. **Distribution approximation validation:** Implement quantitative metrics (beyond MSE) to assess quality of conditional distribution approximation, such as KL divergence estimates between true and learned distributions on held-out validation sets.

3. **Scalability testing:** Evaluate method's performance on high-dimensional Z (>20 dimensions) and mixed-type variables to identify practical limitations of diffusion model architecture and CMI estimator.