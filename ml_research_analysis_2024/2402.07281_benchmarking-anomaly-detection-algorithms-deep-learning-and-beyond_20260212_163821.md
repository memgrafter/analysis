---
ver: rpa2
title: 'Benchmarking Anomaly Detection Algorithms: Deep Learning and Beyond'
arxiv_id: '2402.07281'
source_url: https://arxiv.org/abs/2402.07281
tags:
- anomaly
- detection
- datasets
- data
- anomalies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper benchmarks 16 anomaly detection algorithms, including
  classical ML, tree-based methods, and deep learning (DL) models, on 104 diverse
  datasets. It highlights that DL algorithms perform best on multivariate datasets
  due to their data-hungry nature, but are resource-intensive and require anomaly
  labels in training, limiting real-world applicability.
---

# Benchmarking Anomaly Detection Algorithms: Deep Learning and Beyond

## Quick Facts
- arXiv ID: 2402.07281
- Source URL: https://arxiv.org/abs/2402.07281
- Reference count: 40
- Primary result: Tree-based evolutionary algorithms match or outperform deep learning methods on univariate datasets without requiring labeled anomalies or training.

## Executive Summary
This comprehensive benchmark study evaluates 16 anomaly detection algorithms across 104 diverse datasets, comparing classical machine learning, tree-based evolutionary methods, and deep learning approaches. The research reveals that while deep learning excels on multivariate datasets due to its data-hungry nature, it is resource-intensive and requires labeled anomalies for training, limiting practical applicability. Tree-based methods like MGBTAI and d-BTAI achieve comparable or superior performance, particularly on univariate datasets with small sizes and few anomalies. The study concludes that deep learning is not a universal solution for anomaly detection and emphasizes the importance of unsupervised tree-based approaches for realistic, resource-constrained settings.

## Method Summary
The study benchmarks 16 anomaly detection algorithms on 73 multivariate and 31 univariate datasets using standardized 70% normal training and full-dataset testing splits. Algorithms include classical ML (LOF, OCSVM, KNN), tree-based evolutionary methods (MGBTAI, d-BTAI), and deep learning models (VAE, GAN, LSTM-VAE). Performance is measured using precision, recall, F1-score, and AUC-ROC, with resource utilization tracked for training time and hardware requirements. Hyperparameters are fixed as specified in Table 1, with DL models trained on Nvidia P100 GPU and others on CPU.

## Key Results
- Tree-based evolutionary algorithms (MGBTAI, d-BTAI) achieve top precision on 25/31 univariate datasets and top recall on 25 multivariate datasets.
- Deep learning methods require labeled anomalies in training, making them impractical for real-world scenarios with single anomalies or no training labels.
- DL algorithms perform best on multivariate datasets but are significantly more resource-intensive than classical and tree-based methods.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Deep learning models perform best on multivariate datasets due to their data-hungry nature.
- **Mechanism:** DL models require large volumes of data to learn complex, high-dimensional patterns. Multivariate datasets typically contain more samples and dimensions, providing the necessary complexity for DL to outperform classical methods.
- **Core assumption:** Larger and more complex datasets inherently benefit DL models more than classical methods.
- **Evidence anchors:**
  - [abstract] "DL algorithms perform best on multivariate datasets due to their data-hungry nature"
  - [section] "DL algorithms took significantly more time to run compared to classical and tree-based algorithms"
- **Break condition:** When dataset size or dimensionality is insufficient for DL to extract meaningful patterns.

### Mechanism 2
- **Claim:** Tree-based evolutionary algorithms excel at detecting singleton anomalies in small univariate datasets.
- **Mechanism:** These algorithms use clustering and isolation strategies that don't require anomaly labels or extensive training data, making them effective for datasets with very few anomalies.
- **Core assumption:** Anomaly detection doesn't always require labeled anomalies or large datasets.
- **Evidence anchors:**
  - [abstract] "tree-based evolutionary algorithms match DL methods and sometimes outperform them in many instances of univariate data where the size of the data is small and number of anomalies are less than 10%"
  - [section] "MGBTAI excels in precision (top on 25/31 univariate datasets)"
- **Break condition:** When anomaly prevalence increases significantly, potentially overwhelming the clustering-based approach.

### Mechanism 3
- **Claim:** Recent DL methods requiring labeled anomalies fail on datasets with single anomalies or no training labels.
- **Mechanism:** These methods need anomaly contamination in training data to function effectively, which is unrealistic in real-world scenarios where anomalies are rare and unknown beforehand.
- **Core assumption:** Anomaly detection methods must work in unsupervised settings without labeled anomalies.
- **Evidence anchors:**
  - [abstract] "DL is not a universal solution for anomaly detection" and "These methods require labeled data for anomaly detection, which is not realistic"
  - [section] "these recent SOTA DL methods...require anomaly contamination in the training set...Hence, they do not work on datasets with a single anomaly"
- **Break condition:** When labeled anomaly data becomes available and training can be performed with contamination.

## Foundational Learning

- **Concept: Imbalanced class distribution**
  - Why needed here: Anomaly detection inherently deals with rare events, making class imbalance a fundamental challenge
  - Quick check question: If a dataset has 1000 normal instances and 1 anomaly, what's the class imbalance ratio?

- **Concept: Evaluation metrics in anomaly detection**
  - Why needed here: Standard accuracy metrics fail for imbalanced data; precision, recall, F1-score, and AUC-ROC are critical for proper evaluation
  - Quick check question: Which metric would you prioritize if false positives are extremely costly?

- **Concept: Computational resource tradeoffs**
  - Why needed here: DL methods require GPUs and long training times versus CPU-efficient classical methods
  - Quick check question: How would you decide between a 30-minute DL training versus a 10-second classical method?

## Architecture Onboarding

- **Component map:** Data preprocessing -> Algorithm selection -> Training/execution -> Evaluation -> Resource monitoring
- **Critical path:** Data preparation -> Algorithm execution -> Performance evaluation -> Resource utilization tracking
- **Design tradeoffs:** DL accuracy vs. resource consumption, supervised vs. unsupervised approaches, precision vs. recall requirements
- **Failure signatures:** DL overfitting on small datasets, tree-based methods missing complex patterns, resource exhaustion during training
- **First 3 experiments:**
  1. Run MGBTAI on a small univariate dataset with <10% anomalies to verify singleton detection capability
  2. Execute FTT on a moderate-sized multivariate dataset to observe training time and resource usage
  3. Compare IForest vs. DL methods on a time-series dataset to evaluate performance differences in temporal data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal percentage of anomalies in a dataset beyond which they cease to be outliers?
- Basis in paper: [explicit] The paper notes that with a high percentage of anomalies (such as in multivariate datasets), precision, recall, and F1-score become less informative. It also mentions that most anomaly detection methods work well on datasets with less than 10% anomalies.
- Why unresolved: The paper does not provide a definitive threshold or percentage that distinguishes outliers from normal data, leaving this as an open question.
- What evidence would resolve it: Empirical studies across diverse datasets with varying anomaly percentages to determine the point at which anomaly detection performance metrics become unreliable.

### Open Question 2
- Question: How does the performance of anomaly detection algorithms change with varying resource constraints, such as limited GPU availability or memory?
- Basis in paper: [explicit] The paper highlights that DL algorithms are resource-intensive and require significant GPU resources, while tree-based methods consume minimal resources. It questions the trade-off between performance and resource demand.
- Why unresolved: The paper does not provide a detailed analysis of how different algorithms perform under varying resource constraints, such as low-memory or low-compute environments.
- What evidence would resolve it: Benchmarking studies comparing algorithm performance across different hardware configurations and resource limitations.

### Open Question 3
- Question: How can unsupervised anomaly detection methods be adapted to handle datasets with a single anomaly or extremely low anomaly prevalence?
- Basis in paper: [explicit] The paper notes that recent SOTA DL methods require labeled anomalies and fail to work on datasets with a single anomaly, while tree-based methods do not require labeled anomalies.
- Why unresolved: The paper does not explore potential adaptations or improvements to existing methods to handle singleton anomalies or datasets with very low anomaly prevalence.
- What evidence would resolve it: Development and testing of new algorithms or modifications to existing ones that can effectively detect anomalies in datasets with minimal or single anomalies.

## Limitations

- The study uses fixed hyperparameters and dataset splits, which may not represent optimal configurations for all algorithms.
- Resource consumption measurements focus primarily on training time without comprehensive memory usage analysis.
- The performance rankings may shift with different hyperparameter tuning or evaluation protocols.
- Implementation details for MGBTAI and d-BTAI clustering thresholds are not fully specified.

## Confidence

**High Confidence:** The core finding that tree-based evolutionary methods achieve comparable performance to DL models on univariate datasets, supported by direct experimental comparisons across 31 datasets. The observation about DL methods requiring labeled anomalies for training is well-established in the literature and consistently demonstrated.

**Medium Confidence:** The generalization that DL is not universally superior across all anomaly detection scenarios, as this depends heavily on dataset characteristics and specific algorithm implementations.

**Low Confidence:** The specific threshold values used in d-BTAI's clustering enhancement and their impact on performance across different dataset types, as these details are not fully transparent in the methodology.

## Next Checks

1. **Cross-dataset generalization test:** Validate MGBTAI's precision advantage on univariate datasets by testing across 5-10 additional benchmark datasets from different domains not included in the original study.

2. **Resource consumption audit:** Measure and compare memory usage, CPU utilization, and GPU memory requirements across all 16 algorithms during both training and inference phases on identical hardware.

3. **Hyperparameter sensitivity analysis:** Systematically vary key hyperparameters (tree depth, contamination rates, learning rates) for top-performing algorithms to quantify performance stability and identify breaking points.