---
ver: rpa2
title: Transparent Neighborhood Approximation for Text Classifier Explanation
arxiv_id: '2411.16251'
source_url: https://arxiv.org/abs/2411.16251
tags:
- text
- explanation
- neighborhood
- xprob
- very
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the transparency problem in model-agnostic
  text classifier explanation methods that rely on black-box generative models for
  neighborhood construction. The proposed method, XPROB, introduces a probability-based
  editing approach that generates neighboring texts by integrating tokens from the
  explicand into prototypes using local n-gram context probabilities, avoiding the
  need for neural network generators.
---

# Transparent Neighborhood Approximation for Text Classifier Explanation

## Quick Facts
- arXiv ID: 2411.16251
- Source URL: https://arxiv.org/abs/2411.16251
- Authors: Yi Cai; Arthur Zimek; Eirini Ntoutsi; Gerhard Wunder
- Reference count: 40
- One-line primary result: XPROB achieves competitive performance compared to generator-based methods with fidelity scores around 0.93, confidence drops around 0.58, and AOPC scores around 0.48 while significantly reducing computational costs.

## Executive Summary
This paper addresses the transparency problem in model-agnostic text classifier explanation methods that rely on black-box generative models for neighborhood construction. The proposed method, XPROB, introduces a probability-based editing approach that generates neighboring texts by integrating tokens from the explicand into prototypes using local n-gram context probabilities, avoiding the need for neural network generators. XPROB constructs neighborhoods through recursive editing guided by empirical probability distributions, creating a fully transparent and controllable explanation process.

Evaluation on two real-world datasets (Amazon and Yelp reviews) shows XPROB achieves competitive performance compared to generator-based methods, with fidelity scores around 0.93, confidence drops around 0.58, and AOPC scores around 0.48. XPROB also demonstrates superior stability in attributions across similar contexts and significantly reduces computational costs compared to generator-based alternatives.

## Method Summary
XPROB is a model-agnostic explanation method for text classifiers that replaces black-box generative models with transparent probability-based editing. The method constructs neighborhoods by recursively integrating tokens from the explicand into counterfactual prototypes selected based on tf-idf distance. Local n-gram context probabilities estimated from a retained corpus guide the editing process, ensuring grammatical correctness while exploring diverse text variations. A linear regression surrogate model trained on the constructed neighborhood extracts feature attributions, providing interpretable explanations of the black-box classifier's decisions.

## Key Results
- XPROB achieves competitive performance with fidelity scores around 0.93 and confidence drops around 0.58 compared to generator-based methods
- The method demonstrates superior stability with lower standard deviation in attribution scores across similar contexts
- XPROB significantly reduces computational costs compared to generator-based alternatives while maintaining explanation quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: XPROB generates neighboring texts by probability-based editing using local n-gram contexts instead of black-box generative models.
- Mechanism: The method selects tokens from the explicand and integrates them into prototypes using empirical probability distributions estimated from a corpus. The editing operation maximizes the conditional probability of the resulting text given local n-gram contexts.
- Core assumption: Local n-gram context probabilities can adequately represent the underlying data manifold of the text domain without requiring complex neural network generators.
- Evidence anchors:
  - [abstract]: "XPROB introduces a probability-based editing approach that generates neighboring texts by integrating tokens from the explicand into prototypes using local n-gram context probabilities"
  - [section 3.1]: "The editing process considers local n-gram contexts [26] instead of whole sequences" and "O(w, ˆx) = arg max Ppre(w|ˆxi i−n+1)Psuc(w|ˆxj+n−1 j )"
  - [corpus]: Weak - corpus only provides titles/abstracts without implementation details about probability estimation methods
- Break condition: If local n-gram contexts fail to capture long-range dependencies or semantic coherence in the text, the generated neighbors may become grammatically incorrect or semantically irrelevant.

### Mechanism 2
- Claim: Recursive probability-based editing creates gradual transitions between classes while maintaining locality constraints.
- Mechanism: Starting from counterfactual prototypes selected based on cosine distance in tf-idf space, XPROB recursively integrates explicand tokens into prototypes, creating intermediate texts that show gradual prediction changes from one class to another.
- Core assumption: The locality constraint can be effectively maintained through tf-idf distance in prototype selection and gradual token integration rather than complex latent space sampling.
- Evidence anchors:
  - [abstract]: "Substituting the generator-based construction process with recursive probability-based editing, the resultant explanation method, XPROB... exhibits competitive performance"
  - [section 3.2]: "prototype selection follows their spatial closeness to the explicand... measured by the cosine distance between their tf-idf vectors"
  - [section 3.2]: "By integrating explicand components into counterfactuals, XPROB implements a gradual transition in model predictions from one class to another"
  - [corpus]: Weak - corpus lacks implementation details about the recursive process termination criteria
- Break condition: If the recursive process fails to find valid edits (probability below threshold) or produces neighborhoods with insufficient diversity, the explanation quality will degrade.

### Mechanism 3
- Claim: XPROB's transparent construction process leads to superior stability compared to generator-based methods.
- Mechanism: The deterministic probability-based editing following explicit rules creates consistent attribution scores across similar contexts, unlike generator-based methods where latent space perturbations have unforeseeable effects.
- Core assumption: Deterministic editing rules based on empirical probabilities produce more stable explanations than stochastic generative processes.
- Evidence anchors:
  - [abstract]: "XPROB's fully transparent and more controllable construction process leads to superior stability compared to the generator-based explainers"
  - [section 4.4]: "The consistency in explanation results is credited to its controlled generation process driven by probability-based editing"
  - [section 4.4]: "XPROB constantly assigns approximately zero attributions to the nouns, accurately reflecting their non-informative nature in sentiment analysis"
  - [section 4.5]: "The observed discrepancies suggest that inadequate latent space geometry... is a potential cause of the declined performance"
- Break condition: If the empirical probability estimates become unstable with corpus size or if the editing rules become too rigid to capture nuanced text variations, stability advantages may diminish.

## Foundational Learning

- Concept: Probability estimation from empirical distributions
  - Why needed here: XPROB relies on estimating conditional probabilities from a retained corpus Xp to guide text manipulation decisions
  - Quick check question: How would you estimate Ppre(w|ˆxi i−n+1) using only the retained corpus Xp without external language models?

- Concept: Local context modeling with n-grams
  - Why needed here: The method uses local n-gram contexts instead of entire sequences to enable exploration beyond existing token combinations while maintaining grammatical correctness
  - Quick check question: What trade-off exists between the n-gram size and the feasibility of edits in the probability-based editing process?

- Concept: Prototype selection and neighborhood construction
  - Why needed here: XPROB requires selecting appropriate counterfactual prototypes and constructing neighborhoods through recursive editing to maintain locality constraints
  - Quick check question: Why does XPROB use cosine distance between tf-idf vectors rather than embedding distances for prototype selection?

## Architecture Onboarding

- Component map: Prototype corpus (Xp) -> Probability estimator -> Editor -> Recursive builder -> Surrogate model (g) -> Attribution extractor
- Critical path: Prototype selection → Recursive editing → Neighborhood construction → Surrogate training → Attribution extraction
- Design tradeoffs:
  - Corpus size vs. computational efficiency: Larger Xp provides better probability estimates but increases computation time
  - n-gram size vs. edit feasibility: Larger n captures more context but reduces valid edit opportunities
  - Prototype diversity vs. locality: More diverse prototypes may improve exploration but risk violating locality constraints
- Failure signatures:
  - Low fidelity scores indicate poor neighborhood quality or inadequate surrogate training
  - High standard deviation in attribution scores suggests instability in the editing process
  - Failed edits (no operations exceeding ϵ2 threshold) indicate poor probability estimates or inappropriate n-gram settings
- First 3 experiments:
  1. Test probability estimation accuracy by comparing Ppre and Psuc estimates against held-out validation data
  2. Evaluate prototype selection effectiveness by measuring tf-idf distance distribution between selected prototypes and explicands
  3. Benchmark editing feasibility by measuring the percentage of word-prototype pairs that yield valid edits above the threshold ϵ2

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of XPROB scale when explaining multi-class text classifiers compared to binary classifiers?
- Basis in paper: [explicit] The paper mentions that XPROB can be adapted to multi-class scenarios by redefining counterfactuals as instances with low prediction confidence for the predicted class, but does not evaluate this.
- Why unresolved: The evaluation was limited to binary classification tasks on short texts, leaving the method's effectiveness on multi-class problems unexplored.
- What evidence would resolve it: Comparative experiments on multi-class datasets (e.g., news classification, multi-topic reviews) showing fidelity, completeness, and compactness metrics across different class numbers.

### Open Question 2
- Question: What is the impact of n-gram context size (n) on the quality of generated neighboring texts and explanation accuracy?
- Basis in paper: [explicit] The paper states that n=1 was chosen for short review texts to allow more feasible edits, but does not systematically study how different n values affect performance.
- Why unresolved: The relationship between context window size and explanation quality remains unclear, particularly for longer texts or different domains.
- What evidence would resolve it: Controlled experiments varying n across different text lengths and domains, measuring explanation fidelity, stability, and generation feasibility.

### Open Question 3
- Question: How does XPROB's performance compare to other non-generator-based explanation methods like SHAP or LIME with word replacement strategies?
- Basis in paper: [inferred] The paper compares XPROB only to LIME (word dropping) and generator-based methods, leaving a gap in comparison with more sophisticated non-generator approaches.
- Why unresolved: The competitive advantage of probability-based editing over other perturbation strategies is not established.
- What evidence would resolve it: Direct comparison experiments between XPROB, SHAP, and LIME with various perturbation strategies on identical datasets and metrics.

## Limitations
- The method's performance on multi-class classification tasks remains unexplored, as experiments were limited to binary sentiment analysis
- The empirical probability estimation procedure lacks implementation details, making exact reproduction challenging
- The relationship between n-gram context size and explanation quality across different text domains and lengths is not systematically studied

## Confidence

- High Confidence: The core mechanism of probability-based editing using local n-gram contexts and the claim about transparent construction leading to superior stability are well-supported by both theoretical framework and experimental evidence
- Medium Confidence: The claim about competitive performance compared to generator-based methods is supported by experimental results, though the paper notes that performance is "comparable" rather than superior in most metrics
- Low Confidence: The generalizability of the method to other text classification tasks beyond sentiment analysis is not demonstrated, as the experiments are limited to two sentiment analysis datasets

## Next Checks

1. Implement and validate the empirical probability estimation procedure by comparing Ppre and Psuc estimates against held-out validation data to ensure the probability distributions accurately capture the text domain
2. Conduct ablation studies on n-gram size and corpus size to quantify their impact on edit feasibility, neighborhood quality, and computational efficiency, as these hyperparameters significantly affect the method's performance
3. Test the method's stability claims by systematically varying similar contexts and measuring attribution score deviations, comparing the results against generator-based baselines to verify the deterministic editing advantage