---
ver: rpa2
title: Partitioning Message Passing for Graph Fraud Detection
arxiv_id: '2412.00020'
source_url: https://arxiv.org/abs/2412.00020
tags:
- graph
- neighbors
- fraud
- nodes
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Partitioning Message Passing (PMP), a graph
  neural network approach specifically designed for fraud detection in graphs with
  label imbalance and heterophily-homophily mixture. The key innovation is partitioning
  the message passing process by node labels, using distinct node-specific aggregation
  functions for fraud, benign, and unlabeled neighbors.
---

# Partitioning Message Passing for Graph Fraud Detection

## Quick Facts
- arXiv ID: 2412.00020
- Source URL: https://arxiv.org/abs/2412.00020
- Reference count: 40
- Primary result: PMP achieves state-of-the-art AUC scores of 93.97% (Yelp), 97.57% (Amazon), 97.10% (T-Finance), and 99.62% (T-Social) for fraud detection

## Executive Summary
This paper introduces Partitioning Message Passing (PMP), a graph neural network approach specifically designed for fraud detection in graphs with label imbalance and heterophily-homophily mixture. The key innovation is partitioning the message passing process by node labels, using distinct node-specific aggregation functions for fraud, benign, and unlabeled neighbors. PMP adaptively modulates the influence from different classes through root-specific weight matrices and an adaptive combination for unlabeled neighbors. Theoretical analysis shows PMP operates as a node-specific spectral graph filter. Experiments on four datasets (Yelp, Amazon, T-Finance, T-Social) demonstrate PMP's effectiveness, achieving state-of-the-art results with AUC scores of 93.97% (Yelp), 97.57% (Amazon), 97.10% (T-Finance), and 99.62% (T-Social) under supervised learning, outperforming 11 baseline methods.

## Method Summary
PMP modifies the standard GNN message passing framework by partitioning neighbor aggregation based on node labels. For each node, distinct aggregation functions process fraud, benign, and unlabeled neighbors separately, with node-specific weight matrices generated by weight generators. Unlabeled neighbors are handled through an adaptive combination of fraud and benign weights. The method theoretically connects to node-specific spectral graph filters, enabling each node to adaptively adjust information from different neighbor classes. The approach addresses label imbalance by preventing gradient domination from majority class nodes and handles heterophily-homophily mixture by allowing flexible influence calibration per node.

## Key Results
- PMP achieves 93.97% AUC on Yelp dataset, outperforming 11 baseline methods
- PMP achieves 97.57% AUC on Amazon dataset, setting new state-of-the-art
- PMP achieves 97.10% AUC on T-Finance dataset and 99.62% AUC on T-Social dataset
- Experimental results demonstrate superior performance across four datasets with different characteristics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partitioning message passing by node labels prevents gradient domination by the majority class.
- Mechanism: By using distinct aggregation functions for fraud, benign, and unlabeled neighbors, each class of neighbors contributes independently to the center node's representation. This breaks the shared weight matrix assumption where all neighbors influence the gradient equally.
- Core assumption: Fraud and benign neighbors have fundamentally different feature distributions and should be processed separately during message passing.
- Evidence anchors:
  - [abstract] "By this means, the center node can adaptively adjust the information aggregated from its heterophilic and homophilic neighbors, thus avoiding the model gradient being dominated by benign nodes which occupy the majority of the population."
  - [section 2.2] "Such an imbalance in influence can skew the message passing process, causing it to be insufficiently responsive to the nuances of the minority class nodes."
  - [corpus] Weak - related papers discuss dual-channel approaches but don't directly confirm the gradient domination claim.

### Mechanism 2
- Claim: Root-specific weight matrices allow each node to adaptively adjust influence from different neighbor classes based on its local context.
- Mechanism: Weight generators produce node-specific aggregation weight matrices as functions of the center node's representation. This enables each node to calibrate how much information it receives from fraud versus benign neighbors.
- Core assumption: Different nodes in different graph positions need different balances of fraud/benign information to make accurate predictions.
- Evidence anchors:
  - [abstract] "By this means, each node can adaptively adjust the influence from different classes of neighbors without additional parameters."
  - [section 3] "To achieve it, we treat the parameter matrices of aggregation functions as the output of weight generators with respect to the center node."
  - [corpus] Weak - no direct corpus evidence for this specific adaptive mechanism.

### Mechanism 3
- Claim: Adaptive combination of unlabeled neighbors as weighted fusion of fraud and benign weights prevents forcing definite labels on uncertain connections.
- Mechanism: Unlabeled neighbor weight matrix is defined as W_un = α_i * W_fr + (1 - α_i) * W_be, where α_i is a node-specific scalar function. This allows smooth interpolation between fraud and benign treatment.
- Core assumption: Unlabeled neighbors have mixed characteristics and should not be forced into a single category.
- Evidence anchors:
  - [section 3] "For unlabeled neighbors, we face the challenge of determining an appropriate transformation that acknowledges the uncertainty of these connections."
  - [section 3] "Instead, PMP aims to treat unlabeled neighbors in a way that reflects their uncertain and mixed nature."
  - [corpus] Weak - related papers don't discuss this specific treatment of unlabeled neighbors.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: PMP is a modification of the standard GNN message passing framework, so understanding how GNNs aggregate neighbor information is essential.
  - Quick check question: What is the standard form of message passing in GNNs, and how does it differ from PMP's approach?

- Concept: Label imbalance and heterophily in graphs
  - Why needed here: The paper specifically addresses these two challenges in fraud detection, so understanding their impact on GNN performance is crucial.
  - Quick check question: How do label imbalance and heterophily affect the gradients during GNN training?

- Concept: Spectral graph theory and graph filters
  - Why needed here: The theoretical analysis connects PMP to spectral graph filters, showing how it operates as a node-specific spectral convolution.
  - Quick check question: What is the relationship between spatial message passing and spectral graph filters in GNNs?

## Architecture Onboarding

- Component map:
  - Input: Fraud graph G = (V, {Er}R_r=1, X, Y)
  - Neighbor aggregation: Three separate functions f_fr, f_be, f_un for different neighbor classes
  - Weight generation: Two weight generators Ψ_fr and Ψ_be that produce node-specific weight matrices
  - Adaptive combination: Single-layer MLP Φ that produces α_i for unlabeled neighbor handling
  - Output: Sigmoid applied to final representations for binary classification

- Critical path:
  1. For each node, generate node-specific weight matrices using Ψ_fr and Ψ_be
  2. Aggregate fraud neighbors using f_fr with W_fr,i
  3. Aggregate benign neighbors using f_be with W_be,i
  4. Aggregate unlabeled neighbors using adaptive combination of W_fr,i and W_be,i
  5. Combine all aggregated messages with self-representation
  6. Apply final MLP and sigmoid for classification

- Design tradeoffs:
  - Partitioning vs. unified aggregation: Better class-specific learning vs. increased model complexity
  - Node-specific weights vs. shared weights: More adaptive vs. more parameters
  - Adaptive unlabeled handling vs. separate treatment: Better uncertainty modeling vs. simpler implementation

- Failure signatures:
  - Poor performance on datasets with balanced labels or strong homophily
  - Overfitting on small datasets due to increased model complexity
  - Sensitivity to hyperparameter tuning for weight generators and adaptive combination

- First 3 experiments:
  1. Compare PMP with standard GraphSAGE on a synthetic imbalanced graph to verify gradient domination is addressed
  2. Test PMP with different numbers of layers to find optimal depth before oversmoothing
  3. Evaluate PMP with and without root-specific weights to measure contribution of adaptive node-specific processing

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PMP perform on graphs with more than two classes, and what modifications would be needed?
- Basis in paper: [inferred] The paper focuses on binary fraud detection (fraud vs. benign), but mentions the adaptive combination of unlabeled neighbors as a weighted fusion of labeled data.
- Why unresolved: The paper doesn't explore scenarios with multiple fraud categories or more complex node classifications.
- What evidence would resolve it: Experiments on multi-class fraud detection datasets, showing how PMP partitions message passing across multiple classes and the impact on performance.

### Open Question 2
- Question: How does PMP scale to graphs with billions of nodes and edges, and what are the computational bottlenecks?
- Basis in paper: [explicit] The paper mentions that PMP achieves the optimal trade-off between inference speed and effectiveness, but only tests on datasets with up to ~1M nodes and ~73M edges.
- Why unresolved: The paper doesn't explore performance on graphs at the scale of real-world industrial applications (billions of nodes).
- What evidence would resolve it: Experiments on extremely large-scale graphs, analyzing time and memory complexity, and identifying bottlenecks in the root-specific weight matrix generation.

### Open Question 3
- Question: How robust is PMP to noisy or adversarial label injections in the training set?
- Basis in paper: [inferred] The paper focuses on label imbalance and heterophily-homophily mixture, but doesn't address the robustness of PMP to mislabeled data.
- Why unresolved: Fraud detection datasets may contain noisy or adversarial labels, and the paper doesn't explore how PMP handles such scenarios.
- What evidence would resolve it: Experiments with injected label noise, comparing PMP's performance to baselines, and analyzing the impact on influence distributions and gradient updates.

## Limitations

- Performance improvements rely heavily on proprietary datasets that cannot be independently verified
- Claims about specific mechanisms (gradient domination prevention, adaptive node-specific weighting) lack direct empirical validation through ablation studies
- Theoretical connection to spectral graph filters is mathematically sound but practical significance is unclear

## Confidence

- **High Confidence:** The core methodology of partitioning message passing by node labels is clearly specified and implementable. The experimental methodology (metrics, datasets, training procedures) is well-documented.
- **Medium Confidence:** The performance improvements over baseline methods are demonstrated, but the extent of improvement on proprietary datasets cannot be independently verified. The theoretical analysis connecting PMP to spectral graph filters is mathematically valid but its practical significance is unclear.
- **Low Confidence:** Claims about specific mechanisms (gradient domination prevention, adaptive node-specific weighting effectiveness) lack direct empirical support through ablation studies or controlled experiments.

## Next Checks

1. **Ablation Study on Partitioning:** Implement PMP without partitioning (using shared weights for all neighbors) and compare performance to verify that gradient domination is actually addressed.

2. **Reproduce on Open Datasets:** Implement PMP and run experiments on standard open graph datasets (e.g., Cora, Citeseer, Pubmed) with artificial label imbalance to verify performance claims independently.

3. **Weight Generator Analysis:** Analyze the learned weight matrices from Ψ_fr and Ψ_be to verify that they are indeed node-specific and that different nodes learn different weights, supporting the adaptive node-specific weighting claim.