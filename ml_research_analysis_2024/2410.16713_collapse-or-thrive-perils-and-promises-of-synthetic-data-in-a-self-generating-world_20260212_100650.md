---
ver: rpa2
title: Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating
  World
arxiv_id: '2410.16713'
source_url: https://arxiv.org/abs/2410.16713
tags:
- data
- synthetic
- iteration
- collapse
- real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines the impact of synthetic data on generative
  models, specifically investigating whether "model collapse" occurs when models are
  trained on their own outputs. The research addresses the debate on whether future
  AI systems will suffer from degraded performance due to training on recursive synthetic
  data.
---

# Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World

## Quick Facts
- **arXiv ID:** 2410.16713
- **Source URL:** https://arxiv.org/abs/2410.16713
- **Reference count:** 40
- **Key outcome:** Model collapse is avoidable through careful data management, with synthetic data improving performance when real data are scarce but degrading it when abundant.

## Executive Summary
This study investigates whether "model collapse" occurs when generative models are trained on their own synthetic outputs. Through experiments across three task settings (multivariate Gaussian estimation, kernel density estimation, and language model fine-tuning) and three training workflows (replacing all data with synthetic, accumulating synthetic alongside real data, and fixed-compute budget approaches), the research finds that model collapse is avoidable. The replace workflow induces collapse across all settings, while accumulate and fixed-compute approaches prevent collapse, though with varying performance. Synthetic data can improve test loss when real data are scarce but degrades performance when real data are abundant, suggesting careful data management is crucial for sustainable AI development.

## Method Summary
The study tests three training workflows across three generative model task settings: replacing all data with synthetic data, accumulating synthetic data alongside real data, and a fixed-compute budget approach where data accumulate but training samples are constrained. For each workflow, models are iteratively trained on either real data, synthetic data, or combinations thereof, with performance evaluated on held-out real data. The experiments examine multivariate Gaussian estimation, kernel density estimation, and language model fine-tuning (using Gemma2 on the HelpSteer2 dataset), measuring mean squared error, negative log likelihood, and cross-entropy respectively across multiple iterations.

## Key Results
- The replace workflow induces model collapse across all task settings, with rapidly diverging test loss
- The accumulate workflow prevents model collapse by maintaining non-zero exposure to real data, even as real data proportion approaches zero
- Synthetic data can improve test loss when real data are scarce but degrades performance when real data are abundant
- The fixed-compute budget approach shows gradual performance degradation rather than explosive collapse, with eventual plateauing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model collapse is avoided when synthetic data accumulates alongside real data, even as the proportion of real data asymptotically approaches zero.
- Mechanism: The accumulating data maintains the support and structure of the original data distribution. By preserving a non-zero fraction of real data across all iterations, the generative model retains access to the true data manifold, preventing drift toward degenerate solutions.
- Core assumption: Real data are never deleted and always contribute to the training set in each iteration.
- Evidence anchors:
  - [abstract]: "we consider the training-workflow of accumulating synthetic data alongside real data and training on all data combined and confirming that, although the proportion of real data eventually becomes zero, models remain stable and their test losses do not diverge under this training-workflow"
  - [section]: "accumulating data across model-fitting iterations prevents model collapse (Fig. 1 Right). More specifically, we find that if data are deleted, the squared error between the fit mean ˆµ(n)Replace and the initial mean µ(0) diverges (Fig. 1, Middle Left), and the fit covariance ˆΣ(n)Replace relative to the initial covariance Σ(0) collapses to 0 (Fig. 1, Bottom Left). In contrast, if data accumulate, the squared error between the fit mean and the initial mean plateaus quickly (Fig. 1, Middle Right), as does the fit covariance relative to the initial covariance (Fig. 1, Bottom Right)."
  - [corpus]: Found 25 related papers; average neighbor FMR=0.442. Related titles include theoretical and empirical work on model collapse, but no specific experimental results matching this mechanism's claims.
- Break condition: If real data are deleted or replaced at any iteration, the mechanism fails and model collapse occurs.

### Mechanism 2
- Claim: Synthetic data can improve test loss when real data are scarce, but degrades performance when real data are abundant.
- Mechanism: In low-data regimes, synthetic data fills distributional gaps and regularizes the model by increasing effective sample size. In high-data regimes, synthetic data introduces noise and bias that overwhelms the signal from abundant real data, increasing generalization error.
- Core assumption: The quality of synthetic data is sufficient to regularize in low-data regimes but insufficient to replace real data in high-data regimes.
- Evidence anchors:
  - [abstract]: "the study also finds that synthetic data can improve test loss when real data are scarce, but degrades performance when real data are abundant"
  - [section]: "when real data are scarce, supplementing the training set by adding small amounts of synthetic data can reduce test loss, whereas when real data are ample, any synthetic data increases the test loss calculated on real data"
  - [corpus]: Weak evidence - related papers discuss synthetic data quality but not this specific relationship between real data abundance and synthetic data utility.
- Break condition: If synthetic data quality is uniformly poor or uniformly excellent, this relationship may not hold.

### Mechanism 3
- Claim: Model collapse can be mitigated by subsampling accumulated data under a fixed compute budget, though with slower performance degradation than complete replacement.
- Mechanism: By maintaining a constant training set size while accumulating all data, the model periodically refreshes its exposure to diverse synthetic samples without the catastrophic forgetting induced by complete replacement. This creates a middle ground where performance plateaus rather than diverges.
- Core assumption: Compute constraints prevent training on all accumulated data, necessitating subsampling.
- Evidence anchors:
  - [abstract]: "we consider a training-workflow where real and synthetic data accumulate together but successive generations of pretraining are constrained to use fixed-size data subsets each generation. In this workflow, we observe slow and gradual rather than explosive degradation of test loss performance across generations"
  - [section]: "In accumulate-subsample, real and synthetic data accumulate but are then subsampled so that each model is trained on a constant number of data. Accumulate-subsample's test loss on real data deteriorates more quickly than accumulate's loss but more slowly than replace's loss, and frequently converges, albeit to a higher plateau than accumulate"
  - [corpus]: No direct evidence in corpus - this appears to be a novel experimental setup not well-represented in related work.
- Break condition: If the subsampling strategy becomes too aggressive (sampling too few data points), model collapse may occur.

## Foundational Learning

- Concept: Iterative generative modeling and model-data feedback loops
  - Why needed here: The paper's core experiments involve repeatedly training models on their own outputs, requiring understanding of how this recursive process affects model performance
  - Quick check question: What happens to the distribution of generated data as a model is trained repeatedly on its own outputs?

- Concept: Multivariate Gaussian modeling and kernel density estimation
  - Why needed here: The paper uses these as simplified testbeds to study model collapse before examining more complex language model scenarios
  - Quick check question: How does the variance of a Gaussian distribution change when repeatedly fitting and sampling from it?

- Concept: Supervised fine-tuning and pretraining paradigms
  - Why needed here: The paper extends its analysis from simple statistical models to practical language model scenarios
  - Quick check question: What distinguishes supervised fine-tuning from pretraining in language model workflows?

## Architecture Onboarding

- Component map: Real data → Model training → Synthetic data generation → (Repeat with one of three workflows)
- Critical path:
  1. Generate initial real dataset
  2. Train initial generative model
  3. Generate synthetic data from current model
  4. Combine data according to workflow (replace, accumulate, or subsample)
  5. Train next-generation model
  6. Evaluate on held-out real data
  7. Repeat for multiple iterations

- Design tradeoffs:
  - Replace workflow: Simple implementation but induces model collapse
  - Accumulate workflow: Prevents collapse but requires increasing computational resources
  - Accumulate-Subsample workflow: Balances resource constraints with collapse prevention, but may sacrifice optimal performance

- Failure signatures:
  - Replace workflow: Rapidly diverging test loss, collapsing covariance estimates, drifting mean estimates
  - Accumulate workflow: Stable test loss but increasing computational requirements
  - Accumulate-Subsample workflow: Gradual performance degradation but eventual plateauing

- First 3 experiments:
  1. Implement multivariate Gaussian modeling with replace workflow to reproduce model collapse
  2. Implement accumulate workflow for the same Gaussian setup to verify collapse prevention
  3. Implement accumulate-subsample workflow to observe intermediate behavior between replace and accumulate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions does synthetic data improve test loss during pretraining?
- Basis in paper: Explicit - "identifying under what conditions synthetic data can lower test loss during pretraining would be invaluable to industry practitioners"
- Why unresolved: The paper shows that synthetic data can improve performance when real data are scarce, but doesn't establish general conditions or quantify when this occurs
- What evidence would resolve it: Systematic studies varying the quality, quantity, and type of synthetic data across different domains and model architectures

### Open Question 2
- Question: How should bandwidth be optimally adjusted in KDE to prevent model collapse while accumulating data?
- Basis in paper: Explicit - "model collapse, while inevitable with a fixed bandwidth, can be avoided in all cases by shrinking the bandwidth at a sufficiently fast rate"
- Why unresolved: The paper provides theoretical conditions but doesn't empirically validate optimal bandwidth adjustment strategies
- What evidence would resolve it: Empirical studies testing various bandwidth adjustment schedules and their impact on model performance

### Open Question 3
- Question: What is the optimal balance between real and synthetic data for SFT when real data are scarce?
- Basis in paper: Explicit - "when real data are scarce, supplementing with synthetic data can improve test loss" but doesn't specify optimal ratios
- Why unresolved: The paper finds a small amount of synthetic data helps but doesn't establish precise optimal proportions or scaling laws
- What evidence would resolve it: Systematic experiments varying the ratio of real to synthetic data across different scarcity levels and model types

## Limitations
- Findings rely on specific synthetic data quality assumptions that may not generalize across model architectures
- The accumulate-subsample workflow shows intermediate performance that warrants deeper investigation, particularly regarding optimal subsampling strategies
- Language model results are based on a single fine-tuning dataset (HelpSteer2), limiting generalizability to other domains and tasks

## Confidence
- High confidence: The replace workflow consistently induces model collapse across all three task settings, supported by clear empirical evidence
- Medium confidence: The accumulate workflow prevents collapse, though the mechanism relies on maintaining non-zero real data exposure
- Medium confidence: The fixed-compute budget approach shows slower degradation, but optimal subsampling strategies remain unclear

## Next Checks
1. Test the accumulate workflow with varying proportions of real data to determine the minimum threshold needed to prevent collapse
2. Implement systematic hyperparameter sweeps for the accumulate-subsample workflow to identify optimal subsampling strategies
3. Replicate findings using different language model architectures (beyond Gemma2) and fine-tuning datasets to assess robustness