---
ver: rpa2
title: 'Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better
  Samples'
arxiv_id: '2411.08954'
source_url: https://arxiv.org/abs/2411.08954
tags:
- diffusion
- direct
- learning
- quality
- solving
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between ODE solving accuracy
  and sample quality in consistency models (CMs), a recent approach for distilling
  diffusion models into few-step generators. The authors introduce Direct CMs, which
  directly minimize the error against the probability flow ODE solver, as opposed
  to the original CM objective that provides only weak supervision.
---

# Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples

## Quick Facts
- arXiv ID: 2411.08954
- Source URL: https://arxiv.org/abs/2411.08954
- Reference count: 40
- Primary result: Direct CMs significantly outperform CMs in ODE solving error but generate lower quality images across multiple metrics

## Executive Summary
This paper investigates the relationship between ODE solving accuracy and sample quality in consistency models (CMs), a recent approach for distilling diffusion models into few-step generators. The authors introduce Direct CMs, which directly minimize the error against the probability flow ODE solver, as opposed to the original CM objective that provides only weak supervision. Surprisingly, while Direct CMs achieve significantly better ODE solving error, CMs generate noticeably higher quality images across all image-based metrics including FID, FD-DINO, CLIP score, and aesthetic score. This finding challenges the implicit assumption that better ODE solving necessarily implies better sample quality and calls for further investigation into the confounding factors contributing to the effectiveness of CMs.

## Method Summary
The authors conduct controlled experiments using SDXL as the teacher model, comparing CMs and Direct CMs in terms of ODE solving error and image quality metrics. Direct CMs are trained to directly minimize the error against the probability flow ODE solver, while standard CMs use a denoising-based objective that provides only weak supervision of ODE accuracy. The experiments evaluate single-step generation performance across multiple image quality metrics including FID, FD-DINO, CLIP score, and aesthetic score, revealing a surprising disconnect between ODE solving accuracy and sample quality.

## Key Results
- Direct CMs achieve significantly lower ODE solving error compared to standard CMs
- Standard CMs generate higher quality images than Direct CMs across all metrics: FID (95.3 vs 166.0), FD-DINO (747.7 vs 1148), CLIP score (0.21 vs 0.19), and aesthetic score (5.5 vs 5.0)
- The results challenge the assumption that better ODE solving accuracy implies better sample quality
- This paradox suggests confounding factors in CM training dynamics that warrant further investigation

## Why This Works (Mechanism)
The paper identifies a fundamental inconsistency between ODE solving accuracy and sample quality in consistency models, but does not provide a definitive mechanism for why this occurs. The authors suggest that the denoising-based objective used in standard CMs may provide implicit regularization or training benefits that are not captured by direct ODE error minimization. The role of noise in the learning process and its interaction with the probability flow ODE appears to be a critical factor that requires further investigation to fully understand this counterintuitive phenomenon.

## Foundational Learning

**Probability Flow ODEs**: Mathematical formulation describing the continuous-time evolution of diffusion processes. Why needed: Forms the theoretical foundation for understanding how consistency models operate. Quick check: Verify understanding of the relationship between diffusion processes and their associated ODEs.

**Consistency Models**: Generative models trained to satisfy consistency conditions at various noise levels. Why needed: Core architecture being studied in the paper. Quick check: Confirm understanding of how CMs differ from standard diffusion models.

**ODE Solvers**: Numerical methods for solving ordinary differential equations. Why needed: Essential for implementing and evaluating the probability flow ODEs in practice. Quick check: Ensure familiarity with common ODE solvers and their error characteristics.

**Image Quality Metrics**: Quantitative measures like FID, CLIP score, and aesthetic scoring. Why needed: Tools for evaluating the perceptual quality of generated samples. Quick check: Verify understanding of what each metric measures and their relative importance.

## Architecture Onboarding

**Component Map**: Diffusion model (teacher) -> Consistency Model (student) -> ODE Solver -> Image Quality Metrics

**Critical Path**: Teacher model generates noisy data points -> CM learns consistency conditions -> ODE solver evaluates accuracy -> Metrics assess sample quality

**Design Tradeoffs**: Direct minimization of ODE error vs. denoising-based objectives, single-step vs. multi-step generation, training stability vs. accuracy

**Failure Signatures**: High ODE error with good sample quality, or vice versa; training instability when directly optimizing ODE error

**First Experiments**: 1) Compare ODE error and FID scores across different training epochs, 2) Vary noise levels in training data to observe effects on ODE accuracy and sample quality, 3) Test different ODE solvers to see if the inconsistency persists

## Open Questions the Paper Calls Out
The paper identifies the need for further investigation into the confounding factors contributing to the effectiveness of CMs and to clarify why better ODE solving leads to worse sample quality. The role of noise in the learning process and the potential implicit regularization provided by the denoising-based objective are highlighted as areas requiring deeper understanding.

## Limitations
- Experiments conducted with only a single teacher model (SDXL), limiting generalizability
- The exact mechanisms behind the inconsistency between ODE accuracy and sample quality remain unclear
- Potential confounding factors including training dynamics and objective formulations were not fully explored

## Confidence
- Core claim about inconsistency between ODE accuracy and sample quality: High confidence
- Explanation for the underlying mechanisms: Medium confidence
- Direct CM approach as a research direction: Medium confidence

## Next Checks
1. Replicate experiments across multiple diffusion model architectures and datasets to verify generalizability
2. Conduct ablation studies varying noise levels and training schedules to understand the role of noise
3. Investigate whether the inconsistency persists with different ODE solvers or alternative training objectives