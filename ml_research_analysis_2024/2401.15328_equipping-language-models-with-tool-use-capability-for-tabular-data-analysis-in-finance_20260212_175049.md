---
ver: rpa2
title: Equipping Language Models with Tool Use Capability for Tabular Data Analysis
  in Finance
arxiv_id: '2401.15328'
source_url: https://arxiv.org/abs/2401.15328
tags:
- data
- language
- tool
- task
- raven
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work augments language models with external tools for financial
  domain tasks, training a LLaMA-2 13B model to act as a task router and solver. The
  approach improves exact match accuracy by 35.2% over the base model and 5.06% over
  SFT-only baselines on financial QA benchmarks, outperforming GPT-3.5.
---

# Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance

## Quick Facts
- arXiv ID: 2401.15328
- Source URL: https://arxiv.org/abs/2401.15328
- Reference count: 22
- Fine-tuned LLaMA-2 13B with tool use capability improves exact match accuracy by 35.2% over base model on financial QA benchmarks

## Executive Summary
This work augments language models with external tools for financial domain tasks, training a LLaMA-2 13B model to act as a task router and solver. The approach improves exact match accuracy by 35.2% over the base model and 5.06% over SFT-only baselines on financial QA benchmarks, outperforming GPT-3.5. Key tools include a calculator for arithmetic expressions and a lightweight SQL engine for structured data queries.

## Method Summary
The method fine-tunes a LLaMA-2 13B Chat model using Parameter-Efficient Fine-Tuning (LoRA) to act as both a task router and solver for financial domain tasks. The model is trained on mixed-domain datasets with instruction templates that guide tool selection and execution. External tools (calculator and SQL engine) are integrated to handle arithmetic computations and structured data queries, respectively. The fine-tuning process uses a 0.2% parameter change with LoRA, employing AdamW optimizer and a learning rate of 3e-4.

## Key Results
- Exact match accuracy improved by 35.2% over base model on financial QA benchmarks
- Achieved 5.06% improvement over SFT-only baselines
- Outperformed GPT-3.5 on financial question answering tasks

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning with mixed-task templates improves model's ability to dynamically route to the right tool. Training on instruction-augmented data forces the model to learn context-dependent selection between internal reasoning and external tool use. Core assumption: The model can learn to distinguish between problems that require numerical computation, structured data querying, or direct inference.

### Mechanism 2
Offloading arithmetic computation to a calculator reduces error propagation in multi-step reasoning. Instead of generating arithmetic expressions as final answers, the model produces intermediate derivations that are evaluated by a deterministic calculator. Core assumption: The model can reliably generate well-formed arithmetic expressions that correspond to the intended computation.

### Mechanism 3
SQL execution via lightweight engine enables accurate querying of structured data. The model generates SQL scripts that are executed on the provided table data, avoiding the need for the model to parse and reason over tabular formats directly. Core assumption: The model can translate natural language questions into correct SQL syntax that matches the provided schema.

## Foundational Learning

- Concept: Supervised fine-tuning on mixed-domain question answering datasets
  - Why needed here: To teach the model how to handle different types of questions (arithmetic, classification, SQL, extraction) within a unified framework
  - Quick check question: Can the model switch between tool use and direct answering based on question type?

- Concept: Parameter-efficient fine-tuning (LoRA)
  - Why needed here: To enable fine-tuning on commodity hardware while minimizing memory usage and preserving pre-trained capabilities
  - Quick check question: Does the model maintain base model performance on general tasks while improving on specialized benchmarks?

- Concept: Tool-augmented inference flow
  - Why needed here: To dynamically select and execute appropriate tools during inference based on the question and available context
  - Quick check question: Does the task router correctly identify when to use a tool versus direct answering?

## Architecture Onboarding

- Component map: Base LLAMA-2 13B CHAT model → Task Router (template selection) → Task Solver (template execution) → External tools (calculator, SQL engine) → Final answer
- Critical path: Question → Task Router → Template selection → Task Solver → Tool execution (if needed) → Answer
- Design tradeoffs: Using LoRA (0.2% parameter change) balances fine-tuning efficiency with model performance; mixed-task training simplifies deployment but may reduce specialization
- Failure signatures: Incorrect tool routing, malformed arithmetic expressions, invalid SQL syntax, fallback mechanism activation
- First 3 experiments:
  1. Verify the task router correctly classifies question types on a held-out validation set
  2. Test the calculator tool with known arithmetic expressions to ensure correct evaluation
  3. Execute sample SQL scripts on structured data to validate the SQL engine integration

## Open Questions the Paper Calls Out

### Open Question 1
What is the impact of using larger language models (e.g., 70 billion parameters) on the performance of tool-augmented models in financial domain tasks? Basis: Paper mentions hardware constraints limited experiments to 13B model and hypothesizes larger models could perform better. Unresolved: Paper lacked computational resources to test larger models. Evidence needed: Experiments with larger models on same financial benchmarks.

### Open Question 2
How does the performance of tool-augmented models degrade with increasing complexity of financial questions (e.g., more numerical values to extract)? Basis: Paper discusses RAVEN's performance degradation with numerical values in TAT-QA dataset. Unresolved: Paper provides some analysis but doesn't fully explore relationship across different financial tasks. Evidence needed: Comprehensive analysis across various financial datasets with different complexity levels.

### Open Question 3
What is the optimal context length for financial domain tasks when using tool-augmented models? Basis: Paper mentions 1,204 token limit due to hardware constraints and potential benefits of longer contexts. Unresolved: Paper didn't explore longer contexts that could enable diverse prompts and alternative data representations. Evidence needed: Experiments with different context lengths evaluating tool-augmented model performance on financial tasks.

## Limitations

- Limited tool set only includes calculator and SQL engine, missing capabilities like data visualization and real-time financial data access
- Template-based task routing may not generalize well to unseen question types or edge cases
- Synthetic evaluation environment using public datasets rather than real-world financial analysis scenarios

## Confidence

- **High Confidence**: Core claim that LoRA can successfully add tool-use capabilities to LLaMA-2 13B is well-supported by methodology and results
- **Medium Confidence**: Mechanism claims about task routing and tool offloading are plausible but lack detailed analysis of routing accuracy or tool execution success rates
- **Low Confidence**: Claims about practical financial domain utility not fully validated as benchmarks don't represent real-world financial analysis complexity

## Next Checks

1. Implement comprehensive validation suite to measure task router's accuracy in classifying question types across diverse financial queries, including edge cases and ambiguous prompts

2. Deploy system on actual financial analyst workflows using proprietary datasets or simulated multi-step financial analysis tasks that require tool coordination

3. Systematically evaluate computational overhead and integration complexity of adding additional financial tools (time-series analysis, financial ratio calculators, market data APIs) to assess framework scalability