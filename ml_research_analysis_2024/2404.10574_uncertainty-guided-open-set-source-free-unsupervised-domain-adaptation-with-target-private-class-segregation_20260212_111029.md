---
ver: rpa2
title: Uncertainty-guided Open-Set Source-Free Unsupervised Domain Adaptation with
  Target-private Class Segregation
arxiv_id: '2404.10574'
source_url: https://arxiv.org/abs/2404.10574
tags:
- classes
- samples
- domain
- adaptation
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach for source-free open-set unsupervised
  domain adaptation (SF-OSDA) that addresses the challenge of adapting a model to
  a target domain containing novel classes not present in the source domain. The key
  idea is to leverage the granularity of target-private classes by segregating their
  samples into multiple unknown classes, rather than aggregating them into a single
  "unknown" class as done in previous works.
---

# Uncertainty-guided Open-Set Source-Free Unsupervised Domain Adaptation with Target-private Class Segregation

## Quick Facts
- arXiv ID: 2404.10574
- Source URL: https://arxiv.org/abs/2404.10574
- Reference count: 40
- Primary result: Proposes NL-InfoNCELoss and clustering-based initialization for improved SF-OSDA performance

## Executive Summary
This paper addresses the challenge of source-free open-set unsupervised domain adaptation (SF-OSDA), where a model trained on a labeled source domain must adapt to an unlabeled target domain containing novel classes. The key innovation is a clustering-based initialization strategy that segregates target-private samples into multiple unknown classes rather than aggregating them into a single "unknown" class. This is combined with an uncertainty-guided sample selection mechanism and a novel contrastive loss (NL-InfoNCELoss) that integrates negative learning principles to enhance robustness to noisy pseudo-labels. Extensive experiments on Office31 and Office-Home datasets demonstrate state-of-the-art performance, with the method showing particular strength in discovering the underlying semantics of novel classes.

## Method Summary
The method consists of three main components: (1) Clustering-based initialization that uses K-means to assign initial pseudo-labels to target samples, with clusters not matched to shared class prototypes treated as novel private class prototypes; (2) Uncertainty-guided sample selection that refines pseudo-labels using neighbors consensus and class separation metrics, with samples selected via Bernoulli sampling based on combined uncertainty probabilities; (3) NL-InfoNCELoss, a novel contrastive loss that modifies the standard InfoNCE by excluding query-negative pairs that have shared pseudo-labels in the past τ epochs, thereby incorporating negative learning principles to handle noisy pseudo-labels.

## Key Results
- Establishes new state-of-the-art performance on Office31 and Office-Home datasets for SF-OSDA
- Achieves superior performance on both known (shared) classes and unknown (private) classes compared to existing methods
- Demonstrates the ability to learn underlying semantics of novel classes through effective segregation into multiple unknown classes
- NL-InfoNCELoss shows improved robustness to noisy pseudo-labels compared to standard contrastive losses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Clustering-based initialization segregates target-private samples into multiple unknown classes rather than aggregating them into a single "unknown" class.
- Mechanism: Unsupervised clustering is performed on target features extracted from the source model. Clusters not matched to shared class prototypes are treated as novel private class prototypes, initializing the classifier's unknown class weights.
- Core assumption: Target features exhibit low intra-class variability for both shared and private classes, allowing clustering to roughly separate semantically similar samples.
- Evidence anchors:
  - [abstract] "our method progressively improves the segregation of target-private samples by refining their pseudo-labels with the guide of an uncertainty-based sample selection module."
  - [section] "To alleviate this problem, we propose a clustering-based solution to discover suitable prototypes for the private classes CP, and thus initialize WP in a more convenient way."
  - [corpus] Weak - related papers discuss clustering but not specifically for segregating private classes into multiple clusters.
- Break condition: If target-private classes have high intra-class variability or overlap significantly with shared classes in feature space, clustering will fail to separate them meaningfully.

### Mechanism 2
- Claim: Uncertainty-guided sample selection improves adaptation robustness by filtering noisy pseudo-labels.
- Mechanism: Two uncertainty measures are computed: neighbors consensus (entropy of refined pseudo-labels) and class separation (distance ratio to closest class prototypes). Samples are selected via Bernoulli sampling based on combined uncertainty probabilities.
- Core assumption: Samples with low uncertainty in both measures are more likely to have correct pseudo-labels and should be used for adaptation.
- Evidence anchors:
  - [abstract] "Starting from an initial clustering-based assignment, our method progressively improves the segregation of target-private samples by refining their pseudo-labels with the guide of an uncertainty-based sample selection module."
  - [section] "To mitigate this, we perform a sample selection, in order to pick only samples with low uncertainty: these are selected stochastically via Bernoulli sampling, based on the uncertainty of their pseudo-label, estimated in a twofold manner."
  - [corpus] Weak - related papers discuss uncertainty estimation but not specifically for open-set scenarios with private classes.
- Break condition: If uncertainty estimation fails to distinguish between shared and private classes, sample selection will be ineffective and noisy labels will corrupt training.

### Mechanism 3
- Claim: NL-InfoNCELoss increases robustness to noisy pseudo-labels in contrastive learning by incorporating negative learning principles.
- Mechanism: The standard InfoNCE loss is modified to only push apart query and randomly selected negative samples that have never shared pseudo-labels in the past τ epochs, rather than all negative samples.
- Core assumption: Negative learning, which trains models to output low confidence for complementary labels, helps mitigate the impact of false negative pairs in contrastive learning when pseudo-labels are noisy.
- Evidence anchors:
  - [abstract] "Additionally, we propose a novel contrastive loss, named NL-InfoNCELoss, that, integrating negative learning into self-supervised contrastive learning, enhances the model robustness to noisy pseudo-labels."
  - [section] "Inspired by [54] and differently from our previous work [10], we propose a novel contrastive loss, called NL-InfoNCELoss, that inserts the principle of negative learning in the standard InfoNCELoss."
  - [corpus] Weak - related papers discuss contrastive learning but not specifically with negative learning integration for noisy labels.
- Break condition: If the noise level is too high or the history queue is insufficient, the exclusion strategy may fail to remove true negative pairs, degrading contrastive learning performance.

## Foundational Learning

- Concept: Domain adaptation fundamentals (covariate shift, label shift)
  - Why needed here: Understanding the distinction between shared and private classes, and how distribution shifts affect model performance
  - Quick check question: What is the difference between covariate shift and label shift in domain adaptation?

- Concept: Self-supervised contrastive learning (InfoNCE, MoCo)
  - Why needed here: The NL-InfoNCELoss builds on standard contrastive learning frameworks to handle noisy pseudo-labels
  - Quick check question: How does MoCo maintain a queue of negative samples and why is this important for contrastive learning?

- Concept: Uncertainty estimation and its applications in machine learning
  - Why needed here: The method relies on two uncertainty measures to select reliable samples for training
  - Quick check question: What are common methods for estimating uncertainty in deep learning models and how do they differ?

## Architecture Onboarding

- Component map:
  Source model (feature extractor + classifier) -> Clustering module (K-means on target features) -> Pseudo-label refinement (nearest neighbor voting) -> Uncertainty estimation (neighbors consensus + class separation) -> Sample selection (Bernoulli sampling) -> Adaptation (classification + contrastive losses)

- Critical path: Feature extraction → Clustering initialization → Pseudo-label refinement → Uncertainty estimation → Sample selection → Adaptation (classification + contrastive losses)

- Design tradeoffs:
  - Number of target-private classes: Setting |bCP| too low may merge distinct private classes, while too high may over-segment and reduce shared class accuracy
  - Uncertainty estimation functions: Linear vs exponential functions for converting uncertainty to selection probabilities
  - Contrastive learning parameters: Queue size, temperature, and history window τ for temporal exclusion

- Failure signatures:
  - Poor clustering initialization: Shared and private classes not well separated in feature space
  - Uncertainty estimation failure: High uncertainty samples consistently selected or low uncertainty samples consistently rejected
  - Contrastive learning instability: Feature space not properly regularized, samples from same class not well clustered

- First 3 experiments:
  1. Validate clustering initialization: Check if clusters align with ground truth classes and if private class samples are separated into multiple clusters
  2. Test uncertainty estimation: Compare pseudo-label accuracy with and without uncertainty-based sample selection
  3. Evaluate contrastive learning: Assess feature space structure with standard InfoNCELoss vs NL-InfoNCELoss on a dataset with noisy pseudo-labels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed NL-InfoNCELoss compare to other contrastive losses in handling noisy pseudo-labels in open-set scenarios?
- Basis in paper: [explicit] The paper introduces NL-InfoNCELoss and claims it enhances robustness to noisy pseudo-labels by integrating negative learning principles.
- Why unresolved: While the paper demonstrates improved performance with NL-InfoNCELoss, a direct comparison with other contrastive losses specifically designed for noisy labels is not provided.
- What evidence would resolve it: Ablation studies comparing NL-InfoNCELoss to other contrastive losses like SupCon or MoCo on datasets with varying levels of noise in pseudo-labels.

### Open Question 2
- Question: Can the uncertainty estimation via class separation (Eq. 4) be further improved by incorporating additional information about the feature space geometry?
- Basis in paper: [inferred] The paper proposes uncertainty estimation via class separation but only considers the distance to the two closest prototypes. Incorporating more information about the feature space, such as the density of samples or the presence of outliers, could potentially lead to a more accurate uncertainty estimate.
- Why unresolved: The paper does not explore alternative methods for uncertainty estimation beyond the two proposed strategies.
- What evidence would resolve it: Experiments comparing the proposed uncertainty estimation method to alternative approaches that incorporate additional feature space information.

### Open Question 3
- Question: How does the choice of clustering algorithm affect the initial pseudo-label assignment and subsequent performance in SF-OSDA?
- Basis in paper: [explicit] The paper uses K-means for clustering but acknowledges that the choice of clustering algorithm can impact the results.
- Why unresolved: The paper does not investigate the impact of using different clustering algorithms, such as hierarchical clustering or DBSCAN, on the performance of the proposed method.
- What evidence would resolve it: Experiments comparing the performance of the proposed method using different clustering algorithms on benchmark datasets.

## Limitations

- The clustering-based initialization assumes sufficient intra-class consistency in target features, which may not hold for highly diverse private classes
- The effectiveness of NL-InfoNCELoss depends on the assumption that negative learning can meaningfully mitigate noisy pseudo-label effects, though theoretical justification is limited
- The uncertainty estimation relies on neighborhood structures that may break down in feature spaces with complex geometry or severe domain shift

## Confidence

- **High Confidence**: The overall framework design and experimental methodology are sound. The use of clustering for initialization and uncertainty-based sample selection are well-established techniques in the domain adaptation literature.
- **Medium Confidence**: The specific implementation of NL-InfoNCELoss and its superiority over standard contrastive losses needs further validation across diverse scenarios and noise levels.
- **Low Confidence**: The claim about discovering the underlying semantics of novel classes is primarily supported by qualitative observations and would benefit from more rigorous quantitative analysis.

## Next Checks

1. **Ablation Study on Clustering Granularity**: Systematically vary the number of target-private classes (|bCP|) and evaluate the trade-off between private class separation and shared class accuracy across multiple datasets.

2. **Uncertainty Estimation Robustness**: Test the method's performance when the feature space exhibits varying levels of class overlap or when domain shift is artificially increased through style transfer techniques.

3. **Negative Learning Effectiveness**: Compare NL-InfoNCELoss against alternative contrastive loss variants (e.g., supervised contrastive loss with noisy labels, debiased contrastive loss) to isolate the specific contribution of negative learning integration.