---
ver: rpa2
title: 'DAG: Dictionary-Augmented Generation for Disambiguation of Sentences in Endangered
  Uralic Languages using ChatGPT'
arxiv_id: '2411.01531'
source_url: https://arxiv.org/abs/2411.01531
tags:
- skolt
- lemma
- sami
- languages
- lemmas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ChatGPT can be used to disambiguate lemmas in morphologically complex
  endangered Uralic languages (Erzya and Skolt Sami) by augmenting prompts with dictionary
  translations. The method combines finite-state morphological analysis with a bilingual
  dictionary (Finnish) to provide ChatGPT with sufficient context.
---

# DAG: Dictionary-Augmented Generation for Disambiguation of Sentences in Endangered Uralic Languages using ChatGPT

## Quick Facts
- arXiv ID: 2411.01531
- Source URL: https://arxiv.org/abs/2411.01531
- Authors: Mika H채m채l채inen
- Reference count: 5
- Primary result: 50% accuracy for Skolt Sami, 41% for Erzya on sentence-level disambiguation

## Executive Summary
This paper presents a novel approach to morphological disambiguation for endangered Uralic languages (Erzya and Skolt Sami) using ChatGPT-4o with dictionary augmentation. The method combines finite-state morphological analysis with bilingual dictionary translations to provide ChatGPT with sufficient context to select the correct lemma for each word form. The approach achieved 50% accuracy for Skolt Sami and 41% for Erzya on sentence-level disambiguation tasks, demonstrating that large language models can be effectively used for low-resource language processing without requiring training data or complex rule systems. The method is particularly valuable for endangered languages lacking large annotated corpora, offering a practical solution for morphological analysis in resource-scarce linguistic contexts.

## Method Summary
The approach uses finite-state morphological analyzers (PYHFST) to generate all possible lemma analyses for each word form in Universal Dependencies treebanks. Each lemma is then looked up in the Akusanat bilingual dictionary to obtain Finnish translations. For each sentence, the system generates a prompt containing the original sentence, a table of possible lemmas with their morphological features, and a table of Finnish translations. ChatGPT-4o processes this information and selects the most appropriate lemma for each word form. The method operates in a zero-shot manner without requiring training data or rule-writing, making it particularly suitable for endangered languages with limited linguistic resources.

## Key Results
- Achieved 50% sentence-level accuracy for Skolt Sami morphological disambiguation
- Achieved 41% sentence-level accuracy for Erzya morphological disambiguation
- Most errors were reasonable even for untrained human annotators, suggesting the approach provides useful disambiguation even when not perfectly accurate

## Why This Works (Mechanism)
The approach works by leveraging ChatGPT's strong language understanding capabilities while compensating for its lack of knowledge about the target languages through dictionary augmentation. By providing both the morphological analysis and Finnish translations, the system gives ChatGPT sufficient context to disambiguate between multiple possible lemma analyses. The bilingual dictionary serves as a bridge between the morphologically complex Uralic languages and ChatGPT's linguistic capabilities, allowing the model to reason about the correct word senses based on their Finnish translations.

## Foundational Learning
- **Finite-State Morphological Analysis**: Why needed - To generate all possible lemma analyses for each word form in the target languages. Quick check - Verify that FST analyzers produce comprehensive analyses covering all surface forms in the treebanks.
- **Bilingual Dictionary Lookup**: Why needed - To provide ChatGPT with semantic context for each lemma through translations. Quick check - Confirm dictionary coverage includes all lemmas in the treebanks with appropriate Finnish translations.
- **Prompt Engineering for LLMs**: Why needed - To structure information in a way that enables ChatGPT to effectively disambiguate between lemma options. Quick check - Test prompt variations to ensure ChatGPT consistently produces formatted output with selected lemmas.
- **Sentence-level Evaluation Metrics**: Why needed - To measure disambiguation performance in a realistic linguistic context. Quick check - Verify that evaluation compares complete sentence analyses against gold standard annotations.
- **Zero-shot Learning Approaches**: Why needed - To enable language processing without requiring annotated training data. Quick check - Confirm that no language-specific training or fine-tuning was performed on the target languages.

## Architecture Onboarding

**Component Map**: FST Analyzer -> Dictionary Lookup -> Prompt Generator -> ChatGPT-4o -> Disambiguation Output

**Critical Path**: The morphological analysis pipeline (FST -> Dictionary -> Prompt) must be complete and accurate for ChatGPT to have sufficient information for disambiguation decisions.

**Design Tradeoffs**: The method trades perfect accuracy for zero-shot applicability, sacrificing some precision to avoid the need for training data or rule-writing. Using Finnish as an intermediate language enables disambiguation but may lose some linguistic nuance.

**Failure Signatures**: ChatGPT may omit punctuation or substitute Unicode characters with lookalikes; Finnish translations may not preserve POS distinctions leading to incorrect disambiguations; temperature=1 introduces variability in outputs.

**First Experiments**:
1. Test the pipeline on a small sample of sentences to verify prompt formatting and ChatGPT response structure
2. Run disambiguation on single-word sentences to validate basic functionality before scaling to full sentences
3. Compare disambiguation accuracy with and without Finnish translations to quantify the dictionary augmentation value

## Open Questions the Paper Calls Out
### Open Question 1
How would the accuracy change if dictionary translations were provided to ChatGPT in a language it is more proficient in than Finnish (e.g., English)? The authors note that Finnish was chosen as the majority language for dictionary translations, but acknowledge that ChatGPT is not proficient in the target languages and must rely on these translations. The paper only tests with Finnish translations and does not explore whether a different majority language would yield better results. Running the same experiments with dictionary translations in English (or another language ChatGPT is highly proficient in) and comparing accuracy rates would resolve this.

### Open Question 2
Would fine-tuning ChatGPT on a small amount of annotated data from these endangered languages improve disambiguation accuracy beyond the dictionary-augmented approach? The authors achieved 50% accuracy for Skolt Sami and 41% for Erzya using only dictionary-augmented generation, suggesting there is room for improvement. The paper explicitly states no training or additional annotated data was used, focusing solely on the zero-shot dictionary-augmented approach. Conducting experiments where ChatGPT is fine-tuned on a small annotated corpus of either language and measuring whether disambiguation accuracy increases would resolve this.

### Open Question 3
How would the accuracy change if ChatGPT were prompted to explicitly consider parts-of-speech information from the Finnish translations? The authors note that in 3 cases for Skolt Sami, ChatGPT failed to transfer POS information from Finnish translations, leading to errors. The current prompt template does not explicitly instruct ChatGPT to use POS information from the translations. Modifying the prompt to explicitly instruct ChatGPT to use POS information from the Finnish translations and measuring the impact on accuracy would resolve this.

### Open Question 4
Would using multiple translation options for each lemma (rather than just one) improve disambiguation accuracy? The authors use a single Finnish translation for each lemma, but acknowledge that ChatGPT is not proficient in the target languages and must rely entirely on these translations. The paper only tests with single translations per lemma and does not explore whether multiple translations would provide better context. Running experiments where multiple Finnish translations are provided for each lemma and comparing accuracy rates would resolve this.

## Limitations
- Accuracy levels (50% for Skolt Sami, 41% for Erzya) remain substantially below human performance (75% for Skolt Sami)
- Heavy reliance on Finnish as an intermediate language may not capture full semantic and morphological nuances of target languages
- Effectiveness depends heavily on quality and coverage of bilingual dictionary
- Finnish translations may not always preserve crucial grammatical distinctions
- Temperature=1 setting introduces variability that may affect reproducibility

## Confidence
**Methodology confidence: Medium** - The core approach is sound and innovative, but accuracy levels are limited and the method shows high variability.
**Practical applicability confidence: Low** - High error rate and language-specific dependencies limit real-world deployment potential.
**Scalability confidence: Low-Medium** - Results are specific to the tested language pairs and may not generalize to other morphological systems without validation.

## Next Checks
1. Test the same approach with temperature=0 to assess the impact of randomness on reproducibility and accuracy
2. Validate the method on additional Uralic languages (e.g., V천ro, Kven) with different morphological complexities and available dictionaries
3. Compare the dictionary-augmented approach against a direct morphological disambiguation method using ChatGPT without Finnish translations to quantify the value added by the dictionary augmentation