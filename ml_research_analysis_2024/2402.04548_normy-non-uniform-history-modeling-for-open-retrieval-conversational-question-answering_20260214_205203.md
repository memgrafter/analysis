---
ver: rpa2
title: 'NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question
  Answering'
arxiv_id: '2402.04548'
source_url: https://arxiv.org/abs/2402.04548
tags:
- history
- passages
- context
- question
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of conversational question answering
  with open retrieval (OrConvQA), where a question is answered based on a conversation
  as context and a document collection. The key insight is that different history
  modeling is needed for different modules in the OrConvQA pipeline (Retriever, Reranker,
  Reader) - a broader context for Retriever to not miss relevant documents, and a
  narrower context for Reader to identify the exact answer span.
---

# NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering

## Quick Facts
- **arXiv ID**: 2402.04548
- **Source URL**: https://arxiv.org/abs/2402.04548
- **Reference count**: 40
- **Key outcome**: NORMY outperforms state-of-the-art in individual modules and end-to-end system for OrConvQA

## Executive Summary
NORMY addresses the challenge of conversational question answering with open retrieval (OrConvQA) by proposing a non-uniform history modeling approach. The key insight is that different history modeling is needed for different modules in the OrConvQA pipeline: a broader context for the Retriever to not miss relevant documents, and a narrower context for the Reader to identify the exact answer span. NORMY uses keyphrase extraction and history-aware decay scoring for the Retriever, a fixed window of recent turns for the Reranker, and coreference resolution for the Reader.

## Method Summary
NORMY is the first unsupervised non-uniform history modeling pipeline for OrConvQA. It adapts history modeling to the specific needs of each module in the pipeline. For the Retriever, NORMY uses keyphrase extraction and history-aware decay scoring to broaden the context. For the Reranker, a fixed window of recent turns is used to maintain focus. For the Reader, coreference resolution is employed to ensure precise answer span identification. This approach allows NORMY to balance the trade-off between context breadth and precision across different stages of the OrConvQA pipeline.

## Key Results
- NORMY significantly outperforms state-of-the-art approaches in individual modules and end-to-end system on three datasets (ORQUAC, doc2dial-OR, ConvMix)
- The non-uniform history modeling approach demonstrates superior performance compared to uniform context approaches
- NORMY shows effectiveness across different QA modules, including Retriever, Reranker, and Reader

## Why This Works (Mechanism)
The effectiveness of NORMY stems from its tailored approach to history modeling for different components of the OrConvQA pipeline. By using broader context for the Retriever, it reduces the risk of missing relevant documents. The narrower context for the Reader ensures more precise answer span identification. This non-uniform approach allows for optimal balance between recall and precision at different stages of the pipeline.

## Foundational Learning
1. **Open Retrieval Conversational Question Answering (OrConvQA)**: Why needed: To understand the problem domain and specific challenges of OrConvQA. Quick check: Can you explain the difference between OrConvQA and traditional QA?
2. **History Modeling**: Why needed: To grasp the importance of incorporating conversation history in OrConvQA. Quick check: How does history modeling improve performance in OrConvQA?
3. **Non-uniform Context**: Why needed: To understand the concept of varying context width for different pipeline components. Quick check: Why is a broader context beneficial for the Retriever but not necessarily for the Reader?
4. **Keyphrase Extraction**: Why needed: To comprehend its role in expanding context for the Retriever. Quick check: How does keyphrase extraction contribute to broader context?
5. **History-aware Decay Scoring**: Why needed: To understand how it weights different parts of the conversation history. Quick check: What is the purpose of decay scoring in history modeling?
6. **Coreference Resolution**: Why needed: To grasp its importance in identifying answer spans in the Reader. Quick check: How does coreference resolution improve answer precision in OrConvQA?

## Architecture Onboarding

**Component Map**: Retriever -> Reranker -> Reader

**Critical Path**: The critical path involves passing the conversation history and current question through each module, with history modeling adapted at each stage.

**Design Tradeoffs**: The main tradeoff is between context breadth (for recall) and precision. NORMY addresses this by using non-uniform history modeling, broadening context for the Retriever and narrowing it for the Reader.

**Failure Signatures**: Potential failures include:
- Overly broad context leading to irrelevant document retrieval
- Insufficient context causing missed relevant documents
- Incorrect coreference resolution leading to wrong answer spans

**First Experiments**:
1. Evaluate NORMY on a small subset of the ORQUAC dataset to validate individual module performance
2. Conduct an ablation study removing the history-aware decay scoring to assess its impact
3. Test NORMY with a uniform context approach to quantify the benefits of non-uniform modeling

## Open Questions the Paper Calls Out
None

## Limitations
- The experiments were conducted on three datasets, which may limit generalizability
- The unsupervised nature of NORMY may limit its ability to capture complex conversational patterns compared to supervised approaches
- Standard QA metrics may not fully capture the nuances of conversational question answering

## Confidence
- Effectiveness of non-uniform history modeling: High
- Superior performance of NORMY compared to baselines: Medium
- Generalizability across different QA modules: Low

## Next Checks
1. Test NORMY on a diverse set of datasets from different domains to assess generalizability
2. Conduct a detailed ablation study to isolate the impact of each history modeling component
3. Implement a supervised history modeling approach and compare its performance with NORMY