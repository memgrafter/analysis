---
ver: rpa2
title: Iterative Graph Neural Network Enhancement via Frequent Subgraph Mining of
  Explanations
arxiv_id: '2403.07849'
source_url: https://arxiv.org/abs/2403.07849
tags:
- eegl
- graph
- subgraph
- patterns
- frequent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes EEGL, an XAI-based iterative model improvement
  approach for GNNs that uses frequent subgraph mining on explanation subgraphs to
  extract application-dependent features and improve predictive performance. Starting
  with a "vanilla" GNN, EEGL repeatedly finds frequent patterns in explanation subgraphs
  for nodes of a given class, filters these to obtain application-specific features,
  and updates node feature vectors accordingly.
---

# Iterative Graph Neural Network Enhancement via Frequent Subgraph Mining of Explanations

## Quick Facts
- arXiv ID: 2403.07849
- Source URL: https://arxiv.org/abs/2403.07849
- Authors: Harish G. Naik; Jan Polster; Raj Shekhar; Tamás Horváth; György Turán
- Reference count: 40
- Key outcome: EEGL achieves F1-scores of 100% on most datasets in one iteration and between 86-97% on three fullerenes, outperforming baselines on node classification tasks.

## Executive Summary
This paper introduces EEGL, an XAI-based iterative approach for improving GNN predictive performance through frequent subgraph mining of explanation subgraphs. The method starts with a vanilla GNN and repeatedly extracts frequent patterns from explanation subgraphs, filtering them to obtain application-specific features that are used to update node feature vectors. Experiments demonstrate that EEGL outperforms related approaches on both synthetic and real-world datasets while achieving node-distinguishing power beyond that of vanilla GNNs.

## Method Summary
EEGL is an iterative self-improving algorithm that begins with a learned vanilla GNN and repeatedly uses frequent subgraph mining to identify relevant patterns in explanation subgraphs. The approach extracts frequent connected subgraphs from explanations for nodes of a given class, filters them by F1-score, and updates node feature vectors accordingly. This automated, data-driven pattern selection process aims to overcome the limitations of the Weisfeiler-Leman algorithm and extract application-dependent features without manual domain knowledge.

## Key Results
- EEGL achieved F1-scores of 100% on most datasets in one iteration
- Performance ranged from 86-97% on three fullerenes across iterations
- EEGL outperformed label encoding, random features, adversarial features, and SHA DOW-GNN on all datasets except one where SHA DOW-GNN achieved approximately the same F1-score

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EEGL improves GNN predictive performance by iteratively extracting and using frequent subgraph patterns from explanation subgraphs as node features.
- Mechanism: EEGL starts with a vanilla GNN, uses GNNExplainer to obtain explanation subgraphs for each node, mines frequent connected subgraphs from these explanations per class, filters them by F1-score, and updates node features accordingly for the next iteration.
- Core assumption: Explanation subgraphs generated by GNNExplainer are structurally meaningful and contain frequent patterns that correlate with node classes.
- Evidence anchors: [abstract] "EEGL is an iterative self-improving algorithm, which starts with a learned 'vanilla' GNN, and repeatedly uses frequent subgraph mining to find relevant patterns in explanation subgraphs."
- Break condition: If explanation subgraphs are too noisy or sparse, frequent pattern mining will yield uninformative or misleading features.

### Mechanism 2
- Claim: EEGL can achieve node-distinguishing power beyond that of vanilla GNNs by overcoming the limitations of the Weisfeiler-Leman (1-WL) algorithm.
- Mechanism: By annotating nodes with subgraph-based features not detectable by 1-WL, EEGL extends the expressive power of GNNs beyond 1-WL indistinguishability.
- Core assumption: The patterns mined from explanation subgraphs represent structural features that 1-WL cannot capture but are discriminative for node classes.
- Evidence anchors: [abstract] "EEGL outperforms related approaches in predictive performance and that it has a node-distinguishing power beyond that of vanilla GNNs."
- Break condition: If the application's discriminative information is purely statistical and not structural, subgraph features will not help.

### Mechanism 3
- Claim: EEGL provides an automated, application-dependent solution to the GNN pattern selection problem.
- Mechanism: Instead of manually selecting subgraph patterns based on domain knowledge, EEGL automatically selects frequent patterns from explanation subgraphs, making the approach data-driven and adaptive to the specific application.
- Core assumption: Frequent patterns in explanation subgraphs for a class are indicative of discriminative structural features for that class.
- Evidence anchors: [section] "In this paper we propose an approach to the GNN pattern selection problem for application-dependent features, i.e., the features are extracted from the data in an automatic way, and not by using some domain-specific pattern set."
- Break condition: If the data lacks clear frequent patterns or the explanation subgraphs are too heterogeneous, automated selection will fail.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and the limitations of the Weisfeiler-Leman (1-WL) algorithm.
  - Why needed here: Understanding why vanilla GNNs are limited by 1-WL indistinguishability is crucial to appreciating EEGL's goal of extending expressive power.
  - Quick check question: Can two nodes with the same 1-WL label ever be distinguished by a vanilla GNN? Why or why not?

- Concept: Frequent subgraph mining and its application to explanation subgraphs.
  - Why needed here: EEGL's core mechanism relies on mining frequent patterns from explanation subgraphs; understanding this process is essential.
  - Quick check question: What is the relationship between the frequency threshold τ and the number of patterns mined? How might this affect EEGL's performance?

- Concept: XAI-based model improvement and the use of explanations for feature engineering.
  - Why needed here: EEGL is an XAI-based approach; understanding how explanations can be used to improve models is key to grasping its design.
  - Quick check question: What are the potential risks of using explanations for model improvement, especially if the explanations are imperfect?

## Architecture Onboarding

- Component map: GNN Learning -> Node Explainer -> Pattern Extraction -> Feature Annotation -> (loop back to GNN Learning)
- Critical path: The critical path is the iterative loop: GNN Learning → Node Explainer → Pattern Extraction → Feature Annotation. Each module depends on the output of the previous one.
- Design tradeoffs: EEGL trades computational cost (multiple iterations, frequent subgraph mining) for potentially improved predictive performance. The choice of frequency threshold τ and the number of iterations K are key hyperparameters.
- Failure signatures: EEGL may fail if explanation subgraphs are too noisy, if frequent patterns are not discriminative, or if the data's discriminative information is not structural. Performance plateaus or degradation in later iterations can indicate such issues.
- First 3 experiments:
  1. Run EEGL on a synthetic graph with clear structural motifs (e.g., the "house" motif from GNNExplainer) and verify if it can learn to distinguish nodes based on motif presence.
  2. Run EEGL on a graph where 1-WL cannot distinguish node classes (e.g., nodes at the same distance from a central structure) and verify if EEGL can learn to distinguish them.
  3. Compare EEGL's performance with and without the feature annotation step to isolate the impact of the subgraph-based features.

## Open Questions the Paper Calls Out

- Question: Does improved prediction performance in EEGL iterations imply improved explanation quality?
- Basis in paper: [explicit] The paper mentions this as a future research direction, noting that explanation evaluation is challenging due to lack of ground truth.
- Why unresolved: The paper focuses on predictive performance but does not analyze whether better predictions correspond to more faithful or interpretable explanations.
- What evidence would resolve it: Comparative analysis of explanation faithfulness metrics (e.g., deletion/insertion scores) across EEGL iterations alongside performance metrics.

- Question: How sensitive is EEGL's performance to the choice of GNN explainer and pattern miner?
- Basis in paper: [explicit] The paper notes that performance is highly influenced by classifier and explainer implementations, with different implementations yielding different results on synthetic vs real data.
- Why unresolved: Experiments used specific combinations (GCN + GNNExplainer for synthetic, PyG for others) but did not systematically compare alternative explainers or miners.
- What evidence would resolve it: Controlled experiments varying explainer (e.g., PGExplainer, SubgraphX) and pattern miner (e.g., gSpan, MoSS) while holding other components constant.

- Question: Can EEGL handle node feature explanations in addition to structural explanations?
- Basis in paper: [explicit] The paper states it focused on graph-theoretic structural aspects and did not consider node feature explanations, marking this as future work.
- Why unresolved: Current EEGL implementation only uses structural patterns from explanation subgraphs, ignoring any feature importance information provided by explainers.
- What evidence would resolve it: Extension of EEGL to incorporate feature masks from explainers into the pattern extraction and feature annotation process, with evaluation on datasets with rich node features.

## Limitations
- The frequent subgraph mining approach may struggle with larger, denser graphs due to computational complexity
- The quality of explanations from GNNExplainer is crucial for EEGL's success, but robustness to noise is not thoroughly investigated
- The paper focuses on node classification tasks, with unclear generalization to other GNN tasks like link prediction or graph classification

## Confidence

- **High Confidence:** EEGL's core mechanism of iteratively extracting frequent subgraph patterns from explanation subgraphs and using them as node features is clearly described and supported by the experimental results.
- **Medium Confidence:** The claim that EEGL achieves node-distinguishing power beyond vanilla GNNs is supported by the results, but the paper could provide more detailed analysis of which specific patterns contribute to this increased discriminative power.
- **Low Confidence:** The claim that EEGL provides a universally effective automated solution to the GNN pattern selection problem is somewhat overstated, as the approach's success likely depends heavily on the quality of the explanations and the presence of clear structural patterns in the data.

## Next Checks

1. **Robustness Testing:** Test EEGL's performance on graphs with varying levels of noise and adversarial perturbations to assess the robustness of the explanation-based feature extraction.

2. **Scalability Analysis:** Evaluate EEGL's computational complexity and memory requirements on larger, denser graphs to understand its practical limitations.

3. **Cross-Task Generalization:** Apply EEGL to link prediction and graph classification tasks to determine if the approach generalizes beyond node classification.