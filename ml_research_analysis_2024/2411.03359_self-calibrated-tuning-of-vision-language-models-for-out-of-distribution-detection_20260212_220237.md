---
ver: rpa2
title: Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection
arxiv_id: '2411.03359'
source_url: https://arxiv.org/abs/2411.03359
tags:
- detection
- data
- features
- methods
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of spurious out-of-distribution
  (OOD) features in vision-language model (VLM)-based OOD detection methods, where
  extracted local context from in-distribution (ID) data can be unreliable due to
  imperfect foreground-background decomposition. The proposed Self-Calibrated Tuning
  (SCT) framework dynamically adjusts the importance of OOD regularization from different
  ID samples based on their prediction uncertainty during training.
---

# Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection

## Quick Facts
- arXiv ID: 2411.03359
- Source URL: https://arxiv.org/abs/2411.03359
- Authors: Geng Yu; Jianing Zhu; Jiangchao Yao; Bo Han
- Reference count: 40
- Primary result: SCT improves FPR95 by 3% compared to previous best methods on large-scale ImageNet benchmarks

## Executive Summary
This paper addresses the problem of spurious out-of-distribution (OOD) features in vision-language model (VLM)-based OOD detection methods, where extracted local context from in-distribution (ID) data can be unreliable due to imperfect foreground-background decomposition. The proposed Self-Calibrated Tuning (SCT) framework dynamically adjusts the importance of OOD regularization from different ID samples based on their prediction uncertainty during training. By introducing modulating factors that balance the focus between ID classification and OOD regularization, SCT calibrates the influence of imperfect surrogate OOD features. Experiments on large-scale ImageNet benchmarks show that SCT improves FPR95 by 3% compared to previous best methods, while maintaining comparable ID classification accuracy and demonstrating compatibility with various prompt tuning baselines.

## Method Summary
SCT introduces modulating factors (ϕ and ψ) that respectively scale the classification loss and OOD regularization loss based on prediction confidence. As prediction uncertainty increases (lower confidence), ϕ decreases to reduce emphasis on classification while ψ increases to strengthen OOD regularization. This dynamic adjustment helps VLMs learn from imperfect OOD features without overfitting to ID data. The framework is applied to LoCoOp-style prompt tuning with a ViT-B/16 backbone, trained for 25 epochs with SGD optimizer, and extracts surrogate OOD features using a ranking-based method with 200 local regions.

## Key Results
- Improves FPR95 by 3% compared to previous best methods on ImageNet benchmarks
- Maintains comparable ID classification accuracy while improving OOD detection
- Demonstrates compatibility with various prompt tuning baselines including CoOp and LoCoOp

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SCT dynamically adjusts OOD regularization importance based on prediction uncertainty
- Mechanism: Modulating factors (ϕ and ψ) scale classification and OOD regularization losses respectively, with ϕ decreasing and ψ increasing as confidence increases
- Core assumption: Prediction uncertainty correlates with reliability of extracted OOD features
- Evidence anchors: [abstract], [section 3.2], [corpus]
- Break condition: If uncertainty estimation becomes uncorrelated with OOD feature quality

### Mechanism 2
- Claim: SCT improves calibration while maintaining OOD detection performance
- Mechanism: Down-weighting classification loss on high-confidence samples and up-weighting OOD regularization prevents overfitting and improves calibration
- Core assumption: Reducing emphasis on classification for confident samples prevents overconfidence
- Evidence anchors: [abstract], [section 3.3], [corpus]
- Break condition: If down-weighting classification loss causes unacceptable degradation in ID accuracy

### Mechanism 3
- Claim: SCT is compatible with existing prompt tuning methods
- Mechanism: Modulating factors are applied orthogonally to existing OOD regularization functions
- Core assumption: Modulating factors can be applied to any prompt tuning method using OOD regularization
- Evidence anchors: [abstract], [section 3.3], [corpus]
- Break condition: If certain prompt tuning methods have incompatible loss structures

## Foundational Learning

- Concept: Vision-Language Models (VLMs) like CLIP
  - Why needed here: SCT is built on top of VLMs and their limitations motivate the approach
  - Quick check question: What are the key components of a VLM like CLIP, and how does it differ from traditional vision models?

- Concept: Prompt tuning
  - Why needed here: SCT is a prompt tuning method that modifies how prompts are learned
  - Quick check question: How does prompt tuning differ from full fine-tuning, and what are the advantages of using learnable prompts?

- Concept: Out-of-Distribution (OOD) detection
  - Why needed here: SCT is specifically designed to improve OOD detection performance
  - Quick check question: What are the key challenges in OOD detection, and how do scoring functions like MCM and GL-MCM work?

## Architecture Onboarding

- Component map: VLM backbone -> Text encoder with learnable prompts -> Vision encoder producing local feature maps -> OOD feature extraction module -> Modulating functions (ϕ and ψ) -> Loss computation combining classification and OOD regularization

- Critical path:
  1. Forward pass through VLM to get predictions and local features
  2. Extract OOD features using ranking-based method
  3. Compute modulating factors based on prediction confidence
  4. Calculate weighted loss combining classification and OOD regularization
  5. Backward pass and parameter update

- Design tradeoffs:
  - Choice of modulating function (linear vs. power vs. logarithmic vs. trigonometric)
  - Regularization weight λ balancing classification and OOD tasks
  - Number of local regions K for OOD feature extraction
  - Impact on ID classification accuracy vs. OOD detection performance

- Failure signatures:
  - Significant drop in ID classification accuracy
  - OOD detection performance worse than baseline LoCoOp
  - Modulating factors becoming NaN or exploding
  - Training instability or divergence

- First 3 experiments:
  1. Verify that modulating factors (ϕ and ψ) properly scale with prediction confidence
  2. Compare ID classification accuracy of SCT vs. baseline CoOp and LoCoOp
  3. Measure OOD detection performance (FPR95 and AUROC) on ImageNet benchmark with 16-shot setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific theoretical guarantees for SCT's effectiveness in OOD detection, and how do they relate to sample uncertainty estimation?
- Basis in paper: The paper mentions that theoretical analysis is lacking and that the choice of linear function for modulating factors was made for simplicity rather than theoretical justification
- Why unresolved: The paper acknowledges absence of theoretical analysis to prove SCT's effectiveness
- What evidence would resolve it: Rigorous mathematical proof demonstrating the relationship between sample uncertainty, modulating functions, and OOD detection improvement

### Open Question 2
- Question: How does SCT's performance scale with increasing dataset size and complexity, particularly in real-world scenarios with large-scale and diverse data?
- Basis in paper: The paper focuses on few-shot learning scenarios and mentions that prompt tuning performance can be sensitive to quality of limited ID training data
- Why unresolved: Experiments are primarily conducted on few-shot settings and standard benchmarks
- What evidence would resolve it: Extensive experiments on large-scale, diverse datasets with varying levels of noise and complexity

### Open Question 3
- Question: How does SCT compare to other advanced post-hoc calibration methods specifically designed for prompt tuning based OOD detection?
- Basis in paper: The paper mentions that SCT is compatible with post-hoc methods and suggests future research into post-hoc calibration methods
- Why unresolved: While the paper discusses compatibility, it does not provide empirical comparisons or explore potential synergies or trade-offs
- What evidence would resolve it: Empirical studies comparing SCT with various post-hoc calibration methods

## Limitations

- The correlation between prediction uncertainty and OOD feature reliability is assumed but not empirically validated
- The choice of linear modulating function lacks theoretical justification and sensitivity to different function forms is not explored
- Evaluation is limited to CLIP-based models with ViT-B/16 backbone, raising questions about generalizability

## Confidence

- Mechanism 1 (uncertainty-based modulation): Medium confidence - logical explanation but lacks empirical validation of the uncertainty-OOD feature reliability correlation
- Mechanism 2 (calibration improvement): Low confidence - minimal discussion of calibration metrics and no ablation studies isolating modulating factors' effect on calibration
- Mechanism 3 (compatibility with prompt tuning): High confidence - orthogonality argument is well-reasoned and experimental results support the claim

## Next Checks

1. Validate the uncertainty-OOD reliability correlation by measuring the correlation between prediction uncertainty and quality of extracted OOD features across different confidence levels

2. Test modulating function sensitivity through ablation studies comparing SCT with different modulating function choices (linear, power, logarithmic, trigonometric)

3. Generalize to other VLM architectures by implementing SCT with a different backbone (e.g., ALBEF or OpenCLIP) to verify improvements transfer beyond CLIP-ViT-B/16