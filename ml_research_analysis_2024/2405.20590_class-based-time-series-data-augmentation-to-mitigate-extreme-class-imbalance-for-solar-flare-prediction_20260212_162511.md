---
ver: rpa2
title: Class-Based Time Series Data Augmentation to Mitigate Extreme Class Imbalance
  for Solar Flare Prediction
arxiv_id: '2405.20590'
source_url: https://arxiv.org/abs/2405.20590
tags:
- data
- time
- series
- augmentation
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel class-based data augmentation method
  called Mean Gaussian Noise (MGN) for addressing class imbalance in multivariate
  time series classification, specifically for solar flare prediction using the SWAN-SF
  dataset. MGN generates synthetic data by adding Gaussian noise to the mean time
  series of the underrepresented class, aiming to better represent the class distribution
  and improve model performance.
---

# Class-Based Time Series Data Augmentation to Mitigate Extreme Class Imbalance for Solar Flare Prediction

## Quick Facts
- arXiv ID: 2405.20590
- Source URL: https://arxiv.org/abs/2405.20590
- Reference count: 23
- Primary result: MGN achieves best performance on 3 of 4 partitions for solar flare prediction with competitive computational cost

## Executive Summary
This paper introduces Mean Gaussian Noise (MGN), a novel class-based data augmentation method for addressing extreme class imbalance in multivariate time series classification. The method generates synthetic samples by adding Gaussian noise to the mean time series of the underrepresented class, specifically targeting solar flare prediction using the SWAN-SF dataset. MGN is evaluated against eight basic augmentation techniques on a binary classification task using TimeSeriesSVC, demonstrating superior performance on three of four testing partitions while maintaining competitive computational efficiency.

## Method Summary
MGN generates synthetic samples by computing the mean time series across all samples in the minority class, then perturbing each mean value with Gaussian noise scaled by the mean itself. The method uses random undersampling to balance classes and TimeSeriesSVC with RBF kernel for classification. The approach is evaluated on solar flare prediction using five SHARP parameters from the SWAN-SF dataset, with performance measured by TSS, HSS2, and distance to perfect (DtP) scores across four temporal partitions.

## Key Results
- MGN achieved the best performance on three of four testing partitions in terms of distance to perfect (DtP) score
- Computational analysis shows MGN has competitive cost compared to alternative methods
- The class-based approach demonstrates potential for improving classification performance in scenarios with extremely imbalanced data

## Why This Works (Mechanism)

### Mechanism 1
MGN generates synthetic samples by adding Gaussian noise centered on the mean of the underrepresented class, not on individual samples. Instead of jittering individual time series, MGN computes the mean vector at each time step across all samples in the minority class, then perturbs each mean with Gaussian noise scaled by the mean itself. This creates a new synthetic instance that follows the global statistical structure of the rare class.

### Mechanism 2
MGN's class-based approach yields better exploration of the input space than instance-based methods. By sampling around a global mean, MGN can generate points that are not constrained to the convex hull of existing samples. This helps the classifier explore regions of the feature space that are underrepresented but still belong to the minority class.

### Mechanism 3
MGN is computationally competitive because it requires only one pass to compute the mean and one pass to generate samples. Computing the mean across all samples is O(n·d·t) where n is sample count, d is feature dimension, t is time steps. Adding noise and scaling is O(d·t) per generated sample.

## Foundational Learning

- **Concept: Class imbalance and its impact on classifier bias**
  - Why needed here: The paper addresses solar flare prediction where M/X class flares are extremely rare, so a naive classifier would ignore them
  - Quick check question: What happens to precision/recall for the minority class if you train without addressing imbalance?

- **Concept: Time series augmentation and its domain-specific constraints**
  - Why needed here: Unlike image augmentation, time series methods must preserve temporal dependencies; naive shuffling can destroy patterns
  - Quick check question: Why would random flipping of feature axes be risky for time series data?

- **Concept: Evaluation metrics for imbalanced classification (TSS, HSS2)**
  - Why needed here: Accuracy is misleading; TSS and HSS2 measure discriminative ability and reliability on the rare class
  - Quick check question: How does TSS differ from recall in the presence of extreme class imbalance?

## Architecture Onboarding

- **Component map**: Data → Preprocessing (undersampling NBC) → Augmentation (MGN vs baseline) → Feature extraction (top 5 SHARP params) → TimeSeriesSVC (RBF kernel) → Evaluation (TSS/HSS2)
- **Critical path**: Load SWAN-SF → Compute minority class mean → Generate MGN samples → Combine with undersampled majority → Train TimeSeriesSVC → Evaluate on partitions 2-5
- **Design tradeoffs**: MGN is fast and simple but assumes unimodal minority class; more complex methods (warping, slicing) preserve local structure but cost more
- **Failure signatures**: If MGN underperforms, suspect multimodal minority class or incorrect σ; if training is slow, suspect inefficient mean computation or memory bottlenecks
- **First 3 experiments**:
  1. Verify MGN produces synthetic samples by visualizing mean ± noise for a few features
  2. Compare training runtime of MGN vs jittering with identical sample counts
  3. Run ablation: MGN with σ=0.5, 1.0, 1.5 to see sensitivity to noise scale

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of MGN vary with different values of the standard deviation parameter σ? The paper mentions that σ is a hyperparameter for MGN but only tests it with σ=1.0.

### Open Question 2
Can MGN maintain its performance advantage when combined with deep learning models instead of TimeSeriesSVC? The paper only tested MGN with TimeSeriesSVC and suggests future work should test with diverse classifiers including neural networks.

### Open Question 3
How does MGN perform on other multivariate time series datasets with different characteristics than SWAN-SF? The authors state "our future research endeavors aim to extend the evaluation of our methods across a broader range of multivariate time series datasets."

## Limitations

- The method assumes the minority class distribution is unimodal, but solar flares may have multiple distinct patterns based on magnetic complexity
- While MGN shows best performance on 3 of 4 partitions, the absolute performance gains over basic methods are modest (typically 1-3% improvement in TSS/HSS2)
- The method's effectiveness depends heavily on the undersampling ratio and augmentation factor, which were fixed in this study

## Confidence

- **High Confidence**: MGN is computationally efficient compared to complex augmentation methods like warping or slicing
- **Medium Confidence**: MGN's class-based approach provides better exploration of the feature space than instance-based methods
- **Low Confidence**: The claim that MGN is universally superior to all eight baseline methods - performance varies by partition and metric

## Next Checks

1. Test MGN on synthetic datasets with known multimodal minority classes to quantify performance degradation when the unimodal assumption is violated
2. Apply paired t-tests or bootstrap confidence intervals to determine if MGN's performance improvements over baselines are statistically significant across the 10 repeated experiments
3. Systematically vary the undersampling ratio and MGN's noise parameter σ to identify optimal settings and determine if performance is robust to parameter choices