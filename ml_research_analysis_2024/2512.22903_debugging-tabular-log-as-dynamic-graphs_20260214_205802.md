---
ver: rpa2
title: Debugging Tabular Log as Dynamic Graphs
arxiv_id: '2512.22903'
source_url: https://arxiv.org/abs/2512.22903
tags:
- anomaly
- graph
- event
- detection
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents GraphLogDebugger, a dynamic graph-based framework
  for debugging tabular logs. The core idea is to model tabular logs as evolving heterogeneous
  graphs, where objects and events become nodes and their relationships become edges.
---

# Debugging Tabular Log as Dynamic Graphs

## Quick Facts
- arXiv ID: 2512.22903
- Source URL: https://arxiv.org/abs/2512.22903
- Reference count: 40
- Primary result: GraphLogDebugger models tabular logs as evolving heterogeneous graphs and uses a lightweight dynamic GNN for online anomaly detection, achieving up to 0.99 F1 and 10-100x speedups over LLM-based methods.

## Executive Summary
This paper introduces GraphLogDebugger, a dynamic graph-based framework for debugging tabular logs by modeling them as evolving heterogeneous graphs where objects and events become nodes and their relationships become edges. The framework employs a lightweight dynamic Graph Neural Network (GNN) to perform online anomaly detection by evaluating the likelihood of new connections as logs arrive. Experiments on four real-world datasets (Arxiv, HDFS, Analyst, and Landslide) demonstrate that GraphLogDebugger consistently outperforms both traditional MLP baselines and large language model (LLM)-based RAG methods in terms of detection accuracy (F1 scores up to 0.99) and efficiency (throughput >500 it/s, 10-100x faster than RAG).

## Method Summary
GraphLogDebugger represents tabular logs as dynamic heterogeneous graphs, where each log entry contributes nodes (objects, events) and edges (relationships). A lightweight dynamic GNN is trained to evaluate the likelihood of new connections, enabling real-time anomaly detection. The approach leverages temporal and structural information from logs, updating the graph incrementally as new entries arrive. By avoiding heavyweight LLM pipelines, the method achieves high throughput and scalability while maintaining strong detection accuracy across diverse log types.

## Key Results
- Achieves F1 scores up to 0.99 on four real-world tabular log datasets (Arxiv, HDFS, Analyst, Landslide).
- Demonstrates 10-100x speedup over LLM-based RAG methods, with throughput >500 it/s.
- Outperforms both traditional MLP baselines and LLM-based approaches in accuracy and efficiency.

## Why This Works (Mechanism)
GraphLogDebugger works by leveraging the inherent structure and temporal dynamics of tabular logs. By representing logs as evolving heterogeneous graphs, the framework captures complex relationships and dependencies between objects and events. The dynamic GNN is lightweight and efficient, allowing real-time updates and anomaly scoring as new log entries arrive. This graph-based representation enables the model to generalize across diverse log schemas and anomaly types, providing a scalable alternative to LLM-heavy approaches.

## Foundational Learning
- **Dynamic graph modeling**: Representing logs as evolving heterogeneous graphs allows capturing temporal and structural patterns; needed for effective anomaly detection; quick check: verify node/edge definitions on sample logs.
- **Lightweight GNN**: Using a compact GNN for online updates ensures scalability and efficiency; needed to avoid computational bottlenecks; quick check: measure inference time per log entry.
- **Online anomaly detection**: Evaluating new connections as logs arrive enables real-time debugging; needed for operational log monitoring; quick check: simulate streaming logs and measure detection latency.

## Architecture Onboarding
- **Component map**: Log entries -> Graph construction (nodes/edges) -> Dynamic GNN updates -> Anomaly scoring -> Output
- **Critical path**: Graph update (incremental node/edge addition) -> GNN inference (likelihood evaluation) -> Anomaly decision (thresholding)
- **Design tradeoffs**: Lightweight GNN vs. expressive power; real-time updates vs. full retraining; scalability vs. granularity of anomaly detection
- **Failure signatures**: Missing or incorrect node/edge definitions; GNN overfitting to specific log patterns; threshold misconfiguration leading to false positives/negatives
- **First experiments**: 1) Validate graph construction on small log sample; 2) Measure GNN inference time per log entry; 3) Test anomaly detection on known anomalies in a controlled dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Claims of "general applicability" are based on only four datasets; limited diversity and representativeness.
- No formal ablation study on graph construction choices (node types, edge definitions, feature extraction).
- Comparison with LLM methods focuses on speed and accuracy but not on explainability or adaptability to evolving log schemas.

## Confidence
- Detection accuracy and efficiency claims: **High** (strong empirical support, clear metrics)
- Scalability and generalization claims: **Medium** (limited dataset diversity, no ablation)
- Claims about advantages over LLM-based methods: **Medium** (direct comparison, but narrow scope)

## Next Checks
1. Test the framework on additional tabular log datasets from diverse domains (e.g., network security, manufacturing, finance) to confirm generalizability.
2. Perform an ablation study to identify which graph construction choices most impact detection performance.
3. Evaluate the framework's ability to adapt to schema changes and provide interpretable explanations, comparing these aspects with state-of-the-art LLM-based approaches.