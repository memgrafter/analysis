---
ver: rpa2
title: 'NeuroPictor: Refining fMRI-to-Image Reconstruction via Multi-individual Pretraining
  and Multi-level Modulation'
arxiv_id: '2403.18211'
source_url: https://arxiv.org/abs/2403.18211
tags:
- fmri
- low-level
- neuropictor
- fmri-to-image
- high-level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NeuroPictor addresses fMRI-to-image reconstruction by directly
  modulating diffusion models with fMRI signals, rather than relying on intermediate
  semantic conditioning. It employs multi-individual pretraining to learn a shared
  latent fMRI space and introduces high-level semantic guidance and low-level structural
  manipulation networks to jointly supervise the generation process.
---

# NeuroPictor: Refining fMRI-to-Image Reconstruction via Multi-individual Pretraining and Multi-level Modulation

## Quick Facts
- arXiv ID: 2403.18211
- Source URL: https://arxiv.org/abs/2403.18211
- Reference count: 40
- Primary result: Achieves state-of-the-art fMRI-to-image reconstruction with 98.8% AlexNet(2) and 99.3% AlexNet(5) accuracy on subject 1

## Executive Summary
NeuroPictor is a novel approach for reconstructing natural images from fMRI brain activity signals by directly modulating diffusion models. Unlike previous methods that rely on intermediate semantic conditioning, NeuroPictor learns a shared latent fMRI space across multiple individuals and employs separate high-level semantic guidance and low-level structural manipulation networks. Trained on approximately 67,000 fMRI-image pairs from the Natural Scenes Dataset, the method achieves state-of-the-art performance, particularly excelling in within-subject decoding with accuracy rates exceeding 98% on key metrics. The architecture enables semantic manipulation by swapping high-level features while preserving structural details.

## Method Summary
NeuroPictor processes fMRI-to-image reconstruction through a three-stage pipeline: First, an fMRI calibrated-encoding stage uses a transformer-based autoencoder trained on UK Biobank data to learn a shared latent space that normalizes individual differences across subjects. Second, a multi-subject pretraining stage fine-tunes a Stable Diffusion model with both high-level semantic guidance (via a network combining fMRI-to-text and auxiliary encoders) and low-level structural manipulation (via a feature transformation network that directly modulates U-Net feature maps). Third, single-subject refining optimizes the model for individual subjects. The approach achieves precise control by disentangling semantic and structural information, allowing for semantic editing while maintaining structural fidelity.

## Key Results
- Achieves 98.8% AlexNet(2) and 99.3% AlexNet(5) accuracy on subject 1
- SSIM of 0.385 for low-level structural consistency
- State-of-the-art performance across multiple metrics (PixCorr, Inception, CLIP, EffNet-B, SwAV)
- Enables semantic manipulation by swapping high-level features between subjects while preserving structure

## Why This Works (Mechanism)

### Mechanism 1
Multi-individual pretraining enables learning a shared latent fMRI space that generalizes across subjects. By training an autoencoder on large-scale UKB data from 40k subjects, the model learns to map diverse native-space fMRI signals into unified 2D brain activation images, creating a common representational space. The core assumption is that individual differences in brain activity patterns can be normalized through a shared latent space without losing subject-specific information.

### Mechanism 2
Direct modulation of diffusion model features with fMRI signals provides more precise control than semantic conditioning. The Low-Level Manipulation Network (LLMN) transforms fMRI representations into feature maps that directly manipulate the SD U-Net's feature maps, allowing fine-grained structural control. The core assumption is that feature-level manipulation in the diffusion model's U-Net is more effective than semantic guidance for preserving low-level details.

### Mechanism 3
Decoupling high-level semantic guidance from low-level structural manipulation enables semantic editing while preserving structure. Separate High-Level Guiding Network (HLGN) and LLMN allow swapping high-level features between subjects while maintaining low-level structure consistency. The core assumption is that high-level semantic and low-level structural information in fMRI signals are sufficiently disentangled to allow independent manipulation.

## Foundational Learning

- **Concept: Diffusion models and their conditioning mechanisms** - Needed because NeuroPictor directly modulates the generation process of diffusion models using fMRI signals rather than relying on intermediate semantic conditioning. Quick check: How does the LLMN's feature transformation technique bridge the gap between fMRI representation learning and feature map learning in diffusion models?

- **Concept: Cross-subject representation learning in neuroimaging** - Needed because the fMRI calibrated-encoding stage learns a universal latent fMRI space across multiple individuals to address individual differences. Quick check: What architectural choices in the autoencoder enable it to learn a shared latent space while preserving subject-specific information?

- **Concept: Feature disentanglement and multi-level conditioning** - Needed because NeuroPictor divides fMRI signals into high-level semantic features and low-level structural features for separate guidance. Quick check: How does the HLGN's auxiliary encoder compensate for inaccuracies in the fMRI-to-text encoder when aligning fMRI signals with CLIP text features?

## Architecture Onboarding

- **Component map**: fMRI encoder → shared latent space → HLGN (fMRI-to-text + auxiliary encoder) → LLMN (feature transformation + U-Net manipulator) → SD model → output image
- **Critical path**: fMRI → shared latent space → LLMN feature transformation → LLMN manipulator → SD U-Net → image reconstruction
- **Design tradeoffs**: Direct fMRI-to-image reconstruction vs. intermediate semantic conditioning; multi-subject pretraining vs. subject-specific fine-tuning
- **Failure signatures**: Poor low-level detail preservation (LLMN issue), semantic inconsistency (HLGN issue), poor generalization across subjects (shared latent space issue)
- **First 3 experiments**:
  1. Train fMRI encoder alone on UKB dataset and evaluate reconstruction quality of fMRI surface maps
  2. Train HLGN with fMRI-to-text encoder only and evaluate semantic alignment with CLIP text features
  3. Train LLMN with frozen SD and evaluate low-level structural manipulation capability

## Open Questions the Paper Calls Out

1. **Cross-subject generalization**: How effectively can NeuroPictor generalize to completely unseen subjects without any fine-tuning, and what are the theoretical limits of such cross-subject generalization?

2. **Optimal balance between semantic and structural guidance**: What is the optimal balance between high-level semantic guidance and low-level structural manipulation during inference, and how does this balance affect reconstruction quality for different types of visual stimuli?

3. **Integration of additional brain regions**: How does the inclusion of additional brain regions beyond the visual cortex affect reconstruction quality, and which regions provide the most complementary information to visual cortex signals?

## Limitations

- Limited empirical validation of the shared latent fMRI space's effectiveness in normalizing individual differences
- Insufficient quantitative evidence that high-level and low-level information are truly independent for meaningful disentanglement
- Performance heavily relies on subject-specific fine-tuning despite claims of cross-subject generalization

## Confidence

- **Shared Latent fMRI Space Generalization**: Low - Limited ablation evidence, relies heavily on end-to-end performance metrics
- **Direct Feature Modulation Superiority**: Medium - Novel approach with clear implementation but limited comparative analysis against alternatives
- **Feature Disentanglement for Semantic Editing**: Low - Demonstration of capability but insufficient quantitative validation of independence
- **State-of-the-Art Performance Claims**: Medium-High - Extensive metrics provided, but comparison primarily against baselines rather than concurrent methods

## Next Checks

1. **Ablation Study on Shared Space**: Train NeuroPictor without the multi-individual pretraining stage (using subject-specific fMRI encoders instead) and compare performance degradation across subjects.

2. **Feature Correlation Analysis**: Quantitatively measure the correlation between high-level semantic features and low-level structural features in the fMRI representations across subjects and image categories.

3. **Cross-Modality Transfer Test**: Evaluate NeuroPictor's performance when trained on one subject's data and tested on another subject's data without fine-tuning.