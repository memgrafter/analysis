---
ver: rpa2
title: Disjointness Violations in Wikidata
arxiv_id: '2410.13707'
source_url: https://arxiv.org/abs/2410.13707
tags:
- wikidata
- disjointness
- class
- classes
- violations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper identifies and analyzes disjointness violations in Wikidata,\
  \ a large, community-managed knowledge base. The authors develop SPARQL queries\
  \ to identify culprits\u2014classes that are subclasses of both elements of a disjointness\
  \ pair\u2014and categorize the sources of these violations."
---

# Disjointness Violations in Wikidata

## Quick Facts
- arXiv ID: 2410.13707
- Source URL: https://arxiv.org/abs/2410.13707
- Reference count: 17
- Primary result: 14,480 culprits causing 86,042 subclass violations and 9,951,333 instance violations in Wikidata's ontology

## Executive Summary
This paper analyzes disjointness violations in Wikidata, a large, community-managed knowledge base. The authors develop SPARQL queries to identify culprits—classes that are subclasses of both elements of a disjointness pair—and categorize the sources of these violations. Their systematic approach reveals thousands of violations, with the most significant involving the "gene" class being incorrectly subclassed under "abstract entity." The paper proposes solutions including better tooling, improved disjointness constructs, and community-driven fixes to reduce violations and improve consistency in Wikidata's ontology.

## Method Summary
The authors use SPARQL queries to extract disjointness pairs from Wikidata and identify culprits—most-general classes that are subclasses of both elements of a disjointness pair. They then manually examine these culprits to categorize sources of violations (local mistakes, mistakes in superclasses, incorrect disjointnesses, empty classes) and propose fixes. The analysis focuses on subclass violations but acknowledges the much larger number of instance violations. The approach systematically reduces the problem space by focusing on culprits as root causes.

## Key Results
- 14,480 culprits identified causing 86,042 subclass violations
- 9,951,333 instance violations also present in the knowledge base
- "Gene" class incorrectly subclassed under "abstract entity" causing 10,656 violations
- Violations categorized into four types based on their underlying causes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Identifying "culprits" significantly reduces the problem space for fixing disjointness violations.
- Mechanism: By focusing on the most-general classes that are subclasses of both elements of a disjointness pair, the approach reduces the number of classes that need manual inspection. Each culprit represents a root cause that, when fixed, resolves violations for all its subclasses.
- Core assumption: The culprit class is the root cause of the violation and fixing it will eliminate violations for all its subclasses.
- Evidence anchors: [abstract] "We use SPARQL queries to identify each 'culprit' causing a disjointness violation and lay out formulas to identify and fix conflicting information."
- Break condition: If a culprit class has multiple independent sources of violation, fixing one aspect may not resolve all violations.

### Mechanism 2
- Claim: Disjointness violations can be categorized and addressed based on their underlying causes.
- Mechanism: The paper identifies several types of violations (local mistakes, mistakes in superclasses, incorrect disjointnesses, empty classes) that each require different approaches for resolution. This categorization allows for targeted fixes.
- Core assumption: Violations can be accurately categorized into distinct types with identifiable causes.
- Evidence anchors: [section 5] "In our examination of the culprits we have identified several kinds of violations based on where the mistake occurs..."
- Break condition: If violations don't fit neatly into the identified categories, the categorization approach may miss important patterns.

### Mechanism 3
- Claim: SPARQL queries can efficiently identify disjointness violations and culprits in large knowledge graphs.
- Mechanism: The paper develops specific SPARQL queries to find disjoint pairs, count violations, and identify culprits. This automated approach enables systematic analysis of a large knowledge base like Wikidata.
- Core assumption: The SPARQL query engine (Blazegraph or QLever) can handle the complex queries needed to identify violations and culprits.
- Evidence anchors: [section 3] "We used a Python program that first extracts all the disjointness pairs as above and then constructs queries that counts the number of subclass and instance violations for each pair."
- Break condition: If the query performance degrades significantly with larger datasets or more complex queries, the automated approach may become impractical.

## Foundational Learning

- Concept: Disjointness in ontologies
  - Why needed here: Understanding disjointness is fundamental to grasping why violations occur and how to fix them in Wikidata.
  - Quick check question: What does it mean for two classes to be disjoint in an ontology?

- Concept: SPARQL querying
  - Why needed here: The paper's methodology relies heavily on SPARQL queries to identify violations and culprits in Wikidata.
  - Quick check question: How would you write a SPARQL query to find all subclasses of a given class in Wikidata?

- Concept: Knowledge graph structure
  - Why needed here: Understanding how Wikidata is structured as a knowledge graph is crucial for interpreting the violations and fixes proposed.
  - Quick check question: What are the key components of a knowledge graph, and how are they represented in Wikidata?

## Architecture Onboarding

- Component map: Wikidata -> SPARQL query engine (Blazegraph/QLever) -> Python program -> CSV output files

- Critical path: 1) Extract disjoint pairs from Wikidata using SPARQL 2) For each pair, count subclass and instance violations 3) Identify culprits for each pair 4) Examine culprits to determine causes and fixes 5) Apply fixes to eliminate violations

- Design tradeoffs:
  - Performance vs. completeness: Using QLever for faster queries vs. Blazegraph for more complete results
  - Manual vs. automated analysis: The need for manual examination of culprits vs. the efficiency of automated query generation
  - Scope of analysis: Focusing on subclass violations vs. including instance violations

- Failure signatures:
  - SPARQL query timeouts or errors
  - Incomplete or inconsistent results due to changes in Wikidata structure
  - Misclassification of violations due to ambiguous class definitions

- First 3 experiments:
  1. Verify the SPARQL query for extracting disjoint pairs returns expected results on a small, known dataset
  2. Test the Python program's ability to count violations for a simple disjoint pair with known violations
  3. Manually examine a small set of culprits to validate the categorization and fix approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the most effective way to improve disjointness modeling in Wikidata to reduce violations?
- Basis in paper: [explicit] The authors propose better tooling, improved disjointness constructs, and community-driven fixes.
- Why unresolved: The paper identifies potential solutions but does not provide empirical evidence on which approach would be most effective.
- What evidence would resolve it: A controlled study comparing the impact of different proposed solutions on the number of disjointness violations over time.

### Open Question 2
- Question: How can the Wikidata community be motivated to systematically fix disjointness violations?
- Basis in paper: [explicit] The authors suggest crowdsourcing fixes and mention the possibility of game-like rewards.
- Why unresolved: While the authors propose community involvement, they do not explore specific strategies to incentivize community participation in fixing violations.
- What evidence would resolve it: A pilot program testing various incentive structures (e.g., gamification, recognition systems) and measuring their impact on community engagement in fixing violations.

### Open Question 3
- Question: What are the long-term effects of implementing empty class representations in Wikidata?
- Basis in paper: [explicit] The authors introduce the concept of empty classes and suggest requiring all empty classes to be instances of "empty class".
- Why unresolved: The paper proposes this solution but does not discuss potential challenges or long-term implications of this approach.
- What evidence would resolve it: A longitudinal study tracking the impact of empty class implementation on the overall quality and consistency of the Wikidata ontology.

## Limitations

- Manual examination of culprits introduces potential subjectivity in categorization
- Study focuses only on subclass violations while acknowledging much larger number of instance violations (9,951,333)
- Paper does not provide complete reproducibility details for the SPARQL queries used

## Confidence

- Identification of culprits and violation counts: **High** - based on systematic SPARQL queries and clear methodology
- Categorization of violation sources: **Medium** - relies on manual examination which may vary between reviewers
- Proposed solutions and their effectiveness: **Medium** - while the mechanisms are sound, actual implementation and impact remain untested

## Next Checks

1. Verify the SPARQL query methodology by reproducing the culprit identification process on a small, controlled subset of Wikidata with known disjointness violations
2. Conduct a blind validation where multiple reviewers independently categorize the same set of culprits to assess inter-rater reliability
3. Implement one proposed solution (e.g., improved tooling for disjointness checks) and measure its effectiveness in reducing violations over time