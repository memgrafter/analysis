---
ver: rpa2
title: 'Prompting with Phonemes: Enhancing LLMs'' Multilinguality for Non-Latin Script
  Languages'
arxiv_id: '2411.02398'
source_url: https://arxiv.org/abs/2411.02398
tags:
- script
- languages
- performance
- language
- phonemic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the persistent performance gap between Latin
  and non-Latin script languages in large language models (LLMs), despite their multilingual
  capabilities. The core method introduces phonemic integration via prompting and
  in-context learning (ICL), leveraging phonemic transcriptions to enhance script-invariant
  representations.
---

# Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin Script Languages

## Quick Facts
- arXiv ID: 2411.02398
- Source URL: https://arxiv.org/abs/2411.02398
- Reference count: 40
- Primary result: IPA-ICL improves non-Latin script language performance by up to 15.1% relative gains

## Executive Summary
This study addresses the persistent performance gap between Latin and non-Latin script languages in large language models (LLMs) by introducing phonemic integration via prompting and in-context learning. The core method leverages phonemic transcriptions to enhance script-invariant representations, demonstrating significant improvements across multilingual tasks. Experiments with BM25 retrieval-based ICL show up to 15.1% relative performance gains for non-Latin languages and 12.6% for Latin languages compared to random retrieval. Qualitative analyses confirm that phonemic and orthographic scripts retrieve distinct examples, with mixed retrieval further boosting performance.

## Method Summary
The method integrates phonemic information into LLM inference through two approaches: direct prompting with concatenated IPA transcriptions and BM25-based in-context learning retrieval. Three retrieval strategies are implemented: Script-ICL (orthographic similarity), IPA-ICL (phonemic similarity), and Mixed-ICL (averaged scores from both). The approach uses Epitran to generate IPA transcriptions for multilingual datasets including Aya-Wiki, FLORES, and Aya-MLQA. Evaluation is conducted on Llama3-8B-Instruct and Qwen2-7B-Instruct models across 10 languages (4 non-Latin, 6 Latin), measuring performance with BLEU, chrF, and F1 metrics.

## Key Results
- IPA-ICL improves generative task performance by up to 15.1% relative gains for non-Latin script languages
- Mixed-ICL yields consistent improvements across both Latin and non-Latin languages (up to 12.6% relative gains)
- Script and IPA retrieval retrieve distinct examples with 7.8-13.5% overlap, validating orthogonal information capture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IPA-ICL improves retrieval by surfacing cross-linguistic phonological similarity that orthographic-only retrieval misses
- Mechanism: Phonemic representations capture shared sound patterns across languages (e.g., /Ã¦/s/ in "hacker" across English, Japanese, Hindi) that are masked in scripts, enabling better semantic matching in BM25 retrieval
- Core assumption: BM25 similarity scores on IPA tokenization correlate with semantic and phonological relatedness, not just lexical overlap
- Evidence anchors: [abstract] "integrating phonemic signals improves performance across both non-Latin and Latin script languages"
- Break condition: If IPA tokenization does not meaningfully differ from character-level retrieval, the mechanism collapses

### Mechanism 2
- Claim: Mixed-ICL outperforms single-script retrieval by aggregating complementary retrieval signals
- Mechanism: Script and IPA retrieval capture orthogonal information (orthographic vs phonological alignment), and averaging their scores selects examples that are both script-similar and phonemically aligned
- Core assumption: Orthographic and phonemic similarity are independent dimensions of cross-lingual relatedness
- Evidence anchors: [section] "average overlaps are low, ranging from 7.8% to 13.5%, showing that leveraging phonemic information provides distinct ICL retrieval examples"
- Break condition: If script and IPA retrieval overlap heavily, averaging provides no gain

### Mechanism 3
- Claim: Direct prompting with IPA helps by augmenting LLM's implicit phonology knowledge
- Mechanism: Concatenating IPA transcriptions primes the model to align orthographic and phonological representations, aiding in tasks where sound similarity is critical
- Core assumption: LLMs have latent phonological knowledge accessible via in-context cues
- Evidence anchors: [section] "concatenating IPA information to orthographic inputs consistently improves performance across various tasks"
- Break condition: If models rely solely on surface form, IPA addition provides no benefit

## Foundational Learning

- Concept: International Phonetic Alphabet (IPA)
  - Why needed here: IPA provides a standardized phonemic transcription system that enables script-invariant comparison across languages
  - Quick check question: Can you identify the IPA symbols for the vowels in "hacker" across English, Japanese, and Hindi?

- Concept: In-Context Learning (ICL) retrieval strategies
  - Why needed here: ICL performance depends heavily on the relevance of retrieved examples; different retrieval signals can bias the selection
  - Quick check question: What is the difference between script-only and IPA-based BM25 retrieval in terms of expected top-k overlap?

- Concept: Script vs Phoneme distinction in NLP
  - Why needed here: Understanding why written scripts obscure phonological similarity is key to motivating phonemic integration
  - Quick check question: Why might two words look very different in script but sound similar phonemically?

## Architecture Onboarding

- Component map: Original multilingual dataset -> Epitran IPA generation -> Orthographic-IPA aligned dataset -> BM25 retrieval -> Script/IPA/Mixed scores -> Prompt template -> LLM inference
- Critical path: Dataset alignment -> Retrieval -> Prompt -> LLM inference
- Design tradeoffs:
  - BM25 vs Dense: BM25 is simpler and interpretable; dense might capture deeper semantics but needs embedding models
  - Mixed aggregation: Simple averaging is robust; more complex fusion might improve but risks overfitting
  - IPA quality: Epitran is widely used but imperfect; manual curation could improve but not scalable
- Failure signatures:
  - Low IPA-retrieval gain: IPA tokenization not distinct from character tokenization
  - Mixed underperforms both: Script and IPA signals are highly correlated
  - Direct IPA prompting fails: LLM lacks phonological priors or prompt format ineffective
- First 3 experiments:
  1. Compare BM25 retrieval overlap between script-only and IPA-only on a small multilingual subset
  2. Test Mixed-ICL vs Script-ICL vs IPA-ICL on Aya-Wiki with Llama3-8B-Instruct
  3. Run ablation: Script+IPA vs Script-only vs IPA-only in direct prompting on FLORES

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does phonemic transcription integration compare to romanization in terms of effectiveness for enhancing multilingual LLM performance?
- Basis in paper: [explicit] The paper directly compares IPA and romanization in Section 6, noting that IPA-ICL retrieval consistently outperforms romanization-ICL across all evaluated tasks.
- Why unresolved: While the paper demonstrates IPA's superiority in retrieval contexts, it doesn't explore whether romanization might be more effective in other prompting paradigms or for specific language families.
- What evidence would resolve it: Systematic ablation studies comparing IPA vs romanization across different prompting strategies (direct prompting, few-shot, zero-shot) and across language families would clarify optimal phonemic representation methods.

### Open Question 2
- Question: What is the optimal balance between orthographic and phonemic information in mixed retrieval strategies for different task types?
- Basis in paper: [explicit] The paper finds that Mixed-ICL outperforms both Script-ICL and IPA-ICL alone, but doesn't investigate whether the equal weighting used is optimal or if different tasks benefit from different ratios.
- Why unresolved: The paper uses simple averaging of retrieval scores without exploring whether task-specific weighting schemes might yield better performance.
- What evidence would resolve it: Experiments varying the relative weights assigned to orthographic vs phonemic similarity scores for different task types (NLU vs NLG vs MT) would identify optimal mixing strategies.

### Open Question 3
- Question: How does the effectiveness of phonemic integration scale with model size and pretraining data composition?
- Basis in paper: [inferred] The paper notes that performance gaps persist across contemporary LLM families and explores inference-time integration, implying that pretraining with phonemic data faces data scarcity challenges, but doesn't investigate how model size affects phonemic integration effectiveness.
- Why unresolved: The experiments focus on 7-8B parameter models, leaving open questions about whether larger models with more diverse pretraining data would show different patterns of benefit from phonemic integration.
- What evidence would resolve it: Comparative studies across multiple model scales (from small specialized models to frontier LLMs) would reveal whether phonemic integration becomes more or less effective as model capacity increases.

## Limitations

- Heavy reliance on Epitran for IPA generation without validation of transcription accuracy across diverse languages
- Limited evaluation to 10 languages (4 non-Latin, 6 Latin), restricting generalizability to other script families
- Focus on 7-8B parameter models without exploring scalability to larger architectures or different pretraining regimes

## Confidence

- High Confidence: Mixed-ICL outperforms single-script retrieval (up to 15.1% relative gains) with clear quantitative metrics and multiple task evaluations
- Medium Confidence: Phonemic integration reduces Latin/non-Latin performance gap, though stronger validation with more diverse languages needed
- Low Confidence: LLMs have latent phonological knowledge accessible via IPA prompting, as this mechanism is inferred rather than directly validated

## Next Checks

1. Conduct manual verification of Epitran transcriptions for a subset of languages to establish error rates and assess impact on retrieval performance
2. Implement and evaluate a dense retrieval baseline (e.g., Contriever or sentence transformers) to determine whether BM25's limitations constrain observed gains
3. Extend experiments to include at least two additional script families (e.g., Cyrillic and Thai) to test generalizability beyond Latin/non-Latin binary