---
ver: rpa2
title: A Recurrent YOLOv8-based framework for Event-Based Object Detection
arxiv_id: '2408.05321'
source_url: https://arxiv.org/abs/2408.05321
tags:
- event
- detection
- event-based
- object
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ReYOLOv8, a recurrent object detection framework
  designed to leverage event-based camera data. The authors enhance the YOLOv8 architecture
  by incorporating recurrent blocks and truncated backpropagation through time to
  enable long-range spatiotemporal modeling.
---

# A Recurrent YOLOv8-based framework for Event-Based Object Detection

## Quick Facts
- arXiv ID: 2408.05321
- Source URL: https://arxiv.org/abs/2408.05321
- Reference count: 40
- Primary result: ReYOLOv8 achieves 5-18% mAP improvements over state-of-the-art on event-based object detection datasets

## Executive Summary
This paper introduces ReYOLOv8, a recurrent object detection framework designed to leverage event-based camera data. The authors enhance the YOLOv8 architecture by incorporating recurrent blocks and truncated backpropagation through time to enable long-range spatiotemporal modeling. To address memory efficiency and speed, they propose a novel event encoding scheme called Volume of Ternary Event Images (VTEI) that reduces data size and latency. They also introduce Random Polarity Suppression, a data augmentation technique that randomly suppresses event polarities to improve model robustness. ReYOLOv8 is evaluated on two large-scale event-based datasets, GEN1 (automotive) and PEDRo (robotics), and demonstrates superior performance compared to state-of-the-art methods.

## Method Summary
ReYOLOv8 enhances YOLOv8 with recurrent blocks using ConvLSTM layers and truncated backpropagation through time for long-range temporal modeling. The framework introduces Volume of Ternary Event Images (VTEI) encoding to efficiently represent event streams as ternary images in spatiotemporal bins. Random Polarity Suppression augments training data by randomly suppressing event polarities. The architecture modifies YOLOv8's backbone with Conv2D, C2f, and ConvLSTM blocks, maintaining PANet for feature fusion and three detection heads for different scales. Training uses SGD with momentum and RPS augmentation across sequence lengths of 11 for GEN1 and 5 for PEDRo.

## Key Results
- ReYOLOv8 achieves mAP improvements of 5%, 2.8%, and 2.5% on GEN1 across nano, small, and medium scales respectively
- On PEDRo, mAP improvements range from 9% to 18% while models are 14.5x to 3.8x smaller and 1.67x faster on average
- VTEI encoding reduces data size by 2.95x and achieves 1.54x average speed-up over stacked histograms

## Why This Works (Mechanism)

### Mechanism 1: VTEI Encoding Efficiency
VTEI stores only the latest event polarity per spatiotemporal bin using binary values (+1, -1, 0), reducing data size and latency compared to voxel grids and stacked histograms. This works because event stream sparsity ensures the latest event per bin is sufficient for detection. The approach emerges as top performer with 1.54x average speed-up over alternatives. The mechanism breaks when event density becomes uniform, causing loss of temporal information.

### Mechanism 2: Random Polarity Suppression
RPS randomly suppresses one polarity class in training batches, forcing the network to learn object features independent of polarity distribution. This improves robustness by simulating real-world polarity imbalance from scene lighting or camera bias. Improvements occur up to 12.5% suppression probability with balanced p=0.5 giving best results. The technique may add unnecessary noise if training data already has balanced polarity distribution.

### Mechanism 3: Recurrent Temporal Modeling
ConvLSTM layers integrate past hidden states with current features, capturing temporal dependencies over truncated sequences. This enables long-range temporal modeling beyond frame-based YOLOv8's capabilities. ReYOLOv8s is 1.9x slower but achieves higher mAP than non-recurrent models. The approach adds computation without benefit when temporal dependencies are weak, such as in static scenes.

## Foundational Learning

- **Event-based camera data structure**: Events are represented as (x, y, polarity, timestamp) tuples. Understanding this structure is critical for designing appropriate encodings and augmentations. Quick check: What is the dimensionality of an event tuple and what does polarity represent?

- **Recurrent neural network training with truncated backpropagation through time**: ReYOLOv8 uses ConvLSTM layers; knowing T-BPTT helps tune sequence length and avoid vanishing gradients. Quick check: Why do we reset memory states between training clips but not during validation?

- **Object detection metrics**: Performance claims use mAP@0.5:0.95; understanding these metrics is essential for interpreting results. Quick check: What confidence threshold and IoU threshold were used for evaluation?

## Architecture Onboarding

- **Component map**: Event stream → VTEI tensor (5 temporal bins) → backbone (Conv2D → C2f → ConvLSTM blocks → SPP) → PANet → three detection heads (nano, small, medium scales) → NMS post-processing

- **Critical path**: Event encoding → backbone feature extraction → recurrent temporal modeling → detection head → NMS post-processing

- **Design tradeoffs**: VTEI vs. voxel grids offers faster processing but loses event count information; recurrent vs. feed-forward provides higher mAP but slower inference; RPS augmentation improves robustness but may degrade performance if overused

- **Failure signatures**: Low mAP with high confidence indicates possible encoding mismatch or polarity imbalance; high latency despite small model suggests recurrent layers dominating compute; overfitting on validation indicates RPS too aggressive or insufficient regularization

- **First 3 experiments**: 1) Replace VTEI with voxel grid encoding and compare latency and mAP; 2) Vary RPS suppression probability (s) and polarity balance (p) to find optimal combination; 3) Test sequence length impact on mAP and runtime for each model scale

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several important areas for future research emerge from the methodology and results.

## Limitations
- Architectural specifications for ReYOLOv8n and ReYOLOv8m are incomplete, limiting exact reproduction
- VTEI encoding assumes event sparsity which may not hold for all scenarios
- Performance comparisons are limited to two specific datasets, leaving generalizability uncertain

## Confidence
- **High confidence**: VTEI encoding benefits and RPS augmentation improvements are well-supported by ablation studies
- **Medium confidence**: Recurrent architecture advantages are demonstrated but could benefit from more extensive ablation on sequence length effects
- **Low confidence**: Claims about scalability across all three model variants lack complete architectural specifications

## Next Checks
1. **Architectural completeness**: Obtain or reconstruct the exact layer configurations for ReYOLOv8n and ReYOLOv8m to verify reported parameter reductions and performance metrics

2. **Generalization testing**: Evaluate ReYOLOv8 on additional event-based datasets (e.g., DSEC, MVSEC) to assess cross-dataset performance and robustness

3. **Computational overhead analysis**: Conduct detailed profiling to quantify the exact contribution of ConvLSTM layers versus VTEI encoding to the observed latency increases