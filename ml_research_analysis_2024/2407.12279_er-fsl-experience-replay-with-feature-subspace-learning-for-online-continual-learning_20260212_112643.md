---
ver: rpa2
title: 'ER-FSL: Experience Replay with Feature Subspace Learning for Online Continual
  Learning'
arxiv_id: '2407.12279'
source_url: https://arxiv.org/abs/2407.12279
tags:
- learning
- feature
- samples
- data
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of catastrophic forgetting in
  online continual learning (OCL), where deep neural networks struggle to retain knowledge
  from old data while adapting to new data. The proposed ER-FSL method learns current
  samples in a feature subspace while replaying buffered samples in a larger feature
  space to mitigate forgetting.
---

# ER-FSL: Experience Replay with Feature Subspace Learning for Online Continual Learning

## Quick Facts
- arXiv ID: 2407.12279
- Source URL: https://arxiv.org/abs/2407.12279
- Authors: Huiwei Lin
- Reference count: 40
- Primary result: ER-FSL achieves up to 2.2% higher accuracy on Split CIFAR100 compared to strongest baselines

## Executive Summary
ER-FSL addresses catastrophic forgetting in online continual learning by learning current samples in a feature subspace while replaying buffered samples in a larger accumulated feature space. The method learns new tasks in a subset of feature dimensions, preventing significant alterations to old class representations, while replaying old samples across all previously learned subspaces to maintain historical knowledge. Experiments on CIFAR10, CIFAR100, and MiniImageNet demonstrate consistent improvements over state-of-the-art methods, with particular effectiveness in balancing performance across learning stages.

## Method Summary
ER-FSL implements experience replay with a novel feature subspace learning approach. The model maintains a memory buffer storing past samples and uses a subspace selection mechanism to allocate feature dimensions for learning new tasks. When learning new data, the model operates in a reduced-dimensional subspace, while replay occurs in the accumulated feature space containing all previously learned subspaces. The method includes a subspace reuse mechanism that selects underutilized dimensions based on classifier weight variance when no blank subspace is available. The learning process combines a learning loss on current samples in the subspace and a replay loss on buffered samples in the accumulated space, balanced by a scaling factor Œ≥.

## Key Results
- ER-FSL achieves up to 2.2% higher accuracy on Split CIFAR100 compared to the strongest baseline
- The method shows consistent improvements across all learning stages, not just final performance
- ER-FSL effectively balances performance on both new and old classes, reducing catastrophic forgetting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning in a feature subspace prevents catastrophic forgetting by limiting the model's capacity to alter old feature representations.
- Mechanism: When the model learns current samples in a reduced-dimensional subspace, it can only modify features within that subspace. This constraint prevents the model from significantly altering the feature representations of old classes that reside in the larger accumulated feature space.
- Core assumption: Old classes' features are primarily stored in dimensions outside the current learning subspace.
- Evidence anchors:
  - [abstract]: "Learning in a feature subspace is sufficient to capture novel knowledge from new data while replaying in a larger feature space provides more feature space to maintain historical knowledge from old data."
  - [section]: "Learning current samples across the feature whole-space is not necessary. As illustrated in Figure 2 (a) and (b), only a subset of the features are useful for new classes within the feature whole-space."
  - [corpus]: Weak evidence - no direct supporting papers found in neighbor corpus.
- Break condition: If old class features are not adequately separated from new class features in the accumulated space, or if the subspace becomes too small to capture sufficient discriminative information for new classes.

### Mechanism 2
- Claim: Replaying buffered samples in the accumulated feature space maintains old class knowledge by providing more feature dimensions for representation.
- Mechanism: By replaying old samples in the full accumulated space (all previously learned subspaces combined), the model can preserve and strengthen feature representations for old classes across many dimensions, preventing them from being forgotten.
- Core assumption: More feature dimensions allow for better preservation of complex feature representations for old classes.
- Evidence anchors:
  - [abstract]: "Replaying in a larger feature space provides more features of old data for the model to retain historical knowledge from old data."
  - [section]: "Replaying buffered samples with a larger feature space than the one for learning can improve the ability of anti-forgetting for the model."
  - [corpus]: Weak evidence - no direct supporting papers found in neighbor corpus.
- Break condition: If the accumulated space becomes too large relative to the amount of old data, leading to overfitting or inefficient use of parameters.

### Mechanism 3
- Claim: The subspace reuse mechanism allows continuous learning by efficiently utilizing previously learned feature dimensions.
- Mechanism: When no blank subspace is available for a new task, the model selects a subspace with low variance in its classifier weights, indicating that these dimensions contribute less to class discrimination and can be repurposed.
- Core assumption: Dimensions with low variance in classifier weights are less important for distinguishing between classes and can be safely reused.
- Evidence anchors:
  - [section]: "If the variance of [ùë§ 1 ùëë, ùë§ 2 ùëë, ..., ùë§ ùëê ùëë] is larger, the features on this dimension can provide richer information to distinguish between sample classes. It means that the subspaces on dimensions with small variances contribute less and can be selected for learning new tasks."
  - [corpus]: Weak evidence - no direct supporting papers found in neighbor corpus.
- Break condition: If the variance-based selection fails to identify truly unimportant dimensions, leading to degradation in performance for previously learned classes.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: Understanding why traditional training methods fail in continual learning scenarios is crucial for appreciating the need for ER-FSL's approach.
  - Quick check question: What happens to a neural network's performance on old tasks when it's trained on new data without any special techniques to prevent forgetting?

- Concept: Experience replay in continual learning
  - Why needed here: ER-FSL builds upon the experience replay framework, so understanding how replay-based methods work is essential.
  - Quick check question: How does experience replay help mitigate catastrophic forgetting in continual learning?

- Concept: Feature space dimensionality and representation
  - Why needed here: The core innovation of ER-FSL relies on manipulating feature space dimensions, so understanding how features are represented and used is crucial.
  - Quick check question: Why might learning in a reduced-dimensional subspace be sufficient for distinguishing new classes, even if the full feature space is larger?

## Architecture Onboarding

- Component map: Memory Buffer -> Feature Extractor (CNN) -> Classifier -> Subspace Selection Module -> Loss Function
- Critical path:
  1. Receive new data batch
  2. Update memory buffer with reservoir sampling
  3. Select appropriate feature subspace for learning
  4. Compute learning loss on new data in subspace
  5. Compute replay loss on buffered data in accumulated space
  6. Backpropagate combined loss
  7. Update model parameters

- Design tradeoffs:
  - Subspace size vs. model capacity: Smaller subspaces reduce interference but may limit discriminative power
  - Buffer size vs. memory efficiency: Larger buffers improve forgetting prevention but increase memory usage
  - Scaling factor Œ≥: Balances learning new information vs. preserving old knowledge

- Failure signatures:
  - Increasing forgetting on old classes over time
  - Degraded performance on new classes due to overly restrictive subspace
  - Inefficient subspace reuse leading to performance drops

- First 3 experiments:
  1. Implement basic experience replay baseline on Split CIFAR100 to establish performance floor
  2. Add feature subspace learning without replay to test learning component in isolation
  3. Implement full ER-FSL with subspace reuse to validate complete approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the subspace reuse mechanism perform when the number of tasks exceeds the number of feature subspaces, and what is the optimal strategy for selecting subspaces in this scenario?
- Basis in paper: [explicit] The paper mentions that when there are no blank subspaces available, the model needs to select a portion of space from the previously learned space for new tasks using a subspace reuse mechanism.
- Why unresolved: The paper does not provide empirical results on the performance of the subspace reuse mechanism when the number of tasks is large or when multiple tasks need to reuse the same subspace.
- What evidence would resolve it: Experiments comparing different subspace reuse strategies (e.g., random selection, variance-based selection) and their impact on performance as the number of tasks increases would provide insights into the optimal approach.

### Open Question 2
- Question: How does the scale factor ùõæ in the loss function (Equation 5) affect the balance between learning new knowledge and preserving old knowledge, and what is the optimal value for different datasets and scenarios?
- Basis in paper: [explicit] The paper mentions that the scale factor ùõæ is vital to balance the novel and historical knowledge, but does not provide a systematic study on its impact.
- Why unresolved: The paper only shows the performance of ER-FSL with a fixed ùõæ value and does not explore the sensitivity of the model to different ùõæ values or provide guidance on selecting the optimal ùõæ for different scenarios.
- What evidence would resolve it: A comprehensive study varying ùõæ across a range of values and analyzing its impact on performance for different datasets and buffer sizes would help determine the optimal value and its sensitivity.

### Open Question 3
- Question: How does the performance of ER-FSL compare to other state-of-the-art methods when the buffer size is small, and what are the limitations of the method in such scenarios?
- Basis in paper: [explicit] The paper mentions that ER-FSL is not optimal on Split CIFAR10 when the buffer size is smaller, but does not provide a detailed analysis of its performance with small buffers or compare it to other methods in this setting.
- Why unresolved: The paper focuses on the performance of ER-FSL with larger buffer sizes and does not provide a thorough comparison with other methods when the buffer size is limited, which is a common scenario in real-world applications.
- What evidence would resolve it: Experiments comparing the performance of ER-FSL with other state-of-the-art methods on various datasets with small buffer sizes would help identify the limitations of the method and its competitiveness in resource-constrained scenarios.

## Limitations

- The core mechanisms lack strong theoretical grounding, with assumptions about feature subspace separation and variance-based reuse not rigorously validated
- Experimental validation is limited to image classification tasks on three datasets, leaving uncertainty about generalization to other domains
- The memory buffer management strategy (reservoir sampling for current samples, random sampling for buffered samples) is not thoroughly evaluated against alternative sampling strategies

## Confidence

- **High confidence**: The empirical results showing ER-FSL outperforming baselines on CIFAR10, CIFAR100, and MiniImageNet are well-supported by the experimental data presented.
- **Medium confidence**: The general principle that learning in subspaces while replaying in accumulated spaces can help mitigate catastrophic forgetting is plausible based on the results, though the specific mechanism remains under-validated.
- **Low confidence**: The subspace reuse mechanism based on parameter variance and the claim that old class features primarily reside outside the current learning subspace lack sufficient theoretical or empirical validation.

## Next Checks

1. Conduct an ablation study to isolate the contribution of each component (feature subspace learning, replay in accumulated space, subspace reuse) to verify that improvements are due to the proposed mechanisms rather than other factors.

2. Develop a formal theoretical analysis of why learning in subspaces while replaying in accumulated spaces prevents catastrophic forgetting, potentially through examining the geometry of feature representations and their evolution during training.

3. Test ER-FSL on non-image datasets (e.g., text classification, reinforcement learning tasks) to evaluate whether the approach generalizes beyond the current experimental scope.