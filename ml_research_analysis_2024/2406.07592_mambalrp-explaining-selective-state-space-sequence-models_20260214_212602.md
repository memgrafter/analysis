---
ver: rpa2
title: 'MambaLRP: Explaining Selective State Space Sequence Models'
arxiv_id: '2406.07592'
source_url: https://arxiv.org/abs/2406.07592
tags:
- mamba
- methods
- mambalrp
- explanations
- relevance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces MambaLRP, a novel explanation method for Mamba
  models based on Layer-wise Relevance Propagation (LRP). The authors analyze how
  the conservation axiom of LBP is violated in different Mamba components (SiLU activations,
  selective SSMs, and multiplicative gates) and propose specific adjustments to restore
  conservation.
---

# MambaLRP: Explaining Selective State Space Sequence Models

## Quick Facts
- arXiv ID: 2406.07592
- Source URL: https://arxiv.org/abs/2406.07592
- Authors: Farnoush Rezaei Jafari; Grégoire Montavon; Klaus-Robert Müller; Oliver Eberle
- Reference count: 40
- One-line primary result: MambaLRP achieves faithfulness scores (∆AF) ranging from 1.248 to 4.234 across tasks while maintaining computational efficiency comparable to Gradient×Input.

## Executive Summary
This work introduces MambaLRP, a novel explanation method for Mamba models based on Layer-wise Relevance Propagation (LRP). The authors analyze how the conservation axiom of LBP is violated in different Mamba components (SiLU activations, selective SSMs, and multiplicative gates) and propose specific adjustments to restore conservation. Their method outperforms existing approaches (Gradient×Input, SmoothGrad, Integrated Gradients, AttnRoll, G×AttnRoll, and naive LRP) on four text classification datasets and ImageNet, achieving faithfulness scores (∆AF) ranging from 1.248 to 4.234 across tasks. MambaLRP also enables practical use cases like uncovering gender bias in medical bios datasets and analyzing long-range dependency capabilities through needle-in-a-haystack tests. The approach is theoretically sound, computationally efficient (runtime comparable to Gradient×Input), and provides more focused explanations than baseline methods.

## Method Summary
MambaLRP is an explanation method that adapts Layer-wise Relevance Propagation for Mamba selective state space sequence models. The method identifies and fixes conservation violations in three key Mamba components: SiLU activations, selective state space models, and multiplicative gates. By applying specific propagation rules to these components—including detach operations and half-relevance propagation—MambaLRP restores the conservation axiom while maintaining computational efficiency. The approach can be implemented through a single forward and backward pass, making it as efficient as gradient-based methods while providing more faithful explanations.

## Key Results
- MambaLRP achieves faithfulness scores (∆AF) ranging from 1.248 to 4.234 across SST-2, Medical BIOS, Emotion, and SNLI datasets
- Runtime comparable to Gradient×Input while providing significantly better explanation quality
- Successfully uncovers gender bias in medical bios dataset and analyzes long-range dependency capabilities on HotpotQA
- Outperforms baseline methods including AttnRoll and G×AttnRoll on both text and vision tasks

## Why This Works (Mechanism)

### Mechanism 1: SiLU Conservation Violation
The standard LRP gradient rule for SiLU activations includes an extra term from the sigmoid derivative that breaks conservation. The function y = x·σ(x) produces a residual term ε = (∂f/∂y)·σ'(x)·x² during gradient propagation, violating R(x) = R(y) when non-zero. This occurs for most inputs except when x = 0 or x → ±∞.

### Mechanism 2: Selective SSM Conservation Failure
Input-dependent parameters θt = (Āt, Bt, Ct-1) in selective SSMs create non-local relevance propagation. When propagating relevance from output yt to input xt, the gradient ∂θt/∂xt introduces coupling between xt and θt, violating conservation: R(xt) + R(ht-1) ≠ R(ht) + R(yt-1). Conservation would hold if θt were made constant with respect to xt.

### Mechanism 3: Multiplicative Gate Quadratic Mapping
The gate operation y = zA·zB creates a quadratic relationship where standard gradient propagation yields R(x) = R(y) + ε, representing spurious relevance doubling. The quadratic mapping distorts relevance attribution, making simple gradient propagation unreliable. Conservation would hold if one term in the product were treated as constant (0.5·[zA·zB]cst + 0.5·zA·zB).

## Foundational Learning

- **Concept: Layer-wise Relevance Propagation (LRP)**
  - Why needed here: LRP forms the theoretical foundation for MambaLRP, providing the conservation axiom that guides the method's design.
  - Quick check question: What is the conservation axiom in LRP and why is it important for faithful explanations?

- **Concept: Selective State Space Models (SSMs)**
  - Why needed here: Understanding SSM architecture is crucial for identifying where conservation violations occur and how to fix them.
  - Quick check question: How do selective SSMs differ from standard SSMs in terms of parameter dependence on input?

- **Concept: Gradient-based attribution methods**
  - Why needed here: MambaLRP builds upon gradient-based methods like Gradient×Input, so understanding their limitations is essential.
  - Quick check question: What are the main limitations of gradient-based attribution methods that MambaLRP aims to address?

## Architecture Onboarding

- **Component map:** Input embedding → RMSNorm → Linear → SiLU → Linear → SiLU (gate) → Selective SSM → Linear → Output
- **Critical path:** Identify conservation violations in SiLU, selective SSM, and multiplicative gate → Apply detach operations to restore conservation → Use Gradient×Input on modified model to generate explanations
- **Design tradeoffs:** Detaching parameters vs. modifying propagation rules (simpler but may lose information); Half-relevance propagation vs. full detachment in multiplicative gate (half-relevance preserves directionality better); Generalized LRP-γ rule in convolution layers (improves signal-to-noise ratio but adds complexity)
- **Failure signatures:** Conservation violation (output score ≠ sum of input relevance scores); Noisy explanations (high variance in relevance scores across similar inputs); Focus issues (explanations highlighting irrelevant features or missing important ones)
- **First 3 experiments:** 1) Verify conservation property on simple Mamba-130M model with SST-2 dataset; 2) Compare explanation faithfulness using ∆AF metric against baseline methods; 3) Test ablation study by removing each proposed propagation rule to measure impact on faithfulness

## Open Questions the Paper Calls Out

### Open Question 1
How does MambaLRP's conservation property enforcement compare to other explanation methods in terms of computational overhead?
- Basis in paper: The paper states MambaLRP's runtime is comparable to Gradient×Input and can be implemented via a single forward and backward pass, while methods like Integrated Gradients require multiple function evaluations.
- Why unresolved: While the paper provides runtime comparisons, it doesn't provide a detailed breakdown of computational overhead between different explanation methods, particularly for large-scale models.
- What evidence would resolve it: A detailed computational complexity analysis of MambaLRP compared to other explanation methods, including memory usage and runtime benchmarks for various model sizes.

### Open Question 2
Can MambaLRP be extended to explain other types of sequence models beyond Mamba, such as Transformers or RNNs?
- Basis in paper: The paper focuses on adapting LRP for Mamba models but doesn't explore its applicability to other sequence models. The conservation property analysis could be relevant for other architectures.
- Why unresolved: The paper only demonstrates MambaLRP's effectiveness on Mamba models and doesn't investigate its generalization to other sequence modeling architectures.
- What evidence would resolve it: Applying MambaLRP's conservation property analysis to other sequence models like Transformers or RNNs and evaluating its performance in explaining their predictions.

### Open Question 3
How does MambaLRP perform in explaining model predictions for tasks with long-range dependencies, such as text summarization or machine translation?
- Basis in paper: The paper demonstrates MambaLRP's ability to analyze long-range dependencies in a needle-in-a-haystack test and investigate Mamba's long-range capabilities on the HotpotQA dataset.
- Why unresolved: While the paper shows promising results on specific long-range dependency tasks, it doesn't comprehensively evaluate MambaLRP's performance on other tasks that heavily rely on long-range information, such as text summarization or machine translation.
- What evidence would resolve it: Conducting experiments using MambaLRP to explain model predictions on various tasks with long-range dependencies, such as text summarization or machine translation, and comparing its performance to other explanation methods.

## Limitations
- The conservation violation analysis relies heavily on theoretical derivations without comprehensive empirical validation across different Mamba variants
- Limited evaluation of bias detection capabilities, demonstrated with only a single example rather than systematic analysis
- Unclear whether the proposed fixes generalize to other selective state space models or different hyperparameter configurations

## Confidence
- **High Confidence:** Faithfulness score improvements (∆AF ranging from 1.248 to 4.234) and runtime comparisons are well-supported by experimental results across multiple datasets
- **Medium Confidence:** Theoretical analysis of conservation violations in SiLU, selective SSMs, and multiplicative gates is logically sound but direct empirical validation is limited
- **Low Confidence:** Claim that MambaLRP enables "uncovering bias" in medical bios datasets is demonstrated with a single example rather than systematic bias analysis

## Next Checks
1. **Conservation Verification:** Systematically measure conservation property violation across different Mamba variants (varying hidden dimensions, block sizes) to quantify how prevalent these violations are in practice
2. **Cross-Architecture Testing:** Apply MambaLRP to other selective state space models (like RWKV or S4 variants) to test whether the proposed conservation-preserving mechanisms generalize beyond the tested Mamba architectures
3. **Bias Detection Robustness:** Conduct a more comprehensive analysis of bias detection capabilities by testing MambaLRP on multiple biased datasets and comparing with alternative explanation methods for bias identification