---
ver: rpa2
title: Game-theoretic Counterfactual Explanation for Graph Neural Networks
arxiv_id: '2402.06030'
source_url: https://arxiv.org/abs/2402.06030
tags:
- banzhaf
- values
- shapley
- graph
- edges
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a non-learning-based method using Banzhaf
  values to generate counterfactual explanations for Graph Neural Networks (GNNs)
  on node classification tasks. Unlike existing learning-based approaches, this method
  computes Banzhaf values to identify the most influential edges whose removal changes
  the model's prediction.
---

# Game-theoretic Counterfactual Explanation for Graph Neural Networks

## Quick Facts
- arXiv ID: 2402.06030
- Source URL: https://arxiv.org/abs/2402.06030
- Authors: Chirag Chhablani; Sarthak Jain; Akshay Channesh; Ian A. Kash; Sourav Medya
- Reference count: 40
- One-line primary result: Banzhaf values require 4× fewer samples than Shapley values for counterfactual explanation of GNNs while maintaining robustness to noise.

## Executive Summary
This paper introduces a non-learning-based method using Banzhaf values to generate counterfactual explanations for Graph Neural Networks on node classification tasks. Unlike existing learning-based approaches, this method computes Banzhaf values to identify the most influential edges whose removal changes the model's prediction. The key innovation is using a Maximum Sample Reuse (MSR) estimator that requires 4× fewer samples than Shapley values while maintaining similar or better explanation quality. The method also incorporates a thresholding technique that provides robustness to noise while maintaining computational efficiency.

## Method Summary
The method generates counterfactual explanations for GNNs by computing Banzhaf values on edge coalitions. Given a target node, it samples coalitions of edges and evaluates the utility function (probability drop when edges are deleted) for each coalition. Using the MSR estimator, it computes Banzhaf values to identify the most influential edges. A thresholding mechanism is applied to the utility function using a hinge function to improve robustness to noise. The top-k edges with highest Banzhaf values are returned as the counterfactual explanation. The approach is evaluated on three synthetic graph datasets (BA-SHAPES, TREE-CYCLES, TREE-GRIDS) and one real-world dataset (BGS), comparing against random, top-k, greedy, and Shapley-based baselines.

## Key Results
- Banzhaf values require 4× fewer samples than Shapley values to identify top-k counterfactual edges while maintaining similar fidelity.
- The thresholding method maintains the same safety margin as non-thresholded values, providing robustness to noise.
- Banzhaf values provide both computational efficiency and robustness compared to Shapley values for counterfactual explanation generation.
- The method achieves high fidelity across three graph datasets with varying budgets (3, 4, 5 edges).

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Banzhaf values require 4× fewer samples than Shapley values to identify top-k edges.
- Mechanism: Banzhaf values use a Maximum Sample Reuse (MSR) estimator that reuses utility evaluations across all edges, while Shapley values use a Monte Carlo estimator that evaluates each edge independently.
- Core assumption: The utility function evaluations can be reused across edges without introducing significant bias.
- Evidence anchors:
  - [abstract]: "computing Banzhaf values requires lower sample complexity in identifying the counterfactual explanations compared to other popular methods such as computing Shapley values"
  - [section 4.1]: "The MSR estimator addresses the sub-optimality of the simple Monte Carlo (MC) method for estimating Banzhaf values... maximiz[ing] sample reuse and significantly reduces sample complexity"
  - [corpus]: Weak - no direct corpus evidence found for this specific sample reuse mechanism
- Break condition: If utility function evaluations are highly correlated with specific edges, sample reuse would introduce bias and reduce accuracy.

### Mechanism 2
- Claim: Thresholded Banzhaf values maintain the same safety margin as non-thresholded values, preserving robustness to noise.
- Mechanism: The thresholded utility function uses a hinge function that doesn't affect the worst-case noise analysis because in the critical cases, the utility values remain above the threshold.
- Core assumption: The worst-case scenarios for safety margin analysis occur when utility values are well above the threshold.
- Evidence anchors:
  - [abstract]: "We also design a thresholding method for computing Banzhaf values and show theoretical and empirical results on its robustness in noisy environments"
  - [section 4.3]: "Theorem 2 shows that in the worst case, the threshold doesn't have any effect on the utility function"
  - [corpus]: Weak - no direct corpus evidence found for this specific threshold-robustness relationship
- Break condition: If typical utility values fall below the threshold, the robustness guarantee may not hold.

### Mechanism 3
- Claim: Banzhaf values are more intuitive for counterfactual explanation than Shapley values.
- Mechanism: Banzhaf values represent the average marginal contribution of an edge across all coalitions, which directly corresponds to the expected drop in prediction probability, while Shapley values consider all possible orderings of coalition formation.
- Core assumption: Users can more easily interpret marginal contributions than ordered coalition contributions.
- Evidence anchors:
  - [abstract]: "we focus on another popular semivalue called Banzhaf values [4] and show that they have desirable properties such as robustness in the presence of noise and computational efficiency"
  - [section 4]: "Banzhaf values are more intuitive than Shapley values in our problem context... Banzhaf values can be more intuitive for counterfactual explanation because they can be directly seen as expected drop in the probability caused by an edge"
  - [corpus]: Weak - no direct corpus evidence found for this specific intuition claim
- Break condition: If users are more familiar with Shapley values from other applications, the intuition advantage may not materialize.

## Foundational Learning

- Concept: Cooperative Game Theory
  - Why needed here: The method uses semivalues (Banzhaf and Shapley) which are solutions from cooperative game theory for fairly distributing payoffs among players
  - Quick check question: In a cooperative game with players {A, B, C}, if the coalition {A, B} has utility 10 and coalition {A, B, C} has utility 15, what is the marginal contribution of player C to coalition {A, B}?

- Concept: Graph Neural Networks
  - Why needed here: The method explains predictions made by Graph Neural Networks on node classification tasks
  - Quick check question: In a 3-layer GCN, if node u has neighbors v1 and v2, which nodes' representations directly influence u's representation in the first layer?

- Concept: Counterfactual Explanations
  - Why needed here: The goal is to find minimal edge deletions that change the GNN's prediction, which is a form of counterfactual explanation
  - Quick check question: If a node is currently classified as class A, what would be the minimal change to make it classified as class B instead?

## Architecture Onboarding

- Component map:
  Graph Input -> GNN Model -> Utility Function -> Banzhaf Calculator -> Thresholding Module -> Top-k Selector

- Critical path:
  1. Load graph and GNN model
  2. For target node, compute initial prediction probability
  3. Sample coalitions of edges
  4. For each coalition, compute utility (probability drop)
  5. Estimate Banzhaf values using MSR estimator
  6. Apply thresholding if enabled
  7. Select top-k edges with highest Banzhaf values

- Design tradeoffs:
  - Sampling vs exact computation: Exact Banzhaf requires 2^n evaluations, sampling reduces to O(n*m) but introduces variance
  - Threshold value selection: Higher thresholds reduce noise but may miss subtle effects
  - Coalition size: Should match budget k for best results but may miss effects from larger coalitions

- Failure signatures:
  - Low fidelity values indicate explanations aren't changing predictions effectively
  - High variance in Banzhaf estimates suggests insufficient samples
  - Threshold too high results in all zero utilities, no explanations found
  - Runtime much longer than expected may indicate inefficient coalition sampling

- First 3 experiments:
  1. Verify Banzhaf vs Shapley sample complexity: Compare runtime and accuracy with increasing numbers of samples on a small synthetic graph
  2. Test thresholding effect: Run with different threshold values on a graph with injected noise, measure fidelity and runtime
  3. Validate top-k selection: Remove the top-k edges from an explanation and verify the prediction changes as expected

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the limitations section, several implicit questions emerge:

- How does the Banzhaf value-based method perform on larger, real-world graph datasets compared to the synthetic datasets tested in the paper?
- Can the Banzhaf value-based method be extended to other GNN tasks beyond node classification, such as link prediction or graph classification?
- How does the choice of threshold value (b) affect the performance of the Banzhaf value-based method in terms of fidelity, efficiency, and robustness?

## Limitations

- The theoretical claims about Banzhaf values' robustness to noise through thresholding remain weakly supported by external corpus evidence, with no direct citations found to validate the specific threshold-robustness relationship.
- The computational efficiency claims rely heavily on the MSR estimator's sample reuse mechanism, but the paper doesn't fully address potential bias introduced by this reuse.
- The intuition advantage of Banzhaf values over Shapley values is asserted but not empirically validated through user studies or preference experiments.
- The method's scalability to very large graphs remains untested, as the datasets used are relatively small (up to ~3000 nodes).

## Confidence

- **High Confidence**: The sample complexity advantage (4× fewer samples) is well-supported by the MSR estimator analysis and the mathematical derivation of sample complexity bounds. The fidelity results across three datasets provide empirical validation.
- **Medium Confidence**: The robustness claims through thresholding have theoretical backing in Theorem 2, but lack external validation and depend on specific utility function behaviors that may not generalize.
- **Low Confidence**: The claimed intuitive advantage of Banzhaf values over Shapley values lacks empirical support beyond the authors' assertions about interpretability.

## Next Checks

1. **External Robustness Validation**: Test the thresholding method on datasets with varying noise levels from different domains (e.g., social networks, biological networks) to verify that the robustness claims generalize beyond the three datasets used.

2. **Sample Reuse Bias Analysis**: Implement a variant of the MSR estimator that doesn't reuse samples and compare both accuracy and runtime to quantify the bias-variance tradeoff and validate that sample reuse doesn't compromise explanation quality.

3. **Scalability Benchmark**: Evaluate the method on graphs with 10K+ nodes to measure how the sample complexity advantage scales with graph size, and identify at what graph size the Banzhaf approach becomes computationally prohibitive compared to alternatives.