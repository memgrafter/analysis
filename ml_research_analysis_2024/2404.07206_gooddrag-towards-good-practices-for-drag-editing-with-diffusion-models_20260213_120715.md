---
ver: rpa2
title: 'GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models'
arxiv_id: '2404.07206'
source_url: https://arxiv.org/abs/2404.07206
tags:
- image
- drag
- editing
- point
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GoodDrag introduces an Alternating Drag and Denoising (AlDD) framework
  to address the accumulated perturbation issue in diffusion-based drag editing. Instead
  of performing all drag operations at once, AlDD alternates between drag and denoising
  steps within the diffusion process, resulting in more manageable changes and improved
  image fidelity.
---

# GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models

## Quick Facts
- arXiv ID: 2404.07206
- Source URL: https://arxiv.org/abs/2404.07206
- Authors: Zewei Zhang; Huan Liu; Jun Chen; Xiangyu Xu
- Reference count: 40
- Primary result: Introduces AlDD framework and IPMS approach for stable drag editing with diffusion models

## Executive Summary
GoodDrag addresses the accumulated perturbation issue in diffusion-based drag editing by introducing an Alternating Drag and Denoising (AlDD) framework. Instead of performing all drag operations at once, AlDD alternates between drag and denoising steps within the diffusion process, resulting in more manageable changes and improved image fidelity. Additionally, GoodDrag proposes an information-preserving motion supervision approach to tackle feature drifting problems during point tracking. The method is evaluated on a new benchmark dataset called Drag100, which includes 100 diverse images with various drag tasks and masks.

## Method Summary
GoodDrag introduces two key innovations for diffusion-based drag editing: the Alternating Drag and Denoising (AlDD) framework and Information-Preserving Motion Supervision (IPMS). AlDD alternates between B drag operations and one denoising step during the diffusion process, preventing the accumulation of perturbations that can lead to artifacts. IPMS addresses feature drifting by maintaining the original features of the starting point throughout the editing process rather than aligning to the next handle point. The method uses LoRA fine-tuning on Stable Diffusion 1.5 and is evaluated on a new Drag100 dataset with dedicated metrics for drag accuracy (DAI) and perceptual quality (GScore).

## Key Results
- GoodDrag achieves a GScore of 7.94 on Drag100, outperforming DragDiffusion (6.87) and SDE-Drag (5.38)
- The AlDD framework improves fidelity by distributing editing across multiple diffusion time steps
- IPMS successfully prevents feature drifting, maintaining semantic content identity throughout the editing process

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Alternating Drag and Denoising (AlDD) prevents accumulated perturbations by distributing editing across multiple diffusion time steps.
- Mechanism: Instead of performing all drag operations at once followed by denoising, AlDD alternates between B drag steps and one denoising step within the diffusion process, allowing perturbations to be corrected incrementally.
- Core assumption: Large accumulated perturbations are harder to correct than smaller, incremental ones because they deviate significantly from the natural image manifold.
- Evidence anchors:
  - [abstract]: "AlDD framework that alternates between drag and denoising operations within the diffusion process, effectively improving the fidelity of the result."
  - [section 3.3]: "Existing methods typically conduct all drag operations at once and then attempt to correct the accumulated perturbations subsequently. However, this approach often leads to perturbations that are too substantial to be well-corrected."
- Break condition: If B is set too large (many drag steps before denoising), accumulated perturbations may become too large to correct effectively, defeating the purpose of AlDD.

### Mechanism 2
- Claim: Information-Preserving Motion Supervision (IPMS) prevents feature drifting by maintaining consistency between the handle point and its original appearance throughout the editing process.
- Mechanism: Instead of aligning the current handle point's features to the next handle point (which can accumulate drift), IPMS aligns the next handle point to the original handle point's features, preserving the semantic content identity.
- Core assumption: Small drifts in each iteration compound over time, causing significant deviation from the original semantic content, which leads to artifacts and inaccurate point movement.
- Evidence anchors:
  - [section 3.4]: "The root cause of handle point drifting lies in the design of the motion supervision loss... Consequently, even minor drifts in one iteration can accumulate over time during motion supervision, leading to significant deviations and distorted outcomes."
- Break condition: If the optimization becomes too difficult due to larger feature distances (as mentioned in the paper), the method may fail to move the handle point effectively unless multiple motion supervision steps are employed.

### Mechanism 3
- Claim: Using Large Multimodal Models (LMMs) for quality assessment provides more reliable and perceptually aligned evaluation than traditional NR-IQA methods.
- Mechanism: GScore uses LMMs (specifically Gemini) to evaluate perceptual quality by prompting the model to rate edited images on a 0-10 scale, leveraging the model's training on internet-scale vision and language data.
- Core assumption: LMMs trained on diverse internet data develop perceptual understanding that better aligns with human judgment than handcrafted features or limited training sets used in traditional NR-IQA methods.
- Evidence anchors:
  - [section 4.2]: "We leverage the advancements in Large Multimodal Models (LMMs) and introduce GScore, a new metric for assessing the quality of drag edited images... We utilize LMMs as evaluators, providing them with the edited image and the original input image as a reference."
  - [section 5.3]: "While TReS, MUSIQ, and TOPIQ exhibit low (or even negative) correlations, GScore demonstrates a much higher correlation with the human visual system, indicating the effectiveness of GScore for assessing the perceptual quality of drag editing results."
- Break condition: If the LMM's evaluation criteria don't align well with human perceptual preferences for the specific task of drag editing, the metric may not be reliable.

## Foundational Learning

- Concept: Diffusion models and their reverse process
  - Why needed here: GoodDrag builds upon diffusion models for image generation and editing, so understanding how they work is fundamental to implementing the AlDD framework.
  - Quick check question: What is the key difference between the forward process and reverse process in diffusion models, and how does DDIM improve efficiency?

- Concept: Feature alignment and interpolation in U-Net features
  - Why needed here: The motion supervision operation relies on extracting and aligning features from the U-Net to guide content movement, which requires understanding how features are extracted and interpolated.
  - Quick check question: How does the feature extractor Uθ work with the interpolation function I to align features during motion supervision?

- Concept: Point tracking and feature similarity search
  - Why needed here: After each drag operation, the new handle point location must be determined by finding the location most similar to the original point, which requires understanding feature similarity metrics.
  - Quick check question: What is the mathematical formulation for finding the new handle point location in Eq. 6, and why is this approach effective?

## Architecture Onboarding

- Component map: Source image z0 -> U-Net Uθ with LoRA fine-tuning -> DDIM inversion -> Loop through K drag operations with alternating denoising (AlDD) -> Motion supervision with IPMS -> Point tracking to update handle point locations -> Final denoising steps -> Edited image ˆz0

- Critical path:
  1. LoRA fine-tuning of U-Net on z0
  2. DDIM inversion to get zT
  3. Loop through K drag operations with alternating denoising (AlDD)
  4. Motion supervision with IPMS (multiple steps per drag)
  5. Point tracking to update handle point locations
  6. Final denoising steps to get ˆz0

- Design tradeoffs:
  - AlDD vs. single-step editing: Better fidelity vs. potentially more computation (though AlDD doesn't add overhead)
  - IPMS vs. standard motion supervision: Better feature preservation vs. harder optimization requiring multiple supervision steps
  - GScore vs. traditional metrics: Better human alignment vs. dependency on LMM availability and potential bias

- Failure signatures:
  - Poor drag accuracy: Check if feature alignment loss is too small or if point tracking fails to find correct locations
  - Artifacts and low fidelity: Check if AlDD is properly implemented (B too large) or if IPMS optimization is failing
  - Slow convergence: Check learning rate and number of motion supervision steps J

- First 3 experiments:
  1. Implement AlDD with B=1 (denoise after every drag) and verify that it improves fidelity compared to single-step editing on a simple test case
  2. Implement IPMS and compare feature distance between handle point and original point over iterations to verify drift reduction
  3. Evaluate GScore on a small set of edited images and compare rankings with human judgments to validate the metric

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of AlDD vary with different numbers of denoising steps (Tmax) in the diffusion process?
- Basis in paper: [explicit] The paper mentions using Tmax = 50 with an inversion strength of 0.75, resulting in T = 38. It also states that AlDD involves alternating between drag and denoising operations.
- Why unresolved: The paper does not explore the impact of varying Tmax on the effectiveness of AlDD. Different values of Tmax could affect the accumulated perturbations and the ability of the denoising operations to correct them.
- What evidence would resolve it: Experiments comparing the performance of AlDD with different Tmax values, such as Tmax = 30, 50, and 70, while keeping other parameters constant. Metrics like DAI and GScore should be used to evaluate the quality of the edited images.

### Open Question 2
- Question: Can the information-preserving motion supervision approach be extended to other image editing tasks beyond drag editing?
- Basis in paper: [inferred] The paper introduces the information-preserving motion supervision to address the feature drifting issue in drag editing. This suggests that similar techniques could be applied to other editing tasks where feature consistency is important.
- Why unresolved: The paper focuses on drag editing and does not explore the applicability of the information-preserving approach to other tasks. Different editing tasks may have different requirements for feature preservation.
- What evidence would resolve it: Applying the information-preserving motion supervision to other editing tasks such as image inpainting, style transfer, or object manipulation. Comparing the results with baseline methods to assess the effectiveness of the approach in preserving features and reducing artifacts.

### Open Question 3
- Question: How does the performance of GScore compare to other large multimodal models as evaluation agents?
- Basis in paper: [explicit] The paper mentions exploring the use of both GPT-4V and Gemini as evaluation agents for GScore, but selects Gemini as the primary agent due to its reliability and alignment with human visual judgment.
- Why unresolved: The paper does not provide a detailed comparison of GScore's performance using different large multimodal models. Other models might have different strengths in evaluating image quality.
- What evidence would resolve it: Conducting a study where GScore is calculated using multiple large multimodal models (e.g., GPT-4V, Gemini, and others) on the same set of edited images. Comparing the correlation of each model's scores with human visual perception rankings to determine which model provides the most reliable evaluation.

## Limitations
- The evaluation relies on a relatively small dataset of 100 images, which may not capture the full diversity of real-world drag editing scenarios.
- The GScore metric introduces dependency on LMM availability and potential bias from the model's training data.
- The method's computational efficiency compared to existing approaches is not thoroughly discussed.

## Confidence
- **High Confidence**: The AlDD framework's effectiveness in preventing accumulated perturbations is well-supported by the quantitative results (GScore 7.94 vs 6.87 for DragDiffusion) and the logical mechanism described.
- **Medium Confidence**: The IPMS approach for preventing feature drifting is theoretically sound, but the evidence is primarily based on the authors' analysis rather than extensive ablation studies or comparisons with alternative methods.
- **Medium Confidence**: The GScore metric's correlation with human judgment is demonstrated on the Drag100 dataset, but the claim of it being "more reliable" than traditional methods would benefit from larger-scale human studies across different image editing tasks.

## Next Checks
1. **Ablation Study on AlDD Parameters**: Conduct experiments varying the B parameter (number of drag steps before denoising) to empirically determine the optimal balance between fidelity and efficiency, and test the method's robustness to different B values.

2. **Cross-Dataset Generalization**: Evaluate GoodDrag on additional image datasets beyond Drag100 to assess its performance across different image types, styles, and editing scenarios, particularly focusing on images not well-represented in the current benchmark.

3. **Human Study on GScore Reliability**: Conduct a large-scale human evaluation comparing GScore rankings with human preferences across multiple image editing tasks and datasets to validate the claim that LMM-based assessment better aligns with human perceptual quality judgments.