---
ver: rpa2
title: Denoising Table-Text Retrieval for Open-Domain Question Answering
arxiv_id: '2403.17611'
source_url: https://arxiv.org/abs/2403.17611
tags:
- question
- fused
- block
- retrieval
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses challenges in table-text open-domain question
  answering, specifically dealing with false-positive labels in training data and
  the need for table-level ranking information. The proposed Denoised Table-Text Retriever
  (DoTTeR) tackles these issues by denoising the training dataset to remove false
  positives and incorporating rank-aware table encoding (RATE) to provide table-level
  ranking information.
---

# Denoising Table-Text Retrieval for Open-Domain Question Answering

## Quick Facts
- arXiv ID: 2403.17611
- Source URL: https://arxiv.org/abs/2403.17611
- Reference count: 0
- Denoised Table-Text Retriever (DoTTeR) improves retrieval recall@1 by 6.5% and boosts EM/F1 scores on OTT-QA

## Executive Summary
This paper addresses challenges in table-text open-domain question answering by tackling false-positive labels in training data and incorporating table-level ranking information. The proposed DoTTeR approach denoises the training dataset to remove false positives and introduces Rank-Aware Table Encoding (RATE) to provide table-level ranking information. Experiments on the OTT-QA dataset demonstrate significant improvements in both retrieval recall and downstream question-answering performance compared to strong baselines.

## Method Summary
DoTTeR combines dataset denoising with false-positive detection and rank-aware table encoding. A binary classification model identifies and removes false-positive fused blocks during training. RATE uses a rank-aware column encoder to identify minimum and maximum values within columns, encoding this information into block representations. The system is trained on OTT-QA using OTTeR's synthetic checkpoint and evaluated on retrieval metrics and downstream QA performance.

## Key Results
- 6.5% gain in block recall@1 compared to OTTeR baseline
- Improved EM and F1 scores in question answering
- Significant improvement in table recall@k metrics
- Effective handling of superlative reasoning questions requiring table-level information

## Why This Works (Mechanism)

### Mechanism 1: False Positive Detection and Dataset Denoising
Removing false positive fused blocks during training improves retrieval accuracy by reducing noise in supervision signals. A binary classification model scores relevance of each fused block to the question, retaining only the highest-scoring block per question for training.

### Mechanism 2: Rank-Aware Table Encoding (RATE)
Incorporating table-level ranking information improves retrieval of evidence needed for superlative reasoning across rows. A rank-aware column encoder identifies minimum and maximum values in numeric columns and generates rank embeddings concatenated with block input embeddings.

### Mechanism 3: Enhanced Block Encoding
Enhanced block encoding with rank information improves retrieval performance compared to standard fusion retrieval. The block encoder receives both standard input embeddings and rank embeddings from RATE, capturing both row-level and table-level information.

## Foundational Learning

- **False positive detection in information retrieval**: Why needed - OTT-QA lacks block-level supervision, leading to false positives when multiple fused blocks contain the answer entity. Quick check - How does the detection model differentiate between relevant and irrelevant fused blocks when both contain the answer entity?

- **Rank-aware encoding for superlative reasoning**: Why needed - Questions in OTT-QA often require superlative reasoning across table rows (e.g., "the earliest Olympic event"). Quick check - How does the rank-aware column encoder identify minimum and maximum values in a column?

- **Fusion retrieval for table-text question answering**: Why needed - OTT-QA requires reasoning across both tables and text. Fusion retrieval pre-aligns table rows with related passages, forming fused blocks that capture both modalities. Quick check - How does fusion retrieval handle token limits when encoding large tables?

## Architecture Onboarding

- **Component map**: OTT-QA dataset -> False positive detection model -> Rank-aware column encoder -> Question encoder -> Block encoder -> Cross-Block Reader -> Fused block corpus

- **Critical path**: 1) Preprocess OTT-QA to create denoised training dataset, 2) Train false positive detection model on noiseless instances, 3) Extract numeric columns from OTT-QA table corpus, 4) Train rank-aware column encoder on numeric columns, 5) Initialize question and block encoders with OTTeR checkpoint, 6) Train DoTTeR on denoised OTT-QA using RATE, 7) Evaluate retrieval performance on OTT-QA dev set, 8) Implement CBR for downstream QA evaluation

- **Design tradeoffs**: False positive detection adds complexity but improves accuracy; RATE requires additional encoding steps but captures table-level information; fusion retrieval provides strong baseline but may limit architectural flexibility

- **Failure signatures**: Retrieval recall drops significantly when denoising is disabled; retrieval recall drops significantly when RATE is disabled; retrieval recall is lower than OTTeR baseline; false positive detection model has low precision/recall

- **First 3 experiments**: 1) Evaluate false positive detection model on noiseless OTT-QA instances, 2) Evaluate rank-aware column encoder on numeric columns, 3) Compare retrieval performance with and without denoising and RATE

## Open Questions the Paper Calls Out
None

## Limitations
- False positive detection model effectiveness not thoroughly validated with precision/recall metrics
- Rank-aware column encoder verification is incomplete - no evidence provided for correct identification of min/max values
- Denoising impact quantification is unclear - gains may be from multiple factors beyond just dataset cleaning

## Confidence

- **False Positive Detection and Dataset Denoising**: Medium Confidence - plausible mechanism but effectiveness not fully validated
- **Rank-Aware Table Encoding**: Medium Confidence - novel approach but independent verification is lacking
- **Overall Performance Improvement**: High Confidence - supported by experimental results showing significant gains over baselines

## Next Checks

1. Evaluate the false positive detection model on a held-out validation set to assess its precision and recall in distinguishing relevant from irrelevant fused blocks.

2. Test the rank-aware column encoder on a set of numeric columns to verify its ability to correctly identify minimum and maximum values.

3. Conduct ablation studies comparing DoTTeR performance with and without denoising to quantify the specific contribution of dataset cleaning to overall improvements.