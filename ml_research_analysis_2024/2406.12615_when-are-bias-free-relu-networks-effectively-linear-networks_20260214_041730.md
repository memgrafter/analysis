---
ver: rpa2
title: When Are Bias-Free ReLU Networks Effectively Linear Networks?
arxiv_id: '2406.12615'
source_url: https://arxiv.org/abs/2406.12615
tags:
- relu
- networks
- linear
- learning
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how removing bias terms from ReLU networks
  affects their expressivity and learning dynamics. It proves that two-layer bias-free
  ReLU networks can only express linear functions for odd tasks, while deeper bias-free
  ReLU networks can express certain nonlinear odd functions, demonstrating a depth
  separation.
---

# When Are Bias-Free ReLU Networks Effectively Linear Networks?

## Quick Facts
- arXiv ID: 2406.12615
- Source URL: https://arxiv.org/abs/2406.12615
- Authors: Yedi Zhang; Andrew Saxe; Peter E. Latham
- Reference count: 40
- Two-layer bias-free ReLU networks can only express linear functions for odd tasks, while deeper networks can express certain nonlinear odd functions

## Executive Summary
This paper investigates when bias-free ReLU networks behave like linear networks, revealing that under specific symmetry conditions on datasets (even input distribution and odd target function), two-layer bias-free ReLU networks evolve identically to linear networks. The authors prove that two-layer bias-free ReLU networks have severely limited expressivity for odd functions - they can only express linear functions. However, deeper bias-free ReLU networks can express certain nonlinear odd functions, demonstrating depth separation. The work provides analytical solutions for learning dynamics under symmetry conditions and shows that deep bias-free ReLU networks form low-rank weight structures similar to deep linear networks when trained on even-input, linear-target datasets.

## Method Summary
The authors analyze bias-free ReLU networks through theoretical proofs and empirical validation. They establish symmetry conditions (Condition 3: even input distribution, odd target) and derive learning dynamics that reduce to linear network dynamics with specific scaling factors. The expressivity limitations are proven through decomposition of ReLU activation into linear and absolute value terms. For deep networks, they present a conjecture about rank-one and rank-two weight structures, supported by partial proofs and empirical evidence. Experiments include training networks on orthogonal and XOR datasets, comparing dynamics with linear networks, and visualizing weight structures in deep networks.

## Key Results
- Two-layer bias-free ReLU networks can only express linear functions when the task is odd
- Under symmetric datasets, two-layer bias-free ReLU networks evolve identically to linear networks (modulo scaling)
- Deep bias-free ReLU networks form low-rank weight structures similar to deep linear networks on even-input, linear-target datasets
- ReLU networks can learn nonlinear solutions when symmetry conditions are violated

## Why This Works (Mechanism)

### Mechanism 1
Under symmetric datasets (even input distribution and odd target), two-layer bias-free ReLU networks evolve identically to linear networks, modulo scaling. The symmetry ensures that averages over any half-space equal the full-space averages, enabling the ReLU network dynamics to reduce to linear dynamics with specific scaling factors (α+1)/2 for time and √2/(α+1) for weights. This holds when the dataset satisfies Condition 3 and initial weights satisfy Assumption 7 (rank-one structure with balanced positive/negative elements).

### Mechanism 2
Two-layer bias-free ReLU networks cannot express any odd function except linear functions. The ReLU activation can be decomposed into a linear term and an absolute value term. When the input distribution is even, any absolute value contributions must vanish for odd functions, leaving only linear terms. This limitation holds due to the decomposition σ(z) = (1+α)z/2 + (1-α)|z|/2 and the even input distribution.

### Mechanism 3
Deep bias-free ReLU networks form low-rank weight structures similar to deep linear networks when trained on even-input, linear-target datasets. The weights align in a rank-one structure for first/last layers and rank-two for intermediate layers, with positive/negative elements decoupled, enabling the network to implement linear functions despite the ReLU activations. This occurs when the empirical input distribution is even and the target function is linear, with weights starting from small initialization.

## Foundational Learning

- **Symmetry conditions on datasets**: Understanding even input distributions and odd target functions is crucial for knowing when bias-free ReLU networks behave like linear networks. Quick check: Given a dataset with points (x, y) and (-x, -y) for all x, what symmetry condition does this satisfy?

- **Expressivity limitations of homogeneous functions**: Bias-free ReLU networks can only express positively homogeneous functions. This limitation explains why two-layer networks cannot express certain nonlinear functions. Quick check: Why can't a bias-free ReLU network with scalar input express a quadratic function?

- **Learning dynamics in linear networks**: The paper leverages known results about linear network learning dynamics to understand bias-free ReLU networks when they behave linearly. Quick check: What is the converged solution of a linear network trained with square loss on a dataset with input covariance Σ and input-output correlation β?

## Architecture Onboarding

- **Component map**: Two-layer bias-free ReLU network consists of W1 (H×D weight matrix) and W2 (1×H weight vector) with ReLU activation. Deep networks have L layers with weight matrices W1, W2, ..., WL.

- **Critical path**: For symmetric datasets, the critical path is initialization → early phase rank-one alignment → linear dynamics → convergence to linear solution. For asymmetric datasets, the path may diverge to nonlinear solutions.

- **Design tradeoffs**: Removing bias introduces scale invariance (beneficial for some applications) but severely limits expressivity for odd functions and requires symmetry conditions for linear-like behavior.

- **Failure signatures**: Loss curves that initially match linear networks but then diverge, decision boundaries that don't align with data points, or failure to learn linearly separable but non-symmetric datasets.

- **First 3 experiments**:
  1. Train a two-layer bias-free ReLU network on a symmetric dataset (even input, odd target) and compare loss curves with a linear network.
  2. Test expressivity by attempting to learn an odd nonlinear function with a two-layer bias-free ReLU network.
  3. Train a deep bias-free ReLU network on an even-input, linear-target dataset and visualize the weight structure to check for low-rank patterns.

## Open Questions the Paper Calls Out

### Open Question 1
Under what conditions do deep bias-free ReLU networks maintain the low-rank structure described in Conjecture 11? The paper presents Conjecture 11 and Proposition 12 describing a specific low-rank structure in deep bias-free ReLU networks, but states "the proof of Conjecture 11 remains an open question." This is unresolved because the conjecture is supported by empirical evidence but lacks theoretical proof. Resolution would require a mathematical proof showing that deep bias-free ReLU networks trained from small initialization on datasets with even input distribution and linear target functions necessarily develop the proposed rank-one and rank-two structure.

### Open Question 2
What is the exact scaling relationship between the plateau duration in two-layer bias-free ReLU networks and the degree of asymmetry in datasets that violate Condition 3? Figure 6b shows the inverse of plateau duration scales approximately linearly with the deviation δ, but notes "The scaling becomes less accurate for larger δ." This is unresolved because the paper provides empirical evidence for this scaling relationship but acknowledges it breaks down for larger deviations. Resolution would require mathematical analysis or extensive empirical studies characterizing the precise relationship between δ and plateau duration across a wide range of asymmetry levels.

### Open Question 3
Do two-layer bias-free ReLU networks converge to the max-margin solution for linearly separable binary classification tasks with logistic loss on symmetric datasets, similar to their linear counterparts? While Theorem 8 establishes equivalence in learning dynamics, the paper doesn't explicitly state that bias-free ReLU networks converge to the max-margin solution for logistic loss. Resolution would require proof that the convergence properties of linear networks under logistic loss extend to bias-free ReLU networks when Condition 3 is satisfied.

## Limitations
- Results only hold under strict symmetry conditions (even input distribution, odd target function)
- Two-layer networks have severely limited expressivity, unable to learn nonlinear odd functions
- The rank structure conjecture for deep networks lacks a complete proof
- Real-world datasets rarely satisfy the exact symmetry conditions required

## Confidence
- High confidence in the two-layer expressivity limitation (linear functions only for odd tasks) based on the rigorous proof provided
- Medium confidence in the learning dynamics equivalence results, as they depend on specific symmetry conditions that may not hold in practice
- Medium confidence in the deep network rank structure conjecture due to partial proofs and empirical support but incomplete theoretical framework

## Next Checks
1. Test the learning dynamics equivalence on real-world datasets with approximate symmetry (e.g., centered images with sign-flipped labels) to evaluate practical relevance
2. Verify the rank-one/rank-two weight structure conjecture by training deep bias-free ReLU networks on various even-input datasets and analyzing the empirical weight matrices
3. Investigate the break-down of linear-like behavior by systematically relaxing the symmetry conditions and measuring when nonlinear dynamics emerge