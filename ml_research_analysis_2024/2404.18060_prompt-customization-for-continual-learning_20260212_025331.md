---
ver: rpa2
title: Prompt Customization for Continual Learning
arxiv_id: '2404.18060'
source_url: https://arxiv.org/abs/2404.18060
tags:
- prompts
- learning
- prompt
- tasks
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel prompting method called Prompt Customization
  (PC) for continual learning. The key idea is to generate instance-specific prompts
  through a linear combination of prompts from a fixed-sized codebook, instead of
  hard prompt selection.
---

# Prompt Customization for Continual Learning

## Quick Facts
- arXiv ID: 2404.18060
- Source URL: https://arxiv.org/abs/2404.18060
- Reference count: 40
- Key outcome: Proposed Prompt Customization (PC) method achieves up to 16.2% improvement in average accuracy across class, domain, and task-agnostic incremental learning tasks.

## Executive Summary
This paper introduces Prompt Customization (PC), a novel prompting method for continual learning that generates instance-specific prompts through a linear combination of prompts from a fixed-sized codebook. Unlike conventional hard prompt selection, PC employs a Prompt Generation Module (PGM) that uses attention to assign soft coefficients to codebook prompts, creating tailored prompts for each instance. The method also includes a Prompt Modulation Module (PMM) that adaptively adjusts prompt weights based on correlations with input data. Experimental results on four benchmark datasets demonstrate that PC outperforms state-of-the-art techniques by up to 16.2% in terms of average accuracy across class, domain, and task-agnostic incremental learning tasks.

## Method Summary
The Prompt Customization (PC) method consists of two main components: a Prompt Generation Module (PGM) and a Prompt Modulation Module (PMM). PGM generates instance-specific prompts by assigning soft coefficients to prompts from a fixed-sized codebook using attention mechanisms between input encodings and the codebook. PMM further modulates these prompts by computing correlations between input encodings and generated prompts, then applying adaptive weighting based on quantized correlation values. The method employs a momentum-updated codebook with orthogonality regularization to stabilize knowledge retention and reduce interference across tasks. Experiments were conducted on four benchmark datasets (CIFAR-100, ImageNet-R, Core50, DomainNet) using a frozen ViT-B/16 backbone, with training for 5 epochs per task using Adam optimizer.

## Key Results
- PC outperforms state-of-the-art techniques by up to 16.2% in average accuracy across class, domain, and task-agnostic incremental learning tasks.
- The method maintains competitive performance even with a modest codebook size of 32 prompts.
- PC demonstrates effectiveness across four benchmark datasets including CIFAR-100, ImageNet-R, Core50, and DomainNet.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instance-specific prompts generated via linear combination of a fixed-size codebook outperform hard prompt selection.
- Mechanism: PGM assigns soft coefficients to codebook prompts using attention between input encodings and the codebook, creating a tailored prompt for each instance.
- Core assumption: Attention-based soft weighting captures instance-task relevance better than one-hot task selection.
- Evidence anchors:
  - [abstract]: "In contrast to conventional methods that employ hard prompt selection, PGM assigns different coefficients to prompts from a fixed-sized pool of prompts and generates tailored prompts."
  - [section 3.3]: "PGM takes input encoding and codebook as input and generates input-specific prompts through a linear combination of prompts from a designated codebook."
  - [corpus]: Weak. No direct comparable experiments cited; the claim is mainly from internal comparison tables.
- Break condition: If the codebook becomes too large or the attention mechanism fails to differentiate task-relevant prompts, performance may degrade due to noisy coefficients.

### Mechanism 2
- Claim: Prompt modulation via correlation-based adaptive weighting improves prompt adaptiveness.
- Mechanism: PMM computes correlations between input encodings and generated prompts, then modulates prompt weights using quantized correlation values.
- Core assumption: Correlation between input and prompt reflects the prompt's usefulness for that instance.
- Evidence anchors:
  - [abstract]: "PMM further modulates the prompts by adaptively assigning weights according to the correlations between input data and corresponding prompts."
  - [section 3.4]: "PMM modulates the generated prompts through quantized correlations between input encoding and the generated prompts."
  - [corpus]: Weak. No external ablation on PMM specifically; effectiveness inferred from overall improvement over baseline.
- Break condition: If input encodings are too generic or prompt representations collapse, correlation-based modulation may fail to provide meaningful adaptation.

### Mechanism 3
- Claim: Momentum-updated codebook with orthogonality regularization stabilizes knowledge retention.
- Mechanism: Codebook is updated using momentum optimization and constrained by an orthogonality loss to aggregate task information while reducing interference.
- Core assumption: A shared codebook can capture common task features and reduce forgetting without task-specific isolation.
- Evidence anchors:
  - [section 3.5]: "we employ a momentum optimization [49]. We define Mtâˆ’1â€² at task tâˆ’1 as an ensemble of the current version at task tâˆ’1 and earlier versions of codebook M..."
  - [section 3.5]: "we also add an orthogonality constraint as: Lð‘œð‘Ÿ = ||MMT âˆ’ I||Â²"
  - [corpus]: Weak. Momentum-based codebook update is common but specific to this prompt-based CL setting is not externally validated.
- Break condition: If orthogonality constraint is too strong, it may hinder codebook adaptation to new tasks.

## Foundational Learning

- Concept: Attention mechanisms for soft selection
  - Why needed here: Enables instance-specific prompt generation instead of rigid task assignment.
  - Quick check question: What does the attention score between an input encoding and a codebook prompt represent?

- Concept: Momentum-based parameter updates for stability
  - Why needed here: Keeps codebook updates gradual to prevent catastrophic forgetting.
  - Quick check question: How does momentum optimization differ from plain SGD in this context?

- Concept: Orthogonal regularization to reduce interference
  - Why needed here: Ensures codebook prompts remain distinct and non-redundant across tasks.
  - Quick check question: What effect does enforcing MMT â‰ˆ I have on the codebook matrix?

## Architecture Onboarding

- Component map:
  Input -> Backbone (frozen ViT) -> Input encoding -> PGM: Attention -> Coefficients -> Linear combination with codebook -> Instance prompts -> PMM: Projections -> Correlation matrix -> Sigmoid scaling -> Modulated prompts -> Prompts inserted into MHSA layers -> Classification head -> Loss (CE + orthogonality + momentum)

- Critical path:
  1. Encode input with frozen backbone.
  2. PGM generates instance-specific prompts.
  3. PMM modulates prompts based on correlations.
  4. Insert modulated prompts into MHSA layers.
  5. Compute classification loss and update only PGM/PMM/codebook.

- Design tradeoffs:
  - Fixed codebook size vs. task diversity: smaller codebook is more efficient but may lack expressiveness.
  - Soft weighting vs. hard selection: more flexible but requires careful attention design.
  - Prompt modulation vs. direct use: adaptive but adds computation.

- Failure signatures:
  - Performance drops if codebook becomes too generic (loss of task specificity).
  - If PMM weights collapse toward zero, modulation becomes ineffective.
  - If attention scores become uniform, prompt generation loses instance specificity.

- First 3 experiments:
  1. Verify PGM produces varied prompts per instance by visualizing t-SNE of generated prompts.
  2. Test PMM's effect by comparing with and without modulation on a held-out task.
  3. Check stability by training on increasing number of tasks and monitoring forgetting.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Prompt Customization (PC) method perform on multimodal datasets compared to unimodal datasets?
- Basis in paper: [inferred] The paper mentions adapting the method to "other multimedia or multimodal datasets" as future work, suggesting potential differences in performance.
- Why unresolved: The paper only evaluates PC on visual datasets (CIFAR-100, ImageNet-R, CORe50, DomainNet) and does not explore its effectiveness on multimodal data.
- What evidence would resolve it: Conducting experiments comparing PC's performance on multimodal datasets (e.g., audiovisual data, text-image pairs) against unimodal datasets would provide insights into its generalizability across different data modalities.

### Open Question 2
- Question: What is the impact of varying the size of the prompt pool (codebook) on the performance of PC?
- Basis in paper: [explicit] The paper mentions that PC maintains competitive performance even with a modest codebook size of 32, but the optimal size is determined to be 256.
- Why unresolved: While the paper explores the impact of codebook size on performance, it does not investigate the effects of using a larger or smaller prompt pool than the determined optimal size.
- What evidence would resolve it: Conducting experiments with prompt pool sizes smaller than 32 and larger than 256, and comparing the performance of PC across these different sizes, would provide insights into the sensitivity of PC to the prompt pool size.

### Open Question 3
- Question: How does the proposed Prompt Generation Module (PGM) compare to other prompt generation techniques in terms of computational efficiency and performance?
- Basis in paper: [inferred] The paper mentions that PC outperforms CODA-P with only an appropriate quarter training time, suggesting that PGM is computationally efficient. However, it does not compare PGM to other prompt generation techniques.
- Why unresolved: The paper does not provide a comprehensive comparison of PGM with other prompt generation techniques in terms of computational efficiency and performance.
- What evidence would resolve it: Conducting experiments comparing the computational efficiency and performance of PGM with other prompt generation techniques (e.g., prefix tuning, soft prompt tuning) would provide insights into the relative strengths and weaknesses of PGM.

## Limitations
- The paper lacks ablation studies isolating the contributions of individual components (PGM, PMM, momentum-updated codebook).
- The effectiveness of PMM's correlation-based modulation and the exact impact of the orthogonality constraint are not well-supported by ablation evidence.
- The paper does not provide a comprehensive comparison of PGM with other prompt generation techniques in terms of computational efficiency and performance.

## Confidence
- **High Confidence**: The overall architecture description and experimental setup (datasets, metrics, training procedure) are clearly specified and reproducible.
- **Medium Confidence**: The general approach of using attention-based soft prompt selection is theoretically sound, though the specific implementation details are underspecified.
- **Low Confidence**: The effectiveness of PMM's correlation-based modulation and the exact impact of the orthogonality constraint are not well-supported by ablation evidence.

## Next Checks
1. **Component Ablation Study**: Remove PMM from the full pipeline and retrain on CIFAR-100 (5 tasks) to quantify its contribution to the 16.2% improvement claim. Compare average accuracy with and without PMM to determine if prompt modulation is essential.

2. **Codebook Size Sensitivity**: Vary the codebook size (e.g., 8, 16, 32 prompts) on ImageNet-R (10 tasks) to test the claim that a fixed-size codebook can handle diverse tasks. Measure performance degradation or stability as codebook capacity changes.

3. **Orthogonality Constraint Analysis**: Train the model on DomainNet with orthogonality loss weight Î» set to 0 (no constraint) versus the reported value. Compare forgetting metrics to verify that orthogonality regularization meaningfully reduces catastrophic forgetting.