---
ver: rpa2
title: Geometry of naturalistic object representations in recurrent neural network
  models of working memory
arxiv_id: '2411.02685'
source_url: https://arxiv.org/abs/2411.02685
tags:
- memory
- object
- should
- information
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how recurrent neural networks (RNNs) represent
  naturalistic objects in working memory across different cognitive tasks. Using sensory-cognitive
  models combining CNNs and RNNs trained on nine N-back tasks with naturalistic stimuli,
  the authors analyze the RNN's latent space to understand object encoding, maintenance,
  and retrieval.
---

# Geometry of naturalistic object representations in recurrent neural network models of working memory

## Quick Facts
- arXiv ID: 2411.02685
- Source URL: https://arxiv.org/abs/2411.02685
- Authors: Xiaoxuan Lei; Takuya Ito; Pouya Bashivan
- Reference count: 39
- Primary result: RNNs trained on naturalistic N-back tasks reveal distinct encoding strategies, with gated architectures developing task-specific subspaces while vanilla RNNs use shared representations

## Executive Summary
This study investigates how recurrent neural networks represent naturalistic objects in working memory across different cognitive tasks. The authors develop sensory-cognitive models combining CNNs and RNNs trained on nine N-back tasks with naturalistic stimuli, then analyze the RNN's latent space to understand object encoding, maintenance, and retrieval. Key findings reveal that multi-task RNNs simultaneously encode task-relevant and irrelevant information, gated RNNs develop task-specific subspaces while vanilla RNNs use shared representations, and RNNs employ chronological memory subspaces for tracking information over time. These results provide testable predictions about neural mechanisms of working memory and demonstrate that naturalistic stimuli reveal distinct computational strategies compared to abstract inputs.

## Method Summary
The authors developed sensory-cognitive models by combining pre-trained CNNs with RNNs, creating nine N-back task variants with naturalistic stimuli. RNNs were trained on both single-task and multi-task versions of these tasks, then their latent representations were analyzed using representational similarity analysis and dimensionality reduction techniques. The study examined how different RNN architectures (vanilla RNN, GRU, LSTM) encode and maintain information, comparing representational geometries across tasks and time points. The analysis focused on understanding whether RNNs develop shared or task-specific representations, how object features are orthogonalized in latent space, and how information is tracked over time using memory subspaces.

## Key Results
- Multi-task RNNs simultaneously encode task-relevant and irrelevant information rather than selectively filtering
- Vanilla RNNs use shared representations across tasks while gated RNNs (GRU, LSTM) develop task-specific subspaces
- Object features are less orthogonalized in RNN latent space compared to perceptual representations
- RNNs employ chronological memory subspaces for tracking information over time, supporting resource-based rather than slot-based working memory models

## Why This Works (Mechanism)
The success of these models stems from their ability to capture the complex, high-dimensional nature of naturalistic stimuli while maintaining temporal dynamics necessary for working memory tasks. By combining pre-trained CNNs with RNNs, the models leverage powerful perceptual representations while learning task-specific temporal patterns. The analysis of latent space geometry reveals how information is structured and maintained over time, with different architectures employing distinct computational strategies. The use of multiple task variants allows for examining how models generalize across different working memory demands, while the focus on naturalistic stimuli provides ecological validity that abstract inputs lack.

## Foundational Learning
- **Representational Similarity Analysis (RSA)**: Measures similarity between neural representations across different conditions
  - Why needed: To quantify how information is encoded and organized in RNN latent space
  - Quick check: Can compare RSA patterns between RNNs and brain data to validate models

- **Dimensionality Reduction**: Techniques like PCA to visualize high-dimensional representations
  - Why needed: To understand the geometry of latent space and identify task-specific subspaces
  - Quick check: Should reveal distinct clustering patterns for different tasks/conditions

- **Sensory-Cognitive Integration**: Combining perceptual processing (CNN) with memory maintenance (RNN)
  - Why needed: Working memory requires both stimulus encoding and temporal tracking
  - Quick check: Model performance should correlate with ability to maintain naturalistic information

- **Task Generalization**: Training on multiple task variants to examine representational flexibility
  - Why needed: Real-world working memory involves diverse cognitive demands
  - Quick check: Multi-task models should show distinct patterns from single-task models

## Architecture Onboarding

Component Map: CNN -> RNN -> Output Layer -> Task-specific Classifier

Critical Path: Naturalistic stimulus → CNN feature extraction → RNN temporal processing → Working memory maintenance → Task output prediction

Design Tradeoffs: Pre-trained CNN vs end-to-end training balances computational efficiency with task-specific optimization; single-task vs multi-task training affects representational flexibility; different RNN architectures (vanilla, GRU, LSTM) trade simplicity for gating capabilities

Failure Signatures: Poor performance on naturalistic stimuli indicates insufficient perceptual processing; inability to maintain information across time suggests inadequate temporal dynamics; task confusion indicates insufficient representational separation

First Experiments:
1. Compare representational geometries between CNN features and RNN latent states to identify information transformation
2. Analyze temporal evolution of representations to understand maintenance mechanisms
3. Test model predictions by comparing RNN latent space organization with neural recordings during N-back tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Findings may not generalize beyond N-back tasks to other working memory paradigms
- Synthetic naturalistic stimuli may not capture full complexity of real-world visual inputs
- Computational models remain simplified abstractions of biological neural networks

## Confidence
- High: Multi-task RNNs simultaneously encode task-relevant and irrelevant information
- Medium: Gated RNNs develop task-specific subspaces versus shared representations in vanilla RNNs
- High: Chronological memory subspaces support resource-based working memory models

## Next Checks
1. Test model predictions using fMRI or electrophysiological recordings during N-back tasks with naturalistic stimuli to verify if human brain representations show similar encoding patterns
2. Apply the analytical framework to additional working memory task paradigms beyond N-back to assess generalizability of findings
3. Compare representations learned from synthetic naturalistic stimuli against those derived from real-world image datasets to evaluate ecological validity of computational models