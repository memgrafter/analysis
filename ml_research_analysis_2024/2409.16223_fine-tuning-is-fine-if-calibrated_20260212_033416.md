---
ver: rpa2
title: Fine-Tuning is Fine, if Calibrated
arxiv_id: '2409.16223'
source_url: https://arxiv.org/abs/2409.16223
tags:
- fine-tuning
- classes
- absent
- class
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Fine-tuning pre-trained models on a subset of classes often leads\
  \ to accuracy degradation on absent classes, a problem termed \"holistic transfer.\"\
  \ Surprisingly, this study finds that the fine-tuned model does not degrade features\
  \ or forget class relationships for absent classes\u2014it often improves feature\
  \ discrimination. The primary issue is biased logits toward fine-tuning classes."
---

# Fine-Tuning is Fine, if Calibrated

## Quick Facts
- arXiv ID: 2409.16223
- Source URL: https://arxiv.org/abs/2409.16223
- Reference count: 40
- Primary result: Fine-tuning pre-trained models on a subset of classes can improve feature discrimination for absent classes when calibrated post-hoc.

## Executive Summary
Fine-tuning pre-trained models on a subset of classes often leads to accuracy degradation on absent classes, a problem termed "holistic transfer." Surprisingly, this study finds that the fine-tuned model does not degrade features or forget class relationships for absent classes—it often improves feature discrimination. The primary issue is biased logits toward fine-tuning classes. A simple post-processing calibration (e.g., adding a bias term to absent-class logits) restores absent-class accuracy and even outperforms prior methods, validated across ImageNet variants, Office-Home, and VTAB datasets. This suggests fine-tuning can holistically improve downstream feature quality when calibrated, offering new directions for model adaptation.

## Method Summary
The paper proposes a post-processing calibration approach to address the holistic transfer problem in fine-tuning. First, a pre-trained model is fine-tuned on a subset of classes using standard methods. Then, calibration is applied by adding a bias term to the logits of absent classes, effectively lifting their logit scales to match those of the fine-tuning classes. The calibration factor is estimated using either Average Logit Gap (ALG) or Pseudo Cross-Validation (PCV). The calibrated model is evaluated on absent-class accuracy, showing significant improvements over fine-tuned models without calibration.

## Key Results
- Fine-tuned models often produce more discriminative features for absent classes, even without training on them.
- Biased logits toward fine-tuning classes are the primary cause of accuracy degradation on absent classes.
- Post-processing calibration can restore absent-class accuracy and outperform prior methods across multiple datasets.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning improves feature discrimination for absent classes even without training on them.
- Mechanism: During fine-tuning, absent class examples are updated based on gradients from their most similar fine-tuning class examples, which capture downstream-specific information.
- Core assumption: The gradients w.r.t. fine-tuning class data effectively encode the domain shift information that benefits absent classes.
- Evidence anchors:
  - [abstract] "the fine-tuned model often produces more discriminative features for these other classes, even if they were missing during fine-tuning"
  - [section 6] Derivation showing feature update of absent-class examples is governed by gradients w.r.t. their most similar fine-tuning class examples
  - [corpus] No direct corpus evidence found for this specific mechanism
- Break condition: If gradients w.r.t. fine-tuning class data don't capture downstream-specific information or if domain shift affects classes differently.

### Mechanism 2
- Claim: The primary issue causing accuracy degradation is biased logits toward fine-tuning classes, not feature degradation.
- Mechanism: Fine-tuning increases logit magnitudes for fine-tuning classes relative to absent classes, causing absent examples to be misclassified as fine-tuning classes.
- Core assumption: The feature extractor remains capable of distinguishing absent classes, but classifier weights become imbalanced.
- Evidence anchors:
  - [abstract] "What really hurts the accuracy is the discrepant logit scales between the fine-tuning classes and the other classes"
  - [section 4.3] Analysis decomposing softmax probability and finding biased logits as root cause
  - [section C.2] Figure 20 showing pronounced increase in weight magnitude for fine-tuning classes
- Break condition: If feature degradation occurs alongside classifier bias, or if logit imbalance doesn't exist.

### Mechanism 3
- Claim: Post-processing calibration can restore absent-class accuracy by adjusting logit scales.
- Mechanism: Adding a bias factor to absent-class logits lifts them to comparable levels with fine-tuning class logits, correcting the classification decision.
- Core assumption: The classifier's angular relationships (cosine similarity) remain valid, only magnitude needs adjustment.
- Evidence anchors:
  - [abstract] "a simple post-processing calibration (e.g., adding a bias term to absent-class logits) restores absent-class accuracy"
  - [section 5] Description of calibration approach adding factor γ to absent-class logits
  - [corpus] No direct corpus evidence found for this specific calibration mechanism
- Break condition: If angular relationships are also corrupted, or if calibration factor cannot be properly estimated without absent-class data.

## Foundational Learning

- Concept: Catastrophic forgetting in continual learning
  - Why needed here: This paper builds on and challenges the assumption that fine-tuning causes catastrophic forgetting of absent classes
  - Quick check question: If fine-tuning truly caused catastrophic forgetting, what would you expect to see in the absent-class accuracy?

- Concept: Nearest Class Mean (NCM) classifier
  - Why needed here: Used to assess feature quality independently of the corrupted classifier layer
  - Quick check question: Why is NCM particularly useful for evaluating feature quality when the classifier layer is suspect?

- Concept: Post-processing calibration techniques
  - Why needed here: The proposed solution leverages existing calibration methods to fix biased logits
  - Quick check question: What's the key difference between calibration for class imbalance vs. calibration for fine-tuning bias?

## Architecture Onboarding

- Component map: Pre-trained model → Feature extractor (θ) + Classifier weights (W) → Fine-tuning → Calibrated model
- Critical path: Fine-tuning with subset of classes → Feature extractor improvement → Classifier weight imbalance → Calibration fix
- Design tradeoffs: Full fine-tuning vs. frozen classifier vs. linear probing - each affects absent-class accuracy differently
- Failure signatures: Absent-class accuracy drops while fine-tuning-class accuracy increases; NCM accuracy for absent classes remains high or improves
- First 3 experiments:
  1. Apply NCM classifier to pre-trained vs. fine-tuned features to verify feature quality improvement
  2. Plot logit magnitudes for fine-tuning vs. absent classes during training to confirm bias development
  3. Apply calibration with different γ values to find optimal balance between seen and unseen class accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions does the feature extractor fθ improve absent-class features during fine-tuning, and can this be predicted theoretically?
- Basis in paper: [explicit] The paper shows that fine-tuning with a subset of classes can improve absent-class features, even when absent-class data is not used, but the exact conditions for this improvement are not fully characterized.
- Why unresolved: While the paper offers a preliminary explanation based on gradients from similar fine-tuning classes, the theoretical understanding of when and why feature improvements occur remains incomplete.
- What evidence would resolve it: Controlled experiments varying the similarity between fine-tuning and absent classes, and a theoretical model predicting feature improvement based on class relationships and gradient directions.

### Open Question 2
- Question: Can the proposed post-processing calibration methods (ALG and PCV) be further improved to approach the theoretical upper bound (γ⋆), and what strategies would be most effective?
- Basis in paper: [explicit] The paper shows a gap between current calibration methods and the theoretical upper bound (γ⋆), suggesting room for improvement.
- Why unresolved: The current calibration methods rely on estimates that do not fully capture the optimal bias factor, leaving a performance gap.
- What evidence would resolve it: Development and testing of advanced calibration strategies that better estimate the logit bias or incorporate additional information about the absent classes.

### Open Question 3
- Question: How does the unique data distribution in benchmarks like iWildCam, where training and test sets come from different time periods, affect the performance of fine-tuning, and what strategies can mitigate these effects?
- Basis in paper: [explicit] The paper observes a decline in fine-tuning performance on iWildCam due to natural data collection bias caused by time, but does not fully explore mitigation strategies.
- Why unresolved: The impact of temporal data distribution shifts on fine-tuning is not well understood, and effective strategies to address these shifts are not identified.
- What evidence would resolve it: Experiments testing different fine-tuning strategies on datasets with temporal shifts, and analysis of how these strategies affect absent-class accuracy.

## Limitations

- The paper's central claim that fine-tuning improves feature discrimination for absent classes is supported primarily through NCM classifier evaluation, which measures feature quality independent of the corrupted classifier layer.
- The mechanism by which absent-class examples receive beneficial gradients during fine-tuning (Mechanism 1) lacks direct corpus evidence.
- The calibration approach assumes that angular relationships between features remain valid while only magnitude needs adjustment - this assumption may break down in cases of severe domain shift or when feature distributions shift substantially.

## Confidence

- **High confidence**: The finding that biased logits are the primary cause of absent-class accuracy degradation (Mechanism 2), supported by analysis decomposing softmax probabilities and weight magnitude visualizations.
- **Medium confidence**: The effectiveness of post-processing calibration to restore absent-class accuracy (Mechanism 3), validated across multiple datasets but with limited exploration of calibration parameter sensitivity.
- **Low confidence**: The claim that fine-tuning inherently improves feature discrimination for absent classes (Mechanism 1), as this relies on theoretical derivation without strong empirical validation across diverse scenarios.

## Next Checks

1. Conduct ablation studies testing the calibration approach on datasets where absent classes are semantically dissimilar from fine-tuning classes to verify the assumption about feature improvement holds broadly.
2. Perform controlled experiments isolating the effect of gradient updates on absent-class features by tracking feature space evolution during fine-tuning, comparing scenarios with and without absent-class data.
3. Test the calibration method's robustness to different fine-tuning durations and learning rates to establish the stability of the logit bias phenomenon across training configurations.