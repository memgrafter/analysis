---
ver: rpa2
title: 'PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse
  Exemplars'
arxiv_id: '2408.08869'
source_url: https://arxiv.org/abs/2408.08869
tags:
- pedal
- greedy
- decoding
- language
- output
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces PEDAL, a self-ensembling method for enhancing
  greedy decoding in large language models using diverse exemplars. PEDAL addresses
  the problem of improving the accuracy of greedy decoding while maintaining lower
  inference cost compared to self-consistency approaches.
---

# PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars

## Quick Facts
- **arXiv ID**: 2408.08869
- **Source URL**: https://arxiv.org/abs/2408.08869
- **Reference count**: 10
- **Primary result**: PEDAL achieves 1.89% accuracy improvement on SVAMP using Qwen2 and 3.89% improvement using Llama3, while processing significantly fewer output tokens than self-consistency approaches.

## Executive Summary
PEDAL introduces a self-ensembling method that enhances greedy decoding in large language models by leveraging diverse exemplars for in-context learning. The approach generates multiple candidate responses using greedy decoding with prompts based on different exemplar samples, then aggregates these candidates using the same LLM. This method achieves better accuracy than standard greedy decoding while maintaining lower inference costs compared to self-consistency approaches, processing significantly fewer output tokens while delivering measurable accuracy improvements on benchmark datasets.

## Method Summary
PEDAL constructs multiple LLM prompts by randomly sampling different exemplars for in-context learning, then runs greedy decoding on each prompt to generate candidate responses. These candidates are aggregated using the same LLM following the Universal Self Consistency (USC) approach to produce a final output. The method aims to induce diversity in model outputs through exemplar variation while using LLM-based aggregation to select the best response, achieving a balance between accuracy improvement and computational efficiency.

## Key Results
- PEDAL achieves 1.89% accuracy improvement over greedy decoding on SVAMP using Qwen2-7B-Instruct
- PEDAL achieves 3.89% accuracy improvement over greedy decoding on SVAMP using Llama-3-8B-Instruct
- PEDAL processes significantly fewer output tokens (192 vs 503 for USC on SVAMP) while maintaining better accuracy

## Why This Works (Mechanism)

### Mechanism 1 - Exemplar Diversity
PEDAL achieves better accuracy than greedy decoding by leveraging diverse exemplars to induce diversity in model outputs before aggregation. The approach constructs multiple prompts by randomly sampling different exemplars for in-context learning, then runs greedy decoding on each prompt to generate candidate responses. These candidates are aggregated using the same LLM to produce a final output. The core assumption is that diverse exemplars in prompts lead to sufficiently diverse outputs that can be effectively aggregated to improve accuracy.

### Mechanism 2 - Cost Efficiency
PEDAL achieves lower inference cost than self-consistency by generating fewer output tokens. Instead of generating long reasoning paths as in self-consistency, PEDAL uses greedy decoding which generates fewer tokens per candidate, and then aggregates with a single LLM call. The core assumption is that the cost savings from fewer output tokens outweighs any additional cost from multiple prompt generations and aggregation.

### Mechanism 3 - LLM Aggregation
LLM-based aggregation can effectively select the best response from diverse candidates without custom aggregation methods. The approach uses the same LLM to perform majority consensus aggregation, selecting the most consistent response among candidates. The core assumption is that the LLM can reliably identify the most consistent answer across diverse candidates without task-specific training.

## Foundational Learning

- **In-Context Learning (ICL) and exemplar selection**: Why needed here - PEDAL relies on constructing diverse prompts by sampling different exemplars for ICL, so understanding how exemplar choice affects model outputs is critical. Quick check - How does changing exemplars in a prompt affect the diversity and quality of LLM outputs?

- **Greedy decoding vs. sampling-based decoding**: Why needed here - PEDAL uses greedy decoding for candidate generation, so understanding its behavior and limitations compared to sampling methods is important. Quick check - What are the trade-offs between greedy decoding (deterministic, faster) and sampling methods (more diverse, potentially better quality)?

- **Self-consistency and output aggregation**: Why needed here - PEDAL's aggregation approach is based on USC, so understanding how self-consistency works and why aggregation improves accuracy is essential. Quick check - Why does aggregating multiple diverse outputs often lead to better accuracy than using a single output?

## Architecture Onboarding

- **Component map**: Exemplar selection module -> Prompt construction module -> Greedy decoding module (multiple times) -> LLM aggregation module -> Final output

- **Critical path**: Exemplar selection → Prompt construction → Greedy decoding (multiple times) → LLM aggregation → Final output

- **Design tradeoffs**:
  - Number of exemplars per prompt vs. diversity of outputs
  - Number of diverse prompts vs. inference cost
  - Aggregation strategy (majority vote vs. other methods)
  - Use of same LLM for aggregation vs. different model

- **Failure signatures**:
  - Low diversity in generated outputs despite diverse exemplars
  - Aggregation consistently selects suboptimal responses
  - Inference cost exceeds that of baseline methods
  - Accuracy improvement doesn't justify additional complexity

- **First 3 experiments**:
  1. Run PEDAL with 1, 3, and 5 diverse prompts on SVAMP dataset to measure impact of prompt count on accuracy and cost
  2. Compare PEDAL against baseline methods (greedy decoding, USC) on ARC dataset with both Qwen2 and Llama3 models
  3. Test PEDAL with different numbers of exemplars per prompt (1, 2, 3) to find optimal balance between diversity and performance

## Open Questions the Paper Calls Out

- **Performance scalability**: How does PEDAL's performance scale with larger datasets and more complex tasks beyond elementary math word problems and basic multiple-choice questions? The paper mentions plans to explore extending PEDAL to "a wider range of problem settings involving free-form text generation" in future work, but current experiments are limited to SVAMP and ARC datasets.

- **Optimal prompt number**: What is the optimal number of diverse prompts to use in PEDAL for different types of tasks, and how does this affect the trade-off between accuracy and inference cost? The paper notes that "slight improvements" were observed as the number of prompts increased for SVAMP, but "no specific pattern" was found for ARC, with experiments only varying between 2, 3, and 4 prompts.

- **Comparison with Chain-of-Thought**: How does PEDAL's performance compare to Chain-of-Thought (CoT) reasoning in practical, real-world applications? The paper suggests that PEDAL may be more cost-efficient than CoT in some cases but provides only preliminary comparisons and calls for further investigation.

- **Llama3 performance issues**: What are the specific reasons for USC's unexpectedly poor performance with Llama3 on the ARC dataset, and how can this be addressed? The paper notes that USC achieved "relatively the least" accuracy among the strategies with Llama3 on ARC but states that a deeper analysis is left for future work.

## Limitations
- The exemplar selection mechanism and prompt construction details are not fully specified, making it difficult to assess generalizability
- The aggregation strategy relies on a black-box LLM decision without task-specific training, raising questions about reliability across different domains
- The comparison with self-consistency is based on limited datasets (SVAMP and ARC-Challenge only), and cost-efficiency claims need validation across larger-scale deployments

## Confidence

**Mechanism 1 - Exemplar Diversity (Low Confidence)**: While the paper claims diverse exemplars induce output diversity, there's no direct measurement of candidate diversity or validation that exemplar sampling actually produces meaningfully different responses.

**Mechanism 2 - Cost Efficiency (Medium Confidence)**: The token count comparisons with USC are presented with specific numbers, and the logic of fewer output tokens per candidate is sound, but cost calculations don't account for multiple prompt generations.

**Mechanism 3 - LLM Aggregation (Low Confidence)**: The paper claims the same LLM can effectively aggregate candidates without task-specific training, but provides no evidence of aggregation reliability or consistency.

## Next Checks

1. **Diversity Validation Experiment**: Measure pairwise similarity between the 3 candidate responses generated by PEDAL for each example to verify that diverse exemplars actually produce diverse outputs. Calculate average pairwise BLEU or embedding distance scores across the SVAMP and ARC datasets to quantify the diversity benefit claimed by Mechanism 1.

2. **Cost-Benefit Analysis with Full Implementation**: Implement PEDAL with the exact exemplar selection and aggregation strategy specified, then measure total inference cost (including all prompt generations and aggregation) versus greedy decoding and USC on a larger benchmark set. Compare not just token counts but actual wall-clock time and compute costs across different hardware configurations.

3. **Aggregation Reliability Test**: Run the LLM aggregation step multiple times with different seeds on the same set of candidate responses to measure consistency of the final answer selection. Calculate inter-annotator agreement scores between different LLM aggregation runs to assess whether the aggregation strategy is reliable or introduces significant variability in outputs.