---
ver: rpa2
title: Mitigating the Stability-Plasticity Dilemma in Adaptive Train Scheduling with
  Curriculum-Driven Continual DQN Expansion
arxiv_id: '2408.09838'
source_url: https://arxiv.org/abs/2408.09838
tags:
- learning
- curriculum
- tasks
- task
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the stability-plasticity dilemma in adaptive
  train scheduling, where agents must continually learn to handle changing environments
  without forgetting prior knowledge. The authors propose a curriculum-driven approach
  that sequences tasks (pathfinding, malfunction handling, deadlock avoidance) to
  progressively build agent skills.
---

# Mitigating the Stability-Plasticity Dilemma in Adaptive Train Scheduling with Curriculum-Driven Continual DQN Expansion

## Quick Facts
- **arXiv ID**: 2408.09838
- **Source URL**: https://arxiv.org/abs/2408.09838
- **Reference count**: 25
- **Primary result**: CDE achieves up to 50% improvement in completion rates compared to DQN with rehearsal in adaptive train scheduling.

## Executive Summary
This paper addresses the stability-plasticity dilemma in adaptive train scheduling, where agents must continually learn to handle changing environments without forgetting prior knowledge. The authors propose a curriculum-driven approach that sequences tasks (pathfinding, malfunction handling, deadlock avoidance) to progressively build agent skills. Their Continual Deep Q-Network Expansion (CDE) algorithm dynamically creates and prunes Q-function subspaces based on task requirements, using elastic weight consolidation to prevent catastrophic forgetting and adaptive rational activation functions for enhanced plasticity. Experimental results on the Flatland train scheduling simulator show CDE significantly outperforms standard RL baselines and other continual learning methods.

## Method Summary
CDE dynamically generates and adjusts Q-function subspaces to handle environmental changes and task requirements. The method mitigates catastrophic forgetting through Elastic Weight Consolidation (EWC) while ensuring high plasticity using adaptive rational activation functions (PAU). A curriculum is designed with adjacent skills that build on each other to improve generalization performance. The algorithm creates a sequence of subspaces, each corresponding to a new change in the agent's environment, and evaluates each subspace's performance to prune or expand accordingly.

## Key Results
- CDE achieves up to 50% improvement in completion rates compared to DQN with rehearsal
- The method demonstrates superior balance between stability and plasticity in dynamic train scheduling environments
- Curriculum sequencing of tasks (pathfinding → malfunction handling → deadlock avoidance) maximizes learning efficiency

## Why This Works (Mechanism)

### Mechanism 1
CDE dynamically creates and prunes Q-function subspaces based on task requirements, allowing for selective adaptation without destabilizing prior knowledge. When a new task arises, CDE initializes a new Q-function subspace with adaptive rational activation functions for enhanced plasticity. Simultaneously, existing subspaces are updated using elastic weight consolidation (EWC) to mitigate catastrophic forgetting. The system evaluates each subspace's performance and prunes or expands accordingly. The core assumption is that task boundaries are identifiable, and Q-function subspaces can be meaningfully partitioned to reflect task-specific knowledge.

### Mechanism 2
Adaptive rational activation functions (PAU) provide enhanced plasticity, allowing faster adaptation to new tasks compared to fixed activation functions. PAU allows the activation function shape to be learned per task, enabling the network to represent complex, non-stationary relationships in the environment. This is particularly beneficial in the newly initialized subspaces. The core assumption is that the distribution shift between tasks is significant enough to require flexible activation functions rather than fixed ones.

### Mechanism 3
Curriculum sequencing of tasks (pathfinding → malfunction handling → deadlock avoidance) maximizes learning efficiency by building on adjacent skills and minimizing catastrophic forgetting. The curriculum introduces tasks in a sequence where each new task builds on previously acquired skills, reducing the need for drastic policy changes and leveraging transfer learning. Rehearsal of earlier tasks further mitigates forgetting. The core assumption is that task dependencies exist such that simpler skills (pathfinding) are prerequisites for more complex skills (deadlock avoidance), and skill transfer is possible.

## Foundational Learning

- **Concept**: Markov Decision Process (MDP)
  - Why needed here: The paper frames train scheduling as a sequence of MDPs, each representing a task or environment state. Understanding MDPs is critical to grasping how CDE adapts Q-functions across tasks.
  - Quick check question: What are the components of an MDP, and how does CDE treat each task as a separate MDP?

- **Concept**: Catastrophic Forgetting
  - Why needed here: CDE explicitly addresses catastrophic forgetting through EWC regularization. Knowing what catastrophic forgetting is and how it manifests in neural networks is essential to understanding CDE's design choices.
  - Quick check question: How does catastrophic forgetting occur in continual learning, and why is it particularly problematic in dynamic environments like train scheduling?

- **Concept**: Activation Functions and Plasticity
  - Why needed here: CDE uses adaptive rational activation functions (PAU) to enhance plasticity. Understanding how activation functions influence network adaptability is key to grasping why CDE's plasticity mechanism works.
  - Quick check question: How do standard activation functions differ from adaptive ones like PAU, and why might the latter be more suitable for non-stationary environments?

## Architecture Onboarding

- **Component map**: Task Detection -> Q-function Subspace Initialization (with PAU) -> EWC Regularization -> Performance Evaluation -> Subspace Expansion/Pruning Logic -> Replay Buffer Management
- **Critical path**: 1. Detect new task/environment change. 2. Initialize new Q-function subspace with PAU. 3. Update existing subspaces with EWC. 4. Evaluate performance of all subspaces. 5. Prune or expand subspace set based on performance.
- **Design tradeoffs**: Subspace expansion vs. fixed network size (expansion allows task-specific adaptation but increases computational cost); EWC regularization strength (λ) (higher λ preserves old knowledge but may limit learning new tasks); PAU complexity (m, n polynomial degrees) (higher degrees offer more flexibility but increase parameter count).
- **Failure signatures**: Performance plateaus despite task changes (subspaces not adapting fast enough); sharp performance drop on previous tasks (EWC under-regularized); excessive memory usage (too many subspaces retained); high variance in performance (poor subspace selection or pruning logic).
- **First 3 experiments**: 1. Train CDE on a single task and verify that the Q-function subspace learns correctly. 2. Introduce a second task and confirm that EWC prevents catastrophic forgetting while PAU enables fast adaptation. 3. Test curriculum sequencing by training CDE on pathfinding → malfunction handling → deadlock avoidance and measuring skill retention and transfer.

## Open Questions the Paper Calls Out

### Open Question 1
How does CDE perform on curricula with significantly longer sequences of tasks or environments with continuous non-stationarity? The paper acknowledges that this work focuses on a single type of non-stationary continual learning scenario and questions how the system would perform with much longer curricula or in scenarios where non-stationarity is expressed through changing tasks like in ATARI games. Running CDE on extended curricula with more tasks or environments that continuously change, and measuring performance degradation or improvements over time, would resolve this question.

### Open Question 2
What is the optimal balance between the number of Q-function subspaces and computational efficiency in CDE? While the paper uses N=2 for the main experiments, it does not explore how different numbers of subspaces affect both performance and computational cost across various task complexities. Conducting ablation studies with varying numbers of subspaces (e.g., N=3, N=5) and analyzing the trade-off between performance gains and computational costs would resolve this question.

### Open Question 3
How does CDE compare to operations research approaches in terms of solution quality and adaptability in the train scheduling problem? The paper acknowledges a performance gap compared to traditional operations research methods and raises questions about solving the problem while ensuring adaptability and generalization. Implementing CDE and standard OR methods on the same train scheduling tasks and comparing completion rates, solution quality, and adaptability to dynamic changes would resolve this question.

## Limitations
- The mechanism for detecting task boundaries is not explicitly detailed, raising concerns about applicability in truly non-stationary environments with gradual or ambiguous task transitions.
- The analysis of computational overhead from maintaining multiple Q-function subspaces is insufficient, lacking comprehensive cost-benefit analysis.
- The assumption that curriculum sequencing significantly enhances learning efficiency relies heavily on specific task dependencies that may not generalize to other domains.

## Confidence
- **High Confidence**: The effectiveness of EWC in preventing catastrophic forgetting is well-established in the literature and supported by experimental results.
- **Medium Confidence**: The benefits of adaptive rational activation functions (PAU) for plasticity are plausible but lack extensive empirical support in the specific context of continual RL.
- **Low Confidence**: The assumption that curriculum sequencing significantly enhances learning efficiency relies heavily on specific task dependencies described, which may not generalize to other domains.

## Next Checks
1. Implement and evaluate CDE in a scenario with gradual, non-discrete task transitions to assess the robustness of subspace expansion/pruning logic.
2. Measure and compare the memory and computational costs of CDE against single-network baselines across varying numbers of tasks.
3. Test CDE on a different continual learning benchmark (e.g., supervised image classification with permuted MNIST) to evaluate the transferability of the subspace expansion and curriculum sequencing mechanisms.