---
ver: rpa2
title: Says Who? Effective Zero-Shot Annotation of Focalization
arxiv_id: '2409.11390'
source_url: https://arxiv.org/abs/2409.11390
tags: []
core_contribution: This paper evaluates the ability of large language models (LLMs)
  to perform zero-shot annotation of focalization in literary texts. Focalization
  refers to the perspective through which narrative information is presented, and
  is a complex phenomenon often subject to reader interpretation.
---

# Says Who? Effective Zero-Shot Annotation of Focalization

## Quick Facts
- arXiv ID: 2409.11390
- Source URL: https://arxiv.org/abs/2409.11390
- Authors: Rebecca M. M. Hicke; Yuri Bizzoni; Pascale Feldkamp; Ross Deans Kristensen-McLachlan
- Reference count: 21
- Key outcome: GPT-4o achieves 84.79% F1 score on zero-shot focalization annotation, comparable to human performance

## Executive Summary
This paper evaluates large language models' ability to perform zero-shot annotation of focalization in literary texts. Focalization refers to the perspective through which narrative information is presented, a complex interpretive task often subject to reader disagreement. The authors test several LLM models on excerpts from Stephen King novels, finding that GPT-4o achieves an F1 score of 84.79%, comparable to human annotators. The model demonstrates high confidence in its annotations and resilience to prompt variations. The authors demonstrate how these automated annotations enable large-scale analysis of focalization patterns across King's novels, finding correlations between focalization modes and sensory information presence.

## Method Summary
The authors evaluate multiple LLM models (Naive Bayes, DistilBERT, Llama 3, GPT models) using zero-shot prompting on a corpus of Stephen King novels. They create a small evaluation dataset of 96 excerpts annotated by three human annotators to establish consensus labels. The models are tested using various prompt formats, and their performance is compared to human agreement using F1 scores, precision, and recall for each focalization mode (internal, external, zero). The authors also analyze model confidence scores and their correlation with annotation difficulty.

## Key Results
- GPT-4o achieves an F1 score of 84.79% on focalization annotation, comparable to human performance (87.63% agreement)
- Model confidence scores (log probabilities) correlate with annotation difficulty and human disagreement levels
- Automated annotations enable large-scale analysis revealing structural patterns in focalization distribution across King's novels
- Strong positive correlations found between internal focalization and sensory descriptors, particularly interoception and taste

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4o achieves consistent zero-shot focalization annotation performance across prompt variations
- Mechanism: The model applies a stable internal mapping between textual features and focalization categories, resistant to surface-level prompt changes
- Core assumption: Focalization categories have clear, stable textual indicators that GPT-4o can learn without explicit training
- Evidence anchors:
  - [abstract] "gpt-4o is resilient to prompt perturbations" and "Krippendorf's alpha for the annotations produced from five prompt variants equal to 0.87"
  - [section 4] "gpt-4o annotations were not very sensitive to prompt variations, with a Krippendorf's alpha for the annotations produced from five prompt variants equal to 0.87"
- Break condition: If the textual indicators for focalization are ambiguous or context-dependent, breaking the stable mapping

### Mechanism 2
- Claim: Confidence scores from GPT models correlate with annotation difficulty and accuracy
- Mechanism: Log probabilities for the first token of each annotation reflect the model's certainty about its classification decision
- Core assumption: Higher log probabilities indicate more confident and accurate predictions
- Evidence anchors:
  - [abstract] "the log probabilities output by GPT-family models frequently reflect the difficulty of annotating particular excerpts"
  - [section 4] "we found that the confidence values produced by the GPT models corresponded to outside signals of the difficulty of annotating an excerpt"
- Break condition: If the model produces high-confidence predictions for ambiguous cases or low-confidence predictions for clear cases

### Mechanism 3
- Claim: LLM focalization annotations enable large-scale analysis of narrative patterns across texts
- Mechanism: Automated annotations provide consistent, scalable labels that reveal structural patterns in focalization distribution
- Core assumption: The LLM annotations are sufficiently accurate to capture meaningful patterns despite not being perfect
- Evidence anchors:
  - [abstract] "we provide a case study analyzing sixteen Stephen King novels, demonstrating the usefulness of this approach for computational literary studies"
  - [section 5.1] "we found that the focalization annotations allow for a large-scale comparison of novels, highlighting structural differences even among the works of a single author"
- Break condition: If the annotation errors are systematic or biased in ways that obscure real patterns

## Foundational Learning

- Concept: Focalization theory and taxonomy
  - Why needed here: Understanding the three focalization modes (internal, external, zero) is essential for interpreting the annotation task and evaluating results
  - Quick check question: What distinguishes internal focalization from external focalization in terms of narrative information access?

- Concept: Inter-annotator reliability metrics
  - Why needed here: Evaluating the difficulty of the task and comparing human vs. model performance requires understanding reliability measures
  - Quick check question: What does a Krippendorf's alpha of 0.55 indicate about human agreement on focalization annotation?

- Concept: Log probability interpretation
  - Why needed here: Understanding how confidence scores are derived from model outputs is crucial for interpreting results
  - Quick check question: How is a log probability converted to a probability value in the context of token prediction?

## Architecture Onboarding

- Component map: Data preparation -> Model interface -> Evaluation -> Analysis
- Critical path: Human annotation → Model annotation → Evaluation → Analysis
- Design tradeoffs: Zero-shot approach sacrifices some accuracy for accessibility and scalability
- Failure signatures: Inconsistent annotations across prompt variants, confidence scores uncorrelated with accuracy, poor performance on specific focalization modes
- First 3 experiments:
  1. Run all models on a small subset with known labels to establish baseline performance
  2. Test prompt sensitivity by running one model with multiple prompt variants
  3. Compare confidence scores against human disagreement rates to validate confidence metric

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the zero-shot focalization annotations produced by GPT-4o compare to those produced by other contemporary large language models on literary texts beyond Stephen King's novels?
- Basis in paper: [explicit] The paper states that GPT-4o achieves an F1 score of 84.79% on focalization annotation for Stephen King novels, comparable to human performance, but does not test other models on different literary corpora.
- Why unresolved: The study only evaluates models on Stephen King's works, limiting generalizability to other authors or genres.
- What evidence would resolve it: Testing GPT-4o and other LLMs on focalization annotation tasks using diverse literary corpora (different authors, time periods, genres) and comparing their performance metrics.

### Open Question 2
- Question: Can the correlation between internal focalization and sensory information in Stephen King's novels be generalized to other authors' works, or is it specific to his writing style?
- Basis in paper: [explicit] The paper finds strong positive correlations between internal focalization and sensory descriptors (especially interoception and taste) in Stephen King's novels, but acknowledges this may be specific to his writing.
- Why unresolved: The analysis is limited to a single author, and the relationship between focalization and sensory information may vary across different writing styles or genres.
- What evidence would resolve it: Conducting similar analyses on focalization and sensory information in literary corpora from diverse authors, time periods, and genres to determine if the observed correlations are consistent.

### Open Question 3
- Question: What are the limitations of using log probability values as a proxy for model confidence in focalization annotation tasks, and how can this metric be improved?
- Basis in paper: [inferred] The paper uses log probabilities from GPT models as a confidence metric, noting correlations with annotation difficulty, but does not explore the limitations or potential improvements of this approach.
- Why unresolved: The paper does not thoroughly examine the reliability of log probabilities as confidence measures or explore alternative metrics.
- What evidence would resolve it: Comparative studies using different confidence metrics (e.g., softmax probabilities, entropy) for focalization annotation, and analyses of their correlation with annotation accuracy and difficulty.

## Limitations
- Evaluation is constrained to a single author's corpus (Stephen King), limiting generalizability
- Small evaluation set of 96 excerpts may not capture full variability of focalization phenomena
- Human annotation agreement (Krippendorf's alpha = 0.55) suggests moderate task difficulty, raising questions about whether models are truly "solving" the problem

## Confidence
- **High confidence**: GPT-4o achieves comparable performance to human annotators (84.79% F1 vs 87.63% human agreement)
- **Medium confidence**: Model confidence scores correlate with annotation difficulty across the evaluation set
- **Medium confidence**: Automated annotations enable meaningful large-scale analysis of focalization patterns
- **Low confidence**: The approach generalizes to other authors, genres, or more complex focalization phenomena

## Next Checks
1. **Cross-corpus validation**: Test the same zero-shot approach on literary texts from multiple authors and genres to assess generalizability beyond Stephen King's writing style.

2. **Error analysis by focalization mode**: Perform detailed analysis of model errors for each focalization type (internal, external, zero) to identify systematic weaknesses, particularly for cases where environmental information is presented through character perception.

3. **Confidence calibration testing**: Evaluate whether model confidence scores accurately predict annotation accuracy by testing on a held-out set where ground truth is known, examining calibration curves and potential overconfidence in ambiguous cases.