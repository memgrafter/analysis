---
ver: rpa2
title: Utility-Fairness Trade-Offs and How to Find Them
arxiv_id: '2404.09454'
source_url: https://arxiv.org/abs/2404.09454
tags:
- fairness
- trade-offs
- data
- learning
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of quantifying utility-fairness
  trade-offs in classification systems with demographic fairness considerations. The
  authors introduce two trade-offs - Data-Space Trade-Off (DST) and Label-Space Trade-Off
  (LST) - and propose U-FaTE, a method to numerically estimate these trade-offs from
  data.
---

# Utility-Fairness Trade-Offs and How to Find Them

## Quick Facts
- arXiv ID: 2404.09454
- Source URL: https://arxiv.org/abs/2404.09454
- Reference count: 40
- This paper introduces two utility-fairness trade-offs (Data-Space and Label-Space) and proposes U-FaTE, a method to numerically estimate these trade-offs from data.

## Executive Summary
This paper addresses the fundamental problem of quantifying utility-fairness trade-offs in classification systems with demographic fairness considerations. The authors introduce two distinct trade-offs - Data-Space Trade-Off (DST) and Label-Space Trade-Off (LST) - that together characterize the achievable utility-fairness frontier. They propose U-FaTE, a method that uses closed-form optimization with universal dependence measures to learn fair representations. Experiments across multiple datasets and over 1000 pre-trained models demonstrate that most current fair representation learning approaches are far from the estimated achievable trade-offs, revealing significant room for improvement in this field.

## Method Summary
U-FaTE estimates utility-fairness trade-offs by learning fair representations through a closed-form optimization approach. The method uses a feature extractor (typically ResNet-18) to map raw data to features, then applies a closed-form solver to optimize a linear combination of dependence measures between the representation and target/sensitive attributes. This enables exact optimization without iterative adversarial training. The method employs a Hilbert-Schmidt Independence Criterion (HSIC)-like dependence measure in reproducing kernel Hilbert spaces to capture both linear and non-linear dependencies. By evaluating representations across multiple fairness control parameters λ (between zero and one), U-FaTE generates trade-off curves that bound the achievable utility-fairness frontier.

## Key Results
- Most current fair representation learning methods fall far below the estimated Data-Space Trade-Off (DST) and Label-Space Trade-Off (LST) curves
- CLIP zero-shot models show surprisingly high accuracy on FairFace but violate fairness constraints significantly
- FairFace representations trained on different datasets exhibit varying distances from the estimated trade-off curves, with IMDB-Wiki representations being closest
- U-FaTE successfully identifies the fundamental limits of utility-fairness trade-offs across multiple datasets and fairness metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: U-FaTE provides a closed-form solver for learning fair representations that numerically quantifies utility-fairness trade-offs from raw data.
- **Mechanism**: U-FaTE uses a feature extractor to map raw data to a feature space, then applies a closed-form solver to optimize a linear combination of dependence measures between the representation and target/sensitive attributes. This enables exact optimization without iterative adversarial training.
- **Core assumption**: The kernel matrix KX can be computed over features rather than raw data, making the closed-form solution computationally tractable.
- **Evidence anchors**:
  - [abstract] "U-FaTE uses a closed-form solver and universal dependence measure to learn fair representations."
  - [section 4.3] "Therefore, we incorporate the HSIC-like dependence measure and the closed-form solver into U-FaTE."
  - [corpus] Weak evidence - no directly related papers mention closed-form solvers for fair representation learning.

### Mechanism 2
- **Claim**: The Data-Space Trade-Off (DST) and Label-Space Trade-Off (LST) provide a complete characterization of achievable utility-fairness trade-offs.
- **Mechanism**: DST is defined as the trade-off achievable by an optimally learned fair classifier from data, while LST is the trade-off from an ideal representation that depends only on label distributions. Together they define three regions: possible, possible with extra data, and impossible.
- **Core assumption**: The statistical dependence between target label Y and sensitive attribute S is irreducible, creating fundamental limits on fairness-utility trade-offs.
- **Evidence anchors**:
  - [abstract] "We introduce two utility-fairness trade-offs: the Data-Space and Label-Space Trade-off."
  - [section 3] "By definition, LST necessarily dominates DST since it does not depend on the data X."
  - [corpus] Moderate evidence - related work mentions multi-objective evaluation frameworks for utility-fairness trade-offs.

### Mechanism 3
- **Claim**: Using a universal dependence measure allows U-FaTE to capture both linear and non-linear dependencies between representations and attributes.
- **Mechanism**: The method employs a Hilbert-Schmidt Independence Criterion (HSIC)-like dependence measure that operates in reproducing kernel Hilbert spaces (RKHS), enabling detection of complex statistical relationships.
- **Core assumption**: The universal RKHS basis set US can adequately represent all modes of dependence between random variables.
- **Evidence anchors**:
  - [section 4.2] "We adapt the dependence measure from [32] since it lends itself to a closed-form solution while capturing linear and non-linear dependencies."
  - [section 4.2] "Empirically it can be estimated as, Dep(f (X), S|Y = y) := 1/n2 ∥ΘKXc HL Sc ∥2 F"
  - [corpus] Weak evidence - no corpus papers explicitly discuss universal dependence measures for fairness quantification.

## Foundational Learning

- **Concept: Reproducing Kernel Hilbert Spaces (RKHS)**
  - Why needed here: RKHS provides the mathematical framework for the universal dependence measure used in U-FaTE, allowing the method to capture complex statistical dependencies.
  - Quick check question: What property of RKHS makes it suitable for measuring statistical independence between random variables?

- **Concept: Statistical Dependence Measures**
  - Why needed here: The method relies on quantifying the statistical dependence between representations and sensitive/target attributes to enforce fairness constraints.
  - Quick check question: How does the choice of dependence measure affect the fairness-utility trade-off curve?

- **Concept: Generalized Eigenvalue Problems**
  - Why needed here: The closed-form solution for U-FaTE reduces to solving a generalized eigenvalue problem, which provides the optimal representation parameters.
  - Quick check question: What is the relationship between the eigenvalues of the generalized problem and the achieved fairness-utility trade-off?

## Architecture Onboarding

- **Component map**: Data → Feature Extractor (ResNet-18) → Fair Encoder (closed-form solver) → Classifier (2-layer MLP) → Evaluation

- **Critical path**: Raw data flows through feature extraction, fair representation learning via closed-form optimization, classification, and evaluation to produce utility-fairness trade-off curves.

- **Design tradeoffs**:
  - Closed-form vs iterative optimization: Closed-form provides stability but requires kernel matrix computation
  - Feature dimension vs computational cost: Higher dimensions may capture more information but increase computation
  - Dependence measure choice: HSIC captures non-linear dependencies but may be sensitive to kernel choice

- **Failure signatures**:
  - High variance in trade-off curves: Indicates optimization instability
  - Large gap between DST and LST: Suggests significant information loss in data representation
  - Poor accuracy at low fairness values: May indicate insufficient model capacity

- **First 3 experiments**:
  1. Run U-FaTE on CelebA with EOD fairness constraint and compare against K-TOpt baseline
  2. Evaluate zero-shot CLIP models on FairFace and plot against estimated DST/LST curves
  3. Test supervised representations from different pre-training datasets and measure distance to trade-off curves

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we theoretically guarantee convergence and optimality of the U-FaTE algorithm for estimating utility-fairness trade-offs?
- Basis in paper: [inferred] The authors mention that U-FaTE does not provide convergence or optimality guarantees, and the estimated trade-offs are likely to be suboptimal.
- Why unresolved: The paper focuses on empirical evaluation and does not provide theoretical analysis of the algorithm's convergence and optimality properties.
- What evidence would resolve it: A rigorous theoretical analysis proving convergence and optimality guarantees for U-FaTE under certain conditions.

### Open Question 2
- Question: How sensitive are the estimated utility-fairness trade-offs to the choice of dependence measure in U-FaTE?
- Basis in paper: [explicit] The authors state that different choices of dependence measures lead to different fair representation learning methods, but they only use one specific dependence measure in their experiments.
- Why unresolved: The paper does not explore the impact of using different dependence measures on the estimated trade-offs and the resulting fair representation learning methods.
- What evidence would resolve it: A systematic comparison of U-FaTE's performance using various dependence measures and an analysis of their impact on the estimated trade-offs.

### Open Question 3
- Question: Can the utility-fairness trade-offs be estimated accurately from finite samples, or are there fundamental limitations due to sample complexity?
- Basis in paper: [explicit] The authors mention that they only have access to a finite set of samples to estimate the trade-offs and that their estimates account for the generalization gap between train and test distributions.
- Why unresolved: The paper does not provide a theoretical analysis of the sample complexity required to accurately estimate the trade-offs or discuss the potential limitations due to finite samples.
- What evidence would resolve it: A theoretical analysis of the sample complexity required to estimate the trade-offs within a certain error bound, or empirical studies showing the impact of sample size on the accuracy of the estimates.

## Limitations
- The gap between current methods and estimated trade-offs may be influenced by implementation-specific factors not fully explored
- The assumption that HSIC captures all relevant dependence structures could be violated in high-dimensional feature spaces
- The universal RKHS basis may not adequately represent all modes of dependence in real-world datasets

## Confidence

**High Confidence**: The characterization of DST and LST trade-offs as fundamental limits (Claims 1-3 in Mechanism 2)

**Medium Confidence**: The effectiveness of closed-form optimization compared to iterative methods (Mechanism 1)

**Medium Confidence**: The universality of the dependence measure for capturing complex statistical relationships (Mechanism 3)

## Next Checks

1. Conduct ablation studies varying the kernel choice and RKHS basis to test the sensitivity of the dependence measure
2. Compare U-FaTE's closed-form optimization against iterative adversarial training baselines across multiple dataset types
3. Analyze the sensitivity of trade-off curves to changes in feature extractor architecture and dimensionality