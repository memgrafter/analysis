---
ver: rpa2
title: Do Mice Grok? Glimpses of Hidden Progress During Overtraining in Sensory Cortex
arxiv_id: '2411.03541'
source_url: https://arxiv.org/abs/2411.03541
tags:
- learning
- overtraining
- margin
- neural
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether learning of task-relevant neural
  representations continues after behavioral performance plateaus, a phenomenon analogous
  to "grokking" in deep learning. Using neural data from mice trained on an odor discrimination
  task, the authors find that representations of target and non-target odors in piriform
  cortex continue to separate during overtraining, even though behavior remains at
  near-ceiling performance.
---

# Do Mice Grok? Glimpses of Hidden Progress During Overtraining in Sensory Cortex

## Quick Facts
- arXiv ID: 2411.03541
- Source URL: https://arxiv.org/abs/2411.03541
- Reference count: 40
- The paper finds that neural representations in mouse piriform cortex continue to separate during overtraining, even after behavioral performance plateaus, suggesting continued learning beyond observable behavioral improvements.

## Executive Summary
This study investigates whether neural learning continues after behavioral performance plateaus in mice trained on an odor discrimination task. Using neural recordings from piriform cortex during overtraining, the authors demonstrate that target and non-target odor representations continue to separate even when behavior remains at ceiling performance. This separation is accompanied by increased decoding accuracy and improved generalization on held-out examples. The authors propose that this hidden learning takes the form of approximate margin maximization, analogous to the "grokking" phenomenon in deep learning, and validate this hypothesis using a synthetic model that reproduces the observed phenomena.

## Method Summary
The study analyzes neural data from mice overtrained on an odor discrimination task, tracking representational changes in piriform cortex over time. The authors compute representational similarity matrices between target and non-target odors across overtraining days, calculate decoding accuracy using linear discriminant analysis, and measure the margin of maximum margin classifiers. They construct a synthetic model with a one-hidden-layer MLP trained on a similar odor discrimination task to validate their findings. The neural data consists of spike counts from approximately 15 neurons per session across 15-20 days of overtraining, with around 200 trials per day.

## Key Results
- Class representations in mouse piriform cortex continue actively separating during overtraining while behavior remains unchanged
- Decoding accuracy improves on held-out test examples even after behavioral performance plateaus
- Margin of the maximum margin classifier increases during overtraining, suggesting approximate margin maximization as the underlying mechanism

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continued separation of target and non-target odor representations in piriform cortex drives increased margin of the max-margin classifier during overtraining.
- Mechanism: Even after behavioral performance plateaus, neural representations continue to evolve to increase the distance between class boundaries, making the decision boundary more robust to noise.
- Core assumption: The implicit learning objective in cortex continues to drive feature separation beyond behavioral saturation.
- Evidence anchors:
  - [abstract] "class representations in cortex continue to separate during overtraining, so that examples that were incorrectly classified at the beginning of overtraining can abruptly be correctly classified later on"
  - [section] "target-nontarget odor class representations in mouse piriform cortex continue actively separating during overtraining while behavior remains unchanged"
  - [corpus] Weak - corpus papers don't directly address margin maximization during overtraining.
- Break condition: If behavioral performance stops improving AND no continued separation in representational space is observed.

### Mechanism 2
- Claim: Margin maximization during overtraining causes improved generalization on held-out test examples.
- Mechanism: The learned representations become more linearly separable over time, allowing the classifier to correctly classify examples that were previously misclassified due to proximity to the decision boundary.
- Core assumption: Margin maximization is causally linked to improved generalization rather than being merely correlated.
- Evidence anchors:
  - [abstract] "we hypothesize this hidden yet rich learning takes the form of approximate margin maximization"
  - [section] "We find that the margin of the maximum margin classifier at each day of overtraining is increasing in mouse cortex"
  - [corpus] Weak - corpus doesn't provide direct evidence for margin maximization as causal mechanism.
- Break condition: If ablation studies show that removing margin maximization doesn't affect generalization improvements.

### Mechanism 3
- Claim: Synthetic model replicating piriform cortex dynamics exhibits grokking-like phenomenology through late-time feature learning.
- Mechanism: A simple neural network trained on the odor discrimination task shows continued improvement on test examples after training loss plateaus, mirroring the neural data findings.
- Core assumption: The synthetic model captures essential computational properties of the biological system.
- Evidence anchors:
  - [section] "We construct a synthetic model of piriform cortex performing this task exhibits these properties, as well as the grokking phenomenology"
  - [section] "This simple model captures the key computational phenomena at play in piriform data"
  - [corpus] Weak - corpus papers don't address grokking in synthetic models of sensory cortex.
- Break condition: If more complex models fail to reproduce the observed phenomena.

## Foundational Learning

- Concept: Margin maximization in classification tasks
  - Why needed here: Understanding how increased margin leads to better generalization is central to interpreting the neural data findings
  - Quick check question: What happens to classification performance when the margin between classes increases while training accuracy remains constant?

- Concept: Representational drift vs. representational learning
  - Why needed here: Distinguishing between changes due to drift (random) versus learning (directed) is crucial for interpreting the observed separation
  - Quick check question: How can you distinguish between representational drift and task-relevant representational learning in neural data?

- Concept: Lazy vs. rich learning regimes
  - Why needed here: The paper frames continued learning during overtraining as a transition from lazy to rich learning, which is key to understanding the phenomenon
  - Quick check question: What distinguishes lazy learning (NTK regime) from rich learning in neural networks?

## Architecture Onboarding

- Component map: Neural data preprocessing (spike counts → z-scored matrix) → Linear discriminant analysis decoder → SVM margin calculation → Synthetic model validation
- Critical path: Neural data → z-scoring → decoding accuracy calculation → representational similarity matrices → margin analysis → synthetic model validation
- Design tradeoffs: Using 10-fold cross-validation provides robust accuracy estimates but increases computational cost; z-scoring neurons ensures equal contribution but may remove meaningful baseline differences
- Failure signatures: If decoding accuracy plateaus while behavior improves, or if representational separation decreases during overtraining, the core hypothesis is contradicted
- First 3 experiments:
  1. Replicate decoding accuracy calculation on held-out data to verify overtraining effect
  2. Compute representational similarity matrices at multiple time points to confirm separation
  3. Calculate SVM margin on the same data to verify margin maximization claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does margin maximization causally drive continued learning in mouse piriform cortex during overtraining?
- Basis in paper: [explicit] The authors hypothesize that approximate margin maximization is the underlying mechanism and validate this in both neural data and a synthetic model.
- Why unresolved: The study shows correlation between increasing margin and improved generalization, but cannot definitively prove causation in the biological system.
- What evidence would resolve it: Direct manipulation of margin in mouse cortex (e.g., through optogenetic stimulation) to test if artificially increasing margin during overtraining improves generalization on held-out examples.

### Open Question 2
- Question: Does overtraining reversal generalize beyond olfactory tasks to other sensory modalities and animal species?
- Basis in paper: [inferred] The authors mention that overtraining reversal has been studied in psychology for decades, but their neural evidence comes specifically from mouse olfactory cortex.
- What evidence would resolve it: Replication of the margin maximization and hidden learning phenomena in visual or auditory discrimination tasks across different species (e.g., primates, rats).

### Open Question 3
- Question: What is the biological mechanism driving late-time feature learning during overtraining in cortex?
- Basis in paper: [explicit] The authors speculate on possible drivers including metabolic constraints, small supervised error signals, and implicit penalties on uncertainty in predictions.
- Why unresolved: These remain speculative hypotheses without direct experimental validation in the biological system.
- What evidence would resolve it: Identification of specific neural circuits or molecular pathways that maintain non-vanishing loss signals during behavioral plateau, potentially through recordings of neuromodulatory systems or uncertainty-related neural activity.

## Limitations
- The distinction between representational drift and directed learning remains incompletely addressed
- The causal link between margin maximization and improved generalization is hypothesized but not definitively proven
- The synthetic model may oversimplify the biological complexity of piriform cortex

## Confidence

- **High confidence**: The empirical observation of continued representational separation in piriform cortex during overtraining, and the basic finding that decoding accuracy improves even when behavior plateaus.
- **Medium confidence**: The interpretation that this separation represents "rich learning" analogous to grokking, and that margin maximization is the underlying mechanism rather than a correlated phenomenon.
- **Low confidence**: The strength of the analogy to deep learning grokking, and the claim that this represents a fundamental shift from "lazy" to "rich" learning regimes in biological systems.

## Next Checks

1. Perform cross-species validation by testing whether similar representational separation occurs in other sensory modalities (e.g., visual cortex during visual discrimination tasks) during overtraining.
2. Conduct causal manipulation experiments (e.g., optogenetic inactivation during late overtraining) to determine whether the observed representational changes are necessary for maintaining behavioral performance.
3. Develop more sophisticated synthetic models that incorporate biological constraints (e.g., Dale's law, local connectivity) to test whether the grokking-like phenomena persist under more realistic conditions.