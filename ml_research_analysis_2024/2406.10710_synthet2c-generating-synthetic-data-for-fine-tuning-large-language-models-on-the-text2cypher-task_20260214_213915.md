---
ver: rpa2
title: 'SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models
  on the Text2Cypher Task'
arxiv_id: '2406.10710'
source_url: https://arxiv.org/abs/2406.10710
tags:
- cypher
- question
- llms
- database
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of improving Large Language
  Models'' ability to generate accurate Cypher queries for accessing knowledge graph
  databases, a task known as Text2Cypher. To overcome the lack of annotated datasets,
  the authors propose SyntheT2C, a method that generates synthetic Query-Cypher pairs
  using two pipelines: LLM-based prompting and template-filling.'
---

# SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task

## Quick Facts
- arXiv ID: 2406.10710
- Source URL: https://arxiv.org/abs/2406.10710
- Reference count: 32
- Improves LLMs' ability to generate Cypher queries for knowledge graphs via synthetic data generation and fine-tuning

## Executive Summary
This paper addresses the challenge of generating accurate Cypher queries for knowledge graph databases by proposing SyntheT2C, a synthetic data generation framework. The method combines LLM-based prompting and template-filling pipelines to create diverse Query-Cypher pairs, which are validated through automated checks and manual review. Applied to two medical knowledge graphs, the resulting MedT2C dataset significantly enhances LLM performance on the Text2Cypher task through supervised fine-tuning.

## Method Summary
SyntheT2C employs a dual-pipeline approach for synthetic data generation: an LLM-based prompting pipeline that uses GPT-4o with few-shot examples to generate semantically flexible Cypher queries, and a template-filling pipeline that produces syntactically complex queries through pre-defined templates. Generated pairs undergo five automated validation checks (grammatical, semantic, entity, schema, coherence) before manual review. The validated MedT2C dataset is then used for LoRA-based supervised fine-tuning of various LLMs, improving their Cypher generation capabilities.

## Key Results
- Best fine-tuned model achieved 44% win rate against ground truth Cypher queries
- Execution result matching accuracy reached 39.65% on test dataset
- Fine-tuned models showed significant performance improvements over zero-shot baselines across multiple LLM architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic data generation via dual pipelines enables high-quality Query-Cypher pairs without manual annotation.
- Mechanism: LLM-based pipeline generates diverse semantic queries while template-filling pipeline produces syntactically complex queries.
- Core assumption: LLMs can generate valid Cypher queries with structured metadata and few-shot examples; templates can cover syntactic complexity.
- Evidence anchors: [abstract] Comprehensive experiments demonstrate that the MedT2C dataset effectively enhances performance via SFT; [section 3.2] Dual pipelines aim for semantic flexibility and syntactic complexity.
- Break condition: If templates cannot cover syntactic complexity or LLM-based generation fails to produce valid queries.

### Mechanism 2
- Claim: Automated validators ensure high data quality by filtering invalid or incorrect Query-Cypher pairs.
- Mechanism: Five validators (Grammatical, Semantic, Entity, Schema, Coherence) check different correctness aspects.
- Core assumption: Automated validators can reliably detect syntax errors, semantic inconsistencies, entity mismatches, schema violations, and coherence issues.
- Evidence anchors: [abstract] Generated pairs undergo rigorous automated and manual validation; [section 3.3.1] Five automatic validators proposed.
- Break condition: If any validator produces high false positive/negative rates, data quality will degrade significantly.

### Mechanism 3
- Claim: Supervised fine-tuning with synthetic data improves LLM performance on Text2Cypher task.
- Mechanism: LoRA-based SFT uses validated synthetic dataset to update model weights.
- Core assumption: Synthetic data is sufficiently representative of real query patterns to improve generalization.
- Evidence anchors: [abstract] MedT2C dataset effectively enhances performance of backbone LLMs via SFT; [section 4.4] Win rates calculated in comparison with ground-truth Cyphers.
- Break condition: If synthetic data distribution diverges too much from real data, SFT may degrade rather than improve performance.

## Foundational Learning

- Concept: Neo4j graph databases and Cypher query language
  - Why needed here: The entire task involves translating natural language to Cypher queries for Neo4j databases
  - Quick check question: What is the syntax for matching nodes and relationships in Cypher?

- Concept: Supervised fine-tuning with LoRA
  - Why needed here: The approach uses LoRA-based SFT to adapt pre-trained LLMs to the Text2Cypher task
  - Quick check question: What is the difference between full fine-tuning and LoRA-based fine-tuning?

- Concept: Automated data validation techniques
  - Why needed here: The pipeline relies on multiple automated validators to ensure data quality before SFT
  - Quick check question: How would you design a validator to check if a Cypher query correctly answers a given question?

## Architecture Onboarding

- Component map: LLM-based prompting pipeline -> Template-filling pipeline -> Five automated validators -> Manual validation -> SFT training -> Evaluation
- Critical path: Data generation -> Validation -> SFT -> Evaluation
- Design tradeoffs: LLM-based pipeline offers semantic diversity but may miss syntactic complexity; template-filling offers syntactic complexity but may lack semantic diversity. Combined approach balances both.
- Failure signatures: Low passing rates in validators indicate data quality issues; poor SFT performance indicates synthetic data distribution mismatch.
- First 3 experiments:
  1. Run LLM-based pipeline alone and measure passing rates through validators
  2. Run template-filling pipeline alone and measure passing rates through validators
  3. Combine both pipelines and measure end-to-end performance improvement on small validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the template-filling pipeline be improved to reduce the manual effort required for creating and validating templates?
- Basis in paper: The paper mentions that writing and validating templates is time-consuming and that expanding the current template library is difficult.
- Why unresolved: The authors acknowledge the limitation but do not propose a solution to automate or simplify the template creation and validation process.
- What evidence would resolve it: A method that automates the generation of templates or significantly reduces the manual effort required for template creation and validation would resolve this issue.

### Open Question 2
- Question: Can the automatic validators be improved to handle more complex Cypher queries and reduce the number of samples that fail validation?
- Basis in paper: The paper reports that a significant number of generated Cypher queries are filtered out during the construction of MedT2C, resulting in wasted resources.
- Why unresolved: The authors suggest developing methods to quickly fix Cyphers that do not satisfy all validation criteria, but they do not provide a concrete solution.
- What evidence would resolve it: An improved validation system that can handle more complex queries and reduce the number of failed validations would resolve this issue.

### Open Question 3
- Question: How can the scalability of the SyntheT2C framework be further improved to handle larger and more complex knowledge graphs?
- Basis in paper: The paper conducts scaling experiments but notes that increasing the dataset size beyond a certain point results in marginal improvements or decreases in performance.
- Why unresolved: The authors do not explore the reasons behind the performance plateau or propose methods to overcome this limitation.
- What evidence would resolve it: A study that identifies the factors limiting scalability and proposes methods to overcome these limitations would resolve this issue.

## Limitations

- The framework relies on synthetic data generation without extensive validation on diverse real-world knowledge graphs beyond the two medical databases used.
- Specific template definitions and few-shot examples used in LLM prompts are not disclosed, making exact reproduction challenging.
- Evaluation focuses on Cypher quality and execution accuracy but doesn't extensively measure downstream task performance or real-world applicability.

## Confidence

- **High confidence**: The dual-pipeline approach for synthetic data generation is well-supported by experimental results showing improved performance over baselines.
- **Medium confidence**: The automated validation framework is theoretically sound, but detailed validation accuracy metrics are not provided.
- **Medium confidence**: SFT effectiveness is demonstrated through win rates and accuracy metrics, but long-term stability requires further investigation.

## Next Checks

1. Measure false positive and false negative rates for each of the five automated validators to assess their reliability and identify potential failure modes.
2. Apply the SyntheT2C framework to non-medical knowledge graphs to evaluate performance degradation and identify domain-specific limitations.
3. Conduct experiments measuring performance degradation over multiple fine-tuning iterations and after model updates to assess the robustness of the synthetic data approach.