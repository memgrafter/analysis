---
ver: rpa2
title: Towards Tailored Recovery of Lexical Diversity in Literary Machine Translation
arxiv_id: '2408.17308'
source_url: https://arxiv.org/abs/2408.17308
tags:
- translation
- diversity
- lexical
- books
- reranking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the issue of reduced lexical diversity in
  machine-translated literary works, where translations tend to be lexically poorer
  than human translations. The authors propose a novel approach that re-ranks translation
  candidates using a classifier that distinguishes between original and translated
  text, with the rank selection tailored to the lexical diversity of the source text.
---

# Towards Tailored Recovery of Lexical Diversity in Literary Machine Translation

## Quick Facts
- arXiv ID: 2408.17308
- Source URL: https://arxiv.org/abs/2408.17308
- Reference count: 40
- Primary result: Proposed reranking method recovers lexical diversity in machine-translated literary works, achieving scores closer to human translations for certain books while maintaining translation quality

## Executive Summary
This paper addresses the issue of reduced lexical diversity in machine-translated literary works, where translations tend to be lexically poorer than human translations. The authors propose a novel approach that re-ranks translation candidates using a classifier that distinguishes between original and translated text, with the rank selection tailored to the lexical diversity of the source text. Experiments on 31 English-to-Dutch book translations show that their method can recover lexical diversity scores close to human translations for certain books, while maintaining translation quality metrics. The results demonstrate that their tailored re-ranking approach outperforms rigid methods that simply aim to increase lexical diversity across all texts.

## Method Summary
The method consists of two main components: generating n-best translation hypotheses with a vanilla Transformer-based NMT system, and reranking these hypotheses using a classifier that distinguishes between original and translated Dutch text. The classifier (Dutch BERTje) assigns probabilities that each translation candidate is originally written in Dutch, with higher probabilities indicating more lexically diverse output. Books are binned according to their lexical diversity scores relative to the total distribution, and the selected rank for each book depends on its lexical diversity bin, allowing for tailored diversity recovery rather than a rigid increase across all texts.

## Key Results
- The proposed method recovers lexical diversity scores closer to human translations for certain books while maintaining translation quality metrics
- The tailored re-ranking approach outperforms rigid methods that simply aim to increase lexical diversity across all texts
- Experiments on 31 English-to-Dutch book translations demonstrate the effectiveness of the approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reranking translation hypotheses based on their original-text classification probability recovers lexical diversity closer to human translations.
- Mechanism: The classifier distinguishes between original and translated text, assigning probabilities that candidates are originally written in the target language. Higher probability indicates more original-like (and thus more lexically diverse) output. By selecting ranks based on the lexical diversity of the source text, the method tailors diversity recovery to each book's characteristics.
- Core assumption: The probability of being original text correlates with lexical diversity in the output.
- Evidence anchors: [abstract] "We propose a novel approach that consists of reranking translation candidates with a classifier that distinguishes between original and translated text." [section] "Figure 4 shows the change in MTLD scores for choosing a lower diversity rank. We observe that indeed, choosing a lower rank retrieves lower diversity."

### Mechanism 2
- Claim: Lexical diversity varies considerably across different novels, and this variation should inform MT diversity recovery.
- Mechanism: The approach bins books according to their lexical diversity scores relative to the total distribution. The selected rank for each book depends on its lexical diversity bin, allowing for tailored diversity recovery rather than a rigid increase across all texts.
- Core assumption: Lexical diversity of the source text is a reliable indicator of the desired diversity level in the translation.
- Evidence anchors: [abstract] "Current methods for increasing lexical diversity in MT are rigid. Yet, as we demonstrate, the degree of lexical diversity can vary considerably across different novels." [section] "Figure 2 shows that there is indeed a wide range of diversity across books, for both HT and original text."

### Mechanism 3
- Claim: Reranking is more flexible and computationally efficient than training separate models for different diversity settings.
- Mechanism: Reranking can be applied to any MT model that generates multiple translation candidates without requiring retraining. This flexibility allows tuning at inference time based on the source text's characteristics.
- Core assumption: Generating multiple translation candidates is computationally feasible and does not significantly increase inference time.
- Evidence anchors: [abstract] "Current methods for increasing lexical diversity in MT are rigid. Yet, as we demonstrate, the degree of lexical diversity can vary considerably across different novels." [section] "Our approach consists of two parts: hypothesis generation and hypothesis reranking."

## Foundational Learning

- Concept: Lexical diversity metrics (TTR, Yule's I, MTLD)
  - Why needed here: These metrics quantify the lexical richness of text and are used to evaluate both the source text and translation outputs.
  - Quick check question: Can you explain the difference between type-token ratio (TTR) and measure of textual lexical diversity (MTLD)?

- Concept: Original-text classification
  - Why needed here: The classifier distinguishes between original and translated text, providing probabilities used for reranking translation candidates.
  - Quick check question: How does a binary classifier distinguish between original and translated text, and what features might it use?

- Concept: Reranking hypothesis generation
  - Why needed here: This technique reorders translation candidates based on a criterion (original-text probability) to select more lexically diverse outputs.
  - Quick check question: What are the advantages and disadvantages of reranking compared to generating diversity directly during decoding?

## Architecture Onboarding

- Component map: MT system -> n-best candidates -> Original-text classifier -> Probability scores -> LexDiv scorer -> Bin assignment -> Final selection
- Critical path: Source text -> MT system -> n-best candidates -> Original-text classifier -> Probability scores -> LexDiv scorer -> Bin assignment -> Final selection
- Design tradeoffs:
  - Reranking vs. diverse decoding: Reranking is more flexible but requires generating multiple candidates
  - Classifier vs. diversity-aware decoding: Classifier approach is model-agnostic but adds classification overhead
  - Bin size: Larger bins provide more granularity but may overfit to small test sets
- Failure signatures:
  - All candidates have similar original-text probabilities -> Reranking has minimal effect
  - Classifier accuracy drops significantly -> Wrong candidates selected
  - Source diversity doesn't predict target diversity -> Bin assignments are incorrect
- First 3 experiments:
  1. Compare reranking with diverse beam search decoding to isolate the effect of reranking vs. decoding strategy
  2. Test classifier on held-out validation set to ensure it generalizes beyond training data
  3. Run ablation study with fixed rank selection (no binning) to measure the impact of the tailoring mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method's performance vary across different literary genres, and are there specific genres where it is particularly effective or ineffective?
- Basis in paper: [explicit] The paper mentions that the dataset includes various genres but does not analyze performance differences across these genres.
- Why unresolved: The paper evaluates the method on average across all 31 books without genre-specific analysis.
- What evidence would resolve it: Analyzing the method's performance (lexical diversity scores, translation quality) separately for each genre in the test set would reveal genre-specific strengths and weaknesses.

### Open Question 2
- Question: How does the proposed method scale to language pairs beyond English-Dutch, particularly for non-Indo-European languages or low-resource language pairs?
- Basis in paper: [inferred] The paper acknowledges that experiments were limited to one high-resource language pair (English-Dutch).
- Why unresolved: The current study only evaluates the method on English-to-Dutch translation.
- What evidence would resolve it: Implementing and evaluating the method on multiple language pairs, including both high-resource and low-resource languages from different language families, would demonstrate its generalizability.

### Open Question 3
- Question: What is the optimal n-best list size for the reranking approach, and how does this parameter affect the trade-off between lexical diversity and translation quality?
- Basis in paper: [explicit] The paper experiments with different n-best list sizes (n=5, 10, 20) and decoding strategies but does not determine an optimal configuration.
- Why unresolved: The paper shows that larger n-best lists and top-k sampling can increase lexical diversity but may compromise translation quality.
- What evidence would resolve it: Systematic evaluation of the method with varying n-best list sizes and decoding strategies, measuring both lexical diversity and translation quality metrics, would identify the optimal configuration.

## Limitations
- The approach relies heavily on the quality of the original-text classifier and the assumption that lexical diversity of the source text predicts desired diversity in the target text
- The method's computational overhead, particularly the generation of multiple hypotheses and classifier inference for each candidate, could be prohibitive for large-scale deployment
- The effectiveness of the approach has only been demonstrated for English-to-Dutch translation and may not generalize to other language pairs

## Confidence

- **High Confidence**: The observation that machine-translated literary works exhibit lower lexical diversity than human translations is well-supported by the corpus analysis showing a wide range of diversity scores across books. The mechanism of using original-text classifier probabilities for reranking is also technically sound and well-implemented.

- **Medium Confidence**: The effectiveness of the tailored reranking approach is demonstrated but limited to a single language pair (English-to-Dutch) and a specific literary domain. The binning strategy for rank selection, while intuitive, may be sensitive to corpus composition and the number of bins chosen.

- **Low Confidence**: The assumption that source text lexical diversity reliably predicts target text diversity needs across different books and genres requires further validation. The paper doesn't provide evidence that the classifier's original-text probability truly correlates with lexical diversity rather than other stylistic features.

## Next Checks

1. **Cross-Lingual Validation**: Test the approach on a different language pair (e.g., English-to-Spanish or English-to-German) to assess whether the lexical diversity recovery generalizes beyond the English-Dutch domain.

2. **Quality-Aware Reranking**: Implement a weighted scoring system that balances original-text probability with translation quality metrics (e.g., COMET or human judgments) to ensure that diversity gains don't come at the cost of translation acceptability.

3. **Classifier Feature Ablation**: Conduct an ablation study to determine which features the original-text classifier uses to distinguish original from translated text, and whether these features directly correlate with lexical diversity.