---
ver: rpa2
title: Online Feature Updates Improve Online (Generalized) Label Shift Adaptation
arxiv_id: '2402.03545'
source_url: https://arxiv.org/abs/2402.03545
tags:
- shift
- online
- label
- feature
- ols-ofu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Online Label Shift adaptation with Online Feature
  Updates (OLS-OFU), a method that leverages self-supervised learning to improve feature
  representations during online label shift adaptation. OLS-OFU combines a revised
  version of existing online label shift algorithms with online feature updates using
  SSL techniques such as rotation degree prediction, entropy minimization, and MoCo.
---

# Online Feature Updates Improve Online (Generalized) Label Shift Adaptation

## Quick Facts
- arXiv ID: 2402.03545
- Source URL: https://arxiv.org/abs/2402.03545
- Reference count: 40
- Key outcome: OLS-OFU consistently outperforms existing online label shift methods, with improvements as large as those from earlier methods to current state-of-the-art

## Executive Summary
This paper introduces OLS-OFU, a method that combines online label shift adaptation with online feature updates using self-supervised learning techniques. The approach addresses the challenge of adapting to changing label distributions in online settings where labels are delayed or missing. By leveraging self-supervised learning to refine feature representations during test-time adaptation, OLS-OFU achieves significant performance improvements over existing methods. Theoretical analysis confirms that the method maintains regret convergence guarantees while improving features, and extensive experiments on CIFAR-10, CIFAR-10C, and other datasets demonstrate consistent gains.

## Method Summary
OLS-OFU combines online label shift adaptation (OLS) algorithms with self-supervised learning (SSL) to update feature extractors online. The method operates in a sequence: (1) run the OLS algorithm to get an initial model, (2) update the feature extractor using SSL loss on unlabeled test data, (3) retrain the last linear layer on the labeled training data, and (4) calibrate using a validation set before making predictions. The framework uses SSL techniques like rotation degree prediction, entropy minimization, and MoCo to improve feature representations during test-time adaptation. The OLS-R algorithm is carefully revised to ensure feature updates occur after OLS updates, maintaining theoretical guarantees.

## Key Results
- OLS-OFU consistently outperforms existing online label shift methods across multiple datasets
- Improvements from OLS to OLS-OFU are as large as those from earlier methods to current state-of-the-art
- OLS-OFU provides significant gains especially under domain shifts, though performance degrades when label shift assumptions are violated
- The method maintains theoretical regret convergence guarantees while improving feature representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Online Feature Updates Improve Online (Generalized) Label Shift Adaptation by leveraging self-supervised learning to refine feature representations during online label shift adaptation.
- Mechanism: The method OLS-OFU integrates self-supervised learning techniques (rotation degree prediction, entropy minimization, MoCo) to update feature extractors after running online label shift adaptation, which improves the feature representation learning and prediction accuracy.
- Core assumption: The underlying feature extractor can be improved using unlabeled data at test-time, and this improvement will translate to better performance on the shifted label distributions.
- Break condition: If the self-supervised learning updates do not lead to improved feature representations, or if the assumptions of the online label shift methods are violated by the feature updates.

### Mechanism 2
- Claim: The revised OLS-R algorithm maintains theoretical guarantees by ensuring the feature extractor updates occur after the online label shift updates.
- Mechanism: The OLS-R algorithm is carefully designed to allow online feature updates within the OLS paradigm without violating the key assumptions of OLS algorithms, by updating the feature extractor after running the OLS algorithm and re-training the last linear layer.
- Core assumption: The OLS algorithm can be modified to incorporate feature updates without losing its theoretical guarantees, provided the updates are done in the correct order.
- Break condition: If the order of updates is changed, or if the OLS algorithm assumptions are not carefully maintained during the feature updates.

### Mechanism 3
- Claim: OLS-OFU provides significant improvements over existing methods by reducing the loss of the overall algorithm through enhanced feature representations.
- Mechanism: The theoretical analysis shows that OLS-OFU reduces algorithmic regret by leveraging self-supervised learning techniques to enhance the feature extractor, thereby improving predictions for test samples at each time step.
- Core assumption: Improving the feature extractor will lead to a reduction in the overall algorithm loss, and this improvement can be theoretically bounded.
- Break condition: If the improvement in feature representations does not translate to a reduction in overall algorithm loss, or if the theoretical bounds do not hold in practice.

## Foundational Learning

- Concept: Self-supervised learning (SSL)
  - Why needed here: SSL techniques are used to improve feature representations using unlabeled data at test-time, which is crucial for adapting to label shifts in online settings.
  - Quick check question: What are the three SSL techniques used in OLS-OFU, and how do they each contribute to improving feature representations?

- Concept: Online label shift adaptation
  - Why needed here: The problem setting involves adapting to changes in label distributions over time in an online fashion, where obtaining timely labels is challenging.
  - Quick check question: What is the key assumption of online label shift, and how does it differ from generalized label shift?

- Concept: Regret convergence
  - Why needed here: The theoretical analysis of OLS-OFU focuses on regret convergence, which measures the performance of the algorithm over time compared to the optimal solution.
  - Quick check question: What is the difference between static regret and dynamic regret, and which one is used in the analysis of OLS-OFU?

## Architecture Onboarding

- Component map: Feature Extractor -> Online Label Shift (OLS-R) -> Self-Supervised Learning Update -> Linear Layer Retraining -> Prediction
- Critical path: The critical path is the sequence of operations at each time step: (1) run OLS-R, (2) update feature extractor using SSL, (3) re-train last linear layer, and (4) make predictions.
- Design tradeoffs: The main tradeoff is between the complexity of the SSL updates and the theoretical guarantees of the OLS algorithm. The design carefully balances these to maintain both performance and theoretical bounds.
- Failure signatures: Common failure modes include violation of OLS assumptions due to feature updates, insufficient improvement from SSL updates, and instability in the re-training of the last linear layer.
- First 3 experiments:
  1. Implement OLS-OFU with rotation degree prediction on CIFAR-10 under sinusoidal shift and compare with baseline OLS methods.
  2. Test the batch accumulation strategy for MoCo in OLS-OFU and evaluate its impact on performance.
  3. Analyze the improvement in regret bounds from OLS to OLS-OFU across different datasets and SSL techniques.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical justification for why self-supervised learning methods like rotation degree prediction and MoCo are more effective than entropy minimization for handling domain shifts in generalized label shift scenarios?
- Basis in paper: [explicit] The paper notes that "rotation degree prediction and MoCo are more appropriate SSL to address the domain shift from CIFAR-10 to CIFAR-10C" and observes that "OLS-OFU with SSL entropy minimization shows less improvement from OLS" as domain shift severity increases.
- Why unresolved: The paper provides empirical evidence but doesn't provide theoretical analysis of why certain SSL methods perform better than others in domain shift scenarios.
- What evidence would resolve it: A theoretical analysis comparing the properties of different SSL methods in terms of their ability to learn domain-invariant features, or ablation studies systematically comparing different SSL methods across varying types and severities of domain shifts.

### Open Question 2
- Question: How does the performance of OLS-OFU scale with increasing dataset size and number of classes?
- Basis in paper: [inferred] The theoretical analysis provides regret bounds that depend on K (number of classes) but the paper only evaluates on CIFAR-10 with 10 classes. The paper mentions "we present the theoretical results pertaining to FLHFTL-OFU here" suggesting there may be limitations to the theoretical analysis.
- Why unresolved: The paper focuses on CIFAR-10 experiments and provides limited theoretical analysis. The performance on larger datasets with more classes is unknown.
- What evidence would resolve it: Experiments on datasets with varying numbers of classes (e.g., CIFAR-100, ImageNet) and datasets of different scales, along with theoretical analysis extending regret bounds to these scenarios.

### Open Question 3
- Question: What is the optimal strategy for batch accumulation in MoCo-based OLS-OFU across different online learning scenarios?
- Basis in paper: [explicit] The paper introduces batch accumulation for MoCo but notes "We perform feature extractor update every τ = 50 steps" without systematic exploration of different values, and shows "OLS-OFU (BA=1) is even worse than OLS" while "OLS-OFU (BA=50) can outperform OLS."
- Why unresolved: The paper only evaluates one batch accumulation parameter (τ=50) and doesn't provide guidance on how to select this parameter or whether it should vary based on online learning conditions.
- What evidence would resolve it: Systematic experiments varying the batch accumulation parameter across different online learning scenarios, dataset sizes, and domain shift types, along with theoretical analysis of the trade-offs involved.

## Limitations
- The paper relies on specific SSL techniques which may limit generalizability to other feature update methods
- The assumption that OLS algorithms can be modified without violating theoretical guarantees is not fully validated across diverse settings
- Performance degrades when label shift assumptions are severely violated, particularly under high-severity domain shifts

## Confidence
- **High confidence**: The core claim that OLS-OFU outperforms baseline OLS methods is well-supported by experiments
- **Medium confidence**: The theoretical regret bounds and their connection to practical performance improvements
- **Medium confidence**: The effectiveness of specific SSL techniques (rotation prediction, entropy minimization, MoCo) for online feature updates

## Next Checks
1. Test OLS-OFU with alternative SSL methods beyond the three presented to assess generalizability of the framework
2. Conduct ablation studies on the order of operations (OLS updates vs. feature updates) to confirm the theoretical reasoning
3. Evaluate performance under more extreme domain shifts where label shift assumptions may be violated to identify failure modes