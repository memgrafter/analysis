---
ver: rpa2
title: Not All Layers of LLMs Are Necessary During Inference
arxiv_id: '2403.02181'
source_url: https://arxiv.org/abs/2403.02181
tags:
- layers
- inference
- adainfer
- tasks
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a simple yet effective algorithm named AdaInfer
  to adaptively terminate the inference process for an input instance in large language
  models (LLMs). The key idea is to predict at which layer the inferred results match
  the final results produced by evaluating all layers, thus significantly reducing
  the inference cost.
---

# Not All Layers of LLMs Are Necessary During Inference

## Quick Facts
- **arXiv ID**: 2403.02181
- **Source URL**: https://arxiv.org/abs/2403.02181
- **Reference count**: 30
- **Primary result**: AdaInfer achieves up to 43% inference cost reduction with <1% accuracy drop on sentiment tasks.

## Executive Summary
This paper proposes AdaInfer, a simple yet effective algorithm for adaptively terminating LLM inference at intermediate layers when the results match the final output. Through analysis, the authors show that for some tasks, LLMs can achieve results comparable to the final output at intermediate layers. AdaInfer uses easily obtainable statistical features and classic classifiers like SVM to predict the optimal layer for early exit, significantly reducing inference cost while maintaining accuracy. Experiments on well-known LLMs like Llama2 and OPT demonstrate an average of 17.8% pruning ratio, with up to 43% on sentiment tasks and nearly no performance drop (<1%).

## Method Summary
AdaInfer uses statistical features (gap and top probability) extracted from intermediate layers of LLMs to predict when early exit would produce the same results as evaluating all layers. The method trains a classifier (SVM or CRF) on labeled data where early stops at each layer are marked as correct/incorrect. During inference, the classifier monitors these features at each layer and predicts whether to stop, bypassing remaining layers if confident. The approach is compatible with zero/few-shot learning settings and works across various task types including question answering and text classification.

## Key Results
- Achieves up to 43% inference cost reduction on sentiment tasks with <1% accuracy drop
- Average 17.8% pruning ratio across all evaluated tasks and models
- Compatible with zero/few-shot learning settings
- Works on multiple LLMs including Llama2 series and OPT

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Not all decoder layers are necessary for correct predictions in LLMs; early exit is viable.
- **Mechanism**: During inference, the model can produce the same final prediction at an intermediate layer as it would at the last layer for certain instances.
- **Core assumption**: The logits and probability distribution at intermediate layers can match the final layer's output for some inputs.
- **Evidence anchors**:
  - [abstract] "Through analysis, we show that for some tasks, LLMs can achieve results comparable to the final output at some intermediate layers."
  - [section 3.2] "Using the SST-2 dataset, we conduct sentiment classification experiments on the Llama2-13B (40 layers) model... an early exit at layer 21 (with a variance of 5.1) achieves comparable accuracy to the final layer output."
  - [corpus] Weak support: "Not All LoRA Parameters Are Essential: Insights on Inference Necessity" discusses layer necessity but does not directly confirm logits matching.
- **Break condition**: If intermediate logits diverge significantly from final logits, early exit will degrade accuracy.

### Mechanism 2
- **Claim**: Simple tasks require fewer layers; complex tasks need deeper layers.
- **Mechanism**: The number of optimal decoding layers for inference is instance-dependent; simpler inputs activate fewer layers while complex ones activate more.
- **Core assumption**: Input complexity correlates with the depth of layers needed for correct inference.
- **Evidence anchors**:
  - [abstract] "Simpler tasks require fewer layers for inference, while complex tasks go deeper."
  - [section 3.2] "simpler inputs like 'I like Camera A' activate only 18 layers, while more complex inputs like 'Camera A is better than Camera B in picture quality' activate about 24 layers."
  - [corpus] No direct corpus evidence; assumed from experimental observations.
- **Break condition**: If the classifier cannot reliably estimate task complexity, pruning may occur too early for complex tasks.

### Mechanism 3
- **Claim**: AdaInfer uses easily obtainable statistical features (gap and top prob) to predict optimal early exit layer.
- **Mechanism**: The classifier monitors the probability of the top token and the gap between the top and second token at each layer to decide whether to stop inference.
- **Core assumption**: These two features are universal and correlate with when the model has sufficient information to predict correctly.
- **Evidence anchors**:
  - [section 4.1] "We made two observations: (i) not all layers of LLMs are necessary during inference, i.e., early stopping works, and (ii) simpler tasks require fewer layers, while more complex tasks require more layers of inference."
  - [section 4.1] "Our examination focused specifically on: • Gap measures the current block's prediction confidence... • Top Prob, P (top token), is the probability estimation..."
  - [corpus] Weak support: "Skipping Computations in Multimodal LLMs" discusses skipping but not the specific features used.
- **Break condition**: If the features do not correlate with prediction confidence, the classifier's accuracy will drop.

## Foundational Learning

- **Concept**: Transformer architecture and decoder-only LLMs.
  - Why needed here: Understanding the building blocks (tokenization, embedding, decoder block, classification layer) is essential to grasp how AdaInfer interacts with the model.
  - Quick check question: What are the four main components of an LLM as described in the paper?

- **Concept**: In-context learning and zero/few-shot settings.
  - Why needed here: AdaInfer is evaluated in zero/few-shot scenarios; knowing how prompts are structured and how few-shot learning works is necessary.
  - Quick check question: How does the paper construct prompts for few-shot learning?

- **Concept**: Early exit and dynamic depth in neural networks.
  - Why needed here: AdaInfer is an instance-aware early exit method; understanding prior work on early exit in CNNs and BERT helps contextualize the approach.
  - Quick check question: What is the difference between Early Exit (EE) and Skip Layer methods?

## Architecture Onboarding

- **Component map**:
  Tokenizer and Embedding Layer → Decoder Block (multiple layers) → Classification Layer

- **Critical path**:
  1. Input text → Tokenizer → Embedding Layer
  2. For each decoder layer:
     - Run forward pass
     - Extract logits from classification layer
     - Compute gap and top prob features
     - Classifier predicts stop or continue
  3. If stop, bypass remaining layers and output prediction

- **Design tradeoffs**:
  - **Accuracy vs. speed**: Early exit may reduce accuracy if stopped too soon; tradeoff managed by classifier confidence
  - **Feature simplicity vs. expressiveness**: Using only gap and top prob keeps computation low but may miss other useful signals
  - **Static vs. dynamic pruning**: AdaInfer dynamically decides per instance, unlike fixed pruning ratios

- **Failure signatures**:
  - Accuracy drops below 1% of dense model baseline
  - Pruning ratio lower than expected (e.g., near 0% for complex tasks)
  - Classifier predicts stop too early for complex inputs

- **First 3 experiments**:
  1. **Verify early exit works**: Run sentiment analysis on Llama2-13B, record accuracy at each layer, confirm that layer 21 matches final accuracy
  2. **Test feature correlation**: For a set of inputs, compute gap and top prob at each layer, plot against accuracy, verify features increase and stabilize in deeper layers
  3. **Evaluate classifier impact**: Train SVM on extracted features, test on held-out set, measure accuracy drop and pruning ratio, compare with dense model

## Open Questions the Paper Calls Out
- **Question**: How can AdaInfer be extended to support sequential generative tasks like text completion or translation?
  - **Basis in paper**: [explicit] The paper states that AdaInfer "has not yet been extended to sequential generative tasks" and that this is a "significant avenue for future research."
  - **Why unresolved**: The current implementation relies on a single forward pass and uses features from the final token, which may not be suitable for tasks requiring sequential generation.
  - **What evidence would resolve it**: A modified version of AdaInfer that can dynamically determine when to stop generation for each token in a sequence, along with experimental results demonstrating its effectiveness on generative tasks.

- **Question**: Are there more effective features beyond logits that could improve AdaInfer's performance?
  - **Basis in paper**: [explicit] The paper mentions that "AdaInfer relies on a single forward pass" and that "there may exist more effective features in addition to logits."
  - **Why unresolved**: The current implementation uses only two features (gap and top prob) derived from logits, but other features like attention values or hidden states were found to have little impact or even negative effects.
  - **What evidence would resolve it**: A systematic exploration of additional features and their impact on AdaInfer's performance, potentially leading to the discovery of more informative features for early exit prediction.

- **Question**: How can AdaInfer be adapted for larger LLMs (e.g., 70B or more parameters) to maintain performance without significant accuracy drops?
  - **Basis in paper**: [explicit] The paper reports that for the Llama2 70B model, AdaInfer experiences a "1% to 25% drop across different tasks compared to the dense model" in few-shot settings, indicating a need for "more feature engineering for larger models."
  - **Why unresolved**: The current feature selection and classifier may not capture the complexities of larger models, leading to suboptimal early exit decisions.
  - **What evidence would resolve it**: An improved version of AdaInfer with enhanced feature engineering and/or classifier design that can effectively handle larger models, demonstrated through experimental results showing maintained accuracy and computational efficiency gains.

## Limitations
- Limited evaluation on extremely long sequences where pruning ratio might be less impactful
- Potential overfitting to specific datasets used for training the classifier
- No ablation study on feature importance to identify most effective features
- Compatibility claims with other acceleration techniques are untested

## Confidence

**High Confidence**: The core claim that intermediate layers can produce equivalent predictions for some inputs is well-supported by empirical evidence across multiple tasks and models.

**Medium Confidence**: The effectiveness of the SVM classifier with gap and top prob features is demonstrated, but the specific feature selection and classifier choice could potentially be improved.

**Medium Confidence**: The claim that simpler tasks require fewer layers is supported by analysis but is not universally quantified across all task types.

## Next Checks

1. **Evaluate on long-form generation tasks**: Test AdaInfer on tasks involving multi-sentence or paragraph generation (e.g., summarization, story completion) to assess whether the pruning ratio holds for complex sequential outputs.

2. **Test feature ablation and expansion**: Systematically remove gap and top prob features and add alternative features (e.g., attention entropy, hidden state variance) to quantify their individual and combined contributions to classifier accuracy.

3. **Validate compatibility with speculative decoding**: Implement AdaInfer alongside speculative decoding and measure end-to-end latency improvements and accuracy preservation on a benchmark set of tasks.