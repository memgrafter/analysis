---
ver: rpa2
title: 'Enriching Datasets with Demographics through Large Language Models: What''s
  in a Name?'
arxiv_id: '2409.11491'
source_url: https://arxiv.org/abs/2409.11491
tags:
- llms
- dataset
- nationality
- gender
- race
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the use of Large Language Models (LLMs)\
  \ to enrich datasets with demographic information\u2014such as gender, race, and\
  \ age\u2014from individuals\u2019 names. The authors demonstrate that modern zero-shot\
  \ LLMs outperform prior supervised approaches, including hidden Markov models and\
  \ recurrent neural networks, in demographic prediction."
---

# Enriching Datasets with Demographics through Large Language Models: What's in a Name?

## Quick Facts
- **arXiv ID**: 2409.11491
- **Source URL**: https://arxiv.org/abs/2409.11491
- **Reference count**: 12
- **Primary result**: Zero-shot LLMs outperform supervised models in demographic prediction from names, with strong gender and race accuracy but significant age prediction bias.

## Executive Summary
This paper demonstrates that modern zero-shot Large Language Models (LLMs) can accurately predict demographic attributes—gender, race, and nationality—from individuals' names, often surpassing previous supervised approaches like hidden Markov models and recurrent neural networks. The study evaluates 12 LLMs across multiple datasets, including a real-world Hong Kong financial professionals dataset, and finds that closed-source models like Claude-3.5-Sonnet and GPT-4o achieve the highest accuracy. However, LLMs struggle with age prediction, often defaulting to round numbers or recent dates, indicating biases in pretraining data. The research also reveals significant regional and model-specific biases, highlighting the need for more diverse, non-Western datasets to improve generalizability. These findings advance demographic enrichment techniques and underscore important considerations for mitigating biases in LLM applications.

## Method Summary
The study uses zero-shot LLM prompting to predict demographic attributes from names without fine-tuning. Researchers employed 12 LLMs (6 open-source, 6 closed-source) with a fixed prompt template to predict gender, race, nationality, country of origin, and age/birth date from individuals' names. Three datasets were used: a subsampled Florida Voters Registration dataset (100k points), a Wikipedia dataset with nationality annotations (890k train, 111k dev, 111k test), and a Hong Kong SFC professionals dataset (519k entries). Performance was evaluated using accuracy for classification tasks and Mean Absolute Error (MAE) for age prediction. The study compares LLM performance against baselines (random, most frequent, average) and explores the impact of multi-task prompting on open-source models.

## Key Results
- Zero-shot LLMs outperform traditional supervised models in gender and race prediction from names.
- Closed-source models (Claude-3.5-Sonnet, GPT-4o) achieve the highest accuracy across demographics.
- LLMs exhibit significant age prediction bias, defaulting to round numbers or recent dates.
- Multi-task prompting improves open-source LLM performance on nationality prediction by an average of 15% accuracy.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot LLMs can predict demographic attributes from names with high accuracy, often outperforming traditional supervised models.
- Mechanism: LLMs leverage their broad pretraining on web-scale data to recognize name-to-demographic correlations that were implicitly learned from diverse text sources, enabling direct inference without task-specific fine-tuning.
- Core assumption: The pretraining corpus contained sufficient representative examples linking names to demographic categories across cultures and languages.
- Evidence anchors:
  - [abstract] "we demonstrate that the zero-shot capabilities of Large Language Models (LLMs) can perform as well as, if not better than, bespoke models trained on specialized data."
  - [section 4.2.1] "LLMs are mostly able to predict a person’s gender solely based on the name."
  - [corpus] Weak—no corpus evidence for demographic name links in pretraining.
- Break condition: If pretraining data lacks coverage of non-Western naming conventions, performance degrades significantly for those populations.

### Mechanism 2
- Claim: LLMs exhibit systematic biases in age prediction, defaulting to round numbers or recent dates.
- Mechanism: The model's generative prior favors high-frequency outputs (e.g., round numbers like 1990) and recent dates due to skewed pretraining distributions and limited exposure to historical naming trends.
- Core assumption: Age-related naming trends are underrepresented in pretraining data relative to other demographics.
- Evidence anchors:
  - [section 4.2.2] "LLMs are not able to consistently improve on trivial baselines" and "generate historical dates prior to the nineteenth century" but "predict more recent dates."
  - [section 5.1] "LLMs mostly predict round ages such as 35 or 45 years old."
  - [corpus] No corpus evidence for age prediction patterns.
- Break condition: If additional age-labeling examples are provided in context, the mode collapse may lessen but not fully resolve.

### Mechanism 3
- Claim: Multi-task prompting improves open-source LLM performance on nationality prediction.
- Mechanism: Decomposing tasks into multiple steps with enforced self-consistency constrains the model to reconcile outputs across related attributes, reducing prediction variance.
- Core assumption: Model outputs for correlated attributes (e.g., nationality and country of origin) can be cross-validated to improve accuracy.
- Evidence anchors:
  - [section 4.2.4] "open-source LLMs benefit notably from the complex, multi-task inference setup, gaining on average 15% of accuracy."
  - [section 5.2] "LLMs cluster by source type—open-source vs. closed-source—with a high-agreement cluster of Claude 3.5 Sonnet, GPT-4, GPT-3.5 Turbo, and Claude 3 Haiku."
  - [corpus] No corpus evidence for prompting strategies.
- Break condition: For high-performing closed-source models, additional task decomposition provides no benefit due to already strong internal consistency.

## Foundational Learning

- **Concept**: Transformer architecture and attention mechanisms
  - Why needed here: LLMs rely on self-attention to capture long-range dependencies between name tokens and demographic associations learned during pretraining.
  - Quick check question: How does multi-head attention enable the model to focus on different aspects of a name when inferring demographics?

- **Concept**: Zero-shot prompting and prompt engineering
  - Why needed here: The study uses structured prompts to elicit demographic predictions without fine-tuning, relying on the model's ability to follow instructions and format outputs correctly.
  - Quick check question: What role does temperature=0 play in ensuring deterministic output for evaluation?

- **Concept**: Evaluation metrics for classification vs. regression
  - Why needed here: Gender, race, and nationality are classification tasks (accuracy), while age prediction is a regression task (MAE), requiring different metrics.
  - Quick check question: Why is MAE preferred over accuracy for age prediction?

## Architecture Onboarding

- **Component map**: Dataset ingestion → Prompt template → LLM API/local inference → Output parsing → Metric computation
- **Critical path**: Prompt construction → LLM inference → Format validation → Metric aggregation
- **Design tradeoffs**: Open-source vs. closed-source models (cost, speed, accuracy); zero-shot vs. fine-tuned (generalization vs. performance); local vs. API inference (control vs. convenience)
- **Failure signatures**: Invalid output format (low parsing success); mode collapse (round age predictions); low agreement between models (inconsistent predictions)
- **First 3 experiments**:
  1. Run all LLMs on a small sample of Florida Voters with only gender prediction to verify format parsing and accuracy.
  2. Test age prediction on the same sample to observe mode collapse and MAE distribution.
  3. Compare simple vs. complex prompting on Wikipedia nationality prediction for open-source models to measure multi-task gains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we improve LLM accuracy for age prediction from names without relying on fine-tuning, which requires significant computational resources?
- Basis in paper: [explicit] The paper demonstrates that LLMs struggle with age prediction, often defaulting to round or recent dates, and suggests that further advancements in model training may be required for LLMs to better utilize correlations between names and birth dates.
- Why unresolved: The paper only evaluates zero-shot setups and acknowledges that fine-tuning could significantly improve performance but was beyond the scope of the study due to GPU resource constraints.
- What evidence would resolve it: Comparative experiments showing performance improvements from prompt engineering techniques (e.g., chain-of-thought prompting, self-consistency) versus fine-tuning approaches on age prediction tasks, with resource usage comparisons.

### Open Question 2
- Question: To what extent does data contamination from Wikipedia during LLM pre-training affect demographic predictions, and how can this bias be mitigated?
- Basis in paper: [explicit] The paper notes that Wikipedia content is largely included in pre-training data for most LLMs, leading to potential memorization of certain entries, particularly affecting the Wikipedia dataset used in the study.
- Why unresolved: The paper acknowledges the contamination issue but does not quantify its impact on prediction accuracy or explore methods to mitigate this bias.
- What evidence would resolve it: Ablation studies comparing model performance on Wikipedia-contaminated versus non-contaminated datasets, and experiments testing de-contamination techniques or using out-of-distribution datasets.

### Open Question 3
- Question: Can ensemble methods improve demographic prediction accuracy when LLM outputs are highly correlated, as observed in the study?
- Basis in paper: [explicit] The paper experimented with majority voting ensembles of 12 LLMs and found no performance improvement, attributing this to high correlation between model outputs.
- Why unresolved: While the study found no improvement from simple majority voting, it did not explore more sophisticated ensemble techniques or methods to decorrelate LLM predictions.
- What evidence would resolve it: Experiments comparing various ensemble methods (weighted voting, stacking, diversity-promoting techniques) against individual strong-performing models on demographic prediction tasks.

## Limitations

- Age prediction performance is significantly limited by mode collapse, with LLMs defaulting to round numbers or recent dates.
- The study lacks detailed prompt templates, making exact replication challenging and potentially affecting performance comparisons.
- Performance on non-Western names is not thoroughly evaluated, highlighting the need for more diverse datasets to improve generalizability.

## Confidence

- **Gender and race prediction superiority**: High
- **Age prediction performance claims**: Medium
- **Multi-task prompting benefits for open-source models**: Medium

## Next Checks

1. Re-run gender prediction on Florida Voters with multiple prompt variants to assess sensitivity.
2. Analyze age prediction distributions to quantify mode collapse and compare against baseline trivial predictors.
3. Test multi-task prompting on open-source models with controlled prompt variations to isolate the impact of task decomposition.