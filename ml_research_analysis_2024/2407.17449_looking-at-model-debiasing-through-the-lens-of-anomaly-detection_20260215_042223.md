---
ver: rpa2
title: Looking at Model Debiasing through the Lens of Anomaly Detection
arxiv_id: '2407.17449'
source_url: https://arxiv.org/abs/2407.17449
tags:
- bias
- samples
- bias-conflicting
- debiasing
- anomaly
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of debiasing deep neural networks
  trained on biased datasets. The authors propose a novel approach that frames bias
  identification as an anomaly detection problem, treating bias-conflicting samples
  as outliers in the feature space of a biased model.
---

# Looking at Model Debiasing through the Lens of Anomaly Detection

## Quick Facts
- arXiv ID: 2407.17449
- Source URL: https://arxiv.org/abs/2407.17449
- Reference count: 40
- Authors: Vito Paolo Pastore; Massimiliano Ciranni; Davide Marinelli; Francesca Odone; Vittorio Murino
- One-line primary result: MoDAD achieves state-of-the-art debiasing performance on both synthetic and real-world biased datasets by framing bias-conflicting samples as anomalies in feature space

## Executive Summary
This paper addresses the challenge of debiasing deep neural networks trained on biased datasets by introducing a novel two-step approach that frames bias identification as an anomaly detection problem. The authors propose that bias-conflicting samples (those that violate the spurious correlations learned by a biased model) can be detected as outliers in the feature space of a biased model using One-Class Support Vector Machine (OCSVM). Their method, called MoDAD, combines this bias identification step with a debiasing strategy involving bias-conflicting data upsampling and augmentation, achieving state-of-the-art performance on both synthetic (Corrupted CIFAR-10) and real-world benchmark datasets (BAR, BFFHQ, Waterbirds).

## Method Summary
MoDAD is a two-step debiasing method that first identifies bias-conflicting samples using anomaly detection, then debiases the model through fine-tuning with weighted sampling. In step one, a ResNet-18/50 model is trained on biased data using Generalized Cross Entropy (GCE) loss, then OCSVM is applied to the feature space embeddings to identify bias-conflicting samples as anomalies. In step two, the model is fine-tuned using a weighted random sampler that creates balanced mini-batches with 4x more bias-conflicting samples than bias-aligned samples, combined with augmentation to prevent overfitting. The method uses Average Accuracy and Conflicting Accuracy as evaluation metrics.

## Key Results
- MoDAD achieves state-of-the-art performance on both synthetic (Corrupted CIFAR-10) and real-world benchmark datasets (BAR, BFFHQ, Waterbirds)
- On BFFHQ dataset with bias correlation of 0.995, MoDAD outperforms existing methods by over 4% in conflicting accuracy
- The method demonstrates significant improvements in conflicting accuracy while maintaining overall accuracy
- MoDAD shows robustness to different anomaly detection algorithms and dataset characteristics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bias-conflicting samples are anomalous in the feature space of a biased model
- Mechanism: When a model is trained on biased data, it learns strong spurious correlations. Bias-conflicting samples deviate from these correlations and end up in low-density regions of the feature space, making them detectable as anomalies
- Core assumption: The distribution shift between bias-aligned and bias-conflicting samples is significant enough to be captured by anomaly detection methods
- Evidence anchors:
  - [abstract] "We claim that when data is mostly biased, bias-conflicting samples can be regarded as outliers with respect to the bias-aligned distribution in the feature space of a biased model"
  - [section] "From this figure, one can notice that bias-conflicting samples experience a shift in the feature space distribution of the ResNet-18 model, as compared to the distribution of the bias-aligned ones"

### Mechanism 2
- Claim: Using GCE loss amplifies the distribution shift between bias-aligned and bias-conflicting samples
- Mechanism: GCE loss weights samples based on classification confidence - confident predictions (bias-aligned) get higher weight, uncertain predictions (bias-conflicting) get lower weight. This prevents memorization of bias-conflicting samples and enhances the feature space separation
- Core assumption: The confidence-based weighting of GCE loss effectively prevents overfitting on bias-conflicting samples while amplifying the distinction between sample types
- Evidence anchors:
  - [section] "we employ the Generalized Cross Entropy (GCE) [20] as our loss function for the bias identification step... we use GCE to further amplify the distribution shift between bias-aligned and bias-conflicting samples, avoiding bias-conflicting sample memorization"

### Mechanism 3
- Claim: Upsampling bias-conflicting samples during debiasing restores balance and improves generalization
- Mechanism: After identifying bias-conflicting samples via anomaly detection, the debiasing step uses weighted random sampling to create balanced mini-batches with 4x more bias-conflicting samples, combined with augmentation to prevent overfitting
- Core assumption: The identified bias-conflicting samples are accurate enough that oversampling them during fine-tuning will improve model robustness
- Evidence anchors:
  - [section] "we build each mini-batch such that the ratio of bias-aligned and bias-conflicting samples is roughly balanced. We further perform upsampling adding three augmented images for each bias-conflicting sample"

## Foundational Learning

- Concept: Anomaly Detection (specifically One-Class SVM)
  - Why needed here: The core innovation frames bias-conflicting samples as anomalies in feature space, requiring understanding of how anomaly detection algorithms work
  - Quick check question: How does One-Class SVM differ from standard binary classification SVMs, and why is this distinction important for detecting bias-conflicting samples?

- Concept: Covariate Shift
  - Why needed here: The paper explicitly mentions covariate shift as the cause of the distribution difference between bias-aligned and bias-conflicting samples
  - Quick check question: What distinguishes covariate shift from other types of distribution shift, and how does this relate to the bias-conflicting/bias-aligned sample distinction?

- Concept: Bias Types in Machine Learning
  - Why needed here: Understanding spurious correlations vs. semantic features is crucial for grasping why debiasing is necessary
  - Quick check question: What's the difference between a spurious correlation and a genuine semantic relationship in the context of dataset bias?

## Architecture Onboarding

- Component map: ResNet-18/50 backbone → 128-dim ReLU layer → anomaly detection per class → weighted sampling during fine-tuning
- Critical path: Feature extraction → anomaly scoring → threshold application → bias sample identification → weighted debiasing
- Design tradeoffs: OCSVM provides interpretability and control but may be less powerful than deep anomaly detection methods; simpler debiasing (upsampling+augmentation) vs. complex methods
- Failure signatures: High false positive rate in anomaly detection (identifying bias-aligned as conflicting), poor separation in feature space, or failure to prevent overfitting on bias-conflicting samples
- First 3 experiments:
  1. Verify that bias-conflicting samples show anomalous behavior in feature space using PCA visualization
  2. Test different anomaly detection algorithms (LOF, Isolation Forest) to confirm OCSVM choice isn't critical
  3. Ablation study: debias with oracle bias labels vs. anomaly detection predictions to quantify identification accuracy impact

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions but suggests future work directions including investigating deep anomaly detection approaches for this task and exploring scenarios with multiple bias attributes simultaneously.

## Limitations
- The method's effectiveness on datasets with multiple bias attributes simultaneously is untested
- The sensitivity to hyperparameter choices (particularly anomaly detection thresholds) is not thoroughly explored
- The claim of being "unaffected by bias correlation" needs validation across a broader range of bias strengths

## Confidence
- High Confidence: The overall two-step methodology (anomaly detection + upsampling debiasing) is well-defined and reproducible
- Medium Confidence: The core hypothesis that bias-conflicting samples can be detected as anomalies is plausible but needs stronger empirical validation
- Low Confidence: The specific choice of GCE loss for amplifying distribution shift lacks direct comparative evidence against alternatives

## Next Checks
1. **Distribution Shift Quantification**: Perform statistical tests (e.g., maximum mean discrepancy, Wasserstein distance) to quantify the feature space separation between bias-aligned and bias-conflicting samples, and verify that this separation correlates with debiasing performance.

2. **Algorithm Ablation with Controlled Parameters**: Compare OCSVM against other anomaly detection methods (Isolation Forest, LOF) while controlling for the same anomaly score threshold optimization procedure to isolate the contribution of the algorithm choice itself.

3. **Bias Correlation Robustness Test**: Evaluate MoDAD on a synthetic dataset with systematically varied bias correlations (e.g., 0.7, 0.8, 0.9, 0.95, 0.99) to empirically validate the claim of being "unaffected by bias correlation" and identify potential performance breakpoints.