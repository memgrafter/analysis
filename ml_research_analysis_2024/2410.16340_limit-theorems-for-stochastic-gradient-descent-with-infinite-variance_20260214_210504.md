---
ver: rpa2
title: Limit Theorems for Stochastic Gradient Descent with Infinite Variance
arxiv_id: '2410.16340'
source_url: https://arxiv.org/abs/2410.16340
tags:
- have
- where
- stochastic
- lemma
- thus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes asymptotic theory for stochastic gradient\
  \ descent (SGD) with infinite variance gradients. The authors analyze SGD under\
  \ the assumption that stochastic gradients follow a regular variation with index\
  \ \u03B1 \u2208 (1,2), extending previous one-dimensional results to multi-dimensional\
  \ settings."
---

# Limit Theorems for Stochastic Gradient Descent with Infinite Variance

## Quick Facts
- arXiv ID: 2410.16340
- Source URL: https://arxiv.org/abs/2410.16340
- Reference count: 40
- Primary result: Asymptotic analysis of SGD with infinite variance gradients showing convergence to stable distributions and Ornstein-Uhlenbeck processes

## Executive Summary
This paper establishes fundamental limit theorems for stochastic gradient descent when gradient noise exhibits infinite variance. The authors analyze SGD under heavy-tailed noise conditions where stochastic gradients follow regular variation with index α ∈ (1,2), extending previous one-dimensional results to multi-dimensional settings. For constant learning rates, they demonstrate that scaled SGD paths converge to an Ornstein-Uhlenbeck process driven by stable Lévy processes. With decaying learning rates, convergence occurs to a stationary distribution of a Lévy-driven Ornstein-Uhlenbeck process. These results reveal that heavy-tailed gradient noise leads to fundamentally different asymptotic behavior compared to finite variance cases, with convergence governed by stable distributions rather than normal distributions.

## Method Summary
The authors employ regular variation theory to characterize the asymptotic behavior of SGD under infinite variance conditions. They analyze both constant and decaying learning rates, establishing weak convergence of the scaled SGD paths to appropriate limiting processes. The mathematical framework leverages properties of stable distributions and Lévy processes, extending classical results from finite variance SGD analysis to the heavy-tailed regime. The analysis includes both theoretical derivations and applications to linear and logistic regression models with heavy-tailed errors.

## Key Results
- Scaled SGD paths with constant learning rates converge to Ornstein-Uhlenbeck processes driven by stable Lévy processes
- SGD with decaying learning rates converges to stationary distributions of Lévy-driven Ornstein-Uhlenbeck processes
- Heavy-tailed gradient noise fundamentally changes asymptotic behavior, replacing Gaussian limits with stable distributions
- Practical applications demonstrate heavy-tail phenomena in linear and logistic regression with heavy-tailed errors

## Why This Works (Mechanism)
The mechanism relies on the regular variation property of the gradient noise, which allows characterization of extreme events and tail behavior. The infinite variance condition (α ∈ (1,2)) creates a fundamentally different stochastic environment than classical SGD analysis. The stable distributions emerge as natural limits for sums of heavy-tailed random variables, while the Ornstein-Uhlenbeck structure captures the mean-reverting behavior of SGD in this regime.

## Foundational Learning

Regular Variation Theory
- Why needed: Characterizes heavy-tailed distributions and their asymptotic properties
- Quick check: Verify that the gradient noise exhibits power-law tail behavior

Stable Distributions
- Why needed: Natural limiting distributions for sums of heavy-tailed random variables
- Quick check: Confirm α-stable properties for the limiting processes

Lévy Processes
- Why needed: Stochastic processes with stationary independent increments, crucial for modeling heavy-tailed noise
- Quick check: Validate increment stationarity and independence properties

Ornstein-Uhlenbeck Processes
- Why needed: Mean-reverting stochastic processes that capture SGD dynamics
- Quick check: Verify mean-reversion and Gaussian marginal properties

Weak Convergence
- Why needed: Establishes convergence in distribution for stochastic processes
- Quick check: Confirm tightness and finite-dimensional convergence

## Architecture Onboarding

Component Map: Gradient Noise → Regular Variation → Stable Limit → OU Process → SGD Convergence

Critical Path: The key steps involve establishing regular variation properties of gradient noise, proving stable limit theorems for partial sums, and showing weak convergence of the scaled SGD process to the appropriate Ornstein-Uhlenbeck limit.

Design Tradeoffs: The assumption α ∈ (1,2) balances mathematical tractability with practical relevance, avoiding both finite variance cases and extremely heavy tails where different techniques are needed.

Failure Signatures: Convergence to incorrect limiting distributions, violation of regular variation assumptions, or breakdown of the mean-reversion property would indicate problems with the theoretical framework.

First Experiments:
1. Verify regular variation properties of synthetic heavy-tailed gradient noise
2. Test stable distribution convergence for partial sums of heavy-tailed variables
3. Validate Ornstein-Uhlenbeck approximation for SGD with constant learning rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the convergence properties of SGD change when the stochastic gradient follows a regular variation with index α ≤ 1, which falls outside the current theoretical framework?
- Basis in paper: The paper explicitly states the analysis assumes α ∈ (1,2) and does not address cases where α ≤ 1.
- Why unresolved: The mathematical techniques used for α ∈ (1,2) rely on finite p-th moments for p ∈ (2-1/α, α), which fail when α ≤ 1.
- What evidence would resolve it: Convergence rates and limiting distributions for SGD with α ≤ 1 would need to be established, potentially involving different stochastic processes than the Ornstein-Uhlenbeck process.

### Open Question 2
- Question: What is the impact of time-varying learning rates on the asymptotic behavior of SGD when stochastic gradients have infinite variance?
- Basis in paper: The paper analyzes constant and polynomially decaying learning rates, but does not explore adaptive or cyclical learning rate schedules.
- Why unresolved: The current analysis relies on specific properties of the learning rate sequences that may not hold for adaptive schedules.
- What evidence would resolve it: Theoretical analysis of adaptive learning rate schemes under infinite variance conditions, including conditions for convergence and characterization of limiting distributions.

### Open Question 3
- Question: How do the theoretical results extend to non-convex optimization problems where the objective function has multiple local minima?
- Basis in paper: The analysis assumes strongly convex loss functions, which guarantees a unique global minimum.
- Why unresolved: The current framework relies heavily on the strong convexity assumption for controlling the approximation error and establishing tightness.
- What evidence would resolve it: Extension of the asymptotic theory to non-convex settings, including conditions under which SGD converges to stationary points and characterization of the limiting distributions in such cases.

## Limitations
- Analysis restricted to α ∈ (1,2), excluding extremely heavy-tailed distributions
- Finite-sample behavior and convergence rates not characterized
- Strong convexity assumption limits applicability to non-convex optimization problems
- i.i.d. gradient noise assumption may not hold in practical scenarios with temporal correlations

## Confidence
High confidence in the theoretical framework and mathematical proofs, given the rigorous treatment of stochastic processes and regular variation theory. Medium confidence in the practical applicability of results to real-world machine learning problems, as the assumptions may be too restrictive for complex datasets. Low confidence in the extension of these results to non-convex optimization landscapes, which are more common in deep learning applications.

## Next Checks
1. Empirical validation on synthetic datasets with controlled heavy-tailed noise to verify the predicted stable distribution convergence
2. Extension of analysis to α ∈ (0,1] case to determine if similar limiting behavior emerges for more extreme heavy-tailed distributions
3. Investigation of finite-sample bounds and convergence rates to quantify the gap between theoretical limits and practical implementations