---
ver: rpa2
title: A Granger-Causal Perspective on Gradient Descent with Application to Pruning
arxiv_id: '2412.03035'
source_url: https://arxiv.org/abs/2412.03035
tags:
- pruning
- causal
- parameters
- descent
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores the implicit causality within gradient descent
  and proposes to make this relationship explicit by relating parameter changes to
  loss changes. By introducing parameter-specific coefficients, the authors establish
  a framework to identify important parameters.
---

# A Granger-Causal Perspective on Gradient Descent with Application to Pruning

## Quick Facts
- arXiv ID: 2412.03035
- Source URL: https://arxiv.org/abs/2412.03035
- Authors: Aditya Shah; Aditya Challa; Sravan Danda; Archana Mathur; Snehanshu Saha
- Reference count: 13
- Primary result: Causal pruning method outperforms magnitude pruning by identifying non-causal parameters, leading to sharper accuracy-pruning trade-offs and flatter minima

## Executive Summary
This paper introduces a novel pruning approach based on Granger causality principles applied to gradient descent. The method explicitly models the causal relationship between parameter changes and loss reduction using Lasso regression, allowing identification of parameters that genuinely contribute to learning versus those that don't. The key innovation is pruning parameters that are non-causal, leading to more effective model compression. Experiments across multiple architectures (LeNet, AlexNet, ResNet18) and datasets (CIFAR10, FashionMNIST, TinyImageNet) demonstrate that this causal pruning method achieves better accuracy-pruning trade-offs than traditional magnitude-based approaches, with evidence of flatter minima and clearer phase shifts indicating optimal pruning points.

## Method Summary
The method employs a three-phase training procedure: pre-training the model to reach a basin of attraction, iterative pruning using Lasso regression to identify non-causal parameters, and post-training to evaluate performance. During pruning, parameter changes and losses are collected over Nprune epochs, then Lasso regression with L1 regularization is fitted to establish the causal relationship between parameter updates and loss reduction. Parameters with coefficients (γk) close to zero are considered non-causal and pruned. This process is repeated Niter times to progressively prune more parameters. The approach assumes that parameters contributing consistently to loss reduction are more important than those with large magnitudes but no causal effect on the loss.

## Key Results
- Causal pruning achieves higher accuracy than magnitude pruning at equivalent pruning percentages across multiple architectures and datasets
- The method exhibits clearer phase shifts in accuracy-pruning trade-off curves, indicating more optimal pruning strategies
- Post-pruning models show flatter minima (verified through Hessian eigenvalue analysis) compared to magnitude pruning, suggesting better generalization
- Parameter-specific coefficients (γk) obtained from the causal analysis correlate with parameter importance more effectively than magnitude-based rankings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal pruning identifies more effective parameter subsets than magnitude-based pruning
- Mechanism: By modeling the causal relationship between parameter changes and loss reduction, the method distinguishes genuinely important parameters from those with large magnitudes but no causal effect
- Core assumption: Parameters that consistently contribute to loss reduction are more important than those that don't, regardless of magnitude
- Evidence anchors:
  - [abstract] "causal pruning leads to sharper accuracy-pruning trade-offs, with phase shifts indicating optimal pruning points, and results in flatter minima compared to magnitude pruning."
  - [section] "In this article, we prune the parameters which turn out to be non-causal and hence refer to this procedure as causal pruning. As evidence to our hypothesis, we indeed observe that causal pruning finds a better optimal subset than the competitive methods such as magnitude pruning."
- Break condition: If the implicit causal relationship becomes too complex to capture with the proposed linear model, or if noise in training overwhelms the causal signal

### Mechanism 2
- Claim: Causal pruning results in flatter minima, correlating with better generalization
- Mechanism: Removing non-causal parameters reduces model complexity without sacrificing accuracy, leading to a flatter loss landscape
- Core assumption: Flatter minima lead to better generalization, and removing non-causal parameters reduces complexity effectively
- Evidence anchors:
  - [abstract] "After pruning, we see that minima becomes 'flatter', explaining the increase in accuracy after pruning weights."
  - [section] "We observe that causal pruning either improves (in the sense of flatter minima) the eigenspectrum of the Hessian or remains the same as the no-prune network. In contrast, magnitude pruning increases the eigenvalue spectrum by a large margin."
- Break condition: If the flatness-generalization relationship breaks down for certain architectures, or if pruning removes too many parameters causing underfitting

### Mechanism 3
- Claim: Phase shift in accuracy-pruning curves indicates optimal pruning strategy
- Mechanism: An optimal method should show sharp accuracy drops when pruning beyond the essential parameter set, which causal pruning demonstrates more clearly
- Core assumption: Clear phase shifts indicate that all non-essential parameters have been removed, marking the optimal pruning point
- Evidence anchors:
  - [abstract] "We observe a phase shift as the percentage of pruned parameters increase. Such phase shift is indicative of an optimal pruning strategy."
  - [section] "Observe that the causal pruning reaches very close to the top-right corner, where removing even ≈ 2% (going from 96% to 98% pruned percent) more parameters results in a significant drop in accuracy. Contrast this with magnitude pruning, where the drop is much 'smoother'."
- Break condition: If phase shifts become less pronounced or disappear for certain architectures, or if sharp drops occur at impractically low pruning percentages

## Foundational Learning

- Concept: Granger Causality
  - Why needed here: The paper's core idea is based on the implicit Granger-causal relationship in gradient descent, made explicit through the proposed method
  - Quick check question: What is the key difference between Granger causality and traditional causality in the context of this paper?

- Concept: Lasso Regression
  - Why needed here: Used to fit the linear model capturing the causal relationship between parameter changes and loss reduction, enabling feature selection (parameter pruning)
  - Quick check question: How does the L1 regularization in Lasso regression contribute to the parameter pruning process?

- Concept: Sharp vs. Flat Minima
  - Why needed here: The paper uses this concept to explain the relationship between pruning strategy and model generalization
  - Quick check question: Why is finding a flatter minimum after pruning considered beneficial for model generalization?

## Architecture Onboarding

- Component map: Pre-training phase → Pruning phase (Niter iterations) → Post-training phase
- Critical path: Pre-training → Pruning (Niter iterations) → Post-training
- Design tradeoffs:
  - Computational complexity vs. pruning efficiency: Increasing Niter and Nprune improves pruning efficiency but increases computational cost
  - Storage requirements vs. pruning accuracy: Saving checkpoints after each gradient step requires more storage but provides more accurate data for fitting the Lasso regression model
- Failure signatures:
  - If accuracy drops significantly after pruning, it may indicate too many important parameters were pruned or Lasso regression failed to capture causal relationships
  - If the phase shift in accuracy-pruning trade-off curve is not observed, it may suggest the pruning method is not optimal or the architecture is unsuitable
- First 3 experiments:
  1. Run causal pruning on a small, over-parameterized network (e.g., LeNet on CIFAR10) to observe the phase shift in the accuracy-pruning trade-off curve
  2. Compare the eigenvalues of the Hessian at the minima for models pruned using causal pruning vs. magnitude pruning to verify the claim about flatter minima
  3. Vary the L1 regularization coefficient (L1 coeff) in the Lasso regression to observe its effect on the percentage of pruned parameters and model accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Granger-causal pruning approach generalize to structured pruning (e.g., channel-level or layer-level pruning) compared to unstructured pruning?
- Basis in paper: [explicit] The authors mention that structured pruning can be adapted using a weight-sharing strategy where γk is equal for all parameters within a layer or filter
- Why unresolved: The paper only considers parameter-level pruning and mentions structured pruning as a potential extension without providing experimental validation or detailed methodology
- What evidence would resolve it: Experiments comparing the performance of Granger-causal pruning on structured pruning tasks versus unstructured pruning, including accuracy, computational efficiency, and comparison with existing structured pruning methods

### Open Question 2
- Question: What is the relationship between the γk coefficients obtained from Granger-causal pruning and the optimal parameter-specific learning rates in first-order optimization?
- Basis in paper: [explicit] The authors suggest that the parameters γk obtained as causal pruning are related to the "optimal" parameter-specific learning rate of the first-order optimization
- Why unresolved: The paper proposes this connection but does not provide a detailed mathematical derivation or experimental evidence to support this claim
- What evidence would resolve it: A theoretical analysis linking the γk coefficients to optimal learning rates, along with experiments demonstrating improved convergence or generalization when using γk-informed learning rates in optimization

### Open Question 3
- Question: How does the Granger-causal pruning approach perform on larger-scale models and datasets, such as ResNet50 on ImageNet, compared to state-of-the-art pruning methods like CHITA?
- Basis in paper: [explicit] The authors provide a comparison with CHITA on ResNet50 for ImageNet but note that their objectives differ and the comparison is observational without hyper-parameter tuning
- Why unresolved: The comparison with CHITA is limited and lacks rigorous experimental setup, including hyper-parameter optimization and computational resource parity
- What evidence would resolve it: A comprehensive experimental study comparing Granger-causal pruning with CHITA on ResNet50 for ImageNet, including hyper-parameter tuning, consistent computational resources, and evaluation metrics such as accuracy, pruning ratio, and inference speed

## Limitations
- The linear causal model may not capture complex relationships in deeper architectures where the parameter-loss relationship becomes highly non-linear
- Computational overhead of saving checkpoints and fitting Lasso regression at every step may limit scalability to very large models
- Focus on standard vision datasets and architectures leaves open questions about generalization to other domains like NLP or reinforcement learning

## Confidence
- Mechanism 1 (Causal vs. magnitude pruning effectiveness): High confidence - supported by clear experimental comparisons and theoretical framing
- Mechanism 2 (Flatter minima correlation): Medium confidence - the flatness-generalization link is well-established, but the specific causal mechanism needs more rigorous validation
- Mechanism 3 (Phase shift as optimality indicator): Medium confidence - observed empirically but requires theoretical justification for why this behavior specifically indicates optimality

## Next Checks
1. Test the method on architectures with residual connections (ResNet variants) to verify that the causal relationship remains tractable when gradients can skip layers
2. Perform ablation studies on the frequency of Lasso regression fitting (e.g., every step vs. every epoch) to quantify the trade-off between computational cost and pruning quality
3. Validate the phase shift phenomenon on a regression task (e.g., tabular data) to test whether this behavior is specific to classification or more general across problem types