---
ver: rpa2
title: 'Memory GAPS: Would LLMs pass the Tulving Test?'
arxiv_id: '2402.16505'
source_url: https://arxiv.org/abs/2402.16505
tags:
- memory
- word
- cues
- recall
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether the GAPS framework sheds light
  on Large Language Models (LLMs) acts of remembering. The author adapts the Tulving
  Test, originally designed to investigate human memory performance in recognition
  and recall tasks, to LLM subjects.
---

# Memory GAPS: Would LLMs pass the Tulving Test?

## Quick Facts
- arXiv ID: 2402.16505
- Source URL: https://arxiv.org/abs/2402.16505
- Authors: Jean-Marie Chauvet
- Reference count: 22
- Primary result: LLMs achieve near-perfect immediate recognition but show degraded delayed recall, with semantic memory dominance over episodic traces

## Executive Summary
This paper adapts the Tulving Test—a classic framework for studying human memory recognition and recall—to investigate whether Large Language Models (LLMs) exhibit memory-like behaviors. Using a standard set of 48 words and various cue types (copy, associate, rhyme, unrelated), the study compares LLM performance against human memory patterns. The findings reveal that while LLMs perform immediate recognition tasks with near-perfect accuracy, their delayed recall capabilities are notably weaker, particularly for copy cues and ordinal prompts. These results suggest that LLMs rely more heavily on semantic associations formed during pretraining rather than episodic-like memory traces, providing insights into the nature of memory-like processes in transformer-based architectures.

## Method Summary
The study uses the mistral-7b-instruct-v0 LLM to conduct immediate and delayed recognition and recall tests with 48 common English words. Each test uses 32 cue words (8 copy cues, 8 associate cues, 8 rhyme cues, 8 unrelated cues). Immediate tests present the study list and cue in a single prompt, while delayed tests use multi-turn chat interactions. Performance is measured as proportions of correct recognition and recall across different cue types. The experimental setup includes Python scripts interacting with the LLM via LLM CLI, with response parsing and analysis conducted through custom code.

## Key Results
- LLMs achieve near-perfect immediate recognition (100% familiarity for copy cues, no false positives for non-copy cues)
- Delayed recall performance degrades significantly, especially for copy cues and ordinal prompts
- Semantic associations from pretraining dominate over list-specific episodic traces in delayed recall tasks
- Rhyme cue words fail almost systematically at evoking target words in the list during delayed recall

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs demonstrate recognition performance close to perfect due to strong pretraining on semantic associations.
- Mechanism: The pretraining phase builds a robust probability distribution over tokens, enabling near-flawless mapping from cue to known word in immediate tests.
- Core assumption: Semantic memory formed during pretraining dominates recognition tasks when cue matches learned patterns.
- Evidence anchors:
  - [abstract] "semantic memory information learned during LLM pretraining outweighs episodic memory traces in delayed recall tasks"
  - [section] "Remarkably and contrasting with the human subject, in the immediate recognition task the LLM never erred: no false positives for non-copy cues and 100% familiarity for copy cues"
- Break condition: If pretraining distribution fails to capture the word or context shifts beyond learned semantic associations.

### Mechanism 2
- Claim: Delayed recall degrades in LLMs due to context window limits and weaker episodic-like memory traces.
- Mechanism: Without continuous context, the model loses trace-like cues, causing failure especially on copy cues and ordinal prompts.
- Core assumption: Episodic-like traces in LLMs are shallow and highly dependent on context continuity.
- Evidence anchors:
  - [section] "And in the delayed recall test, the LLM systematically fails on copy cues... Rhyme cue words fail almost systematically at evoking a target word in the list"
  - [abstract] "weaker delayed recall, especially with copy and ordinal cues"
- Break condition: When context window is extended or episodic-like retrieval is reinforced via prompt engineering.

### Mechanism 3
- Claim: LLM retrieval relies more on semantic associations than episodic traces, especially in delayed tasks.
- Mechanism: Retrieval cues trigger pretrained semantic links rather than learned list-specific patterns, leading to semantic dominance over episodic recall.
- Core assumption: Pretrained semantic knowledge is more stable and accessible than context-bound episodic traces in LLMs.
- Evidence anchors:
  - [section] "in delayed recall tests of LLM with copy cue words, the responses were mostly correct associate words, whether or not included in the study list, as if the pretrained associations took over the episodic memory traces"
  - [abstract] "semantic memory information learned during LLM pretraining outweighs episodic memory traces in delayed recall tasks"
- Break condition: When episodic-like retrieval is explicitly reinforced or the cue set is limited to novel list-specific items.

## Foundational Learning

- Concept: Episodic vs Semantic Memory
  - Why needed here: Framework for interpreting LLM performance differences in recognition vs recall tasks.
  - Quick check question: What distinguishes Tulving's episodic memory from semantic memory in terms of content and function?

- Concept: GAPS (General Abstract Processing System)
  - Why needed here: Provides decomposition of memory processes into encoding, ecphory, and conversion relevant to LLM analogy.
  - Quick check question: Which GAPS elements correspond to encoder and decoder in Transformer architecture?

- Concept: Vector Embeddings and Probability Distributions
  - Why needed here: Core mechanism by which LLMs store and retrieve information analogous to engrams.
  - Quick check question: How does the softmax output in a transformer layer represent semantic associations?

## Architecture Onboarding

- Component map: Input tokens -> Encoder (transforms to contextualized embeddings) -> Attention-based retrieval -> Probability distribution -> Output decoding
- Critical path: 1. Prompt encoding → 2. Context embedding → 3. Attention-based retrieval → 4. Probability distribution → 5. Output decoding
- Design tradeoffs:
  - Larger context windows improve episodic-like recall but increase compute cost
  - Stronger pretraining improves semantic recall but may overshadow episodic traces
  - Prompt structure affects ecphoric processes (Tulving's suggestion)
- Failure signatures:
  - Perfect immediate recognition but degraded delayed recall
  - Copy cues failing in delayed recall despite being the target
  - Semantic associations dominating over list-specific traces in delayed tasks
- First 3 experiments:
  1. Replicate immediate vs delayed recognition/recall test with varied context lengths
  2. Test ordinal cue retrieval to assess position-based memory traces
  3. Modify prompt structure to isolate encoding vs retrieval process effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the balance between semantic memory information and engram information differ in LLMs compared to human subjects, particularly in delayed recall tasks?
- Basis in paper: [explicit] The paper states that "semantic memory information, built by pretraining a LLM, and imported by cues into the retrieval information outweighs the engram information of episodic memory."
- Why unresolved: The exact quantitative balance between semantic and engram information in LLMs is not established, and the mechanism by which this balance affects delayed recall tasks is not fully understood.
- What evidence would resolve it: Further experiments quantifying the influence of semantic and engram information in LLMs, possibly through variations in pretraining data or architectural modifications, could provide insights into this balance.

### Open Question 2
- Question: What role does the retrieval cue play in LLMs compared to human memory, and how does this affect the ecphory process?
- Basis in paper: [explicit] The paper notes that "data from Table 5 may suggest that for LLMs the role of retrieval information might be at variance with its role in human memory ecphory as posited by Tulving."
- Why unresolved: The exact differences in how retrieval cues function in LLMs versus human memory are not clearly defined, and the implications for the ecphory process are not fully explored.
- What evidence would resolve it: Comparative studies of retrieval cue effectiveness in LLMs and humans, possibly through controlled experiments with varied cue types, could elucidate these differences.

### Open Question 3
- Question: How do different prompt structures in LLMs influence the ecphoric process, and do they align with Tulving's theories on conversion thresholds?
- Basis in paper: [explicit] The paper suggests that "different structures in the prompts, expressing recognition requests versus recall requests, may indeed entail different ecphoric processes rather than different quantity of information being required."
- Why unresolved: The impact of prompt structure on the ecphoric process in LLMs is not quantitatively assessed, and its alignment with Tulving's conversion thresholds is speculative.
- What evidence would resolve it: Experimental variations in prompt structures and their effects on LLM memory performance could provide empirical data to support or refute the influence of prompt structure on the ecphoric process.

## Limitations

- Single model dependency: Results are based on mistral-7b-instruct-v0 only, limiting generalizability across architectures
- Prompt specification gaps: Exact prompt templates and instructions are not fully detailed, introducing potential variability
- Context window constraints: Systematic variation of context window lengths was not performed to quantify their impact
- Human comparison baseline: Specific experimental conditions and subject pools for human performance data are not detailed

## Confidence

- High Confidence: Near-perfect immediate recognition with degraded delayed recall is consistently demonstrated across cue types
- Medium Confidence: Semantic memory dominance over episodic traces is supported but alternative explanations cannot be fully ruled out
- Low Confidence: The specific mechanism by which pretraining creates stable semantic associations that override episodic traces lacks detailed architectural analysis

## Next Checks

1. **Architecture ablation study**: Test the same Tulving Test protocol across multiple LLM architectures (GPT, Claude, Llama, etc.) with varying context window sizes and parameter counts to isolate whether observed patterns are model-specific or general to transformer-based systems.

2. **Prompt engineering validation**: Systematically vary prompt structures (single prompt vs. multi-turn, explicit vs. implicit instructions) while keeping the test words constant to determine how much performance variation stems from prompt design versus inherent memory architecture.

3. **Context window manipulation**: Conduct experiments with artificially extended context windows (through prompt engineering or model modifications) to quantify the relationship between available context and delayed recall performance, particularly for copy and ordinal cues.