---
ver: rpa2
title: 'SADDLe: Sharpness-Aware Decentralized Deep Learning with Heterogeneous Data'
arxiv_id: '2405.13961'
source_url: https://arxiv.org/abs/2405.13961
tags:
- learning
- q-saddle
- compression
- n-saddle
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SADDLe (Sharpness-Aware Decentralized Deep
  Learning), a set of algorithms designed to improve decentralized learning on heterogeneous
  data. SADDLe leverages Sharpness-Aware Minimization (SAM) to seek flatter loss landscapes
  during training, which helps alleviate local overfitting and improves global model
  generalization.
---

# SADDLe: Sharpness-Aware Decentralized Deep Learning with Heterogeneous Data

## Quick Facts
- **arXiv ID**: 2405.13961
- **Source URL**: https://arxiv.org/abs/2405.13961
- **Reference count**: 40
- **Key outcome**: SADDLe achieves 1-20% improvement in test accuracy compared to existing decentralized learning techniques while demonstrating enhanced robustness to communication compression

## Executive Summary
This paper proposes SADDLe (Sharpness-Aware Decentralized Deep Learning), a set of algorithms designed to improve decentralized learning on heterogeneous data. SADDLe leverages Sharpness-Aware Minimization (SAM) to seek flatter loss landscapes during training, which helps alleviate local overfitting and improves global model generalization. The authors present two versions of their approach: Q-SADDLe (incorporating a Quasi Global Momentum buffer) and N-SADDLe (utilizing cross-gradient information). The proposed methods achieve significant accuracy improvements over existing techniques and demonstrate enhanced robustness to communication compression, with only a 1% average drop in accuracy for up to 4x compression. Theoretical analysis shows that SADDLe's convergence rate matches the well-known best result in decentralized learning.

## Method Summary
SADDLe improves decentralized learning by incorporating Sharpness-Aware Minimization into existing decentralized optimization frameworks. The method introduces two variants: Q-SADDLe, which adds SAM-based gradient updates to the Quasi Global Momentum framework, and N-SADDLe, which incorporates cross-gradient information with SAM. Both approaches seek flatter loss landscapes by perturbing model parameters during training to minimize both loss value and sharpness simultaneously. This flatness-seeking behavior leads to better generalization on heterogeneous data and improved robustness to communication compression errors.

## Key Results
- SADDLe achieves 1-20% improvement in test accuracy compared to existing decentralized learning techniques
- Enhanced robustness to communication compression, with only 1% average accuracy drop for up to 4× compression
- Convergence rate analysis shows SADDLe matches the O(1/√(nT)) rate of state-of-the-art decentralized learning algorithms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sharpness-Aware Minimization (SAM) improves generalization in decentralized learning by seeking flatter loss landscapes
- Mechanism: SAM modifies the local optimizer at each agent to simultaneously minimize loss value and loss sharpness by adding a perturbation ξi to model parameters during training. This perturbation is obtained through a scaled gradient ascent step, causing the optimizer to search for parameters whose neighborhoods have uniformly low loss values rather than just finding parameters with low loss values.
- Core assumption: Flatter loss landscapes correlate with better generalization and are more robust to communication compression errors
- Evidence anchors:
  - [abstract] "SADDLe leverages Sharpness-Aware Minimization (SAM) to seek a flatter loss landscape during training, resulting in better model generalization as well as enhanced robustness to communication compression"
  - [section 4.1] "SADDLe improves generalization by simultaneously minimizing the loss value and the sharpness through gradient perturbation"
  - [corpus] Weak - the corpus papers focus on communication compression and gossip algorithms but don't directly address flatness-seeking optimizers
- Break condition: If the relationship between flatness and generalization doesn't hold for certain architectures or data distributions, or if the additional computational cost of the perturbation step outweighs the generalization benefits

### Mechanism 2
- Claim: Flatter loss landscapes are more robust to communication compression errors
- Mechanism: When using communication compression, models with flatter loss landscapes produce model updates (xi - x̂i) with lower norms, which leads to tighter bounds on compression error. This is because the bound EQ∥Q(θ) - θ∥2 ≤ (1 - δ)∥θ∥2 becomes tighter when ∥θ∥ is smaller, resulting in lower compression error and thus less accuracy degradation.
- Core assumption: The compression error bound directly relates to model update norms, and flatter landscapes produce smaller updates
- Evidence anchors:
  - [section 4.2] "Interestingly, Comp Q-SADDLe and Comp N-SADDLe incur less compression error than Comp QGM and Comp NGM respectively, leading to a lower accuracy drop due to compression"
  - [section 4.2] "Figure 2 shows the norm of compression error (i.e., ∥Q(θ) - θ∥) and the norm of model updates (i.e., ∥θ∥ = ∥xi - x̂i∥) for Comp QGM and Comp Q-SADDLe"
  - [corpus] Missing - the corpus doesn't provide evidence about the relationship between loss landscape flatness and compression error robustness
- Break condition: If the compression scheme itself introduces errors that dominate the benefits from flatter landscapes, or if the relationship between flatness and update norms doesn't hold for certain model architectures

### Mechanism 3
- Claim: Q-SADDLe achieves convergence rate matching existing decentralized learning algorithms
- Mechanism: By incorporating SAM-based gradient updates within the Quasi-Global Momentum framework, Q-SADDLe maintains the O(1/√(nT)) convergence rate while adding a term related to the perturbation radius ρ. The analysis shows that the additional terms introduced by SAM (1/T^3/2 and 1/T^2) are dominated by the main convergence term when T is sufficiently large.
- Core assumption: The SAM perturbation doesn't fundamentally alter the convergence dynamics of decentralized learning beyond adding higher-order terms
- Evidence anchors:
  - [section 5] "We observe that the convergence rate includes three main terms related to the suboptimality gap f(x̄0) - f*, the sampling variance σ and the gradient variance δ representing data heterogeneity, followed by an additional term compared to existing state-of-the-art decentralized convergence bounds"
  - [section 5] "Corollary 2 shows that the dominant term here is (1/√(nT)), and the terms introduced because of the additional SGD step for flatness (i.e., 1/T^3/2 and 1/T^2) can be ignored due to their higher order"
  - [corpus] Weak - the corpus papers focus on communication compression and gossip algorithms but don't directly address convergence analysis with flatness-seeking optimizers
- Break condition: If the perturbation radius ρ is too large, causing the additional terms to dominate the convergence rate, or if the assumptions about smoothness and bounded variance don't hold for the specific problem

## Foundational Learning

- Concept: Decentralized learning with non-IID data
  - Why needed here: The paper specifically addresses the challenge of decentralized learning where data distribution across agents is heterogeneous (non-IID), which leads to local overfitting and poor global model generalization
  - Quick check question: What is the main challenge that decentralized learning faces when data is non-IID across agents, and how does this differ from IID settings?

- Concept: Sharpness-Aware Minimization (SAM)
  - Why needed here: SAM is the core optimization technique used to seek flatter loss landscapes, which is central to both the generalization improvement and compression robustness claims
  - Quick check question: How does SAM differ from standard gradient descent in terms of what it optimizes for during training?

- Concept: Communication compression in decentralized learning
  - Why needed here: The paper evaluates how SAM-based approaches perform under communication compression, which is crucial for practical deployment of decentralized learning systems
  - Quick check question: What is the primary benefit of communication compression in decentralized learning, and what is the main tradeoff?

## Architecture Onboarding

- Component map: Data → SAM perturbation → Local gradient computation → Momentum update → Model aggregation → Communication (compressed or full) → Repeat
- Critical path: Data → SAM perturbation → Local gradient computation → Momentum update → Model aggregation → Communication (compressed or full) → Repeat
- Design tradeoffs:
  - SAM adds computational overhead (extra backward pass) but improves generalization and compression robustness
  - Communication compression reduces bandwidth but introduces error that flatter landscapes help mitigate
  - Momentum buffer helps with non-IID data but requires maintaining additional state
  - Perturbation radius ρ controls flatness-seeking strength vs. training stability
- Failure signatures:
  - Training divergence: Check if perturbation radius ρ is too large or learning rate η is too high
  - Poor generalization: Verify SAM is properly implemented and perturbation is being applied
  - Compression causing large accuracy drop: Ensure mixing matrix W is properly normalized and compression scheme is appropriate
  - Slow convergence: Check momentum coefficients β and µ, and verify they're not too close to 1
- First 3 experiments:
  1. Baseline comparison: Run QGM vs Q-SADDLe on CIFAR-10 with ring topology and α=0.001 to verify the 8.4% accuracy improvement claim
  2. Compression robustness: Test QGM vs Q-SADDLe with 8-bit stochastic quantization to confirm the 1% vs 4.3% accuracy drop difference
  3. Ablation study: Compare DPSGD vs D-SADDLe to verify SAM improves performance even in simpler decentralized settings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SADDLe perform in settings where the mixing matrix W is time-varying or directed, rather than doubly stochastic and symmetric as assumed in the paper?
- Basis in paper: [explicit] The authors acknowledge this as a limitation in Section 7, stating that SADDLe is incompatible with time-varying and directed graphs due to its assumption of a doubly stochastic and symmetric mixing matrix W.
- Why unresolved: The paper does not provide experimental results or theoretical analysis for such scenarios, leaving the performance of SADDLe in these settings unknown.
- What evidence would resolve it: Experimental results comparing SADDLe's performance on time-varying or directed graphs against baselines, or theoretical analysis extending the convergence guarantees to these more general graph settings.

### Open Question 2
- Question: Can the computational overhead introduced by SAM's additional backward pass for computing the perturbation ξi be mitigated without sacrificing performance?
- Basis in paper: [explicit] The authors mention this as a potential limitation in Section 7, suggesting that compute-efficient variants of SAM could be explored to reduce the computational cost.
- Why unresolved: The paper does not investigate or compare the performance of SADDLe with such compute-efficient SAM variants, leaving the trade-off between computational efficiency and model performance unclear.
- What evidence would resolve it: Experimental results comparing SADDLe with and without compute-efficient SAM variants, measuring both accuracy and computational time, to determine if performance can be maintained while reducing computational overhead.

### Open Question 3
- Question: How does the performance of SADDLe scale with extremely large numbers of agents or very large models?
- Basis in paper: [inferred] While the paper presents results for various graph sizes (5 to 40 agents) and models (ResNet-20, ResNet-18, MobileNet-v2), it does not explore scenarios with extremely large numbers of agents or very large models like those used in modern deep learning applications.
- Why unresolved: The paper's experimental setup does not include such extreme scenarios, and the theoretical analysis does not explicitly address scalability concerns for very large-scale systems.
- What evidence would resolve it: Experimental results on decentralized learning with hundreds or thousands of agents and very large models, measuring convergence speed, communication efficiency, and final accuracy to determine if SADDLe's benefits hold at scale.

## Limitations
- The paper assumes a doubly stochastic and symmetric mixing matrix W, limiting compatibility with time-varying and directed graphs
- SAM's additional backward pass introduces computational overhead that could impact training efficiency
- The theoretical analysis does not fully account for the computational overhead of SAM's additional gradient computations

## Confidence

- **High confidence**: The empirical accuracy improvements (1-20%) and compression robustness results are well-supported by experiments across multiple datasets and compression schemes
- **Medium confidence**: The theoretical convergence analysis is sound but depends on assumptions about bounded variance and smoothness that may not hold in all practical scenarios
- **Medium confidence**: The mechanism linking flatness to compression robustness is intuitively compelling but lacks rigorous mathematical proof

## Next Checks

1. Conduct ablation studies varying the perturbation radius ρ to quantify the tradeoff between flatness-seeking strength and computational overhead
2. Perform experiments on additional non-IID data distributions beyond Dirichlet to verify robustness to extreme heterogeneity
3. Implement theoretical compression error bounds to rigorously validate the claimed relationship between flatness and compression robustness