---
ver: rpa2
title: A Rule-Based Behaviour Planner for Autonomous Driving
arxiv_id: '2407.00460'
source_url: https://arxiv.org/abs/2407.00460
tags:
- rule
- layer
- rules
- behaviour
- autonomous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a two-layer rule-based behavior planner for
  autonomous driving, addressing the challenge of creating transparent and explainable
  decision-making systems. The approach uses a rule engine learned from expert driving
  decisions, with the first layer determining feasible parametrized behaviors and
  the second layer resolving parameters into a single behavior.
---

# A Rule-Based Behaviour Planner for Autonomous Driving

## Quick Facts
- arXiv ID: 2407.00460
- Source URL: https://arxiv.org/abs/2407.00460
- Authors: Bouchard Frederic; Sedwards Sean; Czarnecki Krzysztof
- Reference count: 26
- One-line primary result: 98% autonomy over 110 km with up to 300 Hz decision-making speed using a two-layer rule-based behavior planner

## Executive Summary
This paper presents a rule-based behavior planner for autonomous driving that addresses the challenge of creating transparent and explainable decision-making systems. The approach uses a two-layer rule engine learned from expert driving decisions, with the first layer determining feasible parametrized behaviors and the second layer resolving parameters into a single behavior. The system was implemented in a level-3 autonomous vehicle and tested on public urban roads, achieving high autonomy rates while providing immediate identification and potential fixing of logical errors.

## Method Summary
The method employs a two-layer rule-based system where the first layer (maneuver layer) uses environment properties to generate a set of feasible parameterized behaviors, then selects the most conservative maneuver. The second layer (parameter layer) resolves parameter conflicts to produce a single behavior. Rules are learned incrementally using a backward-chaining coverage function that systematically adds or refines rules based on expert-labeled training scenes. The resolution function uses a predefined hierarchy of maneuver conservativeness to ensure safe behavior selection, with Emergency-Stop being the most conservative and Track-Speed the least.

## Key Results
- Achieved 98% autonomy over 110 km testing on public urban roads
- Decision-making speed reached up to 300 Hz
- Successfully identified and potentially fixed logical errors immediately due to transparent rule structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-layer rule-based structure allows transparent, explainable decisions that can be debugged and updated incrementally.
- Mechanism: The first layer generates feasible parameterized behaviors using environment properties, while the second layer resolves parameter conflicts to produce a single behavior. This separation allows logical errors to be identified and fixed at the appropriate layer.
- Core assumption: Driving decisions can be decomposed into high-level maneuver selection followed by parameter resolution without loss of expressiveness.
- Evidence anchors:
  - [abstract] "The approach uses a rule engine learned from expert driving decisions, with the first layer determining feasible parametrized behaviors and the second layer resolving parameters into a single behavior."
  - [section] "The purpose of the parameter layer is to resolve this ambiguity, using different properties and a different set of rules to the maneuver layer."
- Break condition: If driving scenarios require complex interdependencies between maneuver choice and parameter selection that cannot be cleanly separated.

### Mechanism 2
- Claim: The backward-chaining coverage function enables incremental rule learning from expert-labeled examples.
- Mechanism: For each misclassified training scene, the algorithm adds or refines rules to ensure the correct behavior is included in the output set. It uses random selection to avoid bias and terminates when all training scenes are correctly classified.
- Core assumption: Expert-labeled training scenes can be systematically used to generate rules that generalize to novel scenarios.
- Evidence anchors:
  - [section] "To learn the theory, we assume an expert provides a finite set of training scenes E ⊆ S and an associated labelling function L : E → B that assigns a behaviour to every training scene."
  - [section] "The main method of the Rule Engine Update algorithm (Alg. 1) exploits the common structure of the two layers, calling the RuleUpdate subroutine (Alg. 2) per layer."
- Break condition: If the expert-labeled training set is too small or contains inconsistent labels that prevent rule generalization.

### Mechanism 3
- Claim: The resolution function based on maneuver conservativeness ensures safe behavior selection.
- Mechanism: A total order relation ≻ defines conservativeness among maneuvers (Emergency-Stop ≻ Track-Speed), and the resolution function λman selects behaviors with the highest-priority maneuver.
- Core assumption: A predefined hierarchy of maneuver conservativeness accurately captures safety priorities for all driving scenarios.
- Evidence anchors:
  - [section] "We first narrow the range of behaviours seen in the output of the maneuver layer, using a relation ≻ that defines a total order over the conservativeness of high-level maneuvers."
  - [section] "We can thus write Emergency-Stop ≻ Track-Speedto mean Emergency-Stop is more conservative than Track-Speed."
- Break condition: If safety priorities vary significantly across different driving contexts or cultures.

## Foundational Learning

- Concept: Rule-based systems and their syntax
  - Why needed here: Understanding the IF antecedent THEN consequent structure and how constraints are evaluated is fundamental to grasping how the rule engine makes decisions.
  - Quick check question: How does the rule engine determine which rules are triggered for a given scene?

- Concept: Backward-chaining inference
  - Why needed here: The learning algorithm uses backward-chaining to find rules that cover misclassified training scenes and refine them.
  - Quick check question: What happens when a rule has no coverage in the training scenes?

- Concept: Conservative decision-making in autonomous driving
  - Why needed here: The system prioritizes conservative maneuvers to ensure safety, which is central to the behavior planner's design philosophy.
  - Quick check question: How does the resolution function ensure the most conservative behavior is selected?

## Architecture Onboarding

- Component map: Mission Planner -> Behavior Planner -> Local Planner -> Vehicle Controller
- Critical path: Perception → Behavior Planner → Local Planner → Vehicle Controller
- Design tradeoffs:
  - Transparency vs. performance: Rule-based systems are explainable but may require more rules than learned approaches
  - Modularity vs. optimality: Two-layer structure is maintainable but may not capture all interdependencies
  - Conservative vs. efficient: Prioritizing safety may lead to overly cautious behavior
- Failure signatures:
  - High intervention rate by safety driver indicates rule coverage gaps
  - Oscillating behavior between maneuvers suggests parameter resolution issues
  - Slow decision-making points to computational bottlenecks in rule evaluation
- First 3 experiments:
  1. Unit test each rule layer independently with synthetic scenes to verify correct behavior selection
  2. Integration test with simplified perception data to validate end-to-end decision making
  3. Field test in controlled environment to measure intervention rate and identify ODD limitations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the maximum number of rules and constraints that the current rule-based approach can handle before experiencing tractability issues?
- Basis in paper: [inferred] The authors mention potential tractability concerns if the number of rules or data structures significantly increases, but they did not encounter any problems with their prototype implementation.
- Why unresolved: The authors have not conducted experiments to determine the upper limit of rules and constraints their approach can handle without performance degradation.
- What evidence would resolve it: Systematic experiments varying the number of rules and constraints, measuring decision-making speed and memory usage, to identify the point where performance becomes unacceptable.

### Open Question 2
- Question: How does the performance of the rule-based approach compare to deep learning methods in terms of data efficiency and adaptability to new driving scenarios?
- Basis in paper: [explicit] The authors mention that their approach achieves similar autonomy to a deep learning method but acknowledge that their rule-based approach is not rigorously compared due to different tasks and ODDs. They also note that standard machine learning approaches are known to be data inefficient.
- Why unresolved: The authors have not conducted a direct comparison of data efficiency and adaptability between their rule-based approach and deep learning methods under the same conditions.
- What evidence would resolve it: Comparative studies measuring the amount of data required to achieve a certain level of performance and the ability to adapt to new scenarios for both approaches.

### Open Question 3
- Question: How can the rule-based approach be extended to handle more complex driving scenarios and additional high-level maneuvers?
- Basis in paper: [explicit] The authors mention ongoing work to extend the ODD of their prototype rule engine by adding new high-level maneuvers and further stratifying the rule-based theory.
- Why unresolved: The authors have not yet implemented or tested these extensions, and the specific methods for handling more complex scenarios are not detailed.
- What evidence would resolve it: Implementation and testing of the extended rule engine in increasingly complex driving scenarios, demonstrating its ability to handle new maneuvers and adapt to changing conditions.

## Limitations
- The rule-based approach requires expert-labeled training data and may struggle with complex scenarios requiring nuanced decision-making
- The system's performance heavily depends on the quality and coverage of the training scenes
- The fixed maneuver hierarchy may not capture all safety priorities across different driving contexts

## Confidence
- **High Confidence:** The two-layer architecture design and the general learning algorithm (backward-chaining coverage function) are well-established concepts with clear implementation details.
- **Medium Confidence:** The claim of 98% autonomy and 300 Hz decision-making speed is based on real-world testing, but the specific scenarios and conditions are not fully detailed, making independent verification challenging.
- **Low Confidence:** The generalizability of the rule-based theory to novel scenarios and its ability to handle complex driving situations not covered in the training data is uncertain without extensive testing in diverse environments.

## Next Checks
1. **OOD Testing:** Conduct rigorous testing in scenarios significantly different from the training data to evaluate the rule-based theory's generalization capabilities and identify potential coverage gaps.
2. **Safety Priority Validation:** Analyze the maneuver hierarchy's effectiveness across different cultural and legal driving contexts to ensure the conservativeness relation accurately captures safety priorities.
3. **Performance Benchmarking:** Compare the rule-based system's decision-making speed and autonomy rate against state-of-the-art deep learning approaches in identical urban driving scenarios to quantify the trade-offs between transparency and performance.