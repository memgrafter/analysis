---
ver: rpa2
title: 'FACTUAL: A Novel Framework for Contrastive Learning Based Robust SAR Image
  Classification'
arxiv_id: '2404.03225'
source_url: https://arxiv.org/abs/2404.03225
tags:
- learning
- adversarial
- samples
- contrastive
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FACTUAL, a novel framework that leverages supervised
  contrastive learning and adversarial training to improve the robustness of deep
  learning models for synthetic aperture radar (SAR) automatic target recognition
  (ATR). The key idea is to pre-train the model using a combination of clean SAR images
  and adversarial samples generated by both PGD and OTSA attacks, with the goal of
  learning more informative representations that cluster clean and perturbed images
  together.
---

# FACTUAL: A Novel Framework for Contrastive Learning Based Robust SAR Image Classification

## Quick Facts
- **arXiv ID**: 2404.03225
- **Source URL**: https://arxiv.org/abs/2404.03225
- **Reference count**: 36
- **Primary result**: FACTUAL achieves 99.7% accuracy on clean SAR samples and 89.6% accuracy on perturbed samples, outperforming previous state-of-the-art methods

## Executive Summary
This paper proposes FACTUAL, a novel framework that leverages supervised contrastive learning and adversarial training to improve the robustness of deep learning models for synthetic aperture radar (SAR) automatic target recognition (ATR). The key innovation is combining clean SAR images with adversarial samples generated by both PGD and OTSA attacks during pre-training, with the goal of learning more informative representations that cluster clean and perturbed images together. FACTUAL achieves state-of-the-art performance on the MSTAR dataset, demonstrating high prediction accuracy on both clean and adversarial samples while significantly outperforming previous methods.

## Method Summary
FACTUAL is a two-stage framework consisting of supervised contrastive pre-training followed by fine-tuning. The pre-training phase uses a combination of clean SAR images and adversarial samples generated by PGD and OTSA attacks, employing a supervised contrastive loss that pulls clean and perturbed samples of the same class together while pushing samples of different classes apart. After pre-training, a linear classifier is cascaded onto the encoder and the full network is fine-tuned using cross-entropy loss. The framework is trained on the MSTAR dataset with RandAugment data augmentation, and evaluated against both clean samples and adversarial attacks.

## Key Results
- FACTUAL achieves 99.7% accuracy on clean SAR samples
- FACTUAL achieves 89.6% accuracy on perturbed samples
- FACTUAL significantly outperforms previous state-of-the-art methods on the MSTAR dataset

## Why This Works (Mechanism)

### Mechanism 1
FACTUAL's combination of supervised contrastive learning and adversarial training improves robustness by clustering clean and perturbed samples together in the feature space. The framework pre-trains the encoder using a supervised contrastive loss that pulls clean and perturbed samples of the same class together while pushing samples of different classes apart. This creates a feature space where adversarial perturbations don't significantly alter the learned representations.

### Mechanism 2
Using both PGD and OTSA attacks during pre-training creates a more robust model by exposing it to perturbations of different natures and distributions. PGD generates random perturbations across the entire image, while OTSA generates physically realistic perturbations limited to the target region. By training on both, the model learns to be robust to a wider variety of attack strategies and cannot overfit to a single attack pattern.

### Mechanism 3
FACTUAL's pre-training followed by fine-tuning strategy creates representations that are both semantically meaningful and robust to adversarial attacks. The supervised contrastive pre-training phase learns good feature representations that cluster samples by class, while the fine-tuning phase adapts these representations to the specific classification task. This two-stage approach allows the model to first learn robust features and then optimize for classification accuracy.

## Foundational Learning

- **Concept**: Supervised Contrastive Learning (SCL)
  - Why needed here: SCL improves upon standard contrastive learning by using label information to create more meaningful positive pairs (samples from the same class) and more effective negative pairs (samples from different classes). This is crucial for SAR ATR where class boundaries are important.
  - Quick check question: How does SCL differ from standard contrastive learning in terms of how it defines positive and negative pairs?

- **Concept**: Adversarial Training (AT)
  - Why needed here: AT improves model robustness by training on adversarial examples that are specifically designed to fool the model. This is essential for SAR ATR given the critical applications in military domains where adversarial attacks could have severe consequences.
  - Quick check question: What is the min-max optimization problem formulation of adversarial training and why does it help with robustness?

- **Concept**: SAR Imaging Physics
  - Why needed here: Understanding SAR imaging is crucial because it differs from optical imaging in fundamental ways (coherent processing, speckle noise, etc.), which affects how adversarial attacks work and how to defend against them.
  - Quick check question: What makes SAR images fundamentally different from optical images in terms of how they're generated and what properties they have?

## Architecture Onboarding

- **Component map**: Data Augmentation -> Encoder -> Projector (pre-training only) -> Classifier (fine-tuning only) -> Loss Functions
- **Critical path**: 1. Data augmentation generates clean, PGD-perturbed, and OTSA-perturbed samples; 2. Encoder + projector process augmented samples; 3. Supervised contrastive loss pulls same-class samples together; 4. Encoder is pre-trained with this loss; 5. Projector is discarded; 6. Linear classifier is added; 7. Full network is fine-tuned with cross-entropy loss
- **Design tradeoffs**: Pre-training with both attacks vs. single attack (better robustness but potentially slower training); Supervised vs. unsupervised contrastive learning (better performance with labels but requires labeled data); ResNet50 vs. smaller/larger architectures (balance between performance and computational cost)
- **Failure signatures**: Low accuracy on clean samples (model is overfit to adversarial examples); Low accuracy on perturbed samples (model is not sufficiently robust); Large gap between clean and perturbed accuracy (model is overfitting to one type of sample); Slow convergence (too many augmentation strategies or too aggressive attacks)
- **First 3 experiments**: 1. Train with only PGD attacks and compare performance to FACTUAL; 2. Train with only OTSA attacks and compare performance to FACTUAL; 3. Train with standard supervised learning (no contrastive pre-training) and compare performance to FACTUAL

## Open Questions the Paper Calls Out

The paper does not explicitly call out any open questions in the provided content.

## Limitations

- Limited testing against white-box attacks beyond PGD and OTSA leaves uncertainty about performance against other attack methods
- Evaluation is conducted solely on the MSTAR dataset, limiting generalizability to other SAR datasets or real-world deployment scenarios
- Computational overhead of generating OTSA perturbations may be prohibitive for real-time applications

## Confidence

- **Performance claims**: Medium confidence - based on single dataset evaluation with limited attack diversity
- **Mechanism claims about contrastive learning clustering**: Medium confidence - supported by ablation studies but lacks direct visualization of feature space
- **Physical attack realism claims**: Low confidence - theoretical justification without empirical validation of physical plausibility

## Next Checks

1. **Cross-dataset validation**: Test FACTUAL on multiple SAR datasets (e.g., OpenSARShip, SENSR) to assess generalizability beyond MSTAR and verify robustness claims hold across different imaging conditions and target classes.

2. **White-box attack battery**: Evaluate against a comprehensive suite of white-box attacks including AutoAttack, CW, and transfer-based attacks to determine if FACTUAL's robustness extends beyond the specific PGD and OTSA methods used during training.

3. **Physical feasibility study**: Conduct a systematic evaluation of OTSA perturbations by comparing generated adversarial samples against real SAR scattering measurements and analyzing computational requirements for real-time implementation.