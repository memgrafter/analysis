---
ver: rpa2
title: Multi-stream deep learning framework to predict mild cognitive impairment with
  Rey Complex Figure Test
arxiv_id: '2409.02883'
source_url: https://arxiv.org/abs/2409.02883
tags:
- scores
- rcft
- scoring
- performance
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a multi-stream deep learning framework to
  distinguish mild cognitive impairment (MCI) from cognitively normal (CN) subjects
  using Rey Complex Figure Test (RCFT) data. The proposed model integrates a spatial
  stream processing raw RCFT images via EfficientNet-B2 with multi-head self-attention
  and a scoring stream employing a pre-trained automated scoring system.
---

# Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test

## Quick Facts
- arXiv ID: 2409.02883
- Source URL: https://arxiv.org/abs/2409.02883
- Reference count: 0
- Multi-stream deep learning model achieves 0.872 AUC for MCI detection using RCFT data

## Executive Summary
This study presents a novel multi-stream deep learning framework that integrates spatial image analysis with automated scoring data to detect mild cognitive impairment (MCI) from Rey Complex Figure Test (RCFT) drawings. The model combines a spatial stream processing raw RCFT images via EfficientNet-B2 with multi-head self-attention and a scoring stream employing a pre-trained automated scoring system. Trained on 1,740 subjects from the GARD cohort and validated on an external WUH cohort of 222 subjects, the model demonstrates superior performance compared to traditional logistic regression approaches, achieving an AUC of 0.872, accuracy of 0.781, sensitivity of 0.836, and specificity of 0.722.

## Method Summary
The proposed method employs a multi-stream deep learning architecture that processes both raw RCFT images and automated scoring data. The spatial stream uses EfficientNet-B2 to extract features from 512x512 RCFT images, followed by multi-head self-attention to focus on important spatial regions, then passes through fully connected layers for classification. The scoring stream uses a pre-trained automated scoring system to generate RCFT scores, which are concatenated with demographic data (age, sex, education) and passed through fully connected layers. Both streams output probabilities that are averaged for the final MCI prediction. The model was trained on 1,740 subjects from the GARD cohort using binary cross-entropy loss with Adam optimizer, learning rate reduction every 5 epochs, and early stopping after 30 epochs without improvement.

## Key Results
- Achieved AUC of 0.872, accuracy of 0.781, sensitivity of 0.836, and specificity of 0.722 on external validation
- Significantly outperformed logistic regression using MMSE scores (AUC 0.714) and expert RCFT scoring (AUC 0.750)
- Demonstrated successful external validation on independent WUH cohort of 222 subjects
- Integration of image-based and structured scoring data enabled detection of subtle cognitive impairments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-stream architecture improves MCI detection by combining expert-validated scores with raw image details.
- Mechanism: The scoring stream leverages a pre-trained automated scoring system to provide structured, validated RCFT scores, while the spatial stream uses EfficientNet-B2 with multi-head self-attention to capture fine-grained visual patterns from raw images. These two streams are fused to combine structured scoring data with subtle image-based features.
- Core assumption: Expert scoring and raw image data contain complementary information for MCI detection.
- Evidence anchors:
  - [abstract] "The integration of both spatial and scoring streams enables the model to capture intricate visual details from the raw images while also incorporating structured scoring data, which together enhance its ability to detect subtle cognitive impairments."
  - [section] "Our multi-stream network combines both the scoring stream and spatial stream. The scoring stream incorporates an AI scoring system for RCFT, which save time and human resources while proactively preventing human errors, thus improving accuracy."
  - [corpus] Weak evidence - no direct mention of multi-stream approaches in related papers, but several mention AI-driven image or score-based MCI detection.

### Mechanism 2
- Claim: Multi-head self-attention improves model focus on critical spatial regions in RCFT images.
- Mechanism: After EfficientNet-B2 extracts feature maps from RCFT images, the multi-head self-attention layer attends to important spatial regions, allowing the model to prioritize areas of the drawing that are most indicative of cognitive impairment.
- Core assumption: Certain spatial regions in RCFT drawings are more informative for MCI detection than others.
- Evidence anchors:
  - [abstract] "the integration of both spatial and scoring streams enables the model to capture intricate visual details from the raw images... which together enhance its ability to detect subtle cognitive impairments."
  - [section] "the integration of multi-head self-attention layers helps the model to prioritize crucial spatial regions within the feature map, boosting performance."
  - [corpus] No direct evidence - self-attention is not mentioned in related papers.

### Mechanism 3
- Claim: External validation on a separate cohort ensures model robustness and generalizability.
- Mechanism: The model is trained on the GARD cohort (1,740 subjects) and validated on an independent WUH cohort (222 subjects), ensuring that performance gains are not due to overfitting to a single dataset.
- Core assumption: MCI detection patterns are consistent across different cohorts and clinical settings.
- Evidence anchors:
  - [abstract] "Our model was trained on data from 1,740 subjects in the Korean cohort and validated on an external hospital dataset of 222 subjects from Korea."
  - [section] "External validation was performed using WUH cohort. Model performance was assessed using the area under receiver operating characteristics (AUC), the accuracy (ACC), sensitivity (SEN) and specificity (SPE)."
  - [corpus] Weak evidence - while some related papers mention external validation, none provide detailed methodology.

## Foundational Learning

- Concept: Multi-stream deep learning
  - Why needed here: Combining complementary data sources (structured scores and raw images) can improve MCI detection accuracy.
  - Quick check question: What are the two streams in the proposed architecture, and what type of data does each process?

- Concept: Multi-head self-attention
  - Why needed here: Helps the model focus on important spatial regions in RCFT images, improving detection of subtle cognitive impairments.
  - Quick check question: How does multi-head self-attention differ from a standard attention mechanism in terms of feature extraction?

- Concept: External validation
  - Why needed here: Ensures that the model's performance is robust and generalizable across different cohorts and clinical settings.
  - Quick check question: Why is external validation important for assessing the real-world applicability of a medical AI model?

## Architecture Onboarding

- Component map:
  - Input: Pre-processed RCFT images (512x512), demographic data (age, sex, education)
  - Spatial stream: EfficientNet-B2 → Flatten → Multi-head self-attention → FC layers → Softmax
  - Scoring stream: Pre-trained RCFT scoring model → Concatenate scores + demographics → FC layer → Softmax
  - Fusion: Average of spatial and scoring stream outputs → Final classification (MCI vs. CN)

- Critical path: Image preprocessing → Spatial stream processing → Scoring stream processing → Output fusion → Classification

- Design tradeoffs:
  - Using EfficientNet-B2 balances model complexity and performance for limited datasets
  - Fixed weights in the scoring stream prevent overfitting but limit adaptation to new data
  - Multi-head self-attention improves spatial feature extraction but adds computational overhead

- Failure signatures:
  - Poor performance on external validation → Possible overfitting or cohort mismatch
  - Low sensitivity → Model may miss subtle MCI cases; check spatial stream feature extraction
  - Low specificity → Model may overclassify MCI; verify scoring stream accuracy

- First 3 experiments:
  1. Train and evaluate only the spatial stream to establish baseline image-based performance
  2. Train and evaluate only the scoring stream to assess structured data performance
  3. Combine both streams and compare performance gains to individual streams

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would incorporating additional ancillary information, such as kinematic data from digital pen and tablet use during the RCFT, impact the model's predictive performance?
- Basis in paper: [inferred] The authors mention that kinematic parameters like pressure, velocity, and time, which are not captured by traditional paper-and-pencil drawing tests but recorded by tablet-based tests, revealed significant differences between case and control groups. They note this as a potential area for future development.
- Why unresolved: The current study did not incorporate kinematic data, focusing instead on raw images and scoring data. The impact of these additional parameters on the model's accuracy and robustness remains unexplored.
- What evidence would resolve it: Implementing the model with kinematic data and comparing its performance metrics (e.g., AUC, accuracy, sensitivity, specificity) against the current model would provide insights into the added value of these parameters.

### Open Question 2
- Question: How would integrating verbal test data, alongside the visual RCFT data, enhance the model's ability to predict MCI?
- Basis in paper: [inferred] The authors discuss the importance of verbal tests in neuropsychological evaluation and recent advancements in automatic speech recognition technology, suggesting potential for future work to develop tablet-based, fully automated memory tests that integrate both visual and verbal assessments.
- Why unresolved: The current model relies solely on visual data from the RCFT, without incorporating verbal test data. The potential benefits of integrating speech-based methods for AD detection are not yet explored.
- What evidence would resolve it: Developing a model that incorporates both visual RCFT data and verbal test data, and comparing its performance with the current model, would demonstrate the added value of verbal assessments in predicting MCI.

### Open Question 3
- Question: What are the potential effects of resolution differences between training and test images on the spatial stream network's performance?
- Basis in paper: [inferred] The authors note that models relying solely on raw images have shown higher standard deviations in performance compared to logistic models utilizing scores, and mention that the performance of the spatial stream network may be compromised due to differences in resolution between existing training images and new test images.
- Why unresolved: The study acknowledges the potential issue of resolution differences but does not explore its impact on model performance or propose solutions to mitigate this limitation.
- What evidence would resolve it: Conducting experiments with varying image resolutions during training and testing, and analyzing the model's performance across these scenarios, would clarify the impact of resolution differences and inform strategies to enhance model robustness.

## Limitations
- Reliance on automated RCFT scoring may introduce systematic errors despite accuracy claims
- Lack of detailed implementation specifications for the scoring model and multi-head self-attention layer
- Relatively small validation cohort (222 subjects) and potential demographic differences between Korean cohorts

## Confidence
- **High confidence**: The multi-stream architecture combining image and scoring data improves MCI detection compared to single-modal approaches
- **Medium confidence**: Multi-head self-attention significantly improves spatial feature extraction from RCFT images
- **Low confidence**: The automated scoring system's accuracy claims are sufficient for clinical application

## Next Checks
1. **Implementation verification**: Reproduce the multi-head self-attention layer with the stated configuration and verify its impact on feature extraction from RCFT images
2. **Scoring model validation**: Test the automated scoring system's accuracy against expert human raters on a subset of RCFT drawings
3. **Cross-cohort performance**: Evaluate the trained model on an independent dataset from a different geographic region or demographic group to assess true generalizability