---
ver: rpa2
title: Approximation-Aware Bayesian Optimization
arxiv_id: '2406.04308'
source_url: https://arxiv.org/abs/2406.04308
tags:
- optimization
- pages
- page
- function
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational bottleneck in high-dimensional
  Bayesian optimization (BO) by modifying sparse variational Gaussian processes (SVGPs)
  to better align with BO's decision-making goals. The authors propose a utility-calibrated
  variational inference framework that jointly optimizes the SVGP posterior approximation
  and acquisition function, ensuring optimal decisions under limited computational
  budgets.
---

# Approximation-Aware Bayesian Optimization

## Quick Facts
- arXiv ID: 2406.04308
- Source URL: https://arxiv.org/abs/2406.04308
- Authors: Natalie Maus; Kyurae Kim; Geoff Pleiss; David Eriksson; John P. Cunningham; Jacob R. Gardner
- Reference count: 40
- One-line primary result: Utility-calibrated variational inference improves high-dimensional Bayesian optimization by aligning SVGP approximations with acquisition functions.

## Executive Summary
This paper addresses the computational bottleneck in high-dimensional Bayesian optimization by modifying sparse variational Gaussian processes (SVGPs) to better align with BO's decision-making goals. The authors propose a utility-calibrated variational inference framework that jointly optimizes the SVGP posterior approximation and acquisition function, ensuring optimal decisions under limited computational budgets. Experiments on high-dimensional benchmark tasks demonstrate significant performance improvements over standard SVGPs.

## Method Summary
The authors propose utility-calibrated variational inference (UCVI) that jointly optimizes SVGP parameters and acquisition functions through a new objective called the Expected Utility Lower Bound (EULBO). This approach replaces the standard ELBO maximization with a utility-weighted objective that prioritizes posterior accuracy in regions important for decision-making. The framework supports both expected improvement (EI) and knowledge gradient (KG) acquisition functions, with extensions to batch BO using Monte Carlo approximations. The method is implemented in GPyTorch and BoTorch, with experiments conducted across 8 benchmark tasks including molecular design and control problems.

## Key Results
- EULBO-EI consistently outperforms ELBO-EI across all benchmark tasks, with particular gains in high-dimensional molecular design problems
- EULBO-KG achieves comparable performance to EI while maintaining the theoretical advantages of knowledge gradient
- The approach requires fewer function evaluations to achieve comparable results, with 20,000 evaluations sufficient for most tasks
- Batch BO extensions using q-EULBO show improved sample efficiency over sequential methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint optimization of the SVGP posterior approximation and the acquisition function aligns the model's approximation budget with the downstream decision-making goals of BO.
- Mechanism: Standard SVGP training maximizes the ELBO, which models all observed data globally. In BO, only the fidelity of the posterior in regions of high acquisition utility matters. The EULBO explicitly incorporates the utility function into the variational objective, shifting approximation resources toward high-utility regions.
- Core assumption: The utility function is strictly positive or can be transformed into one (e.g., via softplus).
- Evidence anchors:
  - [abstract]: "modify SVGPs to better align with the goals of BO: targeting informed data acquisition rather than global posterior fidelity."
  - [section 3.1]: Derivation of the EULBO as a utility-weighted variational objective.
  - [corpus]: No direct evidence; assumed consistent with general utility-calibrated inference literature.
- Break Condition: If the utility function is not strictly positive and cannot be transformed, Jensen's inequality in the EULBO derivation fails, breaking the lower bound guarantee.

### Mechanism 2
- Claim: The EULBO enables efficient computation of the knowledge gradient (KG) acquisition function, making it comparable in cost to expected improvement (EI).
- Mechanism: The EULBO's expected log-utility term can be computed via Monte Carlo sampling and online updates, avoiding the nested optimization required for standard KG. This is achieved by reparameterizing the predictive mean and leveraging Cholesky updates for posterior conditioning.
- Core assumption: The utility function depends only on function values (not variances), enabling reparameterization.
- Evidence anchors:
  - [section 3.3]: Description of the one-shot KG-EULBO approach using reparameterization and online updates.
  - [abstract]: "Our approach can simplify the implementation and reduce the computational burden of complex (decision-theoretic) acquisition functions like KG."
  - [corpus]: No direct evidence; relies on the described computational optimizations.
- Break Condition: If the utility function requires full predictive distributions (mean and variance), the online update trick no longer applies, and the computational savings vanish.

### Mechanism 3
- Claim: The EULBO framework extends naturally to batch BO by using Monte Carlo approximations of q-EI and q-KG utilities.
- Mechanism: The joint optimization problem in Eq. (10) can be modified to include multiple query points, with the utility function now considering the maximum improvement across the batch. Fixed base samples during each BO iteration improve optimization stability.
- Core assumption: Fixed base samples during each BO iteration provide a reasonable bias-variance tradeoff for batch optimization.
- Evidence anchors:
  - [section 3.4]: Extension of EULBO to q-EI and q-KG with Monte Carlo sampling and fixed base samples.
  - [abstract]: "We extend this framework to be capable of running in batch mode, by introducing q-EULBO analogs of q-KG and q-EI."
  - [corpus]: No direct evidence; consistent with standard batch BO practices in the literature.
- Break Condition: If the batch size is very large, the Monte Carlo approximation becomes too noisy, degrading optimization performance.

## Foundational Learning

- Concept: Variational inference and the evidence lower bound (ELBO).
  - Why needed here: Understanding the ELBO is essential to grasp how the EULBO modifies it by adding a utility term.
  - Quick check question: What is the relationship between the ELBO and the marginal likelihood in variational inference?

- Concept: Decision-theoretic Bayesian optimization and acquisition functions.
  - Why needed here: The EULBO is built on the principle that acquisition functions are posterior-expected utilities, so understanding this connection is crucial.
  - Quick check question: How does the expected improvement (EI) acquisition function relate to the improvement utility function?

- Concept: Sparse variational Gaussian processes (SVGPs) and inducing points.
  - Why needed here: SVGPs are the underlying model, and understanding how inducing points work is necessary to follow the EULBO optimization.
  - Quick check question: What is the role of inducing points in reducing the computational complexity of Gaussian processes?

## Architecture Onboarding

- Component map:
  - Data: BO dataset ùíü‚Çú of input-output pairs
  - Model: SVGP with variational parameters ùùÄ, inducing points ùíÅ, and hyperparameters ùúΩ
  - Utility functions: EI, KG, and their batch/q-variants
  - Optimization: Alternating maximization over the query point ùíô and SVGP parameters ùíò
  - Acquisition: Selection of the next BO query based on EULBO optimization

- Critical path:
  1. Initialize SVGP with ELBO maximization (warm-start)
  2. Maximize the conventional acquisition function to initialize the query point ùíô
  3. Alternate between updating ùíô (query optimization) and ùíò (SVGP parameters) to maximize EULBO
  4. Use the optimized ùíô as the next BO query

- Design tradeoffs:
  - Joint optimization vs. two-step scheme: Joint optimization aligns model and acquisition but is more complex; two-step is simpler but less aligned
  - Number of inducing points: More points improve model fidelity but increase computational cost
  - Batch size: Larger batches improve sample efficiency but increase optimization complexity

- Failure signatures:
  - Poor BO performance: Indicates misalignment between the model and acquisition function
  - Slow EULBO optimization: Suggests a difficult optimization landscape or poor initialization
  - High variance in results: Points to instability in the Monte Carlo approximations or optimization

- First 3 experiments:
  1. Compare EULBO-EI vs. ELBO-EI on a simple 1D test function (e.g., Branin) to verify alignment benefits
  2. Benchmark EULBO-KG vs. ELBO-KG on a medium-dimensional problem (e.g., 6D Hartmann) to assess computational savings
  3. Test EULBO batch acquisition on a molecular design task to evaluate batch BO performance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions beyond noting the need for further theoretical analysis of approximation quality and the relationship between EULBO tightness and BO performance.

## Limitations
- High-dimensional scalability: Experiments only go up to 256 dimensions, and computational cost may scale poorly beyond this range
- Assumption of strictly positive utilities: The EULBO derivation requires utilities to be positive or transformable via softplus, limiting generality
- Limited theoretical analysis: The paper demonstrates empirical performance improvements but provides limited theoretical analysis of approximation quality

## Confidence
- High confidence: The core mechanism of utility-calibrated variational inference (Mechanism 1) is well-established in the Bayesian inference literature and directly applicable to BO settings
- Medium confidence: The computational efficiency claims for KG-EULBO (Mechanism 2) are supported by the described optimization strategies, but actual runtime comparisons are not provided in the paper
- Medium confidence: The batch BO extension (Mechanism 3) follows standard Monte Carlo approaches, but the fixed base sample strategy's effectiveness across different batch sizes needs more rigorous validation

## Next Checks
1. Scalability test: Implement EULBO on synthetic high-dimensional problems (500-1000 dimensions) to evaluate computational scaling and identify potential bottlenecks in the joint optimization
2. Cross-acquisition validation: Test the EULBO framework with acquisition functions beyond EI and KG (e.g., Thompson sampling, entropy search) to verify the generality of the utility-calibration approach
3. Theoretical bounds analysis: Derive approximation bounds for the EULBO objective and empirically measure its tightness across different utility functions and problem domains