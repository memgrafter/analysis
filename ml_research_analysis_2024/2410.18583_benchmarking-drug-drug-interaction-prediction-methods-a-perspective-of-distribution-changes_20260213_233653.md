---
ver: rpa2
title: 'Benchmarking drug-drug interaction prediction methods: a perspective of distribution
  changes'
arxiv_id: '2410.18583'
source_url: https://arxiv.org/abs/2410.18583
tags:
- drug
- distribution
- prediction
- changes
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DDI-Ben, a benchmarking framework for emerging
  drug-drug interaction (DDI) prediction under distribution changes. It addresses
  the challenge that existing methods often neglect distribution shifts between known
  and new drugs, leading to unrealistic evaluations.
---

# Benchmarking drug-drug interaction prediction methods: a perspective of distribution changes

## Quick Facts
- arXiv ID: 2410.18583
- Source URL: https://arxiv.org/abs/2410.18583
- Reference count: 39
- Ten representative DDI prediction methods show significant performance degradation under distribution changes

## Executive Summary
This paper introduces DDI-Ben, a benchmarking framework for drug-drug interaction (DDI) prediction under distribution changes. The framework addresses the critical gap that existing methods often neglect distribution shifts between known and new drugs, leading to unrealistic evaluations. By simulating distribution changes using drug set differences as a surrogate, DDI-Ben provides a more realistic assessment of DDI prediction methods. Benchmarking ten representative methods on Drugbank and TWOSIDES datasets reveals significant performance degradation when distribution changes are introduced, with LLM-based methods showing greater robustness.

## Method Summary
DDI-Ben introduces a distribution change simulation framework that leverages drug set differences as a surrogate for real-world DDI distribution shifts. The framework supports various drug split strategies including random, scaffold-based, and cluster-based approaches. For cluster-based splitting, drugs are grouped based on chemical similarity using Tanimoto Coefficient, then split between known and new drug sets to create realistic distribution changes. The framework was evaluated using ten representative DDI prediction methods including MLP, GNN-based approaches, and LLM-based methods (TextDDI, DDI-GPT). Performance was measured using F1-score, ROC-AUC, accuracy, and Cohen's Kappa across Drugbank and TWOSIDES datasets.

## Key Results
- All ten DDI prediction methods show significant performance degradation when distribution changes are introduced
- LLM-based methods (TextDDI, DDI-GPT) and those integrating drug-related textual information demonstrate greater robustness against distribution changes
- Cluster-based drug split strategy better simulates realistic drug approval patterns compared to random or scaffold-based splits
- The severity of distribution change directly correlates with performance degradation across all methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distribution change simulation using drug set differences serves as a surrogate for real-world DDI distribution shifts.
- Mechanism: The framework models the gap between known and new drug sets (γ(Dk, Dn)) as a proxy for distribution change between training and test DDIs. This allows benchmarking methods under realistic distribution shifts without needing real approval timeline data.
- Core assumption: Differences in drug chemical space between known and new drugs can adequately approximate changes in DDI interaction distributions.
- Evidence anchors:
  - [abstract] "DDI-Ben introduces a distribution change simulation framework that leverages distribution changes between drug sets as a surrogate for real-world distribution changes of DDIs"
  - [section] "We model distribution changes between known drug set and new drug set as a surrogate to simulate the distribution changes in emerging DDI prediction problem"
  - [corpus] No direct evidence found; this appears to be a novel methodological assumption.
- Break condition: If the chemical space similarity does not correlate with DDI type distributions, the surrogate becomes invalid.

### Mechanism 2
- Claim: LLM-based methods show greater robustness against distribution changes due to their ability to process textual drug information.
- Mechanism: TextDDI and DDI-GPT leverage drug-related textual descriptions to capture pharmacological knowledge transferable across drug sets, filtering out irrelevant information through LLM capabilities.
- Core assumption: Textual drug descriptions contain transferable pharmacological knowledge not captured by structural features alone.
- Evidence anchors:
  - [abstract] "LLM-based methods (TextDDI, DDI-GPT) and those integrating drug-related textual information show greater robustness against such degradation"
  - [section] "The LLM that TextDDI uses effectively addresses this issue with its strong text comprehension and processing abilities"
  - [corpus] Weak evidence - no direct comparison of LLM vs non-LLM robustness found in corpus.
- Break condition: If textual information becomes unavailable or LLMs cannot process domain-specific terminology accurately.

### Mechanism 3
- Claim: Cluster-based drug split strategies better simulate realistic drug approval patterns than random or scaffold-based splits.
- Mechanism: By grouping drugs into clusters based on chemical similarity and then splitting clusters between known and new sets, the framework creates more realistic distribution shifts that reflect real-world drug development clusters.
- Core assumption: Drugs developed in similar time periods cluster together in chemical space due to shared technological or safety considerations.
- Evidence anchors:
  - [section] "Based on the above observation, we consider to design a customized cluster-based difference measurement to model the distribution changes between known and new drug set"
  - [section] "drugs developed in specific time periods demonstrate a clustering effect in the chemical space owing to various factors"
  - [corpus] No direct evidence found; this appears to be an inference from the analysis.
- Break condition: If drug development patterns change such that clustering no longer reflects temporal or technological groupings.

## Foundational Learning

- Concept: Distribution shift and covariate shift
  - Why needed here: Understanding how training and test distributions differ is crucial for evaluating DDI prediction methods under realistic conditions
  - Quick check question: What is the difference between covariate shift and concept drift in the context of DDI prediction?

- Concept: Graph neural networks and their application to molecular data
  - Why needed here: Many DDI methods use GNNs to capture structural information from drug molecular graphs
  - Quick check question: How do GNNs propagate information through drug molecular graphs differently from traditional feature-based methods?

- Concept: Large language models for domain-specific tasks
  - Why needed here: LLM-based methods show particular robustness to distribution changes, requiring understanding of how they process domain text
  - Quick check question: What specific advantages do LLMs have over traditional NLP models for processing drug-related textual information?

## Architecture Onboarding

- Component map: Drug fingerprint extraction -> DDI prediction model -> Distribution change simulation -> Evaluation metrics
- Critical path: Drug split (cluster-based) -> Model training on known drugs -> Testing on new drugs -> Performance measurement
- Design tradeoffs: Cluster-based split provides realistic distribution changes but may reduce dataset size; LLM integration adds robustness but increases computational cost
- Failure signatures: Performance degradation across all DDI types suggests fundamental model limitations; specific type failures indicate data imbalance issues
- First 3 experiments:
  1. Implement random drug split baseline and compare performance against cluster-based split
  2. Train a simple MLP on drug fingerprints and test its sensitivity to distribution changes
  3. Evaluate TextDDI on a small subset of drugs with available textual descriptions to verify LLM robustness claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific pharmacological knowledge transfer mechanisms that enable LLM-based DDI prediction methods to maintain performance under distribution changes?
- Basis in paper: [explicit] The paper states that LLM-based methods like TextDDI and DDI-GPT show greater robustness against performance degradation under distribution changes, and attributes this to their ability to process drug-related textual information and filter irrelevant data.
- Why unresolved: The paper provides a case study demonstrating the effectiveness of LLMs in processing textual information, but does not delve into the specific mechanisms by which this textual information transfer leads to robustness against distribution shifts.
- What evidence would resolve it: Detailed analysis of how specific pharmacological concepts extracted from textual data contribute to maintaining prediction accuracy when drug distributions change, including ablation studies on different types of textual features.

### Open Question 2
- Question: How do different similarity measurement approaches for drug clustering affect the simulation of distribution changes and the resulting benchmarking outcomes?
- Basis in paper: [explicit] The paper mentions using Tanimoto Coefficient for similarity measurement in the cluster-based drug split approach, but acknowledges that other factors could be explored in future studies.
- Why unresolved: While the paper demonstrates the effectiveness of their chosen similarity measure, it doesn't explore how alternative similarity metrics (e.g., structural similarity, functional similarity) might impact the simulation fidelity and benchmarking results.
- What evidence would resolve it: Comparative benchmarking results using different similarity metrics to measure drug set differences, along with analysis of how these choices affect the correlation between simulated and real-world distribution changes.

### Open Question 3
- Question: What is the optimal balance between leveraging distribution change simulation and preserving sufficient training data for emerging DDI prediction?
- Basis in paper: [inferred] The paper introduces a simulation framework that creates significant distribution changes between known and new drug sets, but doesn't address the trade-off between realistic simulation and maintaining adequate training data.
- Why unresolved: The framework allows control over distribution change severity through parameter γ, but doesn't provide guidance on finding the optimal balance point where simulation remains realistic without sacrificing model performance due to insufficient training data.
- What evidence would resolve it: Systematic experiments varying the proportion of drugs in known versus new sets while measuring both distribution change severity and prediction performance across multiple methods.

## Limitations

- The framework relies on drug set differences as a surrogate for DDI distribution changes without direct empirical validation of this assumption
- Cluster-based split strategy assumes drugs developed in similar periods cluster in chemical space, which may not hold for all drug classes
- The study focuses on Drugbank and TWOSIDES datasets, potentially limiting generalizability to other DDI data sources

## Confidence

- High: The general methodology of simulating distribution changes and the observed performance degradation across methods
- Medium: The effectiveness of LLM-based methods showing greater robustness, as this requires access to high-quality textual drug information
- Low: The claim that cluster-based splits better simulate real-world approval patterns, which remains largely theoretical without temporal drug approval data

## Next Checks

1. **Correlation validation**: Test whether chemical similarity between drug pairs correlates with DDI type distributions using available Drugbank data
2. **Temporal analysis**: If drug approval dates become available, validate whether cluster-based splits align with actual temporal drug development patterns
3. **Cross-dataset generalization**: Apply DDI-Ben framework to additional DDI datasets (e.g., KEGG, FDA warnings) to verify that performance patterns hold across different data sources