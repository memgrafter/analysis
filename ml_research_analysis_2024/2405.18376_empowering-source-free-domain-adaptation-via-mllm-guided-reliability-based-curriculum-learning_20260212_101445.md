---
ver: rpa2
title: Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based
  Curriculum Learning
arxiv_id: '2405.18376'
source_url: https://arxiv.org/abs/2405.18376
tags:
- mllms
- domain
- adaptation
- learning
- mllm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of source-free domain adaptation
  (SFDA), where a model must adapt to a new target domain without access to the original
  labeled source data. Existing SFDA methods often rely on a single teacher model
  or handcrafted prompts, limiting their robustness.
---

# Empowering Source-Free Domain Adaptation via MLLM-Guided Reliability-Based Curriculum Learning

## Quick Facts
- arXiv ID: 2405.18376
- Source URL: https://arxiv.org/abs/2405.18376
- Reference count: 40
- Key outcome: Achieves state-of-the-art performance on standard SFDA datasets (Office-Home, DomainNet-126, VisDA-C) with up to 280x-2800x model size reduction while surpassing accuracy

## Executive Summary
This paper addresses the challenge of source-free domain adaptation (SFDA), where a model must adapt to a new target domain without access to the original labeled source data. The authors propose Reliability-based Curriculum Learning (RCL), a novel framework that distills robust supervision from multiple frozen Multimodal Large Language Models (MLLMs) into a compact target model. RCL organizes adaptation as a three-stage curriculum that progressively incorporates pseudo-labels based on inter-model agreement and model confidence, enabling stable and noise-aware training. The approach achieves state-of-the-art performance on standard SFDA benchmarks without accessing source data or tuning foundation models.

## Method Summary
RCL addresses SFDA by leveraging multiple frozen MLLMs to generate reliable pseudo-labels for target domain adaptation. The method organizes adaptation into a three-stage curriculum: initial adaptation using high-confidence pseudo-labels, intermediate learning with inter-model agreement filtering, and final fine-tuning with all available pseudo-labels. This progressive approach helps filter noisy pseudo-labels while maintaining adaptation effectiveness. The framework distills knowledge from the MLLM ensemble into a compact target model, achieving significant size reduction while maintaining or improving accuracy compared to direct MLLM usage.

## Key Results
- Achieves state-of-the-art performance on Office-Home, DomainNet-126, and VisDA-C benchmarks
- Outperforms zero-shot MLLMs and their ensembles by distilling knowledge into compact models
- Achieves 280x-2800x model size reduction while maintaining superior accuracy
- Eliminates need for source data access and foundation model tuning

## Why This Works (Mechanism)
RCL leverages the complementary strengths of multiple frozen MLLMs to generate more reliable pseudo-labels than single-model approaches. By organizing adaptation as a curriculum that progressively incorporates pseudo-labels based on inter-model agreement and confidence, the method effectively filters noisy labels while maintaining adaptation momentum. The multi-stage approach allows the target model to first learn from the most reliable predictions before gradually incorporating more challenging cases, leading to more stable and effective domain adaptation.

## Foundational Learning
- **Source-free domain adaptation**: Adapting models to new domains without source data access - needed for privacy-preserving adaptation and practical deployment where source data retention is problematic
- **Multimodal Large Language Models (MLLMs)**: Foundation models that process both text and images - needed as reliable knowledge sources for pseudo-label generation
- **Curriculum learning**: Organizing training to progress from easier to harder examples - needed to stabilize adaptation and filter noisy pseudo-labels
- **Knowledge distillation**: Transferring knowledge from large models to compact ones - needed to create efficient deployable models while preserving MLLM capabilities

## Architecture Onboarding
- **Component Map**: MLLM Ensemble -> Pseudo-label Generator -> Curriculum Manager -> Target Model Trainer
- **Critical Path**: Target images → MLLM ensemble → pseudo-labels (filtered by agreement/confidence) → target model training
- **Design Tradeoffs**: Multiple MLLMs provide reliability but increase computational cost during adaptation; curriculum stages improve stability but add complexity
- **Failure Signatures**: Poor inter-model agreement indicates unreliable pseudo-labels; low confidence scores suggest adaptation challenges; over-reliance on single MLLM degrades performance
- **First Experiments**: 1) Baseline adaptation with single MLLM pseudo-labels; 2) Ablation of curriculum stages; 3) Comparison of different MLLM ensemble compositions

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Performance generalization across diverse visual domains beyond standard benchmarks remains uncertain
- Dependence on MLLM ensemble quality and composition could affect practical deployment
- Computational overhead of multi-MLLM processing during adaptation is not discussed

## Confidence
- State-of-the-art SFDA Performance: High
- Superiority over Zero-shot MLLMs: High
- No Source Data Access Required: High
- Progressive Curriculum Effectiveness: Medium

## Next Checks
1. Evaluate RCL on additional domain adaptation datasets with varying characteristics (medical imaging, satellite imagery, fine-grained classification) to assess generalization
2. Conduct detailed ablation studies on curriculum stages, inter-model agreement thresholds, and MLLM ensemble sizes to quantify individual contributions
3. Measure computational cost of multi-MLLM distillation phase versus size and inference speed benefits of final compact model