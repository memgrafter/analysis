---
ver: rpa2
title: High-Speed Detector For Low-Powered Devices In Aerial Grasping
arxiv_id: '2402.14591'
source_url: https://arxiv.org/abs/2402.14591
tags:
- detection
- object
- which
- dataset
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of autonomous aerial fruit harvesting,
  which requires computationally efficient algorithms on low-powered devices. The
  authors propose Fast Fruit Detector (FFD), a single-stage, postprocessing-free object
  detector that achieves 100FPS@FP32 on a 10W NVIDIA Jetson-NX embedded device.
---

# High-Speed Detector For Low-Powered Devices In Aerial Grasping

## Quick Facts
- arXiv ID: 2402.14591
- Source URL: https://arxiv.org/abs/2402.14591
- Authors: Ashish Kumar; Laxmidhar Behera
- Reference count: 30
- One-line primary result: Fast Fruit Detector (FFD) achieves 100FPS@FP32 on 10W NVIDIA Jetson-NX for aerial fruit harvesting

## Executive Summary
This paper addresses the computational challenges of autonomous aerial fruit harvesting by proposing Fast Fruit Detector (FFD), a single-stage object detector designed specifically for low-powered embedded devices. FFD eliminates traditional detection bottlenecks like anchor boxes, non-maximum suppression, and multi-scale feature pyramids through a novel Latent Object Representation (LOR) module and tiled Hungarian matching strategy. The approach achieves 100 FPS on a 10W NVIDIA Jetson-NX device while maintaining competitive accuracy on challenging fruit detection benchmarks.

The authors also introduce an innovative data multiplication approach that generates large amounts of training data through occlusion-aware scene synthesis, addressing the labeling bottleneck in agricultural datasets. Combined with comprehensive data augmentation, this method enables training without exhaustive manual annotation. The work is validated on both a newly released fruit detection dataset with many small instances and the MinneApple benchmark, demonstrating superior speed-accuracy trade-offs compared to existing detectors.

## Method Summary
FFD is a single-stage CNN-based object detector that processes images through a VGG backbone, passes features to a Latent Object Representation (LOR) module, and generates object queries through tiled Hungarian matching. The LOR module uses a cross-channel global context (CCGC) mechanism to produce object queries without anchor boxes or transformer attention. Predictions are made at a single scale on a low-resolution feature map, with each tile handling its own query assignment. The system requires no post-processing like NMS and achieves 100 FPS on embedded hardware. Training uses cosine annealing with ADAM optimizer for 1000 epochs on datasets augmented with occlusion-aware synthetic scenes.

## Key Results
- Achieves 100 FPS@FP32 on 10W NVIDIA Jetson-NX embedded device
- Outperforms Faster-RCNN and YOLO-v8 on proposed fruit detection dataset and MinneApple benchmark
- Eliminates anchor boxes, NMS, and multi-scale detection while maintaining accuracy
- Introduces occlusion-aware scene synthesis approach for data multiplication

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LOR module eliminates anchor boxes, NMS, and multi-scale detection while maintaining or improving accuracy
- Mechanism: LOR generates object queries directly from backbone output using cross-channel global context (CCGC) instead of learned embeddings or anchor boxes. Queries are produced per spatial location of low-resolution feature map, with each set corresponding to objects whose centers fall within that tile
- Core assumption: Small objects (like fruits) can be adequately detected from a single low-resolution feature map when queries are generated with global context
- Evidence anchors:
  - [abstract] "FFD uses a novel latent object representation (LOR) module and query assignment strategy to eliminate anchor boxes, NMS, and multi-scale detection"
  - [section III.B] "LOR module that is motivated by the query-key-value paradigm of [5] but is free of transformer attention mechanism and is fully convolutional"
  - [corpus] No direct corpus evidence found for LOR effectiveness specifically
- Break condition: If objects require multi-scale features for detection due to significant scale variation beyond what a single resolution can capture

### Mechanism 2
- Claim: Tiled Hungarian matching reduces computational complexity compared to image-wide matching
- Mechanism: Matching is performed per tile rather than over the entire image space, reducing the number of ground truth boxes considered per match operation
- Core assumption: Most tiles are empty or contain few objects, making local matching more efficient
- Evidence anchors:
  - [section III.F] "Tiled Hungarian matching is different from [5], [16]. First, since not all tiles are occupied, it prevents most tiles from performing the matching process"
  - [section III.F] "As mentioned previously that in our case, all of the Ng predictions for each tile are made w.r.t. the top-left corner of that corresponding tile"
  - [corpus] No direct corpus evidence found for tiled matching efficiency claims
- Break condition: If objects are densely distributed across the image such that most tiles contain multiple objects, reducing the efficiency gain

### Mechanism 3
- Claim: Scene synthesis approach generates high-quality training data without exhaustive manual labeling
- Mechanism: Random placement of object instances onto base images while ensuring no overlap between bounding boxes, combined with comprehensive data augmentation
- Core assumption: Synthetic scenes with proper occlusion handling can effectively augment real data for training robust detectors
- Evidence anchors:
  - [section IV] "we make two changes... Second, we put a constraint that none of the boxes overlap with each other"
  - [section IV] "Manual labeling took 5-8 minutes per image of the harvesting region dataset due to a large number of instances"
  - [section VI.H.1] "Table VI shows the effect of proposed occlusion-aware scene synthesis along with comprehensive data augmentation"
- Break condition: If synthetic data distribution significantly differs from real data, causing domain gap issues during inference

## Foundational Learning

- Concept: Convolutional neural network architectures and feature pyramid networks
  - Why needed here: Understanding how backbone networks process images and how multi-scale features work is crucial for appreciating why FFD's single-scale approach is novel
  - Quick check question: Why do traditional object detectors use multi-scale feature maps?

- Concept: Transformer architectures and attention mechanisms
  - Why needed here: FFD is inspired by DETR but removes transformers; understanding transformer limitations on embedded devices explains FFD's design choices
  - Quick check question: What are the main computational bottlenecks of transformer-based object detectors on low-powered devices?

- Concept: Object detection evaluation metrics (AP, AP50, AP75, etc.)
  - Why needed here: The paper extensively uses Average Precision metrics to compare FFD with other detectors; understanding these metrics is essential for interpreting results
  - Quick check question: How does Average Precision differ from simple accuracy in object detection evaluation?

## Architecture Onboarding

- Component map: Backbone (VGG-based) → LOR module (3×QT+CCGC) → Tiled query assignment → Prediction heads (classification + box regression) → Inference (no NMS/postprocessing)
- Critical path: Image → Backbone → LOR → Query transformation → Global context aggregation → Prediction → Denormalization → Output
- Design tradeoffs: Single-scale detection (speed) vs multi-scale detection (accuracy for varied object sizes); CNN-only design (efficiency) vs transformer-based (potential accuracy)
- Failure signatures: Poor detection of small objects in low-resolution features; query assignment mismatches; convergence issues with softmax vs sigmoid in CCGC
- First 3 experiments:
  1. Verify LOR module generates queries correctly from backbone output
  2. Test tiled Hungarian matching on synthetic data with known ground truth
  3. Validate inference pipeline produces correct denormalized boxes without NMS

## Open Questions the Paper Calls Out
The paper mentions exploring transformer-based mobile backbones like MobileOne as a future direction, but does not explicitly call out additional open questions.

## Limitations
- Single-scale detection may struggle with significant object scale variation beyond what a single resolution can capture
- Tiled Hungarian matching efficiency gains depend on sparse object distribution across tiles
- Synthetic data generation may introduce domain gaps if real-world conditions differ significantly from synthetic scenes

## Confidence
- High: Speed and FPS claims (100FPS@FP32 on Jetson-NX is directly measurable)
- Medium: Dataset collection and synthesis methodology (well-documented but not independently verified)
- Low: Comparative performance claims (relies on third-party implementations and may have evaluation discrepancies)

## Next Checks
1. **Cross-dataset generalization**: Evaluate FFD on MinneApple benchmark using identical training protocols as reported competitors to verify claimed performance advantages
2. **Ablation on multi-scale features**: Test whether adding feature pyramid networks improves small object detection without significant speed degradation
3. **Domain adaptation validation**: Assess performance drop when using synthetic data versus real data exclusively to quantify the effectiveness of the scene synthesis approach