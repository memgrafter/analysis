---
ver: rpa2
title: 'ReALM: Reference Resolution As Language Modeling'
arxiv_id: '2403.20329'
source_url: https://arxiv.org/abs/2403.20329
tags:
- entities
- user
- screen
- type
- objects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using large language models (LLMs) to resolve
  references of various types, including conversational, on-screen, and background
  entities. The core method involves converting reference resolution into a language
  modeling problem by encoding entities as natural text.
---

# ReALM: Reference Resolution As Language Modeling

## Quick Facts
- arXiv ID: 2403.20329
- Source URL: https://arxiv.org/abs/2403.20329
- Reference count: 40
- Key outcome: ReALM achieves GPT-4-level performance on reference resolution using fine-tuned smaller LLMs with a novel text-based spatial encoding approach

## Executive Summary
This paper introduces ReALM, a reference resolution system that converts the task into a language modeling problem by encoding entities as natural text. The approach handles conversational, on-screen, and background references through a unified framework. A novel algorithm encodes on-screen entities while preserving their relative spatial positions, and fine-tuning smaller language models achieves performance comparable to much larger models like GPT-4.

## Method Summary
The method involves fine-tuning FLAN-T5 models on reference resolution datasets where entities are encoded as natural language descriptions. For on-screen entities, Algorithm 1 sorts entities by their screen positions (top-to-bottom, left-to-right) and groups nearby elements into lines, creating a text representation that maintains spatial relationships. The model is trained to predict relevant entities from a list given a user query and the encoded entity descriptions.

## Key Results
- The smallest ReALM model achieved over 5% absolute gains for on-screen references compared to existing systems
- ReALM outperformed GPT-3.5 and achieved performance comparable to GPT-4 despite using far fewer parameters
- Performance improved with model size, particularly for on-screen datasets, though with some double-descent behavior on unseen domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM can resolve references across multiple entity types by converting them into text-based language modeling tasks
- Mechanism: The model encodes entities (conversational, on-screen, background) as natural language descriptions and uses standard language modeling to select relevant entities from a list
- Core assumption: Language models can effectively perform reference resolution when entities are properly encoded as text
- Evidence anchors:
  - [abstract] "by showing how reference resolution can be converted into a language modeling problem"
  - [section 5.3] "We use the following pipeline for fine-tuning an LLM (a FLAN-T5 model) in our case. We provide the parsed input to our model, and finetune it."
  - [corpus] Weak - related papers focus on coreference resolution but don't directly address LLM-based reference resolution

### Mechanism 2
- Claim: The novel textual representation of on-screen entities preserves relative spatial positions for accurate reference resolution
- Mechanism: Algorithm 1 sorts entities by their screen positions (top-to-bottom, left-to-right) and groups nearby elements into lines, creating a text representation that maintains spatial relationships
- Core assumption: Screen entities can be accurately represented as text while preserving spatial relationships necessary for reference resolution
- Evidence anchors:
  - [section 5.3.2] "we use the novel algorithm given in Algorithm 1" and describes sorting entities by center positions
  - [section 5.3.2] "effectively encoding the screen in a left-to-right, top-to-bottom fashion in plain text"
  - [corpus] Weak - related papers focus on vision transformers but don't address text-only spatial encoding

### Mechanism 3
- Claim: Fine-tuning smaller LLMs on reference resolution data achieves performance comparable to much larger models like GPT-4
- Mechanism: The ReALM model is specifically fine-tuned on reference resolution datasets, allowing it to learn the task-specific patterns without requiring the massive parameter count of general-purpose models
- Core assumption: Task-specific fine-tuning can compensate for smaller model size by focusing learning on the specific reference resolution task
- Evidence anchors:
  - [abstract] "our smallest model achieving performance comparable to that of GPT-4"
  - [section 6] "we find that our approach performs in the same ballpark as the latest GPT-4 despite being a much lighter (and faster) model"
  - [corpus] Weak - related papers don't directly compare fine-tuned smaller models to larger general models for reference resolution

## Foundational Learning

- Concept: Reference resolution as a multiple choice task
  - Why needed here: The paper frames reference resolution as selecting relevant entities from a list, which maps directly to LLM capabilities
  - Quick check question: How does the model handle cases where multiple entities are relevant to a single reference?

- Concept: Spatial encoding of screen entities
  - Why needed here: On-screen references require understanding of entity positions relative to each other and to the user's query
  - Quick check question: What happens if two entities have similar screen positions - how does the model distinguish between them?

- Concept: Fine-tuning vs. zero-shot prompting
  - Why needed here: The paper compares its fine-tuned approach against zero-shot prompting with ChatGPT/GPT-4
  - Quick check question: What advantages does fine-tuning provide over using larger models with in-context learning?

## Architecture Onboarding

- Component map:
  Upstream entity extractors -> Text encoding module -> Spatial encoder (for on-screen) -> Fine-tuned LLM -> Post-processing module

- Critical path:
  1. Receive user query and list of entities with properties
  2. Encode entities as natural language descriptions
  3. For on-screen entities, apply spatial encoding algorithm
  4. Construct prompt with user query and encoded entities
  5. Pass through fine-tuned LLM
  6. Post-process output to extract relevant entities

- Design tradeoffs:
  - Model size vs. performance: Smaller models require fine-tuning but are more efficient
  - Text-only vs. multimodal: Text-only approach is more efficient but may miss visual cues
  - Spatial encoding complexity vs. accuracy: More complex encoding could improve accuracy but increase computational cost

- Failure signatures:
  - Model outputs invalid entity indices or non-numeric text
  - Spatial encoding groups unrelated entities together
  - Model fails to recognize entity types mentioned in user queries
  - Performance degrades significantly on unseen entity types

- First 3 experiments:
  1. Test the spatial encoding algorithm with various screen layouts to verify it correctly groups related entities
  2. Evaluate model performance on a held-out domain to measure generalization capability
  3. Compare different model sizes to find the optimal balance between performance and efficiency

## Open Questions the Paper Calls Out

- Question: How does the performance of ReALM compare to GPT-4 on real-world on-screen data versus synthetic data?
- Question: What are the specific limitations of the current textual encoding approach for on-screen entities, and how might these be addressed in future work?
- Question: How does the performance of ReALM vary with different screen layouts and entity distributions?
- Question: What is the impact of model size on the performance of ReALM for different types of reference resolution tasks?

## Limitations
- The approach relies heavily on synthetic datasets and may not generalize well to real-world scenarios
- Text-only spatial encoding may struggle with complex visual layouts or entities with similar screen positions
- The method assumes perfect upstream entity extraction, with no evaluation of error propagation

## Confidence

- Mechanism 1 (LLM reference resolution capability): Medium
- Mechanism 2 (Spatial encoding effectiveness): Medium
- Mechanism 3 (Fine-tuning smaller models): High

## Next Checks
1. Evaluate the model on real-world user query logs where entity extraction may contain errors
2. Create test cases with overlapping entities and ambiguous screen layouts to evaluate spatial encoding edge cases
3. Train the model on one domain and evaluate on completely different domains to measure true generalization capability