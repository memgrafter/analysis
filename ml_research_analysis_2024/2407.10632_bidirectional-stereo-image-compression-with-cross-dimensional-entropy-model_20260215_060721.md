---
ver: rpa2
title: Bidirectional Stereo Image Compression with Cross-Dimensional Entropy Model
arxiv_id: '2407.10632'
source_url: https://arxiv.org/abs/2407.10632
tags:
- stereo
- compression
- image
- psnr
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a bidirectional stereo image compression
  architecture named BiSIC, which addresses the problem of imbalanced compression
  quality between stereo views in previous methods. The core idea is to employ a 3D
  convolution based codec backbone to capture local stereo features and incorporate
  bidirectional attention blocks to exploit global features.
---

# Bidirectional Stereo Image Compression with Cross-Dimensional Entropy Model

## Quick Facts
- arXiv ID: 2407.10632
- Source URL: https://arxiv.org/abs/2407.10632
- Authors: Zhening Liu, Xinjie Zhang, Jiawei Shao, Zehong Lin, Jun Zhang
- Reference count: 40
- Primary result: Novel 3D convolution-based stereo compression architecture with cross-dimensional entropy model achieves 3.0%-8.1% BD-rate savings over state-of-the-art methods

## Executive Summary
This paper introduces BiSIC, a bidirectional stereo image compression architecture that addresses the problem of imbalanced compression quality between stereo views in previous methods. The key innovation is a 3D convolution-based codec backbone that captures local stereo features, combined with bidirectional attention blocks to exploit global features. The authors also design a novel cross-dimensional entropy model that integrates hyperprior, spatial context, channel context, and stereo dependency for more accurate probability estimation during entropy coding.

## Method Summary
BiSIC employs a 3D convolution backbone to jointly process stereo image pairs, capturing inter-view correlations more effectively than separate 2D convolutions. Bidirectional mutual attention blocks facilitate feature transfer between views through cross-key, cross-query, and self-attention stages. The cross-dimensional entropy model estimates latent distributions using multiple conditioning factors: hyperpriors, spatial context, channel context, and stereo dependency. The architecture is trained using rate-distortion optimization with MSE or MS-SSIM distortion metrics, and a fast variant with stereo-checkerboard structure is also proposed for reduced runtime.

## Key Results
- Outperforms conventional image/video compression standards and state-of-the-art learning-based methods in terms of PSNR and MS-SSIM
- Achieves 3.0%-8.1% bit savings measured by BD-rate reduction compared to existing methods
- Successfully addresses imbalanced compression quality between stereo views through bidirectional processing
- Demonstrates effectiveness on InStereo2K and Cityscapes datasets with significant performance improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The 3D convolution backbone captures inter-view correlations more effectively than separate 2D convolutions.
- Mechanism: 3D convolutions jointly process stereo image pairs as a whole, enabling inherent extraction of aligned morphs and features between views.
- Core assumption: Joint spatial and stereo dimensions provide richer feature representations than processing each view independently.
- Evidence anchors:
  - [abstract] "we propose a 3D convolution based codec backbone to capture local features and incorporate bidirectional attention blocks to exploit global features"
  - [section] "Different from previous approaches to stereo image compression that employ 2D convolutional layers, we adopt 3D convolutions as the backbone of our codec. Unlike 2D convolution, which operates separately on each view, 3D convolution concurrently processes both stereo images."
  - [corpus] No direct evidence in corpus; related works focus on transformers or attention rather than 3D convolution stereo processing.
- Break condition: If stereo views have significantly different resolutions or if the correlation between views is weak, 3D convolution may not provide advantages.

### Mechanism 2
- Claim: The bidirectional mutual attention block facilitates effective feature transfer between views.
- Mechanism: The block uses cross-key and cross-query attention stages to exchange features between views, followed by self-attention to refine the combined features.
- Core assumption: Features from one view contain useful information for processing the other view, and attention mechanisms can effectively identify these relationships.
- Evidence anchors:
  - [abstract] "we propose a mutual attention block to facilitate the transfer of features between views"
  - [section] "This module enhances the integration and cooperation of the stereo views, leading to improved compression performance"
  - [corpus] No direct evidence; related works focus on different attention mechanisms but not specifically bidirectional stereo attention.
- Break condition: If the views are not correlated or if the attention mechanism cannot effectively identify useful cross-view relationships.

### Mechanism 3
- Claim: The cross-dimensional entropy model improves probability estimation by integrating multiple conditioning factors.
- Mechanism: The model combines hyperpriors, spatial context, channel context, and stereo dependency through a unified framework to estimate latent distributions.
- Core assumption: Multiple conditioning factors provide more accurate probability estimates than single-dimension approaches.
- Evidence anchors:
  - [abstract] "we design a novel cross-dimensional entropy model that integrates various conditioning factors, including the spatial context, channel context, and stereo dependency"
  - [section] "To exploit these dependencies, we construct a cross-dimensional entropy model that aggregates hyperprior, spatial context, channel context, and stereo dependency"
  - [corpus] No direct evidence; related works focus on entropy models but not specifically cross-dimensional approaches for stereo compression.
- Break condition: If the additional conditioning factors do not provide meaningful information or if the model becomes too complex to train effectively.

## Foundational Learning

- Concept: 3D convolutions and their differences from 2D convolutions
  - Why needed here: Understanding how 3D convolutions can capture spatio-stereo information is crucial for grasping the codec backbone design
  - Quick check question: How does a 3D convolution kernel differ from a 2D convolution kernel in terms of input dimensions and what correlations it can capture?

- Concept: Attention mechanisms and cross-attention
  - Why needed here: The mutual attention block relies on attention mechanisms to transfer features between views
  - Quick check question: What is the difference between self-attention and cross-attention, and why are both used in the bidirectional mutual attention block?

- Concept: Entropy models in learned image compression
  - Why needed here: Understanding how entropy models estimate probability distributions is essential for grasping the cross-dimensional entropy model
  - Quick check question: How do hyperpriors, spatial context, and channel context contribute to probability estimation in learned image compression?

## Architecture Onboarding

- Component map: Input -> Joint 3D Encoder -> Quantization -> Hyper Encoder -> Cross-Dimensional Entropy Model -> Arithmetic Coder -> Joint 3D Decoder -> Output
- Critical path: Input → Joint 3D Encoder → Quantization → Entropy Model → Arithmetic Coder → Joint 3D Decoder → Output
- Design tradeoffs:
  - 3D vs 2D convolutions: 3D captures inter-view correlations but increases computational complexity
  - Bidirectional vs unidirectional: Bidirectional provides balanced quality but requires more complex architecture
  - Full vs fast variant: Fast variant reduces runtime but may sacrifice some compression performance
- Failure signatures:
  - High bitrate with poor quality: Likely issues with entropy model probability estimation
  - Imbalanced quality between views: Problem with attention block or codec backbone
  - Slow encoding/decoding: Could be due to auto-regressive entropy model or complex 3D convolutions
- First 3 experiments:
  1. Replace 3D convolutions with 2D convolutions to verify inter-view correlation capture
  2. Remove bidirectional attention blocks to test their impact on feature transfer
  3. Simplify entropy model to only use hyperpriors and compare performance degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the BiSIC model change when using a Vision Transformer backbone instead of 3D convolutions?
- Basis in paper: [explicit] The paper mentions that Vision Transformers have proven effective in single image compression and have the potential to further optimize RD performance when used as the backbone of their model.
- Why unresolved: The paper only speculates about this potential improvement and does not provide any experimental results or comparisons with a Vision Transformer backbone.
- What evidence would resolve it: Experimental results comparing the RD performance of BiSIC with a 3D convolution backbone versus a Vision Transformer backbone on the same datasets.

### Open Question 2
- Question: What is the optimal number of slices K for the channel-wise auto-regressive entropy model in terms of the trade-off between compression performance and speed?
- Basis in paper: [explicit] The paper conducts an ablation study on the number of slices K and shows that reducing K leads to a slight decrease in RD performance but accelerates encoding/decoding. However, they do not determine the optimal value of K.
- Why unresolved: The paper only tests a few values of K (6, 8, 12) and does not provide a systematic analysis of how the performance changes with different values of K.
- What evidence would resolve it: A comprehensive analysis of the RD performance and runtime for a wide range of K values, along with a determination of the optimal K that balances performance and speed.

### Open Question 3
- Question: How does the BiSIC model perform on multi-view video compression or immersive video compression compared to existing methods?
- Basis in paper: [explicit] The paper mentions that extending their work to multi-view video compression or immersive video compression is an interesting direction, but they do not provide any experimental results or comparisons.
- Why unresolved: The paper only discusses the potential of extending their method to these domains but does not validate its performance on these tasks.
- What evidence would resolve it: Experimental results comparing the performance of BiSIC on multi-view video compression or immersive video compression with existing methods on relevant datasets.

## Limitations
- Unknown architectural details of aggregation networks (Gag, Gag-ach, Gag-nac) and combine block limit reproducibility
- Evaluation limited to PSNR and MS-SSIM metrics, potentially missing perceptual quality aspects
- Datasets used (InStereo2K and Cityscapes) may not generalize to all stereo image types
- Cross-dimensional entropy model complexity may lead to training stability and computational efficiency challenges

## Confidence
- **High Confidence**: The effectiveness of 3D convolutions for capturing inter-view correlations is well-supported by the core mechanism description and architectural design
- **Medium Confidence**: The bidirectional mutual attention block's contribution to balanced compression quality is plausible based on the mechanism described, though exact implementation details are limited
- **Low Confidence**: The specific performance improvements claimed (3.0%-8.1% BD-rate savings) are difficult to verify without complete architectural specifications and training details

## Next Checks
1. **Ablation Study on 3D Convolution Backbone**: Implement the same architecture but replace 3D convolutions with separate 2D convolutions for each view, then compare RD performance to quantify the inter-view correlation capture benefit

2. **Entropy Model Isolation Test**: Create a simplified entropy model using only hyperpriors (removing spatial context, channel context, and stereo dependency), then measure the performance degradation to validate the contribution of each conditioning factor

3. **Cross-View Feature Transfer Verification**: Analyze the attention weight distributions in the bidirectional mutual attention block to empirically demonstrate that meaningful feature transfer occurs between views and that this transfer correlates with compression quality improvements