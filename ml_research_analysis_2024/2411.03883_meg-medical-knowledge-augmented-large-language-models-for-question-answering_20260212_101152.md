---
ver: rpa2
title: 'MEG: Medical Knowledge-Augmented Large Language Models for Question Answering'
arxiv_id: '2411.03883'
source_url: https://arxiv.org/abs/2411.03883
tags:
- graph
- language
- medical
- llms
- mapping
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents MEG, a parameter-efficient approach for augmenting
  large language models with knowledge graph embeddings for medical question answering.
  MEG uses a lightweight mapping network to incorporate relevant medical knowledge
  graph embeddings into the LLM, enabling effective interpretation of structured knowledge
  without costly continued pretraining.
---

# MEG: Medical Knowledge-Augmented Large Language Models for Question Answering

## Quick Facts
- arXiv ID: 2411.03883
- Source URL: https://arxiv.org/abs/2411.03883
- Reference count: 30
- Primary result: MEG achieves 54.6% accuracy on MedQA-USMLE, outperforming specialized biomedical LLM baselines by 6.7-9.9%

## Executive Summary
MEG presents a parameter-efficient approach for augmenting large language models with knowledge graph embeddings to enhance medical question answering. The method uses a lightweight mapping network to incorporate relevant medical knowledge graph embeddings into the LLM, enabling effective interpretation of structured knowledge without costly continued pretraining. Evaluated on four medical multiple-choice QA datasets, MEG demonstrates significant accuracy gains over specialized baselines while updating only 2% of parameters through LoRA fine-tuning.

## Method Summary
MEG operates in two phases: (1) training a mapping network to transform knowledge graph embeddings from UMLS into the LLM's vector space using contrastive learning, and (2) fine-tuning the LLM with injected KGEs on downstream medical QA datasets. The approach grounds text entities to KG nodes using scispaCy, maps the corresponding embeddings through a 4-layer MLP, and injects them after the LLM's embedding layer. The method achieves state-of-the-art results for 7B models while maintaining computational efficiency through parameter-efficient fine-tuning.

## Key Results
- MEG achieves 54.6% accuracy on MedQA-USMLE and 58.4% on MedMCQA
- Outperforms specialized biomedical LLMs (BioMistral-7B +6.7%, MediTron-7B +9.9%) without costly continued pretraining
- Maintains strong performance across different KG encoders (GraphSAGE, RDF2Vec, DistMult)
- Demonstrates effectiveness across four medical QA datasets while updating only 2% of parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: KGEs guide the LLM to activate the correct semantic region for answer generation
- Mechanism: The mapping network transforms KGEs into the LLM's vector space while preserving their hierarchical structure. When injected after the embedding layer, these mapped embeddings pull the model's token representations toward regions associated with the correct medical concepts, conditioning the generation process.
- Core assumption: The LLM's embedding space contains semantically meaningful regions that can be activated by external embeddings representing the same concepts
- Evidence anchors:
  - [abstract]: "MEG uses a lightweight mapping network to incorporate knowledge graph embeddings into the LLM, enabling it to leverage external knowledge"
  - [section]: "The mapping seems to activate the LLM's embedding region associated with each concept, providing semantic information the model uses to condition its answer generation"
  - [corpus]: Weak evidence - no direct citations found, though related work on knowledge-augmented LLMs exists
- Break condition: If the LLM's embedding space lacks clear semantic clustering or the mapping function fails to preserve semantic relationships during transformation

### Mechanism 2
- Claim: Fine-tuning on KGE-augmented prompts improves medical reasoning without expensive continued pretraining
- Mechanism: During phase II fine-tuning, the LLM learns to interpret mapped KGEs as contextual signals. The frozen embedding layer and mapping network ensure that medical knowledge from the KG consistently influences token representations, while LoRA fine-tuning adapts only 2% of parameters to optimize this integration for medical QA.
- Core assumption: LLMs can learn to interpret and utilize external embeddings as meaningful context during fine-tuning
- Evidence anchors:
  - [abstract]: "MEG attains an average of +6.7% and +9.9% accuracy over specialized models like BioMistral-7B and MediTron-7B, respectively"
  - [section]: "MEG surpasses well-established biomedical LLM baselines like BioMistral-7B or MediTron-7B, which have followed a costly continued pretraining of the base LLMs on curated biomedical data"
  - [corpus]: Weak evidence - no direct citations found, though parameter-efficient tuning is established in literature
- Break condition: If the LLM cannot learn to interpret KGEs effectively, or if the frozen components prevent necessary adaptation

### Mechanism 3
- Claim: The contrastive loss objective ensures meaningful semantic alignment between KGEs and LLM embeddings
- Mechanism: The NT-Xent contrastive loss pulls KGEs of similar entities closer together in the LLM's space while pushing dissimilar ones apart. This creates a structured embedding space where medical concepts maintain their semantic relationships, enabling the LLM to leverage these relationships during generation.
- Core assumption: Contrastive learning can effectively align two different embedding spaces while preserving semantic relationships
- Evidence anchors:
  - [section]: "We employ a popular contrastive self-supervised learning objective... computes a normalized temperature-scaled cross-entropy loss for a positive pair"
  - [section]: "the contrastive loss serves as an unsupervised objective function for training the network to bring similar entities closer together in Y and push dissimilar ones apart"
  - [corpus]: Weak evidence - no direct citations found, though contrastive learning is well-established in representation learning
- Break condition: If the temperature parameter is poorly tuned, or if the batch size is too small to provide meaningful negative samples

## Foundational Learning

- Concept: Graph embedding methods (node2vec, GraphSAGE, translational models)
  - Why needed here: Understanding how different KG encoders capture graph structure is crucial for selecting the right KGE source for MEG
  - Quick check question: What's the key difference between random-walk-based and message-passing graph encoders in terms of the structural information they capture?

- Concept: Parameter-efficient fine-tuning (LoRA, adapters)
  - Why needed here: MEG uses LoRA to update only 2% of parameters during fine-tuning, making it computationally efficient while still achieving strong performance
  - Quick check question: How does LoRA achieve parameter efficiency compared to full fine-tuning?

- Concept: Contrastive learning objectives (NT-Xent, InfoNCE)
  - Why needed here: The mapping network training uses contrastive loss to align KGE space with LLM embedding space while preserving semantic relationships
  - Quick check question: What role does the temperature parameter play in contrastive learning objectives?

## Architecture Onboarding

- Component map:
  - Knowledge Graph Encoder (GraphSAGE) → generates KGEs from UMLS
  - Mapping Network (4-layer MLP) → transforms KGEs to LLM space
  - Entity Grounding Module → links text entities to KG nodes
  - LLM with Frozen Embedding Layer → generates answers conditioned on KGEs
  - LoRA adapters → enable efficient fine-tuning on downstream tasks

- Critical path: KG Encoder → Mapping Network → LLM Input → Answer Generation
  - The mapping network is the key innovation that bridges the modality gap

- Design tradeoffs:
  - Early injection (after embedding layer) vs late injection (before final layers) - early injection allows more layers to attend to KGEs
  - Fixed vs variable number of KGEs per example - fixed enables batching but may lose some information
  - Contrastive loss vs direct regression - contrastive loss better preserves semantic relationships

- Failure signatures:
  - Low accuracy on zero-shot tasks indicates poor mapping network training
  - Degraded performance when adding KGEs suggests the LLM cannot interpret them
  - High variance across seeds indicates sensitivity to initialization

- First 3 experiments:
  1. Test zero-shot accuracy on MedQA with different KG encoders (GraphSAGE, RDF2Vec, DistMult) to validate Mechanism 3
  2. Compare early injection vs late injection of KGEs to verify the importance of allowing multiple layers to attend to KGEs
  3. Train with and without contrastive loss in the mapping network to demonstrate its importance for semantic alignment

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of chain-of-thought instruction tuning during Phase I on MEG's downstream medical QA performance?
- Basis in paper: [inferred] The paper mentions that future work includes exploring CoT instruction tuning in Phase I, exploiting information from graph triples instead of relying only on entity labels.
- Why unresolved: The authors did not conduct experiments with CoT instruction tuning in Phase I, leaving the potential performance gains from this approach unknown.
- What evidence would resolve it: Experimental results comparing MEG variants with and without CoT instruction tuning during Phase I on medical QA benchmarks like MedQA, MedMCQA, and MMLU-Medical.

### Open Question 2
- Question: How effective is MEG's lightweight approach for handling out-of-vocabulary medical terms compared to more resource-intensive methods?
- Basis in paper: [explicit] The authors state that MEG can initialize KGEs for new terms by averaging their one-hop neighbors in the KG, making it adaptable to new vocabulary, but note that the efficacy of this method should be evaluated in future work.
- Why unresolved: The paper does not provide experimental validation of MEG's out-of-vocabulary term handling capabilities or comparisons with alternative approaches.
- What evidence would resolve it: Experiments introducing novel medical terms to MEG and baselines, measuring accuracy degradation and comparing adaptation efficiency (computational cost, parameter updates) across methods.

### Open Question 3
- Question: Does incorporating knowledge graph embeddings into LLMs help mitigate positional biases in medical multiple-choice questions?
- Basis in paper: [explicit] The authors note that while they use text answer evaluation instead of first-token ranking to alleviate positional bias, whether KGEs further help LLMs mitigate such biases needs to be explored in future work.
- Why unresolved: The paper does not investigate the interaction between KGE incorporation and positional bias mitigation, leaving this potential benefit unexplored.
- What evidence would resolve it: Controlled experiments testing MEG and baselines on medical MCQs with systematically varied answer positions, measuring accuracy differences and comparing performance with and without KGE incorporation.

## Limitations
- Limited evaluation to multiple-choice question answering formats, with unknown performance on open-ended medical reasoning tasks
- Dependence on knowledge graph coverage, with potential degradation when encountering concepts outside UMLS
- Uncertain robustness across different KG encoder architectures beyond the primary GraphSAGE evaluation

## Confidence
**High Confidence**: MEG's overall effectiveness in improving medical QA accuracy over baselines; parameter-efficient nature of the approach (2% parameter updates via LoRA); comparative advantage over costly continued pretraining methods

**Medium Confidence**: Specific mechanism by which KGEs guide semantic activation in the LLM; contrastive loss's role in preserving semantic relationships during mapping; generalizability across different KG encoders

**Low Confidence**: Performance on non-MCQA medical reasoning tasks; robustness to KG coverage limitations; effectiveness in zero-shot or few-shot settings

## Next Checks
1. **Cross-Encoder Robustness Test**: Evaluate MEG using three additional KG encoders with fundamentally different architectures (node2vec, GraphSAGE, and a translational model like TransE). Compare performance distributions across all four encoders to quantify the method's robustness to KG encoder choice.

2. **Task Generalization Experiment**: Test MEG on clinical text summarization and diagnosis generation tasks that require multi-step reasoning beyond multiple-choice answering. This validates whether KGE-augmented LLMs generalize to open-ended medical reasoning.

3. **Knowledge Coverage Analysis**: Systematically identify medical concepts in evaluation datasets that lack corresponding UMLS embeddings. Measure performance degradation on questions containing these "out-of-knowledge-graph" concepts to quantify the approach's dependence on KG completeness.