---
ver: rpa2
title: 'Evaluating the Evaluators: Towards Human-aligned Metrics for Missing Markers
  Reconstruction'
arxiv_id: '2410.14334'
source_url: https://arxiv.org/abs/2410.14334
tags:
- metrics
- markers
- missing
- data
- marker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of evaluating missing marker reconstruction
  in motion capture data. It shows that commonly used metrics like RMSE do not correlate
  well with subjective perception of reconstruction quality.
---

# Evaluating the Evaluators: Towards Human-aligned Metrics for Missing Markers Reconstruction

## Quick Facts
- **arXiv ID**: 2410.14334
- **Source URL**: https://arxiv.org/abs/2410.14334
- **Reference count**: 30
- **Primary result**: Commonly used RMSE metric does not correlate with subjective perception of missing marker reconstruction quality in motion capture data.

## Executive Summary
This paper addresses the problem of evaluating missing marker reconstruction in motion capture data, demonstrating that commonly used metrics like RMSE fail to correlate with human perception of reconstruction quality. The authors propose and evaluate new metrics—Bone Distance Preservation (BDP) and Velocity Distance (VD)—that consider spatial and temporal consistency. A user study with domain experts confirms that VD with Ground Truth and BDP without Ground Truth significantly correlate with subjective quality perception, while RMSE does not.

## Method Summary
The authors evaluate missing marker reconstruction using two neural network models: a Vanilla CNN and a Hips Outwards architecture that predicts body parts sequentially. They train these models on paired raw and clean motion capture data, gradually increasing the difficulty of reconstruction tasks. The evaluation compares traditional RMSE metrics against newly proposed BDP and VD metrics, both with and without ground truth. A user study with 10 domain experts assesses subjective quality by comparing solved skeleton animations, with results showing that VD with GT and BDP without GT correlate significantly with human judgment while RMSE does not.

## Key Results
- RMSE fails to correlate with subjective quality perception of missing marker reconstruction
- Velocity Distance (VD) with Ground Truth shows high correlation with subjective quality
- Bone Distance Preservation (BDP) without Ground Truth also correlates significantly with subjective quality
- The Hips Outwards model consistently outperforms the Vanilla CNN across all metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Velocity Distance (VD) with Ground Truth correlates with subjective quality because it measures temporal smoothness directly aligned with human perception of motion fluidity.
- Mechanism: VD captures the difference between predicted and actual velocity vectors, penalizing abrupt changes that humans perceive as "popping" or "flicking."
- Core assumption: Human evaluators primarily judge motion quality based on temporal coherence rather than absolute positional accuracy.
- Evidence anchors:
  - [abstract]: "VD with Ground Truth and BDP without Ground Truth correlate significantly with subjective quality perception"
  - [section 6]: "VD with GT has a relatively high correlation, followed by BDP"
- Break condition: If velocity patterns are perceptually similar despite different ground truth velocities (e.g., rhythmic motions), VD may fail to capture quality differences.

### Mechanism 2
- Claim: Bone Distance Preservation (BDP) without Ground Truth correlates because it enforces spatial consistency of anatomical proportions across frames.
- Mechanism: BDP measures how well predicted bone lengths remain consistent over time, preventing distortions that humans perceive as "broken" or "twisted" limbs.
- Core assumption: Humans judge marker quality based on the maintenance of body part proportions rather than exact marker positions.
- Evidence anchors:
  - [abstract]: "We introduce and evaluate a set of better-correlated metrics that can drive progress in the field"
  - [section 2.2]: "MSE-based metrics are problematic because they do not account for spatial and temporal cohesion"
- Break condition: If anatomical proportions are consistent but marker positions are perceptually wrong (e.g., incorrect limb orientation), BDP may still pass.

### Mechanism 3
- Claim: RMSE fails to correlate because it treats positional errors equally regardless of perceptual impact.
- Mechanism: RMSE sums squared distances between predicted and ground truth markers, giving equal weight to perceptually critical errors (like foot placement) and less noticeable errors.
- Core assumption: Human perception weights certain marker positions more heavily than others in judging overall quality.
- Evidence anchors:
  - [abstract]: "We show that this metric does not correlate with subjective perception of the fill quality"
  - [section 4.2.1]: "RMSE does not take into account temporal or spatial cohesion"
- Break condition: If all marker errors happen to be in perceptually neutral positions, RMSE might correlate better than expected.

## Foundational Learning

- Concept: Motion capture data representation (marker vs. skeleton space)
  - Why needed here: The paper uses both raw marker data for metric computation and solved skeleton data for human evaluation, requiring understanding of both representations.
  - Quick check question: Why does the paper evaluate metrics in marker space but conduct user studies in skeleton space?

- Concept: Temporal vs. spatial consistency in animation quality
  - Why needed here: The paper's key contribution is metrics that capture both dimensions, which are critical for human perception of quality.
  - Quick check question: What specific perceptual issues does BDP address that RMSE cannot capture?

- Concept: Correlation analysis and statistical significance
  - Why needed here: The paper uses Kendall's tau to measure metric-human correlation, requiring understanding of non-parametric correlation methods.
  - Quick check question: Why might the paper use Kendall's tau instead of Pearson correlation for this analysis?

## Architecture Onboarding

- Component map:
  Raw MoCap -> Interpolation -> Model prediction -> Metrics calculation -> User study with solved animations

- Critical path:
  1. Load paired raw/clean data
  2. Preprocess with hip-centering and interpolation
  3. Train models with increasing gap difficulty
  4. Generate predictions on test set
  5. Compute all metrics
  6. Solve to skeleton for user study stimuli
  7. Run correlation analysis

- Design tradeoffs:
  - Using ground truth in metrics (BDP/VD with GT) provides stronger correlation but requires access to clean data
  - Sequential body part prediction (Hips Outwards) improves quality but increases inference complexity
  - Hip-centering preserves inter-actor distance but loses absolute positioning

- Failure signatures:
  - Poor temporal consistency → High VD without GT, low user ratings
  - Spatial distortions → High BDP without GT, user comments about "broken" limbs
  - General poor reconstruction → High RMSE, but weak correlation with user ratings

- First 3 experiments:
  1. Compare RMSE vs. VD with GT correlation on synthetic corrupted data
  2. Test Hips Outwards vs. Vanilla CNN on data with known spatial-temporal issues
  3. Evaluate BDP without GT on sequences with varying bone length consistency

## Open Questions the Paper Calls Out
- How do the proposed metrics (BDP and VD) perform when evaluated on datasets with different characteristics, such as varying numbers of markers or different types of motion?
- Can the proposed metrics be adapted or extended to evaluate missing marker reconstruction in non-human motion capture data, such as animal movements or robotic motions?
- How do the proposed metrics compare to other existing metrics in terms of computational efficiency and ease of implementation?

## Limitations
- Small dataset with only two actors performing grappling motions limits generalizability
- User study involved only 10 domain experts, limiting statistical power
- Model architectures not fully specified, making exact reproduction challenging

## Confidence
- **High**: The claim that RMSE poorly correlates with subjective quality is well-supported by both theoretical reasoning and empirical correlation analysis
- **Medium**: The superiority of VD with GT and BDP without GT is demonstrated but based on a single dataset and user study
- **Medium**: The mechanism explaining why temporal metrics work better aligns with established perceptual research but requires additional user study data to confirm

## Next Checks
1. Test VD and BDP metrics on a larger, more diverse motion capture dataset with different motion types (walking, running, gestures) to verify generalization
2. Conduct a larger-scale user study (30+ participants) with varied expertise levels to strengthen statistical significance of correlation findings
3. Implement ablation studies removing velocity or spatial components from VD and BDP to quantify their individual contributions to correlation with human judgment