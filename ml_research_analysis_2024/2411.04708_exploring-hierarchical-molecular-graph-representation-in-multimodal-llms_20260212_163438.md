---
ver: rpa2
title: Exploring Hierarchical Molecular Graph Representation in Multimodal LLMs
arxiv_id: '2411.04708'
source_url: https://arxiv.org/abs/2411.04708
tags:
- graph
- molecular
- features
- tasks
- level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores how different levels of graph features impact
  multimodal large language models (MLLMs) in molecular tasks. The authors propose
  a multi-level graph encoder that extracts node, motif, and graph-level features
  from molecular graphs and investigate three fusion strategies: no reduction, hierarchical
  reduction, and all reduction.'
---

# Exploring Hierarchical Molecular Graph Representation in Multimodal LLMs

## Quick Facts
- arXiv ID: 2411.04708
- Source URL: https://arxiv.org/abs/2411.04708
- Authors: Chengxin Hu; Hao Li; Yihe Yuan; Jing Li; Ivor Tsang
- Reference count: 8
- Primary result: Even reducing all graph features to a single token doesn't significantly impact multimodal LLM performance on molecular tasks

## Executive Summary
This paper investigates how different levels of graph features impact multimodal large language models (MLLMs) in molecular tasks. The authors propose a multi-level graph encoder that extracts node, motif, and graph-level features from molecular graphs and evaluate three fusion strategies: no reduction, hierarchical reduction, and all reduction. Experiments on five molecular tasks reveal that LLMs show minimal performance degradation even when all graph features are compressed to a single token, suggesting current models don't fully utilize the rich hierarchical information available in molecular graphs. The study finds that optimal feature levels vary by task, with graph-level features excelling in reaction prediction while motif-level features work best for molecular description.

## Method Summary
The paper employs a two-stage training pipeline for multimodal molecular tasks. First, a multi-level graph neural network extracts hierarchical features (node, motif, and graph levels) from molecular graphs using a dynamic segmentation algorithm. These features are then fused using one of three strategies: no reduction (keeping all levels), hierarchical reduction (progressively reducing levels), or all reduction (compressing to single token). The fused features are projected to the LLM embedding space and concatenated with SELFIES text representations. The model is first pretrained on PubChem data for alignment, then fine-tuned with LoRA adapters on five downstream molecular tasks including reaction prediction and molecular description.

## Key Results
- Reducing all GNN-generated feature tokens to a single one does not significantly impact model performance across tasks
- Graph-level features significantly enhance exact match performance in reaction prediction
- Motif-level features work best for molecular description tasks
- Current LLMs appear to rely more heavily on SELFIES representations than on hierarchical graph features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-level graph features improve molecular task performance by capturing hierarchical structural information
- Mechanism: The model extracts node-level (atomic), motif-level (functional group), and graph-level (whole molecule) features, allowing LLMs to leverage different granularities of molecular information for different tasks
- Core assumption: Different molecular tasks benefit from different levels of structural detail, and LLMs can effectively utilize this hierarchical information when properly aligned
- Evidence anchors:
  - [abstract]: "even reducing all GNN-generated feature tokens to a single one does not significantly impact model performance"
  - [section 4.3]: "graph-level features significantly enhance exact match performance, while features from other levels improve the similarity between the predicted and target molecules"
  - [corpus]: Found 25 related papers discussing hierarchical graph representations for molecular tasks, suggesting active research in this area
- Break condition: If the LLM cannot effectively align and utilize multi-level features, or if tasks don't actually require different levels of detail, the hierarchical approach provides no benefit

### Mechanism 2
- Claim: Static processing of hierarchical graph features is insufficient for optimal LLM performance
- Mechanism: Current linear projectors perform simple dimension mapping without considering the semantic differences between feature levels, preventing the LLM from fully utilizing the hierarchical information
- Core assumption: A dynamic projector that can selectively emphasize or suppress different feature levels based on task requirements would significantly improve performance
- Evidence anchors:
  - [section 4.3]: "The current linear projector only performs a straightforward projection of graph features... adopting a static approach that lacks adaptability"
  - [section 4.3]: "This static approach falls short in tasks requiring a nuanced balance of feature fusion, suppression, or emphasis"
  - [corpus]: Limited evidence in corpus - this appears to be a novel insight from the paper
- Break condition: If task requirements are uniform across different molecular structures, or if LLMs can implicitly learn to handle feature level differences without explicit dynamic processing

### Mechanism 3
- Claim: Graph features provide minimal additional value when LLMs rely primarily on SELFIES representations
- Mechanism: LLMs appear to use SELFIES string relationships for reasoning rather than fully leveraging the rich graph structural information, as evidenced by minimal performance degradation when graph features are reduced or averaged
- Core assumption: LLMs have learned to map inputs to outputs based on textual patterns rather than structural understanding when given both modalities
- Evidence anchors:
  - [abstract]: "even reducing all GNN-generated feature tokens to a single one does not significantly impact model performance"
  - [section 4.3]: "Supplying the LLM with this overly compressed feature set still yielded acceptable performance across three downstream tasks"
  - [section 4.3]: "This may imply that the LLM does not heavily rely on multi-level graph features or may not fully comprehend them"
- Break condition: If future work demonstrates that LLMs can be trained to properly utilize graph features, or if graph information proves critical for more complex molecular tasks

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their application to molecular graphs
  - Why needed here: The paper relies on GNNs to extract hierarchical features from molecular graphs at node, motif, and graph levels
  - Quick check question: How do GNNs propagate information through molecular graphs to capture local and global structural patterns?

- Concept: Multimodal learning and alignment between different data modalities
  - Why needed here: The work involves aligning graph features with LLM embeddings and with textual molecular descriptions
  - Quick check question: What are the key challenges in aligning graph-based representations with text-based representations for multimodal models?

- Concept: Molecular representation formats (SMILES, SELFIES)
  - Why needed here: The paper uses both graph and text representations, with SELFIES serving as the primary textual format for molecular data
  - Quick check question: What are the key differences between SMILES and SELFIES representations, and why might SELFIES be preferred for LLM-based molecular tasks?

## Architecture Onboarding

- Component map: Multi-level GNN -> Projector -> LLM backbone -> LoRA adapters -> Task outputs
- Critical path: 1) Graph feature extraction via multi-level GNN 2) Feature fusion/compression 3) Projection to LLM embedding space 4) LLM processing with concatenated features 5) Task-specific output generation
- Design tradeoffs: Feature granularity vs. computational efficiency; Static vs. dynamic projector design; Graph vs. text modality emphasis
- Failure signatures: Performance degradation when using graph features suggests alignment issues; Inconsistent results across tasks may indicate feature level mismatch; Invalid molecule generation indicates SELFIES understanding problems
- First 3 experiments:
  1. Replicate baseline performance on forward reaction prediction to verify implementation
  2. Test all three reduction methods (no reduction, hierarchical reduction, all reduction) on a single task
  3. Compare individual feature level performance (node, motif, graph) on reagent prediction task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal feature fusion strategy (no reduction, hierarchical reduction, or all reduction) for different molecular tasks?
- Basis in paper: [explicit] The authors explicitly compare these three fusion methods across multiple tasks and find that the optimal strategy varies by task
- Why unresolved: While the paper provides experimental results showing which method works best for specific tasks, it doesn't explain the underlying reasons for these differences or provide a principled way to predict which fusion strategy would work best for a new task
- What evidence would resolve it: A theoretical framework explaining why certain tasks benefit from different fusion strategies, or empirical results showing consistent patterns across a larger variety of molecular tasks

### Open Question 2
- Question: How can we design a dynamic projector that effectively processes hierarchical graph features based on task requirements?
- Basis in paper: [explicit] The authors conclude that "a projector is needed to dynamically process these features and maximize the contribution of each level" and note that the current linear projector is insufficient
- Why unresolved: The paper identifies this as a key limitation and future direction but does not propose specific architectures or training methods for such a dynamic projector
- What evidence would resolve it: Implementation and evaluation of a dynamic projector architecture that can adaptively weight and fuse features from different hierarchical levels based on task context

### Open Question 3
- Question: To what extent do LLMs truly understand graph features versus relying on textual representations like SELFIES?
- Basis in paper: [explicit] The authors observe that "even pooling all feature tokens into one does not significantly harm LLM performance" and conclude that "the LLM may rely more heavily on SELFIES for reasoning"
- Why unresolved: The paper provides evidence suggesting LLMs don't fully utilize graph features, but doesn't directly test whether LLMs can understand graph structures independently of textual representations
- What evidence would resolve it: Controlled experiments comparing LLM performance on graph-only inputs versus graph plus textual representations, or tests where the LLM must reason about graph structures without textual guidance

### Open Question 4
- Question: What alignment pretraining strategies would best enable LLMs to comprehensively understand molecular graph features?
- Basis in paper: [explicit] The authors identify that "new alignment training approaches may be necessary" and that current approaches "may be insufficient for deep comprehension of graph features"
- Why unresolved: While the paper suggests that alignment pretraining needs improvement, it doesn't propose specific methods or evaluate alternative pretraining strategies
- What evidence would resolve it: Comparative evaluation of different alignment pretraining strategies, including those that align graph features with both molecular descriptions and SELFIES representations, showing improvements in graph feature understanding

## Limitations

- The study only examines five specific molecular tasks, limiting generalizability to other molecular domains
- The paper identifies the need for dynamic projectors but doesn't implement or evaluate such architectures
- The finding that LLMs don't fully utilize graph features could be due to feature representation issues rather than LLM limitations

## Confidence

**High Confidence**: Experimental methodology and implementation details are well-specified with clear ablation studies comparing different feature reduction strategies.

**Medium Confidence**: Conclusion that LLMs don't fully utilize hierarchical graph features is supported by evidence but could have alternative explanations related to feature representation.

**Low Confidence**: Broader implications about LLM molecular understanding and specific recommendations for future architectural improvements lack strong empirical support beyond the immediate experimental context.

## Next Checks

1. Conduct ablation studies to determine whether multi-level graph features contain redundant information that explains why reducing them to a single token doesn't hurt performance.

2. Implement and evaluate a simple dynamic projector that can emphasize different feature levels based on task requirements, then compare its performance against the static projector.

3. Test the same feature reduction strategies on molecular tasks outside the current scope (e.g., protein-ligand binding prediction) to determine whether findings generalize to more structurally complex problems.