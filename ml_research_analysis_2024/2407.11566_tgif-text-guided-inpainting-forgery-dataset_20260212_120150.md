---
ver: rpa2
title: 'TGIF: Text-Guided Inpainting Forgery Dataset'
arxiv_id: '2407.11566'
source_url: https://arxiv.org/abs/2407.11566
tags:
- image
- methods
- images
- inpainting
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors present the Text-Guided Inpainting Forgery (TGIF) dataset,
  containing 75k high-resolution images inpainted using generative AI models (SD2,
  SDXL, Adobe Firefly). Each authentic image from MS-COCO is manipulated to replace
  depicted objects with AI-generated counterparts, with both spliced and fully regenerated
  versions saved.
---

# TGIF: Text-Guided Inpainting Forgery Dataset

## Quick Facts
- arXiv ID: 2407.11566
- Source URL: https://arxiv.org/abs/2407.11566
- Authors: Hannes Mareen; Dimitrios Karageorgiou; Glenn Van Wallendael; Peter Lambert; Symeon Papadopoulos
- Reference count: 40
- Primary result: The dataset contains 75k high-resolution images inpainted using generative AI models, revealing that traditional IFL methods fail on fully regenerated images while SID methods detect but cannot localize synthetic regions.

## Executive Summary
The TGIF dataset addresses a critical gap in image forensics by providing a comprehensive benchmark for detecting and localizing forgeries created using text-guided inpainting with modern generative AI models. The dataset contains 75k high-resolution images derived from MS-COCO, where authentic objects are replaced with AI-generated counterparts using three different inpainting models (SD2, SDXL, Adobe Firefly). Each image is manipulated to create both spliced (AI-generated region inserted into original) and fully regenerated versions, with metadata on aesthetic quality and image-text matching included.

Benchmarking results reveal that traditional image forgery localization methods fail completely on fully regenerated images, as the regeneration process destroys forensic traces that these methods rely on. While synthetic image detection methods can identify fully regenerated images as fake, they cannot localize the manipulated regions due to their design for whole-image classification rather than localization. Additionally, both IFL and SID methods show significant performance degradation under compression, particularly with modern formats like WEBP.

## Method Summary
The TGIF dataset was created by selecting objects from MS-COCO images and applying text-guided inpainting using three generative models: SD2, SDXL, and Adobe Firefly. Each authentic image was transformed into 24 manipulated variants (2 masks × 3 variations × 4 methods/splices). For SD2 and Adobe Firefly, both spliced versions (AI-generated region inserted into original image) and fully regenerated versions were saved. For SDXL, only fully regenerated outputs were saved due to significant discoloration when spliced. The dataset includes metadata on aesthetic quality (NIMA, GIQA scores) and image-text matching (ITM scores) for the inpainted regions. The paper benchmarks state-of-the-art IFL methods (PSCC-Net, SPAN, etc.) and SID methods (CNNDetect, DIMD, etc.) on the test set, evaluating performance under JPEG and WEBP compression.

## Key Results
- Traditional IFL methods fail completely on fully regenerated images, achieving near-zero F1 scores.
- SID methods can detect fully regenerated images as fake but cannot localize the synthetic regions.
- Both IFL and SID methods show significant performance degradation under compression, with WEBP causing more disruption than JPEG at equivalent quality levels.
- The dataset provides a valuable benchmark for developing forensic methods that can handle modern generative manipulations.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fully regenerated images bypass traditional IFL methods because the regeneration process destroys forensic traces like compression artifacts and camera noise.
- Mechanism: Text-guided inpainting models regenerate the entire image (not just the masked area), diffusing and denoising the full image. This process removes subtle but detectable forensic cues that IFL methods rely on, rendering them ineffective against fully regenerated inpainting.
- Core assumption: Traditional IFL methods depend on detecting imperceptible inconsistencies introduced during capture, editing, or storage.
- Evidence anchors:
  - [abstract]: "diffusion model-based approaches could either splice the inpainted region into the original image, or regenerate the entire image. In the latter case, traditional image forgery localization (IFL) methods typically fail."
  - [section]: "In Adobe Firefly (Photoshop), the GenAI inpainted image is spliced back into the original image... For SDXL, we only saved the fully regenerated output image as a 1024p image. That is because the SDXL inpainting model discolors the entire image, which is extremely visible when splicing into the original."
- Break condition: If forensic methods are trained on fully regenerated images or if regeneration is limited to the masked area only, traditional IFL may regain some effectiveness.

### Mechanism 2
- Claim: SID methods can detect fully regenerated images but cannot localize the synthetic region because they output global image-level predictions.
- Mechanism: SID models are trained to distinguish entire synthetic images from real ones, not to detect synthetic patches within real images. When applied to spliced or fully regenerated images, they produce a single authenticity score for the whole image rather than a per-pixel mask.
- Core assumption: SID methods are designed for whole-image classification, not for localization.
- Evidence anchors:
  - [abstract]: "traditional SID may detect the regenerated inpainted images to be fake, but cannot localize the inpainted area."
  - [section]: "Table II shows the performance (AUC) results for all evaluated SID methods... We have verified that, indeed, no SID method is able to detect the synthetic spliced regions."
- Break condition: If SID methods are retrained or adapted with localization supervision, they may gain the ability to localize synthetic regions.

### Mechanism 3
- Claim: Compression (especially WEBP) reduces the performance of both IFL and SID methods by further degrading forensic traces.
- Mechanism: Compression introduces or amplifies artifacts and noise patterns that interfere with the forensic cues used by detection models. WEBP compression appears more disruptive than JPEG at equivalent quality levels.
- Core assumption: Compression alters the statistical properties of images in ways that forensic methods are sensitive to.
- Evidence anchors:
  - [abstract]: "both IFL and SID methods fail when exposed to stronger compression, while they are less robust to modern compression algorithms, such as WEBP."
  - [section]: "When performing JPEG compression, F1 scores drop significantly. Moreover, this performance drop is amplified when performing WEBP compression."
- Break condition: If forensic models are trained with compressed images or if compression artifacts are explicitly modeled, robustness may improve.

## Foundational Learning

- Concept: Image Forgery Localization (IFL)
  - Why needed here: IFL methods are the traditional approach to detecting local image manipulations, but fail on fully regenerated inpainting.
  - Quick check question: What type of forensic cues do IFL methods typically rely on to detect forgeries?

- Concept: Synthetic Image Detection (SID)
  - Why needed here: SID methods can detect fully regenerated images but lack localization capability, highlighting a gap in forensic pipelines.
  - Quick check question: Why can SID methods detect fully regenerated images but not localize the inpainted region?

- Concept: Text-Guided Inpainting
  - Why needed here: This is the core manipulation type in the dataset, and understanding its process is key to why it evades detection.
  - Quick check question: How does text-guided inpainting differ from traditional inpainting in terms of image regeneration?

## Architecture Onboarding

- Component map: MS-COCO images -> Object cropping/masking -> Inpainting (SD2, SDXL, Adobe Firefly) -> Splicing vs. full regeneration -> Metadata collection -> Benchmarking
- Critical path:
  1. Select authentic image and object from MS-COCO.
  2. Generate inpainted variants using three methods (SD2, SDXL, Adobe Firefly).
  3. Save both spliced and fully regenerated versions where applicable.
  4. Compute metadata (aesthetic, ITM scores).
  5. Evaluate on IFL and SID methods.
  6. Test robustness under JPEG and WEBP compression.
- Design tradeoffs:
  - High resolution (up to 1024px) increases realism but also computational cost.
  - Providing both spliced and fully regenerated images increases dataset size but enables richer benchmarking.
  - Using multiple inpainting methods increases diversity but introduces methodological complexity.
- Failure signatures:
  - IFL methods: Near-zero F1 scores on fully regenerated images.
  - SID methods: High AUC on full images but inability to localize synthetic regions.
  - Both: Sharp performance drop under WEBP compression.
- First 3 experiments:
  1. Run IFL methods on SD2-sp (spliced) vs. SD2-fr (fully regenerated) to confirm localization gap.
  2. Apply SID methods to fully regenerated images and check if detection occurs without localization.
  3. Compress a subset of images with JPEG Q60 and WEBP Q60, then re-evaluate both IFL and SID performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can image forgery localization (IFL) methods be developed that can effectively detect and localize fully regenerated inpainted regions created by text-guided generative AI models?
- Basis in paper: [explicit] The paper states that traditional IFL methods fail to detect regenerated inpainted images, highlighting this as a new challenge.
- Why unresolved: Current IFL methods rely on detecting imperceptible inconsistencies like compression artifacts or noise patterns, which are removed when the entire image is regenerated by diffusion models.
- What evidence would resolve it: Development and evaluation of new IFL methods that can successfully detect and localize fully regenerated inpainted regions on datasets like TGIF, demonstrating performance metrics above a certain threshold.

### Open Question 2
- Question: How does the choice of compression algorithm (JPEG vs WEBP) impact the effectiveness of synthetic image detection (SID) methods for detecting text-guided inpainted forgeries?
- Basis in paper: [explicit] The paper shows that both IFL and SID methods fail when exposed to stronger compression, with notably worse performance under WEBP compared to JPEG.
- Why unresolved: The paper only benchmarks a limited set of compression qualities and does not explore the full spectrum of compression levels or investigate the underlying reasons for the performance degradation.
- What evidence would resolve it: Systematic evaluation of SID methods across a wide range of compression qualities for both JPEG and WEBP, coupled with analysis of how compression affects the features used by SID methods to detect synthetic images.

### Open Question 3
- Question: Can synthetic image detection (SID) methods be adapted to localize the inpainted regions within images that contain both authentic and synthetically generated content?
- Basis in paper: [explicit] The paper states that while SID methods can detect fully regenerated inpainted images, they cannot localize the inpainted area, as they were not designed for this purpose.
- Why unresolved: SID methods are typically trained to classify entire images as real or fake, rather than identifying specific regions of manipulation within an image.
- What evidence would resolve it: Development and evaluation of SID methods that can accurately localize inpainted regions within mixed-content images, demonstrating pixel-level localization performance metrics on datasets like TGIF.

## Limitations

- The evaluation focuses on a specific set of IFL and SID methods, and results may not generalize to all possible forensic approaches.
- The study does not explore the impact of different inpainting parameters or seed settings on detection performance.
- The compression experiments use fixed quality settings without exploring the full quality-compression artifact tradeoff space.

## Confidence

- High confidence: The dataset construction methodology and the fundamental observation that traditional IFL methods fail on fully regenerated images are well-supported by the evidence provided.
- Medium confidence: The conclusion that SID methods can detect but not localize synthetic regions, as this depends on the specific implementations tested and their architectural limitations.
- Medium confidence: The claim about WEBP compression being more disruptive than JPEG, as this is based on specific quality settings and may vary with different implementations or quality levels.

## Next Checks

1. Evaluate additional IFL methods not included in the benchmark, particularly those designed for GAN-generated images, to test the robustness of the conclusion about traditional IFL failure.
2. Test the impact of varying inpainting model parameters (such as guidance scale, number of steps, or seed values) on detection performance to understand if certain settings preserve more forensic traces.
3. Perform a comprehensive compression analysis across a wider range of quality settings for both JPEG and WEBP to better understand the relationship between compression artifacts and detection performance.