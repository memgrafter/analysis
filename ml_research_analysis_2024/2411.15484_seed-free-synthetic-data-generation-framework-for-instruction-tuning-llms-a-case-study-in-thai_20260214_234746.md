---
ver: rpa2
title: 'Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs:
  A Case Study in Thai'
arxiv_id: '2411.15484'
source_url: https://arxiv.org/abs/2411.15484
tags:
- thai
- data
- dataset
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of developing high-performing
  large language models (LLMs) for low-resource languages, specifically Thai, in a
  data-efficient manner. The authors propose a seed-data-free synthetic data generation
  framework that incorporates three key properties: fluency, diversity, and cultural
  context.'
---

# Seed-Free Synthetic Data Generation Framework for Instruction-Tuning LLMs: A Case Study in Thai

## Quick Facts
- arXiv ID: 2411.15484
- Source URL: https://arxiv.org/abs/2411.15484
- Reference count: 10
- Achieves competitive performance using only 5,000 synthetic instructions compared to SOTA Thai LLMs trained on 50k-300k instructions

## Executive Summary
This paper addresses the challenge of developing high-performing large language models (LLMs) for low-resource languages, specifically Thai, in a data-efficient manner. The authors propose a seed-data-free synthetic data generation framework that incorporates three key properties: fluency, diversity, and cultural context. The framework uses an LLM to generate diverse topics, retrieve relevant contexts from Wikipedia, and create instructions for various tasks such as question answering, summarization, and conversation. Experimental results show that their best-performing synthetic dataset, which incorporates all three key properties, achieves competitive performance using only 5,000 instructions compared to state-of-the-art Thai LLMs trained on hundreds of thousands of instructions.

## Method Summary
The framework employs Claude-3 Haiku to generate diverse topics (general or cultural), retrieve relevant contexts from Wikipedia, and create instructions for four task types (Closed QA, Summarization, Conversation, Multiple Choice). A diversity control mechanism filters out semantically similar samples using BGE-M3 embeddings with cosine similarity threshold of 0.95. The resulting synthetic datasets are used to fine-tune Llama-3 8B using QLoRA with specific hyperparameters. The approach is evaluated on WangchanThaiInstruct benchmark across 7 tasks with multiple evaluation metrics.

## Key Results
- Best synthetic dataset (incorporating fluency, diversity, and cultural context) achieves competitive performance with only 5,000 instructions
- Outperforms other synthetic variants on Thai Culture Test Set and General Test Set
- Demonstrates data-efficient approach for low-resource language instruction-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High-quality synthetic datasets can achieve comparable performance to large-scale human-annotated datasets when they incorporate fluency, diversity, and cultural context.
- Mechanism: The framework generates instructions that are grammatically correct (fluency), cover a wide range of topics (diversity), and are culturally aligned with the target language (cultural context), leading to improved model performance.
- Core assumption: These three properties are sufficient to capture the essential characteristics of high-quality instruction-tuning data.
- Evidence anchors:
  - [abstract] "Our best-performing synthetic dataset, which incorporates all three key properties, achieves competitive performance using only 5,000 instructions when compared to state-of-the-art Thai LLMs trained on hundreds of thousands of instructions."
  - [section] "We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity, and cultural context."
  - [corpus] Weak evidence - no direct citations in the corpus about the effectiveness of these three properties specifically for Thai.
- Break condition: If one or more of these properties is significantly degraded, model performance will drop below that of models trained on large-scale human-annotated datasets.

### Mechanism 2
- Claim: Seed-data-free synthetic data generation is feasible for low-resource languages by using an LLM to generate topics and retrieve relevant contexts.
- Mechanism: The framework uses Claude-3 Haiku to generate diverse topics, retrieve relevant contexts from Wikipedia, and create instructions for various tasks, eliminating the need for human-annotated seed data.
- Core assumption: An LLM can generate high-quality topics and instructions that are representative of the target language and culture.
- Evidence anchors:
  - [section] "We propose a seed-data-free framework for generating synthetic instruction-tuning data that incorporates these essential properties."
  - [section] "Our framework employs an LLM to generate diverse topics, retrieve relevant contexts from Wikipedia, and create instructions for various tasks, such as question answering, summarization, and conversation."
  - [corpus] Weak evidence - no direct citations in the corpus about seed-data-free approaches for low-resource languages.
- Break condition: If the LLM used for data generation is not sufficiently fluent or knowledgeable about the target language and culture, the generated data will be of poor quality.

### Mechanism 3
- Claim: Diversity control through semantic similarity filtering improves the quality of synthetic datasets by ensuring a wide range of instruction topics and contexts.
- Mechanism: The framework uses BGE-M3 embeddings and cosine similarity to filter out closely related samples, ensuring that the final dataset is diverse and covers a wide range of topics and contexts.
- Core assumption: Removing semantically similar samples leads to a more diverse dataset that improves model generalization.
- Evidence anchors:
  - [section] "To ensure that our dataset is diverse, we filter out any samples that are closely related to each other semantically."
  - [section] "If the cosine similarity of the nearest match of that sample is over 0.95, we remove that sample."
  - [corpus] Weak evidence - no direct citations in the corpus about diversity control through semantic similarity filtering.
- Break condition: If the diversity control threshold is set too high, the dataset may become too small and lack sufficient coverage of important topics and contexts.

## Foundational Learning

- Concept: Instruction-tuning
  - Why needed here: The paper focuses on improving the performance of Thai LLMs through instruction-tuning on synthetic datasets.
  - Quick check question: What is the difference between instruction-tuning and fine-tuning?

- Concept: Low-resource languages
  - Why needed here: The paper specifically addresses the challenge of developing high-performing LLMs for low-resource languages like Thai.
  - Quick check question: What are the main challenges in developing LLMs for low-resource languages compared to high-resource languages?

- Concept: Synthetic data generation
  - Why needed here: The paper proposes a framework for generating synthetic instruction-tuning data to improve the performance of Thai LLMs in a data-efficient manner.
  - Quick check question: What are the advantages and disadvantages of using synthetic data compared to human-annotated data for training LLMs?

## Architecture Onboarding

- Component map: Topic generation -> Context selection/generation -> Instruction generation -> Diversity control

- Critical path:
  1. Generate topics (general or cultural)
  2. Select or generate contexts based on topics
  3. Generate instructions for each task
  4. Apply diversity control to filter out similar samples
  5. Combine all instructions into the final dataset

- Design tradeoffs:
  - Quality vs. quantity: Generating a smaller, high-quality dataset vs. a larger, lower-quality dataset.
  - Diversity vs. coherence: Ensuring diversity while maintaining coherence and relevance to the target language and culture.
  - Cost vs. performance: Using a more expensive LLM for data generation vs. a less expensive one that may produce lower-quality data.

- Failure signatures:
  - Poor model performance: Indicates that the synthetic dataset may lack fluency, diversity, or cultural context.
  - Overfitting: Suggests that the dataset may be too small or not diverse enough.
  - High computational cost: Implies that the LLM used for data generation may be too expensive or inefficient.

- First 3 experiments:
  1. Generate a small synthetic dataset (e.g., 1,000 instructions) and evaluate its performance on a subset of the benchmark tasks.
  2. Compare the performance of models trained on synthetic datasets with different combinations of the three key properties (fluency, diversity, cultural context).
  3. Conduct an ablation study to determine the impact of each property on model performance by systematically removing or degrading each property in the synthetic dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal ratio of synthetic to human-generated data for instruction-tuning low-resource language models?
- Basis in paper: Inferred from the "Limitations" section which states the authors did not investigate the optimal combination of synthetic and human-generated data.
- Why unresolved: The paper focuses solely on synthetic data generation without comparing different ratios of synthetic vs human-generated data to determine the most effective composition strategy.
- What evidence would resolve it: Comparative experiments training models on various combinations (e.g., 100% synthetic, 75/25 synthetic/human, 50/50, 25/75, 100% human) and measuring performance across the same evaluation benchmarks.

### Open Question 2
- Question: How does the seed-data-free approach perform on languages with different linguistic properties (e.g., agglutinative vs analytic languages)?
- Basis in paper: Inferred from the "Conclusion and Future Work" section which suggests extending experiments to other low-resource languages with different linguistic properties.
- Why unresolved: The study only evaluates on Thai, so the generalizability of the seed-data-free approach to languages with significantly different morphological and syntactic structures remains unknown.
- What evidence would resolve it: Replicating the entire experimental framework on at least two typologically distinct low-resource languages (e.g., Turkish and Vietnamese) and comparing performance metrics to the Thai results.

### Open Question 3
- Question: What is the long-term performance stability of models trained with the seed-data-free approach compared to traditional fine-tuning methods?
- Basis in paper: Explicit - mentioned in the "Limitations" section which notes the lack of investigation into long-term performance stability.
- Why unresolved: The paper presents only initial performance results without longitudinal studies to assess how models trained on synthetic data maintain their performance over extended use periods.
- What evidence would resolve it: A longitudinal study tracking model performance on the same benchmarks over time (e.g., after 1 month, 3 months, 6 months of deployment) while monitoring for concept drift and degradation patterns.

### Open Question 4
- Question: How sensitive is the performance to variations in the diversity control threshold (currently set at 0.95 cosine similarity)?
- Basis in paper: Explicit - the diversity control mechanism is described with a specific threshold of 0.95 in Section 3.5.
- Why unresolved: The paper uses a fixed threshold without exploring how different similarity cutoffs affect the final dataset quality and model performance.
- What evidence would resolve it: Systematic experiments varying the cosine similarity threshold (e.g., 0.90, 0.92, 0.95, 0.97, 0.99) and measuring the impact on dataset size, diversity metrics, and downstream model performance across all tasks.

## Limitations
- Evaluation scope limited to 5,000-instruction synthetic datasets, not exploring scalability to larger datasets
- Reliance on Wikipedia as knowledge source introduces dependency on external data quality and coverage
- Does not investigate optimal ratio of synthetic to human-generated data for instruction-tuning

## Confidence
- **High Confidence**: The mechanism for synthetic data generation and the three key properties (fluency, diversity, cultural context) are clearly articulated and supported by experimental results
- **Medium Confidence**: The claim of achieving "competitive performance" compared to state-of-the-art Thai LLMs is supported by benchmark results, though limited to specific evaluation tasks
- **Low Confidence**: The assertion that the approach is truly "seed-data-free" is questionable given the reliance on Wikipedia for context retrieval

## Next Checks
1. **Scalability validation**: Test the framework with progressively larger synthetic datasets (10k, 50k, 100k instructions) to determine if the data-efficient advantage persists and identify potential performance saturation points
2. **Cross-lingual generalization**: Apply the same seed-data-free framework to another low-resource language with different cultural characteristics to assess whether the three-property approach generalizes beyond Thai
3. **Diversity control threshold sensitivity**: Systematically vary the semantic similarity threshold (0.90, 0.95, 0.98) to quantify the tradeoff between dataset size and instruction diversity, and determine optimal threshold settings for different task types