---
ver: rpa2
title: Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) --
  a Large Language Model Chatbot for Perioperative Medicine
arxiv_id: '2412.18096'
source_url: https://arxiv.org/abs/2412.18096
tags:
- peach
- page
- clinical
- accuracy
- deployment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents the development and real-world evaluation of
  PEACH, a secure LLM-based chatbot integrated with 35 institutional perioperative
  guidelines to support preoperative clinical decision-making. Using a silent deployment
  model with real-world clinical data, PEACH achieved an overall accuracy of 97.9%
  (235/240) after protocol refinements, with minimal hallucinations (0.4%) and deviations
  (0.8%).
---

# Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine

## Quick Facts
- arXiv ID: 2412.18096
- Source URL: https://arxiv.org/abs/2412.18096
- Reference count: 0
- Achieved 97.9% accuracy with minimal hallucinations (0.4%) and deviations (0.8%) in perioperative clinical decision support

## Executive Summary
PEACH is a secure LLM-based chatbot developed for perioperative medicine that integrates 35 institutional perioperative guidelines to support preoperative clinical decision-making. The system uses a silent deployment model with real-world clinical data, achieving an overall accuracy of 97.9% after protocol refinements. Clinicians reported that PEACH expedited decisions in 95% of cases, with substantial inter-rater reliability (kappa 0.772-0.893). The chatbot demonstrates strong potential as a reliable, adaptable tool for enhancing consistency and efficiency in perioperative decision-making while maintaining high safety standards.

## Method Summary
PEACH was developed using Claude 3.5 Sonnet LLM within the secure PAIR framework, with 35 institutional perioperative protocols embedded directly into the model's context window. The system was evaluated through silent deployment where clinicians performed normal duties, made their own decisions, then compared PEACH's recommendations against their clinical decisions. Accuracy, hallucination, and deviation rates were measured across 80 distinct clinical scenarios, with inter-rater reliability analysis and user acceptability surveys conducted to validate performance and usability.

## Key Results
- PEACH achieved 97.9% overall accuracy (235/240) after protocol refinements
- Minimal hallucinations (0.4%) and deviations (0.8%) were observed in clinical recommendations
- Clinicians reported PEACH expedited decisions in 95% of cases, with substantial inter-rater reliability (kappa 0.772-0.893)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PEACH achieves high accuracy by embedding entire institutional perioperative protocols directly into the LLM's context window, avoiding the retrieval overhead of RAG.
- Mechanism: The large context limits of Claude 3.5 Sonnet (45,000 words) allow structured perioperative guidelines to be fed in full, enabling the model to perform reasoning over complete, domain-specific information without chunking or retrieval step latency.
- Core assumption: The context window is large enough to hold all relevant guidelines and that the structured text can be processed efficiently end-to-end.
- Evidence anchors:
  - [abstract] "PEACH achieved an overall accuracy of 97.9% (235/240) after protocol refinements"
  - [section] "PEACH leveraged the large context limits of advanced language models to directly input structured text data into the model, rather than employing traditional RAG techniques"
- Break condition: If guidelines exceed context window or require frequent updates that exceed re-upload capacity, accuracy would degrade due to incomplete context.

### Mechanism 2
- Claim: Silent deployment with real-world clinical data ensures PEACH's recommendations are validated against actual clinical practice rather than synthetic test cases.
- Mechanism: Clinicians perform normal duties, input queries only after making decisions, and then compare PEACH's output to their own decisions, enabling retrospective accuracy assessment in operational conditions.
- Core assumption: Clinicians will faithfully follow their normal decision-making process and accurately report alignment.
- Evidence anchors:
  - [section] "They were instructed to carry out their usual clinical duties as normal... Only after finalizing their clinical decisions were they allowed to input their questions into the chatbot and access its answers"
  - [abstract] "minimal hallucinations (0.4%) and deviations (0.8%)"
- Break condition: If clinicians alter their decision-making process knowing they will later compare to PEACH, or if reporting bias occurs, the accuracy assessment becomes unreliable.

### Mechanism 3
- Claim: The secure PAIR framework ensures PEACH can safely process sensitive perioperative data without risking information leakage.
- Mechanism: PAIR provides a secure environment supporting restricted and sensitive data classifications, enabling safe storage and processing of clinical data while maintaining compliance.
- Core assumption: The PAIR framework's security controls are robust enough to prevent data exfiltration or re-identification attacks.
- Evidence anchors:
  - [section] "PAIR was developed by GovTech... It is designed to enhance productivity while ensuring strong data security. PAIR provides a secure environment for data storage and processing"
  - [abstract] "secure LLM-based system integrated with local perioperative guidelines"
- Break condition: If PAIR's security model is compromised or if data is mishandled during transfer to/from the chatbot, patient privacy violations could occur.

## Foundational Learning

- Concept: Domain-specific guideline integration
  - Why needed here: Perioperative medicine requires adherence to complex, institution-specific protocols that generic LLMs lack
  - Quick check question: What is the primary advantage of embedding 35 institutional protocols directly into PEACH rather than using RAG?

- Concept: Silent deployment methodology
  - Why needed here: Ensures real-world validation without altering clinical workflows or introducing observation bias
  - Quick check question: Why does PEACH collect queries only after clinicians have made their decisions?

- Concept: Hallucination and deviation categorization
  - Why needed here: Critical for assessing safety in medical applications where incorrect information can harm patients
  - Quick check question: How are hallucinations distinguished from deviations in PEACH's evaluation framework?

## Architecture Onboarding

- Component map: User query → Secure PAIR environment → LLM with embedded guidelines → Response generation → Clinical decision comparison

- Critical path: User query → Secure PAIR environment → LLM with embedded guidelines → Response generation → Clinical decision comparison

- Design tradeoffs:
  - Full guideline embedding vs. RAG: Higher accuracy but requires guideline updates to re-upload entire context
  - Silent deployment vs. active piloting: More realistic validation but slower data collection
  - Secure environment vs. cloud deployment: Better privacy but potentially higher infrastructure costs

- Failure signatures:
  - Accuracy drops below threshold: Check if guidelines were updated correctly in PAIR
  - Increased hallucinations: Verify prompt engineering hasn't degraded
  - Security alerts: Investigate data handling in PAIR environment

- First 3 experiments:
  1. Load a subset of guidelines into PAIR and measure response accuracy on controlled test cases
  2. Conduct a small-scale silent deployment with 10-20 queries to validate workflow
  3. Test security boundaries by attempting to extract sensitive information from responses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can PEACH be adapted to integrate diverse institutional guidelines while maintaining accuracy across different healthcare systems?
- Basis in paper: [explicit] The study acknowledges that protocols embedded in PEACH were specific to a single tertiary hospital, and findings may not be fully generalizable across institutions with varying guidelines and practices.
- Why unresolved: The current deployment only tested PEACH within one hospital's framework, leaving its performance in other settings unexplored.
- What evidence would resolve it: Comparative studies deploying PEACH in multiple hospitals with different protocols, measuring accuracy, safety, and user satisfaction across settings.

### Open Question 2
- Question: What is the impact of PEACH on clinical outcomes and patient safety in perioperative settings?
- Basis in paper: [inferred] The study focused on accuracy, safety (minimal hallucinations and deviations), and usability but did not investigate broader clinical outcomes such as reduced cancellations, improved patient recovery, or overall safety metrics.
- Why unresolved: The evaluation was limited to accuracy and user feedback, without tracking downstream effects on patient care or operational metrics.
- What evidence would resolve it: Longitudinal studies measuring clinical outcomes, patient safety incidents, and operational efficiency (e.g., reduced cancellations or improved recovery times) after PEACH implementation.

### Open Question 3
- Question: How does PEACH's performance compare to traditional clinical decision support systems in terms of reliability and user trust?
- Basis in paper: [explicit] The study highlights PEACH's high accuracy and user acceptance but does not compare its performance or trustworthiness to existing clinical decision support tools.
- Why unresolved: The evaluation was limited to PEACH's standalone performance without benchmarking against other systems.
- What evidence would resolve it: Head-to-head comparisons of PEACH with traditional decision support systems, assessing reliability, user trust, and clinical impact in perioperative settings.

## Limitations
- Evaluation conducted at single institution with specific protocols, limiting generalizability across different healthcare systems
- Sample size of 80 clinical scenarios may not capture full diversity of perioperative decision-making scenarios
- Long-term sustainability and update frequency for institutional guidelines not addressed

## Confidence

**High Confidence**: The overall accuracy metrics (97.9%) and hallucination/deviation rates (0.4%/0.8%) are well-supported by the described methodology and multiple validation approaches including inter-rater reliability analysis (kappa 0.772-0.893).

**Medium Confidence**: The claim that PEACH expedites clinical decision-making in 95% of cases is supported by user acceptability data but relies on subjective clinician assessment rather than objective time measurements.

**Low Confidence**: The scalability assertion that PEACH can be readily adapted to other clinical contexts is based on theoretical design principles rather than empirical testing in different medical domains or institutions.

## Next Checks
1. **External Validation Study**: Deploy PEACH at multiple healthcare institutions with different perioperative protocols to assess whether the 97.9% accuracy rate generalizes across different clinical contexts and guideline structures.

2. **Long-term Performance Monitoring**: Implement continuous monitoring over 6-12 months to evaluate how accuracy and hallucination rates change as institutional guidelines are updated and as clinicians become more familiar with the system.

3. **Comparative Time Efficiency Analysis**: Conduct controlled studies measuring actual decision-making time with and without PEACH to objectively validate the subjective claim that it expedites clinical decisions in 95% of cases.