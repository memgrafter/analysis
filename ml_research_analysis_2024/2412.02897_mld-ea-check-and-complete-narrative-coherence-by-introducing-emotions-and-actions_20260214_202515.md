---
ver: rpa2
title: 'MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and
  Actions'
arxiv_id: '2412.02897'
source_url: https://arxiv.org/abs/2412.02897
tags:
- sentence
- actions
- emotions
- story
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "MLD-EA leverages large language models to identify logical gaps\
  \ in narratives by modeling the interaction between characters\u2019 emotions and\
  \ actions, grounding its approach in cognitive-behavioral theories. The model first\
  \ abstracts actions and classifies emotions for each character in a story, then\
  \ detects where narrative coherence breaks down, and finally predicts and generates\
  \ the missing sentence."
---

# MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions

## Quick Facts
- arXiv ID: 2412.02897
- Source URL: https://arxiv.org/abs/2412.02897
- Reference count: 22
- One-line primary result: MLD-EA leverages large language models to identify logical gaps in narratives by modeling the interaction between characters’ emotions and actions, grounding its approach in cognitive-behavioral theories.

## Executive Summary
MLD-EA introduces a novel framework for improving narrative coherence by integrating character emotions and actions. It detects and repairs logical gaps in stories by leveraging large language models and cognitive-behavioral theory. The method shows significant improvements over baseline approaches in both detecting coherence breaks and generating missing narrative content.

## Method Summary
The MLD-EA model abstracts actions and classifies emotions for each character in a story, then detects where narrative coherence breaks down, and finally predicts and generates the missing sentence. It uses a graph-based representation to model emotion-action dynamics and employs LLMs for inference and generation tasks.

## Key Results
- F1 scores for logic detection improved from ~22% to ~76%
- BLEU scores for sentence generation increased from ~33 to ~44
- Outperforms baselines in both logic detection and sentence generation tasks

## Why This Works (Mechanism)
MLD-EA works by modeling the interaction between characters' emotions and actions using a graph-based representation. By grounding this approach in cognitive-behavioral theories, the model can better understand the logical dependencies in narratives. The LLM backbone enables sophisticated reasoning about these dependencies and generation of coherent missing content.

## Foundational Learning
1. **Emotion-Action Dynamics** - Why needed: Core to understanding narrative coherence; Quick check: Can identify logical gaps based on inconsistent character behavior.
2. **Graph-Based Story Representation** - Why needed: Enables modeling of complex character relationships; Quick check: Can trace action-emotion chains through the narrative.
3. **LLM-Based Inference** - Why needed: Provides sophisticated reasoning capabilities; Quick check: Can generate contextually appropriate missing sentences.
4. **Cognitive-Behavioral Theory** - Why needed: Grounds the approach in established psychological principles; Quick check: Aligns with human understanding of narrative logic.

## Architecture Onboarding

Component Map: Character Emotion/Action Abstraction -> Graph Construction -> Logic Detection -> Missing Sentence Generation

Critical Path: Emotion/Action extraction → Graph representation → Logic gap identification → Sentence generation → Evaluation

Design Tradeoffs: Uses proprietary dataset for evaluation (limiting reproducibility) but achieves strong results; balances complexity of graph modeling with practical generation capabilities.

Failure Signatures: May struggle with subtle coherence issues; potential bias from LLM-based evaluations; scalability concerns for longer narratives.

First Experiments:
1. Validate logic detection on publicly available datasets
2. Compare generated sentences with human-written alternatives
3. Test scalability on progressively longer narrative sequences

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Reliance on proprietary, unreleased dataset limits reproducibility
- Evaluation primarily focuses on synthetic coherence breaks
- Generated sentences may not match original narrative voice and style

## Confidence

**High Confidence:** The experimental results demonstrate clear improvements over baselines in controlled settings.

**Medium Confidence:** The generalizability of the method to real-world narratives and its scalability to longer texts.

**Low Confidence:** The robustness of the approach to subtle or nuanced coherence issues and the absence of bias in LLM-based evaluations.

## Next Checks

1. Replicate the experiments on publicly available datasets to assess generalizability and reproducibility.
2. Conduct human evaluations to verify the contextual and stylistic coherence of generated sentences, as well as to detect potential LLM bias.
3. Test the scalability of the method on longer, more complex narratives to evaluate its practical applicability.