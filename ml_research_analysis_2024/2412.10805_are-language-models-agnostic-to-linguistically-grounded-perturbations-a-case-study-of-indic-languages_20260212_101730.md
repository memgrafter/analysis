---
ver: rpa2
title: Are Language Models Agnostic to Linguistically Grounded Perturbations? A Case
  Study of Indic Languages
arxiv_id: '2412.10805'
source_url: https://arxiv.org/abs/2412.10805
tags:
- phono
- ortho
- rand
- language
- perturbations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the robustness of pre-trained language
  models (PLMs) to linguistically grounded perturbations, focusing on Indic languages
  across Indo-Aryan and Dravidian families. Using character-level perturbations grounded
  in phonology and orthography, the authors assess how effectively these subtle linguistic
  changes can deceive language models on sentiment analysis, paraphrasing, and natural
  language inference tasks.
---

# Are Language Models Agnostic to Linguistically Grounded Perturbations? A Case Study of Indic Languages

## Quick Facts
- arXiv ID: 2412.10805
- Source URL: https://arxiv.org/abs/2412.10805
- Reference count: 40
- Primary result: PLMs show slightly lower vulnerability to linguistically grounded perturbations compared to random perturbations across Indic languages

## Executive Summary
This study investigates how pre-trained language models (PLMs) respond to linguistically grounded perturbations in Indic languages. The authors systematically introduce character-level perturbations based on phonology and orthography to test model robustness across sentiment analysis, paraphrasing, and natural language inference tasks. Results reveal that while PLMs are susceptible to these linguistic attacks, they demonstrate slightly better resilience compared to non-linguistic random perturbations. The study highlights language-specific patterns, with Dravidian languages showing greater robustness than Indo-Aryan languages, and identifies IndicBERTv2 as consistently superior in handling such perturbations.

## Method Summary
The authors developed a perturbation framework grounded in linguistic principles, applying character-level transformations based on phonological and orthographic rules for nine Indic languages. They evaluated three pre-trained language models (IndicBERTv2, Muril, and XLMR) on three NLP tasks using both perturbed and unperturbed datasets. The perturbations included vowel modifications, consonant substitutions, and orthographic changes specific to each language family. Model performance was measured using accuracy and F1 scores to quantify robustness against these linguistic attacks, with results compared against randomly generated perturbations to establish the effectiveness of linguistically motivated attacks.

## Key Results
- PLMs are susceptible to linguistically grounded perturbations but show slightly lower vulnerability compared to random perturbations
- Dravidian languages demonstrate greater robustness to perturbations than Indo-Aryan languages
- IndicBERTv2 consistently outperforms Muril and XLMR across tasks and language families in both performance and robustness

## Why This Works (Mechanism)
The study demonstrates that language models can be deceived by subtle linguistic changes that preserve semantic content while altering surface form. These perturbations work by exploiting the models' reliance on character-level patterns and their learned associations between orthographic forms and linguistic meanings. The effectiveness of linguistically grounded perturbations versus random ones suggests that PLMs have learned some language-specific patterns but remain vulnerable to systematic manipulations that follow natural language rules.

## Foundational Learning
- **Linguistic perturbation theory**: Understanding how systematic character changes affect language understanding - needed to design effective attacks that are both meaningful and challenging for models
- **Character-level processing in PLMs**: Knowledge of how models handle subword and character information - needed to understand model vulnerabilities at the character level
- **Indic language typology**: Familiarity with Indo-Aryan and Dravidian language families - needed to design language-specific perturbations that respect phonological and orthographic constraints
- **Cross-lingual transfer learning**: Understanding how multilingual models handle different languages - needed to interpret performance differences across language families
- **Adversarial robustness evaluation**: Methods for assessing model vulnerability to input manipulations - needed to measure and compare perturbation effectiveness

## Architecture Onboarding

**Component Map**: Input text -> Perturbation engine -> Task-specific PLM -> Performance metrics

**Critical Path**: The perturbation engine applies linguistically motivated character transformations, which are then processed by the PLM for downstream tasks. Performance degradation is measured to assess robustness.

**Design Tradeoffs**: The study prioritizes linguistic validity over attack strength, using constrained perturbations that preserve meaning rather than arbitrary character changes that would make tasks trivially difficult.

**Failure Signatures**: Performance drops when perturbations violate learned character patterns, with greater degradation for languages with more complex orthographic systems or when perturbations cross morpheme boundaries.

**First 3 Experiments to Run**:
1. Apply perturbations to a small sample text and manually verify linguistic validity
2. Test unperturbed model performance to establish baselines
3. Compare performance on perturbed vs. unperturbed versions of the same text

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to three task types and nine languages, which may not generalize to other NLP tasks or language families
- Perturbation methodology relies on relatively simple character-level transformations that may not capture complex linguistic phenomena
- Study does not explore temporal stability or whether models can be fine-tuned to become more robust to these specific perturbations

## Confidence
- Model vulnerability to linguistic vs. random perturbations (Medium): Results show subtle differences that may not hold across different perturbation types
- Dravidian vs. Indo-Aryan robustness patterns (Medium): Interesting patterns based on limited language samples
- IndicBERTv2 superiority (High): Consistently supported across tasks and languages

## Next Checks
1. Test whether adversarial training on the proposed perturbations improves model robustness across all evaluated tasks and languages
2. Extend the perturbation methodology to include morphological and syntactic transformations to assess if results hold for higher-level linguistic phenomena
3. Evaluate model robustness on a broader set of tasks (e.g., named entity recognition, machine translation) to test generalizability of findings