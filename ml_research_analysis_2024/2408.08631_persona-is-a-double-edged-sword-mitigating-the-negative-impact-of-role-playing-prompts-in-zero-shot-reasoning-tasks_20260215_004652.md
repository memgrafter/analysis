---
ver: rpa2
title: 'Persona is a Double-edged Sword: Mitigating the Negative Impact of Role-playing
  Prompts in Zero-shot Reasoning Tasks'
arxiv_id: '2408.08631'
source_url: https://arxiv.org/abs/2408.08631
tags:
- persona
- answer
- jekyll
- hyde
- solver
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how role-playing prompts affect LLM reasoning,
  finding they can both help and hinder performance. It introduces Jekyll & Hyde,
  a framework that generates two solutions (with and without persona) and uses an
  LLM evaluator to select the better one, mitigating position bias.
---

# Persona is a Double-edged Sword: Mitigating the Negative Impact of Role-playing Prompts in Zero-shot Reasoning Tasks

## Quick Facts
- arXiv ID: 2408.08631
- Source URL: https://arxiv.org/abs/2408.08631
- Reference count: 18
- The paper introduces Jekyll & Hyde, a framework that ensembles persona and neutral prompts to improve LLM reasoning performance while mitigating position bias in evaluation.

## Executive Summary
This paper investigates how role-playing prompts affect LLM reasoning performance, finding they can both enhance and degrade results depending on task alignment. The authors introduce Jekyll & Hyde, a framework that generates two solutions (with and without persona) and uses an LLM evaluator to select the better one. By mitigating position bias in the evaluator and using the same LLM for persona generation and solving, Jekyll & Hyde consistently outperforms using only persona or neutral prompts across 12 reasoning datasets.

## Method Summary
Jekyll & Hyde is a framework that improves LLM reasoning by generating two solutions—one with a persona-generated prompt and one with a neutral prompt—then using an LLM evaluator to select the better answer. The framework includes a Persona Generator that creates occupation-based personas from questions, parallel Persona and Neutral Solvers, and an Evaluator that mitigates position bias by running twice with reversed solution order. The same LLM is used for both persona generation and solving to improve stability.

## Key Results
- Jekyll & Hyde outperforms using only persona or neutral prompts across 12 reasoning datasets
- The framework shows consistent performance gains regardless of model type (GPT-4, GPT-3.5-turbo, llama3-8B)
- Position bias mitigation in the evaluator is more effective than prior approaches like Portia and MEC+BPC
- Using the same LLM for persona generation and solving improves performance compared to handcrafted personas

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Role-playing prompts can both enhance and degrade LLM reasoning performance depending on task alignment
- Mechanism: Persona assignment activates domain-specific knowledge but can introduce bias when the persona is misaligned with the task requirements
- Core assumption: LLMs have internal representations that can be triggered by persona prompts, and these representations can either help or hinder depending on the task
- Evidence anchors:
  - [abstract] "assigning a proper persona is difficult since an LLM's performance is extremely sensitive to assigned prompts; therefore, personas sometimes hinder LLMs and degrade their reasoning capabilities"
  - [section 1] "persona prompting can sometimes confuse LLMs...thereby, LLMs provide incorrect solutions to reasoning problems"
  - [corpus] Weak evidence - corpus shows related papers discussing double-edged effects but no direct mechanism evidence
- Break condition: When persona is completely misaligned with task domain or when task requires neutral perspective

### Mechanism 2
- Claim: Jekyll & Hyde framework improves performance by ensembling solutions from persona and neutral perspectives
- Mechanism: Dual execution of persona and neutral solvers provides complementary perspectives, allowing the evaluator to select the better solution
- Core assumption: The two different perspectives will produce different quality outputs for different types of problems
- Evidence anchors:
  - [abstract] "Jekyll & Hyde predicts an appropriate persona using an LLM when defining the role-playing prompt...selects a better solution using the LLM evaluator"
  - [section 3.2] "This dual execution approach provides two different perspectives on solving the question and derives two discriminative responses"
  - [section 4.2] "performance has increased in most datasets, regardless of the model type"
- Break condition: When both persona and neutral solvers produce incorrect answers of similar quality

### Mechanism 3
- Claim: Position bias in LLM evaluators can be mitigated by alternating solution order in evaluation prompts
- Mechanism: Running evaluator twice with reversed solution order and comparing verdicts reduces the effect of solution position on evaluation outcome
- Core assumption: LLMs exhibit position bias that can be averaged out by multiple evaluations with different orders
- Evidence anchors:
  - [abstract] "LLM evaluators tend to be affected by the order of those potential solutions within the prompt when selecting the proper solution"
  - [section 3.4] "we run the Evaluator model twice by inserting the solutions into the evaluation prompt and reversing the order of the solutions"
  - [section 4.5] "we reveal that the evaluator within Jekyll & Hyde derives the best performance among the other methods from most datasets"
- Break condition: When evaluator verdicts differ across all allowed attempts, indicating persistent position bias

## Foundational Learning

- Concept: Zero-shot reasoning with LLMs
  - Why needed here: The paper operates entirely in zero-shot setting without fine-tuning
  - Quick check question: What is the difference between zero-shot and few-shot prompting for LLMs?

- Concept: Position bias in LLM evaluation
  - Why needed here: The framework explicitly addresses position bias in its evaluator design
  - Quick check question: How might the order of inputs in an LLM prompt affect its output?

- Concept: Role-playing prompting and persona effects
  - Why needed here: The paper's core investigation centers on how persona assignment affects LLM performance
  - Quick check question: What mechanisms might explain why assigning a persona could both help and hurt LLM performance?

## Architecture Onboarding

- Component map: Persona Generator → Persona Solver & Neutral Solver (parallel) → LLM Evaluator (with position bias mitigation) → Final Output
- Critical path: Question → Persona Generator → Both Solvers → Evaluator → Final Answer
- Design tradeoffs: Dual execution increases computation cost but improves accuracy; position bias mitigation adds complexity but reduces evaluator bias
- Failure signatures: When both solvers produce incorrect answers; when evaluator cannot reach consistent verdict within max attempts
- First 3 experiments:
  1. Test baseline performance with only Neutral Solver on a small dataset
  2. Test performance with only Persona Solver on the same dataset
  3. Test Jekyll & Hyde framework on the same dataset and compare results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Jekyll & Hyde scale with larger language models (e.g., beyond GPT-4)?
- Basis in paper: [inferred] The paper tests Jekyll & Hyde with GPT-4, GPT-3.5-turbo, and llama3, but doesn't explore larger models or the scaling limits of the framework.
- Why unresolved: The study focuses on three specific models and doesn't investigate the performance ceiling or how the framework might benefit from even larger models.
- What evidence would resolve it: Experiments testing Jekyll & Hyde with larger models (e.g., GPT-5, Claude 3, etc.) and analyzing performance improvements or limitations as model size increases.

### Open Question 2
- Question: Can Jekyll & Hyde be effectively adapted for non-reasoning tasks like text generation or summarization?
- Basis in paper: [explicit] The paper focuses solely on reasoning tasks and explicitly mentions limitations for non-reasoning applications.
- Why unresolved: The framework is specifically designed for reasoning, and its effectiveness on other NLP tasks remains unexplored.
- What evidence would resolve it: Applying Jekyll & Hyde to text generation, summarization, or other NLP tasks and measuring performance compared to standard approaches.

### Open Question 3
- Question: How does the choice of persona generation method affect long-term performance and adaptability of the model?
- Basis in paper: [explicit] The paper shows that LLM-generated personas are more stable than handcrafted ones, but doesn't explore the long-term effects of different persona generation strategies.
- Why unresolved: While the paper demonstrates short-term benefits of LLM-generated personas, it doesn't investigate how different persona generation methods might impact the model's adaptability or performance over time.
- What evidence would resolve it: Longitudinal studies comparing different persona generation methods and their effects on model performance across various tasks and time periods.

## Limitations
- The framework requires increased computational resources due to dual execution of solvers
- Exact prompt templates for key components are not fully specified, limiting exact replication
- Performance gains may not generalize to non-reasoning tasks or domains outside the tested 12 datasets

## Confidence
- **High Confidence**: The dual execution framework design and its general effectiveness in improving performance across multiple datasets and model types
- **Medium Confidence**: The specific effectiveness of position bias mitigation, as this relies on assumptions about evaluator behavior that may vary across different LLM implementations
- **Low Confidence**: The generalizability of findings to tasks outside the tested reasoning domains

## Next Checks
1. **Prompt Template Verification**: Reconstruct and test the exact prompt templates for Persona Generator and Evaluator components using the paper's descriptions and supplementary materials to verify they produce consistent results.

2. **Failure Mode Analysis**: Systematically test scenarios where both persona and neutral solvers produce incorrect answers to determine how often Jekyll & Hyde selects the wrong answer and identify conditions that lead to evaluator failure.

3. **Open-source Model Scalability**: Evaluate Jekyll & Hyde performance using only open-source models (e.g., llama3-8B for all components) to assess whether the framework's benefits extend beyond proprietary models like GPT-4.