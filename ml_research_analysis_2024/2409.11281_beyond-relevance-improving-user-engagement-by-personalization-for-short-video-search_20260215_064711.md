---
ver: rpa2
title: 'Beyond Relevance: Improving User Engagement by Personalization for Short-Video
  Search'
arxiv_id: '2409.11281'
source_url: https://arxiv.org/abs/2409.11281
tags:
- search
- user
- video
- retrieval
- ranking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Personalized search is increasingly popular in various applications
  but less studied in short-video search. This work proposes PR2, a comprehensive
  solution for personalizing short-video search.
---

# Beyond Relevance: Improving User Engagement by Personalization for Short-Video Search

## Quick Facts
- arXiv ID: 2409.11281
- Source URL: https://arxiv.org/abs/2409.11281
- Reference count: 40
- Primary result: PR2 improves user engagement with 10.2% increase in CTR@10, 20% surge in video watch time, and 1.6% uplift in search DAU.

## Executive Summary
This paper presents PR2, a comprehensive solution for personalizing short-video search that goes beyond traditional relevance ranking to improve user engagement. The system combines query-relevant collaborative filtering, personalized dense retrieval, and a query-dominant interest network to extract individually tailored content from large-scale video corpora. Deployed in a production system, PR2 achieved the most significant user engagement improvements in recent years, demonstrating substantial gains in click-through rates, watch time, and daily active users.

## Method Summary
PR2 addresses short-video search personalization through a three-stage pipeline: personalized retrieval (combining query-relevant collaborative filtering and personalized dense retrieval) and personalized ranking (using a query-dominant interest network). The system leverages user profiles and behaviors to retrieve and rank videos that are both relevant to the query and tailored to individual preferences. It employs multi-task learning to predict various user engagement signals including clicks, plays, and likes, optimizing for multiple engagement metrics simultaneously.

## Key Results
- 10.2% increase in CTR@10 compared to baseline systems
- 20% surge in video watch time per query
- 1.6% uplift in search daily active users (DAU)
- Most significant user engagement improvements in recent years for the production system

## Why This Works (Mechanism)

### Mechanism 1: Query-Relevant Collaborative Filtering (QRCF)
QRCF improves retrieval relevance by filtering user behaviors through query embedding similarity. It uses a multi-modal embedding model to project queries and videos into the same semantic space, then selects user behaviors whose video embeddings are top-K similar to the query embedding and exceed a relevance threshold. These filtered behaviors are used to retrieve similar videos via item-to-item similarity, ensuring that only behaviors relevant to the current query contribute to retrieval.

### Mechanism 2: Personalized Dense Retrieval (PDR)
PDR leverages user profiles and behaviors to retrieve content tailored to individual users. Using a dual-encoder architecture, the query-user encoder incorporates user profiles and behavior representations (weighted by query attention) to learn embeddings for both queries and videos. The model optimizes for both relevance and user feedback through a multi-objective loss, enabling personalized retrieval that goes beyond semantic similarity to capture individual preferences.

### Mechanism 3: Query-Dominant Interest Network (QIN)
QIN improves ranking by modeling both long-term and real-time user behaviors and optimizing for multiple engagement signals. It processes long-term behaviors via General and Exact Search Units with query and video filtering, and real-time behaviors via self-attention and target attention. Using an MMOE architecture, it predicts multiple labels (clicks, plays, likes) and fuses them into calibrated ranking scores, effectively harnessing rich user behavior signals across different time horizons.

## Foundational Learning

- **Query-video relevance filtering using embedding similarity**
  - Why needed here: To select only those user behaviors that are semantically related to the current query before applying collaborative filtering
  - Quick check question: How does the system determine which of a user's past video watches are relevant to the current query?

- **Multi-objective learning with sampled softmax and hard negatives**
  - Why needed here: To jointly optimize for relevance and multiple engagement signals in the dense retrieval stage
  - Quick check question: What are the two types of negative samples used in PDR's loss function?

- **Behavior modeling with attention mechanisms (GSU/ESU and real-time attention)**
  - Why needed here: To extract meaningful user interest representations from both long-term and short-term behaviors for ranking
  - Quick check question: How does the GSU filter relevant behaviors differently from the ESU?

## Architecture Onboarding

- **Component map**: Query & User Processing ‚Üí Personalized Retrieval (QRCF + PDR) ‚Üí Personalized Ranking (QIN) ‚Üí Output
- **Critical path**: Query ‚Üí Personalized Retrieval ‚Üí Personalized Ranking ‚Üí Output
- **Design tradeoffs**:
  - QRCF vs. PDR: QRCF is efficient but relies on historical co-occurrence; PDR generalizes but needs more compute
  - GSU vs. ESU: GSU is coarse filtering; ESU is fine-grained attention
  - Multi-task: More labels improve engagement prediction but risk overfitting or calibration issues
- **Failure signatures**:
  - QRCF: Low recall, irrelevant results if threshold ùúñ is too high or K too low
  - PDR: Cold-start for new queries/users, if embeddings poorly aligned
  - QIN: Overfitting to engagement signals, if behavior sequences are too short or noisy
- **First 3 experiments**:
  1. Offline: Compare CTR and Watch Time of QRCF+PDR vs. BM25+DR on sampled logs
  2. Offline: Ablation test QIN components (remove GSU, ESU, or real-time attention) and measure ranking metrics
  3. Online: A/B test integration of QRCF+PDR vs. base retrieval, then QIN vs. base ranking

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we optimize the balance between relevance and diversity when selecting relevant user behaviors in the Query-Relevant Collaborative Filtering (QRCF) module?
- Basis in paper: [explicit] The paper mentions that "ùúñ is a relevance threshold that strikes a balance between the retrieval‚Äôs relevance and diversity. Higher ùúñ leads to fewer but more relevant behaviors left."
- Why unresolved: The paper does not provide a detailed methodology for optimizing this balance or discuss the trade-offs involved.
- What evidence would resolve it: A systematic study comparing different relevance thresholds and their impact on retrieval performance and user engagement would provide insights into the optimal balance.

### Open Question 2
- Question: How does the integration of personalized retrieval and ranking methods affect long-term user retention beyond the immediate increase in engagement metrics?
- Basis in paper: [explicit] The paper reports a 1.6% uplift in search DAU, indicating an improvement in long-term user retention.
- Why unresolved: The paper does not explore the long-term effects on user retention beyond the initial uplift, nor does it discuss potential diminishing returns over time.
- What evidence would resolve it: Longitudinal studies tracking user engagement and retention over an extended period after the implementation of personalized retrieval and ranking would provide insights into long-term effects.

### Open Question 3
- Question: What are the computational costs and scalability challenges associated with implementing personalized dense retrieval (PDR) in large-scale short-video search systems?
- Basis in paper: [inferred] The paper mentions that PDR involves encoding user and query information into embeddings and leveraging dense retrieval methods, which implies computational overhead.
- Why unresolved: The paper does not discuss the computational costs or scalability challenges of implementing PDR, nor does it provide insights into how these challenges are addressed in practice.
- What evidence would resolve it: A detailed analysis of the computational resources required for PDR, including processing time and memory usage, as well as strategies for optimizing scalability, would provide insights into the practical challenges of implementing PDR.

## Limitations

- The paper lacks detailed implementation specifics for the multi-modal embedding model used in QRCF and PDR, which are critical for reproducing the personalization components.
- Hyper-parameter values and training configurations are partially specified, with several key values not provided.
- The evaluation primarily focuses on online A/B test results without extensive offline validation or ablation studies to isolate the contribution of individual components.
- The scalability and efficiency of the proposed approach in different operational contexts (e.g., smaller datasets, different video platforms) is not addressed.

## Confidence

- **High Confidence**: The overall system architecture and the general approach of combining personalized retrieval with personalized ranking using multi-task learning are well-supported by the presented evidence and align with established IR practices.
- **Medium Confidence**: The specific mechanisms of QRCF (query-relevant collaborative filtering) and PDR (personalized dense retrieval) are plausible given the described methodology, but lack sufficient detail for full verification.
- **Low Confidence**: The exact implementation details of the QIN ranking model, particularly the behavior modeling modules (GSU/ESU) and the multi-task learning framework, are not sufficiently detailed to assess their effectiveness independently.

## Next Checks

1. **Offline Evaluation**: Conduct comprehensive offline evaluations comparing the performance of PR2 components (QRCF, PDR, QIN) against baseline methods using standard IR metrics (NDCG, MAP, Recall) on a held-out dataset.
2. **Ablation Studies**: Perform ablation studies to quantify the individual contributions of QRCF, PDR, and QIN to the overall system performance, isolating the impact of each component.
3. **Reproducibility Check**: Attempt to reproduce the core components of PR2 (QRCF and PDR) using publicly available datasets and tools, focusing on the multi-modal embedding alignment and personalized dense retrieval mechanisms.