---
ver: rpa2
title: Knowledge Graph Assisted Automatic Sports News Writing
arxiv_id: '2402.11191'
source_url: https://arxiv.org/abs/2402.11191
tags:
- news
- knowledge
- team
- graph
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a method for automatically generating sports
  news by extracting key events from live broadcasts and refining the draft with a
  domain-specific sports knowledge graph. The knowledge graph contains 5,893 entities
  (teams, players, matches), 4 relationship types, and 27 attributes.
---

# Knowledge Graph Assisted Automatic Sports News Writing

## Quick Facts
- arXiv ID: 2402.11191
- Source URL: https://arxiv.org/abs/2402.11191
- Reference count: 0
- One-line primary result: Automatic sports news generation improved by integrating a domain-specific knowledge graph with key event extraction and template-based drafting

## Executive Summary
This paper presents a method for automatically generating sports news by extracting key events from live broadcasts and refining drafts with a domain-specific sports knowledge graph. The system segments games using key time points, extracts key events, and applies templates to generate news drafts. It then enriches these drafts using background knowledge from the knowledge graph, which contains 5,893 entities, 4 relationship types, and 27 attributes. Subjective evaluations (20 participants) and automatic ROUGE metrics on 50 games show that combining the knowledge graph significantly improves news quality, especially in clarity and information richness, compared to baseline CNN-based methods.

## Method Summary
The method involves segmenting basketball games into logical narrative units using key time points based on score difference fluctuations. Key events are extracted from live broadcast text, and initial drafts are generated using predefined templates. The system then queries a domain-specific sports knowledge graph to enrich the draft with relevant background information about teams, players, and matches. A few-shot knowledge graph completion model based on meta-learning is used to address incomplete triples. The final output is an automatically generated sports news article with interactive visualization of background knowledge.

## Key Results
- Combining the knowledge graph significantly improves news quality compared to CNN-based baselines
- ROUGE metrics and subjective evaluations show improvements in clarity and information richness
- The system generates news with interactive visualization of background knowledge
- 50 games were used for evaluation with 20 participants in subjective assessment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system segments games into logical narrative units using key time points, enabling coherent story generation.
- Mechanism: Score difference fluctuations are analyzed to identify turning points (max/min differences). The game is split into 1-3 segments based on whether the score difference exceeds a threshold of 8 points and the timing of these key points.
- Core assumption: Score difference dynamics accurately reflect narrative interest and game progression.
- Evidence anchors:
  - [abstract] "This draft is further refined by incorporating key details and background information from a specially designed sports knowledge graph."
  - [section] "In order to obtain the development process and trend of news audience's interest in an event, it is necessary to further analyze the frequency and amplitude of the difference fluctuation..."
  - [corpus] Weak: No direct mention of narrative segmentation or key time points in corpus neighbors.
- Break condition: If score differences do not correlate with narrative interest (e.g., constant close scores with no clear turning points).

### Mechanism 2
- Claim: The knowledge graph enriches the initial template-generated draft with structured background information, improving clarity and information richness.
- Mechanism: Extracted key events are used to generate a first draft via templates. This draft is then augmented by querying the sports knowledge graph for player/team attributes and relationships, which are inserted as contextual details.
- Core assumption: Domain-specific knowledge graph entries are relevant and accurate enough to enhance news quality.
- Evidence anchors:
  - [abstract] "This graph contains 5,893 entities, which are classified into three distinct conceptual categories, interconnected through four relationship types..."
  - [section] "The knowledge map of matches constructed in this paper belongs to a specific domain knowledge map, in which the entity class is defined as three important concepts in basketball matches..."
  - [corpus] Weak: Corpus neighbors focus on AI-assisted writing but do not discuss knowledge graph integration.
- Break condition: If knowledge graph entries are outdated, irrelevant, or incorrectly linked to events.

### Mechanism 3
- Claim: The multi-stage learning model combining CNNs and a transformer encoder addresses few-shot knowledge graph completion by effectively modeling entity-task interactions.
- Mechanism: Relational meta-learner uses CNN to capture entity-pair interactions; transformer encoder enriches query set representations; matching processor computes similarity scores for incomplete triples.
- Core assumption: Small sample learning techniques can generalize to new entity-relation pairs in the sports domain.
- Evidence anchors:
  - [abstract] "We create a multi-stage learning model by combining convolutional neural networks and a transformer encoder... addressing few-shot knowledge graph completion problem."
  - [section] "Meta-TKGC consists of a relational meta-learner, a Transformer encoder... to compute matching scores for incomplete triples..."
  - [corpus] Weak: No corpus neighbor discusses few-shot knowledge graph completion.
- Break condition: If limited training data fails to capture meaningful patterns in entity-task relationships.

## Foundational Learning

- Concept: Knowledge Graph Construction and Entity-Relation Modeling
  - Why needed here: The system relies on a custom sports knowledge graph with defined entities (teams, players, matches), relationships, and attributes to enrich news content.
  - Quick check question: Can you list the three entity types and four relationship types used in the sports knowledge graph?

- Concept: Template-Based Text Generation with Dynamic Content Insertion
  - Why needed here: Initial drafts are generated using predefined templates for key events and game trends, later enriched with dynamic KG data.
  - Quick check question: How does the system decide which template to use for a given game segment?

- Concept: Few-Shot Learning for Knowledge Graph Completion
  - Why needed here: The system must handle incomplete triples (e.g., missing tail entities) with limited training examples per relation type.
  - Quick check question: What role does the transformer encoder play in the few-shot KG completion pipeline?

## Architecture Onboarding

- Component map:
  Data Crawler -> Preprocessing -> Key Event Extraction (KEE) -> Template-Based Draft Generation -> Knowledge Graph Query -> Draft Enrichment -> Visualization Module
  Meta-TKGC Model: Relational Meta-Learner (CNN) -> Transformer Encoder -> Matching Processor

- Critical path:
  1. Extract key events from live broadcast text.
  2. Generate initial draft using templates.
  3. Query KG for relevant background info.
  4. Enrich draft and present with interactive visualizations.

- Design tradeoffs:
  - Template-based generation vs. full neural generation: Templates ensure consistency and control but may lack creativity.
  - Domain-specific KG vs. generic KG: Higher relevance and depth but requires manual construction.
  - Few-shot KG completion vs. full supervision: Reduces data needs but may sacrifice accuracy.

- Failure signatures:
  - Poor narrative segmentation -> disjointed news articles.
  - Incorrect KG queries -> irrelevant or misleading background info.
  - Template rigidity -> repetitive or unnatural phrasing.
  - Few-shot model failure -> inaccurate KG completions.

- First 3 experiments:
  1. Test key event extraction accuracy on a small sample of live broadcasts with ground-truth event labels.
  2. Evaluate template generation quality by comparing generated drafts to manually written baselines.
  3. Measure KG enrichment impact by A/B testing news quality with/without KG integration.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the system perform in languages other than Chinese, given that the evaluation was conducted only on Chinese news data?
- Basis in paper: [inferred] The paper evaluates the system on Chinese basketball live text data from Hupo Basketball Website and presents subjective and automatic evaluation results in Chinese. No mention is made of cross-lingual performance or multilingual evaluation.
- Why unresolved: The evaluation is limited to Chinese text, and the knowledge graph construction and event templates are also described in the context of Chinese sports news. There is no evidence or discussion about adapting the system to other languages or cross-lingual knowledge transfer.
- What evidence would resolve it: Conducting the same subjective and automatic evaluations (ROUGE, clarity, information richness, etc.) on live text broadcasts and news writing in other languages, or demonstrating the adaptability of the entity extraction and knowledge graph modules to multilingual inputs.

### Open Question 2
- Question: How robust is the system to changes in live text broadcast format or structure, such as different event labeling or scoring update patterns?
- Basis in paper: [explicit] The paper states that the live text broadcast data used is "concise text live broadcast data" with fixed event types and independent events, and the KEE algorithm relies on segmenting games based on key time points derived from score differences. However, no experiments are described testing the system’s performance on varied or noisy broadcast formats.
- Why unresolved: The paper assumes a consistent and well-structured input format but does not address the system’s adaptability or error tolerance when faced with real-world variability in live broadcasts, such as inconsistent event descriptions or irregular score updates.
- What evidence would resolve it: Testing the system on multiple sources of live text broadcasts with varying formats, or introducing simulated noise and format variations to assess degradation in news quality and extraction accuracy.

### Open Question 3
- Question: Can the knowledge graph completion model generalize to entities or relations not seen during training, especially in a few-shot setting?
- Basis in paper: [explicit] The paper introduces a "small-sample knowledge graph completion model based on meta-learning" and mentions it addresses the "few-shot knowledge graph completion problem," but does not provide detailed quantitative results or ablation studies comparing its performance with other few-shot methods on unseen entities or relations.
- Why unresolved: While the model is described and integrated into the system, the paper does not present comparative experiments or statistical analysis showing how well the model generalizes to novel triples or relations with minimal training examples.
- What evidence would resolve it: Empirical results showing precision/recall/F1 scores on held-out few-shot relation types, or head-to-head comparisons with other few-shot KG completion approaches (e.g., MetaR, GMatching) on the same test set.

## Limitations
- Small subjective test (20 participants) and limited test set (50 games) may not fully capture generalizability
- Knowledge graph construction and few-shot KG completion model implementation details not fully specified
- Performance on sports other than basketball is unknown due to domain-specific KG
- System's adaptability to varied or noisy broadcast formats not evaluated

## Confidence

**High confidence** in the overall architecture and evaluation methodology. The multi-stage approach (event extraction → template generation → KG enrichment) is logically sound and the use of ROUGE and subjective metrics is standard.

**Medium confidence** in the few-shot KG completion component. While the paper describes the model architecture, the lack of detailed implementation and training procedures makes it difficult to assess whether the reported improvements are robust or domain-specific.

**Low confidence** in the narrative segmentation mechanism. The paper claims that score difference fluctuations identify turning points, but provides limited empirical evidence that this correlates with actual narrative interest or news quality.

## Next Checks

1. Replicate the key event extraction on a held-out set of basketball broadcasts to verify that score-based segmentation produces coherent narrative units.

2. A/B test news quality with and without KG enrichment using the same subjective evaluation protocol to confirm the reported improvement in clarity and information richness.

3. Stress-test the few-shot KG completion by evaluating performance on entity-relation pairs not seen during training to assess generalization capability.