---
ver: rpa2
title: 'With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal
  Large Language Models'
arxiv_id: '2409.14917'
source_url: https://arxiv.org/abs/2409.14917
tags:
- symbolism
- llav
- human
- sound
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates whether multimodal large language models\
  \ (LLMs) can understand sound symbolism\u2014the non-arbitrary link between sounds\
  \ and concepts\u2014despite only having access to text and visual modalities. Through\
  \ experiments replicating classic Kiki-Bouba shape symbolism and Mil-Mal magnitude\
  \ symbolism tasks, along with iconicity rating comparisons to human judgments, the\
  \ research finds that VLMs demonstrate varying levels of agreement with human preferences."
---

# With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models

## Quick Facts
- arXiv ID: 2409.14917
- Source URL: https://arxiv.org/abs/2409.14917
- Reference count: 20
- Key outcome: VLMs demonstrate varying levels of agreement with human sound symbolism judgments, with magnitude symbolism tasks showing higher agreement than shape symbolism

## Executive Summary
This study investigates whether multimodal large language models (VLMs) can understand sound symbolism—the non-arbitrary link between sounds and concepts—despite only having access to text and visual modalities. Through experiments replicating classic Kiki-Bouba shape symbolism and Mil-Mal magnitude symbolism tasks, along with iconicity rating comparisons to human judgments, the research finds that VLMs demonstrate varying levels of agreement with human preferences. Magnitude symbolism tasks show higher agreement levels than shape symbolism, suggesting it's an easier pattern for models to identify. The ability to emulate human iconicity ratings scales with model size, with GPT-4 showing the strongest correlations.

## Method Summary
The study employed zero-shot prompting with both standard and "informed" prompts across multiple open and closed-source VLMs and LLMs. Custom image datasets were generated via DALL-E 3 for shape and magnitude symbolism tasks, while existing human iconicity ratings served as benchmarks. Models were tested on their ability to match pseudowords (like Kiki/Bouba, Mil/Mal) with corresponding images, with performance measured against human majority votes and correlation with human iconicity ratings using Spearman and Pearson metrics.

## Key Results
- VLMs show systematic disagreement with human labels in some conditions, suggesting interference from additional knowledge in training data
- Magnitude symbolism tasks demonstrate higher agreement with human preferences than shape symbolism tasks
- The ability to emulate human iconicity ratings scales with model size, with GPT-4 achieving the strongest correlations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VLMs can implicitly learn sound symbolism through patterns in grapheme combinations and meta-level textual discussions of sound in training data
- Mechanism: Text-based models learn associations between grapheme sequences and semantics based on abstract characteristics rather than morpheme combinations alone
- Core assumption: Human languages exhibit mostly regular orthography, allowing auditory information in speech to be moderately reflected in word spellings
- Evidence anchors:
  - [abstract]: "the ability of VLMs and LLMs to reflect a sense of sound symbolism would therefore suggest that these models are capable of acquiring 'phonetic' knowledge indirectly through only the written orthographic form of a language via patterns of grapheme combinations"
  - [section 6]: "due to human languages exhibiting mostly regular orthography, auditory information in speech is moderately reflected in the spellings of words via grapheme sequences"
- Break condition: If orthography is highly irregular or grapheme-phoneme correspondence is inconsistent

### Mechanism 2
- Claim: VLMs learn sound symbolism associations through exposure to poetic, narrative, and descriptive language paired with visual stimuli in training data
- Mechanism: Sound symbolism is naturally present in language forms like poetry and narratives, which are paired with visual stimuli in image captions during training of vision modules for multimodal systems
- Core assumption: Training data contains sufficient examples of sound-symbolic language paired with relevant visual content
- Evidence anchors:
  - [abstract]: "such associations between sounds (or grapheme combinations) and physical characteristics are naturally present in language, such as in poetry, narratives, or descriptions of entities that are cute, scary, small, or large, and are consequently paired with relevant visual stimuli in image captions"
- Break condition: If training data lacks sufficient sound-symbolic language or if poetic/narrative content is underrepresented

### Mechanism 3
- Claim: VLMs demonstrate systematic disagreement with human labels due to interference from additional knowledge in language model training data
- Mechanism: VLMs access knowledge from training data that influences associations between pseudowords and images, creating systematic disagreements with human perception
- Core assumption: Training data contains information about sound symbolism that is not universally present in human perception
- Evidence anchors:
  - [abstract]: "VLMs show systematic disagreement with human labels, indicating the potential interference of additional knowledge contained within language model training data that influences the associations made between pseudowords and images that are not present in humans"
- Break condition: If training data is curated to remove sound symbolism content or if models are explicitly trained to align with human perception

## Foundational Learning

- Concept: Grapheme-to-phoneme conversion
  - Why needed here: Understanding how written language can carry sound information is crucial for explaining how VLMs might learn sound symbolism without direct auditory input
  - Quick check question: How do models map orthographic forms to phonological representations when only text data is available?

- Concept: Minimal pairs and phonological contrasts
  - Why needed here: The study uses minimal pairs (like Mil/Mal, Kiki/Bouba) to test sound symbolism, so understanding phonological contrasts is essential
  - Quick check question: What makes "Mil" and "Mal" a minimal pair, and why is this relevant for testing sound symbolism?

- Concept: Multimodal training data composition
  - Why needed here: Understanding how vision and language modules are trained together with paired data explains potential sources of sound symbolism learning
  - Quick check question: What types of paired visual and textual data are most likely to contain sound symbolism patterns?

## Architecture Onboarding

- Component map: Image → Vision module → Feature extraction → Text prompt → Language module → Response generation
- Critical path: The system processes visual features about shape and size from the vision module while simultaneously processing orthographic information about pseudowords in the language module, combining these inputs to produce sound symbolism judgments
- Design tradeoffs: Using DALL-E 3 generated images reduces memorization risk but introduces potential bias from the image generation model; testing with both standard and "informed" prompts reveals whether task knowledge improves performance but adds complexity to evaluation
- Failure signatures: Systematic disagreement with human labels indicates model bias or contamination from training data; chance-level performance suggests the model hasn't learned intended patterns; large performance gaps between model sizes indicate scale-dependent learning of abstract perceptual properties
- First 3 experiments:
  1. Test Kiki-Bouba shape symbolism with different pseudoword pairs to establish baseline performance and identify which phonetic patterns work best
  2. Test Mil-Mal magnitude symbolism to compare difficulty levels with shape symbolism tasks
  3. Evaluate iconicity ratings across different model sizes to understand scale-dependent performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms in LLM/VLM training data lead to the emergence of sound symbolism abilities?
- Basis in paper: Explicit
- Why unresolved: The paper hypothesizes several potential sources (grapheme-phoneme patterns, sound-symbolism in training data like poetry/narratives, statistical patterns) but doesn't experimentally test which mechanisms are most important or how they interact
- What evidence would resolve it: Controlled experiments varying the presence of sound-symbolism-heavy content in training data, ablation studies isolating different mechanisms, or analysis of attention patterns when processing sound-symbolic content

### Open Question 2
- Question: Why do larger models like GPT-4 show better sound symbolism understanding than smaller open-source models, and why does LLaVA-13B sometimes outperform LLaVA-34B?
- Basis in paper: Explicit
- Why unresolved: The paper notes this pattern but doesn't investigate the underlying reasons - whether it's about parameter count, training data quality/quantity, instruction tuning effects, or architectural differences
- What evidence would resolve it: Detailed analysis of model architectures, training data composition, and systematic testing across different model sizes with controlled variables

### Open Question 3
- Question: How can sound symbolism be explicitly incorporated into LLM training to improve performance on these tasks?
- Basis in paper: Explicit
- Why unresolved: The paper suggests this as a future direction but doesn't explore specific methods for incorporating sound-symbolic knowledge during pre-training or fine-tuning
- What evidence would resolve it: Experiments testing different approaches like sound-symbolism-focused pre-training data, specialized fine-tuning tasks, or architectural modifications that better capture phonetic-graphemic relationships

### Open Question 4
- Question: What causes systematic disagreement between VLMs and human judgments in some conditions, and how can this be mitigated?
- Basis in paper: Explicit
- Why unresolved: The paper observes this phenomenon but doesn't investigate whether it's due to memorization, interference from other knowledge, or fundamental limitations in how VLMs process visual-texual information
- What evidence would resolve it: Analysis of model attention patterns, comparison of model predictions with training data content, and testing whether providing different types of task information reduces disagreement

### Open Question 5
- Question: How transferable are sound symbolism abilities across languages, and what factors affect cross-linguistic performance?
- Basis in paper: Inferred
- Why unresolved: The paper uses only English speakers and phonotactically legal English pseudowords, but sound symbolism is believed to be largely language-agnostic. The paper doesn't test whether VLMs can generalize these abilities to other languages
- What evidence would resolve it: Experiments testing VLMs on sound symbolism tasks in multiple languages, analysis of how orthographic differences affect performance, and investigation of whether multilingual models show better generalization

## Limitations
- Systematic disagreement between VLMs and human labels suggests potential contamination from training data rather than genuine sound symbolism understanding
- Performance differences between open and closed models indicate that scale and training data composition significantly influence results
- The use of DALL-E 3 for image generation, while reducing memorization risk, may introduce its own biases into the experimental stimuli

## Confidence
- High Confidence: VLMs can perform above chance level on sound symbolism tasks when provided with appropriate prompts and visual context
- Medium Confidence: The ability to emulate human iconicity ratings scales with model size, with larger models showing stronger correlations
- Medium Confidence: Magnitude symbolism tasks are generally easier for models to identify than shape symbolism tasks

## Next Checks
1. Test the same experimental protocol with VLMs that have been explicitly trained to ignore sound symbolism patterns in their training data to isolate genuine perceptual capabilities from memorized associations
2. Replicate the experiments using hand-drawn or photographically-realistic images instead of DALL-E 3 generated images to eliminate potential generation model bias
3. Conduct ablation studies where models are given only text prompts, only images, or both to determine the relative contribution of each modality to sound symbolism performance