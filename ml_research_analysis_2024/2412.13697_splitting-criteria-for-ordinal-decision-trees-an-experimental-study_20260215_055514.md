---
ver: rpa2
title: 'Splitting criteria for ordinal decision trees: an experimental study'
arxiv_id: '2412.13697'
source_url: https://arxiv.org/abs/2412.13697
tags:
- ordinal
- splitting
- criteria
- classification
- impurity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work provides a comprehensive survey and experimental study
  of ordinal splitting criteria for decision trees, addressing the limitations of
  standard nominal classification methods in handling ordinal relationships. Three
  ordinal splitting criteria - Ordinal Gini (OGini), Weighted Information Gain (WIG),
  and Ranking Impurity (RI) - are compared to their nominal counterparts (Gini and
  Information Gain) using a large repository of 45 publicly available ordinal classification
  datasets.
---

# Splitting criteria for ordinal decision trees: an experimental study

## Quick Facts
- arXiv ID: 2412.13697
- Source URL: https://arxiv.org/abs/2412.13697
- Reference count: 40
- Key outcome: Ordinal splitting criteria (especially OGini) significantly outperform nominal criteria in decision trees for ordinal classification

## Executive Summary
This study addresses the challenge of applying decision trees to ordinal classification problems by introducing and evaluating three ordinal splitting criteria: Ordinal Gini (OGini), Weighted Information Gain (WIG), and Ranking Impurity (RI). Through extensive experiments on 45 publicly available ordinal classification datasets, the authors demonstrate that these ordinal criteria consistently outperform traditional nominal criteria (Gini and Information Gain) in terms of mean absolute error, quadratic weighted kappa, and ranked probability score. OGini emerges as the most effective criterion, achieving over 3% reduction in mean absolute error compared to the standard Gini criterion.

## Method Summary
The authors implemented five splitting criteria (Gini, OGini, Information Gain, WIG, and RI) in decision tree classifiers and evaluated them across 45 ordinal classification datasets. For each dataset, they performed 20 experimental runs with different random seeds, using 5-fold cross-validation to tune the maximum tree depth from {3, 5, 8, 16}. Performance was assessed using MAE, QWK, and RPS metrics, with statistical validation through Kolmogorov-Smirnov normality tests, ANOVA II, and Tukey post-hoc tests. All code, datasets, and results are publicly available at https://github.com/ayrna/decision-trees-from-scratch.

## Key Results
- OGini achieved the best overall performance, reducing mean absolute error by over 3% compared to Gini
- All three ordinal splitting criteria (OGini, WIG, RI) outperformed nominal criteria across all evaluation metrics
- Performance improvements were most pronounced in datasets with higher numbers of classes (Q)
- Statistical analysis confirmed the significance of performance differences between ordinal and nominal criteria

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Ordinal splitting criteria outperform nominal ones because they explicitly penalize misclassification errors based on the ordinal distance between classes.
- **Mechanism:** Nominal criteria like Gini and Information Gain treat all misclassifications equally, whereas ordinal criteria such as OGini, WIG, and RI incorporate weights or cumulative frequencies that reflect the ordinal relationship between classes.
- **Core assumption:** The ordinal relationship between classes is meaningful and should be preserved in the decision tree structure.
- **Evidence anchors:** [abstract]: "ordinal splitting criteria outperform nominal ones, with OGini achieving the best overall performance, reducing mean absolute error by over 3% compared to Gini."

### Mechanism 2
- **Claim:** The performance improvement of ordinal splitting criteria increases with the number of classes (Q).
- **Mechanism:** As the number of classes increases, the potential costs of misclassification also increase. Ordinal splitting criteria can better exploit the ordinality of the target label and its relationship with the input data, leading to more significant performance differences.
- **Core assumption:** The ordinal nature of the problem becomes more significant as the number of classes increases.
- **Evidence anchors:** [section]: "the differences in performance between nominal and ordinal splitting methods are expected to be more pronounced in datasets with higher values of Q."

### Mechanism 3
- **Claim:** OGini is the most effective ordinal splitting criterion because it is score-free and based on cumulative frequencies.
- **Mechanism:** Unlike other ordinal criteria that rely on assigned scores to classes, OGini uses cumulative frequencies, making it more flexible and applicable to a wider range of ordinal classification problems.
- **Core assumption:** The cumulative frequency of classes is a meaningful measure of heterogeneity in ordinal classification problems.
- **Evidence anchors:** [abstract]: "OGini stands out as the best ordinal splitting criterion to date, reducing the mean absolute error achieved by Gini by more than 3.02%."

## Foundational Learning

- **Concept: Ordinal Classification**
  - Why needed here: Understanding the difference between ordinal and nominal classification is crucial for grasping the motivation behind using ordinal splitting criteria.
  - Quick check question: What is the main difference between ordinal and nominal classification?

- **Concept: Decision Tree Splitting Criteria**
  - Why needed here: Familiarity with decision tree splitting criteria is essential for understanding how ordinal splitting criteria differ from nominal ones.
  - Quick check question: What are the most common splitting criteria used in decision trees for nominal classification?

- **Concept: Impurity Measures**
  - Why needed here: Understanding impurity measures is necessary for comprehending how splitting criteria are derived and how they influence the construction of decision trees.
  - Quick check question: What are the two most common impurity measures used in decision trees?

## Architecture Onboarding

- **Component map:** Decision Tree Classifier -> Splitting Criteria (Gini, OGini, IG, WIG, RI) -> Impurity Measures (Gini-index, Shannon-entropy, OGini-index, weighted entropy, RI) -> Evaluation Metrics (MAE, QWK, RPS)
- **Critical path:** Recursively partition the predictor space using the chosen splitting criterion, guided by the corresponding impurity measure, until a stopping criterion is met.
- **Design tradeoffs:** The main tradeoff is between the complexity of the splitting criteria and their performance. More complex criteria may capture the ordinal relationships better but may also be more computationally expensive.
- **Failure signatures:** If the chosen splitting criterion does not align with the ordinal structure of the data, the resulting decision tree may not perform well. Additionally, if the impurity measure is not appropriate for the problem at hand, the tree may not generalize well to unseen data.
- **First 3 experiments:**
  1. Compare the performance of a decision tree using the Gini splitting criterion versus the OGini splitting criterion on a simple ordinal classification dataset with 3 classes.
  2. Evaluate the impact of the number of classes (Q) on the performance difference between nominal and ordinal splitting criteria by testing on datasets with varying Q.
  3. Investigate the effect of the normalization parameter (∝) in the WIG splitting criterion on the performance of the decision tree.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do ordinal splitting criteria perform in ensemble methods compared to nominal splitting criteria?
- Basis in paper: [explicit] The paper mentions the potential future line of research to study the application of these splitting criteria in ensembles of trees, such as the ordinal forest proposed in [54].
- Why unresolved: The paper does not provide experimental results comparing ordinal and nominal splitting criteria in ensemble methods.
- What evidence would resolve it: Conducting experiments to compare the performance of ordinal and nominal splitting criteria in ensemble methods, such as random forests or boosting, on various ordinal classification datasets.

### Open Question 2
- Question: Can the proposed framework be extended to handle multi-label ordinal classification problems?
- Basis in paper: [inferred] The paper focuses on single-label ordinal classification and does not discuss multi-label scenarios.
- Why unresolved: The framework and experiments are limited to single-label ordinal classification, leaving the applicability to multi-label problems unexplored.
- What evidence would resolve it: Extending the framework to support multi-label ordinal classification and evaluating its performance on multi-label datasets with ordinal relationships between labels.

### Open Question 3
- Question: How sensitive are the ordinal splitting criteria to the choice of scores assigned to ordinal classes?
- Basis in paper: [explicit] The paper mentions that the computation of weights in WIG depends on the scores assigned to ordered categories, and it uses the function v(Cq) = q by default.
- Why unresolved: The paper does not investigate the impact of different scoring functions on the performance of ordinal splitting criteria.
- What evidence would resolve it: Conducting experiments with various scoring functions (e.g., v(Cq) = q^2, v(Cq) = log(q+1)) to assess the sensitivity of ordinal splitting criteria to the choice of scores.

## Limitations

- The study focuses exclusively on decision trees and does not explore performance in ensemble methods like random forests or gradient boosting.
- Results are based on specific dataset characteristics and may not generalize to domains with different ordinal structures.
- The computational efficiency of ordinal criteria relative to nominal ones is not discussed.

## Confidence

- **High confidence**: OGini's superior performance over Gini and IG, as evidenced by consistent improvements across MAE, QWK, and RPS metrics
- **Medium confidence**: The relationship between Q (number of classes) and performance differences, as the analysis is based on observed patterns rather than systematic variation
- **Medium confidence**: The claim that OGini is "score-free," as this depends on the specific implementation details of cumulative frequency calculation

## Next Checks

1. **Dataset diversity validation**: Replicate the experiments on additional ordinal datasets from different domains (medical, economic, educational) to test generalizability beyond the current repository.

2. **Scalability assessment**: Evaluate computational complexity and training time differences between ordinal and nominal criteria on large-scale datasets to assess practical viability.

3. **Hyperparameter sensitivity**: Systematically vary the normalization parameter (α) in WIG and explore alternative score assignments for RI to understand the robustness of ordinal criteria to implementation choices.