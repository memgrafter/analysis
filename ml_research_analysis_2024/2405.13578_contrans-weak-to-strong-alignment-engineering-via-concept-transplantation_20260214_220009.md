---
ver: rpa2
title: 'ConTrans: Weak-to-Strong Alignment Engineering via Concept Transplantation'
arxiv_id: '2405.13578'
source_url: https://arxiv.org/abs/2405.13578
tags:
- concept
- llama
- arxiv
- transplantation
- emotion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel framework, ConTrans, for transferring
  alignment from weak to strong language models via concept transplantation. ConTrans
  refines concept vectors from a weak aligned model and reformulates them to adapt
  to a strong unaligned model via affine transformation.
---

# ConTrans: Weak-to-Strong Alignment Engineering via Concept Transplantation

## Quick Facts
- arXiv ID: 2405.13578
- Source URL: https://arxiv.org/abs/2405.13578
- Authors: Weilong Dong; Xinwei Wu; Renren Jin; Shaoyang Xu; Deyi Xiong
- Reference count: 20
- Key outcome: Proposes a novel framework, ConTrans, for transferring alignment from weak to strong language models via concept transplantation.

## Executive Summary
This paper introduces ConTrans, a method for transferring alignment concepts from weak, aligned language models to strong, unaligned ones through concept transplantation. The approach involves refining concept vectors from the source model, reformulating them via affine transformation to adapt to the target model's feature space, and then transplanting these reformulated vectors into the target model's residual stream. Experiments demonstrate successful transplantation of various concepts like emotions, truthfulness, and toxicity across multiple model sizes and families, with ConTrans even surpassing instruction-tuned models in truthfulness on the TruthfulQA benchmark.

## Method Summary
ConTrans operates through three main steps: concept refinement, concept reformulation, and concept transplantation. First, concept vectors are refined from a weak, aligned source model using the mean difference method between positive and negative examples. These refined vectors are then projected into the target model's feature space using affine transformation. Finally, the reformulated concept vectors are added to the target model's residual stream during inference to influence its outputs. The method aims to improve the alignment of strong, unaligned models along specific conceptual dimensions without additional training.

## Key Results
- Successful transplantation of emotions, truthfulness, and toxicity concepts from 7B models to 13B and 70B models across multiple LLM families
- ConTrans surpasses instruction-tuned models in truthfulness on the TruthfulQA benchmark
- Effectiveness closely related to similarity in base model architecture and pre-training data volume between source and target models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Concept transplantation works by shifting the feature direction associated with specific concepts within the feature space of the target model.
- Mechanism: The refined concept vector from the source model, after affine transformation, is added to the residual stream of the target model, effectively steering the model's output preferences along the corresponding concept direction.
- Core assumption: Concepts are encoded as shared low-rank feature directions across models, and these directions are consistent across models of varying sizes and even across models from different families.
- Evidence anchors:
  - [abstract] "Experiments demonstrate the successful transplantation of a wide range of aligned concepts from 7B models to 13B and 70B models across multiple LLMs and LLM families."
  - [section] "We posit that the efficacy of this method can be generalized to more sophisticated approaches."
  - [corpus] Weak evidence: The corpus includes related papers on cross-model transferability and weak-to-strong generalization, but none specifically address concept transplantation via affine transformation.
- Break condition: If the shared concept directions are not consistent across models, or if the affine transformation does not accurately map the source concept vector to the target feature space, the concept transplantation will fail.

### Mechanism 2
- Claim: The effectiveness of concept transplantation is related to the similarity in base model architecture and pre-training data volume between the source and target models.
- Mechanism: When the source and target models have similar architectures and comparable amounts of pre-trained data, the concept vectors refined from the source model are more likely to accurately represent the shared concept directions in the target model's feature space.
- Core assumption: The base model plays a pivotal role in concept formation and concept transplantation, and the volume of pre-training data influences the crystallization of concepts.
- Evidence anchors:
  - [abstract] "Our experiments demonstrate the successful transplantation of a wide range of aligned concepts from 7B models to 13B and 70B models across multiple LLMs and LLM families."
  - [section] "We find that the effectiveness of CONTRANS is closely related to the similarity in base model architecture and pre-training data volume between Mtgt and Msrc."
  - [corpus] Weak evidence: The corpus includes related papers on transfer learning and weak-to-strong generalization, but none specifically address the impact of base model similarity on concept transplantation.
- Break condition: If the source and target models have significantly different architectures or pre-training data volumes, the concept vectors refined from the source model may not accurately represent the shared concept directions in the target model's feature space, leading to poor transplantation results.

### Mechanism 3
- Claim: Concept transplantation primarily operates by activating concepts that already exist within a model, rather than instilling new concepts.
- Mechanism: The refined concept vector from the source model, after affine transformation, is added to the residual stream of the target model, causing the model to activate and express the existing concept more strongly in its outputs.
- Core assumption: The target model possesses corresponding knowledge but may not generate correct responses due to its "dishonesty" or lack of alignment with human values.
- Evidence anchors:
  - [abstract] "Remarkably, CONTRANS even surpasses instruction-tuned models in terms of truthfulness."
  - [section] "This implies that alignment training may primarily activate the model's inherent honesty rather than instilling it anew."
  - [corpus] Weak evidence: The corpus includes related papers on representation engineering and activation steering, but none specifically address the activation of existing concepts in concept transplantation.
- Break condition: If the target model lacks the corresponding knowledge or concept, the concept transplantation will not be effective in activating and expressing the desired concept in the model's outputs.

## Foundational Learning

- Concept: Affine transformation
  - Why needed here: To project the refined concept vector from the source model's feature space into the target model's feature space, enabling concept transplantation across models with different dimensions.
  - Quick check question: Given a concept vector v_concept from a source model and the hidden states h_src and h_tgt from the source and target models, respectively, how do you compute the affine transformation F that maps v_concept to the target feature space?

- Concept: Mean difference method for concept refinement
  - Why needed here: To extract a concept vector from the source model by computing the difference between the hidden states of positive and negative examples related to the concept.
  - Quick check question: Given a set of positive examples s_positive and negative examples s_negative related to a concept, how do you compute the concept vector v_concept using the mean difference method?

- Concept: Residual stream in transformer models
  - Why needed here: To understand how the refined and reformulated concept vector is added to the target model's hidden states to influence its outputs.
  - Quick check question: In a transformer model with L layers, how is the hidden state h_k at layer k computed using the residual stream from the previous layer and the output of the multi-layer perceptron (MLP) sublayer?

## Architecture Onboarding

- Component map:
  Concept refinement module -> Concept reformulation module -> Concept transplantation module -> Evaluation module

- Critical path:
  1. Refine concept vector from source model using positive and negative examples.
  2. Reformulate concept vector to adapt to target model's feature space via affine transformation.
  3. Transplant reformulated concept vector into target model's residual stream.
  4. Evaluate the effectiveness of concept transplantation on target model's outputs.

- Design tradeoffs:
  - Number of examples for concept refinement: More examples may lead to more accurate concept vectors but increase computational cost.
  - Strength of concept steering (α): Higher values may lead to more pronounced effects but may also introduce instability or incoherence in the model's outputs.
  - Affine transformation method: Analytical solution may be more stable than gradient descent, but may not always provide the optimal solution.

- Failure signatures:
  - Poor concept transplantation results when source and target models have significantly different architectures or pre-training data volumes.
  - Instability or incoherence in the target model's outputs when the strength of concept steering (α) is set too high.
  - Inability to refine accurate concept vectors when the number of examples is too small or the examples are not representative of the concept.

- First 3 experiments:
  1. Transplant emotion concept vectors from LLaMA-7B to LLaMA-13B and evaluate the emotion prediction accuracy on negative scenarios.
  2. Transplant truthfulness concept vectors from LLaMA-2-7B instruct to LLaMA-2-13B base and evaluate the TruthfulQA accuracy.
  3. Transplant fairness concept vectors from LLaMA-2-7B instruct to LLaMA-2-13B base and evaluate the proportion of toxic responses on Toxigen dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of ConTrans vary when transplanting multiple concepts simultaneously versus individually?
- Basis in paper: [inferred] The paper mentions that a significant limitation is the restriction to modifying only a single specific concept at a time, leaving the feasibility of simultaneous transplantation of multiple concepts as an open question.
- Why unresolved: The paper does not provide experimental results or analysis on the effects of transplanting multiple concept vectors at once, making it unclear whether superposition of multiple concept vectors would lead to additive, multiplicative, or conflicting effects.
- What evidence would resolve it: Experiments comparing the performance of ConTrans when transplanting multiple concept vectors simultaneously versus individually, using metrics like accuracy on concept-specific tasks and perplexity on general text generation.

### Open Question 2
- Question: What is the relationship between the volume of pre-training data and the formation of abstract concepts like truthfulness and fairness in language models?
- Basis in paper: [explicit] The paper shows that the effectiveness of ConTrans improves with increased pre-training data size, suggesting that abstract concepts crystallize as models are exposed to more data. However, it does not quantify this relationship or explore its limits.
- Why unresolved: While the paper demonstrates a correlation between pre-training data size and concept effectiveness, it does not provide a detailed analysis of how different types of pre-training data (e.g., diverse vs. domain-specific) influence the formation of abstract concepts.
- What evidence would resolve it: Controlled experiments varying the size and diversity of pre-training data, measuring the effectiveness of ConTrans on abstract concepts like truthfulness and fairness, and analyzing the latent representations of these concepts across different data regimes.

### Open Question 3
- Question: Can ConTrans be effectively applied to enhance model capabilities such as coding or reasoning, or is it limited to modifying concept-related outputs?
- Basis in paper: [explicit] The paper acknowledges that ConTrans may not be effective for enhancing model capabilities like coding or reasoning, as there is currently no evidence to suggest that improvements in these capabilities can be achieved by modifying specific feature directions.
- Why unresolved: The paper does not provide experimental results or theoretical analysis on applying ConTrans to capability-related tasks, leaving it unclear whether the underlying mechanisms of concept transplantation are applicable to skill-based improvements.
- What evidence would resolve it: Experiments applying ConTrans to coding and reasoning benchmarks, measuring improvements in task performance, and analyzing the changes in latent representations related to these capabilities.

## Limitations
- Effectiveness may be limited when source and target models have significantly different architectures or pre-training data volumes
- Long-term stability and potential side effects of concept transplantation on model behavior are not addressed
- Computational cost of the method, particularly for large-scale models, is not thoroughly discussed

## Confidence

**High Confidence**: The core methodology of ConTrans (concept refinement, reformulation, and transplantation) is well-defined and its implementation details are provided. The results demonstrating successful transplantation across different model sizes within the LLaMA family are promising.

**Medium Confidence**: The claims about the effectiveness of ConTrans in surpassing instruction-tuned models on truthfulness are based on experiments with the TruthfulQA benchmark. However, the generalizability of these results to other alignment metrics and real-world scenarios needs further validation.

**Low Confidence**: The paper's assertions about the activation of existing concepts rather than instilling new ones are based on limited evidence and require more rigorous investigation. The impact of ConTrans on model behavior beyond the specific concepts targeted is not explored.

## Next Checks
1. **Cross-Architecture Generalization**: Conduct experiments to evaluate the effectiveness of ConTrans on model architectures beyond LLaMA, such as GPT, BERT, or PaLM families, to assess its broader applicability.
2. **Long-Term Stability Analysis**: Perform longitudinal studies to investigate the long-term stability of concept transplantation and identify any potential side effects or unintended consequences on model behavior over extended periods of use.
3. **Real-World Scenario Testing**: Apply ConTrans to real-world alignment challenges, such as bias mitigation or factuality enhancement, to evaluate its practical utility and limitations in addressing complex alignment issues beyond controlled benchmark settings.