---
ver: rpa2
title: Simulating Multi-Stakeholder Decision-Making with Generative Agents in Urban
  Planning
arxiv_id: '2402.11314'
source_url: https://arxiv.org/abs/2402.11314
tags:
- agents
- agent
- planning
- decision-making
- square
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a multi-agent simulation framework to model
  collective decision-making in urban planning, addressing challenges of stakeholder
  diversity, negotiation dynamics, and potential biases. By integrating large language
  models (LLMs) with real-world demographic and survey data, the system simulates
  discussions among eight stakeholder types regarding Kendall Square redevelopment.
---

# Simulating Multi-Stakeholder Decision-Making with Generative Agents in Urban Planning

## Quick Facts
- arXiv ID: 2402.11314
- Source URL: https://arxiv.org/abs/2402.11314
- Authors: Jin Gao; Hanyong Xu; Luc Dao
- Reference count: 1
- Key outcome: Multi-agent simulation framework using LLMs improves collective reasoning in urban planning by incorporating stakeholder diversity and negotiation dynamics

## Executive Summary
This study introduces a multi-agent simulation framework that leverages large language models to model collective decision-making in urban planning. The system simulates discussions among eight stakeholder types regarding Kendall Square redevelopment, demonstrating that communication among agents significantly enhances argument quality and reasoning depth. By integrating real-world demographic and survey data, the framework enables decision-makers to anticipate stakeholder reactions and refine proposals iteratively, offering a cost-effective alternative to traditional public consultation methods.

The research addresses key challenges in participatory planning, including stakeholder diversity, negotiation dynamics, and potential biases in representation. Results show that including demographic and value-based data increases opinion diversity and stability, while agent communication leads to more enriched outcomes and solutions. The framework acknowledges ethical risks such as misrepresentation and bias amplification, recommending transparent persona design and external auditing as safeguards.

## Method Summary
The study employs a multi-agent system using the AutoGen framework with ChatGPT-4 Turbo APIs to simulate stakeholder discussions in urban planning. The method involves creating generative agents representing eight stakeholder types based on interview data from Kendall Square stakeholders, demographic information, and survey data. Agent prompts are structured with role, demographic, daily life/value, task, and format components. Simulations are run with varying configurations including communication levels and demographic data inclusion, with results analyzed through keyword analysis and decision score comparisons across different setups.

## Key Results
- Communication among agents significantly improves the quality of collective reasoning and argument depth
- Inclusion of demographic and life value data increases opinion diversity and stability across simulation runs
- The framework enables cost-effective anticipation of stakeholder reactions compared to traditional surveys and hearings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Communication among agents improves the quality of collective reasoning in multi-agent simulations.
- Mechanism: Agents exchange opinions through structured group chat, allowing each agent to consider and integrate perspectives from others before forming final decisions.
- Core assumption: Agents can accurately process and incorporate opinions of others into their own reasoning.
- Evidence anchors:
  - [abstract] "communication among agents improves the quality of collective reasoning"
  - [section] "in the multi-agent system, they can consider enriched outcomes and solutions, digest other agent's opinions, and change their output decisions accordingly"
  - [corpus] No direct evidence from corpus papers, but related works on multi-agent collaboration support this claim
- Break condition: If agents cannot process or integrate others' opinions, or if communication leads to opinion convergence rather than diversity.

### Mechanism 2
- Claim: Including demographic and life value data in agent prompts increases opinion diversity and stability.
- Mechanism: Agents with diverse demographic backgrounds and life experiences produce more varied opinions, and this diversity is maintained across simulation runs.
- Core assumption: Demographic and life value data accurately represent diversity of real-world stakeholders.
- Evidence anchors:
  - [abstract] "inclusion of demographic and value-based data increases opinion diversity and stability"
  - [section] "adding the life values and demographics both help the agents to produce more diversifying, diverging, and more stable ratings"
  - [corpus] No direct evidence from corpus papers, but related works on personalized AI agents support this claim
- Break condition: If demographic and life value data do not accurately represent real-world diversity, or if agents converge on similar opinions despite diverse backgrounds.

### Mechanism 3
- Claim: Multi-agent simulations can predict stakeholder reactions to urban planning proposals more cost-effectively than traditional methods.
- Mechanism: Simulated discussions among diverse agents provide insights into potential stakeholder concerns, objections, and support, allowing decision-makers to refine proposals before public release.
- Core assumption: Agent simulations accurately represent real-world stakeholder behavior and preferences.
- Evidence anchors:
  - [abstract] "enables decision-makers to anticipate stakeholder reactions and refine proposals iteratively"
  - [section] "The cost of running a simulated discussion is much cheaper than running actual surveys and hearings"
  - [corpus] No direct evidence from corpus papers, but related works on synthetic participatory planning support this claim
- Break condition: If agent simulations do not accurately represent real-world stakeholder behavior, or if cost savings are not significant enough to justify use of simulations.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their capabilities in knowledge transfer, reasoning, and planning
  - Why needed here: LLMs form the foundation of the generative agents used in the multi-agent simulation
  - Quick check question: What are the key capabilities of LLMs that make them suitable for use in multi-agent simulations?

- Concept: Multi-agent systems and their potential applications in simulating community decision-making
  - Why needed here: The study builds on the concept of multi-agent systems to create a framework for simulating stakeholder discussions in urban planning
  - Quick check question: How do multi-agent systems differ from single-agent systems, and what are their potential advantages in simulating community decision-making?

- Concept: Urban planning decision-making processes and stakeholder involvement
  - Why needed here: The study applies the multi-agent simulation framework to a specific urban planning scenario, requiring an understanding of the decision-making process and stakeholder involvement
  - Quick check question: What are the key steps in the urban planning decision-making process, and how are stakeholders typically involved?

## Architecture Onboarding

- Component map: Government admin agent -> AutoGen framework -> Generative agents (8 stakeholder types) -> Agent prompts (role, demographic, daily life/value, task, format) -> Simulation setup (communication, survey data, demographic variables) -> Analysis tools (keyword analysis, error point plots)

- Critical path:
  1. Define agent roles and create corresponding prompts
  2. Set up simulation environment with AutoGen framework
  3. Run simulations with different configurations (communication, survey data, demographic variables)
  4. Analyze agent outputs and compare results across setups
  5. Draw conclusions about the impact of communication, survey data, and demographic variables on agent decision-making

- Design tradeoffs:
  - Balancing agent diversity with computational efficiency
  - Ensuring accurate representation of stakeholder perspectives while maintaining privacy
  - Managing complexity of agent interactions and decision-making processes

- Failure signatures:
  - Agents converging on similar opinions despite diverse backgrounds
  - Simulation results not aligning with real-world stakeholder behavior
  - Excessive computational resources required for large-scale simulations

- First 3 experiments:
  1. Compare single-agent decision-making with multi-agent decision-making to assess the impact of communication
  2. Vary the inclusion of demographic and life value data in agent prompts to evaluate their effect on opinion diversity and stability
  3. Test different simulation setups with varying numbers of agents and stakeholder types to assess scalability and generalizability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the level of communication among agents impact the stability and convergence of their decision-making outcomes?
- Basis in paper: [explicit] The study compares different setups with varying levels of communication among agents to assess its impact on collective reasoning.
- Why unresolved: While the paper indicates that communication improves the quality of collective reasoning, it does not provide a detailed analysis of how different levels of communication affect the stability and convergence of decisions.
- What evidence would resolve it: Detailed quantitative analysis comparing decision stability and convergence rates across multiple communication setups.

### Open Question 2
- Question: What are the long-term effects of including demographic and life-value data on the diversity of agent opinions in repeated simulations?
- Basis in paper: [explicit] The paper finds that including demographic and life-value data enhances the diversity and stability of agent outputs.
- Why unresolved: The study does not explore the long-term effects of including demographic and life-value data on opinion diversity in repeated simulations.
- What evidence would resolve it: Longitudinal studies showing changes in opinion diversity over multiple simulation runs with varying demographic and life-value data inclusion.

### Open Question 3
- Question: How can the multi-agent decision-making system be improved to better represent the passionate and diverse opinions of real-life stakeholders?
- Basis in paper: [inferred] The paper acknowledges that agents tend to not have strong opinions and are influenced by other agents, suggesting a need for improvement.
- Why unresolved: The paper does not provide specific methods or frameworks to enhance the representation of passionate and diverse opinions in the simulation.
- What evidence would resolve it: Development and testing of enhanced agent models that incorporate more dynamic and passionate opinion representation, validated against real stakeholder feedback.

## Limitations
- Reliance on synthetic stakeholder data with validation limited to comparing simulation outputs against real-world survey responses rather than actual stakeholder decisions
- Findings focus on a single redevelopment case (Kendall Square), limiting generalizability to other urban planning contexts
- Lack of quantitative measures of decision quality beyond opinion diversity and stability metrics

## Confidence

- Agent communication improves reasoning quality: **Medium**
- Demographic data increases opinion diversity: **High**
- Cost-effectiveness for real-world application: **Low**

## Next Checks

1. **Stakeholder Validation Study**: Conduct interviews with actual Kendall Square stakeholders to compare their decision-making processes and final positions against the simulated agent outputs, measuring alignment rates and identifying key divergence factors.

2. **Controlled Environment Testing**: Run parallel simulations using the same framework with synthetic agents and real stakeholder data from completed urban planning projects where outcomes are known, comparing prediction accuracy across multiple case studies.

3. **Bias Impact Analysis**: Systematically test how different demographic distributions and prompt structures affect agent outputs by running controlled simulations with varied population compositions, measuring opinion convergence/divergence rates and identifying potential amplification patterns.