---
ver: rpa2
title: 'MIDGARD: Self-Consistency Using Minimum Description Length for Structured
  Commonsense Reasoning'
arxiv_id: '2405.05189'
source_url: https://arxiv.org/abs/2405.05189
tags:
- graph
- midgard
- samples
- reasoning
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating structured reasoning
  graphs using large language models (LLMs), where error propagation in autoregressive
  decoding and reliance on single samples can lead to inaccuracies. To mitigate these
  issues, the authors propose MIDGARD, a self-consistency approach that aggregates
  multiple graph samples generated by an LLM using Minimum Description Length (MDL)
  principles.
---

# MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning

## Quick Facts
- arXiv ID: 2405.05189
- Source URL: https://arxiv.org/abs/2405.05189
- Authors: Inderjeet Nair; Lu Wang
- Reference count: 14
- Key outcome: Aggregates multiple LLM-generated graph samples using MDL principles to reduce error propagation and improve structured reasoning performance

## Executive Summary
This paper addresses the challenge of generating structured reasoning graphs using large language models (LLMs), where error propagation in autoregressive decoding and reliance on single samples can lead to inaccuracies. To mitigate these issues, the authors propose MIDGARD, a self-consistency approach that aggregates multiple graph samples generated by an LLM using Minimum Description Length (MDL) principles. By minimizing the description length of the aggregated graph, MIDGARD identifies and includes consistent properties across samples while rejecting erroneous ones. Experiments across four structured reasoning tasks—argument structure extraction, explanation graph generation, script planning, and semantic graph generation—demonstrate that MIDGARD consistently outperforms competitive baselines and model variants, achieving significant improvements in edge F1-scores and other task-specific metrics. The approach also generalizes well across different graph complexities and few-shot example settings.

## Method Summary
MIDGARD generates multiple graph samples from an LLM using temperature sampling, then aggregates these samples by minimizing the description length across all generated graphs. The aggregation uses an ILP formulation that optimizes which nodes and edges to include in the final graph based on their frequency across samples. The method introduces asymmetric costs for adding versus deleting edges through a hyperparameter λ, and can enforce DAG constraints for tasks requiring acyclic structures. By construction, this approach retains high-frequency (likely correct) elements while discarding low-frequency (likely erroneous) ones.

## Key Results
- MIDGARD consistently outperforms baselines across four structured reasoning tasks
- Significant improvements in edge F1-scores (up to 15% absolute improvement over baselines)
- The approach generalizes well across different graph complexities and few-shot settings
- Asymmetric MDL costs (λ ≠ 0.5) provide performance gains over symmetric alternatives

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sampling multiple graph generations from an LLM and using MDL to filter inconsistencies reduces error propagation and improves final graph quality.
- **Mechanism:** Each sampled graph has some correct and some incorrect nodes/edges. MDL formulation assigns higher likelihood to nodes/edges appearing across many samples. By optimizing to minimize description length, the aggregated graph keeps high-frequency (likely correct) elements and discards low-frequency (likely erroneous) ones.
- **Core assumption:** Nodes/edges that appear in multiple LLM samples are more likely to be correct than those appearing in only a few.
- **Evidence anchors:**
  - [abstract] "This formulation helps reject properties that appear in only a few samples, which are likely to be erroneous, while enabling the inclusion of missing elements without compromising precision."
  - [section] "Assuming that graph properties consistent across multiple generated samples are more likely to be accurate, we define the description length of a graph sample as the weighted sum of the transformations required to convert a hypothesis into the given sample."
  - [corpus] Found related work on MDL-based graph pooling (MDL-Pool) and graph sampling (GraphSOS) but no direct prior use of MDL for aggregating LLM-generated graph samples.
- **Break condition:** If LLM samples are highly diverse with little overlap, MDL filtering provides minimal benefit and may discard true but infrequent elements.

### Mechanism 2
- **Claim:** Unequal description lengths for addition versus deletion (λ ≠ 0.5) improves aggregation performance compared to symmetric costs.
- **Mechanism:** By setting different bit costs for adding (λ) and deleting (1-λ) edges, the model can be biased toward inclusion or exclusion based on task requirements. This asymmetric cost structure allows the optimization to favor retaining edges that appear with moderate frequency while being less strict about excluding rare edges.
- **Core assumption:** The optimal balance between false positives and false negatives in the final graph is not symmetric, requiring different costs for addition and deletion.
- **Evidence anchors:**
  - [abstract] "We introduce the hyperparameter λ, which can be interpreted as the number of bits needed to describe a single addition, when (1 − λ) bits are needed to describe a single deletion."
  - [section] "While Lam and Bacchus (1994) assigned equal bit requirements for describing a single addition and deletion, our empirical results demonstrate the significance of assuming different bit requirements to achieve enhanced performance."
  - [corpus] Found no direct corpus evidence for asymmetric MDL costs in graph aggregation; this appears to be a novel contribution.
- **Break condition:** If λ is set too far from optimal (either too close to 0 or 1), the aggregation becomes overly conservative or overly permissive, degrading performance.

### Mechanism 3
- **Claim:** Incorporating DAG constraints during aggregation prevents cycles that would invalidate structured reasoning tasks.
- **Mechanism:** The ILP formulation includes binary variables tracking whether paths exist between nodes, enforcing acyclicity through constraints that prevent both direct edges and transitive paths from creating cycles. This ensures the final aggregated graph maintains the structural requirements of tasks like argument mining.
- **Core assumption:** The ground truth graphs in structured reasoning tasks are DAGs, so enforcing this constraint during aggregation aligns the hypothesis space with valid outputs.
- **Evidence anchors:**
  - [abstract] "By constructing a hypothesis that minimizes the description length across all the generated samples, our solution encourages the inclusion of graph properties that were present in many samples, while rejecting properties that were only present in a few samples which are likely to be erroneous."
  - [section] "In many structured reasoning tasks, the graphs typically do not have singleton nodes. For example, in argumentative structures of essays (Stab and Gurevych, 2017), nodes are either supported or attacked by other nodes, or they themselves support or attack other nodes."
  - [corpus] Found related work on graph pooling and graph sampling but no direct corpus evidence for ILP-based DAG constraint enforcement in LLM graph aggregation.
- **Break condition:** If the task allows cyclic structures (like semantic graph generation), enforcing DAG constraints unnecessarily restricts the hypothesis space and degrades performance.

## Foundational Learning

- **Concept: Minimum Description Length (MDL) principle**
  - Why needed here: MDL provides a principled way to balance model complexity with data fit when aggregating multiple graph samples. It helps identify which graph elements are consistently generated across samples (likely correct) versus which are sporadic (likely erroneous).
  - Quick check question: How does MDL differ from maximum likelihood estimation when selecting among competing hypotheses?

- **Concept: Integer Linear Programming (ILP) for constrained optimization**
  - Why needed here: ILP allows us to enforce structural constraints (like DAG requirements) while optimizing the MDL objective. It provides an exact solution method for selecting which nodes and edges to include in the final aggregated graph.
  - Quick check question: What are the key differences between ILP and linear programming, and why is ILP necessary for this graph aggregation problem?

- **Concept: Directed Acyclic Graph (DAG) properties and cycle detection**
  - Why needed here: Many structured reasoning tasks require DAG outputs. Understanding how to represent and enforce acyclicity through path variables and constraints is crucial for the ILP formulation.
  - Quick check question: How can you represent the constraint "no cycles allowed" in a graph using path variables between nodes?

## Architecture Onboarding

- **Component map:** Natural language input -> LLM generation (T samples) -> Parsing (T times) -> MDL optimization -> Final aggregated graph
- **Critical path:** Natural language input → LLM sampling (T times) → Parsing (T times) → MDL optimization → Final graph output
- **Design tradeoffs:**
  - Number of samples (T): More samples improve robustness but increase computation time and cost
  - Temperature setting: Higher temperature increases diversity but may reduce sample quality
  - λ hyperparameter: Controls balance between false positives and false negatives
  - DAG constraints: Necessary for some tasks but restrictive for others
- **Failure signatures:**
  - Low overlap between samples: MDL filtering provides minimal benefit
  - Inconsistent parsing: Parser fails to extract graph structures from LLM output
  - ILP infeasibility: Constraints cannot be satisfied with current samples
  - High computational cost: ILP solver takes excessive time for large graphs
- **First 3 experiments:**
  1. **Sample diversity analysis:** Generate T samples with varying temperatures, measure edge/node overlap, verify that samples are sufficiently diverse for MDL to be beneficial
  2. **Hyperparameter sensitivity:** Vary λ1 and λ2 values, measure impact on precision/recall for component identification and relation prediction
  3. **Constraint necessity:** Compare performance with and without DAG constraints on tasks where cycles are allowed (semantic graph generation)

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions beyond the immediate scope of the experiments conducted. The primary focus is on demonstrating the effectiveness of the MIDGARD approach on the four evaluated tasks.

## Limitations

- Computational complexity may become prohibitive for very large graphs due to exponential growth in ILP solver time
- Performance depends heavily on sufficient diversity among LLM-generated samples
- The asymmetric cost structure (λ ≠ 0.5) requires careful hyperparameter tuning and may be task-dependent

## Confidence

**High Confidence:** The core hypothesis that aggregating multiple LLM-generated samples using MDL principles can improve structured reasoning graph quality. This is supported by consistent performance improvements across four diverse tasks and multiple evaluation metrics.

**Medium Confidence:** The specific implementation details, particularly the asymmetric MDL cost structure and the ILP formulation with DAG constraints. While the paper provides theoretical justification, the empirical sensitivity to these design choices is not fully explored.

**Low Confidence:** The scalability of the approach to very large graphs or to LLMs with different characteristics. The paper focuses on moderate-sized graphs and specific LLM configurations, with limited discussion of computational complexity or performance with alternative model architectures.

## Next Checks

1. **Sample Diversity Analysis:** Generate T samples with systematically varied temperatures (e.g., 0.1, 0.5, 1.0, 2.0) and measure the Jaccard similarity between edge sets. Verify that sample diversity correlates positively with MDL aggregation performance, establishing that the approach requires sufficient sample diversity to be effective.

2. **Hyperparameter Sensitivity Study:** Conduct a grid search over λ values (0.1 to 0.9 in increments of 0.1) for each task, measuring precision, recall, and F1 scores. Identify whether there are task-specific optimal λ values or if a single value works across tasks, and determine the sensitivity of performance to λ perturbations.

3. **Constraint Relaxation Test:** Modify the ILP formulation to allow cycles in the aggregated graph and evaluate performance on tasks where cycles are semantically valid (like semantic graph generation). Compare against the DAG-constrained version to quantify the impact of this structural assumption on tasks with different graph characteristics.