---
ver: rpa2
title: 'On Giant''s Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion'
arxiv_id: '2406.15480'
source_url: https://arxiv.org/abs/2406.15480
tags:
- knowledge
- large
- small
- learning
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores whether task-specific knowledge from a small
  model can be directly transferred to a much larger model without further training.
  The authors propose a dynamic logit fusion method that adaptively combines knowledge
  from multiple task-specific small models at each decoding step, using a KL divergence
  constrained optimization to learn the fusion weights.
---

# On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion

## Quick Facts
- arXiv ID: 2406.15480
- Source URL: https://arxiv.org/abs/2406.15480
- Authors: Chenghao Fan; Zhenyi Lu; Wei Wei; Jie Tian; Xiaoye Qu; Dangyang Chen; Yu Cheng
- Reference count: 40
- Key outcome: Transfers task-specific knowledge from 7B model to 13B model, closing performance gap by 96.4% in single-task and 86.3% in multi-task scenarios compared to full fine-tuning

## Executive Summary
This paper introduces a method to transfer task-specific knowledge from small language models to larger ones without further training the large model. The approach uses dynamic logit fusion with KL divergence constrained optimization to adaptively combine knowledge from multiple task-specific small models during inference. Experiments demonstrate that this method achieves performance close to full fine-tuning of the larger model while being more efficient and supporting multi-task learning and integration with in-context learning.

## Method Summary
The method fine-tunes small models (1.1B, 7B) on specific tasks, then transfers their knowledge to a larger model (13B) through dynamic logit fusion. At each decoding step, the approach searches for optimal fusion weights among the small models using KL divergence constrained optimization, rather than using static pre-defined weights. The method treats multi-task knowledge fusion as a centroid problem in KL-divergence space, optimizing marginal distributions when joint distribution estimation is intractable.

## Key Results
- Transfers knowledge from 7B to 13B model, closing performance gap by 96.4% in single-task scenarios
- Achieves 86.3% performance of full fine-tuning in multi-task scenarios
- Strong results on unseen tasks (PubMedQA) and supports integration with in-context learning and task arithmetic

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Logit arithmetic with dynamic fusion weights allows task-specific knowledge transfer without additional training.
- Mechanism: Adaptively allocates weights among multiple task-specific small models at each decoding step, optimizing these weights via KL divergence constrained optimization.
- Core assumption: Distance between fine-tuned model outputs and pretrained model outputs is the same across different model sizes at each decoding step.
- Break condition: If KL divergence between small and large model distributions varies significantly across model sizes, optimization would fail to find meaningful weights.

### Mechanism 2
- Claim: Dynamic weight adjustment outperforms static pre-defined weights in knowledge transfer.
- Mechanism: Searches for optimal fusion weights at each decoding step rather than using fixed α, allowing better alignment with task requirements.
- Core assumption: Importance of fine-tuned knowledge varies significantly across different tasks, inputs, and decoding steps.
- Break condition: If computational cost of dynamic search outweighs performance gains, or if search space is too large to optimize effectively.

### Mechanism 3
- Claim: Multi-task knowledge fusion can be approximated by optimizing marginal distributions when joint distribution estimation is intractable.
- Mechanism: Optimizes individual KL divergences and finds centroid solution instead of directly optimizing joint distribution of multiple experts.
- Core assumption: Joint distribution of multiple expert model outputs can be approximated by finding central point that minimizes sum of squared KL divergences.
- Break condition: If expert models' outputs are highly correlated or marginal optimization fails to capture important joint dependencies.

## Foundational Learning

- Concept: KL Divergence as a measure of distribution similarity
  - Why needed here: Method uses KL divergence to measure and optimize similarity between model output distributions during knowledge transfer.
  - Quick check question: If distribution P is identical to distribution Q, what is DKL(P||Q)?

- Concept: Logit arithmetic and probability transformations
  - Why needed here: Understanding how logits relate to probabilities through softmax and how arithmetic operations on logits translate to operations on probability distributions.
  - Quick check question: If you add α times the difference of two logit vectors to a third logit vector, what mathematical operation does this represent on the corresponding probability distributions?

- Concept: Constrained optimization and centroid problems
  - Why needed here: Method frames weight optimization as finding centroid in KL-divergence space, requiring understanding of optimization under constraints.
  - Quick check question: In a centroid problem, what property does the optimal solution have relative to the input points?

## Architecture Onboarding

- Component map: Input prompt -> SLM inference -> KL calculation -> Weight optimization -> Logit fusion -> LLM inference -> Output token
- Critical path: Input prompt → SLM inference → KL calculation → Weight optimization → Logit fusion → LLM inference → Output token
- Design tradeoffs:
  - Performance vs. efficiency: Dynamic weight search improves performance but adds computational overhead
  - Number of experts vs. complexity: More experts provide better coverage but exponentially increase search space
  - Granularity of weight search: Finer search steps improve accuracy but increase computation time
- Failure signatures:
  - Poor performance on seen tasks: Indicates weight optimization is not finding good fusion parameters
  - Degraded performance on unseen tasks: Suggests method is overfitting to training distributions
  - Excessive inference time: Weight search is too computationally intensive
- First 3 experiments:
  1. Single-task scenario with one expert: Verify basic logit arithmetic with dynamic weights
  2. Multi-task scenario with two experts: Test marginal distribution optimization
  3. Unseen task evaluation: Assess generalization capability of fused model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance of dynamic logit fusion compare to full fine-tuning when scaling up to much larger models (e.g., 30B+ parameters)?
- Basis in paper: [inferred] Paper demonstrates performance on 13B model but does not explore significantly larger scales.
- Why unresolved: Authors only tested up to 13B model, leaving open question of how well method scales to much larger models.
- What evidence would resolve it: Experiments comparing dynamic logit fusion against full fine-tuning on models with 30B+ parameters across various tasks.

### Open Question 2
- Question: What is impact of using non-homogeneous architectures (different model sizes or configurations) in dynamic logit fusion approach?
- Basis in paper: [explicit] Paper assumes homogeneous architecture and same vocabulary for models, but does not explore non-homogeneous cases.
- Why unresolved: Method is currently limited to models with same architecture and vocabulary, and its effectiveness with heterogeneous models is unknown.
- What evidence would resolve it: Experiments testing dynamic logit fusion with models of different sizes, architectures, or vocabularies to assess performance degradation or adaptation.

### Open Question 3
- Question: How does method perform on tasks requiring multi-step reasoning or complex planning, beyond tested domains?
- Basis in paper: [inferred] Paper tests on math, QA, summarization, and multi-domain tasks, but does not explicitly address complex reasoning or planning tasks.
- Why unresolved: Current experiments focus on relatively straightforward tasks, leaving uncertainty about method's effectiveness on more complex reasoning challenges.
- What evidence would resolve it: Benchmarking method on tasks requiring multi-step reasoning, such as advanced mathematical proofs, strategic game playing, or complex decision-making scenarios.

## Limitations
- Scaling assumptions about logit distance invariance across model sizes remain empirically unverified beyond tested LLaMA2 model family
- Limited analysis of computational overhead from constrained optimization at each decoding step
- Strong performance claims on unseen tasks based on only one dataset (PubMedQA) without broader validation

## Confidence
- High Confidence: Experimental results showing performance improvements over baseline transfer methods are well-documented and reproducible
- Medium Confidence: Mathematical framework for KL divergence constrained optimization appears sound but depends on implementation details not fully specified
- Low Confidence: Claims about handling arbitrary task combinations and superiority in all multi-task scenarios lack sufficient empirical backing

## Next Checks
1. **Scaling Verification Test**: Conduct experiments transferring knowledge from 7B to 33B and 65B models to verify whether logit distance invariance assumption holds across wider range of model scales
2. **Computational Cost Analysis**: Measure and compare inference latency with varying numbers of expert models and different weight search granularity levels to quantify efficiency tradeoff
3. **Unseen Task Generalization**: Test method on diverse set of unseen tasks spanning multiple domains (e.g., code generation, creative writing, scientific reasoning) to validate generalization claims beyond single PubMedQA example