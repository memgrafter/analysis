---
ver: rpa2
title: Identifying Bias in Deep Neural Networks Using Image Transforms
arxiv_id: '2412.13079'
source_url: https://arxiv.org/abs/2412.13079
tags:
- accuracy
- images
- datasets
- bias
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method to identify hidden biases in CNN image
  classification by applying Fourier, wavelet, and median filter transforms to the
  images, combined with VGG16 classification. The method leverages the fact that these
  transforms affect contextual information and background artifacts differently.
---

# Identifying Bias in Deep Neural Networks Using Image Transforms

## Quick Facts
- **arXiv ID:** 2412.13079
- **Source URL:** https://arxiv.org/abs/2412.13079
- **Reference count:** 9
- **Primary result:** Wavelet transforms and median filtering can identify bias in CNN image classification by affecting natural and synthetic datasets differently

## Executive Summary
This paper proposes a method to identify hidden biases in CNN image classification by applying Fourier, wavelet, and median filter transforms to images before classification with VGG16. The transforms affect contextual information and background artifacts differently, allowing the method to distinguish bias-driven classification from contextually relevant classification. Experiments on natural, synthetic, and mixed datasets show that wavelet transforms and median filtering reduce accuracy on natural datasets while maintaining or improving accuracy on synthetic datasets, indicating the presence of bias.

## Method Summary
The method applies image transforms (Fourier transform, wavelet transforms including Haar and Daubechies, median filter with 5×5 window, and combinations) to images before training and testing a VGG16 CNN. The transforms affect contextual visual information differently than systemic background bias, allowing bias detection by comparing classification accuracy changes. The approach leverages the fact that these transforms affect contextual information and background artifacts differently. Datasets used include Imagenette (10 classes), Natural Images (8 classes), CT Scans (4 classes), COIL-20 (20 objects), Yale Faces (15 subjects), and Caltech 20 (20 classes). VGG16 is trained with 70%/15%/15% split, 40 epochs, and Adam optimizer.

## Key Results
- Wavelet transforms reduce accuracy on natural datasets (Imagenette: 59%→50%, Natural Images: 85%→72.8%) but maintain or improve accuracy on synthetic datasets (COIL-20: 100%→100%, Yale Faces: 70%→80%)
- Median filtering followed by wavelet transform enhances hidden bias signals
- Fourier transform reduces classification accuracy across all dataset types
- The method effectively identifies bias-driven classification without requiring blank background sub-images

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Wavelet transforms expose hidden bias signals in synthetic datasets while suppressing bias influence in natural datasets.
- **Mechanism:** Wavelet decomposition separates spatial and frequency information differently for synthetic (controlled) vs natural (variable) datasets, amplifying bias-related artifacts in synthetic data and attenuating them in natural data.
- **Core assumption:** Synthetic datasets contain systematic, repeatable background artifacts that are spatially localized, whereas natural datasets have more variable, distributed context.
- **Evidence anchors:** [abstract] "These transforms affect the contextual visual information in a different manner than it affects the systemic background bias." [section] "Wavelet findings indicate a notable decline in classification accuracy for natural datasets, while non-natural datasets have seen either consistent or improved accuracy rates."

### Mechanism 2
- **Claim:** Median filtering followed by wavelet transform enhances hidden bias signals by smoothing noise while preserving structural artifacts.
- **Mechanism:** Median filtering removes random noise while retaining systematic artifacts; subsequent wavelet transform then amplifies these artifacts for bias detection.
- **Core assumption:** Background bias in synthetic datasets manifests as structured artifacts rather than random noise.
- **Evidence anchors:** [abstract] "applying several image transforms to the original images, including Fourier transform, wavelet transforms, median filter, and their combinations." [section] "The wavelet transform highlights any hidden signals introduced during the image acquisition process."

### Mechanism 3
- **Claim:** Fourier transform reduces classification accuracy across all dataset types by disrupting spatial information patterns used by CNNs.
- **Mechanism:** Fourier transform converts spatial domain to frequency domain, disrupting the local spatial patterns that CNNs rely on for classification.
- **Core assumption:** CNNs are primarily sensitive to spatial rather than frequency domain information.
- **Evidence anchors:** [abstract] "This transformations affect the contextual visual information in a different manner than it affects the systemic background bias." [section] "applying the Fourier transform has reduced the classification accuracy of the CNN across all the datasets, both for the full images and for the cropped sub-images."

## Foundational Learning

- **Concept: Discrete Fourier Transform (DFT)**
  - **Why needed here:** Understanding how Fourier transform converts spatial to frequency domain is crucial for interpreting its effect on CNN classification.
  - **Quick check question:** What is the fundamental difference between spatial and frequency domain representations of an image?

- **Concept: Wavelet Transform**
  - **Why needed here:** Wavelet transforms provide both spatial and frequency information, which is key to understanding how they differentiate between natural and synthetic dataset biases.
  - **Quick check question:** How does a wavelet transform differ from a Fourier transform in terms of information preservation?

- **Concept: Median Filtering**
  - **Why needed here:** Median filtering is used to smooth images while preserving edges, which is important for understanding how it affects bias detection when combined with wavelet transforms.
  - **Quick check question:** What is the primary advantage of median filtering over linear filtering methods?

## Architecture Onboarding

- **Component map:** Input datasets -> Image transforms (Fourier, wavelet, median filter) -> VGG16 CNN -> Classification accuracy metrics
- **Critical path:** 1. Apply transforms to full images 2. Train and test VGG16 on transformed images 3. Compare classification accuracy with original images 4. Interpret accuracy changes to identify bias
- **Design tradeoffs:** Transform choice (Fourier affects all datasets, Wavelet differentiates dataset types, Median smooths noise), Transform combination (single vs. sequential application), Dataset representation (full images vs. background sub-images)
- **Failure signatures:** No accuracy change (transform not affecting bias signals), Similar accuracy changes across all dataset types (transform not differentiating between natural and synthetic biases), Decreased accuracy in all cases (transform removing useful information along with bias)
- **First 3 experiments:** 1. Apply Fourier transform to all datasets and measure accuracy changes 2. Apply Haar wavelet transform to all datasets and measure accuracy changes 3. Apply median filter followed by Daubechies wavelet transform and measure accuracy changes

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the proposed Fourier, wavelet, and median filter transforms be used to correct bias in addition to identifying it?
- **Basis in paper:** [explicit] The paper states the method can identify bias but does not correct it, and suggests future work could focus on bias removal using GANs.
- **Why unresolved:** The study only tested the transforms for bias identification, not correction. No experiments were done to determine if transformed images could be used to train less biased models.
- **What evidence would resolve it:** Experiments showing whether CNNs trained on transformed images have reduced bias compared to CNNs trained on original images, measured by classification accuracy on blank background sub-images.

### Open Question 2
- **Question:** Why do wavelet transforms improve classification accuracy on synthetic datasets like COIL-20 but decrease it on natural datasets?
- **Basis in paper:** [explicit] The paper observes this pattern but does not explain the underlying reason. It suggests wavelets may enhance hidden signals in synthetic datasets but doesn't elaborate.
- **Why unresolved:** The paper doesn't analyze the specific features that wavelets extract from each dataset type or why these features are beneficial for synthetic but not natural images.
- **What evidence would resolve it:** Analysis of the frequency content and spatial patterns in wavelet-transformed images from each dataset type, correlating these patterns with classification performance.

### Open Question 3
- **Question:** How does the size of the median filter window affect bias detection sensitivity?
- **Basis in paper:** [explicit] The paper mentions that window sizes up to 25×25 don't significantly affect results, but doesn't explore the relationship between window size and bias detection effectiveness.
- **Why unresolved:** The study only tested a 5×5 window and briefly mentions larger windows, without systematically varying window size to find optimal parameters for different dataset types.
- **What evidence would resolve it:** Experiments testing multiple window sizes (e.g., 3×3, 7×7, 11×11, 15×15, 21×21) on each dataset, measuring classification accuracy changes to determine the most sensitive window size for bias detection.

## Limitations
- The approach cannot correct identified biases - it only flags their presence, requiring additional steps for bias mitigation
- The transform-based method may not capture all types of dataset bias, particularly those encoded in frequency patterns
- Performance varies significantly across dataset types, suggesting the method may not generalize uniformly

## Confidence

- **High:** The method successfully identifies bias in synthetic datasets (COIL-20: 100%→100%, Yale Faces: 70%→80%)
- **Medium:** The differentiation between natural and synthetic dataset responses is reliable (Natural Images: 85%→72.8%, Imagenette: 59%→50%)
- **Low:** The method's effectiveness on mixed or real-world datasets remains unproven

## Next Checks

1. Test the method on additional mixed datasets containing both natural and synthetic elements to validate cross-dataset generalization
2. Compare results with alternative bias detection methods (e.g., image scrambling, activation analysis) to establish relative effectiveness
3. Implement and evaluate GAN-based bias removal techniques on datasets flagged as biased to assess practical remediation potential