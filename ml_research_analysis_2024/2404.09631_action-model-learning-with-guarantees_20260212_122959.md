---
ver: rpa2
title: Action Model Learning with Guarantees
arxiv_id: '2404.09631'
source_url: https://arxiv.org/abs/2404.09631
tags:
- action
- learning
- version
- space
- sound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses action model learning in fully observable
  settings, focusing on both sound (safe) and complete models. The authors propose
  a novel framework based on version spaces, where the precondition and effect of
  each action are learned by computing version spaces for their preconditions and
  effects, respectively.
---

# Action Model Learning with Guarantees

## Quick Facts
- arXiv ID: 2404.09631
- Source URL: https://arxiv.org/abs/2404.09631
- Authors: Diego Aineto; Enrico Scala
- Reference count: 5
- Primary result: Novel framework based on version spaces for learning sound and complete action models in fully observable settings

## Executive Summary
This paper introduces a novel framework for action model learning using version spaces to maintain compact representations of all consistent action models. The approach learns both preconditions and effects by computing version spaces for each, enabling online learning with convergence guarantees. The framework provides two types of models - sound models that guarantee safety and complete models that enable speculative planning - with experimental results showing their complementary strengths depending on domain characteristics and demonstration accessibility.

## Method Summary
The method uses a version space approach where preconditions and effects of each action are learned by computing version spaces for their preconditions and effects, respectively. An online algorithm called VSLAM maintains L and U boundaries in a partial order defined by set inclusion, pruning inconsistent hypotheses while preserving all solutions. Sound models are extracted using the intersection of all pre-states and union of all post-state deltas, while complete models use the loosest applicable precondition and most permissive effect set. The algorithm can detect convergence to the true model or identify noisy demonstrations.

## Key Results
- VSLAM maintains compact version space representations enabling efficient exploration of solution space
- Sound models guarantee all learned plans will work with the true model, while complete models allow speculation about plan existence
- Experimental results on multiple planning domains show better reasoning capabilities earlier in learning process
- No single model type dominates; performance depends on domain characteristics, learning stage, and demonstration accessibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The version space representation compactly encodes all consistent action models, enabling efficient exploration of the solution space.
- Mechanism: By maintaining L and U boundaries in a partial order defined by set inclusion, the algorithm prunes inconsistent hypotheses while preserving all solutions. The boundaries grow/shrink incrementally as new demonstrations arrive.
- Core assumption: The hypothesis space is finite and ordered by set inclusion, allowing version space compression via boundaries.
- Evidence anchors:
  - [abstract]: "Our theoretical findings are instantiated in an online algorithm that maintains a compact representation of all solutions of the problem."
  - [section 3]: Theorems 2 and 4 define precise update rules for L and U boundaries based on set operations.

### Mechanism 2
- Claim: Sound models are extracted by taking the intersection of all pre-states and the union of all post-state deltas, guaranteeing no invalid transitions.
- Mechanism: The lower boundary (L) of the precondition version space yields the tightest safe precondition; the lower boundary of the effect version space yields the tightest safe effect. Their combination ensures only transitions consistent with all demonstrations are allowed.
- Core assumption: Learning examples from demonstrations fully constrain the true model's preconditions and effects under conjunctive syntax.
- Evidence anchors:
  - [abstract]: "The pessimistic form leads to construct sound models, i.e., those never allowing the agent to take a wrong step as per the safe property studied by SAM."
  - [section 4]: Theorem 11 proves that using lower boundaries yields optimal sound models.

### Mechanism 3
- Claim: Complete models are extracted by taking the union of all possible preconditions and effects, guaranteeing coverage of all consistent transitions.
- Mechanism: The upper boundary (U) of the precondition version space yields the loosest applicable precondition; the union of all effect hypotheses yields the most permissive effect set. This allows speculation about potential plans beyond the observed demonstrations.
- Core assumption: The hypothesis space can express non-deterministic effects and disjunctive preconditions to capture completeness.
- Evidence anchors:
  - [abstract]: "The optimistic form leads to complete models, i.e., those with which an agent can speculate about the existence of a plan."
  - [section 4]: Theorem 12 proves that using upper boundaries yields optimal complete models.

## Foundational Learning

- Concept: Version spaces and hypothesis boundaries
  - Why needed here: They provide a principled way to maintain and update all consistent action models efficiently during online learning.
  - Quick check question: What do the L and U boundaries represent in a version space?

- Concept: Set operations for update rules
  - Why needed here: The algorithm uses intersections, unions, and set differences to update boundaries based on new demonstrations.
  - Quick check question: How does a positive demonstration update the L boundary of a precondition version space?

- Concept: Soundness vs completeness in planning
  - Why needed here: These properties define the safety and expressiveness of the learned models, guiding how boundaries are manipulated.
  - Quick check question: What is the trade-off between a sound model and a complete model?

## Architecture Onboarding

- Component map: Input parser -> Version space manager -> Update engine -> Model extractor -> Convergence detector
- Critical path:
  1. Parse demonstration -> generate learning examples
  2. Update version space boundaries via rules
  3. Check convergence/collapse
  4. Extract model when requested
- Design tradeoffs:
  - Memory vs speed: Maintaining full version spaces is expensive; boundaries compress representation
  - Expressiveness vs tractability: Conjunctive preconditions are easy to learn; disjunctive/non-deterministic require more complex handling
  - Soundness vs completeness: Conservative models are safe but may reject valid plans; speculative models allow more plans but may be invalid
- Failure signatures:
  - Version space collapse: Indicates noisy demonstrations or true model outside hypothesis space
  - Non-convergence: Indicates insufficient demonstrations to identify true model
  - Overly conservative models: Indicates missing positive demonstrations or overly strict hypothesis space
- First 3 experiments:
  1. Single action, single fluent: Verify boundaries update correctly with simple demonstrations
  2. Two actions, shared fluents: Test interaction between version spaces of different actions
  3. Noise injection: Add incorrect demonstrations and verify collapse detection

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the framework perform in domains with partial observability compared to the fully observable case?
  - Basis in paper: The paper mentions partial observability as a future direction and references related work (e.g., SLAF) that handles it, but does not evaluate it.
  - Why unresolved: The current framework is built specifically for full observability, and extending it to partial observability would require new theoretical developments and algorithmic modifications.
  - What evidence would resolve it: Empirical evaluation on benchmarks with partial observability, showing performance gains or limitations compared to the full observability case.

- **Open Question 2**: What is the impact of noisy demonstrations on the performance of the sound and complete models?
  - Basis in paper: The paper mentions that the algorithm can detect noisy demonstrations, but does not provide a detailed analysis of how noise affects the quality of the learned models.
  - Why unresolved: While the framework can handle noisy demonstrations, the extent of their impact on model accuracy and the trade-offs between sound and complete models in noisy settings are not fully explored.
  - What evidence would resolve it: Experiments varying the noise level in demonstrations and measuring the resulting f1-scores for both sound and complete models.

- **Open Question 3**: Can the framework be extended to handle action models with numeric state variables?
  - Basis in paper: The paper references Fox and Long (2003) for PDDL2.1, which supports numeric fluents, but the current framework is limited to Boolean state variables.
  - Why unresolved: Extending the framework to numeric fluents would require significant modifications to the hypothesis spaces and update rules, and the relationship with existing work on numeric action models is not fully explored.
  - What evidence would resolve it: A theoretical extension of the framework to numeric fluents, along with empirical evaluation on benchmarks involving numeric state variables.

## Limitations

- The framework's reliance on conjunctive preconditions and deterministic effects may limit applicability to domains requiring more expressive representations
- The version space approach assumes a finite hypothesis space, which may not scale to larger domains with many fluents
- Experimental validation uses modified IPC domains, raising questions about real-world applicability
- The paper doesn't address partial observability or continuous state spaces

## Confidence

- **High confidence**: The core version space framework and update rules are mathematically sound and well-established in machine learning theory
- **Medium confidence**: The soundness and completeness proofs for extracted models, given the assumptions about hypothesis space expressiveness
- **Low confidence**: The practical effectiveness in real-world domains beyond the modified IPC benchmarks

## Next Checks

1. Test VSLAM on a continuous state space domain to evaluate scalability and handling of non-finite hypothesis spaces
2. Implement version spaces with disjunctive preconditions and non-deterministic effects to assess expressiveness limitations
3. Compare VSLAM's performance against state-of-the-art action model learning approaches on unmodified IPC domains