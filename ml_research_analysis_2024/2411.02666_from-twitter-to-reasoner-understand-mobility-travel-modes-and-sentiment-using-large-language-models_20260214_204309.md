---
ver: rpa2
title: 'From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using
  Large Language Models'
arxiv_id: '2411.02666'
source_url: https://arxiv.org/abs/2411.02666
tags:
- travel
- social
- media
- modes
- mode
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a novel LLM-based framework for inferring\
  \ travel modes and sentiments from Twitter data without manual annotation. The framework\
  \ employs two LLM agents\u2014a reasoner that predicts travel modes and sentiments,\
  \ and a verifier that validates these predictions."
---

# From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using Large Language Models

## Quick Facts
- arXiv ID: 2411.02666
- Source URL: https://arxiv.org/abs/2411.02666
- Reference count: 36
- Key outcome: Novel LLM-based framework for inferring travel modes and sentiments from Twitter data without manual annotation, with GPT-3.5 outperforming other models

## Executive Summary
This study introduces a novel LLM-based framework for inferring travel modes and sentiments from Twitter data without manual annotation. The framework employs two LLM agentsâ€”a reasoner that predicts travel modes and sentiments, and a verifier that validates these predictions. Among the evaluated models, GPT-3.5 outperformed others, while in-context learning proved most effective as the prompting method. Analysis of NYC-based Twitter data revealed subway/metro as the most frequently mentioned travel mode, followed by bikes and private vehicles. The study found that negative sentiments were more prevalent than positive ones across all modes. Major dissatisfaction factors included subway delays, COVID-19 safety concerns, and incidents for subway users; bus service reliability issues; bike lane maintenance and safety concerns; and traffic violations and parking issues for vehicles. The research provides actionable recommendations for transportation operators and policymakers to address these concerns.

## Method Summary
The study employs a two-agent LLM framework consisting of a reasoner and a verifier. The reasoner predicts travel modes and sentiments from Twitter data, while the verifier validates these predictions. The framework was evaluated using GPT-3.5 and other LLMs with different prompting methods, finding that in-context learning was most effective. The methodology focuses on NYC-based Twitter data and does not require manual annotation, making it scalable for large-scale analysis of mobility patterns and user sentiments.

## Key Results
- GPT-3.5 outperformed other evaluated LLMs in predicting travel modes and sentiments
- In-context learning proved most effective as the prompting method
- Subway/metro was the most frequently mentioned travel mode in NYC-based Twitter data
- Negative sentiments were more prevalent than positive ones across all travel modes
- Major dissatisfaction factors included subway delays, COVID-19 safety concerns, and traffic violations

## Why This Works (Mechanism)
The framework leverages the advanced natural language understanding capabilities of LLMs to interpret unstructured social media data. By using two complementary agents (reasoner and verifier), the system can both generate predictions and validate them, reducing errors and improving accuracy. The in-context learning approach allows the model to learn from examples within the prompt, making it more adaptable to the informal language and context-specific references common in social media posts. The absence of manual annotation requirements enables large-scale analysis while maintaining reasonable accuracy through the verification step.

## Foundational Learning
- **In-context learning**: Why needed - Allows models to learn from examples without fine-tuning; Quick check - Verify prompt examples cover diverse travel scenarios
- **Dual-agent verification**: Why needed - Reduces false positives and improves prediction reliability; Quick check - Compare single vs. dual-agent accuracy rates
- **Sentiment classification**: Why needed - Essential for understanding user satisfaction levels; Quick check - Test model on sentiment-labeled datasets
- **Travel mode inference**: Why needed - Identifies transportation patterns from unstructured text; Quick check - Validate predictions against known travel datasets
- **Social media context**: Why needed - Twitter language differs from formal text; Quick check - Analyze informal language patterns in training examples
- **Geographic specificity**: Why needed - Transportation issues vary by location; Quick check - Test framework on data from multiple cities

## Architecture Onboarding

Component map: Twitter data -> Reasoner agent -> Verifier agent -> Travel mode predictions -> Sentiment analysis

Critical path: Data collection -> Preprocessing -> Reasoner prediction -> Verifier validation -> Result aggregation

Design tradeoffs: The framework prioritizes scalability over perfect accuracy by avoiding manual annotation, trading some precision for the ability to process large volumes of data. The dual-agent approach adds computational overhead but improves reliability. The NYC-specific focus limits generalizability but provides detailed insights for that context.

Failure signatures: Common failure modes include misinterpreting ambiguous travel references, confusing sentiment in sarcastic tweets, missing context about temporary service changes, and incorrectly categorizing multimodal journeys. The verifier agent helps catch some errors but may miss nuanced sentiment expressions.

Three first experiments:
1. Test the framework on a small manually annotated dataset to establish baseline accuracy
2. Compare GPT-3.5 performance against human annotators on the same dataset
3. Evaluate the impact of different prompt structures on prediction accuracy

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited generalizability to other geographic contexts and user demographics
- Absence of manual annotation validation raises accuracy concerns
- Does not address temporal variations in travel mode mentions or sentiment patterns

## Confidence
- High confidence in comparative performance findings between GPT-3.5 and other LLMs
- High confidence in in-context learning effectiveness as prompting method
- Medium confidence in travel mode frequencies and sentiment distributions
- Low confidence in specific dissatisfaction factors attributed to each travel mode

## Next Checks
1. Conduct manual annotation validation on a random sample of the dataset to establish ground truth accuracy rates
2. Test the framework on Twitter data from multiple cities with different transportation infrastructures to assess generalizability
3. Implement temporal analysis to identify variations in travel mode mentions and sentiment patterns across different time periods