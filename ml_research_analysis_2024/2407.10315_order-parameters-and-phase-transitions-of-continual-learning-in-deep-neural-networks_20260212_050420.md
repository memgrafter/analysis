---
ver: rpa2
title: Order parameters and phase transitions of continual learning in deep neural
  networks
arxiv_id: '2407.10315'
source_url: https://arxiv.org/abs/2407.10315
tags:
- task
- tasks
- learning
- forgetting
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper develops a statistical mechanics theory of continual
  learning (CL) in deep neural networks, identifying order parameters (OPs) that predict
  when and why CL fails due to catastrophic forgetting and anterograde interference.
  The authors model CL using a Gibbs formulation and derive analytical expressions
  for network performance in the infinite-width limit.
---

# Order parameters and phase transitions of continual learning in deep neural networks

## Quick Facts
- arXiv ID: 2407.10315
- Source URL: https://arxiv.org/abs/2407.10315
- Authors: Haozhe Shan; Qianyi Li; Haim Sompolinsky
- Reference count: 40
- Primary result: Statistical mechanics theory identifies order parameters that predict catastrophic forgetting and anterograde interference in continual learning, with phase transitions between overfitting and generalization regimes.

## Executive Summary
This paper develops a statistical mechanics theory of continual learning in deep neural networks, identifying order parameters that predict when and why CL fails due to catastrophic forgetting and anterograde interference. The authors model CL using a Gibbs formulation and derive analytical expressions for network performance in the infinite-width limit. For single-head CL, two order parameters—relevant-feature similarity and rule similarity—predict short-term forgetting and long-term forgetting dynamics. For multi-head CL, a third order parameter predicts a phase transition between overfitting and generalization regimes, where tasks become dissimilar and network load exceeds a threshold.

## Method Summary
The authors develop a statistical mechanics framework for continual learning by modeling the evolution of network weights as Gibbs sampling in the infinite-width limit. They compute kernel functions (Gaussian Process kernel, Neural Tangent Kernel, and derivative kernel) for task pairs to derive analytical expressions for order parameters that predict CL performance. The theory distinguishes between single-head CL (shared readout) and multi-head CL (task-specific readouts), deriving different order parameters and forgetting metrics for each case. The analytical predictions are validated against empirical results on benchmark task sequences including permuted MNIST, rotated MNIST, and split CIFAR.

## Key Results
- Two scalar order parameters (relevant-feature similarity and rule similarity) predict short-term forgetting in single-head CL
- A phase transition in multi-head CL occurs when tasks are dissimilar and network load exceeds a threshold, leading to zero forgetting but catastrophic anterograde interference
- Increasing network depth reduces forgetting by lowering task conflict between tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two scalar order parameters—relevant-feature similarity (γRF) and rule similarity (γrule)—predict short-term forgetting in single-head CL.
- Mechanism: These OPs quantify how much task rules project onto shared feature subspaces. Forgetting is proportional to γRF - γrule, which we call "conflict". Low conflict → low forgetting.
- Core assumption: In the infinite-width limit, learning dynamics can be approximated by sampling from a Gibbs posterior over weights.
- Evidence anchors:
  - [abstract]: "For networks with a shared readout for all tasks (single-head CL), the relevant-feature and rule similarity between tasks, respectively measured by two OPs, are sufficient to predict a wide range of CL behaviors."
  - [section 3.1]: Defines γRF and γrule and shows F2,1 = 2(γRF - γrule).
  - [corpus]: Weak—no neighbor papers mention these specific OPs.
- Break condition: Assumption fails if network width is not sufficiently large or if learning dynamics deviate significantly from Gibbs sampling.

### Mechanism 2
- Claim: A third order parameter γsim determines a phase transition in multi-head CL between overfitting and generalization regimes.
- Mechanism: γsim = γfeature + cos(V1, V2) - V1⊤P2V1/∥V1∥² captures overall task similarity. For α > 1, a critical αc = γsim⁻² separates regimes: below αc → zero forgetting but catastrophic anterograde interference; above αc → moderate forgetting and generalization.
- Core assumption: In the thermodynamic limit (P, N → ∞ with α = P/N ~ O(1)), the hidden layer representations can be approximated by Gaussian distributions with task-specific statistics.
- Evidence anchors:
  - [abstract]: "For networks with task-specific readouts (multi-head CL), the theory identifies a phase transition where CL performance shifts dramatically as tasks become less similar, as measured by another task-similarity OP."
  - [section 4.2]: Shows how γsim predicts αc and describes the overfitting regime with zero forgetting but divergent G2,2.
  - [corpus]: Missing—no neighbor papers discuss this phase transition.
- Break condition: Assumption fails if α is not in the thermodynamic regime or if the Gaussian approximation for hidden-layer statistics breaks down.

### Mechanism 3
- Claim: Increasing network depth reduces forgetting by lowering task conflict.
- Mechanism: Deeper networks transform input features into higher-level representations where task-relevant subspaces are more orthogonal, decreasing γRF and γrule and thus conflict.
- Core assumption: The feature transformation at layer L preserves task structure in a way that makes task rules more separable.
- Evidence anchors:
  - [abstract]: "In addition, the theory predicts that increasing the network depth can effectively reduce interference between tasks, thereby lowering forgetting."
  - [section 3.4]: Shows F2,1 monotonically decreases with depth for various benchmark sequences.
  - [corpus]: Weak—only "Phase Transitions between Accuracy Regimes in L2 regularized Deep Neural Networks" mentions depth effects but not in CL context.
- Break condition: Assumption fails if depth does not improve feature separation or if other architectural factors dominate forgetting.

## Foundational Learning

- Concept: Gibbs formulation of continual learning
  - Why needed here: Provides a principled probabilistic framework to model the evolution of network weights across tasks, enabling analytical treatment of forgetting dynamics.
  - Quick check question: In the Gibbs formulation, what role does the inverse temperature β play in controlling the trade-off between fitting the current task and preserving previous knowledge?

- Concept: Kernel methods and Neural Tangent Kernel (NTK)
  - Why needed here: Kernel functions capture how inputs are transformed through the network and how they relate across tasks, which is essential for deriving order parameters that predict CL performance.
  - Quick check question: How does the Neural Tangent Kernel differ from traditional kernel methods in its treatment of neural network training dynamics?

- Concept: Statistical mechanics and phase transitions
  - Why needed here: Identifies critical points (e.g., αc) where CL behavior changes qualitatively, providing insights into optimal architecture and regularization choices.
  - Quick check question: In the context of multi-head CL, what physical phenomenon corresponds to the phase transition between the overfitting and generalization regimes?

## Architecture Onboarding

- Component map:
  - Single-head CL: Shared readout + hidden layers with L2 regularization and perturbation penalty
  - Multi-head CL: Task-specific readouts + shared hidden layers with L2 regularization on hidden weights only
  - Order parameters: γRF, γrule (single-head); γsim (multi-head)

- Critical path:
  1. Define task sequence and generate datasets
  2. Compute kernel functions (GP, NTK, derivative kernel) for task pairs
  3. Calculate order parameters from kernel matrices
  4. Evaluate forgetting metrics using analytical expressions
  5. Adjust architecture (depth, width) or regularization (λ) based on OP predictions

- Design tradeoffs:
  - Single-head vs. multi-head: Single-head simpler but more prone to forgetting; multi-head mitigates forgetting but can suffer from anterograde interference in the overfitting regime
  - Width vs. depth: Increasing width reduces α and can push multi-head CL into the overfitting regime (zero forgetting); increasing depth reduces task conflict but may slow long-term forgetting decay
  - Regularization strength λ: Higher λ preserves old tasks better but may prevent new task learning; lower λ allows new learning but increases forgetting

- Failure signatures:
  - Single-head: High γRF - γrule (conflict) → high forgetting; low depth → high forgetting
  - Multi-head: α > αc with low γsim → overfitting regime (zero forgetting, catastrophic anterograde interference)
  - General: Misestimation of OPs due to insufficient data or incorrect kernel calculations

- First 3 experiments:
  1. Implement kernel function computation for a two-task sequence and verify analytical expressions for γRF and γrule
  2. Test the effect of increasing network depth on F2,1 for a permuted MNIST sequence
  3. Simulate multi-head CL with varying α and γsim to observe the overfitting vs. generalization phase transition

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical framework relies heavily on infinite-width limit and Gibbs sampling assumptions that may not hold for practical finite-width networks
- Kernel approximations used to compute order parameters may break down for highly nonlinear task relationships
- Theory does not account for potential interactions between regularization, architecture, and optimization algorithms beyond simple L2 regularization and perturbation penalty

## Confidence
- **High Confidence**: Mathematical derivation of order parameters and their relationship to forgetting metrics in the theoretical framework
- **Medium Confidence**: Predictions about how depth affects forgetting and the phase transition in multi-head CL, as these require empirical validation
- **Low Confidence**: Generalizability of the theory to scenarios outside the controlled benchmark tasks used in experiments, particularly for real-world applications with complex data distributions

## Next Checks
1. Implement the kernel-based order parameter calculations for a real-world continual learning dataset (e.g., CORe50) and compare predicted vs. actual forgetting rates
2. Test the depth effect predictions by systematically varying network depth for a sequence of diverse tasks (e.g., permuted MNIST, rotated MNIST, and split CIFAR) and measuring forgetting and generalization
3. Explore the phase transition in multi-head CL by designing tasks with controlled similarity (via γsim) and varying the network load (α) to observe the transition between overfitting and generalization regimes