---
ver: rpa2
title: Robustness of Explainable Artificial Intelligence in Industrial Process Modelling
arxiv_id: '2407.09127'
source_url: https://arxiv.org/abs/2407.09127
tags:
- methods
- these
- noise
- feature
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper evaluates the robustness of state-of-the-art eXplainable
  AI (XAI) methods under noise by using a simulated Electric Arc Furnace (EAF) process
  with known ground truth sensitivity. The authors propose a novel scoring methodology
  to compare XAI methods against the ground truth effects, addressing challenges in
  scaling and normalizing heterogeneous feature importance scores.
---

# Robustness of Explainable Artificial Intelligence in Industrial Process Modelling

## Quick Facts
- **arXiv ID**: 2407.09127
- **Source URL**: https://arxiv.org/abs/2407.09127
- **Reference count**: 27
- **Primary result**: Effect-based XAI methods (Smooth Gradients, ALE) outperform additive methods (LIME, SHAP) under noise in industrial process modeling

## Executive Summary
This paper investigates the robustness of state-of-the-art eXplainable AI (XAI) methods when applied to industrial process modeling under noisy conditions. The authors develop a novel evaluation methodology using a simulated Electric Arc Furnace (EAF) process with known ground truth sensitivity to compare different XAI approaches. Through systematic experiments with noise-perturbed datasets, they demonstrate that effect-based methods like Smooth Gradients and Averaged Local Effects maintain better performance in noisy environments compared to additive methods like LIME and SHAP, particularly when paired with high-performing models like LightGBM.

## Method Summary
The study introduces a novel scoring methodology to evaluate XAI methods by comparing their outputs against known ground truth effects from a simulated EAF process. The methodology addresses the challenge of normalizing heterogeneous feature importance scores from different XAI approaches. Experiments are conducted using various noise distributions applied to both the input features and the process outputs. The authors test multiple XAI methods including Smooth Gradients, ALE, LIME, and SHAP across different ML models, with LightGBM showing particularly strong performance. Random noise baselines are used to validate the evaluation approach.

## Key Results
- Effect-based methods (Smooth Gradients, ALE) demonstrate superior robustness to noise compared to additive methods (LIME, SHAP)
- The predictive performance of the underlying ML model strongly influences the correctness of XAI interpretations
- LightGBM paired with Smooth Gradients achieves the most accurate feature importance rankings under noisy conditions
- Random noise baselines confirm the validity of the proposed evaluation methodology

## Why This Works (Mechanism)
The paper's evaluation framework works by providing a controlled environment where ground truth feature sensitivities are known, allowing direct comparison between XAI methods. Effect-based methods capture the actual impact of feature variations on the output, while additive methods decompose predictions into individual feature contributions, making them more susceptible to noise distortion. The systematic noise injection and scoring methodology reveal how different XAI approaches handle perturbations in industrial process data.

## Foundational Learning

### EAF Process Simulation
**Why needed**: Provides controlled environment with known ground truth for XAI evaluation
**Quick check**: Verify simulation captures key physical relationships and parameter sensitivities of actual EAF processes

### Feature Importance Normalization
**Why needed**: Enables comparison across heterogeneous XAI methods with different output scales
**Quick check**: Test normalization on synthetic data where ground truth importance is predetermined

### Noise Modeling in Industrial Processes
**Why needed**: Industrial data contains various noise sources that affect XAI reliability
**Quick check**: Compare simulated noise characteristics against real industrial process measurement noise

## Architecture Onboarding

### Component Map
Simulated EAF Process -> Noise Injection -> ML Model Training -> XAI Method Application -> Ground Truth Comparison Scoring

### Critical Path
1. Generate simulated EAF process data with known sensitivities
2. Apply noise perturbations to create test datasets
3. Train ML models (LightGBM, etc.) on noisy data
4. Apply XAI methods to trained models
5. Score XAI outputs against ground truth using novel normalization methodology

### Design Tradeoffs
- Simulation accuracy vs. computational efficiency in EAF process modeling
- Noise realism vs. controlled experimental conditions
- Method comprehensiveness vs. evaluation complexity
- Ground truth fidelity vs. practical applicability

### Failure Signatures
- XAI methods showing inverted importance rankings
- Methods failing to distinguish between relevant and irrelevant features
- Inconsistent results across different noise levels or distributions
- High sensitivity to minor perturbations in input data

### 3 First Experiments
1. Test XAI methods on simple linear process where ground truth is analytically known
2. Apply methods to real industrial dataset with partially known process relationships
3. Evaluate method performance across different noise distributions (Gaussian, uniform, etc.)

## Open Questions the Paper Calls Out
None

## Limitations
- Single industrial case study limits generalizability to other process types
- Uncertainty about whether EAF simulation accurately captures real industrial variability
- Potential gap between simulated noise characteristics and actual process measurement noise
- Focus on static feature relationships may miss temporal dependencies in real processes

## Confidence
- **High**: Relative performance comparison between XAI methods under noise conditions
- **Medium**: Claim that predictive model performance influences XAI interpretation correctness
- **Low**: Generalizability of findings to industrial processes beyond EAF

## Next Checks
1. Test the same XAI methods on multiple industrial processes with different characteristics to assess generalizability
2. Validate the EAF simulation against actual industrial process data to ensure realistic noise characteristics
3. Extend the study to include time-series dependencies and temporal correlations that may exist in real industrial processes