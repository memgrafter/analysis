---
ver: rpa2
title: 'Patch-Based Encoder-Decoder Architecture for Automatic Transmitted Light to
  Fluorescence Imaging Transition: Contribution to the LightMyCells Challenge'
arxiv_id: '2406.01187'
source_url: https://arxiv.org/abs/2406.01187
tags:
- challenge
- images
- training
- architecture
- lightmycells
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors present a deep learning solution to automatically predict
  fluorescence microscopy images from label-free transmitted light inputs (bright
  field, phase contrast, or DIC), as part of the LightMyCells challenge. Their approach
  uses a patch-based encoder-decoder architecture (RUNet) trained separately for each
  organelle (nucleus, mitochondria, tubulin, actin) with a combined objective function
  (MSE, SSIM, PCC, CD).
---

# Patch-Based Encoder-Decoder Architecture for Automatic Transmitted Light to Fluorescence Imaging Transition: Contribution to the LightMyCells Challenge

## Quick Facts
- arXiv ID: 2406.01187
- Source URL: https://arxiv.org/abs/2406.01187
- Authors: Marek Wodzinski; Henning Müller
- Reference count: 0
- Primary result: Top performance in LightMyCells challenge using separate RUNet models per organelle with combined objective function

## Executive Summary
This paper presents a deep learning solution for predicting fluorescence microscopy images from label-free transmitted light inputs as part of the LightMyCells challenge. The authors develop a patch-based encoder-decoder architecture (RUNet) trained separately for each organelle (nucleus, mitochondria, tubulin, actin) using a combined objective function incorporating MSE, SSIM, PCC, and CD metrics. The approach achieved strong performance among challenge participants, with ablation studies demonstrating the importance of separate encoders per organelle, large patch sizes (512x512), and multi-objective training. Key design choices include metadata-informed training and patch assembly with Hann-window averaging to avoid artifacts.

## Method Summary
The method uses a patch-based encoder-decoder architecture (RUNet) trained separately for each of four organelles (nucleus, mitochondria, tubulin, actin). Input transmitted light microscopy images are normalized to [0-1] and split into 512x512 patches. Four separate RUNet models are trained with a combined objective function (MSE, SSIM, PCC, CD) with weights 1.0, 0.2, 0.1, 0.1 respectively. Training uses 80/20 train/validation split with data augmentation (flips for nucleus/mitochondria/tubulin, elastic transforms for actin) on a single NVIDIA A100 GPU. Outputs are assembled using patch-based processing with Hann-window averaging to avoid boundary artifacts.

## Key Results
- Top performance in LightMyCells challenge for transmitted light to fluorescence image translation
- Separate encoder-decoder architecture per organelle significantly outperforms shared encoder approach
- Large patch size (512x512) provides substantial improvement over smaller patches (128x128, 256x256) and direct resampling
- Combined objective function (MSE + SSIM + PCC + CD) improves overall performance compared to single objectives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separate encoder-decoder networks per organelle improve performance compared to shared encoders.
- Mechanism: Different organelles have distinct morphological and fluorescence patterns that benefit from dedicated feature learning.
- Core assumption: Organelle characteristics are sufficiently heterogeneous to warrant specialized models.
- Evidence anchors:
  - [abstract] "The experiments related to the influence of training strategy are presented in Table 1b). The Table presents significant improvement by using the traditional RUNet architecture compared to UNETR, SwinUNETR, or Attention UNet."
  - [section] "The ablation study related to the influence of training strategy is presented in Table 1b). The study confirms that the use of separate encoder-decoder architecture results in better performance than the shared encoder approach, even though the shared encoder has more than twice as many parameters as the final solution."

### Mechanism 2
- Claim: Patch-based processing with large patch sizes (512x512) outperforms direct image resampling and smaller patches.
- Mechanism: Large patches preserve spatial context and local details while providing natural data augmentation through patch extraction.
- Core assumption: Spatial relationships and local patterns are crucial for accurate fluorescence prediction.
- Evidence anchors:
  - [abstract] "The influence of patch size is reported in Table 1d). It can be noted that small patch sizes (128x128, 256x256) result in significantly worse results compared to the larger patch size (512x512)."
  - [section] "The use of the patch-based approach significantly improves the results compared to direct resampling (p-value < 0.01). Resampling the images into single resolution decreases the ability to recover small details and results in instant overfitting because the patch-based approach serves as a natural augmentation strategy."

### Mechanism 3
- Claim: Combining multiple objective functions (MSE, SSIM, PCC, CD) improves model performance compared to single objectives.
- Mechanism: Different objective functions capture different aspects of image quality - MSE measures pixel-level accuracy, SSIM captures structural similarity, PCC measures correlation, and CD measures angular difference.
- Core assumption: No single objective function adequately captures all aspects of image quality needed for this task.
- Evidence anchors:
  - [abstract] "Finally, the effect of combining the objective function is presented in Table 1e). It can be seen that the usage of combined objective function overall improves the average performance, and for SSIM and PCC sometimes even improves the absolute outcomes."
  - [section] "It can be seen that the usage of combined objective function overall improves the average performance, and for SSIM and PCC sometimes even improves the absolute outcomes. It suggests that the use of the combined objective function somehow improves generalizability or decreases the risk of reaching local minima."

## Foundational Learning

- Concept: Encoder-decoder architectures for image-to-image translation
  - Why needed here: The task requires converting transmitted light microscopy images to fluorescence images, which is fundamentally an image-to-image translation problem.
  - Quick check question: What is the primary difference between an encoder-decoder architecture and a standard classification CNN?

- Concept: Transfer learning and domain adaptation
  - Why needed here: The model needs to learn to generate fluorescence images from transmitted light inputs, which are different domains requiring learned mapping.
  - Quick check question: How does transfer learning help when training data is limited or heterogeneous?

- Concept: Objective function design and multi-task learning
  - Why needed here: The ablation studies show that combining multiple objectives (MSE, SSIM, PCC, CD) improves performance, indicating the importance of well-designed loss functions.
  - Quick check question: Why might combining multiple objective functions lead to better generalization than using a single objective?

## Architecture Onboarding

- Component map: Transmitted light image → Patch extraction (512x512) → RUNet encoder → RUNet decoder → Output patch → Patch assembly with Hann-window averaging → Predicted fluorescence image

- Critical path: Image preprocessing → Patch extraction → Encoder → Decoder → Output patch → Patch assembly → Final fluorescence image

- Design tradeoffs:
  - Separate models per organelle vs. shared encoder: More parameters but better specialization vs. parameter efficiency but potential confusion between organelle patterns
  - Large patches (512x512) vs. smaller patches: Better context preservation vs. computational efficiency
  - Combined objective functions vs. single objective: More comprehensive training signal vs. simpler optimization landscape

- Failure signatures:
  - Poor performance on specific organelles: May indicate need for more specialized architecture or additional training data
  - Artifacts at patch boundaries: Could suggest issues with patch assembly or windowing
  - Overfitting to specific studies: May require better study-based sampling or data augmentation

- First 3 experiments:
  1. Compare performance with different patch sizes (128x128, 256x256, 512x512) to validate the importance of spatial context
  2. Test shared encoder architecture vs. separate encoders to quantify the benefit of specialization
  3. Evaluate different objective function combinations (MSE only, SSIM only, combined) to determine optimal training signal

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does incorporating metadata during inference (e.g., physical pixel size, imaging modality) quantitatively affect the model's performance, particularly for underrepresented cases like actin in DIC or tubulin in BF?
- Basis in paper: [explicit] The authors propose this as future work, noting it could improve results especially for less represented cases.
- Why unresolved: Time constraints during the competition prevented testing this approach.
- What evidence would resolve it: Experimental results comparing model performance with and without metadata-informed inference on the full test set.

### Open Question 2
- Question: Would further dividing the dataset by imaging modality (BF, DIC, PC) and training separate models for each modality improve overall performance despite the risk of overfitting due to limited data?
- Basis in paper: [explicit] The authors suggest this could further increase accuracy but acknowledge the risk of overfitting due to sparse annotations.
- Why unresolved: The authors did not test this approach due to concerns about overfitting and limited data, particularly for actin and tubulin.
- What evidence would resolve it: Comparative performance metrics (MAE, SSIM, PCC, CD) between modality-specific models and the current single-model approach.

### Open Question 3
- Question: What is the optimal patch size for balancing computational efficiency and prediction accuracy in this encoder-decoder architecture, and how does this vary across different organelles?
- Basis in paper: [explicit] The authors found 512x512 patches optimal compared to 256x256 or 128x128, but resampling to 1024x1024 was worse.
- Why unresolved: While the authors tested several patch sizes, the analysis focused on fixed sizes without exploring a continuous range or organelle-specific optimization.
- What evidence would resolve it: Systematic evaluation of prediction accuracy and computational cost across a range of patch sizes for each organelle individually.

## Limitations
- Separate encoder-decoder architecture per organelle requires four times the model parameters compared to a shared architecture
- Training data exhibits significant heterogeneity across different studies, potentially limiting generalization
- Ablation studies limited to RUNet framework without exploring alternative architectures like transformers

## Confidence
- High confidence: Large patch sizes (512x512) outperform smaller patches and direct resampling with statistical significance
- Medium confidence: Separate encoder-decoder networks per organelle improve performance over shared encoders
- Medium confidence: Combined objective functions provide better generalization than single objectives

## Next Checks
1. Test trained models on fluorescence prediction tasks from different microscopy modalities or cell types not represented in training data
2. Quantify trade-off between separate organellar models and shared encoder architecture by measuring performance metrics and inference time/memory requirements
3. Implement and evaluate transformer-based architectures (UNETR, SwinUNETR) using the same training protocol to verify RUNet superiority claims