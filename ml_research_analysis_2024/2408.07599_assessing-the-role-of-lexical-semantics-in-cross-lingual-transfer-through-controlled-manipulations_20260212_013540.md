---
ver: rpa2
title: Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled
  Manipulations
arxiv_id: '2408.07599'
source_url: https://arxiv.org/abs/2408.07599
tags:
- language
- english
- word
- each
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines how linguistic properties influence cross-lingual
  transfer by systematically manipulating English to mimic target languages and measuring
  the resulting alignment quality with an English representation space. The study
  isolates three properties: script, word order, and lexical semantics.'
---

# Assessing the Role of Lexical Semantics in Cross-lingual Transfer through Controlled Manipulations

## Quick Facts
- arXiv ID: 2408.07599
- Source URL: https://arxiv.org/abs/2408.07599
- Reference count: 36
- One-line primary result: Lexical semantics have the greatest impact on cross-lingual transfer quality, with word order and script showing minimal effects

## Executive Summary
This paper systematically investigates how linguistic properties influence cross-lingual transfer effectiveness by creating artificial languages through controlled manipulations of English. The study isolates three properties—script, word order, and lexical semantics—and measures their impact on alignment quality with an English representation space. Through knowledge distillation experiments using sentence transformers, the authors find that lexical semantics differences are the primary driver of transfer quality degradation, while script and word order changes have minimal impact. The paper introduces translation entropy as a measure of lexical divergence, showing strong negative correlation with alignment quality. These findings suggest that lexicalization differences between languages are more crucial than other linguistic factors for cross-lingual transfer performance.

## Method Summary
The study employs a knowledge distillation framework where a teacher model (all-mpnet-base-v2) provides English sentence representations, and student models (RoBERTa variants with mean-pooling layers) learn to map target language sentences into this space. The researchers systematically manipulate English text through three controlled interventions: script substitution using character mapping, word reordering using an algorithm from Arviv et al. (2023), and lexical swapping that replaces English words with target language words while preserving sentence structure. Translation entropy is calculated to quantify lexical divergence, and alignment quality is evaluated using cosine similarity between English and manipulated sentence embeddings, along with zero-shot XNLI accuracy. The experiments use parallel corpora from TED-2020, CC-100, Europarl, UM, and XNLI datasets.

## Key Results
- Lexical semantics manipulation causes the most significant degradation in cross-lingual transfer performance compared to script and word order changes
- Translation entropy shows strong negative correlation with alignment quality across all manipulation types
- Student models trained on manipulated data show decreased zero-shot XNLI accuracy proportional to lexical divergence
- Script substitution and word reordering manipulations have minimal impact on transferability compared to lexical semantics changes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lexical semantics differences have the greatest impact on cross-lingual transfer quality.
- Mechanism: The study systematically replaces English lexicon with target language words while preserving sentence structure, revealing that lexical divergence degrades alignment more than script or word order changes.
- Core assumption: The student model learns to map sentences into the teacher's representation space; when lexical mappings are not one-to-one, this alignment quality degrades.
- Evidence anchors:
  - [abstract] "finds that lexical semantics have the greatest impact on transferability, with word order and script showing minimal effects"
  - [section] "We swap words from the English lexicon with words from the target lexicon and observe a substantial degradation in performance"
- Break condition: If the word alignment quality is extremely high (near one-to-one mapping), lexical manipulation may not degrade performance significantly.

### Mechanism 2
- Claim: Translation entropy serves as a reliable predictor of alignment quality.
- Mechanism: By calculating the entropy of word translation distributions in the bipartite graph, the study shows that higher entropy (more varied translations) correlates with worse alignment quality.
- Core assumption: The entropy measure captures the degree of lexical mismatch between languages, and this mismatch directly impacts the student model's ability to learn consistent mappings.
- Evidence anchors:
  - [abstract] "translation entropy as a measure of lexical divergence, showing strong negative correlation with alignment quality"
  - [section] "We observe a robust negative correlation between the entropy of the words we swap and the similarity scores"
- Break condition: If the parallel corpus is too small or noisy, the entropy measure may not accurately reflect true lexical divergence.

### Mechanism 3
- Claim: Knowledge distillation with sentence transformers is an effective method for cross-lingual transfer.
- Mechanism: The teacher model provides English sentence representations, and the student model learns to map target language sentences into this space through contrastive learning on parallel data.
- Core assumption: The teacher model's representation space captures semantic information that can be transferred to other languages when the student model is properly aligned.
- Evidence anchors:
  - [section] "follow a similar setup" and "We follow the distillation method proposed by Reimers and Gurevych (2020)"
  - [section] "The pretrained representations of the teacher model serve us throughout the experiment as ground truth"
- Break condition: If the student model architecture is too small or the parallel data is insufficient, the distillation process may fail to achieve good alignment.

## Foundational Learning

- Concept: Information theory and entropy
  - Why needed here: Understanding how translation entropy measures lexical divergence is crucial for interpreting the results
  - Quick check question: How does the entropy formula in equation (2) capture the uncertainty in word translations?

- Concept: Knowledge distillation in neural networks
  - Why needed here: The entire experimental setup relies on distilling knowledge from a teacher model to student models across languages
  - Quick check question: What is the purpose of the cosine embedding loss in equation (1)?

- Concept: Cross-lingual representation learning
  - Why needed here: The study investigates how well representations transfer across languages, which requires understanding multilingual embedding spaces
  - Quick check question: Why would changing the script of English text have minimal impact on cross-lingual transfer performance?

## Architecture Onboarding

- Component map:
  - Teacher model (all-mpnet-base-v2) -> English sentence representations
  - Student models (RoBERTa variants) -> Target language to English space mapping
  - Data pipeline (TED-2020, CC-100, Europarl, UM, XNLI) -> Parallel corpus processing and tokenization
  - Simalign aligner -> Bilingual word alignments
  - Weighted bipartite graph -> Lexical mapping construction
  - Manipulation modules -> Script substitution, word reordering, lexical swapping
  - Evaluation metrics -> ACS scores, XNLI accuracy, translation entropy

- Critical path:
  1. Extract bilingual word alignments using SimAlign
  2. Build weighted bipartite graph of lexical mappings
  3. Apply lexical manipulation to create artificial languages
  4. Train student models using knowledge distillation
  5. Evaluate alignment quality and zero-shot performance

- Design tradeoffs:
  - Smaller student models (6 layers, 6 heads) work well for low-resource scenarios but may limit capacity
  - Using automatic aligners vs. manual alignments balances scalability with alignment quality
  - Filtering graph edges by weight reduces noise but may remove valid rare alignments

- Failure signatures:
  - Low cosine similarity scores indicate poor alignment quality
  - High translation entropy values predict poor transfer performance
  - Inconsistent word alignments suggest data quality issues

- First 3 experiments:
  1. Train student models on English using different dataset sizes to establish baseline performance
  2. Apply script substitution manipulation and measure performance degradation
  3. Apply word reordering manipulation and compare results across different target languages

## Open Questions the Paper Calls Out

The paper acknowledges several limitations and open questions:

- The potential impact of a representation space that is not tailored to a particular language could be substantial, as all experiments use a monolingual teacher model
- The study focuses on three properties (script, word order, and lexical semantics) but acknowledges that other linguistic factors may also influence cross-lingual transfer
- The systematic replacement of lexicon creates highly regular patterns that may not fully capture real-world lexical divergence found in naturally occurring parallel corpora

## Limitations

- The study's findings rely heavily on artificial language constructs that may not fully capture real-world complexity and lexical divergence
- The translation entropy measure is computed from automatic word alignments that may contain errors, particularly for low-resource language pairs or languages with complex morphology
- The focus on Indo-European languages for most experiments limits generalizability to typologically distant language families

## Confidence

**High Confidence:** The finding that lexical semantics manipulation causes the most significant degradation in cross-lingual transfer performance. This is directly observable from the systematic experiments and supported by multiple evaluation metrics (ACS scores, XNLI accuracy).

**Medium Confidence:** The translation entropy measure as a reliable predictor of alignment quality. While the correlation is robust within the study's controlled settings, its effectiveness in real-world scenarios with noisy or limited parallel data remains to be validated.

**Low Confidence:** The conclusion that word order and script changes have minimal impact on transferability. This finding is based on the specific manipulation methods used and may not generalize to all languages or manipulation approaches.

## Next Checks

1. **Real-world parallel corpus validation:** Apply the translation entropy measure to naturally occurring parallel corpora across diverse language pairs, comparing predicted alignment quality with actual transfer performance to validate the entropy correlation in realistic settings.

2. **Typological diversity expansion:** Replicate key experiments with language pairs from different families (e.g., English-Japanese, English-Arabic) to test whether the lexical semantics primacy holds for languages with fundamentally different morphological and syntactic structures.

3. **Alternative manipulation protocols:** Implement different lexical substitution strategies (e.g., using contextual embeddings to find semantic equivalents rather than one-to-one mappings) to determine if the observed lexical impact persists under alternative controlled manipulation methods.