---
ver: rpa2
title: 'IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic
  Textual Relatedness in Multilingual Texts'
arxiv_id: '2404.04513'
source_url: https://arxiv.org/abs/2404.04513
tags:
- relatedness
- languages
- semantic
- sentence
- sentences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper presents IITK''s participation in SemEval-2024 Task
  1: Semantic Textual Relatedness, focusing on developing a system to automatically
  detect the degree of relatedness between pairs of sentences in 14 languages, including
  both high and low-resource Asian and African languages. The authors propose a BERT-based
  contrastive learning approach with a similarity metric for the supervised task and
  explore autoencoders for the unsupervised task.'
---

# IITK at SemEval-2024 Task 1: Contrastive Learning and Autoencoders for Semantic Textual Relatedness in Multilingual Texts

## Quick Facts
- arXiv ID: 2404.04513
- Source URL: https://arxiv.org/abs/2404.04513
- Reference count: 1
- Primary result: IITK's system uses Distil-RoBERTa with contrastive learning for supervised semantic relatedness and BERT-uncased denoising autoencoders for unsupervised relatedness across 14 languages, achieving reasonable performance but below baseline for some low-resource languages.

## Executive Summary
This paper presents IITK's participation in SemEval-2024 Task 1: Semantic Textual Relatedness, focusing on developing a system to automatically detect the degree of relatedness between pairs of sentences in 14 languages, including both high and low-resource Asian and African languages. The authors propose a BERT-based contrastive learning approach with a similarity metric for the supervised task and explore autoencoders for the unsupervised task. They also create a bigram relatedness corpus using negative sampling strategy to produce refined word embeddings. The results show that the contrastive learning approach did not perform well for some languages, such as Hausa, Moroccan Arabic, Telugu, etc., falling below the baseline scores. However, the unsupervised approach performed reasonably well for most languages, with correlation scores higher than the baseline provided.

## Method Summary
The paper proposes a BERT-based contrastive learning approach for the supervised semantic relatedness task and an autoencoder-based approach for the unsupervised task. For the supervised task, the system uses Distill-RoBERTa as the base model and employs a composite lexical similarity-based measure for relatedness score calculation. The authors experiment with various metrics like cosine similarity, Mahalanobis distance, Euclidean and Manhattan distances, and lexical overlap-based metrics like Jaccard and Dice coefficients. They train a 3-layered feed-forward neural network with GeLU activation to combine these metrics. For the unsupervised task, the system utilizes a BERT-uncased denoising autoencoder and creates a bigram relatedness corpus using a negative sampling strategy to generate word embeddings.

## Key Results
- Contrastive learning approach performed below baseline for some languages (Hausa, Moroccan Arabic, Telugu) in the supervised task.
- Autoencoder-based approach achieved correlation scores higher than baseline for most languages in the unsupervised task.
- The system successfully handled 14 languages, including low-resource Asian and African languages.

## Why This Works (Mechanism)
The paper's approach combines the strengths of contrastive learning for supervised tasks and autoencoders for unsupervised tasks. Contrastive learning helps the model learn to distinguish between semantically related and unrelated sentence pairs, while autoencoders can capture the underlying structure of the data without explicit supervision. The use of a composite lexical similarity-based measure allows the model to leverage multiple metrics for a more robust relatedness score calculation.

## Foundational Learning
- Contrastive learning: A technique for learning representations by comparing similar and dissimilar pairs. Needed for the supervised task to distinguish related from unrelated sentence pairs.
- Autoencoders: Neural networks that learn to reconstruct their input, often used for unsupervised learning. Needed for the unsupervised task to capture the underlying structure of the data.
- Lexical similarity metrics: Measures of the similarity between words or sentences based on their lexical content. Needed to create a composite measure for relatedness score calculation.
- Negative sampling: A technique for creating negative examples in training data by randomly sampling from the non-positive class. Needed for generating the bigram relatedness corpus.
- Multilingual NLP: The application of natural language processing techniques to multiple languages. Needed to handle the diverse set of languages in the dataset.
- Spearman Rank Correlation: A non-parametric measure of rank correlation. Needed to evaluate the performance of the system against the gold standard relatedness scores.

## Architecture Onboarding

### Component Map
SemEval-2024 Task 1 dataset -> Preprocessing -> Supervised track (Distil-RoBERTa + composite lexical similarity) OR Unsupervised track (BERT-uncased denoising autoencoder + bigram relatedness corpus)

### Critical Path
1. Preprocess the dataset (tokenization, stopword removal, POS tagging)
2. For supervised task: Fine-tune Distil-RoBERTa and train the composite measure
3. For unsupervised task: Create bigram relatedness corpus and train autoencoder
4. Evaluate performance using Spearman Rank Correlation

### Design Tradeoffs
- Supervised vs. unsupervised: The authors chose to explore both approaches to handle cases where labeled data might be scarce.
- Composite measure: Using multiple metrics allows for a more robust relatedness score but increases model complexity.
- Bigram relatedness corpus: Creating a separate corpus for word embeddings helps in the unsupervised task but requires additional data and processing.

### Failure Signatures
- Poor performance on low-resource languages: The model may not generalize well to languages with limited training data.
- Overfitting: The model may overfit to the training data, leading to poor performance on unseen examples.
- Suboptimal metric combination: The composite measure may not effectively combine the individual metrics, leading to suboptimal relatedness scores.

### First Experiments
1. Fine-tune Distil-RoBERTa on a small subset of the training data and evaluate its performance.
2. Create a small bigram relatedness corpus and train a simple autoencoder to assess its potential.
3. Experiment with different combinations of the individual metrics in the composite measure to find the most effective combination.

## Open Questions the Paper Calls Out
1. How does the performance of the contrastive learning approach compare to other supervised methods (e.g., fine-tuning BERT, using different loss functions) on the multilingual semantic relatedness task?
2. What are the specific challenges and limitations of applying the NGD metric to low-resource languages, and how can these be addressed?
3. How does the performance of the autoencoders-based approach for unsupervised semantic relatedness compare to other unsupervised methods (e.g., using static embeddings, clustering) on the multilingual dataset?

## Limitations
- The contrastive learning approach performed below baseline for some low-resource languages, indicating potential limitations in cross-lingual generalization.
- The unsupervised approach, while performing reasonably well overall, may not capture complex semantic relationships as effectively as supervised methods.
- The creation and utilization of a bigram relatedness corpus using negative sampling strategy is not fully detailed, which may affect reproducibility.

## Confidence
- High: The general methodology of using Distil-RoBERTa for supervised learning and BERT-uncased denoising autoencoder for unsupervised learning.
- Medium: The effectiveness of the composite lexical similarity-based measure for relatedness score calculation.
- Low: The specific implementation details of the bigram relatedness corpus creation and its impact on word embedding quality.

## Next Checks
1. Conduct a detailed error analysis for languages where the supervised approach performed below baseline to identify specific challenges in cross-lingual semantic understanding.
2. Compare the performance of the proposed composite lexical similarity-based measure against traditional semantic similarity metrics on a subset of the data to validate its effectiveness.
3. Investigate the impact of different negative sampling strategies in the bigram relatedness corpus creation on the quality of generated word embeddings and subsequent relatedness scores.