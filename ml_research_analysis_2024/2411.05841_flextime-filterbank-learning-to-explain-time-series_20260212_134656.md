---
ver: rpa2
title: 'FLEXtime: Filterbank learning to explain time series'
arxiv_id: '2411.05841'
source_url: https://arxiv.org/abs/2411.05841
tags:
- time
- flextime
- frequency
- series
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining time series predictions,
  which are often complex and difficult to interpret in the time domain. Existing
  methods focus on learning saliency masks over time steps, but these approaches struggle
  when important information is localized in the frequency domain.
---

# FLEXtime: Filterbank learning to explain time series

## Quick Facts
- arXiv ID: 2411.05841
- Source URL: https://arxiv.org/abs/2411.05841
- Authors: Thea Brüsch; Kristoffer K. Wickstrøm; Mikkel N. Schmidt; Robert Jenssen; Tommy S. Alstrøm
- Reference count: 40
- Primary result: FLEXtime achieves best average rank across faithfulness, smoothness, and robustness metrics on synthetic and real datasets

## Executive Summary
FLEXtime addresses the challenge of explaining time series predictions by learning saliency maps over interpretable frequency bands rather than time steps. Traditional saliency methods struggle when important information is localized in the frequency domain, so FLEXtime uses a bank of bandpass filters to decompose signals into frequency bands and learns which combination best explains model predictions. The method is evaluated against six baselines on synthetic and real datasets including AudioMNIST, PAM, Epilepsy, ECG, and SleepEDF, consistently outperforming all baselines across multiple evaluation metrics.

The method's key innovation is decomposing time series into interpretable frequency components using filterbanks, then learning a sparse saliency mask over these bands. This approach provides more stable and interpretable explanations compared to directly masking frequency components in the Fourier domain, as it avoids artifacts introduced by ideal filter discontinuities. FLEXtime's objective function combines distortion minimization with sparsity regularization to produce explanations that are both faithful to model predictions and parsimonious.

## Method Summary
FLEXtime learns saliency maps over interpretable frequency bands by decomposing time series using a bank of bandpass filters, then optimizing a mask that identifies which frequency bands are most important for model predictions. The method minimizes a rate-distortion objective that balances explanation fidelity (cross-entropy loss) with sparsity (ℓ1-norm regularization), producing explanations that are both faithful and interpretable. The learned mask is applied to the frequency components to identify salient bands, which are then mapped back to the time domain for visualization and interpretation.

## Key Results
- FLEXtime achieves 0.90 AUPRC on synthetic dataset compared to 0.62 for second-best method
- Consistently outperforms all baselines across multiple metrics: faithfulness (0.968 mean true class probability), smoothness (4.11 average total variation), and robustness (11.89 log ROS)
- Successfully identifies known frequency markers for different sleep stages in SleepEDF dataset
- Best average rank across all evaluation metrics compared to six competing methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FLEXtime outperforms traditional saliency methods because it explains time series in the frequency domain rather than the time domain, where salient information is often localized.
- Mechanism: The method decomposes the time series using a bank of bandpass filters to split the signal into frequency bands, then learns a saliency mask over these interpretable frequency components.
- Core assumption: Salient information in many time series is localized in specific frequency bands rather than individual time steps.
- Evidence anchors:
  - [abstract] "many types of time series are difficult to interpret in the time domain, due to the inherently complex nature of the data"
  - [section] "Instead, we propose to view time series explainability as saliency maps over interpretable parts, leaning on established signal processing methodology on signal decomposition"
- Break condition: If the time series data does not contain salient information in the frequency domain, or if the bandpass filterbank fails to capture the relevant frequency components.

### Mechanism 2
- Claim: FLEXtime's filterbank approach provides more stable and interpretable explanations compared to directly masking frequency components in the Fourier domain.
- Mechanism: By using bandpass filters instead of directly zeroing out Fourier coefficients, FLEXtime avoids artifacts introduced by ideal filter discontinuities (Gibbs phenomenon) and provides smoother saliency maps.
- Core assumption: Directly zeroing frequency components introduces signal artifacts that make explanations less interpretable.
- Evidence anchors:
  - [section] "We therefore believe future work should investigate how to properly quantify and balance different qualities when building new explainability methods for time series"
  - [corpus] "limited insights as semantically meaningful features are often found in other domains"
- Break condition: If the filterbank design parameters (number of filters, filter length) are poorly chosen, leading to either too coarse or too fine frequency resolution.

### Mechanism 3
- Claim: The combination of distortion minimization and sparsity regularization in FLEXtime's objective function produces explanations that are both faithful to the model's predictions and parsimonious.
- Mechanism: The objective function combines cross-entropy loss (measuring distortion) with ℓ1-norm regularization (promoting sparsity) to learn a mask that optimally explains the model's prediction while minimizing the number of active frequency bands.
- Core assumption: A good explanation should be both accurate (faithful to the model) and simple (sparse).
- Evidence anchors:
  - [section] "Combining the minimization of D with the maximization of the sparsity of M through R allows us to define the optimization objective"
  - [section] "For an optimal mask M that has identified all salient information, we expect ŷM ≈ ŷ"
- Break condition: If the trade-off parameter λ is poorly tuned, leading to either overly complex or insufficiently faithful explanations.

## Foundational Learning

- Concept: Signal decomposition using filterbanks
  - Why needed here: FLEXtime relies on decomposing time series into frequency bands to learn interpretable explanations
  - Quick check question: How does a bandpass filterbank differ from the discrete Fourier transform in terms of signal representation?

- Concept: Rate-distortion optimization
  - Why needed here: The method uses a rate-distortion framework to balance explanation fidelity with sparsity
  - Quick check question: What is the relationship between the distortion term and the rate term in the optimization objective?

- Concept: Saliency map evaluation metrics
  - Why needed here: The paper evaluates FLEXtime using multiple metrics including faithfulness, complexity, smoothness, and robustness
  - Quick check question: Why might an explanation with low complexity still be uninformative if it lacks faithfulness?

## Architecture Onboarding

- Component map: Input time series → Filterbank decomposition → Mask learning via gradient descent → Masked signal reconstruction → Model prediction → Loss computation → Mask update
- Critical path: The filterbank design and mask optimization are the most critical components; poor filterbank design will directly impact explanation quality
- Design tradeoffs: Filterbank parameters (number of filters, filter length) versus computational complexity and frequency resolution
- Failure signatures: Poor faithfulness scores indicate the mask is not capturing relevant features; high complexity with low faithfulness indicates overfitting; poor smoothness indicates the learned mask is too fragmented
- First 3 experiments:
  1. Implement a simple FIR filterbank with 32 filters and test on a synthetic dataset with known frequency patterns
  2. Compare FLEXtime's explanations against direct Fourier masking on a simple sinusoidal signal
  3. Evaluate the effect of the sparsity threshold parameter on explanation quality using the synthetic dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FLEXtime vary when using different filter bank designs beyond the equally-spaced FIR filters explored in the paper?
- Basis in paper: [explicit] The authors note that future work should investigate the effect of perfect reconstruction filterbanks and tailored filterbanks for different domains.
- Why unresolved: The paper only evaluates FLEXtime using equally-spaced FIR filterbanks, leaving open the question of how other filter bank designs might perform.
- What evidence would resolve it: Systematic experiments comparing FLEXtime's performance across different filter bank designs (e.g., octave filterbanks, wavelet filterbanks, perfect reconstruction filterbanks) on the same benchmark datasets.

### Open Question 2
- Question: What is the optimal balance between faithfulness and complexity when evaluating time series explainability methods, and how should these metrics be weighted against each other?
- Basis in paper: [inferred] The authors discuss the tension between faithfulness and complexity in their results and acknowledge the challenge of quantifying explanation quality, noting that different optimization objectives yield different results.
- Why unresolved: The paper optimizes for faithfulness but recognizes that other metrics may be valuable, without providing a framework for balancing these competing objectives.
- What evidence would resolve it: Development and validation of a unified evaluation framework that incorporates multiple metrics with appropriate weighting, or user studies determining which metric combinations are most useful for practitioners.

### Open Question 3
- Question: How can automatic filterbank design be implemented for FLEXtime to eliminate the need for manual hyperparameter tuning?
- Basis in paper: [explicit] The authors identify automatic filterbank design as a limitation of FLEXtime and a promising future direction.
- Why unresolved: The current implementation requires cross-validation to choose filterbank parameters, which is computationally expensive and requires expert knowledge.
- What evidence would resolve it: A method that automatically learns optimal filterbank parameters during the explanation process, demonstrated to achieve comparable or superior performance to manually-tuned versions while reducing computational overhead.

### Open Question 4
- Question: Can FLEXtime be extended to provide joint explanations in both time and frequency domains simultaneously?
- Basis in paper: [inferred] The authors note that the current filterbank design only offers insights into the frequency domain, and future work should explore incorporating insights from both domains.
- Why unresolved: The paper focuses exclusively on frequency-domain explanations, leaving open the question of how to combine temporal and spectral information in a single explanation framework.
- What evidence would resolve it: A modified version of FLEXtime that generates explanations in both time and frequency domains, with evaluation showing improved interpretability or performance compared to single-domain explanations.

## Limitations

- The method's reliance on a fixed filterbank design may limit its adaptability to varying signal properties and non-stationary signals
- Poor sensitivity analysis of filterbank design parameters (number of filters, filter length) could significantly impact explanation quality
- Limited evaluation on domains beyond those tested, raising questions about generalizability to different types of time series data

## Confidence

**High confidence** in the core claim that frequency-domain explanations can outperform time-domain saliency methods for certain time series tasks. The synthetic dataset results provide clear evidence of this advantage.

**Medium confidence** in the practical utility of FLEXtime for real-world applications. While performance metrics are strong, the paper lacks user studies or domain expert validation to confirm that the explanations are truly interpretable and actionable.

**Medium confidence** in the claim that FLEXtime's filterbank approach provides more stable explanations than direct Fourier masking. The paper provides theoretical justification but limited empirical comparison of stability across different noise conditions.

## Next Checks

1. **Cross-domain robustness test**: Apply FLEXtime to time series from domains not represented in the paper (e.g., financial data, sensor networks) to assess generalizability beyond the tested domains.

2. **Parameter sensitivity analysis**: Systematically vary filterbank design parameters (number of filters, filter length) across multiple datasets to determine optimal configurations and identify parameter regimes where performance degrades.

3. **Human evaluation study**: Conduct a user study with domain experts to assess whether FLEXtime's frequency-based explanations are more interpretable and useful for decision-making compared to time-domain saliency methods.