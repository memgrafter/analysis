---
ver: rpa2
title: 'Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise
  Networks'
arxiv_id: '2406.02596'
source_url: https://arxiv.org/abs/2406.02596
tags:
- learning
- network
- hare
- tortoise
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of maintaining generalization
  ability in neural networks during continuous learning, revisiting warm-starting
  experiments to understand how trainability and generalizability are related. The
  authors find that while methods to maintain trainability (such as regularization
  and data augmentation) help preserve the ability to minimize training loss, they
  do not necessarily improve generalization to new data.
---

# Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks

## Quick Facts
- arXiv ID: 2406.02596
- Source URL: https://arxiv.org/abs/2406.02596
- Reference count: 40
- Key outcome: Hare & Tortoise architecture improves generalization in continuous learning tasks by using a fast-adapting network periodically reinitialized from a slowly updated network.

## Executive Summary
This paper addresses the challenge of maintaining generalization ability in neural networks during continuous learning. Through warm-starting experiments, the authors discover that while techniques to maintain trainability help minimize training loss, they do not necessarily improve generalization to new data. Instead, reinitializing parts of the network proves most effective at preserving generalization. Drawing inspiration from the brain's complementary learning systems, the authors propose the Hare & Tortoise architecture, which uses two networks with different adaptation speeds. Periodic reinitialization of the fast Hare network to the slow Tortoise network preserves plasticity while retaining prior knowledge, demonstrating improved performance across warm-starting, continual learning, and reinforcement learning tasks.

## Method Summary
The Hare & Tortoise architecture consists of two neural networks: a fast-adapting Hare network and a slowly updating Tortoise network. The Hare network learns quickly from new data but is periodically reinitialized to match the Tortoise network's parameters. The Tortoise network updates slowly using techniques like regularization and data augmentation to preserve learned knowledge. This dual-network approach balances the need for rapid adaptation to new tasks with the retention of previously acquired knowledge. The key mechanism is the periodic synchronization of the Hare network to the Tortoise network, which maintains plasticity while preventing catastrophic forgetting.

## Key Results
- Shrink & Perturb (reinitializing parts of the network) is more effective at maintaining generalization than regularization or data augmentation.
- Hare & Tortoise outperforms existing methods on the Atari-100k benchmark in reinforcement learning tasks.
- The architecture demonstrates consistent improvements in generalization across warm-starting, continual learning, and reinforcement learning scenarios.

## Why This Works (Mechanism)
The Hare & Tortoise architecture works by separating the roles of rapid adaptation and knowledge retention. The Hare network can quickly learn from new data without the constraints of preserving old knowledge, while the Tortoise network slowly accumulates and maintains information from past experiences. Periodic reinitialization of the Hare to the Tortoise ensures that the fast network doesn't drift too far from the consolidated knowledge base, preventing catastrophic forgetting while maintaining the ability to adapt to new tasks. This mirrors the brain's complementary learning systems, where the hippocampus rapidly encodes new information and periodically consolidates it to the neocortex.

## Foundational Learning
- **Catastrophic Forgetting**: Neural networks tend to overwrite previous knowledge when learning new tasks; understanding this is crucial for designing effective continual learning methods.
  - Why needed: To identify the core problem the architecture aims to solve.
  - Quick check: Observe performance degradation on old tasks when training on new tasks sequentially.

- **Complementary Learning Systems**: The brain uses separate systems for rapid learning and slow consolidation; this inspires the dual-network approach.
  - Why needed: Provides biological motivation for separating fast and slow learning processes.
  - Quick check: Compare performance of single vs. dual-network architectures on continual learning tasks.

- **Warm-Starting Experiments**: Evaluating how pre-trained networks perform on new tasks helps understand the relationship between trainability and generalizability.
  - Why needed: Establishes that maintaining trainability doesn't necessarily improve generalization.
  - Quick check: Measure training loss and test accuracy after applying different regularization techniques.

## Architecture Onboarding

**Component Map**: Input -> Hare Network (fast adaptation) -> Output, Tortoise Network (slow update) -> Synchronization (periodic reinitialization)

**Critical Path**: New data enters Hare network for fast learning → Periodic synchronization with Tortoise network → Tortoise network slowly updates with regularization/data augmentation

**Design Tradeoffs**: The architecture trades increased computational overhead (maintaining two networks) for improved generalization and reduced catastrophic forgetting. The frequency of reinitialization must be balanced to prevent the Hare from forgetting too quickly or the Tortoise from becoming too rigid.

**Failure Signatures**: If the Hare network is reinitialized too infrequently, it may suffer from catastrophic forgetting. If reinitialized too often, it may not adapt quickly enough to new tasks. Poor regularization on the Tortoise network can lead to slow learning and inability to retain knowledge.

**First Experiments**:
1. Compare single network with Hare & Tortoise on a simple continual learning benchmark (e.g., permuted MNIST).
2. Vary reinitialization frequency to find optimal balance between adaptation and retention.
3. Test the architecture on a reinforcement learning task (e.g., Atari games) to validate scalability.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but potential areas for further investigation include the architecture's performance on real-world, non-stationary data distributions and the impact of hyperparameter choices on different types of tasks.

## Limitations
- Experimental validation is primarily on synthetic and benchmark tasks, which may not fully represent real-world continuous learning challenges.
- The computational overhead of maintaining two separate networks and the optimal frequency of reinitialization are not thoroughly explored for scalability.
- Effectiveness in domains with highly non-stationary data distributions or long-term catastrophic forgetting remains unclear.

## Confidence
- **High Confidence**: The observation that maintaining trainability doesn't necessarily improve generalization is well-supported by experimental results.
- **Medium Confidence**: Hare & Tortoise shows consistent improvements, but generality to diverse real-world applications is less certain.
- **Low Confidence**: The claim that periodic reinitialization is the "most effective" method is based on limited baseline comparisons and may not hold across all scenarios.

## Next Checks
1. Evaluate Hare & Tortoise on larger-scale datasets (e.g., ImageNet-100) to assess computational feasibility and generalization performance.
2. Conduct experiments to measure catastrophic forgetting over extended sequences of tasks in non-stationary environments.
3. Systematically analyze the impact of reinitialization frequency and relative learning rates on performance across diverse tasks.