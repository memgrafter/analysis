---
ver: rpa2
title: 'PCR-99: A Practical Method for Point Cloud Registration with 99 Percent Outliers'
arxiv_id: '2402.16598'
source_url: https://arxiv.org/abs/2402.16598
tags:
- point
- outlier
- pcr-99
- rsum
- registration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces PCR-99, a robust point cloud registration
  method capable of handling extreme outlier ratios up to 99%. The key idea is to
  use deterministic 3-point sampling with two novel mechanisms: (1) scoring point
  correspondences based on pairwise scale consistency to prioritize inlier selection,
  and (2) an efficient outlier rejection scheme using triplet scale consistency to
  prescreen bad samples.'
---

# PCR-99: A Practical Method for Point Cloud Registration with 99 Percent Outliers

## Quick Facts
- arXiv ID: 2402.16598
- Source URL: https://arxiv.org/abs/2402.16598
- Authors: Seong Hun Lee; Javier Civera; Patrick Vandewalle
- Reference count: 35
- Primary result: Novel deterministic 3-point sampling method achieving state-of-the-art performance at 99% outlier ratios with up to 162× speedup over RANSAC

## Executive Summary
PCR-99 introduces a robust point cloud registration method specifically designed to handle extreme outlier ratios up to 99%. The method combines two novel mechanisms: scoring point correspondences based on pairwise scale consistency and an efficient outlier rejection scheme using triplet scale consistency. By deterministically ordering samples according to their likelihood of containing inliers, PCR-99 significantly outperforms existing methods in both accuracy and speed, particularly for unknown-scale registration problems.

## Method Summary
PCR-99 uses deterministic 3-point sampling where correspondences are scored by their pairwise scale consistency using log-ratio distances. The method generates samples ordered by increasing sum of correspondence rankings, applies triplet scale consistency prescreening to avoid expensive transformation computations for unlikely samples, and iteratively finds the transformation with maximum inliers. The approach leverages Horn's method for solving similarity transformations when samples pass the prescreening test, achieving superior performance at extreme outlier ratios through efficient bad-sample rejection.

## Key Results
- Achieves state-of-the-art performance at 99% outlier ratios with rotation and translation errors matching or outperforming existing methods
- Demonstrates significant speed advantages, with median speedup of up to 162× compared to RANSAC at 99% outliers
- Shows superior accuracy and speed particularly for unknown-scale registration problems
- Robust performance validated on Bunny dataset with 1000 points across various outlier ratios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deterministic 3-point sampling ordered by pairwise scale consistency improves inlier prioritization over random sampling
- Mechanism: Each correspondence is scored by how consistent its log-scale ratio is with many others. Samples are ordered by the sum of their correspondence rankings so that those with higher total scores (more inlier-like) are evaluated first
- Core assumption: Inlier correspondences will have more consistent log-scale ratios with other inliers than outliers will
- Break condition: If outlier scale ratios happen to be accidentally consistent (e.g., uniform noise), the scoring may fail to distinguish inliers from outliers

### Mechanism 2
- Claim: Triplet scale consistency prescreening avoids computing full transformations for bad samples
- Mechanism: For a 3-point sample, the log-scale ratios must satisfy |L(i,j) - L(j,k)| < ε, |L(i,k) - L(k,i)| < ε, and |L(i,j) - L(k,i)| < ε. If any fail, the sample is discarded without computing rotation/translation
- Core assumption: Inlier triplets satisfy near-perfect similarity conditions; outliers violate them
- Break condition: If inliers are very noisy or outlier scale ratios accidentally mimic similarity, prescreening may incorrectly reject inliers or accept outliers

### Mechanism 3
- Claim: Combining scoring + ordering + prescreening yields both speed and robustness at 99% outlier ratio
- Mechanism: Scoring ranks correspondences, ordering tests likely-inlier samples first, prescreening skips expensive transforms for unlikely samples, thus reducing total work while maintaining accuracy
- Core assumption: High outlier ratios mean most random samples are bad, so avoiding them early is critical for efficiency
- Break condition: If outlier ratio drops below ~90%, random sampling may be competitive and deterministic ordering offers less advantage

## Foundational Learning

- Concept: 3D point cloud registration as finding rotation/translation (and optionally scale) between two sets of points
  - Why needed here: PCR-99 is a correspondence-based method; understanding the geometry of rigid/similarity transforms is essential to follow the Horn method usage
  - Quick check question: Given two matched point sets {ai} and {bi} with known correspondence, what minimal number of points is needed to solve for rotation and translation exactly?

- Concept: Scale consistency via log-ratio of inter-point distances
  - Why needed here: The score function and prescreening rely on comparing ∥bi - bj∥ / ∥ai - aj∥ across correspondences; the log transform linearizes multiplicative scale
  - Quick check question: If (ai,bi) and (aj,bj) are both inliers with scale s, what is the expected value of ln(∥bi - bj∥) - ln(∥ai - aj∥)?

- Concept: RANSAC-style consensus maximization but deterministic instead of random
  - Why needed here: PCR-99 shares the high-level goal (find transformation with most inliers) but replaces random sampling with deterministic ordering to improve efficiency
  - Quick check question: In standard RANSAC, why is it important to try many random samples when outlier ratio is high?

## Architecture Onboarding

- Component map: Precompute L -> Score S -> Generate sample (ordered) -> Prescreen -> Evaluate Horn -> Find inliers -> Re-estimate
- Critical path: Precompute L → Score S → Generate sample (ordered) → Prescreen → Evaluate Horn → Find inliers → Re-estimate
- Design tradeoffs:
  - Deterministic ordering vs. random sampling: better prioritization but higher upfront cost to sort scores
  - Log-ratio truncation (ε) vs. full precision: faster but may miss borderline inliers
  - Prescreening thresholds: too loose → wasted transforms; too strict → miss good samples
- Failure signatures:
  - Consistently low inlier counts → scoring or prescreening too aggressive
  - Slow runtime at low outlier ratios → ordering overhead outweighs benefit
  - Erratic results across runs → deterministic ordering may overfit to noisy score estimates
- First 3 experiments:
  1. Run on Bunny dataset with 95% outliers, compare runtime vs. RANSAC baseline
  2. Vary prescreening threshold ε, measure impact on speed and accuracy at 99% outliers
  3. Disable score-based ordering (random sampling), compare performance to full PCR-99

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Novel mechanisms lack direct validation from neighboring literature
- Log-ratio truncation threshold (ε = 0.1) is not rigorously justified for varying noise levels
- Scalability to datasets with millions of points is not addressed

## Confidence

**High confidence**: The fundamental premise that high outlier ratios require specialized sampling strategies is well-supported by the literature. The use of Horn's method for transformation estimation is standard and reliable.

**Medium confidence**: The effectiveness of the pairwise scale scoring mechanism is demonstrated in experiments but lacks ablation studies to isolate its contribution from the prescreening mechanism. The choice of log-ratio threshold ε = 0.1 appears arbitrary.

**Low confidence**: The scalability of the deterministic ordering approach to datasets with millions of points is not addressed. The method's behavior at outlier ratios below 90% is unclear, as the paper focuses exclusively on the extreme 99% case.

## Next Checks

1. **Ablation study**: Run PCR-99 with prescreening disabled to quantify its contribution to the 162× speedup. Measure the trade-off between speed and accuracy.

2. **Threshold sensitivity**: Systematically vary the log-ratio threshold ε and the inlier threshold δin across multiple datasets to determine their optimal ranges and robustness to parameter choice.

3. **Low outlier ratio testing**: Evaluate PCR-99 at outlier ratios of 50%, 70%, and 90% to determine where deterministic ordering provides advantages over random sampling, and identify the crossover point where random sampling becomes competitive.