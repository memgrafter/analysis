---
ver: rpa2
title: 'PICLe: Eliciting Diverse Behaviors from Large Language Models with Persona
  In-Context Learning'
arxiv_id: '2405.02501'
source_url: https://arxiv.org/abs/2405.02501
tags:
- persona
- picle
- examples
- learning
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of eliciting specific personality
  traits or behaviors from large language models (LLMs). The authors propose a novel
  framework called Persona In-Context Learning (PICLe) to achieve this goal.
---

# PICLe: Eliciting Diverse Behaviors from Large Language Models with Persona In-Context Learning

## Quick Facts
- arXiv ID: 2405.02501
- Source URL: https://arxiv.org/abs/2405.02501
- Reference count: 40
- Primary result: Achieves 88.1% success rate on Llama-2, significantly improving upon baseline without ICL (65.5%)

## Executive Summary
This paper addresses the challenge of eliciting specific personality traits from large language models (LLMs) through a novel framework called Persona In-Context Learning (PICLe). PICLe is grounded in Bayesian inference and introduces a new in-context learning example selection criterion based on likelihood ratio to optimally guide models toward target personas. The method demonstrates significant improvements in persona alignment across three contemporary LLMs (Llama-2, Vicuna, and GPT-J), achieving an average success rate of 88.1% on Llama-2 compared to 65.5% without ICL. The framework shows consistent superiority over competitive baselines, highlighting its model-agnostic capability and general applicability.

## Method Summary
PICLe introduces a novel approach to persona elicitation in LLMs through Bayesian inference and likelihood ratio-based in-context learning example selection. The framework selects demonstrative examples that maximize the likelihood of the target persona, creating an optimal learning signal for the model. This selection criterion is designed to efficiently guide the LLM toward specific behavioral traits or personality characteristics. The method is evaluated across three different model architectures (Llama-2, Vicuna, and GPT-J) to demonstrate its model-agnostic nature and general effectiveness in improving persona alignment compared to baseline approaches.

## Key Results
- Achieves 88.1% success rate on Llama-2, improving upon baseline without ICL (65.5%)
- Consistently outperforms competitive ICL baselines across all tested models
- Demonstrates model-agnostic capability through consistent results across three distinct architectures

## Why This Works (Mechanism)
The paper presents a method for eliciting specific personality traits from large language models using in-context learning, but several uncertainties remain. The evaluation relies heavily on automatic metrics like GPT-4 and personality classifiers, which may not fully capture the nuanced quality of persona alignment and could introduce bias. The methodology assumes that likelihood ratio-based example selection is optimal, though this assumption is not empirically validated across diverse persona types. The study focuses on three models (Llama-2, Vicuna, and GPT-J), limiting generalizability to other architectures or sizes. The in-context learning approach may have practical constraints with longer or more complex personas due to context window limitations. Additionally, the method's robustness to adversarial or ambiguous persona descriptions is not explored.

## Foundational Learning
- Bayesian inference: Why needed - provides probabilistic framework for updating beliefs about target personas; Quick check - verify understanding of prior/posterior relationships
- Likelihood ratio: Why needed - quantifies how well examples support target persona; Quick check - confirm ability to calculate and interpret ratios
- In-context learning: Why needed - enables persona alignment without fine-tuning; Quick check - understand how demonstrations influence model behavior
- Personality classification: Why needed - provides automatic evaluation metric; Quick check - verify knowledge of classification algorithms
- Context window limitations: Why needed - impacts practical applicability; Quick check - understand maximum context length constraints

## Architecture Onboarding

Component Map: PICLe framework -> Bayesian inference engine -> Likelihood ratio selector -> In-context demonstration generator -> LLM target

Critical Path: Persona description -> Bayesian inference calculation -> Likelihood ratio evaluation -> Example selection -> In-context learning application -> Persona alignment

Design Tradeoffs: The method balances between example relevance (through likelihood ratio) and diversity, trading off computational cost of Bayesian inference against alignment accuracy, and prioritizes automatic evaluation over human judgment for scalability.

Failure Signatures: Poor persona alignment despite high likelihood ratios, degradation in performance with longer or more complex personas, inconsistent results across different model architectures, and failure to generalize beyond trained persona types.

First Experiments: 1) Test PICLe on a simple, well-defined persona (e.g., "helpful assistant") to establish baseline performance; 2) Evaluate performance degradation with increasing persona complexity; 3) Measure sensitivity to number of in-context examples.

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on automatic metrics (GPT-4, personality classifiers) may not capture nuanced persona quality
- Limited generalizability due to evaluation on only three model architectures
- Potential practical constraints with longer or more complex personas due to context window limitations

## Confidence

High confidence: The overall improvement in persona alignment over baseline without ICL (65.5% to 88.1% on Llama-2) is well-supported by the results

Medium confidence: The claim that PICLe is "model-agnostic" is supported by consistent results across three models but would benefit from testing on additional architectures

Medium confidence: The superiority over competitive ICL baselines is demonstrated but relies on specific evaluation metrics that could be challenged

## Next Checks

1. Conduct human evaluation studies to validate the automatic metrics and assess qualitative aspects of persona alignment

2. Test PICLe on additional LLM architectures (including commercial models like GPT-4) to verify model-agnostic claims

3. Evaluate robustness by testing with adversarial persona descriptions and measuring performance degradation