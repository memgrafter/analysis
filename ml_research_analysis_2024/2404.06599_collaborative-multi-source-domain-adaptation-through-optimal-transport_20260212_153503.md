---
ver: rpa2
title: Collaborative Multi-source Domain Adaptation Through Optimal Transport
arxiv_id: '2404.06599'
source_url: https://arxiv.org/abs/2404.06599
tags:
- domain
- data
- learning
- adaptation
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes CMDA-OT, a framework for unsupervised multi-source
  domain adaptation that preserves data privacy. The approach operates in two phases:
  first, optimal transport is applied to adapt each source domain to the target domain;
  second, a federated learning setup aggregates models from multiple sources without
  accessing source data.'
---

# Collaborative Multi-source Domain Adaptation Through Optimal Transport

## Quick Facts
- arXiv ID: 2404.06599
- Source URL: https://arxiv.org/abs/2404.06599
- Authors: Omar Ghannou; Younès Bennani
- Reference count: 4
- Primary result: CMDA-OT achieves 73.25% accuracy on VLSC and 96.5% on Office-Caltech-10, outperforming state-of-the-art methods

## Executive Summary
This paper proposes CMDA-OT, a framework for unsupervised multi-source domain adaptation that preserves data privacy through optimal transport and federated learning. The approach operates in two phases: first, optimal transport adapts each source domain to the target domain using the Sinkhorn algorithm; second, a federated learning setup aggregates models from multiple sources without accessing source data. The server uses a small set of pseudo-labeled target samples to guide the adaptation and determine the contribution weight of each source. Experiments on VLSC and Office-Caltech-10 datasets show that CMDA-OT achieves significant improvements over state-of-the-art methods, with statistical tests confirming the robustness and superiority of the proposed method.

## Method Summary
CMDA-OT is a two-phase framework for collaborative multi-source domain adaptation. Phase 1 applies optimal transport using the Sinkhorn algorithm with entropy regularization (ε=50) and class regularization (5000) to adapt each source domain to the target domain, reducing domain discrepancies. Phase 2 employs federated learning with FedAvg aggregation, where source models are weighted based on their performance on a pseudo-labeled target validation subset. Spectral clustering generates pseudo-labels for the target domain, and hierarchical optimal transport maps cluster labels to source labels. The framework preserves privacy by never transferring source data, only model weights and validation results.

## Key Results
- Achieves 73.25% average accuracy on VLSC dataset, outperforming state-of-the-art methods
- Achieves 96.5% average accuracy on Office-Caltech-10 dataset
- Statistical significance confirmed via Friedman and Nemenyi tests
- Robust performance across heterogeneous source domains while preserving data privacy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal transport reduces domain shift by finding a minimal cost transformation between source and target distributions.
- Mechanism: The Sinkhorn algorithm with entropy and class regularization computes a soft assignment matrix that maps source data points to target space while preserving label structure.
- Core assumption: The target domain can be represented as a mixture of source domains, and the optimal transport cost matrix captures the domain discrepancy.
- Evidence anchors: [abstract] "optimal transport methods. These methods are adept at discovering and learning the minimal transformation cost from source to target domains, effectively reducing domain discrepancies"; [section 2.2] "The aim of optimal transport is to minimize the total cost of transporting the measure µ into ν"
- Break condition: If the regularization parameters are poorly tuned, the optimal transport may fail to preserve discriminative features or may over-smooth the representation.

### Mechanism 2
- Claim: Federated learning aggregates source models without accessing source data, preserving privacy.
- Mechanism: Each client trains on local source data, sends model weights to server, server averages weights using sample-based or accuracy-based coefficients.
- Core assumption: Model weights contain sufficient information to aggregate knowledge without raw data transfer.
- Evidence anchors: [abstract] "a centralized collaborative learning architecture is employed, which aggregates the N models from the N sources without accessing their data, thereby safeguarding privacy"; [section 3.1] "we employ the FedAvg algorithm [McMahan et al., 2017] for the learning process"
- Break condition: If source domains are too heterogeneous, simple weight averaging may not capture complex domain relationships.

### Mechanism 3
- Claim: Pseudo-labeling the target validation set guides the adaptation process and enables unsupervised training.
- Mechanism: Spectral clustering groups target samples, hierarchical optimal transport maps cluster labels to source labels, majority voting resolves conflicts.
- Core assumption: Target domain samples form meaningful clusters that correspond to source domain classes.
- Evidence anchors: [abstract] "the server leverages a small set of pseudo-labeled samples from the target domain, known as the target validation subset, to refine and guide the adaptation"; [section 3.2] "we propose a pseudo-labeling approach to handle fully unsupervised training for the target domain"
- Break condition: If target clusters are impure or too fragmented, pseudo-labels will be incorrect and misguide adaptation.

## Foundational Learning

- Concept: Domain adaptation and domain shift
  - Why needed here: The entire framework addresses the problem of adapting models across different data distributions
  - Quick check question: What is the difference between domain shift and dataset bias?

- Concept: Optimal transport and Wasserstein distance
  - Why needed here: OT is the core method for reducing domain shift in the first phase
  - Quick check question: How does entropy regularization affect the OT solution?

- Concept: Federated learning and secure aggregation
  - Why needed here: The second phase uses FL to preserve privacy while aggregating knowledge
  - Quick check question: What are the communication tradeoffs between FedAvg and FedSGD?

## Architecture Onboarding

- Component map: Source clients -> Optimal Transport transformation -> Local model training -> Weight upload -> Server validation testing -> Coefficient computation -> Weighted aggregation -> Target model
- Critical path: Source data → OT transformation → Local model training → Weight upload → Validation testing → Coefficient computation → Weighted aggregation → Target model
- Design tradeoffs:
  - Regularization balance: Too much entropy regularization smooths too much; too little may cause numerical instability
  - Validation size: Larger validation set improves coefficient accuracy but reduces target data for training
  - Communication frequency: More frequent aggregation may improve convergence but increases communication cost
- Failure signatures:
  - Degradation in validation accuracy during OT phase suggests poor regularization or incompatible domains
  - Unstable coefficient values across iterations indicate poor pseudo-label quality or highly heterogeneous sources
  - Final model performs worse than source models alone suggests aggregation strategy failure
- First 3 experiments:
  1. Run single-source adaptation on each source individually to establish baseline performance
  2. Apply optimal transport to each source separately and evaluate accuracy improvement with validation set
  3. Run full CMDA-OT with two sources and monitor coefficient stability and final accuracy improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How sensitive is CMDA-OT's performance to the choice of regularization parameters (entropy and class regularization) across different datasets?
- Basis in paper: [explicit] The paper mentions that these parameters are sensitive to data distribution and provides recommendations but notes they require tuning for each source or uniformly across all sources.
- Why unresolved: The paper provides a test-driven approach for parameter tuning but doesn't systematically evaluate the sensitivity of performance to these parameters across diverse datasets.
- What evidence would resolve it: Comprehensive experiments varying regularization parameters across multiple datasets and analyzing performance trends would clarify the sensitivity and optimal tuning strategies.

### Open Question 2
- Question: Can CMDA-OT be extended to dynamic federated learning scenarios where source domains or target data distributions change over time?
- Basis in paper: [inferred] The paper focuses on static adaptation scenarios and doesn't address temporal dynamics or concept drift in federated learning.
- Why unresolved: The proposed framework assumes static data distributions, but real-world applications often involve evolving data, which could impact the effectiveness of the adaptation.
- What evidence would resolve it: Experiments evaluating CMDA-OT's performance on datasets with temporal shifts or simulated concept drift would demonstrate its robustness to dynamic scenarios.

### Open Question 3
- Question: How does CMDA-OT compare to other federated learning frameworks (e.g., decentralized or peer-to-peer) in terms of scalability and privacy preservation?
- Basis in paper: [explicit] The paper mentions adaptability to various collaborative learning paradigms but only implements the centralized FL approach.
- Why unresolved: The paper claims versatility but lacks empirical comparisons with alternative federated learning frameworks to validate these claims.
- What evidence would resolve it: Comparative studies evaluating CMDA-OT against decentralized FL methods on metrics like communication efficiency, scalability, and privacy preservation would provide insights into its relative advantages.

## Limitations
- The framework assumes static data distributions and doesn't address temporal dynamics or concept drift
- Claims about privacy preservation lack formal security analysis or comparison to privacy-preserving alternatives
- The pseudo-labeling approach's sensitivity to cluster quality and fragmentation is not rigorously evaluated

## Confidence
- **High Confidence**: The two-phase framework structure (OT adaptation + federated aggregation) is clearly defined and reproducible.
- **Medium Confidence**: Empirical results show strong performance gains, but the underlying mechanism for why certain regularization parameters work better than others is not rigorously explained.
- **Low Confidence**: Claims about privacy preservation lack formal security analysis or comparison to privacy-preserving alternatives like differential privacy.

## Next Checks
1. **Sensitivity Analysis**: Systematically vary entropy regularization (ε) and class regularization parameters to identify optimal ranges and failure modes for different domain similarity levels.
2. **Cluster Quality Assessment**: Implement cluster purity metrics on the pseudo-labeled target validation set and evaluate how impurity levels affect weight aggregation stability and final accuracy.
3. **Heterogeneous Source Stress Test**: Create controlled experiments with highly imbalanced source domains (varying number of samples, class distributions) to test federated aggregation robustness beyond the balanced settings in current experiments.