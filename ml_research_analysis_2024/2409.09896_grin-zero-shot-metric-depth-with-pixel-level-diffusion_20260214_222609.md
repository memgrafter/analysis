---
ver: rpa2
title: 'GRIN: Zero-Shot Metric Depth with Pixel-Level Diffusion'
arxiv_id: '2409.09896'
source_url: https://arxiv.org/abs/2409.09896
tags:
- depth
- estimation
- grin
- diffusion
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GRIN addresses zero-shot metric monocular depth estimation by using
  a diffusion model to directly process sparse depth data. It introduces 3D geometric
  positional encodings to condition the denoising process globally and locally, enabling
  the model to learn robust priors that generalize across diverse camera geometries
  and datasets.
---

# GRIN: Zero-Shot Metric Depth with Pixel-Level Diffusion

## Quick Facts
- arXiv ID: 2409.09896
- Source URL: https://arxiv.org/abs/2409.09896
- Reference count: 40
- Primary result: New state-of-the-art in zero-shot metric depth estimation across 8 benchmarks

## Executive Summary
GRIN introduces a diffusion-based approach to zero-shot metric depth estimation that processes sparse depth data at the pixel level. By combining image features with 3D geometric positional encodings for both local and global conditioning, GRIN learns robust scale-aware priors that generalize across diverse camera geometries. The method eliminates the need for dense ground truth or specialized auto-encoders, achieving superior performance compared to existing approaches like Metric3D, ZeroDepth, DMD, and UniDepth on indoor and outdoor benchmarks.

## Method Summary
GRIN uses a Recurrent Inference Network (RIN) to denoise sparse depth maps conditioned on RGB images and 3D geometric embeddings derived from camera intrinsics. The architecture processes depth at pixel-level without assuming spatial structure, enabling training from sparse unstructured data. Local conditioning combines image features with geometric embeddings for each pixel, while global conditioning provides scene-level context through multi-scale image features and resized geometric embeddings. The model operates in log-space depth with base 10 and uses DDIM sampling for inference with 10 steps.

## Key Results
- Establishes new state of the art in zero-shot metric depth estimation on 8 indoor and outdoor benchmarks
- Outperforms existing methods including Metric3D, ZeroDepth, DMD, and UniDepth
- Demonstrates strong generalization across diverse camera geometries and datasets without requiring dense ground truth

## Why This Works (Mechanism)

### Mechanism 1
- Claim: 3D geometric positional encodings enable scale-aware priors that generalize across camera geometries
- Mechanism: Geometric embeddings parameterize each pixel by its viewing ray and camera center, embedding physical 3D structure into conditioning
- Core assumption: Geometric embeddings can be successfully projected into latent diffusion space without losing discriminative power
- Break condition: If embeddings collapse to degenerate representations, model reverts to 2D appearance-based depth estimation

### Mechanism 2
- Claim: Pixel-level diffusion allows ingestion of sparse unstructured depth data without requiring dense ground truth
- Mechanism: RIN architecture decouples computation from input size, processing each depth pixel independently with local and global conditioning
- Core assumption: Sparse pixel inputs, when conditioned with local and global features, contain enough information for coherent depth reconstruction
- Break condition: If sparsity exceeds model's inference ability, depth predictions become noisy and spatially inconsistent

### Mechanism 3
- Claim: Combination of local and global conditioning improves performance with sparse data
- Mechanism: Local conditioning provides pixel-specific information while global conditioning supplies scene-level context for consistency
- Core assumption: Global embeddings can be randomly subsampled during training without losing scene-consistency benefit
- Break condition: If global conditioning is too sparse or misaligned, model produces inconsistent depth predictions

## Foundational Learning

- Concept: Diffusion models reverse noise process to generate samples from target distribution
  - Why needed: GRIN uses diffusion to iteratively denoise depth maps conditioned on image and geometric features
  - Quick check: What is the role of noise schedule in diffusion models and why is it important for depth estimation?

- Concept: Sparse data handling in neural networks
  - Why needed: GRIN must learn from depth maps where many pixels are missing, unlike dense ground truth
  - Quick check: How does RIN architecture's tokenization enable processing sparse inputs without assuming grid structure?

- Concept: Geometric embeddings for scale-aware depth estimation
  - Why needed: Monocular depth estimation is ambiguous without camera geometry; embeddings encode physical structure
  - Quick check: How do Fourier-encoded viewing rays help model reason about physical scale and shape?

## Architecture Onboarding

- Component map: Tokenize image and depth -> Generate local conditioning (image + geometric) -> Generate global conditioning (scene context) -> RIN denoising -> Output log-depth predictions
- Critical path: 1) Tokenize input image and depth (sparse) 2) Generate local conditioning 3) Generate global conditioning 4) Feed into RIN for denoising 5) Output log-depth predictions, convert to linear
- Design tradeoffs: Pixel-level diffusion vs latent space (higher fidelity but more compute), sparse supervision vs dense (more scalable but requires careful conditioning), log-space vs linear depth (better range handling but parameterization tuning)
- Failure signatures: Loss of fine detail (insufficient global conditioning), inconsistent depth boundaries (weak local conditioning), poor metric scale transfer (geometric embeddings not well learned)
- First 3 experiments: 1) Train with only local conditioning vs both to measure scene context impact 2) Switch from log-10 to linear depth parameterization and compare indoor vs outdoor performance 3) Gradually increase sparsity (10%, 25%, 50% valid pixels) to find breaking point

## Open Questions the Paper Calls Out

- How does choice of depth parameterization (log-scale vs linear) affect performance across different depth ranges and datasets?
- Can GRIN's efficiency be further improved during inference without sacrificing accuracy?
- How does global conditioning affect model's ability to generalize to unseen camera geometries and environments?

## Limitations

- Paper does not specify exact number of Fourier bands for geometric embedding, which could affect generalization across camera geometries
- Training details for two-stage process are minimal, leaving uncertainty about curriculum learning implementation
- No ablation studies isolate impact of local vs global conditioning, making it difficult to quantify individual contributions
- Claims strong generalization across 8 datasets but lacks per-dataset performance breakdowns or error analysis

## Confidence

- High Confidence: Core claim that GRIN outperforms existing zero-shot metric depth methods on tested benchmarks
- Medium Confidence: Assertion that geometric positional encodings are key to metric generalization (limited ablation evidence)
- Medium Confidence: Claim of robustness to sparse supervision (exact sparsity levels and effects not thoroughly explored)

## Next Checks

1. Perform ablation study comparing GRIN with only local conditioning, only global conditioning, and both together to quantify individual contributions
2. Test model's performance on datasets with varying camera geometries (different focal lengths, resolutions) to validate geometric embedding generalization
3. Evaluate impact of sparsity level on depth quality by systematically varying percentage of valid depth pixels during training and testing