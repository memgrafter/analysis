---
ver: rpa2
title: 'State space models, emergence, and ergodicity: How many parameters are needed
  for stable predictions?'
arxiv_id: '2409.13421'
source_url: https://arxiv.org/abs/2409.13421
tags:
- parameters
- learning
- such
- linear
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether emergent behavior in large language
  models can be replicated in simpler theoretical models. The authors propose that
  tasks exhibiting substantial long-range correlations and lack of ergodicity require
  a critical number of parameters to be executed successfully.
---

# State space models, emergence, and ergodicity: How many parameters are needed for stable predictions?

## Quick Facts
- arXiv ID: 2409.13421
- Source URL: https://arxiv.org/abs/2409.13421
- Authors: Ingvar Ziemann; Nikolai Matni; George J. Pappas
- Reference count: 33
- Primary result: Non-ergodic linear systems require quadratic parameter scaling in unstable eigenvalues for bounded prediction error

## Executive Summary
This paper investigates whether emergent behavior in large language models can be replicated in simpler theoretical models by examining learning linear dynamical systems. The authors propose that tasks exhibiting substantial long-range correlations and lack of ergodicity require a critical number of parameters to be executed successfully. They demonstrate this phenomenon through theoretical analysis of learning linear dynamical systems, showing that non-ergodic systems exhibit a phase transition in parameter requirements. Specifically, the paper proves that for non-ergodic linear systems, there exists a critical threshold in the number of parameters such that learners using fewer parameters cannot achieve bounded error for large sequence lengths.

## Method Summary
The paper analyzes learning linear dynamical systems through the lens of self-supervised learning, specifically next-token prediction. The method involves proving theoretical bounds on prediction error for different parameter regimes using tools from system identification and control theory. For fully observed systems, the analysis focuses on matrix mappings with restricted parameter spaces, while for hidden state systems, the focus is on finite-length linear filters. The key technical approach involves relating the KL-divergence risk for generative modeling to the prediction error of next-token prediction, enabling the analysis to be framed as a linear system identification problem with bounded prediction error requirements.

## Key Results
- Non-ergodic linear systems require at least a quadratic number of parameters (in terms of unstable eigenvalues) for successful learning
- For imperfectly observed random walks, the required filter length must exceed a threshold based on effective memory length and problem horizon
- KL-divergence risk for generative modeling can be bounded by prediction error, enabling analysis through linear system identification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tasks with non-ergodic linear dynamical systems require at least a quadratic number of parameters in the number of unstable eigenvalues to achieve bounded prediction error.
- Mechanism: In non-ergodic systems, unstable modes cause prediction error to grow without bound unless the learner has sufficient parameter capacity to capture the system's structure. The quadratic relationship arises because the learner must parameterize both the eigenvalues and the full Jordan block structure.
- Core assumption: The generative model is a linear dynamical system with hidden or visible state, and the learner uses a parametric hypothesis class to approximate predictions.
- Evidence anchors:
  - [abstract] "at least a quadratic number of parameters (in terms of the number of unstable eigenvalues) are required for successful learning"
  - [section 3] "Let d2⋆ be the sum of the squares of the algebraic multiplicities of all eigenvalues of A⋆ with magnitude at least unity"
  - [corpus] Weak evidence - corpus contains related work on ergodicity and emergence but no direct parameter scaling laws
- Break condition: If the system becomes ergodic (all eigenvalues have magnitude < 1) or if the parameter class is enriched beyond finite-dimensional filters.

### Mechanism 2
- Claim: For imperfectly observed random walks, the required filter length must exceed a threshold based on the effective memory length and horizon of the problem.
- Mechanism: When observations are noisy and the underlying state follows a random walk, the effective memory of the observation process grows with time. Linear filters with insufficient history cannot distinguish between signal and noise, causing prediction error to diverge.
- Core assumption: The observation process is generated by a hidden random walk with additive noise, and the learner uses finite-length linear filters.
- Evidence anchors:
  - [abstract] "the required filter length must exceed a certain threshold based on the effective memory length and horizon of the problem"
  - [section 4] "For every h = o(log T / log(1-ρ)) we have that lim T→∞ T−1ℓ(Mh) = ∞"
  - [corpus] Moderate evidence - corpus contains work on imprecise Markov semigroups but not specifically on filter length thresholds
- Break condition: If the signal-to-noise ratio improves dramatically or if nonlinear filters are permitted.

### Mechanism 3
- Claim: The KL-divergence risk for generative modeling can be bounded by the prediction error of next-token prediction, enabling analysis through the lens of linear system identification.
- Mechanism: Through the chain rule of KL divergence and the maximum entropy principle, the generative modeling error decomposes into a sum of prediction errors. This allows the emergent behavior question to be reframed as a linear system identification problem with bounded prediction error.
- Core assumption: The data distribution has a latent state space model representation, and the learner uses parametric hypothesis classes.
- Evidence anchors:
  - [section 1] "the Gaussian measure QY with the same mean and covariance as Qg−1(Z) satisfies dKL(PY ∥Qg−1(Z)) ≥ dKL(PY ∥QY)"
  - [section 1] "dKL(PZ∥Q) ≳ TXt=1EP∥Et−1P Yt − Et−1Q Yt∥2"
  - [corpus] Weak evidence - corpus contains work on policy optimization and Markov processes but not this specific decomposition
- Break condition: If the maximum entropy principle does not apply or if the bijection between state space models and data distributions breaks down.

## Foundational Learning

- Concept: Linear dynamical systems and state space models
  - Why needed here: The paper's theoretical framework is built entirely on linear state space models, which serve as the generative model for the data distribution being learned.
  - Quick check question: Can you write the state transition equation for a linear dynamical system and explain what each matrix represents?

- Concept: Ergodicity and its implications for learning
  - Why needed here: The paper's central claim about emergence relies on the distinction between ergodic and non-ergodic systems - only non-ergodic systems exhibit the critical parameter threshold phenomenon.
  - Quick check question: What is the spectral condition that distinguishes ergodic from non-ergodic linear systems, and why does it matter for learning?

- Concept: Jordan normal form and eigenvalue analysis
  - Why needed here: The proof of the main theorem relies heavily on analyzing the Jordan structure of the system matrix to determine the required parameter count.
  - Quick check question: How does the algebraic multiplicity of an eigenvalue relate to the size of its Jordan block, and why is this relevant for parameter requirements?

## Architecture Onboarding

- Component map:
  - Data generator: Linear dynamical system (either fully observed or hidden state)
  - Learner: Parametric hypothesis class (matrix mappings or finite-length filters)
  - Evaluation: Prediction error measured as expected squared error between true and predicted observations
  - Theoretical framework: KL divergence bounds and linear system identification theory

- Critical path: Generate trajectories from true system → Learn parameters from data → Predict future observations → Measure prediction error → Verify boundedness as T → ∞

- Design tradeoffs:
  - Parameter count vs. approximation quality: More parameters allow better approximation but increase computational cost
  - Filter length vs. memory requirements: Longer filters can capture more temporal dependencies but require more historical data
  - Model complexity vs. generalization: Simpler models may generalize better but fail on complex tasks

- Failure signatures:
  - Prediction error growing linearly or faster with sequence length T
  - Numerical instability in matrix computations (eigenvalue calculations)
  - Failure to converge when the true system has large Jordan blocks

- First 3 experiments:
  1. Implement a simple 2D linear system with one stable and one unstable eigenvalue; verify that learners with insufficient parameters fail while those with sufficient parameters succeed.
  2. Add observation noise to the system and test how filter length affects prediction performance as T increases.
  3. Vary the Jordan block structure (diagonal vs. non-diagonal) while keeping the same eigenvalues to observe how structure affects parameter requirements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the required filter length in Theorem 4.1 change when the state space model has multiple unstable modes?
- Basis in paper: [explicit] The paper considers only a single unstable mode in the scalar random walk model (4.7), but the general theory should apply to systems with multiple unstable eigenvalues.
- Why unresolved: The proof technique in the paper relies heavily on the simplicity of the scalar case and would need to be generalized to handle multiple Jordan blocks with different eigenvalues.
- What evidence would resolve it: A rigorous proof showing how the filter length threshold scales with the number and magnitude of unstable eigenvalues in a general state space model.

### Open Question 2
- Question: Can the emergence phenomenon be observed in nonlinear state space models with non-ergodic dynamics?
- Basis in paper: [inferred] The paper focuses on linear systems, but many real-world processes exhibit nonlinear dynamics that could lead to emergent behavior.
- Why unresolved: The current theoretical framework relies on linear system theory and may not extend to nonlinear cases without significant modifications.
- What evidence would resolve it: A theoretical analysis or empirical study demonstrating phase transitions in parameter requirements for nonlinear systems exhibiting long-range correlations.

### Open Question 3
- Question: How does the emergence threshold change when the learner uses recurrent neural networks instead of finite-length linear filters?
- Basis in paper: [explicit] The paper specifically considers finite-length linear filters (Mh) but acknowledges that other function classes allowing for some degree of nonlinearity could be interesting.
- Why unresolved: Recurrent networks have unbounded memory in principle, but practical implementations have finite context lengths, creating an interesting middle ground between the theoretical cases studied.
- What evidence would resolve it: A rigorous analysis comparing the minimum parameter requirements for successful learning between recurrent networks and linear filters on tasks with varying degrees of long-range correlation.

## Limitations
- The theoretical framework relies on strong assumptions about linear dynamical systems that may not capture the full complexity of real-world emergence in language models
- The quadratic parameter scaling law is derived under idealized conditions with perfectly linear systems and exact Gaussian noise models
- Specific parameter thresholds derived for linear systems may not directly translate to practical neural network architectures with different optimization dynamics

## Confidence
- **High confidence**: The mathematical proofs for linear systems are rigorous and follow standard techniques from system identification theory
- **Medium confidence**: The extension from linear systems to language model emergence is conceptually sound but relies on analogies requiring empirical validation
- **Low confidence**: The specific parameter thresholds may not directly translate to practical neural network architectures

## Next Checks
1. **Empirical validation on synthetic data**: Generate trajectories from linear systems with known Jordan structure and verify the predicted parameter scaling laws. Test whether learners with insufficient parameters consistently fail while those with sufficient parameters succeed, even with finite sample sizes.

2. **Extension to nonlinear approximations**: Implement the same theoretical framework using nonlinear function approximators (e.g., neural networks with varying widths) instead of linear filters. Test whether similar parameter thresholds emerge when learning nonlinear dynamical systems.

3. **Comparison with neural language models**: Analyze trained language models to measure their effective memory and ergodicity properties. Test whether models with more parameters show improved performance on tasks with known long-range correlations, consistent with the theoretical predictions.