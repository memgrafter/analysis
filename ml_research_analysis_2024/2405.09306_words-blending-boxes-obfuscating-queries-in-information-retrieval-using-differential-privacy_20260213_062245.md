---
ver: rpa2
title: Words Blending Boxes. Obfuscating Queries in Information Retrieval using Differential
  Privacy
arxiv_id: '2405.09306'
source_url: https://arxiv.org/abs/2405.09306
tags:
- privacy
- obfuscation
- mechanism
- query
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a differentially private mechanism for query
  obfuscation in Information Retrieval. It addresses the limitation of existing methods
  that fail to provide practical privacy due to insufficient noise injection.
---

# Words Blending Boxes. Obfuscating Queries in Information Retrieval using Differential Privacy

## Quick Facts
- arXiv ID: 2405.09306
- Source URL: https://arxiv.org/abs/2405.09306
- Reference count: 33
- Primary result: WBB achieves nDCG@10 of 0.622 on DeepLearning'19, approaching original query effectiveness while providing formal ε-DP privacy guarantees

## Executive Summary
This paper introduces WBB, a differentially private mechanism for query obfuscation in information retrieval systems. The key innovation is using safe and candidate boxes to exclude original terms and their highly similar synonyms from obfuscated outputs, then sampling from the candidate set using an exponential mechanism. This approach addresses the fundamental limitation of existing methods that fail to provide practical privacy due to insufficient noise injection. WBB achieves formal ε-DP guarantees while maintaining comparable retrieval effectiveness to original queries.

## Method Summary
WBB preprocesses queries by tokenizing, lowercasing, and applying POS tagging to identify names and adjectives for obfuscation. For each target word, it constructs a safe box excluding the k most similar terms, then defines a candidate box from the remaining vocabulary. The exponential mechanism samples obfuscation words from the candidate box based on normalized utility scores derived from embedding similarity. The system then reranks retrieved documents using the original query to recover effectiveness lost through obfuscation.

## Key Results
- WBB achieves nDCG@10 of 0.622 on DeepLearning'19 collection, approaching original query performance
- The mechanism provides formal ε-DP privacy guarantees through exponential mechanism sampling
- Different distance functions (angle, Euclidean, product) yield varying privacy-utility trade-offs, with angle distance showing optimal results
- POS filtering preserves function words while obfuscating semantically critical nouns and adjectives

## Why This Works (Mechanism)

### Mechanism 1
- Claim: WBB guarantees formal ε-DP while avoiding practical privacy failures by never selecting synonyms/hypernyms of the original term
- Mechanism: Constructs a "safe box" excluding the k most similar terms, then samples from the "candidate box" using an exponential mechanism based on utility scores derived from embedding similarity
- Core assumption: Semantic similarity in embedding space correlates strongly with lexical or contextual synonymy
- Evidence anchors:
  - [abstract] "WBB employs safe and candidate boxes to ensure that original terms and highly similar words are excluded from the obfuscated output."
  - [section] "We argue that it is not sufficient to add controlled statistical noise to word embeddings to ensure the privacy of the queries."
  - [corpus] Weak: no direct DP implementation evidence in neighbors; only general DP and obfuscation topics
- Break condition: If the embedding space fails to separate synonyms from unrelated terms, or if k is set too low, synonyms may still be selected

### Mechanism 2
- Claim: Using the exponential mechanism over a candidate set yields better utility-privacy trade-offs than adding noise to embeddings
- Mechanism: For each term, the candidate set excludes the k nearest neighbors, then the exponential mechanism samples replacements weighted by a normalized utility score based on similarity
- Core assumption: The candidate set size n and safe box size k can be tuned to balance recall and privacy without catastrophic data release
- Evidence anchors:
  - [section] "The exponential mechanism outputs a value r ∈ R with probability proportional to exp(εu(x,r)/∆u)."
  - [abstract] "Privacy is then guaranteed by sampling from the candidate set using an exponential mechanism."
  - [corpus] Weak: no neighbor discusses this exact sampling approach; only general DP sampling
- Break condition: If the utility function is poorly calibrated or if n is too small, the sampling becomes random and recall collapses

### Mechanism 3
- Claim: Preprocessing with POS tagging focuses perturbation on semantically critical terms, improving privacy without hurting recall
- Mechanism: Only nouns and adjectives are obfuscated, preserving function words that maintain query structure
- Core assumption: Names and adjectives carry most of the sensitive information in queries
- Evidence anchors:
  - [section] "we use Part-Of-Speech (POS) tagging to recognize names and adjectives that will be later obfuscated by WBB."
  - [abstract] "WBB preprocesses the original query text... then uses POS tagging to recognize names and adjectives."
  - [corpus] Weak: no neighbor mentions POS filtering in obfuscation
- Break condition: If sensitive terms are not captured by the chosen POS tags, or if function words carry sensitive info, privacy leaks

## Foundational Learning

- Concept: Differential Privacy (ε-DP) and the exponential mechanism
  - Why needed here: WBB's core privacy guarantee is ε-DP via the exponential mechanism; understanding sensitivity and utility is essential
  - Quick check question: What is the sensitivity ∆u in WBB and why is it bounded by 1?

- Concept: Word embeddings and semantic similarity metrics
  - Why needed here: WBB uses GloVe embeddings and cosine/Euclidean distances to define safe/candidate boxes; engineers must know how similarity translates to semantic relatedness
  - Quick check question: How does cosine similarity differ from Euclidean distance in measuring semantic closeness in embedding space?

- Concept: Information Retrieval evaluation (nDCG, recall)
  - Why needed here: WBB's effectiveness is measured via nDCG@10 and recall after reranking; engineers must interpret these metrics
  - Quick check question: Why does pooling results from multiple obfuscated queries help mitigate privacy-induced recall loss?

## Architecture Onboarding

- Component map: Original query → Preprocessing (tokenize, POS tag, lowercase) → GloVe embedding → Safe/Candidate box selection → Exponential mechanism sampling → Obfuscated query → IR system → Reranking with original query
- Critical path: Preprocessing → Safe/candidate box construction → Exponential mechanism sampling → IR system integration
- Design tradeoffs:
  - Safe box size k vs privacy vs recall: larger k = more privacy, less recall
  - Candidate box size n vs variability vs computational cost: larger n = more privacy, higher variance, more computation
  - Embedding model choice (GloVe vs contextual) vs effectiveness vs consistency
- Failure signatures:
  - Recall drops sharply if n is too small
  - Privacy breaches if k is too small or if embedding space is inadequate
  - System slowdown if candidate set construction is unoptimized
- First 3 experiments:
  1. Vary k from 0 to 20 with fixed n=50; measure privacy metrics and recall
  2. Vary n from 5 to 250 with fixed k=4; measure utility and privacy
  3. Swap GloVe with a contextual encoder; measure semantic similarity and effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of distance function (angle, Euclidean, or product) affect the balance between privacy and utility in different domains beyond IR?
- Basis in paper: [explicit] The paper compares the three distance functions and their impact on privacy and utility
- Why unresolved: The paper only tests on two IR collections. It's unclear how these findings generalize to other domains like NLP or social media
- What evidence would resolve it: Experiments on diverse datasets from various domains, comparing the performance of WBB with different distance functions

### Open Question 2
- Question: Can the WBB mechanism be extended to handle contextualized word embeddings, and what are the implications for privacy and utility?
- Basis in paper: [inferred] The paper mentions the potential for future work on "perturbing contextualized dense representations"
- Why unresolved: The paper focuses on non-contextualized embeddings. The challenges and benefits of using contextualized embeddings for query obfuscation are unknown
- What evidence would resolve it: A modified WBB mechanism that incorporates contextualized embeddings, evaluated on its privacy and utility compared to the original

### Open Question 3
- Question: How robust is the WBB mechanism against inference attacks, and what countermeasures can be developed?
- Basis in paper: [explicit] The paper mentions the need to explore "potential inference attacks against the WBB mechanism" as future work
- Why unresolved: The paper doesn't analyze the vulnerability of WBB to attacks like frequency analysis or semantic inference
- What evidence would resolve it: A thorough analysis of potential attack vectors on WBB, along with proposed defense mechanisms and their effectiveness

## Limitations
- The paper does not specify optimal values for safe box size (k) and candidate box size (n), which are critical parameters affecting the privacy-utility tradeoff
- Implementation details of the exponential mechanism sampling are not fully specified, potentially affecting reproducibility
- The choice of GloVe embeddings may limit effectiveness compared to contextual embeddings, but this comparison is not explored

## Confidence
- **High confidence** in the theoretical DP guarantee via the exponential mechanism, as this follows established privacy theory
- **Medium confidence** in practical effectiveness claims due to limited empirical validation across different collections and embedding models
- **Low confidence** in the generalizability of results to real-world scenarios where queries may contain mixed sensitive and non-sensitive terms

## Next Checks
1. **Parameter Sensitivity Analysis**: Systematically vary k (safe box size) from 0 to 20 and n (candidate box size) from 5 to 250 to quantify the impact on privacy metrics and recall, identifying optimal configurations
2. **Embedding Model Comparison**: Replace GloVe with a contextual embedding model (e.g., BERT) and measure changes in semantic similarity and IR effectiveness to assess the robustness of WBB to embedding choice
3. **Cross-Collection Validation**: Test WBB on additional IR collections beyond DL'19 and Robust '04 to evaluate performance consistency across different domains and query distributions