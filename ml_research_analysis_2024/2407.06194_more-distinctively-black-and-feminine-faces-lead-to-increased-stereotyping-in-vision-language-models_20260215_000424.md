---
ver: rpa2
title: More Distinctively Black and Feminine Faces Lead to Increased Stereotyping
  in Vision-Language Models
arxiv_id: '2407.06194'
source_url: https://arxiv.org/abs/2407.06194
tags:
- prototypicality
- gender
- interaction
- americans
- femininity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: VLMs can reproduce racial and gender stereotypes, especially for
  faces perceived as more prototypically Black or feminine. In Study 1, GPT-4V generated
  more homogeneous stories about Black faces compared to White faces, with greater
  homogeneity linked to higher perceived Blackness.
---

# More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models

## Quick Facts
- arXiv ID: 2407.06194
- Source URL: https://arxiv.org/abs/2407.06194
- Reference count: 40
- VLMs reproduce racial and gender stereotypes, especially for faces perceived as more prototypically Black or feminine

## Executive Summary
Vision-Language Models (VLMs) exhibit increased stereotyping when generating text about faces perceived as more prototypically Black or feminine. Using GPT-4V, the study found that generated stories were more homogeneous (semantically similar) for faces rated higher in prototypicality, suggesting stronger stereotype activation. These effects were observed for both racial and gender stereotypes, with prototypicality driving stereotyping beyond simple group membership. The research indicates that visual cues in facial images trigger stereotype-associated text generation in VLMs.

## Method Summary
The study used 186 African and White American male faces and 183 White American male and female faces from the Chicago Face Database. GPT-4V generated 50-word stories for each face image. Homogeneity bias was measured using cosine similarity of Sentence-BERT embeddings across generated stories. Structural Topic Models (STMs) identified latent topics and their prevalence across groups and prototypicality levels. Prototypicality ratings from CFD served as the key independent variable for analyzing stereotyping patterns.

## Key Results
- Stories about Black faces were more homogeneous than stories about White faces, with greater homogeneity linked to higher perceived Blackness
- Stories about women were more homogeneous than stories about men, especially for faces rated as more feminine
- The prototypicality effect was stronger for men than women, with men showing greater stereotyping for feminine faces

## Why This Works (Mechanism)

### Mechanism 1
Stereotyping increases when visual cues are more prototypical of a group. The model maps image embeddings to group-associated textual embeddings. Faces rated more prototypical trigger stronger group membership signals, leading to more stereotyped text generation. Core assumption: Prototype ratings align with the visual features the model uses to infer group identity.

### Mechanism 2
Gender and race stereotypes are driven by perceived group membership rather than explicit attributes. The model implicitly infers group membership from facial features and then generates text using learned associations between that membership and stereotyped traits. Core assumption: Group membership is inferred from facial features without explicit annotation.

### Mechanism 3
Reinforcement Learning with Human Feedback (RLHF) can amplify or distort stereotypes. RLHF may suppress overt stereotypes but leave subtle ones intact, or even introduce new associations based on human preference patterns. Core assumption: RLHF filters affect trait associations differently across groups.

## Foundational Learning

- Concept: Cosine similarity as a homogeneity metric
  - Why needed here: The paper quantifies stereotyping by comparing semantic similarity of generated texts
  - Quick check question: What does a higher cosine similarity between two generated texts indicate in this context?

- Concept: Structural Topic Models (STM)
  - Why needed here: STM identifies latent topics and models their prevalence as a function of group and prototypicality
  - Quick check question: In STM, what does the prevalence of a topic represent?

- Concept: Prototypicality ratings
  - Why needed here: Ratings determine how stereotypically a face represents its group, which drives stereotyping levels
  - Quick check question: How is prototypicality measured in the Chicago Face Database?

## Architecture Onboarding

- Component map: Image encoder (VLM visual backbone) -> Text generator (LLM component) -> Embedding space (shared multimodal space) -> Prompt processor (formatting and instructions) -> Output filter (RLHF layer, if present)

- Critical path: Face image → visual embedding → group membership inference → stereotype-associated text generation → text → cosine similarity or topic extraction

- Design tradeoffs: Use of large datasets → higher generalization but potential for hidden biases; RLHF → reduced overt bias but possible subtle distortions; Prototypicality ratings → good proxy for group cues but subjective

- Failure signatures: Increased cosine similarity for prototypical faces; Topic prevalence shifts with prototypicality; Unexpected trait associations (e.g., women and firefighting)

- First 3 experiments: 1) Measure cosine similarity for faces at different prototypicality levels within one group; 2) Compare topic prevalence across groups for high vs. low prototypicality faces; 3) Test whether masking certain facial features reduces stereotypical output

## Open Questions the Paper Calls Out
- How does the inclusion of non-binary gender identities in the dataset affect the homogeneity bias and trait associations observed in VLMs?
- To what extent do intersectional approaches, considering the interaction between race and gender, alter the patterns of stereotyping observed in VLMs?
- What are the specific mechanisms by which Reinforcement Learning with Human Feedback (RLHF) introduces new biases in VLM-generated texts?

## Limitations
- Study focused exclusively on binary gender identities due to dataset constraints
- Results based on single VLM (GPT-4V), limiting generalizability to other models
- Prototypicality ratings are subjective and may not perfectly align with model-perceived visual features

## Confidence
- High confidence: VLM-generated stories show greater homogeneity for faces rated as more prototypically Black or feminine
- Medium confidence: Effects are driven by visual cues rather than explicit group membership
- Low confidence: RLHF specifically amplifies certain stereotype-related traits

## Next Checks
1. Repeat the study with at least two additional VLMs (e.g., Claude-3 Vision, Gemini Pro Vision) to assess whether prototypicality effects generalize across different architectures and training approaches
2. Systematically mask or modify specific facial features (skin tone, facial structure, hair texture) to determine which visual cues drive the prototypicality-stereotyping relationship
3. Have human raters evaluate a subset of VLM-generated stories for stereotypical content to verify that cosine similarity increases correspond to increased stereotypical content rather than other semantic patterns