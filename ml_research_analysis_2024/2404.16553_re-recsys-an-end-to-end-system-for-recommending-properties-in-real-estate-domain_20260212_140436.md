---
ver: rpa2
title: 'RE-RecSys: An End-to-End system for recommending properties in Real-Estate
  domain'
arxiv_id: '2404.16553'
source_url: https://arxiv.org/abs/2404.16553
tags:
- users
- user
- properties
- have
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes RE-RecSys, an end-to-end real-estate recommendation\
  \ system designed for production environments. The system classifies users into\
  \ four categories\u2014cold-start, short-term, long-term, and short-long term\u2014\
  and applies tailored recommendation strategies for each."
---

# RE-RecSys: An End-to-End system for recommending properties in Real-Estate domain

## Quick Facts
- arXiv ID: 2404.16553
- Source URL: https://arxiv.org/abs/2404.16553
- Reference count: 14
- One-line primary result: RE-RecSys achieves MAP@6 up to 0.881 and NDCG up to 0.69 across user categories, with sub-40 ms latency at 1,000 rpm.

## Executive Summary
RE-RecSys is an end-to-end real-estate recommendation system designed for production environments, addressing the challenge of recommending properties to users with varying levels of interaction history. The system classifies users into four categories—cold-start, short-term, long-term, and short-long term—and applies tailored recommendation strategies for each. Cold-start users are handled with a rule-based engine using locality popularity and preferences; short-term users are served via content filtering based on recent interactions; long-term users use a combination of content and collaborative filtering with a daily retrained ALS model; and short-long term users receive hybrid recommendations averaging both short- and long-term scores. The system achieves high precision (MAP@6 up to 0.881) and NDCG (up to 0.69) while maintaining sub-40 ms latency at 1,000 requests per minute.

## Method Summary
RE-RecSys categorizes users into four types based on historical interaction data and applies distinct recommendation strategies for each. For cold-start users, a rule-based engine uses locality popularity and user preferences to select properties. Short-term users are recommended properties via content filtering using recent interactions and conversion rate-weighted user profiles. Long-term users receive hybrid recommendations combining content and collaborative filtering, with a daily retrained ALS model. Short-long term users get averaged scores from short- and long-term models. The system uses feature engineering and weighting schemes for user interactions, with retraining intervals of every 2 hours for content models and daily for ALS.

## Key Results
- MAP@6 up to 0.881 and NDCG up to 0.69 across user categories.
- Sub-40 ms latency at 1,000 requests per minute in production.
- High recommendation relevance and coverage, validated via offline experiments and real-world deployment.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cold-start users are effectively handled by a rule-based engine using locality popularity and user preferences, avoiding the cold-start problem for new properties.
- Mechanism: The system builds cohorts based on locality, apartment type, profile type, price, and area bins. Each cohort is scored using a weighted sum of property density, total leads, and conversion rates. Properties are then randomly selected from the top cohorts to ensure new properties get exposure.
- Core assumption: Random selection from top cohorts ensures fair visibility and improves model learning by exposing new properties.
- Evidence anchors:
  - [abstract] "For cold-start users, we propose a novel rule-based engine that is based on the popularity of locality and user preferences."
  - [section] "Finally, the top-N matching cohorts are extracted based on search filters for any user, then we return the randomly chosen top 2 properties from each cohort."
  - [corpus] Weak evidence: No direct corpus papers on random selection strategies for cold-start in real-estate.
- Break condition: If cohort scoring does not correlate with user satisfaction or conversion, or if random selection fails to expose properties to relevant users.

### Mechanism 2
- Claim: Short-term users receive personalized recommendations using content-based filtering based on their recent 10 minutes of interactions.
- Mechanism: User profiles are built by converting interaction features into binary vectors and applying weights based on conversion rates. Similarity scores between user profiles and property vectors are calculated using cosine similarity.
- Core assumption: User behavior weights based on conversion rates accurately reflect user preferences and improve recommendation relevance.
- Evidence anchors:
  - [abstract] "For short-term users, we propose to use content-filtering model which recommends properties based on recent interactions of users."
  - [section] "For the user profile vector, we calculate the weighted sum of all the activities done by the user over various properties instead of binary encoding."
  - [corpus] Weak evidence: No direct corpus papers on conversion rate-weighted user profiles in real-estate.
- Break condition: If the 10-minute window is too short or too long to capture meaningful user preferences, or if conversion rate weights are not representative.

### Mechanism 3
- Claim: Long-term users are served by a hybrid of content and collaborative filtering, with a daily retrained ALS model to balance freshness and latency.
- Mechanism: The system uses matrix factorization via ALS for collaborative filtering, trained on weighted user interactions. Content models are retrained every 2 hours. Scores from both models are averaged for recommendations.
- Core assumption: Daily retraining of ALS provides sufficient model freshness without excessive latency, and hybrid scores improve recommendation accuracy.
- Evidence anchors:
  - [abstract] "For long-term and short-long term users, we propose a novel combination of content and collaborative filtering based approach which can be easily productionized in the real-world scenario."
  - [section] "We propose to re-train the collaborative filtering model once a day and use content filtering for users who have interacted with more than five properties but were not included in the previous ALS re-training."
  - [corpus] Weak evidence: No direct corpus papers on daily retraining schedules for ALS in real-estate.
- Break condition: If daily retraining does not capture significant user preference shifts, or if hybrid averaging degrades recommendation quality.

## Foundational Learning

- Concept: User segmentation based on historical data availability.
  - Why needed here: Enables application of different recommendation strategies tailored to the amount and recency of user data, improving relevance and system efficiency.
  - Quick check question: What are the four user categories in RE-RecSys, and how is each handled?

- Concept: Matrix factorization and Alternating Least Squares (ALS) for collaborative filtering.
  - Why needed here: Handles the sparse user-property interaction matrix in real-estate, enabling personalized recommendations based on similar users' behaviors.
  - Quick check question: Why is ALS chosen for long-term users, and what are its advantages in this context?

- Concept: Feature engineering and weighting schemes for user interactions.
  - Why needed here: Converts diverse user actions into a unified numerical representation, allowing the model to prioritize actions that lead to conversions.
  - Quick check question: How are different user actions weighted, and why is this important for content-based filtering?

## Architecture Onboarding

- Component map: Cold-start engine (rule-based) -> short-term content filter -> long-term hybrid (content + ALS) -> short-long hybrid -> REST API -> UI integration widgets.
- Critical path: User request → user classification → model selection → feature computation → recommendation generation → API response → UI display.
- Design tradeoffs: Latency vs. model freshness (daily vs. 2-hour retraining), model complexity vs. interpretability, random property selection vs. deterministic ranking.
- Failure signatures: High latency (>40ms), low MAP@N or NDCG scores, cold-start properties not getting exposure, user dissatisfaction due to irrelevant recommendations.
- First 3 experiments:
  1. Validate user classification accuracy by testing with synthetic user histories.
  2. Test cold-start cohort scoring and random property selection for coverage and relevance.
  3. Benchmark content filtering latency and precision@K for short-term users.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different weighting schemes for user interactions impact recommendation performance in short-term users?
- Basis in paper: [explicit] The paper describes a novel weighing scheme based on conversion rates for user interactions, but does not compare it with alternative schemes.
- Why unresolved: The paper uses a specific weighting scheme for user interactions but does not explore or compare it with other possible schemes.
- What evidence would resolve it: Experimental results comparing the proposed weighting scheme with other schemes like uniform weighting, time-decay weighting, or machine-learned weights would provide insights into the optimal approach.

### Open Question 2
- Question: How does the performance of RE-RecSys vary across different cities or regions with varying property markets?
- Basis in paper: [inferred] The paper uses a dataset from a leading real-estate platform in India, but does not discuss how the system performs in different cities or regions.
- Why unresolved: The paper does not provide any analysis of how the system's performance varies across different geographic locations or property markets.
- What evidence would resolve it: Performance metrics (e.g., MAP, NDCG) for RE-RecSys in different cities or regions would help understand the system's adaptability to varying market conditions.

### Open Question 3
- Question: How does the cold-start rule-based engine handle new properties that do not fit into existing cohorts?
- Basis in paper: [explicit] The paper mentions that new properties will fall under some cohort and random selection from cohorts helps overcome the cold-start problem, but does not detail the mechanism for properties that do not fit existing cohorts.
- Why unresolved: The paper does not provide details on how the system handles new properties that do not fit into any existing cohort.
- What evidence would resolve it: A detailed explanation of the mechanism for handling properties that do not fit existing cohorts, along with performance metrics for such properties, would provide insights into the robustness of the cold-start engine.

## Limitations

- Random property selection for cold-start users lacks direct validation or comparison to deterministic methods.
- Hybrid approach for long-term and short-long term users is not rigorously tested against pure collaborative or content models.
- Reported metrics lack statistical significance testing and comparison to strong baselines.

## Confidence

- **High Confidence**: User categorization logic, latency targets, and system architecture are well-specified and grounded in standard practices.
- **Medium Confidence**: The overall recommendation pipeline and hybrid strategies are plausible and aligned with production requirements, but some details are underspecified.
- **Low Confidence**: Specific implementation details for cohort scoring, feature binning, ALS hyperparameters, and random property selection lack clarity.

## Next Checks

1. Validate the statistical significance of reported MAP@6 and NDCG improvements over baseline methods.
2. Conduct an ablation study to isolate the contribution of hybrid modeling and random property selection to overall performance.
3. Test the cold-start model's ability to expose new properties and measure its impact on long-term model learning.