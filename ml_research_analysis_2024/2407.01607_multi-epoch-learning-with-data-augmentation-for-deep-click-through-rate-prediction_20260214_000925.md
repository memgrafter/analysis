---
ver: rpa2
title: Multi-Epoch learning with Data Augmentation for Deep Click-Through Rate Prediction
arxiv_id: '2407.01607'
source_url: https://arxiv.org/abs/2407.01607
tags:
- training
- meda
- data
- learning
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the one-epoch overfitting problem in deep CTR
  models, where model performance drops significantly after the first training epoch.
  The authors attribute this to overfitting of the embedding layer due to high-dimensional
  data sparsity.
---

# Multi-Epoch learning with Data Augmentation for Deep Click-Through Rate Prediction

## Quick Facts
- arXiv ID: 2407.01607
- Source URL: https://arxiv.org/abs/2407.01607
- Authors: Zhongxiang Fan; Zhaocheng Liu; Jian Liang; Dongying Kong; Han Li; Peng Jiang; Shuang Li; Kun Gai
- Reference count: 40
- One-line primary result: MEDA achieves 0.8% to 4.6% AUC improvement over single-epoch training in deep CTR models

## Executive Summary
This paper addresses the critical problem of one-epoch overfitting in deep CTR models, where performance drops sharply after the first training epoch due to embedding layer overfitting from high-dimensional sparse data. The authors propose MEDA (Multi-Epoch learning with Data Augmentation), a framework that reinitializes embedding parameters at the start of each epoch to reduce overfitting and achieve data augmentation. MEDA has been successfully deployed in a real-world advertising system, demonstrating significant improvements in online A/B testing. The framework includes two variants: non-continual MEDA (reinitializes embeddings every epoch) and continual MEDA (maintains multiple independently initialized embedding layers).

## Method Summary
MEDA tackles one-epoch overfitting by reinitializing embedding parameters at the start of each training epoch, breaking the dependency between embeddings and training data. The framework leverages the observation that MLP layers learn relative relationships among embeddings rather than their absolute positions, allowing them to adapt to different embedding spaces. This creates a form of data augmentation where the MLP effectively sees more diverse representations of the same categorical features. The method includes two variants: non-continual MEDA, which reinitializes embeddings every epoch, and continual MEDA, which maintains multiple independently initialized embedding layers to address catastrophic forgetting in continual learning scenarios.

## Key Results
- MEDA outperforms single-epoch training by 0.8% to 4.6% in test AUC on both public and business datasets
- MEDA achieves comparable performance to single-epoch training with only half the data, demonstrating effective data augmentation
- The framework has been successfully deployed in a real-world advertising system with significant improvements in online A/B testing
- MLP layers can adapt to new embedding spaces without catastrophic performance loss, validating the data augmentation hypothesis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reinitializing embedding parameters at the start of each epoch prevents overfitting by breaking the exact alignment between embedding weights and training data.
- Mechanism: High-dimensional sparse features with low occurrence rates cause embedding vectors to memorize training samples. Reinitializing embeddings each epoch prevents this memorization while the MLP learns relative relationships across varied embedding spaces.
- Core assumption: Embedding overfitting is the primary cause of one-epoch overfitting, and MLP layers can adapt to different embedding spaces without catastrophic performance loss.
- Evidence anchors: [abstract] "We identify the overfitting of the embedding layer, caused by high-dimensional data sparsity, as the primary issue." [section 4.1] "Specifically, repeated training of the embedding layer on the same dataset leads to significant overfitting."

### Mechanism 2
- Claim: MLP layers learn a matching function based on relative relationships among embeddings rather than their absolute positions.
- Mechanism: When embeddings are reinitialized each epoch, the MLP must learn to identify patterns based on relationships between embedding vectors rather than specific values, allowing generalization across different embedding spaces.
- Core assumption: The MLP's role in CTR prediction is to learn relative patterns that are invariant to specific embedding values.
- Evidence anchors: [abstract] "Our findings confirm that pre-trained MLP layers can adapt to new embedding spaces, enhancing performance without overfitting." [section 4.1] "Despite significant differences in the final embedding parameters across epochs, the essential insight is that for CTR model MLP layers, the precise values or absolute positions of embeddings are less critical than their interrelations."

### Mechanism 3
- Claim: Multi-epoch training with varied embedding spaces achieves data augmentation by providing the MLP with diverse representations of the same categorical features.
- Mechanism: Each reinitialization creates a new embedding space for the same categorical features. The MLP learns to extract relevant patterns across these different spaces, effectively seeing more diverse data than what exists in the original dataset.
- Core assumption: Different random initializations of embeddings provide meaningfully different representations that the MLP can learn from.
- Evidence anchors: [abstract] "MEDA minimizes overfitting by reducing the dependency of the embedding layer on subsequent training data or the Multi-Layer Perceptron (MLP) layers, and achieves data augmentation through training the MLP with varied embedding spaces." [section 5.2] "Tables 4 and 5 demonstrate that MEDA achieves comparable test AUC to single-epoch learning with fewer data."

## Foundational Learning

- Concept: Embedding layer overfitting in high-dimensional sparse data
  - Why needed here: Understanding why embedding layers overfit in CTR prediction is crucial for grasping MEDA's approach
  - Quick check question: Why do embedding layers overfit more severely than MLP layers in CTR models with sparse data?

- Concept: Catastrophic forgetting and continual learning
  - Why needed here: MEDA's continual learning variant addresses catastrophic forgetting by maintaining multiple embedding spaces
  - Quick check question: How does MEDA's approach to continual learning differ from traditional methods in handling catastrophic forgetting?

- Concept: Data augmentation techniques
  - Why needed here: MEDA's effectiveness relies on treating varied embedding spaces as augmented data for the MLP
  - Quick check question: How does MEDA's form of data augmentation compare to traditional methods like rotation or flipping in computer vision?

## Architecture Onboarding

- Component map: Input layer (sparse categorical features) → Embedding layer (reinitialized each epoch) → MLP layers (learn matching function) → Output layer (CTR prediction)
- Critical path: Feature → Embedding (reinitialized) → MLP (trained) → Prediction
  - Key insight: The MLP must be able to generalize across different embedding initializations
- Design tradeoffs:
  - Storage cost: MEDA-C requires storing multiple embedding parameter sets
  - Computation cost: Additional initialization overhead vs. improved performance
  - Model complexity: Simple addition of reinitialization vs. complex regularization
- Failure signatures:
  - MLP performance drops significantly with reinitialized embeddings
  - Test AUC decreases across epochs (overfitting occurs)
  - Similar embedding parameters across different epochs (weak augmentation)
- First 3 experiments:
  1. Implement non-continual MEDA on a simple DNN CTR model with Amazon dataset, compare AUC across epochs vs. baseline
  2. Test MLP adaptability by freezing embeddings from epoch 1 and training MLP for additional epochs
  3. Compare storage and computation costs of MEDA-C vs. single-epoch training on a business dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the dependency between embedding and MLP layers affect overfitting in deep CTR models, and can this be quantified?
- Basis in paper: [explicit] The paper identifies embedding-data and embedding-MLP dependencies as key factors in overfitting, suggesting that reducing these dependencies can mitigate overfitting.
- Why unresolved: The paper does not provide a quantitative measure of these dependencies or how they directly impact overfitting, leaving the exact mechanism unclear.
- What evidence would resolve it: Experiments that measure the impact of varying the strength of these dependencies on overfitting, possibly through controlled experiments with different initialization strategies or regularization techniques.

### Open Question 2
- Question: What is the impact of data augmentation through MEDA on the convergence speed of MLP layers, and how does it compare to traditional data augmentation methods?
- Basis in paper: [explicit] The paper suggests that MEDA acts as a form of data augmentation by training MLP layers with varied embedding spaces, potentially enhancing convergence.
- Why unresolved: The paper does not compare MEDA's data augmentation effects to traditional methods, nor does it provide detailed analysis on convergence speed improvements.
- What evidence would resolve it: Comparative studies measuring convergence speed and model performance between MEDA and traditional data augmentation techniques, possibly using different CTR models and datasets.

### Open Question 3
- Question: How can the principles of differential privacy be applied to improve MEDA's performance by tailoring noise levels based on feature frequency?
- Basis in paper: [explicit] The paper suggests that differential privacy principles could be applied to MEDA by designing noise levels based on the frequency of categorical features, potentially enhancing performance.
- Why unresolved: The paper does not explore this application or provide experimental results to validate its effectiveness.
- What evidence would resolve it: Implementation of differential privacy techniques in MEDA, followed by experiments demonstrating improved performance on datasets with varying feature frequencies.

## Limitations

- The theoretical understanding of why MLP layers generalize across reinitialized embeddings remains incomplete
- Storage overhead of MEDA-C (maintaining multiple embedding spaces) is not thoroughly analyzed against performance gains
- Sensitivity of results to embedding dimension and initialization methods is not explored systematically

## Confidence

- **High Confidence**: The empirical demonstration that one-epoch overfitting occurs and that MEDA mitigates this issue (AUC improvements of 0.8-4.6%)
- **Medium Confidence**: The mechanism that MLP layers learn relative relationships rather than absolute positions (supported by observations but not rigorously proven)
- **Medium Confidence**: The data augmentation claim (demonstrated through reduced data requirements but not directly measured)

## Next Checks

1. Conduct ablation studies on MLP layer configurations to determine the minimum architecture required for effective cross-embedding generalization
2. Measure and compare the actual diversity of embedding spaces produced by different random initializations using embedding similarity metrics
3. Implement a controlled experiment comparing MEDA's data augmentation effect against traditional augmentation techniques (feature dropout, synthetic data generation) on the same datasets