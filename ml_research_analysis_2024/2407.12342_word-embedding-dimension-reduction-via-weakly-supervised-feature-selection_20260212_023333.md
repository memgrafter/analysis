---
ver: rpa2
title: Word Embedding Dimension Reduction via Weakly-Supervised Feature Selection
arxiv_id: '2407.12342'
source_url: https://arxiv.org/abs/2407.12342
tags:
- word
- feature
- dimension
- embeddings
- ours
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a weakly-supervised feature selection method
  for word embedding dimension reduction. The approach leverages word similarity data
  as weak supervision to identify and retain the most informative dimensions while
  discarding redundant ones.
---

# Word Embedding Dimension Reduction via Weakly-Supervised Feature Selection

## Quick Facts
- arXiv ID: 2407.12342
- Source URL: https://arxiv.org/abs/2407.12342
- Reference count: 0
- Proposes weakly-supervised feature selection method that outperforms existing techniques while being 10-10,000x faster

## Executive Summary
This paper introduces WordFS, a weakly-supervised feature selection method for reducing word embedding dimensions while preserving semantic information. The approach uses word similarity data as weak supervision to identify and retain informative dimensions while discarding redundant ones. WordFS achieves superior performance compared to existing dimension reduction techniques across multiple tasks including word similarity and downstream applications like classification and sentence similarity. The method demonstrates significant computational efficiency gains, often being orders of magnitude faster than deep learning-based alternatives.

## Method Summary
WordFS operates in three stages: an optional post-processing step that extracts meaningful pairs and removes redundant dimensions, a pair-wise feature extraction phase that computes contributions to specific pairs, and a feature selection stage using either RFT for prediction tasks or Spearman's rank correlation for similarity tasks. The method leverages external similarity datasets as weak supervision, allowing it to identify dimensions that capture semantic relationships without requiring extensive labeled data. The approach can be applied to various word embedding types including GloVe, Word2Vec, and FastText.

## Key Results
- Outperforms existing dimension reduction techniques on word similarity and downstream tasks
- Achieves 10 to 10,000 times faster computation compared to deep learning-based methods
- Maintains strong performance across multiple embedding types (GloVe, Word2Vec, FastText)
- Shows consistent improvements in both classification and sentence similarity tasks

## Why This Works (Mechanism)
The method works by leveraging weak supervision through word similarity data to identify which dimensions in word embeddings capture meaningful semantic relationships. By focusing on pair-wise feature contributions and using statistical measures to select informative dimensions, WordFS can effectively reduce dimensionality while preserving the most semantically relevant information. The three-stage pipeline allows for systematic identification and retention of dimensions that contribute most to semantic similarity, while discarding redundant or less informative dimensions.

## Foundational Learning
- Word embeddings: Dense vector representations where semantic relationships are encoded in geometric relationships between vectors
  - Why needed: Understanding how semantic information is distributed across dimensions
  - Quick check: Can you explain why "king - man + woman â‰ˆ queen" in vector space?

- Weak supervision: Using readily available but imperfect labels (word similarity scores) instead of expensive manual annotation
  - Why needed: Enables feature selection without requiring task-specific labeled data
  - Quick check: What are the trade-offs between weak and strong supervision?

- Feature selection: Identifying and retaining only the most informative dimensions while discarding redundant ones
  - Why needed: Reduces computational cost and storage while maintaining model performance
  - Quick check: How does feature selection differ from feature extraction?

## Architecture Onboarding

Component Map:
Post-processing -> Pair-wise feature extraction -> Feature selection (RFT/Spearman)

Critical Path:
The post-processing stage (when used) filters out irrelevant dimensions early, pair-wise extraction computes dimension contributions for specific word pairs, and feature selection applies statistical criteria to retain only the most informative dimensions for the target task.

Design Tradeoffs:
- Post-processing inclusion vs. computational overhead
- RFT vs. Spearman's correlation based on task type
- Dimension retention threshold (0.5) vs. information preservation

Failure Signatures:
- Inconsistent post-processing retention rates (27-77%) across embedding types
- Potential domain mismatch when using general similarity datasets for specialized embeddings
- Sensitivity to the 0.5 threshold without theoretical justification

First Experiments:
1. Apply WordFS to a small GloVe embedding subset and visualize retained dimensions
2. Compare RFT vs. Spearman's correlation on a word similarity task
3. Measure computational time reduction compared to baseline PCA

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Heavy reliance on external similarity datasets may limit generalization to specialized domains or languages
- Post-processing step shows inconsistent behavior across embedding types with variable dimension retention rates
- Threshold of 0.5 for feature selection lacks theoretical justification and may require task-specific tuning

## Confidence

Performance Claims: High confidence - Extensive experiments across multiple datasets and tasks support the reported improvements

Generalizability Claims: Medium confidence - Results are consistent across three embedding types but limited to English and specific similarity datasets

Methodological Claims: Medium confidence - Framework is well-described but sensitivity to hyperparameters and theoretical justification for threshold choices need further exploration

## Next Checks

1. Cross-linguistic validation: Test WordFS on non-English word embeddings (multilingual BERT, FastText in other languages) to verify cross-linguistic robustness

2. Domain adaptation: Apply the method to specialized domain embeddings (medical, legal, technical) to assess performance on out-of-distribution data

3. Ablation studies: Systematically remove each stage of the pipeline to quantify individual contributions of post-processing, feature extraction, and selection steps to overall performance