---
ver: rpa2
title: '$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient
  Finetuning'
arxiv_id: '2405.17258'
source_url: https://arxiv.org/abs/2405.17258
tags:
- lora
- data
- synthetic
- transfer
- trans-lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of transferring parameter-efficient
  fine-tuning (PEFT) models, specifically LoRA, between different base language models
  without access to the original task data. The proposed method, Trans-LoRA, uses
  synthetic data generation and a discriminator model to create a transfer curriculum
  that allows LoRA models to be effectively transferred across different base models
  and even different PEFT methods.
---

# $\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning

## Quick Facts
- arXiv ID: 2405.17258
- Source URL: https://arxiv.org/abs/2405.17258
- Authors: Runqian Wang; Soumya Ghosh; David Cox; Diego Antognini; Aude Oliva; Rogerio Feris; Leonid Karlinsky
- Reference count: 40
- Primary result: Data-free transfer of LoRA models across different base models and PEFT methods

## Executive Summary
This paper addresses the challenge of transferring parameter-efficient fine-tuning (PEFT) models, specifically LoRA, between different base language models without access to the original task data. The proposed method, Trans-LoRA, uses synthetic data generation and a discriminator model to create a transfer curriculum that allows LoRA models to be effectively transferred across different base models and even different PEFT methods. The key innovation is using the target base model itself to generate synthetic data, filtered by a discriminator trained on a mix of synthetic and real data, to approximate the original training distribution. Experiments on 86 tasks across multiple benchmarks (BBH, MMLU, MBPP, GSM8K) using Llama2 and Gemma model families demonstrate that Trans-LoRA achieves lossless transfer, often improving performance beyond the maximum of the source LoRA and target base model. The method works across different PEFT variants (LoRA, DoRA, Prompt Tuning) and scales well with increased synthetic data generation.

## Method Summary
Trans-LoRA enables data-free transfer of LoRA parameters between different base models by using synthetic data generation and discriminator-based filtering. The method takes a source model with trained LoRA parameters, a target model, and a small set of seed examples (typically 5 samples) as input. It generates synthetic data using the target model as the generator, trains a discriminator on a mix of synthetic and real data to filter synthetic samples that match the original training distribution, and then performs knowledge distillation to transfer LoRA parameters from source to target model. The synthetic data must follow both the task data distribution and the original training set distribution to ensure effective transfer. The method achieves lossless transfer by creating a curriculum where synthetic data is iteratively refined to match the original training distribution through discriminator filtering.

## Key Results
- Trans-LoRA achieves lossless transfer on BBH benchmark, matching baseline performance (50.2% vs 50.0%)
- The method consistently outperforms both the source LoRA and target base model across 86 tasks
- Transfer works across different PEFT methods (LoRA, DoRA, Prompt Tuning) and model families (Llama2, Gemma)
- Performance scales with increased synthetic data generation, with optimal performance at 1000 examples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic data filtered by a discriminator trained on a mix of real and synthetic data approximates the original task data distribution
- Mechanism: The discriminator learns to distinguish between real task data and synthetic data, creating a curriculum where synthetic data must be statistically indistinguishable from real task data to pass filtering
- Core assumption: The discriminator can effectively learn the distribution of real task data from a small subset, and this learned distribution generalizes to filter synthetic data for transfer
- Evidence anchors:
  - [abstract] "Using large language models, we design a synthetic data generator to approximate the data-generating process of the observed task data subset"
  - [section 3.1] "Our proposed discriminator is trained on a mix of synthetic and real data alongside the source LoRA model"
  - [corpus] Weak evidence - related papers mention data-free transfer but don't explain the discriminator mechanism in detail
- Break condition: If the discriminator cannot effectively learn the distribution from the small real data subset, the filtering becomes random and transfer fails

### Mechanism 2
- Claim: Knowledge distillation from the source LoRA model on synthetic data that matches the original training distribution enables lossless transfer
- Mechanism: The source LoRA model acts as a teacher, and the target model learns to replicate the teacher's behavior on inputs that follow the same distribution as the original training data
- Core assumption: The synthetic data that passes discriminator filtering follows the same marginal distribution as the original task data inputs
- Evidence anchors:
  - [section 3.1] "the synthetic data must also adhere to one additional important requirement - it must also follow the distribution used to sample the original training set D out of all possible task data"
  - [abstract] "Training on the resulting synthetic dataset transfers LoRA modules to new models"
  - [corpus] Weak evidence - related work discusses knowledge distillation but not specifically for PEFT transfer
- Break condition: If the synthetic data doesn't match the original training distribution, the target LoRA won't learn the same task capabilities as the source LoRA

### Mechanism 3
- Claim: Using the target model itself for synthetic data generation creates data that is compatible with the target model's capabilities
- Mechanism: The target model, when prompted with task demonstrations, generates synthetic examples that are more likely to be within its understanding and capability range
- Core assumption: The target model can generate synthetic data that follows the task distribution when given appropriate demonstrations
- Evidence anchors:
  - [section 3.1] "we used the target model Mt itself for Mgen, but any model capable of following detailed instructions can be used in its place"
  - [abstract] "Using large language models, we design a synthetic data generator to approximate the data-generating process"
  - [corpus] Weak evidence - no direct evidence in related work about using target model for synthetic data generation
- Break condition: If the target model cannot generate meaningful synthetic data following the task distribution, the transfer curriculum becomes ineffective

## Foundational Learning

- Concept: Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning
  - Why needed here: Understanding why LoRA models are specific to base models and cannot be directly transferred
  - Quick check question: What makes LoRA parameters specific to a particular base model architecture?

- Concept: Knowledge distillation and its requirements for effective transfer
  - Why needed here: The paper relies on distilling knowledge from source LoRA to target LoRA using synthetic data
  - Quick check question: Why does naive distillation on few seed examples fail in this context?

- Concept: Generative adversarial networks (GANs) and discriminator training
  - Why needed here: The discriminator is trained similarly to GAN discriminators to filter synthetic data
  - Quick check question: How does training a discriminator on mixed real/synthetic data help in filtering synthetic data for transfer?

## Architecture Onboarding

- Component map:
  - Source model with trained LoRA
  - Target model (new base model)
  - Discriminator model (LLM with PEFT)
  - Data generator (LLM, typically target model)
  - Synthetic data filtering pipeline
  - Knowledge distillation training loop

- Critical path:
  1. Train discriminator on mix of real task data and synthetic data from source model
  2. Generate synthetic data using target model and seed examples
  3. Filter synthetic data using trained discriminator
  4. Distill knowledge from source LoRA to target LoRA on filtered synthetic data

- Design tradeoffs:
  - Using target model vs source model for data generation
  - Number of seed examples vs. quality of synthetic data
  - Discriminator training complexity vs. filtering effectiveness
  - Amount of synthetic data generated vs. training time

- Failure signatures:
  - Source LoRA outperforms transferred LoRA (indicates ineffective distillation)
  - Target base model outperforms transferred LoRA (indicates poor synthetic data quality)
  - Inconsistent performance across different tasks (indicates discriminator overfitting)

- First 3 experiments:
  1. Transfer LoRA from Llama-2-7b to Llama-2-13b with Llama-2-7b discriminator
  2. Transfer LoRA from Gemma-2b to Gemma-7b with Gemma-2b discriminator
  3. Transfer LoRA from Llama-2-7b to Gemma-7b with Gemma-2b discriminator

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Trans-LoRA change when using different base models for data synthesis (Mgen) rather than the target model itself?
- Basis in paper: Inferred from the statement "In our experiments, we used the target model Mt itself for Mgen, but any model capable of following detailed instructions can be used in its place."
- Why unresolved: The paper only reports results using the target model as Mgen, so the impact of using alternative base models is unknown.
- What evidence would resolve it: Experiments comparing Trans-LoRA performance across various choices of Mgen (e.g., different model sizes, families, or even non-LLM models) would quantify the effect on transfer quality.

### Open Question 2
- Question: What is the impact of the discriminator architecture (e.g., using a different PEFT method or model size) on the quality of filtered synthetic data and final transfer performance?
- Basis in paper: Inferred from the description of the discriminator training process and its role in filtering synthetic data.
- Why unresolved: The paper uses a LoRA-based discriminator trained on the source model, but the sensitivity to these design choices is not explored.
- What evidence would resolve it: Ablation studies varying the discriminator's architecture (e.g., using DoRA, Prompt Tuning, or different model sizes) and measuring both the MMD of filtered data and the final transferred LoRA accuracy would clarify this relationship.

### Open Question 3
- Question: How does Trans-LoRA perform on non-language tasks (e.g., vision, robotics) or with non-LLM base models?
- Basis in paper: Inferred from the focus on LLM families (Llama2, Gemma) and language/code/math tasks.
- Why unresolved: The method is only evaluated in the language domain, leaving its applicability to other modalities unexplored.
- What evidence would resolve it: Applying Trans-LoRA to vision tasks (e.g., image classification with vision transformers) or robotics tasks (e.g., control with policy networks) and comparing transfer performance to baselines would demonstrate its broader utility.

### Open Question 4
- Question: What is the theoretical upper bound on the number of continuous transfers (through multiple intermediate models) that Trans-LoRA can sustain without significant performance degradation?
- Basis in paper: Inferred from the "Continuous Transfer" section, which only tests a single intermediate transfer.
- Why unresolved: The paper demonstrates that one intermediate transfer does not degrade performance, but the limits of this capability are unknown.
- What evidence would resolve it: Experiments chaining multiple transfers (e.g., source → intermediate1 → intermediate2 → ... → target) and measuring the performance drop at each step would establish the practical limits of continuous transfer.

## Limitations

- Limited understanding of failure modes and conditions under which transfer fails
- Heavy dependence on quality of small seed dataset (5 samples) without systematic analysis
- Potential discriminator training instability similar to GAN training issues
- Claims about target model being optimal generator choice based on limited comparison

## Confidence

**High Confidence (8/10)**: The basic mechanism of using synthetic data filtered by a discriminator for LoRA transfer is sound and well-supported by experimental results.

**Medium Confidence (6/10)**: Generalization across different PEFT methods and model families is supported but less thoroughly validated.

**Low Confidence (4/10)**: The claim that the target model itself is the optimal choice for data generation is based on single comparison experiments.

## Next Checks

**Validation Check 1**: Perform systematic analysis of seed dataset quality by varying the number of demonstrations (1, 3, 5, 10 samples) and measuring transfer performance degradation.

**Validation Check 2**: Conduct stress tests on discriminator training stability by monitoring discriminator loss curves and synthetic data quality metrics during training.

**Validation Check 3**: Perform ablation studies comparing different data generator choices (source model, target model, third-party model) across diverse task types.