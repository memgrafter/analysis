---
ver: rpa2
title: 'Debiasify: Self-Distillation for Unsupervised Bias Mitigation'
arxiv_id: '2411.00711'
source_url: https://arxiv.org/abs/2411.00711
tags:
- bias
- debiasify
- layer
- accuracy
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Debiasify addresses simplicity bias in neural networks by proposing
  a self-distillation method that operates without prior bias information. The core
  idea involves clustering feature embeddings in shallow network layers to identify
  attribute-conditioned groups, then using a novel distillation loss to align these
  groups with their class distributions in deeper layers.
---

# Debiasify: Self-Distillation for Unsupervised Bias Mitigation

## Quick Facts
- arXiv ID: 2411.00711
- Source URL: https://arxiv.org/abs/2411.00711
- Authors: Nourhan Bayasi; Jamil Fayyad; Ghassan Hamarneh; Rafeef Garbi; Homayoun Najjarian
- Reference count: 40
- Primary result: Unsupervised debiasing method that outperforms previous approaches on multiple datasets

## Executive Summary
Debiasify addresses simplicity bias in neural networks by proposing a self-distillation method that operates without prior bias information. The core idea involves clustering feature embeddings in shallow network layers to identify attribute-conditioned groups, then using a novel distillation loss to align these groups with their class distributions in deeper layers. This approach encourages the network to learn more robust, debiased representations by minimizing distance between cluster distributions and class distributions. Extensive experiments on CelebA, Waterbirds, and Fitzpatrick datasets show Debiasify significantly outperforms previous unsupervised debiasing methods, achieving up to 10.13% improvement in worst-group accuracy for Wavy Hair classification on CelebA, while maintaining or improving overall accuracy.

## Method Summary
Debiasify uses a ResNet18 backbone with shallow (layer 2) and deep classifiers, plus an auxiliary branch for alignment. The method clusters feature embeddings from the shallow layer to identify attribute-conditioned groups per class, then applies self-distillation by minimizing Maximum Mean Discrepancy (MMD) between these cluster distributions and class distributions from the deep layer. Training uses a hybrid loss combining classification, knowledge distillation, and KL divergence objectives. The approach is unsupervised - it doesn't require prior knowledge of bias attributes, instead discovering them through clustering. Multi-layer distillation can be applied to improve debiasing across all network layers.

## Key Results
- Achieves up to 10.13% improvement in worst-group accuracy for Wavy Hair classification on CelebA compared to previous unsupervised methods
- Maintains or improves overall accuracy while reducing bias across multiple datasets (CelebA, Waterbirds, Fitzpatrick)
- Outperforms both supervised and unsupervised state-of-the-art debiasing approaches across various bias types and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Clustering shallow-layer features reveals attribute-conditioned groups that are biased representations, while deep-layer features contain more class-conditional, attribute-agnostic information.
- Mechanism: The method clusters features in the shallow layer where bias is more decodable, then uses MMD-based self-distillation to align each cluster's distribution with the class distribution from the deep layer. This encourages the model to learn class-relevant features while washing out bias-related ones.
- Core assumption: Bias attributes create separable clusters in shallow feature space, and these clusters can be aligned with class distributions in deeper layers to reduce bias.
- Evidence anchors:
  - [abstract] "leveraging a new distillation loss to distill knowledge within a network; from a deep layer where complex, highly-predictive features reside, to a shallow layer where simpler yet attribute-conditioned features are found in an unsupervised manner."
  - [section] "Expanding on their analysis, we conduct the following experiments to investigate the layer where the clustering could be more pronounced... bias decodability generally decreases with network depth, indicating that shallower layers are more effective at detecting bias."
  - [corpus] Weak evidence - no direct mention of clustering or distillation in corpus neighbors.
- Break condition: If bias does not produce separable clusters in shallow layers, the method cannot identify attribute-conditioned groups.

### Mechanism 2
- Claim: The hybrid loss (classification + knowledge distillation + KL divergence) balances accuracy preservation with bias mitigation.
- Mechanism: The loss function combines LACE for classification, LAKD for distribution alignment, and LKL for knowledge transfer between shallow and deep classifier logits. This ensures the model maintains predictive power while reducing bias.
- Core assumption: The hybrid loss components work synergistically to maintain performance while learning debiased representations.
- Evidence anchors:
  - [abstract] "a novel self-distillation loss that encourages their distributions to converge while simultaneously aligning them with the distribution of their highly-predictive class features in the deep layer."
  - [section] "The final objective for Debiasify's training is given as follows; Lhybrid = LACE + αLAKD + LKL"
  - [corpus] Weak evidence - no direct mention of hybrid loss structure in corpus neighbors.
- Break condition: If α is poorly tuned, the method may prioritize bias mitigation at the cost of classification accuracy or vice versa.

### Mechanism 3
- Claim: Multi-layer distillation (from deep to shallow) is more effective than single-layer approaches for bias mitigation.
- Mechanism: The method can distill from the deep layer to any shallow layer, with multi-layer distillation (Exp. E) showing best worst-group accuracy by guiding all layers to learn debiased representations.
- Core assumption: Different network depths capture different types of features, and aligning them through distillation improves debiasing.
- Evidence anchors:
  - [section] "Interestingly, our method is effective across different shallow layer configurations; i.e., distilling knowledge from the deep layer into any shallow layer consistently improves debiasing."
  - [section] "The multi-layer distillation in Exp. E achieves the highest worst-group accuracy across the other configurations, which is expected as it guides all layers to learn debiased representations."
  - [corpus] Weak evidence - no direct mention of multi-layer distillation in corpus neighbors.
- Break condition: If the deep layer features are too complex or noisy, distillation may not effectively transfer debiased knowledge.

## Foundational Learning

- Concept: Simplicity bias in neural networks
  - Why needed here: Understanding why networks favor simpler features over complex ones is crucial for appreciating the problem Debiasify addresses.
  - Quick check question: Why do neural networks often learn biased representations based on spurious correlations?

- Concept: Feature clustering for unsupervised attribute discovery
  - Why needed here: The method relies on clustering shallow-layer features to identify attribute-conditioned groups without supervision.
  - Quick check question: How does clustering help identify bias attributes when no labels are available?

- Concept: Knowledge distillation and distribution alignment
  - Why needed here: The core mechanism uses self-distillation to align cluster distributions with class distributions, requiring understanding of both concepts.
  - Quick check question: What is the difference between knowledge distillation and standard supervised learning?

## Architecture Onboarding

- Component map: ResNet18 backbone → shallow layer (layer 2) → alignment layer → shallow classifier, deep layer (final layer) → deep classifier, auxiliary branch for alignment, K-means clustering module, MMD-based distillation loss
- Critical path: Input → backbone → shallow features → clustering → deep features → distillation loss → backpropagation
- Design tradeoffs: K-means vs. other clustering methods (speed vs. accuracy), MMD vs. other distance metrics (effectiveness vs. computational cost), number of clusters vs. model complexity
- Failure signatures: Poor clustering results (overlapping clusters, too many/few clusters), distillation loss not converging, degradation in classification accuracy, worst-group accuracy not improving
- First 3 experiments:
  1. Run clustering on shallow features and visualize cluster separability to verify the core assumption
  2. Test different distance metrics (MMD, KL, Mahalanobis) to find optimal distribution alignment method
  3. Experiment with different shallow layer depths to find the most effective distillation point

## Open Questions the Paper Calls Out

- What is the optimal depth of the shallow layer for clustering in Debiasify across different architectures and datasets?
- How does Debiasify perform when applied to non-image domains such as text or tabular data?
- What is the relationship between the number of clusters K and the nature/severity of bias in the dataset?
- Can Debiasify's clustering approach be extended to identify and mitigate bias in sequential or temporal data?

## Limitations

- Relies on hyperparameter tuning (γ for K-means, α for loss weighting) without providing specific values for all experimental settings
- Assumes ResNet18 features are sufficient for clustering without exploring alternative architectures
- Lacks thorough analysis of computational overhead from multi-layer distillation

## Confidence

- High confidence: Overall experimental results showing Debiasify's superior performance across multiple datasets and bias types
- Medium confidence: Core mechanism claim that clustering shallow-layer features reveals attribute-conditioned groups
- Low confidence: Scalability claim regarding computational costs and performance on larger-scale datasets

## Next Checks

1. **Cluster separability validation**: Visualize and quantify the separability of attribute-conditioned clusters in shallow layers across different datasets to verify the core assumption of the method.

2. **Hyperparameter sensitivity analysis**: Systematically test the impact of γ (K-means variance threshold) and α (loss weighting) on debiasing performance to establish robust default values.

3. **Computational efficiency benchmarking**: Measure training time and memory usage of Debiasify compared to baseline methods, particularly for multi-layer distillation, to assess practical scalability.