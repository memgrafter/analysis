---
ver: rpa2
title: Stacking-based deep neural network for player scouting in football 1
arxiv_id: '2403.08835'
source_url: https://arxiv.org/abs/2403.08835
tags:
- players
- network
- player
- football
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of automatically identifying high-potential
  football players from large datasets, to aid human scouts in recruitment. The core
  method involves a stacking-based deep learning model that combines the outputs of
  multiple neural networks trained on player statistics.
---

# Stacking-based deep neural network for player scouting in football 1

## Quick Facts
- arXiv ID: 2403.08835
- Source URL: https://arxiv.org/abs/2403.08835
- Authors: Simon Lacan
- Reference count: 14
- Primary result: Stacked deep learning model improves player potential prediction over single networks, with better identification of high-potential players (classes 0.66 and 1)

## Executive Summary
This paper presents a stacking-based deep learning approach to automatically identify high-potential football players for recruitment purposes. The method uses multiple neural networks trained on player statistics, combined through a stacking technique, to predict player potential based on league progression between seasons. The model achieves improved accuracy compared to single networks and shows promise for automating initial talent screening, though the dataset size and labeling approach are noted limitations.

## Method Summary
The approach involves collecting player statistics from API-SPORTS for players outside top 5 European leagues, creating custom labels based on league progression (0, 0.33, 0.66, 1), and training multiple deep neural networks using per-minute statistics. The stacking technique combines outputs from different networks to create a final prediction model. Weighted loss functions handle class imbalance, and the model is evaluated using confusion matrices and threshold analysis to optimize identification of high-potential players.

## Key Results
- Stacked model achieves higher accuracy than single neural networks for identifying classes 0.66 and 1
- Model successfully distinguishes between classes with clear separation in confusion matrices
- Outperforms average human predictions when tested against football fans on 100 players
- Weighted loss effectively handles class imbalance in the dataset
- Per-minute statistics help highlight young players with limited playing time but high quality

## Why This Works (Mechanism)

### Mechanism 1
Stacking multiple neural networks improves predictive accuracy over a single model by combining complementary error patterns. Individual networks capture different aspects of player potential based on varying architectures or training data splits. The stacking layer learns to weigh these predictions optimally, reducing overall error.

### Mechanism 2
Weighted loss function effectively handles class imbalance in player potential labeling. By assigning higher weights to underrepresented classes (players who improved to top leagues), the model prioritizes learning patterns that distinguish high-potential players from the majority class.

### Mechanism 3
Using ratio statistics (per-minute metrics) effectively highlights young players with limited playing time but high quality. Normalizing statistics by minutes played allows the model to identify players who demonstrate high efficiency despite fewer opportunities, which is crucial for scouting young talent.

## Foundational Learning

- Concept: Supervised learning with custom labeling schemes
  - Why needed here: The paper creates its own labels based on league progression rather than using existing market values or performance metrics, requiring understanding of how to implement and validate custom supervised learning tasks
  - Quick check question: How would you validate that your custom labeling scheme (league progression) actually correlates with true player potential?

- Concept: Neural network architecture design and training
  - Why needed here: The paper uses multiple deep neural networks with different configurations, requiring knowledge of network design choices, hyperparameter tuning, and training optimization
  - Quick check question: What are the key differences between training a single network versus a stacked ensemble, and how would you adjust your training approach?

- Concept: Class imbalance handling techniques
  - Why needed here: The dataset has highly imbalanced classes (most players don't improve leagues), requiring understanding of weighted loss functions and other imbalance mitigation strategies
  - Quick check question: How does weighted loss differ from oversampling or undersampling techniques for handling class imbalance?

## Architecture Onboarding

- Component map: Data collection (API-Football) -> Preprocessing (normalization, per-minute ratios) -> Base model layer (multiple neural networks) -> Stacking layer (meta-model) -> Evaluation layer (confusion matrices, threshold analysis)

- Critical path:
  1. Data collection and preprocessing
  2. Training base neural networks
  3. Generating predictions from base models
  4. Training stacking model on base predictions
  5. Evaluating final model performance

- Design tradeoffs:
  - Single large network vs. ensemble of smaller networks: Ensembles provide better generalization but require more computational resources
  - Weighted loss vs. resampling: Weighted loss maintains dataset size but may create training instability
  - Per-minute vs. raw statistics: Per-minute metrics better for young players but more sensitive to small sample sizes

- Failure signatures:
  - High correlation between base model predictions (stacking provides little benefit)
  - Poor performance on majority class despite weighted loss
  - Overfitting to training data when predicting on new seasons
  - Threshold sensitivity where small changes in alpha dramatically affect results

- First 3 experiments:
  1. Train and evaluate a single neural network baseline using both raw and per-minute statistics to establish performance without stacking
  2. Train two different base networks (e.g., different architectures or training splits) and evaluate their correlation to ensure complementary predictions
  3. Implement and test the weighted loss function with different weight configurations to find optimal balance for class imbalance

## Open Questions the Paper Calls Out

### Open Question 1
Does stacking-based deep learning generalize better than single networks across different leagues and player pools? The authors note that stacking techniques "seem particularly promising" and plan to generalize results to combine more than 2 neural networks or even various types of outputs. This remains untested as the paper only tests stacking on a limited dataset and a single evaluation metric.

### Open Question 2
How robust is the proposed player labeling scheme to variations in league promotion criteria and market biases? The authors acknowledge that their labeling choice is "subjective" and may introduce bias, as it relies on league progression rather than other metrics like market value or individual performance. The labeling method is based on a specific time period and league hierarchy, which may not capture nuanced player potential or account for market-driven biases.

### Open Question 3
Can the stacking model effectively integrate human scouting expertise and AI-driven outputs for improved decision-making? The authors suggest combining AI algorithms, human advice, and other outputs through stacking to mimic a head scout's decision-making process. The paper only compares model outputs to human predictions but does not explore hybrid models that integrate human expertise directly into the stacking framework.

## Limitations

- Dataset size of approximately 7,000 players may be insufficient for robust generalization
- Custom labeling scheme based on league progression lacks external validation against established metrics
- Neural network architectures are not fully specified, making exact reproduction difficult
- Comparison to human predictions on only 100 players provides limited statistical power

## Confidence

- High Confidence: Stacked ensemble approach outperforms single neural networks on the presented dataset
- Medium Confidence: Weighted loss function effectively handles class imbalance
- Low Confidence: Custom labeling scheme accurately represents player potential

## Next Checks

1. Cross-validate the league progression labels against established player valuation metrics (e.g., Transfermarkt market values) and expert scouting assessments to confirm the labels correlate with recognized indicators of player potential.

2. Systematically vary the neural network architectures (number of layers, neurons, activation functions) in both the base models and stacking model to determine whether the stacking improvement is robust across different configurations.

3. Expand the human prediction comparison from 100 to at least 500-1000 players, including a more diverse set of evaluators (professional scouts, data analysts, and casual fans) with documented expertise levels.