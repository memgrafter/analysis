---
ver: rpa2
title: 'IntentGPT: Few-shot Intent Discovery with Large Language Models'
arxiv_id: '2411.10670'
source_url: https://arxiv.org/abs/2411.10670
tags:
- intent
- intents
- prompt
- known
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IntentGPT addresses the challenge of discovering new intents in
  dialogue systems by using large language models for few-shot intent discovery. The
  method employs automatic prompt generation, semantic few-shot sampling, and known
  intent feedback to enable zero-training intent discovery.
---

# IntentGPT: Few-shot Intent Discovery with Large Language Models

## Quick Facts
- arXiv ID: 2411.10670
- Source URL: https://arxiv.org/abs/2411.10670
- Authors: Juan A. Rodriguez; Nicholas Botzer; David Vazquez; Christopher Pal; Marco Pedersoli; Issam Laradji
- Reference count: 40
- Primary result: Achieves up to 96.06 NMI and 88.76% accuracy on CLINC and BANKING benchmarks with GPT-4 using 50-shot examples, requiring no model training and minimal labeled data.

## Executive Summary
IntentGPT addresses the challenge of discovering new intents in dialogue systems by leveraging large language models (LLMs) for few-shot intent discovery. The method combines automatic prompt generation, semantic few-shot sampling, and known intent feedback to enable zero-training intent discovery. By using LLMs to generate diverse prompts and cluster similar utterances, IntentGPT achieves state-of-the-art performance on established benchmarks without requiring extensive labeled data or model training.

## Method Summary
IntentGPT employs a three-stage approach to few-shot intent discovery. First, it automatically generates diverse prompts using the LLM to ensure comprehensive coverage of the intent space. Second, it samples semantically relevant few-shot examples based on the generated prompts. Third, it incorporates feedback from known intents to refine the clustering process. The method leverages the LLM's internal representations to group similar utterances together, enabling the discovery of novel intents without requiring extensive labeled data or model training.

## Key Results
- Achieves up to 96.06 NMI on CLINC benchmark with GPT-4 using 50-shot examples
- Reaches 88.76% accuracy on BANKING benchmark with minimal labeled data
- Outperforms unsupervised and semi-supervised baselines while requiring no model training

## Why This Works (Mechanism)
IntentGPT leverages the semantic understanding capabilities of large language models to identify and group similar intents from dialogue utterances. The approach works by using LLMs to generate diverse prompts that capture different aspects of the intent space, then clustering utterances based on their semantic similarity to these prompts. The few-shot sampling ensures that the model learns from representative examples, while the feedback mechanism from known intents helps refine the clustering process. This combination allows the system to discover novel intents without extensive labeled data or model training.

## Foundational Learning
- **Semantic similarity in NLP**: Understanding how language models measure semantic similarity between utterances is crucial for the clustering approach. Quick check: Verify that the LLM's similarity measures align with human judgment of intent similarity.
- **Prompt engineering**: The quality of automatically generated prompts directly impacts the model's ability to discover intents. Quick check: Test prompt diversity and coverage across different domains.
- **Few-shot learning**: Understanding how LLMs generalize from limited examples is essential for the sampling strategy. Quick check: Validate that the sampled examples represent the full intent space.

## Architecture Onboarding
- **Component Map**: Automatic Prompt Generation -> Semantic Few-shot Sampling -> Known Intent Feedback -> Intent Clustering
- **Critical Path**: The most critical sequence is Prompt Generation → Sampling → Clustering, as each stage builds on the previous one's output.
- **Design Tradeoffs**: The method trades computational efficiency for accuracy by relying on LLM inference rather than training custom models. This eliminates training overhead but requires multiple LLM calls.
- **Failure Signatures**: Poor prompt generation leads to incomplete intent coverage, inadequate sampling results in biased clusters, and insufficient feedback causes misclassification of known intents.
- **First Experiments**:
  1. Test prompt generation diversity on a small dataset to ensure comprehensive intent coverage
  2. Validate few-shot sampling by comparing cluster purity with different sample sizes
  3. Evaluate feedback mechanism by measuring accuracy improvement when incorporating known intents

## Open Questions the Paper Calls Out
None

## Limitations
- Performance heavily depends on LLM quality and may not generalize across all domains or languages
- Automatic prompt generation could introduce bias if LLM responses lack diversity
- Assumes known intents are accurate and comprehensive, potentially limiting discovery of truly novel intents

## Confidence
**High Confidence**: Core methodology is technically sound and experimental results on established benchmarks are reproducible. Zero-training requirement and minimal labeled data usage are well-supported.

**Medium Confidence**: Scalability to very large intent spaces (>150 intents) needs further validation. Performance degradation with increasing intent complexity or cross-domain transfer is not extensively explored.

**Low Confidence**: Claims about "universal applicability" across different dialogue domains are not thoroughly validated. Performance on languages other than English or highly specialized domains remains unexplored.

## Next Checks
1. **Cross-Domain Robustness Test**: Evaluate IntentGPT on datasets from completely different domains (e.g., medical dialogue, technical support) to verify generalizability beyond banking and general conversation.

2. **Prompt Sensitivity Analysis**: Systematically vary automatic prompt generation parameters to quantify how sensitive results are to prompt quality and diversity.

3. **Error Analysis on False Positives**: Conduct detailed analysis of cases where IntentGPT incorrectly clusters utterances, particularly focusing on whether it's missing truly novel intents or incorrectly grouping distinct intents.