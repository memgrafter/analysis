---
ver: rpa2
title: 'Generate then Refine: Data Augmentation for Zero-shot Intent Detection'
arxiv_id: '2410.01953'
source_url: https://arxiv.org/abs/2410.01953
tags:
- data
- intent
- domains
- refiner
- utterances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of intent detection in zero-resource
  domains where no labeled data exists for new intent categories. The authors propose
  a two-stage approach: first generating utterances using a large language model in
  a zero-shot setting, then refining these generated utterances using a smaller sequence-to-sequence
  model trained on data from seen domains.'
---

# Generate then Refine: Data Augmentation for Zero-shot Intent Detection

## Quick Facts
- arXiv ID: 2410.01953
- Source URL: https://arxiv.org/abs/2410.01953
- Authors: I-Fan Lin; Faegheh Hasibi; Suzan Verberne
- Reference count: 12
- One-line primary result: A two-stage approach combining LLM generation with sequence-to-sequence refinement significantly improves intent detection performance in zero-resource domains

## Executive Summary
This paper addresses the challenge of intent detection in zero-resource domains where no labeled data exists for new intent categories. The authors propose a two-stage approach: first generating utterances using a large language model in a zero-shot setting, then refining these generated utterances using a smaller sequence-to-sequence model trained on data from seen domains. The refinement model improves both the utility and diversity of the generated data. Experiments on CLINC150 and SGD datasets show that the refined data significantly outperforms both direct LLM generation and existing data selection approaches, with the refined data achieving accuracy comparable to human-labeled data while producing more diverse utterances.

## Method Summary
The approach consists of two main stages: (1) LLM utterance generation where Zephyr-7B Beta or Llama3-8B-Instruct generates utterances for unseen intents in a zero-shot setting, and (2) refinement using a Flan-T5-large sequence-to-sequence model that is fine-tuned on seen domains to improve the generated utterances. The Refiner is trained for 6 epochs with a batch size of 24, using LoRA fine-tuning with 5M trainable parameters for efficiency. The refined data is then used to train a DistilBERT intent classifier, and performance is evaluated using intent prediction accuracy and lexical diversity metrics (distinct-1 & 2).

## Key Results
- The Refiner model significantly improves lexical diversity of generated utterances compared to direct LLM generation
- Fine-tuned Refiners substantially outperform non-fine-tuned versions, demonstrating effective cross-domain transfer
- Refined data achieves intent detection accuracy comparable to human-labeled data while producing more diverse utterances
- The two-stage approach outperforms existing data selection methods for zero-shot intent detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A smaller sequence-to-sequence refiner can improve LLM-generated utterances for unseen domains after fine-tuning on seen domains.
- Mechanism: The refiner learns to transform sub-optimal LLM outputs into more diverse and intent-aligned utterances by observing patterns in seen-domain human-LLM utterance pairs.
- Core assumption: Utterance patterns and intent representations are transferable across domains.
- Evidence anchors:
  - [abstract] "we develop a smaller sequence-to-sequence model (the Refiner), to improve the generated utterances"
  - [section] "we propose a Refiner model that transforms sub-optimal generated utterances into better ones"
  - [corpus] Weak - corpus provides related papers but no direct evidence for this specific cross-domain transfer mechanism
- Break condition: When domain-specific linguistic patterns differ significantly from seen domains, making cross-domain transfer ineffective.

### Mechanism 2
- Claim: Fine-tuning the refiner on seen domains provides significant performance gains over non-fine-tuned versions.
- Mechanism: Fine-tuning allows the refiner to learn domain-specific patterns and improve utterance quality through exposure to real human-LLM pairs from seen domains.
- Core assumption: The refiner can generalize patterns learned from seen domains to unseen domains.
- Evidence anchors:
  - [abstract] "The Refiner is fine-tuned on seen domains and then applied to unseen domains"
  - [section] "Table 4 shows that the fine-tuned Refiner significantly improves overall accuracy over a non-fine-tuned Refiner"
  - [corpus] Weak - no corpus evidence directly supporting this fine-tuning effectiveness claim
- Break condition: When fine-tuning leads to overfitting on seen domains, reducing generalization to unseen domains.

### Mechanism 3
- Claim: The refiner produces more lexically diverse utterances compared to direct LLM generation.
- Mechanism: By learning to rephrase and diversify LLM outputs during fine-tuning, the refiner generates utterances with higher distinct-n scores while maintaining intent relevance.
- Core assumption: Diversity can be improved through sequence-to-sequence transformation without losing intent alignment.
- Evidence anchors:
  - [abstract] "Our results indicate that a two-step approach...can provide high-quality data for intent detection"
  - [section] "Table 3 shows that the refiner leads to substantially more diverse data than other approaches"
  - [corpus] Weak - corpus lacks direct evidence for diversity improvement claims
- Break condition: When diversity improvements come at the cost of intent accuracy or when diversity metrics don't correlate with downstream task performance.

## Foundational Learning

- Concept: Sequence-to-sequence modeling
  - Why needed here: The refiner uses seq2seq architecture to transform LLM-generated utterances into refined versions
  - Quick check question: How does a seq2seq model learn to map input sequences to output sequences?

- Concept: Cross-domain generalization
  - Why needed here: The refiner must transfer knowledge from seen domains to improve utterances in unseen domains
  - Quick check question: What factors determine whether a model can successfully generalize from seen to unseen domains?

- Concept: Lexical diversity metrics
  - Why needed here: Distinct-n scores are used to evaluate the diversity of generated utterances
  - Quick check question: How does the distinct-n metric penalize longer texts, and why is this important for fair comparison?

## Architecture Onboarding

- Component map:
  - LLM generator (Zephyr-7B or Llama3-8B) → produces initial utterances
  - Refiner (Flan-T5-large) → transforms utterances using fine-tuning on seen domains
  - Intent classifier (DistilBERT) → evaluates refined data quality

- Critical path: LLM generation → Refiner fine-tuning on seen domains → Refiner application to unseen domains → Intent classifier training → Evaluation on real test data

- Design tradeoffs:
  - Larger LLMs vs. smaller refiners: Bigger generators produce better initial data but smaller refiners are more compute-efficient
  - Fine-tuning extent: Full fine-tuning vs. LoRA affects performance vs. resource usage
  - Input/output settings: Different n-to-m settings impact diversity and quality balance

- Failure signatures:
  - Low diversity scores despite refinement
  - Intent accuracy drops when using refined data
  - Refiner fails to improve utterances across domain boundaries
  - Overfitting during fine-tuning (validation loss increases)

- First 3 experiments:
  1. Compare fine-tuned vs. non-fine-tuned refiner on a small dataset to verify cross-domain effectiveness
  2. Test different input/output settings (e.g., 3to1 vs. 7to1) to find optimal diversity-quality tradeoff
  3. Evaluate LoRA vs. full fine-tuning to assess compute-efficiency impact on performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Refiner model perform on zero-resource intent detection tasks in languages other than English, given that current LLMs are known to be more proficient in English?
- Basis in paper: [inferred] The paper mentions that "like most of the prior work, we only focused on English utterance generation" and acknowledges that "current LLMs are known to be more proficient in English than in other languages."
- Why unresolved: The study was conducted exclusively in English, and there is no data or analysis provided on the model's performance in other languages. The paper does not explore whether the Refiner's effectiveness generalizes to multilingual or low-resource language settings.
- What evidence would resolve it: Empirical results from experiments testing the Refiner model on intent detection tasks in multiple languages, particularly lower-resource languages, would provide evidence of its cross-linguistic applicability and performance.

### Open Question 2
- Question: What is the impact of varying the number of input utterances (beyond the tested range of 1 to 7) on the Refiner model's performance and training efficiency?
- Basis in paper: [explicit] The ablation study mentions that "our main results were based on using an input of 7 utterances" and that "we experimented with different input/output settings to see if it affects performance."
- Why unresolved: The paper only tests input numbers up to 7 and does not explore the effects of using a larger number of input utterances. Computational resource constraints limited the exploration of higher input numbers, leaving uncertainty about whether increasing the number of inputs beyond 7 could further improve performance.
- What evidence would resolve it: Experimental results showing the Refiner's performance and training efficiency with input numbers greater than 7 would clarify whether increasing the number of inputs leads to significant improvements or diminishing returns.

### Open Question 3
- Question: How does the Refiner model's performance compare to human-labeled training data when using parameter-efficient fine-tuning methods like LoRA versus full fine-tuning?
- Basis in paper: [explicit] The paper compares full fine-tuning with LoRA fine-tuning in the ablation study and notes that "the Refiner with LoRA fine-tuning generates incorrect utterances more frequently than the fully fine-tuned Refiner."
- Why unresolved: While the paper shows that LoRA leads to a slight drop in accuracy and more incorrect utterances, it does not provide a comprehensive comparison of how these tuning methods affect the model's ability to match the quality of human-labeled data.
- What evidence would resolve it: Detailed performance metrics comparing the Refiner's output quality and accuracy using both LoRA and full fine-tuning against a baseline of human-labeled data would reveal which method better bridges the gap to human-level performance.

## Limitations

- The paper's core claims rely heavily on cross-domain generalization from seen to unseen domains, which represents a fundamental uncertainty
- The evaluation focuses only on two datasets (CLINC150 and SGD), limiting generalizability to other domain types or languages
- The paper doesn't provide deeper analysis of semantic fidelity - whether refined utterances truly capture the intended meaning across all cases
- Computational costs of the two-stage approach versus simpler alternatives are not thoroughly compared

## Confidence

- **High Confidence**: The claim that the Refiner improves lexical diversity over direct LLM generation is well-supported by the distinct-n score comparisons in Table 3
- **Medium Confidence**: The assertion that fine-tuned Refiners significantly outperform non-fine-tuned versions has reasonable support from Table 4, but the evidence is limited to a single comparison point
- **Low Confidence**: The paper's broader claim that this two-step approach "can provide high-quality data for intent detection" in any unseen domain is supported by limited empirical evidence

## Next Checks

1. **Cross-Domain Robustness Test:** Evaluate the Refiner's performance across a wider variety of domain types (e.g., adding datasets from different domains like healthcare, finance, or entertainment) to test whether the cross-domain generalization assumption holds beyond the current limited scope

2. **Semantic Fidelity Analysis:** Conduct human evaluation studies to verify that refined utterances maintain semantic equivalence with their target intents, particularly for edge cases where diversity improvements might compromise intent accuracy

3. **Cost-Benefit Analysis:** Compare the computational costs (training time, inference latency, and resource usage) of the two-stage approach against simpler baselines like direct LLM generation or traditional data augmentation methods, to determine whether the quality improvements justify the additional complexity