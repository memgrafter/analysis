---
ver: rpa2
title: 'Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with Fact-Checking
  in Turkish'
arxiv_id: '2403.00411'
source_url: https://arxiv.org/abs/2403.00411
tags:
- claims
- data
- language
- fact-checking
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the FCTR dataset for Turkish fact-checking,
  containing 3,238 claims annotated for veracity. It investigates cross-lingual transfer
  learning for fact-checking in low-resource languages by comparing zero-shot and
  few-shot prompting, fine-tuning, and machine translation approaches.
---

# Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with Fact-Checking in Turkish

## Quick Facts
- arXiv ID: 2403.00411
- Source URL: https://arxiv.org/abs/2403.00411
- Reference count: 0
- Primary result: Fine-tuning with native Turkish data significantly outperforms cross-lingual transfer methods, achieving F1-macro scores of 0.89 and 0.828 for FCTR500 and FCTR1000 respectively

## Executive Summary
This paper introduces the FCTR dataset for Turkish fact-checking and investigates cross-lingual transfer learning for low-resource languages. The study compares zero-shot and few-shot prompting, fine-tuning, and machine translation approaches for fact-checking in Turkish. Experiments demonstrate that fine-tuning LLaMA language models with small amounts of native Turkish data substantially outperforms cross-lingual transfer methods. The results emphasize the importance of collecting native data for low-resource languages, even when large English datasets and language models are available.

## Method Summary
The study creates the FCTR dataset with 3,238 Turkish claims annotated for veracity, then compares multiple approaches: zero-shot and few-shot prompting, machine translation (Turkish↔English), and parameter-efficient fine-tuning (LoRA/QLoRA) of LLaMA-2 models (7B, 13B, 70B) on both English Snopes data and Turkish FCTR data. Models are evaluated on FCTR500 and FCTR1000 test sets using F1-macro and F1-binary metrics, with class-weighted loss to address imbalance. Evidence summaries are included as input in some experiments to assess their impact on performance.

## Key Results
- Fine-tuning with 500-1000 native Turkish claims achieves F1-macro scores of 0.89 and 0.828, significantly outperforming cross-lingual methods
- Providing evidence summaries alongside claims improves model performance compared to claims alone
- Machine translation from Turkish to English improves cross-lingual transfer compared to zero/few-shot prompting
- All approaches perform worse on global claims than local claims, suggesting pretraining data differences affect performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning on native Turkish data substantially improves fact-checking accuracy over cross-lingual transfer
- Mechanism: Native data allows models to learn domain-specific linguistic patterns and cultural context unique to Turkish fact-checking
- Core assumption: Turkish misinformation patterns differ significantly from English
- Evidence anchors:
  - [abstract]: "fine-tuning with a small amount of native Turkish data significantly outperforms cross-lingual transfer methods, with F1-macro scores of 0.89 and 0.828"
  - [section]: "fine-tuning LLaMA language models with Turkish data resulted in a substantial improvement in the F1-macro score"

### Mechanism 2
- Claim: Providing evidence summaries alongside claims improves model performance compared to claims alone
- Mechanism: Summaries condense key evidence points, allowing models to focus on relevant information
- Core assumption: Summaries capture the most salient evidence needed for verification
- Evidence anchors:
  - [section]: "when both the claim statement and the summary... were given as input, the LLaMA-13B model reached a superior 0.89 and 0.828 F1-macro scores"
  - [section]: "we also include evidence statements as input in some experiments, which show a clear benefit in providing additional information"

### Mechanism 3
- Claim: Machine translation from Turkish to English improves cross-lingual transfer compared to zero/few-shot prompting
- Mechanism: Translation enables English-pretrained models to process Turkish claims using their stronger English capabilities
- Core assumption: Machine translation preserves semantic content sufficiently for English models to process accurately
- Evidence anchors:
  - [section]: "employing translated claims led to higher success rates for LLaMA models compared to the few-shot prompting approach"
  - [corpus]: Weak - only mentions using ChatGPT API for translation without evaluating translation quality

## Foundational Learning

- Concept: Cross-lingual transfer learning
  - Why needed here: To leverage large English datasets for Turkish fact-checking where native data is scarce
  - Quick check question: What are the main challenges when transferring knowledge from high-resource to low-resource languages?

- Concept: Few-shot prompting
  - Why needed here: To evaluate whether providing example instances improves model performance without requiring labeled data
  - Quick check question: How does few-shot prompting differ from zero-shot prompting in terms of model adaptation?

- Concept: Parameter-efficient fine-tuning (PEFT)
  - Why needed here: To adapt large language models to Turkish fact-checking within GPU memory constraints
  - Quick check question: What are the key differences between LoRA and QLoRA approaches to PEFT?

## Architecture Onboarding

- Component map: Web crawling → preprocessing → dataset creation (FCTR, Snopes) → model fine-tuning (LoRA/QLoRA) → translation layer (ChatGPT API, Opus-MT) → evaluation (F1-macro, F1-binary)
- Critical path: Dataset creation → model fine-tuning → evaluation → comparison of approaches
- Design tradeoffs:
  - Memory vs. performance: Using quantization to fit models on available GPUs
  - Data quantity vs. quality: Balancing dataset size with annotation accuracy
  - Translation quality vs. speed: API-based vs. open-source translation models
- Failure signatures:
  - Low F1 scores despite large model size (indicates insufficient language-specific adaptation)
  - Large performance gap between claim-only and claim+summary conditions (indicates importance of evidence)
  - Similar performance across zero-shot, few-shot, and fine-tuning (indicates model limitations)
- First 3 experiments:
  1. Fine-tune LLaMA-7B on FCTR500 with claim-only input to establish baseline
  2. Compare zero-shot vs. few-shot prompting with LLaMA-13B on FCTR1000
  3. Evaluate translation impact by comparing English→Turkish translated claims vs. native Turkish claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific linguistic and factual information do large language models leverage when making fact-checking decisions, and how does this differ between English and Turkish?
- Basis in paper: [explicit] The paper discusses the success of large language models (LLaMA) on English data and their comparatively lower performance on Turkish data
- Why unresolved: The paper does not provide a detailed analysis of the specific linguistic features or factual knowledge utilized by the models for each language
- What evidence would resolve it: A detailed analysis of the linguistic features and factual knowledge extracted by the models for both English and Turkish claims

### Open Question 2
- Question: How does the inclusion of evidence summaries impact the fact-checking performance of models trained on different amounts of native Turkish data?
- Basis in paper: [explicit] The paper shows that including evidence summaries improves performance, particularly for models with limited Turkish training data
- Why unresolved: The paper does not explore the relationship between the amount of native Turkish data and the effectiveness of evidence summaries
- What evidence would resolve it: Experiments comparing the performance of models trained on varying amounts of Turkish data, with and without evidence summaries

### Open Question 3
- Question: To what extent does the type of claim (local vs. global) influence the performance of fact-checking models, and how does this differ between languages?
- Basis in paper: [explicit] The paper briefly explores the impact of claim type (local vs. global) on model performance for Turkish
- Why unresolved: The paper does not provide a comprehensive analysis of the relationship between claim type and model performance across languages
- What evidence would resolve it: Experiments comparing the performance of models on local and global claims for multiple languages

## Limitations
- Relatively small native Turkish dataset (3,238 claims) constrains generalizability of fine-tuning results
- Only evaluates true/false claims, potentially limiting applicability to multi-class verification scenarios
- Translation quality assessment is minimal without detailed error analysis or human evaluation

## Confidence

**High Confidence**: Fine-tuning with native Turkish data significantly outperforms cross-lingual transfer methods (F1-macro scores of 0.89 and 0.828)

**Medium Confidence**: Evidence summaries improve performance, but summary quality validation is lacking

**Low Confidence**: Broader claim about native data importance for all low-resource languages extends beyond Turkish-specific findings

## Next Checks
1. Replication with larger native datasets (10,000+ Turkish claims) to validate fine-tuning advantage
2. Human evaluation of machine-translated claims to quantify semantic preservation and identify error types
3. Application to another low-resource language (e.g., Arabic or Hindi) to validate generalizability of native data requirements