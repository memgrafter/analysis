---
ver: rpa2
title: 'Complexity Matters: Dynamics of Feature Learning in the Presence of Spurious
  Correlations'
arxiv_id: '2403.03375'
source_url: https://arxiv.org/abs/2403.03375
tags:
- spurious
- core
- learning
- feature
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work studies the impact of spurious features on the learning
  of core features in neural networks. It proposes a synthetic dataset based on Boolean
  functions to systematically control the complexity and correlation strength of spurious
  features.
---

# Complexity Matters: Dynamics of Feature Learning in the Presence of Spurious Correlations

## Quick Facts
- arXiv ID: 2403.03375
- Source URL: https://arxiv.org/abs/2403.03375
- Authors: GuanWen Qiu; Da Kuang; Surbhi Goel
- Reference count: 40
- Primary result: Simpler spurious features or stronger spurious correlations slow down core feature learning in neural networks

## Executive Summary
This work systematically studies how spurious features impact core feature learning in neural networks. Using a synthetic dataset based on Boolean functions, the authors control both the complexity of spurious features and their correlation strength with labels. They find that simpler spurious features or stronger correlations significantly slow down the convergence of core feature learning. The study reveals that spurious and core features are learned by separate subnetworks within the network, and that spurious features persist even after core features are learned. The authors also show that Last Layer Retraining can reduce reliance on spurious subnetworks and improve group robustness.

## Method Summary
The authors create a synthetic dataset using Boolean functions (parity and staircase) to systematically control spurious feature complexity and correlation strength. They train a two-layer neural network with ReLU activation using batch SGD and cross-entropy loss. The core metric is "decoded correlation" - measuring feature learning by retraining the last layer to predict individual features. They also analyze neuron specialization by examining weight patterns in the hidden layer, and evaluate Last Layer Retraining on models trained with spurious correlations to measure improvements in group robustness.

## Key Results
- Simpler spurious features or stronger spurious correlations slow down core feature learning convergence
- Spurious and core features are learned by separate subnetworks that persist throughout training
- Spurious features remain in the network representation even after core features are learned
- Last Layer Retraining improves worst-group accuracy by reducing reliance on spurious subnetworks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simpler spurious features slow down core feature learning convergence.
- Mechanism: Spurious features create a gradient gap at initialization; simpler spurious features have larger relative gradient magnitudes compared to core features, causing gradient-based learning to prioritize spurious features and slow core learning.
- Core assumption: Gradient descent prioritizes features with larger initial gradient magnitudes; learning dynamics follow layer-wise or early-stopped ERM patterns.
- Evidence anchors:
  - [abstract] "stronger spurious correlations or simpler spurious features slow down the rate of learning for the core features"
  - [section] "We find that the presence of spurious features notably harm the convergence rate of core feature learning. Spurious features that are easier to learn result in a slower convergence rate compared to their more complex counterparts."
  - [corpus] Weak (no direct neighbor evidence for this specific gradient gap mechanism)
- Break condition: If spurious and core features have similar gradient magnitudes at initialization, the slowdown effect diminishes.

### Mechanism 2
- Claim: Spurious and core features are learned by separate subnetworks within the neural network.
- Mechanism: During training, neurons self-organize into two distinct groups: "spurious neurons" focusing on spurious coordinates and "core neurons" focusing on core coordinates. This separation persists even after core features are learned.
- Core assumption: Neural network weights self-organize during training; neuron specialization is stable over training epochs.
- Evidence anchors:
  - [abstract] "two distinct subnetworks are formed to learn core and spurious features separately"
  - [section] "There exists a classification of neurons into two groups, 'spurious neurons' which have larger weights on the spurious index and 'core neurons' which have larger weights on the core index in the late stage of learning."
  - [corpus] Weak (no direct neighbor evidence for subnetwork separation)
- Break condition: If spurious and core features are not disentangled in the input space, the subnetwork separation may not occur cleanly.

### Mechanism 3
- Claim: Last Layer Retraining (LLR) improves robustness by reducing reliance on spurious subnetworks.
- Mechanism: LLR with balanced data reduces the weights of the last layer connected to the spurious subnetwork, thereby decreasing the model's dependence on spurious features while maintaining core feature learning.
- Core assumption: The core features are already learned in the hidden layers; LLR can effectively reweight the last layer to improve group robustness.
- Evidence anchors:
  - [abstract] "Last Layer Retraining reduces reliance on spurious subnetwork: [KIW23, IKGW22] show LLR with balanced dataset is able to improve robustness of the model but the mechanism behind this remains elusive."
  - [section] "We find that last layer retraining consistently improves the worst group accuracy or core function correlation, with the most significant performance boost occurring during the early stages of training."
  - [corpus] Weak (no direct neighbor evidence for LLR mechanism)
- Break condition: If core features are not sufficiently learned before LLR, or if the spurious subnetwork is too dominant, LLR may not effectively improve robustness.

## Foundational Learning

- Concept: Boolean function analysis and Fourier decomposition
  - Why needed here: The paper uses Boolean functions (parity, staircase) as synthetic features to systematically control complexity and correlation strength of spurious features.
  - Quick check question: Can you explain why parity functions of higher degree are computationally harder to learn than staircase functions of the same degree?

- Concept: Gradient descent optimization dynamics
  - Why needed here: The paper analyzes how gradient-based learning is affected by spurious correlations, including initial gradient gaps and convergence rates.
  - Quick check question: How does the initial gradient magnitude at initialization influence which features are learned first during training?

- Concept: Subnetwork specialization and feature disentanglement
  - Why needed here: The paper observes that spurious and core features are learned by separate subnetworks, which is crucial for understanding feature learning dynamics and designing debiasing algorithms.
  - Quick check question: What conditions would prevent the formation of separate spurious and core subnetworks during training?

## Architecture Onboarding

- Component map:
  Input layer (Boolean vectors) -> Hidden layer (ReLU neurons) -> Output layer (logistic regression)

- Critical path:
  1. Generate synthetic dataset with controlled spurious correlations
  2. Train neural network with batch SGD
  3. Monitor core and spurious feature learning dynamics
  4. Analyze subnetwork formation and feature persistence
  5. Evaluate debiasing algorithms on the synthetic dataset

- Design tradeoffs:
  - Complexity vs. correlation strength: Simpler spurious features or stronger correlations slow core learning more
  - Dataset size: Limited data exacerbates the negative impact of spurious features
  - Model architecture: Deeper networks may show similar subnetwork separation patterns

- Failure signatures:
  - Slow convergence of core feature learning
  - High spurious correlation even after core features are learned
  - Poor performance of debiasing algorithms that assume clear separation between spurious and core learning phases

- First 3 experiments:
  1. Train a two-layer neural network on a synthetic dataset with varying spurious feature complexity and correlation strength, monitoring core and spurious learning dynamics
  2. Analyze neuron specialization by retraining the last layer on core vs. spurious features and observing weight patterns
  3. Evaluate Last Layer Retraining on models trained with spurious correlations to measure improvement in group robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the presence of non-linear, high-degree spurious features impact the learning dynamics of core features in deep neural networks?
- Basis in paper: [explicit] The paper shows that simpler spurious features slow down core feature learning, but does not explore the impact of highly complex spurious features.
- Why unresolved: The paper focuses on parity and staircase functions, which have limited complexity. Real-world spurious features may be more complex and non-linear.
- What evidence would resolve it: Experiments on synthetic datasets with increasingly complex spurious features, and theoretical analysis of the gradient dynamics in such scenarios.

### Open Question 2
- Question: Can the persistence of spurious features in neural network representations be explained by the optimization landscape or the architecture's inductive biases?
- Basis in paper: [explicit] The paper observes that spurious features are retained in the network even after core features are learned, and proposes a theoretical analysis under idealized assumptions.
- Why unresolved: The theoretical analysis is limited to specific cases and does not provide a comprehensive explanation for the persistence of spurious features.
- What evidence would resolve it: A detailed analysis of the optimization landscape and the role of architectural biases in retaining spurious features, supported by experiments on various architectures.

### Open Question 3
- Question: How do different regularization techniques, such as L1 and L2 regularization, affect the learning dynamics of core and spurious features in the presence of spurious correlations?
- Basis in paper: [inferred] The paper mentions the use of L1 regularization in Last Layer Retraining, but does not explore the impact of other regularization techniques on feature learning.
- Why unresolved: The paper does not provide a comprehensive study of the effects of different regularization techniques on the learning dynamics.
- What evidence would resolve it: Experiments comparing the learning dynamics and performance of models trained with different regularization techniques, and theoretical analysis of the impact of regularization on feature learning.

## Limitations
- Theoretical guarantees for gradient-based learning with spurious correlations are incomplete
- Subnetwork formation conditions and stability across architectures are not fully understood
- The synthetic dataset may not capture all real-world spurious correlation scenarios

## Confidence
- Gradient gap mechanism for spurious feature slowdown: Medium
- Subnetwork separation finding: Low
- LLR mechanism explanation: Medium

## Next Checks
1. Test gradient magnitude analysis across different initialization schemes to verify the gradient gap mechanism
2. Evaluate subnetwork separation in deeper networks (3+ layers) to assess generalization
3. Compare LLR effectiveness across different spurious correlation strengths and feature complexities to identify conditions where it succeeds or fails