---
ver: rpa2
title: On Debiasing Text Embeddings Through Context Injection
arxiv_id: '2410.12874'
source_url: https://arxiv.org/abs/2410.12874
tags:
- neutral
- concept
- debiasing
- female
- biases
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of gender bias in text embeddings
  by investigating whether context injection can serve as a debiasing technique. The
  author reviews 19 embedding models, quantifying their biases using two methods:
  a geometry-based approach and WEATs.'
---

# On Debiasing Text Embeddings Through Context Injection

## Quick Facts
- arXiv ID: 2410.12874
- Source URL: https://arxiv.org/abs/2410.12874
- Authors: Thomas Uriot
- Reference count: 40
- Primary result: Context injection can reduce gender bias in text embeddings, but models often over-compensate toward the discriminated group rather than achieving neutrality

## Executive Summary
This paper investigates whether context injection can serve as an effective debiasing technique for text embeddings. The author analyzes 19 embedding models, finding that higher-performing models are more prone to capturing biases but also better at incorporating context. The study identifies a critical limitation: models struggle to embed neutral semantics and often over-compensate toward the discriminated group when given debiasing context. To address this, the author proposes a simple dynamic top-k retrieval algorithm that successfully retrieves all relevant gendered and neutral chunks, demonstrating its effectiveness in reducing bias in retrieval tasks.

## Method Summary
The paper employs a two-pronged approach to debiasing text embeddings through context injection. First, it quantifies bias using both geometry-based SVD analysis and WEATs methods across 19 embedding models. Second, it introduces context injection as a debiasing technique by providing neutral, debiasing, positive, or negative prompts alongside text. The core innovation is a dynamic top-k retrieval algorithm that adjusts retrieval based on gender-related queries to overcome the over-compensating effect observed when models skew toward the discriminated group. The method is evaluated on a synthetic retrieval task where the algorithm successfully captures all relevant chunks despite the inherent bias in the embeddings.

## Key Results
- Higher-performing models (MTEB ranking) show stronger gender bias correlation (ρ = 0.76 for AUC, ρ = 0.79 for neutral context)
- Context injection often produces an "over-compensating effect" where debiasing context causes models to skew toward the female group rather than achieving neutrality
- The dynamic top-k retrieval algorithm successfully retrieves all relevant gendered and neutral chunks in toy retrieval tasks
- Models struggle to embed neutral semantics regardless of context provided, indicating a fundamental limitation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Higher-performing models are more prone to capturing biases because they learn more intricate relationships in the training data
- Mechanism: The MTEB ranking correlates with AUC scores (ρ = 0.76) and bias strength correlation (ρ = 0.79 for neutral context). Better models capture subtle semantic relationships, including biased associations between concepts like gender and occupations
- Core assumption: AUC values accurately reflect concept representation quality, and concept direction vectors truly capture the underlying bias subspace
- Evidence anchors:
  - [abstract] "We show that higher performing models are more prone to capturing biases, but are also better at incorporating context."
  - [section 3.2.1] "we can see that the human-labeled attributes and the projection of those attributes onto the concept direction are highly correlated... This is especially true for the better performing models"
- Break condition: If AUC values don't accurately measure concept representation, or if concept directions don't capture true bias subspaces, the correlation between performance and bias would be misleading

### Mechanism 2
- Claim: Context injection can debias embeddings by providing additional semantic information that overrides biased associations
- Mechanism: When models receive debiasing context (e.g., "This person's gender is unknown"), they should embed the text with reduced gender bias compared to neutral context. The algorithm uses dynamic top-k retrieval where k is adjusted based on bias-related queries
- Core assumption: SOTA models can truly capture semantic meaning at sentence/paragraph level and use context to override existing biases
- Evidence anchors:
  - [abstract] "We introduce a novel and simple debiasing technique using context injection."
  - [section 3.2.2] "we see that results for bias detection (neutral) for both methods are highly correlated: ρ = 0.82"
- Break condition: If models fail to truly understand semantic context (as shown in SugarCrepe++ findings), context injection won't effectively debias embeddings

### Mechanism 3
- Claim: The "over-compensating effect" occurs when debiasing context causes models to skew embeddings toward the discriminated group rather than achieving neutrality
- Mechanism: When debiasing context is added, models may incorrectly interpret this as favoring the female group (in gender examples), leading to p-values closer to 1 rather than 0.5, which would indicate successful debiasing
- Core assumption: Models have a tendency to over-correct when given debiasing instructions, moving too far in the opposite direction
- Evidence anchors:
  - [section 3.2.2] "we find that debiasing context often lead to having the opposite of the expected effect... we dub this finding as the 'over-compensating effect'"
  - [section 4] "we can see that, due to the 'over-compensating effect', the debiasing query is closest to the female chunks"
- Break condition: If models could accurately interpret and implement neutral semantics, the over-compensating effect would not occur

## Foundational Learning

- Concept: Singular Value Decomposition (SVD) and eigenvalue decomposition for extracting concept subspaces
  - Why needed here: The paper uses SVD to identify concept directions from difference matrices (∆X) and selects eigenvectors as concept directions. Understanding SVD is crucial for grasping how the geometry-based bias detection works
  - Quick check question: Given a difference matrix ∆X = X2 - X1 where X1 and X2 are embeddings of gender pairs (she-he, mother-father), what does the first eigenvector represent in terms of the gender concept?

- Concept: Statistical hypothesis testing (binomial test, p-values)
  - Why needed here: The paper uses binomial tests to assess whether bias is present and whether debiasing was successful. Understanding p-values and hypothesis testing is essential for interpreting the results
  - Quick check question: If a binomial test yields p = 0.03 for the neutral context, what does this tell us about bias presence at the 5% significance level?

- Concept: Cosine similarity and vector embeddings
  - Why needed here: The paper relies heavily on cosine similarity between embeddings to measure bias and perform retrieval tasks. Understanding how embeddings represent semantic meaning is fundamental
  - Quick check question: If two sentences have embeddings with cosine similarity of 0.95, what does this indicate about their semantic similarity according to the model?

## Architecture Onboarding

- Component map: Data preparation (concept pairs, attribute sets, WEAT data) -> Bias detection (geometry-based SVD + WEAT binomial tests) -> Debiasing (context injection with neutral/debiasing/positive/negative prompts) -> Evaluation (AUC, p-values, retrieval task) -> Algorithm design (dynamic top-k retrieval)

- Critical path: Data preparation → Bias detection → Debiasing → Evaluation → Algorithm design
  The most critical sequence is from bias detection to debiasing, as the findings directly inform the algorithm design

- Design tradeoffs: Geometry-based method provides explicit concept direction but requires human labels and assumes single-dimension representation; WEAT is simpler but relies on cosine similarity which may not reflect true semantic relationships. The paper uses both to validate findings

- Failure signatures: Low AUC values (< 0.8) indicate poor concept representation; p-values close to 0.5 for debiasing context indicate over-compensating effect; failed retrieval of relevant chunks indicates bias persistence despite debiasing attempts

- First 3 experiments:
  1. Reproduce the correlation between MTEB ranking and bias strength using a subset of 5-10 models to verify the main finding
  2. Test context injection debiasing on a single concept (gender) with one high-performing model to observe the over-compensating effect
  3. Implement the dynamic top-k retrieval algorithm on the toy retrieval task to verify it captures all relevant chunks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed debiasing algorithm scale effectively to multilingual datasets beyond English?
- Basis in paper: [inferred] from the paper's acknowledgment that the study was "strictly performed on English text" and that "it would thus be of interest to perform similar studies on non-English languages with multilingual embedders."
- Why unresolved: The paper's experiments and findings are limited to English text, leaving the algorithm's effectiveness on multilingual datasets unverified
- What evidence would resolve it: Empirical testing of the algorithm on multilingual datasets with diverse language pairs, measuring bias reduction and retrieval performance across languages

### Open Question 2
- Question: How does the debiasing algorithm perform in more complex retrieval scenarios, such as multi-concept bias or longer document retrieval?
- Basis in paper: [explicit] The authors state, "In future work, we would like to investigate this algorithm further on more advanced scenarios," indicating that the current algorithm has not been tested in more complex settings
- Why unresolved: The paper only demonstrates the algorithm on a simple toy retrieval task, without exploring its applicability to more complex scenarios
- What evidence would resolve it: Experimental results showing the algorithm's performance on tasks involving multiple concepts, longer documents, and more nuanced bias patterns

### Open Question 3
- Question: What are the long-term effects of using the debiasing algorithm on model performance and bias in downstream tasks?
- Basis in paper: [inferred] The paper focuses on immediate bias reduction in retrieval tasks but does not address the potential long-term impact on model behavior and bias persistence
- Why unresolved: The study does not include longitudinal analysis or exploration of how the debiased embeddings affect model performance over time or in varied applications
- What evidence would resolve it: Long-term studies tracking model performance and bias levels across different tasks and datasets after applying the debiasing algorithm, assessing any degradation or unintended consequences

## Limitations
- Limited external validation: Relies on self-generated human-labeled attributes with no citations and low FMR scores indicating weak external validation
- Conceptual assumptions: Assumes SVD eigenvectors accurately represent bias subspaces and AUC values properly measure concept quality without rigorous validation
- Generalizability concerns: Findings primarily focus on gender bias with only 19 models tested, limiting extension to other bias types or larger model populations

## Confidence
- High confidence: The correlation between model performance and bias strength (ρ = 0.76 for AUC, ρ = 0.79 for neutral context) is statistically supported by the data presented
- Medium confidence: The effectiveness of the dynamic top-k retrieval algorithm is shown in controlled experiments, but its performance in real-world retrieval tasks with noisy data remains uncertain
- Low confidence: Claims about context injection as a general debiasing technique are premature given the limited testing across different bias types and the fundamental issue that models struggle to embed neutral semantics regardless of context

## Next Checks
1. **Cross-bias validation**: Test the correlation between model performance and bias strength for age and wealth concepts using independently sourced labeled attributes to verify the generalizability of the main finding

2. **Neutral semantics capability**: Design an experiment to measure whether any SOTA model can successfully embed truly neutral sentences (neither gendered nor biased toward any group) when explicitly instructed to do so, isolating this fundamental limitation from context injection effects

3. **Real-world retrieval evaluation**: Implement the dynamic top-k algorithm on a standard information retrieval benchmark (e.g., MS MARCO) with gender-diverse queries to assess practical effectiveness beyond the synthetic toy task