---
ver: rpa2
title: 'GCI-ViTAL: Gradual Confidence Improvement with Vision Transformers for Active
  Learning on Label Noise'
arxiv_id: '2411.05939'
source_url: https://arxiv.org/abs/2411.05939
tags:
- label
- noise
- learning
- active
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles active learning under label noise by proposing
  GCI-ViTAL, which leverages Vision Transformers (ViTs) to improve robustness. The
  method combines prediction entropy with attention vector distances from class-centric
  clean set centroids (C-Core) to select informative samples while identifying potential
  label noise.
---

# GCI-ViTAL: Gradual Confidence Improvement with Vision Transformers for Active Learning on Label Noise

## Quick Facts
- arXiv ID: 2411.05939
- Source URL: https://arxiv.org/abs/2411.05939
- Reference count: 40
- Primary result: ViTs with C-Core-based label smoothing outperform CNNs in AL under label noise

## Executive Summary
GCI-ViTAL addresses active learning under label noise by combining Vision Transformers with a class-centric clean set (C-Core) approach. The method uses prediction entropy and attention vector distances from C-Core centroids to identify informative samples while detecting potential label noise. Label smoothing adjusts probabilities toward C-Core-based assignments, reducing the impact of noisy labels. Experiments across multiple datasets demonstrate ViTs significantly outperform CNNs, particularly under high label noise conditions.

## Method Summary
GCI-ViTAL integrates Vision Transformers with a novel selection strategy that leverages both prediction uncertainty and attention-based class representations. The core innovation is the C-Core framework, which maintains clean-set attention vectors for each class to compute distances from queried samples. This distance metric, combined with entropy-based uncertainty, enables more robust sample selection under label noise. The method applies label smoothing using C-Core-derived pseudo-labels, gradually improving confidence while maintaining noise robustness.

## Key Results
- ViTs significantly outperform CNNs across all tested AL strategies and noise levels
- Performance gains increase with the number of classes, showing particular robustness on CIFAR100 and Food101
- GCI-ViTAL achieves superior generalization without requiring extensive hyperparameter tuning
- Label smoothing with C-Core assignments effectively reduces the impact of noisy labels

## Why This Works (Mechanism)
The method works by grounding sample selection in clean-set attention representations. Vision Transformers naturally produce attention vectors that capture class-specific features, which GCI-ViTAL uses to build C-Core centroids. These centroids serve dual purposes: they provide reliable pseudo-labels for label smoothing and offer a distance metric for detecting label noise. By combining entropy-based uncertainty with attention-based similarity, the method can distinguish between genuinely uncertain samples and those with corrupted labels.

## Foundational Learning
- **Active Learning**: Selecting informative samples to maximize model performance with minimal labeling
  - Why needed: Reduces labeling costs in data-scarce scenarios
  - Quick check: Can identify high-value samples for annotation

- **Label Noise**: Incorrect labels in training data that degrade model performance
  - Why needed: Real-world datasets often contain mislabeled examples
  - Quick check: Can distinguish clean from noisy samples

- **Vision Transformers**: Transformer architectures adapted for image classification
  - Why needed: Produce attention vectors useful for class representation
  - Quick check: Can generate attention maps for image regions

- **Label Smoothing**: Technique that prevents overconfident predictions by adjusting label probabilities
  - Why needed: Reduces memorization of noisy labels
  - Quick check: Can produce calibrated probability distributions

- **Entropy-based Uncertainty**: Measures prediction confidence using information entropy
  - Why needed: Identifies samples where the model is uncertain
  - Quick check: Can rank samples by confidence levels

- **C-Core Framework**: Maintains clean-set attention vectors for each class
  - Why needed: Provides reliable class representations for noise detection
  - Quick check: Can compute distances between samples and class centroids

## Architecture Onboarding

Component Map: Image -> ViT Backbone -> Attention Vectors -> C-Core Centroids -> Selection Strategy -> Label Smoothing -> Final Model

Critical Path: The most important components are the ViT backbone (for attention vector generation), C-Core centroids (for clean class representations), and the combined selection strategy (entropy + attention distance).

Design Tradeoffs: The method trades computational overhead of maintaining C-Core centroids against improved noise robustness. Using attention vectors rather than final layer features provides more interpretable class representations but requires additional storage.

Failure Signatures: Performance degradation when clean set size is too small, failure to detect certain types of label noise, or suboptimal results with very few classes where attention vectors may be less discriminative.

First Experiments:
1. Verify attention vector quality by visualizing attention maps on clean vs. noisy samples
2. Test C-Core distance computation on a small subset of labeled data
3. Evaluate entropy-based selection independently before combining with attention distances

## Open Questions the Paper Calls Out
The paper acknowledges that its evaluation scope is limited to specific datasets and class configurations. It does not address generalizability beyond the tested scenarios or validate against alternative noise detection approaches. The claim of no extensive hyperparameter tuning may not hold for more complex applications.

## Limitations
- Evaluation limited to specific datasets (CIFAR10, CIFAR100, Food101, Chest X-ray)
- Claims of ViT superiority need more rigorous statistical validation across diverse architectures
- Attention-based noise detection not compared against self-supervised or ensemble methods
- No validation on natural label noise distributions from real-world data

## Confidence

| Claim | Confidence |
|-------|------------|
| ViTs outperform CNNs under label noise | Medium |
| C-Core approach improves noise robustness | Medium |
| No extensive hyperparameter tuning needed | Low |
| Performance gains scale with class number | Medium |

## Next Checks
1. Test GCI-ViTAL on datasets with natural label noise distributions (e.g., real-world web-crawled labels) rather than synthetic noise
2. Compare attention-based uncertainty measures against self-supervised representation learning for noise detection
3. Evaluate performance degradation when C-Core clean set size is reduced to test robustness to clean data scarcity