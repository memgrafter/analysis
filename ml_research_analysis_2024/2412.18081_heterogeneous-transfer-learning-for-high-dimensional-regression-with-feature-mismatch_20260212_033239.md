---
ver: rpa2
title: Heterogeneous transfer learning for high-dimensional regression with feature
  mismatch
arxiv_id: '2412.18081'
source_url: https://arxiv.org/abs/2412.18081
tags:
- target
- proxy
- feature
- estimation
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Heterogeneous Transfer Learning (HTL) method
  for high-dimensional regression with differing feature sets between source and target
  domains. The method first learns a feature map from the source data to impute missing
  target features, then performs two-step transfer learning using combined matched
  and imputed features.
---

# Heterogeneous transfer learning for high-dimensional regression with feature mismatch

## Quick Facts
- arXiv ID: 2412.18081
- Source URL: https://arxiv.org/abs/2412.18081
- Authors: Jae Ho Chang; Massimiliano Russo; Subhadeep Paul
- Reference count: 40
- Primary result: Proposes HTL method for high-dimensional regression with differing feature sets between domains, providing theoretical error bounds and demonstrating superior performance over baseline methods

## Executive Summary
This paper addresses the challenge of transfer learning when source and target domains have different feature sets, a problem known as heterogeneous transfer learning (HTL). The authors propose a method that first learns a feature map from source data to impute missing target features, then performs two-step transfer learning using both matched and imputed features. The approach provides theoretical error bounds for both linear and non-linear feature maps, showing that estimation error depends on model complexity, sample sizes, feature map quality, and parameter differences across domains. Through simulations and real data analysis, the method demonstrates superior prediction and estimation performance compared to homogeneous transfer learning and lasso, particularly when features have non-linear relationships.

## Method Summary
The proposed HTL method addresses high-dimensional regression when source and target domains have mismatched feature sets. It operates in two stages: first, a feature map is learned from the source domain to impute missing features in the target domain (using either linear ridge regression or nonparametric sieve estimation), and second, a two-step transfer learning procedure estimates target parameters by shrinking toward proxy estimates via ℓ1 regularization. The method provides theoretical guarantees for both estimation and prediction errors, with bounds that depend on sample sizes, feature map consistency across domains, and the sparsity of parameter differences.

## Key Results
- HTL outperforms homogeneous transfer learning and lasso in both prediction and estimation accuracy
- Nonparametric feature mapping via sieve estimation handles nonlinear relationships between matched and mismatched features more effectively than linear approaches
- Theoretical error bounds show estimation error depends on sample sizes, model complexity, feature map quality, and parameter differences across domains
- Real data validation on ovarian cancer gene expression data confirms improved prediction accuracy over competing methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Imputing missing target features using a learned feature map from the source domain enables transfer learning even when target and source feature sets differ.
- Mechanism: The method first learns a mapping (linear or nonparametric) from matched to mismatched features in the source domain, then applies this map to estimate the missing features in the target domain. These estimated features are combined with the observed matched features, enabling a two-stage transfer learning procedure.
- Core assumption: The feature map between matched and mismatched features is consistent (or approximately so) across source and target domains, allowing the source-learned map to be applied to target data.
- Evidence anchors:
  - [abstract]: "Our method first learns a feature map between the missing and observed features, leveraging the vast source data, and then imputes the missing features in the target."
  - [section 2.2.1]: "Under this formulation, for proxy and target domains, we write zp = hp(xp) + ξp, zt = ht(xt) + ξt with hp(x) := E(zp|x), ht(x) := E(zt|x) are feature maps in proxy and target domains, respectively."
- Break condition: If the feature map differs substantially between source and target (high δP or δΘ), the imputation becomes inaccurate and the transfer benefit diminishes.

### Mechanism 2
- Claim: Two-stage penalized regression with ℓ1 regularization on the parameter difference between domains achieves better estimation and prediction than using only matched features.
- Mechanism: After imputation, the method performs two-step transfer learning: first estimate proxy parameters, then estimate target parameters by shrinking toward the proxy estimates via ℓ1 penalty, allowing sparse differences between domains.
- Core assumption: The difference between source and target parameters is sparse (either in ℓ0 or ℓ1 sense), which allows effective shrinkage without over-regularizing.
- Evidence anchors:
  - [section 2.3]: "We posit that the differences in covariate effects are sparse in the sense that δ∗l = β∗l − ω∗l , is a sparse vector for l = 1, 2, either in the ℓ0 or ℓ1 sense."
  - [section 3.1]: "Our results suggest that the estimation error is related to the target and proxy domain sample sizes, the model's complexity, the strength and cross-domain consistency of the feature map, and the discrepancy between the target and proxy model parameters."
- Break condition: If the parameter difference is not sparse, the ℓ1 penalty may introduce excessive bias and degrade performance.

### Mechanism 3
- Claim: Nonparametric feature mapping via sieve estimation handles nonlinear relationships between matched and mismatched features, improving imputation quality.
- Mechanism: The method models the feature map as unknown smooth functions, expands them in an orthogonal cosine basis, truncates the series, and estimates coefficients via ℓ1-penalized regression, allowing flexible nonlinear imputation.
- Core assumption: The true feature map lies in a Sobolev ellipsoid with dominating mixed smoothness, enabling accurate approximation by a truncated basis.
- Evidence anchors:
  - [section 2.2.2]: "Let the matched features x ∈ Rp1, which are common for both domains, be drawn from the uniform distribution on [−a, a]p1... For the mismatched features z ∈ Rp2, we consider the nonparametric regression model zj = hj(x) + ξj, j = 1, . . . , p2."
  - [section 2.2.2 Assumption 2.4]: "The class of functions described above is introduced in Zhang and Simon (2023), with dominating mixed smoothness 1."
- Break condition: If the feature map has very high complexity or the basis truncation M is too small, sieve approximation error becomes large and imputation suffers.

## Foundational Learning

- Concept: Sub-Gaussian random variables and ensembles
  - Why needed here: The analysis relies on concentration inequalities for sub-Gaussian designs to control estimation error and establish high-probability bounds.
  - Quick check question: What is the sub-Gaussian norm of a zero-mean random variable X, and how does it relate to tail bounds?

- Concept: Ridge regression and ℓ1 penalized regression
  - Why needed here: The two-stage transfer learning uses penalized regression (ℓ1) to estimate parameters and shrink toward proxy estimates, while feature map estimation uses ridge or sieve methods.
  - Quick check question: How does ℓ1 regularization promote sparsity in the estimated coefficients, and why is that useful for transfer learning?

- Concept: Basis expansion and sieve estimation
  - Why needed here: For nonparametric feature maps, the method expands unknown functions in a cosine basis and truncates the series, requiring understanding of approximation theory and basis convergence.
  - Quick check question: What is the sieve approximation error, and how does it depend on the truncation level M and the smoothness of the true function?

## Architecture Onboarding

- Component map: Data ingestion -> Feature map estimation (linear/nonparametric) -> Imputation of missing features -> Two-stage transfer learning estimation -> Evaluation
- Critical path:
  1. Learn feature map from source data (linear: ridge; nonlinear: sieve)
  2. Impute missing features in target data
  3. Perform two-step transfer learning to estimate target parameters
  4. Evaluate performance
- Design tradeoffs:
  - Linear vs. nonparametric feature map: Linear is simpler and requires less data but may miss nonlinear relationships; nonparametric is more flexible but needs more proxy samples and careful basis selection
  - Sparsity assumption: Assumes parameter differences are sparse; if violated, performance degrades
  - Sample size imbalance: Method assumes large source data for complex modeling; if source data is small, estimation of feature map becomes unreliable
- Failure signatures:
  - High imputation error (large RZ) indicates poor feature map estimation or large domain shift
  - Estimation error close to or worse than baseline homogeneous TL suggests the feature map or sparsity assumptions are violated
  - Prediction error not improving with more proxy data indicates the method is saturated or the feature map is misspecified
- First 3 experiments:
  1. Simulate with linear feature map, sparse parameter difference, and varying sample sizes; compare HTL to homogeneous TL and lasso
  2. Simulate with nonlinear feature map; test sieve estimation and compare to linear HTL and baseline methods
  3. Vary the discrepancy between source and target feature maps (δP or δΘ); observe how estimation error changes and compare to theoretical predictions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical lower bound for the estimation error of heterogeneous transfer learning when the feature map discrepancy (δP or δΘ) is non-zero?
- Basis in paper: [explicit] The paper derives upper bounds on estimation error that depend on the feature map discrepancy parameters δP (linear) and δΘ (nonlinear), but does not establish matching lower bounds.
- Why unresolved: Establishing lower bounds requires different proof techniques and would complete the characterization of HTL's fundamental limits, which the paper acknowledges but doesn't address.
- What evidence would resolve it: A minimax lower bound proof showing that the derived upper bounds cannot be improved beyond a constant factor, ideally matching the upper bounds up to logarithmic terms.

### Open Question 2
- Question: How does the performance of HTL degrade when the feature map differences between domains (δP or δΘ) scale with dimension p?
- Basis in paper: [inferred] The paper allows feature maps to differ across domains and shows estimation error increases with δP/δΘ, but doesn't analyze the scaling behavior when these discrepancies grow with p.
- Why unresolved: Understanding this scaling would clarify when HTL becomes ineffective and help practitioners assess whether transfer is worthwhile when domain shifts are substantial.
- What evidence would resolve it: Theoretical analysis or extensive simulations showing HTL's performance as δP/δΘ varies from O(1) to O(p^α) for different α values, identifying the threshold where HTL fails to outperform homogeneous methods.

### Open Question 3
- Question: What is the optimal strategy for choosing the truncation parameter M in the sieve approximation when the true feature map is nonlinear?
- Basis in paper: [explicit] The paper notes that M must be chosen based on p and np in the proxy domain, but doesn't provide a data-driven method for selecting M or analyze the sensitivity of results to this choice.
- Why unresolved: The truncation parameter critically affects both the approximation error and computational complexity, yet the paper relies on cross-validation without theoretical justification.
- What evidence would resolve it: A theoretical framework for adaptive M selection that balances approximation error and estimation variance, potentially through oracle inequalities or information criteria.

### Open Question 4
- Question: How robust is HTL to violations of the sub-Gaussian error assumption in the data-generating process?
- Basis in paper: [inferred] The theoretical analysis assumes sub-Gaussian errors for both the response and feature map estimation, but real-world data often exhibits heavier tails or outliers.
- Why unresolved: The paper's results may not extend to non-sub-Gaussian settings, which would limit HTL's practical applicability in many domains.
- What evidence would resolve it: Simulation studies and theoretical analysis showing HTL's performance under heavy-tailed distributions, or development of robust variants that maintain theoretical guarantees under weaker assumptions.

## Limitations
- The theoretical error bounds rely on sub-Gaussian assumptions and sparsity conditions that may not hold in real-world applications
- The nonparametric sieve approach requires careful tuning of basis functions and truncation parameters, which can be challenging in practice
- The method assumes sufficient proxy domain samples for accurate feature map learning, which may not always be available

## Confidence
- **High**: The two-stage transfer learning framework and ℓ1 penalized estimation procedure are well-established and theoretically sound
- **Medium**: The simulation results demonstrate the method's effectiveness, but the generalizability to real-world datasets needs further validation
- **Medium**: The theoretical error bounds are derived under idealized conditions and may be conservative in practice

## Next Checks
1. **Real-world data validation**: Apply the method to additional real datasets beyond ovarian cancer gene expression to assess generalizability across domains
2. **Robustness to feature map misspecification**: Systematically test the method's performance when the feature map between domains is inconsistent or nonlinear relationships are misspecified
3. **Sensitivity analysis**: Conduct thorough experiments on the impact of tuning parameters (λ, γ, M) and the sparsity assumption on final performance