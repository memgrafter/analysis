---
ver: rpa2
title: 'Learning How to Vote with Principles: Axiomatic Insights Into the Collective
  Decisions of Neural Networks'
arxiv_id: '2410.16170'
source_url: https://arxiv.org/abs/2410.16170
tags:
- voting
- rules
- neural
- data
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework called "axiomatic deep voting"
  that combines neural networks with voting theory axioms to study collective decision-making.
  The authors investigate whether neural networks can learn to aggregate preferences
  while adhering to normative principles expressed by voting-theoretic axioms.
---

# Learning How to Vote with Principles: Axiomatic Insights Into the Collective Decisions of Neural Networks

## Quick Facts
- arXiv ID: 2410.16170
- Source URL: https://arxiv.org/abs/2410.16170
- Reference count: 21
- Primary result: Neural networks can discover novel voting rules with superior axiom satisfaction when directly optimized for normative principles, despite failing to learn these principles through standard training

## Executive Summary
This paper introduces "axiomatic deep voting," a framework combining neural networks with voting theory axioms to study collective decision-making. The authors investigate whether neural networks can learn to aggregate preferences while adhering to normative principles expressed by voting-theoretic axioms. Through experiments with multi-layer perceptrons, convolutional neural networks, and word embedding classifiers, they find that while networks can accurately mimic existing voting rules, they frequently violate core axioms like anonymity and neutrality. However, when directly optimizing axiom satisfaction through custom loss functions, neural networks can discover new voting rules that often outperform existing ones in axiom compliance while being substantially different. The work provides insights for both AI (studying bias, value-alignment, and interpretability) and voting theory (exploring new areas of voting rule space).

## Method Summary
The authors train three neural network architectures (MLP, CNN, WEC) on synthetic preference profiles generated from four distributions (Impartial Culture, Mallows, 2D-Euclidean, Urn) with up to 7 alternatives and 77 voters. They use binary cross-entropy loss to train networks to mimic established voting rules, then evaluate performance using both accuracy metrics and axiom satisfaction scores. Custom loss functions translate voting axioms into differentiable objectives for direct optimization. The framework tests three research questions: whether networks learn correct reasoning (not just outcomes), whether axiom-specific training improves alignment, and whether networks can synthesize new voting rules optimized for axiom satisfaction.

## Key Results
- Neural networks achieve high accuracy in mimicking voting rules but frequently violate core axioms like anonymity and neutrality
- Data augmentation with axiom-specific examples doesn't reliably improve axiom satisfaction
- Direct optimization of axiom satisfaction through custom loss functions discovers novel voting rules that often surpass established rules in axiom compliance
- The discovered neural network voting rules are substantially different from existing rules while maintaining high performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural networks can approximate any voting rule with high accuracy but fail to satisfy voting axioms
- Mechanism: Universal approximation theorem ensures neural networks can learn any function from profiles to winners, but this doesn't guarantee satisfaction of normative axioms like anonymity and neutrality
- Core assumption: Neural network architectures used (MLP, CNN, WEC) are sufficiently complex to approximate voting rules
- Evidence anchors:
  - [abstract] "Neural networks, despite being highly accurate, often fail to align with the core axioms of voting rules"
  - [section 6.1] "Notably, across all voting rules, architectures, and distributions, we see large violations of neutrality despite high accuracy"
  - [corpus] Weak - no direct mention of approximation limits, but related work on "DeepVoting: Learning and Fine-Tuning Voting Rules" suggests similar learning approaches

### Mechanism 2
- Claim: Data augmentation with axiom-specific examples doesn't improve axiom satisfaction
- Mechanism: Adding neutrality-augmented data (permutations of existing profiles) doesn't teach the network to be neutral because it learns spurious correlations rather than the underlying principle
- Core assumption: The neural network learns from data patterns rather than abstract principles
- Evidence anchors:
  - [section 6.2] "Data augmentation does not seem to boost the principled learning of neural networks"
  - [section 6.2] "Thus, neither in the stable nor the unstable cases can we see reliable comparative improvements in neutrality satisfaction with more neutrality-augmented data"
  - [corpus] Weak - no direct evidence about data augmentation effectiveness, but "Learning to Manipulate under Limited Information" suggests manipulation resistance doesn't come from simple data tricks

### Mechanism 3
- Claim: Direct optimization of axiom satisfaction through custom loss functions can discover novel voting rules
- Mechanism: By translating axioms into differentiable loss functions, gradient descent can find voting rules that satisfy axioms better than existing rules, even discovering entirely new rules
- Core assumption: The axioms can be effectively translated into differentiable loss functions that gradient descent can optimize
- Evidence anchors:
  - [abstract] "By solely optimizing axiom satisfaction, neural networks can synthesize new voting rules that often surpass and substantially differ from existing ones"
  - [section 6.3] "The neutrality-averaged WEC clearly outperforms the classic Plurality, Borda, and Copeland rules in every single axiom"
  - [corpus] Weak - no direct evidence about loss function design, but "Methods and Open Problems in Differentiable Social Choice" suggests this approach is underexplored

## Foundational Learning

- Concept: Universal approximation theorem
  - Why needed here: Explains why neural networks can learn any voting rule but not necessarily satisfy axioms
  - Quick check question: Can a sufficiently large neural network approximate any continuous function between finite-dimensional spaces?

- Concept: Axiomatic method in voting theory
  - Why needed here: Provides the normative framework for evaluating whether voting rules are "correct" beyond just accuracy
  - Quick check question: What is the difference between a voting rule that is accurate versus one that satisfies the anonymity axiom?

- Concept: Gradient-based optimization
  - Why needed here: The method used to train networks to optimize axiom satisfaction directly
  - Quick check question: How does gradient descent find voting rules that satisfy multiple competing axioms simultaneously?

## Architecture Onboarding

- Component map: Profile encoding -> Neural network forward pass -> Apply custom loss -> Backpropagate -> Update weights -> Evaluate axiom satisfaction
- Critical path: Encode profile → Neural network forward pass → Apply custom loss → Backpropagate → Update weights → Evaluate axiom satisfaction
- Design tradeoffs: WEC architecture is anonymous by design but less flexible; CNN captures spatial patterns but needs more data; MLP is simplest but performs worst on axiom satisfaction
- Failure signatures: High accuracy but low axiom satisfaction indicates the network learned to mimic outcomes without understanding principles; poor accuracy indicates insufficient model capacity or training data
- First 3 experiments:
  1. Train MLP/CNN/WEC on Plurality/Borda/Copeland data, evaluate accuracy vs axiom satisfaction
  2. Add neutrality-augmented data in different ratios, measure impact on neutrality satisfaction
  3. Optimize for axiom satisfaction directly using custom loss functions, compare to existing voting rules

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the discovered neural network voting rules perform on real-world election data compared to established voting rules?
- Basis in paper: [inferred] The paper uses synthetic data for experiments but suggests future work could explore extrapolation to real data
- Why unresolved: The current experiments are limited to synthetic data distributions, making it unclear how well the neural network voting rules would generalize to real-world voting scenarios
- What evidence would resolve it: Testing the neural network voting rules on real election datasets (e.g., Canadian federal elections, Brazilian presidential elections) and comparing their performance and axiom satisfaction to established voting rules

### Open Question 2
- Question: What is the relationship between axiom satisfaction and voting outcomes when neural networks optimize for different combinations of axioms?
- Basis in paper: [explicit] The paper explores optimizing for different sets of axioms but doesn't fully analyze the trade-offs between axiom satisfaction and voting outcomes
- Why unresolved: While the paper shows neural networks can discover new voting rules with high axiom satisfaction, it doesn't examine how different axiom combinations affect the resulting voting outcomes
- What evidence would resolve it: Systematic experiments varying which axioms are optimized for, measuring both axiom satisfaction and outcome differences compared to established voting rules

### Open Question 3
- Question: Can the neural network voting rules be made more interpretable while maintaining their high axiom satisfaction?
- Basis in paper: [inferred] The paper discusses the tension between neural network opacity and voting transparency, and mentions future work on extracting symbolic representations
- Why unresolved: The current neural network voting rules, while effective, remain black-box models that don't provide clear explanations for their decisions
- What evidence would resolve it: Developing methods to extract interpretable rules or decision processes from the neural network voting rules, and evaluating whether this interpretability comes at the cost of axiom satisfaction

## Limitations
- The synthetic preference profile generation may not capture real-world voting complexities
- The evaluation focuses on 4 axioms while voting theory includes many more, potentially missing important normative considerations
- The neural network architectures may not capture all aspects of human voting behavior
- The study uses fixed-size profiles (up to 7 alternatives and 77 voters), which may not generalize to larger, more complex voting scenarios

## Confidence

- High confidence: Neural networks can achieve high accuracy in mimicking voting rules while violating core axioms
- Medium confidence: Data augmentation with axiom-specific examples doesn't improve axiom satisfaction
- Medium confidence: Direct optimization of axiom satisfaction can discover novel voting rules

## Next Checks

1. Test the discovered novel voting rules on real-world preference data from actual elections or surveys to evaluate practical performance beyond synthetic settings
2. Expand the axiom evaluation to include additional voting-theoretic axioms (e.g., monotonicity, consistency, participation) to provide a more comprehensive normative assessment
3. Investigate alternative neural network architectures or training strategies that might better capture the underlying principles of voting rules rather than just surface-level patterns