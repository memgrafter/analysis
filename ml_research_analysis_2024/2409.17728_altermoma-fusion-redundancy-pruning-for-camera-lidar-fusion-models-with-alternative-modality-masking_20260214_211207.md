---
ver: rpa2
title: 'AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative
  Modality Masking'
arxiv_id: '2409.17728'
source_url: https://arxiv.org/abs/2409.17728
tags:
- pruning
- fusion
- parameters
- backbone
- altermoma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of redundancy in camera-LiDAR fusion
  models due to loading pre-trained single-modal backbones, which introduces similar
  feature extraction across modalities. The authors propose AlterMOMA, a pruning framework
  that employs alternative modality masking to identify and prune redundant parameters.
---

# AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking

## Quick Facts
- arXiv ID: 2409.17728
- Source URL: https://arxiv.org/abs/2409.17728
- Reference count: 40
- Outperforms existing pruning methods on nuScenes and KITTI datasets

## Executive Summary
This paper addresses redundancy in camera-LiDAR fusion models caused by loading pre-trained single-modal backbones, which leads to similar feature extraction across modalities. The authors propose AlterMOMA, a pruning framework that uses alternative modality masking to identify and remove redundant parameters while preserving performance-critical features. By selectively masking one modality during training and observing loss changes, the method distinguishes between fusion-contributed and fusion-redundant parameters. Experiments show state-of-the-art performance with significant improvements in mAP and NDS metrics.

## Method Summary
AlterMOMA employs alternative modality masking to identify redundant parameters in camera-LiDAR fusion models. The method applies binary masks to deactivate one backbone (either camera or LiDAR) while keeping the other active, forcing the model to reactivate previously redundant features from the masked backbone. During this process, the AlterEva importance score evaluation function measures loss changes to distinguish between parameters that contribute to task performance and those that are redundant. The framework then prunes low-score parameters and fine-tunes the model, achieving better performance than single-modal pruning baselines across different architectures and tasks.

## Key Results
- Outperforms single-modal pruning methods (IMP, SynFlow, SNIP, ProsPr) on nuScenes and KITTI datasets
- Achieves state-of-the-art performance with significant improvements in mAP and NDS metrics
- Demonstrates effectiveness across different architectures (BEVFusion, AVOD-FPN) and tasks (detection, segmentation)
- Shows substantial improvements over baseline pruning methods with 80-90% pruning ratios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masking one modality forces the model to reactivate previously redundant features from the other modality during training.
- Mechanism: When LiDAR backbone is masked, the model loses fusion-contributed geometric features and must rely on camera backbone features that were previously redundant to maintain performance.
- Core assumption: Fusion mechanism selectively uses the most reliable modality, making corresponding camera features redundant.
- Evidence anchors:
  - [abstract] "when one modality parameters are masked (deactivated), the absence of features from the masked backbone compels the model to reactivate previous redundant features of the other modality backbone."
  - [section 3.2] "The absence of fusion-contributed features will compel fusion modules to 'reactivate' their fusion-redundant counterparts as supplementary."

### Mechanism 2
- Claim: Importance scores combine deactivated contribution (DeCI) and reactivated redundancy (ReRI) indicators to distinguish between useful and redundant parameters.
- Mechanism: DeCI measures loss increase when a parameter is deactivated, indicating contribution to task performance. ReRI measures loss decrease during redundancy reactivation, indicating redundancy.
- Core assumption: Loss changes during masking and reactivation reliably indicate parameter importance and redundancy.
- Evidence anchors:
  - [section 3.3] "AlterEva calculate the final importance scores by subtracting ReRI from DeCI" and "maximize the scores of parameters that contribute to task performance while minimizing the scores of fusion-redundant parameters."

### Mechanism 3
- Claim: The method works across different camera-LiDAR fusion architectures because redundancy stems from pre-trained backbone similarity rather than specific architecture design.
- Mechanism: By observing loss changes during alternative masking regardless of whether the architecture is two-stage (AVOD-FPN) or unified BEV-based (BEVFusion), the method identifies redundancy that exists due to pre-training.
- Core assumption: Redundancy from similar feature extraction across modalities exists in all camera-LiDAR fusion models, regardless of specific architecture.
- Evidence anchors:
  - [section 4.3] "Our proposed framework AlterMOMA achieves better performance, surpassing the baselines established by single-modal pruning methods" across different architectures.

## Foundational Learning

- Concept: Camera-LiDAR fusion mechanisms in autonomous driving perception
  - Why needed here: Understanding how different modalities complement each other (LiDAR for geometry, camera for semantics) is essential to grasp why redundancy occurs and how masking reveals it.
  - Quick check question: Why would geometric features from camera backbones be considered redundant when LiDAR is present?

- Concept: Network pruning fundamentals (structured vs unstructured, importance-based pruning)
  - Why needed here: The method builds on standard pruning concepts but adapts them for multi-modal scenarios, so understanding pruning basics is crucial.
  - Quick check question: What's the difference between structured pruning (removing channels) and unstructured pruning (removing individual weights)?

- Concept: Taylor approximation for tractable parameter importance estimation
  - Why needed here: The method uses first-order Taylor expansion to approximate individual parameter contributions without computationally intractable per-parameter masking.
  - Quick check question: Why can't we simply mask each parameter individually to measure its importance?

## Architecture Onboarding

- Component map: LiDAR backbone (θl) -> Camera backbone (θc) -> Fusion module & task heads (θf) -> Loss function (L)
- Critical path: 1) Modality masking (apply binary mask to one backbone) → 2) Redundancy reactivation (train with batches to observe loss changes) → 3) Importance evaluation (compute DeCI and ReRI) → 4) Alternative masking (repeat for other backbone) → 5) Pruning (remove low-score parameters) → 6) Fine-tuning
- Design tradeoffs: Unstructured pruning allows finer granularity but is less memory-efficient; structured pruning is more practical but removes entire channels; Taylor approximation trades accuracy for tractability
- Failure signatures: Significant performance drop after pruning (indicates over-pruning), minimal performance difference from baselines (indicates redundancy not properly identified), slow convergence during fine-tuning (indicates important features were removed)
- First 3 experiments:
  1. Run AlterMOMA with 80% pruning ratio on BEVFusion-mit with SwinT + VoxelNet backbone on nuScenes detection task to verify baseline performance
  2. Compare with single-modal pruning methods (IMP, SynFlow, SNIP, ProsPr) at same pruning ratio to demonstrate superiority
  3. Test on different architecture (AVOD-FPN) and task (segmentation) to validate generalizability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can AlterMOMA be effectively adapted to multi-modal fusion models beyond camera-LiDAR perception, such as vision-language models?
- Basis in paper: [explicit] The paper acknowledges that AlterMOMA primarily addresses redundancy in multi-sensor fusion architectures and notes that extending it to models with disparate data types like vision and language requires further research.
- Why unresolved: The paper focuses on camera-LiDAR fusion models and highlights differences in fusion mechanisms between multi-sensor and vision-language models, suggesting that the current framework may not be directly applicable to the latter.
- What evidence would resolve it: Experimental results demonstrating the effectiveness of AlterMOMA on vision-language models or modifications to the framework that account for high-level semantic context matching in these models.

### Open Question 2
- Question: How does the choice of hyperparameters α and β in AlterEva influence the trade-off between preserving fusion-contributed features and pruning fusion-redundant ones?
- Basis in paper: [explicit] The paper presents an ablation study showing that varying the ratio β/α affects the mAP, with optimal performance observed at certain ratios, indicating a balance between DeCI and ReRI is crucial.
- Why unresolved: While the study shows the impact of β/α on performance, it does not fully explain the underlying mechanisms or provide a method to determine the optimal ratio for different tasks or datasets.
- What evidence would resolve it: A comprehensive analysis linking the choice of α and β to specific characteristics of the dataset or task, possibly through theoretical insights or empirical studies across diverse scenarios.

### Open Question 3
- Question: What are the limitations of using first-order Taylor expansion approximations in AlterEva for identifying fusion-redundant parameters?
- Basis in paper: [inferred] The paper uses first-order Taylor expansions to approximate the importance of parameters, which may introduce inaccuracies, especially when the learning rate is not sufficiently small or when higher-order interactions are significant.
- Why unresolved: The paper assumes the approximations are valid under certain conditions but does not explore scenarios where they might fail or compare their accuracy against exact computations.
- What evidence would resolve it: Comparative studies evaluating the performance of AlterMOMA with exact computations versus Taylor approximations, particularly in cases with complex parameter interactions or non-linear loss landscapes.

## Limitations

- The method assumes redundancy exists due to pre-trained backbone similarity, which may not hold for all datasets or pre-training strategies
- The Taylor approximation approach may introduce inaccuracies in parameter importance estimation, especially for complex parameter interactions
- The framework requires careful hyperparameter tuning for optimal performance, and the sensitivity to these parameters is not fully explored

## Confidence

- **High**: The core observation that pre-trained backbones introduce redundancy in fusion models (supported by multiple experiments)
- **Medium**: The effectiveness of alternative masking for identifying redundancy (lacks ablation studies on masking parameters)
- **Medium**: The superiority over existing pruning methods (results show improvement but comparison scope is limited)

## Next Checks

1. Perform ablation studies on alternative masking hyperparameters (training steps, learning rates) to determine optimal settings
2. Test the framework on datasets from different domains (e.g., indoor scenes, robotics) to verify generalization
3. Conduct sensitivity analysis on the Taylor approximation error to quantify its impact on pruning decisions