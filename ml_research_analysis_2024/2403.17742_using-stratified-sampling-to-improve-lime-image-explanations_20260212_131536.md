---
ver: rpa2
title: Using Stratified Sampling to Improve LIME Image Explanations
arxiv_id: '2403.17742'
source_url: https://arxiv.org/abs/2403.17742
tags:
- image
- lime
- sampling
- values
- stratified
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates limitations in LIME Image's Monte Carlo
  sampling strategy for generating synthetic neighborhoods in image classification
  tasks. When using Monte Carlo sampling with many superpixels, the dependent variable
  distribution becomes undersampled, resulting in inadequate linear regression models
  and confused feature importance explanations.
---

# Using Stratified Sampling to Improve LIME Image Explanations

## Quick Facts
- arXiv ID: 2403.17742
- Source URL: https://arxiv.org/abs/2403.17742
- Authors: Muhammad Rashid; Elvio G. Amparore; Enrico Ferrari; Damiano Verda
- Reference count: 9
- Primary result: Stratified sampling significantly improves LIME Image explanations by ensuring uniform representation of superpixel preservation levels, reducing undersampling issues that cause confused feature attributions

## Executive Summary
LIME Image uses Monte Carlo sampling to generate synthetic neighborhoods for explaining black-box image classifiers, but this approach suffers from undersampling when dealing with many superpixels. The dependent variable distribution becomes inadequate for linear regression, resulting in confused feature importance explanations. The authors propose a stratified sampling approach that ensures uniform sampling across all possible strata of preserved superpixels, along with an adjustment factor to maintain unbiasedness in regression coefficients. Experiments on ImageNet images demonstrate that stratified sampling significantly improves the range coverage of dependent variable distributions and produces more consistent feature importance scores compared to Monte Carlo sampling.

## Method Summary
The paper addresses limitations in LIME Image's Monte Carlo sampling strategy by introducing a stratified sampling approach. Instead of sampling masks using the biased binomial distribution of Monte Carlo sampling, the method creates strata based on the number of preserved superpixels (|x|) and samples uniformly from each stratum. An adjustment factor compensates for oversampling in strata with fewer masks, maintaining unbiased regression coefficients. This ensures that extreme cases (few or many preserved superpixels) are adequately represented in the synthetic neighborhood, preventing the undersampling problem that leads to flat Y distributions and confused feature importance explanations.

## Key Results
- Stratified sampling significantly improves range coverage of dependent variable distributions (RC(Y)) compared to Monte Carlo sampling
- The approach produces more consistent feature importance scores with higher coefficient of variation (CV(β))
- Experiments demonstrate reduced occurrence of uniform feature attributions, particularly for images with many superpixels
- The method maintains R² coefficients while producing more interpretable explanations for black-box image classifiers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Stratified sampling improves LIME Image by ensuring uniform representation of all superpixel preservation levels in the synthetic neighborhood.
- Mechanism: The proposed method creates strata based on the number of preserved superpixels (|x|), then samples uniformly from each stratum rather than using the biased binomial distribution of Monte Carlo sampling. This ensures that extreme cases (few or many preserved superpixels) are adequately represented in the synthetic neighborhood, preventing the undersampling problem that leads to flat Y distributions.
- Core assumption: The relationship between feature importance and the number of preserved superpixels varies by stratum, requiring balanced sampling across all possible preservation levels to capture the full behavior of the black-box model.
- Evidence anchors:
  - [abstract]: "The authors propose a stratified sampling approach that ensures uniform sampling across all possible strata of preserved superpixels."
  - [section]: "Consider a stratified partitioning. Let X(i) be the set of all possible masks having |x| = i, i.e. for which exactly i superpixel are preserved... Each stratum X(i) does not have a uniform number of samples, but its size is known a-priori since they follow the binomial distribution"
- Break condition: If the black-box model's predictions are insensitive to the number of preserved superpixels (i.e., the model is "smooth" across different levels of image masking), the stratified sampling advantage disappears since all strata would yield similar Y values.

### Mechanism 2
- Claim: The adjustment factor compensates for oversampling in strata with fewer masks, maintaining unbiased regression coefficients.
- Mechanism: When using uniform sampling across strata, strata with fewer masks (like X(0) with only one mask) are oversampled relative to their natural occurrence probability. The adjustment factor adj(i) = (k+1) · 1/2^k · C(k,|x|) corrects for this oversampling by weighting each sample inversely proportional to its oversampling rate.
- Core assumption: The adjustment factor correctly compensates for the sampling bias introduced by uniform stratum selection, preserving the unbiasedness of the regression coefficients.
- Evidence anchors:
  - [abstract]: "They introduce an adjustment factor to maintain unbiasedness in the regression coefficients."
  - [section]: "We can derive an adjustment factor for the bX samples to correct the bias introduced by the oversampling, which results for an arbitrary sample x in stratum X(i) as adj(i) = Prob(x ∈ X(i) | x ∈ X) / Prob(x ∈ X(i) | x ∈ bX)"
- Break condition: If the adjustment factor calculation is incorrect or if the strata probabilities are misestimated, the regression coefficients will be biased, defeating the purpose of the stratified approach.

### Mechanism 3
- Claim: Stratified sampling reduces variance in feature importance explanations by improving the range coverage of the dependent variable distribution.
- Mechanism: By ensuring that all levels of superpixel preservation are represented, the stratified approach captures a wider range of model predictions (Y values). This improved range coverage (measured by RC(Y)) leads to better variation in the feature importance scores (higher CV(β)), preventing the "confused explanations" where all superpixels receive similar importance values.
- Core assumption: Better range coverage of Y values directly translates to more meaningful feature importance scores with higher variation, making the explanations more interpretable.
- Evidence anchors:
  - [abstract]: "Experiments on ImageNet images demonstrate that stratified sampling significantly improves the range coverage of dependent variable distributions and produces more consistent feature importance scores"
  - [section]: "We also want to quantify the (approximate) range coverage of the Y values in the synthetic neighborhood... Low values of RC(Y) indicate that the sampled Y distribution is squashed into a small range of values, not covering the full [0, f(ξ)] spectrum"
- Break condition: If the model predictions are inherently flat (i.e., the model returns similar scores regardless of which superpixels are preserved), even perfect sampling cannot create meaningful variation in feature importance scores.

## Foundational Learning

- Concept: Monte Carlo sampling and binomial distributions
  - Why needed here: Understanding why the default LIME Image sampling strategy fails requires knowledge of how random sampling from Bernoulli distributions creates biased strata representation, particularly for extreme cases.
  - Quick check question: If you have k=10 superpixels and sample masks using x[i] ~ B(0.5), what is the probability of getting a mask with exactly 1 superpixel preserved?

- Concept: Stratified sampling and variance reduction
  - Why needed here: The paper's core contribution relies on understanding how stratified sampling can reduce variance compared to simple random sampling by ensuring all subpopulations are represented.
  - Quick check question: In a population divided into k+1 strata, if you sample n/(k+1) samples from each stratum uniformly, how does this affect the variance of your estimator compared to simple random sampling?

- Concept: Linear regression with weighted least squares
  - Why needed here: The LIME framework fits a linear model to the synthetic neighborhood, and understanding how weights affect the regression coefficients is crucial for grasping why the adjustment factor is necessary.
  - Quick check question: In weighted least squares regression, how does increasing the weight of certain samples affect the resulting regression coefficients?

## Architecture Onboarding

- Component map: Image segmentation (quick shift) → produces k superpixels → Mask generation (stratified vs Monte Carlo) → creates n perturbed images → Black-box model inference → generates Y values for each perturbed image → Weighted regression → produces feature importance vector β → Adjustment factor calculation → corrects for sampling bias in stratified approach
- Critical path: Image → Segmentation → Mask Generation → Black-box Inference → Regression → Feature Importance
- Design tradeoffs:
  - Computational cost: Stratified sampling requires O(k) adjustment factor calculations per sample vs O(1) for Monte Carlo
  - Implementation complexity: Requires tracking which stratum each sample belongs to and applying adjustment factors
  - Sample efficiency: Stratified sampling may require fewer total samples (n) to achieve stable explanations
- Failure signatures:
  - Uniform feature importance scores (low CV(β)) despite varying superpixel configurations
  - Y distribution concentrated in a narrow range regardless of |x| values
  - Explanation heatmaps showing no clear regions of importance
  - High variance in explanations across multiple runs with the same parameters
- First 3 experiments:
  1. Compare Y distributions (RC(Y) values) for Monte Carlo vs stratified sampling on an image with k=200 superpixels
  2. Measure CV(β) for both sampling methods across 10 runs with n=1000 samples each
  3. Visualize the adjustment factors for different strata to verify they correctly compensate for oversampling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of strata (superpixel counts) to use in the stratified sampling approach for different image sizes and complexities?
- Basis in paper: [explicit] The paper mentions that the number of superpixels (k) significantly affects the sampling distribution, but doesn't investigate the optimal number of strata for different scenarios
- Why unresolved: The authors only tested with fixed numbers of superpixels (50, 100, 150, 200) without exploring how the optimal number of strata varies with image characteristics
- What evidence would resolve it: Experimental results showing the relationship between image complexity, superpixel count, and optimal strata numbers across various image datasets

### Open Question 2
- Question: How does the stratified sampling approach perform when combined with regularization techniques like ridge regression?
- Basis in paper: [explicit] The authors explicitly state "The formulas were formulated assuming no regulariza-tion factor: however, since the main changes are in the sampling strategy, it should be possible to extend these results to ridge regression"
- Why unresolved: The experiments only considered unregularized regression, leaving open questions about how stratification interacts with regularization
- What evidence would resolve it: Comparative experiments between stratified sampling with and without various regularization strengths, measuring both explanation quality and model performance

### Open Question 3
- Question: Can the stratified sampling approach be extended to other types of interpretable feature spaces beyond Boolean (superpixels)?
- Basis in paper: [explicit] The authors mention "Of course the strategy could be of interest for other kind of data, even if some adjustments are probably needed (since the interpretable feature space for images is over the booleans, unlike for other data types)"
- Why unresolved: The paper only demonstrates the approach for image data with Boolean superpixels, without exploring how the methodology would need to be adapted for continuous or categorical features
- What evidence would resolve it: Implementation and testing of stratified sampling approaches for tabular data, text data, or other non-Boolean feature spaces, with quantitative comparisons to existing methods

## Limitations

- The paper's claims are primarily supported by synthetic experiments on ImageNet images, with no external validation on other datasets or model architectures
- The theoretical justification relies on the assumption that the binomial distribution accurately models natural occurrence probabilities, which may not hold for real-world images with varying superpixel distributions
- The paper does not address potential computational overhead introduced by the stratified sampling approach compared to Monte Carlo sampling

## Confidence

- **High Confidence**: The mathematical derivation of the adjustment factor and the uniform sampling across strata is sound and well-justified.
- **Medium Confidence**: The experimental results showing improved range coverage and feature importance consistency are convincing but limited to a specific dataset and model architecture.
- **Low Confidence**: The claim that stratified sampling will generalize to other image classification tasks, datasets, and model architectures remains unverified.

## Next Checks

1. **Dataset Generalization Test**: Apply the stratified sampling approach to LIME Image on a different image classification dataset (e.g., CIFAR-10 or medical imaging datasets) and compare the resulting feature importance explanations and dependent variable distributions with those from standard Monte Carlo sampling.

2. **Model Architecture Robustness Test**: Evaluate the performance of the stratified sampling method across different black-box model architectures (e.g., VGG, Inception, EfficientNet) to assess its generalizability beyond ResNet50.

3. **Computational Overhead Analysis**: Measure the runtime and memory requirements of the stratified sampling approach compared to Monte Carlo sampling for varying numbers of superpixels and samples to quantify the trade-off between improved explanations and increased computational cost.