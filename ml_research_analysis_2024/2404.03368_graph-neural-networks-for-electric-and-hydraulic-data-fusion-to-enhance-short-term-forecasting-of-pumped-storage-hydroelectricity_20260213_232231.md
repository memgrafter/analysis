---
ver: rpa2
title: Graph Neural Networks for Electric and Hydraulic Data Fusion to Enhance Short-term
  Forecasting of Pumped-storage Hydroelectricity
arxiv_id: '2404.03368'
source_url: https://arxiv.org/abs/2404.03368
tags:
- uni00000013
- uni0000005f
- uni00000055
- uni00000052
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a spectral-temporal graph neural network
  (STGNN) for short-term forecasting of phasor currents in pumped-storage hydropower
  plants (PSH). The method learns a unified graph structure across electrical and
  hydraulic subsystems using self-attention, enabling effective data fusion for improved
  state forecasting.
---

# Graph Neural Networks for Electric and Hydraulic Data Fusion to Enhance Short-term Forecasting of Pumped-storage Hydroelectricity

## Quick Facts
- arXiv ID: 2404.03368
- Source URL: https://arxiv.org/abs/2404.03368
- Reference count: 26
- Primary result: STGNN achieves 34.7% NMSE reduction in PSH current forecasting vs. baselines

## Executive Summary
This paper introduces a spectral-temporal graph neural network (STGNN) for short-term forecasting of phasor currents in pumped-storage hydropower plants (PSH). The method learns a unified graph structure across electrical and hydraulic subsystems using self-attention, enabling effective data fusion for improved state forecasting. Evaluated on a Swiss PSH dataset with 58 sensor signals, the approach achieves a 34.7% reduction in normalized mean squared error (NMSE) compared to state-of-the-art baselines. Ablation studies confirm that incorporating hydraulic information further improves forecast accuracy by 6.5% NMSE reduction.

## Method Summary
The proposed STGNN learns a unified graph structure from sensor data using attention mechanisms, then applies spectral-temporal filtering to extract features for forecasting. The model operates on a unified system-wide graph learned directly from data, fusing electrical and hydraulic sensor information. It uses graph-spectral filtering with Chebyshev polynomial approximation and time-spectral filtering with DFT and GLU to capture spatial dependencies and temporal patterns. The approach is trained using sliding windows of size 24 with horizon 1, optimizing NMSE with Adam.

## Key Results
- 34.7% reduction in NMSE compared to state-of-the-art baselines for phasor current forecasting
- 6.5% additional NMSE reduction from incorporating hydraulic sensor data through ablation study
- Learned graph structure aligns with physical topology of the PSH system
- Model demonstrates effective data fusion across electrical and hydraulic subsystems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning a unified graph across electrical and hydraulic subsystems improves state forecasting by capturing cross-domain dependencies.
- Mechanism: The model uses attention-based graph learning to infer a latent correlation graph from sensor data, which encodes interdependencies between sensors across subsystems that are not apparent in separate subsystem graphs.
- Core assumption: The underlying physical interdependencies between hydraulic and electrical systems are reflected in statistical correlations in the sensor data.
- Evidence anchors:
  - [abstract] "Our method effectively fuses data from the PSH's subsystems by operating on a unified, system-wide graph, learned directly from the data"
  - [section] "To overcome this limitation, we propose learning a PSH sensor graph from latent dependencies in the data"
  - [corpus] Weak - no corpus evidence directly supports this mechanism, though related works on graph learning for power systems exist
- Break condition: If the hydraulic and electrical subsystems operate independently with minimal cross-coupling, the learned graph would show little cross-domain connections, negating the benefit.

### Mechanism 2
- Claim: Spectral-temporal filtering extracts relevant features from the graph-structured data for forecasting.
- Mechanism: The model applies graph-spectral filtering using Chebyshev polynomial approximation of the graph Laplacian, followed by time-spectral filtering with DFT and GLU to capture both spatial dependencies (graph structure) and temporal patterns.
- Core assumption: The state dynamics can be effectively represented in both graph-spectral and time-spectral domains, and the filtering operations can extract predictive features.
- Evidence anchors:
  - [abstract] "spectral-temporal graph neural networks, which leverage self-attention mechanisms to concurrently capture and learn meaningful subsystem interdependencies and the dynamic patterns"
  - [section] "We denote the graph Fourier transform as GF , and its inverse as IGF. The j-th channel yj in the graph-spectral domain is therefore computed..."
  - [corpus] Weak - while graph neural networks for power systems are common in the corpus, specific spectral-temporal filtering approaches like this are not well-represented
- Break condition: If the state dynamics are not well-captured by the spectral representations (e.g., highly non-linear dynamics not amenable to spectral decomposition), the filtering would fail to extract useful features.

### Mechanism 3
- Claim: Ablation of hydraulic information demonstrates its value for electrical state forecasting.
- Mechanism: By comparing model performance with and without hydraulic sensor data as input, the ablation study quantifies the improvement from data fusion.
- Core assumption: Hydraulic sensor data contains information relevant to electrical state prediction that is not redundant with electrical sensor data.
- Evidence anchors:
  - [abstract] "Ablation studies confirm that incorporating hydraulic information further improves forecast accuracy by 6.5% NMSE reduction"
  - [section] "In an ablation study, we exclude the hydraulic sensor data from the forecast to validate the effectiveness of fusing electric and hydraulic sensor data"
  - [corpus] Weak - no corpus evidence directly addresses this specific ablation approach for PSH systems
- Break condition: If hydraulic sensors provide no additional information beyond what electrical sensors already capture, the ablation would show no performance difference.

## Foundational Learning

- Concept: Graph Neural Networks
  - Why needed here: The PSH system can be represented as a graph where sensors are nodes and dependencies are edges, allowing GNNs to leverage structural information
  - Quick check question: What is the key difference between a GNN and a standard neural network when processing data?

- Concept: Spectral Graph Theory
  - Why needed here: The model uses graph Fourier transforms and spectral filtering, which require understanding of graph eigenvalues and eigenvectors
  - Quick check question: How does the graph Laplacian matrix relate to the connectivity structure of a graph?

- Concept: Time Series Forecasting
  - Why needed here: The core task is predicting future states of the PSH system based on historical sensor data
  - Quick check question: What is the difference between autoregressive and non-autoregressive forecasting approaches?

## Architecture Onboarding

- Component map: Data → Attention-based graph learning → Graph-spectral filtering → Time-spectral filtering → Residual connections → Forecasting head → Output

- Critical path: Data → Attention-based graph learning → Graph-spectral filtering → Time-spectral filtering → Residual connections → Forecasting head → Output

- Design tradeoffs:
  - Learned graph vs. predefined graph: Learned graphs can capture data-driven dependencies but may be less interpretable than physically-derived graphs
  - Spectral vs. spatial filtering: Spectral methods can be more efficient for certain graph structures but require eigenvalue decomposition or approximation
  - Window size selection: Larger windows capture more temporal context but increase computational cost and may introduce noise

- Failure signatures:
  - Poor forecasting performance: Could indicate issues with graph learning, filtering operations, or insufficient training data
  - Unstable learned graph: May suggest the model is overfitting or the data lacks consistent cross-domain dependencies
  - Gradient vanishing/exploding: Could indicate problems with the residual connections or activation functions

- First 3 experiments:
  1. Validate that the attention-based graph learning produces consistent graphs across random seeds and captures known physical dependencies
  2. Test the model with a predefined graph (from system diagrams) vs. the learned graph to quantify the benefit of data-driven learning
  3. Perform ablation studies varying the amount of hydraulic information included to determine the optimal data fusion level

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the learned graph structure change when applied to different PSH assets with varying physical topologies?
- Basis in paper: [explicit] The paper mentions that the proposed method can be easily transferred to different PSH assets without calibration, but does not explore this transferability.
- Why unresolved: The case study only evaluates a single Swiss PSH asset, leaving uncertainty about how the graph learning generalizes to different physical configurations.
- What evidence would resolve it: Applying the same methodology to multiple PSH plants with different topologies and comparing the learned graphs would reveal whether the attention mechanism consistently captures the same physical relationships or adapts to each asset's unique structure.

### Open Question 2
- Question: What is the impact of including physics-informed losses (such as electromagnetic generator efficiency or power flow constraints) on forecasting accuracy and training data requirements?
- Basis in paper: [explicit] The paper suggests that future work could reintegrate physics-informed losses to potentially reduce training data requirements, but does not explore this approach.
- Why unresolved: The current data-driven approach achieves good results but may benefit from incorporating physical constraints, especially when training data is limited.
- What evidence would resolve it: Comparing the current model against versions with physics-informed losses using datasets of varying sizes would demonstrate whether such constraints improve performance and data efficiency.

### Open Question 3
- Question: How does the learned attention graph compare to ground truth physical network diagrams when available, and what are the implications for interpretability?
- Basis in paper: [explicit] The paper shows that the learned attention graph recovers causal relationships and resembles the physical network, but does not compare it directly to actual network diagrams.
- Why unresolved: While the learned graph shows interpretability, its alignment with true physical connectivity remains unverified.
- What evidence would resolve it: Obtaining and comparing the learned attention graph against ground truth network diagrams for the same PSH asset would quantify how well the data-driven approach captures physical reality versus just statistical correlations.

## Limitations

- Model was trained and evaluated on a single Swiss PSH plant, limiting generalizability to different plant configurations
- Attention-based graph learning produces latent graphs that may not fully align with physical system understanding without additional interpretability analysis
- Spectral-temporal filtering assumes stationarity in the time-spectral domain, which may not hold during transient operating conditions or system faults

## Confidence

- Primary performance claims (34.7% NMSE reduction): **High** - Supported by comprehensive ablation studies and comparison against multiple baselines
- Graph learning mechanism: **Medium** - While empirically effective, the relationship between learned graphs and physical system structure requires further validation
- Hydraulic-electrical data fusion benefit (6.5% NMSE reduction): **Medium** - Ablation results are convincing but limited to the specific sensor configuration tested

## Next Checks

1. Test model performance on PSH plants with different sensor configurations and operating regimes to assess generalizability
2. Compare learned graphs against physically-derived system diagrams to evaluate interpretability and alignment with known dependencies
3. Evaluate model robustness during transient conditions and fault scenarios where spectral assumptions may break down