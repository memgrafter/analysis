---
ver: rpa2
title: Searching for Programmatic Policies in Semantic Spaces
arxiv_id: '2405.05431'
source_url: https://arxiv.org/abs/2405.05431
tags:
- search
- space
- programs
- liss
- policies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new approach to synthesizing programmatic
  policies by searching in semantic spaces rather than traditional syntax-based spaces.
  The authors define semantic spaces using a library of semantically different programs
  learned during training, and introduce a neighborhood function that replaces parts
  of the current candidate program with programs from this library.
---

# Searching for Programmatic Policies in Semantic Spaces

## Quick Facts
- arXiv ID: 2405.05431
- Source URL: https://arxiv.org/abs/2405.05431
- Reference count: 40
- Key outcome: Semantic-space search via Library-Induced Semantic Space (LISS) outperforms syntax-space search in sample efficiency and policy quality for programmatic RL in MicroRTS

## Executive Summary
This paper introduces a novel approach to synthesizing programmatic policies by searching in semantic spaces rather than traditional syntax-based spaces. The authors define semantic spaces using a library of semantically different programs learned during training, and introduce a neighborhood function that replaces parts of the current candidate program with programs from this library. Experiments in MicroRTS show that Stochastic Hill Climbing searching in the semantic space produces much stronger policies than searching in syntax-based spaces, with the synthesized policies outperforming winners of the last three MicroRTS competitions.

## Method Summary
The method constructs a Library-Induced Semantic Space (LISS) by first learning a library of semantically different programs from a training problem. The neighborhood function replaces subtrees of candidate programs with programs from this library, ensuring semantic diversity. SHC with restarts searches this semantic space, mixing with syntax space with probability ϵ=0.20. The approach is evaluated in MicroRTS across six maps, comparing against syntax-based baselines and competition winners through round-robin tournaments.

## Key Results
- The semantic space is β-proper (pβ=0.01) while the syntax space is not (pβ=0.19)
- SHC searching in semantic spaces produces much stronger policies than syntax-based search
- Policies synthesized in semantic spaces outperform winners of the last three MicroRTS competitions

## Why This Works (Mechanism)

### Mechanism 1
The semantic space defined by the library is β-proper, meaning small syntactic changes rarely lead to identical semantic behaviors. By building the library from programs encountered during training and only adding programs with unique action-signatures, the neighborhood function guarantees that replaced subtrees have distinct semantics. This reduces the probability that two syntactically close programs behave identically. Core assumption: The action-signature computed from 400 sampled states is a sufficient approximation of program semantics for this domain.

### Mechanism 2
SHC searching in LISS is more sample-efficient because it avoids evaluating semantically identical programs. Since neighbor programs in LISS have unique behaviors, each evaluation provides new information about the policy landscape, allowing the search to climb more effectively without redundant restarts caused by local optima of identical semantics. Core assumption: The sample efficiency gain outweighs the computational overhead of maintaining and using the library.

### Mechanism 3
The policies synthesized in LISS generalize better to unseen opponents because the semantic space encodes richer behavioral diversity. The library contains programs with distinct behaviors learned during training, so when SHC searches for a policy, it explores a space where small changes produce meaningful behavioral differences, enabling adaptation to new strategies. Core assumption: The training problem Ptrain is sufficiently representative of the space of possible opponents to yield a useful library.

## Foundational Learning

- Concept: Markov Decision Process (MDP) and policy optimization
  - Why needed here: The paper frames the problem as finding programmatic policies that maximize expected discounted rewards in an MDP.
  - Quick check question: What is the objective function that a programmatic policy aims to maximize in this context?

- Concept: Domain-specific language (DSL) and context-free grammar
  - Why needed here: The search space is defined by the set of all programs expressible in a DSL, so understanding AST generation and production rules is essential.
  - Quick check question: How does the neighborhood function generate syntactically valid neighbors in the syntax space?

- Concept: Action-signature as a proxy for program semantics
  - Why needed here: Since exact semantic comparison is infeasible, the paper uses action-signatures computed over sampled states to approximate program behavior.
  - Quick check question: Why does the paper consider two programs semantically identical if they produce the same action-signature?

## Architecture Onboarding

- Component map: DSL grammar → AST generator → program evaluator → action-signature calculator → library builder → LISS neighborhood function → SHC search loop
- Critical path: Library construction → define LISS → run SHC → evaluate policy → update library (optional)
- Design tradeoffs: Larger library → more semantic diversity but slower neighbor generation; smaller library → faster search but risk of β-proper failure
- Failure signatures: High pβ value in experiments, SHC frequently restarting due to local optima of identical semantics, poor generalization to new maps
- First 3 experiments:
  1. Compute pβ values for syntax vs LISS by generating 50 programs, 1000 neighbors each, rolling out once, and comparing action-signatures.
  2. Run SHC with restarts in both spaces on Ptest maps, measuring winning rate vs number of games played.
  3. Compare LISS-synthesized policies against competition winners in round-robin tournaments across all six maps.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of LISS scale with increasing complexity of the domain-specific language (DSL)?
- Basis in paper: [inferred] The paper uses a specific DSL for MicroRTS and shows that LISS outperforms traditional syntax-based approaches. However, it does not explore how the complexity of the DSL affects the performance of LISS.
- Why unresolved: The paper focuses on a single DSL for MicroRTS and does not investigate the impact of DSL complexity on LISS performance.
- What evidence would resolve it: Experiments comparing the performance of LISS across DSLs of varying complexity, such as different levels of abstraction or more expressive languages.

### Open Question 2
Can the library of semantically different programs be effectively learned in domains where the training problem is significantly different from the test problems?
- Basis in paper: [explicit] The paper discusses learning a library of programs while solving the training problem (Ptrain) and using it to define semantic spaces for downstream problems (Ptest). However, it does not explicitly address scenarios where Ptrain is significantly different from Ptest.
- Why unresolved: The paper does not explore the impact of domain differences between Ptrain and Ptest on the effectiveness of the learned library.
- What evidence would resolve it: Experiments evaluating LISS in domains where Ptrain and Ptest have substantial differences, such as different game maps or entirely different tasks.

### Open Question 3
How does the choice of the neighborhood function parameter (k) in LISS affect the sample efficiency and final policy quality?
- Basis in paper: [explicit] The paper uses k = 1000 in the neighborhood function Nk for Stochastic Hill Climbing (SHC) in LISS. However, it does not explore the impact of varying k on the performance of LISS.
- Why unresolved: The paper does not investigate the sensitivity of LISS to the choice of the neighborhood function parameter k.
- What evidence would resolve it: Experiments varying the value of k in LISS and comparing the sample efficiency and final policy quality across different values of k.

## Limitations
- The action-signature approximation may fail in domains with high-dimensional or continuous action spaces
- The library construction process could become computationally prohibitive for complex DSLs
- The β-properness guarantee depends critically on the quality of the sampled state distribution used to compute action-signatures

## Confidence
- Semantic space β-properness and its impact on search efficiency: High confidence
- LISS outperforming syntax-based search in sample efficiency: Medium confidence
- Generalizability of LISS policies to unseen opponents: Medium confidence

## Next Checks
1. Systematically vary the size and diversity of the initial library and measure the resulting pβ values and SHC performance to establish robustness to library quality.
2. Apply LISS to a different programmatic RL domain (e.g., robotic control with different DSL) to test whether semantic-space advantages transfer beyond MicroRTS.
3. Measure and compare the runtime and memory costs of maintaining the library versus the sample efficiency gains, particularly as the number of candidate programs grows large.