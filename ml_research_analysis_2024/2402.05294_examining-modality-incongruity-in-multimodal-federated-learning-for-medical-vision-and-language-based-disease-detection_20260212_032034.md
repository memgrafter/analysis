---
ver: rpa2
title: Examining Modality Incongruity in Multimodal Federated Learning for Medical
  Vision and Language-based Disease Detection
arxiv_id: '2402.05294'
source_url: https://arxiv.org/abs/2402.05294
tags:
- multimodal
- modality
- learning
- clients
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines modality incongruity in multimodal federated
  learning for medical vision and language-based disease detection. The authors analyze
  how missing modalities in clients affect federated learning performance and propose
  solutions to mitigate modality incongruity effects.
---

# Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection

## Quick Facts
- arXiv ID: 2402.05294
- Source URL: https://arxiv.org/abs/2402.05294
- Reference count: 40
- This paper examines modality incongruity in multimodal federated learning for medical vision and language-based disease detection.

## Executive Summary
This paper investigates how missing modalities in federated learning clients affect the performance of multimodal federated learning (MMFL) for medical image and text-based disease detection. The authors analyze three approaches to mitigate modality incongruity: varying self-attention mechanisms, introducing a modality imputation network (MIN), and applying regularization techniques at client and server levels. Experiments on MIMIC-CXR and Open-I datasets demonstrate that modality incongruity can cause incongruent MMFL to underperform unimodal federated learning, particularly under non-IID data distributions. The modality imputation network proves most effective in addressing this issue by generating synthetic reports for unimodal clients.

## Method Summary
The paper investigates modality incongruity in multimodal federated learning for medical vision and language-based disease detection using MIMIC-CXR and NIH-Open-I datasets. The approach involves implementing baseline unimodal and multimodal federated learning models using a BERT-based transformer architecture with ResNet-50 for feature extraction. Three methods are explored to mitigate modality incongruity: varying self-attention mechanisms (isolated, causal, partially bidirectional, bidirectional), a modality imputation network (MIN) using VQ-GAN and a cross-modal transformer to generate synthetic reports, and regularization techniques (FedProx, FedMultiProx, MOON, MultiMOON, MAD, MAD+) at client and server levels. The models are trained under different client ratios and data heterogeneity settings, with performance evaluated using AUC and F1 scores for multilabel disease classification.

## Key Results
- Incongruent MMFL can underperform unimodal FL under non-IID data distribution
- Modality imputation network (MIN) is most effective in addressing modality incongruity
- Server-level fine-tuning using unlabeled data is the second most effective approach
- Varying self-attention mechanisms provides partial mitigation of modality incongruity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modality imputation network (MIN) mitigates modality incongruity by generating synthetic reports for unimodal clients, transforming incongruent MMFL into pseudo-congruent MMFL.
- Mechanism: MIN uses a pre-trained BERT-based cross-modal transformer on multimodal client data to generate reports conditioned on CXR images. These generated reports are then used as proxy text data in unimodal clients, enabling consistent multimodal training across all clients.
- Core assumption: The MIN trained on client 1 data can generalize to generate meaningful reports for other clients despite potential domain shifts.
- Evidence anchors:
  - [abstract]: "The modality imputation network proves most effective in addressing modality incongruity"
  - [section]: "Table 3 shows the report generation performance of MIN across all clients in terms of BLEU-4 score... It is also observed from Table 3 that MIN enables the incongruent MMFL system to be more beneficial than unimodal FL in almost all cases"
  - [corpus]: "Weak - the corpus contains related papers but none directly validate MIN's effectiveness in MMFL"
- Break condition: If domain shift between clients is significant, MIN's generated reports may be too dissimilar from actual reports, reducing their effectiveness.

### Mechanism 2
- Claim: Server-level fine-tuning using unlabeled data reduces modality incongruity by aligning unimodal and multimodal client representations.
- Mechanism: LOOT (Leave-one-out teacher) method fine-tunes each client model using unlabeled server data by maximizing similarity between the student model's embeddings and the mean embeddings of other client models. This encourages unimodal clients to produce multimodal-like embeddings.
- Core assumption: The server data, even if unlabeled, provides enough signal to guide the alignment of client representations across modalities.
- Evidence anchors:
  - [abstract]: "The modality imputation network proves most effective... followed by server-level fine-tuning using unlabeled data"
  - [section]: "LOOT (T+I) consistently performs better than all other methods as it fine-tunes each client model by trying to match the embeddings of other client models"
  - [corpus]: "Weak - the corpus mentions federated learning papers but none specifically discuss server-level fine-tuning for modality incongruity"
- Break condition: If the server data has a large domain gap from client data, the alignment may not transfer effectively, reducing LOOT's effectiveness.

### Mechanism 3
- Claim: Varying self-attention mechanisms in multimodal clients can partially mitigate modality incongruity by optimizing information fusion.
- Mechanism: Different self-attention masks (isolated, causal, bidirectional, partially bidirectional) control how image and text modalities interact in multimodal clients. By optimizing this interaction, the model can better utilize available modalities and partially compensate for missing modalities in other clients.
- Core assumption: Optimizing information fusion in multimodal clients can indirectly improve their ability to collaborate with unimodal clients.
- Evidence anchors:
  - [abstract]: "We first demonstrate how the variation of self-attention masks in the multimodal client(s) vary the effectiveness of information fusion in incongruent MMFL system"
  - [section]: "Bidirectional self-attention mask shows the best performance and outperforms the isolated mask by around 3.27% and 4.54% for Open-I and MIMIC respectively in terms of AUC score"
  - [corpus]: "Weak - the corpus mentions multimodal learning but not specifically self-attention variations for modality incongruity"
- Break condition: If the fundamental modality gap between clients is too large, even optimal information fusion cannot fully compensate for missing modalities.

## Foundational Learning

- Concept: Federated Learning (FL) basics
  - Why needed here: The paper builds on FL foundations to implement MMFL across distributed clients
  - Quick check question: What is the key privacy benefit of FL compared to centralized learning?

- Concept: Multimodal Learning (MML) fundamentals
  - Why needed here: The paper addresses challenges specific to combining multiple modalities (image and text) in FL
  - Quick check question: What are the two main categories of fusion strategies in MML?

- Concept: Non-IID data distributions
  - Why needed here: The paper specifically examines how non-IID data affects modality incongruity in MMFL
  - Quick check question: How does non-IID data distribution typically impact model convergence in FL?

## Architecture Onboarding

- Component map:
  - Visual feature extractor (ResNet-50) -> Text tokenizer (Byte-level BPE) -> Joint embedding layer -> Multimodal transformer (BERT-base) -> Classification heads (14 linear heads)

- Critical path:
  1. Extract visual features from CXR images
  2. Process text reports into embeddings
  3. Combine modalities and pass through transformer
  4. Generate predictions via classification heads
  5. Perform local training on each client
  6. Aggregate models via FedAvg
  7. Evaluate performance and iterate

- Design tradeoffs:
  - Simple transformer vs. complex cross-attention: The paper uses self-attention to handle missing modalities, trading potential cross-modal benefits for robustness
  - Imputation vs. regularization: MIN provides synthetic data while regularization methods align representations; each has different computational costs and effectiveness

- Failure signatures:
  - Performance worse than unimodal FL: Indicates severe modality incongruity that cannot be compensated
  - High variance in client updates: Suggests difficulty in aligning multimodal and unimodal client models
  - Poor BLEU scores from MIN: Indicates MIN may not generalize well to all clients

- First 3 experiments:
  1. Compare performance of different self-attention masks (isolated vs. bidirectional) to understand information fusion impact
  2. Implement and evaluate MIN on a subset of clients to validate report generation quality
  3. Apply LOOT method with unlabeled server data to assess alignment effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions does incongruent multimodal federated learning outperform unimodal federated learning?
- Basis in paper: Explicit - The paper states that incongruent multimodal federated learning outperforms unimodal federated learning only under homogeneous settings (IID data partition), but underperforms under non-IID settings.
- Why unresolved: The paper does not provide a detailed analysis of the specific conditions (e.g., exact client ratios, data heterogeneity levels) under which incongruent multimodal federated learning consistently outperforms unimodal federated learning across different datasets and tasks.
- What evidence would resolve it: Empirical studies varying client ratios, data heterogeneity levels, and datasets to identify precise thresholds or conditions where multimodal learning consistently outperforms unimodal learning in federated settings.

### Open Question 2
- Question: How do different self-attention mechanisms impact the effectiveness of information fusion in multimodal federated learning under modality incongruity?
- Basis in paper: Explicit - The paper investigates various self-attention mechanisms (isolated, causal, partially bidirectional, and bidirectional) and their impact on information fusion in multimodal federated learning.
- Why unresolved: The paper does not provide a comprehensive comparison of how these mechanisms perform under varying levels of modality incongruity and data heterogeneity, nor does it explore the underlying reasons for their effectiveness or limitations.
- What evidence would resolve it: Detailed experiments comparing the performance of each self-attention mechanism across different scenarios of modality incongruity and data heterogeneity, along with analysis of attention patterns and their correlation with performance.

### Open Question 3
- Question: Can modality imputation networks effectively address modality incongruity in multimodal federated learning when there is a domain shift between clients?
- Basis in paper: Inferred - The paper introduces a modality imputation network (MIN) to generate missing modalities in unimodal clients and demonstrates its effectiveness. However, it also notes that if there is a domain shift between the client where the model is trained and the clients where it is utilized, the performance may decrease.
- Why unresolved: The paper does not provide empirical evidence or analysis of how well the modality imputation network performs when there is a domain shift between clients, which is a common scenario in real-world applications.
- What evidence would resolve it: Experiments evaluating the performance of the modality imputation network across clients with varying degrees of domain shift, along with techniques to adapt the model to handle such shifts effectively.

## Limitations
- The effectiveness of the modality imputation network relies heavily on the assumption that synthetic reports can adequately substitute for real reports across different client domains.
- The server-level fine-tuning approach assumes sufficient similarity between server and client data distributions, which may not hold in all federated learning scenarios.
- The study is limited to medical imaging and text data, and results may not directly transfer to other modality combinations or domains.

## Confidence

**High Confidence**: The core finding that modality incongruity negatively impacts MMFL performance is well-supported by experimental results showing unimodal FL outperforming incongruent MMFL in certain configurations. The comparative effectiveness ranking of the three approaches (MIN > server-level fine-tuning > self-attention variations) is also consistently demonstrated across datasets.

**Medium Confidence**: The mechanism by which MIN mitigates incongruity is plausible but could benefit from additional validation. While the paper shows MIN generates reasonable reports (BLEU-4 scores), the clinical relevance and semantic quality of these synthetic reports for downstream disease detection is not thoroughly examined.

**Low Confidence**: The generalizability of the proposed solutions to other MMFL scenarios (different modalities, domains, or client distributions) remains uncertain. The paper does not explore edge cases where modality incongruity is extreme or where client data distributions diverge significantly.

## Next Checks
1. **Domain Shift Analysis**: Conduct experiments where MIN is trained on one client and evaluated on others with varying degrees of domain similarity to quantify its generalization limits and identify break conditions.

2. **Clinical Relevance Evaluation**: Implement a blinded review by medical experts to assess whether MIN-generated reports maintain clinical utility and semantic coherence for disease detection tasks.

3. **Extreme Incongruity Stress Test**: Design experiments with highly imbalanced client distributions (e.g., 90% unimodal, 10% multimodal) and significant data heterogeneity to stress-test the robustness of each mitigation approach.