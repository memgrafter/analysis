---
ver: rpa2
title: 'MEEL: Multi-Modal Event Evolution Learning'
arxiv_id: '2404.10429'
source_url: https://arxiv.org/abs/2404.10429
tags:
- event
- evolution
- events
- meel
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Multi-Modal Event Evolution Learning (MEEL)
  to enhance multi-modal large language models' ability to understand event evolution
  and improve performance on downstream tasks. The core idea is to use ChatGPT to
  generate evolving graphs for diversified seed events, then adapt these graphs into
  instruction-tuning data and apply guiding discrimination to refine evolution pathways.
---

# MEEL: Multi-Modal Event Evolution Learning

## Quick Facts
- arXiv ID: 2404.10429
- Source URL: https://arxiv.org/abs/2404.10429
- Authors: Zhengwei Tao; Zhi Jin; Junqiang Huang; Xiancai Chen; Xiaoying Bai; Haiyan Zhao; Yifan Zhang; Chongyang Tao
- Reference count: 19
- Key outcome: MEEL enhances multi-modal large language models' ability to understand event evolution and improves performance on downstream tasks like visual storytelling and visual question answering

## Executive Summary
MEEL introduces a novel approach to enhance multi-modal large language models' event reasoning capabilities through event evolution learning. The method leverages ChatGPT to generate event evolution graphs from diversified seed events, converts these into instruction-tuning data, and applies guiding discrimination to refine evolution pathways. MEEL is evaluated on a newly curated multi-modal event reasoning benchmark (M-EV 2) covering causal, temporal, and intentional relations across nine datasets. The results demonstrate significant improvements over open-source MLLM baselines in visual storytelling, visual event prediction, and visual question answering tasks.

## Method Summary
MEEL employs a multi-stage approach to improve multi-modal event reasoning. First, it collects diverse seed events and uses ChatGPT to generate evolving event graphs through forward and backward expansion. These graphs are then converted into instruction-tuning format for model training. To address hallucination issues, MEEL introduces guiding discrimination where models learn to distinguish correct from incorrect event evolution paths through carefully curated negative examples. The method is evaluated on M-EV 2, a comprehensive benchmark covering multiple event relation types across nine datasets.

## Key Results
- MEEL achieves competitive performance on M-EV 2 benchmark compared to open-source MLLM baselines
- Significant improvements in visual storytelling (state-of-the-art results) and visual event prediction tasks
- Outperforms baselines in BERT-SCORE on open visual question answering datasets
- Demonstrates enhanced understanding of causal, temporal, and intentional event relations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MEEL improves MMER by learning event evolution graphs that capture complex inter-event relations beyond static inputs
- Mechanism: Event diversification collects diverse seed events → ChatGPT generates evolving graphs → instruction encapsulation converts graphs to training data → guiding discrimination refines evolution paths
- Core assumption: Event evolution graphs encode richer contextual knowledge than isolated event-question pairs, and models can generalize this knowledge to downstream tasks
- Evidence anchors:
  - [abstract] "The core idea is to use ChatGPT to generate evolving graphs for diversified seed events, then adapt these graphs into instruction-tuning data and apply guiding discrimination to refine evolution pathways."
  - [section 2.3] "We apply a breadth-first search (BFS) strategy using the ChatGPT to expand each seed event (E, I) ∈ SE both forward and backward in event happening time."
  - [corpus] Weak - no direct mentions of event evolution graphs or ChatGPT generation in related papers
- Break condition: If ChatGPT cannot generate coherent event sequences or if the graphs become too noisy/diffuse to be useful for training

### Mechanism 2
- Claim: Guiding discrimination mitigates hallucinations by training models to distinguish correct from incorrect event evolution paths
- Mechanism: Negative event mining strategies (semantic similarity, evolving direction) provide challenging distractors → model learns to identify correct evolution → reduces reasoning errors
- Core assumption: Models benefit from contrastive learning with difficult negative examples rather than just positive examples
- Evidence anchors:
  - [abstract] "Finally, we observe that models trained in this way are still struggling to fully comprehend event evolution. In such a case, we propose the guiding discrimination strategy, in which models are trained to discriminate the improper evolution direction."
  - [section 2.5] "The discrimination training is challenging to perform due to the sourcing of these negative events. For which we formulate two negative event acquisition strategies: Semantic and Evolving."
  - [corpus] Weak - no direct mentions of guiding discrimination or negative mining in related papers
- Break condition: If negative examples are too easy or too hard, model fails to learn meaningful discrimination

### Mechanism 3
- Claim: Event diversification broadens the model's exposure to varied event types and scenarios, improving generalization
- Mechanism: Balanced seed event collection (K events per trigger) → broader trigger coverage → richer event scenario training → better downstream performance
- Core assumption: Models learn better when trained on diverse, balanced event distributions rather than skewed, narrow distributions
- Evidence anchors:
  - [section 2.2] "Observing a long-tail distribution in trigger frequency, we only include K events per trigger to establish a balanced seed event set."
  - [section 3.6] "We compute the event verb distribution. We show two verb distributions with or without event diversification. The results are in Figure 6. We find the distribution is significantly diversified after the event diversification process."
  - [corpus] Weak - no direct mentions of event diversification or balanced sampling in related papers
- Break condition: If diversification introduces too much noise or irrelevant events, harming model performance

## Foundational Learning

- Concept: Event relational reasoning (causality, temporality, intention)
  - Why needed here: MEEL targets multi-modal event reasoning, which fundamentally requires understanding how events relate across time, cause-effect, and intent dimensions
  - Quick check question: Can you identify whether a given event pair represents a causal, temporal, or intentional relation?

- Concept: Multi-modal instruction tuning
  - Why needed here: MEEL converts event evolution graphs into instruction-tuning data format, requiring understanding of how to structure prompts and data for MLLM training
  - Quick check question: What are the key components of an effective multi-modal instruction-tuning dataset?

- Concept: Negative sampling and contrastive learning
  - Why needed here: Guiding discrimination relies on selecting appropriate negative examples to train event evolution discrimination
  - Quick check question: What makes a negative example "challenging" vs "easy" for a model to distinguish from the positive?

## Architecture Onboarding

- Component map: Event diversification module → ChatGPT interface → Instruction encapsulation pipeline → Guiding discrimination module → MLLM backbone
- Critical path: Event diversification → ChatGPT evolution → Instruction encapsulation → Model training (with guiding discrimination) → Evaluation on M-EV2 benchmark
- Design tradeoffs:
  - Evolution step count: More steps = richer context but potential semantic drift
  - Negative mining strategy: Semantic similarity vs evolving direction trade-off between difficulty and relevance
  - Prompt design: Rich vs concise instructions for ChatGPT evolution
- Failure signatures:
  - Model performs well on VQA but poorly on visual event prediction → indicates insufficient temporal reasoning
  - BLEU scores high but BERT-SCORE low → indicates lexical similarity without semantic understanding
  - Performance degrades with more evolution steps → indicates semantic drift problem
- First 3 experiments:
  1. Ablation: Train without guiding discrimination to measure its impact on hallucination reduction
  2. Hyperparameter sweep: Test different evolution step counts (1-4) to find optimal balance
  3. Negative mining comparison: Evaluate semantic vs evolving direction strategies on discrimination accuracy

## Open Questions the Paper Calls Out
None

## Limitations

- ChatGPT-generated event graphs reliability: The entire framework depends on ChatGPT to generate coherent event evolution sequences without systematic evaluation of hallucination rates or coherence metrics
- Negative mining effectiveness: Limited ablation study comparing the two negative sampling strategies or evaluating their difficulty calibration
- Generalization beyond curated datasets: Limited evidence that improvements transfer to more diverse, real-world multi-modal scenarios outside tested domains

## Confidence

**High confidence**: The basic architecture of using event diversification, instruction-tuning, and guiding discrimination is logically sound and well-structured. The reported improvements on specific benchmarks are statistically significant and methodologically valid.

**Medium confidence**: The mechanism claims about how event evolution graphs improve reasoning and how guiding discrimination reduces hallucinations are plausible but under-validated. The paper provides conceptual justification but limited empirical proof of these mechanisms.

**Low confidence**: The scalability and robustness of the ChatGPT-based event graph generation in real-world applications. The paper doesn't address computational costs, generation quality variance, or performance degradation with more complex scenarios.

## Next Checks

1. **Hallucination rate measurement**: Conduct human evaluation studies specifically measuring hallucination frequency in ChatGPT-generated event sequences before and after guiding discrimination training

2. **Cross-domain generalization test**: Evaluate MEEL on a diverse set of real-world multi-modal event scenarios (e.g., news videos, social media content, instructional videos) outside the curated benchmarks to assess practical applicability

3. **Ablation on negative mining**: Systematically compare the two negative sampling strategies and test various difficulty levels to determine optimal negative mining parameters for event evolution discrimination