---
ver: rpa2
title: 'Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques
  to Improve GPT-Delivered Problem-Solving Therapy'
arxiv_id: '2409.00112'
source_url: https://arxiv.org/abs/2409.00112
tags:
- prompt
- symptom
- dialogues
- human
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study examined the use of prompt engineering techniques to
  improve the ability of off-the-shelf Large Language Models (GPT-4) to deliver parts
  of Problem-Solving Therapy (PST) for family caregivers via text. Researchers systematically
  evaluated the impact of zero-shot, few-shot, and Chain-of-Thought prompting methods
  on symptom assessment and goal-setting tasks.
---

# Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy

## Quick Facts
- arXiv ID: 2409.00112
- Source URL: https://arxiv.org/abs/2409.00112
- Reference count: 21
- Key outcome: Few-shot and Chain-of-Thought prompting significantly improved GPT-4's ability to deliver PST symptom assessment and goal-setting tasks

## Executive Summary
This study systematically evaluated prompt engineering techniques to enhance Large Language Models' ability to deliver Problem-Solving Therapy (PST) for family caregivers via text. Researchers tested zero-shot, few-shot, and Chain-of-Thought prompting methods on GPT-4 across symptom assessment and goal-setting tasks. Human clinicians evaluated therapy dialogues alongside an automated empathy evaluation algorithm. Results demonstrated that few-shot and Chain-of-Thought techniques, particularly in combination (Model 2), achieved significantly higher scores than baseline prompts for both symptom assessment and goal setting. While empathy ratings showed moderate improvement with few-shot prompting, the study highlights both the potential and limitations of using prompt engineering to improve LLM-delivered therapy.

## Method Summary
The study employed a systematic approach to prompt engineering, testing baseline prompts against zero-shot, few-shot, and Chain-of-Thought techniques using GPT-4 to deliver PST components. Researchers generated 28 therapy dialogues (4 caregiver personas × 7 model variants) and evaluated them using both human clinicians (7 total: 4 nurses, 3 psychologists) and an automated empathy evaluation algorithm. The evaluation focused on three dimensions: symptom assessment, goal setting, and empathy (measured across emotional reactions, interpretations, and explorations). The study compared six different model variants built upon baseline prompt enhancements to determine which techniques most effectively improved therapy delivery.

## Key Results
- Few-shot prompting with 9 curated examples significantly improved symptom assessment and goal-setting task performance
- Chain-of-Thought prompting enhanced empathy ratings, particularly in exploration dimension
- Model 2 (combination of few-shot and Chain-of-Thought) achieved highest scores across all evaluated metrics
- Zero-shot prompting alone proved insufficient for protocolized therapy tasks
- Human and automated empathy evaluations showed low agreement, suggesting limitations in current evaluation methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Few-shot prompting with curated examples significantly improves the model's ability to follow PST protocol by demonstrating correct dialogue structure.
- Mechanism: The model learns task format and expected responses through exposure to high-quality example dialogues, enabling it to generate coherent and contextually appropriate responses.
- Core assumption: The quality and diversity of few-shot examples directly impacts the model's performance in generating appropriate therapy responses.
- Evidence anchors:
  - [abstract]: "Results showed that models enhanced with few-shot and Chain-of-Thought techniques (particularly Model 2) achieved higher scores than baseline prompts"
  - [section]: "Our implementation of the few-shot prompting method incorporates nine high-quality examples curated by clinicians as in-context learning examples to capture the complexities of symptom identification and analysis within the PST framework"
  - [corpus]: Weak - No direct corpus evidence supporting few-shot effectiveness for PST specifically
- Break Condition: If example quality degrades or examples don't cover diverse scenarios, model performance will deteriorate.

### Mechanism 2
- Claim: Chain-of-Thought prompting improves empathy ratings by encouraging more thoughtful, exploratory responses.
- Mechanism: CoT forces the model to "think out loud" through intermediate reasoning steps, leading to more thorough exploration of user feelings and experiences.
- Core assumption: The model's pre-training data contains sufficient exploratory reasoning patterns that can be activated through CoT prompting.
- Evidence anchors:
  - [abstract]: "Empathy ratings showed moderate improvement with few-shot prompting, but remained relatively consistent across models"
  - [section]: "Our implementation of CoT is an attempt to systematically improve the chatbot's analytical and problem-solving capabilities by forcing it to be more 'thoughtful' in its style of output"
  - [corpus]: Weak - No corpus evidence specifically linking CoT to improved empathy in therapeutic contexts
- Break Condition: If CoT prompts don't align with the model's learned reasoning patterns, performance may degrade rather than improve.

### Mechanism 3
- Claim: Zero-shot prompting alone is insufficient for protocolized therapy tasks due to the implicit nature of good therapeutic practice.
- Mechanism: While zero-shot provides explicit task definitions, it cannot capture the nuanced implicit requirements of effective therapy conversations.
- Core assumption: The implicit aspects of therapeutic conversations (like appropriate timing of questions, emotional nuance) cannot be effectively captured through explicit instructions alone.
- Evidence anchors:
  - [section]: "Zero-shot prompting focuses on explicitly defining tasks for the model to follow, but many aspects of what constitutes good therapy are implicit"
  - [section]: "Our finding that explicit directions may not be sufficient to adapt a model to a domain-specific task is in line with the literature"
  - [corpus]: Weak - No direct corpus evidence comparing zero-shot vs. few-shot for therapeutic tasks
- Break Condition: When task complexity increases beyond simple procedural steps to include nuanced interpersonal dynamics.

## Foundational Learning

- Concept: Prompt engineering techniques (zero-shot, few-shot, chain-of-thought)
  - Why needed here: Different prompting methods have varying effectiveness for protocolized therapy tasks; understanding their strengths and limitations is crucial for model optimization
  - Quick check question: Which prompting technique would you use if you needed to provide explicit step-by-step instructions for a new task?

- Concept: Problem-Solving Therapy (PST) protocol structure
  - Why needed here: The study focuses on improving LLM delivery of specific PST steps (symptom assessment and goal setting); understanding this protocol is essential for proper evaluation
  - Quick check question: What are the five key aspects of symptom assessment in PST that the model needs to address?

- Concept: Empathy evaluation frameworks
  - Why needed here: The study uses both human and automated methods to evaluate empathy; understanding these frameworks is critical for interpreting results
  - Quick check question: What are the three communication mechanisms used to measure empathy in text-based mental health support?

## Architecture Onboarding

- Component map:
  Prompt design -> Model development -> Dialogue generation -> Human evaluation -> Results analysis

- Critical path: Prompt design → Model development → Dialogue generation → Human evaluation → Results analysis

- Design tradeoffs:
  - Few-shot examples provide structure but require curation effort
  - Chain-of-Thought improves empathy but may reduce task efficiency
  - Human evaluation provides qualitative insights but is resource-intensive

- Failure signatures:
  - Repetitive questioning patterns
  - Generic responses lacking personalization
  - Failure to assess all five symptom aspects
  - Overly cheerful tone inappropriate for serious contexts

- First 3 experiments:
  1. Compare baseline prompt vs. few-shot prompt performance on symptom assessment task
  2. Test chain-of-thought prompting impact on empathy dimensions (ER, IP, EX)
  3. Evaluate combination of few-shot + chain-of-thought vs. individual techniques

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different prompt engineering techniques specifically affect empathy-related behaviors in LLM-delivered therapy, and can we optimize for empathy without compromising therapeutic task performance?
- Basis in paper: [explicit] The paper found that while Chain-of-Thought prompting improved empathy scores (particularly exploration), it simultaneously reduced performance on symptom assessment and goal setting. The authors note this tradeoff but don't explore optimization strategies.
- Why unresolved: The study showed the negative correlation but didn't investigate whether alternative prompt formulations or techniques could achieve both high empathy and high task performance simultaneously.
- What evidence would resolve it: A systematic study testing multiple variations of CoT prompts and other techniques specifically designed to maintain task performance while improving empathy metrics.

### Open Question 2
- Question: Can LLMs deliver full Problem-Solving Therapy sessions autonomously, and what technical approaches would be required to achieve this?
- Basis in paper: [explicit] The authors state "we will continue to improve the models to deliver full PST by performing fine-tuning and Retrieval Augmented Generation (RAG) techniques" and note that their current models "cannot be deployed directly in psychotherapy settings without human oversight."
- Why unresolved: The study only tested two steps of PST (symptom assessment and goal setting) and identified the need for further development to deliver complete therapy sessions.
- What evidence would resolve it: A subsequent study demonstrating successful delivery of all PST steps through a combination of prompt engineering, fine-tuning, and RAG approaches, validated through both automated and human evaluations.

### Open Question 3
- Question: How well do automated empathy evaluation algorithms generalize to specialized therapeutic domains like PST, and what domain-specific adaptations would improve their accuracy?
- Basis in paper: [explicit] The authors note "we found low agreement between the human and automatic evaluations" and suggest "Future studies should examine the generalizability of the automatic evaluation algorithms with domain shifts."
- Why unresolved: The automated evaluation algorithm was trained on Reddit dialogue data, which differs substantially from structured therapeutic conversations, leading to poor correlation with human evaluations.
- What evidence would resolve it: Development and validation of domain-specific automated evaluation metrics trained on therapeutic dialogue data, showing improved correlation with human expert assessments.

## Limitations
- Simulated rather than actual caregiver responses may not capture real-world therapy complexity
- Small sample size of 7 clinicians limits generalizability of human evaluations
- Automated empathy evaluation algorithm lacks validation for mental health applications
- Study only tested two components of PST, leaving questions about full therapy delivery

## Confidence
**High Confidence Claims:**
- Few-shot and Chain-of-Thought prompting techniques produce significantly better symptom assessment and goal-setting outcomes compared to baseline prompts
- The combination of few-shot and Chain-of-Thought techniques (Model 2) achieves the highest performance across evaluated metrics

**Medium Confidence Claims:**
- Empathy ratings show moderate improvement with few-shot prompting
- Zero-shot prompting alone is insufficient for protocolized therapy tasks
- Prompt engineering can significantly improve LLMs' ability to deliver protocolized therapy

**Low Confidence Claims:**
- Long-term effectiveness of LLM-delivered PST in real clinical settings
- Generalizability of findings to other therapeutic approaches beyond PST
- The specific impact of prompt engineering on clinical outcomes in diverse populations

## Next Checks
1. **Clinical Validation**: Conduct a randomized controlled trial comparing LLM-delivered PST with human-delivered therapy in actual caregiver populations, measuring both symptom reduction and quality of life outcomes over 6-12 weeks.

2. **Prompt Robustness Testing**: Systematically vary the quality and diversity of few-shot examples to establish the relationship between example quality and model performance, testing at least 3 different quality levels across 10+ example sets.

3. **Cross-Domain Generalization**: Test the effectiveness of the best-performing prompt engineering techniques (Model 2) across 3-5 different therapeutic protocols beyond PST, such as Cognitive Behavioral Therapy or Motivational Interviewing, to assess generalizability.