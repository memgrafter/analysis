---
ver: rpa2
title: Training Safe Neural Networks with Global SDP Bounds
arxiv_id: '2409.09687'
source_url: https://arxiv.org/abs/2409.09687
tags:
- neural
- network
- bound
- arxiv
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel method for training neural networks
  with formal safety guarantees by leveraging semidefinite programming (SDP) for verification
  over large, high-dimensional input regions. The approach addresses limitations of
  existing verification methods that focus on small perturbations around dataset points.
---

# Training Safe Neural Networks with Global SDP Bounds

## Quick Facts
- arXiv ID: 2409.09687
- Source URL: https://arxiv.org/abs/2409.09687
- Reference count: 40
- Key outcome: Introduces ADMM-based training with SDP bounds for provable safety in high-dimensional neural networks

## Executive Summary
This paper addresses the challenge of training neural networks with formal safety guarantees by leveraging semidefinite programming (SDP) for verification over large, high-dimensional input regions. The authors propose an ADMM-based training scheme that enforces safety specifications by optimizing a dual SDP formulation, allowing them to train provably safe classifiers on the Adversarial Spheres dataset with input dimensions up to d=40. The key innovation is using tight SDP bounds rather than looser linear bounds for verification during training. Experiments show that linear methods become exponentially costly as network size increases, while the SDP-based approach scales polynomially. The method successfully trains networks achieving perfect recall with provable safety guarantees, whereas linear verification methods time out for larger networks.

## Method Summary
The paper introduces an ADMM-based training method that enforces safety constraints through dual SDP formulation. The approach reformulates the training problem as a constrained optimization where safety specifications are expressed via the dual SDP formulation. ADMM alternates between optimizing network weights, dual variables, and slack variables while maintaining feasibility. The method uses Xavier initialization and trains on the Adversarial Spheres dataset with both L2 and L∞ variants. The verification bounds are computed using SDP relaxation of quadratic constraints from ReLU activations, and the training is guided by the tight SDP bounds rather than looser linear approximations.

## Key Results
- Successfully trains provably safe classifiers on Adversarial Spheres dataset with input dimensions up to d=40
- Achieves perfect recall (100%) on inner class while maintaining provable safety guarantees
- SDP bounds remain tight for high-dimensional input regions while linear bounds become exponentially loose
- Training with SDP bounds scales polynomially, while linear verification methods (α-CROWN) time out for larger networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SDP bounds remain tight for high-dimensional input regions while linear bounds (α-CROWN) become exponentially loose
- Mechanism: SDP uses semidefinite relaxation of the quadratic constraints that arise from ReLU activations, preserving the quadratic structure of the problem. Linear bounds approximate ReLU with piecewise linear constraints that lose accuracy as the input region grows.
- Core assumption: The input region is convex and can be expressed as an L2 or L∞ ball
- Evidence anchors:
  - [abstract] "The key innovation is using tight SDP bounds rather than looser linear bounds (like α-CROWN) for verification during training"
  - [section 2.3] "we observe that in almost all cases, for nearly all dimensions, the α-CROWN bound is an order of magnitude worse than the SDP bound"
  - [corpus] "Interior-Point Vanishing Problem in Semidefinite Relaxations for Neural Network Verification" - SDP relaxation quality degrades in deep networks
- Break condition: When the network becomes so deep that SDP relaxation becomes infeasible due to interior-point vanishing

### Mechanism 2
- Claim: The ADMM-based training scheme enables optimization over both network weights and verification dual variables simultaneously
- Mechanism: The training problem is reformulated as a constrained optimization where the safety constraint is expressed via the dual SDP formulation. ADMM alternates between optimizing network weights, dual variables, and slack variables while maintaining feasibility.
- Core assumption: The SDP duality gap is zero for the verification problem
- Evidence anchors:
  - [section 3.2] "The advantage of the dual problem over the primal one is that any valid (y, S) yields an upper bound on BSDP"
  - [section 3.3] "We begin by writing the augmented Lagrangian, which includes all constraints"
  - [corpus] Weak evidence - no direct comparison to other ADMM-based verification methods
- Break condition: When the tolerance δ is too loose and the ADMM iterations fail to converge to the true SDP bound

### Mechanism 3
- Claim: Xavier initialization with specific layer architecture leads to predictable scaling behavior of SDP bounds
- Mechanism: The theoretical analysis shows that for Xavier-initialized networks, the SDP bound scales as O(1+ε) for L2 input constraints and O(ε√d) for L∞ constraints, while linear bounds scale as Ω(εd).
- Core assumption: Network width d and hidden size h grow proportionally while maintaining the Xavier initialization properties
- Evidence anchors:
  - [section 2.4] "Theorem 2.1... BSDP = O(1 + ε)" and "Theorem 2.2... BLP = Ω(εd)"
  - [section 2.3] "When the network is trained, both gaps become much wider compared with randomly initialized setting"
  - [corpus] "A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks" - Lipschitz constraints scale predictably with network size
- Break condition: When training causes weight norms to grow beyond the assumptions of the theoretical analysis

## Foundational Learning

- Concept: Semidefinite Programming (SDP) relaxation for neural network verification
  - Why needed here: SDP provides tighter bounds than linear relaxations for large input regions, which is essential for safety verification in high dimensions
  - Quick check question: What is the difference between primal and dual SDP formulations in the context of neural network verification?

- Concept: ADMM (Alternating Direction Method of Multipliers) for constrained optimization
  - Why needed here: ADMM allows simultaneous optimization over network weights and verification dual variables while maintaining feasibility of the safety constraint
  - Quick check question: How does the augmented Lagrangian formulation in ADMM differ from standard Lagrangian methods?

- Concept: ReLU network verification via quadratic constraints
  - Why needed here: The ReLU activation can be expressed as quadratic constraints, which form the basis for both SDP and linear relaxations
  - Quick check question: How do you express the ReLU constraint z = relu(x) as a quadratic constraint?

## Architecture Onboarding

- Component map:
  Neural network classifier (2 hidden layers, Xavier initialized) -> SDP verifier (primal and dual formulations) -> ADMM optimizer (weight updates, dual updates, slack variable management) -> Dataset (Adversarial Spheres with L2 and L∞ variants)

- Critical path:
  1. Initialize network with Xavier initialization
  2. Set up SDP constraints for the safety specification
  3. Run ADMM iterations until convergence tolerance δ is met
  4. Verify final network with CVXPY SDP solver
  5. Measure accuracy and safety properties

- Design tradeoffs:
  - SDP vs linear bounds: Tighter but more computationally expensive vs looser but faster
  - ADMM tolerance δ: Smaller values give tighter bounds but require more iterations
  - Input dimension d: Larger dimensions improve scalability but may require more careful hyperparameter tuning

- Failure signatures:
  - ADMM iterations fail to converge (check tolerance δ and dual update rate α)
  - SDP bound becomes too loose during training (check weight norms and network architecture)
  - Verification times become prohibitive (consider network pruning or architecture simplification)

- First 3 experiments:
  1. Train a network on D2 with d=5, h=15 and verify safety properties using both SDP and α-CROWN
  2. Vary the tolerance δ in ADMM to observe its effect on final network accuracy and safety guarantees
  3. Compare training on D2 vs D∞ to understand the impact of input constraint type on final performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ADMM-based training method be extended to handle the L∞-norm safety specifications, which currently show rapidly decreasing accuracy as input dimension increases?
- Basis in paper: [explicit] The authors explicitly state that "in the case of the l∞-norm, based on the experimental results of Section 2.3 and the theoretical result 2.1, the SDP bound becomes too imprecise to guide the training effectively" and that "the logical continuation of this research is to search for new global bounds that can be used for neural network training in the l∞-norm case."
- Why unresolved: The paper only provides experimental results showing the problem, but does not propose a solution or method for addressing the L∞-norm case.
- What evidence would resolve it: A successful extension of the ADMM-based training method that achieves high accuracy (comparable to the L2 case) on L∞-norm safety specifications for input dimensions up to d=40 would resolve this question.

### Open Question 2
- Question: Can the SDP-based verification method be effectively combined with branch-and-bound algorithms to achieve tighter bounds and potentially improve the training of neural networks with L∞-norm safety specifications?
- Basis in paper: [inferred] The authors suggest that "Another direction is to incorporate the SDP bound with a branch-and-bound algorithm" and note that "for a given network, it may serve as a way to trade off computational complexity with final accuracy by making the SDP bounds tighter and more useful in guiding the network's training."
- Why unresolved: The paper does not provide experimental results or theoretical analysis of combining SDP with branch-and-bound algorithms for training neural networks with safety guarantees.
- What evidence would resolve it: Experimental results demonstrating improved accuracy on L∞-norm safety specifications when using a combined SDP-branch-and-bound approach compared to using SDP alone would resolve this question.

### Open Question 3
- Question: How can the proposed SDP-based training method be extended to handle more complex neural network architectures, such as those with multiple layers or non-linear activation functions beyond ReLU?
- Basis in paper: [inferred] The authors focus on shallow neural networks with ReLU activations and suggest that future work should "demonstrate the applicability of this method to safe RL control by extending it to simultaneously train neural policies and neural Lyapunov functions [6] or reach-avoid supermartingales [28], while using SDP bounds to ensure their safety properties."
- Why unresolved: The paper only presents results for shallow neural networks with ReLU activations, and does not explore the scalability of the method to more complex architectures or activation functions.
- What evidence would resolve it: Successful application of the SDP-based training method to deeper neural networks with various activation functions (e.g., tanh, sigmoid) while maintaining safety guarantees and reasonable computational efficiency would resolve this question.

## Limitations

- The method shows rapidly decreasing accuracy for L∞-norm safety specifications as input dimension increases
- Computational overhead remains significant for very large networks despite polynomial scaling
- Reliance on specific initialization schemes (Xavier) and network architectures may limit generalizability

## Confidence

- **High confidence**: The comparative advantage of SDP bounds over linear methods for high-dimensional inputs is well-supported by both theoretical analysis and experimental results
- **Medium confidence**: The ADMM training approach is sound, but the specific hyperparameter choices and their sensitivity across different network scales need further validation
- **Medium confidence**: The theoretical bounds on SDP versus linear approximations hold under the stated assumptions, but real-world networks may deviate from ideal initialization conditions

## Next Checks

1. Test the ADMM training stability across different random seeds and network initializations to verify robustness
2. Compare verification times and bounds on networks trained with different architectures (beyond the 2-hidden layer setup)
3. Evaluate safety guarantees on more diverse datasets beyond Adversarial Spheres to assess practical applicability