---
ver: rpa2
title: Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented
  Language Models
arxiv_id: '2410.05162'
source_url: https://arxiv.org/abs/2410.05162
tags:
- tokens
- context
- token
- object
- subject
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study examines how ATLAS, a retrieval-augmented language model,
  balances parametric knowledge and retrieved context. Using causal mediation analysis,
  the authors investigate two key aspects: which parts of the model drive copying
  behavior and how the model decides to use context.'
---

# Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models

## Quick Facts
- arXiv ID: 2410.05162
- Source URL: https://arxiv.org/abs/2410.05162
- Authors: Mehrdad Farahani; Richard Johansson
- Reference count: 17
- The study uses causal mediation analysis to investigate how ATLAS, a retrieval-augmented language model, balances parametric knowledge and retrieved context

## Executive Summary
This paper examines how retrieval-augmented language models like ATLAS balance parametric knowledge with retrieved context using causal mediation analysis. The authors investigate two key aspects: which model components drive copying behavior and how the model decides to use context. Through experiments, they find that ATLAS consistently relies more on context than parametric memory, particularly when context contains relevant object tokens. The study reveals that object tokens are crucial for copying behavior while subject and relation tokens play important roles in relevance evaluation.

## Method Summary
The study uses causal mediation analysis on ATLAS, a retrieval-augmented language model, to disentangle the effects of parametric knowledge and retrieved context. The researchers conduct experiments using the PopQA and PEQ datasets, creating synthetic context templates from factual triples. They apply counterfactual interventions by replacing object tokens and adding noise to subject/relation embeddings, then measure the model's behavior through causal tracing across different layers. The analysis focuses on computing Total Effect (TE) and Average Indirect Effect (AIE) to quantify how different model components contribute to copying behavior and relevance evaluation.

## Key Results
- ATLAS consistently relies on context over parametric memory when object tokens are present in retrieved context
- Object tokens are the primary drivers of copying behavior, while subject and relation tokens are used for relevance evaluation
- MLP layers in middle layers are crucial for translating object token representations from encoder to decoder space

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model prioritizes copying from retrieved context over relying on parametric memory when object tokens are present in the context.
- Mechanism: When the retrieved context contains the true answer as an object token, the model's copying behavior is triggered. Causal mediation analysis shows that object tokens have the highest average indirect effect (AIE) in copying situations, indicating they are the primary drivers of this behavior.
- Core assumption: Object tokens in the context directly map to the answer the model should generate, and the model has learned to prioritize this mapping over its parametric knowledge.
- Evidence anchors:
  - [abstract]: "Our findings disentangle the effects of parametric knowledge and the retrieved context. They indicate that in cases where the model can choose between both types of information (parametric and non-parametric), it relies more on the context than the parametric knowledge."
  - [section]: "The causal tracing results (Figure 2a–2c) clearly show that object tokens are the most impactful when the model is in copying mode. The AIEs are close to zero for other token positions – such as subject and relation tokens – in the context."
  - [corpus]: Weak evidence. The corpus contains related work on RAG systems and memory interplay, but lacks direct evidence about object token copying mechanisms.
- Break condition: If the context does not contain the correct object token, or if the object token is corrupted or replaced with a counterfactual, the model will fall back to using its parametric memory.

### Mechanism 2
- Claim: The model first evaluates context relevance using subject and relation tokens before deciding to copy from the context.
- Mechanism: The model processes subject and relation tokens in early layers to determine if the context is relevant to the query. If relevance is established, the model then shifts focus to object tokens in later layers for copying. This two-step process is evident from the pattern of average indirect effects across layers.
- Core assumption: The model has learned a hierarchical processing strategy where relevance evaluation precedes answer extraction.
- Evidence anchors:
  - [abstract]: "Furthermore, the analysis investigates the computations involved in how the model uses the information from the context. We find that multiple mechanisms are active within the model and can be detected with mediation analysis: first, the decision of whether the context is relevant, and second, how the encoder computes output representations to support copying when relevant."
  - [section]: "Low AIE values for object tokens in the early layers show that the model mainly focuses on subject and relation tokens in these layers. It is as if the model is first trying to determine the relevance of the context."
  - [corpus]: Weak evidence. The corpus contains related work on RAG systems and memory interplay, but lacks direct evidence about the two-step relevance evaluation and copying process.
- Break condition: If subject or relation tokens are corrupted or replaced with counterfactuals, the model may fail to recognize the context as relevant and default to parametric memory.

### Mechanism 3
- Claim: The MLP layers in the middle of the model are crucial for translating object token representations from the encoder to the decoder space.
- Mechanism: The MLP layers process object token representations in the middle layers, transforming them from the encoder's latent space to a form that can be understood by the decoder. This translation is necessary because the encoder and decoder operate in different latent spaces. Causal tracing shows that MLP layers have high AIE values for object tokens, while attention layers have lower values.
- Core assumption: The encoder and decoder use different latent spaces, requiring a translation mechanism for information flow between them.
- Evidence anchors:
  - [section]: "Moreover, the MLP in mid-layers plays a crucial role in translating representations from the encoder to the decoder. It needs to ensure that the copied object tokens can be passed into the decoder so that they can be generated as output."
  - [section]: "The PSE results show that in the early layers, both the MLP and Attention work closely with subject and relation tokens. Put simply, the model evaluates these tokens together to figure out if the context is relevant. As we move into the later layer, the Attention becomes increasingly engaged with the object tokens."
  - [corpus]: Weak evidence. The corpus contains related work on RAG systems and memory interplay, but lacks direct evidence about the specific role of MLP layers in translating between encoder and decoder spaces.
- Break condition: If MLP layers are severed or corrupted, the model loses its ability to translate object token representations, severely impairing its copying behavior.

## Foundational Learning

- Concept: Causal mediation analysis
  - Why needed here: This study uses causal mediation analysis to disentangle the effects of different model components on the overall behavior. Understanding this technique is crucial for interpreting the results and mechanisms described in the paper.
  - Quick check question: What is the difference between total effect, natural indirect effect, and natural direct effect in causal mediation analysis?

- Concept: Retrieval-augmented generation (RAG) systems
  - Why needed here: The paper investigates how a RAG model (ATLAS) balances parametric and non-parametric memory. Understanding the basic architecture and operation of RAG systems is essential for grasping the research questions and experimental design.
  - Quick check question: In a RAG system, what are the two main components that work together to generate responses, and how do they differ in terms of memory type?

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: The study examines how different components of the transformer architecture (MLP layers, attention layers) contribute to copying behavior and relevance evaluation. Understanding these components is necessary for interpreting the causal tracing results.
  - Quick check question: In a transformer block, what are the two main sub-layers, and what is the primary function of each?

## Architecture Onboarding

- Component map: Retriever -> Encoder -> MLP layers -> Attention layers -> Decoder
- Critical path:
  1. Query is processed by the encoder
  2. Retrieved context is encoded and processed for relevance
  3. If context is deemed relevant, object tokens are extracted
  4. MLP layers translate object token representations for the decoder
  5. Decoder generates output using the translated representations

- Design tradeoffs:
  - Relying on context (non-parametric memory) vs. parametric memory
  - Processing subject/relation tokens for relevance vs. object tokens for copying
  - Using MLP for translation vs. relying solely on attention mechanisms

- Failure signatures:
  - If the model consistently ignores context and relies on parametric memory, it may indicate issues with relevance evaluation or object token extraction
  - If the model fails to copy correct answers from context, it may suggest problems with MLP translation or attention focusing
  - If the model shows inconsistent behavior across different contexts, it may indicate issues with the relevance evaluation mechanism

- First 3 experiments:
  1. Replace object tokens in the context with counterfactuals and observe the model's output. This tests the model's reliance on context vs. parametric memory.
  2. Corrupt subject tokens in the context and measure the impact on context relevance evaluation. This tests the role of subject tokens in the relevance mechanism.
  3. Sever MLP layers in the middle of the model and observe the effect on copying behavior. This tests the hypothesis that MLP is crucial for translating object token representations.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do retrieval-augmented language models balance reliance on parametric versus non-parametric memory in different domains or knowledge types?
- Basis in paper: [explicit] The paper shows ATLAS consistently relies on context over parametric memory when context contains relevant object tokens, and investigates which model components drive this behavior.
- Why unresolved: The experiments focus on entity-centric factual questions from specific datasets. The model's behavior might differ for more subjective, temporal, or rapidly-changing knowledge domains.
- What evidence would resolve it: Experiments testing ATLAS on domains like current events, subjective opinions, or procedural knowledge would reveal whether the observed context-reliance pattern holds across knowledge types.

### Open Question 2
- Question: What mechanisms allow retrieval-augmented models to identify and resolve conflicting information between retrieved context and parametric memory?
- Basis in paper: [inferred] The paper shows ATLAS copies from context when relevant, but doesn't explore how the model handles situations where context contradicts stored knowledge or contains multiple conflicting answers.
- Why unresolved: The experiments use controlled templates with single correct answers. Real-world scenarios often involve ambiguity, conflicting sources, or outdated information requiring reconciliation.
- What evidence would resolve it: Testing ATLAS on queries with deliberately contradictory contexts or comparing responses when context conflicts with parametric knowledge would reveal conflict resolution mechanisms.

### Open Question 3
- Question: How do specific model components (MLP vs Attention) contribute to the translation and integration of retrieved information across different layers?
- Basis in paper: [explicit] The paper identifies that MLP layers in mid-layers are crucial for translating object token representations from encoder to decoder space, while Attention plays a supportive role in maintaining context coherence.
- Why unresolved: The study shows these patterns in controlled experiments but doesn't fully explain why these architectural differences exist or how they might be optimized for different retrieval scenarios.
- What evidence would resolve it: Ablation studies removing or modifying specific MLP and Attention components across layers, combined with architectural analysis, would clarify their distinct roles in information integration.

## Limitations
- The study relies on synthetic contexts generated from factual triples, which may not capture real-world retrieval complexity
- Causal mediation analysis assumes decomposable causal pathways that may oversimplify actual decision-making
- The experimental setup may amplify copying behavior compared to more complex real-world scenarios

## Confidence
- Medium: The model prioritizes context over parametric memory when object tokens are present
- Medium: Subject and relation tokens are used for relevance evaluation before object token copying
- Medium: MLP layers play a crucial role in translating between encoder and decoder spaces

## Next Checks
1. Apply causal mediation analysis to real retrieved contexts from actual retrieval systems to verify if observed mechanisms hold in realistic scenarios
2. Conduct systematic ablation study removing individual layers to quantify their exact contribution to relevance evaluation and copying behavior
3. Test similar copying patterns and relevance evaluation mechanisms in other retrieval-augmented models to determine if findings represent broader principles in RAG architectures