---
ver: rpa2
title: Graph Neural Network based Handwritten Trajectories Recognition
arxiv_id: '2405.09247'
source_url: https://arxiv.org/abs/2405.09247
tags:
- chain
- graph
- handwritten
- trajectories
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a novel approach to handwritten trajectory
  recognition using graph neural networks (GNNs) combined with chain code feature
  extraction. The method transforms handwritten strokes into graph structures, where
  chain codes represent the trajectory direction sequences, and nodes/edges capture
  the stroke geometry.
---

# Graph Neural Network based Handwritten Trajectories Recognition

## Quick Facts
- arXiv ID: 2405.09247
- Source URL: https://arxiv.org/abs/2405.09247
- Authors: Anuj Sharma; Sukhdeep Singh; S Ratna
- Reference count: 6
- Primary result: Achieves 1.10% (MNIST), 1.55% (Unipen), and 6.39% (Gurkhali) error rates using GNNs with chain code features

## Executive Summary
This study introduces a graph neural network approach for handwritten trajectory recognition that combines chain code feature extraction with GNN-based classification. The method transforms handwritten strokes into graph structures where chain codes encode boundary direction sequences, and nodes/edges capture stroke geometry. For offline handwriting, drawing order recovery is applied to convert images into stroke sequences before chain code generation, while online handwriting directly uses pen stroke data. The approach is evaluated on MNIST (offline) and Unipen/Gurkhali datasets (online), achieving error rates of 1.10%, 1.55%, and 6.39% respectively, outperforming previous SVM and HMM methods.

## Method Summary
The method converts handwritten strokes into chain code representations that capture trajectory direction sequences, then transforms these sequences into graph structures suitable for GNN processing. For offline handwriting (MNIST), the approach first recovers drawing order to convert images into stroke sequences, then generates chain codes. For online handwriting (Unipen, Gurkhali), the method directly uses pen stroke data to generate chain codes. The chain codes form nodes and edges in a graph where GNNs perform classification through message passing operations. The system uses batch processing for training efficiency and evaluates performance using error rate metrics compared against traditional SVM and HMM baselines.

## Key Results
- Achieves 1.10% error rate on MNIST dataset (offline handwriting)
- Achieves 1.55% error rate on Unipen dataset (online digits)
- Achieves 6.39% error rate on Gurkhali dataset (online strokes)
- Outperforms previous SVM and HMM methods on all tested datasets
- Demonstrates effective performance in relatively few training epochs through batch processing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain codes convert handwritten strokes into compact graph representations suitable for GNNs
- Mechanism: Chain codes encode boundary direction sequences; these sequences become nodes and edges forming a graph structure that GNNs can process
- Core assumption: Handwriting strokes can be faithfully represented as direction sequences without losing spatial-temporal information
- Evidence anchors:
  - [abstract] "The chain code as feature extraction technique has shown significant results in literature and we have been able to use chain codes with graph neural networks."
  - [section 3] "The chain code formed on the basis of boundary tracing using techniques as Huffman chain codes... These chain codes describe the boundary of the object by encoding the sequence of directions or transitions between neighboring points along the trajectory."
  - [corpus] Weak; neighbors focus on CNNs and edge-weighted GATs, not chain code + GNN combinations
- Break condition: If stroke direction encoding loses critical spatial relationships or temporal order, graph-based recognition fails

### Mechanism 2
- Claim: GNN operators like DeeperGCN outperform traditional classifiers (SVM, HMM) on handwritten trajectory recognition
- Mechanism: GNNs aggregate local node features through message passing, capturing spatial relationships in stroke patterns that traditional classifiers miss
- Core assumption: Graph structure effectively represents stroke geometry for pattern recognition
- Evidence anchors:
  - [section 4] "We have used batch loader to make it efficient to load data... These weights are calculated using the gradient descent approach."
  - [corpus] Weak; neighbors discuss CNNs and edge-weighted GATs but not GNN performance on chain code features specifically
- Break condition: If message passing fails to capture meaningful stroke relationships or overfitting occurs

## Foundational Learning

### Chain Code Encoding
- Why needed: Converts continuous stroke trajectories into discrete direction sequences suitable for graph representation
- Quick check: Verify chain code generation follows Huffman or Freeman encoding schemes with 8-directional compass encoding

### Drawing Order Recovery
- Why needed: Converts static offline images into temporal stroke sequences for chain code generation
- Quick check: Validate that recovered stroke order preserves actual writing sequence before chain code extraction

### GNN Message Passing
- Why needed: Aggregates local node features to capture spatial relationships in stroke geometry
- Quick check: Confirm message passing captures meaningful stroke patterns through node/edge feature propagation

## Architecture Onboarding

### Component Map
Raw Strokes -> Chain Code Extraction -> Graph Construction -> GNN Processing -> Classification

### Critical Path
Chain Code Generation -> Graph Structure Creation -> GNN Message Passing -> Classification Output

### Design Tradeoffs
- Fixed vs variable feature vector lengths (41 for MNIST, 25 for Gurkhali)
- Number of GNN convolution steps (3 steps used)
- Hidden channel dimensionality (16 channels used)

### Failure Signatures
- Poor graph construction leading to overfitting or underfitting
- GNN convergence issues due to incorrect batch loading or learning rate settings
- Loss of temporal information during offline to online conversion

### First Experiments
1. Verify chain code generation from handwritten strokes matches paper's encoding scheme
2. Test graph construction with varying node/edge configurations on small dataset
3. Train GNN with minimal parameters (3 conv steps, 16 hidden channels) on MNIST subset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform on other handwriting scripts and languages beyond the tested Gurmukhi and English datasets?
- Basis in paper: [explicit] The paper tests on MNIST (English digits), Unipen (online digits), and Gurkhali (online strokes), but does not explore other scripts or languages
- Why unresolved: The study is limited to a few datasets, and the generalizability to other scripts (e.g., Chinese, Arabic) or languages is not evaluated
- What evidence would resolve it: Testing the method on diverse handwriting datasets from different scripts and languages to compare performance with existing methods

### Open Question 2
- Question: What is the impact of varying the feature vector length on the recognition accuracy for different handwriting datasets?
- Basis in paper: [inferred] The paper uses fixed feature vector lengths (41 for MNIST, 25 for Gurkhali) but does not explore how varying these lengths affects performance
- Why unresolved: The optimal feature vector length for different datasets is not investigated, leaving uncertainty about the trade-off between computational efficiency and accuracy
- What evidence would resolve it: Conducting experiments with varying feature vector lengths on the same datasets to analyze the relationship between length and accuracy

### Open Question 3
- Question: How does the proposed method handle noise or distortions in handwritten trajectories, such as smudges or incomplete strokes?
- Basis in paper: [inferred] The paper does not address the robustness of the method to noisy or distorted input data, which is a common issue in real-world handwriting recognition
- Why unresolved: The method's performance under noisy conditions is not evaluated, which is critical for practical applications
- What evidence would resolve it: Testing the method on datasets with intentionally added noise or distortions to measure its robustness and compare it with other methods

### Open Question 4
- Question: What is the computational complexity of the proposed method compared to traditional classifiers like SVM or HMM for large-scale handwriting datasets?
- Basis in paper: [inferred] The paper mentions the use of batch loaders for efficiency but does not provide a detailed comparison of computational complexity with traditional methods
- Why unresolved: The scalability and efficiency of the method for large datasets are not quantified, leaving uncertainty about its practicality for real-world applications
- What evidence would resolve it: Benchmarking the method against SVM and HMM on large-scale datasets and analyzing time and memory requirements

## Limitations

- Specific chain code encoding rules and graph construction methodology not fully detailed
- Exact GNN operator implementation details and layer architecture beyond stated parameters unclear
- Performance generalizability to other handwriting scripts and languages unverified
- Method's robustness to noise and distortions in real-world handwriting untested

## Confidence

- Chain code + GNN combination effectiveness: Medium
- Reported error rates vs baselines: Medium
- Exact architectural specifications: Low

## Next Checks

1. Implement chain code generation from handwritten strokes using standard Huffman/Freeman encoding and verify graph construction matches paper's description
2. Reproduce GNN training with DeeperGCN architecture using stated parameters (3 convolution steps, 16 hidden channels, Adam optimizer lr=0.01) and compare error rates on MNIST
3. Test drawing order recovery algorithm on offline handwriting to validate stroke sequence extraction before chain code generation