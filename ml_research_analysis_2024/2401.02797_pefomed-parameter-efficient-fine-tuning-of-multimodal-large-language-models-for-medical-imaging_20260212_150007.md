---
ver: rpa2
title: 'PeFoMed: Parameter Efficient Fine-tuning of Multimodal Large Language Models
  for Medical Imaging'
arxiv_id: '2401.02797'
source_url: https://arxiv.org/abs/2401.02797
tags:
- medical
- evaluation
- gpt-4
- report
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PeFoMed, a parameter-efficient framework for
  fine-tuning multimodal large language models (MLLMs) for medical imaging tasks.
  The method uses pre-trained general-domain models and fine-tunes them with medical
  image-caption pairs and downstream datasets using low-rank adaptation (LoRA), freezing
  most parameters to minimize computational footprint.
---

# PeFoMed: Parameter Efficient Fine-tuning of Multimodal Large Language Models for Medical Imaging

## Quick Facts
- arXiv ID: 2401.02797
- Source URL: https://arxiv.org/abs/2401.02797
- Reference count: 40
- Primary result: PeFoMed achieves competitive performance on medical imaging tasks using only 56.63M trainable parameters versus 7B for full fine-tuning

## Executive Summary
PeFoMed introduces a parameter-efficient framework for fine-tuning multimodal large language models on medical imaging tasks. The method employs a two-stage fine-tuning approach using LoRA to adapt pre-trained general-domain models to medical image-caption pairs and downstream tasks like Med-VQA and medical report generation. The framework demonstrates significant performance improvements over GPT-4v while maintaining computational efficiency through frozen backbone weights and low-rank adaptation layers.

## Method Summary
PeFoMed utilizes pre-trained general-domain MLLMs (LLaMA2-chat and EVA) and fine-tunes them in two stages: first on image captioning datasets, then on medical-specific tasks (Med-VQA and MRG). The approach employs LoRA for parameter efficiency, freezing the vision encoder and LLM while only updating the vision projection layer and LoRA adapters. A 5-point Likert scale with weighted average score metric (WASM) is introduced for evaluating report quality, assessed by both human annotators and GPT-4. The framework achieves competitive results against specialized models while using far fewer trainable parameters.

## Key Results
- PeFoMed significantly outperforms GPT-4v on medical imaging tasks, demonstrating the need for task-specific fine-tuning in medical applications
- The two-stage fine-tuning approach shows effectiveness, with stage 2 contributing most improvements to VQA performance
- GPT-4-based semantic similarity assessments align closely with human evaluations and demonstrate greater stability than conventional lexical metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low-rank adaptation (LoRA) enables effective fine-tuning with minimal parameter updates while preserving general-domain knowledge.
- Mechanism: LoRA introduces low-rank matrices into transformer layers, replacing full weight updates with rank decomposition for efficient task adaptation.
- Core assumption: Low-rank decomposition sufficiently captures task-specific modifications needed for medical imaging tasks.
- Evidence anchors:
  - [abstract]: "We utilize the pre-trained weights of a general domain LLM and ViT, which have been adeptly trained on diverse datasets, and fine-tune them with medical image-caption pairs and downstream Med-VQA and medical reports datasets. In training, the vision encoder and LLM are frozen, and only the vision projection layer and the low-rank adaptation layer (LoRA) are updated"
  - [section]: "We adopt the low-rank adaptation (LoRA) technique in the LLM for efficient fine-tuning, where the other parts of the LLM are entirely frozen during the downstream fine-tuning"
  - [corpus]: Strong evidence - LoRA is a well-established technique with extensive validation in parameter-efficient fine-tuning literature
- Break condition: If medical imaging tasks require highly complex, non-low-rank transformations that cannot be captured by the decomposition.

### Mechanism 2
- Claim: Two-stage fine-tuning (caption → task-specific) provides better performance than direct task-specific fine-tuning.
- Mechanism: Stage 1 pre-training on image-caption pairs helps the model learn general medical image-text associations, creating a better foundation for specialized tasks in stage 2.
- Core assumption: Learning general medical image-text relationships first facilitates better adaptation to specific downstream tasks.
- Evidence anchors:
  - [section]: "We use the weights from MiniGPT-v2 that are pre-trained on datasets in general domains, and further fine-tune the models using multimodal medical datasets in two stages"
  - [section]: "We conducted an ablation study to explore the impacts of the two stage fine tuning strategy on the VQA performance" showing stage 2 contributes most improvements
  - [corpus]: Moderate evidence - Two-stage approaches are common in transfer learning, but specific validation for medical MLLMs is limited
- Break condition: If stage 1 fine-tuning introduces harmful biases or if medical tasks require direct adaptation without intermediate steps.

### Mechanism 3
- Claim: GPT-4-based semantic similarity evaluation provides more stable and consistent assessment than lexical metrics for generative medical tasks.
- Mechanism: GPT-4 evaluates semantic equivalence rather than exact string matching, capturing meaning even when wording differs.
- Core assumption: GPT-4's semantic understanding aligns well with human judgment for medical content evaluation.
- Evidence anchors:
  - [abstract]: "The results indicate that semantic similarity assessments using GPT-4 align closely with human annotators and provide greater stability, yet they reveal a discrepancy when compared to conventional lexical similarity measurements"
  - [section]: "we utilize the GPT-4 model to assess the semantic similarity of generated answers or reports and compare it with human evaluations to examine consistency"
  - [corpus]: Moderate evidence - GPT-4 evaluation shows consistency with human ratings, but concerns about reliability for medical-specific content remain
- Break condition: If GPT-4's evaluation criteria drift from human medical expertise or if the model develops systematic biases in medical assessment.

## Foundational Learning

- Concept: Parameter-efficient fine-tuning (PEFT)
  - Why needed here: Full fine-tuning of large MLLMs is computationally prohibitive; PEFT enables adaptation with minimal trainable parameters
  - Quick check question: How many parameters are actually trained in PeFoMed vs the full model size?

- Concept: Multimodal instruction tuning
  - Why needed here: Medical MLLMs need to process both image and text inputs coherently; instruction tuning helps align visual and language representations
  - Quick check question: What prompt template is used to combine image features and questions for the LLM?

- Concept: Semantic vs lexical similarity metrics
  - Why needed here: Medical report generation requires evaluation of meaning rather than exact word matching; conventional BLEU/Rouge fail for this
  - Quick check question: What metric does PeFoMed introduce to better capture report quality?

## Architecture Onboarding

- Component map:
  Vision encoder (frozen EVA ViT) → Linear projection layer → LLM with LoRA adapters → Text generation
  Input pipeline: Image → token grouping (4x reduction) → visual embeddings → projection → multimodal prompt

- Critical path:
  Image feature extraction → Projection to LLM space → Multimodal prompt construction → LLM generation → Output
  Training path: Stage 1 (captioning) → Stage 2 (Med-VQA/MRG) with frozen vision encoder and LLM

- Design tradeoffs:
  Frozen backbone vs. fine-tuning: Speed and parameter efficiency vs. potential loss of domain-specific feature learning
  Token grouping (4x) vs. full resolution: Significant memory savings vs. potential loss of fine-grained visual details
  GPT-4 evaluation vs. human evaluation: Scalability and consistency vs. potential domain expertise gaps

- Failure signatures:
  Poor Med-VQA performance on open-ended questions suggests semantic similarity evaluation limitations
  Inconsistent results between exact match and GPT-4 evaluation indicate evaluation metric reliability issues
  Stage 1 fine-tuning alone reducing performance suggests potential negative transfer from general captioning to specialized tasks

- First 3 experiments:
  1. Validate projection layer alignment: Feed known image embeddings through projection and check if LLM can reconstruct expected outputs
  2. Test LoRA rank sensitivity: Run with different LoRA ranks (32, 64, 128) to find optimal parameter-efficiency tradeoff
  3. Evaluate stage 1 impact: Compare performance with and without stage 1 fine-tuning on downstream Med-VQA tasks to confirm transfer learning benefits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the discrepancy between exact match evaluation and GPT-4 evaluation vary across different medical specialties and imaging modalities?
- Basis in paper: [explicit] The paper mentions that "Chest mediastinal" was the only organ type yielding consistent results across evaluation methods, while other organ types showed significant discrepancies. The paper also notes that "KG" type questions (requiring additional knowledge) exhibited the largest discrepancy post-evaluations.
- Why unresolved: The study only examined a limited set of medical imaging datasets and question types. The impact of different medical specialties and imaging modalities on evaluation discrepancies remains unexplored.
- What evidence would resolve it: Conducting experiments on a broader range of medical specialties (e.g., neurology, oncology, orthopedics) and imaging modalities (e.g., MRI, CT, ultrasound) would provide insights into how evaluation discrepancies vary across different medical domains.

### Open Question 2
- Question: What are the long-term effects of using GPT-4 as an evaluation metric for medical image report generation, particularly in terms of model bias and reliability?
- Basis in paper: [inferred] The paper suggests that GPT-4 evaluation is more stable than human evaluation, but it also notes that GPT-4 tends to assign higher similarity scores more frequently than human evaluators. This raises concerns about potential model bias.
- Why unresolved: The paper only conducted a short-term analysis of GPT-4 evaluation. Long-term effects, such as model bias accumulation and reliability degradation over time, are not addressed.
- What evidence would resolve it: Conducting longitudinal studies to monitor GPT-4 evaluation performance over extended periods and comparing it with human evaluation would help assess the long-term effects of using GPT-4 as an evaluation metric.

### Open Question 3
- Question: How does the proposed parameter-efficient fine-tuning approach compare to other parameter-efficient fine-tuning methods, such as adapter layers or prefix tuning, in terms of performance and computational efficiency?
- Basis in paper: [explicit] The paper uses LoRA for parameter-efficient fine-tuning, but it does not compare its performance with other parameter-efficient fine-tuning methods.
- Why unresolved: The study only evaluated the proposed LoRA-based approach without benchmarking it against other parameter-efficient fine-tuning methods.
- What evidence would resolve it: Conducting experiments to compare the proposed LoRA-based approach with other parameter-efficient fine-tuning methods, such as adapter layers or prefix tuning, in terms of performance and computational efficiency would provide insights into the relative merits of different approaches.

## Limitations
- Evaluation relies heavily on GPT-4-based semantic similarity metrics, which may not fully capture medical domain expertise
- Two-stage fine-tuning approach shows effectiveness, but the relative contribution of each stage remains unclear from ablation studies
- Performance on more complex medical imaging tasks beyond VQA and report generation has not been demonstrated

## Confidence

**High confidence**: The parameter-efficient fine-tuning methodology using LoRA is well-established and the experimental results showing significant performance improvements over GPT-4v are reproducible. The computational efficiency claims (56.63M trainable parameters vs 7B) are clearly specified and verifiable.

**Medium confidence**: The semantic similarity evaluation using GPT-4 shows consistency with human judgments, but the reliability for specialized medical content evaluation remains uncertain. The two-stage fine-tuning approach demonstrates effectiveness, but the optimal stage sequencing and duration for different medical domains needs further validation.

**Low confidence**: The WASM metric for report quality assessment, while innovative, lacks extensive validation across diverse medical report types. The generalization capability to other medical imaging modalities beyond X-ray and pathology images is not demonstrated.

## Next Checks
1. **Evaluation metric validation**: Conduct a comprehensive comparison between GPT-4-based semantic similarity scores and multiple human expert evaluations across different medical report types to establish reliability thresholds.

2. **Stage contribution analysis**: Systematically vary the duration and data distribution of stage 1 and stage 2 fine-tuning to quantify the marginal benefit of each stage and identify optimal training strategies for different medical tasks.

3. **Domain generalization test**: Evaluate PeFoMed's performance on CT scans and MRI images using the same fine-tuning procedure to assess cross-modality generalization capabilities and identify potential domain-specific adaptation requirements.