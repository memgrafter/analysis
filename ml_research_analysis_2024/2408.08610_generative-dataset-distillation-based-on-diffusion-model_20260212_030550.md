---
ver: rpa2
title: Generative Dataset Distillation Based on Diffusion Model
arxiv_id: '2408.08610'
source_url: https://arxiv.org/abs/2408.08610
tags:
- dataset
- distillation
- diffusion
- generative
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a generative dataset distillation method based
  on Stable Diffusion for the ECCV 2024 Dataset Distillation Challenge. The method
  uses SDXL-Turbo, a diffusion model that generates high-quality images with only
  1-4 sampling steps, enabling faster distillation compared to other diffusion models.
---

# Generative Dataset Distillation Based on Diffusion Model

## Quick Facts
- arXiv ID: 2408.08610
- Source URL: https://arxiv.org/abs/2408.08610
- Authors: Duo Su; Junjie Hou; Guang Li; Ren Togo; Rui Song; Takahiro Ogawa; Miki Haseyama
- Reference count: 40
- Primary result: Third place in ECCV 2024 Dataset Distillation Challenge generative track using SDXL-Turbo for high-speed image generation

## Executive Summary
This paper proposes a generative dataset distillation method using Stable Diffusion XL Turbo (SDXL-Turbo) for the ECCV 2024 Dataset Distillation Challenge. The method leverages SDXL-Turbo's adversarial diffusion distillation (ADD) strategy to generate high-quality images with only 1-4 sampling steps, enabling higher images per class (IPC) compared to traditional diffusion models. By using class labels as text prompts and applying post data augmentation, the method achieves IPC=10 for Tiny-ImageNet and IPC=20 for CIFAR-100, significantly improving classification accuracy. The approach secured third place in the generative track of the challenge.

## Method Summary
The method uses SDXL-Turbo, a diffusion model trained with adversarial diffusion distillation that enables high-speed image generation without sacrificing fidelity. Class labels are used as text prompts in the Text2Image pipeline to condition generation toward specific classes. After generating images with one-step sampling, post data augmentation (PDA) is applied to increase effective IPC without additional generation time. The pipeline generates distilled datasets with IPC=50 for Tiny-ImageNet and IPC=100 for CIFAR-100, which are then used to train a ConvNetD3-W128 classifier for 1000 epochs to evaluate performance.

## Key Results
- Achieved IPC=10 for Tiny-ImageNet and IPC=20 for CIFAR-100, significantly higher than typical diffusion models (IPC=1)
- Secured third place in the generative track of ECCV 2024 Dataset Distillation Challenge
- Improved classification accuracy on both Tiny-ImageNet and CIFAR-100 datasets compared to baseline methods
- Demonstrated that SDXL-Turbo's ADD training strategy enables high-quality image generation in single-step sampling

## Why This Works (Mechanism)

### Mechanism 1: SDXL-Turbo's ADD Training Strategy
SDXL-Turbo uses adversarial diffusion distillation with two objectives: adversarial loss aligning generated images with original data manifolds, and distillation loss minimizing L2 distance between teacher and student outputs. This preserves compositionality while enabling single-step sampling, allowing higher IPC than traditional diffusion models that require multiple iterative steps.

### Mechanism 2: Class Label Text Prompt Conditioning
During SDXL-Turbo training, a projector extracts conditional information from class labels. The trained model can then leverage these text labels as prompts to guide image generation toward specific classes, improving distilled dataset quality by ensuring class-specific image generation.

### Mechanism 3: Post Data Augmentation (PDA)
After generating images with SDXL-Turbo, applying transformations like random cropping, flipping, and brightness/contrast adjustments creates image variants that increase diversity and information richness. This effectively increases IPC without additional generation time or computational complexity.

## Foundational Learning

- Concept: Diffusion models and denoising process
  - Why needed here: Understanding how diffusion models work is essential to grasp why SDXL-Turbo can generate images in few steps while maintaining quality
  - Quick check question: What is the fundamental difference between diffusion models and GANs in terms of training stability and sample quality?

- Concept: Dataset distillation and IPC concept
  - Why needed here: The paper's contribution hinges on achieving higher IPC values (10 for Tiny-ImageNet, 20 for CIFAR-100) compared to typical diffusion models (IPC=1)
  - Quick check question: How does increasing IPC in dataset distillation affect model training time and generalization performance?

- Concept: Text-to-image conditioning in diffusion models
  - Why needed here: The method uses class labels as text prompts, so understanding how text conditioning works in diffusion models is crucial
  - Quick check question: How do text embeddings influence the image generation process in conditional diffusion models?

## Architecture Onboarding

- Component map: SDXL-Turbo diffusion model (pretrained checkpoint) → Text2Image pipeline with class labels as prompts → One-step sampling → Post data augmentation → Distilled dataset
- Critical path: Image generation (SDXL-Turbo sampling) → Data augmentation → Dataset assembly for training
- Design tradeoffs: Speed vs. quality (one-step sampling sacrifices some fidelity but enables higher IPC), augmentation diversity vs. classifier robustness
- Failure signatures: Poor class separation in generated images, classifier confusion between classes, time constraints preventing sufficient generation
- First 3 experiments:
  1. Generate 10 images per class for Tiny-ImageNet using SDXL-Turbo with class labels as prompts, evaluate basic quality visually
  2. Apply PDA to generated images and measure IPC increase without retraining classifier
  3. Train ConvNet classifier on distilled dataset and compare accuracy against baseline diffusion model with IPC=1

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the distribution discrepancy between generative models and target datasets (like CIFAR-100) be effectively addressed to improve distillation performance?
- Basis in paper: The paper explicitly discusses the distribution discrepancy issue, particularly noting that CIFAR-100 shows unsatisfactory performance due to a substantial gap in resolution and data distribution compared to generated models.
- Why unresolved: The paper mentions that common methods like fine-tuning or modifying text prompts have not effectively addressed this issue, indicating that current approaches are insufficient.
- What evidence would resolve it: Experimental results demonstrating improved accuracy on CIFAR-100 using novel techniques to bridge the distribution gap, such as adaptive model architectures or advanced prompt engineering.

### Open Question 2
- Question: What is the optimal balance between IPC (images per class) and data augmentation techniques to maximize accuracy without increasing computational complexity?
- Basis in paper: The paper shows that increasing IPC through post data augmentation improves accuracy, but does not explore the trade-offs or optimal combinations of different augmentation techniques.
- Why unresolved: While the paper demonstrates that PDA increases IPC and accuracy, it doesn't investigate the saturation point or diminishing returns of these techniques.
- What evidence would resolve it: Systematic experiments varying IPC and augmentation combinations to identify the point of maximum accuracy improvement per unit of computational cost.

### Open Question 3
- Question: How does the choice of text prompts and their specificity affect the quality and diversity of generated images in dataset distillation?
- Basis in paper: The paper mentions using class information as text prompts to guide image generation, but does not explore the impact of different prompt structures or specificity levels.
- Why unresolved: The paper uses a straightforward approach of using class labels as prompts but does not investigate how more detailed or varied prompts might affect the distilled dataset quality.
- What evidence would resolve it: Comparative experiments using different prompt structures (e.g., simple labels vs. detailed descriptions) to measure their impact on image quality, diversity, and downstream task performance.

## Limitations

- IPC Scaling Limits: Discrepancy between claimed IPC values (10/20) and implementation details (50/100) suggests uncertainty about optimal scaling and potential diminishing returns
- Class Label Conditioning Quality: Method relies on SDXL-Turbo's ability to generate class-specific images, but doesn't validate whether generated images truly represent their intended classes
- Augmentation Integration Strategy: Paper doesn't specify how augmented images are incorporated into the final dataset (replacement vs. supplementation), which could significantly impact results

## Confidence

**High Confidence Claims**:
- SDXL-Turbo can generate images in 1-4 steps due to ADD training strategy
- Class labels can be used as text prompts in conditional diffusion models
- Post data augmentation can increase effective IPC without additional generation time

**Medium Confidence Claims**:
- The specific IPC values (10 for Tiny-ImageNet, 20 for CIFAR-100) are optimal for this method
- The ConvNet classifier performance is directly comparable to other methods using different architectures
- The third-place ranking in the challenge is solely attributable to the proposed method

## Next Checks

1. **Class Representation Validation**: Generate a subset of images for each class and conduct human evaluation to verify that generated images accurately represent their intended classes. Compare class-wise accuracy distributions to identify any systematic failures in class conditioning.

2. **IPC Scalability Analysis**: Systematically vary IPC from 1 to 50 for both datasets and measure the relationship between IPC, classification accuracy, and generation time. This would identify optimal IPC values and potential diminishing returns.

3. **Baseline Comparison with Controlled Variables**: Implement a direct comparison between SDXL-Turbo with class conditioning versus a standard diffusion model (like Stable Diffusion 1.5) with the same IPC and augmentation strategy. This would isolate the contribution of SDXL-Turbo's ADD strategy versus other factors.