---
ver: rpa2
title: 'Mind the Gap: A Causal Perspective on Bias Amplification in Prediction & Decision-Making'
arxiv_id: '2405.15446'
source_url: https://arxiv.org/abs/2405.15446
tags:
- causal
- prediction
- fairness
- margin
- outcome
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies bias amplification when continuous prediction
  scores are thresholded into binary decisions. It introduces the concept of margin
  complement, which measures the change in score due to thresholding, and shows that
  disparity in optimal 0/1 predictors can be decomposed into disparities inherited
  from the true outcome and disparities arising from the optimization procedure itself.
---

# Mind the Gap: A Causal Perspective on Bias Amplification in Prediction & Decision-Making

## Quick Facts
- **arXiv ID**: 2405.15446
- **Source URL**: https://arxiv.org/abs/2405.15446
- **Reference count**: 40
- **Primary result**: Thresholding continuous prediction scores into binary decisions can amplify existing biases beyond what is present in the original prediction score

## Executive Summary
This paper investigates bias amplification when continuous prediction scores are thresholded into binary decisions. The authors introduce the concept of margin complement, which measures the change in score due to thresholding, and show that disparity in optimal 0/1 predictors can be decomposed into disparities inherited from the true outcome and disparities arising from the optimization procedure itself. Under suitable causal assumptions, the causal decomposition of the L2-optimal prediction score is equivalent to the causal decomposition of the true outcome. The paper introduces new notions of weak and strong business necessity to regulate bias amplification and provides an algorithm for assessing these notions. Experiments on MIMIC-IV, COMPAS, and Census datasets demonstrate that thresholding often amplifies existing biases, highlighting the need for regulatory oversight.

## Method Summary
The paper proposes a causal decomposition framework for analyzing bias amplification in binary decision-making systems. The method involves computing x-specific direct, indirect, and spurious effects for the prediction score S and margin complement M using causal inference techniques. These effects are then used to decompose disparities in the optimal 0/1 predictor. The authors introduce weak and strong business necessity concepts to distinguish between acceptable and unacceptable sources of bias, and provide Algorithm 1 for assessing compliance with these notions. The approach is validated through experiments on three real-world datasets, demonstrating how thresholding operations can amplify existing biases.

## Key Results
- The disparity in optimal 0/1 predictors can be decomposed into contributions from the true outcome and the margin complement due to thresholding
- Under suitable causal assumptions, the causal decomposition of the optimal prediction score S is equivalent to the causal decomposition of the true outcome Y
- Experiments on MIMIC-IV, COMPAS, and Census datasets show that thresholding often amplifies existing biases, with margin complements contributing significantly to bias amplification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Thresholding a continuous prediction score into a binary decision can amplify existing biases beyond what is present in the original prediction score.
- Mechanism: The margin complement measures the change in score due to thresholding. When the prediction score is close to the threshold, even small disparities in the score can be amplified into large disparities in the binary decision. The paper decomposes the disparity in the binary predictor into contributions from the original prediction score and contributions from the margin complement, showing that the margin complement can significantly increase bias.
- Core assumption: The disparity in the optimal L2 prediction score is equivalent to the disparity in the true outcome under suitable causal assumptions.
- Evidence anchors:
  - [abstract] "This yields a new decomposition of the disparity in the predictor bY that allows us to disentangle causal differences inherited from the true outcome Y that exists in the real world vs. those coming from the optimization procedure itself."
  - [section] "We prove that under suitable assumptions, the causal decomposition of the optimal prediction score S is equivalent with the causal decomposition of the true outcome Y (Thm. 2)."
  - [corpus] Weak evidence. Related papers discuss bias amplification but not specifically through thresholding mechanisms.
- Break condition: If the prediction score is far from the threshold for most individuals, the margin complement effect becomes negligible and bias amplification is minimal.

### Mechanism 2
- Claim: The paper introduces new notions of weak and strong business necessity to regulate bias amplification from thresholding operations.
- Mechanism: Weak business necessity allows disparities inherited from the true outcome to be propagated into predictions but disallows disparities arising from the optimization procedure (rounding). Strong business necessity allows both types of disparities. These notions provide a framework for regulatory oversight by distinguishing between acceptable and unacceptable sources of bias in binary decision-making systems.
- Core assumption: Causal effects can be decomposed into direct, indirect, and spurious pathways, and each pathway can be independently assessed for business necessity compliance.
- Evidence anchors:
  - [abstract] "Motivated by the above decompositions, we introduce a new concept of weak and strong business necessity (Def. 3), highlighting a new need for regulatory instructions in the context of automated systems."
  - [section] "According to the definition, there are three versions of BN considerations: (1) A causal pathway is not in the BN set, and is considered discriminatory. In this case, both the contribution of the prediction score S and the margin complement M need to be equal to 0 (i.e., no discrimination is allowed along the pathway); (2) A pathway satisfies weak BN, and is not considered discriminatory. In this case, the effect of X on the prediction score S needs to equal the effect of X onto the true outcome Y along the same pathway [29]."
  - [corpus] Weak evidence. Related papers discuss fairness notions but not specifically business necessity frameworks for thresholding operations.
- Break condition: If the causal pathways cannot be accurately identified or measured, the business necessity framework cannot be reliably applied.

### Mechanism 3
- Claim: The paper provides an algorithm for assessing weak and strong business necessity compliance in automated systems.
- Mechanism: Algorithm 1 computes causal effects along different pathways for the prediction score, margin complement, and binary predictor. It then checks whether these effects satisfy the constraints specified by weak or strong business necessity. The algorithm enables systematic auditing of fairness compliance by comparing the decompositions of the true outcome and the predictor, and by examining the contributions of margin complements along different causal pathways.
- Core assumption: The causal effects can be reliably identified and estimated from observational data using the standard fairness model assumptions.
- Evidence anchors:
  - [abstract] "we introduce new notions of weak and strong business necessity, together with an algorithm for assessing whether these notions are satisfied."
  - [section] "In Alg. 1, we propose a formal approach for evaluating considerations of weak and strong BN for any input of a predictor bY and a prediction score S."
  - [corpus] Weak evidence. Related papers discuss algorithmic fairness assessment but not specifically algorithms for business necessity compliance.
- Break condition: If the identification assumptions are violated or the estimation procedure is inaccurate, the algorithm may produce incorrect assessments of business necessity compliance.

## Foundational Learning

- Concept: Causal inference and structural causal models
  - Why needed here: The paper relies on causal decomposition of disparities into direct, indirect, and spurious effects, which requires understanding of causal inference concepts and the standard fairness model.
  - Quick check question: What is the difference between statistical associations and causal effects, and why is this distinction important for fairness analysis?

- Concept: Optimal prediction and loss functions
  - Why needed here: The paper discusses L2-optimal prediction scores and 0/1-optimal predictors, which requires understanding of different loss functions and their implications for decision-making.
  - Quick check question: How does the choice of loss function (L2 vs 0/1) affect the optimal prediction and the resulting bias amplification?

- Concept: Business necessity and disparate impact doctrine
  - Why needed here: The paper introduces business necessity concepts to regulate bias amplification, which requires understanding of legal frameworks for discrimination and their application to automated systems.
  - Quick check question: How do business necessity considerations in law relate to the weak and strong business necessity notions introduced in the paper?

## Architecture Onboarding

- Component map:
  - Input: Prediction score S and binary predictor bY from automated system
  - Core: Causal decomposition algorithm (Theorem 1 and Corollary 3)
  - Assessment: Business necessity compliance checker (Algorithm 1)
  - Output: Decomposition of disparities and compliance assessment

- Critical path:
  1. Obtain prediction score S and binary predictor bY
  2. Compute causal effects along direct, indirect, and spurious pathways
  3. Decompose disparities into contributions from S and margin complement M
  4. Check compliance with weak or strong business necessity
  5. Generate assessment report

- Design tradeoffs:
  - Precision vs interpretability: More detailed causal decompositions provide better insights but may be harder to interpret
  - Assumption strength vs applicability: Stronger identification assumptions enable more precise estimates but limit applicability to real-world scenarios
  - Regulatory stringency vs practical feasibility: Stricter business necessity requirements may be harder to satisfy in practice

- Failure signatures:
  - High variance in causal effect estimates indicating identification problems
  - Large margin complement contributions suggesting significant bias amplification
  - Violations of business necessity requirements indicating non-compliance

- First 3 experiments:
  1. Implement causal decomposition on synthetic data with known ground truth to verify correctness
  2. Apply decomposition to real-world dataset (e.g., MIMIC-IV) to assess practical utility
  3. Test business necessity compliance checker on datasets with different levels of bias amplification

## Open Questions the Paper Calls Out
- Open Question 1: How does the margin complement behave in settings with non-monotonic utility functions?
  - Basis in paper: [inferred] The paper focuses on monotonic utility settings but does not explore non-monotonic cases
  - Why unresolved: The paper explicitly states their approach is suitable for monotonic utility but does not investigate how the margin complement and decomposition behave with non-monotonic utilities
  - What evidence would resolve it: Empirical studies comparing margin complement behavior in monotonic vs non-monotonic utility settings

- Open Question 2: What is the optimal threshold selection strategy to minimize bias amplification while maintaining utility?
  - Basis in paper: [explicit] The paper uses a fixed threshold of 0.5 in examples but does not discuss threshold selection strategies
  - Why unresolved: The paper demonstrates bias amplification with a standard 0.5 threshold but does not provide guidance on choosing alternative thresholds
  - What evidence would resolve it: Empirical comparison of different threshold selection methods and their impact on bias amplification

- Open Question 3: How do partial identification techniques perform when the Standard Fairness Model assumptions are violated?
  - Basis in paper: [explicit] The paper notes that partial identification techniques could relax SFM assumptions but does not explore this
  - Why unresolved: The paper relies heavily on SFM assumptions but acknowledges they may be limiting and suggests partial identification as a remedy without investigating it
  - What evidence would resolve it: Empirical evaluation of bias amplification analysis under relaxed assumptions using partial identification methods

## Limitations
- The framework relies on the standard fairness model assumptions, which may not capture all relevant confounding structures in complex real-world scenarios
- The practical application of business necessity concepts has not been validated against real-world regulatory requirements
- The identification assumptions for causal effects from observational data may be violated in practice, leading to unreliable estimates

## Confidence
- High confidence in the theoretical foundation of causal decomposition mechanism
- Medium confidence in the practical application of business necessity concepts
- Medium confidence in the generalizability of results across different domains and threshold values

## Next Checks
1. Implement the framework on additional real-world datasets (e.g., criminal justice, hiring) to assess generalizability across domains with different bias patterns
2. Conduct sensitivity analysis on the identification assumptions to understand how violations affect the decomposition results and business necessity assessments
3. Design and run user studies with domain experts to evaluate whether the weak/strong business necessity concepts align with practical regulatory needs and implementation constraints