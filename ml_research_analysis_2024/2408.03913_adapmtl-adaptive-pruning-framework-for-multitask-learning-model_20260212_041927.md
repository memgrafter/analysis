---
ver: rpa2
title: 'AdapMTL: Adaptive Pruning Framework for Multitask Learning Model'
arxiv_id: '2408.03913'
source_url: https://arxiv.org/abs/2408.03913
tags:
- pruning
- sparsity
- task
- learning
- adapmtl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents AdapMTL, an adaptive pruning framework for
  multitask learning models that dynamically allocates sparsity across shared backbones
  and task-specific heads based on their sensitivity to pruning. The method uses learnable
  soft thresholds independently assigned to each component, co-optimized with model
  weights to automatically determine suitable sparsity levels during training.
---

# AdapMTL: Adaptive Pruning Framework for Multitask Learning Model

## Quick Facts
- arXiv ID: 2408.03913
- Source URL: https://arxiv.org/abs/2408.03913
- Reference count: 40
- Adaptive pruning framework that dynamically allocates sparsity across MTL components with 90%+ overall sparsity while maintaining high task accuracy

## Executive Summary
This paper presents AdapMTL, an adaptive pruning framework for multitask learning models that dynamically allocates sparsity across shared backbones and task-specific heads based on their sensitivity to pruning. The method uses learnable soft thresholds independently assigned to each component, co-optimized with model weights to automatically determine suitable sparsity levels during training. An adaptive weighting mechanism further adjusts task-specific loss importance based on each task's robustness to pruning. Experiments on NYU-v2 and Tiny-Taskonomy datasets with ResNet34 and MobileNetV2 architectures show AdapMTL achieves superior performance compared to state-of-the-art pruning methods, maintaining high task accuracy while reaching overall sparsity levels of 90%+. The framework does not require pre-training and demonstrates consistent superiority across different architectures and task numbers.

## Method Summary
AdapMTL implements component-wise learnable soft thresholds for shared backbone and task-specific heads, co-optimized with model weights during training. The framework uses an adaptive weighting mechanism that adjusts task-specific loss importance based on each task's robustness to pruning, determined by training loss stability within a sliding window. The approach enables differentiable pruning through soft thresholding instead of hard thresholding, allowing gradients to flow during backpropagation. The method trains from scratch without pre-training or pre-pruned models, dynamically determining optimal sparsity allocation for each component based on its sensitivity.

## Key Results
- Achieves 90%+ overall sparsity while maintaining superior task performance compared to state-of-the-art pruning methods
- Component-wise soft thresholds automatically learn optimal sparsity allocation between shared backbone and task-specific heads
- Adaptive weighting mechanism successfully balances task performance by adjusting loss importance based on pruning robustness
- Consistent superiority demonstrated across different architectures (ResNet34, MobileNetV2) and task numbers (3-5 tasks)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Different components in multitask models have varying sensitivity to pruning, requiring component-wise soft thresholds.
- **Mechanism:** The framework assigns learnable soft thresholds independently to shared backbone and task-specific heads. During training, these thresholds are co-optimized with model weights to automatically determine suitable sparsity levels for each component.
- **Core assumption:** The sensitivity to pruning differs between the shared backbone and task-specific heads, and this sensitivity can be captured through learnable soft thresholds.
- **Evidence anchors:**
  - [abstract] "AdapMTL leverages multiple learnable soft thresholds independently assigned to the shared backbone and the task-specific heads to capture the nuances in different components' sensitivity to pruning."
  - [section] "We observe that these different model components have different sensitivities to pruning and thus should be treated differently."
  - [corpus] Weak - no direct citations found, but the concept of component-wise pruning is supported by general pruning literature.
- **Break condition:** If all components had uniform sensitivity to pruning, the component-wise threshold approach would offer no advantage over uniform pruning.

### Mechanism 2
- **Claim:** Adaptive weighting based on training loss stability guides sparsity allocation across tasks.
- **Mechanism:** The framework calculates the average deviation of loss within a sliding window for each task. Tasks with more stable loss receive higher weighting factors, allowing more aggressive pruning on those components.
- **Core assumption:** Loss stability during training correlates with a component's robustness to pruning, and this relationship can be used to guide sparsity allocation.
- **Evidence anchors:**
  - [abstract] "It further incorporates an adaptive weighting mechanism that dynamically adjusts the importance of task-specific losses based on each task's robustness to pruning."
  - [section] "if the training loss of a specific task tends to be stable, then we can assign a higher weighting factor and subsequently prune more aggressively on that component"
  - [corpus] Weak - no direct citations, but the concept of using loss stability for pruning decisions aligns with general pruning principles.
- **Break condition:** If loss stability did not correlate with pruning robustness, the adaptive weighting mechanism would fail to guide effective sparsity allocation.

### Mechanism 3
- **Claim:** Soft thresholding enables differentiable pruning during training, avoiding the discontinuity issues of hard thresholding.
- **Mechanism:** The framework uses soft thresholding (ReLU(|W| - α)) instead of hard thresholding. This creates a smooth relationship between weights and thresholds, allowing gradients to flow during backpropagation.
- **Core assumption:** Soft thresholding provides sufficient gradient information for learning while still achieving effective sparsity.
- **Evidence anchors:**
  - [section] "The reason why we choose soft thresholding [55] rather than hard thresholding is illustrated in Figure 2. Soft parameter sharing is the best fit for our approach as it allows us to calculate the gradient and perform the backpropagation process more effectively."
  - [section] "Although ∂S(Wt^n,αt^n)/∂Wt^n is non-differentiable, we can approximate the gradients using the sub-gradient method."
  - [corpus] Weak - no direct citations, but the use of soft thresholding for differentiable pruning is a known technique in sparse training literature.
- **Break condition:** If soft thresholding failed to produce adequate gradients or if the approximation error was too large, the framework would not learn effective pruning masks.

## Foundational Learning

- **Concept:** Multitask learning (MTL) fundamentals and hard parameter sharing
  - Why needed here: The framework operates on MTL models with shared backbones and task-specific heads, requiring understanding of how information flows through such architectures.
  - Quick check question: In a typical MTL model, which components are shared across tasks and which are task-specific?

- **Concept:** Pruning techniques and their impact on model performance
  - Why needed here: The framework's effectiveness depends on understanding how different pruning strategies affect task performance and how to balance sparsity with accuracy.
  - Quick check question: What is the primary trade-off when applying pruning to deep neural networks?

- **Concept:** Gradient-based optimization and backpropagation mechanics
  - Why needed here: The framework relies on co-optimizing soft thresholds with model weights using gradient descent, requiring understanding of how gradients flow through non-differentiable operations.
  - Quick check question: How do sub-gradient methods handle non-differentiable points in optimization?

## Architecture Onboarding

- **Component map:**
  Input -> Shared Backbone (with soft threshold α_B) -> Task-specific Heads (each with soft threshold α_t) -> Task outputs
  Loss functions for each task are weighted by adaptive factors β_t
  Thresholds α_t are derived from learnable parameters θ_init through sigmoid function
  Sliding window mechanism tracks loss stability for adaptive weighting

- **Critical path:**
  1. Forward pass: Apply soft thresholds to weights to create sparse versions
  2. Compute task-specific losses with adaptive weighting
  3. Backward pass: Update both weights and soft thresholds using gradients
  4. Update adaptive weighting factors based on loss stability
  5. Repeat until convergence or desired sparsity reached

- **Design tradeoffs:**
  - Soft vs. hard thresholding: Soft provides differentiability but may be less precise in enforcing sparsity
  - Sliding window size: Larger windows provide more stable loss estimates but require more memory
  - Initial threshold values: Affect early training dynamics and convergence speed

- **Failure signatures:**
  - All components becoming equally sparse or dense (thresholds not learning meaningful differences)
  - One task dominating the loss (adaptive weighting not balancing tasks properly)
  - Slow convergence or divergence (learning rates or window size inappropriate)
  - Final sparsity not matching target (soft thresholds not enforcing desired sparsity levels)

- **First 3 experiments:**
  1. Test with synthetic MTL data where component sensitivities are known, verify that AdapMTL learns appropriate sparsity patterns
  2. Compare AdapMTL with uniform pruning on a simple MTL benchmark, measure task performance vs. sparsity trade-offs
  3. Analyze sensitivity of results to sliding window size by running with different window sizes on the same dataset

## Open Questions the Paper Calls Out

None

## Limitations

- Evaluation limited to vision MTL tasks on NYU-v2 and Tiny-Taskonomy datasets
- Framework requires careful hyperparameter tuning for different architectures
- Adaptive weighting mechanism's assumption about loss stability correlation needs validation across diverse task combinations
- Sensitivity to hyperparameter choices (sliding window size, initial threshold values, scaling factors) not thoroughly explored

## Confidence

**High Confidence**: The core mechanism of component-wise soft thresholding for differentiable pruning is well-supported by the experimental results and aligns with established sparse training principles. The superiority of AdapMTL over baseline methods across multiple datasets and architectures is consistently demonstrated.

**Medium Confidence**: The adaptive weighting mechanism's effectiveness is supported by experiments, but the assumption that loss stability directly indicates pruning robustness needs further validation across diverse task combinations and domains.

**Low Confidence**: The framework's generalizability to non-vision MTL problems and its sensitivity to hyperparameter choices are not thoroughly validated, making real-world deployment outcomes uncertain.

## Next Checks

1. **Cross-domain validation**: Apply AdapMTL to NLP or speech MTL tasks to verify if the component-wise sensitivity approach generalizes beyond vision tasks.

2. **Hyperparameter sensitivity analysis**: Systematically vary the sliding window size, initial threshold values, and scaling factors across multiple runs to quantify their impact on final performance and robustness.

3. **Ablation study**: Compare AdapMTL performance with and without the adaptive weighting mechanism across different task combinations to isolate its contribution to overall effectiveness.