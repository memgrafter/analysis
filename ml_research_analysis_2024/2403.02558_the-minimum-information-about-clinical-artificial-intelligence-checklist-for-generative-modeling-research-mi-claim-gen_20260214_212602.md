---
ver: rpa2
title: The Minimum Information about CLinical Artificial Intelligence Checklist for
  Generative Modeling Research (MI-CLAIM-GEN)
arxiv_id: '2403.02558'
source_url: https://arxiv.org/abs/2403.02558
tags:
- etal
- arxiv
- page
- preprintathttps
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper updates the MI-CLAIM checklist to address the unique
  challenges of generative AI models in clinical research, including LLMs, VLMs, and
  diffusion models. The authors identify key differences in training, evaluation,
  interpretability, and reproducibility compared to traditional AI models, and introduce
  new checklist items for assessing bias, privacy, and potential harm.
---

# The Minimum Information about CLinical Artificial Intelligence Checklist for Generative Modeling Research (MI-CLAIM-GEN)

## Quick Facts
- arXiv ID: 2403.02558
- Source URL: https://arxiv.org/abs/2403.02558
- Reference count: 0
- Authors: Brenda Y. Miao, Irene Y. Chen, Christopher YK Williams, JaysÃ³n Davidson, Augusto Garcia-Agundez, Shenghuan Sun, Travis Zack, Suchi Saria, Rima Arnaout, Giorgio Quer, Hossein J. Sadaei, Ali Torkamani, Brett Beaulieu-Jones, Bin Yu, Milena Gianfrancesco, Atul J. Butte, Beau Norgeot, Madhumita Sushil
- Primary result: Updated MI-CLAIM checklist addressing unique challenges of generative AI models in clinical research, including new items for cohort selection, evaluation, interpretability, reproducibility, and ethical considerations.

## Executive Summary
This paper presents MI-CLAIM-GEN, an updated version of the Minimum Information about CLinical Artificial Intelligence Checklist specifically designed for generative modeling research in clinical settings. The authors identify key differences between generative AI models (LLMs, VLMs, diffusion models) and traditional predictive models, including unique challenges in training, evaluation, interpretability, and reproducibility. The updated checklist introduces new items that address these differences while also emphasizing the importance of bias, privacy, and harm assessments in clinical generative AI applications.

## Method Summary
The MI-CLAIM-GEN checklist was developed through expert consensus to address the unique challenges of generative AI models in clinical research. The methodology involves identifying key differences between generative and traditional AI models, establishing new checklist items for cohort selection with unstructured clinical data, few-shot learning, baseline selection, and automated and human evaluation. The checklist emphasizes the need for both overlap accuracy metrics (BLEU/ROUGE) and semantic accuracy measures, while also requiring detailed reporting of bias, privacy concerns, and potential for harm. The checklist is made available on GitHub for community feedback and ongoing refinement as the field evolves.

## Key Results
- Introduces new checklist items specific to generative AI models for cohort selection with unstructured clinical data and few-shot learning
- Provides comprehensive guidelines for evaluating both automated and human assessments of generative model outputs
- Emphasizes the importance of bias, privacy, and harm assessments with specific reporting requirements
- Promotes end-to-end reproducibility through detailed documentation requirements
- Makes the checklist available on GitHub for community feedback and iterative improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The checklist addresses key differences between generative and traditional AI models in clinical research.
- Mechanism: By updating MI-CLAIM to include new items for cohort selection with unstructured clinical data, few-shot learning, and end-to-end reproducibility, the checklist provides guidelines specific to generative models' unique characteristics.
- Core assumption: Generative models require different evaluation and reporting standards than traditional predictive models due to their ability to produce open-ended outputs and work with minimal training data.
- Evidence anchors:
  - [abstract]: "The updated MI-CLAIM checklist introduces new items that encourage discussion, identification, and mitigation of study biases, privacy concerns, and potential for harm."
  - [section]: "Part 1A. Study design for generative modeling... Generative modeling has opened up new types of tasks that have previously been limited by the capabilities of older models, and require careful consideration of appropriate datasets, labels, evaluation, and interpretation of results."
- Break Condition: If generative models converge to traditional model behavior in terms of output structure and training requirements, the specialized checklist items would become redundant.

### Mechanism 2
- Claim: The checklist provides specific guidance for evaluating generative models' outputs and performance.
- Mechanism: By distinguishing between overlap accuracy, semantic accuracy, and clinical utility metrics, and providing recommendations for both automated and human evaluation methods, the checklist ensures comprehensive assessment of generative model performance.
- Core assumption: Generative models produce complex, unstructured outputs that require different evaluation approaches than traditional classification or regression tasks.
- Evidence anchors:
  - [abstract]: "The new checklist, MI-CLAIM-GEN (Table 1), aims to address differences in training, evaluation, interpretability, and reproducibility of new generative models compared to non-generative ('predictive') AI models."
  - [section]: "Part 4. Model evaluation... Evaluation metrics for generative models should distinguish between metrics that measure overlap accuracy, which measures proportions of overlapping subunits (e.g., tokens, pixels), semantic accuracy, which compare the meanings of outputs and labels, and clinical utility, which measure how models affect clinical workflows or downstream patient outcomes."
- Break Condition: If standardized evaluation metrics emerge that can adequately assess both generative and traditional model outputs, the specialized evaluation guidance would become less critical.

### Mechanism 3
- Claim: The checklist promotes responsible development and deployment of generative AI in clinical settings.
- Mechanism: By including items on bias, privacy, and harm assessments, and encouraging external validation across diverse patient subgroups, the checklist ensures that generative models are developed with ethical considerations in mind.
- Core assumption: Generative models have unique risks related to bias perpetuation, privacy vulnerabilities, and potential for harm that require specific attention in clinical research.
- Evidence anchors:
  - [abstract]: "The updated MI-CLAIM-GEN checklist introduces new items that encourage discussion, identification, and mitigation of study biases, privacy concerns, and potential for harm."
  - [section]: "Part 1C. Bias, privacy, and harm assessments... Model trained on biased data can perpetuate clinical biases in generated content. All available details regarding data distribution of training and evaluation datasets should be reported, including patient sociodemographic information, any data imbalance, the time period when the data was collected, and any changes to best practice medical guidelines during this time period."
- Break Condition: If generative models demonstrate significantly reduced bias and privacy risks compared to traditional models, or if new mitigation techniques emerge that make these assessments less critical, the specialized ethical guidance would become less necessary.

## Foundational Learning

- Concept: Generative AI models (LLMs, VLMs, diffusion models)
  - Why needed here: The checklist is specifically designed for generative AI models, which have unique characteristics and requirements compared to traditional AI models.
  - Quick check question: What are the key differences between generative AI models and traditional predictive models in terms of output structure and training requirements?

- Concept: Clinical research methodology and best practices
  - Why needed here: The checklist aims to ensure that generative AI models used in clinical research are developed and evaluated according to established best practices for transparency, reproducibility, and ethical considerations.
  - Quick check question: What are the key elements of a well-designed clinical study, and how do they apply to the development and evaluation of generative AI models?

- Concept: Evaluation metrics for natural language and image processing tasks
  - Why needed here: Generative AI models often produce unstructured outputs (text, images) that require specialized evaluation metrics to assess their accuracy, relevance, and clinical utility.
  - Quick check question: What are the differences between overlap accuracy, semantic accuracy, and clinical utility metrics, and when should each be used to evaluate generative AI model outputs?

## Architecture Onboarding

- Component map: Study design and cohort selection -> Model development and training -> Evaluation and validation -> Interpretability and error analysis -> End-to-end reproducibility -> Bias, privacy, and harm assessments
- Critical path: The most critical components are study design, evaluation, and reproducibility, as these ensure that the generative AI model is developed and assessed according to established best practices and can be reliably deployed in clinical settings.
- Design tradeoffs: Balancing the need for comprehensive evaluation and ethical considerations with the practical constraints of clinical research, such as limited data availability and computational resources.
- Failure signatures: Incomplete or ambiguous reporting of study design, evaluation methods, or ethical considerations; failure to address potential biases or privacy risks; inability to reproduce results or deploy the model in real-world clinical settings.
- First 3 experiments:
  1. Apply the MI-CLAIM-GEN checklist to an existing generative AI clinical study and assess its completeness and effectiveness in addressing the unique challenges of generative models.
  2. Compare the evaluation results of a generative AI model using both traditional and specialized metrics (e.g., overlap accuracy vs. semantic accuracy) to demonstrate the importance of using appropriate evaluation methods.
  3. Conduct a bias and privacy risk assessment of a generative AI model trained on clinical data, and propose mitigation strategies based on the findings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective methods for evaluating bias, privacy, and potential harm in generative AI models for clinical applications?
- Basis in paper: explicit
- Why unresolved: The paper acknowledges these as significant concerns but only briefly discusses potential approaches, pointing readers to more comprehensive guidelines. The field is rapidly evolving and requires further research to establish standardized evaluation frameworks.
- What evidence would resolve it: Empirical studies comparing different bias, privacy, and harm assessment methodologies in clinical generative AI applications, along with validated evaluation frameworks specifically designed for these concerns.

### Open Question 2
- Question: How can we ensure reproducibility when using proprietary generative models where training data and model architectures are not publicly available?
- Basis in paper: inferred
- Why unresolved: The paper discusses reproducibility best practices but doesn't address the unique challenges posed by proprietary models, which are increasingly common in clinical applications but lack transparency in their training and architecture.
- What evidence would resolve it: Case studies and methodological papers demonstrating successful reproducible research using proprietary generative models, including standardized reporting requirements for model cards and evaluation protocols.

### Open Question 3
- Question: What are the optimal prompt engineering strategies for clinical generative AI tasks, and how can we standardize their evaluation?
- Basis in paper: explicit
- Why unresolved: While the paper emphasizes the importance of prompt engineering and independent prompt validation datasets, it acknowledges that this is a rapidly evolving field and defers to model developers' guidelines, leaving a gap in standardized clinical AI research protocols.
- What evidence would resolve it: Systematic studies comparing different prompt engineering approaches across various clinical tasks, along with validated metrics for prompt effectiveness and standardized reporting guidelines for prompt strategies.

## Limitations

- The checklist's effectiveness depends heavily on community adoption and consistent interpretation of its guidelines
- The rapidly evolving nature of generative AI technology may require frequent updates to maintain relevance
- The paper does not provide concrete examples of checklist application to specific clinical studies, making practical utility assessment difficult

## Confidence

- **High Confidence**: The identification of key differences between generative and traditional AI models in clinical research (training requirements, output evaluation, interpretability challenges)
- **Medium Confidence**: The proposed checklist items for bias, privacy, and harm assessments, as these are based on general best practices rather than generative AI-specific evidence
- **Medium Confidence**: The recommendations for evaluation metrics and human review protocols, as these may require adaptation based on specific clinical tasks and model capabilities

## Next Checks

1. Conduct a pilot study applying the MI-CLAIM-GEN checklist to 5-10 existing generative AI clinical studies and measure inter-rater reliability among different reviewers
2. Test the checklist's effectiveness by having teams develop generative AI models with and without checklist guidance, then compare the resulting models' bias, privacy safeguards, and reproducibility
3. Establish a community feedback mechanism to track which checklist items are most frequently violated or misinterpreted in real-world applications