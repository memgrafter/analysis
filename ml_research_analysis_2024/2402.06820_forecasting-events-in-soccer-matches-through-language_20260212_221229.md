---
ver: rpa2
title: Forecasting Events in Soccer Matches Through Language
arxiv_id: '2402.06820'
source_url: https://arxiv.org/abs/2402.06820
tags:
- event
- lems
- soccer
- data
- events
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a novel approach to predicting soccer match
  events using a language model-inspired framework called Large Event Models (LEMs).
  The method tokenizes soccer event data and uses a single deep learning model to
  sequentially predict event variables, simplifying the architecture compared to previous
  LEMs that relied on multiple models.
---

# Forecasting Events in Soccer Matches Through Language

## Quick Facts
- arXiv ID: 2402.06820
- Source URL: https://arxiv.org/abs/2402.06820
- Reference count: 23
- Primary result: 62.2% accuracy for event type prediction vs 57.5% for previous models

## Executive Summary
This paper introduces Large Event Models (LEMs), a language model-inspired framework for predicting soccer match events. The approach tokenizes soccer event data and uses a single deep learning model to sequentially predict all event variables, representing a significant architectural simplification over previous methods that relied on multiple models. The method achieves substantial improvements in both event type prediction (62.2% vs 57.5%) and spatial coordinate accuracy (24-28% error reduction), while enabling long-term probability forecasting and action valuation through the VAEP framework. The research demonstrates that LEMs can serve as a foundational framework for multifaceted soccer analytics through a singular machine-learning model.

## Method Summary
The method tokenizes soccer event data from the Wyscout V2 API dataset (2017/18 season of top five European leagues) and uses a single deep learning model to sequentially predict event variables. The architecture employs a multi-layer perceptron with 2-3 hidden layers of 256-512 neurons, trained using BCELoss and Adam optimizer with cosine annealing learning rate schedule. The model is trained on three leagues (France, Germany, Italy) and tested on two held-out leagues (England, Spain). Event data is encoded using ordinal encoding of features including event type, location, time, and scores. The sequential prediction approach allows each prediction to inform subsequent predictions, capturing the dynamic nature of soccer matches.

## Key Results
- 62.2% accuracy for event type prediction, significantly outperforming previous models (57.5%)
- 24-28% error reduction in spatial coordinate prediction (x, y locations)
- Single-model architecture simplifies the prediction pipeline while maintaining or improving accuracy
- Enables long-term probability forecasting and action valuation through VAEP framework

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tokenizing soccer event data enables a single model to learn the "language" of soccer events effectively.
- Mechanism: By treating soccer events as tokens in a sequence, the model can predict the next event in the same way LLMs predict the next word, capturing the sequential nature of soccer matches.
- Core assumption: Soccer events can be abstracted as a sequence where each event depends on the previous ones, similar to words in a sentence.
- Evidence anchors:
  - [abstract] "Unlike other methods that severely limit event dynamics in soccer, often abstracting from many variables or relying on a mix of sequential models, our research proposes a novel technique inspired by the methodologies used in LLMs."
  - [section] "LEMs use a set (S) of previous events (e) to forecast the next event, as formalized in Equations 1 and 2. This set of events has size k, defining how many previous events are used to forecast the next event."

### Mechanism 2
- Claim: Using a single model to forecast all event variables simplifies the architecture and improves prediction accuracy.
- Mechanism: Instead of using multiple models for different event aspects, a single model predicts all variables sequentially, with each prediction informing the next.
- Core assumption: The full context of previous predictions can be used to improve the accuracy of subsequent predictions.
- Evidence anchors:
  - [abstract] "Unlike other methods that severely limit event dynamics in soccer, often abstracting from many variables or relying on a mix of sequential models, our research proposes a novel technique inspired by the methodologies used in LLMs."
  - [section] "Instead of relying on sequential inferences from multiple models, we draw inspiration from the core methodologies of language models. By tokenizing soccer event data, we enable a single model to learn the 'language' of soccer events effectively."

### Mechanism 3
- Claim: The model's ability to generate entire sequences of game events enables comprehensive simulation and analysis.
- Mechanism: By predicting not just the next event but a chain of future events, the model can simulate full matches, providing insights into likely game developments.
- Core assumption: The sequential prediction of events can capture the dynamics of a soccer match well enough for meaningful simulation.
- Evidence anchors:
  - [abstract] "This methodology allows for a dynamic and contextually rich analysis of sports games, capturing events' fluid and unpredictable nature as they unfold during a match."
  - [section] "By conceptualizing a soccer match as a series of events — each akin to a 'word' in a sentence — LEMs utilize deep learning techniques to predict the next event in the sequence based on the context provided by previous events."

## Foundational Learning

- Concept: Sequential modeling of events
  - Why needed here: Soccer matches are inherently sequential, with each event depending on previous ones. The model must capture these dependencies to make accurate predictions.
  - Quick check question: Can you explain why predicting the next event in a soccer match is similar to predicting the next word in a sentence?

- Concept: Tokenization and encoding of event data
  - Why needed here: Converting event data into tokens and numerical encodings allows the model to process the data effectively, similar to how LLMs handle text.
  - Quick check question: How would you tokenize a soccer event like "a pass from (x=50, y=30) to (x=60, y=40)"?

- Concept: Deep learning architectures (e.g., multi-layer perceptrons)
  - Why needed here: The model needs to learn complex patterns in the event data, which requires a powerful architecture capable of handling high-dimensional inputs and outputs.
  - Quick check question: What are the advantages and disadvantages of using a multi-layer perceptron versus a transformer for this task?

## Architecture Onboarding

- Component map: Input vector -> LEM model (MLP) -> Sampler with restrictions -> Output token
- Critical path:
  1. Preprocess event data into tokens and numerical encodings
  2. Train the LEM model on the encoded data
  3. Use the trained model to predict sequences of events
  4. Analyze the predicted sequences for insights or simulations

- Design tradeoffs:
  - Using a single model vs. multiple models: A single model simplifies the architecture but may be harder to train effectively
  - Sequential prediction vs. parallel prediction: Sequential prediction allows each prediction to inform the next, but it may be slower
  - Tokenization granularity: More granular tokenization may capture more detail but increase the model's complexity

- Failure signatures:
  - The model predicts unrealistic events (e.g., impossible locations or sequences)
  - The model's predictions diverge significantly from actual game events
  - The model overfits to the training data and performs poorly on new matches

- First 3 experiments:
  1. Train the model on a small subset of the data and evaluate its ability to predict the next event type
  2. Increase the size of the input context (k) and measure its impact on prediction accuracy
  3. Compare the model's performance with a baseline that predicts the most common event type

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the inclusion of off-the-ball data and player/team identification features impact the accuracy and applicability of LEMs in soccer analytics?
- Basis in paper: [inferred] The paper mentions that event data contains limitations such as the absence of off-the-ball data and biases in manual annotation. It also notes that team and player identification data were excluded due to the substantial increase in model size.
- Why unresolved: The paper explicitly states that these features were not included due to data limitations and computational constraints, but does not explore their potential impact on model performance.
- What evidence would resolve it: Conducting experiments with datasets that include off-the-ball data and player/team identification, comparing the performance of LEMs with and without these features, and analyzing the changes in prediction accuracy and model applicability.

### Open Question 2
- Question: Can advanced deep learning architectures like RNNs and Transformers significantly improve the performance of LEMs compared to the current multi-layer perceptron approach?
- Basis in paper: [explicit] The paper mentions that the available event data was insufficient to explore advanced architectures like RNNs and Transformers, which have shown success in other domains.
- Why unresolved: The authors chose a multi-layer perceptron architecture due to data size constraints and did not experiment with more advanced models.
- What evidence would resolve it: Training LEMs using RNNs and Transformers on larger datasets, comparing their performance with the current model, and analyzing the improvements in prediction accuracy and model efficiency.

### Open Question 3
- Question: How can LEMs be adapted to capture the impact of contextual factors such as red cards, injuries, and weather conditions on soccer match outcomes?
- Basis in paper: [inferred] The paper discusses the limitations of LEMs in capturing sudden changes in match dynamics, such as the shift in probabilities due to a red card in the 63rd minute, which is absent from the context given to LEMs.
- Why unresolved: The current LEM framework does not account for external contextual factors that can significantly influence match outcomes.
- What evidence would resolve it: Incorporating additional contextual features into the LEM framework, such as player injuries, weather conditions, and disciplinary actions, and evaluating the changes in prediction accuracy and model robustness.

## Limitations
- Model performance on spatial coordinates (x, y) shows room for improvement despite claimed error reduction
- Wyscout V2 dataset may contain inherent biases from manual tagging affecting generalizability
- Sequential prediction approach may struggle with rare or complex event combinations outside learned patterns
- Computational requirements for real-time applications remain unclear

## Confidence
- High Confidence: Core methodology of tokenizing soccer events and sequential prediction is well-established through language model analogy and supported by clear mathematical formalization
- Medium Confidence: Claimed improvements in spatial prediction accuracy (24-28% error reduction) and effectiveness of single-model approach versus multi-model alternatives
- Low Confidence: Practical applicability for real-time tactical decision-making and player valuation through VAEP framework

## Next Checks
1. **Cross-league generalizability test**: Train the model on a combination of all five leagues and evaluate performance on a held-out season from each league to assess whether the model can generalize beyond the specific training/testing split used in the paper.

2. **Ablation study on architectural components**: Systematically remove or modify key components (sequential prediction, tokenization granularity, number of hidden layers) to quantify their individual contributions to performance improvements, helping isolate which innovations drive the claimed gains.

3. **Real-time performance benchmark**: Measure inference time and memory requirements for predicting sequences of varying lengths (10, 50, 100 events) to establish practical constraints for deployment in live match analysis scenarios.