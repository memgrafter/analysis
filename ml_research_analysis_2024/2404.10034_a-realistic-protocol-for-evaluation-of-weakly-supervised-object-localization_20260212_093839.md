---
ver: rpa2
title: A Realistic Protocol for Evaluation of Weakly Supervised Object Localization
arxiv_id: '2404.10034'
source_url: https://arxiv.org/abs/2404.10034
tags:
- bboxes
- selection
- wsol
- validation
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of evaluating weakly supervised
  object localization (WSOL) methods in a realistic manner. The current evaluation
  protocol relies on manual bounding box annotations for model selection and threshold
  estimation, which is not aligned with the WSOL setting where such annotations are
  typically unavailable in real-world scenarios.
---

# A Realistic Protocol for Evaluation of Weakly Supervised Object Localization

## Quick Facts
- arXiv ID: 2404.10034
- Source URL: https://arxiv.org/abs/2404.10034
- Reference count: 40
- Primary result: Proposes a new evaluation protocol for WSOL using noisy pseudo-bounding boxes from region proposals, avoiding unrealistic reliance on ground truth annotations for model selection and threshold estimation.

## Executive Summary
This paper addresses the unrealistic evaluation of weakly supervised object localization (WSOL) methods that rely on manual bounding box annotations for model selection and threshold estimation. The authors propose a new protocol that generates noisy pseudo-bounding boxes from off-the-shelf region proposal methods like Selective Search, CLIP, and RPN for model selection, and uses these pseudo-bboxes to estimate the localization threshold. This approach eliminates the need for test-set annotations and provides a more realistic evaluation of WSOL methods in scenarios where manual annotations are unavailable. Extensive experiments show that using pseudo-bboxes for validation facilitates model selection and threshold estimation with localization performance comparable to methods selected using ground truth bboxes and test-set thresholds.

## Method Summary
The proposed protocol generates pseudo-bounding boxes using off-the-shelf region proposal methods (Selective Search, RPN, CLIP) and a pointing game analysis to select discriminative boxes based on CAM activation peaks. These pseudo-bboxes are used for model selection on the validation set and for threshold estimation. WSOL models are trained with multiple hyperparameter configurations, and the best model is selected based on pseudo-bbox LOC accuracy. The threshold is estimated from validation pseudo-bboxes and applied to test-set localization maps to produce final bounding boxes. This approach avoids the unrealistic use of ground truth annotations for model selection and threshold tuning, providing a more realistic evaluation of WSOL methods.

## Key Results
- Pseudo-bboxes generated by region proposal methods can effectively substitute for ground truth bounding boxes in model selection for WSOL.
- Using pseudo-bboxes from the validation set to estimate the localization threshold avoids overestimation caused by using test-set ground truth.
- Model selection based on pseudo-bbox LOC accuracy rather than classification accuracy reduces bias and improves realism.

## Why This Works (Mechanism)

### Mechanism 1
Pseudo-bboxes generated by off-the-shelf region proposal models can effectively substitute for ground truth bounding boxes in model selection for WSOL. The protocol leverages pretrained region proposal methods (Selective Search, RPN, CLIP) to generate candidate object regions. A pointing game analysis then selects the most discriminative box based on CAM activation peaks, producing pseudo-bboxes that, despite noise, align with model performance trends. Core assumption: Pseudo-bboxes need not be perfectly accurate—only sufficiently aligned with the true object to guide model selection.

### Mechanism 2
Using pseudo-bboxes from the validation set to estimate the localization threshold avoids the overestimation caused by using test-set ground truth. Instead of tuning thresholds on test-set annotations (unrealistic), the protocol estimates the threshold from pseudo-bboxes on the validation set and applies it to test-set localization maps. Core assumption: The distribution of pseudo-bboxes on validation data approximates that of true boxes, making the estimated threshold transferable.

### Mechanism 3
Model selection based on pseudo-bbox LOC accuracy rather than classification accuracy reduces bias and improves realism. The protocol selects models by evaluating LOC performance using pseudo-bboxes on the validation set, rather than relying on classification accuracy, which may not correlate well with localization quality. Core assumption: LOC accuracy and classification accuracy diverge during training, making LOC-based selection more appropriate for WSOL evaluation.

## Foundational Learning

- **Concept**: Weakly Supervised Object Localization (WSOL)
  - Why needed here: WSOL is the core setting where only image-class labels are available, but both classification and localization are required. Understanding its constraints is essential for appreciating why pseudo-bboxes are necessary.
  - Quick check question: In WSOL, what type of supervision is available during training, and what task is evaluated at test time?

- **Concept**: Region Proposal Networks (RPN) and Selective Search
  - Why needed here: These are the off-the-shelf methods used to generate pseudo-bboxes. Understanding their outputs and limitations is key to evaluating the protocol.
  - Quick check question: How do RPN and Selective Search differ in the type of supervision they require and the nature of the boxes they produce?

- **Concept**: Pointing Game Analysis
  - Why needed here: This technique is used to select the most discriminative pseudo-bbox from multiple proposals by leveraging CAM activation peaks.
  - Quick check question: What is the role of the pointing game in filtering region proposals, and why is it suitable for WSOL?

## Architecture Onboarding

- **Component map**: Images with class labels -> Region Proposal Generator (SS, RPN, CLIP) -> Pointing Game Module -> WSOL Model -> Evaluation using pseudo-bboxes for model selection and threshold estimation

- **Critical path**:
  1. Generate pseudo-bboxes on validation set using region proposals + pointing game
  2. Train multiple WSOL models with shared hyperparameters
  3. Select best model based on pseudo-bbox LOC accuracy on validation set
  4. Estimate threshold from validation pseudo-bboxes
  5. Apply threshold to test-set localization maps to produce final bboxes

- **Design tradeoffs**:
  - Using noisy pseudo-bboxes vs. perfect ground truth: Accepts lower accuracy for realism
  - Choice of region proposal method: CLIP needs class labels, RPN needs bbox supervision, SS is unsupervised
  - Threshold estimation from validation vs. test: Avoids overestimation but may reduce precision

- **Failure signatures**:
  - Pseudo-bboxes poorly aligned with true objects → model selection fails
  - Threshold estimated from validation poorly transfers to test → low IoU
  - Classification accuracy correlates strongly with LOC → pseudo-bbox selection unnecessary

- **First 3 experiments**:
  1. Generate pseudo-bboxes on CUB validation set using RPN + pointing game; evaluate IoU vs. ground truth
  2. Train CAM model with multiple hyperparameter configs; select using pseudo-bbox LOC accuracy; compare test IoU
  3. Estimate threshold from pseudo-bboxes; apply to test set; compare MaxBoxAcc vs. ground truth thresholded evaluation

## Open Questions the Paper Calls Out

### Open Question 1
How do different levels of supervision in region proposal methods (unsupervised, image-class labels, class-agnostic bboxes) impact the quality of generated pseudo-bboxes and subsequent WSOL performance? The paper explores three scenarios of pretrained models with varying supervision levels but lacks a comprehensive analysis of how supervision levels affect WSOL performance.

### Open Question 2
Can the proposed pseudo-bbox generation method be extended to other WSOL tasks beyond classification and localization, such as object detection or instance segmentation? The paper focuses on WSOL for classification and localization, but the concept of generating pseudo-supervision could potentially be applied to other tasks.

### Open Question 3
How sensitive is the proposed evaluation protocol to the choice of region proposal method and its associated hyperparameters? The paper mentions using off-the-shelf region proposal methods but does not thoroughly investigate the impact of method choice or hyperparameter tuning on pseudo-bbox quality and WSOL performance.

## Limitations
- The protocol's effectiveness is validated only on ILSVRC and CUB datasets; performance on other datasets with different object scales and diversity remains unknown.
- The quality of pseudo-bboxes heavily depends on the region proposal method; if proposals are consistently poor or biased, the entire protocol's validity is compromised.
- The assumption that pseudo-bbox-based thresholds transfer well from validation to test sets is not rigorously validated across diverse conditions.

## Confidence
- **High Confidence**: The core claim that using pseudo-bboxes for model selection is more realistic than using ground truth annotations is well-supported by experimental results showing similar LOC performance trends.
- **Medium Confidence**: The effectiveness of threshold estimation from pseudo-bboxes is demonstrated but could benefit from more extensive cross-dataset validation.
- **Low Confidence**: The generalizability of the protocol to datasets beyond ILSVRC and CUB, especially those with significantly different object characteristics, is not established.

## Next Checks
1. Apply the protocol to a third dataset (e.g., COCO or OpenImages) and compare MaxBoxAcc performance with ground truth-based evaluation.
2. Systematically evaluate the impact of different region proposal methods (SS, RPN, CLIP) on pseudo-bbox quality and downstream WSOL performance.
3. Conduct experiments varying the validation-test domain shift (e.g., using different subsets or synthetic transformations) to assess threshold transferability limits.