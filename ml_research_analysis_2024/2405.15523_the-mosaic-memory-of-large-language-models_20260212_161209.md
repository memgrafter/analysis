---
ver: rpa2
title: The Mosaic Memory of Large Language Models
arxiv_id: '2405.15523'
source_url: https://arxiv.org/abs/2405.15523
tags:
- fuzzy
- duplicates
- tokens
- exact
- memorization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "LLMs memorize training data not just through exact repetitions\
  \ but also by assembling information from similar sequences, a phenomenon termed\
  \ \"mosaic memory.\" This study introduces a framework to quantify how fuzzy duplicates\u2014\
  sequences with partial token overlap\u2014contribute to memorization, finding they\
  \ can be as impactful as 0.8 of an exact duplicate. Major models like GPT-Neo, Gemma-2,\
  \ Phi-2, and Llama-3.2 exhibit this behavior, with even heavily modified sequences\
  \ (50% token replacement) retaining up to 0.19 of an exact duplicate\u2019s memorization\
  \ impact."
---

# The Mosaic Memory of Large Language Models

## Quick Facts
- arXiv ID: 2405.15523
- Source URL: https://arxiv.org/abs/2405.15523
- Authors: Igor Shilov; Matthieu Meeus; Yves-Alexandre de Montjoye
- Reference count: 40
- Primary result: LLMs memorize training data through "mosaic memory" - assembling information from similar sequences rather than exact repetitions, with fuzzy duplicates contributing up to 0.8 of an exact duplicate's memorization impact

## Executive Summary
This study reveals that Large Language Models memorize training data not just through exact repetitions but by assembling information from similar sequences, a phenomenon termed "mosaic memory." The research introduces a framework to quantify how fuzzy duplicates - sequences with partial token overlap - contribute to memorization, finding they can be as impactful as 0.8 of an exact duplicate. Major models like GPT-Neo, Gemma-2, Phi-2, and Llama-3.2 exhibit this behavior, with even heavily modified sequences retaining up to 0.19 of an exact duplicate's memorization impact. Surprisingly, memorization is predominantly syntactic rather than semantic, driven by overlapping tokens rather than shared meaning.

## Method Summary
The study employs a controlled experimental approach involving synthetic canary generation using Llama-2 7B, fuzzy duplicate creation through various algorithms (token replacements, insertions, shuffling, paraphrasing), and membership inference attacks (MIAs) to measure memorization. The researchers fine-tune four major LLMs on books from Project Gutenberg with injected canaries and fuzzy duplicates for one epoch, then apply different MIA methodologies to quantify the memorization contribution of fuzzy duplicates. They calculate an "exact duplicate equivalent" (ρ) metric by comparing fuzzy duplicate performance to exact duplicate performance, and validate findings using real-world datasets like SlimPajama.

## Key Results
- Fuzzy duplicates contribute to memorization as much as 0.8 of an exact duplicate
- Even heavily modified sequences (50% token replacement) retain up to 0.19 of an exact duplicate's memorization impact
- Memorization is predominantly syntactic rather than semantic
- Standard deduplication techniques fail to eliminate fuzzy duplicates, with thousands of such duplicates remaining per sequence in SlimPajama

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs memorize training data by assembling information from similar sequences through token overlap
- Mechanism: The model learns to associate and retain overlapping tokens across sequences that are not exact duplicates. Even when sequences differ by up to 50% of tokens, shared vocabulary and syntactic patterns enable the model to reconstruct and memorize original content
- Core assumption: Memorization is primarily syntactic rather than semantic; the model focuses on retaining specific overlapping tokens rather than understanding shared meaning
- Evidence anchors: Abstract states "LLMs memorize by assembling information from similar sequences, a phenomena we call mosaic memory"; section shows "memorization to be predominantly syntactic rather than semantic"

### Mechanism 2
- Claim: Fuzzy duplicates contribute to memorization as much as 0.8 of an exact duplicate
- Mechanism: The model's attention mechanism allows it to focus on meaningful patterns across fuzzy duplicates, effectively filtering out inserted noise tokens as irrelevant while retaining the core memorized content
- Core assumption: The model's attention mechanism can effectively filter out noise and focus on overlapping token patterns, enabling robust memorization despite sequence modifications
- Evidence anchors: Abstract notes "fuzzy duplicates contributing to memorization as much as 0.8 of an exact duplicate"; section shows fuzzy duplicates with 10% token replacement contribute between ρ = 0.50 and ρ = 0.60 of an exact duplicate's impact

### Mechanism 3
- Claim: Standard deduplication techniques fail to eliminate fuzzy duplicates, undermining benchmark fairness
- Mechanism: Deduplication methods targeting exact duplicates neglect mosaic memory, allowing memorization of confidential or copyright-protected content through slightly modified sequences that remain in the training data
- Core assumption: Current deduplication practices are insufficient to address the mosaic nature of memorization, as they do not account for the model's ability to memorize across fuzzy duplicates
- Evidence anchors: Abstract states "Common industry-standard techniques like removing exact matches from benchmarks fail to eliminate fuzzy duplicates"; section notes "Deduplication strategies that target exact duplicates neglect mosaic memory"

## Foundational Learning

- Concept: Levenshtein distance
  - Why needed here: To quantify the similarity between sequences and identify fuzzy duplicates in real-world datasets by measuring the minimum number of single-character edits required to transform one sequence into another
  - Quick check question: How does Levenshtein distance relate to the exact duplicate equivalent (ρ) in the context of fuzzy duplicates?

- Concept: Token overlap and n-gram analysis
  - Why needed here: To understand how the model memorizes across fuzzy duplicates by analyzing shared vocabulary and syntactic patterns, computing overlap in n-grams between sequences to assess their similarity
  - Quick check question: What is the relationship between n-gram overlap and the exact duplicate equivalent (ρ) for paraphrased sequences?

- Concept: Membership inference attacks (MIAs)
  - Why needed here: To quantify memorization by measuring the model's ability to distinguish between sequences included in and excluded from the training data, computing membership scores based on query outputs
  - Quick check question: How do different MIA methodologies (e.g., Loss attack, Ratio attack, Min-K% Prob) compare in measuring the memorization of fuzzy duplicates?

## Architecture Onboarding

- Component map: Reference canary generation -> Fuzzy duplicate generation -> Model training with injected canaries -> Membership inference attack application -> Data analysis (Levenshtein distance, n-gram overlap, ρ values) -> Deduplication impact assessment

- Critical path: Generate reference canaries → Create fuzzy duplicates → Train model with injected canaries → Apply MIAs to measure memorization → Analyze results (ρ values, Levenshtein distances) → Deduplication impact assessment

- Design tradeoffs: Balancing granularity of deduplication (exact n-gram matching vs. Levenshtein distance) against computational cost and data retention; choosing right MIA methodology to accurately measure memorization across different experimental setups

- Failure signatures: Low ρ values despite high token overlap suggest semantic rather than syntactic memorization; inconsistent MIA AUC across different learning rates or model sizes may indicate issues with experimental setup or model capacity

- First 3 experiments:
  1. Generate reference canaries using Llama-2 7B with varying temperatures (T=1.0, 2.5, 5.0) and assess their impact on mosaic memory
  2. Create fuzzy duplicates using Areplace with different token replacement strategies and measure ρ values
  3. Apply sequence-level deduplication (n=50) to SlimPajama and analyze remaining fuzzy duplicates using Levenshtein distance

## Open Questions the Paper Calls Out

- Question: Does semantic deduplication provide more effective training efficiency gains than syntactic deduplication for LLMs?
  - Basis in paper: The paper notes that current LLMs memorize more strongly based on syntactic rather than semantic similarity, suggesting more aggressive syntactic deduplication might be even more effective than semantic approaches for improving training efficiency
  - Why unresolved: The paper only hypothesizes about the potential effectiveness of syntactic deduplication compared to semantic deduplication without conducting experiments to test this hypothesis
  - What evidence would resolve it: Experimental comparison of model performance and training efficiency when using semantic deduplication versus syntactic deduplication on the same datasets

- Question: How does the mosaic memory phenomenon impact the effectiveness of benchmark decontamination techniques?
  - Basis in paper: The paper shows that current benchmark decontamination techniques based on n-gram matching fail to eliminate fuzzy duplicates that contribute substantially to memorization (ρ ≥ 0.2)
  - Why unresolved: While the paper identifies the problem with current decontamination methods, it does not propose or test alternative decontamination approaches that account for mosaic memory
  - What evidence would resolve it: Experimental results showing the difference in model performance on benchmarks when using traditional n-gram decontamination versus decontamination methods that account for Levenshtein distance or other fuzzy duplicate metrics

- Question: Can instruction-tuned LLMs be leveraged to create canaries that are resistant to training data deduplication while still being meaningfully memorized by LLMs?
  - Basis in paper: The paper suggests that LLMs' mosaic memory could be leveraged to design canaries resistant to training data deduplication practices while still being meaningfully memorized
  - Why unresolved: The paper proposes this as a possibility but does not demonstrate or test such canaries in practice
  - What evidence would resolve it: Successful creation and testing of canaries that survive standard deduplication techniques but still trigger high MIA scores when models are trained on data containing them

## Limitations

- The study focuses primarily on relatively small models (up to 7B parameters), leaving uncertainty about whether larger frontier models exhibit similar mosaic memory patterns
- Synthetic canary generation, while providing controlled conditions, may not fully capture the complexity of real-world memorization patterns
- The analysis of real-world datasets like SlimPajama relies on assumptions about the effectiveness of their fuzzy duplicate detection methodology

## Confidence

**High Confidence Claims:**
- LLMs exhibit mosaic memory behavior through token overlap patterns
- Fuzzy duplicates contribute substantially to memorization (0.8 of exact duplicates)
- Standard deduplication techniques fail to address mosaic memory

**Medium Confidence Claims:**
- Memorization is predominantly syntactic rather than semantic
- The exact duplicate equivalent (ρ) metric accurately captures memorization impact
- Real-world datasets contain thousands of fuzzy duplicates per sequence

**Low Confidence Claims:**
- The generalizability of findings to larger models and more complex memorization tasks
- The completeness of fuzzy duplicate detection in real-world datasets
- The long-term implications for model training and privacy protection

## Next Checks

1. **Semantic Complexity Validation**: Test mosaic memory effects using semantically complex content (e.g., technical documentation, code with meaningful variable names) rather than synthetic canaries to verify whether syntactic memorization remains dominant.

2. **Model Scale Impact Assessment**: Replicate key experiments using larger models (e.g., 70B+ parameters) to determine whether mosaic memory patterns scale with model size or change qualitatively in larger architectures.

3. **Advanced Deduplication Evaluation**: Implement and test more sophisticated deduplication approaches that explicitly target fuzzy duplicates using Levenshtein or Hamming distances to assess whether they can effectively mitigate mosaic memory effects.