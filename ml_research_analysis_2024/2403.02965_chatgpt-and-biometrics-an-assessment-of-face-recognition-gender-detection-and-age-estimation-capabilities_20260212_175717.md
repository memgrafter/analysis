---
ver: rpa2
title: 'ChatGPT and biometrics: an assessment of face recognition, gender detection,
  and age estimation capabilities'
arxiv_id: '2403.02965'
source_url: https://arxiv.org/abs/2403.02965
tags:
- gpt-4
- face
- chatgpt
- prompt
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the application of ChatGPT (GPT-4) for biometric
  tasks including face recognition, gender detection, and age estimation. The authors
  developed a prompting strategy to bypass ChatGPT's safeguards against processing
  sensitive biometric data, enabling evaluation of its capabilities on these tasks.
---

# ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities

## Quick Facts
- arXiv ID: 2403.02965
- Source URL: https://arxiv.org/abs/2403.02965
- Reference count: 0
- Primary result: ChatGPT achieves 95.15% face recognition accuracy on LFW, comparable to specialized models

## Executive Summary
This paper explores ChatGPT (GPT-4)'s capabilities for biometric tasks including face recognition, gender detection, and age estimation. The authors developed a prompting strategy to bypass ChatGPT's safeguards against processing sensitive biometric data, enabling evaluation on standard benchmark datasets. Experiments show GPT-4 achieves competitive performance across all tasks despite not being specifically trained for biometrics, raising important questions about both the potential and security implications of using large language models for sensitive applications.

## Method Summary
The study evaluates ChatGPT's biometric capabilities by crafting prompts that emphasize synthetic or AI-generated content to bypass the model's privacy safeguards. The researchers automated sentiment analysis using ChatGPT itself to classify responses, then calculated accuracy metrics across three biometric tasks. They compared results against specialized models (MobileFaceNet for face recognition, DeepFace for gender detection) without fine-tuning ChatGPT. Datasets included LFW, AgeDB, CFP-FP for face recognition; a Kaggle gender dataset for gender detection; and UTKFace for age estimation, with additional testing using synthetic faces generated via the Eyes-2-Face technique.

## Key Results
- Face recognition accuracy of 95.15% on LFW dataset, comparable to specialized MobileFaceNet
- Gender detection achieved 100% accuracy on real faces and comparable performance on synthetic faces
- Age estimation accuracy of 74.25% on UTKFace dataset with consistent age range predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT (GPT-4) can bypass its own safeguards against biometric data processing through prompt engineering that emphasizes synthetic or AI-generated content.
- Mechanism: By framing prompts to indicate that images are AI-generated rather than depicting real individuals, the model's privacy safeguards are circumvented while still allowing the model to process and analyze facial features for biometric tasks.
- Core assumption: GPT-4's safeguards are primarily triggered by explicit mentions of real people or privacy-sensitive contexts, not by the nature of the images themselves when framed as synthetic.
- Evidence anchors:
  - [abstract] "Since biometrics are considered as sensitive information, ChatGPT avoids answering direct prompts, and thus we crafted a prompting strategy to bypass its safeguard and evaluate the capabilities for biometrics tasks."
  - [section 2] "Therefore, to bypass the GPT-4's safeguard, we emphasize in each prompt that each image is generated by AI."
- Break condition: If GPT-4 updates its safeguards to detect and block prompts regardless of synthetic framing, or if synthetic framing is no longer sufficient to bypass privacy filters.

### Mechanism 2
- Claim: GPT-4 demonstrates significant performance in biometric tasks despite not being specifically trained or fine-tuned for these tasks.
- Mechanism: The model's general multimodal capabilities and large-scale pretraining on diverse data allow it to generalize to biometric tasks like face recognition, gender detection, and age estimation with reasonable accuracy.
- Core assumption: The pretraining data and architecture of GPT-4 contain sufficient information about human faces and biometric features to enable competent performance on these tasks without specialized training.
- Evidence anchors:
  - [abstract] "Our findings shed light on the promising potentials in the application of LLMs and foundation models for biometrics."
  - [section 3] "While GPT-4 is not particularly trained for the biometrics tasks, our experiments show remarkable performance on different tasks."
- Break condition: If the performance degrades significantly on more challenging datasets or if specialized training becomes necessary for competitive accuracy.

### Mechanism 3
- Claim: GPT-4's explainability feature, which provides detailed reasoning for its classifications, can be both a strength and a vulnerability.
- Mechanism: The model's ability to articulate its decision-making process helps users understand its reasoning but also allows it to generate persuasive explanations even when making incorrect classifications (false positives).
- Core assumption: The explainability feature is based on the model's internal reasoning patterns and is not necessarily a reliable indicator of correctness.
- Evidence anchors:
  - [section 2.1] "GPT-4 provides an explanation for each prompt. While it can be useful for the explainability study in automatic face recognition, it may also generate misleading outputs in false positive cases."
  - [section 3] "Users should be cautioned that, despite receiving detailed descriptions highlighting similarities, they should not fully rely on GPT-4's answers for face recognition without further verification."
- Break condition: If the explainability feature is disabled or if users begin to over-rely on the explanations without independent verification.

## Foundational Learning

- Concept: Prompt engineering and safety bypass techniques
  - Why needed here: To enable GPT-4 to process biometric data while respecting its built-in privacy safeguards.
  - Quick check question: What specific phrasing in prompts allows GPT-4 to bypass its safeguards for biometric tasks?

- Concept: Multimodal foundation models and generalization
  - Why needed here: To understand how GPT-4 can perform well on biometric tasks despite not being specifically trained for them.
  - Quick check question: How does GPT-4's general pretraining enable it to perform biometric tasks without specialized fine-tuning?

- Concept: Explainability in AI systems
  - Why needed here: To understand the dual nature of GPT-4's explainability feature as both a strength and a potential vulnerability.
  - Quick check question: How can GPT-4's detailed explanations be both helpful and misleading in biometric applications?

## Architecture Onboarding

- Component map:
  GPT-4 API interface -> Automated prompt engineering module -> Sentiment analysis module (using GPT-4) -> Performance evaluation module -> Dataset management system

- Critical path:
  1. Prepare prompt with safety bypass framing (AI-generated content)
  2. Submit prompt and image(s) to GPT-4
  3. Retrieve and analyze GPT-4's response
  4. Perform sentiment analysis on response using GPT-4
  5. Update accuracy metrics based on sentiment analysis
  6. Iterate for all test samples in dataset

- Design tradeoffs:
  - Safety bypass vs. ethical considerations: Bypassing safeguards enables research but raises ethical concerns about privacy and misuse.
  - Generalist vs. specialist performance: GPT-4's generalist nature allows it to perform biometric tasks but may not match specialized models' accuracy.
  - Explainability vs. reliability: Detailed explanations provide insight but can be misleading in false positive cases.

- Failure signatures:
  - GPT-4 consistently refuses to process prompts even with safety bypass framing
  - Performance metrics are significantly lower than specialized models across all biometric tasks
  - Explainability feature is disabled or produces unreliable explanations

- First 3 experiments:
  1. Test GPT-4's face recognition on LFW dataset with standard prompts and safety bypass prompts, comparing accuracy and response rates.
  2. Evaluate GPT-4's gender detection on balanced gender dataset, comparing performance with DeepFace and testing with synthetic faces from Eyes-2-Face technique.
  3. Assess GPT-4's age estimation on UTKFace dataset, analyzing predicted age ranges and comparing accuracy for different age groups.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust are ChatGPT's biometric capabilities when tested on diverse, real-world datasets beyond controlled benchmark sets?
- Basis in paper: [inferred] The paper uses controlled datasets (LFW, AgeDB, CFP-FP) but acknowledges limitations in real-world applicability.
- Why unresolved: The study relies on curated datasets that may not reflect the variability and complexity of real-world biometric data, including factors like occlusion, lighting variations, and demographic diversity.
- What evidence would resolve it: Testing ChatGPT on diverse, uncontrolled real-world datasets with varied demographics, lighting conditions, and occlusions to assess its generalizability and robustness.

### Open Question 2
- Question: What are the potential security risks of bypassing ChatGPT's safeguards through prompt engineering, and how can they be mitigated?
- Basis in paper: [explicit] The authors demonstrate that ChatGPT's safeguards can be bypassed to extract sensitive biometric information.
- Why unresolved: The study highlights the vulnerability but does not explore the broader implications or propose solutions for securing LLMs against such attacks.
- What evidence would resolve it: Conducting adversarial testing to identify other bypass techniques and developing robust safeguards to prevent unauthorized access to sensitive information.

### Open Question 3
- Question: Can ChatGPT's biometric performance be further improved through fine-tuning or domain-specific training?
- Basis in paper: [explicit] The study uses a pre-trained ChatGPT model without fine-tuning, yet achieves competitive results.
- Why unresolved: The paper does not explore whether additional training or domain-specific fine-tuning could enhance ChatGPT's performance in biometric tasks.
- What evidence would resolve it: Comparing ChatGPT's performance with and without fine-tuning on biometric-specific datasets to quantify the impact of domain adaptation.

### Open Question 4
- Question: How does ChatGPT's biometric performance compare to specialized models when handling ambiguous or synthetic data?
- Basis in paper: [inferred] ChatGPT performs well on synthetic faces but the comparison with specialized models is limited to real faces.
- Why unresolved: The study focuses on controlled synthetic data but does not evaluate ChatGPT's performance against specialized models in more challenging, ambiguous scenarios.
- What evidence would resolve it: Testing ChatGPT and specialized models on ambiguous or highly synthetic data to determine which approach is more reliable in complex scenarios.

## Limitations

- Reliance on prompt engineering to bypass safety safeguards raises ethical concerns and may not be consistently reproducible
- Experiments focus on controlled benchmark datasets, limiting generalizability to real-world biometric scenarios
- Performance comparison with specialized models may be misleading without accounting for the training disparity

## Confidence

**High Confidence:** The finding that GPT-4 can achieve competitive performance on face recognition (95.15% on LFW) and perfect gender detection accuracy is well-supported by the experimental results presented.

**Medium Confidence:** The age estimation results (74.25% accuracy) and the effectiveness of the safety bypass technique are reasonably well-supported but depend heavily on the specific implementation details that are not fully disclosed.

**Low Confidence:** Claims about the broader implications for LLM applications in biometrics and the security implications of bypass techniques are more speculative and not directly tested in the experiments.

## Next Checks

1. **Safety Bypass Robustness:** Systematically test the prompt engineering approach across multiple GPT-4 versions and different biometric tasks to verify that the safety bypass technique is consistent and reliable.

2. **Generalization to Challenging Datasets:** Evaluate GPT-4's biometric capabilities on more diverse and challenging datasets that include variations in pose, illumination, occlusion, and demographic diversity.

3. **Comparative Analysis with Fine-tuned Models:** Conduct head-to-head comparisons between GPT-4 and specialized biometric models trained on the same data distributions, controlling for training data and computational resources.