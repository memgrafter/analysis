---
ver: rpa2
title: Feasibility of Federated Learning from Client Databases with Different Brain
  Diseases and MRI Modalities
arxiv_id: '2406.11636'
source_url: https://arxiv.org/abs/2406.11636
tags:
- modalities
- training
- data
- databases
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper shows the feasibility of using federated learning to
  train a single model across multiple brain MRI databases with different diseases
  and modalities. The key method involves designing a model with input channels that
  cover all modalities, using random modality drop during training, and exploring
  feature normalization methods.
---

# Feasibility of Federated Learning from Client Databases with Different Brain Diseases and MRI Modalities

## Quick Facts
- arXiv ID: 2406.11636
- Source URL: https://arxiv.org/abs/2406.11636
- Reference count: 33
- Key outcome: Federated learning framework trains single model across 7 brain MRI databases with different diseases and modalities, achieving performance within 4.1% of centralized upper bound

## Executive Summary
This paper demonstrates the feasibility of federated learning (FL) for training a single segmentation model across multiple brain MRI databases with different diseases and modality combinations. The authors develop a FL framework that handles heterogeneous client data by expanding input channels to cover all modalities, implementing random modality drop during training, and using client-specific batch normalization. The approach enables a single model to segment multiple pathologies while preserving patient privacy through decentralized training.

## Method Summary
The method involves training a 3D U-Net segmentation model via federated learning across 7 brain MRI databases containing 5 different diseases. Key innovations include: (1) expanding input channels to accommodate all unique MRI modalities across clients, (2) applying random modality drop during training to improve generalization to unseen modality combinations, and (3) using client-specific batch normalization parameters to handle data heterogeneity. The model is trained to segment all lesion types combined into a single label, with evaluation on both source databases and unseen databases with different modality configurations.

## Key Results
- Federated model achieves Dice scores within 4.1% of centralized upper bound on target databases
- Random modality drop during training improves generalization to unseen modality combinations
- Client-specific batch normalization maintains source database performance while enabling knowledge transfer
- Joint training across multiple pathologies outperforms disease-specific models for databases with limited data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random modality drop during training enables the model to generalize to unseen combinations of MRI modalities
- Mechanism: By randomly masking input modalities during training, the model learns to rely on the subset of modalities available rather than memorizing specific modality-disease associations
- Core assumption: The model can learn robust representations that work across different modality combinations
- Evidence anchors:
  - [abstract] "training with random modality drop"
  - [section] "To develop a model that generalises to modality combinations not seen during training, we introduce modality drop, where we randomly set input modalities to zero during training"
  - [corpus] No direct evidence found in corpus papers

### Mechanism 2
- Claim: Client-specific batch normalization layers improve performance on source databases in federated learning
- Mechanism: Each client maintains its own batch normalization statistics, preventing the averaging of statistics across heterogeneous data distributions
- Core assumption: The data distribution shift across clients is significant enough to warrant client-specific normalization
- Evidence anchors:
  - [abstract] "exploring the effects of feature normalization methods"
  - [section] "To tackle this, we employ Batch Normalization (BN), but keep client-specific BN parameters and statistics, and exclude them from the model averaging step"
  - [corpus] No direct evidence found in corpus papers

### Mechanism 3
- Claim: Knowledge transfer across different brain pathologies improves segmentation performance
- Mechanism: Joint training on multiple diseases allows the model to learn shared features and transfer knowledge between related tasks
- Core assumption: There are shared features between different brain diseases that can be leveraged
- Evidence anchors:
  - [abstract] "Evaluation on 7 brain MRI databases with 5 different diseases shows that such FL framework can train a single model that is shown to be very promising in segmenting all disease types seen during training"
  - [section] "This paper demonstrates effectiveness of FL for jointly learning to segment multiple pathologies, achieving performance that compares favorably to disease-specific models"
  - [corpus] No direct evidence found in corpus papers

## Foundational Learning

- Concept: Federated learning
  - Why needed here: To train a model across multiple institutions without sharing sensitive patient data
  - Quick check question: What is the main challenge federated learning addresses in healthcare applications?

- Concept: Multi-modal MRI
  - Why needed here: Different diseases may be imaged with different sets of MRI modalities, requiring the model to handle variable input
  - Quick check question: Why can't a model trained on one set of modalities be directly applied to data with a different set of modalities?

- Concept: Batch normalization
  - Why needed here: To stabilize training across heterogeneous data distributions from different clients
  - Quick check question: How does batch normalization help with covariate shift in deep learning models?

## Architecture Onboarding

- Component map: Input → Modality drop → U-Net → Client-specific BN → Output
- Critical path: Input → Modality drop → U-Net → Client-specific BN → Output
- Design tradeoffs:
  - Modality drop rate: Higher rates improve generalization but may hurt performance on seen modalities
  - BN strategy: Client-specific BN improves source performance but complicates inference on new clients
  - Model complexity: Larger models may capture more complex relationships but require more data
- Failure signatures:
  - Poor performance on source clients: May indicate insufficient capacity or learning rate issues
  - Poor generalization to new modalities: May indicate insufficient modality drop or inappropriate BN strategy
  - Unstable training: May indicate inappropriate learning rate or batch size
- First 3 experiments:
  1. Train with no modality drop and standard BN to establish baseline performance
  2. Add modality drop with small probability to test generalization improvement
  3. Implement client-specific BN and compare performance to standard BN approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of federated learning compare to centralized learning when the modalities are missing in different patterns across clients?
- Basis in paper: [explicit] The paper explores missing modalities during testing and compares performance with and without modality drop, but does not specifically address different patterns of missing modalities across clients.
- Why unresolved: The paper focuses on the impact of modality drop during training and its effect on missing modalities at test time, but does not investigate how different patterns of missing modalities across clients affect federated learning performance.
- What evidence would resolve it: Experiments comparing federated learning performance with centralized learning under various missing modality patterns across clients.

### Open Question 2
- Question: What is the impact of the number of clients on the performance of federated learning for brain lesion segmentation?
- Basis in paper: [inferred] The paper demonstrates feasibility with 7 clients but does not explore how performance scales with the number of clients.
- Why unresolved: The study uses a fixed number of clients and does not investigate how increasing or decreasing the number of clients affects the model's ability to segment different brain lesions and handle diverse MRI modalities.
- What evidence would resolve it: Experiments varying the number of clients while keeping the total amount of data constant to observe changes in performance.

### Open Question 3
- Question: How does federated learning perform on rare brain diseases with limited data compared to disease-specific models?
- Basis in paper: [explicit] The paper mentions the benefits of knowledge transfer for databases with limited data (MSSEG, TBI, and WMH) but does not provide a detailed comparison with disease-specific models for rare diseases.
- Why unresolved: While the paper shows improvements for databases with limited data, it does not specifically address the performance of federated learning on rare brain diseases compared to models trained specifically for those diseases.
- What evidence would resolve it: A comparison of federated learning performance with disease-specific models on rare brain diseases, particularly focusing on datasets with very limited samples.

## Limitations
- Modality drop rate is not explicitly specified, making it unclear how much randomness was introduced during training
- The exact performance gap between federated learning and centralized training on source databases is not reported
- Generalizability to non-brain imaging applications is untested

## Confidence
- High confidence: Feasibility of federated learning across heterogeneous databases with different modalities
- Medium confidence: Effectiveness of random modality drop for generalization to unseen modality combinations
- Medium confidence: Importance of client-specific batch normalization for maintaining source database performance

## Next Checks
1. Conduct ablation studies varying the modality drop probability to identify the optimal rate for balancing source performance and generalization
2. Test the federated model on completely new brain MRI databases not used in any form during training to assess true out-of-distribution generalization
3. Evaluate whether the approach generalizes to other medical imaging modalities (CT, ultrasound) and anatomical regions beyond the brain