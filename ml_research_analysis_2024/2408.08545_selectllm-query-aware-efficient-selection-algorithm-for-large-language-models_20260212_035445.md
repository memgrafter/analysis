---
ver: rpa2
title: 'SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models'
arxiv_id: '2408.08545'
source_url: https://arxiv.org/abs/2408.08545
tags:
- llms
- select
- performance
- gsm8k
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of improving performance and
  efficiency in large language model (LLM) ensembles by selectively querying a subset
  of models rather than the entire pool. The proposed SELECTLLM algorithm uses a multi-label
  classifier to predict which LLMs are most likely to correctly answer a given query,
  combined with confidence-based selection policies (e.g., weighted max confidence)
  to choose an optimal subset.
---

# SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language Models

## Quick Facts
- arXiv ID: 2408.08545
- Source URL: https://arxiv.org/abs/2408.08545
- Reference count: 31
- Primary result: SELECTLLM achieves 1.90 points higher accuracy on GSM8K and 4.89 points on MMLU compared to top baselines, while reducing inference latency by 13% and 70% respectively.

## Executive Summary
SELECTLLM addresses the challenge of improving performance and efficiency in large language model (LLM) ensembles by selectively querying a subset of models rather than the entire pool. The method uses a multi-label classifier to predict which LLMs are most likely to correctly answer a given query, combined with confidence-based selection policies to choose an optimal subset. Evaluated on GSM8K and MMLU reasoning benchmarks, SELECTLLM outperforms existing ensemble baselines, achieving higher accuracy while significantly reducing inference latency. The approach demonstrates strong out-of-domain generalization and maintains competitive performance with similarly sized top-performing LLM subsets.

## Method Summary
SELECTLLM employs a multi-label classifier (RoBERTa-based) fine-tuned on a dataset mapping queries to LLMs that correctly answered them (determined via majority voting across multiple generations). During inference, the classifier predicts a subset of LLMs and their confidence scores for each new query. Selection policies (LABELLED MAXCONF, MAXCONF, WEIGHTED MAXCONF) then choose an optimal subset of LLMs based on these predictions and confidences. The selected LLMs execute the query in parallel, and answers are combined via weighted voting to produce the final output. The method balances accuracy and latency by routing each query to only the most suitable subset of models.

## Key Results
- SELECTLLM achieves 1.90 points higher accuracy on GSM8K and 4.89 points on MMLU compared to top baselines
- Reduces inference latency by 13% on GSM8K and 70% on MMLU compared to top-performing baselines
- Maintains competitive performance with similarly sized top-performing LLM subsets
- Demonstrates strong out-of-domain generalization capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-label classifier learns which LLMs are most likely to correctly answer a given query.
- Mechanism: The model is fine-tuned on a dataset (SLDATA) that associates each query with the LLMs that correctly answered it (using majority voting across M samples). During inference, it predicts a subset of LLMs and their confidence scores for each new query.
- Core assumption: The training data SLDATA is representative of the query space, and the classifier can generalize from seen to unseen queries.
- Break condition: If the query distribution in deployment differs significantly from the training data, or if the classifier fails to capture nuanced LLM capabilities, the predictions become unreliable.

### Mechanism 2
- Claim: Confidence-based policies select an optimal subset of LLMs for each query, improving both accuracy and latency.
- Mechanism: Three policies are proposed:
  1. LABELLED MAXCONF: selects top-s LLMs from the classifier's predicted set
  2. MAXCONF: selects top-s LLMs based on confidence scores alone
  3. WEIGHTED MAXCONF: adjusts answer frequencies by dividing by the square root of the confidence score to reduce bias toward high-confidence models
- Core assumption: Confidence scores correlate with actual LLM performance, and the policy logic effectively balances accuracy and latency.
- Break condition: If confidence scores are poorly calibrated or if the adjustment factor in WEIGHTED MAXCONF is suboptimal, the policy may select suboptimal LLM subsets.

### Mechanism 3
- Claim: SELECTLLM achieves significant latency reduction by querying fewer LLMs than baselines like "All LLMs" or "Top-s LLMs."
- Mechanism: Instead of querying all available LLMs for every query, SELECTLLM routes each query to a small, query-specific subset. The number of LLMs queried per query (s) is chosen based on the confidence distribution and is typically smaller than the total pool size.
- Core assumption: The selected subset is sufficient to achieve high accuracy, and the latency savings from fewer queries outweigh any marginal accuracy loss.
- Break condition: If the optimal subset size s is misestimated, or if the latency model doesn't account for all sources of delay (e.g., network, preprocessing), the latency gains may not materialize.

## Foundational Learning

- Concept: Multi-label classification
  - Why needed here: Each query can be correctly answered by multiple LLMs, so the problem is naturally multi-label rather than single-label
  - Quick check question: Can a query have more than one correct LLM answer? (Yes)

- Concept: Majority voting across multiple generations
  - Why needed here: To reliably determine if an LLM can solve a query, multiple responses are generated and the most frequent answer is taken. This reduces noise from individual generations
  - Quick check question: Why not use a single generation per LLM? (To ensure reliability and replicability)

- Concept: Weighted voting with confidence adjustment
  - Why needed here: To prevent high-confidence but potentially biased LLMs from dominating the final answer, their vote weights are adjusted downward
  - Quick check question: What is the purpose of dividing by the square root of confidence in WEIGHTED MAXCONF? (To mitigate bias toward high-confidence models)

## Architecture Onboarding

- Component map: Query text -> Multi-label classifier (RoBERTa-based) -> Confidence scores + predictions -> Selection policy (e.g., WEIGHTED MAXCONF) -> Subset of LLMs -> Answer extraction -> Final answer

- Critical path:
  1. Query → Multi-label classifier → Confidence scores + predictions
  2. Policy selects subset of LLMs
  3. Subset LLMs execute query in parallel
  4. Extract and combine answers via weighted voting
  5. Return final answer

- Design tradeoffs:
  - Model size vs. latency: Smaller MLC models reduce latency but may sacrifice accuracy
  - Subset size (s) vs. accuracy: Larger s improves accuracy but increases latency
  - Confidence adjustment factor: Too aggressive reduces high-confidence LLM contributions; too mild allows bias

- Failure signatures:
  - Low accuracy: Classifier predictions are unreliable or policy selection is suboptimal
  - High latency: Subset size s is too large or confidence calibration is poor
  - Invalid answers: Answer extraction fails due to unstructured LLM outputs

- First 3 experiments:
  1. Train MLC on SLDATA and evaluate F1 score on validation set
  2. Test all three policies (LABELLED MAXCONF, MAXCONF, WEIGHTED MAXCONF) on validation set and compare accuracy/latency
  3. Perform ablation study varying s (subset size) to find optimal balance of accuracy and latency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the SELECTLLM algorithm perform on general generation tasks such as machine translation or question generation, which are not covered in the current study?
- Basis in paper: [explicit] The paper explicitly states that the scope is limited to reasoning benchmarks (GSM8K and MMLU) and does not cover general generation tasks
- Why unresolved: The study focuses on reasoning tasks with discrete outputs, while general generation tasks involve open-ended outputs. Adapting the algorithm to such tasks requires robust voting mechanisms and may involve different evaluation metrics
- What evidence would resolve it: Conducting experiments with SELECTLLM on general generation benchmarks (e.g., WMT for machine translation, QG benchmarks) and comparing its performance and efficiency against baseline methods

### Open Question 2
- Question: What is the impact of increasing the size of the training dataset for the multi-label classifier on the performance of SELECTLLM?
- Basis in paper: [explicit] The paper mentions that the multi-label classifier is trained on a limited dataset (7K for GSM8K, 14K for MMLU), leading to suboptimal performance with weighted F1 scores of 0.71 and 0.68, respectively
- Why unresolved: The study does not explore the effect of larger training datasets on the classifier's ability to predict LLM suitability for queries. More data could potentially reduce the performance gap between SELECTLLM and the Oracle
- What evidence would resolve it: Training the multi-label classifier on a significantly larger dataset (e.g., augmented with synthetic data or external sources) and evaluating its impact on SELECTLLM's accuracy and latency

### Open Question 3
- Question: How does SELECTLLM generalize to out-of-domain (OOD) tasks beyond the preliminary experiments conducted on MMLU?
- Basis in paper: [explicit] The paper presents preliminary OOD experiments on MMLU at grade and subject levels, showing comparable performance to in-domain tasks
- Why unresolved: The study only tests OOD generalization on one dataset (MMLU) and does not explore other domains or datasets. The robustness of SELECTLLM to OOD tasks across diverse domains remains unclear
- What evidence would resolve it: Evaluating SELECTLLM on multiple OOD datasets from different domains (e.g., biomedical, legal, or technical domains) and analyzing its performance relative to in-domain and baseline methods

## Limitations
- Evaluation is limited to two reasoning benchmarks (GSM8K and MMLU) with a fixed pool of 6-7 open-source LLMs, which may not generalize to other domains or larger/more diverse model pools
- The method assumes that the multi-label classifier can reliably generalize from training data to unseen queries, which may not hold for out-of-distribution queries or when LLM capabilities shift over time
- Latency savings are presented as relative percentages but absolute values are not provided, making it difficult to assess real-world impact

## Confidence

- SELECTLLM's accuracy improvement: Medium confidence
- Latency reduction claims: Medium confidence  
- Multi-label classifier effectiveness: Medium confidence

## Next Checks
1. **Out-of-domain robustness test**: Evaluate SELECTLLM on a dataset from a different domain (e.g., medical or legal reasoning) to assess generalization beyond GSM8K and MMLU
2. **Scalability assessment**: Test the method with larger model pools (10+ models) and measure how accuracy and latency scale as pool size increases
3. **Confidence calibration validation**: Perform reliability diagram analysis to verify that confidence scores from the multi-label classifier are well-calibrated and correlate with actual model performance