---
ver: rpa2
title: 'Building FKG.in: a Knowledge Graph for Indian Food'
arxiv_id: '2409.00830'
source_url: https://arxiv.org/abs/2409.00830
tags:
- food
- knowledge
- recipe
- indian
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors developed a knowledge graph for Indian food called
  FKG.in by designing an ontology adapted from FoodOn and FoodKG and implementing
  an AI-driven semi-automated pipeline to extract culinary data from recipe blogs.
  The core approach combines crawling, large language model (GPT-3.5) extraction,
  and a human-in-the-loop validation to ensure soundness.
---

# Building FKG.in: a Knowledge Graph for Indian Food

## Quick Facts
- arXiv ID: 2409.00830
- Source URL: https://arxiv.org/abs/2409.00830
- Reference count: 27
- Primary result: Developed a knowledge graph for Indian food (FKG.in) using AI-driven semi-automated pipeline with ~9.6k recipes, ~38.8k ingredients, and ~50 MB size

## Executive Summary
The authors present FKG.in, a knowledge graph for Indian food constructed using a semi-automated pipeline combining web crawling, large language model (GPT-3.5) extraction, and human-in-the-loop validation. The system addresses challenges unique to Indian culinary data, including multilingual ingredient names, code-mixing, and compositional recipe structures. By adapting established food ontologies (FoodOn, FoodKG) and implementing AI-driven entity extraction, the authors create a scalable framework for building comprehensive food knowledge graphs. The pipeline achieves soundness through automated extraction followed by human validation, while maintaining extensibility for domain-specific requirements.

## Method Summary
The approach combines crawling recipe blogs, LLM-driven entity extraction from unstructured content, and human validation to build FKG.in. The pipeline extracts entities (ingredients, measures, techniques, nutrition) using GPT-3.5 Turbo with prompts, resolves entities via LSH clustering and vocabulary matching, and validates results through human-in-the-loop intervention. The ontology extends FoodOn and FoodKG with Indian-specific concepts and multilingual handling. Data is stored as RDF/XML triples in GraphDB, with a SKOS-based vocabulary store for ingredient and cuisine names. The system is designed to be application-agnostic and extensible.

## Key Results
- Successfully built FKG.in containing ~50 MB, ~9.6k unique recipes across 39 categories, and ~38.8k ingredient nodes
- Demonstrated effective LLM-driven extraction with human-in-the-loop validation for maintaining knowledge graph soundness
- Adapted FoodOn and FoodKG ontologies to capture unique aspects of Indian food while maintaining application-agnostic design
- Established a semi-automated pipeline that handles multilingual ingredient names and compositional recipe structures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-driven extraction with zero-shot/few-shot prompts is effective at pulling semi-structured culinary data from unstructured recipe blog content.
- Mechanism: GPT-3.5 Turbo is prompted to parse raw HTML or long text from recipe pages, extracting entities like ingredients, measures, cooking techniques, and nutrition info into a structured XML-like format that can be matched against recipe cards.
- Core assumption: The LLM can accurately interpret domain-specific culinary language and context, including Indian ingredient names, multilingual scripts, and non-standard measurement expressions.
- Evidence anchors:
  - [section]: "We have identified 40 recipe blogs and websites with rich information about Indian food recipes... To begin with, we have crawled 5 recipe blogs... The crawler gathers content... GPT 3.5 is also employed to translate Indian ingredient names, written in Indian or Roman scripts to their English names."
  - [abstract]: "We also present a novel workflow that uses AI, LLM, and language technology to curate information from recipe blog sites in the public domain to build knowledge graphs for Indian food."
- Break condition: If the LLM misidentifies multi-word named entities (e.g., "pudina chutney sandwich" parsed as "pudina" + "chutney") or fails to handle code-mixing, the soundness score drops and the pipeline requires more human intervention.

### Mechanism 2
- Claim: Human-in-the-loop validation after LLM extraction ensures knowledge graph soundness without sacrificing automation.
- Mechanism: After initial extraction, entities are clustered using Locality Sensitive Hashing (LSH) for entity resolution, cross-checked against existing vocabularies, and inconsistencies are flagged for human review via an interface.
- Core assumption: Human reviewers can efficiently correct entity misclassifications and enrich the ontology, while feedback is used to iteratively improve LLM prompts and reduce future errors.
- Evidence anchors:
  - [section]: "– Task 4.2 - All inconsistencies identified in the earlier step are presented to human curators for validation and correction if needed... Human feedback is also used to augment the ontology in an atomic, reliable, and consistent manner to accommodate new information obtained from the recipe web pages."
  - [abstract]: "We also present a novel workflow that uses AI, LLM, and language technology to curate information... along with a human-in-the-loop intervention to ensure the soundness of information."
- Break condition: If the volume of flagged inconsistencies exceeds human capacity or if reviewer feedback does not improve LLM accuracy over iterations, the system may not scale.

### Mechanism 3
- Claim: Ontology inheritance from established food ontologies (FoodOn, FoodKG) provides a robust, extensible base that can be adapted for Indian culinary specifics.
- Mechanism: FKG.in's core classes (Recipe, Ingredient, Dish, Platter, Meal) and properties are modeled after FoodKG, extended with Indian-specific subclasses (e.g., curry, bharta), multilingual ingredient handling, and compositional recipe logic.
- Core assumption: The chosen ontologies are comprehensive enough to cover the majority of Indian food concepts, and extensions can be made without breaking compatibility.
- Evidence anchors:
  - [abstract]: "The proposed ontology adapts from earlier food ontologies along with modifications and extensions to capture unique aspects of Indian food and is designed in an application-agnostic way."
  - [section]: "We now present the details of FKG.in, the Indian Food Ontology, which is inspired by FoodOn [14] and FoodKG [15], and wherever needed, adapted them to suit the Indian context."
- Break condition: If Indian food concepts fall outside the coverage of FoodOn/FoodKG or require incompatible structural changes, the inheritance model breaks and requires a new foundational design.

## Foundational Learning

- Concept: Knowledge graph fundamentals (RDF, OWL, triples)
  - Why needed here: The system stores data as RDF/XML triple-stores in an OWL file; understanding the model is critical for ingestion, querying, and extending the graph.
  - Quick check question: How would you represent "Aloo samosa is a recipe that uses potato" in RDF triple form?

- Concept: Ontology design patterns (class inheritance, property restrictions)
  - Why needed here: The design relies on extending existing ontologies with restrictions like "if cuisine = 'Non-vegetarian', then at least one ingredient must have category 'meat'"; knowing how to express these is essential.
  - Quick check question: What OWL construct would you use to enforce that a vegetarian recipe cannot contain meat ingredients?

- Concept: NLP entity recognition and multilingual text handling
  - Why needed here: Ingredient names appear in multiple scripts and languages; the pipeline uses LLMs for translation and entity resolution; understanding tokenization, script mapping, and entity linking is required.
  - Quick check question: How would you handle "haldi" (Hindi) and "manjal" (Tamil) mapping to the same turmeric entity?

## Architecture Onboarding

- Component map:
  Crawler -> LLM pipeline -> Entity resolver -> Human interface -> Ingestion module -> Vocabulary store

- Critical path:
  HTML crawl → LLM extraction → LSH entity resolution → soundness check → human validation → GraphDB ingestion

- Design tradeoffs:
  - LLM vs rule-based extraction: LLM handles variability but needs human checks; rule-based is precise but brittle with Indian culinary language.
  - Frequency of human intervention vs. prompt tuning: more manual work now may reduce future corrections but delays scaling.
  - SKOS vs custom vocabularies: SKOS is interoperable but less flexible for domain-specific metadata.

- Failure signatures:
  - High negative soundness score: LLM is misparsing entities; prompt needs refinement or data augmentation.
  - Duplicate ingredient nodes with Hindi vs. English names: code-mixing not handled; need transliteration normalization.
  - GraphDB ingestion errors: RDF/XML malformed; check OWL compliance and triple consistency.

- First 3 experiments:
  1. Run LLM extraction on a small set of known good recipe pages, compare extracted vs. ground truth, compute precision/recall.
  2. Simulate entity resolution by clustering known synonyms and measuring false positives/negatives.
  3. Ingest a minimal ontology with 10 recipes into GraphDB, run SPARQL queries to validate structure and constraints.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the completeness of the knowledge graph be quantitatively assessed, given that current methods focus primarily on soundness validation?
- Basis in paper: [explicit] The paper acknowledges that completeness is a future focus, noting that "completeness of information in situations where the large language model fails to extract a piece of information altogether" needs to be addressed.
- Why unresolved: Current evaluation metrics and automated methods primarily target soundness (correctness) rather than completeness (coverage). The paper does not describe systematic completeness assessment frameworks.
- What evidence would resolve it: A defined metric and methodology for measuring coverage gaps in FKG.in, including benchmarks against reference Indian food datasets or expert-validated recipe collections.

### Open Question 2
- Question: How can the system handle and normalize the multilingual nature of Indian food terminology, especially with code-mixing and script variations in recipe blogs?
- Basis in paper: [explicit] The paper highlights the challenge of the same food items having various vernacular names across Indian languages and mentions that "some nodes have Hindi names in Devanagari fonts, indicating that more resolution rules will need to be added to address code-mixing."
- Why unresolved: While entity resolution and translation using LLMs are mentioned, there is no detailed methodology for handling the full complexity of multilingual and code-mixed data in the knowledge graph.
- What evidence would resolve it: A validated multilingual entity resolution pipeline that successfully maps vernacular and code-mixed ingredient names to a unified ontology, demonstrated with performance metrics.

### Open Question 3
- Question: How can the knowledge graph be extended to incorporate contextual information such as user dietary preferences, geographic data, and agricultural information to support personalized health and recommendation applications?
- Basis in paper: [explicit] The paper mentions that the design is "application-agnostic" and can be complemented with "contextual information such as user information, food biochemistry, geographic information, agricultural information," but does not detail how this integration would be achieved.
- Why unresolved: The current ontology and curation workflow focus on core food and recipe data, with no clear strategy for integrating external contextual datasets or supporting personalized applications.
- What evidence would resolve it: A framework or prototype showing how FKG.in can be linked to or enriched with external data sources (e.g., user health profiles, agricultural databases) to enable personalized food recommendations or health tracking.

## Limitations

- Limited details on LLM prompt design and error rates, making it difficult to assess extraction quality without human intervention
- No systematic completeness assessment framework, with current methods focusing primarily on soundness validation
- Scalability concerns when scaling from 5 crawled blogs to 40+ target blogs, particularly regarding human validation capacity

## Confidence

- LLM extraction mechanism: Medium confidence due to limited details on prompt design, error rates, and human reviewer training
- Human-in-the-loop validation: Medium confidence due to unspecified validation criteria and interface details
- Ontology inheritance mechanism: High confidence as it builds directly on established food ontologies (FoodOn, FoodKG) with documented extensions

## Next Checks

1. Test the LLM extraction pipeline on a small, controlled set of recipe pages with known ground truth entities to measure precision and recall before and after human validation.

2. Simulate the entity resolution process using a test vocabulary containing known synonyms (e.g., "haldi" vs "manjal") to quantify false positive and false negative rates in the LSH clustering.

3. Attempt to ingest a minimal ontology with 10-20 recipes into GraphDB and run SPARQL queries to verify OWL compliance, constraint enforcement, and structural integrity.