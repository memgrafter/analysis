---
ver: rpa2
title: 'Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using
  Counterfactuals As Guides?'
arxiv_id: '2403.00980'
source_url: https://arxiv.org/abs/2403.00980
tags:
- semi-factual
- methods
- semi-factuals
- explanations
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper compares counterfactual-free and counterfactual-guided
  methods for generating semi-factual explanations in XAI, addressing the question
  of whether using counterfactuals as guides leads to better semi-factuals. The authors
  evaluate 8 semi-factual methods (4 counterfactual-free, 4 counterfactual-guided)
  across 7 datasets using 5 key metrics: distance, plausibility, confusability, robustness,
  and sparsity.'
---

# Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using Counterfactuals As Guides?

## Quick Facts
- arXiv ID: 2403.00980
- Source URL: https://arxiv.org/abs/2403.00980
- Reference count: 37
- The study finds that counterfactual guidance is not necessary for generating high-quality semi-factual explanations, with counterfactual-free methods often performing as well or better than counterfactual-guided ones.

## Executive Summary
This paper investigates whether using counterfactuals as guides improves the quality of semi-factual explanations in explainable AI (XAI). Through comprehensive evaluation of 8 semi-factual methods (4 counterfactual-free and 4 counterfactual-guided) across 7 datasets and 5 key metrics, the authors find that counterfactual guidance is not necessary for generating the best semi-factuals. The counterfactual-free MDN method performs best overall, while C2C-VAE (counterfactual-guided) excels in robustness and distance metrics. The study reveals that methods selecting existing instances produce more plausible semi-factuals compared to generative methods, suggesting that other factors beyond counterfactual guidance are more important in determining semi-factual quality.

## Method Summary
The paper evaluates 8 semi-factual explanation methods (4 counterfactual-free: Local-Region, DSER, MDN, S-GEN; 4 counterfactual-guided: KLEOR, PIECE, C2C-VAE, DiCE) using 5 key metrics: distance (L2-norm), plausibility (L2 distance to nearest training instance), confusability (distance ratio to counterfactual/query classes), robustness (local Lipschitz continuity), and sparsity (ideal/observed feature differences). The methods are tested across 7 benchmark tabular datasets (Adult Income, Blood Alcohol, Default Credit Card, Diabetes, German Credit, HELOC, Lending Club) using 5-fold cross-validation with a Random Forest classifier for validation. Results are normalized between 0 and 1 for comparison.

## Key Results
- Counterfactual-free methods, particularly MDN, perform best overall across multiple metrics
- C2C-VAE (counterfactual-guided) excels specifically in robustness and distance metrics
- Methods that select existing instances (MDN, KLEOR, Local-Region) produce more plausible semi-factuals compared to generative methods
- No single method dominates across all metrics, suggesting explanation quality is multidimensional

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual guidance is not necessary for generating high-quality semi-factual explanations because other aspects of the decision space are more important.
- Mechanism: The paper evaluates 8 semi-factual methods using 5 metrics. Counterfactual-free methods like MDN perform best overall, while counterfactual-guided methods excel in specific metrics but not universally, suggesting computational approach matters more than counterfactual guidance.
- Core assumption: Quality of semi-factuals is determined by factors other than counterfactual guidance, such as instance selection strategy and distance calculations.
- Evidence anchors: [abstract] "the results show that counterfactual guidance is not necessary for generating the best semi-factuals"; [section] "MDN method performs best overall, while C2C-VAE excels in robustness and distance metrics"

### Mechanism 2
- Claim: Methods that select existing instances produce more plausible semi-factuals compared to generative methods.
- Mechanism: Instance selection methods like MDN and KLEOR find real data points within the query class, making them inherently plausible as they come from the training distribution, while generative methods create synthetic instances that may not match the data distribution.
- Core assumption: Plausibility is best measured by proximity to existing training instances, and methods that select from known data are inherently more plausible.
- Evidence anchors: [section] "methods selecting existing instances (MDN, KLEOR, Local-Region) produce more plausible semi-factuals compared to generative methods"; [abstract] "the counterfactual-free MDN method performs best overall"

### Mechanism 3
- Claim: Quality of semi-factual explanations depends on the specific metric being optimized, with different methods excelling at different aspects.
- Mechanism: Each method optimizes different aspects of explanation quality. C2C-VAE excels at robustness and distance by analyzing differences between instances with respect to classes, while MDN excels at plausibility by selecting known instances, suggesting explanation quality is multidimensional.
- Core assumption: Explanation quality is not a single dimension but rather a set of competing objectives that different methods optimize differently.
- Evidence anchors: [section] "the top-3 methods – MDN, C2C-VAE, Local-Region – are really not that good on further analysis of their performance"; [abstract] "the findings suggest that other factors beyond counterfactual guidance are more important"

## Foundational Learning

- Concept: Difference between counterfactuals and semi-factuals
  - Why needed here: The paper explicitly compares methods that use counterfactual guidance versus those that don't, so understanding this distinction is crucial
  - Quick check question: What is the key difference between a counterfactual explanation ("if-only") and a semi-factual explanation ("even-if")?

- Concept: XAI evaluation metrics for explanations
  - Why needed here: The paper evaluates methods using distance, plausibility, confusability, robustness, and sparsity - understanding these metrics is essential for interpreting which methods are "best"
  - Quick check question: Why might a semi-factual explanation that is too far from the query be problematic for users?

- Concept: Instance-based vs. generative explanation methods
  - Why needed here: The paper distinguishes between methods that select existing instances versus those that generate new ones, which appears to be a key factor in their performance differences
  - Quick check question: What are the potential advantages and disadvantages of selecting existing instances versus generating new ones for explanation purposes?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> Method implementation -> Evaluation -> Cross-validation -> Results aggregation
- Critical path: Load dataset and preprocess features -> Train classifier model for validation -> For each query instance, generate semi-factual explanations using all 8 methods -> Evaluate generated semi-factuals using all 5 metrics -> Aggregate results across folds and datasets -> Compare performance and generate insights
- Design tradeoffs: Instance selection vs. generation (trade-off between plausibility and flexibility), Metric optimization (different methods optimize different aspects), Computational cost (some methods are more expensive), Interpretability (simpler methods may be more interpretable)
- Failure signatures: Poor plausibility scores (method may be generating synthetic instances that don't match data distribution), High confusability (semi-factuals may be too close to counterfactuals), Low robustness (small perturbations lead to vastly different semi-factuals), High sparsity but poor other metrics (method is finding instances too different from query)
- First 3 experiments: 1) Implement and test MDN method on a single dataset to understand instance selection approach, 2) Compare performance of C2C-VAE (generative) vs. KLEOR (instance-based) on the same dataset, 3) Evaluate all 8 methods on a small dataset using only distance and plausibility metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Which specific combination of existing semi-factual methods would produce the best overall performance across all evaluation metrics?
- Basis in paper: [explicit] The authors conclude that "the most promising direction for future research may be to extract what is best from the current methods and somehow combine them in one."
- Why unresolved: The paper demonstrates that no single method dominates across all metrics, but doesn't explore hybrid approaches or identify which specific methodological components could be combined effectively.
- What evidence would resolve it: Systematic testing of hybrid methods that combine the best-performing aspects of different approaches (e.g., MDN's plausibility with C2C-VAE's robustness) across the same evaluation metrics.

### Open Question 2
- Question: How do semi-factual explanations perform in terms of psychological validity and user comprehension compared to counterfactual explanations?
- Basis in paper: [explicit] The authors state "we do not know whether people find the semi-factuals produced by any of these methods are psychologically valid" and note that existing user studies "suffer from design flaws."
- Why unresolved: The paper focuses entirely on computational metrics and doesn't include any human subject testing or evaluation of how well users understand or find useful these explanations.
- What evidence would resolve it: Controlled user studies comparing semi-factual and counterfactual explanations across various domains, measuring comprehension, trust, and perceived usefulness.

### Open Question 3
- Question: Do the findings about counterfactual guidance extend to non-tabular data types such as images and time series?
- Basis in paper: [explicit] The authors acknowledge this as a limitation, stating "This work primarily focuses on tabular data; so, it would be interesting to determine whether the results extend to other data-types (e.g., images and time series)."
- Why unresolved: All experiments were conducted exclusively on tabular datasets, and the computational properties of semi-factual methods may behave differently with unstructured or sequential data.
- What evidence would resolve it: Replication of the comprehensive evaluation across image datasets (e.g., MNIST, CIFAR) and time series datasets (e.g., medical signals, financial data) using the same metrics.

## Limitations
- The study's conclusions are based on evaluations across 7 tabular datasets using 8 specific methods, limiting generalizability to other data types or method families.
- The focus on a fixed set of 5 metrics may miss other important aspects of explanation quality, particularly for real-world deployment scenarios.
- No human subject testing was conducted to evaluate whether higher metric scores translate to better human understanding and trust.

## Confidence
- High: The comparative ranking of methods across metrics is reliable given the rigorous 5-fold cross-validation and normalization approach
- Medium: The conclusion that counterfactual guidance is not necessary is well-supported but may not hold for all semi-factual applications or data domains
- Low: The specific mechanism explaining why MDN performs best (instance selection vs. generation) is plausible but not definitively proven by this study alone

## Next Checks
1. Test the top-performing methods (MDN, C2C-VAE, Local-Region) on non-tabular datasets like images or text to assess cross-domain robustness
2. Conduct user studies to evaluate whether higher metric scores translate to better human understanding and trust in real-world applications
3. Implement an ablation study removing counterfactual guidance from counterfactual-guided methods to isolate its specific contribution to performance