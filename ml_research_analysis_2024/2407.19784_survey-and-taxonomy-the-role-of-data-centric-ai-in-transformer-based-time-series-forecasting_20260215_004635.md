---
ver: rpa2
title: 'Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time
  Series Forecasting'
arxiv_id: '2407.19784'
source_url: https://arxiv.org/abs/2407.19784
tags:
- time
- data
- series
- forecasting
- transformer-based
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey addresses the gap in integrating data-centric AI (DCAI)
  with transformer-based time series forecasting models. It proposes a taxonomy based
  on the CRISP-DM framework to systematically review previous research from a DCAI
  perspective, focusing on three research questions: how datasets are preprocessed
  before being fed into models, how data and models interact with each other, and
  how models are evaluated on the data.'
---

# Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting

## Quick Facts
- **arXiv ID**: 2407.19784
- **Source URL**: https://arxiv.org/abs/2407.19784
- **Reference count**: 40
- **Primary result**: This survey addresses the gap in integrating data-centric AI with transformer-based time series forecasting models using a CRISP-DM grounded taxonomy.

## Executive Summary
This survey addresses the integration gap between data-centric AI (DCAI) and transformer-based time series forecasting (TSF) models. The authors propose a taxonomy grounded in the CRISP-DM framework to systematically review previous research from a data-centric perspective. The survey identifies three critical research questions: how datasets are preprocessed before being fed into models, how data and models interact with each other, and how models are evaluated on the data. The work highlights the importance of considering computational performance and carbon footprint in model evaluation, providing experimental results on CO2 emissions for various transformer-based models.

## Method Summary
The survey analyzes 50 datasets across 24 transformer-based models and 4 LLM-based models, including datasets like electricity, traffic, and weather. The authors apply the CRISP-DM framework to build a taxonomy categorizing processes into Input Data preprocessing, Data-Model Interaction, and Output Evaluation. They systematically review literature on dataset preparation, preprocessing, feature engineering, data reduction/augmentation, input embedding, position encoding, and model evaluation metrics. The survey also measures CO2 emissions for sustainability assessment using specific hardware configurations.

## Key Results
- The taxonomy based on CRISP-DM phases systematically bridges the gap between transformer-based TSF models and data-centric AI practices
- Transformer models' performance in TSF is heavily dependent on high-quality input data representation, including embedding and position encoding
- Comprehensive evaluation of transformer-based TSF models must include both predictive accuracy and computational efficiency (including carbon footprint)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The taxonomy grounded in CRISP-DM phases systematically bridges the gap between transformer-based TSF models and data-centric AI practices.
- Mechanism: CRISP-DM's six phases are mapped to three survey categories (Input Data, Data-Model Interaction, Output Evaluation), ensuring every aspect of the forecasting pipeline is examined through a data-centric lens.
- Core assumption: CRISP-DM's process phases are universally applicable for describing data-centric workflows in TSF.
- Evidence anchors: [abstract]: "We apply the CRoss-Industry Standard Process for Data Mining (CRISP-DM) to build a taxonomy..." [section 3]: "We adopt the CRISP-DM and Transformer model workflow as the foundational framework..."

### Mechanism 2
- Claim: Transformer models' performance in TSF is heavily dependent on high-quality input data representation, including embedding and position encoding.
- Mechanism: The transformer architecture processes sequential data via multi-head attention, requiring explicit temporal ordering and meaningful feature embeddings for effective forecasting.
- Core assumption: Attention mechanisms in transformers require explicit temporal ordering and meaningful feature embeddings for effective forecasting.
- Evidence anchors: [section 5.1]: "Input embedding techniques commonly include 1-D convolutional filters... Time position encoding typically applies temporal position encoding..."

### Mechanism 3
- Claim: Comprehensive evaluation of transformer-based TSF models must include both predictive accuracy and computational efficiency (including carbon footprint).
- Mechanism: Predictive metrics quantify forecasting quality while computational metrics measure resource consumption, ensuring sustainable model deployment.
- Core assumption: Model evaluation should balance performance with sustainability, especially as model complexity grows.
- Evidence anchors: [section 6.2]: "However, with the growing importance of sustainability... it is crucial to develop models with lower environmental impact..."

## Foundational Learning

- Concept: Transformer architecture (encoder-decoder, multi-head attention, positional encoding)
  - Why needed here: Understanding how transformers process sequential data is essential for designing effective input representations and interpreting model-data interactions in TSF.
  - Quick check question: What is the role of positional encoding in transformers, and why is it critical for time series forecasting?

- Concept: Time series forecasting concepts (stationarity, seasonality, lag features, decomposition)
  - Why needed here: These concepts inform feature engineering and preprocessing decisions, directly impacting model input quality.
  - Quick check question: How does seasonal decomposition improve the forecasting performance of transformer models?

- Concept: Data-centric AI principles (systematic data engineering, data quality, data lifecycle)
  - Why needed here: Data-centric AI emphasizes data preparation and preprocessing over model architecture, aligning with the survey's focus on improving TSF via better data handling.
  - Quick check question: Why is data-centric AI particularly important for transformer-based TSF compared to traditional statistical methods?

## Architecture Onboarding

- Component map: CRISP-DM phases → Survey sections → Input Data (preprocessing, feature engineering) → Data-Model Interaction (embedding, encoding) → Output Evaluation (metrics, CO2)
- Critical path: Dataset → Preprocessing → Embedding/Encoding → Model → Evaluation (with CO2 measurement)
- Design tradeoffs: Depth vs. breadth in coverage, technical detail vs. accessibility, predictive vs. computational focus
- Failure signatures: Incomplete preprocessing leading to poor performance, incorrect embedding/encoding causing attention failures, overemphasis on predictive metrics while ignoring computational costs
- First 3 experiments:
  1. Replicate the carbon footprint measurement on a small dataset to validate the experimental setup and measurement tools.
  2. Apply different position encoding schemes (sinusoidal vs. learned) to the same TSF model and compare forecasting accuracy.
  3. Vary data splitting ratios (e.g., 80/10/10 vs. 70/20/10) and measure the impact on model performance and training efficiency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal data splitting ratios (training, validation, testing) for transformer-based time series forecasting models?
- Basis in paper: [explicit] The paper mentions that most transformer-based TSF models use a 70/20/10 ratio, but notes that this can vary and that optimal data splitting ratios remain insufficiently explored.
- Why unresolved: While some papers discuss optimal data splitting ratios, they are not well-explored for transformer-based TSF models.
- What evidence would resolve it: Experimental studies comparing the performance of transformer-based TSF models using different data splitting ratios on various datasets.

### Open Question 2
- Question: How do different input embedding strategies affect the performance of transformer-based time series forecasting models?
- Basis in paper: [inferred] The paper discusses input embedding as part of data representation but notes that research on optimizing input embedding strategies tailored for transformer-based time series models remains insufficient.
- Why unresolved: Despite advancements in position encoding techniques, input embedding strategies for transformer-based time series models have not been thoroughly investigated.
- What evidence would resolve it: Comparative studies of transformer-based TSF models using different input embedding techniques on various time series datasets.

### Open Question 3
- Question: What are effective methods for uncertainty management in transformer-based time series forecasting models?
- Basis in paper: [explicit] The paper highlights that understanding the reliability and trustworthiness of transformer-based models remains challenging due to the opacity of neural networks within transformers.
- Why unresolved: While methods for identifying, quantifying, and communicating uncertainties in model outputs are discussed in other domains, their application to transformer-based time series forecasting is limited.
- What evidence would resolve it: Development and evaluation of uncertainty quantification techniques specifically designed for transformer-based TSF models across diverse datasets.

## Limitations
- Limited empirical validation from the corpus for the taxonomy application to transformer-based TSF
- Only one paper directly mentions CRISP-DM in relation to transformer TSF in the surveyed literature
- No corpus papers discuss carbon footprint measurement in transformer-based TSF context
- Experimental CO2 measurements based on specific hardware configuration may not generalize

## Confidence

- **High Confidence**: The foundational mechanism that transformer models require proper input representation (embedding and position encoding) is well-established in broader ML literature.
- **Medium Confidence**: The application of CRISP-DM as a taxonomy framework is methodologically sound but its practical utility for transformer TSF research remains largely theoretical.
- **Low Confidence**: The claim that carbon footprint measurement should be standard practice for transformer TSF model evaluation lacks precedent in the surveyed literature.

## Next Checks

1. **Corpus Validation**: Conduct a more comprehensive literature review to identify additional papers that either support or challenge the proposed taxonomy framework and its CRISP-DM grounding in the context of transformer-based TSF.

2. **Experimental Replication**: Replicate the CO2 emission measurements across different hardware configurations (e.g., consumer GPUs, cloud instances) to establish whether the sustainability findings are robust to computational environment variations.

3. **Embedding Impact Study**: Design a controlled experiment comparing different input embedding and position encoding strategies across multiple TSF models and datasets to empirically validate the claimed importance of these data-centric preprocessing steps.