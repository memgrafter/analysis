---
ver: rpa2
title: Logical Consistency of Large Language Models in Fact-checking
arxiv_id: '2412.16100'
source_url: https://arxiv.org/abs/2412.16100
tags:
- consistency
- logical
- fact
- facts
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to assess and improve the logical
  consistency of LLMs in fact-checking over knowledge graphs. The authors introduce
  a new benchmark of logical fact-checking datasets (FreebaseLFC, NELLLFC, and WikiLFC)
  and propose quantitative measures of logical consistency for propositional logic
  queries with operators like negation, conjunction, and disjunction.
---

# Logical Consistency of Large Language Models in Fact-checking

## Quick Facts
- **arXiv ID**: 2412.16100
- **Source URL**: https://arxiv.org/abs/2412.16100
- **Reference count**: 40
- **Primary result**: Proposes a method to assess and improve LLM logical consistency in fact-checking over knowledge graphs

## Executive Summary
This paper addresses the critical issue of logical inconsistency in large language models when performing fact-checking over knowledge graphs. The authors propose a comprehensive framework that includes new benchmark datasets (FreebaseLFC, NELLLFC, and WikiLFC), quantitative measures of logical consistency for propositional logic queries, and supervised fine-tuning techniques to improve consistency. Through systematic evaluation, the paper demonstrates that existing LLMs lack logical consistency, particularly on complex queries involving negation, conjunction, and disjunction, and shows that their fine-tuning approach achieves a 14% average improvement in consistency while maintaining accuracy.

## Method Summary
The paper introduces a framework for assessing and improving LLM logical consistency in fact-checking over knowledge graphs. The method involves creating logical fact-checking datasets from KG triplets, implementing consistency measures for propositional logic queries, and employing supervised fine-tuning via QLoRA (parameter-efficient fine-tuning) to improve consistency. The approach uses BFS-based or vector embedding methods for KG context retrieval, applies instruction prompting with chain-of-thought reasoning, and evaluates performance on both in-distribution and out-of-distribution facts and logic rules.

## Key Results
- Existing LLMs exhibit significant logical inconsistency on fact-checking queries, particularly with negation, conjunction, and disjunction operators
- Supervised fine-tuning improves logical consistency by 14% on average while maintaining accuracy
- Fine-tuned models successfully generalize to more complex facts and rules beyond the training distribution
- PEFT via QLoRA achieves 3X efficiency improvement over full fine-tuning while maintaining performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs lack logical consistency on complex fact-checking queries, especially involving negation, conjunction, and disjunction.
- Mechanism: The paper introduces a consistency measure that checks whether LLM responses to logically equivalent or negated queries remain semantically opposite or equivalent, respectively.
- Core assumption: Logical consistency can be quantified by comparing LLM responses to atomic facts and their logical combinations.
- Evidence anchors:
  - [abstract] "We propose consistency measures of LLMs on propositional logic queries and demonstrate that existing LLMs lack logical consistency, especially on complex queries."
  - [section] "An LLM is logically consistent with a query under the negation operator if the LLM response to the base query and the negated query are semantically opposite."
- Break condition: If the LLM fails to maintain semantic relationships under logical transformations, it breaks consistency.

### Mechanism 2
- Claim: Supervised fine-tuning improves logical consistency by teaching LLMs to recognize primitive logical operators.
- Mechanism: The fine-tuning process uses labeled data from knowledge graphs to train LLMs to correctly classify simple facts and their negations, conjunctions, and disjunctions.
- Core assumption: Improving accuracy on primitive logical operators will generalize to complex facts and rules.
- Evidence anchors:
  - [abstract] "We employ supervised fine-tuning to improve the logical consistency of LLMs on the complex fact-checking task with KG contexts."
  - [section] "Our hypothesis therefore is that fine-tuning to recognize single operators should generalize to complex logic facts and rules with multiple operators."
- Break condition: If the fine-tuned model fails to generalize to unseen complex facts or rules, the mechanism breaks.

### Mechanism 3
- Claim: Parameter-efficient fine-tuning (PEFT) via QLoRA is more efficient than full fine-tuning while maintaining performance.
- Mechanism: QLoRA freezes pre-trained model weights and updates only low-rank matrices, reducing the number of parameters to train.
- Core assumption: Low-rank adaptation can capture the necessary changes for logical consistency without full model retraining.
- Evidence anchors:
  - [abstract] "We showcase that pre-train, prompt, and predict paradigm is often insufficient to improve the consistency of LLMs for complex fact-checking with KG contexts, thus we resort to pre-train, fine-tune, and predict approach."
  - [section] "Our empirical results demonstrate that PEFT is 3X more efficient than full fine-tuning for logical consistency."
- Break condition: If the low-rank approximation fails to capture necessary logical reasoning patterns, PEFT breaks down.

## Foundational Learning

- Concept: Propositional Logic and Knowledge Graphs
  - Why needed here: The paper assesses logical consistency on propositional logic queries over knowledge graph facts.
  - Quick check question: Can you explain how a conjunction of two atomic facts differs from their disjunction in terms of truth values?

- Concept: Consistency Measurement
  - Why needed here: The paper proposes specific measures to quantify LLM logical consistency.
  - Quick check question: How would you verify that an LLM is consistent on negation using the proposed measure?

- Concept: Supervised Fine-tuning
  - Why needed here: The paper uses supervised fine-tuning to improve LLM logical consistency.
  - Quick check question: What is the difference between zero-shot prompting and supervised fine-tuning in the context of this paper?

## Architecture Onboarding

- Component map:
  - Knowledge Graph (KG) as context source
  - LLM as fact-checking model
  - Consistency measurement module
  - Supervised fine-tuning pipeline
  - Parameter-efficient fine-tuning (PEFT) via QLoRA

- Critical path:
  1. Retrieve relevant KG context for a fact-checking query
  2. Generate LLM response to the query with context
  3. Measure logical consistency of the response
  4. If consistency is insufficient, perform supervised fine-tuning
  5. Evaluate fine-tuned model on consistency metrics

- Design tradeoffs:
  - BFS vs. vector embedding for context retrieval (BFS is more interpretable but slower; vector embedding is faster but requires offline preprocessing)
  - Full fine-tuning vs. PEFT (full fine-tuning may achieve better performance but is computationally expensive; PEFT is more efficient but may have slightly lower performance)
  - Context length (longer context provides more information but may degrade LLM performance; shorter context is more efficient but may miss relevant information)

- Failure signatures:
  - Low accuracy on simple facts indicates the LLM doesn't understand basic KG facts
  - Low consistency on negation indicates the LLM fails to recognize logical opposites
  - Poor generalization to complex facts indicates the fine-tuning didn't capture necessary logical patterns

- First 3 experiments:
  1. Measure baseline consistency of Llama2-7B on simple negation facts without context
  2. Measure baseline consistency with KG context retrieval via BFS
  3. Fine-tune Llama2-7B on simple facts and measure consistency improvement

## Open Questions the Paper Calls Out
None

## Limitations
- The generalizability of consistency measures to logical operators beyond negation, conjunction, and disjunction remains untested
- The impact of KG context retrieval methods on consistency measurements needs further exploration, particularly regarding scalability
- The efficiency claims regarding PEFT may vary significantly depending on model size, dataset characteristics, and hardware configurations

## Confidence

- **High Confidence**: The paper demonstrates that existing LLMs exhibit logical inconsistency on fact-checking queries, particularly with negation, conjunction, and disjunction. The consistency measures are well-defined and the experimental results showing improvement through fine-tuning are reproducible.
- **Medium Confidence**: The effectiveness of supervised fine-tuning for improving logical consistency is supported by experimental results, but the extent of generalization to more complex facts and rules requires further validation across different domains and KG schemas.
- **Low Confidence**: The efficiency claims regarding PEFT (3X more efficient than full fine-tuning) are based on limited empirical results and may vary significantly depending on model size, dataset characteristics, and hardware configurations.

## Next Checks

1. **Dataset Coverage Validation**: Evaluate the proposed consistency measures on additional logical operators (implication, biconditional) and validate whether the constructed datasets adequately represent the logical complexity of real-world knowledge graphs.

2. **Context Retrieval Impact Study**: Systematically compare the impact of BFS and vector embedding methods on consistency measurements across different KG sizes and densities to determine optimal context retrieval strategies.

3. **Cross-Domain Generalization Test**: Apply the fine-tuned models to knowledge graphs from different domains (e.g., biomedical, financial) and evaluate whether logical consistency improvements generalize beyond the original Freebase, NELL, and WikiKG datasets.