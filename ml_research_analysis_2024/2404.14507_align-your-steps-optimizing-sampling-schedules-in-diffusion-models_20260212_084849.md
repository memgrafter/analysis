---
ver: rpa2
title: 'Align Your Steps: Optimizing Sampling Schedules in Diffusion Models'
arxiv_id: '2404.14507'
source_url: https://arxiv.org/abs/2404.14507
tags:
- schedule
- diffusion
- sampling
- schedules
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Align Your Steps (AYS) optimizes sampling schedules for diffusion
  models by minimizing discretization errors between stochastic solvers and the true
  generative SDE using techniques from stochastic calculus. The method formulates
  schedule optimization as minimizing an upper bound on the KL-divergence between
  the true and linearized generative SDEs.
---

# Align Your Steps: Optimizing Sampling Schedules in Diffusion Models

## Quick Facts
- arXiv ID: 2404.14507
- Source URL: https://arxiv.org/abs/2404.14507
- Authors: Amirmojtaba Sabour; Sanja Fidler; Karsten Kreis
- Reference count: 40
- Primary result: Optimizes sampling schedules for diffusion models using stochastic calculus, achieving up to 1.5x speedup while maintaining comparable FID scores across multiple datasets and models

## Executive Summary
Align Your Steps (AYS) addresses the critical challenge of optimizing sampling schedules in diffusion models to reduce discretization errors between stochastic solvers and true generative SDEs. The method formulates schedule optimization as minimizing an upper bound on KL-divergence between true and linearized SDEs, leveraging techniques from stochastic calculus. Through extensive experiments across diverse datasets (CIFAR10, FFHQ, ImageNet) and models (Stable Diffusion 1.5, SDXL, Stable Video Diffusion), AYS demonstrates significant improvements in output quality, particularly in low NFE regimes, while generalizing across different solver types and data modalities.

## Method Summary
The method optimizes sampling schedules by iteratively minimizing an upper bound on KL-divergence between the true generative SDE and the solver's linearized approximation. Starting with a coarse 10-step schedule, the approach uses zeroth-order optimization with Monte Carlo integration and importance sampling to estimate the KLUB. The optimization proceeds hierarchically, refining intermediate points and doubling the schedule length through subdivision steps. The framework assumes stochastic SDE solvers but empirically generalizes to ODE solvers as well, with early stopping preventing over-optimization of the upper bound objective.

## Key Results
- Optimized schedules achieve up to 1.5x speedup while maintaining comparable FID scores to baseline heuristic schedules
- Schedules generalize across different stochastic and deterministic solvers despite being derived for specific solver types
- Significant improvements in output quality, especially in low NFE regimes, across multiple datasets and models
- Method successfully applied to diverse data modalities including images and videos

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The optimized sampling schedule reduces discretization error between the true generative SDE and the solver's linearized approximation.
- Mechanism: The method formulates schedule optimization as minimizing an upper bound on KL-divergence between true and linearized SDEs, using stochastic calculus to quantify the mismatch.
- Core assumption: The linearized SDE solved by stochastic solvers closely approximates the true generative SDE within each subinterval.
- Evidence anchors:
  - [abstract]: "We leverage methods from stochastic calculus and find optimal schedules specific to different solvers, trained DMs and datasets."
  - [section 3.2]: "We analyze the error introduced by discretizing the interval of the SDE into n sub-intervals that define the sampling schedule, and formulate finding an optimal schedule as an optimization problem which can be solved iteratively."
- Break condition: If the linearization assumption breaks down for certain solvers or the KLUB no longer bounds the actual discretization error accurately.

### Mechanism 2
- Claim: The optimized schedules generalize across different stochastic and deterministic solvers despite being derived for specific solvers.
- Mechanism: The schedules are optimized using the KLUB derived for stochastic solvers, but empirical results show these schedules improve performance even for ODE solvers.
- Core assumption: The discretization error patterns captured by the KLUB optimization are similar enough across solver types to benefit from shared schedules.
- Evidence anchors:
  - [abstract]: "The method generalizes across different stochastic and deterministic solvers and various data modalities including images and videos."
  - [section 3.2]: "Although the framework assumes the use of stochastic SDE solvers, we empirically find that the optimized schedules generalize to several popular ODE solvers as well."
- Break condition: If certain ODE solvers have fundamentally different discretization error characteristics that make KLUB-optimized schedules suboptimal.

### Mechanism 3
- Claim: The hierarchical optimization approach with early stopping prevents over-optimization of the upper bound objective.
- Mechanism: The optimization starts with coarse schedules, iteratively refines intermediate points, and uses early stopping to prevent fitting the KLUB upper bound at the expense of actual output quality.
- Core assumption: The KLUB upper bound is not tight enough that minimizing it directly leads to optimal output distributions.
- Evidence anchors:
  - [section 3.3]: "After this process is finished, two rounds of subdivision and further fine-tuning are performed to obtain a 40-step schedule."
  - [appendix A.3]: "Using the KLUB objective to optimize the schedule does not translate directly into minimizing the mismatch between final output distributions."
- Break condition: If the KLUB bound becomes tight enough that direct minimization would be beneficial, making early stopping counterproductive.

## Foundational Learning

- Concept: Stochastic differential equations and their numerical solution
  - Why needed here: The entire framework is built on interpreting diffusion model sampling as solving SDEs backwards in time.
  - Quick check question: What is the key difference between solving an SDE and an ODE in the context of diffusion models?

- Concept: Girsanov's theorem and KL-divergence upper bounds
  - Why needed here: These mathematical tools are used to quantify the mismatch between the true SDE and the solver's linearized approximation.
  - Quick check question: How does Girsanov's theorem allow us to compare two SDEs with the same diffusion term?

- Concept: Importance sampling for variance reduction
  - Why needed here: Used to efficiently estimate the KLUB during optimization by sampling time points according to their contribution to the error.
  - Quick check question: Why does importance sampling significantly reduce variance when estimating the KLUB compared to naive Monte Carlo?

## Architecture Onboarding

- Component map: Denoiser model -> KLUB estimation with importance sampling -> Schedule optimization (hierarchical with early stopping) -> Evaluation metrics
- Critical path: Pretrained denoiser → KLUB estimation with importance sampling → Schedule optimization (hierarchical with early stopping) → Evaluation on target dataset/model
- Design tradeoffs: Zeroth-order optimization vs. gradient-based methods (simplicity vs. potential speed), coarse-to-fine optimization vs. direct optimization (stability vs. precision), KLUB objective vs. direct output quality optimization (principled approach vs. potentially better results)
- Failure signatures: Over-optimization leading to worse perceptual quality despite lower KLUB, poor generalization to new models or solvers, instability during hierarchical optimization steps
- First 3 experiments:
  1. Optimize schedule for CIFAR10 with SDE-DPM-Solver++ and compare against EDM baseline using FID
  2. Test if KLUB-optimized schedule for stochastic solver also improves DDIM performance
  3. Evaluate schedule generalization by using CIFAR10-optimized schedule on FFHQ model

## Open Questions the Paper Calls Out
None

## Limitations
- The theoretical justification for why schedules optimized using stochastic solver KLUBs also improve deterministic ODE solver performance remains incomplete
- Zeroth-order optimization may converge to suboptimal schedules compared to gradient-based methods, particularly for high-dimensional schedule optimization problems
- Scalability to extremely large models or high-resolution generation tasks (512x512, 1024x1024) remains unverified

## Confidence

*High confidence:* The empirical demonstration that optimized schedules outperform heuristic baselines across multiple datasets and models is well-supported by the experimental results. The claim that optimized schedules achieve comparable FID scores with fewer steps (up to 1.5x speedup) is directly validated through controlled experiments comparing against EDM and time-uniform schedules.

*Medium confidence:* The claim about generalization across different solver types (stochastic and deterministic) is supported by experiments but lacks complete theoretical justification. The hierarchical optimization approach with early stopping is described but the exact criteria for early stopping and the impact of different neighborhood ranges on optimization quality are not fully specified.

*Low confidence:* The assertion that the method generalizes to video diffusion models and large-scale text-to-image models like Stable Diffusion and SDXL is based on limited experimental evidence, with only one or two datasets per model type evaluated. The scalability of the approach to extremely large models or high-resolution generation tasks remains unverified.

## Next Checks

1. **Solver-specific validation**: Test whether schedules optimized for stochastic solvers actually degrade performance on certain ODE solvers where the linearization assumption may not hold, by systematically comparing ODE solver performance across schedules optimized for different solver types.

2. **KLUB tightness analysis**: Measure the correlation between KLUB values during optimization and actual output quality metrics (FID, perceptual quality) across different optimization stages to quantify how tight the upper bound is and whether direct minimization would be more effective.

3. **Scalability assessment**: Evaluate the method on higher-resolution image generation tasks (e.g., 512x512 or 1024x1024) and longer sequence video generation to determine if the optimization approach scales effectively to more challenging generation tasks with larger state spaces.