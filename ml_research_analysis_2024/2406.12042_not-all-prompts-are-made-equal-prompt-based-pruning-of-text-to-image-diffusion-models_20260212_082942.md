---
ver: rpa2
title: 'Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion
  Models'
arxiv_id: '2406.12042'
source_url: https://arxiv.org/abs/2406.12042
tags:
- architecture
- diffusion
- pruning
- prompt
- aptp
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes APTP, a prompt-based pruning method for text-to-image
  diffusion models that outperforms static pruning baselines by assigning prompts
  to specialized experts based on semantic similarity. The method uses a prompt router
  with contrastive learning and optimal transport to map prompts to architecture codes,
  which define pruned sub-networks tailored to specific prompt types.
---

# Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion Models

## Quick Facts
- arXiv ID: 2406.12042
- Source URL: https://arxiv.org/abs/2406.12042
- Authors: Alireza Ganjdanesh; Reza Shirkavand; Shangqian Gao; Heng Huang
- Reference count: 40
- Primary result: APTP outperforms static pruning baselines with up to 23% latency reduction while maintaining better image quality

## Executive Summary
This paper introduces APTP, a prompt-based pruning method for text-to-image diffusion models that assigns prompts to specialized experts based on semantic similarity. Unlike static pruning approaches, APTP dynamically routes prompts to sub-networks with appropriate computational capacity based on their complexity. The method combines contrastive learning and optimal transport to train a prompt router that maps prompts to architecture codes, which define specialized pruned sub-networks. Experiments on CC3M and COCO datasets demonstrate that APTP achieves better FID, CLIP, and CMMD scores than static pruning while reducing computational cost.

## Method Summary
APTP employs a prompt router that maps input prompts to specialized architecture codes using contrastive learning and optimal transport. The prompt encoder (Sentence Transformer) converts text prompts to embeddings, which are then transformed by an architecture predictor into architecture embeddings. A router module uses optimal transport to assign prompts to architecture codes, ensuring even distribution across experts. These codes define specialized sub-networks that are pruned from the base Stable Diffusion 2.1 model. The framework is trained using a denoising objective, distillation loss, resource usage regularization, and contrastive objective to ensure semantically similar prompts map to similar sub-networks while maintaining diversity.

## Key Results
- APTP achieves better FID, CLIP, and CMMD scores than static pruning baselines
- Reduces latency by up to 23% while maintaining image quality
- Automatically identifies semantically meaningful prompt clusters (e.g., text and human images routed to higher-capacity experts)
- Shows consistent improvements across both CC3M and COCO datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Prompt-based pruning adapts model capacity to prompt complexity.
- **Mechanism:** The prompt router maps input prompts to specialized sub-networks (architecture codes) based on semantic similarity, allocating higher capacity to complex prompts and lower capacity to simpler ones.
- **Core assumption:** Prompts with similar semantic content benefit from similar architectural configurations.
- **Evidence anchors:**
  - [abstract] "assigns prompts to specialized experts based on semantic similarity"
  - [section] "The prompt router learns to determine the required capacity for an input text prompt and routes it to an architecture code"
- **Break condition:** If prompts with similar semantics require vastly different capacities, or if semantic similarity doesn't correlate with architectural needs.

### Mechanism 2
- **Claim:** Contrastive learning ensures similar prompts map to similar architecture codes.
- **Mechanism:** The architecture predictor is trained with a contrastive objective that regularizes it to map prompt embeddings to architecture embeddings that preserve semantic similarity, ensuring similar prompts get routed to similar experts.
- **Core assumption:** The contrastive objective effectively captures the relationship between prompt semantics and architectural requirements.
- **Evidence anchors:**
  - [section] "We train the prompt router and architecture codes using contrastive learning, ensuring that similar prompts are mapped to nearby codes"
  - [section] "The architecture predictor transforms prompt embeddings z into architecture embeddings e...ensuring similar prompts are mapped to similar sub-networks"
- **Break condition:** If the contrastive objective fails to capture the true relationship between prompt semantics and architectural needs, or if the embedding space becomes too noisy.

### Mechanism 3
- **Claim:** Optimal transport prevents architecture code collapse and ensures diversity.
- **Mechanism:** Optimal transport evenly distributes prompts across architecture codes during training, preventing them from collapsing into a single code and ensuring diverse experts with varying computational requirements.
- **Core assumption:** Equal assignment of prompts to architecture codes during training leads to diverse and effective experts.
- **Evidence anchors:**
  - [section] "We employ optimal transport to prevent the codes from collapsing into a single one"
  - [section] "We employ optimal transport in our router module during the pruning phase...ensuring that each architecture code gets enough samples for training"
- **Break condition:** If the optimal transport assignment doesn't lead to diverse experts, or if some experts receive insufficient training samples despite the assignment.

## Foundational Learning

- **Concept:** Diffusion Models
  - **Why needed here:** Understanding the base model being pruned and how it generates images.
  - **Quick check question:** What is the forward and reverse process in diffusion models, and how do they relate to image generation?

- **Concept:** Model Pruning
  - **Why needed here:** Understanding the techniques used to reduce model size and computational cost.
  - **Quick check question:** What are the differences between static and dynamic pruning, and why is static pruning insufficient for T2I models?

- **Concept:** Contrastive Learning
  - **Why needed here:** Understanding the objective function used to train the prompt router and ensure semantic similarity mapping.
  - **Quick check question:** How does contrastive learning work, and why is it effective for learning representations that preserve semantic similarity?

## Architecture Onboarding

- **Component map:** Prompt Encoder -> Architecture Predictor -> Router -> Architecture Code -> Pruned T2I Model
- **Critical path:** Input prompt → Prompt Encoder → Architecture Predictor → Router → Architecture Code → Pruned T2I Model → Generated Image
- **Design tradeoffs:**
  - Number of experts vs. performance and efficiency
  - Granularity of pruning (width vs. depth) vs. impact on quality
  - Complexity of prompt router vs. effectiveness of specialization
- **Failure signatures:**
  - Poor FID/CLIP scores indicating ineffective pruning
  - Uneven distribution of prompts across experts indicating router issues
  - Collapse of architecture codes indicating optimal transport failure
- **First 3 experiments:**
  1. Implement the prompt router with a simple nearest-neighbor approach and compare to the optimal transport version.
  2. Vary the number of experts and evaluate the impact on performance and efficiency.
  3. Experiment with different pruning strategies (width-only, depth-only, combined) and measure their impact on image quality.

## Open Questions the Paper Calls Out
None

## Limitations
- The relationship between prompt semantics and architectural requirements is assumed but not fully validated
- Optimal transport's role in ensuring diverse experts is primarily theoretical
- Computational efficiency claims are limited to A100 GPU measurements and may not generalize to different hardware

## Confidence
- High confidence in: The basic premise that prompt-based pruning can outperform static pruning baselines, as supported by quantitative metrics (FID, CLIP, CMMD) and qualitative analysis of semantic clusters.
- Medium confidence in: The specific mechanisms of contrastive learning and optimal transport achieving their stated objectives, as these rely on assumptions about the relationship between prompt