---
ver: rpa2
title: 'Don''t Half-listen: Capturing Key-part Information in Continual Instruction
  Tuning'
arxiv_id: '2403.10056'
source_url: https://arxiv.org/abs/2403.10056
tags:
- instruction
- tasks
- train
- task
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting and the "half-listening"
  problem in continual instruction tuning for large language models, where models
  forget previously learned tasks and overfit to surface-level instruction patterns.
  The proposed method, Key-part Information Gain (KPIG), computes information gain
  on masked key parts to dynamically replay historical data and refine the training
  objective, enabling models to focus on task-aware information rather than general
  descriptions.
---

# Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning

## Quick Facts
- **arXiv ID**: 2403.10056
- **Source URL**: https://arxiv.org/abs/2403.10056
- **Reference count**: 40
- **Primary result**: KPIG achieves state-of-the-art performance on both seen and held-out tasks with improved instruction-following ability and reduced violations

## Executive Summary
This paper addresses catastrophic forgetting and the "half-listening" problem in continual instruction tuning for large language models. The proposed Key-part Information Gain (KPIG) method computes information gain on masked key parts to dynamically replay historical data and refine the training objective, enabling models to focus on task-aware information rather than surface-level patterns. Experiments on Super-NaturalInstructions and a Chinese domain dataset show KPIG achieves state-of-the-art performance with significantly improved instruction-following ability and reduced violations such as out-of-scope responses and incorrect formats.

## Method Summary
The KPIG method introduces instruction diversity through GPT-4-based rewriting, key-part extraction and masking, information gain computation, and dynamic replay selection. At each time step, tasks with the lowest information gain are selected for replay, ensuring the model revisits the most challenging or poorly learned tasks. The training objective is refined using Jensen-Shannon divergence on masked instructions to maintain original capabilities while learning new tasks. Two novel evaluation metrics, P-score (generalization ability) and V-score (instruction-following ability), are introduced to comprehensively assess model performance.

## Key Results
- KPIG achieves state-of-the-art performance on both seen and held-out tasks in continual instruction tuning scenarios
- The method significantly improves instruction-following ability, reducing violations such as out-of-scope responses and incorrect formats
- P-score and V-score metrics demonstrate superior generalization and instruction-following compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Key-part masking enables the model to focus on task-relevant information rather than surface-level patterns.
- Mechanism: By masking key parts in instructions and computing information gain, the model learns to identify and prioritize the most relevant parts of the instruction for generating correct responses.
- Core assumption: The key parts of instructions contain the most task-relevant information that directly influences the content, length, and format of the ground truth.
- Evidence anchors: [abstract] states the method "enables LLMs to capture task-aware information relevant to the correct response" and [section 3.3] describes computing information gain by masking key parts.

### Mechanism 2
- Claim: Dynamic replay based on information gain prevents catastrophic forgetting while improving generalization.
- Mechanism: At each time step, tasks with the lowest information gain are selected for replay, ensuring that the model revisits the most challenging or poorly learned tasks.
- Core assumption: Information gain is an effective indicator of how well a task is learned and can guide selective replay to prevent forgetting.
- Evidence anchors: [abstract] mentions computing information gain "to dynamically replay data" and [section 3.3] describes selecting tasks with lowest mean IG for replay.

### Mechanism 3
- Claim: Instruction diversity through key-part rewriting improves the model's ability to handle varied instructions.
- Mechanism: Using GPT-4 to rewrite instructions while preserving key parts creates diverse instruction variations that help the model learn to focus on task-relevant information regardless of surface-level differences.
- Core assumption: Diverse instruction representations help the model learn task-agnostic patterns rather than memorizing specific instruction formats.
- Evidence anchors: [abstract] mentions rewriting instructions to "diversify the combination of key parts and general descriptions" and [section 3.2] describes using GPT-4 for this purpose.

## Foundational Learning

- **Concept**: Information Gain as a measure of task-aware ability
  - Why needed here: KPIG relies on calculating information gain to determine which tasks need replay and how to adjust the training objective dynamically.
  - Quick check question: How would you compute information gain for a masked instruction, and what does it tell you about the model's understanding of that task?

- **Concept**: Catastrophic Forgetting in Continual Learning
  - Why needed here: The paper addresses catastrophic forgetting as the primary problem that KPIG aims to solve in continual instruction tuning scenarios.
  - Quick check question: What are the main strategies to prevent catastrophic forgetting, and how does KPIG's approach differ from traditional methods?

- **Concept**: Key-part identification and masking
  - Why needed here: The core mechanism of KPIG depends on correctly identifying and masking key parts of instructions to compute information gain and adjust training.
  - Quick check question: What criteria would you use to identify key parts in an instruction, and how would you validate that your identification is accurate?

## Architecture Onboarding

- **Component map**: Foundation LLM -> Instruction diversity module -> Key-part extraction and masking system -> Information gain computation engine -> Dynamic replay selector -> Training objective refinement module -> Evaluation pipeline
- **Critical path**: Instruction → Key-part extraction → Masking → Information gain computation → Replay selection → Training with refined objective → Evaluation
- **Design tradeoffs**:
  - Memory vs. Performance: Storing multiple versions of instructions vs. computing them on-the-fly
  - Complexity vs. Effectiveness: More sophisticated key-part identification vs. simpler heuristics
  - Compute cost vs. Accuracy: Using GPT-4 for instruction diversity vs. rule-based approaches
- **Failure signatures**:
  - Poor P-score/V-score performance indicates issues with key-part identification or replay strategy
  - High variance in information gain across similar tasks suggests inconsistent masking
  - Slow convergence or training instability may indicate problems with the dynamic temperature adjustment
- **First 3 experiments**:
  1. Validate key-part identification accuracy by comparing GPT-4 extractions against human annotations on a small sample of instructions
  2. Test information gain calculation by comparing masked vs. unmasked instruction performance on held-out tasks
  3. Evaluate replay effectiveness by measuring catastrophic forgetting with and without the dynamic replay mechanism on sequential task training

## Open Questions the Paper Calls Out

1. The gap between manual writing and automated key-part extraction in controllability and accuracy is not fully evaluated
2. There may be other constraints or ways for evaluating instruction-following ability that deserve consideration
3. The effects of masking other parts (e.g., context, demonstrations) within instances can be explored
4. The implications of mask information gain on other natural language processing tasks involving LLMs
5. Dynamically adjusting hyperparameters (λ and α) according to IG may be more rigorous
6. The gap between this method and manual writing in controllability and accuracy is not fully evaluated
7. These phenomena merit further exploration such as more carefully designed data construction
8. These phenomena merit further exploration such as staged training
9. Saliency score patterns in different task types (e.g., compared to classification-task 1645 vs generation-task 1664)
10. Accuracy of GPT-4 key-part identification for tasks with fewer constraints and definitions
11. Alternative constraint annotation methods for evaluating instruction-following ability
12. Validation of manual annotation process quality and consistency

## Limitations

- Reliance on GPT-4 for instruction diversity introduces a significant dependency that may not be replicable with other language models
- The effectiveness of key-part identification heavily depends on GPT-4's extraction quality, which could vary across domains
- The paper does not thoroughly explore the computational overhead of KPIG compared to simpler continual learning approaches

## Confidence

- **High confidence** in the core claim that KPIG addresses catastrophic forgetting through dynamic replay based on information gain, supported by experimental results on both English and Chinese datasets
- **Medium confidence** in the assertion that key-part masking specifically improves generalization and instruction-following ability, as the metrics (P-score and V-score) are novel
- **Low confidence** in the scalability of the method to larger models or more diverse task distributions, as experiments were limited to 7B parameter models

## Next Checks

1. **Cross-domain validation**: Test KPIG on a dataset with significantly different instruction structures (e.g., technical documentation or conversational tasks) to verify the robustness of key-part identification and masking
2. **Ablation study**: Conduct a detailed ablation study removing the GPT-4-based instruction diversity to isolate the contribution of key-part masking and information gain computation to overall performance
3. **Resource efficiency analysis**: Measure and compare the computational overhead (training time, memory usage) of KPIG against baseline continual learning methods to assess practical applicability