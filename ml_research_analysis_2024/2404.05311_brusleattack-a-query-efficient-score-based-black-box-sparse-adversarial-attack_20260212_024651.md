---
ver: rpa2
title: 'BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack'
arxiv_id: '2404.05311'
source_url: https://arxiv.org/abs/2404.05311
tags:
- attack
- sparse
- image
- sparsity
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes BruSLeAttack, a query-efficient score-based
  black-box sparse adversarial attack method. It addresses the challenge of generating
  sparse adversarial examples by observing score-based replies to model queries, which
  is an NP-hard problem due to the non-differentiable search space.
---

# BruSLeAttack: A Query-Efficient Score-Based Black-Box Sparse Adversarial Attack

## Quick Facts
- arXiv ID: 2404.05311
- Source URL: https://arxiv.org/abs/2404.05311
- Reference count: 40
- Proposes a query-efficient score-based black-box sparse adversarial attack method

## Executive Summary
BruSLeAttack addresses the challenge of generating sparse adversarial examples through score-based queries in black-box settings. The method introduces a lower-dimensional search space combined with a Bayesian framework to identify influential pixels and select perturbations based on pixel dissimilarity. By leveraging score-based responses rather than direct gradients, BruSLeAttack achieves state-of-the-art attack success rates while maintaining query efficiency, particularly at lower sparsity levels.

## Method Summary
The proposed method tackles the NP-hard problem of sparse adversarial attacks by reducing the search space dimensionality and employing a Bayesian framework. It learns influential pixel information through iterative queries and selects perturbations based on the dissimilarity between the search space and source image. The approach specifically addresses the non-differentiable nature of sparse attack spaces in black-box settings where only score-based feedback is available.

## Key Results
- Achieves state-of-the-art attack success rates on ImageNet
- Demonstrates superior query efficiency compared to baseline methods
- Shows particularly strong performance at lower sparsity levels

## Why This Works (Mechanism)
The method works by transforming the high-dimensional sparse attack problem into a more tractable lower-dimensional search space. The Bayesian framework enables efficient learning of pixel influence through score-based queries, while the pixel dissimilarity metric guides perturbation selection. This combination allows the attack to navigate the non-differentiable search space effectively while maintaining sparsity constraints.

## Foundational Learning
- Bayesian optimization - why needed: Efficiently explores search space with limited queries; quick check: convergence rate on synthetic functions
- Score-based black-box attacks - why needed: Real-world scenarios where gradients are unavailable; quick check: success rate vs query budget
- Sparse adversarial perturbations - why needed: Creates more realistic, less detectable attacks; quick check: sparsity-accuracy tradeoff curve
- Pixel dissimilarity metrics - why needed: Guides perturbation selection in reduced space; quick check: correlation with attack success
- Lower-dimensional search spaces - why needed: Reduces computational complexity; quick check: dimensionality vs performance tradeoff

## Architecture Onboarding

**Component Map:** Input Image -> Lower-Dimensional Search Space -> Bayesian Framework -> Pixel Dissimilarity Metric -> Perturbation Selection -> Adversarial Example

**Critical Path:** Image preprocessing → Search space projection → Bayesian pixel influence learning → Dissimilarity-based perturbation → Query generation → Score evaluation → Update Bayesian model

**Design Tradeoffs:** Dimensionality reduction vs. attack fidelity; query efficiency vs. success rate; sparsity level vs. perturbation perceptibility

**Failure Signatures:** High query counts with low success rates; perturbations concentrated in non-influential regions; premature convergence to suboptimal solutions

**3 First Experiments:** 1) Ablation test removing Bayesian component to measure its contribution, 2) Sensitivity analysis varying search space dimensionality, 3) Comparison of different pixel dissimilarity metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation primarily to standard computer vision tasks like ImageNet
- Lacks comprehensive ablation studies of individual component contributions
- No comparison with recent alternative sparse attack approaches published after BruSLeAttack

## Confidence
High confidence in achieving state-of-the-art attack success rates and query efficiency for sparse adversarial attacks.

## Next Checks
1. Conduct ablation studies to quantify the contribution of the Bayesian framework versus the lower-dimensional search space component
2. Test scalability and performance on higher-resolution images and non-standard datasets
3. Compare against recent state-of-the-art sparse attack methods published after BruSLeAttack to ensure continued competitive performance