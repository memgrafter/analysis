---
ver: rpa2
title: A Bayesian explanation of machine learning models based on modes and functional
  ANOVA
arxiv_id: '2411.02746'
source_url: https://arxiv.org/abs/2411.02746
tags:
- deviation
- value
- mode
- values
- mean
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Bayesian framework for explaining deviations
  of machine learning model predictions from their modes, addressing a gap in explainable
  AI where most methods focus on feature impacts on predictions rather than explaining
  why predictions deviate from expected values. The method uses Bayesian inference
  to recover "true" feature values conditioned on observed label deviations, then
  employs ANOVA functional decomposition to quantify feature contributions through
  "responsible scores" based on distances from mode values rather than means.
---

# A Bayesian explanation of machine learning models based on modes and functional ANOVA

## Quick Facts
- arXiv ID: 2411.02746
- Source URL: https://arxiv.org/abs/2411.02746
- Reference count: 7
- Introduces Bayesian framework for explaining deviations of ML model predictions from modes using responsible scores

## Executive Summary
This paper presents a novel Bayesian framework for explainable AI that focuses on explaining why machine learning model predictions deviate from their modes rather than their means. The method uses Bayesian inference to recover "true" feature values conditioned on observed label deviations, then employs ANOVA functional decomposition to quantify feature contributions through "responsible scores" based on distances from mode values. This mode-based approach is shown to be more robust and human-intuitive than traditional methods like SHAP, particularly in multimodal scenarios.

## Method Summary
The method combines Bayesian inverse computation with ANOVA functional decomposition to explain label deviations from mode values. It computes posterior distributions of features given observed labels, finds MAP estimates of mode values using direct search, and estimates ANOVA functions through Monte Carlo sampling. The approach generates mode-specific responsible scores that quantify each feature's contribution to label deviations, providing more intuitive explanations than mean-based approaches.

## Key Results
- Mode-based responsible scores provide more intuitive feature rankings than mean-based SHAP values in multimodal synthetic data
- The approach demonstrates stable explanations in river flow prediction while SHAP values become unstable near mean values
- Computational cost is dimension-independent, making the method scalable to high-dimensional problems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bayesian inverse explanation recovers "true" feature values conditioned on observed label deviations
- Mechanism: Uses Bayes theorem to compute posterior distribution p(xi|yi) = p(yi|xi)p(xi)/p(yi), where likelihood p(yi|xi) measures model fit and prior p(xi) encodes feature distributions
- Core assumption: The model f(x,θ*) accurately represents the relationship between features and labels, and the likelihood function correctly captures prediction errors
- Evidence anchors:
  - [abstract] "We use a Bayesian framework to recover the 'true' features, conditioned on the observed label value"
  - [section 2] "We use the following form of Bayes theorem to inversely compute the distributions of the features, conditioned on the observed labels"
  - [corpus] Weak evidence - related papers discuss Bayesian approaches to ANOVA but not this specific inverse problem formulation
- Break condition: Model f is misspecified or likelihood function doesn't capture actual prediction error distribution

### Mechanism 2
- Claim: Mode-based deviation decomposition provides more intuitive and robust explanations than mean-based approaches
- Mechanism: Decomposes label deviation from mode δm_i = yi - y*m using ANOVA functional decomposition, where each feature's contribution is measured by distance from mode rather than mean
- Core assumption: Mode is a more meaningful reference point than mean for understanding label deviations, especially in multimodal distributions
- Evidence anchors:
  - [abstract] "We efficiently explain the deviation of a label value from the mode, by identifying and ranking the influential features using the 'distances' in the ANOVA functional decomposition"
  - [section 3.1] "Instead of using sample-mean-based approach, we use the modes. The mode-based approach provides salient robustness"
  - [section 5.1] Experimental results show mode-based scores provide more intuitive feature rankings in multimodal synthetic data
- Break condition: Data distribution is symmetric and unimodal where mean and mode coincide

### Mechanism 3
- Claim: Dimension-independent computational cost makes method scalable to high-dimensional problems
- Mechanism: Uses direct search method that finds MAP estimates through a series of optimization problems with computational cost bounded by no ≥ log β - log K / log(1 - p), where the number of runs is dimension-independent
- Core assumption: The number of local optima K and convergence probability p are not strongly dependent on feature dimensionality
- Evidence anchors:
  - [abstract] "The extra costs of solving a Bayesian inverse problem are dimension-independent"
  - [section 3.2] "Long (2022) shown that the number of necessary runs is a dimension-independent value bounded by the inequality"
  - [corpus] No direct evidence in related papers about dimension-independent scaling for this specific method
- Break condition: Feature space becomes extremely high-dimensional with exponentially many local optima

## Foundational Learning

- Concept: Bayesian inference and posterior computation
  - Why needed here: The entire explanation framework relies on computing p(xi|yi) to recover "true" feature values
  - Quick check question: Given prior p(x) ~ N(0,1) and likelihood p(y|x) ~ N(x, 0.5²), what is the posterior distribution for x given y=2?

- Concept: ANOVA functional decomposition
  - Why needed here: Used to break down label deviation into contributions from individual features and their interactions
  - Quick check question: For f(x,y) = x + y + xy, write out the ANOVA decomposition terms f0, f_x, f_y, and f_xy

- Concept: Maximum a posteriori (MAP) estimation
  - Why needed here: Required to find mode values and "true" feature values through optimization
  - Quick check question: For posterior p(x|y) ∝ e^(-x²/2) * e^(-(y-x)²/4), what is the MAP estimate of x given y=1?

## Architecture Onboarding

- Component map:
  - Data preprocessing: Feature extraction, normalization, mode detection
  - Model training: Any ML model (linear regression, XGBoost, neural network)
  - Bayesian inverse computation: MAP estimation for modes and feature values
  - ANOVA decomposition: Monte Carlo estimation of conditional expectations
  - Scoring engine: Computation of mode-specific responsible scores
  - Visualization layer: Feature importance ranking and explanation display

- Critical path:
  1. Train ML model on original data
  2. Detect modes in label distribution
  3. For each observation:
     - Compute MAP estimate of "true" features given label
     - Compute MAP estimate of mode reference features
     - Estimate ANOVA functional decomposition
     - Calculate responsible scores
  4. Rank features by contribution magnitude

- Design tradeoffs:
  - Computational cost vs accuracy: More Monte Carlo samples improve ANOVA estimation but increase runtime
  - Mode detection sensitivity: Different clustering methods may identify different numbers of modes
  - Model choice flexibility: Method works with any ML model but different models may require different optimization strategies

- Failure signatures:
  - Unstable responsible scores near mean values (indicates mode-based approach advantage)
  - High variance in Monte Carlo ANOVA estimates (indicates need for more samples)
  - Multiple local optima in MAP estimation (indicates need for more optimization runs)
  - Poor model fit (indicates fundamental approach breakdown)

- First 3 experiments:
  1. Synthetic linear data with known ground truth: Verify that responsible scores correctly identify feature contributions
  2. Multimodal synthetic data: Compare mode-based vs mean-based explanations for intuitive rankings
  3. Real-world river flow data: Validate stability of explanations compared to SHAP values near mean values

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the computational complexity scale with the number of features in high-dimensional problems?
- Basis in paper: [explicit] The paper states that "The extra costs of solving a Bayesian inverse problem are dimension-independent," but this refers to the number of optimization runs needed to find the MAP, not the overall complexity.
- Why unresolved: The paper doesn't provide detailed analysis of how computational cost scales with dimensionality beyond the optimization runs, particularly for the ANOVA decomposition estimation step.
- What evidence would resolve it: Empirical studies showing runtime growth across datasets with increasing feature dimensions, or theoretical analysis of computational complexity for the ANOVA estimation step.

### Open Question 2
- Question: How does the mode-based approach perform when the distribution has multiple modes of similar probability?
- Basis in paper: [inferred] The paper demonstrates effectiveness on a dataset with one dominant mode (y* = 15.7) but doesn't explore scenarios with multiple comparable modes.
- Why unresolved: The paper focuses on cases where one mode clearly dominates the distribution, leaving uncertainty about performance when modes are equally probable.
- What evidence would resolve it: Experiments comparing performance across datasets with different numbers of modes and varying probability distributions among modes.

### Open Question 3
- Question: What is the optimal number of samples needed for reliable ANOVA function estimation using Monte Carlo methods?
- Basis in paper: [inferred] The paper mentions using Monte Carlo sampling for estimating ANOVA functions (Equation 5) but doesn't discuss convergence criteria or sample size requirements.
- Why unresolved: While the paper provides the estimation formula, it doesn't specify how many samples are needed to achieve stable estimates or how this requirement changes with problem complexity.
- What evidence would resolve it: Analysis showing estimation error versus sample size, or guidelines for determining sufficient sample sizes based on data characteristics.

## Limitations
- Limited empirical validation across diverse real-world datasets and model architectures
- Dimension-independent computational cost claim requires further validation on truly high-dimensional problems
- Performance in scenarios with multiple comparable modes not thoroughly explored

## Confidence

- **High Confidence**: The mathematical framework for Bayesian inverse computation and ANOVA decomposition is sound and well-established
- **Medium Confidence**: The dimension-independent computational cost claim based on theoretical bounds, though empirical verification is limited
- **Medium Confidence**: The mode-based approach provides more intuitive explanations than mean-based methods, based on synthetic data experiments
- **Low Confidence**: Generalizability of results across diverse real-world datasets and model architectures

## Next Checks

1. **High-dimensional scaling test**: Apply the method to datasets with 100+ features to empirically verify dimension-independent computational scaling
2. **Cross-architecture comparison**: Compare mode-based explanations against SHAP and other XAI methods across multiple model types (linear, tree-based, neural networks) on diverse datasets
3. **Robustness to mode detection**: Test sensitivity of responsible scores to different mode detection algorithms and clustering parameters in multimodal distributions