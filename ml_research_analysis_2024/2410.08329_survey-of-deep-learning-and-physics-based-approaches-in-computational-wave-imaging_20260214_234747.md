---
ver: rpa2
title: Survey of Deep Learning and Physics-Based Approaches in Computational Wave
  Imaging
arxiv_id: '2410.08329'
source_url: https://arxiv.org/abs/2410.08329
tags:
- data
- imaging
- methods
- learning
- inversion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This review paper provides a comprehensive overview of machine
  learning (ML) methods for computational wave imaging (CWI), a technique used to
  extract hidden structures and physical properties of materials by analyzing wave
  signals. The paper focuses on three main application areas: seismic full-waveform
  inversion (FWI), acoustic and industrial ultrasonic imaging (including non-destructive
  testing), and medical ultrasound computed tomography (USCT).'
---

# Survey of Deep Learning and Physics-Based Approaches in Computational Wave Imaging

## Quick Facts
- arXiv ID: 2410.08329
- Source URL: https://arxiv.org/abs/2410.08329
- Reference count: 40
- Primary result: Comprehensive review of ML methods for computational wave imaging across three main application areas

## Executive Summary
This survey paper provides a comprehensive overview of machine learning methods for computational wave imaging (CWI), a technique used to extract hidden structures and physical properties of materials by analyzing wave signals. The paper focuses on three main application areas: seismic full-waveform inversion (FWI), acoustic and industrial ultrasonic imaging (including non-destructive testing), and medical ultrasound computed tomography (USCT). It categorizes ML methods for CWI into four supervision strategies and four learning strategies, highlighting the importance of incorporating physics into ML models to improve their performance and generalization capabilities.

## Method Summary
The paper reviews over 200 papers from CWI communities, analyzing ML methods based on supervision strategy (fully supervised, semi-supervised, self-supervised, and unsupervised) and learning strategy (simulations/measurements-driven, physics-aware, parameterized solutions, and plug-and-play priors). The review identifies emerging trends including uncertainty quantification (UQ) and generative AI (GenAI) models, discussing their implementation and potential benefits for CWI applications.

## Key Results
- Physics-aware ML models improve generalization by incorporating wave equation constraints into loss functions
- Semi-supervised learning reduces label dependency by generating pseudo-labels from unlabeled data using physics consistency
- Generative AI models reduce ill-posedness by constraining solutions to high-probability manifolds learned from data distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Physics-aware ML models improve generalization by incorporating wave equation constraints into the loss function
- Mechanism: By including the forward wave equation as a differentiable operator in the loss function, the model learns solutions that are consistent with the underlying physics, reducing the solution space and mitigating ill-posedness
- Core assumption: The wave equation accurately represents the physical system and can be effectively incorporated into differentiable ML frameworks
- Evidence anchors:
  - [abstract] "integrating physics into ML models contributes to improved model generalization and robustness"
  - [section] "Incorporating the governing wave equation into ML models has effectively enhanced their performance"
  - [corpus] Weak - no direct evidence in related papers

### Mechanism 2
- Claim: Semi-supervised learning reduces label dependency by generating pseudo-labels from unlabeled data using physics consistency
- Mechanism: Unlabeled waveform data is processed through an initial model to generate velocity maps, which are then validated through forward modeling to create new labeled pairs for training
- Core assumption: The physics-based forward model can generate reliable pseudo-labels from unlabeled data
- Evidence anchors:
  - [section] "The high-level idea is to adapt the training set to the particular waveform d that was measured, by incrementally generating more data samples that are close to the measured data"
  - [section] "The first step is to learn a reconstruction operator g0 from the waveform-data manifold to velocity-map manifold using the original pairwise data"
  - [corpus] Weak - related papers focus on general ML applications but not this specific semi-supervised approach

### Mechanism 3
- Claim: Generative AI models reduce ill-posedness by constraining solutions to high-probability manifolds learned from data distributions
- Mechanism: Diffusion models learn the probability distribution of velocity maps and use this as a prior during inversion, effectively regularizing the solution space
- Core assumption: The learned prior distribution accurately represents realistic geological structures and is transferable across different scenarios
- Evidence anchors:
  - [section] "By learning an accurate characterization of the model parameter prior distribution, GenAI can 1) enhance the solution of the Bayesian inverse problem and UQ"
  - [section] "Wang et al. [114] use a diffusion model for solving CWI problems with quantified uncertainties"
  - [corpus] Weak - related papers discuss general ML applications but not specific GenAI applications in CWI

## Foundational Learning

- Concept: Wave equation physics and numerical methods
  - Why needed here: Understanding the underlying physics is essential for incorporating it into ML models and interpreting results
  - Quick check question: Can you explain the difference between acoustic and elastic wave equations and when each would be used?

- Concept: Inverse problem theory and regularization
  - Why needed here: CWI problems are inherently ill-posed, requiring proper regularization and understanding of solution uniqueness
  - Quick check question: What are the main challenges of ill-posed inverse problems and how do different regularization approaches address them?

- Concept: Deep learning architectures for image processing
  - Why needed here: Many CWI methods use CNN-based architectures for processing waveform data and velocity maps
  - Quick check question: What are the key differences between encoder-decoder architectures and U-Nets, and when would you choose each?

## Architecture Onboarding

- Component map: Input layer (waveform data) → Encoder network → Latent space → Decoder network → Output layer (velocity map), with optional physics modules (forward modeling) integrated at various points
- Critical path: Data preprocessing → Model training/inference → Physics validation → Post-processing → Quality assessment
- Design tradeoffs: Accuracy vs. computational cost (physics modules increase accuracy but computational load), generalization vs. specialization (broad training data vs. task-specific fine-tuning), model complexity vs. interpretability
- Failure signatures: Cycle-skipping in traditional methods, poor generalization to new geological structures, artifacts in reconstructed images, slow convergence
- First 3 experiments:
  1. Implement a basic InversionNet on synthetic seismic data to verify data flow and training pipeline
  2. Add physics-aware regularization using the wave equation to compare with baseline performance
  3. Test model generalization by evaluating on out-of-distribution data from a different geological setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can machine learning models be made more robust to out-of-distribution data in computational wave imaging applications?
- Basis in paper: [explicit] The paper discusses model generalization as a key challenge, noting that ML models often assume training and testing data share the same distribution, which doesn't always hold in real-world CWI scenarios.
- Why unresolved: The paper identifies this as an ongoing challenge and suggests that both data-centric and model-centric approaches are being explored, but more research is needed to determine the most effective strategies.
- What evidence would resolve it: Comparative studies demonstrating the effectiveness of different generalization techniques (e.g., data augmentation, transfer learning, physics-informed models) across various CWI applications and datasets would help resolve this question.

### Open Question 2
- Question: What is the most effective way to incorporate physics knowledge into machine learning models for computational wave imaging?
- Basis in paper: [explicit] The paper discusses various strategies for integrating physics into ML models, including physics-aware regularization, parameterized solutions, and plug-and-play priors, but notes that choosing the right approach can be challenging.
- Why unresolved: While the paper provides examples of different methods, it doesn't conclusively determine which approach is most effective across different CWI applications and scenarios.
- What evidence would resolve it: Systematic comparisons of different physics incorporation methods, evaluating their performance on benchmark CWI problems and analyzing their strengths and weaknesses in various contexts, would help resolve this question.

### Open Question 3
- Question: How can uncertainty quantification be effectively integrated into machine learning models for computational wave imaging?
- Basis in paper: [explicit] The paper discusses uncertainty quantification as an emerging trend in ML-enhanced CWI methods, highlighting its importance for assessing prediction confidence and improving model robustness.
- Why unresolved: While the paper presents some methods for UQ, such as quantile regression and Monte Carlo dropout, it doesn't provide a comprehensive framework for integrating UQ into ML models for CWI or evaluate their effectiveness across different applications.
- What evidence would resolve it: Studies comparing different UQ methods in terms of their accuracy, computational efficiency, and impact on downstream tasks in CWI would help resolve this question. Additionally, research on developing UQ methods specifically tailored to the unique challenges of CWI would be valuable.

## Limitations
- Limited empirical validation of proposed mechanisms, relying primarily on theoretical arguments and literature references
- Difficulty in transferring physics-aware ML models across different geological structures and material properties
- Scalability challenges of semi-supervised learning approaches to real-world, large-scale CWI problems

## Confidence
- Mechanism 1: Medium - Supported by theoretical arguments and references but lacks direct empirical validation in CWI context
- Mechanism 2: Medium - Conceptually sound but limited evidence of effectiveness in CWI applications
- Mechanism 3: Medium - Promising approach but effectiveness depends on quality of training data distribution

## Next Checks
1. Implement and evaluate a physics-aware ML model on a diverse set of synthetic and real-world CWI datasets to assess generalization capabilities
2. Conduct a thorough analysis of the computational cost and scalability of semi-supervised learning approaches for CWI, comparing them with fully supervised methods
3. Develop and test generative AI models for CWI on multi-modal datasets, evaluating their ability to capture complex geological structures and reduce ill-posedness