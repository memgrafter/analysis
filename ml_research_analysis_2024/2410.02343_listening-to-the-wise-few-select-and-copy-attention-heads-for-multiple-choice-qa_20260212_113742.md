---
ver: rpa2
title: 'Listening to the Wise Few: Select-and-Copy Attention Heads for Multiple-Choice
  QA'
arxiv_id: '2410.02343'
source_url: https://arxiv.org/abs/2410.02343
tags:
- heads
- qk-score
- baseline
- options
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a new scoring mechanism based on the interaction
  between query and key representations in attention heads of LLMs to improve multiple-choice
  question answering. The authors identify select-and-copy attention heads that consistently
  perform well across different MCQA datasets and use their outputs to derive QK-scores
  and attention scores.
---

# Listening to the Wise Few: Select-and-Copy Attention Heads for Multiple-Choice QA

## Quick Facts
- arXiv ID: 2410.02343
- Source URL: https://arxiv.org/abs/2410.02343
- Reference count: 40
- Primary result: QK-score method improves MCQA accuracy by up to 16% on LLaMA2-7B and up to 10% on larger models

## Executive Summary
This work introduces a novel scoring mechanism based on query-key (QK) alignment in attention heads to improve multiple-choice question answering (MCQA) with large language models. The authors identify specific "select-and-copy" attention heads that consistently extract correct answer options by focusing on semantically representative tokens. By computing QK-scores and attention scores from these heads, the method achieves significant accuracy improvements across multiple MCQA benchmarks while demonstrating robustness to option permutations. The approach also shows promise in synthetic datasets where correct answers are explicitly known.

## Method Summary
The method extracts QK-scores and attention scores from specific attention heads in LLMs to identify the correct answer option in MCQA tasks. The approach uses end-of-line tokens as option-representative tokens and computes scores based on query-key alignment without positional bias. The best-performing head is selected based on validation accuracy, and its QK-score is used for final answer prediction. The method also includes zero-ablation experiments to verify the causal importance of select-and-copy heads.

## Key Results
- Up to 16% accuracy improvement on LLaMA2-7B across popular MCQA benchmarks
- Up to 10% improvement on larger LLaMA models (8B, 70B parameters)
- Nearly 60% accuracy increase on synthetic datasets where correct answers are explicitly known
- Improved robustness to option permutations compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
Select-and-copy attention heads can extract correct answer options by focusing attention on semantically representative tokens and using query-key alignment to score options. The attention mechanism computes weighted sums of value vectors where attention weights are derived from query-key dot products. When attention weights for an option's representative token are much larger than others, the head effectively "copies" the value vector associated with the correct answer.

### Mechanism 2
The QK-score, computed as the dot product of the query from the last token and the key from the option-representative token, captures semantic alignment between question and answer options without positional bias. By ignoring the positional encoding component, the QK-score focuses purely on semantic similarity, selecting the option with the highest score as the answer.

### Mechanism 3
Zero-ablation of select-and-copy heads causes significant accuracy drops, proving their causal role in MCQA performance. Setting specific attention head outputs to zero removes their contribution to the residual stream, and if these heads are critical for option selection, their removal degrades performance substantially.

## Foundational Learning

- **Attention mechanism in transformers**: Understanding how attention heads compute weighted sums of value vectors based on query-key interactions is crucial for the method. Quick check: Given query vector q, key vector k, and value vector v, write the formula for attention weight a and output o for a single attention head.

- **Positional encoding and its impact on attention**: The method introduces QK-score to mitigate positional bias, making it essential to understand how positional information is incorporated into attention. Quick check: How does Rotary Position Embedding modify query and key vectors before computing attention weights?

- **Zero-ablation technique for identifying causal roles**: The paper uses zero-ablation to prove causal importance of select-and-copy heads. Quick check: What is the effect of setting an attention head's output to zero on the residual stream and final model output?

## Architecture Onboarding

- **Component map**: Input question and options → Tokenization with special separator tokens → Transformer model with attention heads → QK-score calculation for each option → Option selection based on highest QK-score

- **Critical path**: 1) Tokenize question and options 2) Pass sequence through transformer 3) Compute QK-scores for each attention head and option 4) Select option with highest QK-score from best-performing head

- **Design tradeoffs**: Using end-of-line tokens vs. other representative tokens (end-of-line tokens are semantically representative but may not capture all nuances); QK-score vs. attention score (QK-score ignores positional bias but may lose useful positional information); task-specific heads vs. universal heads (task-specific may perform better but require validation data)

- **Failure signatures**: Low accuracy on permuted option datasets (indicates method not robust to order changes); high synthetic accuracy but low real accuracy (suggests overfitting to synthetic patterns); no improvement over baseline (indicates heads not effectively isolating correct answers)

- **First 3 experiments**: 1) Compute QK-scores using single attention head and compare selected option to ground truth on validation set 2) Test different option-representative tokens to find most effective choice 3) Perform zero-ablation on top-performing heads to verify causal role

## Open Questions the Paper Calls Out

### Open Question 1
What are the precise mechanisms by which select-and-copy heads influence final model output and how do they interact with other attention heads in later layers? The paper shows causal importance through ablation but doesn't detail how these heads' outputs are processed by subsequent layers or how they compete with other heads.

### Open Question 2
Can the select-and-copy head identification method be generalized to other NLP tasks beyond MCQA? The paper focuses specifically on MCQA and doesn't explore whether the same approach works for tasks requiring different types of information selection and copying.

### Open Question 3
How does performance of QK-score and attention-score methods vary across different model architectures beyond the Llama family? Experiments are limited to Llama models, leaving uncertainty about whether findings generalize to other transformer architectures like GPT or Mistral.

## Limitations

- The method shows some sensitivity to option permutations, with relative performance drops by PA metric present across all datasets
- The paper has limited external validation with only 25 related papers found and average citation count of 0.0
- The methodology for finding select-and-copy heads without validation labels lacks sufficient detail for full assessment

## Confidence

- **High confidence**: Core mechanism of using query-key alignment to identify answer options is well-established and zero-ablation experiments prove causal importance of select-and-copy heads
- **Medium confidence**: Claims of up to 16% improvement on LLaMA2-7B and 10% on larger models are supported by experimental results, though synthetic dataset results may not generalize
- **Low confidence**: Claims about finding heads without validation labels lack sufficient methodological detail in provided sections

## Next Checks

1. **Permutation robustness test**: Systematically permute answer options across multiple runs and measure consistency of QK-score rankings versus ground truth to quantify method's robustness claims

2. **Cross-dataset head generalization**: Apply heads selected on one dataset to unseen datasets without re-selection to test whether truly universal select-and-copy heads exist or if head selection is dataset-specific

3. **Zero-shot ablation control**: Perform zero-ablation on randomly selected heads (not just top performers) to establish whether observed performance drops are specifically due to select-and-copy heads or could occur with any head ablation