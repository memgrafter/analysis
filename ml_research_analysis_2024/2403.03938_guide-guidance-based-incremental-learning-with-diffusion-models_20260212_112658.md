---
ver: rpa2
title: 'GUIDE: Guidance-based Incremental Learning with Diffusion Models'
arxiv_id: '2403.03938'
source_url: https://arxiv.org/abs/2403.03938
tags:
- diffusion
- samples
- task
- classifier
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GUIDE, a continual learning method for diffusion
  models that uses classifier guidance to generate rehearsal samples prone to forgetting.
  Existing generative replay methods rely on random sampling, which fails to prioritize
  samples most at risk of being forgotten.
---

# GUIDE: Guidance-based Incremental Learning with Diffusion Models

## Quick Facts
- arXiv ID: 2403.03938
- Source URL: https://arxiv.org/abs/2403.03938
- Reference count: 40
- Primary result: Classifier-guided diffusion sampling generates rehearsal samples near decision boundaries, improving generative replay in continual learning

## Executive Summary
This paper introduces GUIDE, a continual learning method that uses classifier guidance during diffusion sampling to generate rehearsal examples prone to forgetting. Unlike standard generative replay that relies on random sampling, GUIDE steers the diffusion process toward current task classes while generating samples from previous tasks, creating samples near the classifier's decision boundary. Experiments on CIFAR-10/100 and ImageNet-100 demonstrate that GUIDE outperforms state-of-the-art generative replay methods, achieving higher average accuracy and lower forgetting rates across multiple task sequences.

## Method Summary
GUIDE modifies the diffusion sampling process by incorporating classifier guidance to generate rehearsal samples specifically targeting information prone to forgetting. The method uses gradients from the current classifier to steer the denoising process toward current task classes while still generating samples from previous task classes. This creates rehearsal examples that are more likely to be misclassified by the continually trained classifier, forcing the model to maintain discriminative features for previous classes. The approach bridges the gap between standard generative replay and buffer-based methods by producing samples that are both high-quality and strategically positioned near decision boundaries to combat catastrophic forgetting.

## Key Results
- GUIDE achieves 64.47% average accuracy on CIFAR-100/5 compared to 59.00% for standard DGR
- Average forgetting reduced from 40.38% to 14.79% on CIFAR-100/5
- GUIDE outperforms state-of-the-art generative replay methods across all tested benchmarks (CIFAR-10/2, CIFAR-10/5, CIFAR-100/5, CIFAR-100/10, ImageNet100-64/5)
- The guidance mechanism shows consistent performance across different gradient scales with a trade-off between stability and plasticity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Classifier guidance during diffusion sampling generates rehearsal samples that are more likely to be misclassified by the continually trained classifier.
- Mechanism: The guidance steers the denoising process toward classes from the current task while still generating samples from previous task classes. This places the generated samples near the classifier's decision boundary, making them prone to misclassification.
- Core assumption: Samples near the decision boundary are more likely to be forgotten during continual learning.
- Evidence anchors:
  - [abstract]: "We propose to bridge this gap by incorporating classifier guidance into the diffusion process to produce rehearsal examples specifically targeting information forgotten by a continuously trained model."
  - [section 4.1]: "Rehearsal examples obtained with the modified sampling process yield lower outputs for class yi−1 in the current classifier fϕi(y|x) compared to the previous classifier fϕi−1(y|x). Hence, these examples can be interpreted as data samples that are more likely to be forgotten during continual training."
  - [corpus]: Weak evidence - only indirect support from related works on adversarial examples near decision boundaries.
- Break condition: If the classifier's decision boundary shifts significantly, guidance may no longer target samples prone to forgetting.

### Mechanism 2
- Claim: Generating rehearsal samples close to the decision boundary reduces catastrophic forgetting.
- Mechanism: Training on samples that are challenging for the classifier (near the decision boundary) forces the model to maintain discriminative features for previous classes even as it learns new classes.
- Core assumption: The classifier's decision boundary is dynamic and shifts during continual learning.
- Evidence anchors:
  - [section 4.1]: "This approach enables the generation of samples from preceding task distributions, which are more likely to be misclassified in the context of recently encountered classes."
  - [section 5.4]: "Since rehearsal examples generated with GUIDE are much more likely to be misclassified after a simple modification with predefined magnitude, this indicates that the modification of diffusion's prediction introduced in our method successfully moves the generations closer to the classifier's decision boundary."
  - [corpus]: Weak evidence - no direct experimental evidence in corpus papers.
- Break condition: If the classifier becomes too confident, samples near the decision boundary may no longer be effective for rehearsal.

### Mechanism 3
- Claim: Classifier guidance creates a trade-off between stability (retaining old knowledge) and plasticity (learning new knowledge).
- Mechanism: Stronger guidance (higher gradient scale) produces samples that are more challenging, improving retention of old knowledge but potentially hindering learning of new classes.
- Core assumption: There exists an optimal balance between guiding strength and learning effectiveness.
- Evidence anchors:
  - [section 6.1]: "We observe that the scaling parameter introduces a trade-off between the stability and plasticity of the continually trained classifier. When we increase s, the accuracy on the previous task increases along with a drop in accuracy on the current task."
  - [section A]: "Results indicate that our method works well with different values of this hyperparameter. Nonetheless, the results we achieved show that our method works well with different values of this hyperparameter."
  - [corpus]: Weak evidence - no direct experimental evidence in corpus papers.
- Break condition: If the gradient scale is too high, sample quality degrades, reducing the effectiveness of rehearsal.

## Foundational Learning

- Concept: Diffusion models and the denoising process
  - Why needed here: GUIDE relies on modifying the diffusion sampling process through classifier guidance to generate challenging rehearsal samples.
  - Quick check question: What is the role of the variance schedule {βt} in the forward diffusion process?

- Concept: Classifier guidance in diffusion models
  - Why needed here: The core innovation of GUIDE is using classifier guidance not for generating desired outputs, but for steering the generation of samples that are likely to be forgotten.
  - Quick check question: How does classifier guidance modify the denoising process at each timestep?

- Concept: Continual learning and catastrophic forgetting
  - Why needed here: GUIDE is designed to mitigate catastrophic forgetting by generating rehearsal samples that are specifically prone to being forgotten.
  - Quick check question: What is the difference between buffer-based and generative replay approaches in continual learning?

## Architecture Onboarding

- Component map:
  Classifier model (fϕi(y|x)) -> Diffusion model (ϵθi(xt, t, y)) -> Classifier guidance mechanism -> Rehearsal sampling module

- Critical path:
  1. Train classifier on real data from current task
  2. Generate rehearsal samples using classifier-guided diffusion
  3. Train classifier on combined real and generated samples
  4. Train diffusion model on current task data and generated samples from previous tasks

- Design tradeoffs:
  - Gradient scale (s) - controls strength of guidance, balancing stability vs plasticity
  - Number of denoising steps - affects sample quality and computational cost
  - Generation interval - determines how often new rehearsal samples are created, affecting speed vs accuracy

- Failure signatures:
  - Poor sample quality (artifacts, incorrect class) - may indicate too high gradient scale or insufficient denoising steps
  - No improvement in forgetting metrics - may indicate guidance is not effectively targeting decision boundary
  - Significant drop in current task performance - may indicate too strong guidance, prioritizing stability over plasticity

- First 3 experiments:
  1. Test classifier guidance on unconditional diffusion model to verify it can steer generation toward unknown classes
  2. Evaluate the effect of different gradient scales on sample quality and classifier performance
  3. Compare rehearsal sample quality (using metrics like FID) between standard DGR and GUIDE

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions. However, based on the discussion and limitations, several implicit questions emerge:

1. How does classifier guidance strength affect the diversity of generated rehearsal samples in GUIDE?
2. Does GUIDE's effectiveness generalize to more complex continual learning scenarios beyond class-incremental learning?
3. What is the relationship between the quality of the current classifier and GUIDE's effectiveness in mitigating forgetting?
4. Can the guidance mechanism be extended to work with self-supervised diffusion models that lack explicit class labels?
5. How does GUIDE's replay sample generation strategy compare to buffer-based sampling strategies in terms of sample efficiency and coverage?

## Limitations

- Only tested on image classification with limited task sequences (up to 5 tasks)
- Performance benefits diminish as task sequence length increases
- Heavy computational requirements due to diffusion model sampling
- Limited ablation studies on critical hyperparameters beyond gradient scale

## Confidence

- **High**: The superiority of GUIDE over standard generative replay baselines on standard benchmarks is well-supported by experimental evidence
- **Medium**: The mechanism of classifier guidance targeting decision boundary samples is theoretically sound but lacks direct experimental validation
- **Low**: The claim that GUIDE generalizes to larger task sequences or more complex continual learning scenarios remains unproven

## Next Checks

1. Evaluate GUIDE on longer task sequences (10+ tasks) to assess scalability and whether the guidance mechanism remains effective
2. Test the method on more complex continual learning scenarios including domain shifts and task agnosticism
3. Conduct ablation studies on the number of denoising steps and sampling frequency to optimize computational efficiency while maintaining performance