---
ver: rpa2
title: Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction
arxiv_id: '2410.23692'
source_url: https://arxiv.org/abs/2410.23692
tags:
- prediction
- mobility
- human
- trajectory
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents Llama-3-8B-Mob, an instruction-tuned large
  language model for long-term citywide human mobility prediction. The model reframes
  trajectory prediction as a Q&A task with structured instructions and achieves state-of-the-art
  performance on Japanese metropolitan data, outperforming traditional BERT-based
  methods.
---

# Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction

## Quick Facts
- **arXiv ID**: 2410.23692
- **Source URL**: https://arxiv.org/abs/2410.23692
- **Reference count**: 16
- **Primary result**: Instruction-tuned Llama-3-8B achieves state-of-the-art city-scale mobility prediction with strong zero-shot generalization across cities

## Executive Summary
This study introduces Llama-3-8B-Mob, an instruction-tuned version of Llama-3-8B for long-term citywide human mobility prediction. The model reframes trajectory prediction as a Q&A task with structured instructions and achieves state-of-the-art performance on Japanese metropolitan data, outperforming traditional BERT-based methods. It demonstrates strong zero-shot generalization across cities and achieves superior GEO-BLEU and DTW scores despite using only single-city training data. The approach addresses limitations of traditional mobility models by leveraging LLMs' inherent understanding of human movement patterns.

## Method Summary
The researchers fine-tuned Llama-3-8B using LoRA adapters (rank 16) on Japanese metropolitan mobility data represented as spatial-temporal quadruples. They converted trajectory data into structured Q&A format with instruction, question, and answer blocks, then trained for 3 epochs using AdamW optimizer with cosine learning rate scheduler. The model was evaluated using DTW (Dynamic Time Warping) and GEO-BLEU metrics, demonstrating superior performance compared to baseline LP-Bert models while showing strong cross-city generalization capabilities.

## Key Results
- Llama-3-8B-Mob outperforms BERT-based methods on Japanese metropolitan mobility data
- Achieves strong zero-shot generalization across cities with only single-city training data
- Demonstrates superior GEO-BLEU and DTW scores compared to traditional approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instruction tuning enables the LLM to treat trajectory prediction as a Q&A task with structured context, improving reasoning.
- Mechanism: By adding instruction, question, and answer blocks, the model receives clear task definitions, examples, and expected output formats. This structured prompting mimics how humans solve problems step-by-step.
- Core assumption: The LLM's pre-trained knowledge already includes general human mobility patterns, and instruction tuning can activate and adapt this knowledge for specific prediction tasks.
- Evidence anchors:
  - [abstract] "We introduce Llama-3-8B-Mob, an instruction-tuned version of Llama-3-8B [9], for long-term citywide mobility prediction."
  - [section] "We re-framed the trajectory prediction (Equation 2) as a Q&A task with instructions (Figure 1)"
  - [corpus] Weak evidence - no corpus neighbor discusses instruction tuning for mobility prediction specifically.
- Break condition: If the instruction block lacks sufficient detail or examples, the model may produce malformed outputs or deviate from the task.

### Mechanism 2
- Claim: LoRA adapters allow efficient fine-tuning by updating only low-rank matrices in key transformer components.
- Mechanism: Instead of full fine-tuning, LoRA inserts small adapter layers that learn to modify the original weights, drastically reducing the number of trainable parameters while preserving most of the model's knowledge.
- Core assumption: Human mobility prediction requires only localized adaptation of the base model's parameters rather than wholesale retraining.
- Evidence anchors:
  - [section] "we applied Low Rank Adaptation (LoRA) adapters [14] to optimize fine-tuning efficiency, only targeting the key modules in the model, such as the query, key, value, and output projections of transformers"
  - [corpus] No direct evidence; corpus focuses on foundation models and transformers but not LoRA specifically.
- Break condition: If the LoRA rank is too low, the model may underfit and fail to capture city-specific mobility nuances.

### Mechanism 3
- Claim: Zero-shot generalization across cities emerges because the LLM captures universal human movement patterns during pretraining.
- Mechanism: The model learns abstract representations of movement (e.g., daily routines, commute patterns) that apply across urban environments, allowing it to predict in unseen cities with minimal fine-tuning.
- Core assumption: Core human mobility behaviors are consistent enough across cities that a model trained on one can generalize to others.
- Evidence anchors:
  - [abstract] "It also displays strong zero-shot generalization capabilitiesâ€”effectively generalizing to other cities even when fine-tuned only on limited samples from a single city."
  - [section] "Llama-3-8B-Mobw/ single city performs remarkably well in predictions for other cities, showcasing its generalization ability across different urban environments without the need for city-specific data!"
  - [corpus] Weak evidence - corpus contains foundation models but not zero-shot cross-city generalization.
- Break condition: If cities have drastically different mobility structures (e.g., car-centric vs. transit-centric), the model may fail to generalize.

## Foundational Learning

- Concept: Trajectory representation as sequences of spatial-temporal quadruples
  - Why needed here: The model must parse and generate structured trajectory data; understanding the quadruple format (<day_id>, <timeslot_id>, <x>, <y>) is essential for both input and output.
  - Quick check question: Given a quadruple (2, 10, 150, 120), what does each number represent?
- Concept: Instruction tuning workflow and LoRA adapters
  - Why needed here: The model is instruction-tuned using LoRA; engineers must understand how to prepare datasets, set LoRA rank, and monitor fine-tuning.
  - Quick check question: What are the benefits of using LoRA over full fine-tuning in this context?
- Concept: Evaluation metrics (DTW and GEO-BLEU)
  - Why needed here: Performance is measured using shape similarity (DTW) and geospatial n-gram matching (GEO-BLEU); understanding these metrics is crucial for model validation.
  - Quick check question: How does GEO-BLEU differ from standard BLEU in evaluating trajectory predictions?

## Architecture Onboarding

- Component map: Base LLM (Llama-3-8B) -> LoRA adapters -> Instruction template -> Dataset pipeline -> Evaluation module
- Critical path: 1. Prepare dataset -> 2. Apply instruction template -> 3. Fine-tune with LoRA -> 4. Generate predictions -> 5. Evaluate with DTW/GEO-BLEU
- Design tradeoffs:
  - Full fine-tuning vs. LoRA: Full fine-tuning may yield better performance but is computationally prohibitive; LoRA offers a good balance.
  - Longer trajectories vs. inference time: Longer trajectories increase prediction accuracy but linearly increase inference time due to auto-regressive nature.
- Failure signatures:
  - Malformed JSON output -> likely issue with instruction formatting or model understanding
  - Consistently low GEO-BLEU but decent DTW -> model may capture shape but miss precise location details
  - High variance in predictions across seeds -> insufficient fine-tuning data or unstable LoRA training
- First 3 experiments:
  1. Test zero-shot performance on a small validation set to confirm baseline capability.
  2. Fine-tune on a single city with minimal data (e.g., 1000 trajectories) and evaluate cross-city generalization.
  3. Vary LoRA rank (e.g., 8, 16, 32) to find optimal balance between performance and efficiency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal data combination for fine-tuning Llama-3-8B-Mob to achieve maximum generalization across cities while minimizing redundancy?
- Basis in paper: [explicit] The authors note that they only investigated four data fine-tuning settings (B, C, D, A+B) and believe there exists an optimal data combination that covers more scenarios while minimizing information redundancy.
- Why unresolved: The study was limited by computational resources and time, preventing comprehensive exploration of all possible data combinations.
- What evidence would resolve it: Systematic experiments testing all combinations of city data (A, B, C, D) and analyzing their impact on cross-city generalization performance would identify the optimal training set composition.

### Open Question 2
- Question: How can the slow inference time of Llama-3-8B-Mob be reduced while maintaining prediction accuracy?
- Basis in paper: [explicit] The authors acknowledge that the inference time is 16,000x slower than LP-Bert, with the longest inference time reaching up to 15 minutes, presenting a significant challenge for practical application.
- Why unresolved: The study only mentions plans to explore efficient inference techniques without implementing or testing specific solutions.
- What evidence would resolve it: Implementation and evaluation of techniques such as speculative decoding, model pruning, quantization, or knowledge distillation to reduce inference time while benchmarking prediction accuracy.

### Open Question 3
- Question: How does the instruction-tuned Llama-3-8B-Mob perform on trajectory datasets beyond human mobility and grid-level data?
- Basis in paper: [explicit] The authors mention expanding validation to more trajectory datasets beyond human trajectories and grid-level data as a future direction.
- Why unresolved: The current study is limited to one specific dataset format (human mobility data from Japanese metropolitan areas with 200x200 grid discretization).
- What evidence would resolve it: Testing the model on diverse trajectory datasets such as animal movement data, vehicle GPS trajectories, or different spatial resolutions and time granularities to assess generalizability.

## Limitations

- **Computational Cost**: The model requires 225 seconds of inference time per trajectory, making city-scale deployment computationally expensive despite LoRA optimization.
- **Geographic Scope**: Training on only four Japanese metropolitan areas may limit the model's ability to generalize to cities with different mobility patterns and cultural contexts.
- **Evaluation Metrics**: Reliance primarily on DTW and GEO-BLEU may not capture all important aspects of mobility prediction such as temporal consistency or demographic fairness.

## Confidence

- **High Confidence**: The claim that instruction tuning enables Q&A framing for trajectory prediction (Mechanism 1) is well-supported by the paper's methodology and results.
- **Medium Confidence**: The assertion that LoRA adapters provide efficient fine-tuning (Mechanism 2) is plausible but lacks direct comparison to full fine-tuning in terms of final performance trade-offs.
- **Low Confidence**: The claim about universal human movement patterns enabling cross-city generalization (Mechanism 3) is the weakest link, as it lacks evidence beyond similar Japanese urban environments.

## Next Checks

1. **Cross-Cultural Generalization Test**: Evaluate the model on mobility data from non-Japanese cities (e.g., European or American cities with different transportation modes and cultural patterns) to validate the assumption of universal mobility patterns.

2. **Ablation Study on Instruction Design**: Systematically vary the instruction template components (instruction block, question format, answer examples) to determine which elements are critical for performance.

3. **Computational Efficiency Analysis**: Profile the model's inference time and memory usage across different hardware configurations and batch sizes, and test model compression techniques to determine if the accuracy-cost trade-off can be improved.