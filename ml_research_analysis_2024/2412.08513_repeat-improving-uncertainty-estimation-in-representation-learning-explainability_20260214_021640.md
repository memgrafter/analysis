---
ver: rpa2
title: 'REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability'
arxiv_id: '2412.08513'
source_url: https://arxiv.org/abs/2412.08513
tags:
- repeat
- uncertainty
- importance
- learning
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces REPEAT, a new method for explaining unsupervised
  representations in representation learning XAI (R-XAI). Unlike prior approaches
  that measure variability in importance scores, REPEAT directly models whether a
  pixel is certainly important by treating each pixel as a Bernoulli random variable.
---

# REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability

## Quick Facts
- arXiv ID: 2412.08513
- Source URL: https://arxiv.org/abs/2412.08513
- Reference count: 37
- Primary result: REPEAT achieves 1.000 AUROC for OOD detection on VOC dataset vs 0.000 for RELAX baseline

## Executive Summary
REPEAT introduces a novel approach to uncertainty estimation in representation learning explainability (R-XAI) by directly modeling pixel importance certainty rather than measuring variability in importance scores. The method treats each pixel as a Bernoulli random variable, leveraging stochasticity in base R-XAI methods combined with thresholding to generate samples and estimate pixel importance probabilities. Extensive evaluation demonstrates superior performance in out-of-distribution detection, complexity reduction, and poisoned data detection compared to state-of-the-art methods like RELAX.

## Method Summary
REPEAT improves uncertainty estimation in R-XAI by treating each pixel as a Bernoulli random variable to model certainty of importance. The method generates multiple importance estimates through stochastic base R-XAI methods (like RELAX or Kernel SHAP), applies thresholding to create binary samples, and estimates pixel importance probabilities along with associated uncertainty as the variance of the Bernoulli distribution. This approach directly models whether a pixel is certainly important rather than measuring variability in importance scores, resulting in more intuitive uncertainty estimates that better align with human judgment and show superior performance in OOD detection and complexity reduction.

## Key Results
- Achieves perfect OOD detection (1.000 AUROC) on VOC dataset compared to RELAX's 0.000 AUROC
- Produces more concise uncertainty estimates with lower entropy (9.97 vs 10.82 for RELAX)
- Strong performance in poisoned data detection (0.86 AUROC for uncertainty vs 0.59 for importance)
- Demonstrates generalization capability with Kernel SHAP base method

## Why This Works (Mechanism)

### Mechanism 1
- Claim: REPEAT directly models certainty in pixel importance by treating each pixel as a Bernoulli random variable, rather than measuring variability in importance scores.
- Mechanism: For each pixel, REPEAT generates multiple importance estimates through stochastic base R-XAI methods, then thresholds these scores to create binary samples (important/unimportant). From these samples, it estimates the probability of a pixel being important and calculates uncertainty as the variance of the Bernoulli distribution.
- Core assumption: The stochasticity in base R-XAI methods combined with repeated thresholding provides sufficient diversity in importance estimates to accurately model pixel importance probabilities.
- Evidence anchors:
  - [abstract] "REPEAT directly models whether a pixel is certainly important by treating each pixel as a Bernoulli random variable"
  - [section] "REPEAT leverages the stochasticity of current R-XAI methods to produce multiple estimates of importance, thus considering each pixel in an image as a Bernoulli random variable"

### Mechanism 2
- Claim: REPEAT provides more intuitive uncertainty estimates that better align with human judgment about pixel importance.
- Mechanism: By modeling certainty directly rather than variability, REPEAT can distinguish between pixels that are always important (low uncertainty) versus pixels that fluctuate around the importance threshold (high uncertainty), even if their average importance scores are similar.
- Core assumption: Human intuition about pixel importance correlates more with certainty of importance rather than variability in importance scores.
- Evidence anchors:
  - [abstract] "REPEAT gives certainty estimates that are more intuitive, better at detecting out-of-distribution data"
  - [section] "Consider an estimated importance map, where all pixels with importance scores higher than 2 are considered important. Now, take one pixel with importance value 5.6 ±0.1 and another with importance value 5.6 ±1.2. Due to the higher variance of the second pixel, current R-XAI methods would assign high uncertainty to this pixel. However, since all values within the 95% confidence interval of the pixel would still be above the importance threshold, we would still be certain that this pixel is important"

### Mechanism 3
- Claim: REPEAT generalizes to different base R-XAI methods while maintaining strong performance.
- Mechanism: REPEAT's framework is modular - it takes any stochastic R-XAI method as input, generates binary samples through thresholding, and estimates importance probabilities. This allows it to leverage the strengths of various base methods while adding certainty estimation.
- Core assumption: The thresholding process and Bernoulli modeling are compatible with different base R-XAI methods' output distributions and stochastic behaviors.
- Evidence anchors:
  - [section] "REPEAT is more general and can be used with any stochastic R-XAI method. To illustrate this, we have conducted the same OOD detection and complexity experiments as earlier but with Kernel-SHAP (Lundberg and Lee 2017) as the base stochastic R-XAI method"
  - [section] "The performance for OOD detection is very similar for RELAX compared to Kernel-SHAP, but RELAX gives lower complexity compared to using Kernel-SHAP as the base R-XAI method"

## Foundational Learning

- Concept: Bernoulli random variables and their properties (mean and variance)
  - Why needed here: REPEAT treats each pixel as a Bernoulli RV where the mean represents importance probability and variance represents uncertainty
  - Quick check question: If a pixel has importance probability 0.8, what is its uncertainty according to REPEAT's framework?

- Concept: Stochasticity in machine learning models and its role in uncertainty estimation
  - Why needed here: REPEAT leverages stochastic base R-XAI methods to generate diverse importance estimates for reliable probability estimation
  - Quick check question: Why is stochasticity in the base R-XAI method critical for REPEAT's performance?

- Concept: Image thresholding techniques and their properties
  - Why needed here: REPEAT uses thresholding to convert continuous importance scores into binary samples for Bernoulli modeling
  - Quick check question: How might different thresholding methods (Otsu, mean, triangle) affect the quality of binary samples in REPEAT?

## Architecture Onboarding

- Component map: Input image → Feature extractor → Base R-XAI method (stochastic) → Multiple importance maps → Histogram → Thresholding (mean, Otsu, triangle, Li) → Binary samples → Bernoulli probability estimation → Importance and uncertainty outputs
- Critical path: The sequence from base R-XAI method through thresholding to Bernoulli probability estimation is the core of REPEAT's innovation
- Design tradeoffs: Higher number of repeats (K) improves probability estimation accuracy but increases computational cost; different thresholding methods offer different biases in binary sample generation
- Failure signatures: Poor OOD detection performance, high complexity scores, or uncertainty estimates that don't align with human judgment indicate issues with the Bernoulli modeling or thresholding
- First 3 experiments:
  1. Verify that REPEAT produces reasonable importance maps on a simple dataset with known important pixels
  2. Compare REPEAT's uncertainty estimates against human judgments of pixel importance certainty
  3. Test REPEAT with different base R-XAI methods to confirm generalization capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does REPEAT perform when applied to other types of stochasticity beyond RELAX, such as Dropout-based methods?
- Basis in paper: [explicit] The paper demonstrates REPEAT's flexibility by testing it with Kernel SHAP, but only briefly mentions the potential for other stochastic R-XAI methods.
- Why unresolved: The paper only evaluates Kernel SHAP as an alternative base method, leaving the performance with other stochastic approaches unexplored.
- What evidence would resolve it: Experiments comparing REPEAT's performance across a broader range of stochastic R-XAI methods (e.g., Dropout-based, Monte Carlo methods) would clarify its generalizability.

### Open Question 2
- Question: Can REPEAT's thresholding mechanism be further optimized for specific datasets or tasks?
- Basis in paper: [inferred] The paper uses mean thresholding as a default but mentions that Otsu's method produced higher thresholds in their example, suggesting potential variability in performance.
- Why unresolved: The paper evaluates only four standard thresholding methods without exploring dataset-specific optimizations or adaptive thresholding strategies.
- What evidence would resolve it: Comparative studies of adaptive thresholding methods tailored to specific datasets or tasks would reveal whether optimization improves REPEAT's performance.

### Open Question 3
- Question: How does REPEAT scale with larger datasets or more complex models, such as those used in large-scale vision tasks?
- Basis in paper: [explicit] The paper evaluates REPEAT on datasets like PASCAL-VOC and MS-COCO but does not address scalability to larger datasets or more complex architectures.
- Why unresolved: The computational efficiency and performance of REPEAT on large-scale datasets or advanced models (e.g., Vision Transformers with more parameters) remain untested.
- What evidence would resolve it: Scalability studies involving larger datasets (e.g., ImageNet) and more complex models would provide insights into REPEAT's practical applicability.

## Limitations

- The Bernoulli modeling approach's effectiveness depends heavily on the stochasticity level of base R-XAI methods, which varies significantly across implementations
- The method's performance on datasets with naturally ambiguous pixel importance (textures, shadows) remains unexplored
- Limited evaluation of different thresholding methods' impact on the quality of binary samples and overall performance

## Confidence

- **High Confidence**: The core mathematical framework of treating pixels as Bernoulli random variables and computing importance probabilities through repeated sampling is sound and well-defined
- **Medium Confidence**: The empirical performance claims (OOD detection, complexity reduction) are supported by the presented results, though the evaluation could benefit from additional baseline comparisons
- **Low Confidence**: The generalization claims to different base R-XAI methods and the assertion that certainty-based uncertainty is more intuitive than variability-based approaches lack extensive empirical validation

## Next Checks

1. Conduct ablation studies varying the number of repeats (K) and thresholding methods to quantify their impact on OOD detection performance and complexity scores across multiple datasets

2. Compare REPEAT's certainty-based uncertainty estimates against human judgments of pixel importance using a controlled user study with images where important pixels are clearly identifiable

3. Evaluate REPEAT's performance when applied to base R-XAI methods with varying levels of stochasticity (e.g., deterministic vs highly stochastic implementations) to establish the relationship between base method properties and REPEAT's effectiveness