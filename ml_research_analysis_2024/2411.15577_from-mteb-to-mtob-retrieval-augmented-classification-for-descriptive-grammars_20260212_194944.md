---
ver: rpa2
title: 'From MTEB to MTOB: Retrieval-Augmented Classification for Descriptive Grammars'
arxiv_id: '2411.15577'
source_url: https://arxiv.org/abs/2411.15577
tags:
- specific
- order
- instruct
- grammars
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces benchmarks to assess how well language models
  can extract typological features from descriptive grammars, which are vital for
  low-resource languages. The proposed Retrieval-Augmented Generation (RAG) pipeline
  retrieves relevant grammar sections and uses an LLM to classify linguistic features.
---

# From MTEB to MTOB: Retrieval-Augmented Classification for Descriptive Grammars

## Quick Facts
- **arXiv ID**: 2411.15577
- **Source URL**: https://arxiv.org/abs/2411.15577
- **Reference count**: 40
- **Primary result**: BM25 retrieval matches embedding-based rerankers for extracting typological features from descriptive grammars

## Executive Summary
This work introduces benchmarks to assess how well language models can extract typological features from descriptive grammars, which are vital for low-resource languages. The proposed Retrieval-Augmented Generation (RAG) pipeline retrieves relevant grammar sections and uses an LLM to classify linguistic features. Evaluations on 148 languages and 700 annotated paragraphs show that BM25, a traditional retriever, performs comparably to modern embedding-based rerankers. The pipeline outperforms baseline LLM-only approaches across four typological features, with weighted F1 scores ranging from 0.5328 to 0.9611 depending on the feature. The findings highlight the potential of combining traditional and modern retrieval methods for linguistic information extraction.

## Method Summary
The authors propose a RAG pipeline that combines traditional retrieval methods with language models to classify typological features from descriptive grammars. The system uses BM25 for initial retrieval and an LLM for classification. The pipeline was evaluated on 148 languages with 700 annotated paragraphs across four typological features. Performance was compared against baseline LLM-only approaches, with results showing superior performance of the RAG approach.

## Key Results
- BM25 retrieval performs comparably to embedding-based rerankers for linguistic information extraction
- RAG pipeline outperforms baseline LLM-only approaches with weighted F1 scores of 0.5328-0.9611 across four typological features
- Strong performance demonstrated across 148 languages using 700 annotated paragraphs from descriptive grammars

## Why This Works (Mechanism)
The RAG pipeline works by first retrieving relevant sections of descriptive grammars using BM25, then using an LLM to classify linguistic features from the retrieved context. This approach addresses the challenge of extracting typological information from unstructured grammatical descriptions by combining the precision of traditional retrieval methods with the reasoning capabilities of modern language models. The success of BM25 suggests that keyword-based matching is effective for this task, possibly because descriptive grammars follow standardized terminology for linguistic features.

## Foundational Learning

1. **Descriptive grammars**: Detailed linguistic descriptions of individual languages, essential for low-resource language documentation
   - *Why needed*: Primary data source for typological feature extraction
   - *Quick check*: Verify grammar contains section on "Typological Features" or similar

2. **BM25 retrieval**: Traditional keyword-based information retrieval method using term frequency and document length
   - *Why needed*: Baseline retrieval method that surprisingly matches modern approaches
   - *Quick check*: Ensure proper IDF calculation for the specific domain

3. **RAG pipeline**: Combines retrieval with language model generation for knowledge-intensive tasks
   - *Why needed*: Enables extraction of structured information from unstructured text
   - *Quick check*: Validate retrieved context actually contains target information

4. **Typological features**: Linguistic properties used to classify languages (e.g., word order, case systems)
   - *Why needed*: Target classification task for the system
   - *Quick check*: Confirm feature definitions match linguistic standards

## Architecture Onboarding

**Component map**: Query -> BM25 Retriever -> LLM Classifier -> Typological Feature Output

**Critical path**: Input query → BM25 retrieval → Context assembly → LLM classification → Output prediction

**Design tradeoffs**: Traditional BM25 vs. embedding-based retrievers; simpler keyword matching proved sufficient despite modern alternatives

**Failure signatures**: 
- BM25 may miss relevant sections if terminology varies from expected keywords
- LLM may misclassify features if retrieved context lacks sufficient detail
- Performance depends heavily on grammar quality and structure

**3 first experiments**:
1. Test BM25 retrieval on sample grammar paragraphs to verify keyword matching effectiveness
2. Run LLM classification on retrieved contexts for a single typological feature
3. Compare RAG pipeline performance against LLM-only baseline on small language sample

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Performance uncertainty: Whether BM25's strong results reflect dataset characteristics or general retriever quality
- Feature generalization: Evaluation limited to four typological features, potentially limiting broader applicability
- Computational scalability: Does not address challenges of varying grammar quality, language family diversity, or computational costs at larger scales

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| RAG pipeline superiority for tested features | High |
| BM25 performance matching embedding-based methods | Medium |
| Approach scales effectively for low-resource languages | Medium |

## Next Checks
1. Test the RAG pipeline on typological features beyond the four studied (e.g., phonological inventories, word order patterns) to assess generalizability
2. Evaluate performance across different grammar quality levels and publication formats (PDF vs. structured text) to measure robustness
3. Compare computational costs and inference times between BM25 and embedding-based approaches at scale to quantify practical advantages