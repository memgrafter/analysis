---
ver: rpa2
title: Minimax Optimal Fair Classification with Bounded Demographic Disparity
arxiv_id: '2403.18216'
source_url: https://arxiv.org/abs/2403.18216
tags:
- have
- when
- fair
- lemma
- case
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the statistical foundations of fair binary classification
  with two protected groups, focusing on controlling demographic disparity (DDP),
  defined as the difference in acceptance rates between the groups. The authors show
  that using a finite dataset incurs additional costs due to the need to estimate
  group-specific acceptance thresholds, even when fairness is achieved with infinite
  data.
---

# Minimax Optimal Fair Classification with Bounded Demographic Disparity

## Quick Facts
- arXiv ID: 2403.18216
- Source URL: https://arxiv.org/abs/2403.18216
- Reference count: 40
- This paper introduces FairBayes-DDP+, a group-wise thresholding method that achieves the minimax optimal rate for fair binary classification with bounded demographic disparity.

## Executive Summary
This paper establishes statistical foundations for fair binary classification with two protected groups, focusing on controlling demographic disparity (DDP). The authors show that finite-sample estimation of fairness constraints incurs additional costs beyond standard statistical error. They introduce "fairness-aware excess risk" as a performance metric and derive a minimax lower bound that all classifiers must satisfy. The FairBayes-DDP+ algorithm combines local polynomial regression with group-wise thresholding and offsets, achieving this lower bound while controlling disparity at user-specified levels.

## Method Summary
The FairBayes-DDP+ method operates in two stages: first, it estimates group-specific regression functions using local polynomial estimators with bandwidth selected based on smoothness assumptions; second, it estimates optimal decision thresholds by solving empirical fairness constraints with carefully chosen offsets to handle boundary estimation. The algorithm detects whether the disparity function is continuous or has a jump discontinuity at the optimal threshold and adjusts accordingly. This plug-in approach with offsets ensures consistent estimation of level sets near the decision boundary while maintaining asymptotic fairness control.

## Key Results
- Introduces fairness-aware excess risk and derives a minimax lower bound combining classification error and threshold estimation costs
- FairBayes-DDP+ achieves the minimax lower bound under smoothness and margin conditions
- Experiments show FairBayes-DDP+ controls disparity at specified levels while being faster and offering better fairness-accuracy tradeoffs than baselines
- Proves that finite-sample estimation of fairness constraints incurs additional costs beyond standard statistical error

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Finite-sample estimation of fairness constraints incurs an additional cost beyond the usual statistical error in classification.
- Mechanism: When fairness is not satisfied by the unconstrained Bayes-optimal classifier (fairness-impacted case), the optimal decision thresholds must be adjusted to satisfy the fairness constraint. Estimating these thresholds introduces a second source of error that scales as $n^{-1/(2\gamma)}$ where $\gamma$ governs the margin condition near the decision boundary.
- Core assumption: The distribution of the regression function near the decision boundary satisfies the $\gamma$-margin condition, and the fairness constraint forces non-zero group-specific thresholds.
- Evidence anchors:
  - [abstract] "...using a finite sample incurs additional costs due to the need to estimate group-specific acceptance thresholds..."
  - [section 4.3] "the minimax lower bound may contain a second term due to the estimation of thresholds."
  - [corpus] No direct evidence in neighbors about threshold estimation cost; assumption is supported only by the paper's proof structure.
- Break condition: If the unconstrained Bayes-optimal classifier already satisfies the fairness constraint (automatically fair case), then no threshold adjustment is needed and this extra cost vanishes.

### Mechanism 2
- Claim: FairBayes-DDP+ achieves minimax optimality by combining local polynomial regression with a group-wise thresholding rule that adapts to possible jump discontinuities in the disparity function.
- Mechanism: The estimator uses a local polynomial estimator of the regression function for each group, then estimates the optimal threshold $t^*_\delta$ by solving an empirical fairness constraint. An offset is introduced to handle boundary estimation issues. The method detects whether the disparity function is continuous or has a jump discontinuity at $t^*_\delta$, and adjusts bandwidth accordingly.
- Core assumption: Local polynomial estimators achieve the optimal nonparametric rate for smooth regression functions, and the disparity function $D(t)$ is either continuous or has a jump discontinuity at $t^*_\delta$.
- Evidence anchors:
  - [abstract] "...propose FairBayes-DDP+, a group-wise thresholding method with an offset that we show attains the minimax lower bound."
  - [section 5.2] "we define $t^*_{\delta,\text{mid}}, t^*_{\delta,\Delta_n,\min}, t^*_{\delta,\Delta_n,\max}$ as in (5.3) using empirical versions of the above relations."
  - [corpus] No direct evidence in neighbors; assumption relies on the paper's technical construction.
- Break condition: If the regression function is not smooth enough or the disparity function behaves pathologically (e.g., extremely flat near $t^*_\delta$), the method may not achieve the optimal rate.

### Mechanism 3
- Claim: The offset in FairBayes-DDP+ ensures consistent estimation of level sets near the decision boundary, enabling asymptotic fairness control.
- Mechanism: The plug-in estimator with offset $\ell_{n,a}$ estimates the set $\{x: \eta_a(x) > T^*_{\delta,a}\}$ by thresholding the estimated regression function at $T^*_{\delta,a} + \ell_{n,a}$. This avoids the boundary bias that would occur with a naive plug-in estimator when the true level set has positive measure.
- Core assumption: The offset sequence $\ell_{n,a}$ decays slowly enough (e.g., $\ell_{n,a} \gtrsim n^{-1/(2\beta+d)}$) to ensure consistent estimation of the boundary set probability while not dominating the convergence rate.
- Evidence anchors:
  - [abstract] "...improves previous estimators of fair Bayes-optimal classifiers...by introducing offsets to handle the case where the decision boundary has a positive probability."
  - [section 5.3] "e$\Lambda_g,\ell_n(\lambda) = \Lambda_g(\lambda + \ell_n) = \{x \in X, \hat{g}(x) > \lambda + \ell_n\}$..."
  - [corpus] No direct evidence in neighbors; assumption is technical and specific to the paper.
- Break condition: If the offset is too small, boundary estimation is inconsistent and fairness is violated; if too large, accuracy suffers unnecessarily.

## Foundational Learning

- Concept: Hölder smoothness and margin conditions in nonparametric classification.
  - Why needed here: The convergence rate of the regression function estimator and the difficulty of threshold estimation both depend on these conditions. The minimax lower bound combines errors from both sources.
  - Quick check question: What is the convergence rate of a local polynomial estimator when the regression function is β-Hölder smooth and satisfies a γ-margin condition?

- Concept: Minimax lower bounds via Assouad's and Le Cam's lemmas.
  - Why needed here: The paper constructs two families of distributions to prove the lower bound: one for the classical classification error, one for the threshold estimation error. Both use these tools.
  - Quick check question: How does Assouad's lemma apply to a fair classification problem with multiple parameters indexed by hypercube vertices?

- Concept: Plug-in estimators with offset for level set estimation.
  - Why needed here: Naive plug-in estimators fail when the boundary set has positive measure. The offset ensures consistent estimation of the probability of being above/below the threshold.
  - Quick check question: Why does thresholding at $\hat{g}(x) > \lambda + \ell_n$ give a consistent estimate of $\{x: g(x) > \lambda\}$ when the boundary $\{x: g(x) = \lambda\}$ has positive measure?

## Architecture Onboarding

- Component map: Data preprocessing -> Group-wise regression estimation -> Threshold estimation -> Decision rule application
- Critical path: Regression estimation → Threshold estimation → Decision rule application. Each step depends on the previous; errors propagate.
- Design tradeoffs: (a) Bandwidth choice: smaller bandwidth reduces bias but increases variance. (b) Offset choice: larger offset improves fairness control but slows convergence. (c) Smoothness assumption: if violated, local polynomial may not achieve optimal rate.
- Failure signatures: (1) Disparity exceeds δ despite large offsets → regression function poorly estimated. (2) Very slow convergence of fairness-aware excess risk → offsets too large relative to estimation error. (3) Instability in threshold estimation → margin condition too weak.
- First 3 experiments:
  1. Simulate data with known regression function and varying β, γ to verify convergence rates of both regression and threshold estimation.
  2. Test sensitivity of fairness control to offset size ℓn,a on synthetic data.
  3. Compare FairBayes-DDP+ to baseline post-processing methods on Adult dataset for different δ values.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed FairBayes-DDP+ method perform in high-dimensional settings where local polynomial estimators are no longer optimal?
- Basis in paper: [explicit] The paper mentions that while the theory relies on the low-dimensional optimality of local polynomial methods, empirical results with neural nets show good performance in higher dimensions.
- Why unresolved: The paper does not provide theoretical guarantees for high-dimensional settings or rigorous analysis of alternative estimation methods like neural networks.
- What evidence would resolve it: Experimental results comparing FairBayes-DDP+ with various estimation methods in high-dimensional settings, along with theoretical analysis of convergence rates for these methods.

### Open Question 2
- Question: How does the choice of fairness metric affect the minimax lower bound and the performance of FairBayes-DDP+?
- Basis in paper: [inferred] The paper focuses on demographic parity but acknowledges that other group fairness metrics exist and could be explored in future work.
- Why unresolved: The paper only considers demographic parity, and it is unclear how other fairness metrics would impact the theoretical results and the performance of the proposed method.
- What evidence would resolve it: Derivation of minimax lower bounds and analysis of FairBayes-DDP+ for other group fairness metrics, such as equality of opportunity or predictive equality.

### Open Question 3
- Question: How sensitive is the FairBayes-DDP+ method to the choice of hyperparameters, such as the smoothness parameter β and the offsets ℓn,a?
- Basis in paper: [explicit] The paper mentions that the smoothness hyperparameter β influences the choice of bandwidth and that larger offsets lead to slower convergence rates but lower probability of disparity.
- Why unresolved: The paper does not provide a systematic study of the sensitivity of FairBayes-DDP+ to hyperparameter choices or guidance on selecting these parameters in practice.
- What evidence would resolve it: Extensive sensitivity analysis of FairBayes-DDP+ to various hyperparameters, along with practical recommendations for parameter selection based on data characteristics.

## Limitations

- The theoretical guarantees depend on smoothness and margin conditions that may not hold in practice
- The FairBayes-DDP+ algorithm requires careful bandwidth and offset selection with limited guidance for finite-sample implementation
- Experiments are limited to two datasets and do not fully explore sensitivity to hyperparameters or violations of assumptions

## Confidence

- **High**: The theoretical framework for fairness-aware excess risk and the minimax lower bound construction
- **Medium**: The FairBayes-DDP+ algorithm achieves the minimax rate under stated assumptions
- **Low**: The practical performance and fairness guarantees in real-world settings with complex, unknown distributions

## Next Checks

1. **Robustness to assumption violations**: Test FairBayes-DDP+ on synthetic data where the margin condition is weak or the regression function is not smooth, and measure the impact on fairness control and convergence rates.

2. **Hyperparameter sensitivity analysis**: Systematically vary bandwidth, offset, and other tuning parameters on real datasets to understand their impact on the fairness-accuracy tradeoff and identify stable operating regimes.

3. **Comparison to adaptive methods**: Compare FairBayes-DDP+ to data-driven approaches that adapt to unknown smoothness (e.g., cross-validation for bandwidth) on datasets with varying levels of noise and class imbalance.