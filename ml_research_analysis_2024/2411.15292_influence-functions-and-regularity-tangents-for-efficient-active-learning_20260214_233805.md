---
ver: rpa2
title: Influence functions and regularity tangents for efficient active learning
arxiv_id: '2411.15292'
source_url: https://arxiv.org/abs/2411.15292
tags:
- data
- which
- regularity
- point
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces an efficient active learning method using
  "regularity tangents" to estimate how new data points influence model complexity.
  The key innovation is computing a tangent vector during training that, when combined
  with the loss gradient, provides a measure of a point's impact on the model's regularizer
  (complexity measure).
---

# Influence functions and regularity tangents for efficient active learning

## Quick Facts
- arXiv ID: 2411.15292
- Source URL: https://arxiv.org/abs/2411.15292
- Authors: Frederik Eaton
- Reference count: 21
- Primary result: Introduces an efficient active learning method using regularity tangents to estimate influence of new data points on model complexity

## Executive Summary
This paper presents an efficient approach to active learning that uses "regularity tangents" to estimate how new data points influence model complexity. The key innovation is computing a tangent vector during training that, when combined with the loss gradient, provides a measure of a point's impact on the model's regularizer. This approach is more efficient than traditional influence function methods as it requires only one calculation of the tangent vector rather than separate computations for each candidate point.

The method demonstrates that this tangent vector represents the derivative of the regularizer with respect to a hyperparameter, making it equivalent to an influence function. The paper shows applications in polynomial regression and discusses applicability to both large-scale models using stochastic gradient descent and smaller models using second-order methods. The approach enables efficient active learning by identifying data points most likely to improve model generalization.

## Method Summary
The paper introduces a method for efficient active learning by computing regularity tangents during training. The core algorithm uses stochastic gradient descent with forward-mode differentiation (SGDF) to simultaneously compute parameter updates and their derivatives with respect to a regularity hyperparameter. This tangent vector can then be used to efficiently compute influence functions for candidate data points through simple inner products with loss gradients, avoiding the need to recompute influence for each point separately.

## Key Results
- Regularity tangents enable efficient influence computation for active learning by requiring only one calculation rather than separate computations for each candidate point
- SGDF algorithm efficiently computes regularity tangents by applying forward-mode automatic differentiation to SGD updates
- The method enables hierarchical regularization for multi-user models, where individual user tangents inherit from a shared global tangent

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Regularity tangent vectors enable efficient influence computation for active learning
- Mechanism: The regularity tangent vector (dθ*/ds) captures the derivative of optimal parameters with respect to model complexity. By computing this tangent during training, we can efficiently estimate how new data points affect model complexity through simple inner products with loss gradients, avoiding expensive recomputation for each candidate point.
- Core assumption: The regularity tangent computed during training remains valid for evaluating influence of new data points on model complexity
- Evidence anchors:
  - [abstract] "computing a 'regularity tangent' vector that can be calculated (with only a constant slow-down) together with the model's parameter vector during training"
  - [section 3.1] "Finding a new data point which maximizes the expected change in squared derivative of the loss at that point with respect to the regularity hyperparameter can be justified intuitively..."
- Break Condition: If the relationship between θ* and s becomes non-smooth or discontinuous during training, the regularity tangent approximation breaks down

### Mechanism 2
- Claim: SGDF efficiently computes regularity tangents
- Mechanism: By applying forward-mode automatic differentiation to SGD updates, we can simultaneously compute parameter updates and their derivatives with respect to the regularity hyperparameter. This hybrid approach leverages the fact that Hessian-vector products can be computed as efficiently as gradients.
- Core assumption: Forward-mode automatic differentiation can be applied to SGD without significantly impacting convergence or computational efficiency
- Evidence anchors:
  - [section 3.5] "We call this algorithm 'stochastic gradient descent with forward-mode differentiation' or SGDF"
  - [section 3.6] "The LiSSA algorithm is based on the observation that vH^-1 = v I I - (I - H) = v sum_{k=0}^infinity (I - H)^k"
- Break Condition: If the Hessian becomes ill-conditioned or the optimization landscape becomes highly non-convex, the SGDF approximation may become unstable

### Mechanism 3
- Claim: Regularity tangent enables hierarchical regularization for multi-user models
- Mechanism: In multi-user settings, each user's model parameters can be regularized against a shared global parameter vector. The regularity tangent for individual users inherits from the global tangent, allowing efficient computation of influence functions that capture both user-specific and shared knowledge.
- Core assumption: The hierarchical regularization structure allows decomposition of influence computation across user-specific and global parameters
- Evidence anchors:
  - [section 3.4] "The regularity tangent ˙θ for a single user will inherit from the common ˙θ0: ˙θ = dθ/ds = ∂θ/∂θ0 · dθ0/ds + (dθ/ds)(θ0)"
  - [section 3.4] "This fact ensures that each user's model has a non-zero regularity tangent even before any data points have been seen"
- Break Condition: If user interactions are too sparse or the global parameter vector becomes too dissimilar across user groups, the hierarchical structure may break down

## Foundational Learning

- Concept: Automatic Differentiation
  - Why needed here: The entire method relies on computing derivatives efficiently using forward-mode and reverse-mode automatic differentiation to calculate regularity tangents and influence functions
  - Quick check question: What is the key difference between forward-mode and reverse-mode automatic differentiation in terms of what they compute?

- Concept: Influence Functions
  - Why needed here: The method is fundamentally based on influence functions, which measure how infinitesimal changes in training data affect model parameters and predictions
  - Quick check question: How does the regularity tangent relate to the traditional influence function in terms of computational efficiency?

- Concept: Regularization and Model Complexity
  - Why needed here: The method uses regularization terms to measure model complexity and employs regularity tangents to estimate how new data points affect this complexity
  - Quick check question: Why is the regularity hyperparameter s used as the basis for computing tangents rather than directly perturbing individual data points?

## Architecture Onboarding

- Component map:
  - Training loop with SGDF integration -> Regularity tangent storage and computation -> Active learning query selection module -> Multi-user hierarchical regularization support (if applicable) -> Hessian-vector product computation utilities

- Critical path:
  1. Initialize model parameters and regularity tangent
  2. During training, compute both parameter updates and regularity tangent updates using SGDF
  3. Store final regularity tangent after training
  4. For active learning, compute inner products between regularity tangent and loss gradients for candidate points
  5. Select points with highest influence scores

- Design tradeoffs:
  - Forward-mode vs. reverse-mode for tangent computation
  - Single vs. multi-user hierarchical regularization
  - L1 vs. L2 regularization for sparsity vs. smoothness
  - Batch vs. per-example tangent computation

- Failure signatures:
  - Regularity tangent shows erratic behavior during training
  - Influence scores become uniformly high or low
  - Hessian-vector products become computationally prohibitive
  - Multi-user inheritance breaks down with sparse user data

- First 3 experiments:
  1. Simple polynomial regression with synthetic data to verify regularity tangent computation and basic active learning selection
  2. Linear regression with real dataset to test efficiency gains over traditional influence function computation
  3. Multi-user synthetic dataset to validate hierarchical regularization and inheritance of regularity tangents across users

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed regularity tangent approach compare in practice to traditional influence function methods in terms of computational efficiency and accuracy for active learning?
- Basis in paper: [explicit] The paper states that the regularity tangent method is more efficient than traditional influence function methods as it requires only one calculation of the tangent vector rather than separate computations for each candidate point.
- Why unresolved: The paper mentions theoretical efficiency but does not provide experimental comparisons of computational time or accuracy between the two approaches.
- What evidence would resolve it: Empirical studies comparing the runtime and active learning performance of regularity tangent methods versus traditional influence functions on benchmark datasets would provide concrete evidence.

### Open Question 2
- Question: Can the regularity tangent approach be effectively applied to non-convex loss functions commonly used in deep learning?
- Basis in paper: [inferred] The paper discusses applicability to large-scale models using SGD but focuses on polynomial regression examples. It does not explicitly address non-convex loss landscapes.
- Why unresolved: The mathematical properties of regularity tangents in non-convex optimization are not explored, and the convergence guarantees for SGD with forward-mode AD in non-convex settings are not discussed.
- What evidence would resolve it: Experimental validation of regularity tangent-based active learning on deep neural networks with non-convex losses, along with theoretical analysis of convergence properties, would address this question.

### Open Question 3
- Question: What is the optimal way to combine multiple regularity tangent-based query heuristics for active learning?
- Basis in paper: [explicit] The paper introduces several query heuristics (SLD, SSI, STI) based on regularity tangents and mentions that they could be combined, but does not provide guidance on optimal combination strategies.
- Why unresolved: The paper presents multiple heuristics but does not evaluate their relative performance or provide a framework for combining them effectively.
- What evidence would resolve it: Comparative studies evaluating different combination strategies (e.g., weighted sums, Bayesian optimization) for the proposed query heuristics on diverse active learning tasks would help determine optimal approaches.

## Limitations
- The method demonstrates primarily on synthetic polynomial regression problems without extensive validation on real-world datasets or deep learning architectures
- Computational complexity analysis assumes efficient Hessian-vector product computations, which may not hold for all model architectures
- Hierarchical regularization approach for multi-user settings is described theoretically but lacks empirical demonstration of its benefits

## Confidence

- Mechanism 1 (Regularity tangent for efficient influence): **High** - The theoretical foundation connecting regularity tangents to influence functions is well-established
- Mechanism 2 (SGDF for tangent computation): **Medium** - While the algorithmic approach is sound, practical implementation challenges for complex models are not fully explored
- Mechanism 3 (Hierarchical regularization): **Low-Medium** - The theoretical framework is presented but lacks empirical validation on realistic multi-user scenarios

## Next Checks
1. Implement and test the method on real-world regression datasets (e.g., UCI datasets) to verify practical efficiency gains over traditional influence function computation
2. Extend the method to neural network architectures and measure scalability and performance compared to standard active learning approaches
3. Conduct ablation studies on the different query heuristics (SLD, SSI, STI) to determine which provides the best trade-off between computational efficiency and active learning performance