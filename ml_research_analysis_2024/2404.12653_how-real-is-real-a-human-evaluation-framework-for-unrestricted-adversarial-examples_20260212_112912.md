---
ver: rpa2
title: How Real Is Real? A Human Evaluation Framework for Unrestricted Adversarial
  Examples
arxiv_id: '2404.12653'
source_url: https://arxiv.org/abs/2404.12653
tags:
- image
- unrestricted
- attacks
- human
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "SCOOTER is a human evaluation framework designed to assess the\
  \ imperceptibility of unrestricted adversarial examples (AEs) in images. While traditional\
  \ adversarial attacks use \u2113p norm restrictions to ensure imperceptible modifications,\
  \ unrestricted attacks can make significant, semantically meaningful changes that\
  \ appear natural to humans but mislead ML models."
---

# How Real Is Real? A Human Evaluation Framework for Unrestricted Adversarial Examples

## Quick Facts
- arXiv ID: 2404.12653
- Source URL: https://arxiv.org/abs/2404.12653
- Reference count: 6
- Key outcome: SCOOTER provides a human evaluation framework for assessing the imperceptibility of unrestricted adversarial examples using continuous slider ratings and standardized protocols.

## Executive Summary
This paper introduces SCOOTER, a human evaluation framework designed to assess the imperceptibility of unrestricted adversarial examples in images. Unlike traditional adversarial attacks that make small, bounded perturbations, unrestricted attacks can make significant semantic changes that appear natural to humans but mislead machine learning models. The framework addresses the challenge of evaluating these attacks by providing standardized study protocols, empirical sample size estimation, and an online leaderboard for comparing attack effectiveness across different models.

## Method Summary
SCOOTER is a Flask-based web application that conducts human studies to evaluate unrestricted adversarial examples. The framework uses continuous slider ratings ranging from -100 (certain unmodified) to +100 (certain modified) instead of binary choices. Studies include colorblindness checks (5 Ishihara-like plates) and comprehension checks (6 image pairs) to ensure high-quality data. Participants are recruited through Prolific with pre-screening for colorblindness and English fluency. The framework provides empirical sample size estimation for statistically significant evaluations and maintains an online leaderboard for tracking results across different attack strategies and victim models.

## Key Results
- Continuous slider ratings capture nuanced perceptions of image modifications better than binary classification
- Colorblindness and comprehension checks are necessary to ensure high-quality human evaluation data
- Standardized protocols enable reproducible comparisons of unrestricted adversarial attacks across different models
- Empirical sample size estimation is required since traditional apriori methods don't apply to this domain

## Why This Works (Mechanism)

### Mechanism 1
Unrestricted adversarial examples bypass traditional defense strategies by avoiding ℓp norm-constrained patterns that these defenses recognize and mitigate. Traditional defenses are designed to detect small, bounded perturbations, but unrestricted attacks make significant semantic changes that fall outside these threat models.

### Mechanism 2
Human evaluation using continuous slider ratings captures nuanced perceptions of image modifications better than binary classification. The continuous scale from -100 to +100 allows participants to express degrees of confidence rather than making discrete choices, capturing subtle perceptual differences.

### Mechanism 3
Standardized study protocols with comprehension and colorblindness checks ensure high-quality human evaluation data. By filtering out colorblind participants who would overestimate imperceptibility and requiring comprehension checks, the framework ensures that only capable participants contribute to the evaluation.

## Foundational Learning

- Concept: Human evaluation methodology in machine learning research
  - Why needed here: Understanding how to design and implement human studies is crucial for evaluating the perceptibility of unrestricted adversarial examples, which requires subjective human judgment
  - Quick check question: What are the key components of a statistically significant human evaluation study, and why are attention/comprehension checks important?

- Concept: Adversarial machine learning and threat models
  - Why needed here: To understand why unrestricted adversarial examples are significant and how they differ from traditional ℓp-norm constrained attacks, and why they can bypass existing defenses
  - Quick check question: How do unrestricted adversarial examples differ from traditional adversarial examples in terms of constraints and potential impact on ML model security?

- Concept: Statistical power and sample size determination
  - Why needed here: The framework includes empirical sample size estimation to determine how many participants are needed for statistically significant results, which requires understanding of statistical concepts
  - Quick check question: Why is empirical sample size estimation necessary in this domain, and what factors influence the required sample size for human evaluation studies?

## Architecture Onboarding

- Component map: Web application (Flask) -> Database (stores AEs and results) -> Leaderboard (comparison interface) -> Quality checks (colorblindness, comprehension) -> Main study (slider-based evaluation)

- Critical path: Participant recruitment → Colorblindness check → Comprehension check → Main study evaluation → Data collection → Statistical analysis → Leaderboard update

- Design tradeoffs: Prioritizes data quality over participant convenience by implementing multiple screening checks, which may reduce completion rates but ensures more reliable results

- Failure signatures: High variance in ratings, systematic bias in colorblind participants, low comprehension check pass rates, or statistical insignificance despite large sample sizes

- First 3 experiments:
  1. Test the colorblindness and comprehension check modules with a small pilot group to validate their effectiveness
  2. Run the main study with a small sample size on a single attack-model pair to validate the study protocol
  3. Conduct the full-scale empirical sample size estimation study with three attacks on one victim model

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal sample size for statistically significant human evaluations of unrestricted adversarial examples across different attack strategies and victim models? The authors acknowledge they cannot perform apriori sample size estimation and plan to empirically determine it through large-scale data collection.

### Open Question 2
How do continuous slider-based ratings compare to binary classification in capturing nuanced perceptions of adversarial image modifications? While the paper proposes using slider inputs, they don't provide comparative data showing how this approach performs versus traditional binary classification methods.

### Open Question 3
How effective are colorblindness and comprehension checks at ensuring high-quality human evaluation data for unrestricted adversarial examples? The framework includes these quality control measures but doesn't report on their actual effectiveness in practice.

## Limitations

- The framework may not account for other visual impairments or perceptual differences beyond colorblindness that could affect evaluation quality
- Continuous slider ratings may not fully capture the subjective nature of visual perception across different cultural contexts
- The assumption that traditional defenses are ineffective against unrestricted attacks may be challenged by new defense strategies specifically designed for unrestricted AEs

## Confidence

**High Confidence**: The framework's core methodology of using standardized human evaluation protocols with comprehension and colorblindness checks is well-grounded in HCI research principles and provides a reproducible approach for comparing unrestricted adversarial attacks.

**Medium Confidence**: The claim that continuous slider ratings provide meaningfully better data than binary choices is supported by reasoning but would benefit from empirical validation comparing both approaches directly.

**Medium Confidence**: The assumption that traditional defenses are ineffective against unrestricted attacks is reasonable given the shift in threat model, but specific defense strategies for unrestricted AEs may emerge that could challenge this claim.

## Next Checks

1. **Cross-cultural validation**: Conduct the same evaluation framework across participants from different cultural backgrounds to verify that the perception of image modifications is consistent and that the framework captures universal aspects of human perception.

2. **Alternative rating method comparison**: Run parallel studies using both the continuous slider method and a binary classification approach with the same attack examples to empirically validate whether the continuous ratings provide additional meaningful information.

3. **Defense strategy testing**: Evaluate whether existing traditional defense mechanisms can be adapted or extended to detect unrestricted adversarial examples, testing the claim that these attacks inherently bypass traditional defenses.