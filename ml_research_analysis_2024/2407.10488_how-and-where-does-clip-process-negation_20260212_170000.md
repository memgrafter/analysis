---
ver: rpa2
title: How and where does CLIP process negation?
arxiv_id: '2407.10488'
source_url: https://arxiv.org/abs/2407.10488
tags:
- attention
- negation
- layer
- clip
- caption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes how CLIP, a vision-and-language model, processes
  negation using interpretability methods. The authors focus on the text encoder in
  CLIP and investigate which components are responsible for understanding negation
  in the VALSE benchmark, which tests models' ability to distinguish correct captions
  from foils containing negation.
---

# How and where does CLIP process negation?

## Quick Facts
- arXiv ID: 2407.10488
- Source URL: https://arxiv.org/abs/2407.10488
- Authors: Vincent Quantmeyer; Pablo Mosteiro; Albert Gatt
- Reference count: 22
- Primary result: CLIP processes negation through distributed mechanisms across early and middle layers, with layer 4 attention heads playing a key role in shifting negation information

## Executive Summary
This paper investigates how CLIP, a vision-and-language model, processes negation using interpretability methods focused on the text encoder. The authors apply causal tracing to localize components responsible for negation processing in the VALSE benchmark, which tests models' ability to distinguish captions from foils containing negation. They find that negation processing is distributed across positions and layers in the early and middle layers of the encoder, with particular emphasis on negator-selective attention heads in layer 4 that shift negation information from the negator position to later positions. The study also reveals limitations in the VALSE benchmark, showing that dataset features like caption length and subject size may influence model performance and calling into question the benchmark's validity for measuring linguistic understanding.

## Method Summary
The authors apply causal tracing, a technique from language model interpretability, to localize parts of the CLIP text encoder that process negation. They substitute activations from negated to non-negated inputs to measure the proportion of the original classification effect that can be restored, isolating the role of each component. Additionally, they analyze attention patterns by comparing attention maps between negated and non-negated sentences to identify negator-selective attention heads. The study uses the VALSE existence dataset (505 image-caption-foil triples) and validates findings using the CANNOT dataset. Preprocessing ensures equal sequence length by inserting "some" in non-negated plural sentences, with 15 instances filtered out that don't follow the standard structure.

## Key Results
- Negation processing is distributed across positions and layers in the early and middle layers of the CLIP text encoder
- Negator-selective attention heads exist predominantly in the early layers, with the most prominent in layer 4
- Layer 4 attention heads shift negation information from the negator position to later positions in the sequence
- Classification scores correlate weakly with caption length and subject size, suggesting dataset features may influence performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal tracing reveals which layers and positions in the CLIP text encoder process negation by substituting activations from negated to non-negated inputs.
- Mechanism: The method measures the proportion of the original classification effect that can be restored by replacing activations at specific layer-position pairs, isolating the role of each component in negation processing.
- Core assumption: The substituted activation from the negated input will only affect the output if the layer-position pair processes negation.
- Evidence anchors:
  - [abstract] "We localise parts of the encoder that process negation and analyse the role of attention heads in this task."
  - [section] "The model processes the non-negated caption, but at a given layer and position it is made to behave as if it was processing the negated foil."
  - [corpus] Weak: corpus lacks direct mentions of causal tracing application to CLIP; relies on extrapolation from general interpretability literature.
- Break condition: If the effect cannot be restored by any single position, the assumption that negation is localized fails.

### Mechanism 2
- Claim: Negator-selective attention heads in early layers, especially layer 4, shift negation information from the negator position to later positions in the sequence.
- Mechanism: Attention patterns show which heads attend more to the negator in negated sentences; the most prominent is in layer 4, where the causal tracing effect drops at the negator position and increases at later positions.
- Core assumption: Attention heads in layer 4 are responsible for moving negation information downstream.
- Evidence anchors:
  - [abstract] "we provide concrete insights into how CLIP processes negation on the VALSE existence task"
  - [section] "The most negator-selective attention head is found in layer 4."
  - [corpus] Weak: corpus mentions negator-selective attention in related models but not specifically in CLIP; evidence is indirect.
- Break condition: If other heads or layers also show high negator-selective attention, the role of layer 4 becomes less certain.

### Mechanism 3
- Claim: Dataset features like caption length and subject size in images influence CLIP's classification score, affecting the validity of the VALSE benchmark.
- Mechanism: Longer captions and foils produce more similar embeddings, making them harder to distinguish; larger subjects are more accurately classified, correlating with higher scores.
- Core assumption: CLIP's performance is partly due to dataset characteristics rather than purely linguistic understanding.
- Evidence anchors:
  - [abstract] "we highlight inherent limitations in the VALSE dataset as a benchmark for linguistic understanding"
  - [section] "The classification score is weakly correlated with the similarity between caption and foil, especially for those instances when the negation is in the foil."
  - [corpus] Weak: corpus does not mention dataset features like caption length or subject size; must infer from study.
- Break condition: If no correlation is found after controlling for dataset features, the claim about benchmark validity is weakened.

## Foundational Learning

- Concept: Causal tracing methodology
  - Why needed here: To localize model components responsible for negation processing in CLIP.
  - Quick check question: How does substituting activations from negated to non-negated inputs reveal which components process negation?

- Concept: Attention patterns in transformers
  - Why needed here: To identify which attention heads selectively focus on negation words.
  - Quick check question: What does it mean if an attention head has high negator-selective attention?

- Concept: Embedding space similarity
  - Why needed here: To understand how caption-foil similarity affects classification scores.
  - Quick check question: Why might longer captions and foils produce more similar embeddings?

## Architecture Onboarding

- Component map: Input text → text encoder layers (12-layer transformer) → attention heads → output embeddings → similarity with image embeddings (ViT/ResNet) → classification
- Critical path: Input text → text encoder layers → attention heads → output embeddings → similarity with image embeddings → classification
- Design tradeoffs: Simple contrastive design without cross-attention vs. richer fusion models; reliance on text encoder interpretability vs. black-box multimodal models
- Failure signatures: Low accuracy on VALSE due to dataset features (caption length, subject size) or insufficient negation processing in text encoder
- First 3 experiments:
  1. Apply causal tracing to a different VL benchmark (e.g., GQA) to see if negation processing is similarly localized.
  2. Vary caption length in VALSE and measure effect on classification accuracy and embedding similarity.
  3. Edit the negator-selective attention head in layer 4 and test if classification improves on negation instances.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the CLIP text encoder use the same attention heads for negation processing across different negation-related tasks (e.g., VALSE vs. CANNOT datasets)?
- Basis in paper: [explicit] The authors found similar negator-selective attention patterns in layer 4 of the CLIP text encoder across both VALSE and CANNOT datasets.
- Why unresolved: The study only compared two datasets, and the patterns were similar but not identical. More diverse negation tasks could reveal whether these attention heads are truly specialized for negation or task-specific.
- What evidence would resolve it: Testing the CLIP text encoder on multiple diverse negation tasks and comparing the attention head patterns across all tasks would clarify if the same heads are consistently used for negation processing.

### Open Question 2
- Question: How do dataset features like caption length and subject size in images influence the reliability of linguistic benchmarks like VALSE for measuring true linguistic understanding?
- Basis in paper: [explicit] The authors found correlations between classification scores and caption length, as well as subject size in images, suggesting that these features may influence model performance.
- Why unresolved: The study identified correlations but did not establish causation or determine the extent to which these features affect the validity of linguistic benchmarks.
- What evidence would resolve it: Conducting controlled experiments that systematically vary caption length and subject size while measuring model performance would help determine their impact on benchmark reliability.

### Open Question 3
- Question: Are the attention heads in the early layers of the CLIP text encoder specialized for negation, or do they serve other syntactic functions as well?
- Basis in paper: [inferred] The authors found that negator-selective attention is predominantly located in the early layers, with the most prominent head in layer 4.
- Why unresolved: The study did not investigate whether these attention heads are exclusive to negation or if they also process other syntactic elements.
- What evidence would resolve it: Analyzing the attention patterns of these heads across a wide range of syntactic tasks would reveal their versatility and potential specialization for negation.

## Limitations

- The study acknowledges that dataset features like caption length and subject size may influence model performance, potentially confounding the interpretation of linguistic understanding.
- The causal tracing methodology relies on assumptions about activation substitution that may not fully capture the complexity of negation processing in CLIP's architecture.
- The negator-selective attention analysis is based on aggregate attention patterns rather than individual instance analysis, which may mask variability in how different sentences are processed.

## Confidence

- **High confidence**: The observation that negation processing is distributed across multiple layers and positions in the early and middle layers of CLIP's text encoder, as this is directly measurable through causal tracing.
- **Medium confidence**: The claim about layer 4 attention heads being most prominent in negator-selective attention, as this is based on aggregate patterns but individual variation may exist.
- **Low confidence**: The broader implications for CLIP's linguistic understanding capabilities, given the authors' own acknowledgment of dataset feature confounding effects.

## Next Checks

1. Apply the causal tracing methodology to a different VL benchmark (e.g., GQA) to determine if the distributed negation processing pattern holds across tasks, controlling for caption length and subject size effects.

2. Conduct ablation studies on the identified negator-selective attention head in layer 4 to verify its causal role in negation processing, using intervention techniques to edit its behavior.

3. Perform a controlled experiment varying caption length and subject size independently in VALSE to quantify their individual contributions to classification accuracy, separating these effects from linguistic understanding.