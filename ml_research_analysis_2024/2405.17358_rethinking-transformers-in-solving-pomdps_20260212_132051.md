---
ver: rpa2
title: Rethinking Transformers in Solving POMDPs
arxiv_id: '2405.17358'
source_url: https://arxiv.org/abs/2405.17358
tags:
- regular
- arxiv
- tasks
- learning
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the limitations of Transformers for solving
  Partially Observable Markov Decision Processes (POMDPs). The authors establish that
  regular languages, which Transformers struggle to model, can be reduced to POMDPs,
  posing a challenge for Transformers due to their lack of inherent recurrence.
---

# Rethinking Transformers in Solving POMDPs

## Quick Facts
- arXiv ID: 2405.17358
- Source URL: https://arxiv.org/abs/2405.17358
- Reference count: 40
- Key outcome: Transformers struggle with POMDPs due to inability to model regular languages, while linear RNNs like LRU show superior performance

## Executive Summary
This paper establishes fundamental limitations of Transformers for solving Partially Observable Markov Decision Processes (POMDPs) by proving that regular languages, which Transformers cannot model, are reducible to POMDPs. Through theoretical analysis and empirical validation, the authors demonstrate that Transformers fail to effectively reconstruct hidden states from partial observations, particularly in tasks requiring long-term memory and state space modeling. The proposed Deep Linear Recurrent Unit (LRU) architecture, which combines Transformer-like parallelizability with RNN-like state reconstruction capabilities, emerges as a well-suited alternative for partially observable reinforcement learning.

## Method Summary
The paper introduces a framework called (SEQ, RL) that decouples sequence modeling from reinforcement learning, allowing direct evaluation of different sequence models (Transformer, LSTM, LRU) on POMDP tasks. Theoretical analysis establishes that Transformers cannot solve NC1-complete POMDPs derived from regular languages, while empirical validation compares sequence models on tasks including PARITY language modeling, PyBullet occlusion environments, and long-term memory tasks. The LRU architecture is implemented as a linear RNN with pointwise recurrence, providing a balanced approach between Transformer efficiency and RNN state reconstruction capabilities.

## Key Results
- Transformers fail to model regular languages that are reducible to POMDPs, limiting their effectiveness in partially observable environments
- LRU outperforms both Transformers and LSTMs on POMDP benchmarks, particularly in state reconstruction and long-term memory tasks
- The (SEQ, RL) framework successfully decouples sequence modeling from RL, enabling direct comparison of different architectures on POMDP-specific challenges

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformers cannot effectively solve POMDPs because they fail to model regular languages, which are reducible to POMDPs.
- Mechanism: Regular languages can be directly mapped to POMDPs by constructing states that represent transitions in the language and observations that correspond to input symbols. Since Transformers struggle with regular languages due to their lack of inherent recurrence, they cannot accurately recover the true state from partial observations in POMDPs.
- Core assumption: The computational complexity of regular languages (specifically NC1-complete languages) exceeds what log-precision Transformers can handle, as shown by the equivalence between log-precision Transformers and TC0 circuits.
- Evidence anchors:
  - [abstract]: "We establish that regular languages, which Transformers struggle to model, are reducible to POMDPs."
  - [section 4.2]: Theorem 4.4 proves that log-precision Transformers with polynomial hidden dimensions cannot solve NC1-complete POMDP problems.
  - [corpus]: Weak evidence - the corpus neighbors discuss recurrent approaches to POMDPs but don't directly address the regular language reduction.
- Break condition: If the POMDP problem maps to a regular language in TC0 or lower complexity class, Transformers may perform adequately since these are within their computational bounds.

### Mechanism 2
- Claim: Transformers fail at length generalization in POMDPs because their attention mechanism provides limited robustness to input perturbations.
- Mechanism: As input length increases, the hidden state change from perturbing a single input position is bounded by O(1/n) for Transformers with softmax attention. This means that long-term information has diminishing impact on the output, preventing accurate state reconstruction needed for length generalization in POMDPs.
- Core assumption: RL algorithms used with sequence models are Lipschitz continuous functions, ensuring small changes in hidden states produce small changes in policy outputs.
- Evidence anchors:
  - [section 4.3]: Theorem 4.6 shows that Transformers cannot solve ML for regular languages where certain symbol occurrence patterns create non-monotonic acceptance conditions.
  - [abstract]: "Transformers falter to model [regular languages], posing a significant challenge for Transformers in learning POMDP-specific inductive biases."
  - [corpus]: Weak evidence - neighbors discuss POMDP solutions but don't address length generalization limitations of Transformers.
- Break condition: If the RL algorithm uses non-Lipschitz operations (like argmax) or if the POMDP structure doesn't require long-term information for state reconstruction.

### Mechanism 3
- Claim: Linear RNNs with pointwise recurrence provide a balanced solution for POMDPs by combining Transformer-like parallelizability with RNN-like state reconstruction capabilities.
- Mechanism: Linear RNNs can be viewed as diagonalized versions of standard RNNs (xt = Λxt-1 + ut) or as point-wise recurrent Transformers. This structure maintains the computational efficiency of attention mechanisms while providing better inductive biases for state space modeling and regular language recognition.
- Core assumption: Linearizing and diagonalizing RNN recurrence preserves sufficient modeling capacity while eliminating gradient explosion issues and maintaining computational tractability.
- Evidence anchors:
  - [section 5]: "Linear RNNs can be viewed as a balance point between Transformers and RNNs" with experimental validation showing LRU outperforming both pure Transformers and standard RNNs.
  - [abstract]: "The Deep Linear Recurrent Unit (LRU) emerges as a well-suited alternative for Partially Observable RL"
  - [corpus]: Moderate evidence - neighbor papers discuss recurrent approaches to POMDPs, suggesting this is an active research direction.
- Break condition: If the POMDP problem requires highly non-linear state transitions that cannot be adequately approximated by linear recurrence, or if the computational benefits of parallel attention are critical for the specific task.

## Foundational Learning

- Concept: Partially Observable Markov Decision Processes (POMDPs)
  - Why needed here: The paper's core argument is that Transformers cannot solve POMDPs effectively, so understanding POMDP structure is essential for grasping the problem being addressed.
  - Quick check question: What distinguishes a POMDP from a standard MDP, and why does this distinction matter for sequence modeling?

- Concept: Regular languages and formal language theory
  - Why needed here: The theoretical limitations of Transformers are established through their inability to model regular languages, which are shown to be reducible to POMDPs.
  - Quick check question: How can you construct a DFA for a simple regular language like even parity, and why would a Transformer struggle with this task?

- Concept: Computational complexity classes (AC0, TC0, NC1)
  - Why needed here: The paper uses circuit complexity theory to prove theoretical limitations of Transformers, establishing bounds on what log-precision Transformers can compute.
  - Quick check question: What is the relationship between Transformer computational power and TC0 circuits, and why does this matter for solving NC1-complete problems?

## Architecture Onboarding

- Component map:
  - Observation history → Sequence Model (Transformer/LSTM/LRU) → State Representation → RL Algorithm (DQN/SAC/TD3) → Policy Output

- Critical path:
  - For POMDPs: Observation history → sequence model → state reconstruction → RL decision → action
  - For state space modeling: Historical observations → sequence model → current state prediction → MSE loss
  - For regular language tasks: Symbol sequence → sequence model → accept/reject decision → reward signal

- Design tradeoffs:
  - Transformer vs RNN: Parallel computation and long-range attention vs inherent recurrence and state reconstruction
  - Linear RNN vs standard RNN: Computational efficiency and gradient stability vs expressive power of non-linear activation functions
  - Sequence model depth: More layers increase representational capacity but also computational cost and potential overfitting

- Failure signatures:
  - Transformer failure: Poor performance on tasks requiring state reconstruction from history, especially with increasing sequence length
  - RNN failure: Gradient vanishing/explosion on very long sequences, poor sample efficiency compared to Transformers
  - LRU failure: Potential underfitting if linear recurrence is insufficient for complex state transitions

- First 3 experiments:
  1. Implement a simple PARITY task (binary string with even number of 1s) and compare Transformer, LSTM, and LRU performance on both fitting and length generalization
  2. Test state reconstruction capability on PyBullet occlusion tasks by training sequence models to predict true states from partial observations
  3. Evaluate long-term memory on Passive T-Maze with varying corridor lengths to identify the point where each architecture breaks down

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific structural or algorithmic changes could enable Transformers to effectively solve NC1-complete regular languages without relying on additional assumptions or modifications?
- Basis in paper: [explicit] The paper demonstrates that Transformers cannot solve NC1-complete regular languages like SYM(5) even with massive data, as shown in Theorem 4.4 and the empirical results.
- Why unresolved: The paper establishes the theoretical limitations of Transformers for NC1-complete problems but does not propose concrete solutions to overcome these limitations while preserving the Transformer architecture.
- What evidence would resolve it: Successful experimental results showing a Transformer variant solving NC1-complete regular languages with reasonable data efficiency and generalization capabilities.

### Open Question 2
- Question: How does the theoretical relationship between Transformers and regular languages extend to other classes of formal languages, such as context-free or context-sensitive languages?
- Basis in paper: [inferred] The paper focuses on the relationship between Transformers and regular languages but does not explore how these limitations might generalize to more complex language classes.
- Why unresolved: The paper establishes a connection between Transformers and regular languages but does not investigate whether similar limitations exist for more complex language classes or what implications this might have for more advanced sequential decision-making tasks.
- What evidence would resolve it: Theoretical proofs or empirical studies demonstrating Transformers' capabilities or limitations with context-free or context-sensitive languages.

### Open Question 3
- Question: What are the specific mechanisms by which linear RNNs like LRU implicitly reconstruct underlying states in POMDPs, and can these mechanisms be formally characterized?
- Basis in paper: [explicit] The paper shows that LRU performs well in state space modeling tasks but does not provide a formal characterization of how it achieves this.
- Why unresolved: While the paper demonstrates LRU's effectiveness in practice, it does not explain the theoretical underpinnings of how linear RNNs implicitly learn state representations in partially observable environments.
- What evidence would resolve it: A formal mathematical framework describing the state reconstruction capabilities of linear RNNs in POMDPs, supported by empirical validation.

## Limitations

- The theoretical reduction from regular languages to POMDPs may not capture the full complexity of real-world POMDPs, which often have more structured state transitions than worst-case NC1-complete problems
- Empirical validation focuses primarily on synthetic and benchmark tasks, with limited testing on truly complex, high-dimensional real-world POMDPs
- While LRU shows promise, its practical advantages over well-tuned LSTMs in standard POMDP settings require further exploration

## Confidence

- **High**: The theoretical proof that Transformers cannot model NC1-complete POMDPs derived from regular languages, as this follows directly from established circuit complexity results.
- **Medium**: The empirical demonstration that Transformers underperform RNNs and LRU on POMDP benchmarks, as results are consistent but sample sizes and hyperparameter sensitivity could affect conclusions.
- **Low**: The claim that linear recurrence provides the optimal balance between Transformers and RNNs, as this represents an emerging research direction requiring more extensive validation.

## Next Checks

1. Test LRU architecture on more complex POMDPs with non-linear state dynamics to verify linear recurrence remains sufficient for state reconstruction.
2. Conduct ablation studies comparing LRU with various Transformer modifications (memory-augmented, recurrence-augmented) to isolate the specific architectural benefits.
3. Evaluate sequence models on real-world POMDP applications (robotics, navigation) with partial observability to assess practical relevance of theoretical limitations.