---
ver: rpa2
title: 'AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents'
arxiv_id: '2410.13825'
source_url: https://arxiv.org/abs/2410.13825
tags:
- agent
- task
- page
- action
- occam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AgentOccam, a web agent that enhances large
  language models' performance on web tasks by refining their observation and action
  spaces. Unlike prior work that relies on complex strategies or additional modules,
  AgentOccam simplifies the agent by removing non-essential actions, disabling scrolling,
  and adding planning actions (branch and prune).
---

# AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents

## Quick Facts
- arXiv ID: 2410.13825
- Source URL: https://arxiv.org/abs/2410.13825
- Authors: Ke Yang; Yao Liu; Sapana Chaudhary; Rasool Fakoor; Pratik Chaudhari; George Karypis; Huzefa Rangwala
- Reference count: 40
- Primary result: AgentOccam achieves 43.1% success rate on WebArena, surpassing state-of-the-art by 9.8 absolute points (+29.4%)

## Executive Summary
AgentOccam introduces a novel approach to enhancing LLM-based web agents by focusing on refining observation and action spaces rather than complex strategies or additional modules. The method achieves state-of-the-art performance on the WebArena benchmark by removing non-essential actions, disabling scrolling, and adding planning actions (branch and prune). It also optimizes the observation space by removing redundant web elements and selectively replaying relevant information. The results demonstrate that careful alignment of observation and action spaces with LLM capabilities can yield strong zero-shot performance.

## Method Summary
AgentOccam refines LLM-based web agents through three main components: (1) Action space alignment - removing non-essential actions (noop, tab operations, scroll), disabling scrolling, adding planning actions (branch, prune), and simplifying actions; (2) Observation space alignment - simplifying web page elements, selectively replaying web elements in one page using pivotal nodes, and selectively replaying past pages using planning tree; (3) Implementing changes using generic rules applicable to all types of markup-language-formatted web pages. The approach is evaluated on WebArena and WebVoyager benchmarks using zero-shot performance metrics.

## Key Results
- Achieves 43.1% success rate on WebArena, surpassing state-of-the-art by 9.8 absolute points (+29.4%)
- Improves over similar plain agents by 26.6 points (+161%) without additional training
- Demonstrates strong zero-shot performance across different LLM model families (GPT-4-Turbo and Gemini-1.5-Flash)

## Why This Works (Mechanism)

### Mechanism 1
- Reducing non-essential actions improves focus and efficiency by eliminating actions requiring embodiment knowledge
- Core assumption: LLMs struggle with embodied reasoning and fine-grained control
- Evidence: WebArena results show 29.4% improvement over state-of-the-art
- Break condition: If environment introduces new action types requiring embodied reasoning

### Mechanism 2
- Simplifying web observations improves LLM processing by removing redundant formatting
- Core assumption: LLMs process Markdown more effectively than verbose HTML structures
- Evidence: Observation space alignment contributes to overall performance gains
- Break condition: If web pages contain highly structured elements where Markdown loses context

### Mechanism 3
- Selective replay improves memory efficiency by retaining only task-relevant context
- Core assumption: Only small subset of web content is relevant to any given task step
- Evidence: Planning tree mechanism supports improved task organization
- Break condition: If tasks require broad context from multiple pages

## Foundational Learning

- Concept: Partially Observable Markov Decision Process (POMDP)
  - Why needed here: Web interaction framed as POMDP where agent makes decisions based on partial observations
  - Quick check: In POMDP, why is state transition typically deterministic in this context?

- Concept: Action and observation space alignment
  - Why needed here: Core contribution focuses on aligning spaces with LLM pre-training data
  - Quick check: How does reducing non-essential actions improve agent performance?

- Concept: Planning via generation (branch and prune)
  - Why needed here: Agent uses branch and prune actions to autonomously generate and manage plans
  - Quick check: What is role of planning tree in selectively replaying past pages?

## Architecture Onboarding

- Component map: Web simulator (WebArena) -> Agent core (LLM API) -> Action space processor -> Observation space processor -> History manager -> Evaluator
- Critical path:
  1. Receive web page observation and task objective
  2. Process observation (simplify HTML, identify pivotal nodes, update planning tree)
  3. Generate action via LLM (using processed observation and history)
  4. Execute action in web simulator
  5. Update history and planning tree
  6. Repeat until task completion or failure
- Design tradeoffs: Simplifying observations reduces token usage but may lose context; removing actions improves focus but limits capabilities; planning tree improves efficiency but adds complexity
- Failure signatures: Agent gets stuck in loops (missing actions or poor observation processing); agent misses crucial information (overly aggressive simplification); agent takes too many steps (poor action selection or missing planning)
- First 3 experiments:
  1. Run simple task (e.g., click button) with vanilla agent vs. AgentOccam to see observation processing difference
  2. Test multi-step task requiring navigation to observe planning tree in action
  3. Run task with dense information to test pivotal node selection aggressiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would AgentOccam perform if trained to understand web-specific actions like scrolling and hovering?
- Basis: Paper mentions LLMs struggle with these actions but they could potentially be learned with minimal examples
- Why unresolved: Paper focuses on non-trainable LLM approach
- Evidence needed: Experiments comparing performance with and without training on web-specific actions

### Open Question 2
- Question: Can planning tree mechanism be further optimized for complex tasks without increasing context window size?
- Basis: Paper introduces planning actions but notes observation history scales up context length
- Why unresolved: Impact on context window size and efficiency for complex tasks not fully explored
- Evidence needed: Comparative studies on context window usage and task success rates with varying planning tree complexity

### Open Question 3
- Question: How does performance vary across different LLM model families and what adaptations are needed?
- Basis: Paper demonstrates generalizability to different base models but variations not deeply analyzed
- Why unresolved: Paper shows generalizability without detailed analysis of model-specific effects
- Evidence needed: Detailed performance metrics across multiple LLM families identifying strengths and weaknesses

## Limitations

- Evaluation constrained to WebArena simulator and subset of WebVoyager, which may not represent real-world web complexity
- Pivotal node identification mechanism and planning tree management details underspecified
- Observation simplification rules not exhaustively documented

## Confidence

- **High confidence**: Simplifying action spaces by removing non-essential actions and adding planning capabilities improves performance
- **Medium confidence**: Observation space alignment through HTML simplification and Markdown conversion improves LLM processing
- **Medium confidence**: Selective replay mechanism using pivotal nodes and planning trees improves efficiency

## Next Checks

1. Test AgentOccam on additional web agent benchmarks or real-world web applications to assess generalizability beyond curated environments

2. Systematically vary level of observation simplification (raw HTML vs. simplified Markdown) to quantify impact of each simplification step on different task types

3. Identify minimum viable action set by incrementally adding back non-essential actions and measuring performance degradation to understand true necessity of each removed action type