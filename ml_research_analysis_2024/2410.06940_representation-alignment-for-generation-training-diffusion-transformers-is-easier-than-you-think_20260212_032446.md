---
ver: rpa2
title: 'Representation Alignment for Generation: Training Diffusion Transformers Is
  Easier Than You Think'
arxiv_id: '2410.06940'
source_url: https://arxiv.org/abs/2410.06940
tags:
- diffusion
- repa
- conference
- training
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of improving representation learning
  in diffusion transformers (DiTs) for image generation. The authors argue that a
  key bottleneck in training these models is the quality of internal representations,
  which are typically inferior to those from self-supervised learning methods.
---

# Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think

## Quick Facts
- **arXiv ID:** 2410.06940
- **Source URL:** https://arxiv.org/abs/2410.06940
- **Reference count:** 40
- **Primary result:** Introduces REPA to align diffusion transformer representations with pretrained self-supervised encoder features, accelerating SiT training >17.5x and achieving FID=1.42 on ImageNet.

## Executive Summary
This paper addresses a critical bottleneck in training diffusion transformers (DiTs) for image generation: the quality of internal representations. The authors propose Representation Alignment (REPA), a regularization technique that aligns the noisy input representations of the diffusion model with clean image representations from a pretrained self-supervised visual encoder. By adding a distillation loss between the diffusion model's hidden states and the target encoder's output, REPA encourages the model to learn noise-invariant, semantically rich features. The method is applied to both DiTs and SiTs, showing substantial improvements in training efficiency and generation quality. For example, SiT training is accelerated by over 17.5x, achieving state-of-the-art FID=1.42 on ImageNet generation. The approach is also shown to scale well with model size and to work across different visual encoders, offering a flexible and effective way to boost diffusion model performance.

## Method Summary
The paper introduces REPresentation Alignment (REPA), a simple regularization technique that improves representation learning in diffusion transformers (DiTs) for image generation. REPA works by aligning the noisy input representations of the diffusion transformer with clean image representations from a pretrained self-supervised visual encoder, such as DINO-v2. During training, a distillation loss is added between the diffusion model's hidden states and the target encoder's output, encouraging the model to learn noise-invariant, semantically rich features. This alignment is applied at multiple scales within the transformer, ensuring that the model's internal representations are semantically aligned with those of the pretrained encoder. The method is agnostic to the choice of encoder and can be applied to both DiTs and SiTs, leading to significant improvements in training efficiency and generation quality.

## Key Results
- SiT training accelerated by over 17.5x with REPA, achieving FID=1.42 on ImageNet generation.
- REPA improves representation quality, leading to better noise robustness and semantic alignment.
- The method scales well with model size and is effective across different visual encoders.
- REPA enables state-of-the-art generation quality for both DiTs and SiTs.

## Why This Works (Mechanism)
The effectiveness of REPA stems from its ability to bridge the representation gap between diffusion transformers and self-supervised visual encoders. During the diffusion process, the input image is gradually corrupted by noise, leading to degraded representations in the transformer's hidden states. By aligning these noisy representations with clean, semantically rich features from a pretrained encoder, REPA guides the transformer to maintain meaningful information throughout the denoising process. This alignment encourages the model to learn noise-invariant features, which are crucial for high-quality image generation. The distillation loss acts as a regularizer, ensuring that the transformer's internal representations are semantically aligned with those of the encoder, leading to improved training efficiency and generation quality.

## Foundational Learning
- **Diffusion Models:** Generative models that learn to reverse a gradual noising process; needed to understand the denoising objective and the role of internal representations.
- **Self-Supervised Learning:** Pretraining methods that learn representations without labels; needed to understand the source of clean, semantically rich features for alignment.
- **Transformer Architectures:** Models that use self-attention mechanisms; needed to understand the structure of DiTs and SiTs and how REPA interacts with their hidden states.
- **Knowledge Distillation:** Technique for transferring knowledge from a teacher to a student model; needed to understand how REPA uses the pretrained encoder as a teacher for the diffusion model.
- **Representation Learning:** The process of learning useful features from data; needed to grasp why representation quality is critical for diffusion model performance.
- **Loss Functions in GANs/VDVAEs:** Understanding how different loss formulations affect training dynamics; needed to contextualize REPA's impact on optimization.

## Architecture Onboarding
**Component Map:** Image -> Noising Process -> DiT/SiT Encoder -> REPA Distillation Loss -> Pretrained Encoder (e.g., DINO-v2) -> Generation Quality

**Critical Path:** Image noising → DiT/SiT hidden states → REPA distillation loss → Pretrained encoder features → Improved representations → Better denoising and generation

**Design Tradeoffs:** REPA adds a small computational overhead due to the distillation loss, but this is offset by faster convergence and improved quality. The choice of pretrained encoder can influence results, but the method is flexible across different encoders.

**Failure Signatures:** If REPA is ineffective, training may remain slow, and generated images may lack semantic coherence or diversity. Poor alignment between the diffusion model and encoder features could lead to suboptimal denoising.

**3 First Experiments:**
1. Apply REPA to a small DiT on a toy dataset and measure training speed and generation quality.
2. Vary the strength of the REPA distillation loss to find the optimal balance between alignment and generation fidelity.
3. Replace the pretrained encoder (e.g., DINO-v2) with another self-supervised model to test encoder-agnostic benefits.

## Open Questions the Paper Calls Out
None explicitly identified in the paper.

## Limitations
- The analysis of representation quality relies on visual inspection and downstream metrics, lacking deeper investigation into learned feature spaces.
- Limited exploration of REPA's impact on representation utility for tasks beyond image generation, such as classification or transfer learning.
- Focus is primarily on ImageNet-sized datasets, leaving scalability and effectiveness on larger or more diverse image distributions untested.

## Confidence
- **High Confidence:** The core empirical findings regarding training acceleration (>17.5x for SiT) and generation quality improvements are well-supported by the experimental results and are consistent across multiple models and ablations.
- **Medium Confidence:** The claim that the improvement is primarily due to better representation learning is plausible but not definitively proven; other factors such as optimization dynamics could also contribute. The generalization of benefits across different encoders and model scales is demonstrated but warrants further testing.
- **Medium Confidence:** The assertion that this is a "bottleneck" in DiT training is based on observed performance gaps, but a rigorous analysis of alternative bottlenecks or failure modes is not provided.

## Next Checks
1. Conduct ablation studies to isolate the contribution of representation alignment from other potential effects, such as improved optimization or regularization.
2. Evaluate the quality and utility of the learned representations on downstream tasks (e.g., classification, transfer learning) to assess whether the distillation leads to genuinely useful features beyond the generative task.
3. Test the method on larger-scale or more diverse datasets (e.g., LAION, COCO) to assess robustness and scalability beyond ImageNet.