---
ver: rpa2
title: Evolutionary Multi-Objective Optimisation for Fairness-Aware Self Adjusting
  Memory Classifiers in Data Streams
arxiv_id: '2404.12076'
source_url: https://arxiv.org/abs/2404.12076
tags:
- discrimination
- data
- emosam
- feature
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents EMOSAM, an evolutionary multi-objective optimisation
  approach for fairness-aware data stream classification. The method integrates the
  Self-Adjusting Memory K-Nearest-Neighbour algorithm with Speed-constrained Multi-objective
  PSO to balance accuracy and discrimination reduction simultaneously.
---

# Evolutionary Multi-Objective Optimisation for Fairness-Aware Self Adjusting Memory Classifiers in Data Streams

## Quick Facts
- arXiv ID: 2404.12076
- Source URL: https://arxiv.org/abs/2404.12076
- Authors: Pivithuru Thejan Amarasinghe; Diem Pham; Binh Tran; Su Nguyen; Yuan Sun; Damminda Alahakoon
- Reference count: 10
- Primary result: EMOSAM achieves competitive accuracy while significantly reducing discrimination in streaming data classification

## Executive Summary
This paper introduces EMOSAM, an evolutionary multi-objective optimization approach for fairness-aware data stream classification. The method integrates the Self-Adjusting Memory K-Nearest-Neighbour algorithm with Speed-constrained Multi-objective PSO to balance accuracy and discrimination reduction simultaneously. EMOSAM optimises feature weights using SMPSO when rising discrimination trends are detected via Hodrick-Prescott filtering, maintaining a majority-voting ensemble over non-dominated solutions. Experiments on six datasets show EMOSAM achieves competitive accuracy while significantly reducing discrimination compared to fairness-unaware baselines and traditional fairness-aware methods.

## Method Summary
EMOSAM integrates SAMKNN with SMPSO to optimize feature weights for balancing accuracy and discrimination. The system detects rising discrimination trends using Hodrick-Prescott filtering and triggers EMO optimization when conditions are met. A majority voting ensemble aggregates predictions from all Pareto-optimal solutions rather than selecting a single weight vector. The approach is evaluated on six classification datasets with sensitive attributes like race, gender, and age, comparing against multiple baseline methods including HT, HAT, SAM, FAHT, FABBOO, FOMOS, and FAS Stream.

## Key Results
- EMOSAM achieves competitive accuracy while significantly reducing discrimination compared to fairness-unaware baselines
- The approach outperforms traditional fairness-aware methods on both accuracy and discrimination metrics
- Ablation studies confirm the effectiveness of the HP filter trigger mechanism and majority voting solution selection

## Why This Works (Mechanism)

### Mechanism 1
EMOSAM achieves competitive accuracy while significantly reducing discrimination by integrating SAMKNN with SMPSO. SAMKNN handles concept drift using STM and LTM, while SMPSO optimizes feature weights to maximize accuracy and minimize discrimination simultaneously. This works because feature weights can effectively mitigate discrimination without sacrificing accuracy when optimized via multi-objective evolutionary search. The mechanism could break if concept drift is too rapid for STM/LTM to adapt, or if the Pareto front becomes too sparse to provide meaningful trade-offs.

### Mechanism 2
HP filter detects rising discrimination trends, triggering timely feature weight optimization. The filter decomposes discrimination time series into trend and cycle components, with optimization triggered when trend exceeds threshold and cycle is positive. This works because discrimination in streaming data exhibits detectable trends that can be separated from noise using HP filtering. The mechanism could break if discrimination fluctuates too erratically for HP filter to identify meaningful trends, or if threshold tuning is ineffective.

### Mechanism 3
Majority voting over Pareto-optimal solutions provides balanced accuracy and fairness without selecting single weight vectors. Each Pareto solution generates predictions via weighted SAMKNN, with final prediction being majority vote across ensemble. This works because ensemble voting over diverse Pareto solutions can achieve better trade-offs than selecting a single solution. The mechanism could break if ensemble voting introduces too much noise or if majority vote consistently favors one objective over the other.

## Foundational Learning

- Concept: Concept drift in data streams
  - Why needed here: SAMKNN's core strength is handling heterogeneous concept drift, which is essential for streaming data classification
  - Quick check question: What are the two memory components in SAMKNN and what do they represent?

- Concept: Multi-objective optimization
  - Why needed here: SMPSO optimizes two conflicting objectives (accuracy and discrimination) simultaneously
  - Quick check question: Why is evolutionary multi-objective optimization suitable for balancing accuracy and fairness?

- Concept: Statistical parity as discrimination measure
  - Why needed here: EMOSAM uses absolute statistical parity to quantify discrimination between protected and unprotected groups
  - Quick check question: How is statistical parity calculated and what range does it fall within?

## Architecture Onboarding

- Component map: SAMKNN classifier (STM/LTM management) -> HP filter (discrimination trend detection) -> SMPSO (feature weight optimization) -> Majority voting (ensemble prediction)
- Critical path: Data chunk -> Weighted SAMKNN prediction -> Discrimination calculation -> HP filter analysis -> SMPSO optimization (if triggered) -> Ensemble prediction via majority vote
- Design tradeoffs: EMO optimization cost vs. accuracy/fairness gains; ensemble voting complexity vs. solution diversity; HP filter sensitivity vs. responsiveness
- Failure signatures: High discrimination persistence despite optimization; accuracy degradation after weight updates; optimization frequency too high or too low
- First 3 experiments:
  1. Run EMOSAM on a single dataset with fixed feature weights (no optimization) to establish baseline SAMKNN performance
  2. Test HP filter sensitivity by varying trend threshold Î¦ on synthetic discrimination patterns
  3. Compare majority voting vs. knee point selection on Pareto fronts using fixed optimization results

## Open Questions the Paper Calls Out

### Open Question 1
How would the EMOSAM approach perform on datasets with continuous sensitive attributes rather than binary ones? The paper focuses on binary sensitive attributes (race, gender) and uses statistical parity as the fairness measure, but doesn't explore continuous sensitive attributes. This remains unresolved because the paper only tests on datasets with binary sensitive attributes, leaving the performance on continuous sensitive attributes unknown.

### Open Question 2
What is the optimal balance between the population size and maximum iterations for SMPSO in EMOSAM to achieve the best trade-off between accuracy, discrimination, and computational time? The paper sets population size to 30 and maximum iterations to 10 for SMPSO, but notes this is for supporting online learning without exploring the impact of these parameters. This remains unresolved because the paper uses fixed parameters for SMPSO without investigating how different values affect the balance between accuracy, discrimination, and computational time.

### Open Question 3
How does the performance of EMOSAM change when using different evolutionary multi-objective optimization algorithms instead of SMPSO? The paper specifically uses SMPSO and highlights its effectiveness, but doesn't compare it with other EMO algorithms. This remains unresolved because the paper focuses solely on SMPSO without comparing its performance to other EMO algorithms that could potentially yield better results.

## Limitations
- Scalability concerns for high-dimensional streaming data due to EMO optimization overhead
- Sensitivity of HP filter parameters to different discrimination patterns not extensively validated
- Computational cost of maintaining ensemble voting may be prohibitive in real-time applications

## Confidence

- Accuracy-fairness tradeoff mechanism: **High** (supported by ablation studies and comparative experiments)
- HP filter trend detection: **Medium** (robustness mentioned but not extensively validated across diverse patterns)
- Majority voting superiority: **Medium** (shown effective but relative performance vs. single-solution selection needs more exploration)

## Next Checks

1. Stress test HP filter sensitivity by applying EMOSAM to synthetic streaming data with controlled discrimination trends (rapid vs. gradual changes)
2. Benchmark EMOSAM's runtime overhead against real-time constraints on large-scale streaming datasets
3. Evaluate ensemble diversity by measuring correlation between Pareto-optimal solutions' predictions across varying stream conditions