---
ver: rpa2
title: Evaluating Very Long-Term Conversational Memory of LLM Agents
arxiv_id: '2402.17753'
source_url: https://arxiv.org/abs/2402.17753
tags:
- event
- events
- llms
- conversation
- dialogue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces LOCOMO, a new dataset of very long-term
  open-domain dialogues (300 turns, 9K tokens on average, spanning up to 35 sessions)
  collected via a human-machine pipeline using LLM-based agents grounded in personas
  and temporal event graphs. The authors also propose a comprehensive evaluation benchmark
  consisting of three tasks: question answering (with five reasoning types), event
  summarization, and multimodal dialogue generation.'
---

# Evaluating Very Long-Term Conversational Memory of LLM Agents

## Quick Facts
- arXiv ID: 2402.17753
- Source URL: https://arxiv.org/abs/2402.17753
- Reference count: 40
- The paper introduces LOCOMO, a new dataset of very long-term open-domain dialogues spanning up to 35 sessions

## Executive Summary
This paper introduces LOCOMO, a new dataset of very long-term open-domain dialogues (300 turns, 9K tokens on average, spanning up to 35 sessions) collected via a human-machine pipeline using LLM-based agents grounded in personas and temporal event graphs. The authors also propose a comprehensive evaluation benchmark consisting of three tasks: question answering (with five reasoning types), event summarization, and multimodal dialogue generation. Experiments with various LLMs and RAG approaches reveal that while long-context models and RAG can improve memory capabilities, they still lag behind human performance, particularly on temporal reasoning and adversarial questions. Long-context LLMs are especially prone to hallucinations and misattribution of dialogues. RAG performs best when dialogues are converted into a database of observations about speakers.

## Method Summary
The paper introduces LOCOMO, a new dataset of very long-term open-domain dialogues (300 turns, 9K tokens on average, spanning up to 35 sessions) collected via a human-machine pipeline using LLM-based agents grounded in personas and temporal event graphs. The authors also propose a comprehensive evaluation benchmark consisting of three tasks: question answering (with five reasoning types), event summarization, and multimodal dialogue generation. Experiments with various LLMs and RAG approaches reveal that while long-context models and RAG can improve memory capabilities, they still lag behind human performance, particularly on temporal reasoning and adversarial questions. Long-context LLMs are especially prone to hallucinations and misattribution of dialogues. RAG performs best when dialogues are converted into a database of observations about speakers.

## Key Results
- LOCOMO dataset contains very long-term dialogues with 300 turns and 9K tokens on average
- Long-context LLMs show significant performance gaps compared to human baselines, especially on temporal reasoning
- RAG-based approaches outperform pure LLMs when dialogues are converted to structured observation databases

## Why This Works (Mechanism)
The paper demonstrates that conversational memory in LLMs can be enhanced through structured retrieval and long-context modeling, but these approaches still fall short of human-level performance. The mechanism relies on combining persona grounding, temporal event graphs, and retrieval-augmented generation to maintain context across extended dialogue sessions.

## Foundational Learning
- **Temporal event graphs**: Why needed - To track chronological relationships between dialogue events; Quick check - Verify graph connectivity and temporal consistency
- **Persona grounding**: Why needed - To maintain consistent character identities across sessions; Quick check - Validate persona coherence in generated responses
- **RAG optimization**: Why needed - To retrieve relevant dialogue history efficiently; Quick check - Measure retrieval precision and recall on test queries
- **Long-context modeling**: Why needed - To process extended dialogue sequences without truncation; Quick check - Evaluate context retention at different sequence lengths
- **Multimodal integration**: Why needed - To combine text and image information in dialogue; Quick check - Assess cross-modal alignment quality
- **Adversarial question generation**: Why needed - To test robustness of memory systems; Quick check - Verify question difficulty and diversity

## Architecture Onboarding

### Component Map
LLM Agent -> Persona Module -> Temporal Graph -> RAG Retriever -> Dialogue Manager -> Evaluation Engine

### Critical Path
Persona grounding → Temporal event tracking → Dialogue session management → Memory retrieval → Response generation → Evaluation

### Design Tradeoffs
The paper balances between using pure LLMs versus RAG-based approaches, finding that structured retrieval generally outperforms long-context models for very long dialogues. However, the conversion of dialogues to observation databases requires additional preprocessing overhead.

### Failure Signatures
Long-context LLMs show hallucinations and misattribution errors, particularly when processing very long sequences. RAG systems fail when retrieval precision drops or when persona information becomes fragmented across sessions.

### First 3 Experiments
1. Compare pure LLM performance versus RAG-based approaches on the LOCOMO dataset
2. Evaluate temporal reasoning capabilities across different dialogue lengths
3. Test multimodal dialogue generation with and without background knowledge integration

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset construction relies entirely on LLM-based pipeline, potentially introducing systematic biases
- Evaluation primarily focuses on English language dialogues, limiting cross-linguistic generalizability
- Multimodal evaluation components lack detailed validation methodology

## Confidence
- **High confidence**: Technical implementation of LOCOMO dataset construction and basic evaluation framework
- **Medium confidence**: Reported performance gaps between LLMs and human baselines
- **Medium confidence**: Effectiveness of RAG-based approaches

## Next Checks
1. Conduct ablation studies on the LOCOMO dataset construction pipeline to quantify the impact of LLM-generated content versus human-written content
2. Implement cross-linguistic validation using translated versions of LOCOMO to test generalization across languages
3. Develop more rigorous evaluation metrics for the multimodal components, including human evaluation of image-dialogue coherence and factual accuracy