---
ver: rpa2
title: Code-Based English Models Surprising Performance on Chinese QA Pair Extraction
  Task
arxiv_id: '2401.10286'
source_url: https://arxiv.org/abs/2401.10286
tags:
- chinese
- code
- data
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper reveals an unexpected performance gap in Chinese QA\
  \ pair extraction tasks, where code-based English models outperform Chinese language\
  \ models. Through controlled experiments and carefully designed metrics, the authors\
  \ demonstrate that code-based models' superior \"copying\" ability\u2014extracting\
  \ text verbatim from source materials\u2014leads to better performance in this domain."
---

# Code-Based English Models Surprising Performance on Chinese QA Pair Extraction Task

## Quick Facts
- arXiv ID: 2401.10286
- Source URL: https://arxiv.org/abs/2401.10286
- Reference count: 11
- Code-based English models outperform Chinese language models on Chinese QA pair extraction tasks

## Executive Summary
This paper reveals an unexpected performance gap in Chinese QA pair extraction tasks, where code-based English models outperform Chinese language models. Through controlled experiments and carefully designed metrics, the authors demonstrate that code-based models' superior "copying" ability—extracting text verbatim from source materials—leads to better performance in this domain. The findings show that models with less Chinese knowledge hallucinate less and perform better, while extending code models' vocabulary with Chinese tokens moderately improves performance. The work challenges assumptions about language-specific model requirements and suggests that task-relevant structural understanding may be more important than linguistic congruence for certain NLP tasks.

## Method Summary
The study involves fine-tuning various pre-trained models (both Chinese-based and English-based) on a Chinese QA pair extraction task using full parameter SFT or QLoRA methods. The training set contains 143,846 documents from encyclopedias and news articles, each with labeled question-answer pairs. Models are evaluated on a test set of 300 private documents using automated metrics (ROUGE-L, COV, CCR, REJ, TEAC, LISR) and human expert evaluation (EXPERTS metric). The research compares performance across different model types, tests vocabulary extension with Chinese tokens, and analyzes hallucination rates and copying ability.

## Key Results
- Code-based English models outperform Chinese language models on Chinese QA pair extraction tasks
- Models with less Chinese knowledge hallucinate less and achieve better performance
- Extending code models' vocabulary with Chinese tokens moderately improves performance without introducing hallucinations

## Why This Works (Mechanism)

### Mechanism 1
Code-based models outperform Chinese language models in Chinese QA pair extraction due to superior copying ability. The task requires extracting text verbatim from source materials, and code-based models have stronger structural understanding and consistency maintenance capabilities from training on code data. This works because the key performance factor is the ability to extract text without hallucination, not linguistic fluency in Chinese. Evidence shows code-based models score higher on EXPERTS metric and have lower hallucination rates. This would break if the task required generative understanding rather than verbatim extraction.

### Mechanism 2
Models with less Chinese knowledge hallucinate less and perform better on this task. Chinese knowledge in models introduces unwanted information that interferes with the extraction task, leading to hallucinations and lower performance. This works because the task is essentially a data processing task where verbatim copying is essential, not a comprehension task requiring additional knowledge. Experimental results indicate that excess Chinese knowledge can interfere with the task. This would break if the task required understanding and generating novel information rather than extracting existing content.

### Mechanism 3
Extending code models' vocabulary with Chinese tokens moderately improves performance without introducing hallucinations. Adding Chinese vocabulary tokens improves the model's ability to process Chinese text while maintaining the structural advantages of code-based models, leading to better coverage and summarization. This works because the model can process Chinese text at a surface level without needing deep linguistic understanding, and vocabulary extension provides sufficient capability for the task. Evidence shows improved TEAC and CCR metrics after vocabulary extension. This would break if the task requires deep linguistic understanding that vocabulary extension cannot provide.

## Foundational Learning

- Concept: ROUGE-L metric for coverage analysis
  - Why needed here: To measure the degree of content overlap between extracted QA pairs and source material, ensuring the model captures relevant information
  - Quick check question: What does a higher ROUGE-L score indicate about a model's performance on this task?

- Concept: Hallucination measurement (CCR - Content Creation Rate)
  - Why needed here: To quantify how much the model generates information not present in the source material, which is penalized in this task
  - Quick check question: Why would a lower CCR score be desirable for this Chinese QA pair extraction task?

- Concept: Cross-domain learning and transfer
  - Why needed here: The task involves applying code-based models (trained on English/code data) to Chinese text processing, requiring understanding of cross-domain transfer capabilities
  - Quick check question: What does the success of code-based models on Chinese tasks suggest about the importance of linguistic vs structural understanding?

## Architecture Onboarding

- Component map: Pre-trained models (Code Llama, DeepSeek code, etc.) -> Fine-tuning pipeline -> QA pair extraction -> Evaluation metrics (EXPERTS, LISR, TEAC, COV, CCR, ROUGE-L) -> Performance comparison
- Critical path: Document input -> Model processing -> QA pair extraction -> Evaluation using multiple metrics -> Performance comparison
- Design tradeoffs: Full parameter fine-tuning vs QLoRA for efficiency vs effectiveness, vocabulary extension vs training on more Chinese data, code-based vs language models for this specific task
- Failure signatures: High hallucination (high CCR), poor coverage (low ROUGE-L), inability to reject invalid documents, poor summarization (high TEAC)
- First 3 experiments:
  1. Compare performance of code-based vs Chinese language models on EXPERTS metric
  2. Test the effect of vocabulary extension with Chinese tokens on model performance
  3. Compare full fine-tuning vs QLoRA methods for this task

## Open Questions the Paper Calls Out

### Open Question 1
What specific architectural differences between code-based models and text-based models lead to superior copying ability in Chinese QA pair extraction tasks? The paper demonstrates that code-based models outperform text-based models in Chinese QA pair extraction tasks due to superior "copying" ability, but doesn't specify the exact architectural features responsible for this difference. The paper focuses on experimental results showing code-based models' superior performance but doesn't delve into the specific architectural components or mechanisms that enable this copying ability. Comparative analysis of attention mechanisms, token embeddings, or other architectural components between code-based and text-based models that directly correlate with copying performance in Chinese text tasks would resolve this.

### Open Question 2
How does the amount of Chinese data in pre-training affect the balance between copying ability and hallucination in code-based models for Chinese tasks? The paper notes that code-based models with less Chinese knowledge hallucinate less and perform better, while models with more Chinese data show improved summarization but increased hallucination. The paper identifies a correlation between Chinese data volume and hallucination but doesn't establish the optimal balance or the underlying mechanisms driving this relationship. Controlled experiments varying the amount of Chinese data in pre-training while measuring both copying fidelity and hallucination rates across different task types would resolve this.

### Open Question 3
Can the copying-focused approach of code-based models be effectively transferred to other non-English language tasks beyond Chinese? The paper demonstrates code-based English models' surprising effectiveness on Chinese QA pair extraction, suggesting task-relevant structural understanding may be more important than linguistic congruence. The study focuses specifically on Chinese tasks, leaving open whether this phenomenon extends to other non-English languages or different types of text processing tasks. Replication of the experiments across multiple non-English languages (e.g., Japanese, Arabic, Hindi) with varying linguistic structures to determine if copying ability consistently predicts task performance regardless of language family would resolve this.

## Limitations

- Narrow scope focusing on a single Chinese QA pair extraction task, limiting generalizability to other Chinese NLP tasks
- Task design specifically rewards verbatim copying and penalizes hallucination, which may not reflect broader Chinese language understanding requirements
- Limited set of pre-trained models used (three Chinese models and two code-based models), potentially missing relevant alternatives

## Confidence

**High Confidence**: The core finding that code-based models outperform Chinese language models on this specific task is well-supported by experimental results. The mechanism explanation—that verbatim copying ability is more important than Chinese linguistic knowledge for this task—is consistent with the data.

**Medium Confidence**: The claim that extending code models' vocabulary with Chinese tokens moderately improves performance is supported by some metrics but not others. The lack of EXPERTS improvement despite TEAC and CCR gains suggests the benefits may be task-dependent.

**Low Confidence**: The broader claim that code-based models are generally better for Chinese tasks requiring structural understanding is an extrapolation beyond the evidence. The task's specific design may artificially favor code models' strengths.

## Next Checks

1. Cross-task Validation: Test the same models on additional Chinese NLP tasks (e.g., text summarization, translation, question answering) to determine if the code-based advantage extends beyond verbatim extraction tasks.

2. Model Ablation Study: Conduct controlled experiments varying the amount of Chinese training data in code models to quantify the relationship between Chinese knowledge and hallucination rates, providing clearer evidence for Mechanism 2.

3. Vocabulary Extension Refinement: Perform systematic ablation studies on different Chinese token sets in vocabulary extension to identify which token types (characters, words, phrases) drive the observed improvements, and test whether these improvements generalize across multiple evaluation metrics.