---
ver: rpa2
title: 'Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive
  Sampling and Visual Persistence'
arxiv_id: '2407.18899'
source_url: https://arxiv.org/abs/2407.18899
tags:
- domain
- adaptation
- active
- target
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the source-free active domain adaptation (SFADA)
  problem, where the goal is to adapt a model from a source domain to a target domain
  without access to source data, using minimal annotation budget in the target domain.
  The key idea is to "learn from the learnt" by leveraging the knowledge encapsulated
  in the source-trained model and actively iterated models during the adaptation process.
---

# Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence

## Quick Facts
- arXiv ID: 2407.18899
- Source URL: https://arxiv.org/abs/2407.18899
- Authors: Mengyao Lyu; Tianxiang Hao; Xinhao Xu; Hui Chen; Zijia Lin; Jungong Han; Guiguang Ding
- Reference count: 40
- Primary result: Achieves 87.4% accuracy on VisDA-C with 1% labeling budget using Contrastive Active Sampling and Visual Persistence-guided Adaptation

## Executive Summary
This paper addresses the source-free active domain adaptation (SFADA) problem, where the goal is to adapt a model from a source domain to a target domain without access to source data, using minimal annotation budget in the target domain. The key innovation is learning from intermediate models during the adaptation process rather than just the initial source model. The authors propose a Contrastive Active Sampling (CAS) strategy to prioritize target samples that are informative to the current model and persistently challenging, combined with a Visual Persistence-guided Adaptation (VPA) approach to maintain feature representations of active target samples and facilitate cross-domain alignment.

## Method Summary
The method alternates between Contrastive Active Sampling (CAS) and Visual Persistence-guided Adaptation (VPA) to iteratively query novel knowledge and optimize towards the target domain. CAS learns from the hypothesis of the preceding model to identify samples where the current model shows high uncertainty by comparing current and previous model predictions. VPA uses a visual persistence vault with exponential moving average to preserve judgments on active anchors from source and intermediate models, facilitating feature distribution alignment. The framework leverages intermediate results already computed during iteration to avoid specialized architectures while achieving superior accuracy and efficiency.

## Key Results
- Achieves 87.4% accuracy on VisDA-C with just 1% labeling budget and 780 training iterations
- Demonstrates state-of-the-art performance on three benchmarks (VisDA-C, Office-Home, Office-31)
- Shows superior computational efficiency compared to existing SFADA methods
- Exhibits continuous improvements as annotation budget increases

## Why This Works (Mechanism)

### Mechanism 1
The Contrastive Active Sampling (CAS) strategy leverages hypothesis transfer from the previous model to identify samples where the current model shows high uncertainty. By comparing the current model's predictions with the previous model's predictions, it highlights samples that the current model has not yet fully grasped. This approach continuously harvests fresh information without additional computational burden.

### Mechanism 2
The Visual Persistence-guided Adaptation (VPA) approach maintains feature representations of active target samples using a visual persistence vault with exponential moving average. It preserves judgments on active anchors derived from source and intermediate models, facilitating cross-domain alignment by encouraging unlabeled samples to be centralized around these memory-preserving representatives.

### Mechanism 3
The LFTL framework achieves state-of-the-art performance by leveraging learnt knowledge from the source pretrained model and actively iterated models. By alternating between CAS and VPA, it iteratively queries novel knowledge and optimizes towards the target domain, avoiding the need for specialized architecture or sophisticated learning schemes.

## Foundational Learning

- **Domain Adaptation (DA)**: Understanding the fundamental problem of adapting models across domains is crucial, as LFTL addresses the SFADA variant. Quick check: What is the main goal of Domain Adaptation, and how does it differ from traditional machine learning?
- **Active Learning**: This is essential for grasping the CAS strategy and its benefits. Quick check: How does Active Learning differ from traditional supervised learning, and what are its main advantages?
- **Hypothesis Transfer**: This is the basis for the CAS strategy, leveraging previous model predictions to identify challenging samples. Quick check: What is Hypothesis Transfer, and how can it be used to improve machine learning models?

## Architecture Onboarding

- **Component map**: Source Model (Ms) -> Contrastive Active Sampling (CAS) -> Visual Persistence-guided Adaptation (VPA) -> Target Model (Mt)
- **Critical path**: The iterative process of CAS identifying informative samples for annotation, followed by VPA optimizing the target model using these samples
- **Design tradeoffs**: Trades source data access for minimal annotation budget, leveraging intermediate model knowledge for superior accuracy and efficiency
- **Failure signatures**: May fail if intermediate model knowledge becomes unrepresentative of target domain or if CAS fails to identify informative samples
- **First 3 experiments**:
  1. Validate CAS effectiveness by comparing with other active learning strategies on benchmark datasets
  2. Validate VPA effectiveness by comparing with other domain adaptation strategies on benchmark datasets
  3. Validate overall LFTL performance by comparing with other SFADA methods on multiple benchmarks

## Open Questions the Paper Calls Out

### Open Question 1
How does CAS perform on datasets with significantly different characteristics than VisDA-C, Office-Home, and Office-31? The paper focuses on three specific benchmarks without exploring generalizability to datasets with different characteristics.

### Open Question 2
What is the impact of varying annotation budget beyond tested percentages (1%, 5%, 10%, 20%) on LFTL performance? The paper does not investigate performance with budgets significantly lower or higher than tested percentages.

### Open Question 3
How does VPA compare to other domain alignment techniques in performance and computational efficiency? The paper does not provide comprehensive comparison of VPA to techniques like adversarial training or self-training.

## Limitations
- Limited empirical validation of hypothesis transfer quality between consecutive models in CAS
- No detailed computational benchmarking or wall-clock time comparisons against alternatives
- Claims of continuous improvement need more rigorous statistical validation across varying domain discrepancy levels

## Confidence
- **High Confidence**: Core SFADA problem formulation and experimental methodology
- **Medium Confidence**: State-of-the-art performance claims on benchmark datasets  
- **Low Confidence**: Computational efficiency assertions and continuous improvement guarantees

## Next Checks
1. Conduct ablation studies isolating the impact of hypothesis transfer quality on CAS performance across different domain adaptation scenarios
2. Perform controlled experiments measuring feature representation drift in the VPA vault across multiple adaptation rounds
3. Execute comprehensive computational benchmarking comparing wall-clock time and memory usage against established SFADA methods at varying annotation budget levels