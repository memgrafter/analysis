---
ver: rpa2
title: 'PhonologyBench: Evaluating Phonological Skills of Large Language Models'
arxiv_id: '2404.02456'
source_url: https://arxiv.org/abs/2404.02456
tags:
- syllable
- llms
- words
- word
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces PhonologyBench, a benchmark for evaluating
  the phonological skills of large language models (LLMs) in English. The benchmark
  comprises three tasks: grapheme-to-phoneme conversion, syllable counting, and rhyme
  word generation.'
---

# PhonologyBench: Evaluating Phonological Skills of Large Language Models

## Quick Facts
- **arXiv ID**: 2404.02456
- **Source URL**: https://arxiv.org/abs/2404.02456
- **Reference count**: 33
- **Primary result**: Introduces PhonologyBench to evaluate LLM phonological skills, finding 17% and 45% performance gaps compared to humans on rhyme generation and syllable counting respectively.

## Executive Summary
This paper introduces PhonologyBench, a benchmark designed to evaluate the phonological skills of large language models (LLMs) in English across three tasks: grapheme-to-phoneme conversion, syllable counting, and rhyme word generation. The authors evaluate six widely used LLMs, including both closed-source and open-source models, and find that despite being trained solely on textual data, these models demonstrate notable performance across all tasks. However, significant gaps remain when compared to human performance, particularly in more creative phonological tasks like rhyme generation. The benchmark highlights the importance of studying LLM performance on phonological tasks that impact real-world applications and provides researchers with a tool to evaluate LLMs based on their performance on specific phonological tasks relevant to their downstream applications.

## Method Summary
The authors created PhonologyBench using three datasets: 3,000 words from SIGMORPHON 2021 G2P task for grapheme-to-phoneme conversion, 1,000 sentences from Romance Books and Reddit Short Stories datasets for syllable counting, and 300 words from Spelling Bee Study List and Google One Trillion corpus for rhyme word generation. Six LLMs (GPT-4, Claude-3-Sonnet, GPT-3.5-Turbo, LLaMA-2-13B-Chat, Mistral-7B, Mixtral-8X7B) were evaluated using zero-shot prompting with task-specific prompts. Performance was measured using accuracy metrics for G2P and syllable counting tasks, and success rate for rhyme word generation. The evaluation also examined frequency effects and tokenization strategies on model performance.

## Key Results
- LLMs demonstrate notable performance across all three phonological tasks despite being trained solely on textual data
- Significant performance gaps exist compared to human benchmarks: 17% in rhyme word generation and 45% in syllable counting
- Model performance shows strong frequency dependence, with higher accuracy on high-frequency words (10M+ occurrences) versus low-frequency words (<1M occurrences)
- Whole-word tokenization leads to higher accuracy compared to subword tokenization, indicating loss of phonological information with subword approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs leverage imperfect associations between orthographic and phonological forms learned during pretraining to perform phonological tasks without explicit speech data.
- Mechanism: During pretraining on large-scale text corpora, LLMs encounter patterns linking written forms to their phonetic counterparts (e.g., rhyming patterns, syllable structures) through statistical co-occurrences in training data, enabling them to perform phonological reasoning tasks.
- Core assumption: The training corpus contains sufficient implicit phonological information through patterns, rhymes, and linguistic structures that LLMs can learn and generalize from.
- Evidence anchors:
  - [abstract]: "LLMs can potentially learn imperfect associations between orthographic and phonological forms from the training data."
  - [section]: "Despite being trained solely on textual data, LLMs showcased notable performance on the PhonologyBench tasks."
  - [corpus]: Weak evidence - corpus shows related work on phonological reasoning but lacks direct evidence of orthographic-phonological associations in pretraining data.
- Break condition: If training data lacks sufficient phonological patterns or if task requires phonological reasoning beyond what can be learned from text patterns alone.

### Mechanism 2
- Claim: Word frequency in pretraining data significantly impacts LLM phonological performance.
- Mechanism: High-frequency words appear more often in training data, giving models more exposure to their correct phonological forms, while low-frequency words receive less exposure, resulting in poorer performance on phonological tasks.
- Core assumption: The pretraining corpus distribution reflects real-world word usage patterns, and frequency correlates with phonological knowledge acquisition.
- Evidence anchors:
  - [section]: "We observe that models (including the baseline) generally have higher performance on high-frequency words than on low-frequency words."
  - [section]: "Our dataset comprises 1,000 high-frequency words with more than 10M occurrences and 2,000 low-frequency words that occur less than 1M in pretraining corpora."
  - [corpus]: No direct evidence in corpus about word frequency effects on phonological performance.
- Break condition: If word frequency distribution in pretraining data doesn't correlate with phonological knowledge, or if models use alternative strategies for rare words.

### Mechanism 3
- Claim: Tokenization strategy affects phonological task performance by preserving or fragmenting phonological information.
- Mechanism: Whole-word tokenization preserves complete phonological units, while subword tokenization splits words into fragments that may lose phonological structure, impacting the model's ability to generate correct phonemes or count syllables.
- Core assumption: Phonological information is best preserved when words remain intact during tokenization rather than being split into subword units.
- Evidence anchors:
  - [section]: "Results in Table 3 show that LLMs achieve higher accuracy with whole-word tokens compared to split-word tokens."
  - [section]: "This highlights that subword tokenization may lead to loss of phonological information that eventually affects the phonological skills of LLMs."
  - [corpus]: No direct evidence in corpus about tokenization effects on phonological tasks.
- Break condition: If tokenization strategy has minimal impact on phonological performance, or if models can recover phonological information from subword fragments.

## Foundational Learning

- Concept: Grapheme-to-Phoneme Conversion
  - Why needed here: Understanding the relationship between written symbols (graphemes) and their corresponding sounds (phonemes) is fundamental to evaluating how well LLMs can convert written text to phonetic representations.
  - Quick check question: What is the IPA transcription for the word "cat" in American English?

- Concept: Syllable Structure and Counting
  - Why needed here: Syllable counting requires understanding vowel-consonant patterns and how they form pronunciation units, which is essential for evaluating phonological awareness in LLMs.
  - Quick check question: How many syllables are in the word "beautiful"?

- Concept: Rhyme Generation Principles
  - Why needed here: Rhyme generation depends on understanding sound patterns and phonological similarities between words, which tests whether LLMs have learned these patterns from text alone.
  - Quick check question: What are five words that rhyme with "light"?

## Architecture Onboarding

- Component map: Data curation -> Prompt engineering -> Model inference -> Performance measurement -> Analysis by task and model type
- Critical path: Data curation → Prompt engineering → Model inference → Performance measurement → Analysis of results by task and model type
- Design tradeoffs: The benchmark trades comprehensive phonological coverage for focused evaluation on three core tasks, and uses zero-shot prompting rather than fine-tuning to maintain generality across different LLM architectures
- Failure signatures: Models failing on rare words indicates frequency dependence; poor performance on complex sentences suggests limitations with syntactic complexity; tokenization-related failures point to architectural constraints in handling phonological information
- First 3 experiments:
  1. Run all models on the high-frequency subset of the G2P task to establish baseline performance and identify frequency effects
  2. Test whole-word vs split-word tokenization on the same G2P dataset to measure tokenization impact
  3. Compare model performance on simple vs complex sentences in the syllable counting task to assess syntactic complexity effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLMs on phonological tasks vary across different languages and dialects?
- Basis in paper: [inferred] The paper focuses on American English and acknowledges that future studies can explore multilingual phonological phenomena and different dialects.
- Why unresolved: The current benchmark is limited to American English, and there is no data or analysis on how LLMs perform on other languages or dialects.
- What evidence would resolve it: A multilingual extension of PhonologyBench that includes tasks and datasets for various languages and dialects, followed by a comprehensive evaluation of LLMs on these tasks.

### Open Question 2
- Question: What is the impact of incorporating phonetic data during LLM pretraining on their phonological task performance?
- Basis in paper: [explicit] The paper suggests that adding more phonological data during pretraining could improve LLM performance on phonological tasks and mentions prior work showing the efficacy of joint textual and phonetic embeddings.
- Why unresolved: The paper does not conduct experiments to directly measure the impact of phonetic data on LLM performance, relying instead on theoretical suggestions.
- What evidence would resolve it: An experimental study comparing LLM performance on phonological tasks with and without access to phonetic data during pretraining, controlling for other variables.

### Open Question 3
- Question: How do different tokenization strategies affect LLM performance on phonological tasks, and can alternative strategies improve performance?
- Basis in paper: [explicit] The paper discusses the impact of subword tokenization on phoneme generation, showing that whole-word tokens lead to better performance than split-word tokens.
- Why unresolved: The paper only explores one alternative tokenization strategy (whole-word tokens) and does not investigate other potential strategies or their impact on different phonological tasks.
- What evidence would resolve it: A systematic evaluation of various tokenization strategies (e.g., character-level, word-level, mixed approaches) on LLM performance across all phonological tasks in the benchmark.

## Limitations

- The benchmark focuses exclusively on American English, limiting generalizability to other languages and dialects
- Performance gaps of 17% and 45% compared to human benchmarks indicate significant limitations in creative phonological reasoning tasks
- Tokenization strategies fundamentally constrain phonological information processing, with subword tokenization fragmenting phonological units

## Confidence

**High Confidence**: The finding that LLMs achieve strong performance on grapheme-to-phoneme conversion (G2P) tasks using only text-based training data. This is well-supported by the SIGMORPHON 2021 benchmark comparisons and multiple model evaluations showing consistent performance across different architectures.

**Medium Confidence**: The claim that frequency effects significantly impact phonological task performance. While the paper shows clear performance differences between high and low-frequency words, the underlying mechanism (memorization vs. learned patterns) remains uncertain without deeper analysis of model behavior.

**Low Confidence**: The assertion that LLMs have learned "imperfect associations between orthographic and phonological forms" from text alone. This remains a hypothesis requiring validation through ablation studies or analysis of intermediate representations, as the paper doesn't directly examine what phonological knowledge models actually learn during training.

## Next Checks

1. **Frequency Analysis Validation**: Conduct a detailed analysis of model performance across a broader frequency spectrum (e.g., 10 frequency bands from 100K to 100M occurrences) to determine if the relationship between frequency and performance follows a predictable pattern, and whether this pattern differs across phonological tasks.

2. **Tokenization Impact Study**: Systematically test the same models with different tokenization strategies (word-piece, byte-pair encoding, sentence-piece) on the G2P task to quantify how tokenization choice affects phonological accuracy and identify whether certain tokenizers preserve phonological information better than others.

3. **Human Comparison Protocol**: Design a controlled human evaluation protocol using the same test sets to precisely measure the 17% and 45% performance gaps, ensuring that human performance is measured under equivalent conditions and that the gap is not due to evaluation methodology differences rather than true capability differences.