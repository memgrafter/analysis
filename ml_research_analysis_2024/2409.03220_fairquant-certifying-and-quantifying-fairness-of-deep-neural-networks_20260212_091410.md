---
ver: rpa2
title: 'FairQuant: Certifying and Quantifying Fairness of Deep Neural Networks'
arxiv_id: '2409.03220'
source_url: https://arxiv.org/abs/2409.03220
tags:
- input
- fairness
- cation
- partition
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FairQuant is a method for certifying and quantifying individual
  fairness of deep neural networks. It addresses the challenge of verifying that similar
  individuals are treated similarly, regardless of protected attributes like gender
  or race.
---

# FairQuant: Certifying and Quantifying Fairness of Deep Neural Networks

## Quick Facts
- **arXiv ID**: 2409.03220
- **Source URL**: https://arxiv.org/abs/2409.03220
- **Reference count**: 40
- **Key outcome**: FairQuant is a method for certifying and quantifying individual fairness of deep neural networks, achieving fair certification rates of up to 94% while running orders of magnitude faster than existing methods.

## Executive Summary
FairQuant is a method for certifying and quantifying individual fairness in deep neural networks (DNNs). It addresses the challenge of verifying that similar individuals are treated similarly regardless of protected attributes like gender or race. The method combines symbolic interval-based analysis with iterative refinement guided by fairness properties. Unlike existing approaches, FairQuant provides both qualitative certification (fair/unfair/undecided) and quantitative measurement (percentage of fair/unfair inputs). It was evaluated on DNNs trained on four popular fairness datasets, demonstrating significant improvements in accuracy and speed compared to state-of-the-art techniques.

## Method Summary
FairQuant uses symbolic interval analysis to overapproximate DNN behavior, avoiding the exponential blowup of enumerating all concrete inputs. It defines symbolic intervals for inputs with different protected attribute values, then propagates these through the network using interval arithmetic. When forward analysis returns "undecided," the method splits the input partition along the attribute with the highest smear value (gradient × range), focusing refinement where it most affects output differences between protected groups. After certifying or falsifying a partition, the method updates global certification/falsification rates by adding the partition's fraction of the input domain, providing lower bounds on certified and falsified percentages.

## Key Results
- FairQuant achieved fair certification rates of up to 94% on some models
- The method runs orders of magnitude faster than existing fairness certification approaches
- FairQuant provides both qualitative certification and quantitative measurement of fairness, lifting symbolic interval analysis from conventional qualitative to quantitative certification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Symbolic interval analysis overapproximates DNN behavior in a way that is both sound and scalable compared to SMT-based methods.
- **Mechanism**: The method assigns symbolic intervals to inputs and propagates them through the network using interval arithmetic.
- **Core assumption**: The network's behavior on the symbolic interval includes all possible concrete behaviors for inputs in that partition.
- **Evidence anchors**: [abstract], [section V.A], [corpus]
- **Break condition**: If the network contains operations that cannot be soundly overapproximated by intervals, the method may become unsound or overly conservative.

### Mechanism 2
- **Claim**: Iterative refinement guided by fairness properties efficiently partitions the input space to increase the accuracy of fairness certification.
- **Mechanism**: When forward analysis returns "undecided," the method splits the input partition along the attribute with the highest smear value.
- **Core assumption**: Partitioning along high-influence attributes reduces approximation error more effectively than random or uniform splits.
- **Evidence anchors**: [abstract], [section VI.B], [corpus]
- **Break condition**: If the gradient computation is too coarse or the network is highly non-linear, refinement may not converge to a decisive partition within the depth limits.

### Mechanism 3
- **Claim**: Quantitative fairness measurement provides actionable feedback by computing lower bounds on certified and falsified percentages.
- **Mechanism**: After certifying or falsifying a partition, the method updates global rates by adding the partition's fraction of the input domain.
- **Core assumption**: The symbolic interval analysis is sound, so when it declares a partition fair/unfair, the declaration holds for all concrete inputs in that partition.
- **Evidence anchors**: [abstract], [section VII], [corpus]
- **Break condition**: If the symbolic intervals become too conservative, the method may undercount fair/unfair inputs, leading to lower rates than actually achievable.

## Foundational Learning

- **Concept**: Individual fairness definition and its distinction from group fairness.
  - **Why needed here**: The method certifies that similar individuals (differing only in protected attributes) receive the same output.
  - **Quick check question**: What is the difference between individual fairness and group fairness? Answer: Individual fairness requires similar individuals to be treated similarly; group fairness requires similar demographic groups to be treated similarly.

- **Concept**: Symbolic interval analysis and its soundness guarantees.
  - **Why needed here**: The method relies on sound overapproximation of DNN behavior using intervals.
  - **Quick check question**: Why does symbolic interval analysis provide soundness? Answer: Because the computed interval contains all possible concrete outputs for inputs in the partition.

- **Concept**: Gradient-based refinement heuristics (smear value).
  - **Why needed here**: The method uses gradients to decide which attribute to split.
  - **Quick check question**: How is the smear value computed? Answer: smear(xi) = g(xi) × |ub(xi) − lb(xi)|, where g(xi) is the gradient and the range is the input interval length.

## Architecture Onboarding

- **Component map**: SYMBOLIC_FORWARD() -> BACKWARD_REFINEMENT() -> QUANTIFY_FAIRNESS()
- **Critical path**: SYMBOLIC_FORWARD() → (if undecided) BACKWARD_REFINEMENT() → QUANTIFY_FAIRNESS(). The loop continues until stack empty or timeout.
- **Design tradeoffs**:
  - Soundness vs. precision: Interval analysis is sound but can be overly conservative, leading to many undecided partitions.
  - Depth limits: Setting min_sample_depth=15 and max_refinement_depth=20 balances speed and accuracy but may leave some inputs undecided.
  - Sampling vs. splitting: After depth 15, the method samples for counterexamples instead of further splitting, trading completeness for speed.
- **Failure signatures**:
  - Too many undecided partitions: Indicates overly conservative intervals or insufficient refinement depth.
  - Slow convergence: Suggests poor choice of split attribute or network with many non-linearities.
  - Incorrect fairness rates: Could indicate bugs in interval propagation or rate computation.
- **First 3 experiments**:
  1. Run on a small synthetic network (2-3 layers, ReLU) with known fair/unfair regions to verify correctness of fairness decisions.
  2. Vary max_refinement_depth on a medium network to observe tradeoff between undecided rate and runtime.
  3. Compare smear value split vs. random split on a network to validate refinement heuristic.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does FairQuant's performance scale with increasing network depth and width, particularly for models with 10,000+ neurons?
- **Basis in paper**: [explicit] The paper mentions testing on models up to 10,000 neurons, but doesn't provide detailed scaling analysis or results for even larger networks
- **Why unresolved**: The experimental results only cover models up to 10,000 neurons, leaving uncertainty about performance on much larger models
- **What evidence would resolve it**: Systematic testing of FairQuant on progressively larger models (e.g., 20K, 50K, 100K+ neurons) with runtime and accuracy measurements

### Open Question 2
- **Question**: How does FairQuant perform on neural networks with non-ReLU activation functions like sigmoid, tanh, or Swish?
- **Basis in paper**: [explicit] The paper states FairQuant can be extended to non-ReLU activations but only evaluates on ReLU networks, with generalization mentioned only as a theoretical possibility
- **Why unresolved**: The theoretical extension is mentioned but not experimentally validated, leaving uncertainty about practical effectiveness and any modifications needed
- **What evidence would resolve it**: Experimental evaluation of FairQuant on networks using various non-ReLU activation functions, comparing performance and accuracy to ReLU networks

### Open Question 3
- **Question**: What is the impact of different population distributions (non-uniform) on FairQuant's fairness quantification accuracy?
- **Basis in paper**: [inferred] The paper mentions the method can be extended to non-uniform distributions but only demonstrates uniform distribution case, suggesting this is an area for future work
- **Why unresolved**: The paper only demonstrates the uniform distribution case and mentions non-uniform extension as possible but doesn't validate it experimentally
- **What evidence would resolve it**: Comparative experiments showing FairQuant's accuracy under various realistic population distributions versus uniform distribution baseline

### Open Question 4
- **Question**: How does FairQuant's refinement strategy compare to alternative partitioning methods (like static partitioning used in Fairify) in terms of both accuracy and computational efficiency?
- **Basis in paper**: [explicit] The paper claims iterative refinement is more effective than static partitioning but doesn't provide direct experimental comparison of these approaches
- **Why unresolved**: The paper mentions the advantage of iterative refinement over static partitioning but doesn't directly compare these approaches under controlled conditions
- **What evidence would resolve it**: Head-to-head experimental comparison of FairQuant's iterative refinement against static partitioning approaches on identical benchmarks with runtime and accuracy metrics

### Open Question 5
- **Question**: What is the trade-off between the refinement depth thresholds (min_sample_depth and max_refinement_depth) and FairQuant's performance in terms of speed versus accuracy?
- **Basis in paper**: [explicit] The paper uses fixed threshold values (15 and 20) but doesn't explore how different values affect performance or provide guidance on optimal parameter selection
- **Why unresolved**: The paper uses fixed parameter values without exploring the parameter space or providing sensitivity analysis
- **What evidence would resolve it**: Systematic parameter sensitivity analysis showing how different threshold values affect runtime, certification rates, and undecided percentages across various benchmarks

## Limitations
- The interval arithmetic approach may become overly conservative for networks with complex non-linear behaviors, leading to high undecided rates.
- The gradient-based refinement heuristic lacks empirical validation against alternative splitting strategies.
- The method's performance on non-ReLU activation functions has not been experimentally validated.

## Confidence

- **High Confidence**: The quantitative fairness measurement mechanism (lower bounds on certified/falsified percentages) is sound due to the interval analysis guarantees. The basic architecture of forward analysis followed by iterative refinement is well-established in DNN verification literature.
- **Medium Confidence**: The effectiveness of the smear value heuristic for refinement depends on the quality of gradient approximations and may not generalize to all network architectures.
- **Low Confidence**: The claim of significant improvements in both accuracy and speed compared to existing methods requires careful scrutiny, as the benchmarks and comparison metrics are not fully specified.

## Next Checks

1. **Formal Verification of Soundness**: Develop a formal proof or counterexample showing whether the interval analysis maintains soundness when propagating through ReLU activations with overlapping bounds.

2. **Refinement Strategy Comparison**: Implement and compare the smear value heuristic against random splitting and other refinement strategies on benchmark networks to quantify the actual improvement in undecided rate reduction.

3. **Generalization Test**: Apply FairQuant to a diverse set of network architectures beyond those presented in the paper (e.g., convolutional networks, networks with sigmoid/tanh activations) to assess the method's robustness and identify failure modes.