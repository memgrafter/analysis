---
ver: rpa2
title: 'Retail-GPT: leveraging Retrieval Augmented Generation (RAG) for building E-commerce
  Chat Assistants'
arxiv_id: '2408.08925'
source_url: https://arxiv.org/abs/2408.08925
tags:
- user
- chatbot
- product
- cart
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of building a reliable, open-source
  chatbot for retail e-commerce that can guide users through product recommendations
  and cart operations while avoiding overreliance on commercial chat platforms. The
  authors present Retail-GPT, a system that combines a Dual Intent and Entity Transformer
  (DIET) classifier with a large language model (GPT-4o) via a Retrieval-Augmented
  Generation (RAG) framework, integrated with external product search and cart management
  tools.
---

# Retail-GPT: leveraging Retrieval Augmented Generation (RAG) for building E-commerce Chat Assistants

## Quick Facts
- arXiv ID: 2408.08925
- Source URL: https://arxiv.org/abs/2408.08925
- Reference count: 0
- Open-source RAG-based chatbot for retail e-commerce with 70-100% tool selection accuracy

## Executive Summary
This work presents Retail-GPT, an open-source RAG-based chatbot for retail e-commerce that combines a Dual Intent and Entity Transformer (DIET) classifier with GPT-4o via function calling. The system handles product recommendations, cart operations, and checkout through a hybrid architecture that routes queries between pre-written responses and LLM generation. Qualitative tests show natural conversation capabilities and successful task completion, while quantitative evaluation using a custom test set indicates 70-100% accuracy in tool selection but reveals security vulnerabilities with 75% robustness against prompt injection attacks.

## Method Summary
Retail-GPT uses a DIET classifier to route user messages to either pre-written responses or an LLM subsystem (GPT-4o via OpenAI API). The LLM generates function calls for product search, cart operations, and purchase completion, with conversation history maintained in Redis. Input messages pass through guardrails for moderation and jailbreak detection before reaching the LLM. The system was tested on a fictional 50-product dataset with custom test sets for tool call accuracy and security evaluation.

## Key Results
- Tool selection accuracy ranges from 60% (cart additions) to 100% (product search and off-topic handling)
- System correctly identifies appropriate tool to use in 70-100% of cases across different operations
- Security analysis shows 75% robustness against prompt injection attacks, with 25% of attempts succeeding
- Qualitative tests demonstrate natural conversation capabilities and successful completion of retail tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The DIET classifier effectively routes user messages to either pre-written responses or LLM-based generation, reducing hallucination risk and computational cost.
- Mechanism: The DIET classifier acts as a first filter, extracting intents and entities from user messages. Based on classification results, the system either serves pre-written responses for common queries or delegates to the LLM for complex, context-dependent responses.
- Core assumption: DIET can accurately classify user intents and entities to determine appropriate response routing.
- Evidence anchors:
  - [section] "the classifier can delegate message processing to the LLM-based subsystem when needed"
  - [section] "a lighter Natural Language Processing (NLP) approach composed by a transformer-based message classifier and pre-written responses"
- Break condition: If DIET's classification accuracy drops below a threshold (estimated around 70% based on tool selection results), the system will frequently misroute messages, leading to inappropriate responses or unnecessary LLM calls.

### Mechanism 2
- Claim: RAG framework with function calling enables the chatbot to interact with external systems (product search, cart operations) while maintaining conversational context.
- Mechanism: The LLM generates function calls for specific operations (product search, cart editing, purchase completion) based on user intent. The system maintains conversation history in a database to provide context for these operations.
- Core assumption: The LLM can reliably generate correct function calls with appropriate arguments when prompted correctly.
- Evidence anchors:
  - [section] "The LLM's textual response is then checked for appropriateness before being returned to the user. Alternatively, the LLM generates one of three function calls: purchase completion, cart operations, or product search"
  - [section] "The chatbot can process multiple function calls concurrently for efficiency"
- Break condition: If the LLM generates malformed function calls or incorrect arguments (as evidenced by the 60% accuracy for cart additions), the system cannot execute intended operations correctly.

### Mechanism 3
- Claim: Guardrails and input moderation prevent security vulnerabilities while allowing legitimate user interactions.
- Mechanism: Input messages pass through guardrails that block inappropriate content and detect jailbreak attempts before reaching the LLM. This protects against prompt injection attacks and maintains system integrity.
- Core assumption: Guardrails can effectively detect and block malicious inputs while allowing legitimate queries.
- Evidence anchors:
  - [section] "The message first passes through input guardrails to block inappropriate content or sensitive data using moderation models and an LLM designed to detect jailbreak attempts"
  - [section] "in 25% of the prompt injections, the guardrails system and the chatbot prompt were insufficient to prevent RetailGPT from being misled"
- Break condition: If guardrails fail to detect sophisticated prompt injection attacks (as shown by the 75% robustness), malicious users can manipulate the system into providing incorrect information or unauthorized actions.

## Foundational Learning

- Concept: Intent classification and entity extraction
  - Why needed here: Forms the basis for understanding user requests and routing them appropriately through the system
  - Quick check question: How would the system handle a message like "I want to buy a red shirt in size medium" without proper intent classification?

- Concept: Function calling in LLMs
  - Why needed here: Enables the chatbot to interact with external systems and databases while maintaining conversational context
  - Quick check question: What happens if the LLM generates a function call with incorrect arguments, such as missing the product ID for a cart addition?

- Concept: Prompt engineering and few-shot learning
  - Why needed here: Critical for guiding the LLM to generate appropriate responses and function calls
  - Quick check question: How would adding Chain-of-Thought reasoning to the prompt affect the system's ability to handle complex user requests?

## Architecture Onboarding

- Component map:
  User Interface → Message Processor → DIET Classifier → (Pre-written Responses OR LLM Subsystem)
  LLM Subsystem → Guardrails → Function Call Generator → External Systems (Product Search, Cart DB, Redis)
  All components → Conversation History Database

- Critical path: User message → DIET classification → LLM with guardrails → Function call generation → External system interaction → Response to user

- Design tradeoffs:
  - DIET classifier vs. pure LLM: Reduced computational cost and hallucination risk vs. potentially lower flexibility in handling novel queries
  - Pre-written responses vs. LLM generation: Guaranteed accuracy for common queries vs. inability to handle variations
  - Guardrails complexity vs. user experience: Better security vs. potential false positives blocking legitimate requests

- Failure signatures:
  - High rate of malformed function calls → LLM prompt engineering issue
  - Frequent misclassification by DIET → Need for retraining or threshold adjustment
  - Security vulnerabilities → Guardrail bypass or insufficient input validation

- First 3 experiments:
  1. Test DIET classifier accuracy on a labeled dataset of e-commerce user messages to establish baseline performance
  2. Validate LLM function call generation with various user inputs, measuring success rate and hallucination frequency
  3. Security penetration testing with prompt injection attempts to evaluate guardrail effectiveness and identify vulnerabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Retail-GPT perform with larger, more diverse product catalogs compared to the 50-product dataset used in this study?
- Basis in paper: [inferred] The authors note that the search mechanism was mocked using a fictional dataset of around 50 products and that alternative approaches could be tested in future work.
- Why unresolved: The study used a limited product set, and performance may degrade with larger, more complex catalogs due to increased search complexity and potential LLM confusion.
- What evidence would resolve it: Quantitative evaluation of Retail-GPT's accuracy and response time with catalogs of varying sizes (e.g., 100, 500, 1000+ products) and diversity.

### Open Question 2
- Question: Can the security vulnerabilities identified in Retail-GPT (e.g., susceptibility to prompt injection attacks) be mitigated through more advanced guardrail mechanisms without significantly impacting usability?
- Basis in paper: [explicit] The authors found that 25% of prompt injection attempts succeeded, and they suggest that more rigid guardrails are needed for production environments.
- Why unresolved: While the authors acknowledge the security issues, they did not implement or test enhanced guardrail mechanisms, leaving the trade-off between security and usability unexplored.
- What evidence would resolve it: Testing of Retail-GPT with advanced guardrail systems (e.g., fine-tuned moderation models, adversarial training) and evaluation of their impact on both security robustness and user experience.

### Open Question 3
- Question: How does the inclusion of Chain-of-Thought (CoT) reasoning or ReAct techniques affect the accuracy and reliability of Retail-GPT's tool selection and response generation?
- Basis in paper: [explicit] The authors suggest that adding CoT reasoning or ReAct techniques could minimize LLM errors and enhance system robustness but did not implement these approaches.
- Why unresolved: The potential benefits of CoT or ReAct were hypothesized but not empirically tested, leaving their impact on system performance unknown.
- What evidence would resolve it: Comparative evaluation of Retail-GPT with and without CoT or ReAct techniques, measuring tool selection accuracy, hallucination rates, and overall user satisfaction.

## Limitations
- Small test set size limits generalizability of quantitative results
- Security vulnerabilities with 25% of prompt injection attempts succeeding
- LLM-based product search not scalable to large inventories
- Lack of analysis of computational costs and latency metrics

## Confidence

- **High Confidence:** The architectural design combining DIET classifier with LLM function calling is technically sound and follows established RAG patterns. The qualitative demonstrations of basic functionality (product search, cart operations, checkout) are credible given the described implementation.

- **Medium Confidence:** The quantitative evaluation results (70-100% tool selection accuracy, 75% security robustness) are internally consistent with the methodology described, but the small test set size and lack of comparison to baseline approaches reduces confidence in these specific metrics.

- **Low Confidence:** Claims about production readiness and user experience quality cannot be substantiated without larger-scale testing, real-world deployment data, or comparison with commercial alternatives.

## Next Checks

1. **Expand Test Coverage:** Develop a larger, diverse test dataset (minimum 500-1000 examples) covering varied user intents, edge cases, and malicious inputs to provide statistically meaningful performance metrics across all system components.

2. **Security Penetration Testing:** Conduct systematic security testing using established prompt injection attack patterns and adversarial examples to identify specific guardrail bypass mechanisms and measure true robustness against sophisticated attacks.

3. **End-to-End Latency and Cost Analysis:** Measure system performance under realistic load conditions, including DIET classification time, LLM response latency, and total cost per conversation, to assess scalability and economic viability for production deployment.