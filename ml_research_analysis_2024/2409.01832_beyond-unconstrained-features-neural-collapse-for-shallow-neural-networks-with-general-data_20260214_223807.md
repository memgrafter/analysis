---
ver: rpa2
title: 'Beyond Unconstrained Features: Neural Collapse for Shallow Neural Networks
  with General Data'
arxiv_id: '2409.01832'
source_url: https://arxiv.org/abs/2409.01832
tags: []
core_contribution: This paper studies the emergence of neural collapse (NC) in shallow
  ReLU neural networks with general datasets, extending beyond unconstrained feature
  models (UFM) used in prior works. The authors focus on two-layer and three-layer
  ReLU networks and investigate how network width, depth, data dimension, and statistical
  properties influence NC.
---

# Beyond Unconstrained Features: Neural Collapse for Shallow Neural Networks with General Data

## Quick Facts
- **arXiv ID**: 2409.01832
- **Source URL**: https://arxiv.org/abs/2409.01832
- **Authors**: Wanli Hong; Shuyang Ling
- **Reference count**: 40
- **Primary result**: This paper studies the emergence of neural collapse (NC) in shallow ReLU neural networks with general datasets, extending beyond unconstrained feature models (UFM) used in prior works.

## Executive Summary
This paper extends the understanding of neural collapse (NC) beyond unconstrained feature models to shallow ReLU neural networks with general datasets. The authors investigate when NC emerges in two-layer and three-layer ReLU networks, focusing on how network width, depth, data dimension, and statistical properties influence this phenomenon. They provide a complete characterization showing that for two-layer networks, NC depends on data dimension, sample size, and signal-to-noise ratio rather than network width. For three-layer networks, NC occurs as long as the first layer is sufficiently wide. The paper also demonstrates that NC does not guarantee good generalization, which heavily depends on the SNR in the data.

## Method Summary
The paper analyzes shallow ReLU neural networks (two-layer and three-layer) trained with ℓ2-loss and cross-entropy loss using regularized empirical risk minimization. The authors theoretically characterize when neural collapse occurs by examining conditions on the feature matrix rank, data linear separability, and signal-to-noise ratio. They use Gaussian mixture models as benchmark datasets and prove theorems establishing sufficient conditions for NC emergence in different network architectures. The analysis combines optimization theory with statistical learning principles to understand the relationship between network architecture, data properties, and NC.

## Key Results
- For two-layer ReLU networks, NC emergence depends on data dimension d ≥ N, sample size, and SNR rather than network width.
- Three-layer ReLU networks exhibit NC as long as the first layer is sufficiently wide to produce full-rank random features.
- NC does not guarantee good generalization; generalization performance heavily depends on SNR even when NC occurs.
- The paper provides complete characterization of NC conditions for shallow networks, extending beyond unconstrained feature models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural collapse emerges in shallow ReLU networks when the first layer produces a feature matrix of full column rank, enabling orthogonal class mean alignment.
- Mechanism: The paper proves that for a two-layer network, NC occurs if the ReLU feature matrix σReLU(W1^TX) has full column rank (rank N), which requires the input dimension d ≥ N or cluster separation sufficient to allow linear feasibility. For three-layer networks, NC occurs as long as the first layer is wide enough to produce a full-rank random feature matrix.
- Core assumption: The data is balanced, and the activation regularization term encourages collapse by penalizing feature variance.
- Evidence anchors:
  - [abstract]: "For two-layer ReLU neural networks, a sufficient condition on when the global minimizer of the regularized empirical risk function exhibits the NC configuration depends on the data dimension, sample size, and the signal-to-noise ratio in the data instead of the network width."
  - [section]: "Theorem 2.2 (Neural collapse for general datasets). For any general dataset X, we have the following results: (a) Suppose X is not linearly separable, then the neural collapse does not occur."
  - [corpus]: Weak evidence. The corpus papers focus on unconstrained models or deep networks, not on the shallow ReLU analysis presented here.
- Break condition: If the data is not linearly separable (Theorem 2.2a), or if d < N and the cluster separation is insufficient (Theorem 2.3), then NC does not occur.

### Mechanism 2
- Claim: The signal-to-noise ratio (SNR) in the data determines whether NC occurs in shallow networks, not network width.
- Mechanism: Under Gaussian mixture models, the paper shows that NC is more likely when σ (noise) is small relative to ∥μ∥ (signal), quantified by conditions like σ ≲ (1-ε)√((d-n)/d log n)∥μ∥. This shows NC depends on data separability, not width.
- Core assumption: The data follows a Gaussian mixture model with K clusters, each of size n, and the cluster means μk are separated.
- Evidence anchors:
  - [abstract]: "For a two-layer neural network, even if it is sufficiently wide, the NC may not occur if the dimension of input data is not sufficiently large."
  - [section]: "Theorem 2.3 (Neural collapse for GMM with two clusters). Let 0 < ε < 1, 2n ≥ d > n+Cε^-2 log n, and θ be the angle between μ1 and μ2. With probability at least 1− O(n^-1), (2.12) is feasible..."
  - [corpus]: Weak evidence. Corpus papers do not address SNR dependence in shallow networks.
- Break condition: If SNR is too low (σ large relative to ∥μ∥), then NC does not occur even if d ≥ N.

### Mechanism 3
- Claim: NC does not guarantee good generalization; generalization heavily depends on SNR even when NC occurs.
- Mechanism: The paper analyzes a simplified two-neuron classifier under NC and shows that the misclassiﬁcation error is bounded by Φ(-⟨μ,β⟩/(σ∥β∥)). For high SNR, this error can be small; for low SNR, it remains large even with NC.
- Core assumption: The data is from a two-cluster GMM, and the classifier is reduced to a two-neuron model exploiting NC.
- Evidence anchors:
  - [abstract]: "Regarding the connection between NC and generalization, we show the generalization heavily depends on the SNR (signal-to-noise ratio) in the data: even if the NC occurs, the generalization can still be bad provided that the SNR in the data is too low."
  - [section]: "Theorem 2.7 (Misclassiﬁcation of a two-neuron classiﬁer under the N C). Consider f(x) = gβ1(x) − gβ2(x) in (2.24) where βk ∈ C k for k = 1, 2. (a) Under the assumption of Theorem 2.6(a), there exists βk ∈ C k such that the misclassiﬁcation error of f(x) in (2.24) is bounded by O(n^-2);"
  - [corpus]: Weak evidence. Corpus papers focus on NC properties, not generalization under noise.
- Break condition: If SNR is low, even with NC, the misclassiﬁcation error remains high.

## Foundational Learning

- Concept: Linear separability of data clusters
  - Why needed here: NC in shallow networks requires that each class can be separated by a hyperplane, which is equivalent to the linear feasibility condition Xk^⊤βk = 1n for each class k.
  - Quick check question: Given a dataset X with K classes of size n each, what condition on X guarantees that there exists β such that Xk^⊤β = 1n for all k?
- Concept: Signal-to-noise ratio (SNR) in classification
  - Why needed here: The paper shows that NC emergence and generalization depend critically on the ratio of cluster separation (signal) to within-cluster variance (noise).
  - Quick check question: If data is sampled from a GMM with means μk and noise σ, how does increasing σ affect the probability of NC occurring?
- Concept: Full column rank of feature matrices
  - Why needed here: For NC to occur, the ReLU feature matrix must have full column rank to allow orthogonal alignment of class means.
  - Quick check question: What is the minimum width D of a two-layer ReLU network such that σReLU(W1^TX) can have full column rank for a dataset of N points?

## Architecture Onboarding

- Component map: Two-layer network: input → W1 (d×D) → ReLU → W (D×K) → output. Three-layer network: input → W1 (d×d1) → ReLU → W2 (d1×D) → ReLU → W (D×K) → output.
- Critical path: Feature extraction (W1, W2) → regularization (activation penalty) → alignment (orthogonal class means) → classification (W).
- Design tradeoffs: Wider networks (larger D or d1) increase the chance of full-rank features but add parameters. Activation regularization λH encourages collapse but may slow convergence.
- Failure signatures: NC does not occur if data is not linearly separable, or if SNR is too low. Training may stall if λH is too high.
- First 3 experiments:
  1. Generate GMM data with varying σ/∥μ∥ and d/n ratios; train a two-layer ReLU network; measure NC1 metric.
  2. Fix d ≥ N, vary σ; check if NC occurs and measure generalization error.
  3. Train a three-layer network with random W1; verify NC occurs as d1 increases.

## Open Questions the Paper Calls Out
None

## Limitations
- The theoretical analysis relies on idealized assumptions (balanced classes, specific loss functions, and regularization) that may not hold in practical settings.
- The extension from unconstrained feature models to ReLU networks introduces approximation gaps that are not fully characterized.
- The paper's analysis of generalization under low SNR conditions shows that NC does not guarantee good performance, but the bounds provided may not capture the full complexity of real-world datasets.

## Confidence
- **High confidence** in the characterization of NC conditions for two-layer networks when data is linearly separable and d ≥ N.
- **Medium confidence** in the SNR-dependent emergence of NC for GMM data.
- **Medium confidence** in the three-layer network results.

## Next Checks
1. Test the linear separability condition empirically by training two-layer networks on datasets with controlled d/n ratios and measuring the NC1 metric to verify the phase transition predicted by Theorem 2.3.
2. Verify the SNR dependence by generating GMM data with systematically varying σ/∥μ∥ ratios and confirming that NC emergence follows the theoretical predictions in both two-layer and three-layer architectures.
3. Validate the generalization claims by training networks with NC under different SNR conditions and measuring actual test error, comparing results with the theoretical bounds on misclassification error.