---
ver: rpa2
title: Adaptive Group Robust Ensemble Knowledge Distillation
arxiv_id: '2411.14984'
source_url: https://arxiv.org/abs/2411.14984
tags:
- ensemble
- teachers
- student
- teacher
- distillation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how ensemble knowledge distillation affects
  model robustness to spurious correlations, where models rely on unintended features
  (e.g., background) for predictions. The authors show that traditional ensemble knowledge
  distillation can amplify bias and hurt worst-group accuracy, even when teachers
  are debiased.
---

# Adaptive Group Robust Ensemble Knowledge Distillation

## Quick Facts
- arXiv ID: 2411.14984
- Source URL: https://arxiv.org/abs/2411.14984
- Reference count: 40
- One-line primary result: AGRE-KD improves worst-group accuracy compared to baselines, sometimes outperforming deep ensemble teachers themselves

## Executive Summary
This paper studies how ensemble knowledge distillation affects model robustness to spurious correlations, where models rely on unintended features (e.g., background) for predictions. The authors show that traditional ensemble knowledge distillation can amplify bias and hurt worst-group accuracy, even when teachers are debiased. To address this, they propose Adaptive Group Robust Ensemble Knowledge Distillation (AGRE-KD), which uses a biased model to guide teacher weighting based on gradient direction similarity, upweighting teachers that deviate from the biased model. Experiments on synthetic (Colored MNIST) and real-world datasets (Waterbirds, CelebA, CivilComments) show AGRE-KD significantly improves worst-group accuracy compared to baselines, sometimes outperforming deep ensemble teachers themselves.

## Method Summary
The method uses a biased ERM model to compute per-sample weights for teachers based on gradient direction similarity. For each batch, it computes KD loss and gradient for each teacher, then calculates dot products between normalized gradients of each teacher and the biased model. Teachers whose gradients align closely with the biased model are downweighted, preventing the student from reinforcing spurious correlations. Some teachers are debiased using Deep Feature Reweighting (DFR) by retraining only their last layer with group-balanced data. The student is trained using a weighted average of KL losses from teachers, optimizing for both overall accuracy and worst-group accuracy.

## Key Results
- AGRE-KD significantly improves worst-group accuracy compared to baselines across four datasets
- Traditional ensemble knowledge distillation can amplify bias and hurt worst-group accuracy even with debiased teachers
- Self-distillation with larger student capacity also improves robustness
- The method is robust to teacher architecture choices and improves with more debiased teachers in the ensemble

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient-based teacher weighting improves worst-group accuracy by avoiding the bias direction learned by the ERM model.
- Mechanism: AGRE-KD computes dot products between the normalized gradients of each teacher and the biased ERM model. Teachers whose gradients align closely with the ERM model are downweighted, preventing the student from reinforcing spurious correlations.
- Core assumption: The direction of the gradient of the KD loss with a biased teacher points toward solutions that amplify reliance on spurious features.

### Mechanism 2
- Claim: Retraining only the last layer with group-balanced data (DFR) yields debiased teacher outputs that reduce reliance on spurious features in KD.
- Mechanism: After ERM training, the last classification layer is retrained on a small held-out set of group-balanced samples, altering the mapping from learned features to logits without changing feature extraction.
- Core assumption: Spurious correlations are captured primarily in the final classification layer rather than earlier feature representations.

### Mechanism 3
- Claim: Ensemble KD can amplify bias unless debiasing mechanisms are applied, because averaging over biased teachers reinforces the majority spurious direction.
- Mechanism: Simple averaging or random teacher selection in ensemble KD aggregates predictions from models that all rely on the same spurious correlation, magnifying its effect on the student.
- Core assumption: The aggregation of multiple biased models' outputs does not cancel out spurious patterns but instead reinforces them.

## Foundational Learning

- Concept: Gradient similarity via cosine similarity (normalized dot product).
  - Why needed here: AGRE-KD uses the cosine similarity between normalized gradients to compare direction without magnitude noise, ensuring fair teacher weighting.
  - Quick check question: If two gradients are [1, 0] and [0, 1], what is their cosine similarity? (Answer: 0, they are orthogonal.)

- Concept: Knowledge distillation loss as KL divergence between softened softmax outputs.
  - Why needed here: The KD loss drives the student to mimic teacher outputs; in AGRE-KD, this loss is computed separately per teacher and weighted adaptively.
  - Quick check question: What does the temperature parameter τ control in KD? (Answer: Smoothness of the probability distribution.)

- Concept: Group robustness metrics (worst-group accuracy).
  - Why needed here: The paper's evaluation focuses on worst-group accuracy to measure resilience to spurious correlations, not just overall accuracy.
  - Quick check question: How is worst-group accuracy computed? (Answer: Minimum accuracy across all subgroups defined by class-spurious attribute pairs.)

## Architecture Onboarding

- Component map: Pretrained teachers (ERM and DFR variants) -> Biased ERM model (frozen) -> Student model -> Training loop with gradient weighting

- Critical path:
  1. Load teachers and biased model (frozen)
  2. For each batch: compute KD loss and gradient for each teacher
  3. Compute gradient dot products with biased model
  4. Derive sample-wise weights
  5. Compute weighted KD loss and update student
  6. Validate on worst-group accuracy

- Design tradeoffs:
  - Using a biased model as reference is simple but depends on its architecture matching the bias direction
  - Gradient-based weighting ignores magnitude, which may miss confidence signals
  - DFR retraining is computationally cheap but assumes bias lives in last layer

- Failure signatures:
  - Student WGA does not improve despite debiased teachers: likely all teachers share similar bias direction
  - AGRE-KD underperforms Random KD: gradient directions may be too noisy or insufficient diversity
  - Training instability: extreme gradient magnitudes or ill-conditioned dot products

- First 3 experiments:
  1. Verify gradient alignment: compute dot products between biased model and each teacher; ensure some deviate
  2. Test weighting scheme: run AGRE-KD with all teachers biased; confirm it still improves over uniform averaging
  3. Ablate capacity: compare student WGA when using same-capacity vs smaller-capacity student to confirm effect

## Open Questions the Paper Calls Out

- Open Question 1: Does feature-level knowledge distillation (beyond logits) improve worst-group accuracy more than logit-only distillation in AGRE-KD?
  - Basis in paper: [inferred] The authors restrict themselves to logit distillation and mention "leave feature distillation for future exploration."

- Open Question 2: How does AGRE-KD perform when all teachers are strongly biased (e.g., extreme spurious correlation settings)?
  - Basis in paper: [explicit] "the WGA improvement in the proposed method is less pronounced when all teachers in the ensemble are biased" and "opportunity to leverage class labels."

- Open Question 3: Can AGRE-KD maintain its advantages when scaling to larger, more complex datasets like health datasets?
  - Basis in paper: [explicit] "additional evaluation using more complex datasets, such as health datasets, is necessary to validate the approach across a wider range of applications."

- Open Question 4: What is the impact of different temperature scaling strategies on AGRE-KD's performance?
  - Basis in paper: [explicit] "We perform an ablation study by varying the temperature parameter (τ∈{1, 2, 4,...,10}) and analyze its influence on the spurious correlation captured by the student model."

## Limitations
- The method relies on having sufficient diversity among teachers, which may not hold in all settings
- The effectiveness depends on the biased model's architecture matching the bias direction
- Assumes spurious correlations are primarily encoded in the final classification layer, which may not always be true
- Limited evaluation to four well-known benchmarks, not testing on more complex health datasets

## Confidence
- High confidence: The experimental results showing AGRE-KD outperforming baselines on worst-group accuracy across multiple datasets
- Medium confidence: The claim that simple ensemble KD amplifies bias, as this relies on observed performance differences rather than direct causal analysis
- Medium confidence: The mechanism of gradient alignment for debiasing, as the theoretical justification is intuitive but not rigorously proven

## Next Checks
1. Test gradient-based weighting with all biased teachers: Create an ensemble where all teachers capture the same spurious correlation and verify that AGRE-KD still improves over uniform averaging
2. Ablate bias detection mechanism: Replace gradient-based weighting with random or performance-based weighting to quantify the specific contribution of the gradient alignment approach
3. Validate DFR assumption: Compare teacher debiasing performance when retraining earlier layers versus just the last layer to test whether spurious correlations are primarily encoded in the final classification layer