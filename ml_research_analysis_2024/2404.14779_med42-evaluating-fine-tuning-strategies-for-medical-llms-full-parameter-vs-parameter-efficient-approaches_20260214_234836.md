---
ver: rpa2
title: 'Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter
  vs. Parameter-Efficient Approaches'
arxiv_id: '2404.14779'
source_url: https://arxiv.org/abs/2404.14779
tags:
- medical
- fine-tuning
- language
- dataset
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates two fine-tuning strategies\u2014full-parameter\
  \ fine-tuning and parameter-efficient tuning\u2014for adapting Large Language Models\
  \ (LLMs) to the medical domain. A medical LLM, Med42, based on Llama-2, was developed\
  \ using a comprehensive instruction-tuning dataset that combines medical and general\
  \ domain sources."
---

# Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches

## Quick Facts
- arXiv ID: 2404.14779
- Source URL: https://arxiv.org/abs/2404.14779
- Reference count: 10
- Primary result: Full-parameter fine-tuning outperformed LoRA in medical LLM adaptation, with Med42 achieving 72% USMLE accuracy

## Executive Summary
This study evaluates two fine-tuning strategies—full-parameter fine-tuning and parameter-efficient tuning—for adapting Large Language Models (LLMs) to the medical domain. A medical LLM, Med42, based on Llama-2, was developed using a comprehensive instruction-tuning dataset that combines medical and general domain sources. Full-parameter fine-tuning involved updating all 70 billion parameters over 3 epochs, while parameter-efficient tuning via LoRA modified 104 million parameters over 8 epochs. Models were evaluated on medical benchmarks including USMLE, MedQA, PubMedQA, and others in a zero-shot setting. Med42 achieved 72% accuracy on USMLE, outperforming other openly available medical LLMs. Full-parameter fine-tuning consistently outperformed LoRA across most benchmarks, though the gap was small. A decontamination analysis confirmed minimal overlap between training and evaluation data, ensuring result integrity. The study highlights the effectiveness of full-parameter fine-tuning for medical LLMs, while demonstrating that parameter-efficient methods offer a viable alternative when computational resources are constrained.

## Method Summary
The study developed Med42 by fine-tuning Llama-2 on a curated medical instruction-tuning dataset combining medical sources (MedicalQA, PubMedQA, BioASQ, etc.) and general domain sources (Arcee, Alpaca, ShareGPT, etc.). Two fine-tuning strategies were compared: full-parameter fine-tuning (updating all 70B parameters for 3 epochs) and LoRA-based parameter-efficient tuning (updating 104M parameters for 8 epochs). Models were evaluated zero-shot on medical benchmarks including USMLE, MedQA, PubMedQA, MedMCQA, and MMLU. A decontamination analysis was performed to ensure minimal overlap between training and evaluation data. The study used ROCm on AMD GPUs for training and evaluated performance using accuracy metrics.

## Key Results
- Med42 achieved 72% accuracy on USMLE, outperforming other openly available medical LLMs
- Full-parameter fine-tuning consistently outperformed LoRA across most medical benchmarks
- The performance gap between full-parameter and LoRA was relatively small despite the significant difference in parameter updates
- Decontamination analysis confirmed minimal overlap between training and evaluation data, validating result integrity

## Why This Works (Mechanism)
Full-parameter fine-tuning updates all model parameters, allowing comprehensive adaptation to the medical domain and better capture of domain-specific patterns and knowledge. The extensive medical instruction-tuning dataset (combining multiple high-quality medical and general sources) provides rich training signals for the model to learn medical reasoning and knowledge. The zero-shot evaluation setting tests the model's ability to generalize to unseen medical questions without additional adaptation. LoRA achieves parameter efficiency by learning low-rank updates to the original weight matrices, reducing the number of trainable parameters from billions to millions while maintaining reasonable performance.

## Foundational Learning
- **Large Language Models (LLMs)**: Pre-trained transformer-based models that can be fine-tuned for specific domains; needed to understand the base architecture being adapted for medical applications; quick check: model has attention mechanisms and next-token prediction capability
- **Parameter-Efficient Fine-Tuning**: Methods like LoRA that modify only a small subset of parameters during adaptation; needed to reduce computational costs while maintaining performance; quick check: trainable parameters <1% of total model parameters
- **Medical Knowledge Bases**: Structured collections of medical information used for training and evaluation; needed to ensure comprehensive medical domain coverage; quick check: dataset includes multiple medical specialties and question types
- **Decontamination Analysis**: Process of checking for overlap between training and evaluation datasets; needed to ensure evaluation integrity and prevent data leakage; quick check: minimal token overlap between train and test sets
- **Zero-Shot Evaluation**: Testing model performance without any task-specific fine-tuning; needed to assess generalization capability; quick check: no examples from target task in training data
- **Benchmarking in Medical AI**: Standardized evaluation protocols for medical language models; needed to compare performance across different approaches; quick check: established metrics like accuracy on USMLE questions

## Architecture Onboarding

**Component Map**: Dataset -> Pre-training -> Fine-tuning (Full/LoRA) -> Evaluation -> Comparison

**Critical Path**: High-quality medical dataset preparation → comprehensive fine-tuning → rigorous evaluation with decontamination → benchmark comparison

**Design Tradeoffs**: Full-parameter fine-tuning provides better performance but requires significantly more computational resources and memory; LoRA offers computational efficiency with acceptable performance trade-offs; dataset size and quality directly impact final model performance

**Failure Signatures**: Performance degradation on medical benchmarks may indicate insufficient medical domain coverage in training data; overfitting to general domain knowledge suggests poor medical fine-tuning; contamination between train and test sets would invalidate performance claims

**First Experiments**:
1. Evaluate model performance on held-out medical QA pairs to assess domain adaptation quality
2. Compare inference latency and memory usage between full-parameter and LoRA-tuned models
3. Test model robustness by evaluating on adversarial medical questions not present in training data

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Computational resource comparison lacks explicit cost analysis for full-parameter vs. LoRA approaches
- Study focuses on single base model (Llama-2) and specific parameter-efficient method (LoRA), limiting generalizability
- Zero-shot evaluation setting may not reflect real-world deployment scenarios where few-shot approaches are more common

## Confidence

**High Confidence**: Med42's benchmark performance superiority and the decontamination methodology
**Medium Confidence**: The relative performance gap between full-parameter and LoRA fine-tuning
**Medium Confidence**: The general recommendation favoring full-parameter fine-tuning for medical LLMs

## Next Checks
1. Conduct a comprehensive cost-benefit analysis comparing GPU hours, memory usage, and inference latency between full-parameter and LoRA fine-tuning approaches
2. Evaluate Med42 and comparative models using few-shot and chain-of-thought prompting to assess practical deployment capabilities
3. Test alternative parameter-efficient methods (such as prefix tuning or adapters) and different base model architectures to verify the robustness of findings across approaches