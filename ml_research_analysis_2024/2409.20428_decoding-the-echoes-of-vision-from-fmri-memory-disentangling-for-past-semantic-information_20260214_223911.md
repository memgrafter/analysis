---
ver: rpa2
title: 'Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic
  Information'
arxiv_id: '2409.20428'
source_url: https://arxiv.org/abs/2409.20428
tags:
- fmri
- memory
- brain
- visual
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses how the brain encodes and retrieves visual
  memories during continuous visual processing. It proposes a new task called Memory
  Disentangling, which aims to extract and decode past visual information from fMRI
  signals while mitigating interference from current visual input.
---

# Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information

## Quick Facts
- **arXiv ID**: 2409.20428
- **Source URL**: https://arxiv.org/abs/2409.20428
- **Reference count**: 19
- **Primary result**: Proposes Memory Disentangling task to extract past visual information from fMRI while mitigating current visual interference using disentangled contrastive learning

## Executive Summary
This paper addresses the challenge of extracting past visual information from fMRI signals during continuous visual processing. The authors propose a new task called Memory Disentangling that aims to decode what a person has seen in the past from their current fMRI signals while overcoming interference from ongoing visual input. The core approach uses disentangled contrastive learning to separate current and past visual information within adjacent fMRI signals, inspired by proactive interference observed in working memory studies. The method maps fMRI signals to semantic features and generates image captions, demonstrating that the model can effectively disentangle information with best performance at the current time point and gradually declining accuracy for past moments.

## Method Summary
The approach involves mapping fMRI signals to semantic features using a pretrained vision-language model, then applying disentangled contrastive learning to separate current visual information from past visual memories. The method leverages the observation that proactive interference occurs when recalling past information during continuous visual processing, creating distinct patterns in adjacent fMRI signals. The model generates image captions as a proxy task to evaluate the quality of retrieved visual information. The disentangling process specifically addresses the challenge of fMRI's low temporal resolution by learning to separate temporally adjacent but semantically distinct visual inputs.

## Key Results
- Best performance at current time point: CIDEr 39.9%, METEOR 11.7%, SPICE 9.95%
- Performance gradually declines for past moments, consistent with working memory limitations
- Successfully disentangles current and past visual information in fMRI signals
- Performance decay pattern aligns with known cognitive working memory constraints of 3-4 items

## Why This Works (Mechanism)
The method exploits the distinct neural signatures created when current visual input interferes with recall of past visual information. By training on adjacent fMRI signals where proactive interference occurs, the model learns to separate temporally overlapping but semantically distinct visual content. The contrastive learning framework creates explicit separation between representations of current and past visual information, leveraging the natural interference patterns that emerge during continuous visual processing.

## Foundational Learning
- **Proactive interference**: Why needed - understanding how current visual input interferes with past memory recall; Quick check - does performance degrade predictably with temporal distance?
- **Semantic feature mapping**: Why needed - bridging neural signals to interpretable visual content; Quick check - are generated captions semantically meaningful and relevant to actual visual input?
- **Contrastive learning**: Why needed - separating overlapping representations of current and past information; Quick check - does contrastive loss effectively separate temporally adjacent signals?
- **fMRI temporal resolution**: Why needed - understanding constraints of neuroimaging data; Quick check - is 1-2 second resolution sufficient for moment-to-moment disentangling?
- **Working memory limitations**: Why needed - establishing baseline for expected performance decay; Quick check - does model performance align with 3-4 item capacity constraint?

## Architecture Onboarding

**Component Map**: fMRI signals -> Semantic feature extraction -> Disentangled contrastive learning -> Caption generation

**Critical Path**: The disentangling contrastive learning module is the core innovation, learning to separate current and past visual information from adjacent fMRI signals. The semantic feature extraction provides the bridge between neural activity and interpretable visual content.

**Design Tradeoffs**: The method trades temporal resolution (limited by fMRI) for semantic richness (via vision-language models). Contrastive learning requires careful balance between separation of current/past information and preservation of semantic content.

**Failure Signatures**: Performance degradation with temporal distance may indicate insufficient separation of overlapping neural patterns. Low caption quality could suggest poor semantic feature mapping or inadequate disentangling.

**First Experiments**: 1) Test disentangling on synthetic data with known temporal patterns, 2) Evaluate performance across different temporal intervals between current and past moments, 3) Compare disentangling performance against baseline models without contrastive separation.

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- fMRI temporal resolution (1-2 seconds) may be insufficient for clean moment-to-moment disentangling
- Semantic mapping between fMRI signals and visual content may not be complete or accurate
- Performance decay relationship to cognitive working memory constraints is correlational, not necessarily causal

## Confidence
- **High confidence**: Method's ability to extract current visual information from fMRI
- **Medium confidence**: Disentangling approach for past information retrieval
- **Low confidence**: Direct mapping between model performance and working memory constraints

## Next Checks
1. Conduct experiments with higher temporal resolution neuroimaging methods (EEG/MEG) to validate disentangling approach at finer temporal scales
2. Perform ablation studies varying time intervals between current and past moments to establish true temporal limits of disentanglement
3. Design controlled experiments with known visual sequences to precisely measure information decay patterns and compare against established working memory models