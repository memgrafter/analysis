---
ver: rpa2
title: 'Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation
  data'
arxiv_id: '2401.17600'
source_url: https://arxiv.org/abs/2401.17600
tags:
- positive
- negative
- image
- gpt-4v
- land
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper benchmarks GPT-4V and other instruction-following VLMs
  on Earth observation tasks including scene understanding, object localization/counting,
  and change detection. VLMs like GPT-4V excel at high-level scene understanding tasks
  such as landmark recognition and image captioning, but struggle with spatial reasoning
  needed for object localization and counting.
---

# Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data

## Quick Facts
- arXiv ID: 2401.17600
- Source URL: https://arxiv.org/abs/2401.17600
- Authors: Chenhui Zhang; Sherrie Wang
- Reference count: 40
- VLMs excel at high-level scene understanding but struggle with spatial reasoning tasks

## Executive Summary
This paper benchmarks GPT-4V and other instruction-following VLMs on Earth observation tasks including scene understanding, object localization/counting, and change detection. The study reveals that while VLMs like GPT-4V demonstrate strong capabilities in high-level scene understanding tasks such as landmark recognition and image captioning, they significantly underperform on spatial reasoning tasks requiring precise object localization and counting. Performance varies considerably across different Earth observation tasks, with notable failures in counting trees and animals, and underestimating building damage in change detection scenarios. The findings suggest that current VLMs are not yet suitable for fine-grained Earth observation applications that demand accurate spatial understanding and precise quantitative analysis.

## Method Summary
The study evaluates GPT-4V and other VLMs on three primary Earth observation tasks: scene understanding, object localization/counting, and change detection. Scene understanding includes landmark recognition and image captioning tasks. Object localization and counting tasks involve identifying and quantifying specific objects like vehicles, buildings, trees, and animals in satellite imagery. Change detection evaluates the models' ability to identify and assess building damage between temporal image pairs. The evaluation uses various datasets with different resolutions and considers factors like label ambiguity and task complexity. Performance metrics include accuracy, precision, and qualitative assessment of model responses.

## Key Results
- VLMs excel at landmark recognition and image captioning but struggle with spatial reasoning tasks
- Counting accuracy varies significantly: moderate for vehicles and buildings, poor for trees and animals
- Change detection shows systematic underestimation of building damage
- Land use classification performance depends heavily on image resolution and label ambiguity

## Why This Works (Mechanism)
VLMs leverage large-scale pretraining on diverse image-text pairs to develop strong semantic understanding capabilities. Their transformer-based architecture enables effective pattern recognition and contextual understanding for high-level scene interpretation. However, these models lack explicit spatial reasoning mechanisms and geometric understanding, making them poorly suited for tasks requiring precise object localization, counting, and quantitative analysis. The absence of spatial attention mechanisms and coordinate-based reasoning limits their ability to accurately identify object positions and relationships in Earth observation imagery.

## Foundational Learning
- **Scene Understanding**: Why needed - to interpret visual content in Earth observation imagery; Quick check - can the model identify landmarks and describe scene content accurately
- **Spatial Reasoning**: Why needed - to locate and quantify objects in satellite images; Quick check - can the model count objects and determine their positions correctly
- **Change Detection**: Why needed - to monitor environmental changes and assess damage; Quick check - can the model identify differences between temporal image pairs and quantify changes

## Architecture Onboarding

**Component Map**
VLM (GPT-4V) -> Vision Encoder -> Text Encoder -> Attention Mechanism -> Output Generator

**Critical Path**
Vision Encoder processes satellite imagery → Text Encoder processes instructions → Attention Mechanism integrates visual and textual information → Output Generator produces responses

**Design Tradeoffs**
The models prioritize semantic understanding over spatial precision, trading geometric accuracy for contextual interpretation. This design choice enables strong performance on high-level tasks but limits effectiveness for fine-grained spatial analysis required in Earth observation.

**Failure Signatures**
- Systematic underestimation of damage in change detection
- Variable counting accuracy dependent on object type
- Resolution-dependent performance in classification tasks
- Sensitivity to prompt engineering in spatial reasoning tasks

**First Experiments**
1. Test landmark recognition and captioning accuracy on diverse Earth observation imagery
2. Evaluate counting performance across different object types and resolutions
3. Assess change detection capabilities using temporal image pairs with known damage levels

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability concerns across different VLM architectures
- Limited dataset diversity may constrain robustness of findings
- Performance highly sensitive to prompt engineering and task framing
- Binary damage assessment may oversimplify complex change detection scenarios

## Confidence
- **High confidence**: VLM excellence at high-level scene understanding tasks (landmark recognition, captioning)
- **Medium confidence**: Performance variation in land use classification due to resolution and label ambiguity
- **Medium confidence**: Counting task limitations for trees and animals, moderate success with vehicles and buildings
- **Medium confidence**: Change detection underestimation of building damage
- **Low confidence**: Generalization to other VLMs and Earth observation scenarios beyond tested conditions

## Next Checks
1. Expand evaluation to include multiple VLM architectures (Claude, Gemini, open-source models) to assess whether GPT-4V limitations are architecture-specific or general VLM constraints
2. Create a larger, more diverse Earth observation benchmark dataset with fine-grained spatial annotations to test model capabilities across varied environmental conditions and object types
3. Implement cross-validation with human expert assessments on change detection tasks to quantify model underestimation and identify systematic biases