---
ver: rpa2
title: Empirical Perturbation Analysis of Linear System Solvers from a Data Poisoning
  Perspective
arxiv_id: '2410.00878'
source_url: https://arxiv.org/abs/2410.00878
tags:
- perturbation
- data
- linear
- solvers
- poisoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies how data poisoning attacks affect the accuracy
  and convergence of linear system solvers used in machine learning. The authors formulate
  two types of perturbations: Label-guided Perturbation (LP) that directly aims to
  degrade testing performance, and Unconditioning Perturbation (UP) that increases
  the condition number of the system matrix.'
---

# Empirical Perturbation Analysis of Linear System Solvers from a Data Poisoning Perspective

## Quick Facts
- arXiv ID: 2410.00878
- Source URL: https://arxiv.org/abs/2410.00878
- Reference count: 40
- This paper studies how data poisoning attacks affect the accuracy and convergence of linear system solvers used in machine learning.

## Executive Summary
This paper investigates the vulnerability of linear system solvers to data poisoning attacks in machine learning contexts. The authors propose two types of perturbations - Label-guided Perturbation (LP) that directly targets testing performance degradation, and Unconditioning Perturbation (UP) that increases matrix ill-conditioning. They develop theoretical convergence bounds for gradient descent under both attack types and empirically evaluate six iterative solvers plus a direct solver across synthetic regression problems. The work provides insights into how different solver architectures respond to poisoning attacks and suggests preconditioning as a defense strategy.

## Method Summary
The authors formulate two optimization-based poisoning attacks: LP maximizes the testing error given perturbed data within a bounded radius, while UP maximizes the condition number of the perturbed system matrix. They implement six iterative solvers (Jacobi, Gauss-Seidel, SOR, CG, GMRES, GD) and one direct solver (Normal Equations). Using SLSQP optimization, they generate poisoned datasets and evaluate solver performance across varying perturbation radii. Theoretical analysis derives convergence bounds for gradient descent under both attacks, showing how UP increases the smoothness constant L while LP affects residual minimization.

## Key Results
- UP more severely degrades direct solver accuracy by increasing matrix ill-conditioning, with NES experiencing significantly higher errors compared to LP
- LP more negatively impacts iterative solvers by affecting residuals, causing consistent performance degradation across solvers
- Both attacks slow convergence for most iterative methods, except GMRES which remains robust
- Theoretical bounds show UP increases the smoothness constant L by factor α², requiring smaller GD step sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unconditioning Perturbation (UP) increases the condition number of the system matrix, causing direct solvers like Normal Equations to produce inaccurate solutions.
- Mechanism: UP maximizes the singular value of the perturbed matrix X', which directly increases κ(X') = σmax(X')/σmin(X'). Since NES computes (A⊤A)⁻¹, any increase in κ(X) is squared in κ(A⊤A), amplifying numerical instability.
- Core assumption: The condition number κ(X) is a reliable proxy for ill-conditioning sensitivity of the linear system.
- Evidence anchors:
  - [abstract] "UP more severely degrades direct solver accuracy by increasing matrix ill-conditioning"
  - [section 6.2] "we observe that UP consistently results in a significantly higher error compared to LP across all values of ϵ"
  - [corpus] Weak - no direct references to NES or condition number amplification found.
- Break condition: If the matrix is already well-conditioned or if regularization is applied, the effect of UP on κ(X) diminishes.

### Mechanism 2
- Claim: Label-guided Perturbation (LP) directly corrupts the right-hand side of the linear system, causing iterative solvers to converge to inaccurate solutions.
- Mechanism: LP maximizes ∥y' - Xt w'∥ by modifying y, which directly affects the residual at each iteration of iterative solvers. Since iterative solvers refine solutions based on residuals, this corruption propagates through iterations.
- Core assumption: Iterative solvers are sensitive to perturbations in the right-hand side vector b.
- Evidence anchors:
  - [abstract] "LP more negatively impacts iterative solvers by affecting residuals"
  - [section 6.3] "LP consistently causes more significant performance degradation than UP across the iterative solvers"
  - [section 6.3] "we find that LP and UP both lead to slower convergence for most of the solvers as ϵ increases"
- Break condition: If the solver has robust residual handling or uses preconditioning to mitigate right-hand side effects.

### Mechanism 3
- Claim: UP increases the smoothness constant L of the underlying objective function, slowing gradient descent convergence.
- Mechanism: UP increases σmax(X) by factor α, which increases L = 2σmax(X)² by factor α². Since GD step size γ is bounded by 1/L, larger L requires smaller steps, slowing convergence.
- Core assumption: The smoothness constant L directly determines the maximum allowable step size in GD.
- Evidence anchors:
  - [section 5.2] "UP impacts the smoothness factor L of the loss function f (w) by a factor of α²"
  - [section 6.3] "GD is the most sensitive to perturbation" and "UP introduces a larger smoothness factor increase, leading to a more significant convergence slowdown than LP"
  - [section 6.3] "we can see that UP introduces a larger smoothness factor increase, leading to a more significant convergence slowdown"
- Break condition: If adaptive step sizes are used or if the learning rate is already optimized for the perturbed system.

## Foundational Learning

- Concept: Condition number κ(A) and its relationship to numerical stability
  - Why needed here: Understanding why UP degrades direct solvers requires knowing that κ(A⊤A) = κ(A)², so ill-conditioning is amplified.
  - Quick check question: If κ(A) = 10, what is κ(A⊤A)?
- Concept: Residual minimization in iterative solvers
  - Why needed here: LP's effectiveness relies on the fact that iterative solvers use residuals to refine solutions, so corrupting residuals degrades performance.
  - Quick check question: What does the residual vector represent in an iterative solver?
- Concept: Smoothness constant L and gradient descent convergence
  - Why needed here: UP's effect on GD convergence depends on how it changes L, which determines the maximum step size.
  - Quick check question: If L doubles, how does this affect the maximum allowable step size in GD?

## Architecture Onboarding

- Component map: Data poisoning module -> Linear solver suite -> Evaluation pipeline -> Theoretical analysis
- Critical path: Generate poisoned data -> Solve with target solver -> Evaluate accuracy and convergence -> Analyze sensitivity
- Design tradeoffs: LP requires label access but directly targets testing error; UP is label-free but may be less targeted. Direct solvers are fast but sensitive to ill-conditioning; iterative solvers are robust but sensitive to residual corruption.
- Failure signatures: Excessive condition number growth (UP on direct solvers), slow convergence or inaccurate solutions (LP on iterative solvers), unstable GD with large L values.
- First 3 experiments:
  1. Verify that UP increases κ(X) and causes NES to fail on simple synthetic data
  2. Confirm that LP increases residuals and slows iterative solver convergence
  3. Test GD convergence with varying L values under UP to validate theoretical bounds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different preconditioning techniques beyond ILU factorization compare in mitigating poisoning attacks on linear solvers?
- Basis in paper: [explicit] The paper mentions ILU factorization as a preliminary exploration for stabilizing convergence under perturbations, suggesting future work could explore other preconditioning techniques.
- Why unresolved: The paper only conducts preliminary experiments with ILU preconditioning and does not compare it with other preconditioning methods like incomplete Cholesky or algebraic multigrid.
- What evidence would resolve it: Comprehensive experiments comparing multiple preconditioning techniques on various linear solvers under different poisoning attacks, measuring convergence speed and solution accuracy.

### Open Question 2
- Question: How does the effectiveness of LP and UP attacks scale with increasing problem dimensions and ill-conditioning?
- Basis in paper: [inferred] The paper conducts experiments on relatively small linear systems (n=d=3 for direct solvers, n=d=20 for iterative solvers) and discusses how UP exploits solver sensitivity to ill-conditioned matrices, but does not systematically study scaling behavior.
- Why unresolved: The experiments use small problem sizes and the theoretical analysis does not explicitly address how attack effectiveness changes with problem scale or initial matrix condition number.
- What evidence would resolve it: Systematic experiments varying problem dimensions and initial condition numbers, measuring attack success rates and solver performance degradation across different scales.

### Open Question 3
- Question: Can adaptive poisoning strategies that exploit solver-specific vulnerabilities outperform the general LP and UP attacks?
- Basis in paper: [explicit] The paper analyzes solver-specific vulnerabilities (e.g., iterative solvers' reliance on residuals, GMRES's Krylov subspace properties) but only tests two general attack types without tailoring attacks to specific solvers.
- Why unresolved: While the paper identifies solver-specific weaknesses, it does not design attacks that specifically target these vulnerabilities or compare their effectiveness against general attacks.
- What evidence would resolve it: Experiments comparing general LP/UP attacks against solver-specific attacks designed to exploit identified vulnerabilities, measuring relative effectiveness across different solver types.

## Limitations
- Limited experimental validation of NES solver condition number amplification mechanism
- Experiments conducted on small synthetic datasets, limiting generalizability
- Theoretical bounds for UP's effect on GD convergence may not hold under practical conditions
- No systematic study of attack effectiveness scaling with problem dimensions

## Confidence
- High Confidence: LP degrades iterative solver performance by affecting residuals - supported by multiple experimental results showing consistent performance degradation
- Medium Confidence: UP significantly increases condition number and degrades direct solver accuracy - supported by theoretical analysis but lacking direct experimental verification
- Medium Confidence: GMRES is robust to both attacks - supported by experimental results, though the mechanism could be explored further
- Low Confidence: Theoretical convergence bounds for UP's effect on GD - derived analytically but not extensively validated against experimental results

## Next Checks
1. Validate NES Condition Number Amplification: Implement the Normal Equations Solver with synthetic data where condition number is systematically varied. Measure how κ(A⊤A) relates to κ(A) and quantify the accuracy degradation as κ increases, directly testing the mechanism described in Mechanism 1.

2. Test Preconditioning as Defense: Apply ILU preconditioning to iterative solvers under both LP and UP attacks. Measure the impact on convergence rates and final accuracy to validate the defense strategy suggested in the discussion section, particularly for solvers most affected by the attacks.

3. Scale Up to Real-World Data: Reproduce the experiments using real-world regression datasets (e.g., housing prices, crime data) with larger dimensions. Compare solver vulnerabilities between synthetic and real data to assess the practical relevance of the findings and identify any scaling effects on attack effectiveness.