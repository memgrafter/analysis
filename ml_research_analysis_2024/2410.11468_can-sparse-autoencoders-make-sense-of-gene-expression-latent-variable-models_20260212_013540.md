---
ver: rpa2
title: Can sparse autoencoders make sense of gene expression latent variable models?
arxiv_id: '2410.11468'
source_url: https://arxiv.org/abs/2410.11468
tags:
- features
- data
- neurons
- hidden
- cell
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Sparse autoencoders can extract meaningful features from single-cell
  expression models, enabling interpretability and steering of biological processes.
  The method recovers hidden variables in simulated data when they are learned in
  superposition, with performance improving for variables closer to the observed data
  and for wider models.
---

# Can sparse autoencoders make sense of gene expression latent variable models?

## Quick Facts
- arXiv ID: 2410.11468
- Source URL: https://arxiv.org/abs/2410.11468
- Reference count: 40
- Sparse autoencoders extract meaningful features from single-cell expression models, enabling interpretability and steering of biological processes

## Executive Summary
Sparse autoencoders (SAEs) can extract meaningful features from single-cell expression models, enabling interpretability and steering of biological processes. The method recovers hidden variables in simulated data when they are learned in superposition, with performance improving for variables closer to the observed data and for wider models. In real-world applications, SAEs identify local and global features from pre-trained models like multiDGD and Geneformer. Local features distinguish rare cell subpopulations, while global features capture broad biological programs like red blood cell differentiation. An automated pipeline, scFeatureLens, links SAE features to biological concepts via gene ontology enrichment, enabling large-scale hypothesis generation.

## Method Summary
The study applies sparse autoencoders to gene expression latent variable models trained on single-cell data. SAEs are trained to reconstruct outputs from pre-trained models like multiDGD and Geneformer, with sparsity regularization encouraging interpretable feature extraction. The approach works in two regimes: (1) recovering hidden variables from simulated data where ground truth is known, and (2) discovering meaningful biological features from real gene expression models. The scFeatureLens pipeline automates the process of linking SAE-extracted features to biological concepts through gene ontology enrichment analysis.

## Key Results
- SAEs successfully recover hidden variables in simulated data when variables are learned in superposition
- Performance improves for variables closer to observed data and for wider model architectures
- In real applications, SAEs identify both local features distinguishing rare cell subpopulations and global features capturing broad biological programs like red blood cell differentiation
- The scFeatureLens pipeline automates feature-to-biological-concept linking via gene ontology enrichment

## Why This Works (Mechanism)
Sparse autoencoders work by imposing L1 regularization on the latent representations, which encourages the model to learn sparse, interpretable features rather than distributed representations. This sparsity constraint forces the autoencoder to identify the most salient patterns in the data, making the learned features more human-interpretable. The reconstruction objective ensures that these sparse features still capture the essential information needed to reproduce the original model outputs.

## Foundational Learning
- Single-cell RNA sequencing: Measures gene expression at individual cell resolution, enabling discovery of cellular heterogeneity and rare cell types
  - Why needed: Provides the raw data for modeling gene expression patterns
  - Quick check: Understand how gene expression is quantified and normalized

- Latent variable models in genomics: Capture underlying biological processes that generate observed gene expression patterns
  - Why needed: These models learn compressed representations that SAEs can then interpret
  - Quick check: Review how variational autoencoders and similar models work in genomics

- Gene Ontology (GO) enrichment: Statistical method to link gene sets to biological functions, processes, and cellular components
  - Why needed: Provides the framework for interpreting SAE-extracted features biologically
  - Quick check: Understand how enrichment p-values are calculated and corrected

- Superposition learning: When models represent multiple features in overlapping dimensions
  - Why needed: Explains why SAEs are particularly useful for interpreting compressed representations
  - Quick check: Consider how distributed vs. sparse representations affect interpretability

## Architecture Onboarding
Component map: Gene expression data -> Pre-trained model (multiDGD/Geneformer) -> SAE encoder -> Sparse latent features -> SAE decoder -> Reconstruction loss + sparsity loss

Critical path: The encoder-decoder architecture with sparsity regularization is the core mechanism. The pre-trained model provides stable inputs, while the sparsity constraint ensures interpretability.

Design tradeoffs: Wider models improve SAE performance but increase computational cost. The sparsity weight must balance between reconstruction accuracy and feature interpretability.

Failure signatures: Poor reconstruction indicates inadequate model capacity or improper sparsity weighting. Non-interpretable features suggest insufficient sparsity or biologically irrelevant training data.

First experiments:
1. Train SAE on simulated data with known ground truth to verify recovery of hidden variables
2. Vary sparsity regularization weight to find optimal balance between reconstruction and interpretability
3. Compare SAE features against random gene sets using GO enrichment to establish significance baseline

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation primarily based on simulated data with known ground truth and limited real-world examples
- Performance improvements for variables closer to observed data suggest architectural dependencies requiring systematic exploration
- Biological interpretations lack independent experimental validation in real-world applications

## Confidence
- Simulated data results: Medium confidence (ground truth provides clear validation)
- Real-world applications: Low confidence (biological interpretations plausible but lack independent validation)
- scFeatureLens pipeline: Medium confidence (automated but dependent on ontology quality)

## Next Checks
1. Independent experimental validation of SAE-identified biological features, particularly the red blood cell differentiation program and rare cell subpopulation markers, through targeted perturbation experiments or orthogonal measurement techniques
2. Systematic ablation studies varying model width, depth, and training hyperparameters to quantify their impact on SAE feature quality and interpretability across diverse biological contexts
3. Comparison with alternative interpretability methods for gene expression models, including post-hoc attribution techniques and supervised feature selection, to establish the relative advantages of the SAE approach for specific biological questions