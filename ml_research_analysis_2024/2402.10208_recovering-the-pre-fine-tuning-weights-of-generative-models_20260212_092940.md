---
ver: rpa2
title: Recovering the Pre-Fine-Tuning Weights of Generative Models
arxiv_id: '2402.10208'
source_url: https://arxiv.org/abs/2402.10208
tags:
- lora
- rank
- arxiv
- fine-tuned
- detuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the task of Pre-Fine-Tuning (Pre-FT) Weight
  Recovery, demonstrating that the original weights of a pre-trained model can be
  recovered from LoRA fine-tuned models using Spectral DeTuning, an iterative low-rank
  matrix factorization method. Spectral DeTuning achieves near-perfect recovery of
  pre-trained model weights on a benchmark of real models including Stable Diffusion,
  Mistral-7B, and a ViT, with weight error values as low as -22.06 (log MSE) and semantic
  equivalence metrics showing near-identical outputs to the original models.
---

# Recovering the Pre-Fine-Tuning Weights of Generative Models

## Quick Facts
- arXiv ID: 2402.10208
- Source URL: https://arxiv.org/abs/2402.10208
- Authors: Eliahu Horwitz; Jonathan Kahana; Yedid Hoshen
- Reference count: 40
- This paper demonstrates that original pre-trained model weights can be recovered from LoRA fine-tuned models using Spectral DeTuning.

## Executive Summary
This paper introduces the task of Pre-Fine-Tuning (Pre-FT) Weight Recovery, demonstrating that original weights of pre-trained models can be recovered from LoRA fine-tuned models. The authors propose Spectral DeTuning, an iterative low-rank matrix factorization method that achieves near-perfect recovery of pre-trained model weights without requiring any training data. The method exposes a critical vulnerability in the widely-used practice of LoRA-based model alignment, as it can reconstruct the original model weights from as few as 2-15 LoRA fine-tuned versions.

## Method Summary
The paper presents Spectral DeTuning, an iterative gradient-free algorithm that recovers pre-trained weights from multiple LoRA fine-tuned models. The method works by iteratively performing SVD on differences between fine-tuned models to factorize and extract the original weights. A rank scheduler progressively increases rank during optimization to improve convergence speed and quality. The algorithm requires no training data, is parallelizable, and operates in an unsupervised manner. LoRA rank estimation uses a heuristic based on pairwise differences between LoRA models, and the method is evaluated across multiple model types including Stable Diffusion, Mistral-7B, and Vision Transformers.

## Key Results
- Spectral DeTuning achieves weight error values as low as -22.06 (log MSE) in recovering pre-trained model weights
- Near-identical semantic outputs to original models with LPIPS scores of 0.0033 for Stable Diffusion and SBERT scores of 0.0114 for Mistral
- The method works with as few as 2 LoRA models and scales effectively with more models, showing improved recovery quality
- No training data required - the algorithm operates solely on the LoRA fine-tuned model weights

## Why This Works (Mechanism)
Spectral DeTuning exploits the additive nature of LoRA fine-tuning, where LoRA matrices are added to the pre-trained weights during inference. By analyzing multiple fine-tuned versions of the same base model, the algorithm can factorize out the LoRA contributions and recover the original weights. The iterative SVD-based approach progressively refines the estimate by treating the problem as a low-rank matrix factorization task. The rank scheduler helps avoid local minima by starting with lower ranks and progressively increasing complexity, enabling better convergence to the true pre-trained weights.

## Foundational Learning

**LoRA (Low-Rank Adaptation)** - A parameter-efficient fine-tuning method that adds low-rank matrices to pre-trained weights. Why needed: Understanding this is crucial because Spectral DeTuning exploits the additive property of LoRA to recover original weights. Quick check: Verify that LoRA matrices are added to original weights during inference and can be separated.

**SVD (Singular Value Decomposition)** - Matrix factorization technique that decomposes a matrix into singular vectors and values. Why needed: Core mathematical operation used in Spectral DeTuning's iterative refinement process. Quick check: Ensure SVD implementation correctly truncates to specified rank during M-step.

**Rank Scheduling** - Progressive increase in rank during optimization to improve convergence. Why needed: Prevents algorithm from getting stuck in poor local minima by starting simple and adding complexity. Quick check: Monitor if rank scheduler properly increases rank when convergence plateaus.

## Architecture Onboarding

**Component Map:** Source Model -> Multiple LoRA Fine-tuned Models -> Spectral DeTuning Algorithm -> Recovered Pre-FT Weights

**Critical Path:** The algorithm requires multiple LoRA fine-tuned models as input, applies iterative SVD-based factorization, and outputs recovered weights. The rank scheduler and convergence criteria are critical for success.

**Design Tradeoffs:** The method trades computational cost (iterative SVD on large matrices) for data efficiency (no training data required). Using more LoRA models improves recovery quality but increases computational overhead.

**Failure Signatures:** Poor convergence when rank scheduler is not used, incorrect LoRA rank estimation leading to suboptimal performance, and failure when fewer than 5 LoRA models are available. Monitoring W-Error per layer helps diagnose issues.

**First Experiments:**
1. Test Spectral DeTuning on a single LoRA model to establish baseline performance
2. Run with 2-3 LoRA models to verify minimum requirements for recovery
3. Implement rank scheduler and compare convergence speed/quality against fixed-rank approach

## Open Questions the Paper Calls Out

**Open Question 1:** How does the number of LoRA fine-tuned models required for accurate Pre-FT weight recovery scale with model size and complexity? The paper shows trends but doesn't establish a clear scaling relationship with model parameters.

**Open Question 2:** Are there alternative LoRA fine-tuning methods or architectures that could inherently resist Pre-FT weight recovery attacks? The study is limited to standard LoRA fine-tuning without exploring other PEFT methods.

**Open Question 3:** What is the minimum number of LoRA fine-tuned models required to achieve semantic equivalence with the Pre-FT model for practical applications? The paper shows that fewer LoRAs lead to worse convergence but doesn't establish a threshold for semantic equivalence.

## Limitations

- Requires multiple LoRA fine-tuned models of the same source model, which may not always be available
- Rank estimation heuristic could fail when LoRA models use different ranks or training procedures
- Assumes standard LoRA methodology without additional regularization or post-processing steps
- Performance may decrease for models with highly non-linear fine-tuning processes

## Confidence

**High confidence:** The core algorithm (Spectral DeTuning) and its effectiveness in recovering pre-trained weights from multiple LoRA models, as demonstrated across multiple model types and metrics.

**Medium confidence:** The rank estimation heuristic's generalizability to LoRA models fine-tuned under different conditions or with different ranks than those tested.

**Low confidence:** Performance guarantees when fewer than 5 LoRA models are available, or when LoRA fine-tuning involves non-standard procedures beyond simple weight updates.

## Next Checks

1. Test Spectral DeTuning on a broader range of model architectures (e.g., LLaMA, BLOOM) and LoRA fine-tuning scenarios to validate generalizability.

2. Evaluate the method's performance with fewer than 5 LoRA models to establish minimum requirements and robustness.

3. Investigate whether the rank estimation heuristic can be improved or made more robust to variations in LoRA fine-tuning procedures and ranks.