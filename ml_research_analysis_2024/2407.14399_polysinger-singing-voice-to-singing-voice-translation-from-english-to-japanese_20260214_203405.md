---
ver: rpa2
title: 'PolySinger: Singing-Voice to Singing-Voice Translation from English to Japanese'
arxiv_id: '2407.14399'
source_url: https://arxiv.org/abs/2407.14399
tags:
- lyrics
- japanese
- translation
- polysinger
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PolySinger is the first system for singing-voice to singing-voice
  translation (SV2SVT), translating English lyrics to Japanese while preserving melody
  and rhythm. It uses a cascaded approach combining automatic lyrics transcription
  (Whisper), phoneme-level lyrics alignment, frame-level vocal melody extraction,
  automatic lyrics translation (fine-tuned NLLB-200), and singing-voice synthesis
  (Synthesizer V).
---

# PolySinger: Singing-Voice to Singing-Voice Translation from English to Japanese

## Quick Facts
- **arXiv ID**: 2407.14399
- **Source URL**: https://arxiv.org/abs/2407.14399
- **Reference count**: 0
- **Key outcome**: First system for singing-voice to singing-voice translation (SV2SVT) translating English lyrics to Japanese while preserving melody and rhythm

## Executive Summary
PolySinger introduces the first system for singing-voice to singing-voice translation (SV2SVT), enabling English songs to be translated into Japanese while preserving their original melody and rhythm. The system employs a cascaded approach that combines automatic lyrics transcription, phoneme-level lyrics alignment, frame-level vocal melody extraction, automatic lyrics translation, and singing-voice synthesis. A mean opinion score test with native Japanese speakers demonstrated promising results, though the system still needs improvement in the naturalness of Japanese lyrics and pronunciation.

## Method Summary
The PolySinger system follows a cascaded approach where each component processes the output of the previous stage. It begins with Whisper for automatic lyrics transcription from the English singing voice, followed by phoneme-level lyrics alignment and frame-level vocal melody extraction. The transcribed lyrics are then translated to Japanese using a fine-tuned NLLB-200 model. Finally, the translated lyrics and extracted melody are synthesized into Japanese singing voice using Synthesizer V. This end-to-end pipeline maintains the original musical characteristics while transforming the language of the lyrics.

## Key Results
- First system for singing-voice to singing-voice translation (SV2SVT)
- Successfully translates English lyrics to Japanese while preserving melody and rhythm
- Mean opinion score test with native Japanese speakers showed promising results
- Identified need for improvement in naturalness of Japanese lyrics and pronunciation

## Why This Works (Mechanism)
The system works by maintaining the musical structure (melody and rhythm) while transforming only the linguistic content. By separating the melody extraction from the lyrical content, the system can preserve the musical characteristics that define a song while replacing the language-specific elements. The cascaded approach allows each component to specialize in its specific task - transcription, translation, and synthesis - while the intermediate representations (phonemes, melody) serve as stable bridges between stages.

## Foundational Learning
1. **Singing-Voice Transcription** - Converting singing audio to text lyrics; needed for extracting source language lyrics from audio; quick check: verify transcription accuracy against ground truth lyrics
2. **Phoneme-Level Alignment** - Mapping lyrics to specific time points in the audio; needed for maintaining rhythmic structure during translation; quick check: measure alignment error rates
3. **Vocal Melody Extraction** - Identifying pitch contours from singing voice; needed to preserve musical characteristics; quick check: compare extracted melody to reference melody
4. **Cross-Lingual Singing Synthesis** - Generating singing voice in target language; needed for producing natural-sounding Japanese vocals; quick check: evaluate pronunciation naturalness
5. **Cascaded System Design** - Processing through sequential specialized components; needed for modularity and task specialization; quick check: measure cumulative error propagation
6. **Mean Opinion Score Testing** - Human evaluation methodology; needed for subjective quality assessment; quick check: ensure native speaker evaluators

## Architecture Onboarding

**Component Map**: English Singing Audio -> Whisper (Transcription) -> Phoneme Alignment -> Melody Extraction -> NLLB-200 (Translation) -> Synthesizer V (Synthesis) -> Japanese Singing Audio

**Critical Path**: The critical path flows from the original singing audio through each processing stage to the final synthesized output. The transcription and translation stages are most critical as errors here directly impact the final output quality.

**Design Tradeoffs**: The cascaded approach offers modularity and allows using specialized models for each task, but introduces potential error accumulation. Using existing models (Whisper, NLLB-200, Synthesizer V) enables rapid development but may limit optimization for singing-specific characteristics.

**Failure Signatures**: 
- Poor transcription leads to incorrect source lyrics being translated
- Translation errors propagate to unnatural Japanese lyrics
- Melody extraction errors can cause rhythm mismatches
- Synthesis limitations can result in robotic or unnatural Japanese pronunciation

**First 3 Experiments**:
1. Test system on simple English songs with clear pronunciation and straightforward melodies
2. Evaluate performance on songs with different vocal styles and ranges
3. Assess translation quality on lyrics with varying complexity and cultural references

## Open Questions the Paper Calls Out
The paper acknowledges that the naturalness of Japanese lyrics and pronunciation needs improvement, but does not provide detailed quantitative analysis of these specific aspects. The performance of the lyrics translation component on singing-specific content is unclear, as it was originally designed for general text translation.

## Limitations
- Small-scale mean opinion score test may not capture full range of quality issues
- Cascaded approach introduces multiple potential failure points with compounding errors
- Translation component (NLLB-200) not specifically optimized for singing content
- Limited evaluation of system performance across diverse musical styles and vocal characteristics

## Confidence
- **High confidence**: Novelty claim as first SV2SVT system and technical approach description
- **Medium confidence**: Translation quality assessment given limited evaluation methodology
- **Low confidence**: Generalizability to diverse musical styles, vocal characteristics, and complex Japanese phonetic structures

## Next Checks
1. Conduct large-scale perceptual evaluation with professional singers and linguists to assess translation accuracy, phonetic quality, and naturalness across different musical genres and vocal styles
2. Perform ablation studies to quantify the impact of each component on overall system performance and identify the most critical bottlenecks
3. Test system robustness by evaluating performance on non-English source languages and more complex Japanese linguistic features such as pitch accent and mora timing