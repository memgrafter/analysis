---
ver: rpa2
title: A Survey for Large Language Models in Biomedicine
arxiv_id: '2409.00133'
source_url: https://arxiv.org/abs/2409.00133
tags:
- llms
- biomedical
- medical
- data
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively analyzes the landscape of large language
  models (LLMs) in biomedicine, examining 484 publications from 2019 to 2024. It evaluates
  the zero-shot performance of LLMs across various biomedical tasks and explores adaptation
  strategies, including fine-tuning and multimodal approaches.
---

# A Survey for Large Language Models in Biomedicine

## Quick Facts
- arXiv ID: 2409.00133
- Source URL: https://arxiv.org/abs/2409.00133
- Reference count: 40
- One-line primary result: Comprehensive analysis of 484 publications on LLMs in biomedicine, evaluating zero-shot performance and adaptation strategies.

## Executive Summary
This survey provides a comprehensive analysis of large language models (LLMs) in biomedicine, examining 484 publications from 2019 to 2024. The study evaluates the zero-shot performance of LLMs across various biomedical tasks and explores adaptation strategies, including fine-tuning and multimodal approaches. The research finds that while general-purpose LLMs show promise in basic biomedical understanding, they often fall short in complex, specialized tasks without domain-specific adaptation. Fine-tuned models demonstrate significant improvements in performance across various biomedical applications. The survey also identifies key challenges such as data privacy, model interpretability, and ethical concerns, while proposing future research directions including federated learning and explainable AI.

## Method Summary
The survey systematically analyzed 484 publications from PubMed, Web of Science, and arXiv databases spanning 2019-2024. The research focused on 137 key studies for zero-shot evaluation, examining LLMs' performance across biomedical tasks including diagnostic assistance, drug discovery, personalized medicine, and literature analysis. The study evaluated adaptation strategies such as full-parameter fine-tuning, instruction fine-tuning, parameter-efficient fine-tuning, and hybrid fine-tuning for both unimodal and multimodal LLMs. Performance metrics included Accuracy, BLEU-1, F1 Score, and ROUGE-L across various benchmark datasets.

## Key Results
- Fine-tuned LLMs significantly outperform general LLMs in biomedical tasks through domain-specific adaptation
- Multimodal LLMs show promise in integrating diverse data types for comprehensive biomedical insights
- Federated learning emerges as a potential solution for privacy-preserving training on decentralized biomedical data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuned LLMs significantly outperform general LLMs in biomedical tasks due to domain-specific adaptation.
- Mechanism: Fine-tuning adapts general-purpose LLMs to the specialized vocabulary, complex concepts, and linguistic patterns of biomedicine, enabling better performance on domain-specific tasks.
- Core assumption: Domain-specific fine-tuning can effectively bridge the knowledge gap between general LLMs and biomedical applications.
- Evidence anchors:
  - [abstract] "Fine-tuned models demonstrate significant improvements in performance across various biomedical applications."
  - [section] "GatorTron excelled in various clinical NLP tasks after full-parameter fine-tuning [81]"
  - [corpus] Weak - No direct corpus evidence for fine-tuning effectiveness in biomedicine.
- Break Condition: If domain-specific data is insufficient or of poor quality, fine-tuning may not improve performance or could introduce biases.

### Mechanism 2
- Claim: Multimodal LLMs integrate diverse data types to provide comprehensive insights in biomedical applications.
- Mechanism: Multimodal LLMs fuse information from text, images, and molecular sequences, mirroring the multifaceted nature of medical diagnosis and research.
- Core assumption: Integration of diverse data modalities can enhance model performance in complex biomedical tasks.
- Evidence anchors:
  - [abstract] "The study finds that while general-purpose LLMs show promise in basic biomedical understanding, they often fall short in complex, specialized tasks without domain-specific adaptation."
  - [section] "Med-Gemini [111] and Med-PaLM M [66] have shown promising results in tasks requiring the integration of visual and textual information"
  - [corpus] Weak - Limited corpus evidence for multimodal LLM performance in biomedicine.
- Break Condition: If the model fails to effectively align or integrate different data modalities, performance may not improve or could degrade.

### Mechanism 3
- Claim: Federated learning enables privacy-preserving training of LLMs on decentralized biomedical data.
- Mechanism: Federated learning allows models to be trained across multiple decentralized datasets without sharing raw data, addressing privacy concerns in biomedical applications.
- Core assumption: Federated learning can maintain model performance while preserving data privacy in distributed biomedical settings.
- Evidence anchors:
  - [abstract] "The study also identifies key challenges such as data privacy, model interpretability, and ethical concerns"
  - [section] "FedMed, a framework specifically designed to enhance medical language modeling while mitigating performance degradation in federated settings"
  - [corpus] Weak - Limited corpus evidence for federated learning effectiveness in biomedical LLM training.
- Break Condition: If federated learning introduces significant performance degradation or communication overhead, it may not be viable for large-scale biomedical LLM training.

## Foundational Learning

- Concept: Transformer architecture
  - Why needed here: Understanding the core architecture is crucial for grasping how LLMs process and generate language, which is fundamental to their application in biomedicine.
  - Quick check question: What are the main components of a transformer architecture, and how do they differ from previous neural network architectures?

- Concept: Fine-tuning techniques
  - Why needed here: Knowledge of various fine-tuning approaches (full-parameter, parameter-efficient, instruction tuning) is essential for adapting general LLMs to biomedical tasks.
  - Quick check question: What are the key differences between full-parameter fine-tuning and parameter-efficient fine-tuning, and when would you use each approach?

- Concept: Multimodal learning
  - Why needed here: Understanding how to integrate and process different data types (text, images, sequences) is crucial for developing effective multimodal biomedical LLMs.
  - Quick check question: How do multimodal models align and integrate information from different modalities, and what challenges arise in this process?

## Architecture Onboarding

- Component map: Input data → Preprocessing and tokenization → Transformer layers (encoder/decoder) → Specialized biomedical modules → Output generation

- Critical path: Data preprocessing and curation → Model adaptation (fine-tuning) → Evaluation on biomedical benchmarks → Iterative refinement based on performance and ethical considerations

- Design tradeoffs: Balancing model size and performance with computational efficiency and data privacy requirements. Choosing between unimodal and multimodal approaches based on the specific biomedical task and available data types.

- Failure signatures: Poor performance on domain-specific tasks, inability to generalize across biomedical specialties, failure to integrate multimodal data effectively, or violation of data privacy regulations.

- First 3 experiments:
  1. Evaluate a general LLM's zero-shot performance on a simple biomedical task (e.g., medical question answering) to establish a baseline.
  2. Fine-tune the LLM on a domain-specific dataset and compare performance to the baseline.
  3. Implement a parameter-efficient fine-tuning method and assess its impact on performance and computational efficiency compared to full fine-tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between general biomedical knowledge and specialized task-specific training for LLMs in healthcare applications?
- Basis in paper: [explicit] The paper discusses both zero-shot performance of general LLMs and the need for adaptation strategies, noting that while LLMs show promise in basic biomedical understanding, they often fall short in complex, specialized tasks without domain-specific adaptation.
- Why unresolved: The paper shows that both general LLMs and specialized fine-tuned models have advantages and limitations, but doesn't provide clear guidelines on when to use each approach or how to optimally combine them.
- What evidence would resolve it: Systematic comparison studies evaluating different adaptation strategies (zero-shot, fine-tuning, instruction tuning, parameter-efficient fine-tuning) across various biomedical tasks, with clear performance benchmarks and resource efficiency metrics.

### Open Question 2
- Question: How can multimodal LLMs effectively integrate diverse biomedical data types (text, images, genomic sequences) while maintaining accuracy and interpretability in clinical decision-making?
- Basis in paper: [explicit] The paper discusses multimodal adaptation strategies and the potential of integrating diverse data types, but notes challenges in data processing and model interpretability.
- Why unresolved: While the paper identifies multimodal approaches as promising, it doesn't provide specific solutions for effectively fusing different data types or addressing the interpretability challenges that arise from such integration.
- What evidence would resolve it: Empirical studies demonstrating successful multimodal integration in clinical settings, with clear metrics for both accuracy and interpretability, and validation against established clinical standards.

### Open Question 3
- Question: What are the most effective methods for ensuring data privacy and ethical compliance when deploying LLMs in healthcare settings, particularly in multi-institutional environments?
- Basis in paper: [explicit] The paper identifies data privacy concerns as a key challenge and mentions federated learning as a potential solution, but doesn't provide specific implementation guidelines.
- Why unresolved: The paper acknowledges the importance of privacy and ethics but doesn't provide concrete frameworks or best practices for implementing privacy-preserving techniques in real-world healthcare settings.
- What evidence would resolve it: Comparative studies of different privacy-preserving approaches (federated learning, differential privacy, etc.) in healthcare contexts, with clear evaluations of both privacy protection and model performance, along with ethical impact assessments.

## Limitations
- Limited direct experimental validation within the survey itself
- Reliance on published benchmark results which may vary in evaluation methodologies
- Insufficient practical implementation details for federated learning and privacy-preserving techniques

## Confidence

*High Confidence*: The general landscape analysis of biomedical LLM publications and the identification of major adaptation strategies (fine-tuning, multimodal approaches) are well-supported by the extensive literature review. The observation that general-purpose LLMs struggle with complex biomedical tasks without domain-specific adaptation is consistently reported across multiple studies.

*Medium Confidence*: Claims about the effectiveness of specific fine-tuning approaches (LoRA, instruction tuning) and the performance improvements of specialized models like GatorTron are supported by published results but may be sensitive to implementation details and dataset quality not fully captured in the survey.

*Low Confidence*: Predictions about future directions, particularly regarding federated learning and explainable AI in biomedical LLMs, are largely speculative based on current trends rather than demonstrated implementations. The assessment of ethical concerns and privacy challenges, while important, lacks specific quantitative analysis of current systems' vulnerabilities.

## Next Checks

1. Replicate the zero-shot evaluation of general LLMs (GPT-4, GPT-3.5) on a standardized biomedical benchmark (e.g., MultiMedQA) using consistent evaluation protocols to verify reported performance gaps.

2. Conduct a controlled experiment comparing different fine-tuning strategies (full-parameter vs. LoRA vs. instruction tuning) on a representative biomedical dataset to quantify performance trade-offs and resource requirements.

3. Implement a small-scale federated learning experiment using distributed biomedical data sources to assess the practical challenges and performance implications discussed in the survey.