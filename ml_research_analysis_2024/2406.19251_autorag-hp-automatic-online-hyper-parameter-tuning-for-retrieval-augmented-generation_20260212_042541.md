---
ver: rpa2
title: 'AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented
  Generation'
arxiv_id: '2406.19251'
source_url: https://arxiv.org/abs/2406.19251
tags:
- search
- hyper-parameter
- optimization
- tuning
- hyper-parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of hyper-parameter optimization
  for Retrieval-Augmented Generation (RAG) systems by framing it as an online multi-armed
  bandit (MAB) problem. To efficiently explore large search spaces, the authors propose
  a novel two-level Hierarchical MAB (Hier-MAB) method, where a high-level MAB selects
  which hyper-parameter to tune and low-level MABs search for optimal settings within
  each hyper-parameter.
---

# AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2406.19251
- Source URL: https://arxiv.org/abs/2406.19251
- Reference count: 14
- Key outcome: Hier-MAB achieves Recall@5 ≈ 0.8 using ~20% of LLM API calls compared to Grid Search

## Executive Summary
This paper addresses the challenge of hyper-parameter optimization for Retrieval-Augmented Generation (RAG) systems by framing it as an online multi-armed bandit (MAB) problem. The authors propose a novel two-level Hierarchical MAB (Hier-MAB) method that efficiently explores large search spaces by decomposing the joint optimization into a high-level MAB for selecting which hyper-parameter to tune and low-level MABs for selecting values within each hyper-parameter. Experiments on ALCE-ASQA and Natural Questions datasets demonstrate that Hier-MAB outperforms traditional methods like Grid Search and other MAB baselines while using significantly fewer LLM API calls.

## Method Summary
The method formulates RAG hyper-parameter tuning as an online multi-armed bandit problem where each arm represents a specific configuration. The proposed Hier-MAB approach decomposes the optimization into two levels: a high-level MAB selects which hyper-parameter to tune, while low-level MABs search for optimal values within each hyper-parameter. The Upper Confidence Bound (UCB) algorithm is used for arm selection, balancing exploration and exploitation. The system uses a reward function combining accuracy and token length, and experiments show that Hier-MAB achieves comparable performance to Grid Search while using only ~20% of the LLM API calls.

## Key Results
- Hier-MAB achieves Recall@5 ≈ 0.8 on ALCE-ASQA and Natural Questions datasets
- Uses only ~20% of LLM API calls compared to Grid Search while maintaining similar performance
- Outperforms UCB, Thompson Sampling, and Random Search baselines in medium-complexity optimization scenarios
- Successfully handles joint optimization of up to three hyper-parameters (top-k, compression ratio, embedding model)

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical MAB reduces search space complexity from exponential to linear by decomposing joint optimization into high-level MAB for selecting which hyper-parameter to tune and low-level MABs for selecting values within each hyper-parameter. Instead of enumerating all combinations, the algorithm sequentially optimizes one parameter at a time, reducing arms from product of all values to sum of parameters plus values.

### Mechanism 2
Framing hyper-parameter tuning as MAB enables online learning and adaptation based on user feedback. Each arm represents a configuration, and the algorithm selects arms, evaluates performance (reward), and updates value estimates. This allows the system to adapt to new data or user preferences over time, continuously improving performance.

### Mechanism 3
Upper Confidence Bound algorithm effectively balances exploration and exploitation in RAG hyper-parameter tuning. UCB selects arms based on upper confidence bounds derived from estimated value and uncertainty, encouraging exploration of less-selected arms while exploiting high-reward arms. The exploration-exploitation tradeoff is controlled by parameter α.

## Foundational Learning

- **Concept:** Multi-armed bandit problem
  - **Why needed here:** Understanding MAB framework is crucial for grasping how the algorithm balances exploration and exploitation in searching for optimal hyper-parameter configurations.
  - **Quick check question:** In RAG hyper-parameter tuning, what does an "arm" represent in the multi-armed bandit problem?

- **Concept:** Upper Confidence Bound (UCB) algorithm
  - **Why needed here:** UCB is the specific MAB algorithm used in Hier-MAB approach, and understanding its mechanism is essential for tuning parameters and interpreting behavior.
  - **Quick check question:** How does UCB algorithm balance exploration and exploitation, and what role does parameter α play in this balance?

- **Concept:** Hierarchical optimization
  - **Why needed here:** Hierarchical decomposition of joint optimization problem into high-level and low-level MABs is a key innovation of Hier-MAB approach, crucial for extending method to other optimization problems.
  - **Quick check question:** What are potential advantages and disadvantages of decomposing a joint optimization problem into a hierarchy of subproblems?

## Architecture Onboarding

- **Component map:** RAG system -> Hyper-parameter search space -> Multi-armed bandit framework (UCB) -> Hierarchical decomposition (high-level and low-level MABs) -> Reward function

- **Critical path:** 1) Initialize Hier-MAB with search space and reward function 2) Select high-level arm (which hyper-parameter to tune) 3) Select low-level arm (value for selected hyper-parameter) 4) Evaluate performance of selected configuration 5) Update estimates of arm values based on observed reward 6) Repeat for predetermined iterations or until convergence

- **Design tradeoffs:** Exploration vs. exploitation controlled by α parameter; granularity of search space affects size and computational cost; hierarchical vs. flat optimization balances search space complexity against solution quality.

- **Failure signatures:** Slow convergence from excessive exploration or large search space; suboptimal configurations from poorly designed reward function or imbalanced exploration-exploitation; high variance in performance from noisy rewards or many local optima.

- **First 3 experiments:** 1) Baseline comparison: Run Hier-MAB and compare to random search and grid search on simple optimization problem with known optimal configuration 2) Parameter sensitivity: Vary α parameter in UCB and observe effect on convergence speed and quality of final configurations 3) Hierarchical vs. flat: Compare Hier-MAB performance to flat MAB on joint optimization problem with multiple hyper-parameters and analyze tradeoffs.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided. However, based on the content, several open questions emerge regarding scalability to larger hyper-parameter spaces, sensitivity to optimization algorithm choice, and handling of noisy or non-stationary reward distributions.

## Limitations
- Hierarchical decomposition assumes parameters can be optimized sequentially, which may not hold for strongly interacting parameters
- Performance depends on reward signal being stationary and representative of true effectiveness
- Specific implementation details of prompt compression module and exact Hier-MAB code are not fully specified, affecting reproducibility

## Confidence

- **High:** The core claim that framing RAG hyper-parameter tuning as a multi-armed bandit problem enables online learning and adaptation
- **Medium:** The claim that two-level Hier-MAB approach reduces search space complexity from exponential to linear and outperforms other baselines
- **Low:** The assumption that optimal joint configuration can be approximated by sequentially optimizing one hyper-parameter at a time, and that reward signal is always reliable indicator of effectiveness

## Next Checks

1. **Parameter Interaction Analysis**: Conduct experiments systematically varying multiple hyper-parameters simultaneously and compare Hier-MAB performance to flat MAB approaches to quantify impact of parameter interactions on solution quality.

2. **Reward Signal Robustness**: Design experiments with intentionally non-stationary or noisy reward distributions and evaluate how quickly and effectively Hier-MAB adapts compared to other optimization methods.

3. **Implementation Verification**: Re-implement two-level Hier-MAB approach and prompt compression module based on paper descriptions, and run experiments on simplified RAG system to verify reported performance improvements can be reproduced.