---
ver: rpa2
title: Alleviating Catastrophic Forgetting in Facial Expression Recognition with Emotion-Centered
  Models
arxiv_id: '2404.12260'
source_url: https://arxiv.org/abs/2404.12260
tags:
- dataset
- images
- datasets
- training
- ecgr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in CNNs for facial
  expression recognition by proposing an emotion-centered generative replay (ECgr)
  approach. The method generates synthetic images per emotion class using WGAN-GPs,
  filters them with a quality assurance algorithm, and integrates them into retraining
  to preserve knowledge from source datasets while adapting to new ones.
---

# Alleviating Catastrophic Forgetting in Facial Expression Recognition with Emotion-Centered Models

## Quick Facts
- arXiv ID: 2404.12260
- Source URL: https://arxiv.org/abs/2404.12260
- Reference count: 15
- Primary result: ECgr with QA improves accuracy and F1 scores over fine-tuning, particularly in retaining emotion classes like happiness and surprise

## Executive Summary
This paper addresses catastrophic forgetting in CNNs for facial expression recognition by proposing an emotion-centered generative replay (ECgr) approach. The method generates synthetic images per emotion class using WGAN-GPs, filters them with a quality assurance algorithm, and integrates them into retraining to preserve knowledge from source datasets while adapting to new ones. Experimental results on MUG, JAFFE, TFEID, and CK+ datasets show ECgr with QA significantly improves accuracy and F1 scores over fine-tuning, particularly in retaining emotion classes like happiness and surprise. Weighted QA benefits initial adaptations but less so with multiple datasets. The approach mitigates forgetting, though computational cost and network-dependent variability remain challenges.

## Method Summary
The method uses emotion-specific WGAN-GPs to generate synthetic facial images for each emotion class from the source dataset. These synthetic images are filtered through a quality assurance (QA) algorithm that uses the original CNN to retain only correctly classified images. The filtered synthetic images are then used for continual retraining when adapting to new datasets, preserving knowledge of source emotion classes. A weighted loss function based on CNN confidence scores further refines the process by emphasizing high-quality synthetic samples during training.

## Key Results
- ECgr with QA significantly improves accuracy and F1 scores compared to fine-tuning across multiple datasets
- Emotion classes like happiness and surprise show particularly strong retention with ECgr+QA
- Weighted QA provides initial adaptation benefits but diminishing returns with multiple dataset transfers
- The approach effectively mitigates catastrophic forgetting while maintaining adaptation capability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Emotion-centered generative replay (ECgr) with WGAN-GPs generates high-quality synthetic images that act as pseudo-rehearsal data to preserve knowledge of emotion classes.
- Mechanism: For each emotion class, a WGAN-GP generates synthetic facial images. These images are filtered by a CNN trained on the source dataset (quality assurance). Only correctly classified synthetic images are used for retraining, so the CNN rehearses old emotion patterns while adapting to new datasets.
- Core assumption: Synthetic images generated by emotion-specific WGAN-GPs are visually and semantically similar enough to real images to be correctly classified by the original CNN.
- Evidence anchors:
  - [abstract] "integrating synthetic images from generative adversarial networks"
  - [section] "Using these trained WGAN-GPs, we generate augmented datasets for each class"
  - [corpus] Weak. Corpus neighbors discuss FER, but none directly address GAN-based pseudo-rehearsal.
- Break condition: If synthetic images are misclassified by the original CNN, they are filtered out, reducing rehearsal effectiveness.

### Mechanism 2
- Claim: Quality assurance (QA) filtering ensures that only high-fidelity synthetic images are used, preventing the introduction of noise that could confuse the CNN during retraining.
- Mechanism: Generated images are passed through the original CNN; only those classified correctly are retained. This acts as a gatekeeper to remove low-quality or incorrectly generated samples.
- Core assumption: The original CNN can reliably distinguish high-quality synthetic images from low-quality ones for emotion classes.
- Evidence anchors:
  - [section] "The QA algorithm filters out low-quality or incorrect images... Only the high-quality synthetic samples... are retained for training."
  - [section] "The QA process is performed using the CNN trained on the source dataset."
  - [corpus] Weak. No corpus papers directly address QA filtering of GAN outputs for FER.
- Break condition: If the original CNN's classification performance degrades, QA filtering may start removing useful images or letting in poor ones.

### Mechanism 3
- Claim: Weighted loss functions based on CNN confidence penalize low-confidence synthetic images, guiding the network to focus on high-quality samples during retraining.
- Mechanism: Each synthetic image prediction is weighted by the CNN's confidence score. Low-confidence predictions reduce the loss contribution, discouraging the network from overfitting to uncertain samples.
- Core assumption: Confidence scores from the CNN correlate with the quality and usefulness of synthetic images for rehearsal.
- Evidence anchors:
  - [section] "we weigh the importance of the synthetic images, considering the CNN output score as an image quality assignment"
  - [section] "Equation (1)... a weight w is applied to each prediction. This weight is determined by the CNN's confidence percentage"
  - [corpus] Weak. Corpus does not discuss weighted loss for GAN-generated samples.
- Break condition: If confidence scores are unreliable (e.g., overconfident on poor images), weighting can harm learning.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: Understanding why fine-tuning degrades performance on old tasks is essential to appreciate the value of pseudo-rehearsal.
  - Quick check question: What happens to a CNN's performance on a source dataset after fine-tuning on a new dataset without any rehearsal strategy?

- Concept: Generative adversarial networks (GANs) and WGAN-GPs
  - Why needed here: WGAN-GPs are used to generate synthetic emotion-class images; understanding their training dynamics explains why they were chosen over standard GANs.
  - Quick check question: How does the gradient penalty in WGAN-GPs stabilize training compared to standard GANs?

- Concept: Quality assurance via classifier-based filtering
  - Why needed here: QA ensures synthetic data quality; knowing how classifier confidence can act as a proxy for sample fidelity is key to the method.
  - Quick check question: Why might a CNN trained on real images be a good judge of synthetic image quality in this context?

## Architecture Onboarding

- Component map:
  WGAN-GP generator -> WGAN-GP discriminator -> Original CNN (source-trained) -> Weighted loss module -> Retraining pipeline

- Critical path:
  1. Train emotion-specific WGAN-GPs on source dataset
  2. Generate synthetic images per emotion class
  3. Pass synthetic images through source CNN for QA
  4. Apply confidence-based weights to accepted images
  5. Combine synthetic and target data for continual retraining

- Design tradeoffs:
  - Using confidence weights helps filter low-quality images but may discard useful but uncertain samples.
  - Emotion-specific WGAN-GPs increase training time but improve class fidelity.
  - QA filtering reduces rehearsal set size but improves sample quality.

- Failure signatures:
  - ECgr+QA performance degrades faster than ECgr alone -> QA filtering too aggressive.
  - Synthetic images fail QA consistently -> WGAN-GP training unstable or class data too limited.
  - Weighted loss hurts more than helps -> CNN confidence scores are unreliable.

- First 3 experiments:
  1. Train WGAN-GP per emotion class on source dataset and qualitatively inspect synthetic outputs.
  2. Run QA filtering: measure acceptance rate and inspect rejected samples for patterns.
  3. Compare continual retraining with ECgr vs ECgr+QA vs ECgr+wQA on a two-dataset transfer (e.g., MUG->JAFFE).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the ECgr+QA method vary across different network architectures beyond CNNs, such as transformers or recurrent neural networks, in mitigating catastrophic forgetting?
- Basis in paper: [inferred] The paper primarily focuses on CNNs and does not explore other architectures.
- Why unresolved: The study is limited to CNNs, leaving the effectiveness of ECgr+QA on other architectures unexplored.
- What evidence would resolve it: Comparative experiments applying ECgr+QA to transformers or RNNs would provide insights into its generalizability.

### Open Question 2
- Question: What is the computational cost and feasibility of real-time implementation of the ECgr+QA method using WGAN-GPs for data generation?
- Basis in paper: [explicit] The paper mentions that WGAN-GP-based data generation can be computationally expensive.
- Why unresolved: While computational cost is acknowledged, the paper does not provide detailed analysis or solutions for real-time application.
- What evidence would resolve it: Profiling the computational resources and runtime of ECgr+QA in real-time scenarios would clarify its practicality.

### Open Question 3
- Question: How can the quality assurance algorithm be improved to reduce errors from classes with high confidence misclassifications?
- Basis in paper: [explicit] The paper discusses that errors with high confidence can negatively affect synthetic image weights and retraining.
- Why unresolved: The paper identifies the issue but does not propose specific improvements to the QA algorithm.
- What evidence would resolve it: Developing and testing enhanced QA algorithms that address high-confidence misclassifications would provide a solution.

## Limitations

- Data dependency: Method assumes balanced class distributions in source datasets for effective synthetic image generation
- Computational overhead: Training emotion-specific WGAN-GPs significantly increases resource requirements
- QA reliability: Method depends on original CNN's classification performance remaining stable across adaptations
- Generalization uncertainty: Effectiveness across different network architectures remains unexplored

## Confidence

**High Confidence**: ECgr with QA improves accuracy and F1 scores over fine-tuning is supported by experimental results on multiple datasets.

**Medium Confidence**: Weighted QA benefits initial adaptations but less so with multiple datasets is plausible but requires further validation.

**Low Confidence**: Emotion-specific WGAN-GPs will consistently generate high-quality synthetic images across diverse datasets is uncertain without extensive qualitative analysis.

## Next Checks

1. **Synthetic Image Quality Analysis**: Conduct detailed qualitative and quantitative analysis of synthetic images using FID/KID metrics and inspect class-specific features.

2. **QA Filtering Robustness Test**: Measure acceptance rates and confidence score distributions; test QA robustness by degrading CNN performance.

3. **Cross-Architecture Generalization**: Reproduce ECgr+QA using different CNN architectures or non-CNN models as QA filter to assess generalizability.