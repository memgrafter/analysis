---
ver: rpa2
title: Towards Unified Multi-granularity Text Detection with Interactive Attention
arxiv_id: '2405.19765'
source_url: https://arxiv.org/abs/2405.19765
tags:
- text
- detection
- page
- granularities
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DAT (Detect Any Text), a unified framework
  for multi-granularity text detection that combines scene text detection, document
  layout analysis, and page segmentation into a single end-to-end model. The key innovation
  is an interactive attention module that correlates structural information across
  text instances at different granularities (word, line, paragraph, page), enabling
  mutual improvement in detection performance.
---

# Towards Unified Multi-granularity Text Detection with Interactive Attention

## Quick Facts
- arXiv ID: 2405.19765
- Source URL: https://arxiv.org/abs/2405.19765
- Authors: Xingyu Wan; Chengquan Zhang; Pengyuan Lyu; Sen Fan; Zihan Ni; Kun Yao; Errui Ding; Jingdong Wang
- Reference count: 26
- Primary result: Introduces DAT, a unified framework for multi-granularity text detection achieving state-of-the-art performance across multiple benchmarks

## Executive Summary
This paper introduces DAT (Detect Any Text), a unified framework for multi-granularity text detection that combines scene text detection, document layout analysis, and page segmentation into a single end-to-end model. The key innovation is an interactive attention module that correlates structural information across text instances at different granularities (word, line, paragraph, page), enabling mutual improvement in detection performance. The model employs a mixed-granularity training strategy allowing parallel training on datasets with incomplete annotations, and includes a prompt-based segmentation module for handling arbitrarily-shaped texts and complex layouts. Experimental results demonstrate state-of-the-art performance across multiple benchmarks, with the DAT model achieving F-scores of 92.66 on ICDAR2015, 90.98 on CTW1500, and 65.7 mAP on M6Doc dataset.

## Method Summary
DAT is built on a Swin Transformer Large backbone and employs a multi-granularity detection framework with group-wise queries for each text level. The interactive attention module uses a binary attention mask with interaction factor I=1 to enable bidirectional information flow between adjacent text granularities during representation learning. The model uses a mixed-granularity training strategy with dynamic loss weighting to handle datasets with incomplete annotations, and includes a prompt-based segmentation module that refines detection outcomes using multi-granularity detection results as prompts. The entire framework is trained end-to-end for 120 epochs using a combination of detection and segmentation losses.

## Key Results
- Achieves F-score of 92.66 on ICDAR2015 benchmark for word detection
- Achieves F-score of 90.98 on CTW1500 benchmark for line detection
- Achieves 65.7 mAP on M6Doc dataset for page segmentation tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Interactive attention across adjacent granularities enables mutual performance improvement between text detection tasks.
- Mechanism: The model uses an attention mask with interaction factor I=1 to allow bidirectional information flow between adjacent text granularities (word↔line, line↔paragraph, paragraph↔page). This enables lower-level features to benefit from higher-level context and vice versa during representation learning.
- Core assumption: Text instances at different granularities share intrinsic structural correlations that can be exploited through attention mechanisms.
- Evidence anchors:
  - [abstract]: "A pivotal innovation in DAT is the across-granularity interactive attention module, which significantly enhances the representation learning of text instances at varying granularities by correlating structural information across different text queries."
  - [section]: "The attention mask A is a binary matrix... When I = 1, the global query embedding is enabled to interactive across different levels of query embeddings only in adjacent granularities"
  - [corpus]: No direct evidence in corpus papers about interactive attention between text granularities.
- Break condition: If interaction factor I is increased beyond 1 (to 2 or 3), the performance drops sharply as shown in Table 3, suggesting that unrestricted interactions introduce noise rather than useful correlations.

### Mechanism 2
- Claim: Mixed-granularity training enables effective parallel training on datasets with incomplete annotations.
- Mechanism: The model dynamically adjusts loss weights based on which granularities are annotated in each training sample, allowing training on datasets that only have partial annotations while still learning to predict all granularities.
- Core assumption: Models can learn multi-granularity detection from incomplete supervision through the proposed loss weighting strategy.
- Evidence anchors:
  - [abstract]: "Additionally, a prompt-based segmentation module refines detection outcomes for texts of arbitrary curvature and complex layouts"
  - [section]: "The loss weights ωt for each text granularity are dynamically adjusted within each training batch" and "Such framework design leverages the power of parallel training on diverse datasets, even those with limited annotation granularities"
  - [corpus]: No direct evidence in corpus papers about mixed-granularity training with incomplete annotations.
- Break condition: If training data lacks sufficient examples for certain granularity combinations, the model may fail to learn robust representations for those levels.

### Mechanism 3
- Claim: Prompt-based segmentation module significantly improves detection of arbitrarily-shaped texts and complex layouts.
- Mechanism: The segmentation branch uses multi-granularity detection results as prompts to perform fine-grained foreground-background segmentation, refining the detection polygons beyond what regression-based approaches can achieve.
- Core assumption: Segmentation conditioned on detection results can produce more accurate boundaries for complex text shapes than direct polygon regression.
- Evidence anchors:
  - [abstract]: "Additionally, a prompt-based segmentation module refines detection outcomes for texts of arbitrary curvature and complex layouts, thereby improving DAT's accuracy and expanding its real-world applicability"
  - [section]: "The introduced mask decoder can perform more fine-grained text contour segmentation by using the multi-granularity detection results as prompts"
  - [corpus]: No direct evidence in corpus papers about prompt-based segmentation for text detection.
- Break condition: For datasets with simple quadrilateral annotations (ICDAR2015, MSRA-TD500), the segmentation refinement may actually hurt evaluation performance since the ground truth is in simpler format.

## Foundational Learning

- Concept: Transformer-based object detection (DETR architecture)
  - Why needed here: DAT builds upon DETR/DINO architecture, using transformer decoders with learnable query embeddings for text detection
  - Quick check question: How does DETR differ from traditional anchor-based object detection methods in terms of label assignment and post-processing requirements?

- Concept: Multi-task learning with dynamic loss weighting
  - Why needed here: The mixed-granularity training strategy requires dynamically adjusting loss weights based on available annotations per sample
  - Quick check question: What is the formula for computing loss weights ωt when multiple granularities are annotated in the same sample?

- Concept: Interactive attention mechanisms
  - Why needed here: The core innovation relies on allowing query embeddings to attend to adjacent granularity levels through controlled attention patterns
  - Quick check question: How does the interaction factor I control the extent of cross-granularity interactions in the attention mask?

## Architecture Onboarding

- Component map: Backbone -> Multi-scale features -> Transformer decoder -> Detection heads for all granularities -> Mask decoder -> Segmentation masks
- Critical path:
  1. Image → Backbone → Multi-scale features
  2. Features + Group queries → Transformer decoder (self-attention → interactive attention → cross-attention)
  3. Decoder output → Detection heads for all granularities
  4. Detection results + Fused features → Mask decoder → Segmentation masks
  5. Combined DET + SEG losses → Backpropagation

- Design tradeoffs:
  - Single unified model vs. separate task-specific models: Increased GFLOPS (474 vs ~249) but eliminates need for 4 separate models
  - Interactive attention I=1 vs I>1: Controlled interactions prevent noise but may miss some cross-granularity benefits
  - Segmentation refinement vs. direct regression: Better for arbitrary shapes but hurts performance on simple quadrilateral datasets

- Failure signatures:
  - Performance drops when interaction factor I is increased beyond 1
  - Segmentation refinement hurts performance on quadrilateral-only annotated datasets
  - Low utilization of multilingual training data due to annotation granularity mismatches

- First 3 experiments:
  1. Train baseline without interactive attention to establish performance floor
  2. Enable interactive attention with I=1 and compare against baseline
  3. Test different interaction factors (I=2, I=3) to understand optimal interaction range

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the interactive attention module's performance vary when applied to datasets with more than four text granularity levels (e.g., character-level, block-level, or region-level annotations)?
- Basis in paper: [inferred] The paper focuses on word, line, paragraph, and page levels but mentions the framework could theoretically handle additional granularities. The interactive attention mechanism's design with adjustable interaction factors suggests scalability, but no experiments validate this.
- Why unresolved: The paper only evaluates the interactive attention module on four text granularities. No experiments or analysis exist for additional granularity levels that might be present in other datasets or real-world scenarios.
- What evidence would resolve it: Experimental results showing DAT's performance with additional granularity levels (character, block, region) on appropriate datasets, along with ablation studies demonstrating how the interactive attention module scales with more granularity levels.

### Open Question 2
- Question: What is the precise mechanism by which the mixed-granularity training strategy enables the model to generate high-quality pseudo labels for incomplete-granularity datasets, and can this process be mathematically formalized?
- Basis in paper: [explicit] The paper claims the mixed-granularity training strategy allows parallel training on datasets with incomplete annotations and enables generation of high-quality pseudo labels, but doesn't provide a mathematical formulation of this process.
- Why unresolved: While the paper demonstrates empirically that pseudo labels can be generated, it doesn't explain the underlying mechanism or provide a theoretical framework for how the model learns to extrapolate missing granularity information during training.
- What evidence would resolve it: A formal mathematical analysis showing how the loss weighting scheme (Eq. 4) and interactive attention mechanism enable the model to infer missing granularity information, along with experiments isolating and validating this mechanism.

### Open Question 3
- Question: How does the performance of DAT vary when trained on datasets with different language distributions, particularly when the proportion of multilingual text changes significantly?
- Basis in paper: [explicit] The paper mentions using multilingual datasets (MLT, ArT) with different annotation granularities for different languages, but notes limited utilization due to annotation inconsistencies and doesn't explore how performance varies with different language proportions.
- Why unresolved: The paper acknowledges the challenge of multilingual datasets with varying annotation granularities but only provides a basic masking strategy without exploring how different language distributions affect overall performance or whether the model can effectively learn from mixed-language annotations.
- What evidence would resolve it: Systematic experiments varying the proportion of different languages in training data and measuring how this affects detection performance across all granularity levels, along with analysis of whether the interactive attention mechanism helps bridge annotation granularity differences across languages.

## Limitations
- The paper lacks comparisons against other state-of-the-art unified approaches or established multi-task learning baselines
- Mixed-granularity training strategy may face scalability challenges with very sparse annotations across granularities
- Segmentation refinement hurts performance on datasets with simple quadrilateral annotations

## Confidence
- **High Confidence**: The architectural design and implementation details of the DAT model, including the transformer-based backbone and detection heads for multiple granularities
- **Medium Confidence**: The performance claims on benchmark datasets, as they are based on established evaluation metrics but may benefit from independent replication
- **Medium Confidence**: The effectiveness of the interactive attention mechanism, supported by ablation studies but requiring further validation across different domains

## Next Checks
1. **Cross-Domain Generalization**: Test the DAT model on document datasets with significantly different layouts and text arrangements than those used in training to evaluate robustness
2. **Computational Efficiency Analysis**: Conduct detailed analysis of the trade-off between unified model performance and computational overhead compared to specialized single-task models
3. **Attention Mechanism Visualization**: Visualize the interactive attention weights to empirically verify that cross-granularity information flow occurs as theorized and identify any potential attention collapse scenarios