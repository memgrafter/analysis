---
ver: rpa2
title: Provably Better Explanations with Optimized Aggregation of Feature Attributions
arxiv_id: '2406.05090'
source_url: https://arxiv.org/abs/2406.05090
tags:
- attribution
- explanations
- feature
- aggregation
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of unreliable and inconsistent
  explanations from individual feature attribution methods in machine learning models.
  The authors propose a novel approach to optimize convex combinations of multiple
  feature attribution results to provably improve explanation quality metrics like
  robustness and faithfulness.
---

# Provably Better Explanations with Optimized Aggregation of Feature Attributions

## Quick Facts
- arXiv ID: 2406.05090
- Source URL: https://arxiv.org/abs/2406.05090
- Reference count: 40
- One-line primary result: Novel approach to provably improve feature attribution explanations by optimizing convex combinations via constrained quadratic programming.

## Executive Summary
This paper addresses the problem of unreliable and inconsistent explanations from individual feature attribution methods in machine learning models. The authors propose a novel approach to optimize convex combinations of multiple feature attribution results to provably improve explanation quality metrics like robustness and faithfulness. Their method formulates the aggregation as a constrained quadratic program that can be solved efficiently. Through extensive experiments on various model architectures and attribution techniques, they demonstrate that their aggregation strategies consistently outperform individual methods and existing baselines, achieving significant improvements in explanation quality.

## Method Summary
The method optimizes convex combinations of multiple feature attribution results by formulating the aggregation as a constrained quadratic program. This approach minimizes a generalized L2 metric (e.g., Average-Sensitivity or Infidelity) over convex combinations of attribution results. The authors use Rademacher complexity analysis to establish generalization bounds, ensuring that estimated weights from limited samples still yield near-optimal improvement. The aggregation weights are model- and sample-dependent, capturing the complementarity of different attribution methods.

## Key Results
- Aggregation strategies consistently outperform individual methods and existing baselines
- Significant improvements in explanation quality metrics like robustness and faithfulness
- Theoretically grounded with provable improvement guarantees and generalization bounds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimized convex combinations provably improve explanation quality metrics like robustness and faithfulness.
- Mechanism: The aggregation is framed as a constrained quadratic program where weights minimize a generalized L2 metric (e.g., Average-Sensitivity or Infidelity) over convex combinations of attribution results.
- Core assumption: The quality metrics can be expressed as generalized L2 metrics, enabling efficient optimization via quadratic programming.
- Evidence anchors:
  - [abstract]: "provable improvements of desired quality criteria such as robustness or faithfulness"
  - [section]: "evaluating such metrics can simply be performed by estimating the expectation with a finite set of metric evaluation samples"
  - [corpus]: Weak - no direct support; assumes generalized L2 formulation is standard in explainability.
- Break condition: If the metric cannot be expressed in L2 form, the quadratic program formulation fails.

### Mechanism 2
- Claim: Generalization bounds ensure that estimated weights from limited samples still yield near-optimal improvement.
- Mechanism: Rademacher complexity analysis bounds the deviation between estimated and ideal weights, guaranteeing improvement with high probability.
- Core assumption: The attribution results are normalized and bounded, and the loss function (squared Euclidean distance) is Lipschitz continuous.
- Evidence anchors:
  - [section]: "Theorem 4.3 establishes a corresponding result" with "worst-case performance gap diminishes with order O(1/√m)"
  - [corpus]: Weak - the bound relies on Maurer's concentration result but no direct empirical check is shown.
- Break condition: If the attribution vectors are unbounded or highly non-convex, the Lipschitz assumption fails and bounds become meaningless.

### Mechanism 3
- Claim: Aggregation weights are model- and sample-dependent, avoiding reliance on a single universal attribution method.
- Mechanism: Boxplots show weight distributions spanning nearly the full [0,1] range and vary across models, implying method complementarity.
- Core assumption: Different attribution methods capture complementary aspects of model behavior; no single method is universally best.
- Evidence anchors:
  - [section]: "distribution of aggregation weights... varies substantially among samples covering oftentimes even the entire possible range between 0 and 1"
  - [corpus]: Weak - no ablation study on what happens if methods are highly correlated or redundant.
- Break condition: If all methods produce identical or highly correlated attributions, the diversity benefit disappears and weights collapse.

## Foundational Learning

- Concept: Generalized L2 metrics for explanation quality
  - Why needed here: They enable the optimization of convex combinations via quadratic programming.
  - Quick check question: Can you express Average-Sensitivity as an expectation of a squared Euclidean distance?

- Concept: Rademacher complexity and generalization bounds
  - Why needed here: They quantify how well weights estimated from finite samples will generalize to unseen metrics.
  - Quick check question: What is the order of the worst-case performance gap as a function of sample size m?

- Concept: Constrained quadratic programming
  - Why needed here: It efficiently finds optimal convex weights that improve multiple quality metrics simultaneously.
  - Quick check question: Why must the aggregation weights sum to one and be non-negative?

## Architecture Onboarding

- Component map:
  - Input: Attribution outputs from multiple methods (ϕ₁…ϕₖ)
  - Core: Constrained QP solver (cvxpy) optimizing over Ω
  - Metric estimator: Monte Carlo sampling of γ₁,γ₂ for L2 formulation
  - Output: Aggregated attribution ϕω and weight vector ω
  - Evaluation: Separate hold-out samples for robustness/faithfulness checks

- Critical path:
  1. Generate attribution results for each method
  2. Sample metric evaluation points (γ₁,γ₂)
  3. Formulate and solve constrained QP
  4. Apply aggregation weights to attributions
  5. Validate on unseen metric samples

- Design tradeoffs:
  - More methods → better diversity but higher QP dimension and runtime
  - More metric samples → tighter generalization bounds but more computation
  - Choice of metrics → affects which aspects of quality are optimized

- Failure signatures:
  - All weights collapse to one method → loss of diversity
  - Very high QP solve times → too many methods or high-dimensional attributions
  - No improvement over baselines → metric not well-suited to L2 form or poor sampling

- First 3 experiments:
  1. Two gradient methods on a small CNN, compare SENSAVG before/after aggregation
  2. Three attribution methods on ResNet18, test generalization to SENSMAX
  3. Six LIME variants on VGG16, evaluate ROAD metric improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number and diversity of feature attribution methods to combine for maximizing explanation quality?
- Basis in paper: [inferred] The authors conduct ablation studies showing that increasing the number of methods improves metrics up to a point of saturation, and combining different types of methods (gradient-based vs. perturbation-based) provides additional benefits.
- Why unresolved: The paper only explores a limited range of method combinations (up to 7 methods) and does not systematically investigate the optimal number or diversity. The saturation point and diminishing returns are not precisely quantified.
- What evidence would resolve it: Systematic experiments varying the number of methods (e.g., 2, 4, 8, 16) and types of methods (e.g., gradient-based only, perturbation-based only, mixed) on multiple datasets and models, measuring the trade-off between explanation quality and computational cost.

### Open Question 2
- Question: How does the proposed aggregation approach generalize to other types of explanations beyond feature attributions, such as concept-based, optimization-based, or counterfactual explanations?
- Basis in paper: [explicit] The authors mention this as a potential future direction, stating that "Future work could also explore how to best incorporate supplementary insights derived from concept-based, optimization-based or counterfactual explanations to even further enhance explainability with aggregation."
- Why unresolved: The paper focuses specifically on feature attribution methods and does not investigate the applicability of the aggregation approach to other types of explanations. The potential benefits and challenges of combining different explanation types are not explored.
- What evidence would resolve it: Experiments applying the aggregation approach to combinations of feature attributions with other explanation types (e.g., concept-based, optimization-based, counterfactual) on multiple datasets and models, measuring the impact on explanation quality and identifying any unique challenges or benefits.

### Open Question 3
- Question: What are the theoretical guarantees for the generalization of the aggregation approach to unseen models and data distributions?
- Basis in paper: [explicit] The authors provide a generalization bound (Theorem 4.3) for the aggregation weights estimated from a limited number of metric evaluation samples, but this bound is specific to the generalized L2 metrics and the assumptions made in the theorem.
- Why unresolved: The generalization bound provided is specific to the assumptions made in the theorem and does not directly address the generalization to unseen models or data distributions. The paper does not investigate the robustness of the aggregation approach to distributional shifts or model variations.
- What evidence would resolve it: Experiments evaluating the aggregation approach on unseen models and data distributions, measuring the degradation in explanation quality and comparing it to the theoretical bounds. Additionally, investigating the impact of distributional shifts and model variations on the aggregation weights and explanation quality.

## Limitations

- The theoretical guarantees hinge on expressing quality metrics as generalized L2 metrics, which may not hold for all explanation evaluation criteria.
- The Rademacher complexity bounds assume bounded, normalized attributions and Lipschitz continuity, conditions that could fail with unbounded or highly non-convex attribution methods.
- The empirical validation primarily compares against simple baselines rather than state-of-the-art ensemble methods.

## Confidence

- High Confidence: The quadratic programming formulation for optimizing convex combinations is mathematically sound and computationally tractable.
- Medium Confidence: The improvement guarantees over individual methods are demonstrated empirically, though the theoretical bounds are asymptotic and may not reflect finite-sample behavior.
- Medium Confidence: The generalization bounds are theoretically established but rely on assumptions about attribution properties that require empirical validation.

## Next Checks

1. **Metric Expressibility Test**: Systematically verify which commonly used explanation quality metrics (e.g., Insertion/Deletion, SHAP dependence measures) can be expressed as generalized L2 metrics and which cannot.

2. **Attribution Property Analysis**: Empirically measure the boundedness, normalization, and Lipschitz continuity of attribution vectors from different methods across multiple datasets to validate theoretical assumptions.

3. **Correlation Impact Study**: Conduct controlled experiments with highly correlated attribution methods to quantify when the diversity benefit of aggregation diminishes and weights collapse to dominant methods.