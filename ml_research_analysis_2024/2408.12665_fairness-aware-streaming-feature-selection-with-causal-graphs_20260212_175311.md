---
ver: rpa2
title: Fairness-Aware Streaming Feature Selection with Causal Graphs
arxiv_id: '2408.12665'
source_url: https://arxiv.org/abs/2408.12665
tags:
- features
- feature
- causal
- fairness
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Streaming Feature Selection with Causal\
  \ Fairness (SFCF), the first approach for online feature selection in streaming\
  \ features that considers both algorithmic accuracy and fairness. The core idea\
  \ is to construct two egocentric causal graphs\u2014one for the protected feature\
  \ and one for the label\u2014to model non-associational feature correlations."
---

# Fairness-Aware Streaming Feature Selection with Causal Graphs

## Quick Facts
- arXiv ID: 2408.12665
- Source URL: https://arxiv.org/abs/2408.12665
- Reference count: 40
- First approach for online feature selection in streaming features that considers both algorithmic accuracy and fairness

## Executive Summary
This paper introduces Streaming Feature Selection with Causal Fairness (SFCF), a novel approach for online feature selection in streaming feature environments that addresses both accuracy and fairness. The method constructs egocentric causal graphs for both the protected feature and the label to model non-associational feature correlations, enabling real-time identification of inadmissible features that are causally related to protected features but independent of labels. SFCF dynamically updates these causal structures using Markov blanket and d-separation techniques, allowing feature selection without requiring complete feature space knowledge.

## Method Summary
SFCF operates by building two egocentric causal graphs—one centered on the protected feature and one on the label—to identify admissible and inadmissible features in streaming data. The algorithm uses Markov blanket to determine strongly relevant features and conditional independence tests to update graphs incrementally. Inadmissible features (causally related to protected features but independent of labels) are removed and replaced with admissible features from the label's causal graph. This approach allows SFCF to optimize the tradeoff between accuracy and fairness while maintaining real-time performance through incremental graph construction rather than complete powerset searches.

## Key Results
- Achieves 52% improvement in equalized odds fairness metric compared to state-of-the-art methods
- Maintains 98% sparsity (proportion of selected features) while significantly reducing runtime by 99%
- Delivers near-identical accuracy to baseline methods while providing substantial fairness improvements

## Why This Works (Mechanism)

### Mechanism 1
Causal graphs egocentric to both protected feature and label allow non-associational modeling of streaming features, enabling real-time identification of inadmissible features without full feature space knowledge. By constructing two egocentric causal graphs, SFCF can determine whether a streaming feature is strongly relevant to the label but conditionally independent of the protected feature, indicating it is admissible. This dynamic construction avoids the need for prior domain knowledge or complete feature space, and allows continuous updating as new features arrive. Core assumption: Causal relationships among streaming features, labels, and protected features can be learned incrementally using Markov blanket and d-separation, without requiring a complete causal graph upfront.

### Mechanism 2
SFCF can replace inadmissible features with admissible features from the label's causal graph to optimize the tradeoff between accuracy and fairness, without significant accuracy loss. After identifying inadmissible features (those causally related to the protected feature but not to the label), SFCF searches for admissible features—originally deemed redundant to the label but d-separated from the protected feature—that can be substituted in their place. This allows the algorithm to maintain predictive power while reducing bias. Core assumption: Features redundant to the label may become strongly relevant after removing inadmissible features, and such admissible features can be found in the complement of the two causal graphs.

### Mechanism 3
Incremental construction of causal graphs via Markov blanket and conditional independence tests allows SFCF to scale to high-throughput streaming feature environments, with runtime efficiency significantly better than offline methods. By using Markov blanket to identify strongly relevant features and conditional independence tests to update graphs incrementally, SFCF avoids the combinatorial complexity of searching powersets for each incoming feature. This results in much lower computational overhead than offline fairness-aware methods. Core assumption: The conditional independence tests (Fisher's z test and G2 test) accurately identify relevant and redundant features in real-time, and the Markov blanket approach remains tractable as feature streams grow.

## Foundational Learning

- Concept: Causal graphs and d-separation
  - Why needed here: Understanding how to model non-associational feature correlations and identify inadmissible features requires knowledge of causal structure and d-separation.
  - Quick check question: Can you explain what d-separation means and how it differs from statistical independence?

- Concept: Markov blanket and conditional independence
  - Why needed here: Incremental causal graph construction and feature selection rely on Markov blanket to identify strongly relevant features and conditional independence to update graphs as new features arrive.
  - Quick check question: What is a Markov blanket, and how does it relate to feature selection?

- Concept: Fairness metrics (Equalized Odds, Demographic Parity)
  - Why needed here: The algorithm explicitly optimizes for Equalized Odds, so understanding this metric is essential for interpreting results and configuring the model.
  - Quick check question: What is the difference between Equalized Odds and Demographic Parity?

## Architecture Onboarding

- Component map: Input streaming feature vector Xi -> Two egocentric causal graphs (GS, GY) -> Feature sets (MBi(T), Redundanti(T), Irrelevant i(T)) -> Output selected feature subset F*i optimized for accuracy and fairness
- Critical path: 1. Receive new feature Xi, 2. Update causal graphs GS and GY using Markov blanket and conditional independence tests, 3. Identify inadmissible features (IAi) and admissible features (Ai), 4. Replace inadmissible features with admissible ones (AD1i, AD2i), 5. Output final selected feature set F*i
- Design tradeoffs: Real-time vs. accuracy (incremental causal graph construction trades off some accuracy for real-time performance), Feature subset size vs. fairness (removing more inadmissible features improves fairness but may reduce accuracy if admissible features are insufficient), Runtime efficiency vs. robustness (fast conditional independence tests may miss subtle causal relationships)
- Failure signatures: Accuracy drops significantly after feature replacement (not enough admissible features or poor feature selection), Fairness metric does not improve (inadmissible features not correctly identified or not removed), Runtime increases dramatically (Markov blanket or conditional independence tests not scaling)
- First 3 experiments: 1. Run SFCF on a small synthetic dataset with known causal structure to verify graph construction and inadmissible feature detection, 2. Compare SFCF's feature selection and fairness metrics against baseline on a real dataset (e.g., Credit Card) with streaming features, 3. Benchmark SFCF's runtime efficiency against OSFS and offline fairness-aware methods on a medium-sized dataset (e.g., D2)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the tradeoff between accuracy and fairness be optimized in online streaming feature selection when the number of admissible features is limited?
- Basis in paper: [explicit] The paper discusses the tradeoff between accuracy and fairness, particularly when removing inadmissible features leads to information loss.
- Why unresolved: The paper suggests using admissible features to compensate for accuracy loss but does not provide a concrete method to determine the optimal number of admissible features to include.
- What evidence would resolve it: Experimental results showing the impact of varying the number of admissible features on both accuracy and fairness metrics.

### Open Question 2
- Question: What is the impact of feature arrival rate on the performance of the SFCF algorithm in real-world scenarios?
- Basis in paper: [inferred] The paper mentions that new features may appear in high throughput, questioning the scalability of traditional methods.
- Why unresolved: The paper does not explore how different feature arrival rates affect the algorithm's performance or its ability to maintain accuracy and fairness.
- What evidence would resolve it: Experiments testing the SFCF algorithm under varying feature arrival rates to assess its scalability and performance consistency.

### Open Question 3
- Question: How does the SFCF algorithm handle situations where the causal structure is unknown or cannot be accurately learned?
- Basis in paper: [explicit] The paper notes that most causal fairness studies postulate a known causal structure, which is often unrealistic.
- Why unresolved: The paper does not address the robustness of the SFCF algorithm when the learned causal structure is inaccurate or incomplete.
- What evidence would resolve it: Analysis of the algorithm's performance with different levels of causal structure accuracy or in scenarios where the structure is partially known.

## Limitations
- Relies on accurate real-time causal graph construction, which is challenging in high-dimensional streaming environments
- Evaluation relies on five benchmark datasets without full methodological transparency on critical implementation details
- Novelty claim of being "first" in this domain lacks comprehensive literature review of similar streaming fairness methods

## Confidence
- **High confidence**: The paper's overall framework of using egocentric causal graphs for fairness-aware streaming feature selection is logically coherent and methodologically sound
- **Medium confidence**: The claimed performance improvements (runtime efficiency 99%, sparsity 98%) are impressive but lack detailed methodological transparency for verification
- **Low confidence**: The novelty claim of being "first" in this domain and the specific implementation details required for exact reproduction

## Next Checks
1. Implement the SFCF algorithm with specified conditional independence tests and Markov blanket construction on a synthetic dataset with known causal structure to verify correct identification of inadmissible features
2. Contact authors for clarification on implementation details, particularly the parameters for Fisher's z test, G2 test thresholds, and the fairness constraint threshold λ used in the optimization objective
3. Apply SFCF to additional streaming datasets beyond the five benchmark datasets, including those with higher dimensionality and different protected attribute distributions, to assess robustness across varied scenarios