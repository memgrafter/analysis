---
ver: rpa2
title: CountARFactuals -- Generating plausible model-agnostic counterfactual explanations
  with adversarial random forests
arxiv_id: '2404.03506'
source_url: https://arxiv.org/abs/2404.03506
tags:
- counterfactuals
- plausibility
- counterfactual
- data
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces countARFactuals, a method for generating
  plausible counterfactual explanations using adversarial random forests (ARFs). The
  authors address the challenge of creating counterfactuals that are both plausible
  (realistic within the data manifold) and satisfy other desiderata like proximity
  and sparsity.
---

# CountARFactuals -- Generating plausible model-agnostic counterfactual explanations with adversarial random forests

## Quick Facts
- arXiv ID: 2404.03506
- Source URL: https://arxiv.org/abs/2404.03506
- Reference count: 40
- Primary result: ARF-based methods generate more plausible counterfactuals than competing methods without major sacrifices in proximity, sparsity, or runtime

## Executive Summary
This paper introduces countARFactuals, a method for generating plausible counterfactual explanations using adversarial random forests (ARFs). The authors address the challenge of creating counterfactuals that are both plausible (realistic within the data manifold) and satisfy other desiderata like proximity and sparsity. They propose two algorithms: (1) integrating ARF into the multi-objective counterfactual explanations (MOC) framework to speed up search and improve plausibility, and (2) using ARF directly to generate plausible counterfactuals without optimization. Experiments on synthetic and real data show that ARF-based methods generate more plausible counterfactuals than competing methods (MOC, MOCCTREE, NICE) without major sacrifices in proximity, sparsity, or runtime.

## Method Summary
The method leverages adversarial random forests (ARFs) to generate plausible counterfactual explanations in a model-agnostic way. ARF combines density estimation (FORDE) and generative modeling (FORGE) to learn the joint distribution of features and predictions. Two algorithms are proposed: (1) Integrating ARF into the MOC framework by using ARF-based density estimation as a plausibility measure and sampling plausible candidates with FORGE during mutation, and (2) Direct ARF generation by training ARF on observed data and sampling plausible counterfactuals that satisfy validity constraints. The methods handle mixed tabular data naturally and allow easy integration of additional objectives like proximity and sparsity.

## Key Results
- ARF achieved higher plausibility (median correlation 0.84 vs 0.69) compared to competing methods
- ARF-based methods were computationally faster, with ARF generating counterfactuals the fastest on average
- The integration of ARF into MOC resulted in a significantly higher hypervolume of Pareto sets compared to the original MOC
- ARF-based methods generated counterfactuals with comparable proximity and sparsity to competing methods

## Why This Works (Mechanism)

### Mechanism 1
ARF improves counterfactual plausibility by modeling the joint density of features and predictions in a single tree-based model. ARF combines density estimation (FORDE) and generative modeling (FORGE). FORDE estimates the joint density p(x) using a mixture of univariate densities in the leaves of a random forest, while FORGE generates new instances by sampling from these densities. By training ARF on (xi, f(xi)) pairs, the model learns both the feature distribution and the prediction behavior, enabling conditional sampling of plausible counterfactuals.

### Mechanism 2
Integrating ARF into MOC speeds up the counterfactual search and finds more plausible counterfactuals. By using ARF-based density estimation (o*plaus) as a plausibility measure in MOC and sampling plausible candidates with FORGE during mutation, the search space is restricted to more realistic counterfactuals from the start. This reduces the number of iterations needed to find Pareto-optimal solutions.

### Mechanism 3
ARF-based counterfactual generation is computationally efficient and handles mixed tabular data naturally. ARF uses tree-based learners that can handle mixed data types without preprocessing like one-hot encoding. The density estimation and sampling are based on simple univariate distributions in the leaves, which are computationally cheap. This allows for fast generation of plausible counterfactuals even in high-dimensional settings.

## Foundational Learning

- Concept: Multi-objective optimization
  - Why needed here: Counterfactual explanations involve multiple objectives like validity, proximity, plausibility, and sparsity, which often conflict with each other. Multi-objective optimization allows for finding a set of Pareto-optimal solutions that balance these objectives.
  - Quick check question: What is the difference between a Pareto-optimal solution and a dominated solution in multi-objective optimization?

- Concept: Generative modeling
  - Why needed here: To generate plausible counterfactuals, we need a model that can sample realistic data points from the underlying distribution. Generative modeling provides techniques like ARF that can learn the joint density of features and generate new samples.
  - Quick check question: How does the FORGE algorithm in ARF generate new samples conditioned on certain feature values?

- Concept: Density estimation
  - Why needed here: To evaluate the plausibility of counterfactuals, we need a measure of how likely they are under the true data distribution. Density estimation techniques like FORDE in ARF provide an estimate of the joint density, which can be used as a plausibility score.
  - Quick check question: How does the FORDE algorithm in ARF estimate the joint density using a mixture of univariate densities?

## Architecture Onboarding

- Component map: ARF model -> FORDE density estimation -> FORGE generative sampling -> MOC optimization -> Pareto set
- Critical path: 1) Train ARF on (xi, f(xi)) pairs 2) Use FORDE to evaluate plausibility of candidate counterfactuals 3) Use FORGE to generate plausible counterfactuals in MOC or standalone 4) Optimize for Pareto-optimal set of counterfactuals
- Design tradeoffs: Speed vs. plausibility (using ARF for sampling can speed up MOC but may restrict the search space), Dimensionality vs. accuracy (higher-dimensional data may require more complex tree structures or dimensionality reduction), Density estimation vs. generative modeling (FORDE focuses on evaluation while FORGE focuses on generation, each with its own strengths and limitations)
- Failure signatures: Poor plausibility (ARF fails to converge or learns a poor approximation of the joint density), Slow runtime (tree structure becomes too complex or sampling becomes inefficient in high dimensions), Invalid counterfactuals (ARF does not accurately capture the prediction function or the conditional sampling is not well-calibrated)
- First 3 experiments: 1) Train ARF on a simple synthetic dataset and evaluate the density estimation accuracy 2) Use FORGE to generate samples conditioned on certain feature values and check their plausibility 3) Integrate ARF into MOC and compare the runtime and solution quality to the original MOC

## Open Questions the Paper Calls Out

### Open Question 1
How does the plausibility measure o*plaus (Equation 6) compare to alternative plausibility measures that could be used with ARF, such as using the density estimate directly or other transformations? The paper compares o*plaus to the k-nearest neighbor plausibility measure oplaus but does not explore other transformations of the ARF density estimate or alternative plausibility measures that could be used with ARF.

### Open Question 2
How sensitive are the proposed ARF-based methods to the choice of hyperparameters, such as the number of features to change (m) in Algorithm 2 and the maximum set size (mmax) in Algorithm 1? The paper mentions these hyperparameters but does not provide a sensitivity analysis of their impact on the quality of the generated counterfactuals.

### Open Question 3
How do the proposed ARF-based methods perform on high-dimensional tabular data, and what are the limitations in terms of dimensionality? The paper evaluates the methods on datasets with up to 20 features but does not explicitly discuss the limitations of ARF-based methods for higher-dimensional data.

### Open Question 4
How do the proposed ARF-based methods perform on tabular data with complex feature interactions or non-linear relationships between features and the target variable? The paper uses randomly generated Bayesian networks with linear and non-linear relationships but does not explicitly discuss the performance of ARF-based methods on data with complex feature interactions or non-linear relationships.

## Limitations

- Generalization to high-dimensional mixed tabular data remains unclear
- Scalability and robustness to complex feature interactions are not fully evaluated
- Reliance on tree-based density estimation may struggle with highly non-linear manifolds in feature space

## Confidence

- High confidence: The computational efficiency gains of ARF-based methods and their ability to handle mixed data types naturally
- Medium confidence: The superiority of ARF-based plausibility measures over traditional distance-based metrics
- Medium confidence: The integration of ARF into MOC framework significantly speeds up counterfactual search

## Next Checks

1. Test ARF-based counterfactual generation on high-dimensional datasets (d > 50) to evaluate scalability and runtime efficiency
2. Compare ARF-generated counterfactuals against ground truth plausible instances in datasets with known generative processes
3. Evaluate the sensitivity of ARF's plausibility measure to hyperparameters like tree depth and number of trees to establish robustness bounds