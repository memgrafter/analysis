---
ver: rpa2
title: How to use and interpret activation patching
arxiv_id: '2404.15255'
source_url: https://arxiv.org/abs/2404.15255
tags:
- arxiv
- patching
- clean
- activations
- components
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive guide to using and interpreting
  activation patching, a mechanistic interpretability technique for understanding
  neural network circuits. The authors summarize practical advice and best practices
  based on their experience, covering different patching methods, interpretation of
  results, and metric selection.
---

# How to use and interpret activation patching

## Quick Facts
- arXiv ID: 2404.15255
- Source URL: https://arxiv.org/abs/2404.15255
- Authors: Stefan Heimersheim; Neel Nanda
- Reference count: 11
- Primary result: Provides comprehensive guide to using and interpreting activation patching for mechanistic interpretability

## Executive Summary
This paper serves as a practical guide for using activation patching, a key mechanistic interpretability technique for understanding neural network circuits. The authors compile best practices and practical advice based on extensive experience, covering different patching methods (denoising vs noising), metric selection, and interpretation of results. They explain how these techniques can reveal different aspects of circuit structure and provide guidance on avoiding common pitfalls.

## Method Summary
Activation patching involves running a model on a source prompt, saving intermediate activations, then running on a target prompt while replacing selected activations with those from the source. The paper covers two main approaches: denoising (patching clean→corrupt) which reveals sufficient components, and noising (patching corrupt→clean) which reveals necessary components. The method includes various metric choices for measuring the impact of patches, with logit difference recommended as the primary exploratory metric due to its continuity and approximate linearity.

## Key Results
- Denoising (clean→corrupt) reveals sufficient components while noising (corrupt→clean) reveals necessary components
- Logit difference is the most appropriate metric for exploratory patching due to its continuity and approximate linearity
- Path patching can distinguish between direct connections and mediated connections in circuits
- Different metrics can yield varying insights into circuit structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Denoising reveals sufficient components while noising reveals necessary components
- Mechanism: When patching clean activations into a corrupted prompt, any restored behavior must come from the patched component itself. When patching corrupted activations into a clean prompt, the model needs all necessary components intact to maintain correct behavior.
- Core assumption: The model processes information sequentially through layers, and patched components interact with clean/clean-approximated upstream activations

### Mechanism 2
- Claim: Logit difference is the most appropriate metric for exploratory patching
- Mechanism: Logit difference measures confidence gaps between correct and incorrect answers. It's continuous and approximately linear in the residual stream, making it sensitive to partial effects and easy to attribute to individual components.
- Core assumption: Most effects from patching are linear and additive in logit space

### Mechanism 3
- Claim: Path patching can distinguish between direct and mediated connections
- Mechanism: By allowing patches to affect only specific target components rather than all downstream components, path patching reveals whether two components interact directly or through intermediate components.
- Core assumption: Circuit components can be isolated in their effects on downstream processing

## Foundational Learning

- Concept: Sequential processing in transformers
  - Why needed here: Understanding sequential information flow is crucial for interpreting patching results, especially the difference between denoising and noising
  - Quick check question: If you patch layer 5 activations, what state are layers 0-4 in during the patched run?

- Concept: Residual stream arithmetic
  - Why needed here: The paper emphasizes that effects are linear and additive in logit space, essential for understanding why logit difference is a good metric
  - Quick check question: If component A adds +2 to a logit and component B adds +3, what's the total effect on that logit?

- Concept: Circuit structure (AND vs OR gates)
  - Why needed here: The paper uses AND/OR gate examples to explain why denoising and noising give different results
  - Quick check question: In an AND gate circuit, if you patch one input with clean activations but leave the other corrupted, will the output be restored?

## Architecture Onboarding

- Component map: Patching execution engine -> Metric computation -> Analysis pipeline
- Critical path: Clean prompt → Run and cache activations → Corrupted prompt → Patch activations → Run with patches → Compute metrics → Analyze results
- Design tradeoffs: Denoising is more sensitive to sufficient components but may miss necessary ones; noising is more comprehensive but noisier; logit difference is linear but may miss absolute effects
- Failure signatures: If all patches show similar small effects, the metric may be saturating; if results are inconsistent across metrics, there may be backup behavior or negative components
- First 3 experiments:
  1. Run a simple denoising experiment on a known circuit (like IOI) to verify the basic mechanism works
  2. Compare denoising vs noising results on the same circuit to observe the difference between sufficient and necessary components
  3. Test multiple metrics (logit difference, logprob, accuracy) on the same patches to understand their different sensitivities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop a principled framework for determining when denoising vs. noising is the appropriate patching technique for a given interpretability task?
- Basis in paper: The paper discusses that denoising and noising are not symmetric and that the choice between them depends on circuit structure (AND vs OR gates)
- Why unresolved: The paper provides examples of when each technique works better but doesn't offer a systematic way to determine which to use for arbitrary circuit structures

### Open Question 2
- Question: How can we address the problem of negative components in circuit analysis that consistently negatively affect performance?
- Basis in paper: The paper notes that some work noticed attention heads that consistently negatively affected performance, making it hard to judge circuit completeness
- Why unresolved: While KL divergence is mentioned as a potential metric, no clear solution is proposed for distinguishing between true negative components and artifacts

### Open Question 3
- Question: What is the optimal metric selection strategy for exploratory patching that balances sensitivity, specificity, and interpretability?
- Basis in paper: The paper extensively discusses various metrics and their strengths/weaknesses but doesn't offer a systematic approach for metric selection
- Why unresolved: The effectiveness of different metrics likely varies across circuit types, tasks, and model architectures, but this hasn't been empirically characterized

## Limitations

- The distinction between sufficient and necessary components may not capture all aspects of circuit functionality
- The paper's recommendations are based on empirical observations rather than rigorous theoretical justification
- Path patching's effectiveness on complex circuits remains largely theoretical without extensive experimental validation

## Confidence

- High confidence: The distinction between denoising and noising patching is well-established with clear theoretical grounding
- Medium confidence: Logit difference as the primary metric is based on practical experience rather than rigorous theoretical justification
- Low confidence: Path patching's ability to distinguish direct vs mediated connections lacks empirical validation on complex circuits

## Next Checks

1. Run identical patching experiments using logit difference, logprob, and accuracy metrics on a well-understood circuit to empirically verify which metric best captures circuit structure

2. Implement path patching on a simple known circuit (e.g., a toy AND gate) to verify it can distinguish between direct and mediated connections

3. Systematically vary the similarity between clean and corrupted prompts across multiple patching experiments to determine how prompt choice affects the reliability of sufficient/necessary component identification