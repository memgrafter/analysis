---
ver: rpa2
title: 'PDL: A Declarative Prompt Programming Language'
arxiv_id: '2410.19135'
source_url: https://arxiv.org/abs/2410.19135
tags:
- language
- block
- code
- https
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Prompt Declaration Language (PDL), a
  simple declarative data-oriented language for programming with large language models
  (LLMs). PDL aims to overcome the brittleness and complexity of existing prompting
  frameworks by providing a language that is orthogonal, typed, and keeps prompts
  at the forefront.
---

# PDL: A Declarative Prompt Programming Language

## Quick Facts
- arXiv ID: 2410.19135
- Source URL: https://arxiv.org/abs/2410.19135
- Reference count: 40
- Primary result: Introduces PDL, a declarative YAML-based language for LLM programming that reduces brittleness and enhances developer experience

## Executive Summary
This paper introduces the Prompt Declaration Language (PDL), a simple declarative data-oriented language for programming with large language models (LLMs). PDL aims to overcome the brittleness and complexity of existing prompting frameworks by providing a language that is orthogonal, typed, and keeps prompts at the forefront. PDL programs are represented as YAML documents, allowing for human-readable and structured prompts. The language supports various blocks for model calls, reading data, creating data, control constructs, and modularity. PDL's tooling includes an interpreter, IDE support, a Jupyter Notebook extension, a live document visualizer, and an SDK. Case studies demonstrate PDL's effectiveness in implementing RAG, agents, and generating PDL from PDL. Overall, PDL simplifies prompt programming, reduces brittleness, and enhances the developer experience.

## Method Summary
PDL is implemented as a declarative language using YAML syntax with JSON Schema for type checking. The approach centers on making programs data structures that can be manipulated and analyzed. The language provides a small set of orthogonal features including model blocks, read blocks, control structures, and modularity constructs. An interpreter executes PDL programs with dynamic type checking, while tooling support includes IDE extensions, notebook integration, and visualization capabilities. The method emphasizes simplicity and data-oriented design over imperative control flow, allowing programs to generate other programs and enabling potential optimizations through static analysis.

## Key Results
- PDL successfully implements RAG systems, agents, and code generation using a simple declarative approach
- YAML representation enables program transformations and meta-programming capabilities
- Comprehensive tooling ecosystem (IDE support, notebook integration, visualizer) enhances developer experience

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PDL reduces brittleness by using structured YAML and type checking to enforce data integrity in LLM interactions
- Mechanism: PDL represents programs as YAML data structures, allowing static analysis and dynamic type checking via JSON Schema. This constrains LLM outputs and interactions to well-typed formats, reducing errors from unstructured text handling
- Core assumption: Structured data representation and type checking are sufficient to prevent common LLM brittleness issues like hallucinations and unexpected output formats
- Evidence anchors:
  - [abstract] "PDL is a simple declarative data-oriented language that puts prompts at the forefront, based on YAML"
  - [section] "PDL is currently implemented by an interpreter, and the interpreter performs dynamic type checking"
  - [corpus] Weak evidence - corpus focuses on related prompt engineering approaches but doesn't directly address PDL's type checking mechanisms
- Break condition: When LLM outputs cannot be constrained to expected types, or when type specifications become too restrictive for flexible LLM interactions

### Mechanism 2
- Claim: PDL's orthogonality and simplicity reduce learning complexity compared to imperative prompting frameworks
- Mechanism: PDL provides a small set of orthogonal features (model blocks, read blocks, control structures) that compose in powerful ways without requiring developers to learn complex framework-specific APIs
- Core assumption: A small set of orthogonal features is sufficient to express complex LLM prompting patterns without requiring framework-specific complexity
- Evidence anchors:
  - [abstract] "PDL is a simple declarative data-oriented language that puts prompts at the forefront"
  - [section] "PDL is a simple declarative data-oriented language that puts prompts at the forefront by intentionally blurring the line between programs (e.g. for chaining and tools) and data (for prompts)"
  - [corpus] Weak evidence - corpus shows related work but doesn't directly compare learning complexity
- Break condition: When complex prompting patterns require features beyond PDL's orthogonal set, forcing developers to work around limitations

### Mechanism 3
- Claim: PDL's data-oriented design enables LLM programs to generate other PDL programs, supporting meta-programming capabilities
- Mechanism: Since PDL programs are represented as YAML data, they can be manipulated as data structures, allowing LLM-generated code to produce executable PDL programs
- Core assumption: The data-as-code approach is practical and safe for LLM-generated programs
- Evidence anchors:
  - [abstract] "Rendering programs in a data representation format even facilitates PDL programs that generate PDL programs with LLMs, similar to PAL"
  - [section] "One benefit of representing programs as data is that it facilitates program transformations"
  - [corpus] Weak evidence - corpus shows related work on prompt optimization but doesn't address PDL's meta-programming capabilities
- Break condition: When LLM-generated PDL code becomes too complex or unsafe to execute directly

## Foundational Learning

- Concept: YAML data serialization and structure
  - Why needed here: PDL is based on YAML, so understanding YAML syntax and structure is fundamental to reading and writing PDL programs
  - Quick check question: What is the difference between YAML block style and flow style syntax?

- Concept: JSON Schema for type specifications
  - Why needed here: PDL uses JSON Schema for type checking, so understanding schema syntax is necessary for defining and enforcing data types
  - Quick check question: How would you specify an array of strings in JSON Schema shorthand?

- Concept: Jinja2 template expressions
  - Why needed here: PDL uses Jinja2 expressions for templating within prompts and programs, so understanding basic Jinja2 syntax is essential
  - Quick check question: What is the syntax for embedding a variable in a Jinja2 expression?

## Architecture Onboarding

- Component map:
  - PDL Interpreter: Execution engine with CLI, sandboxing, and streaming mode
  - PDL IDE Support: VSCode extension with syntax highlighting, auto-complete, tooltips, and error checking
  - PDL Notebook Integration: Jupyter Notebook extension with %%pdl cell magic
  - PDL Live Visualizer: Tool for visualizing execution traces with colored nested boxes
  - PDL SDK: Python library for calling PDL from Python applications
  - Model Integration Layer: Supports various LLM platforms and models including Granite, watsonx, and Replicate

- Critical path:
  1. Developer writes PDL program as YAML document
  2. PDL interpreter parses and type checks the program
  3. Interpreter executes blocks sequentially, building context
  4. Model blocks call LLMs with accumulated context
  5. Results are collected and formatted for output

- Design tradeoffs:
  - Declarative vs Imperative: PDL uses YAML instead of Python, sacrificing imperative control flow for simplicity and structure
  - Control vs Automation: PDL gives developers precise control over prompts rather than automatically generating them like DSPy
  - Safety vs Flexibility: Sandboxing provides security but may limit some capabilities

- Failure signatures:
  - Type errors: PDL programs fail validation when outputs don't match specified JSON Schema types
  - LLM errors: Model blocks fail when LLM API calls return errors or unexpected formats
  - Parsing errors: Read blocks fail when input cannot be parsed according to specified parser (json, yaml, regex, jsonl)
  - Execution errors: Code blocks fail when Python execution encounters runtime errors

- First 3 experiments:
  1. Simple chatbot: Implement the basic chatbot example from Section 2 to understand core PDL concepts (read, model, repeat blocks)
  2. RAG implementation: Build the RAG example from Section 5.1 to understand data blocks, parser specifications, and integration with external code
  3. Agent creation: Implement the ReAct agent from Section 5.2 to understand control flow, JSON parsing, and multi-block coordination

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PDL's declarative approach compare to imperative prompting frameworks in terms of computational efficiency and runtime performance?
- Basis in paper: [inferred] The paper mentions that PDL's declarative nature could enable automatic optimizations for speed, accuracy, and security, and references SGLang's approach to optimizing computational performance through scheduling and caching.
- Why unresolved: The paper does not provide empirical data comparing PDL's performance to other prompting frameworks, and the potential for optimization is stated as future work.
- What evidence would resolve it: Benchmarking studies comparing PDL's runtime performance and resource utilization against popular imperative prompting frameworks like LangChain and Guidance in various use cases (chatbots, RAG, agents).

### Open Question 2
- Question: Can PDL effectively scale to handle complex, real-world applications involving multiple interconnected agents and large-scale data processing?
- Basis in paper: [explicit] The paper demonstrates PDL's capabilities with case studies including chatbots, RAG, and agent implementations, but does not explore large-scale, multi-agent systems or enterprise-level applications.
- Why unresolved: The case studies focus on relatively simple examples, and the paper does not address challenges of scaling PDL to enterprise-level complexity, such as handling concurrent requests, managing distributed state, or integrating with existing enterprise systems.
- What evidence would resolve it: Case studies or pilot implementations of PDL in enterprise environments, demonstrating its performance, reliability, and integration capabilities with existing systems and workflows.

### Open Question 3
- Question: How does the adoption of PDL impact the developer experience and productivity compared to existing prompting frameworks?
- Basis in paper: [explicit] The paper emphasizes PDL's goal of making prompt programming simpler, less brittle, and more enjoyable, and mentions tooling support for VSCode and Jupyter Notebooks.
- Why unresolved: While the paper highlights PDL's potential benefits for developer experience, it does not provide empirical data on developer productivity, learning curve, or satisfaction compared to other frameworks.
- What evidence would resolve it: User studies or surveys comparing developer productivity, code quality, and satisfaction when using PDL versus other prompting frameworks, measuring metrics such as time to implement common patterns, code maintainability, and error rates.

## Limitations

- Limited empirical evidence across diverse LLM platforms and model types
- Case studies focus on relatively simple applications, lacking large-scale deployment data
- Type system expressiveness may be constrained by JSON Schema limitations for complex LLM outputs

## Confidence

**High Confidence Claims**:
- PDL successfully implements a declarative, data-oriented approach to prompt programming
- The YAML-based representation enables program transformations and meta-programming capabilities
- PDL's tooling (IDE support, visualizer, SDK) enhances the developer experience

**Medium Confidence Claims**:
- PDL reduces brittleness compared to imperative frameworks (based on limited case studies)
- The orthogonality principle leads to simpler learning curves (conceptual, not empirically validated)
- Type checking via JSON Schema effectively prevents common LLM brittleness issues

**Low Confidence Claims**:
- PDL's performance and scalability in production environments (insufficient real-world deployment data)
- The trade-off between type safety and flexibility is optimal (not thoroughly explored)
- PDL's approach is superior to all existing frameworks for all use cases (limited comparative analysis)

## Next Checks

1. **Performance Benchmark**: Implement the same RAG application using PDL and two other popular frameworks (e.g., LangChain, DSPy) and measure execution time, memory usage, and developer effort required to build and maintain the application.

2. **Type System Stress Test**: Create a comprehensive test suite with intentionally malformed LLM outputs and measure PDL's ability to catch errors versus the brittleness of raw prompt engineering approaches. Include edge cases like nested structures, optional fields, and polymorphic types.

3. **Large-Scale Deployment Simulation**: Develop a complex application with 50+ prompts and multiple LLM providers, then measure PDL's performance in terms of program compilation time, memory usage, and developer productivity compared to maintaining the same application using imperative frameworks.