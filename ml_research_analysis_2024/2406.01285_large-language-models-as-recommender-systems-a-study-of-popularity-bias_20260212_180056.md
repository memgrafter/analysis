---
ver: rpa2
title: 'Large Language Models as Recommender Systems: A Study of Popularity Bias'
arxiv_id: '2406.01285'
source_url: https://arxiv.org/abs/2406.01285
tags:
- popularity
- bias
- recommender
- metric
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies popularity bias in LLM-based recommender systems.
  The authors first introduce a principled framework for measuring popularity bias
  by defining a set of desiderata and proposing a new metric called "log popularity
  difference" that satisfies these desiderata.
---

# Large Language Models as Recommender Systems: A Study of Popularity Bias

## Quick Facts
- arXiv ID: 2406.01285
- Source URL: https://arxiv.org/abs/2406.01285
- Authors: Jan Malte Lichtenberg; Alexander Buchholz; Pola Schwöbel
- Reference count: 40
- Primary result: LLM-based recommenders exhibit less popularity bias than traditional methods, with prompt-based mitigation offering further reduction at accuracy cost

## Executive Summary
This paper investigates popularity bias in Large Language Model (LLM)-based recommender systems, introducing a principled framework for measuring bias and evaluating a simple LLM recommender (WOK) against traditional baselines. The authors find that LLM-based recommenders exhibit less popularity bias than traditional collaborative filtering methods, even without explicit mitigation. They also experiment with prompt-based self-debiasing strategies, finding they can reduce popularity bias but at the cost of recommendation accuracy. The study suggests LLM-based recommenders have potential for more diverse recommendations while highlighting the challenges of balancing bias reduction with accuracy.

## Method Summary
The study evaluates LLM-based recommenders (WOK) using pre-trained models (GPT-3.5, GPT-4, Claude v1, Claude v2.1) with a simple prompt template that includes user history. The system is compared against traditional baselines (UserKNN, ItemKNN, TopPop, Random) on the MovieLens 10M dataset using 5-fold cross-validation with 1000 users per fold. The authors measure recommendation accuracy (HR@5, HR@10), popularity bias using a new "log popularity difference" metric, and the number of invalid recommendations. Prompt-based mitigation strategies are tested by instructing the LLM to match user history popularity or focus on less popular items.

## Key Results
- WOK models exhibit less popularity bias than traditional baselines, with only WOK-gpt-3.5 showing higher bias than the least-biased baseline
- Prompt-based mitigation strategies can reduce popularity bias but at the cost of recommendation accuracy
- The log popularity difference metric satisfies desiderata for measuring popularity bias in power-law distributed data
- LLM-based recommenders produce more invalid recommendations than traditional methods due to output parsing challenges

## Why This Works (Mechanism)

### Mechanism 1
LLM-based recommenders are less popularity-biased than traditional collaborative filtering methods. LLMs trained on diverse web content learn richer item representations that are less dependent on interaction frequency, allowing them to surface niche items more effectively than interaction-based models. This works when the LLM's training corpus contains sufficient diverse item coverage beyond their interaction counts.

### Mechanism 2
Prompt-based self-debiasing can reduce popularity bias in LLM recommenders. By instructing the LLM to match the user's historical popularity level or focus on niche items, the model adjusts its output distribution toward the desired popularity profile. This works when the LLM has learned to associate linguistic cues with popularity levels and can modulate recommendations accordingly.

### Mechanism 3
The log popularity difference metric satisfies desiderata for measuring popularity bias. By applying a log transformation to popularity scores before aggregation, the metric becomes robust to heavy-tailed distributions while maintaining anti-symmetry and sensitivity to long-tail items. This works when item popularity follows a power-law distribution, making log transformation statistically appropriate.

## Foundational Learning

- **Power-law distributions and their statistical properties**: Understanding why metrics based on empirical averages fail for power-law distributed popularity scores is crucial for interpreting the log popularity difference metric.

- **Collaborative filtering vs. content-based recommendation**: Understanding the fundamental difference between traditional RS and LLM-based RS is crucial for interpreting results, particularly regarding data requirements and recommendation logic.

- **Prompt engineering and self-debiasing in LLMs**: Understanding how LLMs respond to instructions is essential for evaluating the effectiveness and limitations of prompt-based mitigation strategies.

## Architecture Onboarding

- **Component map**: LLM API integration (OpenAI/Anthropic) -> Prompt template with user history injection -> Output parsing and movie ID resolution -> Popularity bias calculation module -> Evaluation pipeline with MovieLens dataset

- **Critical path**: 1) User history → Prompt template → LLM → Natural language output, 2) Output parsing → Movie ID resolution → Recommendation slate, 3) Popularity calculation → Bias metric computation → Evaluation

- **Design tradeoffs**: LLM-based RS requires no training data and enables cross-domain generalization but is slower and prone to hallucinations; traditional RS is fast and accurate but requires interaction data and may amplify popularity bias; prompt-based mitigation is simple but may trade accuracy for bias reduction

- **Failure signatures**: High percentage of invalid recommendations (parsing failures, out-of-catalog items), sudden spikes in popularity bias when adding high-popularity items (metric ill-behavedness), mitigation prompts causing dramatic accuracy drops

- **First 3 experiments**: 1) Compare WOK models with and without prompt-based mitigation on popularity bias and accuracy, 2) Test different prompt instructions (match user history vs. minimize popularity) to find optimal balance, 3) Evaluate correlation between log popularity difference and average popularity lift across different datasets

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The study relies on static MovieLens 10M data without considering temporal dynamics of popularity bias
- The log popularity difference metric lacks empirical validation across diverse datasets beyond MovieLens 10M
- The prompt-based mitigation strategy shows promise but requires careful engineering to balance bias reduction against accuracy

## Confidence
- **High**: LLM recommenders exhibit less popularity bias than traditional baselines
- **Medium**: Prompt-based self-debiasing effectively reduces popularity bias
- **Low**: Log popularity difference metric is universally applicable across all popularity distributions

## Next Checks
1. Test WOK models on multiple datasets with varying popularity distributions to validate metric robustness and generalization
2. Conduct ablation studies removing world knowledge from prompts to isolate the source of reduced popularity bias
3. Implement controlled experiments comparing LLM recommenders with and without catalog metadata access to determine if bias reduction comes from knowledge or filtering