---
ver: rpa2
title: Are LLM-based methods good enough for detecting unfair terms of service?
arxiv_id: '2409.00077'
source_url: https://arxiv.org/abs/2409.00077
tags:
- privacy
- service
- policy
- number
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models can help
  users detect unfair terms in privacy policies. The authors create a dataset of 12
  questions about privacy policies from 220 popular websites, then test five open-source
  and commercial chatbots on answering these questions.
---

# Are LLM-based methods good enough for detecting unfair terms of service?

## Quick Facts
- arXiv ID: 2409.00077
- Source URL: https://arxiv.org/abs/2409.00077
- Authors: Mirgita Frasheri; Arian Bakhtiarnia; Lukas Esterle; Alexandros Iosifidis
- Reference count: 18
- Current LLM performance (best at 53.3% accuracy) is insufficient for practical deployment in detecting unfair privacy terms

## Executive Summary
This paper investigates whether large language models can help users detect unfair terms in privacy policies. The authors create a dataset of 12 questions about privacy policies from 220 popular websites, then test five open-source and commercial chatbots on answering these questions. The best performance comes from ChatGPT-4 with 53.3% accuracy, while the best open-source model (Mixtral-8x7B) achieves 44.2%. All models perform better than random guessing but need significant improvement before practical deployment. The study finds that some questions are consistently harder to answer, with accuracy ranging from 15% to 71% depending on the question.

## Method Summary
The authors collected privacy policies from 220 popular websites and formulated 12 specific questions about privacy practices using a template that asks for yes/no answers. They used five different LLMs (three commercial: ChatGPT-3.5, ChatGPT-4, ChatGPT-4-turbo; two open-source: Mixtral-8x7B, Nous-Hermes-Llama2-13b) to answer these questions, implementing a summarization procedure for documents exceeding token limits. The model responses were compared against ground truth answers from PrivacySpy to calculate accuracy metrics for each question and model.

## Key Results
- ChatGPT-4 achieved the highest accuracy at 53.3% across all questions
- Mixtral-8x7B was the best-performing open-source model with 44.2% accuracy
- Question-specific performance varied significantly, ranging from 15% to 71% accuracy
- All models performed better than random guessing but require substantial improvement for practical use

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can parse and understand complex legal text in privacy policies to answer specific questions about unfair terms.
- Mechanism: The transformer architecture with attention mechanisms allows LLMs to capture long-range dependencies and contextual relationships in lengthy documents, enabling them to identify relevant clauses and extract answers to specific questions about data practices, security measures, and user rights.
- Core assumption: The model has been trained on sufficient legal and technical documentation to understand the domain-specific language used in privacy policies.
- Evidence anchors:
  - [abstract] "Large language models (LLMs) are good at parsing long text-based documents"
  - [section] "Text generation is an NLP task where the goal is to generate novel text given another text as input"
  - [corpus] Weak - corpus neighbors discuss privacy policy analysis but don't directly address the parsing mechanism
- Break condition: The model encounters terminology or clause structures that fall outside its training distribution, leading to misinterpretation of legal obligations or user rights.

### Mechanism 2
- Claim: Summarization techniques enable LLMs to handle privacy policies that exceed their token limits.
- Mechanism: The iterative summarization algorithm breaks down long documents into smaller pieces, summarizes each piece, and concatenates the summaries to create a condensed version that fits within the model's input constraints while preserving key information.
- Core assumption: The summarization process maintains sufficient detail and context for the model to accurately answer questions about the original document.
- Evidence anchors:
  - [section] "The lengths of the terms of service documents vary between 62-41510 words... As a result in some cases, the text needed to be summarized to fit the maximum number of tokens permitted for each bot."
  - [section] "Algorithm 1 Summarization Procedure" describes the iterative process
  - [corpus] Weak - corpus doesn't address summarization specifically
- Break condition: The summarization process loses critical information about specific clauses or conditions, leading to incorrect answers even when the question is straightforward.

### Mechanism 3
- Claim: Question-specific performance varies due to differences in answer complexity and availability of explicit information in privacy policies.
- Mechanism: Some questions require simple extraction of stated facts (e.g., "Does the policy list the personal data it collects?"), while others require inference or interpretation of complex legal language (e.g., "When does the policy allow law enforcement access to personal data?"), leading to performance differences.
- Core assumption: Privacy policies contain explicit information for some questions but require interpretation for others, and the model's performance reflects this variance in information accessibility.
- Evidence anchors:
  - [section] "Additionally, it can be noted that, even the best performing chatbot does not perform equally well on all questions. For example, chatGPT-4-turbo has only 35.9% accuracy for question 2, and accuracy as high as 71.4% for questions 4 and 12."
  - [section] "The lowest performance is recorded for question 10, where Nous-Hermes-Llama2-13b (NH-L2), chatGPT-3.5-turbo-0125 (gpt-3.5), and chatGPT-4-turbo (gpt-4) report the best accuracies. It is not known at the time of writing why some questions are more difficult to answer than others."
  - [corpus] Weak - corpus doesn't provide evidence about question-specific performance variance
- Break condition: When questions require cross-referencing multiple sections or understanding implicit implications that aren't explicitly stated in the document.

## Foundational Learning

- Concept: Natural Language Processing and Text Generation
  - Why needed here: Understanding how LLMs process and generate text is fundamental to grasping why they can answer questions about privacy policies
  - Quick check question: What architectural feature allows transformers to handle long-range dependencies in text?

- Concept: Legal Document Structure and Terminology
  - Why needed here: Privacy policies use specific legal language and follow particular structural conventions that models must understand to extract relevant information
  - Quick check question: What are the typical sections found in a privacy policy and what kind of information does each contain?

- Concept: Prompt Engineering and Template Design
  - Why needed here: The way questions are formatted and presented to the model significantly impacts performance, requiring understanding of effective prompt design
  - Quick check question: How does the format of a prompt affect the quality of responses from an LLM?

## Architecture Onboarding

- Component map:
  - Privacy policy collection and preprocessing → Question template application → Ground truth labeling → Model selection → Prompt formatting → Token limit handling → Summarization (if needed) → Question answering → Answer comparison to ground truth → Accuracy calculation → Performance analysis by question type

- Critical path: Privacy policy → Summarization (if needed) → Prompt formatting → LLM query → Answer extraction → Ground truth comparison → Accuracy calculation

- Design tradeoffs:
  - Open-source vs commercial models: Open-source offers transparency and customization but may require more computational resources; commercial models offer convenience but less control
  - Token limits vs document completeness: Summarization enables processing of long documents but may lose critical details
  - Question specificity vs generalization: Specific questions may yield better accuracy but limit the system's applicability

- Failure signatures:
  - Consistent low accuracy across all questions indicates fundamental limitations in the model's understanding of legal text
  - High variance in performance between questions suggests difficulty with certain types of information extraction
  - Frequent summarization failures indicate the need for better document preprocessing or alternative approaches

- First 3 experiments:
  1. Test baseline accuracy without summarization on short privacy policies to establish upper performance bounds
  2. Implement and test the summarization algorithm on progressively longer documents to find the optimal summarization depth
  3. Conduct ablation studies on prompt formatting to determine which elements most significantly impact answer quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do some questions consistently perform worse than others across all models?
- Basis in paper: explicit
- Why unresolved: The paper notes that question 10 has the lowest performance (15-25% accuracy) but does not investigate the underlying reasons for this variance.
- What evidence would resolve it: A detailed analysis of question difficulty, including linguistic complexity, ambiguity in ground truth answers, and whether certain question types inherently require more context than others.

### Open Question 2
- Question: Does the performance drop when requesting line numbers indicate a fundamental limitation in current LLMs for document analysis?
- Basis in paper: explicit
- Why unresolved: The paper observes that accuracy drops from 44.2% to 38.1% when Mixtral is asked to also provide the specific line containing the answer, but doesn't explore whether this is due to task complexity or model architecture limitations.
- What evidence would resolve it: Systematic testing of whether this performance drop occurs with other document types, or if specialized fine-tuning for document grounding could mitigate this issue.

### Open Question 3
- Question: Can the summarization procedure be optimized to improve accuracy for longer documents?
- Basis in paper: inferred
- Why unresolved: The paper uses a heuristic summarization approach but doesn't explore whether alternative summarization strategies (different split sizes, summarization models, or progressive summarization) could improve accuracy.
- What evidence would resolve it: Comparative experiments testing multiple summarization approaches and their impact on final question-answering accuracy.

## Limitations

- Current LLM performance (best at 53.3% accuracy) is insufficient for practical deployment in detecting unfair privacy terms
- Variability in question-specific performance (ranging from 15% to 71% accuracy) suggests fundamental limitations in models' ability to consistently extract and interpret legal information
- The lack of explanation for why certain questions are consistently harder to answer represents a significant gap in understanding models' failure modes

## Confidence

- High confidence: LLMs can outperform random guessing on privacy policy question answering tasks
- Medium confidence: Commercial models (ChatGPT-4) outperform open-source alternatives on this task
- Medium confidence: Question difficulty varies significantly and affects model performance
- Low confidence: The specific reasons for performance variance across different question types

## Next Checks

1. Conduct error analysis on incorrectly answered questions to identify whether failures stem from summarization information loss, prompt formatting issues, or fundamental limitations in legal text understanding
2. Test the same models on privacy policies from a different set of websites to verify whether performance is consistent across different domains and writing styles
3. Implement and evaluate alternative approaches to handling long documents (such as hierarchical processing or chunking strategies) to determine if summarization is the optimal solution for token limit constraints