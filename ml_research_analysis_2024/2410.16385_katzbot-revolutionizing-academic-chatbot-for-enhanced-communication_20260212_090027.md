---
ver: rpa2
title: 'KatzBot: Revolutionizing Academic Chatbot for Enhanced Communication'
arxiv_id: '2410.16385'
source_url: https://arxiv.org/abs/2410.16385
tags:
- katzgpt
- data
- language
- chatbot
- academic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces KatzBot, a university chatbot powered by\
  \ KatzGPT, a custom large language model fine-tuned on domain-specific academic\
  \ data. The authors collected and curated two datasets\u20146,280 sentence-completion\
  \ pairs and 7,330 question-answer pairs\u2014from university sources, then fine-tuned\
  \ leading LLMs (Mistral Instruct, Llama 2, GPT-2, Microsoft Phi 1.5) using Parameter-efficient\
  \ Fine-tuning (PEFT) and Quantized Low-Rank Adaptation (QLoRA)."
---

# KatzBot: Revolutionizing Academic Chatbot for Enhanced Communication

## Quick Facts
- **arXiv ID**: 2410.16385
- **Source URL**: https://arxiv.org/abs/2410.16385
- **Reference count**: 40
- **Primary result**: University chatbot powered by custom LLM KatzGPT, achieving Rouge-1: 0.53, Rouge-2: 0.43, and Rouge-L: 0.51

## Executive Summary
KatzBot is a university chatbot that leverages KatzGPT, a custom large language model fine-tuned on domain-specific academic data. The system integrates Retrieval Augmented Generation (RAG) for enhanced accuracy and supports voice and bilingual (Chinese-English) interactions. The authors collected and curated two datasets from university sources and fine-tuned leading LLMs using Parameter-efficient Fine-tuning (PEFT) and Quantized Low-Rank Adaptation (QLoRA). The chatbot interface is publicly available, offering a user-friendly solution for university-related queries.

## Method Summary
The authors collected two datasets: 6,280 sentence-completion pairs and 7,330 question-answer pairs from university sources. They fine-tuned multiple LLMs (Mistral Instruct, Llama 2, GPT-2, Microsoft Phi 1.5) using PEFT and QLoRA techniques. KatzBot incorporates RAG for enhanced accuracy and supports voice and bilingual interactions. The system was evaluated using Rouge scores, with an ablation study confirming 12 transformer blocks as optimal for performance.

## Key Results
- KatzGPT achieved Rouge-1: 0.53, Rouge-2: 0.43, and Rouge-L: 0.51
- Ablation study confirmed 12 transformer blocks as optimal configuration
- Publicly available chatbot interface with voice and bilingual support

## Why This Works (Mechanism)
The system works by combining a custom fine-tuned LLM with RAG to provide accurate university-specific responses. The fine-tuning process adapts general-purpose LLMs to academic domain knowledge using curated university datasets, while RAG enables the system to retrieve relevant information from external sources when needed.

## Foundational Learning
- **Fine-tuning LLMs**: Adapting pre-trained models to specific domains by continuing training on relevant data
  - *Why needed*: General LLMs lack specialized knowledge about university operations and policies
  - *Quick check*: Verify fine-tuning dataset quality and domain relevance

- **Parameter-efficient Fine-tuning (PEFT)**: Training only a subset of model parameters while keeping most frozen
  - *Why needed*: Reduces computational cost and memory requirements compared to full fine-tuning
  - *Quick check*: Confirm memory usage and training time improvements

- **Retrieval Augmented Generation (RAG)**: Combining retrieval systems with generation models to enhance response accuracy
  - *Why needed*: Ensures chatbot can access up-to-date information beyond its training data
  - *Quick check*: Test retrieval accuracy and relevance to queries

- **Rouge scores**: Evaluation metric measuring n-gram overlap between generated and reference text
  - *Why needed*: Provides quantitative measure of generation quality
  - *Quick check*: Compare against alternative evaluation metrics

## Architecture Onboarding

**Component Map**: Data Collection -> Dataset Curation -> Model Fine-tuning -> RAG Integration -> Chatbot Interface

**Critical Path**: University data sources → Curated datasets → Fine-tuned KatzGPT → RAG-enhanced responses → User interface

**Design Tradeoffs**: 
- Custom fine-tuning vs. prompt engineering trade-off for domain adaptation
- Model size vs. response time for real-time interaction
- Dataset size vs. training cost and time

**Failure Signatures**: 
- Poor responses to novel queries not covered in training data
- Hallucinations when RAG fails to retrieve relevant information
- Latency issues during voice interactions

**First Experiments**: 
1. Test chatbot with university-specific queries not in training data
2. Evaluate response accuracy with and without RAG component
3. Measure response time for voice vs. text interactions

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies solely on Rouge scores, lacking human evaluation or task-specific benchmarks
- Dataset collection process lacks transparency regarding quality controls and potential biases
- No comparative analysis with existing academic chatbots or evidence of novel technical contributions

## Confidence
- **High**: Technical implementation details (fine-tuning approach, RAG integration, interface availability)
- **Medium**: Claim that KatzGPT "outperforms" other models (based only on Rouge scores)
- **Low**: Claim that this represents a "revolutionizing" advancement (lacks comparative analysis and evidence of novel contributions)

## Next Checks
1. Conduct human evaluation studies with actual university users to assess response quality, helpfulness, and accuracy beyond Rouge metrics
2. Perform a comparative study against existing academic chatbots using both automated metrics and human evaluation
3. Release the curated datasets and evaluation scripts to enable independent verification of results and replication studies