---
ver: rpa2
title: Knowledge-Aware Multi-Intent Contrastive Learning for Multi-Behavior Recommendation
arxiv_id: '2404.11993'
source_url: https://arxiv.org/abs/2404.11993
tags:
- graph
- knowledge
- user
- behaviors
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of multi-behavior recommendation,
  where users interact with items through various behaviors (e.g., view, add to cart,
  purchase). The key insight is that these behaviors are driven by distinct user intents,
  which are often overlooked in existing methods.
---

# Knowledge-Aware Multi-Intent Contrastive Learning for Multi-Behavior Recommendation

## Quick Facts
- arXiv ID: 2404.11993
- Source URL: https://arxiv.org/abs/2404.11993
- Authors: Shunpan Liang; Junjie Zhao; Chen Li; Yu Lei
- Reference count: 40
- Primary result: Achieves 12.15% and 17.19% average lifts on HR and NDCG over state-of-the-art methods

## Executive Summary
This paper addresses multi-behavior recommendation by proposing Knowledge-Aware Multi-Intent Contrastive Learning (KAMCL). The method leverages knowledge graphs to construct user intents from item relationships and attributes, then applies two contrastive learning schemes to address data sparsity and balance behavior differences. KAMCL segments knowledge graphs by relations, propagates information through GNNs, generates intent representations via attention mechanisms, and optimizes using both relation-aware and behavior-aware contrastive losses. Experiments on Movielens, Yelp, and Tmall datasets demonstrate significant performance improvements over existing methods.

## Method Summary
KAMCL integrates knowledge graphs with multi-behavior recommendation through a two-stage contrastive learning framework. First, it segments the knowledge graph by relations and uses GNNs to generate relation-specific item embeddings, which are then fused and optimized via contrastive learning to address sparsity. Second, it generates user intent embeddings through attention over relation-based intents, computes behavior-specific user representations through interaction graph propagation, and applies contrastive learning to balance differences between behaviors. The model is trained end-to-end with BPR loss optimization and evaluated using HR@K and NDCG@K metrics.

## Key Results
- Achieves average lifts of 12.15% and 17.19% on HR and NDCG respectively compared to state-of-the-art methods
- Shows consistent performance improvements across three real-world datasets (Movielens, Yelp, Tmall)
- Ablation studies confirm effectiveness of both knowledge graph components and contrastive learning schemes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Relation-aware knowledge graph segmentation and propagation captures richer item representations than flat knowledge graph integration
- Mechanism: The knowledge graph is partitioned by relations into sub-graphs, each focusing on one perspective of the item. Graph neural networks propagate messages within each sub-graph, generating relation-specific embeddings. These embeddings are then fused via a learnable function, producing a more nuanced item representation
- Core assumption: Item attributes and relationships from different knowledge graph relations contribute distinct, complementary information to item representation
- Evidence anchors: [abstract] "KAMCL incorporates a relation-aware knowledge aggregation module to capture information about the attributes of an item from different relations" and [section] "we meticulously partition the knowledge graph based on relation information...each sub-graph focuses on information from only one perspective (e.g., Brand) of the item"
- Break condition: If knowledge graph relations are redundant or uninformative, relation-aware segmentation provides no benefit over flat integration

### Mechanism 2
- Claim: Contrastive learning on knowledge sub-graph embeddings addresses data sparsity in item representations
- Mechanism: Item embeddings from different relation sub-graphs are treated as positive samples, while embeddings from different items are treated as negatives. InfoNCE loss optimizes similarity between these pairs, effectively imputing missing neighbor information and enriching item representations
- Core assumption: Item embeddings from different knowledge sub-graphs of the same item are semantically similar, and contrastive learning can leverage this to overcome sparsity
- Evidence anchors: [abstract] "We propose a contrastive learning scheme to augment item representation" and [section] "Due to differences in the information regarding item characteristics obtained from each knowledge sub-graph, we treat the item embedding acquired from different knowledge sub-graphs as a positive sample"
- Break condition: If relation sub-graphs are too sparse or uncorrelated, contrastive learning may amplify noise rather than improve representations

### Mechanism 3
- Claim: Intent-based multi-behavior interaction balances differences between behaviors and captures behavior-specific user intents
- Mechanism: User intent embeddings are generated by attending over relation-based intent embeddings. User behavior embeddings are computed by aggregating item embeddings from the interaction graph and combining with intent embeddings. An attention layer fuses behavior-specific embeddings into a final user representation. Contrastive learning on behavior embeddings balances behavior differences
- Core assumption: Users have distinct intents under different behaviors, and these intents can be modeled via attention over relation-based intents
- Evidence anchors: [abstract] "KAMCL uses relationships in the knowledge graph to construct intents...to mine the connections between users' multi-behaviors from the perspective of intents" and [section] "User interactions with items under different behaviors are motivated by distinct intentions...we employ the attention mechanism approach"
- Break condition: If user intents do not vary meaningfully across behaviors, the intent-based modeling and behavior contrastive learning add unnecessary complexity

## Foundational Learning

- Concept: Knowledge graph embedding and relation modeling (e.g., TransE, TransR)
  - Why needed here: KAMCL leverages knowledge graph relations to construct intents and enrich item representations. Understanding how entities and relations are embedded is foundational to grasping the model's knowledge integration
  - Quick check question: How does TransE represent a triple (h, r, t) in vector space?

- Concept: Graph neural networks (GNNs) and message passing
  - Why needed here: KAMCL uses GNNs to propagate information within knowledge sub-graphs and user-item interaction graphs. Understanding GNN propagation and aggregation is essential for understanding how information flows in the model
  - Quick check question: What is the key operation in GNN message passing?

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: KAMCL employs two contrastive learning schemes to address data sparsity and balance behavior differences. Understanding how contrastive learning works and how InfoNCE loss is calculated is crucial for understanding the model's optimization
  - Quick check question: How does InfoNCE loss encourage similarity between positive pairs and dissimilarity between negative pairs?

## Architecture Onboarding

- Component map: User-item multi-behavior interaction graph + Knowledge graph -> Relation-aware Knowledge Graph Aggregation -> Intent Generation -> Intent-based User Multi-behavior Interaction -> Model Prediction -> Loss Optimization

- Critical path:
  1. Input: User-item interaction graph, Knowledge graph
  2. Relation-aware Knowledge Graph Aggregation: Generate item embeddings
  3. Intent Generation: Generate intent embeddings
  4. Intent-based User Multi-behavior Interaction: Generate user embeddings
  5. Model Prediction: Compute user-item scores
  6. Loss Optimization: Optimize model parameters

- Design tradeoffs:
  - Relation-aware vs. Flat knowledge graph integration: Relation-aware provides richer representations but adds complexity
  - Number of aggregation layers (L): More layers capture more information but risk overfitting
  - Number of intents (|P|): More intents capture more nuance but increase computational cost and risk redundancy

- Failure signatures:
  - Poor performance on sparse datasets: Indicates contrastive learning or knowledge graph integration is not effective
  - Overfitting: Indicates too many layers or intents, or insufficient regularization
  - Unstable training: Indicates issues with contrastive learning scheme or hyperparameter settings

- First 3 experiments:
  1. Validate relation-aware knowledge graph aggregation: Compare item embeddings from relation-aware aggregation vs. flat integration on a downstream task (e.g., link prediction)
  2. Validate intent generation: Visualize or analyze generated intent embeddings to ensure they capture meaningful user preferences
  3. Validate contrastive learning schemes: Analyze the impact of removing each contrastive learning scheme on model performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of KAMCL vary with different knowledge graph sparsity levels across datasets?
- Basis in paper: [inferred] The paper mentions that KAMCL outperforms baselines, particularly on the sparse Tmall dataset, suggesting knowledge graph effectiveness in sparse data scenarios
- Why unresolved: The paper does not provide detailed ablation studies isolating knowledge graph sparsity as a variable
- What evidence would resolve it: Controlled experiments varying knowledge graph density on multiple datasets, measuring HR and NDCG for KAMCL vs. variants without knowledge graph components

### Open Question 2
- Question: What is the optimal number of intents (|P|) for different multi-behavior recommendation scenarios, and how does it interact with behavior type diversity?
- Basis in paper: [explicit] The paper conducts intent number experiments but notes significant impact on Yelp and Tmall, minimal on Movielens due to knowledge graph sparsity
- Why unresolved: The study only tests four fixed intent values; optimal configuration likely depends on behavior diversity and dataset characteristics
- What evidence would resolve it: Systematic testing across datasets with varying behavior types, analyzing intent performance curves to identify optimal |P| ranges

### Open Question 3
- Question: How do the two contrastive learning schemes (relation-aware and behavior-aware) contribute differently to KAMCL's performance across diverse recommendation contexts?
- Basis in paper: [explicit] The paper mentions two contrastive learning schemes but only reports combined performance; ablation study removes both together (w/o-CL)
- Why unresolved: No individual ablation analysis of each contrastive learning component's contribution
- What evidence would resolve it: Separate ablation experiments for each contrastive learning scheme across multiple datasets, comparing performance degradation patterns

## Limitations
- The knowledge graph segmentation approach relies heavily on the quality and informativeness of relation types, which may vary significantly across datasets
- The contrastive learning schemes assume that embeddings from different knowledge sub-graphs are semantically similar, which may not hold for all relation types
- The intent generation mechanism through attention over relation embeddings may not capture all nuances of user behavior across different contexts

## Confidence
- High Confidence: The relation-aware knowledge graph aggregation mechanism and its implementation details are clearly specified and well-justified
- Medium Confidence: The contrastive learning approaches for both items and behaviors are theoretically sound but may be sensitive to hyperparameter choices
- Low Confidence: The claim about intent-based behavior balancing lacks detailed validation beyond performance metrics

## Next Checks
1. **Ablation study on knowledge graph quality**: Systematically vary the completeness and relevance of knowledge graph relations to assess their impact on model performance
2. **Behavior intent analysis**: Conduct qualitative analysis of generated intent embeddings to verify they capture meaningful differences between behaviors
3. **Cross-dataset generalization test**: Evaluate the model on datasets with different knowledge graph structures to assess robustness of the relation-aware approach