---
ver: rpa2
title: New Method for Keyword Extraction for Patent Claims
arxiv_id: '2407.07923'
source_url: https://arxiv.org/abs/2407.07923
tags:
- patent
- search
- relevant
- page
- claims
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a new keyword extraction method for patent
  claims based on the structural way information is presented in claims, using a "specialization
  tree" to identify and score meaningful words. The method outperformed the existing
  baseline "More Like This" algorithm significantly in prior art search tasks, achieving
  37% improvement in PRES@10, 45% in PRES@100, and 36% in PRES@1000 when searching
  "from claims to claims." The approach leveraged the hierarchical structure of claims
  to extract keywords more effectively, and while the performance gap was notable,
  further improvements were expected to come from interactive search and technologically
  assisted review rather than keyword extraction alone.
---

# New Method for Keyword Extraction for Patent Claims

## Quick Facts
- arXiv ID: 2407.07923
- Source URL: https://arxiv.org/abs/2407.07923
- Reference count: 0
- This study developed a new keyword extraction method for patent claims based on the structural way information is presented in claims, using a "specialization tree" to identify and score meaningful words.

## Executive Summary
This study introduces a novel keyword extraction method for patent claims that exploits the hierarchical structure of claim language. The method constructs "specialization trees" from dependency parsing of claims, scoring words based on their depth in both the tree and claim hierarchy. When tested on CLEF-IP 2011 data using a "from claims to claims" search task, the method achieved significant improvements over the baseline MLT algorithm, with 37% improvement in PRES@10, 45% in PRES@100, and 36% in PRES@1000. The approach leverages the consistent "split-and-detail" pattern found in patent claims to extract more meaningful keywords for prior art search.

## Method Summary
The method builds specialization trees from patent claims by parsing sentences into fragments where each fragment specializes the previous one. Words are scored based on their depth in these trees and their position in the claim hierarchy, with deeper words receiving higher scores as they represent more specific technical details. The algorithm uses Stanford CoreNLP for initial parsing, corrects POS tagging for patent-specific language (particularly the word "said"), then rebuilds trees and scores words. The top 100 keywords are extracted for each patent and used to construct search queries against a claims-only corpus, with performance evaluated against the EPO's Lucene-based MLT baseline system.

## Key Results
- Achieved 37% improvement in PRES@10 when searching "from claims to claims"
- Achieved 45% improvement in PRES@100 and 36% in PRES@1000
- Showed consistent performance improvements across multiple metrics with statistical significance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The specialization tree structure captures the hierarchical detail progression inherent in patent claims, enabling better keyword extraction.
- Mechanism: Patent claims are written with a "split-and-detail" structure where each sentence fragment specializes the previous one. The algorithm builds a tree where each node represents a specialization relationship, with depth indicating how far down the detail chain a word appears. Words appearing deeper in the tree are scored higher as they represent more specific technical details.
- Core assumption: The "split-and-detail" construction pattern is consistent and dominant in patent claim writing across different technical domains.
- Evidence anchors:
  - [section] "The claims provide details about the invention, each sentence fragment providing details about its previous sentence fragment. We will base our keyword extraction on this specific feature"
  - [abstract] "This study developed a new keyword extraction method for patent claims based on the structural way information is presented in claims, using a 'specialization tree' to identify and score meaningful words"
- Break condition: If patent claims evolve to use different structural patterns (e.g., more narrative or less hierarchical writing), the specialization tree would fail to capture meaningful relationships.

### Mechanism 2
- Claim: The scoring function favors words that appear both deep in the specialization tree and deep in the claim hierarchy.
- Mechanism: The algorithm assigns scores based on node depth (how detailed the specialization is) and claim depth (how specific the claim is within the overall claim set). The scoring formula weights these factors to identify words that represent significant technical details.
- Core assumption: Words appearing at greater depths in both dimensions are more likely to be meaningful technical terms rather than generic language.
- Evidence anchors:
  - [section] "The main idea is to favour the words that appear deep in a specialization tree, and also deep in the claim tree"
  - [abstract] "using a 'specialization tree' to identify and score meaningful words"
- Break condition: If certain domains use shallower claim structures or if the relationship between depth and importance doesn't hold uniformly across technical fields.

### Mechanism 3
- Claim: POS tagging correction for the word "said" prevents misclassification that would disrupt the parsing and tree-building process.
- Mechanism: Standard NLP tools misclassify "said" (which functions as a relative adjective in patent claims) as a verb. The algorithm uses a Support Vector Classifier trained on patent-specific data to correct this, ensuring proper parsing and tree construction.
- Core assumption: The incorrect classification of "said" as a verb is frequent enough to materially impact parsing quality and subsequent keyword extraction.
- Evidence anchors:
  - [section] "Claims have their own idiom, the most famous one being the use of the word 'said', which is almost always a relative adjective, as opposed to a conjugation of 'to say'. NLP tools that were trained on generic literature will likely misclassify 'said' as a verb"
  - [section] "We implemented and trained a Support Vector Classifier, based on annotated fragments of claim, with the proper POS-tagging for words that were tagged as VERB by the initial POS-tagging"
- Break condition: If patent language evolves away from using "said" in this way, or if parsing accuracy improves through other means, the correction may become unnecessary.

## Foundational Learning

- Concept: Specialization tree construction from dependency parsing
  - Why needed here: The algorithm relies on correctly identifying specialization relationships between sentence fragments to build the tree structure used for scoring
  - Quick check question: How does the algorithm determine which words in a sentence fragment are "specializing" others?

- Concept: TF-IDF and keyword extraction principles
  - Why needed here: Understanding the baseline comparison with statistical keyword extraction methods helps contextualize the performance improvements
  - Quick check question: What are the limitations of pure frequency-based keyword extraction that the specialization approach addresses?

- Concept: Patent claim structure and terminology
  - Why needed here: The algorithm exploits specific structural features of patent claims that differ from general text
  - Quick check question: What makes patent claim language different from standard technical writing in terms of structure and vocabulary?

## Architecture Onboarding

- Component map:
  Stanford CoreNLP server -> POS tagging correction -> Re-parsing -> Specialization tree builder -> Scoring engine -> Keyword extraction -> Search integration layer

- Critical path: Claim text → Stanford CoreNLP parsing → POS correction → Re-parsing → Tree building → Scoring → Keyword extraction → Search query

- Design tradeoffs:
  - Depth vs. breadth in tree construction: Deeper trees capture more detail but increase computational complexity
  - Number of keywords: More keywords improve recall but may introduce noise
  - POS correction vs. computational overhead: Correction improves accuracy but adds processing time

- Failure signatures:
  - Poor performance on domains with non-standard claim structures
  - Degradation when claims use less hierarchical writing patterns
  - Issues with very long sentences that exceed parser memory limits
  - Reduced effectiveness when "said" usage patterns change

- First 3 experiments:
  1. Run the algorithm on a small set of claims (10-20) and manually verify the specialization tree structure and keyword rankings
  2. Compare keyword extraction results with and without POS tagging correction on claims containing "said"
  3. Test the algorithm on claims from different CPC domains to identify performance variations

## Open Questions the Paper Calls Out

- Question: How does the specialization tree method perform on patent claims in languages other than English, such as French and German?
  - Basis in paper: [explicit] The paper mentions that the method needs to be tested on French and German patent claims to evaluate its performance in those languages.
  - Why unresolved: The current study only tested the method on English patent claims. The authors acknowledge the need to extend the method to other languages used by the EPO.
  - What evidence would resolve it: Testing the specialization tree method on a dataset of French and German patent claims and comparing its performance to the baseline MLT algorithm in terms of PRES@100 and Recall@100 metrics.

- Question: Can the keyword extraction method be further improved by incorporating semantic information, such as synonyms and hyponyms, into the scoring algorithm?
  - Basis in paper: [inferred] The paper discusses the potential of semantic-based methods that use synonyms and hyponyms to expand the query, but notes that these methods did not significantly improve performance in previous studies. However, the specialization tree method focuses on the structure of claims, so incorporating semantic information could potentially enhance its performance.
  - Why unresolved: The current method relies solely on the structural analysis of claims and does not incorporate semantic information. It is unclear whether adding semantic information would improve the method's performance.
  - What evidence would resolve it: Implementing a modified version of the specialization tree method that incorporates semantic information into the scoring algorithm and comparing its performance to the original method on a dataset of patent claims.

- Question: How does the specialization tree method perform in different patent domains, and are there domain-specific variations in the method's effectiveness?
  - Basis in paper: [explicit] The paper mentions that the performance of the method varies across different patent domains, with domain C showing the best results and domains G and H showing the worst results.
  - Why unresolved: The current study does not provide a detailed analysis of the method's performance in different patent domains or explore potential domain-specific variations in the method's effectiveness.
  - What evidence would resolve it: Conducting a comprehensive analysis of the method's performance across all patent domains and identifying any domain-specific variations in its effectiveness. This could involve developing domain-specific versions of the method or adjusting the scoring algorithm based on the characteristics of each domain.

## Limitations

- The evaluation is limited to English patent claims from the CLEF-IP 2011 dataset, which may not generalize to other languages or claim structures.
- The study compares only against a single baseline system (EPO's Lucene-based MLT), leaving performance on other search scenarios and competitive methods untested.
- The keyword extraction method's effectiveness may diminish when applied to very short or unusually structured claims that don't follow the typical hierarchical pattern.

## Confidence

- **High confidence**: The specialization tree approach effectively exploits patent claim structure to improve keyword extraction for prior art search, as evidenced by consistent performance improvements across multiple metrics (PRES@10, PRES@100, PRES@1000) and statistical significance.
- **Medium confidence**: The specific performance gains (37-45% improvement) are reliable for the tested dataset and search task, but may vary across different patent domains or claim types.
- **Medium confidence**: The claim that further improvements will come primarily from interactive search and TAR rather than keyword extraction alone is plausible but requires additional validation through user studies.

## Next Checks

1. **Cross-domain validation**: Test the keyword extraction method on patent claims from different CPC classification codes to verify consistent performance across technical domains, particularly for non-mechanical/engineering fields.

2. **Baseline expansion**: Compare the specialization tree method against modern neural keyword extraction approaches and transformer-based retrieval systems to establish its relative effectiveness in current patent search contexts.

3. **Error analysis**: Conduct systematic analysis of search failures where the method underperforms to identify specific claim patterns or technical domains where the specialization tree approach breaks down, informing targeted improvements.