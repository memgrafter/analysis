---
ver: rpa2
title: Synthetic Counterfactual Faces
arxiv_id: '2407.13922'
source_url: https://arxiv.org/abs/2407.13922
tags:
- faces
- face
- attribute
- transformed
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a generative AI-based pipeline for constructing
  targeted, counterfactual, high-quality synthetic face data. The method addresses
  the challenge of collecting diverse, annotated face data for evaluating computer
  vision system robustness and fairness.
---

# Synthetic Counterfactual Faces

## Quick Facts
- arXiv ID: 2407.13922
- Source URL: https://arxiv.org/abs/2407.13922
- Reference count: 40
- Key outcome: 75.09% human alignment in synthetic counterfactual face generation pipeline validated through user studies

## Executive Summary
This work introduces a generative AI-based pipeline for constructing targeted, counterfactual, high-quality synthetic face data to evaluate computer vision system robustness and fairness. The method addresses the challenge of collecting diverse, annotated face data by generating 15k synthetic face images across 8 demographic groups and 19 semantic attributes. The pipeline combines a text-to-image diffusion model with distortion and attribute detectors to ensure valid counterfactuals. The efficacy is validated through user studies, and utility is demonstrated by evaluating Instagram's commercial vision model, revealing performance disparities across demographics and attributes.

## Method Summary
The pipeline generates synthetic counterfactual face data by first creating source faces using Stable Diffusion with demographic-specific prompts, then applying semantic attributes through SEGA latent manipulation, and finally filtering with distortion and attribute detectors. The process uses 100 celebrity names per demographic (8 groups), 19 binary facial attributes, and a strict two-stage filtering process to retain only valid counterfactuals. The generated dataset enables comprehensive assessment of face recognition systems' sensitivity to demographic and semantic shifts.

## Key Results
- Pipeline generates 15k synthetic faces from 91.2k candidates using two-stage filtering
- Achieved 75.09% human alignment in user studies validating generated counterfactuals
- Revealed performance disparities in Instagram's commercial vision model across demographics and attributes
- Filtering process uses 97% distortion detector recall threshold and attribute detectors for validation

## Why This Works (Mechanism)

### Mechanism 1
The synthetic pipeline generates valid counterfactual face images by combining diffusion-based generation with attribute detectors to filter out invalid samples. The pipeline first generates source faces using Stable Diffusion with demographic-specific prompts. Then, semantic attributes are applied using SEGA latent manipulation. Finally, attribute detectors validate that only the intended attribute changes while preserving identity.

### Mechanism 2
The pipeline achieves high human alignment (75.09%) by using a strict two-stage filtering process with both distortion detection and attribute validation. First, a distortion detector removes images with unnatural facial artifacts. Second, attribute detectors verify that only the target attribute (and any coinciding/contradicting attributes) change while maintaining identity.

### Mechanism 3
The generated dataset reveals performance disparities in commercial vision models by providing controlled counterfactual examples across demographics and attributes. By systematically varying attributes like glasses, makeup, and facial hair across different demographic groups, the pipeline creates test cases that expose how commercial models respond to these changes.

## Foundational Learning

- **Diffusion models for image generation**: The pipeline relies on Stable Diffusion to generate realistic synthetic face images that can be manipulated for counterfactual analysis. *Quick check*: What distinguishes diffusion models from GANs in terms of image quality and diversity?

- **Counterfactual examples in machine learning**: The paper's core contribution is generating counterfactual face images to evaluate model fairness and robustness. *Quick check*: What are the three requirements for counterfactual examples according to the paper?

- **Vision-language models (VLMs) for attribute detection**: GPT-4o is used to validate that the correct attributes are applied to generated faces. *Quick check*: How does the paper use GPT-4o differently from traditional attribute classifiers?

## Architecture Onboarding

- **Component map**: Text-to-Image Diffusion (Stable Diffusion) → Latent Manipulation (SEGA) → Distortion Detector → Attribute Detectors (GPT-4o + age estimator) → Filtered Dataset
- **Critical path**: The transformation from source face to validated counterfactual face requires all components to function correctly; failure at any stage eliminates the sample
- **Design tradeoffs**: The pipeline prioritizes quality over quantity, achieving 75.09% human alignment but generating only 15k images from 91.2k candidates
- **Failure signatures**: Low efficacy indicates either the diffusion model cannot generate realistic faces, SEGA cannot apply clean edits, or detectors cannot validate attributes accurately
- **First 3 experiments**:
  1. Generate 100 source faces across all 8 demographics and verify they appear realistic and identity-preserving
  2. Apply one attribute (e.g., glasses) to 10 faces per demographic and measure distortion detector recall
  3. Run the complete pipeline on a small subset (100 faces) and measure human alignment percentage

## Open Questions the Paper Calls Out

### Open Question 1
What is the precise impact of using different hyperparameters in SEGA for different demographic groups on the final generated face quality? The paper mentions that ideally different hyperparameters of SEGA have to be tuned for editing every face and attribute but due to scalability, they used the same hyperparameters for all source faces.

### Open Question 2
How does the inclusion of additional semantic attributes, such as pupil color or nose shape, affect the performance and utility of the counterfactual face generation pipeline? The paper mentions that the pipeline can be extended for other attributes like pupil color and nose shape, but does not explore this extension.

### Open Question 3
What are the potential biases introduced by using GPT-4o for attribute detection, and how can they be mitigated? The paper discusses the use of GPT-4o for attribute detection but does not address potential biases in its responses.

## Limitations

- The pipeline's efficacy heavily depends on GPT-4o's attribute detection performance, which has acknowledged limitations in face recognition and can hallucinate
- The attribute transition matrix contains 76% unspecified entries, limiting comprehensiveness for complex attribute interactions
- The assumption that attribute detectors can reliably verify all 19 semantic attributes across 8 demographic groups without bias remains untested

## Confidence

- **High Confidence**: The core mechanism of using diffusion models for face generation and the two-stage filtering process is well-established and validated through user studies achieving 75.09% human alignment
- **Medium Confidence**: The claim that the pipeline reveals performance disparities in commercial vision models is supported by the Instagram model evaluation, but generalizability to other commercial models remains untested
- **Low Confidence**: The assumption that attribute detectors can reliably verify all 19 semantic attributes across 8 demographic groups without bias or systematic errors, given GPT-4o's acknowledged limitations in face recognition tasks

## Next Checks

1. Conduct a comprehensive error analysis of the attribute detectors by comparing their outputs with human annotations across all 19 attributes and 8 demographics to quantify false positive and false negative rates

2. Test the pipeline's generalizability by evaluating additional commercial vision models (beyond Instagram's) to verify that the revealed performance disparities are consistent across different systems

3. Perform ablation studies by varying the filtering thresholds and examining how this affects the human alignment percentage and the quality of the generated counterfactuals, particularly for complex attribute interactions with high percentages of unspecified transition matrix entries