---
ver: rpa2
title: 'LAMP: A Language Model on the Map'
arxiv_id: '2403.09059'
source_url: https://arxiv.org/abs/2403.09059
tags:
- lamp
- user
- about
- queries
- geospatial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LAMP, a language model fine-tuned on city-specific
  geospatial data to enable accurate POI retrieval in conversational interactions.
  The proposed framework uses synthetic query generation and RAG to train the model
  on real POI information, addresses the hallucination problem by including queries
  from random positions, and achieves 86% truthfulness and 92% spatial awareness scores
  on POI-retrieval tasks in Singapore.
---

# LAMP: A Language Model on the Map

## Quick Facts
- arXiv ID: 2403.09059
- Source URL: https://arxiv.org/abs/2403.09059
- Reference count: 9
- Primary result: Language model fine-tuned on city-specific geospatial data achieves 86% truthfulness and 92% spatial awareness on POI-retrieval tasks in Singapore

## Executive Summary
This paper introduces LAMP, a language model fine-tuned on city-specific geospatial data to enable accurate POI retrieval in conversational interactions. The proposed framework uses synthetic query generation and RAG to train the model on real POI information, addresses the hallucination problem by including queries from random positions, and achieves 86% truthfulness and 92% spatial awareness scores on POI-retrieval tasks in Singapore. LAMP outperforms both open-source models and closed-source alternatives like ChatGPT in providing correct, nearby POI recommendations while maintaining conversational capabilities. The model successfully handles complex queries like day planning, demonstrating practical utility for real-world geospatial applications.

## Method Summary
LAMP fine-tunes LLaMa-2-7B-Chat using synthetic queries generated from random positions near POIs in Singapore. The training data is created by sampling positions within 150m of each POI and generating conversational queries from those locations. The model uses reverse geocoding to convert user positions to addresses, making input more suitable for the LLM. LoRA is employed during fine-tuning to reduce computational requirements, and random position queries with non-existent POIs are included to reduce hallucination. The model is evaluated on truthfulness, spatial awareness, and semantic relatedness by GIS experts.

## Key Results
- LAMP achieves 86% truthfulness score, outperforming baselines including ChatGPT
- LAMP demonstrates 92% spatial awareness, correctly identifying the closest POIs
- The model successfully handles complex day-planning queries while maintaining conversational capabilities

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning on synthetic queries generated near each POI forces the model to learn spatial proximity relationships. The training data is generated by sampling random positions within 150m of each POI and creating queries from those positions. The model learns to associate the user's position (converted to an address via reverse geocoding) with nearby POIs, effectively building a spatial map in its weights.

### Mechanism 2
Including random position queries with non-existent POIs reduces hallucination by teaching the model that nearby POIs aren't always available. The training corpus includes queries from random positions about random place names or categories. This teaches the model that when a nearby POI isn't available, it should retrieve a real POI further away rather than hallucinating a non-existent one.

### Mechanism 3
The reverse geocoding of user positions to addresses makes the input more suitable for the LLM, improving performance. User positions are converted to addresses using Nominatim (OSM reverse geocoding API) before being fed to the model. This provides more natural language input that the LLM can process better than raw coordinates.

## Foundational Learning

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: RAG is used to generate the synthetic training data by retrieving POI information to construct responses
  - Quick check question: What is the primary purpose of using RAG in this framework?

- Concept: Low-Rank Adaptation (LoRA)
  - Why needed here: LoRA is used during fine-tuning to reduce the number of trainable parameters and decrease GPU memory requirements
  - Quick check question: How does LoRA help with the computational requirements of fine-tuning large language models?

- Concept: Spatial awareness in language models
  - Why needed here: The model needs to understand spatial relationships between POIs and user positions to provide relevant recommendations
  - Quick check question: What key capability must the model develop to successfully retrieve nearby POIs?

## Architecture Onboarding

- Component map: User query → Reverse geocoding → Model inference → POI recommendation
- Critical path: User query → Reverse geocoding → Model inference → POI recommendation
- Design tradeoffs:
  - Using synthetic data vs. real user queries
  - Including random position queries to reduce hallucination
  - Tradeoff between model size and computational requirements
- Failure signatures:
  - High hallucination rate (truthfulness score low)
  - Poor spatial awareness (recommending distant POIs)
  - Generic or irrelevant responses (low semantic relatedness)
- First 3 experiments:
  1. Train LAMP-no-rq (without random position queries) and compare hallucination rate to LAMP
  2. Test different radii for random position sampling around POIs
  3. Evaluate the impact of reverse geocoding accuracy on model performance

## Open Questions the Paper Calls Out

### Open Question 1
How does LAMP's performance generalize to cities with different POI distributions and urban layouts compared to Singapore? The paper only evaluates LAMP on Singapore data and doesn't test its transferability to other cities with different POI densities, street layouts, or urban planning patterns.

### Open Question 2
What is the optimal radius for sampling random positions around POIs during synthetic query generation? The paper uses a fixed 150m radius without exploring how different radii affect model performance or whether the optimal radius varies by POI category or urban density.

### Open Question 3
How does the inclusion of queries from random positions (the "rq" component) affect LAMP's ability to handle requests for non-existent or distant POIs? While the paper shows LAMP outperforms LAMP-no-rq, it doesn't analyze how the "rq" training specifically impacts handling of edge cases like out-of-area requests or completely non-existent places.

## Limitations
- Evaluation relies on expert assessment by GIS professionals rather than automated metrics, introducing potential subjectivity
- The study focuses exclusively on Singapore's POI landscape, raising questions about generalizability to cities with different spatial layouts
- Synthetic data generation may not fully capture the diversity of real user queries, potentially limiting handling of edge cases

## Confidence

**High Confidence Claims:**
- LAMP demonstrates superior performance compared to baseline models on established POI retrieval tasks
- The synthetic query generation approach successfully produces training data that improves spatial awareness
- The inclusion of random position queries effectively reduces hallucination rates

**Medium Confidence Claims:**
- The 86% truthfulness and 92% spatial awareness scores accurately reflect real-world performance
- The model's day-planning capabilities translate to practical utility for users
- The LoRA fine-tuning approach is optimal for this application

**Low Confidence Claims:**
- Performance would remain consistent when deployed across different cities or regions
- The current training duration (78 hours) is optimal for convergence
- The 150m radius for random position sampling is universally optimal

## Next Checks

1. **Cross-city validation**: Evaluate LAMP's performance on POI retrieval tasks in a geographically and culturally distinct city (e.g., New York or Tokyo) to assess generalizability beyond Singapore's unique urban layout.

2. **A/B testing with real users**: Deploy LAMP alongside baseline models in a controlled user study to compare actual user satisfaction, task completion rates, and perceived relevance of POI recommendations.

3. **Error analysis on failure modes**: Systematically analyze cases where LAMP fails (low truthfulness or spatial awareness scores) to identify whether failures stem from data limitations, model architecture, or the inherent difficulty of certain POI retrieval scenarios.