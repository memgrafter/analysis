---
ver: rpa2
title: Mitigating Hallucinations of Large Language Models in Medical Information Extraction
  via Contrastive Decoding
arxiv_id: '2410.15702'
source_url: https://arxiv.org/abs/2410.15702
tags:
- medical
- llms
- decoding
- alcd
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses hallucinations in Large Language Models (LLMs)
  for Medical Information Extraction (MIE) tasks, where models may fabricate entities
  or make classification errors. The proposed ALternate Contrastive Decoding (ALCD)
  method decouples identification and classification abilities by masking token optimization
  during fine-tuning and alternately contrasting predictions during inference.
---

# Mitigating Hallucinations of Large Language Models in Medical Information Extraction via Contrastive Decoding

## Quick Facts
- arXiv ID: 2410.15702
- Source URL: https://arxiv.org/abs/2410.15702
- Reference count: 7
- Key outcome: ALCD significantly outperforms eight baseline decoding methods, achieving up to 4.87% improvement in micro F1 scores for medical information extraction tasks.

## Executive Summary
This paper addresses hallucinations in Large Language Models (LLMs) when applied to Medical Information Extraction (MIE) tasks, where models may fabricate entities or make classification errors. The proposed ALternate Contrastive Decoding (ALCD) method decouples identification and classification abilities by masking token optimization during fine-tuning and alternately contrasting predictions during inference. The approach uses adaptive constraints based on distribution similarities to enhance sub-model capabilities while minimizing interference. Experiments on six diverse medical datasets with two LLM backbones show ALCD significantly outperforms eight baseline decoding methods, achieving up to 4.87% improvement in micro F1 scores.

## Method Summary
ALCD works by first decoupling the identification and classification functions of LLMs during fine-tuning through selective token masking, creating specialized sub-models for each task. During inference, ALCD alternately contrasts output distributions from these sub-task models against the normal model, selectively enhancing either identification or classification ability while minimizing interference. The method employs adaptive constraints based on Jensen-Shannon Divergence to adjust the scale and scope of contrastive tokens, improving capability enhancement while avoiding false positives. This approach is implemented with LoRA for parameter-efficient fine-tuning on two LLM backbones across six medical datasets.

## Key Results
- ALCD achieves up to 4.87% improvement in micro F1 scores compared to baseline decoding methods
- The method shows particular effectiveness on datasets with more entity candidates and classification labels (CMeEE-V2, IMCS-V2-NER, CHIP-MDCFNPC)
- ALCD effectively reduces both identification and classification errors in medical information extraction tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ALCD decouples identification and classification abilities by masking token optimization during fine-tuning, preventing interference between the two functions.
- Mechanism: During training, tokens related to one subtask (e.g., classification) are masked when optimizing the other subtask (e.g., identification). This creates specialized sub-models that focus on specific capabilities.
- Core assumption: The joint next-word generation for identification and classification in standard LLMs compromises each other's performance, leading to hallucinations.
- Evidence anchors:
  - [abstract]: "We then separate the identification and classification functions of LLMs by selectively masking the optimization of tokens during fine-tuning."
  - [section 3.2.1]: "When fine-tuning the parameters of the identification model, classification tokens are masked to focus the model's attention solely on identification tokens, thereby ignoring its classification capability."
  - [corpus]: Weak evidence. The corpus contains papers on hallucination mitigation but none specifically validate this decoupling mechanism for MIE tasks.
- Break condition: If the masking strategy fails to create sufficiently distinct sub-models, or if the identified interference between identification and classification is not the primary source of hallucinations in MIE tasks.

### Mechanism 2
- Claim: ALCD alternately contrasts predictions from sub-task models during inference, selectively enhancing identification or classification while minimizing interference from other abilities.
- Mechanism: At each inference step, ALCD determines the next token type (identification, classification, or other) and applies contrastive decoding between the normal model and the relevant sub-model. This amplifies the desired capability while contrasting against the other.
- Core assumption: The normal LLM contains unwanted capabilities that interfere with MIE tasks, and contrasting against specialized sub-models can suppress these.
- Evidence anchors:
  - [abstract]: "During the inference stage, we alternately contrast output distributions derived from sub-task models."
  - [section 3.2.2]: "ALCD bolsters its classification/identification ability and contrasts logit predictions with another model. This contrastive decoding process alternates between classification and identification."
  - [corpus]: Moderate evidence. The corpus contains papers on contrastive decoding for hallucination mitigation, but none specifically validate this alternating approach for MIE tasks.
- Break condition: If the alternating contrast fails to consistently improve performance, or if the rule-based judgment for token type determination is inadequate.

### Mechanism 3
- Claim: ALCD uses adaptive constraints based on distribution similarities to adjust the scale and scope of contrastive tokens, improving sub-model capability enhancement while minimizing interference.
- Mechanism: Jensen-Shannon Divergence measures the distance between normal model and sub-model distributions to determine adaptive scales (did, dcl) for contrastive decoding. A scope constraint removes low-confidence tokens that might cause false positives.
- Core assumption: The degree of difference between normal and sub-model distributions indicates how much to rely on the sub-model's capability during contrast.
- Evidence anchors:
  - [abstract]: "Additionally, we propose an alternate adaptive constraint strategy to more effectively adjust the scale and scope of contrastive tokens."
  - [section 3.2.2]: "did and dcl are adaptive scales proposed to measure the distance between two logit distributions: one between Mnl and Mid, and the other between Mnl and Mcl."
  - [section 3.2.3]: "We implement a constraint that is contingent upon the confidence level: Vhead(y<t) = {v ∈ V : Pθ(v|i, x, y<t) ≥ β maxv Pθ(v|i, x, y<t)}."
  - [corpus]: Weak evidence. The corpus mentions contrastive decoding and hallucination mitigation but lacks specific validation of this adaptive constraint approach.
- Break condition: If the adaptive scaling fails to improve performance across different samples, or if the scope constraint removes too many true positive tokens.

## Foundational Learning

- Concept: Contrastive Decoding
  - Why needed here: ALCD builds upon contrastive decoding principles to address hallucinations in MIE tasks by contrasting specialized sub-models against the normal LLM.
  - Quick check question: How does contrastive decoding typically work in the context of LLMs, and what is its primary purpose?

- Concept: Token Masking During Fine-tuning
  - Why needed here: Understanding how token masking works is crucial for implementing the decoupling mechanism that separates identification and classification abilities.
  - Quick check question: What is the purpose of masking tokens during fine-tuning, and how does it affect the optimization process?

- Concept: Jensen-Shannon Divergence
  - Why needed here: JSD is used to calculate adaptive scales for contrastive decoding based on the similarity between normal and sub-model distributions.
  - Quick check question: How does Jensen-Shannon Divergence measure the similarity between two probability distributions, and why is it suitable for this application?

## Architecture Onboarding

- Component map:
  - Normal LLM (Mnl) -> Identification LLM (Mid) -> Classification LLM (Mcl) -> ALCD Controller -> Adaptive Constraint Module

- Critical path:
  1. Input text and instruction processed by all three LLMs
  2. ALCD Controller determines next token type (cls, ide, other)
  3. Appropriate contrastive decoding applied using adaptive scales
  4. Scope constraint removes low-confidence tokens
  5. Final logits used for next token prediction

- Design tradeoffs:
  - Increased fine-tuning and inference costs due to three models instead of one
  - Rule-based token type determination vs. learned approaches
  - Static vs. adaptive constraint parameters
  - Decoupling strength (masking ratio) vs. model performance

- Failure signatures:
  - Performance degradation when increasing decoupling steps (Figure 5)
  - Suboptimal results with extreme α values (>0.4) in contrastive scaling
  - Poor performance with β values <0.45 or >0.65 in scope constraints
  - Inconsistent improvements across different datasets and backbone models

- First 3 experiments:
  1. Validate decoupling effectiveness by training Mid and Mcl with varying fine-tuning steps and measuring performance on a validation set
  2. Test adaptive constraint parameters (α and β) on a small dataset to find optimal ranges
  3. Compare ALCD against baseline decoding methods (greedy, beam, top-k, nucleus, CFG, CAD, CD, DoLa) on one dataset to establish performance gains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of ALCD compare when applied to different types of medical tasks beyond information extraction, such as medical diagnosis or treatment recommendation?
- Basis in paper: [inferred] The paper states that ALCD has been validated on medical information extraction tasks and suggests future exploration of applying it to other medical tasks.
- Why unresolved: The paper only investigates the effectiveness of ALCD on medical information extraction tasks. There is no experimental evidence or theoretical analysis to support its potential effectiveness on other types of medical tasks.
- What evidence would resolve it: Conducting experiments to apply ALCD to different types of medical tasks, such as medical diagnosis or treatment recommendation, and comparing its performance with other methods or baseline models would provide evidence for its effectiveness on these tasks.

### Open Question 2
- Question: What is the impact of the number of entities and classification labels on the performance of ALCD compared to other decoding methods?
- Basis in paper: [explicit] The paper mentions that ALCD particularly performs well on datasets with more entity candidates and classification labels, such as CMeEE-V2, IMCS-V2-NER, and CHIP-MDCFNPC.
- Why unresolved: While the paper suggests that ALCD performs better on datasets with more entities and labels, it does not provide a detailed analysis of how the number of entities and labels affects the performance of ALCD compared to other decoding methods.
- What evidence would resolve it: Conducting experiments to systematically vary the number of entities and classification labels in the datasets and comparing the performance of ALCD with other decoding methods on these variations would provide insights into the impact of the number of entities and labels on ALCD's performance.

### Open Question 3
- Question: How does the choice of the hyper-parameter α in the contrastive decoding formula affect the performance of ALCD on different medical tasks?
- Basis in paper: [explicit] The paper mentions that the hyper-parameter α controls the scale of contrastive decoding and provides experimental results showing the effect of different α values on the performance of ALCD.
- Why unresolved: The paper only provides a limited analysis of the effect of α on the performance of ALCD. It does not explore the optimal range of α values for different medical tasks or provide a theoretical explanation for the observed effects.
- What evidence would resolve it: Conducting experiments to systematically vary the α value for different medical tasks and analyzing the relationship between α and the performance of ALCD would provide insights into the optimal choice of α for each task. Additionally, developing a theoretical model to explain the effect of α on ALCD's performance would enhance our understanding of the underlying mechanisms.

## Limitations
- The method's generalizability to non-medical domains remains untested, as it was only validated on medical information extraction tasks
- Performance appears sensitive to hyperparameter values (α and β), with optimal ranges that may not transfer well to different model sizes or domains
- The approach requires three models during both fine-tuning and inference, potentially limiting practical deployment in resource-constrained environments

## Confidence

**High Confidence (9/10)**: The core mechanism of decoupling identification and classification through token masking during fine-tuning is well-specified and theoretically sound. The performance improvements on the six medical datasets are clearly demonstrated with statistical significance.

**Medium Confidence (7/10)**: The adaptive constraint strategy using Jensen-Shannon Divergence and scope constraints shows promise, but the hyperparameter sensitivity and limited ablation studies leave some uncertainty about optimal configuration across different scenarios.

**Low Confidence (5/10)**: The generalizability of ALCD to non-medical domains and different model architectures remains untested, limiting confidence in the method's broader applicability beyond the demonstrated medical information extraction tasks.

## Next Checks

1. **Cross-Domain Validation**: Test ALCD on non-medical information extraction tasks (e.g., legal document analysis, financial reporting) to assess whether the decoupling and contrasting mechanisms generalize beyond medical contexts.

2. **Ablation Study on Adaptive Constraints**: Systematically evaluate the contribution of each component (JSD-based scaling, scope constraints, alternating mechanism) by removing them individually and measuring performance degradation on a representative medical dataset.

3. **Computational Efficiency Analysis**: Measure the actual inference time overhead of ALCD compared to standard decoding methods and evaluate whether the performance gains justify the increased computational costs in practical deployment scenarios.