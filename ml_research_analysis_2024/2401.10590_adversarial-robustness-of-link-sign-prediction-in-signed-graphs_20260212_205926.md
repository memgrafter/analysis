---
ver: rpa2
title: Adversarial Robustness of Link Sign Prediction in Signed Graphs
arxiv_id: '2401.10590'
source_url: https://arxiv.org/abs/2401.10590
tags:
- graph
- balance
- signed
- learning
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of signed graph neural networks
  (SGNNs) to adversarial attacks, specifically through a novel balance-attack method
  that exploits balance theory by reducing the graph's balance degree. The authors
  propose Balance Augmented-Signed Graph Contrastive Learning (BA-SGCL), which uses
  contrastive learning with balance augmentation to create robust node embeddings
  that maintain high balance degree in the latent space, thereby circumventing the
  "Irreversibility of Balance-related Information" challenge.
---

# Adversarial Robustness of Link Sign Prediction in Signed Graphs

## Quick Facts
- arXiv ID: 2401.10590
- Source URL: https://arxiv.org/abs/2401.10590
- Authors: Jialong Zhou; Xing Ai; Yuni Lai; Tomasz Michalak; Gaolei Li; Jianhua Li; Di Tang; Xingxing Zhang; Mengpei Yang; Kai Zhou
- Reference count: 40
- Primary result: BA-SGCL achieves up to 90.8% AUC and 0.73 Macro-F1 on clean graphs, and maintains 74.7% AUC and 0.57 Macro-F1 under 20% balance-attack perturbation on BitcoinAlpha

## Executive Summary
This paper addresses the vulnerability of signed graph neural networks (SGNNs) to adversarial attacks by proposing a novel defense framework called BA-SGCL. The authors identify that balance theory, while essential for modeling signed relationships in SGNNs, introduces exploitable vulnerabilities through a balance-attack method that reduces graph balance degree. BA-SGCL uses contrastive learning with balance augmentation to create robust node embeddings that maintain high balance degree in the latent space, effectively circumventing the "Irreversibility of Balance-related Information" challenge. Extensive experiments demonstrate that BA-SGCL significantly outperforms existing baselines, achieving robust performance even under substantial adversarial perturbations.

## Method Summary
BA-SGCL is a defense framework for signed graph neural networks that uses contrastive learning with balance augmentation to create robust node representations. The method employs a learnable augmenter that generates a high-balance positive view from a poisoned graph, while training an SDGCN encoder to maximize agreement between views. The model is trained using a combined loss function that includes contrastive loss, label loss, and balance loss, with the encoder parameters optimized using α×L_con + L_label and the augmenter's probability matrix trained using balance loss. The approach specifically targets the "Irreversibility of Balance-related Information" challenge by maintaining high balance degree in the latent space rather than attempting to recover the original clean graph.

## Key Results
- BA-SGCL achieves up to 90.8% AUC and 0.73 Macro-F1 on clean graphs across multiple datasets
- Under 20% balance-attack perturbation, BA-SGCL maintains 74.7% AUC and 0.57 Macro-F1 on BitcoinAlpha
- BA-SGCL outperforms all baseline SGNN models by significant margins, with improvements of 11.4% AUC and 0.09 Macro-F1 on BitcoinAlpha under attack
- The model shows consistent robustness across four real-world datasets: Bitcoin-Alpha, Bitcoin-OTC, Slashdot, and Epinions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Balance-Attack exploits SGNNs' reliance on balance theory by reducing graph balance degree, degrading the model's ability to learn from unbalanced triangles.
- Mechanism: Iteratively flips edge signs to minimize balance degree D3(G) using a greedy heuristic selecting edges with largest gradient magnitude.
- Core assumption: SGNNs perform poorly on graphs with low balance degree because they cannot effectively learn from unbalanced triangle structures.
- Evidence anchors:
  - [abstract] "Our investigation reveals that balance theory... inadvertently introduces exploitable vulnerabilities to black-box attacks."
  - [section V.A] "Prior research [11] has shown that SGNNs struggle to learn effective node representations from unbalanced triangles."
- Break condition: If SGNNs develop mechanisms to learn effectively from unbalanced structures, the attack would lose effectiveness.

### Mechanism 2
- Claim: BA-SGCL learns robust embeddings by maximizing mutual information between poisoned graph view and high-balance augmented view, circumventing the "Irreversibility of Balance-related Information" challenge.
- Mechanism: Uses contrastive learning with learnable augmenter that flips edge signs to create positive view with enhanced balance degree, while encoder maximizes agreement between views.
- Core assumption: Maintaining high balance degree in latent space through contrastive learning enables robust representations without recovering original clean graph.
- Evidence anchors:
  - [abstract] "By maintaining high balance degree in the latent space, BA-SGCL not only effectively circumvents the irreversibility challenge but also significantly enhances model resilience."
  - [section VI.B] "The primary challenge in defending SGNNs is the 'Irreversibility of Balance-related Information,' which makes directly recovering the original clean graph an ineffective strategy."
- Break condition: If contrast between positive and negative views cannot be maintained effectively, learning signal weakens.

### Mechanism 3
- Claim: Balance augmentation strategy is more effective than random augmentation because it specifically targets balance degree rather than random perturbations.
- Mechanism: Learnable augmenter optimizes probability matrix to determine edge sign flips that increase balance degree, creating structurally informative positive view.
- Core assumption: Positive view with high balance degree provides stronger learning signal than randomly perturbed view, leading to more robust embeddings.
- Evidence anchors:
  - [section VII.Proposition VII.2] "The contrastive loss L_con aims to maximize the MI between the two views, I(Z1;Z2)."
  - [section IX] "BA-SGCL consistently outperforms random-SGCL, demonstrating the effectiveness of our proposed balance augmentation strategy."
- Break condition: If balance augmentation becomes computationally intractable or balance degree cannot be effectively optimized.

## Foundational Learning

- Concept: Signed Graph Neural Networks (SGNNs) and Balance Theory
  - Why needed here: Understanding how SGNNs use balance theory is crucial for comprehending both attack mechanism and defense strategy.
  - Quick check question: How does balance theory define balanced vs unbalanced triangles in signed graphs?

- Concept: Contrastive Learning and Mutual Information Maximization
  - Why needed here: BA-SGCL relies on contrastive learning principles to create robust representations by maximizing mutual information between different graph views.
  - Quick check question: What is the relationship between contrastive loss and mutual information in the context of graph representation learning?

- Concept: Adversarial Attacks and Poisoning in Graph Neural Networks
  - Why needed here: The threat model and attack strategies form the foundation for understanding why robust defenses like BA-SGCL are necessary.
  - Quick check question: What distinguishes black-box attacks from white-box attacks in the context of graph neural networks?

## Architecture Onboarding

- Component map: Poisoned graph -> Balance augmentation -> Contrastive learning -> Robust embeddings -> Link sign prediction
- Critical path: Poisoned graph → Balance augmentation → Contrastive learning → Robust embeddings → Link sign prediction
- Design tradeoffs:
  - Computational cost vs. robustness: Balance augmentation adds complexity but provides significant robustness gains
  - Hyperparameter sensitivity: The α parameter balancing contrastive and label losses requires careful tuning
  - Model complexity vs. performance: BA-SGCL adds components but significantly outperforms baselines
- Failure signatures:
  - Poor performance on clean graphs: May indicate over-regularization or suboptimal hyperparameter settings
  - Degraded performance under attack: Could suggest balance augmentation is not effective for specific attack type
  - High variance in results: Might indicate sensitivity to random initialization or augmentation sampling
- First 3 experiments:
  1. Compare BA-SGCL performance on clean vs. poisoned graphs across different perturbation rates
  2. Evaluate effectiveness of balance augmentation by comparing with random augmentation
  3. Test BA-SGCL's performance against different attack types (balance-attack vs. FlipAttack)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can BA-SGCL maintain robustness when perturbation budget exceeds 20%, and what is the theoretical upper limit of its effectiveness?
- Basis in paper: [inferred] The paper tests up to 20% perturbation rates but doesn't explore higher values or establish theoretical limits.
- Why unresolved: Experimental evaluation stops at 20% perturbation, leaving open questions about scalability and robustness boundaries.
- What evidence would resolve it: Testing BA-SGCL at perturbation rates of 25%, 30%, and 50% across multiple datasets, along with theoretical analysis of robustness guarantees as perturbation increases.

### Open Question 2
- Question: How does BA-SGCL perform when defending against adaptive attacks that specifically target its balance augmentation mechanism?
- Basis in paper: [inferred] The paper evaluates against balance-attack and FlipAttack but doesn't consider attacks designed to specifically circumvent balance augmentation strategy.
- Why unresolved: Current evaluation uses standard attack methods, not adversarial strategies that might exploit BA-SGCL's specific defense mechanism.
- What evidence would resolve it: Developing and testing specialized attacks that attempt to circumvent balance augmentation, then measuring BA-SGCL's performance under these targeted attacks.

### Open Question 3
- Question: What is the relationship between optimal balance augmentation budget (nD%) and dataset characteristics such as density, class imbalance, or sign ratio?
- Basis in paper: [explicit] The paper mentions using nD% to limit edge flips but doesn't explore how this parameter should be tuned for different datasets or what factors influence optimal value.
- Why unresolved: The paper uses fixed approach for setting augmentation budget without analyzing sensitivity to dataset properties.
- What evidence would resolve it: Systematic experiments varying nD% across datasets with different characteristics, coupled with analysis of how graph properties correlate with optimal augmentation parameters.

## Limitations
- The balance-attack method relies on a greedy heuristic that may not find globally optimal edge flips, potentially underestimating attack effectiveness
- Model performance on graphs with naturally low balance degree (such as Epinions) suggests approach may be less effective on certain real-world network structures
- The "Irreversibility of Balance-related Information" challenge is theoretically compelling but remains empirically underexplored

## Confidence

- **High Confidence**: The experimental methodology is rigorous, with extensive hyperparameter tuning and multiple evaluation metrics across four real-world datasets.
- **Medium Confidence**: The theoretical claims about balance theory vulnerabilities and effectiveness of contrastive learning for robustness are supported by experiments but would benefit from additional ablation studies.
- **Low Confidence**: The generalizability of results to signed graphs with different characteristics (e.g., directed vs. undirected, different balance distributions) remains untested.

## Next Checks

1. **Ablation Study**: Test BA-SGCL variants with random augmentation vs. balance augmentation on each dataset to isolate the contribution of the balance-aware component.

2. **Cross-Dataset Transfer**: Train BA-SGCL on one dataset and evaluate its robustness when transferred to another dataset to assess generalizability across different graph structures.

3. **Attack Diversity**: Evaluate BA-SGCL against additional attack strategies beyond balance-attack and FlipAttack, such as gradient-based or reinforcement learning-based attacks, to test robustness to a broader threat model.