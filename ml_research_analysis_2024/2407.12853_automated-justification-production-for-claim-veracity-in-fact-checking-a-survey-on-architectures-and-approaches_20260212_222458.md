---
ver: rpa2
title: 'Automated Justification Production for Claim Veracity in Fact Checking: A
  Survey on Architectures and Approaches'
arxiv_id: '2407.12853'
source_url: https://arxiv.org/abs/2407.12853
tags:
- justification
- claim
- production
- justifications
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a multidimensional taxonomy for categorizing
  justification production methods in automated fact-checking (AFC). The authors analyze
  current AFC pipeline architectures and identify four main approaches: attention-based,
  knowledge graph-based, summarization-based, and LLM prompting with RAG/fine-tuning.'
---

# Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches

## Quick Facts
- **arXiv ID**: 2407.12853
- **Source URL**: https://arxiv.org/abs/2407.12853
- **Reference count**: 26
- **Key outcome**: This survey provides a multidimensional taxonomy for categorizing justification production methods in automated fact-checking (AFC), identifying four main approaches and key challenges including evaluation frameworks, multi-modal content handling, and LLM hallucinations.

## Executive Summary
This survey comprehensively examines justification production methods in automated fact-checking systems, focusing on how these methods generate explanations for claim veracity predictions. The authors propose a multidimensional taxonomy that categorizes approaches based on explainability, input types, and output formats. They analyze four main justification production approaches - attention-based, knowledge graph-based, summarization-based, and LLM prompting with RAG/fine-tuning - and discuss their effectiveness across different AFC pipeline architectures. The paper identifies critical challenges in the field, including the need for standardized evaluation frameworks, handling multi-modal content, and addressing LLM hallucinations, while suggesting counterfactual justifications as a promising direction for future research.

## Method Summary
The survey methodology involves a comprehensive literature review of automated fact-checking systems, with particular focus on justification production components. The authors analyze existing AFC pipeline architectures and classification schemes, then propose their own multidimensional taxonomy based on five key dimensions: explainability type, input type, output type, approach category, and pipeline integration. Through systematic analysis of published works, they identify and categorize different justification production approaches, examining their strengths, limitations, and relationships to overall AFC system performance. The survey also synthesizes current challenges and future research directions based on gaps identified in the literature.

## Key Results
- The survey identifies four main justification production approaches: attention-based, knowledge graph-based, summarization-based, and LLM prompting with RAG/fine-tuning
- Key challenges include developing standardized evaluation frameworks for justifications, generating natural language explanations for multi-modal content, and addressing LLM hallucinations
- The proposed multidimensional taxonomy provides a structured framework for categorizing justification production methods across multiple dimensions
- Counterfactual justifications are identified as a promising direction for improving explainability in AFC systems

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The survey's taxonomy effectively categorizes justification production methods in automated fact-checking by considering multiple dimensions including explainability, input type, and output type.
- **Mechanism**: The taxonomy provides a structured framework that captures the diversity of approaches and their relationships, enabling systematic comparison and analysis of different methods.
- **Core assumption**: Different approaches to justification production can be meaningfully differentiated based on their characteristics across multiple dimensions.
- **Evidence anchors**:
  - [abstract] "This survey provides a multidimensional taxonomy for categorizing justification production methods in automated fact-checking (AFC)."
  - [section 6] "We propose five dimensions (illustrated by the first five levels/columns of the Taxonomy tree in Figure 3)."
- **Break condition**: If approaches cannot be meaningfully differentiated along the proposed dimensions or if the dimensions fail to capture important distinctions between methods.

### Mechanism 2
- **Claim**: The survey identifies key challenges in justification production including evaluation frameworks, multi-modal content handling, and LLM hallucinations.
- **Mechanism**: By systematically analyzing existing literature and identifying gaps, the survey highlights areas requiring further research and development.
- **Core assumption**: Challenges in justification production can be identified through comprehensive literature review and analysis of current approaches.
- **Evidence anchors**:
  - [key outcome] "The paper identifies key challenges including evaluating justifications against desiderata, generating natural language explanations for multi-modal content, and addressing LLM hallucinations."
  - [section 7] "Evaluating and Generating Justifications According to Desiderata... Natural Language Justifications in Multi-modal AFC... Non-factual Hallucinations in LLMs in AFC"
- **Break condition**: If the identified challenges are not actually significant problems or if the literature review misses important challenges.

### Mechanism 3
- **Claim**: The survey's comparative analysis of pipeline architectures helps understand the evolution and current state of justification production methods.
- **Mechanism**: By examining different pipeline architectures and their relationships to justification production, the survey provides insights into how approaches have evolved and where current research is focused.
- **Core assumption**: Understanding pipeline architectures is crucial for comprehending the development and current state of justification production methods.
- **Evidence anchors**:
  - [section 6.3] "We propose to differentiate various pipelines for Explainable AFC based on the relationship between the justification production stage and the veracity prediction stage."
  - [section 3.4] "This stage produces justifications to explain the verdict of an AFC model regarding a claim's veracity."
- **Break condition**: If pipeline architectures are not actually important for understanding justification production or if the analysis misses significant architectural variations.

## Foundational Learning

- **Concept**: Automated Fact-Checking (AFC) pipeline stages
  - Why needed here: Understanding the AFC pipeline is essential for contextualizing justification production within the broader fact-checking process.
  - Quick check question: What are the main stages in the AFC pipeline and how does justification production fit into this process?

- **Concept**: Desiderata for justifications
  - Why needed here: Desiderata define the quality criteria that justifications should meet, which is crucial for evaluating and improving justification production methods.
  - Quick check question: What are the key desiderata for justifications in AFC and why are they important?

- **Concept**: Multi-modal fact-checking
  - Why needed here: With the increasing prevalence of multi-modal content, understanding how justification production works with different input types is becoming increasingly important.
  - Quick check question: How does justification production differ when dealing with multi-modal input compared to text-only input?

## Architecture Onboarding

- **Component map**:
  - AFC pipeline stages (claim detection, evidence retrieval, veracity prediction, justification production)
  - Justification production approaches (attention-based, knowledge graph-based, summarization-based, LLM prompting)
  - Input types (text-only, multi-modal)
  - Output types (natural language, highlighted text, SOP triples)

- **Critical path**: The most common pipeline for justification production involves claim detection → evidence retrieval → veracity prediction → justification production, with the justification stage being the focus of this survey.

- **Design tradeoffs**:
  - Pipeline architecture: Separated vs. Joint vs. Veracity-then-justification vs. Justification-then-veracity
  - Input handling: Text-only vs. multi-modal processing
  - Output format: Natural language vs. highlighted text vs. structured triples
  - Approach selection: Attention-based vs. knowledge graph vs. summarization vs. LLM prompting

- **Failure signatures**:
  - Contradictions between justification and veracity predictions
  - Inability to handle multi-modal input effectively
  - Production of non-factual hallucinations in LLM-based approaches
  - Failure to meet desired desiderata for justifications

- **First 3 experiments**:
  1. Implement a simple attention-based justification production model and evaluate its performance on a text-only dataset.
  2. Compare the performance of different pipeline architectures (separated vs. joint) on a multi-modal dataset.
  3. Evaluate the effectiveness of LLM prompting approaches in generating counterfactual justifications.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop quantitative frameworks to measure desiderata for justifications in AFC systems, and what would be the impact of integrating these measurements into model training?
- Basis in paper: explicit
- Why unresolved: Current research has only explored modeling one particular desired property (coherence/faithfulness) as a learning signal in model training, with limited further exploration in this area.
- What evidence would resolve it: Development and validation of quantitative metrics for measuring multiple desiderata, followed by empirical studies showing improved justification quality when these metrics are incorporated into training objectives.

### Open Question 2
- Question: What are the most effective techniques to reduce computational costs associated with multi-hop and LLM reasoning methods in justification production?
- Basis in paper: explicit
- Why unresolved: The paper notes that justification production via multi-hop or LLM reasoning methods are computationally and financially costly, but does not provide concrete solutions.
- What evidence would resolve it: Comparative studies of various techniques (knowledge distillation, quantization, model compression) showing significant reductions in computational requirements while maintaining or improving justification quality.

### Open Question 3
- Question: How can counterfactual justifications be effectively implemented in AFC systems to achieve multiple desiderata such as completeness, coherence, actionability, and novelty?
- Basis in paper: explicit
- Why unresolved: While the paper suggests counterfactual justifications as a promising direction, it does not provide concrete implementation details or evaluate their effectiveness in achieving multiple desiderata.
- What evidence would resolve it: Development and evaluation of counterfactual justification generation methods that demonstrate improvements in multiple desiderata compared to traditional justification approaches.

## Limitations
- The survey's taxonomy relies heavily on the authors' interpretation of existing literature, which may not capture all relevant approaches or emerging methods
- The confidence in the identified challenges (evaluation frameworks, multi-modal handling, LLM hallucinations) is Medium as these are based on current literature analysis rather than empirical validation
- The survey does not provide quantitative performance comparisons between different approaches, limiting the ability to assess their relative effectiveness

## Confidence
- **High**: The classification of justification production approaches (attention-based, knowledge graph-based, summarization-based, LLM prompting) is well-supported by existing literature.
- **Medium**: The identification of key challenges and the proposed multidimensional taxonomy are reasonable but require further validation.
- **Low**: The survey's predictions about future research directions (counterfactual justifications, standardized evaluation frameworks) are speculative and not yet empirically supported.

## Next Checks
1. **Empirical validation of challenges**: Conduct a systematic study to measure the prevalence and impact of identified challenges (evaluation frameworks, multi-modal handling, LLM hallucinations) across multiple AFC datasets and approaches.
2. **Taxonomy comprehensiveness assessment**: Apply the proposed multidimensional taxonomy to a broader range of AFC systems and identify any gaps or missing dimensions that could improve classification accuracy.
3. **Performance benchmarking**: Implement representative approaches from each category (attention-based, knowledge graph-based, summarization-based, LLM prompting) and conduct head-to-head comparisons on standardized AFC datasets with comprehensive evaluation metrics.