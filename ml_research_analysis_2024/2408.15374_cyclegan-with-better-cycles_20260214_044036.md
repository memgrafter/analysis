---
ver: rpa2
title: CycleGAN with Better Cycles
arxiv_id: '2408.15374'
source_url: https://arxiv.org/abs/2408.15374
tags:
- consistency
- cycle
- image
- cyclegan
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'CycleGAN enforces pixel-level cycle consistency that can lead
  to unrealistic artifacts in image-to-image translation tasks. The authors propose
  three modifications to improve cycle consistency: (1) adding L1 loss on CNN features
  extracted by discriminators alongside pixel-level loss, (2) gradually decaying the
  weight of cycle consistency loss during training, and (3) weighting cycle consistency
  by the quality of generated images as determined by discriminator outputs.'
---

# CycleGAN with Better Cycles

## Quick Facts
- arXiv ID: 2408.15374
- Source URL: https://arxiv.org/abs/2408.15374
- Reference count: 4
- Authors: Tongzhou Wang; Yihan Lin
- Key outcome: Modified CycleGAN with feature-level cycle consistency, decaying cycle loss weight, and discriminator-quality weighting produces more realistic translations with fewer artifacts on horse2zebra dataset

## Executive Summary
CycleGAN enforces pixel-level cycle consistency that can lead to unrealistic artifacts in image-to-image translation tasks. The authors propose three modifications to improve cycle consistency: (1) adding L1 loss on CNN features extracted by discriminators alongside pixel-level loss, (2) gradually decaying the weight of cycle consistency loss during training, and (3) weighting cycle consistency by the quality of generated images as determined by discriminator outputs. These changes were tested on the horse2zebra dataset, where the modified approach produced more realistic translations with fewer artifacts compared to the original CycleGAN, though reconstructed images were less pixel-accurate. The weighting by discriminator quality showed limited benefit due to discriminators being jointly trained with generators, suggesting pretraining discriminators could improve results.

## Method Summary
The paper modifies CycleGAN by adding L1 loss on discriminator CNN features to reduce pixel-level artifacts, implementing a schedule that gradually decays cycle consistency weight during training, and weighting cycle consistency by discriminator output quality. These modifications aim to prioritize structural and semantic consistency over exact pixel matching, allow generators to focus on realism early in training, and prevent enforcing cycle consistency when generated images are unrealistic. The approach was evaluated on the horse2zebra dataset with qualitative comparisons showing improved translation realism and reduced artifacts compared to the original CycleGAN.

## Key Results
- Feature-level cycle consistency reduces unrealistic artifacts while maintaining structural properties
- Gradually decaying cycle consistency weight allows early focus on realism before refining reconstruction quality
- Weighting cycle consistency by discriminator output quality has limited benefit when discriminators are jointly trained

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding L1 loss on discriminator CNN features reduces unrealistic artifacts while maintaining structural consistency
- Mechanism: The discriminator's CNN features capture higher-level semantic information about image domain characteristics. By enforcing L1 consistency on these features rather than raw pixels, the model prioritizes preserving structural and semantic properties over exact pixel matching, which allows for more natural-looking translations
- Core assumption: The discriminator's learned features represent meaningful semantic information about the target domain that should be preserved during translation
- Evidence anchors:
  - [abstract]: "adding L1 loss on CNN features extracted by discriminators alongside pixel-level loss"
  - [section 3.1]: "we should better only require that it recover the general structures... we enforce this weaker notion of cycle consistency by including an L1 loss on the CNN features extracted by the corresponding discriminator"
- Break condition: If discriminators are not properly trained to capture meaningful domain-specific features, or if γ is set too high early in training when discriminator features are unreliable

### Mechanism 2
- Claim: Gradually decaying cycle consistency weight allows generators to focus on realism early, then refine reconstruction quality later
- Mechanism: Early in training, generators benefit from focusing on producing realistic outputs rather than perfect reconstructions. As training progresses and generators can reliably produce realistic images, the model can then focus more on maintaining cycle consistency without sacrificing output quality
- Core assumption: Cycle consistency helps stabilize early training but becomes restrictive as generators mature and should be gradually reduced to allow for more creative translations
- Evidence anchors:
  - [abstract]: "gradually decaying the weight of cycle consistency loss during training"
  - [section 3.2]: "cycle consistency loss helps stabilizing training a lot in early stages but becomes an obstacle towards realistic images in later stages"
- Break condition: If λ decays too quickly, generators may lose structural consistency entirely; if too slowly, unrealistic artifacts persist

### Mechanism 3
- Claim: Weighting cycle consistency by discriminator quality prevents generators from optimizing for poor reconstructions when outputs are unrealistic
- Mechanism: Early in training, when generators produce unrealistic outputs, enforcing cycle consistency can lead to degenerate solutions (like color inversion mappings). By weighting the loss based on discriminator output quality, the model prioritizes learning to generate realistic images before worrying about perfect reconstruction
- Core assumption: Discriminator outputs correlate with image realism and should be used to gate when cycle consistency is enforced
- Evidence anchors:
  - [abstract]: "weighting cycle consistency by the quality of generated images as determined by discriminator outputs"
  - [section 3.3]: "Enforcing cycle consistency on cycles where generated images are not realistic actually hinders training"
- Break condition: If discriminators are jointly trained and their outputs remain constant, the weighting has no effect; pretraining discriminators may be necessary for this mechanism to work

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: CycleGAN is built on GAN architecture with two generator-discriminator pairs working in opposite directions
  - Quick check question: What is the difference between the generator loss and discriminator loss in a standard GAN setup?

- Concept: Cycle Consistency
  - Why needed here: The core innovation of CycleGAN is the cycle consistency loss that enables training with unpaired data by enforcing that translating A→B→A returns to the original image
  - Quick check question: Why is cycle consistency necessary for unpaired image-to-image translation?

- Concept: Perceptual Loss
  - Why needed here: The proposed modification uses perceptual similarity (L1 on CNN features) rather than pixel-level similarity, which is a key concept from style transfer and perceptual metrics literature
  - Quick check question: How does perceptual loss differ from pixel-wise L2 loss in terms of what it optimizes for?

## Architecture Onboarding

- Component map:
  Two generators (G: X→Y, F: Y→X) -> Two discriminators (DX for domain X, DY for domain Y) -> Feature extractors (fD(X) and fD(Y) from discriminators) -> Loss components (GAN loss, pixel-level cycle loss, feature-level cycle loss, weighted cycle loss)

- Critical path:
  1. Input image flows through generator G
  2. Discriminator DY evaluates generated image quality
  3. Reconstructed image flows through feature extractor from DY
  4. L1 loss computed between reconstructed feature and original feature
  5. Weighted by discriminator output quality
  6. Combined with pixel-level loss and decayed by epoch

- Design tradeoffs:
  - Feature-level vs pixel-level consistency: More flexible but less precise reconstruction
  - Weight decay schedule: Too fast loses structure, too slow retains artifacts
  - Pretrained vs jointly-trained discriminators: Pretrained may improve feature-based consistency but requires additional data/computation

- Failure signatures:
  - Constant discriminator outputs around 0.3 indicate poor discrimination capability
  - Hallucinations appearing in reconstructed images suggest γ is too high or λ is decaying too slowly
  - Color inversion patterns suggest need for quality-weighted consistency

- First 3 experiments:
  1. Train baseline CycleGAN with original hyperparameters to establish reference performance
  2. Implement feature-level cycle consistency with fixed γ=0.5 to test perceptual loss impact
  3. Add weight decay to cycle consistency and tune decay schedule to balance realism vs reconstruction quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does pretraining discriminators impact the effectiveness of weighting cycle consistency by discriminator output quality?
- Basis in paper: [explicit] The authors note that "using pretrained discriminators will make this modification actually have positive effect" and observe that discriminators jointly trained with generators produce outputs that stay around a constant value (approximately 0.3), limiting the benefit of this modification.
- Why unresolved: The authors only speculated about this approach and did not experimentally test it due to time constraints. They explicitly state that "using pretrained discriminators, either trained with CycleGAN task or initialized with pretrained CNN weights like AlexNet, along with fine-tuning, should give a considerable improvement."
- What evidence would resolve it: Experimental results comparing CycleGAN with and without pretrained discriminators, showing quantitative metrics (like FID scores) and qualitative examples of generated images, would demonstrate whether pretraining improves the effectiveness of weighting cycle consistency by discriminator output.

### Open Question 2
- Question: What is the optimal scheduling strategy for the cycle consistency weight decay parameter λt and CNN feature loss ratio γt?
- Basis in paper: [explicit] The authors state that "we found that the result quality is very sensitive to different parameters" and that "due to time limit, we are only able to try a few combinations," identifying parameter tuning as an important future work direction.
- Why unresolved: The authors experimented with only a linear decay for λt and linear increase for γt, but acknowledge that other scheduling strategies might be more effective. They did not systematically explore the parameter space.
- What evidence would resolve it: A comprehensive ablation study testing various scheduling functions (exponential decay, cosine annealing, step decay, etc.) for λt and different progression patterns for γt, along with quantitative evaluation metrics, would identify optimal scheduling strategies.

### Open Question 3
- Question: How can stochastic inputs be effectively incorporated into CycleGAN to enable one-to-many mappings while maintaining cycle consistency?
- Basis in paper: [explicit] The authors attempted adding noise channels to inputs but "weren't able to achieve comparable results with the original CycleGAN within same period of training, likely due to a full channel of noise being too much randomness." They identify this as an "exciting direction" for future work.
- Why unresolved: The authors' initial attempts failed to produce competitive results, and they did not explore alternative architectural modifications or noise injection strategies that might better balance randomness with the constraints of cycle consistency.
- What evidence would resolve it: Successful implementation of a stochastic CycleGAN variant that achieves comparable or better quantitative metrics than standard CycleGAN while producing diverse outputs for the same input, demonstrating that one-to-many mappings can be achieved without sacrificing quality or cycle consistency.

## Limitations

- Limited to single dataset (horse2zebra), reducing generalizability claims
- Parameter tuning found to be highly sensitive with only limited exploration due to time constraints
- Discriminator quality weighting mechanism shows limited benefit when discriminators are jointly trained rather than pretrained

## Confidence

- **High confidence**: The observation that pixel-level cycle consistency can lead to unrealistic artifacts and the general approach of using perceptual similarity via CNN features
- **Medium confidence**: The specific implementation details of feature-level cycle consistency and the qualitative improvements shown on horse2zebra dataset
- **Low confidence**: The effectiveness of discriminator quality weighting without pretrained discriminators, and the generalizability of results to other datasets and translation tasks

## Next Checks

1. **Ablation study on feature extraction layer**: Test different layers from the discriminator CNN for feature extraction to determine which captures most semantically relevant information for cycle consistency
2. **Pretrained discriminator experiment**: Train discriminators on auxiliary datasets before CycleGAN training to validate whether quality weighting mechanism works as intended
3. **Cross-dataset evaluation**: Apply the modified approach to at least two additional unpaired image-to-image translation datasets (e.g., Monet paintings↔photos, cityscapes↔labels) to assess generalizability beyond horse2zebra