---
ver: rpa2
title: 'SelfIE: Self-Interpretation of Large Language Model Embeddings'
arxiv_id: '2403.10949'
source_url: https://arxiv.org/abs/2403.10949
tags:
- prompt
- inst
- control
- interpretation
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SelfIE, a framework that enables LLMs to
  interpret their own hidden embeddings in natural language without training. The
  method leverages the LLM's own decoding capability by inserting target embeddings
  into a separate forward pass with an interpretation prompt.
---

# SelfIE: Self-Interpretation of Large Language Model Embeddings

## Quick Facts
- arXiv ID: 2403.10949
- Source URL: https://arxiv.org/abs/2403.10949
- Authors: Haozhe Chen; Carl Vondrick; Chengzhi Mao
- Reference count: 34
- Key outcome: Zero-shot open-world interpretation of LLM embeddings using the model itself without training, enabling control over reasoning behaviors

## Executive Summary
SelfIE introduces a framework that enables large language models to interpret their own hidden embeddings in natural language without requiring additional training. The method works by inserting target embeddings into a separate forward pass with an interpretation prompt, leveraging the model's existing decoding capability to describe what information the embeddings contain. SelfIE demonstrates zero-shot open-world interpretation capabilities and enables new control methods for modifying model behaviors through gradient-based editing of individual layers.

## Method Summary
SelfIE works by first performing a standard forward pass through an LLM to extract embeddings from a chosen layer and position. These embeddings are then inserted into a separate interpretation forward pass by replacing a placeholder token in a specially constructed prompt. The model generates natural language descriptions by predicting next tokens repeatedly. For control applications, SelfIE uses gradient-based methods to modify embeddings - Supervised Control optimizes embeddings to match desired interpretations, while Reinforcement Control extends RLHF to the embedding space. The framework enables both interpretation of hidden knowledge and precise control over model behaviors.

## Key Results
- Achieves zero-shot open-world interpretation of embeddings without training
- Matches 100-shot linear probe performance on TextWorld world state elicitation
- Reduces prompt injection harmful response success rate by 84.66%
- Achieves 95% effectiveness in overriding ethical steering

## Why This Works (Mechanism)

### Mechanism 1
SelfIE leverages the LLM's ability to respond to inquiries about a given passage by replacing passage tokens with latent embeddings. The LLM's decoding capability is repurposed to interpret hidden embeddings, assuming the model can handle the complexity of these compressed representations. The residual structure in Transformers decomposes output as applying the final projection matrix on linear combinations over each layer's output, leading to unified representations across different layers.

### Mechanism 2
The residual structure in Transformers enables faithful interpretation by creating unified representations across layers. This mechanism allows embeddings from one layer to be interpreted by the model's later layers as if they were normal tokens, with information propagating effectively through the network layers to produce coherent natural language descriptions.

### Mechanism 3
SelfIE's text descriptions enable precise control over model behaviors in the latent space by locating and modifying individual layers. The interpretations can be used to identify where specific knowledge or behaviors are represented in the network, allowing targeted modifications through gradient-based optimization methods that either directly optimize embeddings (Supervised Control) or use reinforcement learning (Reinforcement Control).

## Foundational Learning

- **Transformer architecture and forward pass**: Understanding how transformers process input and generate output is crucial for understanding how SelfIE works. Quick check: What are the main components of a transformer and how do they interact during the forward pass?
- **Embedding and token representation**: Understanding how words and concepts are represented as embeddings is essential for understanding how SelfIE interprets hidden embeddings. Quick check: How are words and concepts represented as embeddings in a transformer, and how do these embeddings capture semantic information?
- **Gradient descent and optimization**: Understanding how gradients are used to optimize model parameters is important for understanding how SelfIE's control methods work. Quick check: How does gradient descent work, and how can it be used to optimize model parameters based on a given loss function?

## Architecture Onboarding

- **Component map**: LLM -> Embedding extraction -> Interpretation prompt with placeholder -> Modified forward pass -> Natural language description
- **Critical path**: input prompt → original forward pass → extract embedding → interpretation forward pass → natural language description
- **Design tradeoffs**: The main design tradeoff is between the complexity of the interpretation prompt and the quality of the natural language description. More complex prompts may lead to better descriptions but may also be more difficult to construct.
- **Failure signatures**: Potential failure modes include the LLM failing to interpret the embedding accurately, control methods not effectively modifying model behaviors, or the interpretation prompt not being well-formed.
- **First 3 experiments**:
  1. Verify that the LLM can interpret a simple embedding (e.g., a single word) using a basic interpretation prompt.
  2. Test the quality of natural language descriptions produced by SelfIE for different types of embeddings (e.g., words, phrases, sentences).
  3. Evaluate the effectiveness of control methods (Supervised Control and Reinforcement Control) in modifying model behaviors based on interpretations.

## Open Questions the Paper Calls Out

### Open Question 1
How does SelfIE handle ambiguous or underspecified prompts where multiple interpretations could be valid? The method relies on the LLM's ability to provide a single coherent interpretation, but real-world embeddings may contain multiple overlapping concepts or conflicting information.

### Open Question 2
What is the relationship between the layer chosen for interpretation (k) and the quality of explanations across different types of concepts? The paper treats all interpretations uniformly without examining whether semantic information is distributed differently across layers for different types of concepts.

### Open Question 3
How does SelfIE's interpretation quality scale with model size beyond the 7B, 13B, and 70B models tested? The paper tests three model sizes but doesn't explore whether very large models (e.g., 175B+ parameters) show improved or degraded interpretation quality.

## Limitations
- Interpretation quality depends critically on prompt engineering, which remains an art rather than a science
- Control methods may face interference from other layers during normal inference, potentially limiting effectiveness in complex reasoning tasks
- The assumption that residual structure leads to unified representations across layers may not hold for all transformer architectures or tasks

## Confidence
- **High Confidence**: SelfIE's ability to generate natural language descriptions of embeddings; zero-shot open-world interpretation capability; Supervised Control effectiveness for simple fact editing; prompt injection reduction
- **Medium Confidence**: Ethical steering override at 95% effectiveness; comparison to 100-shot linear probe performance; residual structure hypothesis
- **Low Confidence**: Claims that SelfIE opens "new avenues for light-weighted controls"; mechanism by which interpretation tokens relate to original embedding content; assumption that interpretation quality scales linearly with model capability

## Next Checks
1. **Layer Dependency Analysis**: Systematically test SelfIE's interpretation quality across different layers (k values) and embedding locations (ℓ*) to verify the residual structure hypothesis and identify optimal configurations for different task types.

2. **Prompt Robustness Testing**: Conduct ablation studies on interpretation prompts to determine which prompt components are essential versus optional, and test whether the method works with different prompt styles or requires specific formatting.

3. **Cross-Model Generalization**: Apply SelfIE to multiple LLM architectures (different model families, sizes, and training objectives) to determine whether the interpretation and control capabilities generalize beyond the specific model used in the paper's experiments.