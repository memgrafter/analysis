---
ver: rpa2
title: Personalized Multi-task Training for Recommender System
arxiv_id: '2407.21364'
source_url: https://arxiv.org/abs/2407.21364
tags:
- task
- gradient
- pmtrec
- tasks
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes PMTRec, a personalized multi-task training
  algorithm for recommender systems that dynamically adjusts task weights for each
  user/item based on gradient norms. The method addresses three challenges in multi-task
  learning for RecSys: personalized task weights, varied task orientations, and gradient
  magnitude differences across tasks.'
---

# Personalized Multi-task Training for Recommender System

## Quick Facts
- arXiv ID: 2407.21364
- Source URL: https://arxiv.org/abs/2407.21364
- Reference count: 40
- Primary result: Achieves up to 11.58% improvement in NDCG@40 on Office dataset vs baselines

## Executive Summary
PMTRec introduces a personalized multi-task training algorithm for recommender systems that dynamically adjusts task weights based on gradient norms for each user/item. The method addresses three key challenges in multi-task learning for RecSys: personalized task weights, varied task orientations, and gradient magnitude differences across tasks. PMTRec employs a Task Focusing module to gradually align training with the main recommendation task and a Gradient Magnitude Balancing module to ensure balanced training across tasks. Experiments on three real-world datasets demonstrate significant improvements over existing multi-task learning methods.

## Method Summary
PMTRec is a personalized multi-task training algorithm that combines gradients from multiple tasks (recommendation + auxiliary tasks) for each user/item based on gradient norms. The method uses matrix factorization as an encoder to produce user/item embeddings from the user-item bipartite graph. During training, PMTRec collects gradients from all tasks, applies task focusing to gradually emphasize the main recommendation task, balances gradient magnitudes across tasks using temperature scaling, and combines personalized gradients for each user/item before updating parameters. The approach is evaluated on three datasets (Epinion, Video Game, Office) with various auxiliary tasks including social prediction, category prediction, co-view/buy prediction, alignment/uniformity, and rating prediction.

## Key Results
- Achieves up to 11.58% improvement in NDCG@40 on Office dataset compared to Nash MTL and RLW baselines
- Outperforms existing multi-task learning methods across all three datasets
- Demonstrates effectiveness of personalized gradient combinations in enhancing recommendation accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Personalized task weights based on gradient norms improve recommendation accuracy by adapting to user-specific task importance
- Mechanism: PMTRec computes the L2 norm of each task's gradient for each user/item, then uses these norms as importance signals to weight task gradients before combining them
- Core assumption: The magnitude of a task's gradient for a specific user/item reflects that task's current usefulness for that user/item's embedding update
- Evidence anchors:
  - [abstract] "PMTRec dynamically adjusts task weights based on gradient norms for each user/item"
  - [section] "PMTRec first collects the gradient from each task during backpropagation and then combines the gradient on each user embedding separately"
- Break condition: If gradient norms don't correlate with task usefulness (e.g., when auxiliary tasks are poorly designed), this mechanism fails

### Mechanism 2
- Claim: Task Focusing module gradually aligns training with the main recommendation task to prevent conflicting updates from auxiliary tasks
- Mechanism: During training, PMTRec multiplies the RecSys task gradient norm by an epoch-dependent factor α^s (where s is the current epoch)
- Core assumption: Auxiliary task gradients can conflict with or dilute the main task's optimization direction, and gradual refocusing prevents this while retaining exploration benefits
- Evidence anchors:
  - [abstract] "employs a Task Focusing module to align gradient combinations with the main recommendation task"
  - [section] "PMTRec will explore all the tasks first and gradually focus the training on the main RecSys task"
- Break condition: If auxiliary tasks are well-aligned with the main task from the start, this gradual refocusing may slow convergence unnecessarily

### Mechanism 3
- Claim: Gradient Magnitude Balancing prevents small-gradient tasks from being overshadowed during multi-task training
- Mechanism: PMTRec applies a temperature-scaled softmax to normalized gradient norms to compute task weights, where temperature τ controls the balancing
- Core assumption: Different task loss functions produce gradients of vastly different magnitudes, and simple averaging or addition would underweight important but low-magnitude tasks
- Evidence anchors:
  - [abstract] "uses a Gradient Magnitude Balancing module to ensure balanced training across tasks"
  - [section] "Multi-task training algorithms overlook gradients with smaller magnitudes without considering the difference"
- Break condition: If all tasks naturally produce similar gradient magnitudes, this balancing mechanism adds unnecessary complexity

## Foundational Learning

- Concept: Multi-task learning gradient combination strategies
  - Why needed here: PMTRec builds on existing MTL approaches but innovates at the gradient combination level rather than loss weighting or parameter space approaches
  - Quick check question: What's the key difference between PCGrad and PMTRec's approach to handling multi-task gradients?

- Concept: Personalized recommendation system fundamentals
  - Why needed here: Understanding how user/item embeddings are learned from interaction graphs is essential for grasping why auxiliary task information helps
  - Quick check question: How does the user-item bipartite graph structure relate to the embedding learning process?

- Concept: Gradient-based optimization in deep learning
  - Why needed here: PMTRec's mechanisms operate directly on gradients during backpropagation, requiring understanding of how gradients propagate and combine
  - Quick check question: What does the L2 norm of a gradient vector represent in the context of parameter updates?

## Architecture Onboarding

- Component map: Encoder (Matrix factorization) -> Task modules (RecSys + auxiliary tasks) -> Backward pipeline (Gradient collection -> Task focusing -> Gradient magnitude balancing -> Personalized gradient combination -> Parameter update)

- Critical path:
  1. Forward pass through encoder and all task modules
  2. Backward pass collecting gradients from all tasks
  3. Task focusing module modifies RecSys gradient weights
  4. Gradient magnitude balancing module normalizes task weights
  5. Personalized gradient combination creates per-user/item aggregated gradient
  6. Parameter update via optimizer

- Design tradeoffs:
  - Task focusing vs. exploration: Larger α focuses faster but may miss useful auxiliary task signals
  - Gradient balancing temperature: Higher τ treats tasks more equally; lower τ emphasizes strongest gradients
  - Encoder choice: Simpler encoders train faster but may limit representation capacity

- Failure signatures:
  - Degraded performance on datasets where auxiliary tasks don't provide useful signal
  - Instability when auxiliary tasks have highly conflicting gradients
  - Slow convergence when task focusing parameter α is too large

- First 3 experiments:
  1. Run PMTRec with only the RecSys task (no auxiliary tasks) to establish baseline
  2. Add one well-designed auxiliary task and compare to baseline
  3. Add all auxiliary tasks with varying α and τ values to find optimal hyperparameters

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PMTRec perform when applied to datasets with different sparsity levels, particularly extremely sparse datasets?
- Basis in paper: [explicit] The paper mentions that recommender systems naturally face data sparsity issues, and PMTRec aims to address this by leveraging multi-task learning to incorporate external knowledge
- Why unresolved: The paper does not explore how PMTRec performs on datasets with varying sparsity levels
- What evidence would resolve it: Experiments comparing PMTRec's performance on datasets with different sparsity levels, including extremely sparse datasets

### Open Question 2
- Question: How does the performance of PMTRec change when using different types of auxiliary tasks, such as those based on user demographics or item attributes?
- Basis in paper: [inferred] The paper discusses the use of auxiliary tasks like social prediction and category prediction, but it does not explore the impact of using different types of auxiliary tasks
- Why unresolved: The paper does not investigate how the choice of auxiliary tasks affects PMTRec's performance
- What evidence would resolve it: Experiments testing PMTRec with various types of auxiliary tasks, including those based on user demographics or item attributes

### Open Question 3
- Question: What is the impact of the task focusing base (α) and temperature (τ) hyper-parameters on PMTRec's performance across different datasets?
- Basis in paper: [explicit] The paper mentions that PMTRec introduces hyper-parameters α and τ in the task focusing and gradient magnitude balancing modules, respectively, and provides sensitivity analysis for these parameters
- Why unresolved: While the paper provides sensitivity analysis, it does not explore how these hyper-parameters affect PMTRec's performance across different datasets
- What evidence would resolve it: Experiments analyzing the impact of α and τ on PMTRec's performance across various datasets

## Limitations
- Lacks detailed information about auxiliary task formulations across datasets, making exact reproduction challenging
- No ablation studies showing the individual contribution of Task Focusing vs. Gradient Magnitude Balancing modules
- Limited baseline comparison and lack of statistical significance testing reduce confidence in empirical claims

## Confidence
- High confidence in the core mechanism: gradient-norm-based personalized weighting is clearly specified and theoretically sound
- Medium confidence in empirical claims: results show significant improvements but limited baseline comparison and lack of statistical significance testing
- Medium confidence in practical applicability: approach requires auxiliary tasks with available signal, limiting generalizability

## Next Checks
1. Conduct ablation studies to isolate the contribution of Task Focusing vs. Gradient Magnitude Balancing modules
2. Perform statistical significance testing on performance improvements across all datasets
3. Test PMTRec on a dataset where auxiliary tasks are intentionally poorly designed to verify failure conditions