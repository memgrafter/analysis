---
ver: rpa2
title: 'GLANCE: Global Actions in a Nutshell for Counterfactual Explainability'
arxiv_id: '2405.18921'
source_url: https://arxiv.org/abs/2405.18921
tags: []
core_contribution: GLANCE introduces an agglomerative clustering approach for global
  counterfactual explainability, jointly considering feature space and action space
  to balance effectiveness, cost, and interpretability. The method generates initial
  clusters and counterfactual actions, then iteratively merges them using distance
  metrics in both spaces to produce compact, high-quality global explanations.
---

# GLANCE: Global Actions in a Nutshell for Counterfactual Explainability

## Quick Facts
- arXiv ID: 2405.18921
- Source URL: https://arxiv.org/abs/2405.18921
- Authors: Loukas Kavouras; Eleni Psaroudaki; Konstantinos Tsopelas; Dimitrios Rontogiannis; Nikolaos Theologitis; Dimitris Sacharidis; Giorgos Giannopoulos; Dimitrios Tomaras; Kleopatra Markou; Dimitrios Gunopulos; Dimitris Fotakis; Ioannis Emiris
- Reference count: 40
- Primary result: GLANCE achieves up to 100% effectiveness with significantly reduced costs compared to existing methods, producing interpretable action sets of only 3 actions versus hundreds of micro-actions in other approaches

## Executive Summary
GLANCE addresses the challenge of generating global counterfactual explanations that are both effective and interpretable. The method uses an agglomerative clustering approach that jointly considers feature space and action space to produce compact sets of counterfactual actions. By iteratively merging clusters based on combined distance metrics, GLANCE balances three competing objectives: effectiveness (ability to reverse unfavorable predictions), cost (magnitude of changes required), and interpretability (number of distinct actions).

The framework introduces three algorithmic variants: Iterative Merges for balanced optimization, Augmented Space for cost-focused explanations, and Counterfactual Tree for creating interpretable partitions. Experiments across four datasets and three model types demonstrate that GLANCE consistently outperforms state-of-the-art methods (GLOBE-CE and CET) by achieving higher effectiveness with lower cost while maintaining fewer actions.

## Method Summary
GLANCE generates global counterfactual explanations through a two-phase process: initial clustering and iterative merging. The method first clusters instances using k-means in feature space, then generates counterfactual actions for each cluster using the DiCE library. These initial clusters and actions serve as input to one of three GLANCE algorithms: Iterative Merges, Augmented Space, or Counterfactual Tree. Each algorithm merges clusters based on distance metrics in feature space and action space, producing a final set of clusters with representative actions. The merging process continues until no further Pareto improvements can be made, resulting in explanations that are both effective and interpretable.

## Key Results
- GLANCE achieves up to 100% effectiveness while significantly reducing costs compared to baseline methods
- The method produces compact action sets (average of 3 actions) versus hundreds of micro-actions in existing approaches
- GLANCE consistently dominates state-of-the-art methods (GLOBE-CE and CET) across multiple datasets and model types
- The Augmented Space algorithm variant shows particular strength in minimizing costs while maintaining high effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GLANCE achieves higher effectiveness with fewer actions by leveraging agglomerative clustering in both feature and action spaces
- Mechanism: The algorithm iteratively merges clusters based on combined distance metrics (feature space centroid distance + action space centroid distance), preserving effective actions while reducing total count
- Core assumption: Similar instances can be explained by similar actions, and similar actions can be replaced by a single action with minimal impact on cost and effectiveness
- Evidence anchors:
  - [abstract] "employ a novel agglomerative approach, jointly considering both the feature space and the space of counterfactual actions"
  - [section 4] "The core idea is to establish multiple small clusters and determine representative actions for each"
  - [corpus] Weak evidence - no direct mentions of GLANCE in corpus
- Break condition: If the distance metrics don't capture meaningful similarity, merging clusters could eliminate actions that are actually effective for distinct populations

### Mechanism 2
- Claim: The Augmented Space algorithm prioritizes cost reduction by mapping instances to their minimum-cost effective actions
- Mechanism: Each instance is augmented with its minimum-cost effective action, then reclustered in this augmented space to preserve low-cost solutions
- Core assumption: For each instance, there exists at least one action that flips its prediction to positive
- Evidence anchors:
  - [section 4] "The second algorithm, named Augmented Space and described in Algorithm 2, adopts a strategy focused on optimizing the cost metric"
  - [algorithm 2 description] "concatenates each instance with its minimum-cost effective action"
  - [corpus] Weak evidence - no direct mentions of GLANCE in corpus
- Break condition: If no cluster action flips the class of an instance, the feature vector becomes all zeros, potentially degrading clustering quality

### Mechanism 3
- Claim: The Counterfactual Tree algorithm creates interpretable partitions by recursively splitting on features that maximize effectiveness improvement
- Mechanism: Starting with all affected instances, the algorithm generates actions for each potential split and selects the feature that yields the highest average effectiveness improvement
- Core assumption: Splitting on features that maximize effectiveness improvement will create partitions where each subset has actions that are highly effective for that subset
- Evidence anchors:
  - [section 5] "This algorithm starts with a single cluster containing all affected instances and recursively divides it into smaller clusters defined by subsets of the input features"
  - [algorithm 3 description] "The decision to split is determined by comparing the actions of the parent node with those of the child nodes"
  - [corpus] Weak evidence - no direct mentions of GLANCE in corpus
- Break condition: If no split produces actions better than the parent node, the algorithm terminates, potentially missing finer-grained partitions

## Foundational Learning

- Concept: Pareto dominance in multi-objective optimization
  - Why needed here: GLANCE must balance three competing objectives (effectiveness, cost, and number of actions), and Pareto dominance provides a principled way to compare solutions
  - Quick check question: If solution A has higher effectiveness, lower cost, and fewer actions than solution B, what is the relationship between A and B under Definition 3?

- Concept: Counterfactual explanations and algorithmic recourse
  - Why needed here: The entire framework is built around finding actions that reverse unfavorable predictions, so understanding the basics of counterfactual explanations is essential
  - Quick check question: What is the definition of an action being "effective" for an instance in this context?

- Concept: Agglomerative clustering and distance metrics
  - Why needed here: GLANCE uses agglomerative clustering twice (once in feature space, once in augmented space), so understanding how clustering works and how distance metrics affect results is crucial
  - Quick check question: How does the combined distance metric (feature space + action space) influence which clusters get merged first?

## Architecture Onboarding

- Component map: Data preprocessing pipeline -> Model training module (XGBoost, Logistic Regression, DNN) -> Local counterfactual generator (DiCE) -> Clustering engine (k-means implementation) -> GLANCE core algorithms (Iterative Merges, Augmented Space, Counterfactual Tree) -> Evaluation framework (effectiveness, cost, dominance calculations)

- Critical path: Local counterfactual generation → Initial clustering → GLANCE algorithm execution → Result evaluation → Dominance comparison with baselines

- Design tradeoffs:
  - Number of initial clusters (k) vs. computational cost
  - Sampling method for counterfactuals ("centroid" vs. "sampling") vs. action diversity
  - Distance metric choice vs. cluster quality
  - Number of final clusters vs. interpretability

- Failure signatures:
  - Very high runtime → Check clustering parameters and number of counterfactuals generated
  - Low effectiveness → Verify counterfactual generation is working correctly
  - High cost despite few actions → Check that minimum-cost actions are being selected in augmented space

- First 3 experiments:
  1. Run Iterative Merges on HELOC dataset with DNN model using default parameters to verify basic functionality
  2. Compare effectiveness and cost between Iterative Merges and Augmented Space on German Credit dataset
  3. Test Counterfactual Tree with 4 leaves on COMPAS dataset to validate partitioning behavior

## Open Questions the Paper Calls Out
None

## Limitations
- Cluster initialization sensitivity: Results may vary across runs due to k-means initialization using random centroids
- Distance metric assumptions: The combined distance metric assumes feature and action spaces are equally important and commensurable
- Pareto dominance assumptions: The effectiveness of GLANCE relies on correctly identifying Pareto-optimal solutions without addressing conflicting trade-offs

## Confidence

**High confidence** in: The core agglomerative clustering mechanism and the three algorithm variants (Iterative Merges, Augmented Space, Counterfactual Tree) are technically sound and implementable as described.

**Medium confidence** in: The claimed performance improvements over baselines, as the paper doesn't provide statistical significance testing or confidence intervals for the reported metrics.

**Medium confidence** in: The interpretability benefits, since while the method produces fewer actions, the paper doesn't include human studies to validate that these explanations are actually more interpretable to end-users.

## Next Checks

1. **Statistical significance testing**: Run GLANCE and baseline methods multiple times with different random seeds and perform paired t-tests to verify that performance differences are statistically significant rather than due to initialization randomness.

2. **Parameter sensitivity analysis**: Systematically vary the number of initial clusters (k) and the sampling method parameters to understand how sensitive the final explanations are to these hyperparameters.

3. **Real-world deployment validation**: Implement GLANCE on a new dataset (not in the paper) and measure not just the three reported metrics but also runtime efficiency and ease of implementation to assess practical deployment considerations.