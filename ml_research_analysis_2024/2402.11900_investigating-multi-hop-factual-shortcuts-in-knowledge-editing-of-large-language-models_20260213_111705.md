---
ver: rpa2
title: Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language
  Models
arxiv_id: '2402.11900'
source_url: https://arxiv.org/abs/2402.11900
tags:
- knowledge
- multi-hop
- shortcuts
- uni00000013
- editing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates factual shortcuts in large language models
  (LLMs) when answering multi-hop questions. The authors analyze whether LLMs rely
  on direct associations between initial and terminal entities in multi-hop knowledge,
  bypassing intermediate reasoning steps.
---

# Investigating Multi-Hop Factual Shortcuts in Large Language Models

## Quick Facts
- arXiv ID: 2402.11900
- Source URL: https://arxiv.org/abs/2402.11900
- Authors: Tianjie Ju; Yijin Chen; Xinwei Yuan; Zhuosheng Zhang; Wei Du; Yubin Zheng; Gongshen Liu
- Reference count: 23
- Key outcome: This paper investigates factual shortcuts in LLMs when answering multi-hop questions, finding they're prevalent and correlated with entity co-occurrence frequency, and proposes neuron erasure to mitigate editing failures.

## Executive Summary
This paper investigates factual shortcuts in large language models (LLMs) when answering multi-hop questions, where models bypass intermediate reasoning steps by directly associating initial and terminal entities. The authors find that these shortcuts are strongly correlated with entity co-occurrence frequency in pre-training corpora and cause significant failures in multi-hop knowledge editing. Using knowledge neurons, they demonstrate that few-shot prompting leverages more shortcuts than chain-of-thought prompting. The paper proposes erasing shortcut neurons as an effective mitigation strategy, significantly reducing knowledge editing failures caused by shortcuts.

## Method Summary
The authors analyze factual shortcuts by computing co-occurrence frequencies of initial and terminal entities in pre-training corpora (Wikipedia and Dolma), then use knowledge neurons with integral gradients to quantify shortcut usage in different prompting strategies. They evaluate knowledge editing failures across multiple methods (MEND, ROME, MEMIT) and categorize failures into single-hop, shortcut, and other types. The proposed mitigation approach involves identifying and erasing neurons associated with high-co-occurrence shortcuts, then measuring improvements in knowledge editing success rates.

## Key Results
- Factual shortcuts are highly prevalent, with ~20% of knowledge editing failures attributed to shortcuts
- Few-shot prompting leverages more shortcuts compared to chain-of-thought prompting
- Co-occurrence frequency between initial and terminal entities strongly correlates with shortcut strength (Pearson Coefficient 0.74 with Dolma corpus)
- Neuron erasure of shortcut-associated neurons significantly reduces multi-hop knowledge editing failures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Factual shortcuts are strongly correlated with the frequency of co-occurrence of initial and terminal entities in pre-training corpora
- Mechanism: During pre-training, when initial subject (s1) and terminal object (on) of a multi-hop fact appear together frequently, the model learns a direct association between them, bypassing intermediate reasoning steps
- Core assumption: LLMs form direct associations between frequently co-occurring entities during pre-training, creating shortcut pathways
- Evidence anchors: Strong correlation found between Wikipedia and Dolma corpus co-occurrence frequencies (Pearson Coefficient 0.74); s1 and on co-occurrence within same paragraph suggests direct connection formation

### Mechanism 2
- Claim: Few-shot prompting leverages more factual shortcuts compared to chain-of-thought prompting in multi-hop question answering
- Mechanism: Few-shot prompts provide demonstrations without explicitly guiding through intermediate reasoning steps, allowing shortcuts to be used. Chain-of-thought prompts force explicit step-by-step reasoning, constraining shortcut usage
- Core assumption: The prompt format influences whether the model uses learned shortcuts or performs explicit reasoning
- Evidence anchors: Knowledge Neuron analysis shows few-shot leverages more shortcuts than chain-of-thought; LLM adheres more to single-hop reasoning patterns under chain-of-thought prompts

### Mechanism 3
- Claim: Erasing neurons associated with factual shortcuts reduces failures in multi-hop knowledge editing caused by shortcuts
- Mechanism: By identifying and nullifying neurons that store shortcut associations (based on integral gradient attribution), the model can no longer use these direct paths and must rely on correct multi-hop reasoning paths
- Core assumption: Factual shortcuts are stored in specific neurons that can be identified and modified without catastrophic loss of other knowledge
- Evidence anchors: Proposed erasing shortcut neurons for instances with co-occurrence >10; this approach significantly reduces failures in multiple-hop knowledge editing caused by shortcuts

## Foundational Learning

- Concept: Multi-hop reasoning
  - Why needed here: The paper investigates whether LLMs can perform true multi-hop reasoning or rely on shortcuts. Understanding what constitutes multi-hop reasoning is essential to grasp the problem
  - Quick check question: Given the fact chain "Paris is in France, France is in Europe," what is the multi-hop answer to "What continent is Paris in?" and what would be a shortcut answer?

- Concept: Knowledge neurons and attribution methods
  - Why needed here: The paper uses Knowledge Neurons (Dai et al., 2022) and integral gradients to identify which neurons store knowledge and shortcuts. This technique is central to their analysis
  - Quick check question: How does the integral gradient method identify important neurons, and what threshold is used in this paper to consider a neuron "crucial"?

- Concept: Knowledge editing in LLMs
  - Why needed here: The paper analyzes how factual shortcuts create problems in knowledge editing scenarios where intermediate facts are updated but shortcuts persist with outdated information
  - Quick check question: If you edit the fact "Tokyo is in Japan" to "Tokyo is in a fictional country," what would happen to answers about Tokyo's continent if shortcuts exist?

## Architecture Onboarding

- Component map: Pre-training corpus analysis (Wikipedia, Dolma) -> Knowledge neuron identification system (integral gradients) -> Multi-hop question-answering pipeline -> Knowledge editing evaluation framework -> Neuron erasure implementation

- Critical path: 1. Identify multi-hop knowledge instances with high s1-on co-occurrence 2. Use Knowledge Neurons to quantify shortcut usage in different prompting strategies 3. Analyze knowledge editing failures attributed to shortcuts 4. Erase identified shortcut neurons and measure improvement

- Design tradeoffs: Using Wikipedia/Dolma as proxy corpora vs. actual pre-training data (accuracy vs. feasibility); Few-shot vs. chain-of-thought prompting (natural language flow vs. explicit reasoning); Selective neuron erasure vs. complete model retraining (targeted intervention vs. comprehensive solution)

- Failure signatures: High s1-on co-occurrence with low reasoning overlap in Knowledge Neuron analysis; Knowledge editing failures where answers match pre-edit values despite intermediate edits; Low success rates in multi-hop knowledge editing (only 10-20% success reported)

- First 3 experiments: 1. Replicate the co-occurrence frequency analysis on Wikipedia for a subset of multi-hop instances to verify shortcut prevalence 2. Implement Knowledge Neuron analysis comparing few-shot vs chain-of-thought prompting on a small model 3. Test neuron erasure on a simple two-hop example (like Olympic Games example) to verify the mechanism works as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the relationship between the frequency of factual shortcuts and the depth of multi-hop reasoning chains?
- Basis in paper: Explicit
- Why unresolved: The paper investigates two-hop, three-hop, and four-hop questions but does not analyze whether the prevalence of shortcuts increases with the depth of reasoning chains
- What evidence would resolve it: Analyzing the frequency of shortcuts across different hop depths and correlating it with co-occurrence statistics would show if deeper chains have more or fewer shortcuts

### Open Question 2
- Question: How do factual shortcuts impact the generalizability of LLMs to novel multi-hop questions?
- Basis in paper: Inferred
- Why unresolved: While the paper shows that shortcuts cause failures in knowledge editing, it does not investigate whether shortcuts limit the LLM's ability to generalize to unseen multi-hop questions that require genuine reasoning
- What evidence would resolve it: Testing LLM performance on novel multi-hop questions where shortcuts cannot be applied, and comparing results with those on questions where shortcuts are available, would reveal the impact on generalization

### Open Question 3
- Question: Can the pre-training process be modified to reduce the formation of factual shortcuts without sacrificing overall performance?
- Basis in paper: Inferred
- Why unresolved: The paper proposes erasing shortcut neurons post-training but does not explore whether architectural or algorithmic changes during pre-training could prevent shortcut formation in the first place
- What evidence would resolve it: Experimenting with pre-training modifications such as curriculum learning, data augmentation, or architectural changes to encourage step-by-step reasoning would determine if shortcuts can be minimized during training

## Limitations

- Corpus Validity: The paper uses Wikipedia and Dolma as proxies for pre-training corpora to measure co-occurrence frequencies, but these may not match the actual pre-training data used for the LLMs, introducing uncertainty about whether observed correlations generalize to the true pre-training corpus.

- Knowledge Neuron Attribution: The integral gradient method used to identify shortcut neurons relies on attribution thresholds (v=0.1) that may be sensitive to the specific value chosen, and the paper doesn't provide systematic sensitivity analysis for these architectural choices.

- Editing Method Variability: The paper tests multiple knowledge editing methods (MEND, ROME, MEMIT) but reports mixed results, with ROME showing worse performance than MEMIT/MEND in multi-hop scenarios, and the reasons for these differences are not fully explored.

## Confidence

- High Confidence: The observation that factual shortcuts exist and can cause knowledge editing failures is well-supported by the experimental evidence. The correlation between co-occurrence frequency and shortcut usage is statistically significant across multiple datasets.

- Medium Confidence: The claim that few-shot prompting leverages more shortcuts than chain-of-thought prompting is supported by knowledge neuron analysis, but this relies on the assumption that neuron attribution accurately reflects reasoning patterns. The effectiveness of neuron erasure in reducing editing failures is demonstrated, but the long-term stability and potential side effects are not evaluated.

- Low Confidence: The specific quantitative claims about the proportion of editing failures caused by shortcuts (~20%) depend heavily on the particular dataset and models used, and may not generalize to other domains or model architectures.

## Next Checks

1. **Corpus Validation Study**: Replicate the co-occurrence frequency analysis using multiple proxy corpora (including the actual pre-training corpus if available) to verify that the correlation between co-occurrence and shortcut usage is robust across different data sources.

2. **Attribution Sensitivity Analysis**: Systematically vary the integral gradient threshold (v=0.05, 0.1, 0.2) and neuron attribution methods to assess how sensitive the shortcut detection and neuron erasure results are to these methodological choices.

3. **Cross-Domain Generalization Test**: Apply the shortcut analysis and neuron erasure method to a different multi-hop reasoning domain (e.g., scientific reasoning or mathematical problem-solving) to evaluate whether the findings generalize beyond factual knowledge editing.