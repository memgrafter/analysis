---
ver: rpa2
title: Asymptotics of Learning with Deep Structured (Random) Features
arxiv_id: '2402.13999'
source_url: https://arxiv.org/abs/2402.13999
tags:
- random
- feature
- learning
- networks
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a precise asymptotic characterization of the
  test error for ridge regression with Lipschitz feature maps, including deep structured
  random features. The authors derive a deterministic equivalent for the generalization
  error in terms of the population covariance of the features, applicable when input
  dimension, hidden layer widths, and number of training samples grow proportionally.
---

# Asymptotics of Learning with Deep Structured (Random) Features

## Quick Facts
- arXiv ID: 2402.13999
- Source URL: https://arxiv.org/abs/2402.13999
- Reference count: 40
- One-line primary result: Provides asymptotic characterization of ridge regression test error for deep structured random features in high-dimensional regime.

## Executive Summary
This paper provides a precise asymptotic characterization of the test error for ridge regression with Lipschitz feature maps, including deep structured random features. The authors derive a deterministic equivalent for the generalization error in terms of the population covariance of the features, applicable when input dimension, hidden layer widths, and number of training samples grow proportionally. For Gaussian rainbow networks (deep random networks with structured weights), they derive closed-form expressions for the feature covariance in terms of the weight matrices. The theory is validated through numerical experiments showing good agreement with both random and trained network features, including some real-world datasets. The work bridges the gap between random features at initialization and trained networks by introducing linearization techniques for population covariances, providing insights into the inductive bias of deep networks in the high-dimensional regime.

## Method Summary
The paper characterizes ridge regression test error asymptotically by deriving a deterministic equivalent for the resolvent G(λ) in terms of the population covariance Ω of the features. This is achieved through self-consistent equations for the Stieltjes transform m(λ), which depends only on the eigenvalues of Ω. For Gaussian rainbow networks, the authors recursively linearize population covariances using Wiener chaos expansions and Stein's method, yielding closed-form recursions in terms of the weight matrices. The framework extends to trained networks in the lazy regime by approximating the feature map as a stochastic linear model with effective weight matrix and noise covariance.

## Key Results
- Asymptotic test error characterization for ridge regression on Lipschitz feature maps in high-dimensional regime
- Closed-form formulas for population covariances of Gaussian rainbow networks with structured weights
- Validation on synthetic and real-world datasets showing good agreement between theory and experiment
- Framework extends to trained networks in lazy regime via linearization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The test error can be characterized asymptotically using a deterministic equivalent of the resolvent G(λ) in terms of the population covariance Ω.
- Mechanism: The authors derive a self-consistent equation (8) for m(λ), which depends only on the eigenvalues of Ω, and use it to construct M(λ) as a deterministic proxy for G(λ). This proxy is then used in closed-form expressions for the generalization error that remain valid in the high-dimensional limit.
- Core assumption: Feature maps φ are Lipschitz-continuous and the feature covariances have uniformly bounded spectral norm; inputs and features are sub-Gaussian.
- Evidence anchors:
  - [abstract] "This characterization is formulated in terms of the population covariance of the features."
  - [section] "Our main result is a rigorous asymptotic expression for Eq. (7)."
- Break condition: If the Lipschitz or sub-Gaussian assumptions fail, the concentration bounds used to justify the deterministic equivalent no longer hold, and the asymptotic formula becomes invalid.

### Mechanism 2
- Claim: Gaussian rainbow networks with structured weights can be linearized into an equivalent stochastic linear network with the same second moments.
- Mechanism: The authors recursively define linearized population covariances Ωlinℓ, Φlinℓ, Ψlinℓ that approximate the true covariances of the post-activations. This linearization is justified by Wiener chaos expansions and Stein's method, yielding a closed-form recursion in terms of the weight matrices.
- Core assumption: The rows of the weight matrices are sub-Gaussian with bounded covariances, and the network is sufficiently deep for the linearization to converge.
- Evidence anchors:
  - [abstract] "For such networks we also derive a closed-form formula for the feature covariance in terms of the weight matrices."
  - [section] "The linearization itself only involves products of the weights matrices, and coefficient depending on weight covariances which can straightforwardly be estimated therefrom."
- Break condition: If the weight matrices have unbounded spectral norms or if the activation functions are not smooth enough, the linearization step fails and the covariance recursion no longer approximates the true covariances.

### Mechanism 3
- Claim: The deterministic equivalent generalizes beyond random features to trained networks in the lazy regime, provided the feature map is effectively linear.
- Mechanism: The authors observe that in the lazy regime, the trained network's feature map can be approximated by a stochastic linear map with an effective weight matrix Weff and noise covariance Ceff. These are constructed from the trained weights, and ridge regression on this linearized model yields a generalization error that matches numerical experiments.
- Core assumption: The network is trained in a regime where the feature map is approximately linear (i.e., the NTK limit), and the linearization of the population covariance holds.
- Evidence anchors:
  - [abstract] "We further find that in some cases our results can capture feature maps learned by deep, finite-width neural networks trained under gradient descent."
  - [section] "The linearization itself only involves products of the weights matrices, and coefficient depending on weight covariances which can straightforwardly be estimated therefrom."
- Break condition: If the network leaves the lazy regime (e.g., by aggressive learning rates or strong feature learning), the effective linear model no longer approximates the true feature map, and the deterministic equivalent fails.

## Foundational Learning

- Concept: Marchenko-Pastur law for sample covariance matrices
  - Why needed here: It provides the foundation for approximating the resolvent G(λ) with a deterministic matrix M(λ), which is central to the asymptotic characterization of the test error.
  - Quick check question: Can you write down the Stieltjes transform equation for a Marchenko-Pastur distribution and explain its role in approximating G(λ)?

- Concept: Leave-one-out identities in random matrix theory
  - Why needed here: These identities allow the authors to decouple the randomness of individual samples and derive self-consistent equations for the resolvent and its moments, which are essential for the anisotropic Marchenko-Pastur law.
  - Quick check question: How does the leave-one-out resolvent G−i relate to the full resolvent G, and what concentration properties does this relationship enable?

- Concept: Wiener chaos expansion for Gaussian random variables
  - Why needed here: It is used to linearize the population covariances of Gaussian rainbow networks by decomposing non-linear functions of Gaussian inputs into orthogonal components, enabling the closed-form recursion.
  - Quick check question: In a Wiener chaos expansion, what is the relationship between the Hermite polynomials and the multiple integrals Ip, and how does this help in approximating E f(Wx)g(Vx)⊤?

## Architecture Onboarding

- Component map: Data generation (x_i, y_i) -> Feature map φ(x) -> Ridge regression -> Compute test error -> Compare with theoretical prediction
- Critical path: The bottleneck is computing or estimating the feature population covariances, especially for deep networks. For random features this is analytic; for trained networks it requires Monte Carlo estimation from data.
- Design tradeoffs: One can trade off depth of the student network against the complexity of the covariance linearization; deeper networks give richer feature maps but make linearization harder. Another tradeoff is between the generality of the Lipschitz assumption and the tightness of concentration bounds.
- Failure signatures: Poor agreement between theory and experiment often signals violation of sub-Gaussian or bounded spectral norm assumptions, or that the network is no longer in the lazy regime. Large eigenvalues in weight matrices can also break the linearization.
- First 3 experiments:
  1. Implement a two-layer random feature model with Gaussian weights, compute the exact population covariance, and verify the closed-form test error matches empirical ridge regression on synthetic data.
  2. Extend to a three-layer Gaussian rainbow network with correlated weights, linearize the population covariances using the recursion, and compare the theoretical and empirical learning curves.
  3. Train a finite-width ReLU network in the lazy regime, extract the feature map, estimate its population covariance from data, and check whether the linearized deterministic equivalent predicts the test error.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what precise conditions does the linearization approximation of population covariances (Theorem 4.4) extend beyond two-layer networks to deeper architectures?
- Basis in paper: [explicit] The authors state in Section B.6 that "we leave the extension to L, rL ≥ 3 as an interesting open question" and note that "it seems hard to apply Theorem B.10 to the d-dimensional vector" for deeper networks.
- Why unresolved: The proof technique relies on applying the multivariate version of Stein's method (Theorem B.10) to 2-dimensional vectors, but extending to d-dimensional vectors requires "much more careful error analysis" that the authors haven't completed.
- What evidence would resolve it: A rigorous proof demonstrating that the linearization approximation holds with high probability for population covariances at any depth L ≥ 3, or alternatively, a counterexample showing where the approximation breaks down.

### Open Question 2
- Question: What are the boundaries of applicability for the Gaussian rainbow framework in capturing the generalization performance of trained neural networks?
- Basis in paper: [explicit] The authors note in the "Limitations" section that "understanding the boundaries of applicability of the Gaussian rainbow framework (and hence of our theory) is an interesting problem" and reference recent work on single-step training approximations.
- Why unresolved: While the framework captures performance well for some trained networks in lazy regimes, the paper acknowledges this "only captures a subset of neural networks" without precisely characterizing which networks or training regimes fall outside its scope.
- What evidence would resolve it: Systematic experiments across different architectures, training regimes, and datasets identifying specific conditions (e.g., depth, width, activation functions, training algorithms) where the framework fails to predict generalization performance.

### Open Question 3
- Question: How does the effective anisotropic regularization in the linearized model (Section 5) quantitatively relate to the inductive bias learned by trained networks in high-dimensional regimes?
- Basis in paper: [explicit] The authors observe that trained networks "can still encode very different biases, yielding different phenomenology" and note that "the interplay between these two matrices – both depending on the weights ˆWℓ – defines the inductive bias of the trained network in the high-dimensional regime."
- Why unresolved: While the paper provides a heuristic interpretation of trained networks as stochastic linear models with effective weight matrices Weff. and covariance Ceff., it doesn't quantify how these matrices encode inductive bias or provide a framework for comparing biases across different training procedures.
- What evidence would resolve it: Mathematical characterization of how Weff. and Ceff. evolve during training, and empirical validation showing that networks with similar Weff./Ceff. configurations exhibit similar generalization behaviors across different tasks.

## Limitations
- Requires input dimension, hidden layer widths, and training sample size to grow proportionally (β = p/n → β_∞)
- Relies on feature covariances having uniformly bounded spectral norm
- Linearization technique requires sub-Gaussian weight matrices with controlled covariances
- Extension to trained networks assumes lazy regime with minimal feature learning

## Confidence
- High: Asymptotic characterization for Lipschitz feature maps with sub-Gaussian inputs and bounded spectral norm assumptions.
- Medium: Closed-form expressions for Gaussian rainbow networks and their linearization.
- Medium: Extension to trained networks in the lazy regime.

## Next Checks
1. **Robustness to Assumption Violations**: Test the deterministic equivalent formula when weight matrices have a few large eigenvalues or when the feature maps exhibit heavy-tailed behavior, quantifying the breakdown of the asymptotic predictions.

2. **Depth Sensitivity**: Vary the depth of Gaussian rainbow networks and measure how well the linearization of population covariances approximates the true covariances, especially for deep architectures where higher-order terms may become significant.

3. **Lazy vs. Feature-Learning Regime**: Train finite-width ReLU networks with varying learning rates and model capacities, and systematically compare the performance of the linearized deterministic equivalent against empirical test errors to delineate the boundary of the lazy regime.