---
ver: rpa2
title: 'ComFairGNN: Community Fair Graph Neural Network'
arxiv_id: '2411.04371'
source_url: https://arxiv.org/abs/2411.04371
tags:
- fairness
- graph
- node
- nodes
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ComFairGNN, a community-level graph neural
  network fairness framework that addresses structural bias in GNN neighborhood aggregation.
  The key idea is to sample coreset nodes from different communities based on neighborhood
  homophily distribution ratios and optimize embedding similarity between nodes with
  identical labels across communities.
---

# ComFairGNN: Community Fair Graph Neural Network

## Quick Facts
- **arXiv ID**: 2411.04371
- **Source URL**: https://arxiv.org/abs/2411.04371
- **Reference count**: 40
- **Primary result**: Achieves near-zero fairness metrics (ΔSP and ΔEO) while maintaining high accuracy across three real-world datasets, outperforming existing methods

## Executive Summary
This paper introduces ComFairGNN, a community-level graph neural network fairness framework that addresses structural bias in GNN neighborhood aggregation. The key idea is to sample coreset nodes from different communities based on neighborhood homophily distribution ratios and optimize embedding similarity between nodes with identical labels across communities. The method uses a learnable debiasing function that balances local neighborhood distributions to mitigate structural bias. Experiments on three real-world datasets (Pokec-z, Pokec-n, and Facebook) show ComFairGNN achieves fairness metrics (ΔSP and ΔEO) close to zero while maintaining high accuracy, outperforming existing methods like FairGNN, NIFTY, and UGE.

## Method Summary
ComFairGNN addresses community-level structural bias in GNNs by first clustering nodes into communities using node2vec embeddings and k-means. For each community, it samples coreset nodes based on neighborhood homophily distribution ratios from both sensitive attribute groups. The model then optimizes a combined loss function that includes both classification loss and a fairness loss that maximizes similarity between coreset nodes with identical labels but different community memberships. This approach effectively balances local neighborhood distributions and mitigates structural bias that traditional graph-level methods miss.

## Key Results
- ComFairGNN achieves ΔSP and ΔEO values close to zero on Pokec-z, Pokec-n, and Facebook datasets
- Maintains high accuracy (ACC) and AUC metrics comparable to or better than baseline methods
- Outperforms existing fairness methods (FairGNN, NIFTY, UGE) on community-level fairness evaluation
- Reveals fairness paradoxes at community level that are masked by traditional graph-level metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Community-level evaluation reveals fairness paradoxes masked by traditional graph-level metrics.
- Mechanism: By clustering nodes based on structural embeddings and measuring fairness within each community, the method uncovers local disparities that global fairness metrics average out.
- Core assumption: Community structure in real-world graphs correlates with sensitive attributes, creating localized structural bias.
- Evidence anchors:
  - [abstract] "community-level evaluation reveals fairness paradoxes masked by traditional graph-level metrics"
  - [section 3.1] "We first design a strategy of communities using a clustering algorithm based on structural contrast"
  - [corpus] Weak - corpus neighbors focus on counterfactual and disentanglement approaches, not community-level evaluation
- Break condition: If community clustering fails to capture meaningful structural groups, or if communities are not correlated with sensitive attributes.

### Mechanism 2
- Claim: Coreset sampling from diverse neighborhood homophily distributions balances structural bias across communities.
- Mechanism: Selecting coreset nodes from both extremes of the homophily ratio distribution ensures representative samples from high and low bias areas, allowing the debiasing function to address structural disparities.
- Core assumption: Nodes with identical labels but different neighborhood homophily distributions will have different embeddings after GNN aggregation.
- Evidence anchors:
  - [abstract] "sample coreset nodes from different communities based on neighborhood homophily distribution ratios"
  - [section 3.2] "coreset nodes are sampled based on their neighborhood distribution from all communities of the graph"
  - [section 3.2] "We select top and bottom 15 sample homophily neighborhood distribution ratio from each community"
- Break condition: If neighborhood homophily is not correlated with bias, or if the selected coreset is not representative of the community diversity.

### Mechanism 3
- Claim: Contrastive loss on coreset nodes with identical labels but different community memberships improves embedding similarity and reduces structural bias.
- Mechanism: By maximizing similarity between coreset nodes with the same label across different communities, the model implicitly learns to produce similar embeddings for identical nodes regardless of community membership.
- Core assumption: The embedding space can be adjusted through contrastive learning to make identical label nodes from different communities more similar.
- Evidence anchors:
  - [abstract] "optimize embedding similarity between nodes with identical labels across communities"
  - [section 3.1] "contrast the output similarity of nodes with the same label in the coreset"
  - [section 3.3] "similarity-based loss, trying to achieve parity in the average pairwise similarities for the two label groups"
- Break condition: If the contrastive loss is not effective in bridging the embedding gap, or if the model overfits to the coreset samples.

## Foundational Learning

- Concept: Graph Neural Networks and neighborhood aggregation
  - Why needed here: ComFairGNN is built on top of any neighborhood aggregation-based GNN architecture, so understanding how GNNs aggregate information is crucial.
  - Quick check question: How does the neighborhood aggregation in a two-layer GCN differ from a one-layer GCN in terms of receptive field and potential for bias amplification?

- Concept: Community detection and structural clustering
  - Why needed here: The method relies on clustering nodes into communities based on structural similarities to identify local structural bias.
  - Quick check question: What are the differences between community detection based on structural embeddings (node2vec + k-means) and community detection based on attribute similarity?

- Concept: Group fairness metrics (Demographic Parity and Equal Opportunity)
  - Why needed here: The evaluation of ComFairGNN's effectiveness relies on these fairness metrics, and understanding their limitations is key to interpreting the results.
  - Quick check question: How do Demographic Parity and Equal Opportunity differ in their treatment of true positives and false positives, and what are the implications for fairness evaluation in imbalanced datasets?

## Architecture Onboarding

- Component map:
  - Community detection module: Uses node2vec embeddings and k-means clustering to partition the graph into communities
  - Coreset selection module: Samples nodes from each community based on neighborhood homophily distribution ratios
  - GNN backbone: Any neighborhood aggregation-based GNN (e.g., GCN) for node representation learning
  - Debiasing module: Implements a contrastive loss on coreset nodes to balance embedding similarity across communities
  - Loss function: Combines task loss (cross-entropy for node classification) and fairness loss (contrastive similarity loss)

- Critical path:
  1. Input graph and node features
  2. Community detection to identify structural groups
  3. Coreset selection from each community based on homophily distribution
  4. GNN forward pass to generate node embeddings
  5. Calculate task loss and fairness loss on coreset nodes
  6. Backpropagation to update model parameters
  7. Repeat steps 4-6 for multiple epochs

- Design tradeoffs:
  - Community detection granularity: Finer-grained communities may capture more localized bias but increase computational cost and potential for overfitting
  - Coreset size and selection strategy: Larger coresets provide more representative samples but increase computational cost; selecting from extremes of homophily distribution ensures diversity but may miss intermediate cases
  - Contrastive loss formulation: Different similarity metrics (e.g., cosine vs. Euclidean) may have different effects on embedding space geometry

- Failure signatures:
  - Model performance degrades significantly on certain communities while improving on others
  - Fairness metrics improve on the overall graph but worsen on specific communities
  - Coreset selection consistently picks nodes from only a few communities, indicating poor diversity
  - Training loss oscillates or plateaus early, suggesting the contrastive loss is not effective

- First 3 experiments:
  1. Ablation study on coreset selection: Compare random selection, top homophily selection, and bottom homophily selection against the full ComFairGNN approach on a small dataset (e.g., Facebook) to validate the importance of diverse homophily sampling
  2. Community-level fairness analysis: Apply ComFairGNN and a baseline debiasing method (e.g., FairGNN) to Pokec-z and evaluate fairness metrics (ΔSP and ΔEO) within each community to identify potential fairness paradoxes
  3. Sensitivity analysis on coreset size: Vary the number of coreset nodes sampled from each community and observe the effect on both accuracy and fairness metrics to find the optimal trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does community-level structural bias interact with different types of GNN architectures (beyond GCN) such as Graph Attention Networks (GAT) or GraphSAGE?
- Basis in paper: [explicit] The paper states "ComFairGNN works with any neighborhood aggregation-based GNNs" and uses GCN as a backbone, but does not empirically test other architectures
- Why unresolved: The experiments only validate ComFairGNN with GCN as the backbone model, leaving uncertainty about its effectiveness across different GNN architectures
- What evidence would resolve it: Experiments showing ComFairGNN's performance across multiple GNN architectures (GAT, GraphSAGE, etc.) on the same datasets with community-level fairness metrics

### Open Question 2
- Question: What is the optimal size and composition of coreset nodes for maximizing fairness without compromising accuracy?
- Basis in paper: [explicit] The paper discusses coreset selection methods but notes "selecting the coreset at the community level is effective" without determining optimal parameters
- Why unresolved: The paper only compares different coreset selection approaches but does not establish optimal parameters for size or composition across different graph characteristics
- What evidence would resolve it: Systematic ablation studies varying coreset sizes and compositions across diverse graph types, identifying sweet spots for fairness-accuracy trade-offs

### Open Question 3
- Question: How does ComFairGNN perform on graphs with overlapping communities or fuzzy community boundaries?
- Basis in paper: [inferred] The paper assumes clear community structures based on node2vec embeddings and k-means clustering, but real-world graphs often have overlapping communities
- Why unresolved: The evaluation focuses on graphs with well-defined, non-overlapping communities (Pokec-z, Pokec-n, Facebook), which may not represent the complexity of real-world social networks
- What evidence would resolve it: Experiments on datasets with known overlapping communities and metrics measuring performance degradation as community overlap increases

### Open Question 4
- Question: Can the fairness paradoxes identified at the community level be mitigated by hierarchical fairness evaluation approaches?
- Basis in paper: [explicit] The paper identifies that "fairness inconsistencies and paradoxes across various graph communities" and that "absolute measures might dilute these effects"
- Why unresolved: While the paper identifies the problem of fairness paradoxes at the community level, it does not explore potential solutions beyond its ComFairGNN approach
- What evidence would resolve it: Comparative studies of hierarchical fairness evaluation methods that aggregate community-level fairness metrics versus traditional graph-level metrics, showing whether hierarchical approaches better capture local disparities

## Limitations

- Limited to three datasets with binary sensitive attributes, potentially limiting generalizability
- Does not address computational overhead or scalability concerns for large graphs
- Lacks transparency in hyperparameter selection and implementation details, particularly for node2vec parameters and fairness loss computation

## Confidence

- Community-level fairness paradoxes: Medium - the concept is theoretically sound but empirical validation is limited
- Coreset sampling effectiveness: Medium - the method is well-specified but depends heavily on implementation details
- Contrastive loss performance: Medium - the mechanism is plausible but effectiveness varies with hyperparameter choices

## Next Checks

1. Implement ablation studies varying coreset selection strategies to isolate the impact of homophily-based sampling on fairness improvements
2. Conduct community-level fairness analysis on additional datasets with multi-class sensitive attributes to test generalizability
3. Perform runtime and scalability analysis comparing ComFairGNN to baseline methods on graphs of increasing size to understand computational tradeoffs