---
ver: rpa2
title: 'M6(GPT)3: Generating Multitrack Modifiable Multi-Minute MIDI Music from Text
  using Genetic algorithms, Probabilistic methods and GPT Models in any Progression
  and Time Signature'
arxiv_id: '2409.12638'
source_url: https://arxiv.org/abs/2409.12638
tags:
- music
- genetic
- notes
- system
- generating
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: M6(GPT)3 is a symbolic music generation system that uses a GPT
  model to interpret natural language prompts into structured JSON, then generates
  multi-track MIDI compositions via genetic algorithms for melodies and probabilistic
  methods for percussion. Unlike neural-only systems, it avoids reliance on dominant
  musical structures like 4/4 meter.
---

# M6(GPT)3: Generating Multitrack Modifiable Multi-Minute MIDI Music from Text using Genetic algorithms, Probabilistic methods and GPT Models in any Progression and Time Signature

## Quick Facts
- **arXiv ID**: 2409.12638
- **Source URL**: https://arxiv.org/abs/2409.12638
- **Reference count**: 27
- **Primary result**: A hybrid symbolic music generation system combining GPT-based prompt parsing, genetic algorithms for melodies, and probabilistic methods for percussion that outperforms baselines on subjective musical quality metrics while supporting any time signature and chord progression.

## Executive Summary
M6(GPT)3 introduces a novel symbolic music generation system that interprets natural language prompts using GPT-4 to generate structured JSON parameters, then creates multi-track MIDI compositions using genetic algorithms for melodic content and probabilistic methods for percussion. Unlike neural-only approaches, it avoids reliance on dominant musical structures like 4/4 meter, enabling flexible generation across any time signature. The system produces editable symbolic music without requiring large training datasets, addressing limitations of existing neural music generation systems. Human evaluations demonstrate superior performance on richness, memorability, entertainment, emotional conveyance, and inspiration compared to baseline models.

## Method Summary
The system uses GPT-4 to parse text prompts into structured JSON containing song parameters including time signature, scales, chord progressions, and valence-arousal values. Three melodic track types (melody, bass, motif) are generated via genetic algorithms with musically significant mutations and a Gaussian-based fitness function. Percussion generation uses probabilistic methods including Markov chains for fills and probability tables for bass/snare placement across time signatures. The system supports three chord progression modes (Continuous, Repeated, Arpeggio) with emotional parameter influence. All components integrate through the MusPy framework to produce final MIDI compositions.

## Key Results
- Human evaluations show M6(GPT)3 outperforms baseline models on richness/diversity, memorability, entertainment, emotional conveyance, and inspiration metrics
- Objective metrics (pitch class entropy, scale consistency, groove consistency) align closely with real music benchmarks
- The system successfully generates music in any time signature without relying on dominant 4/4 structures
- All code and demos are publicly released to support further research

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-based natural language prompt mapping provides flexible control over composition parameters
- Mechanism: GPT interprets user prompts into structured JSON containing time signature, scales, chord progressions, and valence-arousal values, which control subsequent generative components
- Core assumption: GPT can reliably map diverse natural language prompts to valid musical parameters
- Evidence anchors:
  - [abstract] "The system utilizes an autoregressive transformer language model to map natural language prompts to composition parameters in JSON format."
  - [section] "To generate song structure and parameters, an LLM is used... To obtain the structure in an appropriate form, the model is provided with precise instructions as a system prompt."
  - [corpus] Weak - corpus lacks direct GPT-to-music mapping examples, but MIDI-GPT paper supports feasibility
- Break condition: If GPT fails to interpret musical terms correctly or produces invalid JSON structures

### Mechanism 2
- Claim: Genetic algorithms with musically significant mutations produce expressive and varied melodic content
- Mechanism: Three melodic track types (melody, bass, motif) use encoded note representations with one-point crossover, tournament selection, and mutations like interval creation, transposition, and note extension, optimized by a fitness function based on normal distribution
- Core assumption: The defined musical mutations and fitness metrics capture essential melodic qualities
- Evidence anchors:
  - [abstract] "We propose a genetic algorithm for the generation of melodic elements. The algorithm incorporates mutations with musical significance and a fitness function based on normal distribution..."
  - [section] "We use mutations with musical significance to introduce musical features into melodies... The operations used in our genetic algorithm are: Random initialization, One-point crossover, Tournament selection..."
  - [corpus] Moderate - Genetic algorithms for music are established, but specific mutation definitions are novel
- Break condition: If fitness function weights don't align with perceived musical quality or mutations don't produce desired expressiveness

### Mechanism 3
- Claim: Probabilistic methods enable flexible percussion generation across any time signature
- Mechanism: Binary encoding of 12 percussion components with Markov chains for fills, probability tables for bass/snare placement across time signatures, and emotional parameter influence on hi-hat patterns and ride/cymbal placement
- Core assumption: Drum patterns can be effectively captured by probability distributions and Markov models rather than neural networks
- Evidence anchors:
  - [abstract] "The system for generating percussion in any time signature utilises probabilistic methods, including Markov chains."
  - [section] "To generate songs in odd time signatures, Deep Learning models like Transformers may not be ideal... We opted for a rule-based system incorporating probability and Markov Chains."
  - [corpus] Strong - MIDI-GPT and MIDI-LLM papers confirm probabilistic approaches work for drum generation
- Break condition: If probability tables don't generalize well to uncommon time signatures or Markov chains produce unrealistic fill patterns

## Foundational Learning

- Concept: Genetic algorithms with fitness-based selection
  - Why needed here: Enables evolution of musical sequences toward desired properties without requiring large training datasets
  - Quick check question: How does tournament selection differ from roulette wheel selection in maintaining population diversity?

- Concept: Markov chains for sequential pattern generation
  - Why needed here: Captures transition probabilities between drum states for realistic fill patterns across time signatures
  - Quick check question: What's the difference between first-order and second-order Markov chains for percussion pattern generation?

- Concept: Valence-arousal emotional modeling in music
  - Why needed here: Provides continuous parameters to influence musical features like tempo, dynamics, and note density
  - Quick check question: How would you map valence-arousal values to chord voicing complexity?

## Architecture Onboarding

- Component map: GPT language model → JSON parameter generator → Genetic algorithm module → Melodic tracks → Probabilistic percussion module → Drum tracks → MIDI integration layer → Final composition
- Critical path: GPT → Genetic algorithm → MIDI generation
- Design tradeoffs:
  - Rule-based percussion vs. neural generation: Better time signature flexibility vs. potential for more nuanced patterns
  - Genetic algorithms vs. neural melody generation: Editability and interpretability vs. potentially higher quality
  - Fixed mutation set vs. learned transformations: Predictable behavior vs. adaptability
- Failure signatures:
  - GPT produces invalid JSON: Check prompt engineering and parameter constraints
  - Genetic algorithm converges poorly: Adjust fitness weights or population parameters
  - Percussion patterns sound mechanical: Tune probability tables or Markov chain parameters
- First 3 experiments:
  1. Test GPT parameter generation with simple prompts (e.g., "4/4 pop song") and verify JSON validity
  2. Run genetic algorithm on fixed chord progression with default parameters and listen to melodic output
  3. Generate percussion for 4/4 and 3/4 time signatures and compare pattern diversity and musicality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do M6(GPT)3's generated melodies compare to those from purely neural network-based systems in terms of long-term musical coherence and listener engagement?
- Basis in paper: [explicit] The paper states that M6(GPT)3 offers "a viable alternative to purely neural network-based systems" but does not directly compare melodic coherence or long-term engagement metrics against neural-only systems
- Why unresolved: The study focuses on comparing M6(GPT)3 with specific baseline models (ComposerX and MMT) and MIDICaps data, but lacks direct comparison with state-of-the-art neural-only melody generation systems like Music Transformer or Pop Music Transformer
- What evidence would resolve it: A controlled listening study or objective metric analysis comparing M6(GPT)3 melodies with those generated by leading neural-only melody systems, using metrics like melodic repetition, thematic development, and listener fatigue over multi-minute tracks

### Open Question 2
- Question: What is the computational efficiency of M6(GPT)3 compared to fully neural network-based music generation systems, particularly in terms of real-time generation and resource usage?
- Basis in paper: [inferred] The paper highlights M6(GPT)3's advantage of not requiring "extensive music datasets" and mentions it uses genetic algorithms and probabilistic methods, but does not provide computational benchmarks or comparisons to neural systems
- Why unresolved: The paper focuses on musical quality and flexibility but does not address performance metrics like generation speed, memory usage, or scalability, which are important for practical deployment
- What evidence would resolve it: Benchmarking studies measuring generation time, memory consumption, and latency for M6(GPT)3 versus neural models like MusicLM or MusicGen under identical conditions, including both single-track and multi-track generation scenarios

### Open Question 3
- Question: How does the system handle more complex time signatures beyond 9/8, and what are the limitations of its recursive decomposition approach for very high or irregular meters?
- Basis in paper: [explicit] The paper describes a recursive decomposition method for time signatures beyond 9/8 (e.g., 13/8 splits into 7/8 and 6/8) but does not explore the system's behavior with more complex or irregular meters
- Why unresolved: The evaluation focuses on time signatures up to 9/8, and the paper does not test the limits of the decomposition approach or analyze the musical quality of generated pieces in very complex meters
- What evidence would resolve it: Systematic testing of M6(GPT)3 with time signatures like 11/8, 13/16, or 7/4, including both objective metrics (rhythmic consistency, groove) and subjective listening tests to assess musical coherence and naturalness in these complex meters

## Limitations
- Key implementation details including fitness function weights, mutation probabilities, and probability table values remain underspecified
- Limited human evaluation sample (30 participants, 30 samples) restricts statistical significance and generalizability
- System performance heavily depends on GPT-4's ability to parse natural language prompts, with no systematic evaluation of prompt reliability
- Limited validation of percussion generation claims across complex time signatures beyond common practice

## Confidence
- **High Confidence (4/5)**: GPT-4's ability to map natural language prompts to structured musical parameters is well-supported and technically sound
- **Medium Confidence (3/5)**: Genetic algorithm approach shows theoretical soundness but lacks complete parameter specifications and diverse genre evaluation
- **Low Confidence (2/5)**: Claims about percussion generation in "any time signature" are least substantiated with minimal empirical validation for complex meters

## Next Checks
1. Conduct systematic evaluation of GPT-4's prompt interpretation reliability across 100 diverse prompts, measuring valid JSON output percentage and parameter distribution accuracy
2. Perform ablation study on genetic algorithm components by testing different fitness function weight combinations and mutation probability settings, measuring impact on musical quality metrics and subjective scores
3. Test percussion generation across comprehensive time signatures (4/4, 3/4, 6/8, 5/4, 7/4, 11/8, 13/16) using rhythm analysis metrics and comparison to established drum patterns to assess generalization capability