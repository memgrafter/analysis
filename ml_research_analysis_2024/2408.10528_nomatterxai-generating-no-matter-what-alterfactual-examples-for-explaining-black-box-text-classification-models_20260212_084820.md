---
ver: rpa2
title: 'NoMatterXAI: Generating "No Matter What" Alterfactual Examples for Explaining
  Black-Box Text Classification Models'
arxiv_id: '2408.10528'
source_url: https://arxiv.org/abs/2408.10528
tags:
- words
- word
- text
- such
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NOMATTER XAI, a novel algorithm that generates
  "alterfactual explanations" for black-box text classifiers by replacing irrelevant
  features with semantically opposite words to validate model fairness. The method
  achieves high fidelity (up to 95%) and context preservation (over 90%) across four
  datasets and three transformer models.
---

# NoMatterXAI: Generating "No Matter What" Alterfactual Examples for Explaining Black-Box Text Classification Models

## Quick Facts
- arXiv ID: 2408.10528
- Source URL: https://arxiv.org/abs/2408.10528
- Authors: Tuc Nguyen; James Michels; Hua Shen; Thai Le
- Reference count: 30
- One-line primary result: NOMATTER XAI generates alterfactual examples with up to 95% fidelity and over 90% context preservation while detecting model biases

## Executive Summary
NOMATTER XAI introduces a novel algorithm for generating "alterfactual explanations" that systematically replace irrelevant features in text with semantically opposite words to validate black-box text classifier fairness. Unlike traditional counterfactual explanations that focus on relevant features, NOMATTER XAI targets irrelevant features first, achieving high fidelity (up to 95%) and context preservation (over 90%) across four datasets and three transformer models. Human evaluation confirms users can effectively use these explanations to compare model biases, with the method showing strong correlation between fidelity and gender bias detection.

## Method Summary
NOMATTER XAI generates alterfactual examples by ranking words by importance, selecting least important (irrelevant) features, and greedily replacing them with antonyms or distinct items from the same semantic field using ConceptNet or ChatGPT. The algorithm validates that perturbations maintain prediction stability while maximizing semantic distance from the original. The method is evaluated on four datasets (gender bias, hate speech classification, emotion classification, and toxicity detection) using three transformer models (DistilBERT, BERT, RoBERTa), measuring fidelity, context preservation, runtime, and semantic similarity.

## Key Results
- Achieves high fidelity of up to 95% while preserving context similarity of over 90%
- Successfully detects model biases by correlating fidelity with bias levels
- Outperforms baselines in context preservation while maintaining competitive fidelity rates
- Human evaluation confirms effectiveness in comparing model biases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NOMATTER XAI generates alterfactual examples by systematically replacing irrelevant features with semantically opposite words while maintaining prediction fidelity and context similarity.
- Mechanism: The algorithm ranks words by importance, selects least important (irrelevant) features, and greedily replaces them with antonyms or distinct items from the same semantic field using ConceptNet or ChatGPT. This perturbation maintains model output while maximizing semantic distance from the original.
- Core assumption: Irrelevant features can be identified by their low importance scores (minimal prediction probability drop when removed), and their perturbations won't significantly affect the model's decision boundary.
- Evidence anchors: [abstract]: "Our approach achieves high fidelity of up to 95% while preserving context similarity of over 90%"; [section 4]: "We prioritize perturbing features of lower importance–a.k.a., irrelevant features, first, since their perturbations are less likely to alter the model's prediction probability to the predicted class"

### Mechanism 2
- Claim: Using external knowledge bases (ConceptNet) and LLMs (ChatGPT) enables systematic identification of opposite words that maintain semantic field membership.
- Mechanism: ConceptNet provides structured semantic relationships (antonyms, distinctFrom, hypernym/hyponym) to find words in the same semantic field. ChatGPT leverages contextual understanding to generate grammatically correct antonyms for each word.
- Core assumption: Semantic fields can be reliably identified through ConceptNet relations or LLM understanding, and opposite words within the same semantic field preserve context while maximizing semantic distance.
- Evidence anchors: [section 4]: "We adopt the definition of oppositeness in terms of incompatibility... such opposite words also often share the same semantic field"; [section 4]: "ConceptNet's word relations are notably annotated with numerical weightings... we check for words registered as members of a common set via the /r/DistinctFrom relation"

### Mechanism 3
- Claim: The fidelity of alterfactual examples correlates with model bias detection, where unbiased models yield higher fidelity and biased models yield lower fidelity.
- Mechanism: When perturbing identity words (gender, race terms), unbiased models maintain predictions (high fidelity) while biased models change predictions (low fidelity). This correlation validates NOMATTER XAI's effectiveness in bias detection.
- Core assumption: Model bias manifests as sensitivity to identity terms, and fidelity serves as a proxy measure for bias detection.
- Evidence anchors: [section 6]: "Fig. 4 confirms the quality of NOMATTER XAI. This also shows the potential utility of NOMATTER XAI in approximating bias levels of text classifiers"; [section 6]: "Since AEs emphasize irrelevant features, a model that is highly biased against gender should result in almost no AEs–i.e., near zero fidelity when we only perturb identity words"

## Foundational Learning

- Concept: Counterfactual vs. Alterfactual explanations
  - Why needed here: Understanding the distinction between "what if" (minimal changes to relevant features) and "no matter what" (maximal changes to irrelevant features) is fundamental to grasping NOMATTER XAI's unique approach.
  - Quick check question: What is the key difference between counterfactual explanations and alterfactual explanations in terms of which features they target and why?

- Concept: Semantic field and oppositeness
  - Why needed here: The algorithm relies on finding words that are both opposite in meaning and belong to the same semantic field to preserve context while maximizing perturbation.
  - Quick check question: How do you determine if two words belong to the same semantic field, and why is this important for generating valid alterfactual examples?

- Concept: Feature importance ranking in NLP
  - Why needed here: The algorithm uses feature importance scores to identify irrelevant features, requiring understanding of how word importance is quantified in text classification.
  - Quick check question: How is feature importance typically calculated in text classification models, and why would less important words be considered "irrelevant" for the model's decision?

## Architecture Onboarding

- Component map: Input processor -> Importance ranker -> Perturbation engine -> Constraint checker -> Output formatter
- Critical path: Input → Importance ranking → Word perturbation (with constraints) → Validation → Output
- Design tradeoffs:
  - Single vs. multi-word perturbation: Single-word perturbations are faster but may miss bias patterns; multi-word perturbations are more thorough but computationally expensive
  - ConceptNet vs. ChatGPT: ConceptNet is deterministic but limited by database coverage; ChatGPT is more comprehensive but may hallucinate or be inconsistent
  - Fidelity threshold: Lower thresholds increase success rate but may produce less meaningful perturbations
- Failure signatures:
  - Low fidelity (<70%): Target model is highly biased or perturbation strategy fails to find valid opposites
  - Poor context similarity: Perturbations break semantic coherence despite belonging to same semantic field
  - Runtime timeouts: Excessive model queries due to large input text or inefficient perturbation strategy
- First 3 experiments:
  1. Run NOMATTER XAI on a single sentence from the GB dataset with DistilBERT model, using ConceptNet-Single configuration. Verify that at least one valid alterfactual is generated with >80% context similarity.
  2. Test the double negative detection mechanism by creating sentences with intentional double negatives and verifying they are correctly rejected during perturbation.
  3. Compare ConceptNet-Single vs ChatGPT-Single configurations on the same input to evaluate which produces better context preservation and fidelity.

## Open Questions the Paper Calls Out
- How does NOMATTER XAI perform on datasets with longer average sentence lengths compared to those used in the experiments?
- What is the impact of using different language models (e.g., GPT-4, Claude) for finding opposite words on NOMATTER XAI's performance?
- How does NOMATTER XAI handle cases where the opposite word found significantly changes the part of speech or introduces grammatical errors?

## Limitations
- Semantic field identification reliability may degrade for rare words or specialized domains
- Bias detection correlation strength may be dataset-specific or model-dependent
- Generalizability to other NLP tasks beyond text classification remains untested

## Confidence
- High confidence: The core mechanism of perturbing irrelevant features to generate alterfactual examples is well-defined and technically sound
- Medium confidence: The effectiveness of ConceptNet and ChatGPT for semantic field identification is demonstrated but not extensively validated
- Low confidence: The generalizability of NOMATTER XAI to other NLP tasks and its performance with different model architectures beyond the three tested transformers

## Next Checks
1. Cross-task validation: Test NOMATTER XAI on non-classification NLP tasks (e.g., text generation, summarization) to assess generalizability and identify task-specific limitations
2. Alternative semantic knowledge sources: Replace ConceptNet with other knowledge bases (e.g., WordNet, Wikidata) and compare performance in semantic field identification and alterfactual generation quality
3. Bias type expansion: Evaluate the fidelity-bias correlation across multiple bias types (age, ethnicity, disability) and models to validate the robustness of the bias detection mechanism