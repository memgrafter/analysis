---
ver: rpa2
title: Data Stream Sampling with Fuzzy Task Boundaries and Noisy Labels
arxiv_id: '2404.04871'
source_url: https://arxiv.org/abs/2404.04871
tags:
- learning
- data
- memory
- noisy
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses noisy label challenges in online continual
  learning with fuzzy task boundaries. The proposed Noisy Test Debiasing (NTD) method
  uses test-time augmentation and data-based debiasing to filter high-quality samples
  for episodic memory.
---

# Data Stream Sampling with Fuzzy Task Boundaries and Noisy Labels

## Quick Facts
- arXiv ID: 2404.04871
- Source URL: https://arxiv.org/abs/2404.04871
- Reference count: 29
- Primary result: NTD achieves 1-3.2% accuracy improvements on real-world noise datasets while being 2.3x faster and using <20% of GPU memory

## Executive Summary
This paper addresses the challenge of online continual learning (OCL) with noisy labels and fuzzy task boundaries. The proposed Noisy Test Debiasing (NTD) method uses test-time augmentation and data-based debiasing to filter high-quality samples for episodic memory. NTD clusters samples by noisy labels, applies augmentation-based quality measurement, and balances class representation in memory. Experiments on four datasets (CIFAR10/100 with synthetic noise, mini-WebVision and Food-101N with real-world noise) show NTD achieves comparable or superior accuracy to the previous leading approach while being 2.3x faster and using less than one-fifth of the GPU memory. The method demonstrates 1-3.2% accuracy improvements on complex real-world noise datasets and maintains clean ratios above 96% in episodic memory.

## Method Summary
NTD operates by first clustering incoming samples based on their noisy labels, then applying test-time augmentation (TTA) to compute mean loss across multiple perturbed views of each sample. This quality score is used to filter samples into episodic memory. When memory is full, data-based debiasing removes the highest-loss sample from the most overrepresented class to maintain balance. The approach prioritizes memory purity over quantity, accepting potentially smaller but cleaner episodic memories.

## Key Results
- 1-3.2% accuracy improvements on real-world noise datasets (mini-WebVision, Food-101N)
- 2.3x faster training time compared to PuriDivER baseline
- Less than 20% of GPU memory usage compared to PuriDivER
- Memory clean ratio consistently above 96% across all tested datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Test-time augmentation improves sample quality detection by aggregating multiple perturbed views to reduce noise impact
- Mechanism: TTA computes mean loss across augmented versions, providing robust label quality estimates
- Core assumption: Loss variance across augmentations is higher for noisy labels than clean labels
- Evidence anchors: Abstract states NTD uses systematic sample selection; section mentions augmentation strengthens robustness
- Break condition: If augmentations don't meaningfully change predictions for noisy samples, or if clean samples also show high variance

### Mechanism 2
- Claim: Data-based debiasing balances class representation in episodic memory
- Mechanism: Removes highest-loss sample from largest class when memory is full
- Core assumption: Class imbalance leads to bias during training and evaluation
- Evidence anchors: Abstract mentions data-based debiasing mitigates imbalance; section discusses ensuring equal category quantities
- Break condition: If class distribution in stream is severely imbalanced or if removing high-loss samples disproportionately affects minority classes

### Mechanism 3
- Claim: Clustering samples by noisy labels enables targeted quality filtering within each class
- Mechanism: Groups samples by noisy labels first, then applies TTA and debiasing within each group
- Core assumption: Noisy labels provide useful information for grouping samples into coherent clusters
- Evidence anchors: Section states samples are clustered based on provided noisy labels
- Break condition: If noisy labels are too random to form meaningful clusters, or if clusters are too small for statistical significance

## Foundational Learning

- Concept: Online Continual Learning (OCL)
  - Why needed here: NTD operates in OCL setting with fuzzy task boundaries and streaming data
  - Quick check question: What distinguishes OCL from traditional batch learning in terms of data access patterns?

- Concept: Test-Time Augmentation (TTA)
  - Why needed here: TTA is core quality measurement mechanism that enables NTD to distinguish clean from noisy samples
  - Quick check question: How does averaging loss across augmentations provide more robust quality estimates than single-sample evaluation?

- Concept: Catastrophic Forgetting
  - Why needed here: NTD aims to prevent catastrophic forgetting by maintaining high-quality episodic memory
  - Quick check question: Why is episodic memory quality more important than quantity in continual learning scenarios?

## Architecture Onboarding

- Component map: Mini-batch → Noisy Labels Grouping → Test-time Augmentation → Data-based Debiasing → Episodic Memory
- Critical path: Receive mini-batch → perform Noisy Labels Grouping → compute TTA losses → apply Data-based Debiasing → update episodic memory
- Design tradeoffs: Trades computational overhead for improved memory quality; prioritizes memory purity over quantity
- Failure signatures: Watch for degraded performance when TTA fails to distinguish clean from noisy samples, class imbalance in episodic memory, high computational overhead during memory full conditions, poor performance when noisy labels are too random
- First 3 experiments:
  1. Verify TTA effectiveness: Run NTD on synthetic dataset with known clean/noisy labels and measure whether TTA successfully ranks clean samples higher
  2. Test debiasing balance: Run NTD on highly imbalanced dataset and verify episodic memory maintains near-equal class representation
  3. Benchmark memory clean ratio: Compare percentage of clean samples in episodic memory before and after applying NTD on real-world noisy dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does NTD perform under different types of noise beyond symmetric and asymmetric noise, such as class-dependent noise or adversarial noise?
- Basis in paper: [inferred] The paper evaluates NTD on synthetic noise datasets (CIFAR10 and CIFAR100) with symmetric and asymmetric noise, as well as real-world noise datasets (mini-WebVision and Food-101N). However, it does not explore other types of noise.
- Why unresolved: The paper does not provide experimental results or theoretical analysis on the performance of NTD under different noise types beyond symmetric and asymmetric noise.
- What evidence would resolve it: Conducting experiments with various noise types, such as class-dependent noise or adversarial noise, and comparing the performance of NTD to baseline methods would provide insights into the method's robustness under different noise conditions.

### Open Question 2
- Question: What is the impact of episodic memory size on NTD performance in terms of accuracy and clean ratio?
- Basis in paper: [inferred] The paper uses fixed episodic memory sizes for each dataset but does not explore varying memory size effects.
- Why unresolved: The paper does not provide systematic analysis of the relationship between episodic memory size and NTD performance in terms of accuracy and clean ratio.
- What evidence would resolve it: Conducting experiments with different episodic memory sizes and analyzing the trade-off between accuracy, clean ratio, and memory usage would provide insights into optimal memory size for NTD.

### Open Question 3
- Question: How does NTD compare to other state-of-the-art methods in terms of training time and GPU memory usage when applied to larger-scale datasets or more complex models?
- Basis in paper: [explicit] The paper compares NTD to PuriDivER on CIFAR10 dataset but does not explore scalability to larger datasets or complex models.
- Why unresolved: The paper does not provide experimental results or theoretical analysis on NTD's scalability to larger-scale datasets or more complex models in terms of training time and GPU memory usage.
- What evidence would resolve it: Conducting experiments with larger-scale datasets or more complex models and comparing training time and GPU memory usage of NTD to other state-of-the-art methods would provide insights into NTD's scalability and efficiency.

## Limitations
- Core mechanism that TTA effectively distinguishes clean from noisy samples through loss variance is not directly validated
- Clustering by noisy labels assumes these labels retain semantic coherence despite being corrupted, which is not empirically verified
- Computational overhead claims are based on comparison with a specific baseline without broader benchmarking

## Confidence
- **High Confidence**: Memory clean ratio results (>96%) and training time/memory usage comparisons are well-supported by experimental data
- **Medium Confidence**: Accuracy improvements on real-world noise datasets are demonstrated but lack ablation studies isolating NTD's contribution
- **Low Confidence**: Core mechanism claim that TTA effectively identifies noisy samples through loss variance is not directly validated with supporting experiments

## Next Checks
1. Conduct an ablation study isolating TTA effectiveness by testing NTD with and without augmentation on datasets with known clean/noisy label distributions
2. Test NTD's performance across multiple competing baselines beyond PuriDivER to validate the claimed computational efficiency advantages
3. Analyze the correlation between TTA loss variance and actual label correctness on held-out validation sets to empirically verify the core detection mechanism