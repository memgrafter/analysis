---
ver: rpa2
title: 'Dynamic Sentiment Analysis with Local Large Language Models using Majority
  Voting: A Study on Factors Affecting Restaurant Evaluation'
arxiv_id: '2407.13069'
source_url: https://arxiv.org/abs/2407.13069
tags:
- sentiment
- arxiv
- data
- llms
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a majority voting mechanism for sentiment
  analysis using local large language models (LLMs) to analyze restaurant reviews.
  By comparing multiple LLM configurations, it demonstrates that a medium-sized model
  with iterative inferences and majority voting produces more accurate and robust
  results than a large model with a single inference.
---

# Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting: A Study on Factors Affecting Restaurant Evaluation

## Quick Facts
- arXiv ID: 2407.13069
- Source URL: https://arxiv.org/abs/2407.13069
- Authors: Junichiro Niimi
- Reference count: 40
- Primary result: Medium-sized LLMs with iterative inferences and majority voting produce more accurate sentiment analysis than large models with single inference

## Executive Summary
This study introduces a majority voting mechanism for sentiment analysis using local large language models (LLMs) to analyze restaurant reviews. By comparing multiple LLM configurations, it demonstrates that a medium-sized model with iterative inferences and majority voting produces more accurate and robust results than a large model with a single inference. The approach enables dynamic extraction of aspect-based sentiments from textual data without additional training. Validation through regression analysis confirms the generalizability of the results, showing that the predicted sentiment values align closely with actual user ratings.

## Method Summary
The method employs local LLM inference with one-shot learning, using Llama models (70B and 8B parameters) with varying quantization precision (3-5 bits). The approach performs multiple inference trials per review with different random seeds, then aggregates results using a majority voting mechanism based on median values across virtual "workers." Aspect-based sentiment analysis extracts granular sentiment information about specific restaurant features, and the entire pipeline operates without requiring model fine-tuning or additional training data.

## Key Results
- Medium-sized models with iterative inferences and majority voting achieve higher accuracy than large models with single inference
- Lower quantization precision (3-bit) sometimes yields better accuracy than higher precision, contrary to expectations
- Predicted sentiment values align closely with actual user ratings, confirmed through regression analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using medium-sized LLMs with iterative inferences and majority voting produces more robust results than using a large model with a single inference.
- Mechanism: Multiple inference trials with different random seeds generate diverse responses. The median of these responses across virtual "workers" reduces noise and outliers while capturing consistent sentiment signals.
- Core assumption: Individual LLM inferences contain variability that can be reduced through ensemble voting, and medium-sized models provide sufficient accuracy while being computationally efficient.
- Evidence anchors:
  - [abstract] "majority voting with multiple attempts using a medium-sized model produces more robust results than using a large model with a single attempt"
  - [section 4.3] "a five-fold increase in the processing time led to that of 3.9% using majority voting. This indicates that a medium-sized model with iterative inferences using the majority voting mechanism is significantly more efficient"
  - [corpus] Weak - no direct supporting evidence found in neighbor papers
- Break condition: If the individual model inferences are too inconsistent or the median becomes unstable due to extreme outliers.

### Mechanism 2
- Claim: Quantization precision affects model performance in a non-linear way, with lower precision sometimes yielding better results.
- Mechanism: Reducing quantization bits decreases model size and inference time while maintaining sufficient accuracy for sentiment analysis tasks, with potential regularization effects from quantization noise.
- Core assumption: The sentiment analysis task doesn't require the full precision of higher-bit models, and quantization can act as a form of regularization.
- Evidence anchors:
  - [section 4.2] "in terms of precision in quantization for 8B models (Models 2-4), in contrast to expectations, the accuracy improved with lower precision"
  - [section 2.2] "the performance of the model and the precision of the quantization have a tradeoff relationship"
  - [corpus] Weak - no direct supporting evidence found in neighbor papers
- Break condition: If task complexity increases beyond the representational capacity of lower-precision models.

### Mechanism 3
- Claim: Aspect-based sentiment analysis using LLMs can capture consumer preferences with accuracy comparable to ground truth ratings.
- Mechanism: LLMs can parse review text, identify relevant aspects, and assign sentiment scores that align with overall user ratings through zero-shot or few-shot learning capabilities.
- Core assumption: Pretrained LLMs have sufficient domain knowledge from training data to understand restaurant-related aspects and sentiment without fine-tuning.
- Evidence anchors:
  - [section 4.1] "we can freely extract any aspect of sentiment from review texts accurately with medium-scale LLMs using the majority voting mechanism"
  - [section 4.4] "there is no significant discrepancy between the predicted and actual values of the overall evaluation"
  - [corpus] Weak - no direct supporting evidence found in neighbor papers
- Break condition: If the review text contains highly domain-specific terminology or sarcasm that the pretrained model cannot interpret.

## Foundational Learning

- Concept: Ensemble methods and majority voting
  - Why needed here: To reduce variability in LLM outputs and improve robustness of sentiment predictions
  - Quick check question: How does majority voting reduce the impact of outlier predictions compared to simple averaging?

- Concept: Quantization and model compression
  - Why needed here: To enable local execution of LLMs on resource-constrained devices while maintaining acceptable performance
  - Quick check question: What is the relationship between quantization bit-width and model accuracy in the context of sentiment analysis?

- Concept: Aspect-based sentiment analysis
  - Why needed here: To extract granular sentiment information about specific restaurant features rather than just overall sentiment
  - Quick check question: How does aspect-based analysis differ from traditional sentiment analysis in terms of output structure?

## Architecture Onboarding

- Component map: LLM inference engine → Multiple seed-based runs → Median voting mechanism → Aspect extraction → Structured output parser → Regression analysis pipeline
- Critical path: Prompt construction → LLM inference (multiple seeds) → Response parsing → Median voting → Output validation
- Design tradeoffs: Model size vs. inference speed vs. accuracy; quantization precision vs. computational efficiency; number of voting rounds vs. processing time
- Failure signatures: High variance in individual LLM responses; systematic bias in certain aspects; missing values in majority voting; parsing errors in JSON output
- First 3 experiments:
  1. Compare single vs. multiple inference accuracy for a fixed model configuration
  2. Test different quantization precisions (3-bit, 4-bit, 5-bit) on the same model size
  3. Validate aspect extraction consistency across different random seeds with the same prompt

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different quantization techniques (QAT vs PTQ) affect the accuracy and computational efficiency of LLMs for sentiment analysis tasks?
- Basis in paper: [explicit] The paper discusses PTQ as the chosen approach and mentions its advantages over QAT, but does not provide a direct comparison between the two methods.
- Why unresolved: The paper focuses on PTQ without exploring the potential benefits of QAT for sentiment analysis.
- What evidence would resolve it: A comparative study implementing both QAT and PTQ on the same LLM models for sentiment analysis tasks, measuring accuracy and computational efficiency.

### Open Question 2
- Question: How does the choice of instruction examples in one-shot learning impact the performance of LLMs in aspect-based sentiment analysis?
- Basis in paper: [explicit] The paper mentions using one-shot learning with random examples from the dataset but does not explore the impact of different example choices.
- Why unresolved: The effect of instruction example selection on model performance is not investigated, leaving uncertainty about optimal example selection.
- What evidence would resolve it: Experiments testing various instruction examples in one-shot learning setups and measuring their impact on sentiment analysis accuracy.

### Open Question 3
- Question: Can the majority voting mechanism be effectively applied to other NLP tasks beyond sentiment analysis, such as text classification or named entity recognition?
- Basis in paper: [inferred] The paper introduces majority voting for sentiment analysis and suggests it reduces prediction errors, implying potential applicability to other tasks.
- Why unresolved: The paper does not explore the use of majority voting in tasks other than sentiment analysis.
- What evidence would resolve it: Implementing and testing majority voting on various NLP tasks and comparing results with traditional methods.

## Limitations
- The study relies on 1,000 Yelp reviews from a single dataset, limiting generalizability to other domains or review types
- Critical implementation parameters remain unspecified, including exact one-shot examples and precise median aggregation mechanism
- Statistical significance testing is not reported for observed differences between model configurations

## Confidence

**High Confidence**: The effectiveness of majority voting in reducing prediction variance across multiple LLM inferences

**Medium Confidence**: The assertion that medium-sized models with iterative inferences outperform large models with single inference

**Low Confidence**: The unexpected finding that lower quantization precision (3-bit) sometimes improves accuracy

## Next Checks

**Check 1**: Run ablation studies comparing single vs. five-trial inference across different model sizes (70B vs. 8B) while holding quantization constant to isolate the voting mechanism's contribution

**Check 2**: Test the approach on out-of-domain sentiment analysis tasks (e.g., product reviews, movie reviews) to evaluate generalizability beyond restaurant evaluations

**Check 3**: Conduct statistical significance testing (t-tests or ANOVA) on accuracy improvements between voting mechanisms and model configurations to verify that observed differences are not due to random variation