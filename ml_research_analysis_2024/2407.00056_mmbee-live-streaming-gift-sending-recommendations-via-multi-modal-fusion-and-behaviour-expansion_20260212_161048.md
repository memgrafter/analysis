---
ver: rpa2
title: 'MMBee: Live Streaming Gift-Sending Recommendations via Multi-Modal Fusion
  and Behaviour Expansion'
arxiv_id: '2407.00056'
source_url: https://arxiv.org/abs/2407.00056
tags:
- graph
- live
- multi-modal
- streaming
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MMBee introduces a novel live streaming gifting prediction model
  that addresses the challenges of multi-modal content modeling and behavior sparsity
  through Multi-modal Fusion with Learnable Query (MFQ) and Graph-guided Interest
  Expansion (GIE) modules. The MFQ module leverages orthogonal projection and cross-attention
  mechanisms to process visual, speech, and text modalities while incorporating learnable
  queries to capture streamer-specific content patterns.
---

# MMBee: Live Streaming Gift-Sending Recommendations via Multi-Modal Fusion and Behaviour Expansion

## Quick Facts
- arXiv ID: 2407.00056
- Source URL: https://arxiv.org/abs/2407.00056
- Reference count: 40
- Multi-modal live streaming gifting prediction model achieving 0.960302 AUC, 2.862% increase in users sending gifts, and 4.775% increase in total gifts sent

## Executive Summary
MMBee addresses the challenges of live streaming gift recommendation through a novel architecture combining multi-modal content understanding with graph-based behavior expansion. The system processes visual, speech, and text modalities from live streams using orthogonal projection and learnable queries, while enriching sparse user interaction histories through graph-guided interest expansion. The model has been successfully deployed on Kuaishou's platform serving hundreds of millions of users, demonstrating significant improvements over state-of-the-art baselines in both offline and online evaluations.

## Method Summary
MMBee introduces a decoupled training and serving architecture with two core modules: MFQ for multi-modal fusion using orthogonal projection and learnable queries to capture streamer-specific content patterns, and GIE for graph-guided behavior expansion using contrastive learning on User-to-Author and Author-to-Author donation graphs. The system processes live streaming segments containing visual frames, speech, and text comments, then expands user behavior sequences through metapaths up to 3 hops to address sparsity. All graph processing and expansion are performed offline with results stored in key-value databases for real-time serving, ensuring low latency while handling 3 billion-scale datasets.

## Key Results
- Achieves 0.960302 AUC, 0.743678 UAUC, and 0.76044 GAUC on Kuaishou's industrial dataset
- Online A/B tests show 2.862% increase in users sending gifts and 4.775% increase in total gifts sent
- Outperforms state-of-the-art baselines on both Kuaishou's 3 billion scale dataset and public datasets (TikTok, MovieLens)
- Successfully deployed serving hundreds of millions of users on Kuaishou's live streaming platform

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The MFQ module captures real-time streaming content patterns by leveraging learnable queries tied to individual streamers.
- Mechanism: For each live streaming segment, the MFQ module first applies orthogonal projection to fuse visual, speech, and text modalities, removing redundant information. Then it uses cross-attention between fused features and learnable query tokens, followed by self-attention among queries, producing streamer-aware content embeddings.
- Core assumption: Streamers exhibit recurring content patterns that can be modeled as learnable query embeddings, and these patterns align with gifting behavior.
- Evidence anchors:
  - [abstract] "The MFQ module leverages orthogonal projection and cross-attention mechanisms to process visual, speech, and text modalities while incorporating learnable queries to capture streamer-specific content patterns."
  - [section] "We produce several learnable query tokens ùííùëö ‚àà RùëÅ √óùëë to extract streamer-aware content patterns... Each author keeps a set number of learnable query embeddings which are randomly initialized."
  - [corpus] No direct corpus evidence for learnable query effectiveness in live streaming; assumption based on general transformer literature.
- Break condition: If gifting behavior does not correlate with content patterns, or if query initialization fails to capture meaningful streamer-specific signals, the MFQ module will not improve prediction.

### Mechanism 2
- Claim: The GIE module addresses behavior sparsity by expanding users' and authors' interaction graphs and enriching their representations through metapath-guided exploration.
- Mechanism: The GIE module first constructs User-to-Author and Author-to-Author donation graphs, then learns node embeddings via contrastive learning (GraphCL). It further expands behavior sequences by traversing metapaths up to 3 hops, retrieving neighbors that reflect shared interests or similar authors. These expanded sequences are concatenated and pooled to produce richer embeddings for the recommendation model.
- Core assumption: The donation graph structure contains latent preferences that can be uncovered through metapaths, and these extended neighbors meaningfully represent user interests beyond observed gifting history.
- Evidence anchors:
  - [abstract] "The GIE module constructs large-scale user-to-author and author-to-author graphs, applying contrastive learning for node embeddings and metapath-guided behavior expansion to enrich sparse interaction histories."
  - [section] "We construct large-scale gifting graphs based on the history of gifting interactions... we further extend behavior sequences through metapaths with the graph structural information."
  - [corpus] No corpus evidence for metapath-guided behavior expansion in live streaming; assumption based on general heterogeneous graph recommendation literature.
- Break condition: If metapaths fail to capture relevant interests or if the graph structure is too sparse to provide meaningful neighbors, the expansion will not improve performance and may introduce noise.

### Mechanism 3
- Claim: The decoupled offline training and online inference strategy allows large-scale graph processing without harming real-time serving latency.
- Mechanism: The GIE module performs graph node embedding training and metapath neighbor expansion offline, storing results in a key-value store. During online inference, the recommendation model retrieves precomputed embeddings instead of walking the graph in real time, ensuring low latency.
- Core assumption: Precomputing graph embeddings and expanded neighbors is computationally feasible offline and the storage cost is acceptable, while retrieval is fast enough for online serving.
- Evidence anchors:
  - [section] "To meet the low latency requirements of the online serving system, we propose a decoupled graph offline training and online inference strategy."
  - [section] "We store the pre-aggregated embeddings of the metapath-guided expanded neighbors of each user and author on the graph into memories or key-value databases to be further utilized in the online training stage."
  - [corpus] No corpus evidence for this specific offline/online decoupling in live streaming; assumption based on general industrial recommendation system practices.
- Break condition: If graph size or expansion complexity exceeds offline storage capacity, or if retrieval latency grows beyond acceptable limits, the strategy fails.

## Foundational Learning

- Concept: Multi-modal fusion via orthogonal projection
  - Why needed here: Live streaming segments contain visual frames, speech, and text comments; naive concatenation loses modality-specific information and introduces redundancy.
  - Quick check question: What does the orthogonal projection operation compute between two modality representations?

- Concept: Graph contrastive learning for node embeddings
  - Why needed here: The donation graph is sparse and cold-start authors lack sufficient interaction history; contrastive learning clusters similar nodes and pushes apart dissimilar ones, creating robust embeddings.
  - Quick check question: In GraphCL, how are positive and negative samples defined for a given node?

- Concept: Metapath-guided neighbor expansion
  - Why needed here: Users' gifting behavior is sparse (average 0.3 donations per user); metapath expansion retrieves users with shared authors, similar authors, or users who donated to similar authors, uncovering latent preferences.
  - Quick check question: What is the maximum hop distance used for metapath expansion in MMBee?

## Architecture Onboarding

- Component map:
  - MFQ module: orthogonal projection ‚Üí cross-attention (modality fused ‚Üí learnable query) ‚Üí self-attention (query refinement)
  - GIE module: graph construction ‚Üí GraphCL pretraining ‚Üí metapath expansion ‚Üí embedding storage
  - Recommendation backbone: SIM with GSU/ESU + MFQ output + GIE output ‚Üí GTR prediction

- Critical path: Input multimodal features ‚Üí MFQ ‚Üí concatenated with expanded graph embeddings ‚Üí SIM backbone ‚Üí GTR output

- Design tradeoffs:
  - MFQ learns streamer-specific patterns but adds learnable parameters per author; risk of overfitting for rare streamers.
  - GIE expansion increases representation richness but storage and retrieval costs grow with graph size.
  - Offline graph processing trades freshness for serving speed; stale embeddings may hurt performance if user behavior changes rapidly.

- Failure signatures:
  - Poor MFQ performance: modality fusion collapses to one modality, learnable queries become uniform across authors, or cross-attention weights vanish.
  - Poor GIE performance: expanded neighbors are irrelevant or too generic, contrastive loss diverges, or metapath retrieval fails due to graph sparsity.
  - Serving latency spikes: offline storage retrieval slows, or graph embedding dimension too large for memory bandwidth.

- First 3 experiments:
  1. Replace MFQ with simple modality concatenation and measure AUC drop; confirm importance of orthogonal fusion.
  2. Remove metapath expansion (use only observed behavior) and measure AUC drop; confirm value of GIE expansion.
  3. Run online A/B with and without decoupled graph inference; measure latency and GTR lift; confirm serving strategy effectiveness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the MFQ module handle cases where one modality is missing or severely degraded in quality?
- Basis in paper: [inferred] The paper describes MFQ's orthogonal projection and cross-attention mechanisms for fusing visual, speech, and text modalities, but doesn't address robustness to missing or low-quality inputs.
- Why unresolved: The paper focuses on MFQ's architecture and performance improvements but doesn't evaluate its behavior under modality degradation or absence scenarios.
- What evidence would resolve it: Experiments showing MFQ's performance when individual modalities are corrupted, removed, or of varying quality levels compared to baselines.

### Open Question 2
- Question: What is the computational overhead of pre-computing and storing metapath-guided behavior expansions for all users and authors?
- Basis in paper: [explicit] Section 5.4 mentions storing metapath-guided neighbors in Graph Behavior Offline Storage in advance to avoid on-the-fly graph walking, but doesn't quantify the storage and computation costs.
- Why unresolved: While the paper explains the offline storage strategy, it doesn't provide metrics on the size of the stored data, memory requirements, or pre-computation time.
- What evidence would resolve it: Quantitative analysis of storage requirements, pre-computation time, and memory usage for maintaining the expanded behavior sequences.

### Open Question 3
- Question: How does the performance of MMBee scale with increasing graph size and density?
- Basis in paper: [inferred] The paper mentions constructing large-scale User-to-Author and Author-to-Author graphs but doesn't analyze how model performance changes with graph size or density variations.
- Why unresolved: While the paper demonstrates effectiveness on Kuaishou's 3 billion scale dataset, it doesn't explore how performance metrics like AUC, UAUC, and GAUC change as the graph grows larger or becomes denser.
- What evidence would resolve it: Performance analysis across datasets of varying sizes and densities, showing how MMBee's metrics scale with increasing graph complexity.

## Limitations
- Core assumptions about streamer-specific content patterns captured by learnable queries remain untested in live streaming contexts
- Metapath-guided behavior expansion lacks specific evidence for live streaming gifting scenarios
- Offline/online decoupling strategy has unknown scalability limits at 3 billion scale with dense graph expansion

## Confidence
- High confidence in the decoupled serving strategy's practical effectiveness given its industrial deployment
- Medium confidence in MFQ's multi-modal fusion approach, as orthogonal projection is well-established but learnable query adaptation to streaming is novel
- Low confidence in GIE's behavior expansion mechanism due to lack of corpus evidence and unspecified implementation details

## Next Checks
1. **Query pattern validation**: Analyze whether learnable query embeddings actually capture streamer-specific patterns by clustering them and correlating with gifting rates per streamer - verify the core MFQ assumption.
2. **Expansion relevance testing**: Measure the gifting similarity between users and their metapath-expanded neighbors - compute the percentage of expanded neighbors who actually donate to the same authors as the original user.
3. **Offline/online freshness tradeoff**: Compare model performance when using fresh vs. stale graph embeddings (e.g., embeddings from different time windows) to quantify the freshness cost of the decoupled serving strategy.