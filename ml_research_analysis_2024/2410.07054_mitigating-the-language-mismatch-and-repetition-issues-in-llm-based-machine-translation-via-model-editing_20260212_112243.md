---
ver: rpa2
title: Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine
  Translation via Model Editing
arxiv_id: '2410.07054'
source_url: https://arxiv.org/abs/2410.07054
tags:
- language
- translation
- repetition
- neurons
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies two critical error types in LLM-based machine
  translation: language mismatch (wrong target language output) and repetition (uncontrolled
  text repetition). These errors occur frequently and severely degrade translation
  quality.'
---

# Mitigating the Language Mismatch and Repetition Issues in LLM-based Machine Translation via Model Editing

## Quick Facts
- arXiv ID: 2410.07054
- Source URL: https://arxiv.org/abs/2410.07054
- Reference count: 40
- Primary result: Model editing methods reduce language mismatch errors by up to 92% and repetition errors by 26% while maintaining or improving translation quality

## Executive Summary
This paper addresses two critical error types in LLM-based machine translation: language mismatch (wrong target language output) and repetition (uncontrolled text repetition). These errors significantly degrade translation quality and occur frequently in practice. The authors adapt model editing methods, Function Vectors and Knowledge Neurons, to locate and modify components responsible for these errors. Through a novel intersection refinement approach that filters out error-irrelevant components across different language settings, the proposed methods (MTV-I-D for language mismatch and RPN-I for repetition) significantly reduce error rates while maintaining or improving general translation quality.

## Method Summary
The authors adapt two model editing methods to address language mismatch and repetition errors in LLM-based translation. First, they locate responsible components using causal mediation analysis and integrated gradient attribution. Direct application of these methods showed limited effectiveness as the located components were also vital for general translation. To address this, they refined the located components by intersecting results across different language settings, filtering out error-irrelevant components. This led to the development of MTV-I-D for language mismatch and RPN-I for repetition errors. The methods were tested on LLaMA2-7B across four language directions using WMT test sets, with evaluation using BLEU, COMET, and LLM capability benchmarks.

## Key Results
- MTV-I-D reduces language mismatch error rates by up to 92% while maintaining or improving BLEU and COMET scores
- RPN-I reduces repetition error rates by 26% with minimal impact on translation quality
- Both methods achieve performance comparable to or exceeding traditional fine-tuning approaches
- The intersection refinement approach preserves general LLM capabilities while targeting specific error patterns

## Why This Works (Mechanism)

### Mechanism 1
Language mismatch errors stem from improper target language identification in LLM translation, while repetition errors arise from uncontrolled generation loops. Model editing methods can identify and modify specific attention heads and FFN neurons responsible for these errors. The responsible components for language mismatch and repetition are localized within specific attention heads (for language identification) and FFN neurons (for generation control).

### Mechanism 2
Direct application of model editing methods has limited effectiveness because the located components are crucial for both error patterns and general translation. The same components that cause errors when malfunctioning are essential for correct translation when functioning properly.

### Mechanism 3
Refining located components by intersecting results across different language settings filters out error-irrelevant components while preserving error-relevant ones. Components responsible for error patterns should be language-independent, while language-specific components should be filtered out through intersection.

## Foundational Learning

- **Causal mediation analysis and integrated gradient attribution**: These techniques identify which attention heads and neurons are most responsible for specific error patterns. Why needed: To locate the specific components causing language mismatch and repetition errors. Quick check: What is the difference between direct and indirect effects in causal mediation analysis?

- **Feed-Forward Network (FFN) as key-value memory**: Understanding FFNs as memory stores helps explain how knowledge neurons can store and modify translation-related information. Why needed: To understand how FFN neurons can be edited to control generation behavior. Quick check: How do FFN neurons differ from attention heads in their role within transformer architecture?

- **Residual stream manipulation**: Function vectors are added to the residual stream to influence model behavior during translation. Why needed: To understand how function vectors modify model behavior through residual connections. Quick check: At which layer are function vectors typically added in the transformer architecture?

## Architecture Onboarding

- **Component map**: Input layer → Multiple transformer layers → Output layer; Each transformer layer contains: Multi-Head Self-Attention + Feed-Forward Network + Layer Norm; Model editing targets: Attention heads (for language identification) and FFN neurons (for generation control)

- **Critical path**: 1. Identify error patterns in translation outputs; 2. Locate responsible components using causal mediation (attention heads) and integrated gradient (neurons); 3. Refine located components through intersection across language settings; 4. Apply modified editing methods (MTV-I-D for language mismatch, RPN-I for repetition)

- **Design tradeoffs**: Direct editing vs. intersection refinement (faster vs. preserves capabilities); Number of components to edit (too few ineffective, too many harmful); Language setting selection (more settings improve refinement but increase computation)

- **Failure signatures**: Increased repetition when reducing language mismatch (shared components); BLEU score degradation after editing (removal of translation-essential components); No improvement in error rates (incorrect component identification)

- **First 3 experiments**: 1. Apply MTV-I-D to pre-trained LLaMA2-7B on zh→en translation and measure language mismatch reduction and BLEU score change; 2. Apply RPN-I to same model on zh→en translation and measure repetition reduction and BLEU score change; 3. Compare MTV-I-D and RPN-I performance against traditional fine-tuning on all four language directions

## Open Questions the Paper Calls Out

### Open Question 1
Are the language mismatch and repetition errors universal across different LLM architectures (e.g., Mistral-7B, OLMO, GPT-4, Claude-3.5-Sonnet) or specific to LLaMA series models? The paper only tested LLaMA2 models and acknowledges this limitation.

### Open Question 2
How do these errors behave in low-resource or non-English language pair settings (e.g., zh→de translation)? The study focused on high-resource language pairs and notes this may differ in other settings.

### Open Question 3
What is the relationship between repetition error mechanism and specific token patterns, and can this understanding lead to more effective prevention strategies? The authors observe token pattern connections but don't provide detailed analysis.

### Open Question 4
Can model editing methods be optimized to achieve better performance on repetition errors while maintaining effectiveness on language mismatch errors? Current KN-based approaches are noted as "not stable" for repetition errors.

## Limitations
- Effectiveness on other LLM architectures remains unexplored
- Performance may degrade on X→en language settings due to English-centric nature of LLaMA2 models
- Focus on high-resource languages may limit applicability to low-resource or non-English language pairs

## Confidence

**High Confidence**: Empirical observation that language mismatch and repetition errors occur frequently in LLM-based translation systems, and direct application of model editing methods can harm general translation quality.

**Medium Confidence**: Effectiveness of intersection refinement approach in preserving general translation capabilities while reducing targeted errors, demonstrated across tested language pairs.

**Low Confidence**: Assumption that error-relevant components are language-independent, based on limited experimental evidence that may not generalize to all language combinations.

## Next Checks

1. **Cross-Architecture Validation**: Test MTV-I-D and RPN-I methods on multiple LLM architectures (GPT, OPT, BLOOM) and smaller models to assess generalizability and identify architecture-specific limitations.

2. **Long-Term Stability Assessment**: Evaluate whether edited models maintain improved error rates and translation quality over extended inference periods with diverse input distributions.

3. **Error Type Expansion**: Investigate whether intersection refinement approach can be extended to other error types (e.g., factual errors, cultural adaptation failures) by identifying if these errors share similar localization characteristics.