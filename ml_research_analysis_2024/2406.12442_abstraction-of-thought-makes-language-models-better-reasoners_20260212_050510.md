---
ver: rpa2
title: Abstraction-of-Thought Makes Language Models Better Reasoners
arxiv_id: '2406.12442'
source_url: https://arxiv.org/abs/2406.12442
tags:
- reasoning
- niv2
- question
- language
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Abstraction-of-Thought (AoT), a structured
  reasoning format that requires multiple levels of abstraction within the reasoning
  process. The method addresses the limitation of existing Chain-of-Thought (CoT)
  approaches by explicitly incorporating abstract skeletal solutions to organize reasoning.
---

# Abstraction-of-Thought Makes Language Models Better Reasoners

## Quick Facts
- arXiv ID: 2406.12442
- Source URL: https://arxiv.org/abs/2406.12442
- Reference count: 37
- Key result: AoT-finetuned models achieve +9.7% average accuracy improvement on reasoning tasks

## Executive Summary
This paper introduces Abstraction-of-Thought (AoT), a structured reasoning format that requires multiple levels of abstraction within the reasoning process. The method addresses the limitation of existing Chain-of-Thought (CoT) approaches by explicitly incorporating abstract skeletal solutions to organize reasoning. To align models with AoT, the authors collect AOT COLLECTION, a dataset of 348k high-quality reasoning samples with varying abstraction levels, using an automated pipeline. Experiments on the Big-Bench Hard benchmark show that AoT-finetuned models significantly outperform CoT-finetuned models, achieving +9.7% average accuracy improvement on reasoning tasks, with particularly strong gains on algorithmic tasks (+10.0%). The results demonstrate that AoT effectively elicits abstract reasoning and enhances model performance across diverse reasoning challenges.

## Method Summary
The authors introduce Abstraction-of-Thought (AoT), a structured reasoning format that requires multiple levels of abstraction within the reasoning process. Unlike traditional Chain-of-Thought approaches that focus on step-by-step solutions, AoT explicitly incorporates abstract skeletal solutions to organize reasoning. To train models in this format, the researchers created AOT COLLECTION, a dataset of 348k high-quality reasoning samples with varying abstraction levels. The dataset was collected using an automated pipeline that generates reasoning traces across multiple abstraction levels. Models were finetuned on this dataset and evaluated on the Big-Bench Hard benchmark, demonstrating significant improvements over standard CoT approaches.

## Key Results
- AoT-finetuned models achieve +9.7% average accuracy improvement over CoT baselines on Big-Bench Hard benchmark
- Particularly strong gains on algorithmic tasks (+10.0% improvement)
- AoT effectively elicits abstract reasoning and enhances model performance across diverse reasoning challenges

## Why This Works (Mechanism)
The paper doesn't explicitly detail the mechanism behind why AoT works better than traditional Chain-of-Thought approaches. The authors suggest that requiring multiple levels of abstraction helps models organize their reasoning more effectively, but the specific cognitive or computational mechanisms are not elaborated upon in the provided content.

## Foundational Learning

### Structured Reasoning Formats
- **Why needed**: Traditional CoT approaches often produce verbose, low-level reasoning traces that may not capture the essential abstract structure of problems
- **Quick check**: Compare reasoning trace lengths and quality between AoT and CoT approaches

### Abstraction Levels in Reasoning
- **Why needed**: Different levels of abstraction help models capture both high-level problem structure and detailed solution steps
- **Quick check**: Analyze how models perform when different abstraction levels are included or excluded

### Automated Data Collection for Reasoning
- **Why needed**: Manually creating large-scale reasoning datasets with multiple abstraction levels is prohibitively expensive
- **Quick check**: Verify the quality and consistency of automatically collected reasoning traces

## Architecture Onboarding

### Component Map
AOT COLLECTION Dataset -> AoT-Finetuned Model -> Big-Bench Hard Evaluation

### Critical Path
1. Create AOT COLLECTION dataset with automated pipeline
2. Finetune language model on AoT-formatted reasoning samples
3. Evaluate on Big-Bench Hard benchmark

### Design Tradeoffs
- **Dataset size vs. quality**: 348k samples collected automatically may sacrifice some quality for scale
- **Abstraction complexity vs. model capacity**: More abstraction levels may exceed model's reasoning capabilities
- **Generalization vs. specialization**: AoT format may improve performance on specific task types

### Failure Signatures
- Inconsistent abstraction levels across reasoning traces
- Models producing overly verbose or overly terse reasoning
- Poor transfer to tasks outside Big-Bench Hard

### First 3 Experiments
1. Compare AoT vs. CoT performance on algorithmic reasoning tasks
2. Evaluate impact of different abstraction level combinations
3. Test model performance with varying amounts of AoT training data

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on automated data collection raises questions about data quality consistency across 348k samples
- Ablation studies examining individual abstraction levels would strengthen claims about which aspects drive improvements
- Evaluation focuses primarily on Big-Bench Hard, limiting generalizability to other reasoning benchmarks and real-world applications

## Confidence

**High confidence**: The +9.7% average accuracy improvement over CoT baselines on Big-Bench Hard is statistically significant and methodologically sound.

**Medium confidence**: Claims about AoT's effectiveness on algorithmic tasks (+10.0%) are supported but could benefit from broader task diversity.

**Medium confidence**: The automated data collection pipeline's ability to generate high-quality reasoning samples is plausible but unverified through manual inspection.

## Next Checks
1. Conduct manual quality assessment of 100 randomly sampled reasoning traces from AOT COLLECTION to verify abstraction level consistency and reasoning validity
2. Evaluate AoT-finetuned models on additional reasoning benchmarks (e.g., GSM8K, MATH, LogiQA) to test generalizability beyond Big-Bench Hard
3. Perform ablation studies removing different abstraction levels from AoT prompts to quantify their individual contributions to performance gains