---
ver: rpa2
title: 'BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using Camera-LiDAR
  Data'
arxiv_id: '2406.18414'
source_url: https://arxiv.org/abs/2406.18414
tags:
- object
- detection
- trajectory
- fusion
- tracking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BiTrack, a 3D offline multi-object tracking
  (OMOT) framework that fuses camera and LiDAR data for accurate and efficient object
  tracking. The framework addresses challenges in 2D-3D detection fusion, initial
  trajectory generation, and trajectory refinement by developing novel techniques
  including point-level object registration using density-based similarity metrics,
  bidirectional trajectory generation with improved similarity evaluation and track
  management, and a greedy-based trajectory re-optimization scheme.
---

# BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using Camera-LiDAR Data

## Quick Facts
- arXiv ID: 2406.18414
- Source URL: https://arxiv.org/abs/2406.18414
- Authors: Kemiao Huang; Yinqi Chen; Meiying Zhang; Qi Hao
- Reference count: 31
- Achieves HOTA score of 84.54% on KITTI test set, outperforming existing methods

## Executive Summary
BiTrack is a 3D offline multi-object tracking framework that fuses camera and LiDAR data for accurate and efficient object tracking. The method addresses key challenges in 2D-3D detection fusion, initial trajectory generation, and trajectory refinement through novel techniques including point-level object registration using density-based similarity metrics, bidirectional trajectory generation with improved similarity evaluation, and greedy-based trajectory re-optimization. Experiments on the KITTI dataset demonstrate state-of-the-art performance with a HOTA score of 84.54%, significantly outperforming existing approaches.

## Method Summary
BiTrack implements a post-processing pipeline that takes pre-computed 2D instance segmentation and 3D object detection results and fuses them using point-level object registration via bipartite matching. The framework then generates initial trajectories using a normalized center distance similarity metric and track management with hit-miss thresholds. Finally, it performs bidirectional tracking and re-optimization, selecting the best trajectory fragments from both forward and backward passes using a greedy algorithm with single-trajectory refinement via Gaussian process regression.

## Key Results
- Achieves HOTA score of 84.54% on KITTI test set, outperforming state-of-the-art methods
- Improves 2D-3D detection fusion accuracy through point-level registration, avoiding bounding box misalignment issues
- Bidirectional trajectory re-optimization reduces ID switches and false negatives compared to unidirectional approaches

## Why This Works (Mechanism)

### Mechanism 1
Point-level object registration improves 2D-3D detection fusion accuracy by avoiding bounding box misalignment issues. The method uses pixel-level segmentation masks and LiDAR point clouds within 3D bounding boxes to compute similarity metrics, directly comparing object points rather than box geometries. This avoids the issues of box misalignment, occlusions, and corner spaces that plague IoU-based approaches.

### Mechanism 2
Normalized Center Distance (NCD) metric improves object similarity evaluation by incorporating size and rotation information while maintaining bounded values. The NCD metric computes the Euclidean distance between object centers and normalizes it by the maximum distance between bounding box vertices. This provides a bounded similarity measure that captures spatial relationships better than IoU or raw center distance alone.

### Mechanism 3
Bidirectional trajectory re-optimization improves tracking accuracy by selecting the best object links from both forward and backward tracking results. The method generates trajectories in both time directions, splits them at common links, and uses a priority-based greedy algorithm to select the best fragments from each direction. This addresses velocity changes and initialization errors that affect unidirectional tracking.

## Foundational Learning

- **Bipartite graph matching**: Used to solve object registration and trajectory association problems by formulating them as optimization problems with assignment matrices. Quick check: What algorithm is typically used to solve the assignment problem in bipartite matching?

- **Kalman filter tracking**: Used for state prediction and update in the initial trajectory generation module, requiring understanding of motion models and covariance updates. Quick check: How does the Kalman filter handle process and measurement noise in object tracking?

- **Point cloud processing**: Required for LiDAR point cloud processing for 2D-3D fusion, including point projection, cropping, and density calculations. Quick check: What coordinate transformation is needed to project 3D LiDAR points into 2D image space?

## Architecture Onboarding

- **Component map**: 2D Instance Segmentation → Point-level Fusion → 3D Object Detection → Initial Trajectory Generation → Bidirectional Tracking → Trajectory Re-optimization → Final Trajectories
- **Critical path**: 2D-3D detection fusion → initial trajectory generation → bidirectional re-optimization
- **Design tradeoffs**: Offline processing enables bidirectional tracking but increases computational cost; point-level fusion is more accurate but computationally heavier than box-level methods; greedy fragment selection is fast but may miss global optima
- **Failure signatures**: High false positives indicate 2D-3D fusion issues; ID switches suggest similarity metric problems; missing objects indicate track management threshold issues
- **First 3 experiments**:
  1. Test 2D-3D fusion accuracy with synthetic data where ground truth correspondences are known
  2. Compare NCD metric performance against IoU and center distance on a validation set
  3. Evaluate bidirectional vs unidirectional tracking on a subset of sequences to measure improvement magnitude

## Open Questions the Paper Calls Out

### Open Question 1
How does the point-level object registration technique compare in performance to alternative 2D-3D detection fusion methods under varying levels of sensor miscalibration? The paper introduces the technique but doesn't conduct controlled experiments varying sensor miscalibration levels to quantify performance differences.

### Open Question 2
What is the computational complexity of the bidirectional trajectory re-optimization module, and how does it scale with increasing numbers of trajectories and objects? The paper describes the approach but doesn't provide explicit complexity analysis or scaling behavior with dataset size.

### Open Question 3
How sensitive is the track management mechanism to the choice of hit-miss thresholds, and what is the optimal strategy for threshold selection in different tracking scenarios? The paper implements specific thresholds but doesn't investigate sensitivity analysis or provide guidance on threshold selection.

## Limitations

- Method is offline-only, limiting real-time applications and requiring full sequence storage
- Performance depends heavily on pre-trained detector quality and cannot recover from systematic detector failures
- Computational complexity scales with sequence length and object density, potentially prohibitive for long sequences

## Confidence

- **High Confidence**: Core framework architecture and 2D-3D fusion methodology are well-described and reproducible
- **Medium Confidence**: Implementation details for single-trajectory refinement (Gaussian process regression kernel, confidence weighting) are referenced but not fully specified
- **Medium Confidence**: Performance claims rely on KITTI dataset, which may not generalize to other domains with different object densities, sensor configurations, or environmental conditions

## Next Checks

1. **Implementation Validation**: Compare BiTrack's fused detection quality against baseline IoU-based methods using controlled synthetic data with known ground truth correspondences to verify claimed accuracy improvements

2. **Cross-Dataset Generalization**: Test the complete pipeline on nuScenes or Waymo datasets to assess robustness to different sensor configurations and object densities beyond KITTI

3. **Computational Analysis**: Measure actual runtime and memory usage on sequences of varying length and object density to quantify the offline processing cost and identify scalability limits