---
ver: rpa2
title: 'KISS-Matcher: Fast and Robust Point Cloud Registration Revisited'
arxiv_id: '2409.15615'
source_url: https://arxiv.org/abs/2409.15615
tags:
- registration
- point
- cloud
- ieee
- fpfh
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents KISS-Matcher, a fast and robust point cloud
  registration library that combines several technical innovations to achieve state-of-the-art
  performance. The key contributions include Faster-PFH, an optimized version of the
  classical FPFH descriptor that reduces unnecessary computations by subsampling points
  for normal estimation and filtering out unreliable points based on linearity; k-core-based
  graph-theoretic pruning to efficiently reject outlier correspondences with linear
  time complexity instead of exponential; and geometric suppression to filter out
  repeating patterns like ground and walls.
---

# KISS-Matcher: Fast and Robust Point Cloud Registration Revisited

## Quick Facts
- arXiv ID: 2409.15615
- Source URL: https://arxiv.org/abs/2409.15615
- Authors: Hyungtae Lim, Daebeom Kim, Gunhee Shin, Jingnan Shi, Ignacio Vizzo, Hyun Myung, Jaesik Park, Luca Carlone
- Reference count: 40
- Key outcome: Achieves 4.5-20× speedup over TEASER++ while maintaining similar accuracy, operates at ~14 Hz vs ~6 Hz for TEASER++, and handles map-level registration problems

## Executive Summary
This paper presents KISS-Matcher, a fast and robust point cloud registration library that combines several technical innovations to achieve state-of-the-art performance. The method introduces Faster-PFH, an optimized version of FPFH that reduces unnecessary computations through subsampling and filtering unreliable points; k-core-based graph-theoretic pruning that efficiently rejects outlier correspondences with linear time complexity; and geometric suppression to filter out repeating patterns like ground and walls. Extensive experiments show KISS-Matcher achieves 4.5-20× speedup over TEASER++ while maintaining similar accuracy, operates at ~14 Hz for entire pipeline versus ~6 Hz for TEASER++, and successfully handles map-level registration problems where other methods fail.

## Method Summary
KISS-Matcher is a four-component point cloud registration pipeline consisting of geometric suppression (preprocessing), Faster-PFH feature extraction and matching, k-core-based graph-theoretic outlier pruning, and GNC-based non-minimal solver. The method optimizes the classical FPFH descriptor by subsampling points for normal estimation and filtering out unreliable points based on linearity, achieving significant speedups. It uses k-core decomposition to efficiently reject outlier correspondences with linear time complexity instead of exponential, and applies geometric suppression to remove repeating patterns that create overwhelming outliers. The approach is particularly effective for large-scale registration tasks and demonstrates superior scalability from scan-level to map-level applications.

## Key Results
- Achieves 4.5-20× speedup over TEASER++ while maintaining similar accuracy
- Operates at ~14 Hz for entire pipeline versus ~6 Hz for TEASER++
- Successfully handles map-level registration problems where other methods fail
- Demonstrates superior scalability from scan-level to map-level applications

## Why This Works (Mechanism)

### Mechanism 1
Faster-PFH reduces computation by subsampling points for normal estimation and filtering out unreliable points based on linearity, achieving 4.5-20× speedup over TEASER++. The method performs radius search only once, then subsamples neighboring points for normal estimation and rejects points with high linearity (λ1-λ2/λ1 > τlin) or insufficient neighbors (less than τnum), thereby avoiding unnecessary FPFH computation on unreliable points. Core assumption: Points with high linearity or insufficient neighbors produce unreliable normal vectors, making their FPFH features meaningless for registration. Break condition: If τnum is set too low, more unreliable points will be processed; if τlin is set too high, too many points will be filtered out, reducing the number of valid correspondences.

### Mechanism 2
k-core-based graph-theoretic pruning achieves linear time complexity O(|V| + |E|) for outlier rejection instead of exponential complexity. Constructs a compatibility graph where vertices represent correspondences and edges connect mutually consistent pairs based on pairwise-invariant inequality, then finds maximum k-core to identify inliers and filter outliers. Core assumption: Inlier correspondences must satisfy the pairwise-invariant inequality -2β ≤ ||bj - bj'|| - ||ai - ai'|| ≤ 2β, where β is the inlier noise bound. Break condition: If β is set too large, many outlier pairs will be considered compatible; if Nτ is too small, valid correspondences will be prematurely filtered out.

### Mechanism 3
Geometric suppression as preprocessing removes repeating patterns (ground, walls) that create overwhelming outliers in correspondence matching. Identifies and removes points belonging to planar surfaces before feature extraction, reducing the number of potential spurious correspondences. Core assumption: Points on planar surfaces (ground, ceiling, walls) generate many incorrect correspondences when matched to other planar surfaces due to their lack of distinctive geometric features. Break condition: If geometric suppression removes too many points, the remaining cloud may lack sufficient distinctive features for reliable registration.

## Foundational Learning

- **Normal vector estimation using PCA on neighboring points**
  - Why needed here: Normal vectors are essential for computing angular features in FPFH/Faster-PFH descriptors
  - Quick check question: What condition makes normal vector estimation unreliable in point cloud registration?

- **Graph k-core decomposition**
  - Why needed here: Used to efficiently find large sets of mutually consistent correspondences for outlier rejection
  - Quick check question: How does finding a k-core in the compatibility graph help identify inliers?

- **Graduated Non-Convexity (GNC) for robust optimization**
  - Why needed here: Solves the registration problem robustly even after some outliers remain after graph-theoretic pruning
  - Quick check question: Why is GNC preferred over standard least-squares for point cloud registration with outliers?

## Architecture Onboarding

- **Component map**: Geometric suppression -> Faster-PFH -> k-core pruning -> GNC solver
- **Critical path**: Geometric suppression must complete before feature extraction, and k-core pruning must complete before the solver can run
- **Design tradeoffs**: Faster-PFH trades some descriptor expressiveness for speed by subsampling and filtering; k-core pruning trades optimal outlier rejection (MCIS) for linear complexity; geometric suppression trades completeness for robustness by removing potentially useful planar features
- **Failure signatures**: Low success rate indicates poor parameter tuning; slow performance suggests k-core pruning is still processing too many correspondences; poor accuracy suggests geometric suppression removed too many distinctive features
- **First 3 experiments**:
  1. Run with default parameters on KITTI 10m benchmark to establish baseline success rate and runtime
  2. Vary τlin from 0.9 to 0.99 to find optimal balance between speed and accuracy
  3. Compare k-core pruning runtime vs number of input correspondences to verify linear scaling

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal parameterization of τnum and τlin thresholds across different sensor types and environments beyond the voxel size-based approach tested in the paper? The paper only tested these specific parameters on KITTI and MulRan datasets with 64-channel LiDAR. Different sensor configurations may require different threshold values for optimal performance.

### Open Question 2
How does KISS-Matcher's performance scale when registering point clouds with non-rigid deformations or dynamic objects that violate the rigid body assumption? The paper focuses on rigid point cloud registration problems but doesn't address scenarios where objects move independently between frames.

### Open Question 3
What is the theoretical lower bound on registration accuracy for point cloud registration algorithms when the overlap ratio between source and target clouds becomes very small? While the paper demonstrates strong performance in typical registration scenarios, it doesn't establish fundamental limits on registration accuracy when the source and target clouds share minimal overlap.

## Limitations
- GNC solver implementation lacks detailed specifications about robust loss function and convergence criteria
- Parameter sensitivity may require careful re-tuning for different sensor types or environmental conditions
- Geometric suppression mechanism lacks detailed implementation specifications for handling various repeating patterns

## Confidence

**High Confidence**: Claims about Faster-PFH's computational efficiency (4.5-20× speedup) and the overall pipeline's speed (14 Hz vs 6 Hz for TEASER++) are well-supported by systematic experiments across multiple datasets and point cloud sizes.

**Medium Confidence**: The k-core pruning effectiveness relies on proper parameter selection and the assumption that most correspondences are outliers. The linear complexity claim is theoretically sound but may vary in practice depending on graph density.

**Low Confidence**: The geometric suppression mechanism lacks detailed implementation specifications, making it difficult to assess its actual contribution to robustness or determine optimal parameters for different environments.

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically vary τnum (1-5), τlin (0.95-0.995), and β (1.0v-2.0v) on KITTI 10m benchmark to identify parameter regimes where performance degrades and understand the robustness envelope.

2. **Cross-Dataset Generalization**: Test KISS-Matcher on datasets with different characteristics (e.g., urban vs indoor, varying point densities, different sensor modalities) to evaluate whether the reported performance generalizes beyond the training domains.

3. **Breakdown Analysis**: Conduct ablation studies to isolate the individual contributions of Faster-PFH, k-core pruning, and geometric suppression to overall accuracy and speed, particularly for cases where the method fails or produces large errors.