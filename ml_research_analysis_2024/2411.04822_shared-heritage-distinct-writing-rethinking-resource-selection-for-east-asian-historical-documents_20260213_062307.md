---
ver: rpa2
title: 'Shared Heritage, Distinct Writing: Rethinking Resource Selection for East
  Asian Historical Documents'
arxiv_id: '2411.04822'
source_url: https://arxiv.org/abs/2411.04822
tags:
- chinese
- classical
- data
- hanja
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study challenges the assumption that Classical Chinese resources\
  \ benefit language models for historical East Asian documents. Comprehensive experiments\
  \ across machine translation, named entity recognition, and punctuation restoration\
  \ tasks reveal minimal improvements from incorporating Classical Chinese data for\
  \ Hanja documents, with performance differences within \xB10.0068 F1-score for sequence\
  \ labeling tasks and up to +0.84 BLEU score for translation."
---

# Shared Heritage, Distinct Writing: Rethinking Resource Selection for East Asian Historical Documents

## Quick Facts
- **arXiv ID**: 2411.04822
- **Source URL**: https://arxiv.org/abs/2411.04822
- **Reference count**: 40
- **Key outcome**: Classical Chinese resources provide minimal improvement for Hanja documents when sufficient local data exists

## Executive Summary
This study challenges the assumption that Classical Chinese resources benefit language models for historical East Asian documents. Through comprehensive experiments across machine translation, named entity recognition, and punctuation restoration tasks, the researchers demonstrate that incorporating Classical Chinese data shows minimal improvements for Hanja documents, with performance differences within ±0.0068 F1-score for sequence labeling tasks. The findings persist across various model sizes, architectures, and domain-specific datasets, showing substantial improvements only in extremely low-resource scenarios.

The research reveals that while Classical Chinese and Hanja share many characters, linguistic divergence occurs at deeper levels than shared character vocabulary. Benefits diminish rapidly as local Hanja data increases, with the study emphasizing the need for careful empirical validation rather than assuming benefits from indiscriminate cross-lingual transfer.

## Method Summary
The study investigates cross-lingual transfer from Classical Chinese to Hanja through fine-tuning experiments on three NLP tasks: machine translation, named entity recognition, and punctuation restoration. Researchers used Qwen2-7B for MT tasks and SikuRoBERTa for NER and PR tasks, comparing models trained with and without Classical Chinese data. The experimental framework systematically varied Hanja:Lzh ratios (1:0, 1:1, 1:2, 1:4, 1:8) and tested different document types (royal records vs literary works). Performance was evaluated using BLEU scores for MT and F1-scores for NER/PR, with paired bootstrap resampling for statistical significance testing.

## Key Results
- Classical Chinese resources provide benefit only for extremely low-resource scenarios, with effectiveness diminishing rapidly as local language data increases
- Performance differences for sequence labeling tasks remain within ±0.0068 F1-score when Classical Chinese data is added
- Incorporating Classical Chinese data shows mixed results overall, while careful selection of similar writing styles can lead to marginal improvements
- Models trained on royal Hanja documents perform poorly on literary Hanja texts (BLEU scores below 11.82)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual transfer from Classical Chinese to Hanja shows minimal improvement because linguistic divergence occurs at deeper levels than shared character vocabulary.
- Mechanism: While Classical Chinese and Hanja share many characters, the languages have evolved distinct grammatical structures, semantic interpretations of characters, and domain-specific usage patterns over centuries of independent development.
- Core assumption: Shared writing systems imply shared linguistic patterns that transfer effectively across languages.
- Evidence anchors:
  - [abstract] "while showing substantial improvements only in extremely low-resource scenarios for both Korean and Japanese historical documents"
  - [section] "Our investigation reveals that Classical Chinese resources provide benefit for only extremely low-resource scenarios, with their effectiveness diminishing rapidly as local language data increases for Hanja"
  - [corpus] Weak evidence - the corpus analysis shows minimal character-level divergence but doesn't explain deeper linguistic differences
- Break condition: When sufficient local Hanja data exists (approximately 1/8 the volume of Classical Chinese data), the benefits of Classical Chinese resources diminish below 5.5% improvement across all tasks.

### Mechanism 2
- Claim: The effectiveness of cross-lingual transfer is highly dependent on the specific domain and writing style of the target documents.
- Mechanism: Different document types (royal records vs literary works) exhibit distinct linguistic patterns, and Classical Chinese resources are more effective when the domain and writing style align closely with the target documents.
- Core assumption: All Hanja documents share similar linguistic characteristics that would benefit equally from Classical Chinese resources.
- Evidence anchors:
  - [abstract] "incorporating Classical Chinese data shows mixed results overall, while careful selection of similar writing styles—such as using Chinese classical poetry for Korean literary works—can lead to marginal improvements"
  - [section] "Our results reveal a clear division between royal and literary Hanja texts. Models trained on HjR perform poorly on HjL (BLEU scores below 11.82)"
  - [corpus] Moderate evidence - the KLC dataset reveals diverse writing styles from individual scholars that differ from government chronicles
- Break condition: When document types have fundamentally different purposes and authorship patterns (government chronicles vs individual literary works), cross-lingual transfer becomes ineffective.

### Mechanism 3
- Claim: Low-resource scenarios are the only conditions where cross-lingual transfer from Classical Chinese provides meaningful benefits.
- Mechanism: In extremely low-resource settings, the additional data from Classical Chinese provides regularization effects and pattern coverage that would otherwise be unavailable, but this benefit disappears as local data increases.
- Core assumption: Adding more data always improves model performance regardless of the source language.
- Evidence anchors:
  - [abstract] "Classical Chinese resources provide benefit for only extremely low-resource scenarios, with their effectiveness diminishing rapidly as local language data increases for Hanja"
  - [section] "We hypothesize that sufficient Hanja data exists to train effective language models without relying on Classical Chinese resources"
  - [corpus] Strong evidence - the token count analysis shows available Hanja training data exceeds Classical Chinese by factors of 4.4, 18.6, and 6.8 for different tasks
- Break condition: When Hanja data volume reaches approximately 12.5% of Classical Chinese data volume, the benefits of cross-lingual transfer become negligible.

## Foundational Learning

- Concept: Statistical significance testing and its interpretation
  - Why needed here: The paper uses paired bootstrap resampling and Mann-Whitney U tests to determine whether performance differences are meaningful, which is critical for understanding when results are actually improvements vs noise
  - Quick check question: If a model shows +0.84 BLEU improvement but the paired bootstrap test shows p > 0.05, is this considered a meaningful improvement?

- Concept: Low-resource vs high-resource learning dynamics
  - Why needed here: The paper demonstrates that cross-lingual transfer effectiveness varies dramatically based on data availability, requiring understanding of how models behave differently in scarce vs abundant data regimes
  - Quick check question: Why would adding Classical Chinese data help more in low-resource scenarios but potentially harm performance in high-resource scenarios?

- Concept: Domain adaptation and transfer learning principles
  - Why needed here: The paper shows that even within the same writing system, different document types (royal vs literary) require different approaches, illustrating the importance of domain alignment in transfer learning
  - Quick check question: What would happen if you trained a model on Classical Chinese poetry and tested it on Hanja government chronicles?

## Architecture Onboarding

- Component map: Data preprocessing pipeline -> Model training framework -> Evaluation system
- Critical path: Data preprocessing → Model training (with/without Classical Chinese data) → Evaluation (task-specific metrics + statistical testing) → Analysis of results across different data ratios and document types
- Design tradeoffs: Using Classical Chinese data provides potential benefits in low-resource scenarios but risks introducing linguistic noise and domain mismatch; the tradeoff depends on data availability and document type specificity
- Failure signatures: If models show improved training loss but decreased validation performance when adding Classical Chinese data, this indicates domain mismatch; if performance plateaus at similar levels regardless of Classical Chinese inclusion, this suggests insufficient linguistic similarity
- First 3 experiments:
  1. Train MT models with 100% Hanja data vs 100% Classical Chinese data on HjR documents to establish baseline performance differences
  2. Systematically vary the Hanja:Lzh ratio (1:0, 1:1, 1:2, 1:4, 1:8) for MT on HjL documents to identify the diminishing returns threshold
  3. Compare model performance across different document types (HjR vs HjL) when trained with and without Classical Chinese data to validate domain-specific effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: At what precise threshold ratio of Hanja to Classical Chinese training data do the benefits of Classical Chinese resources diminish for different NLP tasks (MT, NER, PR)?
- Basis in paper: Explicit - Figure 3 and Table 15 show performance differences across varying Hanja data ratios
- Why unresolved: The paper identifies that benefits diminish around 1/8 ratio but doesn't specify task-specific thresholds or whether the optimal ratio differs by task complexity
- What evidence would resolve it: Task-specific ablation studies across finer-grained ratios (e.g., 1/4, 1/6, 1/8, 1/10) with statistical significance testing for each task type

### Open Question 2
- Question: Which specific linguistic features (syntax, morphology, semantic concepts) account for the limited cross-lingual transfer despite minimal character-level divergence?
- Basis in paper: Explicit - The paper notes that character-level divergence is minimal but transfer is still poor, suggesting deeper linguistic differences
- Why unresolved: The paper identifies the phenomenon but doesn't conduct detailed linguistic analysis of what features specifically differ between Classical Chinese and Hanja
- What evidence would resolve it: Comparative linguistic analysis of syntactic structures, semantic shifts, and domain-specific terminology across the writing systems using corpus linguistics methods

### Open Question 3
- Question: How do different types of Classical Chinese data (genre, period, authorship) affect transfer effectiveness to different Hanja genres?
- Basis in paper: Explicit - Section 4.3 shows domain-specific transfer learning experiments but only with broad domain categories
- Why unresolved: The paper tests only three broad domains (History, Religion, Miscellaneous) without examining finer-grained genre distinctions or temporal variations
- What evidence would resolve it: Systematic experiments varying Classical Chinese data by specific genres (poetry, prose, historical chronicles), time periods, and authorship types paired with Hanja data of corresponding genres

## Limitations

- Findings may not generalize to other East Asian languages or writing systems that share Classical Chinese heritage
- The study cannot fully capture deeper semantic and grammatical differences that may affect transfer learning effectiveness
- Experimental scope is constrained to three specific NLP tasks, potentially missing task-specific dynamics

## Confidence

- **High Confidence**: Minimal improvement from Classical Chinese resources for Hanja documents with sufficient local data (supported by extensive empirical evidence)
- **Medium Confidence**: Domain and writing style alignment significantly impacts transfer learning effectiveness (limited to two specific document categories)
- **Low Confidence**: Generalizability of findings to other historical East Asian languages and writing systems (focuses exclusively on Korean and Japanese)

## Next Checks

1. **Cross-Lingual Generalization Test**: Replicate the experimental framework using Vietnamese historical documents (Hán-Nôm) to determine whether the minimal transfer benefits observed for Korean and Japanese Hanja documents extend to other languages with Classical Chinese heritage.

2. **Deeper Linguistic Analysis**: Conduct comprehensive linguistic feature analysis comparing Classical Chinese and Hanja at syntactic, semantic, and discourse levels to identify specific linguistic divergences that explain the limited transfer effectiveness observed in the experiments.

3. **Extended Task Suite Validation**: Expand the experimental scope to include additional NLP tasks such as document classification, sentiment analysis, and information extraction to determine whether task complexity or nature influences the effectiveness of cross-lingual transfer from Classical Chinese resources.