---
ver: rpa2
title: 'Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates
  for Efficient and Effective Retrieval'
arxiv_id: '2405.12801'
source_url: https://arxiv.org/abs/2405.12801
tags:
- candidates
- candidate
- entity
- query
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes CMC, a novel reranking framework that jointly
  compares a query and multiple candidates using shallow self-attention layers. CMC
  leverages pre-computed candidate embeddings and parallel computation to efficiently
  rerank a large number of candidates, offering a balance between effectiveness and
  scalability.
---

# Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval

## Quick Facts
- arXiv ID: 2405.12801
- Source URL: https://arxiv.org/abs/2405.12801
- Reference count: 23
- Primary result: CMC framework jointly compares query and multiple candidates using shallow self-attention, improving recall at various K with minimal additional latency

## Executive Summary
This paper introduces CMC (Comparing Multiple Candidates), a novel reranking framework that leverages shallow self-attention layers to jointly compare a query with multiple candidate embeddings. Unlike traditional cross-encoders that process candidates one-by-one, CMC contextualizes each candidate's representation by comparing it with other candidates and the query simultaneously. The framework achieves a balance between effectiveness and scalability, functioning as a "virtually enhanced retriever" that improves recall at various K with minimal additional latency compared to bi-encoders.

## Method Summary
CMC processes a query and multiple candidate embeddings through shallow self-attention layers to generate contextualized representations. The framework uses pre-computed single vector embeddings for each candidate, stored offline for efficiency. During inference, query and candidate embeddings are concatenated and passed through self-attention layers, producing enriched representations that capture relationships between candidates. Final scores are computed via dot products of contextualized query and candidate embeddings. The entire process is parallelizable, allowing CMC to rerank large numbers of candidates with latency comparable to bi-encoders while achieving accuracy closer to cross-encoders.

## Key Results
- CMC achieves 11x speedup compared to cross-encoders while maintaining or improving prediction accuracy
- On ZeSHEL dataset, CMC as a virtually enhanced retriever improves Recall@64 by +3.5% compared to using only bi-encoders
- CMC scales to handle ~10K candidates with similar time requirements as comparing 16 candidates with cross-encoders

## Why This Works (Mechanism)

### Mechanism 1: Contextualized Candidate Representation
CMC improves candidate ranking by contextualizing each candidate's embedding with other candidates and the query through self-attention. This allows each candidate to be compared with others, enriching its representation beyond simple dot product. The core assumption is that a single vector embedding per candidate, when contextualized with others, provides sufficient signal for fine-grained comparison.

### Mechanism 2: Virtually Enhanced Retrieval
CMC functions as a "virtually enhanced retriever" by filtering candidates from an initial retriever with minimal additional latency. Parallel computation of query encoders at bi-encoders and CMC allows the system to rerank candidates with only the latency of its self-attention layer, improving recall at various K without significant slowdown.

### Mechanism 3: Scalable Single-Embedding Approach
CMC achieves scalability by using a single vector embedding per candidate, avoiding the memory and indexing overhead of methods requiring multiple token embeddings. This approach enables interactions among multiple candidates with enhanced scalability while maintaining efficiency through offline pre-computation and storage.

## Foundational Learning

- **Bi-encoder architecture and its efficiency vs. effectiveness trade-off**: Understanding why bi-encoders are fast but less accurate is crucial to appreciating CMC's role in improving accuracy without sacrificing much efficiency. Quick check: Why are bi-encoders less effective than cross-encoders, and how does CMC address this limitation?

- **Self-attention mechanisms and their role in contextualizing representations**: CMC relies on self-attention to compare multiple candidates and the query simultaneously, enriching candidate representations. Quick check: How does self-attention enable CMC to compare multiple candidates jointly, and why is this beneficial compared to comparing candidates one-by-one?

- **Dense retrieval and candidate filtering in multi-stage ranking systems**: CMC functions as both a reranker and a virtually enhanced retriever, requiring understanding of how candidate filtering impacts overall system performance. Quick check: How does improving recall at K with CMC affect the performance of subsequent reranking stages like cross-encoders?

## Architecture Onboarding

- **Component map**: Query Encoder -> Candidate Encoder -> Self-Attention Layer -> Scoring Mechanism
- **Critical path**: Query and candidates are encoded → embeddings are concatenated and processed by self-attention → contextualized embeddings are scored to produce final ranking
- **Design tradeoffs**:
  - Single vs. multiple embeddings per candidate: CMC uses single embeddings for scalability, trading off potential information loss for memory and speed
  - Shallow vs. deep self-attention: CMC uses shallow layers for efficiency, assuming they are sufficient for contextualization
  - Parallel vs. sequential computation: CMC leverages parallel computation to minimize latency, but requires multiple GPUs
- **Failure signatures**:
  - Poor recall despite high candidate set size: Indicates self-attention layers are not effectively contextualizing candidates
  - Latency increase disproportionate to candidate set size: Suggests self-attention layer is becoming a bottleneck
  - Memory errors with large candidate sets: Implies single embeddings are insufficient to represent candidates
- **First 3 experiments**:
  1. Compare CMC's recall@K with bi-encoder and cross-encoder on a small dataset to validate effectiveness
  2. Measure CMC's latency with varying numbers of candidates to confirm scalability claims
  3. Ablate self-attention layers (e.g., remove them) to confirm their contribution to performance improvement

## Open Questions the Paper Calls Out

1. How does the performance of CMC scale when comparing more than 1,000 candidates, especially in datasets with over 1 million candidates?
2. What are the specific biases and error patterns exhibited by CMC, and how do they affect the model's predictions?
3. How does the performance of CMC compare to other reranking methods when using a single vector embedding for each candidate, especially in tasks where the knowledge base is frequently updated?

## Limitations

- Single embedding sufficiency may not capture all relevant information for complex comparisons requiring fine-grained distinctions
- Optimal depth of self-attention layers is not explored, potentially missing opportunities for better contextualization
- Performance with extremely large candidate sets (>1,000) is not extensively validated, raising concerns about scalability

## Confidence

- **High Confidence**: CMC functioning as a virtually enhanced retriever with minimal additional latency is well-supported by experiments
- **Medium Confidence**: Single-vector approach being comparable to cross-encoders in representing candidate information is supported but needs more diverse datasets
- **Low Confidence**: 11x speedup claim is based on specific conditions and may vary with different candidate set sizes and resources

## Next Checks

1. Conduct ablation study on self-attention layers to determine optimal depth for different tasks
2. Evaluate CMC's performance with extremely large candidate sets (100K+) to test scalability limits
3. Design task requiring fine-grained distinctions to test if single embeddings are sufficient compared to multi-token approaches