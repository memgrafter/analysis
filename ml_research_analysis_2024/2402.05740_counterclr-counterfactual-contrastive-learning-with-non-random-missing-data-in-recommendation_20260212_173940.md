---
ver: rpa2
title: 'CounterCLR: Counterfactual Contrastive Learning with Non-random Missing Data
  in Recommendation'
arxiv_id: '2402.05740'
source_url: https://arxiv.org/abs/2402.05740
tags:
- data
- learning
- contrastive
- counterclr
- rating
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes CounterCLR, a novel counterfactual contrastive
  learning framework for recommendation systems that addresses two key issues: selection
  bias and data sparsity in observed user feedback. The core idea is to employ a causality-based
  network (CauNet) to infer non-random missing data and introduce a self-supervised
  contrastive learning task to enhance generalization under sparse data conditions.'
---

# CounterCLR: Counterfactual Contrastive Learning with Non-random Missing Data in Recommendation

## Quick Facts
- arXiv ID: 2402.05740
- Source URL: https://arxiv.org/abs/2402.05740
- Reference count: 40
- Key outcome: CounterCLR outperforms state-of-the-art debiasing methods on real-world datasets, achieving lower MSE (1.0956 on Coat), MAE (0.8008 on Coat), and higher NDCG@5 (0.8002 on Coat) compared to baselines while requiring no additional models or unbiased datasets.

## Executive Summary
CounterCLR addresses selection bias and data sparsity in recommendation systems through a novel counterfactual contrastive learning framework. The method employs a causality-based network (CauNet) to infer non-random missing data and introduces a self-supervised contrastive learning task to enhance generalization under sparse data conditions. Experiments on Coat, Yahoo! R3, and KuaiRec datasets demonstrate that CounterCLR achieves superior performance compared to state-of-the-art debiasing methods while maintaining stability across varying levels of data sparsity.

## Method Summary
CounterCLR is a causality-based contrastive learning framework that combines a causal prediction network (CauNet) with a contrastive learning objective. The CauNet predicts exposure and non-exposure ratings using a three-headed architecture, while the contrastive learning objective enhances generalization by pulling together exposure and non-exposure user preference embeddings. The method requires no additional imputation or propensity models, making it practically preferred for real-world deployment.

## Key Results
- Achieves lower MSE (1.0956 on Coat), MAE (0.8008 on Coat), and higher NDCG@5 (0.8002 on Coat) compared to baselines
- Maintains stable performance across varying levels of data sparsity (10%, 30%, 50% observed data)
- Outperforms state-of-the-art debiasing methods without requiring additional models or unbiased datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CauNet infers non-random missing data by modeling exposure and non-exposure ratings separately under the Potential Outcome Framework.
- Mechanism: The architecture uses a three-headed network where two heads predict exposure ratings (r1_u,i) and non-exposure ratings (r0_u,i) respectively, while a third head estimates propensity scores. The momentum update on the non-exposure head ensures its distribution stays close to the exposure head.
- Core assumption: User preferences are invariant to exposure treatment, so r0_u,i and r1_u,i should follow similar distributions.
- Evidence anchors:
  - [abstract] "The proposed CounterCLR employs a deep representation network, called CauNet, to infer non-random missing data in recommendations"
  - [section] "the rating prediction task under POF is different with the traditional POF problems like investigating the therapeutic effects of different treatments"
  - [corpus] Weak evidence - only general mentions of "causality" and "counterfactual" without specific implementation details
- Break condition: If user preferences actually change based on exposure (e.g., popularity bias affects genuine preference), the assumption breaks and distributions diverge.

### Mechanism 2
- Claim: Contrastive learning enhances generalization under sparse data by learning user preference embeddings that are robust across exposure conditions.
- Mechanism: The contrastive loss pulls together exposure and non-exposure user preference embeddings (f_r1_u and f_r0_u) for the same user while pushing apart embeddings from different users. This creates invariant representations.
- Core assumption: The exposure user preference embedding and non-exposure one should be similar since ratings distribution should be the same between observed and unobserved user-item pairs.
- Evidence anchors:
  - [abstract] "perform user preference modeling by further introducing a self-supervised contrastive learning task"
  - [section] "by minimizing Lcon, we can pull closer f_r1_u and f_r0_u for the user u, and push away f_r1_u and f_r0_u' for u' ≠ u"
  - [corpus] Moderate evidence - mentions contrastive learning for recommendation but lacks specific implementation details
- Break condition: If the contrastive loss overwhelms the primary rating prediction task (β too large), performance degrades despite theoretical benefits.

### Mechanism 3
- Claim: CounterCLR eliminates the need for additional imputation or propensity models by integrating these functions into the CauNet architecture.
- Mechanism: CauNet directly predicts propensity scores using a simple linear transformation with random features, and uses these scores to weight the base loss L_base. This eliminates separate model training.
- Core assumption: A simple random feature regression can provide sufficiently accurate propensity estimates for debiasing.
- Evidence anchors:
  - [abstract] "Our CounterCLR mitigates the selection bias problem without the need for additional models or estimators"
  - [section] "Since the propensity score estimates are not passed to the contrastive learning objective... we can construct a rather simple model for the propensity score estimation"
  - [corpus] Weak evidence - general mentions of propensity scoring but no specific implementation comparisons
- Break condition: If the random feature approach fails to capture complex selection bias patterns, the debiasing will be insufficient.

## Foundational Learning

- Concept: Potential Outcome Framework (POF) in causal inference
  - Why needed here: Provides mathematical framework to model selection bias where observed feedback is systematically different from true user preferences
  - Quick check question: In the diabetes treatment example, what do y(0) and y(1) represent?

- Concept: Self-supervised contrastive learning
  - Why needed here: Enables learning from sparse observed data by creating artificial supervision through similarity/dissimilarity between augmented views
  - Quick check question: What is the key difference between supervised and self-supervised contrastive learning?

- Concept: Matrix Factorization and Neural Collaborative Filtering
  - Why needed here: These serve as the base rating prediction models that CounterCLR enhances with causal and contrastive components
  - Quick check question: How does NCF differ from standard matrix factorization in processing user-item pairs?

## Architecture Onboarding

- Component map: Input → hW1 → (hW2, hW3, propensity) → user preference extractor → contrastive loss
- Critical path: Input → hW1 → (hW2, hW3, propensity) → user preference extractor → contrastive loss
- Design tradeoffs: Simple propensity estimation (random features) vs. accuracy; contrastive loss strength (β) vs. primary task performance; momentum update rate (m) vs. distribution alignment
- Failure signatures: High variance in propensity estimates causing unstable training; contrastive loss overwhelming rating prediction; poor generalization on sparse datasets
- First 3 experiments:
  1. Train CounterCLR on fully observed subset of KuaiRec with varying observed ratios (10%, 30%, 50%) to verify stability claims
  2. Compare MSE/MAE on Coat dataset with DR-NB baseline to confirm debiasing claims
  3. Perform ablation study removing contrastive loss (β=0) to measure its contribution to performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CounterCLR change when using different architectures for the CauNet component, such as attention-based models or graph neural networks, instead of the current neural network design?
- Basis in paper: [inferred] The paper uses a standard neural network for CauNet but does not explore alternative architectures.
- Why unresolved: The paper does not experiment with alternative CauNet architectures, leaving open whether more sophisticated models could further improve performance.
- What evidence would resolve it: Comparative experiments showing CounterCLR performance with CauNet variants using attention mechanisms, graph neural networks, or other advanced architectures against the current design.

### Open Question 2
- Question: What is the impact of varying the momentum parameter (m) in the CauNet on the debiasing performance and generalization ability of CounterCLR?
- Basis in paper: [explicit] The paper mentions using a momentum update for W3 but only fixes m=0.999 without exploring its sensitivity.
- Why unresolved: The optimal value of m is not explored, and its impact on the balance between exposure and non-exposure rating predictions is unclear.
- What evidence would resolve it: Systematic experiments varying m across a range of values and analyzing its effect on MSE, MAE, NDCG, and propensity score estimation accuracy.

### Open Question 3
- Question: How does CounterCLR perform on datasets with different types of selection bias, such as position bias or presentation bias, beyond the MNAR bias studied in the paper?
- Basis in paper: [inferred] The paper focuses on MNAR bias from user self-selection but does not test other bias types.
- Why unresolved: The generalizability of CounterCLR to different bias mechanisms is not established, which is crucial for real-world deployment.
- What evidence would resolve it: Experiments on datasets with known position bias or presentation bias, comparing CounterCLR against specialized debiasing methods for each bias type.

### Open Question 4
- Question: What is the computational overhead of CounterCLR compared to baseline methods, and how does it scale with dataset size and dimensionality?
- Basis in paper: [inferred] The paper does not report training/inference time or memory usage comparisons with baselines.
- Why unresolved: Practical deployment requires understanding the trade-off between performance gains and computational cost.
- What evidence would resolve it: Benchmarking experiments measuring training time, inference latency, and memory consumption of CounterCLR versus baselines across datasets of varying sizes and feature dimensions.

## Limitations
- The effectiveness of the simple random feature approach for propensity estimation versus more sophisticated methods remains unclear
- The specific hyperparameter choices (particularly β and m) appear critical but lack systematic sensitivity analysis
- Performance claims rely heavily on comparisons with baselines that may not be directly comparable in implementation details

## Confidence
- **High Confidence**: The core mechanism of using causality-based inference for non-random missing data in recommendation systems is theoretically sound and well-grounded in causal inference literature.
- **Medium Confidence**: The empirical results showing performance improvements over baselines are promising but would benefit from more extensive ablation studies and comparison with alternative propensity estimation methods.
- **Low Confidence**: The specific hyperparameter choices (particularly the contrastive loss weight β and momentum update rate m) appear to be critical for performance but lack systematic sensitivity analysis.

## Next Checks
1. Conduct systematic ablation studies to quantify the individual contributions of causal debiasing versus contrastive learning to overall performance improvements.
2. Compare the random feature propensity estimation approach against more sophisticated propensity scoring methods on the same datasets to validate the claimed simplicity benefit.
3. Perform extensive sensitivity analysis on key hyperparameters (β, m, t) across multiple random seeds to establish robustness of reported performance gains.