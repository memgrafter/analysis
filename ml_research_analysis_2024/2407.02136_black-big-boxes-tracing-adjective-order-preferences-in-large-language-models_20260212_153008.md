---
ver: rpa2
title: 'Black Big Boxes: Tracing Adjective Order Preferences in Large Language Models'
arxiv_id: '2407.02136'
source_url: https://arxiv.org/abs/2407.02136
tags:
- adjective
- order
- language
- context
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates how large language models acquire adjective\
  \ order preferences\u2014a graded and context-sensitive linguistic phenomenon. Using\
  \ the Pythia model suite, the authors measure model preferences across training\
  \ stages, finding that adjective ordering preferences emerge early in training and\
  \ are strongly influenced by distributional statistics from the training corpus."
---

# Black Big Boxes: Tracing Adjective Order Preferences in Large Language Models

## Quick Facts
- arXiv ID: 2407.02136
- Source URL: https://arxiv.org/abs/2407.02136
- Reference count: 40
- This paper investigates how large language models acquire adjective order preferences—a graded and context-sensitive linguistic phenomenon.

## Executive Summary
This study examines how large language models learn adjective order preferences through distributional statistics in training data. Using the Pythia model suite, the authors track model preferences across training stages, finding that adjective ordering emerges early and is strongly correlated with corpus frequencies. The research reveals that while models primarily learn from distributional patterns, they also generalize to unseen adjective combinations and are influenced by sentence context. Feature attribution methods identify two types of contextual cues that shape preferences, suggesting LMs develop context-sensitive ordering strategies that differ from traditional linguistic theories.

## Method Summary
The study uses Pythia language models (70M to 12B parameters) trained on The Pile corpus to evaluate adjective order preferences on the CAP corpus of 9396 double adjective noun phrases. Models are assessed using AOP-∆ (log probability difference) and AOP-% (percentage of items with positive AOP-∆). The research compares model predictions to Infini-gram statistics from The Pile and analyzes learning dynamics across three phases. Feature attribution methods (Integrated Gradients) identify contextual cues influencing predictions. Four contemporary LLMs (Llama3-8b, OLMo2-7b, OLMo3-7b, Qwen3-8b) are also evaluated for comparison.

## Key Results
- Adjective order preferences emerge early in training and are strongly correlated with distributional statistics from the training corpus
- Simple bigram counts from The Pile account for much of model behavior (correlations of 0.61-0.88)
- Models generalize robustly to unseen adjective combinations, though performance decreases with increasing item difficulty
- Sentence context systematically improves predictions, with contextual cues identified as either local collocational or earlier semantic signals

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language models learn adjective order preferences primarily through distributional statistics in the training corpus, not through abstract linguistic rules.
- Mechanism: The model associates adjective pairs with their observed frequencies during training, creating strong preferences for orders that appear more frequently in the training data.
- Core assumption: The training corpus contains sufficient examples of natural adjective orders that the model can extract reliable frequency statistics.
- Evidence anchors:
  - [abstract] "simple bigram counts from the Pile corpus account for much of model behavior"
  - [section 5.1] "bigram statistics account for a large portion of AOP behaviour, and are strongly correlated with model predictions"
  - [corpus] The Pile corpus contains approximately 300B tokens with naturally occurring adjective pairs
- Break condition: If the training corpus contains insufficient examples of certain adjective combinations, the model cannot learn reliable frequency statistics for those pairs.

### Mechanism 2
- Claim: Language models generalize adjective order preferences to unseen adjective combinations beyond direct memorization.
- Mechanism: The model learns abstract patterns about adjective ordering that apply to new combinations, allowing it to make reasonable predictions even for adjective pairs it hasn't encountered during training.
- Core assumption: The model extracts higher-level principles about adjective ordering that transcend specific adjective pairs.
- Evidence anchors:
  - [abstract] "models also generalize robustly to unseen adjective combinations"
  - [section 5.2] "performance on unseen pairs decreases...likely reflects increasing item difficulty rather than a qualitative change in model generalization"
  - [corpus] Only 0.4% of adjective pairs in CAP are unseen in The Pile, limiting direct evidence
- Break condition: If the model encounters completely novel adjective combinations with no similar patterns in the training data, generalization may fail.

### Mechanism 3
- Claim: Sentence context provides additional information that shapes adjective order preferences beyond what can be determined from the adjective-noun pair alone.
- Mechanism: The model uses contextual cues to disambiguate cases where multiple adjective orders are possible, with certain words in the context serving as signals for preferred ordering.
- Core assumption: Context contains meaningful information that correlates with adjective ordering preferences.
- Evidence anchors:
  - [abstract] "sentence context further shapes preferences, with contextual information systematically improving predictions"
  - [section 6.2] "we identify two classes of contextual cues: local collocational cues and earlier semantic cues"
  - [corpus] Context includes various POS tags (determiners, adverbs, prepositions, nouns) that influence ordering
- Break condition: If context is removed or randomized, the model loses the additional disambiguation information.

## Foundational Learning

- Concept: Distributional learning
  - Why needed here: The model learns adjective order preferences through exposure to patterns in the training data rather than explicit rules
  - Quick check question: Can you explain how a language model learns word order preferences without being explicitly programmed with grammatical rules?

- Concept: Feature attribution methods
  - Why needed here: These methods help identify which specific context tokens influence the model's adjective order predictions
  - Quick check question: What is the purpose of using feature attribution methods like Integrated Gradients in this study?

- Concept: Generalization vs. memorization
  - Why needed here: Understanding whether the model's behavior comes from memorizing specific examples or learning abstract patterns
  - Quick check question: How can you distinguish between a model that memorizes training data versus one that generalizes from it?

## Architecture Onboarding

- Component map: CAP corpus → Pythia models (70M-12B) → Infini-gram statistics → Feature attribution analysis
- Critical path: Data preparation → Model evaluation on adjective order tasks → Analysis of distributional statistics → Generalization assessment → Context analysis
- Design tradeoffs: Using large pre-trained models provides realistic assessment but limits control over training data; intermediate checkpoints enable fine-grained analysis but require substantial computational resources
- Failure signatures: Poor performance on adjective ordering tasks, lack of correlation between model behavior and corpus statistics, inability to generalize to unseen combinations
- First 3 experiments:
  1. Evaluate Pythia models on CAP dataset using AOP-∆ metric to establish baseline performance
  2. Compare model predictions with Infini-gram statistics from The Pile to assess correlation with corpus frequencies
  3. Test model performance on unseen adjective combinations by using intermediate checkpoints with fewer training examples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the exact mechanisms by which local collocational cues and earlier semantic cues interact to influence adjective order preferences in LMs?
- Basis in paper: [explicit] The paper identifies two sources of contextual influence: local collocational cues and earlier semantic cues, but does not detail their interaction.
- Why unresolved: The paper mentions these two sources but does not explore how they might work together or conflict in shaping model preferences.
- What evidence would resolve it: Experimental manipulation of context to isolate and compare the effects of collocational vs. semantic cues on adjective order predictions.

### Open Question 2
- Question: To what extent do LMs' generalization abilities for adjective order reflect abstract linguistic principles versus memorization of frequent patterns?
- Basis in paper: [inferred] The paper discusses the trade-off between memorization and generalization but does not fully resolve how abstract these generalizations are.
- Why unresolved: While the paper shows some generalization, it does not determine if this reflects abstract principles or just more flexible memorization.
- What evidence would resolve it: Corpus interventions removing all double adjective constructions to test if models can still learn adjective order from indirect evidence.

### Open Question 3
- Question: How do the contextual cues identified in LMs compare to the factors that influence human adjective order preferences?
- Basis in paper: [explicit] The paper identifies contextual cues in LMs but notes these are absent from existing human linguistic theories.
- Why unresolved: The paper suggests these cues might inform future human studies but does not compare LM cues to human behavior.
- What evidence would resolve it: Empirical studies measuring human adjective order preferences with manipulated contextual cues similar to those identified in LMs.

## Limitations

- The study's primary limitation is the restricted size of unseen adjective pairs (only 0.4% of CAP items), which constrains the strength of evidence for genuine generalization beyond memorization.
- The reliance on Pythia models trained on The Pile corpus means results may not generalize to models with different training data or architectures.
- The feature attribution analysis, while identifying contextual cues, cannot definitively prove causal relationships between specific context tokens and adjective order preferences.

## Confidence

- **High confidence:** The claim that distributional statistics from training data strongly influence adjective order preferences is well-supported by the high correlations (0.61-0.88) between model predictions and bigram frequencies across model sizes.
- **Medium confidence:** The assertion that models generalize to unseen adjective combinations is plausible but limited by the small sample size of truly unseen pairs in the evaluation corpus.
- **Medium confidence:** The identification of contextual cues influencing adjective order is methodologically sound, though the interpretation of feature attribution results requires careful consideration of potential confounding factors.

## Next Checks

1. **Replicate with alternative model families:** Test whether similar adjective order patterns emerge in models trained on different corpora (e.g., C4, Common Crawl) to assess the robustness of distributional learning effects.
2. **Expand unseen pair evaluation:** Create a dedicated test set with a larger proportion of adjective pairs absent from training data to more rigorously evaluate generalization capabilities.
3. **Controlled intervention study:** Systematically manipulate context tokens identified as influential through feature attribution and measure resulting changes in adjective order predictions to establish causal relationships.