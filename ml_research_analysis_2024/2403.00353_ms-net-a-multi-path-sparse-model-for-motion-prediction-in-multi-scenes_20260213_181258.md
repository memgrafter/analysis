---
ver: rpa2
title: 'MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes'
arxiv_id: '2403.00353'
source_url: https://arxiv.org/abs/2403.00353
tags:
- layer
- prediction
- knowledge
- ms-net
- motion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents MS-Net, a multi-path sparse model for motion
  prediction across multiple traffic scenarios (merging, roundabout, intersection).
  The key idea is to decompose the multi-scene prediction task into a multi-task learning
  problem and use an evolutionary algorithm to learn optimal parameter subsets for
  each scenario while sharing common knowledge.
---

# MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes

## Quick Facts
- arXiv ID: 2403.00353
- Source URL: https://arxiv.org/abs/2403.00353
- Authors: Xiaqiang Tang; Weigao Sun; Siyuan Hu; Yiyang Sun; Yafeng Guo
- Reference count: 40
- One-line primary result: MS-Net achieves 9% ADE reduction on ETH/UCY and ranks 2nd on INTERACTION challenge leaderboard

## Executive Summary
This paper presents MS-Net, a multi-path sparse model for motion prediction across multiple traffic scenarios (merging, roundabout, intersection). The key innovation is decomposing the multi-scene prediction task into a multi-task learning problem and using an evolutionary algorithm to learn optimal parameter subsets for each scenario while sharing common knowledge. By selectively activating scenario-relevant parameters during inference, MS-Net improves over existing unified models in both accuracy and efficiency. Experiments demonstrate strong performance on both ETH/UCY pedestrian trajectories and INTERACTION vehicle trajectories, with the model ranking 2nd in the INTERACTION challenge.

## Method Summary
MS-Net addresses multi-scene motion prediction by treating it as a multi-task learning problem where each traffic scenario is a separate task. The method initializes a Knowledge Pool with a meta-model, then uses an evolutionary algorithm to generate scenario-specific sub-models through Knowledge Transfer (copying and freezing layers from parent models) and Model Evolution (dynamically adding/removing layers). A Scoring Function selects optimal sub-models based on accuracy and parameter efficiency. During inference, only the relevant sub-model parameters for a given scenario are activated, creating a sparse model that combines the benefits of shared knowledge and scenario-specific optimization.

## Key Results
- Achieves 9% ADE reduction compared to state-of-the-art unified models on ETH/UCY dataset
- Ranks 2nd in the INTERACTION challenge leaderboard
- Reduces model size by selectively activating scenario-specific parameters
- Improves inference time through sparse parameter activation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MS-Net improves prediction accuracy by decomposing multi-scene motion prediction into a multi-task learning problem and selectively activating scenario-specific parameters during inference.
- Mechanism: The method creates a sparse model where only a small subset of parameters is activated for each traffic scenario through an evolutionary algorithm that learns optimal parameter subsets.
- Core assumption: Different traffic scenarios have distinct characteristics that can be better captured by scenario-specific parameter subsets rather than a single unified model.
- Evidence anchors:
  - [abstract] "MS-Net selectively activates a subset of its parameters during the inference stage to produce prediction results for each scene."
  - [section] "MS-Net employs a multi-path sparse model that only activates a small subset of parameters in the model for each traffic scenario"
  - [corpus] Weak evidence. Related works focus on trajectory prediction but do not directly discuss parameter sparsity or evolutionary algorithms for multi-scene learning.
- Break condition: If the evolutionary algorithm fails to find effective parameter subsets for each scenario, or if the parameter sharing mechanism leads to catastrophic forgetting.

### Mechanism 2
- Claim: The evolutionary algorithm improves model efficiency by dynamically compressing or expanding the network architecture based on scenario complexity.
- Mechanism: The Model Evolution component randomly removes or adds layers during sub-model generation, with mutation rate controlling the probability of these changes.
- Core assumption: Traffic scenarios have varying levels of complexity that require different model capacities for optimal performance.
- Evidence anchors:
  - [section] "Model Evolution mechanism to dynamically compress or expand the motion forecasting models" and "our evolution algorithm only targets those components to perform mutational operations"
  - [abstract] "an evolutionary algorithm is designed to encourage the network search of the optimal parameters for each scene"
  - [corpus] No direct evidence. Related works discuss trajectory prediction but not evolutionary algorithms for model architecture adaptation.
- Break condition: If the mutation rate is too high, leading to unstable evolution, or too low, preventing adequate exploration of model architectures.

### Mechanism 3
- Claim: Knowledge Transfer mechanism enables effective sharing of common knowledge across scenarios while preventing catastrophic forgetting.
- Mechanism: Selected layers from the parent model are copied to sub-models and fine-tuned for specific scenarios, while remaining layers are frozen to preserve previously learned knowledge.
- Core assumption: There exists common knowledge across different traffic scenarios that can be shared while maintaining scenario-specific distinctiveness.
- Evidence anchors:
  - [section] "Knowledge Transfer mechanism randomly selects each layer l in m with a probability of mutation rate... Those copies of layers can be fine-tuned by the sub-model during the training process"
  - [abstract] "sharing common knowledge between different scenes"
  - [corpus] No direct evidence. Related works discuss trajectory prediction but not knowledge transfer mechanisms with frozen layers.
- Break condition: If the frozen layer mechanism fails to prevent catastrophic forgetting, or if the fine-tuning process overfits to specific scenarios.

## Foundational Learning

- Concept: Multi-task learning
  - Why needed here: MS-Net frames motion prediction across different traffic scenarios as a multi-task learning problem, where each scenario is treated as a separate task that shares some parameters with other tasks.
  - Quick check question: How does multi-task learning differ from single-task learning, and what are the potential benefits and challenges of sharing parameters across tasks?

- Concept: Evolutionary algorithms
  - Why needed here: The evolutionary algorithm is used to search for optimal parameter subsets for each traffic scenario by iteratively generating and evaluating sub-models through mutation and selection operations.
  - Quick check question: What are the key components of an evolutionary algorithm, and how do mutation and selection operations contribute to finding optimal solutions?

- Concept: Catastrophic forgetting
  - Why needed here: When fine-tuning models for new scenarios, there's a risk of overwriting previously learned knowledge. The Knowledge Transfer mechanism with frozen layers is designed to prevent this by preserving common knowledge across scenarios.
  - Quick check question: What is catastrophic forgetting in the context of neural networks, and what are some strategies to mitigate it when training on sequential tasks?

## Architecture Onboarding

- Component map: Knowledge Pool -> Evolutionary Algorithm -> Sub-model Generation (Model Evolution + Knowledge Transfer) -> Scoring Function -> Selected Sub-models
- Critical path: The critical path for training MS-Net involves: 1) Initializing the Knowledge Pool with a meta-model, 2) Selecting a parent model from the pool, 3) Generating sub-models through Model Evolution and Knowledge Transfer, 4) Training sub-models on specific scenarios, 5) Evaluating sub-models using the scoring function, and 6) Adding the best sub-model to the Knowledge Pool.
- Design tradeoffs: MS-Net trades increased training time (due to sampling multiple child models) for improved inference efficiency and prediction accuracy. The evolutionary approach allows for dynamic adaptation to scenario complexity but requires careful tuning of mutation rates and scoring functions.
- Failure signatures: Potential failure modes include: 1) Evolutionary algorithm failing to find effective parameter subsets (leading to poor performance), 2) Catastrophic forgetting due to inadequate frozen layer mechanism, 3) Overfitting to specific scenarios due to insufficient parameter sharing, 4) Increased training time becoming prohibitive for real-time applications.
- First 3 experiments:
  1. Implement the Knowledge Transfer mechanism with frozen layers on a simple multi-task learning problem to verify that common knowledge is preserved while allowing task-specific adaptation.
  2. Test the Model Evolution component by applying mutational operations to a baseline model and evaluating the impact on performance and parameter count.
  3. Evaluate the scoring function by generating multiple sub-models with varying parameter counts and accuracies, then selecting the optimal sub-model based on the scoring criteria.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MS-Net compare when applied to pedestrian datasets without map information versus vehicle datasets with detailed map data?
- Basis in paper: [explicit] The paper notes that Agentformer, which doesn't require map information, significantly improved with MS-Net, while AutoBot, which uses detailed map data, also showed improvement. The authors suggest this difference might be due to the nature of the datasets.
- Why unresolved: The paper doesn't directly compare MS-Net's performance on pedestrian versus vehicle datasets, nor does it isolate the impact of map information availability on MS-Net's effectiveness.
- What evidence would resolve it: A controlled experiment applying MS-Net to both pedestrian and vehicle datasets, with and without map information, would clarify whether the performance gains are consistent across different data types and how map information influences the results.

### Open Question 2
- Question: What is the optimal number of sub-models to generate per scenario in the evolutionary algorithm, and how does this affect the trade-off between performance and computational efficiency?
- Basis in paper: [explicit] The paper states that MS-Net was trained for 3 generations, sampling three sub-models for each scenario in ETH/UCY and five for INTERACTION. However, it doesn't explore whether these numbers are optimal or how varying them impacts results.
- Why unresolved: The paper doesn't provide a sensitivity analysis on the number of sub-models generated, leaving uncertainty about whether the chosen numbers are ideal for balancing performance gains with increased training time and computational cost.
- What evidence would resolve it: A comprehensive study varying the number of sub-models per generation and measuring the resulting performance improvements against computational costs would determine the optimal configuration.

### Open Question 3
- Question: How does MS-Net's performance degrade or improve when applied to scenarios outside its training distribution, such as rare or unseen traffic situations?
- Basis in paper: [inferred] While MS-Net shows strong performance on standard datasets, the paper doesn't address its ability to generalize to novel scenarios. The focus is on known scenarios within ETH/UCY and INTERACTION datasets.
- Why unresolved: The paper doesn't include experiments testing MS-Net's robustness to out-of-distribution scenarios or rare traffic events not present in the training data.
- What evidence would resolve it: Testing MS-Net on a diverse set of scenarios, including edge cases and rare events not seen during training, would reveal its generalization capabilities and limitations in real-world deployment.

## Limitations
- Lacks specific mutation rates and hyperparameter ranges for the evolutionary algorithm beyond a single value (0.2)
- Doesn't specify exact architecture of base Transformer models used as meta-models
- Evaluation on ETH/UCY uses different prediction horizons (8â†’12 timesteps) compared to typical benchmarks, affecting comparability

## Confidence

- Multi-task decomposition effectiveness: **Medium** - The 9% ADE improvement over unified models is compelling, but the lack of ablation studies on the evolutionary algorithm's contribution creates uncertainty about whether parameter sparsity or the evolutionary search itself drives performance gains.
- Knowledge Transfer mechanism: **Low-Medium** - While the frozen layer concept is sound, the paper doesn't provide evidence that catastrophic forgetting is effectively prevented, nor does it quantify the trade-off between parameter sharing and scenario-specific optimization.
- Model efficiency claims: **Medium** - The reported parameter reduction and inference speed improvements are notable, but without baseline comparisons showing what a standard multi-scene model would require, it's unclear if the gains are exceptional or expected from sparsity.

## Next Checks

1. **Ablation on evolutionary vs static sparsity**: Train a variant of MS-Net where parameter subsets are manually designed rather than evolved, to isolate the contribution of the evolutionary algorithm from the benefits of parameter sparsity itself.

2. **Catastrophic forgetting analysis**: After training sub-models for all three scenarios, retrain on a single scenario and measure performance degradation on the other two to quantify the effectiveness of the frozen layer mechanism.

3. **Parameter efficiency benchmarking**: Compare MS-Net's parameter count and inference time against a naive ensemble of three independent models (one per scenario) trained with identical architectures to the sub-models, establishing whether the evolutionary approach provides meaningful efficiency gains beyond simple model selection.