---
ver: rpa2
title: The Role of Graph Topology in the Performance of Biomedical Knowledge Graph
  Completion Models
arxiv_id: '2409.04103'
source_url: https://arxiv.org/abs/2409.04103
tags:
- hetionet
- same
- relation
- figure
- head
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines how the topological properties of biomedical
  knowledge graphs influence the performance of knowledge graph completion models.
  The authors analyze six public biomedical KGs and five popular KGE models, focusing
  on edge cardinalities (one-to-one, one-to-many, many-to-one, many-to-many) and topological
  patterns (symmetry, inference, inverse, composition).
---

# The Role of Graph Topology in the Performance of Biomedical Knowledge Graph Completion Models

## Quick Facts
- arXiv ID: 2409.04103
- Source URL: https://arxiv.org/abs/2409.04103
- Reference count: 40
- Primary result: Entity degrees are stronger predictors of KGE model accuracy than coarse edge cardinality classifications

## Executive Summary
This paper investigates how the topological properties of biomedical knowledge graphs influence the performance of knowledge graph completion models. Through analysis of six public biomedical KGs and five popular KGE models, the authors demonstrate that entity degrees (particularly tail in-degree and head out-degree of same relation type) are more predictive of model accuracy than traditional edge cardinality classifications. The study reveals that composition patterns improve performance when entity degrees are small, and that the presence of counterpart edges in training data significantly impacts predictions for symmetric, inverse, and inference patterns. The authors also demonstrate through a case study that larger training graphs don't always improve performance, suggesting that smaller, task-specific graphs with larger embedding sizes may be preferable for biomedical applications.

## Method Summary
The study analyzes six public biomedical knowledge graphs using five KGE models (TransE, DistMult, RotatE, TripleRE, ConvE) with log-sigmoid loss, negative adversarial sampling, and Adam optimizer. Models are trained with fixed batch size of 768 (192 for PharMeBINet) across different embedding sizes optimized for IPU memory utilization. The authors compute edge cardinalities (one-to-one, one-to-many, many-to-one, many-to-many) and topological patterns (symmetry, inference, inverse, composition) at the individual triple level. Performance is evaluated using MRR and Hits@1/10 metrics, with analysis focusing on the correlation between topological properties and model accuracy. A case study compares Hetionet and PharMeBINet to examine how graph size affects predictive performance.

## Key Results
- Entity degrees (tail in-degree and head out-degree of same relation type) are stronger predictors of model accuracy than coarse cardinality classifications
- Composition patterns improve performance when entity degrees are small, even for models like DistMult that cannot explicitly model them
- Presence of counterpart edges in training data significantly impacts predictions for symmetric, inverse, and inference patterns
- Training on larger graphs can surprisingly harm predictive performance, suggesting smaller, tailored graphs with larger embedding sizes may be preferable

## Why This Works (Mechanism)

### Mechanism 1
Entity degrees (tail in-degree and head out-degree of same relation type) are stronger predictors of model accuracy than coarse edge cardinality classifications. Higher tail in-degree increases the likelihood that the model will assign a high score to the correct entity, while higher head out-degree increases difficulty because the task is to predict one specific correct tail among many possible correct tails. The incompleteness of the knowledge graph means that many correct tail entities are missing from the graph, so filtering during inference cannot remove all incorrect candidates.

### Mechanism 2
Composition patterns improve model performance when entity degrees are small. When both head and tail degrees are low, the model benefits from the additional structural information provided by composition patterns, even for models like DistMult that cannot explicitly model them. Low-degree entities have fewer direct connections, so compositional paths provide valuable indirect evidence for predicting missing links.

### Mechanism 3
The presence of counterpart edges in training data significantly impacts predictions for symmetric, inverse, and inference patterns. When the counterpart edge (e.g., reverse edge for symmetric triples) is present in training, the model learns additional information that makes prediction easier; when absent, prediction becomes harder and the pattern's effect on accuracy changes.

## Foundational Learning

- **Concept: Edge cardinalities (one-to-one, one-to-many, many-to-one, many-to-many)**
  - Why needed here: Understanding how the distribution of edges affects model performance is crucial for analyzing topological patterns.
  - Quick check question: What is the difference between one-to-many and many-to-one edge cardinalities?

- **Concept: Topological patterns (symmetry, inference, inverse, composition)**
  - Why needed here: These patterns represent different types of relationships between entities and affect how models learn to predict missing links.
  - Quick check question: How does a composition pattern differ from an inference pattern?

- **Concept: Entity degree and relation type-specific degree**
  - Why needed here: The paper shows that degrees of same relation type are better predictors than overall degrees, so understanding this distinction is essential.
  - Quick check question: What is the difference between deg(h) and deg_r(h)?

## Architecture Onboarding

- **Component map:** KGs -> Topological analysis tools -> KGE models (TransE, DistMult, RotatE, TripleRE, ConvE) -> Evaluation metrics (MRR, Hits@1, Hits@10)
- **Critical path:** Load KG → compute topological properties → train KGE models → evaluate performance → analyze correlation between topology and accuracy
- **Design tradeoffs:** Using individual triple-level analysis instead of relation-type aggregation provides finer-grained insights but requires more computation and storage
- **Failure signatures:** Poor demixing performance indicates the model cannot distinguish entity types; TransE performing poorly on symmetric patterns indicates inability to capture that pattern
- **First 3 experiments:**
  1. Compute edge cardinalities and topological patterns for a small KG and verify the counts match expectations.
  2. Train a simple KGE model (e.g., TransE) on a small dataset and evaluate MRR to establish baseline performance.
  3. Analyze the correlation between entity degrees and MRR for individual triples to confirm the paper's findings.

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of embedding size interact with graph size when training KGE models for biomedical knowledge graphs? The paper demonstrates that smaller, tailored graphs with larger embedding sizes often outperform larger graphs with smaller embeddings, but the relationship between these factors across different graph sizes and model types remains unclear.

### Open Question 2
What is the optimal strategy for constructing training knowledge graphs for specific biomedical tasks, balancing completeness versus task-specific relevance? The paper shows that additional training data from larger graphs can harm performance, suggesting that task-specific graph construction is crucial, but doesn't provide concrete guidelines for this process.

### Open Question 3
How do different KGE model architectures handle varying degrees of topological imbalance in biomedical knowledge graphs? While the paper identifies the problem of degree imbalance, it doesn't provide a comprehensive analysis of which model architectures are most robust to this issue.

## Limitations
- Focus on static topological properties without considering dynamic aspects like temporal evolution or data quality variations
- Analysis assumes training-test split represents realistic real-world scenario, but biomedical KGs often have systematic curation biases
- Study uses only six biomedical KGs, which may not capture full diversity of biomedical knowledge representation

## Confidence
- **High confidence:** Entity degrees are stronger predictors than coarse cardinality classifications
- **Medium confidence:** Composition patterns improve performance when entity degrees are small
- **Medium confidence:** Presence of counterpart edges in training data significantly impacts predictions

## Next Checks
1. **Cross-domain validation:** Apply the topological analysis framework to non-biomedical KGs (e.g., social networks, citation networks) to test whether the degree-based predictors generalize beyond the biomedical domain.

2. **Dynamic evaluation:** Implement a temporal split of the KGs (training on older data, testing on newer) to assess whether the topological patterns hold when considering the evolution of biomedical knowledge over time.

3. **Quality-aware analysis:** Incorporate data quality metrics (such as source reliability or curation confidence scores) into the analysis to determine if the topological patterns remain predictive when controlling for knowledge graph completeness and accuracy.