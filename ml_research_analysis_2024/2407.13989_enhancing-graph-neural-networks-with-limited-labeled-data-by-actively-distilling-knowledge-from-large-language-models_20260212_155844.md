---
ver: rpa2
title: Enhancing Graph Neural Networks with Limited Labeled Data by Actively Distilling
  Knowledge from Large Language Models
arxiv_id: '2407.13989'
source_url: https://arxiv.org/abs/2407.13989
tags:
- llms
- gnns
- learning
- nodes
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel approach to improve few-shot node classification
  on graphs by leveraging the zero-shot inference and reasoning capabilities of Large
  Language Models (LLMs) through active knowledge distillation. The method uses LLMs
  to generate soft labels, logits, and rationales for unlabeled nodes, which are then
  distilled into Graph Neural Networks (GNNs) to enhance their performance with limited
  labeled data.
---

# Enhancing Graph Neural Networks with Limited Labeled Data by Actively Distilling Knowledge from Large Language Models

## Quick Facts
- arXiv ID: 2407.13989
- Source URL: https://arxiv.org/abs/2407.13989
- Reference count: 40
- Key outcome: GNN node classification accuracy improves 6-35% using LLM knowledge distillation in few-shot settings

## Executive Summary
This paper introduces a novel approach to improve few-shot node classification on graphs by leveraging Large Language Models (LLMs) through active knowledge distillation. The method uses LLMs to generate soft labels, logits, and rationales for unlabeled nodes, which are then distilled into Graph Neural Networks (GNNs) to enhance their performance with limited labeled data. A Graph-LLM-based active learning strategy is introduced to select valuable nodes where GNNs struggle but LLMs can provide dependable predictions. Experiments on citation datasets demonstrate significant improvements in node classification accuracy compared to state-of-the-art baselines.

## Method Summary
The method combines GNNs with LLMs using active knowledge distillation. LLMs generate soft labels, logits, and rationales for unlabeled nodes through zero-shot inference. These are distilled into GNNs via two losses: knowledge distillation loss (logits) and feature alignment loss (rationales). An active learning module iteratively selects nodes for LLM annotation based on a composite score combining GNN confidence, node homophily, degree, and neighborhood entropy reduction. The training uses a combined loss function balancing classification loss on labeled data with distillation and alignment losses.

## Key Results
- Achieves 6-35% accuracy improvements across Cora, Citeseer, and PubMed datasets in few-shot settings
- Outperforms state-of-the-art baselines in 1, 3, 5, and 7-shot experiments
- Demonstrates effective knowledge transfer from LLMs to GNNs through soft labels and rationales

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM zero-shot inference enables high-quality pseudo-label generation for nodes with high homophily ratios and degrees.
- Mechanism: LLMs classify nodes based on raw text features, prioritizing nodes where GNNs have low confidence but LLMs can confidently predict. These high-confidence pseudo-labels expand the labeled training set.
- Core assumption: LLMs consistently generate correct pseudo-labels for high homophily/degree nodes due to pre-training knowledge.
- Evidence anchors: Abstract mentions LLM-generated soft labels/logits for unlabeled nodes; preliminary experiments show LLM capability on high homophily/degree nodes.
- Break condition: If LLM performance degrades on high homophily/degree nodes or GNN-LLM confidence gap narrows.

### Mechanism 2
- Claim: Knowledge distillation from LLM logits and rationales improves GNN representation learning.
- Mechanism: Dual supervision through soft labels/logits (probability distributions) and rationale embeddings (feature-level supervision) provides richer representations incorporating hidden label distributions and enhanced textual features.
- Core assumption: LLM rationales contain valuable information that improves GNN embeddings when aligned.
- Evidence anchors: Abstract mentions rationales distilled into GNNs; paper describes using loss function to minimize differences between enhanced and original representations.
- Break condition: If rationale embeddings are too dissimilar from GNN representations or alignment disrupts structural information.

### Mechanism 3
- Claim: Graph-LLM active learning iteratively selects most valuable nodes for annotation.
- Mechanism: Composite score evaluates nodes using GNN confidence (inverted), homophily ratio, degree, and entropy reduction. High-scoring nodes are selected for LLM annotation.
- Core assumption: Nodes with low GNN confidence but high homophily/degree are most valuable for improvement when annotated by LLMs.
- Evidence anchors: Abstract mentions active learning strategy for valuable nodes; paper describes seeking nodes where GNNs exhibit low confidence but LLMs offer high-quality pseudo-labels.
- Break condition: If active learning fails to identify valuable nodes due to poor confidence estimation or ineffective entropy calculation.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: GNNs are the backbone model enhanced by LLM knowledge. Understanding node representation updates is crucial for knowledge distillation.
  - Quick check question: How does a standard GNN update a node's representation using information from its neighbors?

- Concept: Knowledge distillation and teacher-student learning
  - Why needed here: Core mechanism involves distilling knowledge from LLM "teachers" to GNN "students." Understanding soft labels, logits, and feature-level supervision is essential.
  - Quick check question: What is the difference between hard labels and soft labels in knowledge distillation, and why are soft labels often more informative?

- Concept: Active learning and query strategies
  - Why needed here: Model uses active learning to select nodes for LLM queries. Understanding different strategies and informativeness evaluation is key.
  - Quick check question: What are the main differences between uncertainty sampling and query-by-committee strategies in active learning?

## Architecture Onboarding

- Component map: Text features -> SBERT encoder -> GNN backbone -> LLM component -> Alignment module -> Combined loss -> Updated GNN

- Critical path:
  1. Encode raw text to embeddings
  2. GNN processes graph to generate initial node representations
  3. LLM generates pseudo-labels, logits, and rationales for candidate nodes
  4. Align rationale embeddings with GNN output via MLP
  5. Compute combined loss and update GNN parameters
  6. Active learning selects new nodes for LLM queries
  7. Iterate until budget exhausted

- Design tradeoffs:
  - LLM selection vs. cost: More powerful LLMs improve quality but increase cost/latency
  - Active learning budget vs. performance: Larger budget improves performance but increases query costs
  - Balance parameters (α, β) vs. learning stability: Incorrect balance may cause overfitting or ignore LLM knowledge

- Failure signatures:
  - GNN performance plateaus or degrades after iterations (poor node selection or noisy pseudo-labels)
  - Rationale alignment loss dominates training (misalignment between LLM rationales and GNN representations)
  - High variance across random seeds (sensitivity to initial labeled node selection)

- First 3 experiments:
  1. Verify LLM pseudo-label quality: Run LLM on held-out validation set and compare to ground truth to establish baseline accuracy on high homophily/degree nodes.
  2. Test knowledge distillation impact: Train GNN with and without LLM knowledge distillation on small dataset to measure performance improvement from logits and rationales.
  3. Validate active learning selection: Implement composite scoring function and verify it identifies nodes where GNNs have low confidence but LLMs can provide reliable predictions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do performance and generalization capabilities scale with increasingly large and complex graphs, particularly those with millions of nodes and diverse node features?
- Basis in paper: [inferred] Paper evaluates on three citation datasets with 25,122 total nodes and homogeneous features, not exploring larger or more complex graphs.
- Why unresolved: Experiments limited to small-scale citation networks; scaling to industrial-sized graphs could reveal efficiency and effectiveness limitations.
- What evidence would resolve it: Experiments on graphs with millions of nodes, diverse feature types, and varying label sparsity.

### Open Question 2
- Question: What is the impact of different LLM architectures and sizes on performance, and how does this trade-off affect computational efficiency and cost?
- Basis in paper: [explicit] Paper evaluates with three LLM base models but doesn't explore impact of smaller/larger models or different architectures on performance and efficiency.
- Why unresolved: LLM choice significantly influences performance and computational requirements; understanding trade-offs is crucial for practical deployment.
- What evidence would resolve it: Systematic experiments comparing performance and computational costs of different LLM architectures and sizes.

### Open Question 3
- Question: How does the model handle noisy or adversarial node features, and what mechanisms can improve robustness in such scenarios?
- Basis in paper: [inferred] Paper assumes clean node features and doesn't address impact of noisy or adversarial features on performance.
- Why unresolved: Real-world graphs often contain noisy or adversarial features that can degrade graph-based model performance.
- What evidence would resolve it: Experiments on graphs with injected noise or adversarial features, along with robustness-enhancing mechanism evaluation.

## Limitations

- Effectiveness heavily depends on LLM zero-shot performance on high homophily/degree nodes, which may vary significantly across datasets and domains
- Selection mechanism assumes a clear gap between GNN uncertainty and LLM confidence that may not exist in all scenarios
- Method's scalability to larger graphs with millions of nodes remains untested, and computational cost of repeated LLM queries could become prohibitive

## Confidence

- **High Confidence**: Core knowledge distillation framework (using LLM logits and rationales to enhance GNN training) is well-established and experimental results on standard citation datasets are reproducible.
- **Medium Confidence**: Active learning strategy for node selection shows promise but lacks detailed implementation specifications and corpus provides weak evidence for effectiveness.
- **Low Confidence**: Specific claim about LLMs consistently generating high-quality pseudo-labels for nodes with high homophily ratios and degrees is based on preliminary experiments without comprehensive validation across diverse graph types.

## Next Checks

1. **Cross-dataset LLM performance validation**: Systematically evaluate LLM zero-shot accuracy on nodes with varying homophily ratios and degrees across multiple graph datasets beyond citation networks to verify the core assumption about LLM effectiveness on high-homophily nodes.

2. **Ablation study of selection criteria**: Conduct controlled experiments removing individual components of the composite selection score (homophily, degree, entropy reduction) to quantify each factor's contribution and identify which components are truly essential versus potentially redundant.

3. **Budget sensitivity analysis**: Systematically vary the active learning budget B across a wider range (e.g., 10-100 nodes per class) to establish the relationship between query budget and performance gains, and identify whether diminishing returns occur at specific budget thresholds.