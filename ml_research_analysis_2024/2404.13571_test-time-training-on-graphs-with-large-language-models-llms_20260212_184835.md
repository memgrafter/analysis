---
ver: rpa2
title: Test-Time Training on Graphs with Large Language Models (LLMs)
arxiv_id: '2404.13571'
source_url: https://arxiv.org/abs/2404.13571
tags:
- training
- test
- llmttt
- node
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LLMTTT, a novel test-time training method
  for addressing distribution shifts in graph neural networks (GNNs). The approach
  leverages large language models (LLMs) as annotators to generate pseudo labels for
  a carefully selected subset of test nodes, enabling supervised fine-tuning of pre-trained
  GNN models.
---

# Test-Time Training on Graphs with Large Language Models (LLMs)

## Quick Facts
- arXiv ID: 2404.13571
- Source URL: https://arxiv.org/abs/2404.13571
- Authors: Jiaxin Zhang, Yiqi Wang, Xihong Yang, Siwei Wang, Yu Feng, Yu Shi, Ruicaho Ren, En Zhu, Xinwang Liu
- Reference count: 40
- Key outcome: LLMTTT significantly outperforms existing out-of-distribution generalization methods, achieving accuracy improvements of up to 3.71% on text-attributed graph datasets

## Executive Summary
This paper introduces LLMTTT, a novel test-time training method for addressing distribution shifts in graph neural networks (GNNs). The approach leverages large language models (LLMs) as annotators to generate pseudo labels for a carefully selected subset of test nodes, enabling supervised fine-tuning of pre-trained GNN models. LLMTTT employs a hybrid active node selection strategy that combines uncertainty sampling, node diversity, and model prediction signals, followed by a two-stage training process to handle noisy labels. Theoretical analysis and extensive experiments demonstrate that LLMTTT significantly outperforms existing out-of-distribution generalization methods, achieving accuracy improvements of up to 3.71% compared to state-of-the-art baselines on text-attributed graph datasets.

## Method Summary
LLMTTT addresses distribution shifts in GNNs through test-time adaptation using LLM-generated pseudo labels. The method begins with a pre-trained GNN making predictions on test data, followed by hybrid active node selection that identifies uncertain nodes based on prediction entropy and refines them using PageRank and FeatProp for structural and feature diversity. Selected nodes are annotated by LLMs with pseudo labels and confidence scores. The model then undergoes two-stage training: Stage 1 trains on confidence-filtered labeled nodes using cross-entropy loss, while Stage 2 performs self-training with unlabeled data through weighted cross-entropy between original and augmented views. The adapted model makes final predictions on test data.

## Key Results
- LLMTTT achieves up to 3.71% accuracy improvement over state-of-the-art OOD generalization methods on text-attributed graph datasets
- Performance is robust across different types of distribution shifts including covariate shift and concept shift
- Hybrid active node selection strategy effectively balances model uncertainty and node diversity, contributing to adaptation quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hybrid active node selection improves test-time adaptation by balancing model uncertainty and node diversity
- Mechanism: The method first selects uncertain nodes based on prediction entropy from the pre-trained model, then refines selection using PageRank and FeatProp to ensure structural and feature diversity
- Core assumption: Nodes with high prediction entropy are most valuable for adaptation, and diversity prevents overfitting to local neighborhoods
- Evidence anchors:
  - [abstract]: "hybrid active node selection strategy that considers not only node diversity and representativeness, but also prediction signals from the pre-trained model"
  - [section 3.2]: Describes uncertainty sampling based on prediction entropy and distribution-based selection using PageRank and FeatProp
  - [corpus]: No direct evidence in corpus papers about this specific hybrid approach

### Mechanism 2
- Claim: Two-stage training strategy effectively leverages both noisy labeled nodes and unlabeled test data
- Mechanism: Stage 1 trains with filtered nodes using cross-entropy loss to adapt to pseudo labels; Stage 2 uses self-training with unlabeled data through weighted cross-entropy between original and augmented views
- Core assumption: Filtering noisy labels and incorporating unlabeled data through self-training can improve model adaptation without overfitting
- Evidence anchors:
  - [abstract]: "two-stage training strategy is designed to tailor the test-time model with the limited and noisy labels"
  - [section 3.4]: Details both stages, including confidence-based filtering and self-training with augmented views
  - [corpus]: No direct evidence in corpus papers about this specific two-stage approach for test-time training

### Mechanism 3
- Claim: LLM-generated pseudo labels with confidence scores enable effective semi-supervised adaptation
- Mechanism: LLMs annotate selected nodes with high-quality pseudo labels and confidence scores, which are used to weight training and filter noisy samples
- Core assumption: LLMs can generate accurate enough labels for a small subset of nodes, and confidence scores correlate with label quality
- Evidence anchors:
  - [abstract]: "leverages large language models (LLMs) as annotators to generate pseudo labels for a carefully selected subset of test nodes"
  - [section 3.3]: Describes confidence-aware annotation and the use of few-shot prompting with GCN predictions
  - [section 5.3.1]: Shows correlation between pseudo label accuracy and LLMTTT performance

## Foundational Learning

- Concept: Test-time training (TTT)
  - Why needed here: LLMTTT builds on TTT by replacing unsupervised adaptation with semi-supervised learning using LLM annotations
  - Quick check question: What is the key difference between traditional TTT and LLMTTT's approach?

- Concept: Graph neural networks (GNNs)
  - Why needed here: The pre-trained GNN model provides uncertainty signals and serves as the base model for adaptation
  - Quick check question: How does the GNN's prediction entropy indicate uncertainty in node classification?

- Concept: Active learning on graphs
  - Why needed here: Node selection strategy balances model uncertainty and data distribution characteristics
  - Quick check question: What are the trade-offs between uncertainty sampling and diversity-based selection in graph active learning?

## Architecture Onboarding

- Component map:
  Pre-trained GNN model -> Hybrid active selection module -> LLM annotator -> Two-stage training pipeline -> Inference engine

- Critical path:
  1. Pre-trained GNN makes predictions on test data
  2. Hybrid selection identifies most valuable nodes
  3. LLM annotates selected nodes with pseudo labels and confidence
  4. Stage 1 trains on filtered labeled nodes
  5. Stage 2 self-trains on unlabeled data
  6. Adapted model makes final predictions

- Design tradeoffs:
  - Budget allocation between node selection and annotation quality
  - Balance between filtering noisy labels and maintaining label diversity
  - Trade-off between model complexity and adaptation speed

- Failure signatures:
  - Poor performance despite high pseudo label accuracy (suggests other factors dominate)
  - Performance drops after self-training (indicates overfitting or incorrect pseudo labels)
  - No improvement over traditional TTT (suggests hybrid selection or LLM annotations are ineffective)

- First 3 experiments:
  1. Ablation study: Compare full LLMTTT vs. versions without hybrid selection, without confidence filtering, and without self-training
  2. Sensitivity analysis: Vary annotation budget and measure impact on performance across different datasets
  3. Cross-dataset evaluation: Test model adaptation when training and test distributions differ significantly in structure or content

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLMTTT scale with increasing graph size and complexity?
- Basis in paper: [inferred] The paper evaluates LLMTTT on several graph datasets but does not explicitly explore scaling behavior with graph size or complexity.
- Why unresolved: The paper focuses on demonstrating effectiveness rather than scalability analysis.
- What evidence would resolve it: Systematic experiments varying graph size and complexity parameters, measuring runtime and accuracy trade-offs.

### Open Question 2
- Question: What is the impact of different LLM architectures (e.g., GPT-4 vs. GPT-3.5) on the quality of pseudo labels and overall LLMTTT performance?
- Basis in paper: [explicit] The paper uses GPT-3.5-turbo-0613 for generating annotations but does not compare with other LLM architectures.
- Why unresolved: The paper does not conduct comparative studies with different LLM models.
- What evidence would resolve it: Experiments using various LLM architectures to generate pseudo labels and measuring resulting performance differences in LLMTTT.

### Open Question 3
- Question: How robust is LLMTTT to adversarial attacks on graph structures during test-time adaptation?
- Basis in paper: [inferred] The paper focuses on distribution shift but does not explicitly address adversarial robustness during test-time training.
- Why unresolved: The paper's focus is on distribution shift, not adversarial robustness.
- What evidence would resolve it: Experiments introducing adversarial perturbations to graph structures during test-time training and measuring LLMTTT's resilience.

### Open Question 4
- Question: What is the optimal budget allocation strategy for node selection across different graph domains and tasks?
- Basis in paper: [explicit] The paper uses a fixed budget for node selection but does not explore adaptive budget allocation strategies.
- Why unresolved: The paper does not investigate dynamic budget allocation based on domain characteristics or task requirements.
- What evidence would resolve it: Experiments comparing fixed vs. adaptive budget allocation strategies across diverse graph domains and tasks, measuring performance improvements.

## Limitations
- Dependence on LLM quality and cost - effectiveness may degrade if LLM accuracy falls below demonstrated threshold
- Hybrid node selection strategy lacks extensive ablation studies to quantify individual component contributions
- Experiments focus on text-attributed graphs, leaving open questions about performance on pure structural graphs or multimodal graph data

## Confidence
- Mechanism 1 (Hybrid selection): Medium - supported by theoretical reasoning but limited empirical validation of individual components
- Mechanism 2 (Two-stage training): Medium - conceptually sound but hyperparameter sensitivity not thoroughly examined
- Mechanism 3 (LLM pseudo labels): Medium-High - demonstrated effectiveness but heavily dependent on LLM quality

## Next Checks
1. Ablation study varying individual components: test LLMTTT performance with only uncertainty sampling, only diversity-based selection, and without confidence filtering to quantify each mechanism's contribution
2. Cross-LLM evaluation: replicate experiments using different LLM models (varying sizes/capabilities) to assess robustness to LLM quality variations
3. Scalability analysis: measure adaptation performance and computational cost as graph size increases to evaluate practical deployment constraints