---
ver: rpa2
title: Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov Barrier
  Certificates
arxiv_id: '2405.14058'
source_url: https://arxiv.org/abs/2405.14058
tags:
- certificates
- certificate
- control
- state
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of formally verifying safety
  and liveness properties of deep reinforcement learning (DRL) controllers for complex
  dynamical systems. The authors propose a novel framework using Neural Lyapunov Barrier
  (NLB) certificates, which are learned functions over the system whose properties
  indirectly imply correct behavior.
---

# Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov Barrier Certificates

## Quick Facts
- arXiv ID: 2405.14058
- Source URL: https://arxiv.org/abs/2405.14058
- Reference count: 40
- Authors: Udayan Mandal, Guy Amir, Haoze Wu, Ieva Daukantas, Fletcher Lee Newell, Umberto J. Ravaioli, Baoluo Meng, Michael Durling, Milan Ganai, Tobey Shim, Guy Katz, Clark Barrett

## Executive Summary
This paper addresses the challenge of formally verifying safety and liveness properties of deep reinforcement learning (DRL) controllers for complex dynamical systems. The authors propose a novel framework using Neural Lyapunov Barrier (NLB) certificates, which are learned functions over the system whose properties indirectly imply correct behavior. The key contributions are: (1) introducing Filtered Reach-while-Avoid (FRWA) certificates, which simplify training and verification by hard-coding goal/unsafe region values; (2) proposing compositional certificates that break the verification problem into smaller subproblems solved independently; and (3) demonstrating the approach on a 2D spacecraft docking case study.

## Method Summary
The paper presents a framework for formally verifying DRL controllers using Neural Lyapunov Barrier certificates. The approach uses a counterexample-guided inductive synthesis (CEGIS) loop to iteratively train certificates and verify their properties. The key innovations are FRWA certificates, which simplify training by hard-coding goal/unsafe region values, and compositional certificates, which break the verification problem into smaller subproblems. The method is demonstrated on a 2D spacecraft docking task, showing significant improvements in scalability and verification success rates compared to standard approaches.

## Key Results
- FRWA certificates significantly outperform standard RWA certificates in scalability and verification efficiency
- Compositional certificates enable verification for much larger state spaces (verified safety and liveness for spacecraft starting within [-11, 11])
- A 5-stage compositional certificate achieved what neither RWA nor FRWA alone could accomplish within a 12-hour timeout

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FRWA certificates hard-code goal/unsafe region values to simplify training and verification.
- Mechanism: By assigning fixed values to states in the goal and unsafe regions, the neural network only needs to learn the intermediate region, reducing the complexity of the verification problem.
- Core assumption: The goal and unsafe regions can be described using simple predicates that can be checked efficiently.
- Evidence anchors:
  - [abstract] "introducing Filtered Reach-while-Avoid (FRWA) certificates, which simplify training and verification by hard-coding goal/unsafe region values"
  - [section IV-B] "The idea behind FRWA is straightforward. Often, we can describe the goal and unsafe regions using simple predicates (or filters) on the state space."
- Break condition: If the goal/unsafe regions cannot be expressed as simple predicates, or if the hard-coded values introduce verification artifacts.

### Mechanism 2
- Claim: Compositional certificates break the verification problem into smaller subproblems solved independently.
- Mechanism: Instead of training one large certificate for the entire state space, the approach trains a sequence of certificates, each covering a subset of the state space. This allows each individual verification problem to be smaller and more tractable.
- Core assumption: The state space can be partitioned into regions such that each region can be handled by a separate certificate, and a meta-controller can be designed to select the appropriate certificate for a given state.
- Evidence anchors:
  - [abstract] "proposing compositional certificates that break the verification problem into smaller subproblems solved independently"
  - [section V] "We introduce compositional certificates, which aim to aid scalability by training multiple controller-certificate pairs, each covering different parts of the state space."
- Break condition: If the state space cannot be effectively partitioned, or if the meta-controller introduces significant overhead or complexity.

### Mechanism 3
- Claim: The CEGIS loop iteratively refines the controller and certificate based on verification counterexamples.
- Mechanism: The approach alternates between training the controller and certificate and using a DNN verifier to find counterexamples. When a counterexample is found, it is added to the training data to improve the learned functions.
- Core assumption: The DNN verifier can effectively find counterexamples, and the training data can be augmented to address these counterexamples.
- Evidence anchors:
  - [section IV-C] "We use a counterexample-guided inductive synthesis (CEGIS) loop... to obtain a fully verified controller and certificate."
  - [section IV-C] "If the verifier identifies a counterexample violating constraints (4) or (5)... we sample points in the proximity of the counterexample and use these to augment the training data."
- Break condition: If the DNN verifier fails to find counterexamples, or if the training process does not converge to a solution that satisfies the constraints.

## Foundational Learning

- Concept: Lyapunov functions and their role in stability analysis.
  - Why needed here: The paper relies on Lyapunov functions as a foundation for the Neural Lyapunov Barrier certificates.
  - Quick check question: What are the key properties a Lyapunov function must satisfy to guarantee stability of a dynamical system?

- Concept: Control Barrier Functions and their role in safety verification.
  - Why needed here: The paper uses Barrier Functions as part of the Control Lyapunov Barrier Functions to verify safety properties.
  - Quick check question: How do Control Barrier Functions ensure that a system remains within a safe region of the state space?

- Concept: Reach-Avoid tasks and their formalization.
  - Why needed here: The paper focuses on verifying controllers for Reach-Avoid tasks, which require both safety and liveness guarantees.
  - Quick check question: What are the formal definitions of the "reach" and "avoid" components of a Reach-Avoid task?

## Architecture Onboarding

- Component map:
  - DRL controller (DNN) -> Neural Lyapunov Barrier certificate (DNN) -> DNN verifier -> CEGIS loop
  - Meta-controller (for compositional approach) -> Certificate selector

- Critical path:
  1. Initialize the DRL controller.
  2. Train the Neural Lyapunov Barrier certificate using the CEGIS loop.
  3. Verify the certificate using the DNN verifier.
  4. If verification fails, augment the training data with counterexamples and repeat.
  5. (For compositional approach) Repeat steps 1-4 for each certificate in the sequence.

- Design tradeoffs:
  - DNN architecture size vs. verification tractability: Smaller architectures are easier to verify but may have limited expressiveness.
  - FRWA vs. standard RWA: FRWA simplifies training and verification but requires the goal/unsafe regions to be expressible as simple predicates.
  - Compositional approach vs. single large certificate: Compositional certificates improve scalability but add complexity in designing the meta-controller.

- Failure signatures:
  - CEGIS loop fails to converge: The training process may not be able to find a certificate that satisfies the constraints.
  - DNN verifier fails to find counterexamples: The verifier may not be able to effectively explore the state space to find violations.
  - Meta-controller selects the wrong certificate: The meta-controller may not correctly identify the appropriate certificate for a given state.

- First 3 experiments:
  1. Implement and train a simple RWA certificate for a basic dynamical system (e.g., a pendulum).
  2. Modify the RWA certificate to use the FRWA approach and compare training and verification times.
  3. Implement a compositional certificate for a slightly more complex system and verify its effectiveness in scaling to larger state spaces.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How should intermediate goal regions be optimally selected for compositional certificates in the general case?
- Basis in paper: [explicit] The paper states "Finding good heuristics for choosing these sets in the general case is a promising direction for future work."
- Why unresolved: The paper only provides a basic monotonic requirement for intermediate sets but does not explore optimization strategies for selecting them.
- What evidence would resolve it: Comparative studies showing performance differences between various heuristics for selecting intermediate goal regions, with metrics on verification time and success rates.

### Open Question 2
- Question: Can the compositional certificate approach be extended to handle larger state spaces beyond [-11, 11] effectively?
- Basis in paper: [inferred] The paper demonstrates success up to [-11, 11] but notes scalability challenges remain, suggesting potential limits.
- Why unresolved: The paper does not test the approach on state spaces larger than [-11, 11], leaving the scalability limits unexplored.
- What evidence would resolve it: Experimental results showing successful verification for significantly larger state spaces, with analysis of how the number of certificates and verification time scale.

### Open Question 3
- Question: How would the approach perform on spacecraft with different dynamics, such as different masses or thruster configurations?
- Basis in paper: [explicit] The paper focuses on a specific spacecraft model with fixed mass and thruster constraints, noting it as a case study.
- Why unresolved: The paper does not explore variations in system dynamics, only demonstrating the approach on one specific spacecraft model.
- What evidence would resolve it: Experimental results applying the framework to spacecraft models with varying physical parameters, showing verification success rates and training times across different configurations.

## Limitations
- The approach assumes the goal/unsafe regions can be expressed as simple predicates, which may not hold for all systems
- The compositional approach requires careful design of intermediate regions and meta-controller, which could be complex in practice
- Performance guarantees depend on the effectiveness of the DNN verifier in finding counterexamples

## Confidence
- High confidence: FRWA simplification mechanism and its empirical benefits for training/verification efficiency
- Medium confidence: Compositional certificate approach, as the spacecraft case study provides strong evidence but may not generalize to all system types
- Medium confidence: Overall framework's scalability, as the 5-stage compositional certificate represents a significant achievement but was tested on a single case study

## Next Checks
1. Test the compositional certificate approach on a system with higher-dimensional state space (e.g., 3D spacecraft dynamics) to assess scalability beyond the 2D case
2. Evaluate the framework on a system where the goal/unsafe regions cannot be easily expressed as simple predicates to test FRWA limitations
3. Compare the verification performance against alternative approaches (e.g., counterexample-guided training without Lyapunov certificates) on identical benchmarks