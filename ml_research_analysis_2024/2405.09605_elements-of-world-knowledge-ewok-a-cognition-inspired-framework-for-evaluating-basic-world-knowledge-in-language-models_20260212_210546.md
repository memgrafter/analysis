---
ver: rpa2
title: 'Elements of World Knowledge (EWoK): A Cognition-Inspired Framework for Evaluating
  Basic World Knowledge in Language Models'
arxiv_id: '2405.09605'
source_url: https://arxiv.org/abs/2405.09605
tags:
- knowledge
- language
- fatima
- jose
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Elements of World Knowledge (EWoK), a framework
  for evaluating language models' understanding of fundamental world knowledge concepts.
  EWoK tests 192 concepts across 11 domains of knowledge (e.g., social interactions,
  spatial relations, physical dynamics) using controlled minimal pair items that require
  contextual integration.
---

# Elements of World Knowledge (EWoK): A Cognition-Inspired Framework for Evaluating Basic World Knowledge in Language Models

## Quick Facts
- arXiv ID: 2405.09605
- Source URL: https://arxiv.org/abs/2405.09605
- Authors: Anna A. Ivanova; Aalok Sathe; Benjamin Lipkin; Unnathi Kumar; Setayesh Radkani; Thomas H. Clark; Carina Kauf; Jennifer Hu; R. T. Pramod; Gabriel Grand; Vivian Paulun; Maria Ryskina; Ekin Akyürek; Ethan Wilcox; Nafisa Rashid; Leshem Choshen; Roger Levy; Evelina Fedorenko; Joshua Tenenbaum; Jacob Andreas
- Reference count: 40
- Key outcome: All models perform below human levels (best: 0.80 vs human: 0.95), with performance varying drastically by domain - highest on social interactions (0.86) and lowest on spatial relations (0.62)

## Executive Summary
This paper introduces Elements of World Knowledge (EWoK), a framework for evaluating language models' understanding of fundamental world knowledge concepts. EWoK tests 192 concepts across 11 domains of knowledge using controlled minimal pair items that require contextual integration. The authors evaluate 20 open-weight LLMs (1.3B-70B parameters) and compare their performance with human participants. Results show all models perform below human levels, with significant variation across domains - models excel at social knowledge but struggle with physical and spatial reasoning, suggesting current models still lack robust world modeling capabilities.

## Method Summary
EWoK uses a template-based framework with typed fillers to generate controlled minimal pair items across 11 knowledge domains. Each item consists of two minimal pair contexts and two minimal pair target sentences, where the same target is plausible in one context but implausible in another. The framework evaluates models using log probability (LOGPROBS) and prompt-based methods, comparing results to human baselines. The dataset includes 4,374 items across 192 concepts, testing models' ability to integrate contextual information with world knowledge.

## Key Results
- All 20 evaluated LLMs perform below human baselines (best: 0.80 vs human: 0.95)
- Performance varies drastically by domain: social interactions (0.86) > others > spatial relations (0.62)
- Model performance correlates with surface features like word frequency and sentence length
- Domain remains a significant predictor even when controlling for surface features
- LOGPROBS evaluation often outperforms direct prompting even for large, instruction-tuned models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EWoK uses minimal pair contrasts to isolate specific concept knowledge from surface heuristics
- Mechanism: By creating controlled context-target pairs where the same target is plausible in one context but implausible in another, the framework forces models to use conceptual understanding rather than frequency-based heuristics
- Core assumption: Models cannot rely solely on surface-level statistics to distinguish plausible from implausible scenarios when context-target combinations are manipulated
- Evidence anchors:
  - [abstract] "our framework tests LLMs' ability to evaluate contextual plausibility, such that the same exact target (The piano is left of Ali) is either plausible or implausible depending on the context"
  - [section] "Each item consists of two minimal pair contexts... and two minimal pair target sentences... The two target concepts are juxtaposed such that in any item, P(T1|C1) > P(T1|C2) and P(T2|C1) < P(T2|C2)"
  - [corpus] Weak - corpus shows related work on NLI and minimal pairs but no direct evidence about this specific contrast mechanism
- Break condition: If models develop sophisticated heuristics that can infer plausibility from surface features alone, the minimal pair design would fail to isolate conceptual knowledge

### Mechanism 2
- Claim: EWoK's cognition-inspired domain selection targets knowledge areas with dedicated neural substrates in humans
- Mechanism: By selecting domains (social interactions, physical dynamics, spatial relations, etc.) that have been shown to recruit dedicated cognitive and/or neural machinery in humans, the framework tests knowledge that should be fundamental to world modeling
- Core assumption: Knowledge domains with dedicated neural substrates in humans are more likely to represent fundamental world knowledge that models should acquire
- Evidence anchors:
  - [abstract] "We systematically select a range of knowledge domains that have been shown to recruit dedicated cognitive and/or neural machinery in humans, such as knowledge of intuitive physics... social reasoning... and reasoning about agents"
  - [section] "Domains were contributed based on past literature during the development of EWoK by a team of experts in the field (authors of this paper: professors, post-docs, and grad students in cognitive science and neuroscience across a few institutions)"
  - [corpus] Moderate - corpus shows related work on commonsense knowledge but limited evidence about neural substrate connection
- Break condition: If the relationship between neural substrates and fundamental world knowledge is not as strong as assumed, or if models can acquire world knowledge through different mechanisms

### Mechanism 3
- Claim: EWoK's flexible template system with typed fillers enables controlled generation of semantically valid items
- Mechanism: By using templates with placeholders that can be populated with specific types of fillers (objects, agents, locations) while respecting semantic constraints, the framework ensures generated items are both diverse and semantically coherent
- Core assumption: Type restrictions on template variables can prevent generation of semantically anomalous sentences while allowing sufficient diversity
- Evidence anchors:
  - [abstract] "Objects, agents, and locations in the items can be flexibly filled in, enabling easy generation of multiple controlled datasets"
  - [section] "Placeholders in templates (e.g., OBJECT or AGENT) can be restricted to only allow fillers of specific types... These type restrictions prevent generation of semantically anomalous or incomprehensible sentences"
  - [corpus] Moderate - corpus shows related work on template-based generation but limited evidence about typed filler effectiveness
- Break condition: If type restrictions are too restrictive (limiting item diversity) or too permissive (allowing semantic anomalies), the controlled generation would fail

## Foundational Learning

- Concept: Minimal pairs and controlled contrasts
  - Why needed here: Understanding how EWoK uses minimal pairs to isolate specific conceptual knowledge from surface heuristics is fundamental to grasping the framework's methodology
  - Quick check question: Why does EWoK use minimal pairs of contexts and targets instead of just testing targets in isolation?

- Concept: Template-based synthetic data generation
  - Why needed here: The ability to generate diverse yet controlled items from templates is central to EWoK's flexibility and scalability
  - Quick check question: How do typed fillers in templates help ensure semantic validity while maintaining item diversity?

- Concept: Log probability vs. prompt-based evaluation
  - Why needed here: Understanding the tradeoffs between different evaluation methods (LOGPROBS vs. prompting) is crucial for interpreting results and choosing appropriate methods
  - Quick check question: Why does LOGPROBS evaluation often outperform direct prompting even for large, instruction-tuned models?

## Architecture Onboarding

- Component map: Domains → Concepts → Templates → Fillers → Items → Model evaluation (LOGPROBS/prompting) → Human validation → Analysis

- Critical path:
  1. Define domain-concept-template structure
  2. Create filler databases with type restrictions
  3. Implement item generation pipeline
  4. Set up evaluation framework (LOGPROBS and prompting)
  5. Validate items with human data
  6. Analyze results across domains and models

- Design tradeoffs:
  - Synthetic vs. naturalistic items: Synthetic items allow controlled testing but may not reflect natural language statistics
  - English-only vs. multilingual: Current framework is English-specific, limiting cross-linguistic comparisons
  - LOGPROBS vs. prompting: LOGPROBS is more reliable for many models but prompting may be more intuitive for humans

- Failure signatures:
  - Poor model performance across all domains: May indicate issues with evaluation methodology or fundamental model limitations
  - Domain-specific performance gaps: Could reveal model weaknesses in specific knowledge areas or issues with domain design
  - High variance across dataset versions: May indicate sensitivity to specific fillers or need for more robust generation

- First 3 experiments:
  1. Generate a small dataset with 2-3 domains and test on a single model to validate the pipeline
  2. Compare LOGPROBS vs. prompting evaluation on the same dataset to understand method differences
  3. Create a version with non-Western names to test cultural bias sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do LLMs show consistent performance patterns across different languages for EWoK tasks, or are there systematic differences based on linguistic structure or cultural context?
- Basis in paper: [inferred] The paper notes that EWoK is currently in English and suggests adapting it to other languages might require redesigning concepts and materials, indicating potential language-specific effects.
- Why unresolved: The study only evaluated English-language models, leaving open whether performance differences between domains (social vs. physical) would replicate in other languages or cultures.
- What evidence would resolve it: Direct comparison of multilingual models on EWoK across languages, or systematic adaptation of EWoK to different linguistic and cultural contexts with cross-linguistic performance analysis.

### Open Question 2
- Question: What specific neural or architectural mechanisms in LLMs enable better performance on social knowledge versus physical/spatial knowledge?
- Basis in paper: [explicit] The paper shows that social interactions are consistently easiest for LLMs while physical and spatial relations are hardest, with domain remaining a significant predictor even when controlling for surface features.
- Why unresolved: While the paper demonstrates the performance gap, it doesn't investigate the underlying reasons why certain domains are easier, such as differences in training data distribution or architectural biases.
- What evidence would resolve it: Mechanistic interpretability studies identifying specific circuits or attention patterns that differ between social and physical/spatial reasoning, or ablation studies testing which architectural components contribute to domain performance differences.

### Open Question 3
- Question: How does the performance of LLMs on EWoK tasks change as models are exposed to more diverse training data, particularly data that includes richer physical and spatial descriptions?
- Basis in paper: [inferred] The paper shows that even large models struggle with physical and spatial relations, suggesting these domains might benefit from more targeted training data.
- Why unresolved: The study used a fixed set of models with existing training data, but didn't explore how performance would change with different training regimes or data augmentation strategies.
- What evidence would resolve it: Controlled experiments training models with varying proportions of physical/spatial versus social data, or performance tracking as models are exposed to progressively more diverse and grounded training examples.

## Limitations
- Reliance on synthetic data may not capture real-world knowledge application complexity
- English-only focus limits generalizability across languages and cultures
- Minimal pair design may not fully account for nuanced ways humans integrate world knowledge

## Confidence

**High Confidence**: The finding that all evaluated models perform below human baselines (best: 0.80 vs human: 0.95) is well-supported by the systematic evaluation across 20 models and the controlled comparison with human participants. The domain-specific performance patterns (highest on social interactions at 0.86, lowest on spatial relations at 0.62) are robust given the large sample size and controlled experimental design.

**Medium Confidence**: The correlation between model performance and surface features (word frequency, sentence length) while controlling for domain effects is statistically sound but may not fully capture the complex relationship between linguistic patterns and world knowledge. The claim that dedicated neural substrates in humans indicate fundamental world knowledge domains is theoretically grounded but not empirically validated for language models.

**Low Confidence**: The assertion that current models lack robust world modeling capabilities based on performance on synthetic minimal pairs may overstate the limitations, as models might employ different reasoning strategies than humans. The framework's ability to isolate conceptual knowledge from surface heuristics through minimal pairs assumes models cannot develop sophisticated strategies to game the evaluation, which may not hold as models evolve.

## Next Checks

1. **Cross-linguistic validation**: Create a multilingual version of EWoK using translated items and culturally diverse fillers to test whether the domain performance patterns hold across languages and cultural contexts, particularly examining if spatial reasoning deficits persist in languages with different spatial reference frames.

2. **Naturalistic generalization test**: Evaluate the same models on EWoK items embedded in longer, more naturalistic passages rather than minimal contexts to determine if performance degrades when world knowledge must be integrated with broader discourse, revealing whether models rely on local heuristics.

3. **Alternative evaluation paradigm**: Implement a human-like evaluation protocol where models must generate explanations for their plausibility judgments rather than simply selecting or scoring options, testing whether models possess the metaknowledge to articulate their reasoning about world knowledge concepts.