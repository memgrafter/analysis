---
ver: rpa2
title: An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting
arxiv_id: '2408.04867'
source_url: https://arxiv.org/abs/2408.04867
tags:
- time
- series
- llmtime
- arima
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates LLMTIME, a large language model (LLM)-based
  approach for time series forecasting, and compares its performance to traditional
  ARIMA models across diverse datasets. LLMTIME converts numerical time series data
  into text and leverages LLMs like GPT-3.5 for zero-shot forecasting.
---

# An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting

## Quick Facts
- arXiv ID: 2408.04867
- Source URL: https://arxiv.org/abs/2408.04867
- Authors: Rui Cao; Qiao Wang
- Reference count: 36
- Standard ARIMA models significantly outperform LLMTIME for time series with trend and complex frequency patterns

## Executive Summary
This paper evaluates LLMTIME, an LLM-based approach for time series forecasting that converts numerical data into text for zero-shot prediction using models like GPT-3.5. The study compares LLMTIME against traditional ARIMA models across diverse datasets including AirPassengers, synthetic signals, and economic time series. Results reveal that while LLMTIME performs adequately for purely periodic series, its predictive accuracy deteriorates significantly when handling time series with trend components, mixed periodic-trend patterns, or complex frequency structures. ARIMA consistently achieves lower mean squared error and greater forecasting reliability across these challenging scenarios, highlighting the limitations of current LLM approaches for general time series forecasting tasks.

## Method Summary
The evaluation compares LLMTIME (an LLM-based zero-shot forecasting approach) against ARIMA models across multiple datasets. LLMTIME converts numerical time series into tokenized text sequences using digit-by-digit encoding with comma separators, then leverages GPT-3.5-turbo-instruct for next-token prediction. The approach is tested on real datasets (AirPassengers) and synthetic signals including almost periodic functions with varying noise levels. ARIMA models serve as baselines, capturing autoregressive, integrated, and moving average components. Performance is measured using mean squared error across different time series characteristics.

## Key Results
- LLMTIME's predictive accuracy significantly deteriorates when handling time series with trend and periodic components together
- ARIMA consistently outperforms LLMTIME in MSE across datasets with complex frequency patterns and mixed characteristics
- LLMTIME shows effectiveness only for fully periodic time series, while ARIMA remains robust for general forecasting tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMTIME converts numerical time series data into tokenized text to leverage LLM forecasting capabilities.
- **Mechanism:** Numerical values are tokenized digit-by-digit, separated by commas, and rescaled to a fixed precision. The LLM treats the sequence as language and generates the next token(s) as predictions.
- **Core assumption:** A well-trained LLM can infer numerical patterns from tokenized sequences and extrapolate future values in a zero-shot manner.
- **Evidence anchors:**
  - [abstract] states that LLMTIME "converts numerical time series data into text and leverages LLMs like GPT-3.5 for zero-shot forecasting."
  - [section D. LLMTIME] explains the encoding method: separating digits, using commas for time steps, removing decimals for fixed precision, and rescaling values based on percentiles.
- **Break condition:** When time series contain trend and periodic components together, or complex frequency components, the LLM's autoregressive text modeling fails to capture the underlying numerical dynamics, leading to large MSE errors.

### Mechanism 2
- **Claim:** ARIMA models remain more robust for time series with trend and complex frequency patterns because they explicitly model autocorrelation and differencing.
- **Mechanism:** ARIMA decomposes the series into autoregressive (AR), integrated (I), and moving average (MA) components, directly modeling the lagged relationships and stochastic shocks.
- **Core assumption:** Time series with both trend and periodic components require explicit statistical modeling of autocorrelation, which ARIMA provides but LLMs lack.
- **Evidence anchors:**
  - [section C. Time Series Forecasting Tasks] describes ARIMA as using "historical data to make future predictions" and capturing "both trends and temporary, sudden, or noisy data."
  - [section III] reports that "the predictive accuracy of LLMTIME diminishes significantly" for such series, while ARIMA consistently yields lower MSE.
- **Break condition:** If the series is purely periodic (no trend or mixed frequencies), the text-based LLM approach can perform comparably; ARIMA's advantage disappears.

### Mechanism 3
- **Claim:** The LLM-based approach is limited to zero-shot forecasting and cannot be fine-tuned effectively for time series due to lack of pre-training datasets.
- **Mechanism:** LLMs are pre-trained on general text corpora, not on time series; thus, they lack specialized temporal priors and cannot adapt without labeled time series data.
- **Core assumption:** Without large-scale, coherent pre-trained time series datasets, LLMs cannot learn the statistical properties of time series through pre-training.
- **Evidence anchors:**
  - [section I. INTRODUCTION] notes that "the utilization of pre-training in time series modeling faces certain challenges" because "time series data, unlike visual and textual data, lacks well-defined unsupervised targets."
  - [section I. INTRODUCTION] also mentions that "conventional time-series approaches (e.g., ARIMA) often outperform deep learning methods in widely used benchmarks."
- **Break condition:** If future work develops large-scale time series foundation models with pre-training, this limitation could be mitigated.

## Foundational Learning

- **Concept:** Autoregressive language modeling
  - Why needed here: LLMTIME treats time series as a token sequence and uses LLM's next-token prediction to forecast.
  - Quick check question: In LLMTIME, how are numerical values converted before being fed to the LLM?
- **Concept:** ARIMA model components (AR, I, MA)
  - Why needed here: ARIMA's explicit modeling of lagged dependencies and differencing is key to its robustness for trend and complex frequency series.
  - Quick check question: What are the three components of an ARIMA model and their roles?
- **Concept:** Almost periodic functions and frequency components
  - Why needed here: The study tests LLMTIME on signals like cos(2πt) + cos(2t) + noise to expose limitations in handling complex frequencies.
  - Quick check question: What is an almost periodic function and why is it challenging for LLMTIME?

## Architecture Onboarding

- **Component map:** Data preprocessing -> Tokenization and scaling -> LLM inference -> Postprocessing and evaluation
- **Critical path:**
  1. Convert raw time series to tokenized text format
  2. Send to LLM (e.g., GPT-3.5-turbo-instruct) for next-token prediction
  3. Decode predicted tokens back to numerical forecasts
  4. Compare against ARIMA baseline and compute metrics
- **Design tradeoffs:**
  - Tokenization granularity (digit-by-digit vs. whole number) affects context length and precision
  - Rescaling percentile (α) balances dynamic range vs. LLM familiarity with values
  - Zero-shot approach avoids fine-tuning but limits adaptation to specific series characteristics
- **Failure signatures:**
  - Sharp drop in predicted values after initial trend (as seen in AirPassengers dataset)
  - Large MSE spikes when series contain both trend and periodic components
  - Inability to extrapolate non-periodic signals (e.g., sin(t) + 0.2t + noise)
- **First 3 experiments:**
  1. Run LLMTIME on a purely periodic series (e.g., sin(t)) and compare MSE to ARIMA.
  2. Run both models on a mixed trend+periodic series (e.g., AirPassengers) and plot predictions.
  3. Generate synthetic almost periodic signals with increasing noise levels and evaluate both methods.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental limitations of LLMTIME that prevent it from effectively handling time series with trend and periodic components?
- Basis in paper: [explicit] The paper states that "the predictive capacity of LLMTIME, similar to other LLMs, significantly deteriorates when dealing with time series data that contain both periodic and trend components, as well as when the signal comprises complex frequency components."
- Why unresolved: The paper identifies this limitation but does not provide a detailed explanation of the underlying reasons for LLMTIME's poor performance on such time series.
- What evidence would resolve it: A thorough analysis of LLMTIME's internal workings, focusing on how it processes and interprets different types of time series data, could shed light on the reasons for its limitations.

### Open Question 2
- Question: Can LLMTIME be improved to handle non-periodic time series and time series with trend components more effectively?
- Basis in paper: [inferred] The paper suggests that "LLMTIME is effective only for fully periodic time series, while it struggles to forecast non-periodic signals." This implies that there is potential for improvement in handling non-periodic time series.
- Why unresolved: The paper does not explore potential methods or techniques to enhance LLMTIME's performance on non-periodic time series and time series with trend components.
- What evidence would resolve it: Developing and testing new approaches or modifications to LLMTIME that specifically address its limitations in handling non-periodic time series and time series with trend components would provide evidence of its potential for improvement.

### Open Question 3
- Question: How does the performance of LLMTIME compare to other LLM-based approaches for time series forecasting?
- Basis in paper: [inferred] The paper focuses on evaluating LLMTIME's performance but does not compare it to other LLM-based approaches for time series forecasting.
- Why unresolved: The paper does not provide a comprehensive comparison of LLMTIME's performance with other LLM-based approaches, which could offer insights into the relative strengths and weaknesses of different methods.
- What evidence would resolve it: Conducting a systematic comparison of LLMTIME with other LLM-based approaches for time series forecasting, using the same datasets and evaluation metrics, would provide evidence of their relative performance and help identify the most effective methods.

## Limitations

- Evaluation based on limited set of time series datasets, potentially limiting generalizability to all real-world applications
- Reliance on zero-shot forecasting approach may not fully explore LLM potential for time series tasks
- Small number of tested periodic series and lack of comparison with other deep learning baselines introduces uncertainty in conclusions

## Confidence

- **High confidence**: ARIMA's superior performance for time series with trend and complex frequency components
- **Medium confidence**: LLMTIME's effectiveness limited to purely periodic time series
- **Medium confidence**: Assertion that LLMs cannot be effectively fine-tuned for time series due to lack of pre-training datasets

## Next Checks

1. Test LLMTIME on a broader range of real-world time series datasets (e.g., from M4 competition, UCI repository) to assess generalizability beyond the current sample
2. Compare LLMTIME against other deep learning baselines (e.g., LSTMs, Transformers) that have been pre-trained or fine-tuned on time series to isolate the effect of the text-based approach
3. Experiment with alternative tokenization strategies (e.g., whole number encoding, byte-pair encoding) and prompting techniques to determine if LLMTIME's performance can be improved for trend+periodic series