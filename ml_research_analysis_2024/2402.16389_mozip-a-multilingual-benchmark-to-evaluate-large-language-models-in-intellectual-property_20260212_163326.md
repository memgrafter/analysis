---
ver: rpa2
title: 'MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual
  Property'
arxiv_id: '2402.16389'
source_url: https://arxiv.org/abs/2402.16389
tags:
- patent
- language
- llms
- data
- benchmark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces MoZIP, the first multilingual benchmark
  for evaluating large language models (LLMs) on intellectual property (IP) knowledge.
  MoZIP includes three tasks: IPQuiz (multiple-choice questions), IPQA (question answering),
  and PatentMatch (patent similarity detection), covering nine languages.'
---

# MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property

## Quick Facts
- arXiv ID: 2402.16389
- Source URL: https://arxiv.org/abs/2402.16389
- Authors: Shiwen Ni; Minghuan Tan; Yuelin Bai; Fuqiang Niu; Min Yang; Bowen Zhang; Ruifeng Xu; Xiaojun Chen; Chengming Li; Xiping Hu; Ye Li; Jianping Fan
- Reference count: 0
- This paper introduces MoZIP, the first multilingual benchmark for evaluating large language models (LLMs) on intellectual property (IP) knowledge

## Executive Summary
This paper introduces MoZIP, the first multilingual benchmark for evaluating large language models (LLMs) on intellectual property (IP) knowledge. MoZIP includes three tasks: IPQuiz (multiple-choice questions), IPQA (question answering), and PatentMatch (patent similarity detection), covering nine languages. The authors also propose MoZi, an IP-oriented multilingual LLM based on BLOOMZ, trained with patent documents and IP-specific instruction data. Experiments on five models (MoZi, BLOOMZ, BELLE, ChatGLM, ChatGPT) show ChatGPT performs best overall, but even it does not reach passing level on MoZIP. MoZi outperforms other 7B-parameter models, demonstrating the effectiveness of IP-specific fine-tuning. However, all models struggle with the challenging MoZIP tasks, indicating significant room for improvement in LLMs' understanding of IP domain knowledge.

## Method Summary
The authors developed MoZIP as a comprehensive evaluation framework for IP knowledge in multilingual settings. They created three distinct tasks: IPQuiz for multiple-choice questions testing factual IP knowledge, IPQA for open-ended question answering requiring reasoning about IP concepts, and PatentMatch for assessing the ability to determine similarity between patent documents. The benchmark covers nine languages and includes carefully curated datasets for each task. To address the evaluation needs, they also developed MoZi, an IP-specialized multilingual model based on BLOOMZ architecture, trained on patent documents and IP-specific instruction data. The evaluation compared MoZi against several other multilingual models including BLOOMZ, BELLE, ChatGLM, and ChatGPT across all three tasks and all nine languages.

## Key Results
- ChatGPT achieves the highest overall performance on MoZIP but still fails to reach passing level
- MoZi outperforms other 7B-parameter models, validating the effectiveness of IP-specific fine-tuning
- All evaluated models struggle significantly with MoZIP tasks, highlighting the challenge of IP domain knowledge
- The benchmark reveals substantial performance gaps across different languages and task types

## Why This Works (Mechanism)
The success of MoZi and the overall MoZIP framework stems from targeted domain adaptation of multilingual models to IP-specific knowledge. By fine-tuning BLOOMZ on patent documents and IP instruction data, MoZi develops specialized representations for technical and legal terminology common in IP contexts. The three-task structure of MoZIP captures different aspects of IP knowledge: factual recall (IPQuiz), reasoning (IPQA), and semantic understanding of technical documents (PatentMatch). The multilingual design ensures that IP knowledge is evaluated across linguistic boundaries, revealing whether models truly understand concepts rather than memorizing language-specific patterns.

## Foundational Learning
- Patent document structure and terminology - why needed: Understanding the technical and legal language of patents is essential for IP tasks; quick check: ability to identify patent sections and extract key claims
- Multilingual semantic equivalence - why needed: IP concepts must be recognized across languages for global patent systems; quick check: consistent performance across language pairs
- IP legal frameworks and standards - why needed: Different jurisdictions have varying IP laws that models must distinguish; quick check: correct classification of IP rights by jurisdiction
- Technical domain knowledge in patent claims - why needed: Patents often involve specialized technical fields requiring domain expertise; quick check: accurate interpretation of technical specifications
- Question answering with reasoning - why needed: IP queries often require combining multiple pieces of information; quick check: coherent multi-step reasoning in responses
- Patent similarity metrics - why needed: Assessing novelty and prior art requires understanding patent relationships; quick check: correlation with human expert judgments

## Architecture Onboarding
Component map: MoZi (BLOOMZ-based) -> IP-specific fine-tuning -> Multilingual IP tasks
Critical path: Pre-training on multilingual corpus -> Fine-tuning on patent data -> Evaluation on MoZIP tasks
Design tradeoffs: Larger model capacity vs. computational efficiency; general vs. specialized knowledge; language coverage vs. depth per language
Failure signatures: Poor performance on technical terminology; confusion between similar patent claims; language-specific knowledge gaps
First experiments: 1) Evaluate zero-shot performance on each task individually; 2) Test cross-lingual transfer between high-resource and low-resource languages; 3) Compare performance on factual vs. reasoning-intensive questions

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark difficulty and construct validity remain uncertain without extensive validation studies
- Patent similarity task relies on CRAFT metric without thorough validation for multilingual contexts
- Training data composition for MoZi is incompletely specified, affecting reproducibility
- Limited analysis of performance variations across different language families and script types
- Only zero-shot and few-shot prompting strategies were tested, missing potentially better approaches
- Focus on technical IP knowledge may not capture practical legal reasoning needed in real-world applications

## Confidence
- High confidence: The creation of a multilingual IP benchmark represents a novel contribution to the field
- Medium confidence: Claims about MoZi's superior performance relative to other 7B-parameter models
- Low confidence: The assertion that all models fail to reach "passing level" without clear passing criteria defined

## Next Checks
1. Conduct inter-annotator reliability testing on the benchmark question creation process to establish construct validity
2. Test the CRAFT metric's correlation with human judgments of patent similarity across the nine languages
3. Perform ablation studies on MoZi's training data to quantify the contribution of different data sources to performance improvements