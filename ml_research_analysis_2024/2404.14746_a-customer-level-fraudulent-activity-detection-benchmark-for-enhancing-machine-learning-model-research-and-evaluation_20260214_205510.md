---
ver: rpa2
title: A Customer Level Fraudulent Activity Detection Benchmark for Enhancing Machine
  Learning Model Research and Evaluation
arxiv_id: '2404.14746'
source_url: https://arxiv.org/abs/2404.14746
tags:
- fraud
- detection
- data
- dataset
- recall
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study addresses the challenge of fraud detection in banking
  by introducing a Customer-level Fraud Detection Benchmark (CFDB) that aggregates
  transaction-level data into customer profiles, enabling more accurate fraud detection
  models. The benchmark includes three datasets: SAML-D, AML-World LI-Small, and AML-World
  HI-Small, converted to focus on customer behavior.'
---

# A Customer Level Fraudulent Activity Detection Benchmark for Enhancing Machine Learning Model Research and Evaluation

## Quick Facts
- arXiv ID: 2404.14746
- Source URL: https://arxiv.org/abs/2404.14746
- Reference count: 0
- Introduces Customer-level Fraud Detection Benchmark (CFDB) to improve fraud detection model research and evaluation.

## Executive Summary
This study introduces the Customer-level Fraud Detection Benchmark (CFDB), a novel approach to enhance fraud detection in banking by aggregating transaction-level data into customer profiles. The benchmark includes three datasets: SAML-D, AML-World LI-Small, and AML-World HI-Small, focusing on customer behavior rather than individual transactions. Various machine learning models, including Linear Regression, Decision Tree, XGBoost, and Neural Network, were evaluated. XGBoost consistently outperformed other models, achieving perfect accuracy, AUC, and high F1 scores across datasets, highlighting the importance of customer-level data and advanced models for effective fraud detection.

## Method Summary
The study converts existing transaction-level datasets into customer-level profiles, aggregating features such as transaction amounts, frequency, and patterns. Three datasets were prepared: SAML-D (customer credit card transactions), AML-World LI-Small (low-value money laundering), and AML-World HI-Small (high-value money laundering). Machine learning models were trained and evaluated on these datasets, with XGBoost emerging as the top performer. The study emphasizes the importance of customer-level aggregation in addressing data privacy concerns and improving fraud detection accuracy.

## Key Results
- XGBoost consistently outperformed other models, achieving perfect accuracy and AUC scores across all datasets.
- Customer-level aggregation improved fraud detection by focusing on behavioral patterns rather than individual transactions.
- The benchmark datasets (SAML-D, AML-World LI-Small, AML-World HI-Small) provided a controlled environment for evaluating model performance.

## Why This Works (Mechanism)
The success of customer-level aggregation lies in its ability to capture broader behavioral patterns that are indicative of fraud, rather than relying on isolated transaction data. By summarizing transaction histories into customer profiles, the models can identify anomalies and suspicious activities more effectively. This approach also addresses data privacy concerns by reducing the granularity of the data, making it easier to share and analyze without compromising individual transaction details.

## Foundational Learning
1. **Customer-level Aggregation** - Why needed: Reduces data privacy risks and focuses on behavioral patterns. Quick check: Ensure aggregated features capture relevant fraud indicators.
2. **XGBoost Model** - Why needed: Handles complex, non-linear relationships in data. Quick check: Verify model hyperparameters are optimized for fraud detection.
3. **Benchmark Datasets** - Why needed: Provide standardized evaluation metrics for model comparison. Quick check: Validate dataset representativeness of real-world fraud scenarios.

## Architecture Onboarding
- **Component Map**: Data Aggregation -> Feature Engineering -> Model Training -> Evaluation
- **Critical Path**: Customer-level data preparation -> XGBoost model training -> Performance evaluation
- **Design Tradeoffs**: Customer-level aggregation vs. transaction-level granularity; simplicity vs. model complexity.
- **Failure Signatures**: Poor performance on datasets with limited customer diversity; overfitting on small datasets.
- **First Experiments**: 1) Test XGBoost on larger, real-world datasets. 2) Evaluate transaction-level models for comparison. 3) Assess model fairness across customer demographics.

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample sizes in benchmark datasets may limit generalizability to real-world scenarios.
- Customer-level aggregation may overlook nuanced transaction-level patterns critical for detecting sophisticated fraud.
- Datasets may not fully capture the complexity and diversity of real-world banking fraud, particularly emerging tactics.

## Confidence
- High: XGBoost superiority in this benchmark setting.
- Medium: Customer-level aggregation enhances fraud detection accuracy, given limited dataset diversity.
- Low: Generalizability of results to real-world fraud detection scenarios, especially for complex or emerging fraud tactics.

## Next Checks
1. Test benchmark models on larger, more diverse real-world banking datasets to assess scalability and robustness.
2. Evaluate models' performance on transaction-level data to identify gaps in detecting fraud missed by customer-level aggregation.
3. Investigate the impact of data biases and fairness across different customer demographics to ensure equitable fraud detection.