---
ver: rpa2
title: African or European Swallow? Benchmarking Large Vision-Language Models for
  Fine-Grained Object Classification
arxiv_id: '2406.14496'
source_url: https://arxiv.org/abs/2406.14496
tags:
- image
- uni00000013
- uni00000046
- uni00000055
- uni00000044
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large Vision-Language Models (LVLMs) show strong performance on
  image understanding and reasoning tasks but are rarely tested on fine-grained object
  classification, which is crucial for applications like visual information-seeking.
  This work introduces FOCI, a multiple-choice benchmark for fine-grained object classification,
  created by converting existing datasets (e.g., Oxford-Pets, Flowers102) into challenging
  multiple-choice tasks using a CLIP model to mine difficult negative labels.
---

# African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification

## Quick Facts
- arXiv ID: 2406.14496
- Source URL: https://arxiv.org/abs/2406.14496
- Authors: Gregor Geigle; Radu Timofte; Goran Glavaš
- Reference count: 38
- Large Vision-Language Models (LVLMs) show strong performance on image understanding and reasoning tasks but are rarely tested on fine-grained object classification, which is crucial for applications like visual information-seeking.

## Executive Summary
Large Vision-Language Models (LVLMs) excel at general image understanding but struggle with fine-grained object classification tasks that require distinguishing between visually similar objects. This work introduces FOCI, a multiple-choice benchmark created by converting existing fine-grained datasets into challenging classification tasks using CLIP-based negative label mining. The benchmark evaluates 12 publicly available LVLMs across nine diverse datasets, revealing that LVLM performance on FOCI is largely uncorrelated with their performance on standard image understanding benchmarks. This indicates that fine-grained object classification is a distinct skill requiring specific capabilities that current LVLMs lack.

## Method Summary
The paper creates FOCI by converting nine existing fine-grained object classification datasets into multiple-choice format using a CLIP model to mine difficult negative labels for each image. The benchmark covers diverse domains including aircraft, flowers, food, pets, and cars. Twelve publicly available LVLMs are evaluated on FOCI using standardized multiple-choice prompts. The study also conducts controlled experiments varying training data composition, image encoder quality, and LLM size to identify factors affecting fine-grained classification performance.

## Key Results
- LVLMs' performance on FOCI is largely uncorrelated with their performance on standard image understanding benchmarks, indicating fine-grained object classification is a complementary skill.
- LVLMs significantly lag behind their underlying CLIP models on FOCI, suggesting insufficient alignment between the image encoder and LLM for fine-grained distinctions.
- Larger LLMs, better image encoders (e.g., SigLIP), and explicit object mentions in training captions improve performance on fine-grained classification tasks.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-grained object classification requires explicit object mention in captions for alignment training.
- Mechanism: During pretraining, images paired with captions that explicitly name the object improve the image-encoder-to-LLM alignment more effectively than generic captions. The alignment module learns to associate specific visual features with the named object, enabling better discrimination between similar objects.
- Core assumption: The alignment module is trainable and sensitive to the granularity of semantic content in training captions.
- Evidence anchors:
  - [section] "Incorporating captions into the training data that explicitly name the downstream objects helps with classification. Similarly, including fine-grained classification objectives to the training mix can improve models' FOCI performance."
  - [section] "just having images containing the object does not suffice (or is, at least, less effective). Note that only the feed-forward alignment module is trained in the first phase, so the improvements with Template captions can only be the result of having learned a better alignment and not due to the image encoder or LLM (both frozen) obtaining better representations of objects and their mentions, respectively."
  - [corpus] "Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models" – discusses limitations of pre-trained recipes for fine-grained tasks.
- Break condition: If alignment module is not trainable or if captions are too generic to differentiate fine-grained objects.

### Mechanism 2
- Claim: CLIP zero-shot classification accuracy serves as an upper bound for LVLM performance on fine-grained object classification.
- Mechanism: The LVLM inherits the image encoder from CLIP. If CLIP cannot correctly classify an image in zero-shot, the LVLM is unlikely to classify it correctly because the image encoder's feature representation is insufficient for the task.
- Core assumption: The image encoder is frozen during LVLM training and its feature extraction capability is the primary determinant of classification accuracy.
- Evidence anchors:
  - [section] "CLIP models exhibit dramatically better performance than LVLMs. Since the image encoders of LVLMs come from these CLIP models, this points to inadequate alignment for fine-grained object distinction between the encoder and the LLM."
  - [section] "we observe that LVLM accuracy plummets on examples on which the corresponding CLIP fails: in fact, for instances that CLIP cannot correctly classify, the performance of the corresponding LVLM gets close to random (25%) for all three LVLMs in the analysis."
  - [corpus] "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding" – addresses insufficiency in fine-grained visual understanding evaluation.
- Break condition: If the alignment module significantly enhances the image features before they reach the LLM, or if the LLM has strong world knowledge that compensates for poor image encoding.

### Mechanism 3
- Claim: Fine-grained object classification is a distinct skill from general image understanding and reasoning.
- Mechanism: Performance on fine-grained classification tasks is largely uncorrelated with performance on standard image understanding benchmarks (GQA, MMBench, MMMU). This indicates that the skills required for fine-grained classification (distinguishing between similar objects) are not directly transferable from skills tested in general image understanding benchmarks.
- Core assumption: The correlation (or lack thereof) between benchmark performances is a valid indicator of distinct or overlapping skills.
- Evidence anchors:
  - [section] "We observe that models with similar performance on established benchmarks can yield quite different and uncorrelated results on FOCI, highlighting that fine-grained object classification is indeed a distinct skill for LVLMs."
  - [section] "Model's results on FOCI are much less correlated with their respective results on other benchmarks: better results on GQA, MMBench, or MMMU do not necessarily imply better results for fine-grained object classification and vice versa."
  - [corpus] "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?" – discusses hallucination in object attributes, a related fine-grained challenge.
- Break condition: If a new benchmark reveals a strong correlation between fine-grained classification and general image understanding performance.

## Foundational Learning

- Concept: Image encoder pre-training and feature extraction
  - Why needed here: Understanding how CLIP models encode visual information is crucial for grasping why LVLM performance is capped by CLIP's zero-shot accuracy.
  - Quick check question: What type of neural network architecture is typically used as the image encoder in CLIP models?

- Concept: Cross-modal alignment and fine-tuning
  - Why needed here: The alignment between the image encoder and LLM is the key differentiator in LVLM performance on fine-grained tasks.
  - Quick check question: What is the purpose of the alignment module in an LVLM architecture?

- Concept: Multiple-choice task formulation vs. open-ended QA
  - Why needed here: The paper argues that multiple-choice is a better formulation for evaluating fine-grained classification due to well-defined answer candidates.
  - Quick check question: What are the two main problems with using open-ended QA for fine-grained object classification?

## Architecture Onboarding

- Component map: Image Encoder -> Alignment Module -> LLM -> Multiple-Choice Output
- Critical path:
  1. Image encoder extracts features from input image
  2. Alignment module projects image features to LLM embedding space
  3. LLM processes image features along with multiple-choice options
  4. LLM outputs a letter corresponding to the chosen option
- Design tradeoffs:
  - Training data scale vs. fine-grained annotation quality
  - Image encoder resolution vs. computational cost
  - LLM size vs. inference latency
  - Multiple-choice mining difficulty vs. task validity
- Failure signatures:
  - Low accuracy on FOCI despite high accuracy on standard benchmarks (indicates distinct skill requirement)
  - LVLM accuracy close to random on examples where CLIP fails (indicates image encoder limitation)
  - Minimal improvement with higher resolution images (indicates feature representation sufficiency)
- First 3 experiments:
  1. Replace the alignment module with a simple identity function and measure FOCI performance to isolate alignment impact.
  2. Train an LVLM with only template captions (explicit object mentions) vs. only synthetic captions and compare FOCI performance.
  3. Use a stronger image encoder (e.g., SigLIP) with the same alignment and LLM, and measure the change in FOCI performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LVLMs perform on fine-grained object classification when trained on more diverse and globally representative datasets?
- Basis in paper: [inferred] The paper mentions that FOCI may exhibit bias towards Anglospheric concepts and that geographic distribution shifts in training data impact LVLM performance.
- Why unresolved: The paper briefly touches on geographic bias but does not extensively explore how training on more diverse datasets affects LVLM performance on fine-grained object classification.
- What evidence would resolve it: Training LVLMs on datasets that include a wider variety of cultural and geographic representations and evaluating their performance on FOCI.

### Open Question 2
- Question: How does the performance of LVLMs on fine-grained object classification compare to specialized fine-grained classification models?
- Basis in paper: [explicit] The paper discusses that LVLMs struggle with fine-grained object classification and suggests that future improvements in image encoding are likely to propagate to LVLM object recognition capabilities.
- Why unresolved: The paper does not directly compare LVLM performance to specialized models designed specifically for fine-grained classification tasks.
- What evidence would resolve it: Benchmarking LVLMs against state-of-the-art fine-grained classification models on datasets like FOCI.

### Open Question 3
- Question: What specific aspects of the alignment training data most significantly impact LVLM performance on fine-grained object classification?
- Basis in paper: [explicit] The paper indicates that incorporating captions that explicitly name objects and including fine-grained classification objectives improve LVLM performance.
- Why unresolved: The paper suggests these factors are important but does not isolate and analyze the individual contributions of each aspect of the training data.
- What evidence would resolve it: Controlled experiments varying different aspects of the alignment training data (e.g., caption explicitness, dataset diversity) and measuring their impact on LVLM performance on fine-grained object classification.

## Limitations

- The controlled experiments lack detailed training hyperparameters and data split information, making exact reproduction difficult.
- The evaluation methodology for 12 different LVLMs may have varying inference setups that aren't fully specified.
- The correlation analysis between FOCI performance and standard benchmarks assumes benchmark performance differences are primarily skill-based rather than influenced by evaluation artifacts or prompt engineering variations.

## Confidence

**High Confidence Claims:**
- Fine-grained object classification is a distinct skill from general image understanding, evidenced by low correlation between FOCI and standard benchmark performance.
- LVLMs significantly underperform their underlying CLIP models on fine-grained classification, indicating insufficient alignment between image encoder and LLM.
- Larger LLMs, better image encoders (SigLIP), and explicit object mentions in captions improve fine-grained classification performance.

**Medium Confidence Claims:**
- The effectiveness of template captions (explicit object mentions) for training data is demonstrated, but the relative importance compared to other factors like training data scale is not quantified.
- The upper bound relationship between CLIP zero-shot accuracy and LVLM performance is observed but not rigorously proven across all datasets.

**Low Confidence Claims:**
- The paper suggests that the alignment module's trainability is the primary mechanism for performance differences, but doesn't provide ablation studies isolating alignment impact from other factors like prompt engineering.

## Next Checks

1. Replicate the correlation analysis between FOCI and standard benchmark performance using multiple random seeds to verify the stability of the low correlation finding.
2. Conduct an ablation study where the alignment module is replaced with an identity function to quantify its exact contribution to FOCI performance.
3. Test the template caption hypothesis by training an LVLM with only template captions versus only synthetic captions, controlling for all other variables, to isolate the effect of explicit object mentions.