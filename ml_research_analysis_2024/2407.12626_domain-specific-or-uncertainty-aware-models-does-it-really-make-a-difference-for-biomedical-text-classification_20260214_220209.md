---
ver: rpa2
title: 'Domain-specific or Uncertainty-aware models: Does it really make a difference
  for biomedical text classification?'
arxiv_id: '2407.12626'
source_url: https://arxiv.org/abs/2407.12626
tags:
- entropy
- uncertainty
- language
- classification
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines the interaction between domain-specific pretraining
  and uncertainty-awareness in biomedical text classification. Using six datasets
  (English and French), it compares general-domain and domain-specific models with
  frequentist and Bayesian approaches.
---

# Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification?

## Quick Facts
- **arXiv ID**: 2407.12626
- **Source URL**: https://arxiv.org/abs/2407.12626
- **Reference count**: 23
- **Primary result**: Combining domain-specific pretraining with uncertainty modeling yields benefits, but task specificity often outweighs these effects

## Executive Summary
This study systematically compares the effects of domain-specific pretraining and uncertainty-aware modeling on biomedical text classification across six datasets (three English, three French). Using a factorial design, the authors evaluate four model configurations: general-domain frequentist, domain-specific frequentist, general-domain Bayesian, and domain-specific Bayesian. The results show that while domain-specific models generally achieve better classification performance, uncertainty-aware models produce better-calibrated probabilities. However, the specific classification task has the strongest influence on overall performance, with no single approach consistently dominating across all metrics.

## Method Summary
The authors conduct a comprehensive comparison of biomedical text classification models using six datasets (MedABS, MedNLI, SMOKING, PxSLU, MedMCQA, MORFITT) and four model configurations (-D/-U, -D/+U, +D/-U, +D/+U). They fine-tune PLMs (BERT/BioBERT for English, CamemBERT/CamemBERT-bio for French) with 10 random seeds per configuration, training with Adam optimizer across various learning rates and epochs. Evaluation includes classification metrics (Macro-F1, accuracy), uncertainty quantification (Brier score, ECE, SCE, NLL, coverage, entropy), and SHAP-based attribution analysis to quantify the relative impact of domain-specificity, uncertainty-awareness, and dataset effects.

## Key Results
- Domain-specific pretraining reduces entropy and improves classification metrics, while uncertainty-aware models increase entropy and improve calibration
- Task specificity has the strongest influence on model performance, outweighing both domain-specificity and uncertainty-awareness effects
- Statistical tests show domain-specific and uncertainty-aware models produce the most coherent entropy distributions, but no clear winner emerges across all metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific pretraining reduces entropy by concentrating probability mass on task-relevant tokens.
- Mechanism: Pretraining on biomedical corpora enables the model to learn domain-specific embeddings and vocabulary, leading to sharper probability distributions when encountering domain text.
- Core assumption: Domain-specific pretraining improves token-level representations in a way that generalizes to downstream classification tasks.
- Evidence anchors:
  - [abstract] "Domain-specific pretraining will lead to more probability mass assigned to a single (hopefully correct) estimate, leading to a lower entropy"
  - [section] "We find +D − U and +D + U to lead to lower entropy scores"
  - [corpus] Weak evidence - no direct mention of entropy reduction from domain-specific pretraining
- Break condition: If domain-specific pretraining introduces overfitting to training domain, leading to poor generalization on out-of-domain biomedical text.

### Mechanism 2
- Claim: Uncertainty-aware models increase entropy by spreading probability mass across multiple classes.
- Mechanism: Bayesian techniques (like DropConnect) introduce stochasticity in the classification layer, leading to multiple predictions per input that are aggregated to produce calibrated probabilities.
- Core assumption: Stochasticity in the classification layer leads to better uncertainty quantification without harming task performance.
- Evidence anchors:
  - [abstract] "uncertainty-aware designs intend to not neglect valid alternatives—meaning that the probability mass should be spread out, which entails a higher entropy when uncertainty is due"
  - [section] "uncertainty-aware models tend to be better calibrated"
  - [corpus] Weak evidence - no direct mention of entropy increase from uncertainty-awareness
- Break condition: If the stochasticity introduces too much noise, leading to degraded classification performance or unreliable uncertainty estimates.

### Mechanism 3
- Claim: Task specificity outweighs both domain-specificity and uncertainty-awareness effects.
- Mechanism: The inherent difficulty and characteristics of the classification task (dataset complexity, class imbalance, etc.) have a stronger impact on model performance than architectural choices.
- Core assumption: Dataset characteristics are the primary determinant of model performance, not architectural decisions.
- Evidence anchors:
  - [abstract] "the exact task at hand weighs in much more strongly"
  - [section] "we also observe that actual performances are highly sensitive to the exact classification task at hand"
  - [corpus] Moderate evidence - related works focus on task-specific challenges in biomedical text
- Break condition: If architectural choices (domain-specificity or uncertainty-awareness) have strong effects that consistently override task-specific factors.

## Foundational Learning

- Concept: Entropy as a measure of uncertainty
  - Why needed here: The paper uses entropy to compare how domain-specificity and uncertainty-awareness affect probability distributions
  - Quick check question: If a model is very confident in its predictions, will its entropy be high or low?

- Concept: Calibration in probabilistic models
  - Why needed here: The paper evaluates whether uncertainty-aware models produce well-calibrated probabilities using metrics like ECE and SCE
  - Quick check question: What does it mean for a model to be well-calibrated in terms of predicted probabilities vs actual accuracy?

- Concept: Domain adaptation vs domain-specific pretraining
  - Why needed here: The paper distinguishes between adapting general models to biomedical tasks vs using models pretrained specifically on biomedical data
  - Quick check question: What's the key difference between domain adaptation approaches and domain-specific pretraining approaches?

## Architecture Onboarding

- **Component map**: PLM encoder → Bayesian module (DropConnect) → Classification layer. The Bayesian module introduces stochasticity by randomly zeroing out classifier weights during training and inference.
- **Critical path**: For uncertainty-aware models, the critical path is the repeated sampling of predictions with different weight configurations, then aggregating them. For standard models, it's the direct forward pass.
- **Design tradeoffs**: Domain-specific pretraining improves performance but requires domain-specific data and computational resources. Uncertainty-awareness improves calibration but adds computational overhead during inference.
- **Failure signatures**: If entropy doesn't increase with uncertainty (incorrect predictions), the Bayesian module may not be working correctly. If domain-specific models don't outperform general models, the domain-specific pretraining may have been ineffective.
- **First 3 experiments**:
  1. Train a baseline model (general-domain, frequentist) on one dataset and measure entropy, F1, and calibration metrics
  2. Train a domain-specific model (biomedical pretraining, frequentist) on the same dataset and compare all metrics
  3. Train an uncertainty-aware model (general-domain, Bayesian) on the same dataset and compare all metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions does domain-specific pretraining provide more benefit than uncertainty-awareness for biomedical text classification?
- Basis in paper: [inferred] The paper notes that "the exact task at hand weighs in much more strongly" than classifier design, and that domain-specific models tend to perform better on classification metrics while uncertainty-aware models are better calibrated, but no clear winner emerges across all metrics.
- Why unresolved: The study shows that the effectiveness of each approach varies significantly across different datasets and tasks, suggesting task-specific factors determine which approach is more beneficial.
- What evidence would resolve it: Systematic experiments comparing domain-specific and uncertainty-aware models across a broader range of biomedical tasks with varying characteristics (e.g., class imbalance, dataset size, label complexity) could identify patterns in when each approach excels.

### Open Question 2
- Question: How does the interaction between domain-specific pretraining and uncertainty modeling affect model calibration across different types of biomedical classification tasks?
- Basis in paper: [explicit] The paper finds that uncertainty-aware models tend to be better calibrated but notes that "the exact task at hand weighs in much more strongly" than classifier design.
- Why unresolved: While the study observes that uncertainty-aware models generally improve calibration, it doesn't provide a comprehensive analysis of how this interaction varies across different biomedical classification scenarios.
- What evidence would resolve it: Detailed calibration analysis across multiple biomedical tasks, examining how domain-specific pretraining affects uncertainty modeling's calibration benefits in different classification contexts.

### Open Question 3
- Question: What are the optimal architectural combinations of domain-specific pretraining and uncertainty modeling for different biomedical text classification scenarios?
- Basis in paper: [inferred] The paper compares various Bayesian architectures (DropConnect, MCDropout, Variational Inference) and finds DropConnect performs well on average, but notes that no single approach dominates across all metrics and tasks.
- Why unresolved: The study suggests that the optimal combination depends on the specific task, but doesn't provide clear guidelines for selecting appropriate architectures based on task characteristics.
- What evidence would resolve it: Comprehensive benchmarking of different architectural combinations across a diverse set of biomedical tasks, with analysis of which combinations work best for different task types.

## Limitations

- The study's findings are limited by the relatively small number of datasets (n=6) and potential domain-specificity of the observed effects
- French datasets (MORFITT, PxSLU, MedMCQA) may not generalize to other biomedical domains or languages
- The paper does not provide detailed analysis of individual model failures or specific error patterns

## Confidence

- **High confidence**: The general observation that task specificity outweighs architectural choices is well-supported by the data and aligns with broader literature on domain adaptation
- **Medium confidence**: The finding that domain-specific models tend to have lower entropy and better classification performance is supported but could be influenced by dataset-specific factors
- **Medium confidence**: The observation that uncertainty-aware models are better calibrated is well-established, but the practical impact on downstream tasks needs further validation

## Next Checks

1. **Dataset expansion**: Test the same experimental setup on additional biomedical datasets (both English and other languages) to assess generalizability of the findings
2. **Error analysis**: Conduct detailed error analysis on misclassified examples to understand when domain-specific pretraining helps versus hurts performance
3. **Real-world validation**: Evaluate model performance on out-of-distribution biomedical text (e.g., different medical specialties or time periods) to assess robustness beyond the training domains