---
ver: rpa2
title: A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language
  Models
arxiv_id: '2408.02377'
source_url: https://arxiv.org/abs/2408.02377
tags:
- relation
- data
- extraction
- https
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores using Large Language Models (LLMs), specifically
  ChatGPT, for few-shot learning in relation extraction domain adaptation within the
  Architecture, Engineering, Construction, and Operations (AECO) field. The researchers
  generated in-domain training data by leveraging ChatGPT's in-context learning capabilities
  with structured prompts and minimal expert annotation.
---

# A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models

## Quick Facts
- arXiv ID: 2408.02377
- Source URL: https://arxiv.org/abs/2408.02377
- Authors: Vanni Zavarella; Juan Carlos Gamero-Salinas; Sergio Consoli
- Reference count: 29
- One-line primary result: Combining ChatGPT-generated annotations with curated out-of-domain data improves relation extraction performance in the AECO domain by up to 23.78% F1 for entity extraction and 21.82% for relation extraction.

## Executive Summary
This study explores using Large Language Models (LLMs), specifically ChatGPT, for few-shot learning in relation extraction domain adaptation within the Architecture, Engineering, Construction, and Operations (AECO) field. The researchers generated in-domain training data by leveraging ChatGPT's in-context learning capabilities with structured prompts and minimal expert annotation. They tested different prompt configurations on AECO research paper titles and abstracts, comparing the results to a baseline model trained on out-of-domain data. While the quality of LLM-generated annotations alone was insufficient for full domain customization, combining them with curated out-of-domain labels significantly improved performance.

## Method Summary
The researchers used ChatGPT's in-context learning capabilities to generate schema-constrained annotations for AECO domain texts. They created structured prompts containing task definitions, schema descriptions, and few-shot examples, then used the OpenAI API to generate entity and relation annotations for approximately 476k AECO research abstracts. These LLM-generated annotations were combined with curated out-of-domain SciERC dataset labels and used to train a SpERT model with SciBERT embeddings. The approach was evaluated on a test set of ~50 annotated AECO abstracts, measuring micro F1 scores for entity extraction, relation detection, and relation detection with entity classification.

## Key Results
- Micro-average F1 score of 23.78% for entity extraction when using ChatGPT-generated data with schema descriptions and 10 examples
- Micro-average F1 score of 21.82% for relation extraction with the same configuration
- Performance improved when combining ChatGPT-generated annotations with curated out-of-domain SciERC labels
- Adding explicit task definitions and increasing few-shot examples consistently raised performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Few-shot learning with LLMs can generate structured annotations that match a predefined schema
- Mechanism: ChatGPT receives structured prompts containing task definitions, schema descriptions, and few-shot examples, then outputs entity and relation annotations in a consistent format
- Core assumption: The LLM can interpret the schema correctly and apply it to new text without further training
- Evidence anchors:
  - [abstract] "experiment with leveraging in-context learning capabilities of Large Language Models to perform schema-constrained data annotation"
  - [section 3] "we experiment on schema-constrained instruction prompts sent to the Chat Completion endpoint of the OpenAI gpt-3.5-turbo-0125 (ChatGPT) API"
  - [corpus] Weak - only mentions similar papers but no direct evidence for schema compliance
- Break condition: When LLM generates annotations that don't align with the schema or when semantic manipulation occurs (e.g., creating non-text-anchored entities)

### Mechanism 2
- Claim: Combining LLM-generated annotations with curated out-of-domain data improves model performance
- Mechanism: ChatGPT-generated data is merged with existing SciERC dataset to create a hybrid training set that improves domain adaptation
- Core assumption: LLM-generated data, despite noise, provides useful domain-specific patterns that complement existing out-of-domain knowledge
- Evidence anchors:
  - [section 4] "best results are obtained by adding ChatGPT generated labels to curated out-of-domain SciERC labels"
  - [abstract] "combining them with curated out-of-domain labels significantly improved performance"
  - [corpus] Weak - no corpus evidence directly supports this hybrid approach
- Break condition: When noise in LLM-generated data outweighs the benefits or when domain-specific patterns conflict with out-of-domain knowledge

### Mechanism 3
- Claim: Increasing few-shot examples and adding schema descriptions improves LLM performance
- Mechanism: More examples and explicit schema descriptions help the LLM better understand the annotation task and produce higher-quality outputs
- Core assumption: The LLM's few-shot learning capabilities benefit from more examples and clearer task definitions
- Evidence anchors:
  - [section 4] "Adding explicit Task definitions and increasing the number of few-shot examples both consistently raise the performance"
  - [abstract] "using a few-shot learning strategy with structured prompts and only minimal expert annotation"
  - [corpus] Weak - corpus mentions similar approaches but no direct evidence for this specific mechanism
- Break condition: When additional examples don't provide new information or when schema descriptions are redundant

## Foundational Learning

- Concept: In-context learning
  - Why needed here: The entire approach relies on LLMs' ability to learn from examples without fine-tuning
  - Quick check question: Can you explain the difference between in-context learning and fine-tuning?

- Concept: Relation extraction task structure
  - Why needed here: Understanding entity and relation types is crucial for creating effective prompts
  - Quick check question: What are the main entity and relation types in the SciERC schema?

- Concept: Few-shot learning principles
  - Why needed here: The method's success depends on selecting informative examples for prompts
  - Quick check question: How do you determine which examples are most effective for few-shot learning?

## Architecture Onboarding

- Component map: Data collection (OpenAlex) -> Annotation generation (ChatGPT API) -> Model training (SpERT with SciBERT) -> Evaluation (SCIERC-AEC test set)
- Critical path: Prompt design → ChatGPT annotation generation → SpERT training → Performance evaluation
- Design tradeoffs:
  - ChatGPT vs. fine-tuning: Cost vs. control over output
  - Schema complexity: More detailed schemas improve accuracy but require more examples
  - Data volume: More generated data may improve performance but increases noise
- Failure signatures:
  - Low entity extraction F1 but high relation extraction F1: Indicates entity recognition issues
  - Consistent annotation format errors: Suggests prompt structure problems
  - Performance worse than baseline: Indicates LLM-generated data quality issues
- First 3 experiments:
  1. Test basic schema prompt with 3 examples on 50 sentences
  2. Compare performance with schema description added to prompt
  3. Evaluate impact of increasing examples from 3 to 10 on same 50 sentences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of domain adaptation using LLMs vary across different scientific domains beyond AECO?
- Basis in paper: [inferred] The paper suggests future work could involve testing the approach on other domains beyond AECO, implying that domain-specific variations in performance are an open question.
- Why unresolved: The current study only focuses on the AECO domain, so there is no comparative data on performance across different scientific domains.
- What evidence would resolve it: Conducting similar experiments across various scientific domains (e.g., biology, physics, social sciences) and comparing the performance metrics (e.g., F1 scores) would provide insights into how domain adaptation using LLMs varies.

### Open Question 2
- Question: How does the quality of LLM-generated annotations impact the performance of the relation extraction model?
- Basis in paper: [explicit] The paper mentions that the quality of LLM-generated annotations alone was insufficient for full domain customization, but combining them with curated out-of-domain labels significantly improved performance.
- Why unresolved: While the paper shows that combining LLM-generated data with curated data improves performance, it does not provide a detailed analysis of how the quality of LLM-generated annotations alone affects the model's performance.
- What evidence would resolve it: Conducting experiments with varying quality levels of LLM-generated annotations and analyzing their impact on the relation extraction model's performance would provide insights into this relationship.

### Open Question 3
- Question: What is the optimal balance between the number of few-shot examples and the quality of schema descriptions for effective LLM-based annotation?
- Basis in paper: [inferred] The paper tests different configurations of few-shot examples (K=3 and K=10) and the inclusion of schema descriptions, but it does not determine the optimal balance between these factors.
- Why unresolved: The paper provides performance results for different configurations but does not explicitly identify the optimal combination of few-shot examples and schema descriptions.
- What evidence would resolve it: Conducting a systematic study with varying numbers of few-shot examples and different levels of schema description detail, while measuring the impact on annotation quality and model performance, would help identify the optimal balance.

## Limitations
- Performance improvements are moderate (21.82% F1 for relation extraction), suggesting the approach may need refinement for production use
- Results are limited to one specialized domain (AECO), making generalizability claims uncertain
- The study doesn't address scalability to larger datasets or full research papers versus abstracts

## Confidence

**High Confidence**: The core finding that combining LLM-generated annotations with curated out-of-domain data improves performance over using either alone is well-supported by the experimental results.

**Medium Confidence**: The assertion that increasing few-shot examples and adding schema descriptions consistently improves performance is supported by the experiments, but the magnitude of improvement varies significantly.

**Low Confidence**: The broader claim about LLMs being a general solution for domain adaptation in relation extraction across different scientific fields lacks sufficient evidence due to the AECO-only focus.

## Next Checks

1. **Cross-domain validation**: Apply the same methodology to at least two additional scientific domains (e.g., biomedical and physics literature) to test the generalizability of the approach. Compare performance consistency across domains and identify which aspects of the prompt design are domain-agnostic versus domain-specific.

2. **Scale-up experiment**: Increase the volume of LLM-generated annotations from the current small-scale experiment to thousands of sentences. Measure how performance scales with annotation volume and identify the point of diminishing returns where additional noisy annotations no longer improve model performance.

3. **Alternative LLM comparison**: Replace ChatGPT with other large language models (e.g., Claude, LLaMA) using identical prompts and training procedures. Quantify the variance in performance across different models to determine whether the approach is robust to LLM choice or heavily dependent on specific model capabilities.