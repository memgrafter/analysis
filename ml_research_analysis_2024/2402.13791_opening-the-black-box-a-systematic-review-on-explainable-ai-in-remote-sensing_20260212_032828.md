---
ver: rpa2
title: 'Opening the Black-Box: A Systematic Review on Explainable AI in Remote Sensing'
arxiv_id: '2402.13791'
source_url: https://arxiv.org/abs/2402.13791
tags:
- issn
- learning
- methods
- remote
- sensing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts a systematic review of explainable AI (xAI)
  methods in remote sensing, analyzing over 200 publications to identify key trends,
  objectives, and challenges. The review reveals that while machine learning methods
  dominate remote sensing applications, there is a significant gap in using xAI approaches
  to interpret these models.
---

# Opening the Black-Box: A Systematic Review on Explainable AI in Remote Sensing

## Quick Facts
- arXiv ID: 2402.13791
- Source URL: https://arxiv.org/abs/2402.13791
- Reference count: 40
- One-line primary result: Systematic review reveals gap between ML dominance and xAI adoption in remote sensing, with SHAP and CAM most commonly used methods

## Executive Summary
This paper conducts a systematic review of explainable AI (xAI) methods in remote sensing, analyzing over 200 publications to identify key trends, objectives, and challenges. The review reveals that while machine learning methods dominate remote sensing applications, there is a significant gap in using xAI approaches to interpret these models. The most commonly used xAI methods are local approximation approaches like SHAP and backpropagation methods like CAM, primarily applied to tasks like landcover mapping and agricultural monitoring. The review highlights the need for better evaluation metrics, the development of methods tailored to remote sensing data properties (scale, temporal dependencies, geographic relationships), and the combination of xAI with related fields like uncertainty quantification and physics-aware machine learning.

## Method Summary
The authors performed a systematic literature review following PRISMA guidelines, executing comprehensive search queries across IEEE, Scopus, and Springer databases. They employed a tree-like categorization framework to organize xAI methods and analyzed usage patterns, objectives, and evaluation approaches across different Earth observation tasks. The review focused on publications from 2017 to 2023, covering various remote sensing applications including landcover mapping, agricultural monitoring, and natural hazard monitoring.

## Key Results
- SHAP and CAM dominate xAI usage in remote sensing due to ease of application and broad applicability
- Explanation interpretation requires domain knowledge integration due to semantic gaps in remote sensing features
- Significant gap exists between machine learning adoption and xAI usage in remote sensing applications

## Why This Works (Mechanism)

### Mechanism 1
The systematic review successfully maps the landscape of xAI methods in remote sensing by combining broad literature search with a hierarchical categorization framework. The authors execute a comprehensive search query combining xAI and remote sensing keywords across three databases and introduce a tree-like categorization of xAI methods to organize the findings. This approach captures the full scope of xAI applications in remote sensing without significant bias, though the combination remains niche with weak corpus support.

### Mechanism 2
The review identifies that model-agnostic, post-hoc methods (SHAP, CAM) dominate xAI usage in remote sensing due to their ease of application and broad applicability. By analyzing the frequency of xAI method usage across publications, the authors find that these approaches are most frequently used for interpreting CNN models in landcover mapping and agricultural monitoring. This dominance reflects both technical suitability and community preference for methods requiring minimal architectural changes.

### Mechanism 3
The review reveals that explanation interpretation in remote sensing requires domain knowledge integration because raw features often lack intuitive semantics. The authors identify that practitioners frequently transform raw remote sensing features into interpretable features or associate domain knowledge with explanations post-hoc to make them meaningful. This semantic gap created by remote sensing data properties necessitates domain expertise to bridge the interpretability divide.

## Foundational Learning

- Concept: Systematic literature review methodology
  - Why needed here: The review's validity depends on comprehensive and unbiased literature collection and analysis
  - Quick check question: What are the key differences between PRISMA guidelines and typical review approaches in computer science?

- Concept: xAI method categorization frameworks
  - Why needed here: The hierarchical categorization enables structured analysis of diverse xAI approaches
  - Quick check question: How does the four-way categorization (feature attribution, distillation, intrinsic, contrastive) compare to alternative taxonomies in the xAI literature?

- Concept: Remote sensing data properties and challenges
  - Why needed here: Understanding scale, spectral resolution, and temporal dependencies is crucial for interpreting xAI findings in this domain
  - Quick check question: What specific properties of remote sensing data make standard CV xAI methods less effective?

## Architecture Onboarding

- Component map: Literature search engine (3 databases) -> Paper screening pipeline (duplicate removal, abstract screening, full-text screening) -> Categorization framework (tree-like structure) -> Analysis modules (usage patterns, evaluation methods, objectives) -> Synthesis engine (trend identification, challenge mapping)

- Critical path: Execute comprehensive search query across databases → Screen and filter papers through multiple stages → Apply categorization framework to organize findings → Analyze patterns in method usage, evaluation, and objectives → Synthesize insights into challenges and future directions

- Design tradeoffs: Breadth vs. depth in search coverage; categorization granularity vs. complexity; anecdotal vs. quantitative evaluation reliability

- Failure signatures: Incomplete literature coverage indicated by missing key papers; categorization mismatches where methods don't fit neatly into defined categories; inconsistent evaluation criteria across different xAI approaches

- First 3 experiments: Validate search query by checking if known seminal papers are captured; test categorization framework by applying it to a small subset of papers and checking for consistency; compare anecdotal vs. quantitative evaluation approaches on a representative sample of papers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop more standardized and objective evaluation methods for xAI approaches in remote sensing?
- Basis in paper: The paper highlights the lack of standardized and objective evaluation methods for xAI, with most studies relying on anecdotal evidence.
- Why unresolved: Current evaluation methods are subjective and prone to biases, hindering the comparison and adoption of xAI approaches.
- What evidence would resolve it: Development and validation of quantitative metrics and user studies specifically designed for evaluating xAI in remote sensing tasks.

### Open Question 2
- Question: How can we adapt xAI methods to better handle the unique properties of remote sensing data, such as scale, temporal dependencies, and geographic relationships?
- Basis in paper: The paper discusses the challenges of applying traditional xAI methods to remote sensing data due to its unique properties.
- Why unresolved: Existing xAI methods are primarily designed for natural images and do not explicitly consider the characteristics of remote sensing data.
- What evidence would resolve it: Development and evaluation of xAI methods that explicitly incorporate the properties of remote sensing data, such as scale-aware attention mechanisms or temporal graph neural networks.

### Open Question 3
- Question: How can we leverage the combination of xAI with related fields like physics-aware machine learning and uncertainty quantification to enhance model reliability and interpretability in remote sensing?
- Basis in paper: The paper suggests the potential of combining xAI with physics-aware machine learning and uncertainty quantification to improve model reliability and interpretability.
- Why unresolved: The integration of these fields is still in its early stages, and the benefits and challenges of such combinations need to be further explored.
- What evidence would resolve it: Development and evaluation of hybrid approaches that combine xAI with physics-aware machine learning or uncertainty quantification, demonstrating improved model performance and interpretability.

## Limitations
- Search coverage may have missed emerging methods or niche applications due to recent xAI adoption in remote sensing
- Categorization framework may not fully capture nuances of hybrid or novel approaches combining multiple xAI strategies
- Assessment of current evaluation metrics' insufficiency is based on observed gaps rather than comprehensive analysis

## Confidence

**High confidence**: Dominance of model-agnostic post-hoc methods (SHAP, CAM) is well-supported by quantitative analysis of method usage across publications. Landcover mapping and agricultural monitoring as primary application domains is strongly supported by data.

**Medium confidence**: Challenges related to explanation interpretation and need for domain knowledge integration are supported by anecdotal evidence and expert observations, but would benefit from more systematic evaluation of practitioner experiences.

**Low confidence**: Assertion that current evaluation metrics are insufficient is based on observed gaps rather than comprehensive analysis of existing metrics' effectiveness.

## Next Checks

1. **Search coverage validation**: Verify that the systematic search captures all seminal xAI papers in remote sensing by comparing against manually curated lists of key publications.

2. **Categorization consistency test**: Apply the xAI categorization framework to a subset of papers using multiple reviewers to assess inter-rater reliability and identify potential categorization gaps.

3. **Domain knowledge integration assessment**: Conduct structured interviews with remote sensing practitioners to validate the identified challenges in explanation interpretation and quantify the extent of domain knowledge integration in practice.