---
ver: rpa2
title: 'HARP: Human-Assisted Regrouping with Permutation Invariant Critic for Multi-Agent
  Reinforcement Learning'
arxiv_id: '2409.11741'
source_url: https://arxiv.org/abs/2409.11741
tags:
- learning
- human
- group
- agents
- reinforcement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of incorporating human guidance
  in multi-agent reinforcement learning (MARL) where agents dynamically form groups
  for collaboration. The authors propose HARP, a framework that allows non-expert
  humans to provide effective guidance during deployment with minimal intervention.
---

# HARP: Human-Assisted Regrouping with Permutation Invariant Critic for Multi-Agent Reinforcement Learning

## Quick Facts
- arXiv ID: 2409.11741
- Source URL: https://arxiv.org/abs/2409.11741
- Reference count: 36
- Primary result: Human-assisted regrouping framework achieving >10% performance improvement in StarCraft II MARL

## Executive Summary
This paper introduces HARP (Human-Assisted Regrouping with Permutation Invariant Critic), a framework that integrates human guidance into multi-agent reinforcement learning systems where agents dynamically form collaborative groups. The key innovation lies in combining automatic agent regrouping during training with strategic human-assisted regrouping during deployment, evaluated through a permutation invariant group critic. The method addresses the challenge of incorporating non-expert human guidance while minimizing intervention requirements, demonstrating substantial performance gains across three difficulty levels in StarCraft II micromanagement tasks.

## Method Summary
HARP employs a dual-phase approach to multi-agent regrouping. During training, agents learn optimal regrouping strategies through reinforcement learning with a permutation invariant critic that evaluates group configurations regardless of agent ordering. During deployment, the framework allows for human intervention to assist regrouping decisions when needed. The permutation invariant critic ensures that group performance evaluation remains consistent across different agent permutations, enabling efficient learning of regrouping policies. Human guidance is integrated through a minimal intervention protocol where humans assist only when the automated system encounters uncertainty or suboptimal configurations.

## Key Results
- Achieved over 10% performance improvement across three difficulty levels in StarCraft II environments
- Attained 100% win rates on all tested maps (8m, MMM, 5m vs 6m, 8m vs 9m, MMM2, corridor)
- Limited human involvement to less than 25% of total deployment steps while improving success rates from 65% to 100% on challenging scenarios

## Why This Works (Mechanism)
The framework succeeds by addressing a fundamental challenge in MARL: the need for flexible agent grouping that adapts to changing environmental conditions and task requirements. Traditional MARL approaches often assume fixed agent roles or static groupings, which limits adaptability in complex scenarios. HARP's permutation invariant critic enables the system to evaluate group configurations without being constrained by agent identity ordering, allowing the learning algorithm to discover optimal regrouping strategies that maximize collective performance. The human-in-the-loop component provides strategic guidance during deployment when automated regrouping might be uncertain, particularly in novel or highly complex situations.

## Foundational Learning
- **Permutation invariant critics**: Needed to evaluate group configurations independent of agent ordering; quick check: verify critic output remains constant under agent permutation
- **Dynamic regrouping policies**: Required for adaptive agent collaboration; quick check: test policy response to environmental changes
- **Human-in-the-loop MARL**: Essential for incorporating strategic guidance without expert-level human involvement; quick check: measure performance impact of human intervention frequency
- **StarCraft II micromanagement**: Provides complex multi-agent testbed with hierarchical decision-making; quick check: validate performance across different map complexities
- **Group formation evaluation**: Critical for determining optimal agent configurations; quick check: compare performance with and without regrouping
- **Minimal intervention protocols**: Enables practical deployment with limited human resources; quick check: analyze intervention frequency vs performance tradeoff

## Architecture Onboarding

**Component Map:** Environment -> Agent Observation -> Policy Network -> Action Selection -> Environment Feedback -> Permutation Invariant Critic -> Reward Calculation -> Regrouping Decision -> Human Intervention (optional)

**Critical Path:** Agent observations are processed through policy networks to generate actions, which interact with the environment to produce feedback. The permutation invariant critic evaluates group configurations from these interactions, informing regrouping decisions. Human intervention occurs only when the system identifies uncertainty or suboptimal performance.

**Design Tradeoffs:** The framework balances between fully automated MARL and human-guided systems. While complete automation would eliminate human involvement, it risks suboptimal performance in complex scenarios. Conversely, heavy human involvement would ensure optimal decisions but becomes impractical at scale. HARP's approach of minimal intervention during deployment with automatic regrouping during training represents a middle ground.

**Failure Signatures:** System failures may manifest as persistent suboptimal regrouping patterns, high frequency of human interventions, or performance degradation in novel scenarios. The permutation invariant critic may also fail to capture important spatial or temporal dependencies in highly complex environments.

**First Experiments:**
1. Test HARP performance on a single StarCraft II map with varying difficulty levels
2. Compare regrouping frequency and human intervention rates across different scenarios
3. Evaluate permutation invariant critic performance against standard critics using agent ordering variations

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions or areas for future research.

## Limitations
- Relies on human intervention during deployment, even with minimal requirements
- Evaluation limited to StarCraft II micromanagement tasks, limiting generalizability
- Performance metrics may be sensitive to specific map configurations and opponent strategies

## Confidence
- **High Confidence**: Performance improvements over baseline methods (>10% gain)
- **Medium Confidence**: Human intervention effectiveness with <25% deployment involvement
- **Medium Confidence**: Applicability of permutation invariant critics for group evaluation

## Next Checks
1. Test HARP on non-StarCraft environments (e.g., robot coordination, traffic control) to assess cross-domain applicability
2. Conduct ablation studies removing human intervention to quantify the exact contribution of the human-in-the-loop component
3. Evaluate performance against dynamic opponent strategies that adapt to observed regrouping patterns