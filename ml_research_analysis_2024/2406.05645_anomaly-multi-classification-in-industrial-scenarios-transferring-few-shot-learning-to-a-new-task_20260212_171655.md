---
ver: rpa2
title: 'Anomaly Multi-classification in Industrial Scenarios: Transferring Few-shot
  Learning to a New Task'
arxiv_id: '2406.05645'
source_url: https://arxiv.org/abs/2406.05645
tags:
- anomaly
- learning
- contrastive
- classification
- industrial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel task called anomaly multi-classification,
  which aims to classify the type of anomaly in industrial scenarios. The authors
  propose a baseline model combining RelationNet and PatchCore, along with a data
  generation method that creates pseudo classes and corresponding proxy tasks.
---

# Anomaly Multi-classification in Industrial Scenarios: Transferring Few-shot Learning to a New Task

## Quick Facts
- **arXiv ID**: 2406.05645
- **Source URL**: https://arxiv.org/abs/2406.05645
- **Reference count**: 40
- **Primary result**: Achieves 37.16% ± 0.42% accuracy in two-shot anomaly classification on MVTec and MVTec3D datasets

## Executive Summary
This paper introduces the novel task of anomaly multi-classification in industrial scenarios, where the goal is to classify the specific type of defect in industrial products after anomaly detection. The authors propose a baseline model that combines RelationNet and PatchCore, along with a data generation method to create pseudo classes for pretraining. By utilizing contrastive learning and evaluating on MVTec AD and MVTec3D AD datasets, their approach demonstrates superior performance in this challenging task, particularly in few-shot scenarios with limited defect examples.

## Method Summary
The proposed method combines PatchCore for anomaly detection with a RelationNet-based classifier, enhanced by a data generation approach that creates pseudo defect classes using DTD textures and Poisson noise segmentation. The model is pretrained on these generated classes before being fine-tuned on few-shot real defect samples. Contrastive learning with InfoNCE loss is employed to improve the classifier's ability to distinguish between different defect types. The approach addresses the challenge of classifying rare defect types in industrial products by leveraging synthetic data generation and transfer learning from a pretraining phase.

## Key Results
- Achieves 37.16% ± 0.42% average accuracy in two-shot scenarios across 14 product categories
- Shows significant improvement over baseline methods in anomaly multi-classification
- Demonstrates performance gap between few-shot (39.19%) and many-shot (62.29%) scenarios, highlighting the challenge of limited defect examples
- Validates effectiveness on both MVTec AD and MVTec3D AD datasets

## Why This Works (Mechanism)
The method works by leveraging the strengths of multiple approaches: PatchCore provides robust anomaly detection through nearest neighbor search in a memory bank of normal sample features, while RelationNet enables few-shot learning through metric-based classification. The data generation component addresses the fundamental challenge of limited defect examples by creating synthetic defect classes that allow pretraining on diverse anomaly types. Contrastive learning further enhances the model's ability to distinguish between different defect categories by maximizing the similarity of positive pairs and minimizing negative pairs in the feature space.

## Foundational Learning
- **PatchCore for anomaly detection**: Why needed - to extract residual features that capture deviations from normal patterns; Quick check - verify residual features show clear separation between normal and anomalous patches
- **Few-shot learning with RelationNet**: Why needed - to classify defect types with minimal examples; Quick check - monitor pretraining accuracy to ensure it doesn't exceed 40% to avoid overfitting
- **Contrastive learning (InfoNCE)**: Why needed - to improve discrimination between defect categories; Quick check - verify loss decreases during training and feature embeddings show class separation
- **Data generation with pseudo classes**: Why needed - to address scarcity of real defect examples; Quick check - ensure generated defects maintain realistic characteristics and diversity

## Architecture Onboarding

**Component Map**: Normal samples -> PatchCore feature extraction -> Memory bank -> Pseudo class generation -> RelationNet pretraining -> Contrastive fine-tuning -> Defect classification

**Critical Path**: The critical path involves PatchCore extracting features from normal samples, followed by data generation to create pseudo defect classes, pretraining the RelationNet classifier, and finally fine-tuning with contrastive learning on few-shot real defect samples.

**Design Tradeoffs**: The approach balances the need for diverse training data (through synthetic generation) with the risk of introducing unrealistic defect patterns. The choice of 10 pseudo-classes represents an empirical tradeoff between sufficient diversity and computational efficiency. The use of contrastive learning adds training complexity but significantly improves classification performance.

**Failure Signatures**: 
- Poor performance may indicate improper PatchCore feature extraction or synthetic data that doesn't capture real defect characteristics
- Pretraining collapse suggests overfitting to synthetic classes or inadequate diversity in generated defects
- Contrastive learning failure may result from improper temperature scaling or insufficient positive/negative pairs

**First Experiments**:
1. Validate PatchCore feature extraction by visualizing residuals and checking for meaningful separation
2. Test data generation pipeline by examining synthetic defects for realism and diversity
3. Conduct ablation study to measure the individual contribution of contrastive learning

## Open Questions the Paper Calls Out
### Open Question 1
- **Question**: What is the optimal number of pseudo-classes to use in the data generation process for pretraining?
- **Basis in paper**: [explicit] The authors use 10 pseudo-classes (empirical value) but note that different numbers could be explored.
- **Why unresolved**: The paper only tests one value and doesn't explore the impact of varying the number of pseudo-classes on final performance.
- **What evidence would resolve it**: Experiments systematically varying the number of pseudo-classes and measuring classification accuracy across different shot scenarios.

### Open Question 2
- **Question**: How does the proposed method perform on other types of industrial defect datasets beyond MVTec and MVTec3D?
- **Basis in paper**: [explicit] The authors only evaluate on MVTec and MVTec3D datasets and acknowledge this limitation.
- **Why unresolved**: The paper only tests on two specific datasets, limiting generalizability to other industrial scenarios.
- **What evidence would resolve it**: Experiments on additional industrial defect datasets with varying characteristics (e.g., different defect types, image resolutions, lighting conditions).

### Open Question 3
- **Question**: What is the impact of different residual feature extraction strategies on classification performance?
- **Basis in paper**: [explicit] The authors use PatchCore for residual feature extraction but don't compare with other methods like PaDim or ReConPatch.
- **Why unresolved**: The paper only uses one residual feature extraction method without exploring alternatives.
- **What evidence would resolve it**: Experiments comparing different residual feature extraction methods while keeping the classification network architecture constant.

## Limitations
- The 37.16% accuracy in two-shot scenarios, while promising, still represents limited performance for industrial applications
- Significant performance gap between few-shot and many-shot scenarios (39.19% vs 62.29%) highlights the fundamental challenge of learning from limited defect examples
- Data generation approach using DTD textures and Poisson noise may not fully capture the complexity and diversity of real-world industrial defects

## Confidence
- **High Confidence**: The overall experimental methodology and dataset usage (MvTec AD, MvTec3D AD) are clearly specified and reproducible
- **Medium Confidence**: The combination of PatchCore and RelationNet provides a reasonable baseline for this novel task, though exact implementation details remain partially unspecified
- **Medium Confidence**: The contrastive learning approach shows promise but may not fully address the fundamental challenge of few-shot defect classification

## Next Checks
1. Validate the data generation pipeline by testing whether generated pseudo classes maintain realistic defect characteristics and distribution properties
2. Conduct ablation studies to quantify the individual contributions of PatchCore feature extraction, contrastive learning, and data generation components
3. Test model performance on a held-out set of real industrial defects not present in the original MvTec datasets to assess true generalization capability