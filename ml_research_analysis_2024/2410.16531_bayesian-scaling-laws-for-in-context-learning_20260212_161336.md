---
ver: rpa2
title: Bayesian scaling laws for in-context learning
arxiv_id: '2410.16531'
source_url: https://arxiv.org/abs/2410.16531
tags:
- bayesian
- scaling
- laws
- ginc
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel Bayesian scaling law for in-context
  learning (ICL) that models ICL as an ideal Bayesian learner. The method uses Bayes'
  theorem to derive a functional form relating the number of in-context examples to
  the probability of correct predictions, introducing interpretable parameters for
  task priors, learning efficiency, and per-example probabilities.
---

# Bayesian scaling laws for in-context learning

## Quick Facts
- arXiv ID: 2410.16531
- Source URL: https://arxiv.org/abs/2410.16531
- Authors: Aryaman Arora; Dan Jurafsky; Christopher Potts; Noah D. Goodman
- Reference count: 40
- Key outcome: Bayesian scaling law matches or surpasses power law baselines in accuracy while providing interpretable parameters for task priors, learning efficiency, and per-example probabilities

## Executive Summary
This paper proposes a novel Bayesian scaling law for in-context learning (ICL) that models ICL as an ideal Bayesian learner. The method uses Bayes' theorem to derive a functional form relating the number of in-context examples to the probability of correct predictions, introducing interpretable parameters for task priors, learning efficiency, and per-example probabilities. Experiments on both synthetic GINC data and real-world LLMs (1B-405B parameters) show that the Bayesian scaling law matches or surpasses existing power law baselines in accuracy while providing better interpretability.

## Method Summary
The Bayesian scaling law treats ICL as an ideal Bayesian learner, where each in-context example provides evidence that shifts posterior task probabilities via repeated application of Bayes' theorem. The method involves training GPT-2 models on synthetic GINC data, generating ICL curves by measuring next-token prediction probabilities, and fitting the Bayesian scaling law alongside baseline scaling laws (power, bounded power, logistic) using numerically stable optimization with L-BFGS. The approach introduces interpretable parameters including task priors, ICL efficiency, and task-conditional probabilities, and evaluates performance using normalized root mean-squared error (NRMSE).

## Key Results
- Bayesian scaling law matches or exceeds power law baselines in fitting accuracy on both synthetic and real LLM data
- The law accurately predicts ICL behavior and explains when suppressed behaviors reemerge after post-training
- Parameter analysis reveals interpretable patterns: SFT primarily modifies task priors while preserving task knowledge across model scales

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ICL approximates Bayesian learning by updating posterior task probabilities after each in-context example
- Mechanism: Each in-context example provides evidence that shifts the posterior over tasks via Bayes' theorem, with task probabilities converging to the task that best explains the examples
- Core assumption: The LLM processes in-context examples sequentially and updates beliefs in a Bayesian manner
- Evidence anchors:
  - [abstract] "we seek to explain this correlation by showing that ICL approximates a Bayesian learner"
  - [section 3.1] "we can use repeated application of Bayes' theorem to derive a Bayesian law for ICL"
  - [corpus] Weak - no direct citations to Bayesian ICL mechanisms
- Break condition: If the model processes examples in parallel rather than sequentially, or if learning is non-Bayesian (e.g., gradient-based)

### Mechanism 2
- Claim: The Bayesian scaling law accurately predicts ICL behavior by modeling task priors, learning efficiency, and per-example probabilities
- Mechanism: The derived formula relates number of examples to prediction accuracy through interpretable parameters that capture the underlying Bayesian inference process
- Core assumption: ICL behavior follows the functional form predicted by Bayesian theory
- Evidence anchors:
  - [abstract] "our scaling law matches existing scaling laws in accuracy while also offering interpretable terms for task priors, learning efficiency, and per-example probabilities"
  - [section 4.1] "Bayesian law is in agreement with our knowledge about the pretraining distribution"
  - [corpus] Weak - no direct citations to Bayesian scaling law validation
- Break condition: If ICL behavior deviates significantly from Bayesian predictions or if non-Bayesian models fit better

### Mechanism 3
- Claim: Post-training affects ICL by modifying task priors rather than fundamental task knowledge
- Mechanism: Fine-tuning adjusts the prior probability of tasks but leaves the conditional probabilities (task knowledge) largely unchanged
- Core assumption: Post-training operations primarily reweight task priors in the Bayesian framework
- Evidence anchors:
  - [abstract] "our law accurately predicts the conditions under which ICL will cause suppressed behaviors to reemerge, which sheds light on the ineffectiveness of post-training at increasing LLM safety"
  - [section 4.2] "SFT makes similar changes to model knowledge about distributions across scales, but changes the prior more for smaller models"
  - [corpus] Weak - no direct citations to Bayesian interpretation of post-training
- Break condition: If post-training fundamentally alters task knowledge beyond prior modification

## Foundational Learning

- Concept: Bayesian inference and posterior updating
  - Why needed here: The entire scaling law derivation depends on Bayesian updating of task probabilities
  - Quick check question: Can you explain how Bayes' theorem updates the probability of a task given observed examples?

- Concept: Scaling laws and their functional forms
  - Why needed here: The paper compares the Bayesian law against established scaling law baselines
  - Quick check question: What are the key differences between power law, bounded power law, and logistic scaling laws?

- Concept: In-context learning evaluation methodology
  - Why needed here: Understanding how ICL curves are measured is crucial for interpreting results
  - Quick check question: How is the ICL curve constructed from model predictions on in-context examples?

## Architecture Onboarding

- Component map: Synthetic data generation (GINC) -> Model training (pretraining/SFT/DPO) -> ICL evaluation pipeline -> Scaling law fitting module -> Parameter analysis -> Result interpretation
- Critical path: Data generation → Model training → ICL evaluation → Scaling law fitting → Parameter analysis → Result interpretation
- Design tradeoffs: Bayesian law offers interpretability but requires more parameters; non-Bayesian laws are simpler but less interpretable; steps-matched vs FLOPs-matched training affects model comparability
- Failure signatures: Poor NRMSE indicates model-Bayesian law mismatch; parameter instability suggests overfitting; unexpected prior shifts indicate non-Bayesian behavior
- First 3 experiments:
  1. Train small GPT-2 models on GINC and evaluate ICL curves to verify Bayesian behavior
  2. Fit Bayesian scaling law to ICL data and compare NRMSE with baselines
  3. Apply SFT to modify priors and observe effects on ICL curve parameters

## Open Questions the Paper Calls Out
None

## Limitations
- The Bayesian scaling law was primarily validated on synthetic GINC data with controlled task distributions, with uncertain generalizability to natural language
- Parameter identifiability issues are not addressed, potentially reducing interpretability claims
- No direct evidence is provided that LLMs perform sequential Bayesian updates as assumed
- The Bayesian interpretation of post-training effects is plausible but not rigorously tested

## Confidence

**High Confidence**: The experimental methodology for fitting scaling laws and computing NRMSE is standard and well-established. The mathematical derivation of the Bayesian scaling law from Bayes' theorem is correct.

**Medium Confidence**: The claim that the Bayesian law matches or surpasses baseline accuracy in fitting ICL curves is supported by experiments, but the magnitude of improvement and its statistical significance across different model families could be more thoroughly characterized.

**Low Confidence**: The interpretability claims regarding the biological meaning of learned parameters (task priors, ICL efficiency) are speculative. The paper doesn't validate that these parameters correspond to meaningful aspects of model behavior beyond curve fitting.

## Next Checks

1. **Ablation on Sequential vs Parallel Processing**: Design experiments where in-context examples are presented in different orders or simultaneously to test whether ICL truly follows sequential Bayesian updating. Compare ICL curves under these conditions to predictions from the Bayesian law.

2. **Parameter Recovery Study**: Generate synthetic ICL data from known Bayesian parameters, then attempt to recover these parameters using the proposed fitting procedure. Vary noise levels and sample sizes to establish bounds on parameter identifiability and fitting accuracy.

3. **Cross-Domain Transfer Test**: Apply the Bayesian scaling law to ICL tasks from domains significantly different from the pretraining distribution (e.g., code generation, mathematical reasoning) and examine whether the same functional form and parameter interpretations hold, or if systematic deviations emerge.