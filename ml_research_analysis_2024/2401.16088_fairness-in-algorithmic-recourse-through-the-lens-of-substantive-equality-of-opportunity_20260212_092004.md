---
ver: rpa2
title: Fairness in Algorithmic Recourse Through the Lens of Substantive Equality of
  Opportunity
arxiv_id: '2401.16088'
source_url: https://arxiv.org/abs/2401.16088
tags:
- recourse
- effort
- time
- agents
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces two new fairness metrics for algorithmic
  recourse: effort-to-recourse and time-to-recourse, designed to capture disparities
  in how much effort and time different groups need to achieve a positive outcome
  after receiving a negative algorithmic decision. The authors use an agent-based
  simulation to show that even when decision-making is fair, recourse can be unfair
  due to initial qualification disparities and differences in effort distributions
  between advantaged and disadvantaged populations.'
---

# Fairness in Algorithmic Recourse Through the Lens of Substantive Equality of Opportunity

## Quick Facts
- arXiv ID: 2401.16088
- Source URL: https://arxiv.org/abs/2401.16088
- Authors: Andrew Bell; Joao Fonseca; Carlo Abrate; Francesco Bonchi; Julia Stoyanovich
- Reference count: 40
- Key outcome: Introduces effort-to-recourse and time-to-recourse fairness metrics; proposes CNS intervention to mitigate disparities

## Executive Summary
This paper introduces two new fairness metrics for algorithmic recourse: effort-to-recourse and time-to-recourse, designed to capture disparities in how much effort and time different groups need to achieve a positive outcome after receiving a negative algorithmic decision. The authors use an agent-based simulation to show that even when decision-making is fair, recourse can be unfair due to initial qualification disparities and differences in effort distributions between advantaged and disadvantaged populations. They propose a mitigation strategy called Circumstance-Normalized Selection (CNS), which selects individuals for positive outcomes proportionally by population, and show it significantly reduces disparities compared to baseline methods. Combining CNS with counterfactual data augmentation yields the best fairness improvements.

## Method Summary
The authors develop an agent-based simulation framework where agents from advantaged and disadvantaged populations receive negative algorithmic decisions and attempt to achieve positive outcomes through recourse actions. The simulation models initial qualifications using bimodal distributions and tracks effort and time required for successful recourse. They introduce two fairness metrics (effort-to-recourse and time-to-recourse) and evaluate a mitigation strategy called Circumstance-Normalized Selection (CNS) that proportionally assigns positive outcomes by population. The framework is tested across 100 simulation seeds with varying levels of initial qualification disparity and effort distribution differences.

## Key Results
- CNS intervention significantly reduces effort-to-recourse disparities between advantaged and disadvantaged groups
- Even when disadvantaged agents exert more effort, they still experience persistent time-to-recourse disparities due to initial qualification gaps
- Combined CNS + Counterfactual Data Augmentation (CDA) approach yields the best fairness improvements
- CNS maintains high precision in assigning positive outcomes while reducing unfair effort disparities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Disparities in effort-to-recourse arise when initial qualification distributions differ between groups, even if classifier decision-making is fair.
- Mechanism: The simulation models initial qualifications using bimodal distributions (high-performing vs. lower-performing agents). Lower-performing agents from disadvantaged groups have a lower mean qualification (µd < µa), requiring more effort to cross the decision threshold. Since the classifier is fair in terms of demographic parity, but initial qualifications differ, the disadvantaged group must exert more effort per successful recourse event.
- Core assumption: Initial qualification differences between groups are due to morally arbitrary factors (e.g., socioeconomic background) and not innate ability. The effort distribution is tied to population membership.
- Evidence anchors:
  - [abstract] "recourse itself may be unfair due to differences in the initial circumstances of individuals, compounding disparities for marginalized populations and requiring them to exert more effort than others."
  - [section] "Importantly, each P a and P d have an associated initial qualification and effort... Our choice to focus on the feature generation method from Figure 4(a), where populations have similar performance distributions (equal variance) but many members of the disadvantaged group have lower initial qualifications (different means), is consistent with this normative framing."
- Break condition: If initial qualification distributions are equalized (q=0), the disparity in effort-to-recourse disappears.

### Mechanism 2
- Claim: Time-to-recourse disparities persist even when effort disparities are mitigated because initial qualification gaps require more time to overcome.
- Mechanism: Even if the disadvantaged group exerts more effort (ea < ed), they still take longer to achieve a positive outcome due to their lower initial qualifications. The simulation shows that increased effort doesn't compensate for the time needed to overcome the initial gap. New agents entering at each time step create competitive pressure, making it harder for disadvantaged agents to catch up.
- Core assumption: Time is a critical element in recourse because model drift and changing contexts weaken recourse recommendations over time. The competitive environment means that disadvantaged agents are continually subject to competitive effects.
- Evidence anchors:
  - [abstract] "Time is a critical element in recourse because the longer it takes an individual to act, the more the setting may change due to model or data drift."
  - [section] "We observed that it is more difficult for disadvantaged populations to successfully act on recourse—taking more time and more repeated effort—even under a classifier that is fair."
- Break condition: If initial qualifications are equalized or if the system accounts for time-to-recourse in selection (e.g., rewarding effort over time).

### Mechanism 3
- Claim: Circumstance-Normalized Selection (CNS) mitigates effort-to-recourse disparities by selecting individuals proportionally by population, rather than across the entire population.
- Mechanism: CNS assigns positive outcomes to the highest-scoring individuals from each sub-population, proportionally by population size. This means individuals compete within their population rather than against the entire population. Since initial circumstances and effort are population-level attributes, this approach is fair under substantive equality of opportunity.
- Core assumption: The normative framework of substantive equality of opportunity justifies rewarding effort and mitigating disadvantage due to morally arbitrary factors. The intervention is post-hoc (after scoring and generating recourse recommendations), making it agnostic to the scoring and recourse recommendation methods.
- Evidence anchors:
  - [section] "Following this justification, we develop an intuitive selection intervention, based on rank-aware proportional representation by Yang and Stoyanovich [2017]."
  - [section] "It involves assigning positive outcomes to the highest-scoring individuals from each sub-population, proportionally by population size."
- Break condition: If the population sizes are highly imbalanced or if the effort distributions within populations are highly variable.

## Foundational Learning

- Concept: Agent-based simulation modeling
  - Why needed here: The paper uses an agent-based framework to simulate recourse over time, allowing researchers to model the dynamics of effort and time in a controlled environment. Understanding how agents interact with the classifier and each other is crucial for interpreting the results.
  - Quick check question: How does the agent-based simulation model the competition between agents for limited positive outcomes over time?

- Concept: Counterfactual explanations and recourse
  - Why needed here: Algorithmic recourse provides recommendations to individuals on how to change their features to receive a positive outcome. Understanding how counterfactual explanations are generated and how they relate to effort and time is essential for grasping the fairness issues discussed in the paper.
  - Quick check question: What are the two conditions that a recourse recommendation must satisfy according to the paper?

- Concept: Normative frameworks for fairness (substantive equality of opportunity)
  - Why needed here: The paper grounds its fairness metrics in the normative framework of substantive equality of opportunity, which focuses on removing morally irrelevant barriers and rewarding morally relevant effort. Understanding this framework is crucial for interpreting the proposed metrics and intervention.
  - Quick check question: How does the paper's normative framework justify the Circumstance-Normalized Selection intervention?

## Architecture Onboarding

- Component map:
  Agent-based simulation -> Classifier (ranker) -> Recourse recommendation generator -> Effort/time tracking -> Fairness metrics calculation -> CNS intervention

- Critical path:
  1. Initialize populations with initial qualifications (bimodal distribution)
  2. Score agents using classifier
  3. Assign positive outcomes (baseline: top-k; CNS: proportionally by population)
  4. Generate recourse recommendations for negatively classified agents
  5. Agents act on recommendations (effort drawn from population-specific distribution)
  6. Repeat for T time steps
  7. Calculate effort-to-recourse and time-to-recourse metrics

- Design tradeoffs:
  - Fairness vs. overall utility: CNS may select individuals with sub-optimal scores relative to a fixed threshold, potentially reducing overall utility.
  - Computational cost: Running the agent-based simulation for 100 seeds and multiple experimental conditions is computationally expensive.
  - Model simplicity vs. realism: The ranker (f(x) = 0.5 × x1 + 0.5 × x2) is simple but may not capture the complexity of real-world decision-making.

- Failure signatures:
  - High variance in effort-to-recourse and time-to-recourse metrics across simulation runs (indicates instability)
  - CNS not effectively mitigating disparities (indicates implementation error or inappropriate normative grounding)
  - CDA performing worse than baseline (indicates unintended consequences of the intervention)

- First 3 experiments:
  1. Baseline simulation with q=0 (no initial qualification disparity) and ea=ed (equal effort) to verify that CNS doesn't introduce unfairness when it's not needed.
  2. Simulation with q=1 and ea < ed (disadvantaged group exerts more effort) to observe the persistence of time-to-recourse disparities despite increased effort.
  3. Combined CNS + CDA intervention with q=3 and ea > ed (largest initial disparity and advantaged group exerts more effort) to evaluate the effectiveness of the combined approach.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the magnitude of the trade-off between mitigating effort-to-recourse disparities and maintaining overall utility (e.g., maximizing the number of positive outcomes)?
- Basis in paper: [explicit] The authors mention this trade-off in the Discussion section but do not explore it further.
- Why unresolved: The authors explicitly state they do not explore this trade-off due to scope limitations.
- What evidence would resolve it: Experimental results quantifying the decrease in overall utility (e.g., fewer positive outcomes assigned) when implementing mitigation strategies that prioritize effort-to-recourse fairness.

### Open Question 2
- Question: How do the proposed fairness metrics (effort-to-recourse and time-to-recourse) perform in real-world datasets with more complex feature distributions and non-linear decision boundaries?
- Basis in paper: [inferred] The authors acknowledge the lack of real-world algorithmic recourse datasets and rely on simulations with simplified assumptions (e.g., linear scoring function, bimodal feature distributions).
- Why unresolved: The authors rely on synthetic data and simulations, highlighting the absence of real-world algorithmic recourse datasets.
- What evidence would resolve it: Empirical evaluation of the proposed metrics on real-world datasets where individuals receive algorithmic recourse recommendations (e.g., credit denial reason codes).

### Open Question 3
- Question: What are the long-term societal impacts of implementing the Circumstance-Normalized Selection (CNS) strategy, particularly regarding potential unintended consequences like reduced incentives for self-improvement?
- Basis in paper: [explicit] The authors discuss potential trade-offs but do not delve into long-term societal impacts.
- Why unresolved: The authors acknowledge the need to consider long-term effects but do not explore them due to scope limitations.
- What evidence would resolve it: Longitudinal studies tracking individuals' behavior and outcomes after the implementation of CNS, examining changes in motivation, effort exerted, and overall societal well-being.

## Limitations

- The agent-based simulation uses simplified assumptions about effort distributions and competitive dynamics that may not generalize to real-world settings
- The study focuses on binary group comparisons, which may not capture intersectional effects
- The framework relies on synthetic data and simulations due to the absence of real-world algorithmic recourse datasets

## Confidence

- High: CNS intervention reduces effort-to-recourse disparities; Combined CNS+CDA approach yields best fairness improvements
- Medium: Initial qualification disparities cause effort-to-recourse unfairness; Time-to-recourse disparities persist despite increased effort
- Low: The normative justification for CNS is universally applicable; Real-world implementation would yield similar results

## Next Checks

1. External validation: Test CNS intervention on a real-world dataset (e.g., credit scoring) to verify that simulation results generalize to practical settings.

2. Intersectional analysis: Extend the framework to handle more than two demographic groups and examine how CNS performs with intersectional categories.

3. Dynamic qualification modeling: Replace the fixed bimodal qualification distribution with a dynamic model that allows qualifications to evolve over time based on past outcomes and interventions.