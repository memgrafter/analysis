---
ver: rpa2
title: 'Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based
  approach'
arxiv_id: '2407.09039'
source_url: https://arxiv.org/abs/2407.09039
tags:
- data
- learning
- forgetting
- tril3
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TRIL3, a continual learning framework designed
  to address catastrophic forgetting in tabular data classification. The approach
  uses XuILVQ to generate synthetic prototypes from past data and a modified DNDF
  algorithm for classification, enabling incremental learning without storing old
  samples.
---

# Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based approach

## Quick Facts
- arXiv ID: 2407.09039
- Source URL: https://arxiv.org/abs/2407.09039
- Reference count: 6
- Key outcome: TRIL3 framework with 50% synthetic data consistently outperforms replay-based MLP and offline DNDF training in catastrophic forgetting scenarios

## Executive Summary
This paper introduces TRIL3, a continual learning framework designed to address catastrophic forgetting in tabular data classification. The approach uses XuILVQ to generate synthetic prototypes from past data and a modified DNDF algorithm for classification, enabling incremental learning without storing old samples. The framework combines synthetic and real data in training batches to preserve old knowledge while adapting to new patterns. Experiments across four real-world datasets show that TRIL3 with 50% synthetic data consistently outperforms other methods, particularly during forgetting phases.

## Method Summary
TRIL3 is a continual learning framework that uses XuILVQ to generate synthetic prototypes and a modified DNDF algorithm for incremental classification. The method involves online standardization of incoming batches, XuILVQ prototype updates, synthetic prototype generation, mixed batch creation (combining real and synthetic data), and DNDF incremental training. The framework processes tabular data in streaming batches, generating synthetic samples to represent previously learned classes when new data arrives, thus avoiding the need to store old samples.

## Key Results
- TRIL3 with 50% synthetic data consistently outperforms replay-based MLP and offline DNDF training across four datasets
- Strong robustness against forgetting while maintaining classification performance close to or better than batch offline training
- F1-score improvements during forgetting phases demonstrate effective knowledge preservation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic prototypes generated by XuILVQ preserve decision boundaries for old classes during forgetting phases.
- Mechanism: XuILVQ incrementally updates prototypes that approximate statistical distribution of each class. Underrepresented classes are balanced by adding synthetic prototypes mixed with real data for training.
- Core assumption: Prototype distribution is statistically representative enough to prevent decision boundary drift.
- Evidence anchors: Abstract mentions XuILVQ preserves old knowledge; section explains prototype updates.
- Break condition: If data distribution shifts rapidly or XuILVQ cannot maintain adequate coverage, synthetic samples may fail to represent true distribution.

### Mechanism 2
- Claim: Partial gradient updates on mixed real/synthetic batches reduce catastrophic forgetting compared to full retraining.
- Mechanism: DNDF updated with one epoch of SGD on batches containing both new real samples and synthetic prototypes, moderating weight updates.
- Core assumption: Mixed-batch gradient signal is sufficient to adapt to new data while retaining old knowledge.
- Evidence anchors: Abstract mentions modified DNDF for incremental learning; section describes partial gradient updates.
- Break condition: If real data fraction is too low, model may underfit new classes; if too high, forgetting accelerates.

### Mechanism 3
- Claim: Online standardization ensures consistent feature scaling across real and synthetic samples, preventing domain shift.
- Mechanism: Incoming batches standardized (zero mean, unit variance) before XuILVQ updates or DNDF training.
- Core assumption: Standardization parameters adequately capture evolving feature distribution for both real and synthetic data.
- Evidence anchors: Section mentions online standardization for consistent preparation.
- Break condition: If feature distributions shift drastically, running standardization may become outdated.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper's core problem is preventing model degradation on old classes when learning new ones.
  - Quick check question: What happens to a neural network's weights when trained only on new data after learning old classes?

- Concept: Rehearsal strategies (buffer-based vs generative)
  - Why needed here: TRIL3 uses generative rehearsal via XuILVQ prototypes instead of storing old samples.
  - Quick check question: How does generative rehearsal differ from replay-based rehearsal in terms of memory and data privacy?

- Concept: Incremental learning vector quantization (ILVQ)
  - Why needed here: XuILVQ is the prototype-based generative model that drives synthetic sample creation.
  - Quick check question: In ILVQ, under what condition is a new sample added as a prototype rather than updating existing ones?

## Architecture Onboarding

- Component map: Data ingestion → Online standardization → XuILVQ prototype update → Synthetic prototype generation → Mixed batch creation → DNDF incremental training → (Optional) Prediction
- Critical path: Standardization → XuILVQ update → Prototype generation → DNDF update
- Design tradeoffs:
  - Prototype set size vs memory: Larger sets improve fidelity but increase training cost.
  - Real/synthetic ratio: Balancing forgetting resistance vs new-class learning capacity.
  - Update frequency: More frequent updates adapt faster but risk instability.
- Failure signatures:
  - Degraded F1 on old classes during forgetting phase → prototype coverage insufficient.
  - Unstable loss curves → learning rate too high or ratio misbalanced.
  - High variance in predictions → synthetic samples poorly represent true distribution.
- First 3 experiments:
  1. Validate prototype generation: Train XuILVQ on a small dataset, generate prototypes, and visualize using UMAP to confirm coverage.
  2. Test forgetting resistance: Train TRIL3 on two classes, hide one during a forgetting phase, measure F1 retention.
  3. Ratio sweep: Vary real/synthetic ratios (25%, 50%, 75%, 100%) and plot F1 before/during forgetting to find optimal mix.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TRIL3 vary with different percentages of synthetic data (e.g., 25%, 50%, 75%, 100%) across various datasets?
- Basis in paper: The paper mentions evaluating different ratios of real to synthetic data and identifies 50% as optimal.
- Why unresolved: The paper identifies 50% as optimal but doesn't provide comprehensive analysis of other percentages across datasets.
- What evidence would resolve it: Conducting experiments with range of synthetic data percentages on various datasets and comparing performance metrics would provide insights.

### Open Question 2
- Question: How does TRIL3 perform on multiclass classification problems compared to binary classification problems?
- Basis in paper: The paper mentions potential extension to multiclass problems but doesn't provide experimental results.
- Why unresolved: Current evaluation focuses on binary classification, leaving multiclass effectiveness unexplored.
- What evidence would resolve it: Testing TRIL3 on multiclass datasets and comparing performance to binary classification results would clarify applicability.

### Open Question 3
- Question: How does the performance of TRIL3 compare to other state-of-the-art continual learning methods beyond those mentioned in the paper?
- Basis in paper: The paper compares TRIL3 to replay-based MLP and offline DNDF training but doesn't explore other methods.
- Why unresolved: Limited comparisons leave relative performance in broader context unclear.
- What evidence would resolve it: Evaluating TRIL3 against wider range of state-of-the-art methods on various datasets would provide comprehensive understanding.

## Limitations
- Limited evaluation to 2-class classification tasks across four datasets, may not generalize to complex multi-class scenarios
- Lack of comparison with other state-of-the-art rehearsal methods beyond replay-based MLP
- Online standardization assumes stable feature distributions, which may not hold in highly dynamic data environments

## Confidence

- **High confidence** in experimental methodology and dataset preparation, as these are clearly specified
- **Medium confidence** in core claim that TRIL3 reduces catastrophic forgetting, supported by comparative results
- **Medium confidence** in mechanism explanations, though lack of neighbor citations for key components reduces confidence

## Next Checks

1. Reproduce core results: Implement TRIL3 framework and verify F1 score improvements on four specified datasets during forgetting phases
2. Validate prototype quality: Generate synthetic prototypes using XuILVQ and compare statistical properties to real data using visualization and clustering metrics
3. Test robustness to distribution shifts: Evaluate TRIL3 performance when feature distributions change rapidly between batches to assess limits of online standardization approach