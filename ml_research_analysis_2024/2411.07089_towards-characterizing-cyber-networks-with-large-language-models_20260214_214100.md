---
ver: rpa2
title: Towards Characterizing Cyber Networks with Large Language Models
arxiv_id: '2411.07089'
source_url: https://arxiv.org/abs/2411.07089
tags:
- data
- embeddings
- network
- cyber
- logs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents CLEM, a tool that applies large language models
  to analyze cyber logs for threat hunting. The approach uses BERT to embed Zeek network
  logs and deliberately overfits each sliding window of data to capture behavioral
  semantics.
---

# Towards Characterizing Cyber Networks with Large Language Models

## Quick Facts
- arXiv ID: 2411.07089
- Source URL: https://arxiv.org/abs/2411.07089
- Authors: Alaric Hartsock; Luiz Manella Pereira; Glenn Fink
- Reference count: 22
- Key outcome: CLEM applies BERT to embed Zeek network logs and clusters them to detect anomalies, showing meaningful agreement with expert labels

## Executive Summary
This paper introduces CLEM, a novel approach that leverages large language models to analyze cyber network logs for threat hunting. The method applies BERT with WordPiece tokenization to embed Zeek connection logs, deliberately overfits on sliding windows to capture behavioral semantics, and uses clustering to identify anomalous patterns. By comparing k-means clustering results to expert labels using Adjusted Rand Index, the authors demonstrate that their approach can uncover latent behavioral patterns in network data that could help detect compromised systems and anomalies.

## Method Summary
CLEM processes Zeek connection logs by first preprocessing to remove UID and timestamp fields, then tokenizing using WordPiece vocabulary. A BERT model (bert-base-cased) is trained on sliding windows of 10,000 log lines until cross-entropy loss drops below 0.02, then advances 5,000 lines and repeats. The method extracts 5-tuple embeddings, reduces dimensions using UMAP, and applies k-means clustering. The clustering results are evaluated against expert-derived labels using Adjusted Rand Index to measure agreement.

## Key Results
- CLEM successfully embeds Zeek network logs using BERT with WordPiece tokenization
- Deliberate overfitting on sliding windows captures meaningful behavioral semantics
- K-means clustering of embeddings shows strong correlation with expert-labeled behavioral groups using ARI

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BERT embeddings capture semantic relationships in cyber logs because tokenization reduces arbitrary network identifiers into manageable semantic units
- Mechanism: WordPiece tokenization maps variable-length network identifiers into a fixed dictionary of 30,522 tokens, creating consistent embeddings for semantically similar patterns
- Core assumption: Network behavior patterns share enough token-level similarity to be embedded meaningfully
- Evidence anchors:
  - [abstract] "we employ these latent features of cyber data to find anomalies"
  - [section] "we use the WordPiece tokenization originally described by Wu, et al. [17]; this reduced the token dictionary to a constant 30,522 tokens"
  - [corpus] No direct corpus evidence for WordPiece effectiveness on cyber data; assumption based on NLP literature
- Break condition: If network data contains patterns with no shared token-level structure, embeddings will fail to capture semantic relationships

### Mechanism 2
- Claim: Deliberate overfitting on sliding windows allows the model to tightly characterize behavioral semantics within each time window
- Mechanism: Training continues on each window until cross-entropy loss < 0.02, forcing the model to memorize the specific behavioral patterns of that window
- Core assumption: Cyber behavioral patterns are consistent enough within short time windows to be learned through memorization
- Evidence anchors:
  - [abstract] "The model is deliberately overtrained on a sliding window of data to characterize each window closely"
  - [section] "we train over each window in batches until a desired degree of loss is achieved"
  - [corpus] No direct corpus evidence for effectiveness of overfitting in cyber log analysis
- Break condition: If behavioral patterns change rapidly within windows, the model will fail to capture meaningful semantics

### Mechanism 3
- Claim: K-means clustering of BERT embeddings produces clusters that correlate with expert-labeled behavioral groups
- Mechanism: After embedding, dimension reduction via UMAP creates spatial arrangements where similar behaviors cluster together, and K-means identifies these clusters
- Core assumption: Behavioral semantics captured in embeddings translate to spatial proximity after dimension reduction
- Evidence anchors:
  - [abstract] "We use the Adjusted Rand Index (ARI) to comparing the k-means clustering of CLEM output to expert labeling of the embeddings"
  - [section] "By dimensionally-reducing and plotting these embeddings, we find that they cluster meaningfully"
  - [corpus] No direct corpus evidence for effectiveness of UMAP+K-means on cyber embeddings
- Break condition: If embeddings do not preserve behavioral semantics in reduced dimensions, clustering will not match expert labels

## Foundational Learning

- Concept: Tokenization and vocabulary construction
  - Why needed here: Network data contains arbitrary identifiers (IP addresses, ports) that require systematic tokenization for meaningful embedding
  - Quick check question: What tokenization strategy would you use for a dataset containing 10 million unique IP addresses?

- Concept: Overfitting as a feature
  - Why needed here: Deliberate overfitting forces the model to memorize window-specific patterns, creating tight behavioral characterization
  - Quick check question: How would you determine the optimal stopping point for overfitting on a new dataset?

- Concept: Dimension reduction techniques
  - Why needed here: UMAP preserves local structure in high-dimensional embeddings while reducing to 2-3 dimensions for visualization and clustering
  - Quick check question: What properties of UMAP make it suitable for preserving behavioral clusters in reduced dimensions?

## Architecture Onboarding

- Component map: Data ingestion -> Zeek log preprocessing -> BERT embedding -> UMAP dimension reduction -> K-means clustering -> ARI evaluation
- Critical path:
  1. Load Zeek logs and preprocess (remove UID, ts fields)
  2. Tokenize using WordPiece vocabulary
  3. Train BERT on sliding windows until loss < 0.02
  4. Extract embeddings for 5-tuple connections
  5. Reduce dimensions with UMAP
  6. Cluster with K-means and compare to expert labels using ARI
- Design tradeoffs:
  - Memory vs. granularity: Larger windows capture more context but require more memory
  - Training time vs. accuracy: More epochs improve loss but increase computation time
  - Dimension reduction vs. cluster preservation: UMAP parameters affect cluster separation
- Failure signatures:
  - Low or negative ARI scores indicate poor semantic capture
  - Uniform embedding distributions suggest tokenization issues
  - Rapid cluster movement between windows may indicate overfitting
- First 3 experiments:
  1. Run CLEM on synthetic data with known behavioral patterns to verify ARI calculation
  2. Test different window sizes (5000, 10000, 15000 lines) to find optimal granularity
  3. Compare WordPiece vs. standard BERT tokenizer performance on Zeek logs

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on novel application of NLP techniques to cyber logs without extensive empirical validation
- Deliberate overfitting approach may not generalize to networks with rapidly evolving patterns
- Clustering methodology assumes behavioral semantics translate to meaningful clusters in reduced dimensions

## Confidence
- Confidence in core claims: Medium
- The paper provides a coherent theoretical framework and demonstrates initial success on two datasets, but lacks extensive empirical testing and detailed implementation specifics

## Next Checks
1. Test CLEM on synthetic datasets with known behavioral patterns to verify that the method can accurately recover ground truth clusters across varying network conditions
2. Conduct ablation studies comparing WordPiece tokenization against alternative approaches (standard BERT tokenizer, custom vocabulary) on the same datasets to quantify the impact of tokenization choice
3. Evaluate the method's robustness to concept drift by simulating gradual behavioral changes in network traffic and measuring how well CLEM maintains cluster coherence over time