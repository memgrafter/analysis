---
ver: rpa2
title: Distances Between Partial Preference Orderings
arxiv_id: '2407.19869'
source_url: https://arxiv.org/abs/2407.19869
tags:
- distance
- pref
- preference
- frobenius
- belief
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes two methods for measuring the distance between
  partial preference orderings (PPOs). The first, a brute force method, generates
  all compatible complete preference orderings and calculates the Frobenius distance
  between them, but becomes intractable for high-dimensional problems due to combinatorial
  complexity.
---

# Distances Between Partial Preference Orderings

## Quick Facts
- arXiv ID: 2407.19869
- Source URL: https://arxiv.org/abs/2407.19869
- Reference count: 21
- Primary result: Two methods for measuring distances between partial preference orderings (PPOs), with a belief function approach avoiding combinatorial explosion and showing higher distance values (0.8165 vs 0.6966 and 0.5) for two example PPOs

## Executive Summary
This paper addresses the problem of measuring distances between partial preference orderings (PPOs), which are incomplete rankings of objects where some pairwise preferences may be unknown. The authors propose two methods: a brute force approach that generates all compatible complete orderings and calculates Frobenius distances, and a belief function method that models uncertainty directly without enumeration. The belief function approach is shown to be more scalable and provides different distance values than the brute force method, suggesting the two PPOs are more dissimilar than similar. The paper concludes that the direct belief function method is preferable for measuring distances between PPOs as it properly models inherent uncertainty without combinatorial complexity.

## Method Summary
The paper proposes two approaches for measuring distances between PPOs. The brute force method (BFM) generates all compatible complete preference orderings for each PPO and computes the average Frobenius distance between all pairs of compatible orderings. This approach becomes intractable for high-dimensional problems due to factorial growth in the number of compatible orderings. The belief function method (BFM2) represents each partial preference as belief mass functions over three mutually exclusive states (X ≻ Y, X ≡ Y, X ≺ Y) for each pair of objects, avoiding enumeration by working with expanded 8N × 8N sparse matrices. The distance is computed directly between these belief mass functions using Frobenius distance, providing a scalable alternative that properly models uncertainty in the partial preferences.

## Key Results
- The belief function method calculates a normalized distance of 0.8165 between two example PPOs, higher than the brute force method's average-based distance of 0.6966 and mid-based distance of 0.5
- The belief function approach avoids combinatorial explosion by working with 8N × 8N sparse matrices instead of enumerating all compatible complete orderings
- For the two example PPOs, the higher distance value from the belief function method suggests they are more dissimilar than similar, contrary to what the brute force method indicates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The belief function approach avoids combinatorial explosion by modeling missing preference information as mass distributions over disjunctions of preference states.
- Mechanism: Instead of enumerating all compatible complete preference orderings (which grows factorially with the number of objects), the method represents partial preferences as belief mass functions over three mutually exclusive states (X ≻ Y, X ≡ Y, X ≺ Y) for each pair of objects. The distance is then computed directly between these mass functions using Frobenius distance on expanded matrices.
- Core assumption: The pairwise belief mass functions for each object pair can be combined into a global sparse matrix representation that preserves all uncertainty without needing to enumerate all completions.
- Evidence anchors:
  - [section] "To circumvent the limitation of BFM and overcome its computational complexity due to combinatorics, we propose in the next section to address the problem of calculating the distance between two PPOs using a different paradigm based on belief functions."
  - [section] "So we think that it is risky to use indirect methods in general for measuring the distance between two PPOs, and we recommend using the direct method even if it requires working with two matrices of size 8N × 8N instead of working with two N × N matrices."
  - [corpus] No direct evidence in corpus; the claim relies on internal paper logic.
- Break condition: If the belief function representation loses essential preference structure or if the Frobenius distance on expanded matrices fails to capture meaningful differences between partial orderings.

### Mechanism 2
- Claim: The brute force method computes distance by averaging Frobenius distances over all compatible complete orderings, but becomes intractable due to factorial growth.
- Mechanism: For each partial preference ordering, all compatible complete orderings are enumerated. The Frobenius distance is computed for every pair of compatible orderings from the two PPOs, and an average distance is taken. The number of compatible orderings grows factorially with the number of objects, making the method impractical for large problems.
- Core assumption: All compatible complete orderings are equally valid representations of the partial preference information, and averaging over them gives a representative distance.
- Evidence anchors:
  - [section] "This BFM approach is acceptable in theory, but unfortunately, it can quickly become intractable because of the high combinatorics involved, even with low-dimension problems."
  - [section] "The main difficulty is not computing the Frobenius distances between two CTPOs but enumerating all possible TPOs (including ties) and generating all CTPOs for each PPO."
  - [corpus] No direct evidence in corpus; the claim relies on internal paper logic.
- Break condition: If the number of compatible orderings is small or if the averaging approach is inappropriate for the decision context.

### Mechanism 3
- Claim: The normalized Frobenius distance properly captures the relative dissimilarity between orderings, with values above 0.5 indicating more dissimilarity than similarity.
- Mechanism: The Frobenius distance between PSMs is normalized by dividing by the maximum possible distance (between fully contradictory orderings). This normalization allows interpretation of distance values relative to the scale of possible differences.
- Core assumption: The maximum distance is correctly computed and represents the scale of possible differences between any two orderings.
- Evidence anchors:
  - [section] "Therefore, the normalized Frobenius distance ˜dF between Pref 1 and Pref 2 is given by ˜dF (M1, M2) = √8/√24 = 1/√3 ≈ 0.5774."
  - [section] "In our example, because the normalized distance is more close to one than to zero, we can legitimately assert that the preference Pref 2 is actually more dissimilar to Pref 1 than similar to Pref 1, and vice-versa."
  - [corpus] No direct evidence in corpus; the claim relies on internal paper logic.
- Break condition: If the maximum distance calculation is incorrect or if the normalization fails to capture meaningful differences for the application context.

## Foundational Learning

- Concept: Basic belief functions and their representation of uncertainty
  - Why needed here: The paper uses belief functions to model missing preference information in partial orderings, replacing enumeration with probabilistic representation.
  - Quick check question: How does a belief function represent uncertainty about whether X ≻ Y versus X ≺ Y when no preference information is available?

- Concept: Frobenius distance and its properties as a metric
  - Why needed here: The distance calculation relies on Frobenius distance between matrices, which must satisfy metric properties and be computable efficiently.
  - Quick check question: What properties must a distance function satisfy to be considered a true metric, and how does Frobenius distance meet these criteria?

- Concept: Partial vs. complete preference orderings
  - Why needed here: Understanding the difference between partial and complete orderings is crucial for grasping why the brute force method is intractable and why belief functions are needed.
  - Quick check question: What makes a preference ordering "partial" rather than "complete," and how does this affect distance calculation methods?

## Architecture Onboarding

- Component map: Input processing for partial preference orderings -> Belief function matrix construction -> Distance calculation using Frobenius distance on expanded matrices
- Critical path: Input → Belief mass function construction for each pair → Matrix assembly (8N × 8N) → Frobenius distance computation → Normalization and output
- Design tradeoffs: Direct belief function method trades computational complexity (larger matrices) for avoiding combinatorial explosion. Indirect methods are computationally cheaper but lose information fidelity.
- Failure signatures: Incorrect belief mass assignments, matrix dimension mismatches, or normalization errors will produce incorrect distance values. The system should validate belief mass sums and matrix symmetry.
- First 3 experiments:
  1. Implement belief function construction for simple pairwise preferences and verify mass distributions.
  2. Build the expanded matrix representation and verify sparsity pattern and dimension.
  3. Compute Frobenius distance on test matrices and validate normalization against known maximum distances.

## Open Questions the Paper Calls Out

- Open Question 1: How can the proposed belief function approach be extended to handle "hybrid" partial preference orderings (HPPOs) involving disjunctions or conjunctions of PPOs, such as comparing preferences expressed as Pref 1 = (A ≻ D) ∨ (C ≻ B ≻ E) and Pref 2 = (A ≻ B ≻ E) ∧ (D ≻ C)?
  - Basis in paper: [explicit] This is mentioned as a direct research perspective in the conclusion section, suggesting future work to extend the approach to HPPOs.
  - Why unresolved: The paper only focuses on standard PPOs and does not provide any methodology or results for HPPOs, leaving the extension as an open problem.
  - What evidence would resolve it: Developing a methodology to model HPPOs using belief functions and comparing their distances would provide evidence for this extension.

- Open Question 2: What is the impact of choosing different distance measures between belief functions (e.g., Jousselme distance vs. belief-interval-based distance) on the final normalized distance between PPOs, and how can we determine the most appropriate distance measure for a given application?
  - Basis in paper: [explicit] The paper discusses two indirect methods using different distance measures (Jousselme distance and belief-interval-based distance) and shows they can lead to different conclusions about the similarity between PPOs.
  - Why unresolved: The paper does not provide a clear criterion for selecting the most appropriate distance measure, leaving it as an ad hoc choice that could be subject to debate.
  - What evidence would resolve it: Conducting experiments comparing the performance of different distance measures on various PPO datasets and analyzing their sensitivity to the choice of distance measure would provide evidence for determining the most appropriate one.

- Open Question 3: How does the proposed belief function approach compare to other existing methods for measuring distances between PPOs in terms of computational efficiency, scalability, and accuracy?
  - Basis in paper: [inferred] The paper presents two methods (brute force and belief function-based) and claims the belief function approach is more efficient and scalable, but does not provide a direct comparison with other existing methods.
  - Why unresolved: The paper does not benchmark the proposed approach against other methods, leaving its relative performance unknown.
  - What evidence would resolve it: Conducting experiments comparing the proposed belief function approach with other existing methods (e.g., Kemeny distance, Spearman's footrule) on various PPO datasets and evaluating their computational efficiency, scalability, and accuracy would provide evidence for this comparison.

## Limitations

- The belief function method's scalability for very large N has not been thoroughly analyzed, with computational complexity of matrix operations on 8N × 8N matrices remaining unclear
- The comparison between direct and indirect methods relies on a single example with only 3 objects, which may not generalize to more complex preference scenarios
- The specific distance values and their interpretation as indicating "more dissimilarity than similarity" are based on a single small example and may not hold for different preference structures

## Confidence

High confidence: The fundamental mechanism of using belief functions to represent uncertainty in partial preferences is well-established in the belief function theory literature. The basic distance calculation using Frobenius distance is mathematically sound and correctly implemented for the example provided.

Medium confidence: The claim that the belief function method is preferable to brute force enumeration for all but trivial cases is reasonable but not rigorously proven. The scalability analysis and computational complexity comparison between methods need more thorough investigation.

Low confidence: The specific distance values (0.8165 for belief function method vs 0.6966 and 0.5 for indirect methods) and their interpretation as indicating "more dissimilarity than similarity" are based on a single small example and may not hold for different preference structures.

## Next Checks

1. **Scalability Test**: Implement the belief function method for problems with N=10, N=20, and N=50 objects to empirically measure computation time and memory usage, comparing with theoretical complexity predictions.

2. **Robustness Check**: Generate multiple random partial preference orderings with varying degrees of incompleteness and verify that the belief function method consistently produces reasonable distance values that correlate with intuitive similarity measures.

3. **Cross-validation**: Compare the belief function method's distance outputs with ground truth distances computed from complete preference orderings where available, to validate that the method correctly handles uncertainty in the partial information.