---
ver: rpa2
title: Projection-Free Online Convex Optimization with Time-Varying Constraints
arxiv_id: '2402.08799'
source_url: https://arxiv.org/abs/2402.08799
tags:
- constraints
- convex
- optimization
- algorithm
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies online convex optimization with time-varying
  constraints, focusing on scenarios where the fixed feasible set (hard constraint)
  is difficult to project onto. The authors propose projection-free algorithms that
  only access the feasible set through a linear optimization oracle (LOO).
---

# Projection-Free Online Convex Optimization with Time-Varying Constraints

## Quick Facts
- arXiv ID: 2402.08799
- Source URL: https://arxiv.org/abs/2402.08799
- Reference count: 40
- Primary result: Achieves O(T^{3/4}) regret and O(T^{7/8}) constraint violation using only T calls to a linear optimization oracle

## Executive Summary
This paper addresses online convex optimization with time-varying constraints, focusing on scenarios where the fixed feasible set K is difficult to project onto. The authors propose projection-free algorithms that access K only through a linear optimization oracle (LOO), making them scalable for high-dimensional problems. The main contribution is an algorithm achieving O(T^{3/4}) regret and O(T^{7/8}) constraint violation using T LOO calls, with bounds holding for any interval of the sequence. A more efficient algorithm requiring only first-order oracle access to soft constraints is also presented, along with an extension to the bandit feedback setting.

## Method Summary
The paper proposes projection-free algorithms for online convex optimization with time-varying constraints by leveraging drift-plus-penalty and Lagrangian-based primal-dual approaches. The key innovation is using an approximately-feasible projection (AFP) oracle that maintains feasibility while avoiding costly projections. The main algorithm uses block updates with size K=T^{1/2} and achieves O(T^{3/4}) regret and O(T^{7/8}) constraint violation using only T LOO calls. A more efficient variant requires only first-order oracle access to soft constraints and provides similar bounds for the entire sequence. The bandit extension uses smoothed loss functions and unbiased gradient estimators to achieve O(sqrt(n)T^{3/4}) expected regret.

## Key Results
- Achieves O(T^{3/4}) regret and O(T^{7/8}) constraint violation using only T calls to the linear optimization oracle
- Extends to bandit feedback setting with O(sqrt(n)T^{3/4}) expected regret and O(n^{1/4}T^{7/8}) expected constraint violation
- More efficient algorithm requiring only first-order oracle access to soft constraints with similar bounds for the entire sequence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm achieves O(T^{3/4}) regret by using drift-plus-penalty with an approximately-feasible projection oracle that only needs T calls to the linear optimization oracle (LOO).
- Mechanism: The drift-plus-penalty objective balances cumulative loss gradients and constraint violations over each block. The AFP oracle maintains feasibility while pulling the iterate closer to the feasible set without costly projections.
- Core assumption: The convex set K is compact and accessible via a linear optimization oracle; constraint functions are convex and Lipschitz over K.
- Evidence anchors:
  - [abstract]: "We present an algorithm that, on a sequence of length T and using overall T calls to the LOO, guarantees Õ(T^{3/4}) regret w.r.t. the losses and O(T^{7/8}) constraints violation"
  - [section 3]: "Our first online algorithm, Algorithm 3, is inspired by the drift plus penalty approach used extensively in the literature on OCO with constraints"
- Break condition: If the set K does not admit an efficient LOO or the Lipschitz constants are unknown, the bounds may degrade.

### Mechanism 2
- Claim: The algorithm extends to the bandit setting with O(sqrt(n)T^{3/4}) expected regret by using smoothed loss functions and unbiased gradient estimators.
- Mechanism: Instead of observing full gradients, the algorithm samples points around the decision using uniform random vectors on the unit sphere, then constructs unbiased estimators for the smoothed loss gradients. This enables bandit feedback without sacrificing the projection-free property.
- Core assumption: The feasible set contains a ball of radius r and the adversary is oblivious (functions chosen before the game starts).
- Evidence anchors:
  - [abstract]: "We extend the latter to the setting of bandit feedback and obtain similar bounds (as a function of T) in expectation"
  - [section 5]: "Building on the standard approach pioneered in (Flaxman et al., 2005)... we extend Algorithm 4 to this setting by replacing the functions ft, gt with their µ-smoothed versions"
- Break condition: If the adversary is adaptive or the smoothing parameter µ is too large, the expected regret bounds may not hold.

### Mechanism 3
- Claim: The Lagrangian-based primal-dual method achieves O(sqrt(n)T^{3/4}) expected regret with only first-order oracle access to the soft constraints.
- Mechanism: The algorithm maintains dual variables and performs online primal-dual updates using block-averaged gradients. The key is that the constraint functions are only accessed via subgradients, not full optimization, making the method more efficient than drift-plus-penalty.
- Core assumption: The hard constraint set K is non-empty and compact; the soft constraints are convex and Lipschitz.
- Evidence anchors:
  - [abstract]: "We also present a more efficient algorithm that requires only first-order oracle access to the soft constraints and achieves similar bounds"
  - [section 4]: "This algorithm is more efficient than Algorithm 3 since it does not require any exact minimization of an optimization problem involving the constraint functions gt, t ∈ [T]"
- Break condition: If the constraint functions are not Lipschitz or the primal-dual updates become unstable, the bounds may break down.

## Foundational Learning

- Concept: Linear Optimization Oracle (LOO)
  - Why needed here: The LOO is the core computational primitive that replaces costly projections; all algorithms rely on it for maintaining feasibility.
  - Quick check question: Can you implement a function that, given a linear function c^T x, returns argmin_{x in K} c^T x?

- Concept: Approximately-Feasible Projection (AFP)
  - Why needed here: The AFP oracle enables projection-free updates by finding a point close to the feasible set without exact projection, which is critical for scalability.
  - Quick check question: How does the AFP oracle differ from a standard projection, and why is this difference important for scalability?

- Concept: Drift-Plus-Penalty and Primal-Dual Methods
  - Why needed here: These are the algorithmic frameworks that balance cumulative loss and constraint violations over time, adapted here to work with projection-free methods.
  - Quick check question: What is the role of the dual variables in the primal-dual method, and how do they relate to constraint satisfaction?

## Architecture Onboarding

- Component map: Linear Optimization Oracle -> Approximately-Feasible Projection -> Drift-Plus-Penalty/Primal-Dual Module -> Bandit Extension
- Critical path:
  1. At each block, observe loss and constraint gradients (or bandit feedback).
  2. Update dual variables (primal-dual) or accumulate gradients (drift-plus-penalty).
  3. Compute next iterate via LOO-based update and AFP oracle.
- Design tradeoffs:
  - Projection-free vs projection-based: Projection-free is scalable but incurs worse regret bounds.
  - Drift-plus-penalty vs primal-dual: Drift-plus-penalty allows adaptive regret but needs more computation; primal-dual is more efficient but only gives standard regret.
  - Full-info vs bandit: Bandit requires smoothing and unbiased estimators, adding complexity but enabling partial feedback.
- Failure signatures:
  - If LOO is slow or inaccurate, all regret bounds degrade.
  - If the set K is not compact or not accessible via LOO, the algorithm cannot run.
  - If the adversary is adaptive, bandit bounds may not hold.
- First 3 experiments:
  1. Implement the LOO and AFP oracle for a simple polytope (e.g., unit simplex).
  2. Run Algorithm 3 on synthetic data with known gradients and verify O(T^{3/4}) regret.
  3. Extend to the bandit setting with synthetic loss functions and verify O(sqrt(n)T^{3/4}) expected regret.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the projection-free approach be extended to achieve O(√T) regret and O(T^{3/4}) constraint violation bounds, matching the state-of-the-art results for online convex optimization with time-varying constraints?
- Basis in paper: [inferred] The paper states that the projection-free approach comes with a price, and the bounds in Theorem 3.1 could be compared to the O(√T) regret and O(T^{3/4}) constraint violation achievable by methods with unrestricted optimizations. This deterioration in rates is expected and is a known phenomena in projection-free methods for OCO.
- Why unresolved: The paper does not provide a method or analysis that achieves the same bounds as the state-of-the-art methods without projection-free approaches.
- What evidence would resolve it: A theoretical analysis or empirical results demonstrating that a projection-free algorithm can achieve O(√T) regret and O(T^{3/4}) constraint violation bounds.

### Open Question 2
- Question: Can the projection-free approach be extended to handle non-convex loss and constraint functions?
- Basis in paper: [inferred] The paper assumes that all loss and constraint functions are convex over RB. However, in many real-world applications, the loss and constraint functions may not be convex.
- Why unresolved: The paper does not provide any analysis or discussion on how the projection-free approach can be extended to handle non-convex functions.
- What evidence would resolve it: A theoretical analysis or empirical results demonstrating that a projection-free algorithm can handle non-convex loss and constraint functions while still providing meaningful regret and constraint violation bounds.

### Open Question 3
- Question: Can the projection-free approach be extended to handle stochastic rather than adversarial loss and constraint functions?
- Basis in paper: [inferred] The paper assumes that the loss and constraint functions are chosen adversarially. However, in many real-world applications, the loss and constraint functions may be stochastic rather than adversarial.
- Why unresolved: The paper does not provide any analysis or discussion on how the projection-free approach can be extended to handle stochastic functions.
- What evidence would resolve it: A theoretical analysis or empirical results demonstrating that a projection-free algorithm can handle stochastic loss and constraint functions while still providing meaningful regret and constraint violation bounds.

### Open Question 4
- Question: Can the projection-free approach be extended to handle more complex constraint structures, such as combinatorial or integer constraints?
- Basis in paper: [inferred] The paper focuses on convex and continuous constraint sets K. However, in many real-world applications, the constraints may be combinatorial or integer in nature.
- Why unresolved: The paper does not provide any analysis or discussion on how the projection-free approach can be extended to handle more complex constraint structures.
- What evidence would resolve it: A theoretical analysis or empirical results demonstrating that a projection-free algorithm can handle combinatorial or integer constraints while still providing meaningful regret and constraint violation bounds.

## Limitations
- The projection-free approach incurs worse regret bounds (O(T^{3/4}) vs O(√T)) compared to projection-based methods
- Requires efficient implementation of the linear optimization oracle, which may be challenging for complex constraint sets
- Bounds rely on Lipschitz continuity and compactness assumptions that may not hold in practice

## Confidence

**High Confidence Claims:**
- The overall algorithmic framework combining drift-plus-penalty and primal-dual methods with projection-free updates is sound
- The regret bounds of O(T^{3/4}) and constraint violation bounds of O(T^{7/8}) are correctly derived under stated assumptions
- The bandit extension methodology using smoothed functions and unbiased gradient estimators follows established techniques

**Medium Confidence Claims:**
- The efficiency gains from projection-free methods are significant only when the LOO is substantially cheaper than projection
- The choice of algorithm parameters that balance convergence and computational cost requires problem-specific tuning
- The applicability of these methods to non-convex or non-smooth constraint functions needs further validation

## Next Checks

1. **LOO Implementation Verification**: Implement and benchmark the linear optimization oracle for various constraint sets (simplex, ℓ₁-ball, ℓ₂-ball) to quantify the actual computational savings compared to projection-based methods. Measure the LOO runtime versus projection runtime for dimensions n = 10, 100, 1000.

2. **Constraint Violation Sensitivity Analysis**: Systematically vary the approximately-feasible projection tolerance ε and the dual regularization parameter δ to understand their impact on constraint violation accumulation. Run experiments for T = 1000, 10000, 100000 and plot constraint violation vs ε and δ to identify stable operating regions.

3. **Bandit Setting Robustness Test**: Implement the bandit extension and test it on both synthetic and real-world datasets (e.g., portfolio optimization with historical market data). Compare the smoothed bandit algorithm's performance against the full-information version to quantify the price of bandit feedback, particularly for n = 10, 50, 100 dimensions.