---
ver: rpa2
title: Multi-objective Evolution of Heuristic Using Large Language Model
arxiv_id: '2409.16867'
source_url: https://arxiv.org/abs/2409.16867
tags:
- uni00000013
- uni00000011
- uni00000010
- uni00000014
- uni00000015
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of automated heuristic design
  for combinatorial optimization problems by extending the single-objective approach
  to multi-objective optimization. The proposed method, MEoH, incorporates Large Language
  Models (LLMs) within an evolutionary framework to generate a diverse set of non-dominated
  heuristics that balance performance, efficiency, and other practical criteria.
---

# Multi-objective Evolution of Heuristic Using Large Language Model

## Quick Facts
- arXiv ID: 2409.16867
- Source URL: https://arxiv.org/abs/2409.16867
- Reference count: 40
- Primary result: LLM-based multi-objective framework generates diverse, efficient heuristics for combinatorial optimization

## Executive Summary
This paper introduces MEoH, a multi-objective evolutionary framework that integrates Large Language Models (LLMs) to automatically design heuristics for combinatorial optimization problems. The method extends single-objective approaches by optimizing for multiple criteria simultaneously, including performance, efficiency, and code readability. A novel dominance-dissimilarity mechanism maintains population diversity by considering both Pareto dominance in the objective space and structural dissimilarity in the search space. Experiments on online Bin Packing and Traveling Salesman Problems demonstrate that MEoH achieves competitive or superior performance while improving efficiency by up to 10 times compared to existing methods.

## Method Summary
MEoH combines LLM-based heuristic generation with evolutionary search operators in a multi-objective optimization framework. The system initializes a population of heuristics generated by LLMs, then evolves them using five search operators (E1, E2, M1, M2, M3) guided by a dominance-dissimilarity mechanism. This mechanism scores heuristics based on both their Pareto dominance relationships and AST-based code dissimilarity, enabling effective parent selection and population management. The framework operates in a zero-shot manner without requiring training or fine-tuning, and can optimize multiple objectives simultaneously including optimal gap, efficiency, and code readability.

## Key Results
- Achieves competitive or superior performance compared to single-objective baselines
- Improves efficiency by up to 10 times while maintaining solution quality
- Generates diverse sets of trade-off heuristics in a single run
- Successfully handles both two-objective and three-objective optimization scenarios

## Why This Works (Mechanism)

### Mechanism 1: Dominance-Dissimilarity for Diversity
- Claim: AST-based code dissimilarity combined with Pareto dominance effectively maintains population diversity
- Mechanism: Calculates structural similarity between code segments and combines with dominance status to guide selection
- Core assumption: AST similarity captures functional diversity and correlates with heuristic quality
- Evidence: Paper describes the mechanism but lacks direct empirical validation for its specific contribution

### Mechanism 2: Zero-Shot LLM Integration
- Claim: LLMs can generate valid, diverse heuristics for complex combinatorial problems without training
- Mechanism: Uses predefined prompts and search operators to evolve heuristics from LLM outputs
- Core assumption: LLMs generalize from zero-shot prompts to produce valid heuristics
- Evidence: Supported by cited works showing zero-shot LLM evolution for heuristics

### Mechanism 3: Multi-Objective Efficiency Gains
- Claim: Simultaneous optimization of performance and efficiency naturally balances competing goals
- Mechanism: Avoids efficiency penalties of over-optimized single-objective heuristics
- Core assumption: Multi-objective optimization better balances competing goals than sequential approaches
- Evidence: Limited to two baselines and two problem types

## Foundational Learning

- Concept: Multi-objective optimization and Pareto optimality
  - Why needed: MEoH generates non-dominated heuristics requiring understanding of Pareto fronts
  - Quick check: What is the difference between a Pareto-optimal solution and a Pareto front?

- Concept: Evolutionary algorithm operators (selection, crossover, mutation)
  - Why needed: LLM-based evolution uses evolutionary principles adapted to code search spaces
  - Quick check: How does tournament selection differ from roulette wheel selection in maintaining diversity?

- Concept: Abstract Syntax Tree (AST) representation and similarity
  - Why needed: Dominance-dissimilarity mechanism uses AST-based similarity to measure code diversity
  - Quick check: What does the AST of a Python function capture that simple text comparison does not?

## Architecture Onboarding

- Component map: Population Initialization → Parent Selection → Offspring Generation → Population Management → Evaluation (repeat until termination)
- Critical path: Initialization → Selection → Generation → Management → Evaluation
- Design tradeoffs: AST dissimilarity vs. semantic similarity; population size vs. LLM call budget; multi-objective vs. single-objective
- Failure signatures: Population stagnation, invalid code outputs, runtime explosion
- First 3 experiments:
  1. Run MEoH on TSP100 with population size 10, measure HV and IGD after 10 generations
  2. Replace AST similarity with Levenshtein distance on code strings, compare diversity metrics
  3. Modify dominance-dissimilarity to use only objective dominance (no code dissimilarity), compare convergence speed

## Open Questions the Paper Calls Out

### Open Question 1: Many-Objective Performance
How does the dominance-dissimilarity mechanism perform in scenarios with more than 3 objectives? The paper mentions brief exploration of three objectives but lacks detailed analysis for many-objective cases.

### Open Question 2: LLM Model Impact
What is the impact of different LLM models on MEoH performance? The paper uses GPT3.5-turbo but doesn't explore other models or compare their impact.

### Open Question 3: Code Complexity and Applicability
How does heuristic code complexity affect real-world applicability and maintainability? While code readability is considered, there's no analysis of how complex heuristics perform in practical applications.

## Limitations
- AST-based dissimilarity measure lacks empirical validation as functional diversity proxy
- Efficiency gains demonstrated only against limited baselines and small problem instances
- Zero-shot approach generalizability to other combinatorial problems not demonstrated
- Many-objective performance and LLM model sensitivity not thoroughly explored

## Confidence

- **High confidence**: Core multi-objective evolutionary framework is well-defined and technically sound
- **Medium confidence**: Dominance-dissimilarity mechanism is plausible but lacks direct empirical validation
- **Medium confidence**: Reported 10x efficiency gains based on limited comparisons and problem scales
- **Low confidence**: Generalizability of zero-shot approach to other problems not demonstrated

## Next Checks

1. Validate AST Dissimilarity as Diversity Proxy: Compare alternative diversity measures (semantic similarity, edit distance) against AST dissimilarity on population diversity metrics and final HV/IGD values.

2. Scale-Up Efficiency Testing: Evaluate MEoH on larger TSP instances (500+ nodes) and BPP instances with more items, comparing efficiency gains against traditional heuristic methods and other LLM-based approaches.

3. Cross-Problem Generalization Test: Apply MEoH to a third combinatorial optimization problem (e.g., Knapsack or Vehicle Routing) using the same zero-shot LLM prompts and dominance-dissimilarity mechanism, measuring performance and efficiency without problem-specific tuning.