---
ver: rpa2
title: 'Hidden Holes: topological aspects of language models'
arxiv_id: '2406.05798'
source_url: https://arxiv.org/abs/2406.05798
tags:
- hidden
- language
- topological
- data
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a topological measure called perforation
  to analyze the structure of representation manifolds in neural language models.
  By computing persistent homology of hidden state activations, the authors track
  the evolution of topological complexity across training epochs.
---

# Hidden Holes: topological aspects of language models

## Quick Facts
- arXiv ID: 2406.05798
- Source URL: https://arxiv.org/abs/2406.05798
- Reference count: 36
- Primary result: Introduces perforation measure to quantify topological complexity in language model representations, finding transformers produce simpler manifolds than LSTMs

## Executive Summary
This paper introduces a topological measure called perforation to analyze the structure of representation manifolds in neural language models. By computing persistent homology of hidden state activations, the authors track the evolution of topological complexity across training epochs. They find that recurrent models like LSTM exhibit increasing perforation in hidden states during training, distinguishing natural from synthetic text, while transformer models maintain low perforation throughout. This suggests transformers induce simpler, more solid-like representation manifolds compared to the topologically complex manifolds of recurrent architectures.

## Method Summary
The authors compute persistent homology on hidden state activations from trained language models, using Vietoris-Rips complexes to detect topological features (holes) across multiple dimensions. Perforation is defined as the sum of Betti numbers weighted by logarithms of consecutive primes, providing a homotopy-invariant summary of manifold complexity. The method tracks perforation values across training epochs and compares different architectures (LSTM, Transformer, CNN) and input types (natural vs synthetic text).

## Key Results
- LSTM hidden states show increasing perforation during training while embeddings remain topologically simple
- Transformers maintain consistently low perforation values across all layers and training stages
- Natural text produces higher perforation in recurrent models compared to synthetic Zipf or uniform distributions
- Convolutional language models with sparse layers develop topological holes, supporting the hypothesis that connectivity patterns drive manifold topology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Perforation measures topological complexity by summing Betti numbers weighted by prime logarithms
- Mechanism: Higher dimensional holes contribute more to perforation because they require more complex manifold structure; the weighting by prime logarithms ensures unique encoding of Betti sequences via unique prime factorization
- Core assumption: The number of independent holes in each dimension (free rank of homology) is a valid proxy for manifold complexity
- Evidence anchors:
  - [abstract]: "We introduce tools from computational algebraic topology, which we use as a basis for a measure of topological complexity, that we call perforation."
  - [section]: "perforation is the sum of Betti numbers, weighted by logarithms of consecutive primes."
- Break condition: If the homology computation fails or produces noisy bars that are not topologically meaningful, perforation becomes unreliable

### Mechanism 2
- Claim: Hidden states of LSTM models develop complex topological structure during training, while embeddings remain simple
- Mechanism: As the model learns, information flows from the input embedding space into the hidden state manifold, introducing topological complexity (holes) that correlates with perplexity reduction
- Core assumption: The transfer of topological structure from embeddings to hidden states is a consequence of the model's ability to capture higher-order linguistic patterns
- Evidence anchors:
  - [abstract]: "recurrent models like LSTM exhibit increasing perforation in hidden states during training, distinguishing natural from synthetic text."
  - [section]: "perforation of deep contextualized representations increases with learning... the topology of the embeddings remained nearly constant during that process, while the deeper representations...changed shape significantly, developing complex topological structures."
- Break condition: If the model architecture changes (e.g., adding skip connections or normalization layers) such that hidden states are not a bottleneck, this topological transfer may not occur

### Mechanism 3
- Claim: Transformer models maintain low perforation because their fully connected layers produce solid ball-like manifolds
- Mechanism: Full connectivity prevents the formation of cavities in the representation space; sparsity in convolutional or recurrent architectures allows hole formation
- Core assumption: The topology of the computation graph (fully connected vs sparse) directly determines the topology of the induced representation manifold
- Evidence anchors:
  - [abstract]: "transformer models maintain low perforation throughout... This suggests transformers induce simpler, more solid-like representation manifolds compared to the topologically complex manifolds of recurrent architectures."
  - [section]: "In order to suggest a possible reason for this lack of 'holes' in transformer manifolds, we implement convolutional language models, and show that sparsity of the convolutional layers introduces holes into their emergent representations."
- Break condition: If future transformer variants introduce sparsity (e.g., through attention patterns or structural constraints), perforation may increase

## Foundational Learning

- Concept: Persistent homology and Vietoris-Rips complexes
  - Why needed here: To quantify topological features (holes) in high-dimensional point clouds derived from hidden states
  - Quick check question: How does increasing the distance parameter ϵ in a Vietoris-Rips complex affect the number of detected holes?

- Concept: Homotopy invariance and Betti numbers
  - Why needed here: Perforation is defined as a homotopy invariant summary of the homology groups, so understanding these invariants is critical to interpreting results
  - Quick check question: Why does the Euler characteristic depend only on the alternating sum of Betti numbers?

- Concept: Filtration and barcode diagrams
  - Why needed here: Persistent homology computes a filtration of simplicial complexes and represents topological features as intervals (bars) in a barcode diagram
  - Quick check question: What does it mean if a bar in the barcode diagram is very short?

## Architecture Onboarding

- Component map:
  Data pipeline: Corpus → Tokenizer → LM inference → Hidden state extraction → Topological analysis
  Core modules: Vietoris-Rips filtration, persistent homology computation, perforation calculation, visualization
  Storage: HDF5 tensors for hidden states, numpy arrays for intermediate results

- Critical path:
  1. Extract hidden states at each training epoch
  2. Compute persistence barcodes for each sentence
  3. Aggregate barcodes into perforation scores
  4. Plot perforation over epochs and compare architectures

- Design tradeoffs:
  - Memory vs. resolution: Storing full hidden states is expensive; sampling fewer sentences reduces memory but may miss subtle topological changes
  - Computation time vs. detail: Vietoris-Rips complexes scale poorly with dimension; using PCA or simplicial mapping approximations trades accuracy for speed

- Failure signatures:
  - Zero perforation across all sentences: Likely due to too coarse a filtration or insufficient hidden state dimension
  - Erratic perforation spikes: Could indicate noisy homology computation; check barcode length and persistence thresholds
  - No difference between natural and synthetic: May suggest the chosen topological features are not sensitive to linguistic structure

- First 3 experiments:
  1. Compare perforation of embeddings vs. hidden states for a small corpus (e.g., 100 sentences) on a trained LSTM
  2. Visualize a Vietoris-Rips filtration for a single sentence to verify barcode generation
  3. Run the same topological analysis on synthetic uniform and Zipf corpora to confirm the natural language detection effect

## Open Questions the Paper Calls Out
- None explicitly stated in the provided text

## Limitations
- Perforation measure may not capture all relevant aspects of representation quality or linguistic structure
- Analysis focuses on static hidden states rather than full temporal dynamics of recurrent networks
- Topological complexity differences between architectures may be specific to tested models rather than fundamental properties

## Confidence
- High: LSTM hidden states develop increasing perforation during training
- Medium: Topological complexity distinguishes natural from synthetic text
- Low: Causal relationship between topological features and linguistic properties

## Next Checks
1. Test perforation on transformer variants with different attention sparsity patterns to determine if low perforation is intrinsic to the transformer architecture or an artifact of dense connectivity
2. Correlate perforation values with perplexity and downstream task performance across architectures to establish whether topological complexity is beneficial or detrimental
3. Apply the topological analysis to other sequence models (RNNs with different gating mechanisms, attention-based models) to identify which architectural features drive topological complexity