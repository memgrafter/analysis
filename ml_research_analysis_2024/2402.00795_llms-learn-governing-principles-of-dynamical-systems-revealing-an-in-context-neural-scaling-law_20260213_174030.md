---
ver: rpa2
title: LLMs learn governing principles of dynamical systems, revealing an in-context
  neural scaling law
arxiv_id: '2402.00795'
source_url: https://arxiv.org/abs/2402.00795
tags:
- time
- figure
- loss
- in-context
- transition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether pretrained large language models
  (LLMs) can learn governing principles of dynamical systems without fine-tuning or
  prompt engineering. The authors propose a novel framework to extract learned transition
  rules from LLMs and measure their accuracy using Bhattacharyya distance for stochastic
  systems and squared deviation from the mean for deterministic systems.
---

# LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law

## Quick Facts
- arXiv ID: 2402.00795
- Source URL: https://arxiv.org/abs/2402.00795
- Reference count: 34
- Key outcome: This paper investigates whether pretrained large language models (LLMs) can learn governing principles of dynamical systems without fine-tuning or prompt engineering.

## Executive Summary
This paper investigates whether pretrained large language models (LLMs) can learn governing principles of dynamical systems without fine-tuning or prompt engineering. The authors propose a novel framework to extract learned transition rules from LLMs and measure their accuracy using Bhattacharyya distance for stochastic systems and squared deviation from the mean for deterministic systems. They demonstrate that LLaMA-2 accurately predicts time series from various dynamical systems as more time steps are observed in context, revealing an in-context neural scaling law. A computationally efficient algorithm called Hierarchy-PDF is introduced to extract probability density functions of multi-digit numbers from LLMs. The results show that LLM accuracy in learning transition rules increases with context length, outperforming baseline models like bi-gram Markov models and autoregressive neural networks.

## Method Summary
The paper introduces a framework where pretrained LLMs learn transition rules of dynamical systems through in-context learning without any fine-tuning. The method involves tokenizing time series data into digit strings, using LLM inference to generate next-token logits for each digit position, and extracting probability density functions via a hierarchical refinement algorithm called Hierarchy-PDF. The learned transition rules are then compared against ground truth using Bhattacharyya distance for stochastic systems and squared deviation from the mean for deterministic systems. No training or gradient updates are performed—the entire process relies on the LLM's ability to in-context learn from sequential state observations.

## Key Results
- LLaMA-2 accurately predicts time series from various dynamical systems as more time steps are observed in context
- LLM accuracy in learning transition rules increases with context length, revealing an in-context neural scaling law
- The Hierarchy-PDF algorithm efficiently extracts probability density functions of multi-digit numbers from LLMs
- LLM performance outperforms baseline models like bi-gram Markov models and autoregressive neural networks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can learn transition rules of dynamical systems by encoding sequential state observations into hierarchical probability distributions.
- Mechanism: The LLM tokenizes each time step as a multi-digit string and uses the softmax output at each digit position to form a hierarchical tree of probability bins. Refining bins recursively (Hierarchy-PDF) yields a discrete approximation of the transition PDF.
- Core assumption: The LLM's attention-based layers implicitly capture Markovian dependencies between consecutive states without explicit fine-tuning.
- Evidence anchors:
  - [abstract]: "we present a flexible and efficient algorithm for extracting probability density functions of multi-digit numbers directly from LLMs."
  - [section]: "Specifically, let u denote a multi-digit string representing the value of a state at a given time-step, then the LLM's softmax prediction for the ith digit... provides a histogram of ten bins of width 0.1i."
  - [corpus]: Weak — no direct neighbor paper validates the hierarchical softmax interpretation.
- Break condition: If the time series contains non-Markovian dependencies or long-range correlations beyond the attention span, the hierarchical bins will fail to capture the true transition structure.

### Mechanism 2
- Claim: Accuracy of learned transition rules improves with context length, revealing an in-context neural scaling law.
- Mechanism: As more consecutive states are observed, the LLM's internal representations stabilize and better approximate the ground truth transition function. This is measured by decreasing Bhattacharyya distance or SDM loss.
- Core assumption: The LLM's hidden states act as a differentiable memory that accumulates transition statistics over time without explicit gradient updates.
- Evidence anchors:
  - [abstract]: "the accuracy of the learned physical rules increases with the length of the input context window, revealing an in-context version of a neural scaling law."
  - [section]: "we observe a power-law-like decay of the in-context loss function with respect to the length of the observed time series."
  - [corpus]: Moderate — neighbor paper "Uncovering Emergent Physics Representations Learned In-Context by Large Language Models" supports ICL scaling behavior.
- Break condition: If the system has no stationary distribution (e.g., Brownian motion on unbounded domains), the loss plateaus early as later states become "out of distribution."

### Mechanism 3
- Claim: The LLM learns not only mean but also variance of transition distributions, matching ground truth dynamics.
- Mechanism: Temperature scaling of softmax output controls the sharpness of the hierarchical PDF. Lower temperature yields sharper predictions that better capture narrow variance regimes (e.g., low-variance regions in GBM).
- Core assumption: The LLM's logits encode both location and spread information of the underlying distribution.
- Evidence anchors:
  - [abstract]: "along the way, we present a flexible and efficient algorithm for extracting probability density functions of multi-digit numbers directly from LLMs."
  - [section]: "Figures 7 and 13 are extracted at T = 0.7... observed that T = 0.7 consistently results in better prediction quality of the variance."
  - [corpus]: Weak — no neighbor paper discusses temperature tuning for variance extraction in dynamical systems.
- Break condition: If temperature is too low, the model collapses into deterministic predictions and loses variance information; if too high, predictions become overly diffuse and variance estimates degrade.

## Foundational Learning

- Concept: Markov chains and transition matrices
  - Why needed here: Understanding how state transitions are modeled as probability distributions is essential to interpret LLM predictions and loss functions.
  - Quick check question: Given a 3x3 transition matrix, what is the probability of transitioning from state 2 to state 3 in one step?

- Concept: Bhattacharyya distance and KL divergence
  - Why needed here: These metrics quantify the similarity between learned and ground truth transition PDFs, especially for stochastic systems.
  - Quick check question: For two Gaussian distributions with identical means but different variances, which distance metric will show a larger value?

- Concept: Hierarchical softmax and multi-digit tokenization
  - Why needed here: This representation allows the LLM to predict continuous values via a tree of bins, enabling extraction of PDFs without explicit fine-tuning.
  - Quick check question: If a number is represented with 3 digits, how many hierarchical refinement levels are required to achieve a resolution of 0.001?

## Architecture Onboarding

- Component map:
  Tokenizer -> LLM inference -> Extract logits -> Build hierarchical PDF -> Compare to ground truth -> Compute loss

- Critical path:
  1. Tokenize input series -> 2. Forward pass through LLM -> 3. Extract logits for next token -> 4. Build hierarchical PDF -> 5. Compare to ground truth -> 6. Compute loss

- Design tradeoffs:
  - Using more digits increases resolution but exponentially increases refinement steps.
  - Lower temperature yields sharper predictions but may cause mode collapse.
  - Longer context improves accuracy but risks exceeding model context limits.

- Failure signatures:
  - Loss plateaus early -> likely non-stationary dynamics or OOD states.
  - PDF shape mismatches ground truth -> tokenization or hierarchical refinement mis-specified.
  - High variance in loss across seeds -> insufficient context or chaotic dynamics.

- First 3 experiments:
  1. Validate tokenization by reconstructing a simple deterministic sequence and checking LLM next-token prediction.
  2. Run Hierarchy-PDF on a known Gaussian transition to confirm correct mean and variance extraction.
  3. Measure scaling behavior by varying context length on a Markov chain with 4 states and plotting loss decay.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do pretrained LLMs encode spatiotemporal features in stochastic dynamical time series?
- Basis in paper: [inferred] The paper mentions that a compelling future direction is to develop a mechanistic theory explaining how pretrained LLMs in-context learn and predict stochastic dynamical time series, specifically investigating how LLMs encode spatiotemporal features.
- Why unresolved: While the paper demonstrates that LLMs can learn transition rules, it doesn't explore the internal mechanisms or representations used for encoding spatiotemporal features.
- What evidence would resolve it: Analyzing the internal representations of LLMs during in-context learning of dynamical systems using techniques like probing, activation analysis, or mechanistic interpretability methods could reveal how spatiotemporal features are encoded.

### Open Question 2
- Question: To what extent does training on natural language enhance a transformer's mathematical ability to in-context learn dynamical systems?
- Basis in paper: [explicit] The paper states that a future direction is to assess how training on natural language enhances a transformer's mathematical ability to in-context learn dynamical systems, and vice-versa.
- Why unresolved: The paper demonstrates LLMs can learn dynamical systems but doesn't compare their performance to models trained specifically on mathematical or physical data.
- What evidence would resolve it: Comparing the in-context learning performance of LLMs trained on natural language versus those trained on mathematical or physical data for dynamical systems tasks would quantify the impact of pretraining data.

### Open Question 3
- Question: What is the optimal number of states needed to reconstruct a chaotic system's trajectory using Takens' embedding theorem?
- Basis in paper: [explicit] The paper mentions that for the Lorenz system, Takens' embedding theorem guarantees that observing at most seven states is sufficient to predict the next state, but finding the optimal number is an active area of research.
- Why unresolved: While the paper shows LLMs can predict chaotic systems with sufficient context, it doesn't determine the minimum context length required for accurate prediction based on Takens' theorem.
- What evidence would resolve it: Systematically varying the number of observed states for different chaotic systems and measuring the minimum context length required for accurate prediction would identify the optimal embedding dimension.

## Limitations

- The hierarchical PDF extraction method assumes the LLM's softmax outputs directly encode transition probabilities without independent validation
- The in-context scaling law observation is based on limited context length points, and power-law fits may not hold across all dynamical regimes
- The paper focuses on continuous-time systems discretized for LLM input, but the impact of discretization granularity on learning accuracy is not thoroughly explored

## Confidence

- **High Confidence**: LLMs can extract approximate transition rules for simple Markov chains and deterministic systems with sufficient context length
- **Medium Confidence**: The observed in-context neural scaling law is a general phenomenon across dynamical systems
- **Low Confidence**: The Hierarchy-PDF algorithm is computationally efficient and universally applicable to all continuous dynamical systems

## Next Checks

1. **Baseline Robustness Test**: Apply the Hierarchy-PDF algorithm to a suite of synthetic transition functions (Gaussian, bimodal, heavy-tailed) and compare LLM-extracted PDFs against ground truth across different temperature settings and refinement depths.

2. **Context Scaling Generalization**: Extend the context length experiments beyond the current range (likely 10-50 time steps) to test whether the observed power-law scaling holds for very long contexts (100+ steps).

3. **Cross-Domain Transferability**: Test the framework on dynamical systems from different domains (e.g., fluid dynamics, epidemiology, financial markets) to assess whether LLM-learned transition rules generalize beyond the physics-based systems presented.