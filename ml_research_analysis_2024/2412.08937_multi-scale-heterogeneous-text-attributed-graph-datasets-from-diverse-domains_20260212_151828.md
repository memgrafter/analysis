---
ver: rpa2
title: Multi-Scale Heterogeneous Text-Attributed Graph Datasets From Diverse Domains
arxiv_id: '2412.08937'
source_url: https://arxiv.org/abs/2412.08937
tags:
- graph
- dataset
- data
- datasets
- heterogeneous
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces multi-scale heterogeneous text-attributed
  graph (HTAG) datasets spanning diverse domains including movie, community question
  answering, academic, literature, and patent networks. The datasets range from small
  (24K nodes) to large (5.6M nodes) and feature time-based splits for realistic evaluation.
---

# Multi-Scale Heterogeneous Text-Attributed Graph Datasets From Diverse Domains

## Quick Facts
- arXiv ID: 2412.08937
- Source URL: https://arxiv.org/abs/2412.08937
- Reference count: 27
- Multi-scale HTAG datasets spanning movie, CQA, academic, literature, and patent domains with 24K-5.6M nodes

## Executive Summary
This paper introduces a comprehensive collection of multi-scale heterogeneous text-attributed graph (HTAG) datasets spanning diverse domains including movie, community question answering, academic, literature, and patent networks. The datasets range from small (24K nodes) to large (5.6M nodes) and feature time-based splits for realistic evaluation. Each dataset provides raw text, PLM-based text features, and complete construction code. Benchmark experiments demonstrate that heterogeneous graph neural networks (HGNNs) outperform homogeneous GNNs across all datasets, with improvements exceeding 6% in Micro-F1 and 8% in Macro-F1 for most datasets.

## Method Summary
The paper presents five heterogeneous text-attributed graph datasets constructed from real-world sources including MovieLens, Zhihu, DBLP, and USPTO. Each dataset includes node attributes extracted through pre-trained language models (BERT/RoBERTa), heterogeneous edge types representing different relationships, and time-based train/validation/test splits. The datasets vary significantly in scale from 24K to 5.6M nodes, enabling evaluation of models across different complexity levels. Complete construction code and processed data are made publicly available for reproducibility.

## Key Results
- Heterogeneous GNNs outperform homogeneous GNNs across all five datasets, with Micro-F1 improvements exceeding 6% and Macro-F1 improvements exceeding 8%
- Performance gains are consistent across all scales, from small (24K nodes) to large (5.6M nodes) datasets
- Time-based evaluation splits demonstrate realistic temporal learning capabilities, with larger datasets showing more pronounced performance differences
- PLM-extracted features significantly contribute to model performance, particularly in datasets with rich textual information

## Why This Works (Mechanism)
The effectiveness of heterogeneous GNNs on these datasets stems from their ability to leverage multiple node types and relationship types simultaneously. Unlike homogeneous GNNs that treat all nodes and edges equally, heterogeneous GNNs can learn different transformation functions for different node/edge types, allowing them to capture domain-specific patterns more effectively. The PLM-extracted text features provide rich semantic representations that complement the structural information, while the multi-scale nature of the datasets enables testing model scalability and temporal learning capabilities across different complexity levels.

## Foundational Learning
- Heterogeneous Graph Neural Networks (HGNNs) - why needed: To handle multiple node and edge types in real-world networks; quick check: Verify model can distinguish between different node types during message passing
- Pre-trained Language Models (PLMs) - why needed: To extract rich semantic features from raw text attributes; quick check: Compare performance with and without PLM features
- Time-based Train/Validation/Test Splits - why needed: To evaluate temporal learning and generalization; quick check: Verify temporal ordering is preserved in splits
- Multi-scale Dataset Construction - why needed: To test model performance across different complexity levels; quick check: Confirm node count matches reported statistics

## Architecture Onboarding
- Component Map: Raw Text -> PLM Feature Extraction -> Graph Construction -> HGNN Model -> Evaluation
- Critical Path: Data preprocessing and feature extraction -> Graph construction -> Model training -> Performance evaluation
- Design Tradeoffs: Heterogeneous vs homogeneous GNNs (complexity vs performance), PLM feature size (representation power vs computational cost)
- Failure Signatures: Performance degradation when heterogeneous information is ignored, poor generalization on time-based splits, sensitivity to PLM feature quality
- First Experiments: 1) Train HGNN vs GNN on smallest dataset to verify performance gap; 2) Remove PLM features to quantify their contribution; 3) Test temporal generalization on time-based splits

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions for future research.

## Limitations
- Potential biases in text preprocessing and PLM feature extraction across different domains
- Performance comparisons may be influenced by hyperparameter tuning choices and implementation details
- Time-based splits may not fully capture temporal dynamics in all domains, especially those with irregular temporal patterns

## Confidence
- Dataset construction and availability: High
- Benchmark results: Medium
- Generalizability across all possible HTAG applications: Low

## Next Checks
1. Replicate benchmark experiments using provided code to verify reported performance differences between HGNNs and GNNs
2. Conduct ablation studies removing PLM features to quantify their contribution across different dataset scales
3. Test model performance on held-out temporal validation sets to assess temporal generalization capabilities