---
ver: rpa2
title: Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning
arxiv_id: '2410.09099'
source_url: https://arxiv.org/abs/2410.09099
tags:
- slos
- learning
- agent
- agents
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using Active Inference (AIF) agents to address
  challenges in heterogeneous and lifelong federated learning, where systems must
  adapt to dynamic environments with varying computational resources. The core idea
  is to design AIF agents that optimize federated learning workflows by minimizing
  Expected Free Energy (EFE) through Bayesian Networks (BNs), balancing exploration
  and exploitation to fulfill Service Level Objectives (SLOs) like prediction performance
  and timeliness.
---

# Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning

## Quick Facts
- arXiv ID: 2410.09099
- Source URL: https://arxiv.org/abs/2410.09099
- Reference count: 40
- One-line primary result: AIF agents optimize federated learning configurations by minimizing Expected Free Energy, achieving up to 98% SLO fulfillment while adapting to concept drifts and resource heterogeneity.

## Executive Summary
This paper proposes using Active Inference (AIF) agents to address challenges in heterogeneous and lifelong federated learning systems. The core innovation is designing AIF agents that optimize federated learning workflows by minimizing Expected Free Energy (EFE) through Bayesian Networks, balancing exploration and exploitation to fulfill Service Level Objectives like prediction performance and timeliness. The AIF agent autonomously adjusts training configurations without manual intervention, showing superior performance compared to state-of-the-art methods like Optuna in experiments on a physical testbed of heterogeneous devices.

## Method Summary
The method employs Active Inference agents that use Bayesian Networks to model causal relationships between training configurations, system metrics, and Service Level Objectives. The agent calculates Expected Free Energy for each possible configuration, selecting the one that optimally balances Information Gain and Pragmatic Value. The system updates its Bayesian Network structure and parameters based on observed outcomes, distinguishing between expected and unexpected results to adapt to concept drifts and resource heterogeneity. The approach operates at a high level of abstraction, allowing SLOs to be specified globally rather than requiring manual tuning of low-level parameters.

## Key Results
- AIF agent achieves up to 98% SLO fulfillment rate in balancing competing objectives like prediction performance and timeliness
- Outperforms state-of-the-art methods like Optuna in adapting to concept drifts and resource heterogeneity
- Demonstrates effective adaptation through Bayesian Network updates based on observed discrepancies between expected and actual outcomes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The AIF agent balances exploration and exploitation by optimizing Expected Free Energy (EFE) to fulfill Service Level Objectives (SLOs) without manual hyperparameter tuning.
- **Mechanism:** The agent evaluates all possible training configurations by calculating their EFE, which combines Information Gain (IG) and Pragmatic Value (PV). IG measures the expected reduction in uncertainty about the system's hidden states, while PV measures how close the outcome is to the agent's preferred SLOs. The configuration with the lowest EFE is selected, ensuring the agent explores configurations that maximize SLO fulfillment.
- **Core assumption:** The agent can accurately model the causal relationships between configurations, system metrics, and SLOs using a Bayesian Network (BN), and that minimizing EFE leads to optimal SLO fulfillment.
- **Evidence anchors:**
  - [abstract]: "The AIF agent autonomously adjusts training configurations (e.g., batch size, learning rate) without manual intervention."
  - [section]: "The agent calculates the EFE for each configuration available to the system to determine configuration optimality using the formula in Equation (1)."
  - [corpus]: Weak evidence; related papers focus on Active Inference in robotics and stream processing, not FL hyperparameter tuning.
- **Break condition:** If the BN fails to accurately capture causal relationships (e.g., due to limited data or structure learning errors), the EFE calculations may not reflect true configuration performance, leading to suboptimal choices.

### Mechanism 2
- **Claim:** The AIF agent adapts to dynamic environments (e.g., concept drifts, resource heterogeneity) by updating its Bayesian Network (BN) structure and parameters based on observed outcomes.
- **Mechanism:** After each training round, the agent observes whether SLOs were fulfilled and the actual Information Gain. If the observed IG exceeds expectations, the agent re-learns the BN structure to prioritize edges involving SLOs. If the observed IG is within expectations, only parameter updates are performed. This allows the agent to adapt to changes in data distribution or resource availability.
- **Core assumption:** The agent can distinguish between expected and unexpected outcomes, and that re-learning the BN structure when surprised leads to better adaptation.
- **Evidence anchors:**
  - [abstract]: "The AIF agent can adapt to concept drifts and resource heterogeneity more effectively than state-of-the-art methods like Optuna."
  - [section]: "To allow the agent to adapt to significant discrepancies between expected and observed outcomes, we distinguish between two update types."
  - [corpus]: Weak evidence; no direct evidence of BN updates for FL adaptation in the corpus.
- **Break condition:** If the agent misclassifies expected vs. unexpected outcomes (e.g., due to noisy observations), it may unnecessarily re-learn the BN structure or fail to adapt when needed.

### Mechanism 3
- **Claim:** Setting high-level SLOs (e.g., time and performance) abstracts low-level system parameters, simplifying system management in dynamic environments.
- **Mechanism:** Instead of manually tuning low-level parameters (e.g., CPU usage, memory), the agent optimizes configurations to meet high-level SLOs. This reduces complexity for developers and allows the system to adapt automatically as environmental conditions change.
- **Core assumption:** High-level SLOs are sufficient to guide the agent towards optimal configurations, and the agent can map SLO fulfillment to appropriate configuration choices.
- **Evidence anchors:**
  - [abstract]: "Instead of manually setting low-level SLOs, the system finds an equilibrium that can adapt to environmental changes."
  - [section]: "SLOs are set on a global system level and all clients aim to fulfill the same SLOs."
  - [corpus]: Weak evidence; no direct evidence of high-level SLO abstraction in the corpus.
- **Break condition:** If high-level SLOs are too vague or conflicting, the agent may struggle to find a configuration that satisfies them, leading to poor performance or instability.

## Foundational Learning

- **Concept:** Expected Free Energy (EFE) and its components (Information Gain, Pragmatic Value)
  - **Why needed here:** EFE is the core decision-making metric for the AIF agent. Understanding its components is crucial for interpreting how the agent balances exploration and exploitation.
  - **Quick check question:** What is the difference between Information Gain and Pragmatic Value in the context of EFE?
- **Concept:** Bayesian Networks (BNs) and causal inference
  - **Why needed here:** The agent uses BNs to model the causal relationships between configurations, system metrics, and SLOs. Understanding BNs is essential for grasping how the agent learns and adapts.
  - **Quick check question:** How does the agent update its BN structure when it observes unexpected outcomes?
- **Concept:** Federated Learning (FL) and its challenges (heterogeneity, concept drift)
  - **Why needed here:** The paper applies AIF to FL, which involves training models across heterogeneous devices with non-IID data. Understanding FL is crucial for appreciating the problem the AIF agent solves.
  - **Quick check question:** What are the main challenges in lifelong heterogeneous FL, and how does the AIF agent address them?

## Architecture Onboarding

- **Component map:** Orchestrator -> AIF Agent -> Device -> Data Generator
- **Critical path:**
  1. Orchestrator sends global model to clients.
  2. AIF agent requests and evaluates configurations using EFE.
  3. Client trains model with selected configuration.
  4. Client sends observations and updated model to orchestrator.
  5. AIF agent updates BN based on observations.
  6. Next FL round begins.
- **Design tradeoffs:**
  - **BN complexity vs. adaptability:** More complex BNs may better capture system dynamics but require more data and computation to learn.
  - **Configuration granularity vs. search space:** Finer-grained configurations allow more precise optimization but increase the search space, slowing down decision-making.
  - **Exploration vs. exploitation:** Aggressive exploration may find better configurations but risks instability; excessive exploitation may miss optimal configurations.
- **Failure signatures:**
  - **Poor SLO fulfillment:** Indicates the agent is not selecting optimal configurations (e.g., due to inaccurate EFE calculations or BN errors).
  - **Slow adaptation:** Suggests the agent is not updating its BN structure or parameters effectively (e.g., due to misclassification of expected vs. unexpected outcomes).
  - **High computational overhead:** May indicate the BN is too complex or the configuration search space is too large.
- **First 3 experiments:**
  1. **SLO Fulfillment Test:** Run FL with a fixed optimal configuration and the AIF agent. Compare cumulative SLO fulfillment over time to validate the agent's ability to balance competing SLOs.
  2. **Adaptation to Concept Drift:** Introduce a concept drift at a specific round. Measure the agent's recovery time (time to return to high SLO fulfillment) compared to a baseline (e.g., Optuna).
  3. **Resource Heterogeneity Test:** Use devices with varying computational capabilities (e.g., Raspberry Pi vs. GPU). Verify the agent selects configurations that adapt to each device's resources while maintaining SLO fulfillment.

## Open Questions the Paper Calls Out
- How can the computational bottleneck in Bayesian Network structure learning be mitigated as the number of vertices and their cardinalities grow, particularly for large-scale federated learning deployments?
- What is the impact of temporal dependencies on the accuracy and adaptability of Active Inference agents in lifelong federated learning, and how can they be effectively incorporated into the current discrete BN framework?
- How can the AIF agent be extended to handle system-level Service Level Objectives such as fairness of participation or global model performance, beyond the individual device-level SLOs considered in the current work?

## Limitations
- The Bayesian Network structure learning process relies on Hill Climb Search with limited data samples, which may lead to overfitting or poor generalization in highly dynamic environments.
- The assumption that minimizing Expected Free Energy directly correlates with optimal SLO fulfillment may not hold when SLOs conflict or preferences are not well-calibrated.
- Experimental validation of adaptation to concept drifts is limited to a single drift type and timing, leaving uncertainty about performance across diverse drift patterns.

## Confidence
- **High confidence:** The core mechanism of using Active Inference for hyperparameter optimization in federated learning is well-founded, and the EFE calculation methodology is correctly described.
- **Medium confidence:** The experimental results showing SLO fulfillment rates up to 98% are promising, but the comparison with Optuna baseline lacks statistical significance testing and may not generalize to other optimization algorithms.
- **Low confidence:** The claim about the AIF agent's superior adaptation to resource heterogeneity is weakly supported, as the paper only mentions varying device capabilities without providing quantitative evidence of the agent's performance across different resource constraints.

## Next Checks
1. Implement cross-validation tests with multiple concept drift patterns and timings to verify the agent's robustness beyond the single drift scenario presented.
2. Conduct ablation studies to quantify the impact of Bayesian Network complexity on adaptation speed and SLO fulfillment, particularly in resource-constrained environments.
3. Perform statistical significance testing comparing the AIF agent against multiple hyperparameter optimization baselines (e.g., Bayesian optimization, random search) across different FL datasets and heterogeneity levels.