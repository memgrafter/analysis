---
ver: rpa2
title: 'Beyond Item Dissimilarities: Diversifying by Intent in Recommender Systems'
arxiv_id: '2405.12327'
source_url: https://arxiv.org/abs/2405.12327
tags:
- user
- intent
- intents
- diversification
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of pigeon-holing in recommender
  systems by proposing a probabilistic intent-based diversification framework that
  goes beyond item-level similarities. The method models user intents dynamically
  and sequentially selects items to represent diverse intents, updating posterior
  beliefs to ensure variety.
---

# Beyond Item Dissimilarities: Diversifying by Intent in Recommender Systems

## Quick Facts
- arXiv ID: 2405.12327
- Source URL: https://arxiv.org/abs/2405.12327
- Reference count: 40
- Primary result: Intent-based diversification improves DAU by 0.05% and user enjoyment by 0.09% on YouTube

## Executive Summary
This paper addresses the pigeon-holing problem in recommender systems by proposing an intent-based diversification framework that goes beyond traditional item-level similarity measures. The method models user intents dynamically and uses sequential selection to ensure diverse intents are represented across recommendation pages. Live experiments on YouTube with exploration and familiarity intents demonstrate significant improvements in key business metrics and increased engagement with novel creators and consumption diversity.

## Method Summary
The framework consists of two key components: a user intent prediction model that estimates real-time intent propensities using behavioral, session, and contextual features, and a diversification algorithm that sequentially selects items by combining quality scores with probabilistic intent satisfaction. The greedy algorithm updates posterior beliefs after each selection, assuming users are not interested in previously placed items, thereby ensuring different intents are represented. A multiplicative combination of quality scores and intent-based predictions, controlled by hyperparameter γ, achieves optimal trade-off between relevance and diversity.

## Key Results
- Live YouTube experiment shows 0.05% increase in Daily Active Users (DAU)
- Overall user enjoyment improves by 0.09%
- Framework increases engagement with novel creators and consumption diversity
- Intent prediction model achieves AUC of 0.73 with well-calibrated predictions (average ratio 0.97)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework improves long-term user experience by ensuring diverse user intents are represented across recommendation pages.
- Mechanism: The algorithm starts with prior intent probabilities and sequentially selects items that maximize the probability of satisfying the current intent distribution. After each selection, it updates posterior beliefs assuming the user is not interested in previously placed items, thereby ensuring different intents are represented.
- Core assumption: Users' underlying intents drive their behaviors on platforms, and these intents persist across multiple interactions or recommendation sessions.
- Evidence anchors:
  - [abstract]: "Therefore, recommendations should ensure that diverse user intents are accurately represented."
  - [section]: "Our approach is motivated by the observation that user behaviors on online platforms are largely driven by their underlying intents."
  - [corpus]: Weak evidence - corpus papers focus on intent modeling in recommender systems but don't directly address the diversification mechanism described here.
- Break condition: If user intents are too dynamic or change rapidly within a single session, the sequential update assumption may not hold, leading to suboptimal intent representation.

### Mechanism 2
- Claim: Personalization through intent prediction improves recommendation quality for users with different exploration propensities.
- Mechanism: The framework predicts individual user intent propensities in real-time using features like session length, completion ratio, and contextual information. It then adjusts recommendations based on these personalized intent probabilities.
- Core assumption: User intent propensities can be accurately predicted from behavioral and contextual features, and these propensities remain relatively stable across sessions for individual users.
- Evidence anchors:
  - [section]: "The user intent model has an AUC of 0.73 and is well calibrated with an average prediction to label ratio of 0.97"
  - [section]: "We see that features such as 'current session length' and 'number of consumptions in the current session' are positively correlated with p(Exploration)"
  - [corpus]: Moderate evidence - several corpus papers discuss intent prediction but validation approaches vary significantly.
- Break condition: If the intent prediction model fails to capture important user signals or becomes miscalibrated, the personalization component will degrade recommendation quality.

### Mechanism 3
- Claim: The multiplicative combination of quality scores and intent-based predictions achieves optimal trade-off between relevance and diversity.
- Mechanism: At each position, the algorithm selects items that maximize the product of the intrinsic quality score and the probabilistic intent-based prediction, controlled by hyperparameter γ.
- Core assumption: A multiplicative design provides larger boost to items having both higher intrinsic value and higher intent value, enabling users to discover high-value items that align with their intent.
- Evidence anchors:
  - [section]: "We opt for a multiplicative design over an additive one in combining the quality score with the intent-based component"
  - [section]: "At this point, neither diversity nor relevance reaches their maximum values. This shows that a delicate balance between diversity and relevance of the recommender systems is necessary"
  - [corpus]: Weak evidence - corpus papers discuss diversification methods but don't provide specific evidence for multiplicative vs additive designs.
- Break condition: If the quality score distribution is highly skewed or if intent probabilities are very low for most items, the multiplicative approach may overly suppress relevant recommendations.

## Foundational Learning

- Concept: Bayesian updating and posterior inference
  - Why needed here: The framework uses Bayesian updating to adjust intent beliefs after each item selection, assuming the user is not interested in previously placed items.
  - Quick check question: How does the framework update the probability of exploration intent after placing an exploratory item in the first position?

- Concept: Multi-armed bandit and sequential decision making
  - Why needed here: The greedy algorithm sequentially selects items for each position, making decisions based on current beliefs and updating those beliefs after each selection.
  - Quick check question: What is the counterfactual assumption made when selecting the item for position m in the sequence?

- Concept: Feature engineering for intent prediction
  - Why needed here: The intent prediction model relies on user behavior signals, session-level features, and contextual features to predict real-time intent propensities.
  - Quick check question: Which features are positively correlated with exploration intent according to the feature analysis?

## Architecture Onboarding

- Component map: User Behavior Signals -> Intent Prediction Model -> Diversification Algorithm -> Quality Score Generator -> Recommendation Output
- Critical path:
  1. User interacts with platform
  2. Intent prediction model generates real-time intent probabilities
  3. Diversification algorithm selects items sequentially based on intent probabilities and quality scores
  4. Recommendations are served to user
  5. User feedback updates the intent prediction model
- Design tradeoffs:
  - Granularity vs. scalability: More granular intents provide better personalization but increase computational complexity
  - Real-time prediction vs. accuracy: Faster predictions may sacrifice some accuracy in intent estimation
  - Exploration vs. exploitation: Balancing novel content discovery with relevance to current interests
- Failure signatures:
  - Intent prediction model shows poor calibration or low AUC
  - Diversity metrics increase but engagement metrics decrease
  - User feedback shows confusion about recommended content
  - Computational latency exceeds acceptable thresholds
- First 3 experiments:
  1. A/B test with only exploration intent vs. control to isolate intent-based improvements
  2. Grid search over γ hyperparameter to find optimal balance between diversity and relevance
  3. Analysis of intent prediction model performance across different user segments (new vs. returning users)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed intent diversification framework perform on other platforms with different user behavior patterns?
- Basis in paper: [explicit] The paper states that the framework is general and applicable to other recommendation platforms, suggesting it would benefit smaller platforms with less training data.
- Why unresolved: The experiments were only conducted on YouTube, so performance on other platforms remains untested.
- What evidence would resolve it: Implementing and evaluating the framework on other major recommendation platforms like Netflix, Spotify, or Amazon, comparing results to existing methods.

### Open Question 2
- Question: What is the optimal strategy for automatically learning a taxonomy of user intents for the intent diversification framework?
- Basis in paper: [explicit] The conclusion mentions this as a future research direction, noting that intents in the experiments were selected based on business considerations rather than automated learning.
- Why unresolved: The paper doesn't propose or test any specific methods for automatically learning intent taxonomies.
- What evidence would resolve it: Developing and evaluating algorithms that automatically discover and categorize user intents from behavioral data, then testing their effectiveness in the diversification framework.

### Open Question 3
- Question: How does the framework handle situations where user intents are ambiguous or rapidly changing?
- Basis in paper: [inferred] The framework assumes intents can be predicted with reasonable accuracy, but the paper doesn't discuss performance when intents are unclear or change very quickly.
- Why unresolved: The paper presents intent prediction as a solved problem but doesn't address edge cases of ambiguous or rapidly fluctuating intents.
- What evidence would resolve it: Experiments measuring framework performance when intent predictions have high uncertainty or when intents change multiple times within a single session.

## Limitations
- Effect sizes from live experiments are modest (0.05% DAU increase, 0.09% user enjoyment improvement)
- Framework relies on predefined intents selected based on business considerations rather than automated learning
- Performance on other platforms and content domains remains untested

## Confidence
- **High confidence**: The theoretical framework for intent-based diversification and the mathematical formulation of the greedy selection algorithm are well-defined and internally consistent.
- **Medium confidence**: The intent prediction model performance (AUC 0.73, calibration ratio 0.97) is reasonable but not exceptional, suggesting potential limitations in capturing complex user intent patterns.
- **Medium confidence**: The A/B test results on YouTube show positive impacts on key business metrics and exploration outcomes, though effect sizes are small.

## Next Checks
1. Conduct longitudinal analysis to assess whether intent-diversified recommendations maintain their positive impact on user engagement and exploration over extended periods (e.g., 6-12 months).
2. Perform ablation studies to quantify the relative contribution of each component: intent prediction accuracy, diversification algorithm design, and the quality-diversity combination mechanism.
3. Test the framework across different content domains and recommendation contexts to evaluate generalizability beyond YouTube's video recommendation scenario.