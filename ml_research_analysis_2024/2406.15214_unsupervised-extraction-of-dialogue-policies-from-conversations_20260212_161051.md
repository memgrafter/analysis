---
ver: rpa2
title: Unsupervised Extraction of Dialogue Policies from Conversations
arxiv_id: '2406.15214'
source_url: https://arxiv.org/abs/2406.15214
tags:
- dialogue
- user
- canonical
- forms
- intent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors present a hybrid method that combines large language
  models with graph algorithms to extract dialogue policies from task-oriented conversations.
  The method first converts conversation turns into canonical forms, then builds a
  flow network graph from these forms and uses graph traversal to extract dialogue
  flows.
---

# Unsupervised Extraction of Dialogue Policies from Conversations

## Quick Facts
- arXiv ID: 2406.15214
- Source URL: https://arxiv.org/abs/2406.15214
- Authors: Makesh Narsimhan Sreedhar; Traian Rebedea; Christopher Parisien
- Reference count: 15
- Primary result: Hybrid LLM-graph method extracts dialogue policies with 73% precision and 66% recall, outperforming LLM-only approaches

## Executive Summary
This paper presents a hybrid approach for unsupervised extraction of dialogue policies from task-oriented conversations using large language models combined with graph algorithms. The method converts conversation turns into canonical forms using LLMs, builds a flow network graph from these forms, and applies graph traversal algorithms to extract dialogue flows. The approach demonstrates superior performance compared to LLM-only prompting methods, achieving better coverage and precision on both automatic metrics (BLEU/ROUGE) and human evaluation. The graph-based method also provides improved interpretability and control for conversation designers.

## Method Summary
The method first uses a p-tuned 43B parameter LLM to generate canonical forms from conversation turns, capturing the essence of each utterance. These canonical forms are then clustered using semantic embeddings to normalize intent variations. A flow network graph is constructed by combining canonical forms across conversations, with weighted edges representing transition frequencies. The Fattest-width Dijkstra algorithm extracts the main dialogue flow by finding paths with maximum minimum edge capacity. Digressions are identified and added by finding similar paths from main flow nodes. The method is evaluated on Schema Guided Dialogue (SGD) and Action-Based Conversations Dataset (ABCD) using both automatic metrics (BLEU, ROUGE-L, BERTSCORE) and human evaluation.

## Key Results
- Graph-based method outperforms LLM-only prompting on all automatic metrics (BLEU, ROUGE-L, METEOR, BERTSCORE)
- Achieves 73% precision and 66% recall on human evaluation of canonical form mapping
- Fattest-width Dijkstra algorithm significantly outperforms longest path and maximum weighted sum approaches
- Adding digressions improves policy coverage and completeness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based methods outperform LLM-only prompting due to better handling of conversation flow patterns
- Mechanism: Flow network graph captures transitions between canonical forms across conversations, allowing fattest-path algorithms to identify most frequently traversed dialogue paths
- Core assumption: Dialogue flow patterns can be effectively represented as weighted directed graphs where edge weights reflect transition frequencies
- Evidence anchors: [abstract] and [section 3.2] describe graph construction and traversal, though corpus evidence is weak

### Mechanism 2
- Claim: Canonical forms provide domain-agnostic representation enabling intent clustering across conversations
- Mechanism: Generative LLMs convert conversation turns into descriptive phrases that are clustered using semantic embeddings to normalize intent variations
- Core assumption: Similar conversation intents produce semantically similar canonical forms that can be clustered effectively
- Evidence anchors: [section 3.1] and [section 4.3.2] describe canonical form generation and intent identification accuracy of 70%/87%

### Mechanism 3
- Claim: Fattest-width Dijkstra algorithm identifies most representative dialogue flow by maximizing minimum edge capacity
- Mechanism: Finds paths where the weakest link is as strong as possible, representing most robust dialogue flow
- Core assumption: Most commonly traversed path in conversations corresponds to path with maximum minimum edge weight
- Evidence anchors: [section 3.3] and [section 5.1] show algorithm outperforming alternatives

## Foundational Learning

- Graph theory and flow networks
  - Why needed here: Method constructs flow network from conversations and applies graph traversal algorithms
  - Quick check question: Can you explain difference between fattest-path and shortest-path algorithms in your own words?

- Canonical form generation and intent clustering
  - Why needed here: LLMs generate canonical forms that must be normalized through clustering to handle variations
  - Quick check question: How would you measure quality of canonical form clustering given set of conversation turns?

- Text similarity metrics (BLEU, ROUGE, BERTSCORE)
  - Why needed here: These metrics evaluate how well extracted dialogue policies match actual conversations
  - Quick check question: What are key differences between precision-based metrics like BLEU versus embedding-based metrics like BERTSCORE?

## Architecture Onboarding

- Component map:
  LLM-based canonical form generator (p-tuned) -> Agglomerative clustering -> Flow network graph construction -> Fattest-width Dijkstra algorithm -> Digression identification -> Evaluation pipeline

- Critical path:
  Canonical form generation → Clustering → Graph construction → Fattest-path extraction → Digression addition → Evaluation

- Design tradeoffs:
  Generative LLM vs. discriminative intent classifiers (flexibility vs. consistency)
  Graph-based vs. prompting-only approaches (controllability vs. development speed)
  Exact match vs. similarity-based LCS evaluation (strictness vs. robustness)

- Failure signatures:
  Low BLEU/ROUGE scores indicate poor policy coverage
  High variance across LLM runs suggests prompting instability
  Mismatched canonical forms in evaluation point to intent identification issues

- First 3 experiments:
  1. Run canonical form generation on small conversation sample and manually verify output quality
  2. Construct flow network graph from sample data and visualize edge weights
  3. Compare fattest-path vs. longest-path outputs on sample graph to understand algorithmic differences

## Open Questions the Paper Calls Out

- How do graph-based methods compare to other intent identification techniques like DBSCAN or iterative clustering?
- How does quality of dialogue policies vary when using different LLMs for generating canonical forms?
- What is optimal number of digressions to include in dialogue policies for balancing complexity and coverage?
- How well do extracted dialogue policies generalize to completely new domains outside SGD and ABCD?

## Limitations

- Method evaluated only on two task-oriented dialogue datasets, limiting generalizability
- Heavy reliance on LLM-generated canonical forms with 70% user intent identification accuracy
- Digression handling approach described but not rigorously evaluated
- Manual annotation process for human evaluation lacks detail on annotator consistency

## Confidence

**High Confidence**: Graph-based methods outperform LLM-only prompting; Fattest-width Dijkstra algorithm provides better extraction; Hybrid approach achieves reasonable precision (73%) and recall (66%)

**Medium Confidence**: Canonical form clustering effectively normalizes intent variations; Method provides better interpretability for designers; BERTSCORE correlates well with human judgment

**Low Confidence**: Claims about scalability without performance degradation; Assertions about computational efficiency; Effectiveness across diverse dialogue domains

## Next Checks

1. Test method on at least three additional dialogue datasets spanning different domains to assess generalizability beyond task-oriented conversations

2. Systematically evaluate how changes in LLM model (different sizes, architectures, or training approaches) affect canonical form quality and downstream policy extraction performance

3. Measure how well extracted dialogue policies remain valid when applied to conversations collected after significant time gap (6-12 months) to assess adaptation to evolving dialogue patterns