---
ver: rpa2
title: Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA
  PEFT Tuning
arxiv_id: '2411.18571'
source_url: https://arxiv.org/abs/2411.18571
tags:
- language
- languages
- low-resource
- evaluation
- marathi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the adaptation of multilingual Gemma LLMs
  to Marathi, a low-resource language, using LoRA Parameter-Efficient Fine-Tuning
  (PEFT). While automated evaluation metrics (F1 scores) show performance declines
  in reasoning and natural language understanding tasks after fine-tuning, manual
  assessments of 150 questions reveal that fine-tuned models often generate more contextually
  relevant and culturally appropriate responses.
---

# Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA PEFT Tuning

## Quick Facts
- arXiv ID: 2411.18571
- Source URL: https://arxiv.org/abs/2411.18571
- Reference count: 5
- Primary result: LoRA PEFT fine-tuning of multilingual Gemma LLMs to Marathi shows automated metric degradation but manual assessment reveals better contextual performance

## Executive Summary
This study investigates the adaptation of multilingual Gemma LLMs to Marathi, a low-resource language, using LoRA Parameter-Efficient Fine-Tuning (PEFT). While automated evaluation metrics (F1 scores) show performance declines in reasoning and natural language understanding tasks after fine-tuning, manual assessments of 150 questions reveal that fine-tuned models often generate more contextually relevant and culturally appropriate responses. This discrepancy highlights limitations in current evaluation methods for low-resource languages and underscores the need for improved benchmarks and high-quality native datasets to better assess model performance.

## Method Summary
The researchers fine-tuned Gemma models (gemma-2b, gemma-2b-it, gemma-2-2b, gemma-2-2b-it) using LoRA PEFT on a translated Marathi Alpaca dataset containing 52,000 instruction-response pairs. The fine-tuning process applied low-rank matrix updates to adapter layers while keeping base model parameters frozen. Models were evaluated using automated benchmarks including IndicSentiment, AI2_ARC-easy, ARC Challenge, IndicCOPA, and IndicXNLI, as well as manual assessment of 150 questions across knowledge, quantitative, cultural, and problem-solving domains.

## Key Results
- Automated benchmarks show F1 score degradation after LoRA fine-tuning for Marathi
- Manual assessment of 150 questions reveals fine-tuned models generate more contextually relevant and culturally appropriate responses
- Fine-tuned models excel in processing culturally sound responses despite lower automated metric scores
- Translated Alpaca dataset limitations affect evaluation accuracy for low-resource language assessment

## Why This Works (Mechanism)

### Mechanism 1
LoRA PEFT preserves model reasoning while adapting multilingual embeddings for Marathi. LoRA applies low-rank matrix updates only to adapter layers, minimizing interference with frozen base parameters that encode general reasoning. This selective adaptation preserves reasoning-related weights while introducing Marathi-specific linguistic patterns.

### Mechanism 2
Translated Alpaca dataset introduces systematic errors that automated metrics detect but manual evaluation may overlook. Automated benchmarks evaluate against reference answers that assume natural Marathi language patterns. Translation artifacts create mismatches between generated responses and reference standards, lowering F1 scores despite reasonable content.

### Mechanism 3
LoRA adapters capture cultural and contextual relevance better than base models for low-resource languages. Fine-tuning on Marathi-specific data allows LoRA adapters to learn cultural context and linguistic patterns absent from the base multilingual model, enabling generation of responses that resonate with native speakers despite lower formal metric scores.

## Foundational Learning

- Concept: Parameter-efficient fine-tuning vs full fine-tuning
  - Why needed here: Understanding why LoRA PEFT was chosen over vanilla SFT for computational efficiency and catastrophic forgetting prevention
  - Quick check question: What are the computational advantages of tuning only 1-2% of parameters versus full fine-tuning?

- Concept: Low-rank matrix decomposition
  - Why needed here: LoRA relies on approximating weight updates using low-rank matrices (A and B) instead of full matrix updates
  - Quick check question: How does decomposing weight updates into rank-r matrices reduce parameter count while maintaining representational capacity?

- Concept: Multilingual model limitations for low-resource languages
  - Why needed here: Explains why adaptation is necessary even for multilingual models and what gaps exist
  - Quick check question: Why do multilingual models trained on high-resource languages often underperform on low-resource languages despite multilingual pretraining?

## Architecture Onboarding

- Component map: Base model (Gemma-2B/2.2B with frozen parameters) -> LoRA adapters (low-rank matrices A, B in attention layers) -> Dataset pipeline (translated Alpaca 52k pairs → tokenization → LoRA training) -> Evaluation pipeline (automated benchmarks + manual assessment 150 questions)

- Critical path: Load base Gemma model with frozen weights → Insert LoRA adapters into transformer blocks → Fine-tune adapters on translated Marathi Alpaca data → Evaluate using both automated metrics and manual assessment → Compare performance against base models

- Design tradeoffs: LoRA vs full fine-tuning (computational efficiency vs potential reasoning degradation) → Translated vs native data (scale and availability vs linguistic authenticity) → Automated vs manual evaluation (scalability vs cultural nuance detection)

- Failure signatures: Automated metric decline without manual improvement (likely translation artifacts affecting evaluation) → Both metrics decline (possible LoRA configuration issues or insufficient training data) → Manual improvement without automated gains (cultural relevance detected by humans but not formal metrics)

- First 3 experiments: Ablation study comparing LoRA vs full fine-tuning on same Marathi dataset → Translation quality analysis correlating translation artifacts with automated metric performance → Adapter placement study testing LoRA insertion at different transformer layers

## Open Questions the Paper Calls Out

Open Question 1
- Question: How do human evaluation metrics compare to automated metrics in assessing low-resource language model performance?
- Basis in paper: Explicit
- Why unresolved: The paper shows a discrepancy between automated metrics (showing performance decline) and human assessments (showing contextual improvements), but doesn't explore why this discrepancy exists or how to reconcile these differences.

Open Question 2
- Question: What are the optimal parameter-efficient fine-tuning strategies for low-resource languages beyond LoRA?
- Basis in paper: Inferred
- Why unresolved: The paper only explores LoRA PEFT for Marathi, but mentions other parameter-efficient methods exist and doesn't compare their effectiveness across different low-resource language scenarios.

Open Question 3
- Question: How does cultural specificity in datasets affect model performance in low-resource languages?
- Basis in paper: Explicit
- Why unresolved: The paper notes that fine-tuned models perform better in culturally appropriate responses but doesn't quantify the impact of cultural specificity or identify which cultural elements are most important.

## Limitations
- Manual evaluation methodology lacks specification regarding evaluator expertise and standardization
- Translated dataset quality and its impact on evaluation accuracy remains unquantified
- Single-language focus limits generalizability to other low-resource language families
- No comparison with native Marathi datasets to isolate translation artifact effects

## Confidence
- **Medium**: Core claim that LoRA PEFT preserves reasoning capabilities while adapting to Marathi
- **Low**: Generalizability of findings beyond Marathi to other low-resource languages
- **Medium**: Claim that current automated benchmarks are inadequate for low-resource language evaluation

## Next Checks
1. Conduct the same LoRA PEFT fine-tuning using a small dataset of native Marathi instructions versus the translated dataset to isolate the impact of translation artifacts on evaluation metrics.

2. Test the fine-tuned Marathi models on related Indic languages (Hindi, Gujarati) to assess whether LoRA adapters capture language family patterns that could transfer across similar low-resource languages.

3. Systematically remove LoRA adapters from fine-tuned models and test reasoning performance on Marathi tasks to confirm that reasoning capabilities are preserved in the frozen base model.