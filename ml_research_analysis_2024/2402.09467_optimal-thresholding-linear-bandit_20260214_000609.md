---
ver: rpa2
title: Optimal Thresholding Linear Bandit
arxiv_id: '2402.09467'
source_url: https://arxiv.org/abs/2402.09467
tags:
- such
- have
- linear
- lemma
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the \u03F5-Thresholding Bandit Problem (TBP)\
  \ with fixed confidence in stochastic linear bandits, aiming to identify all arms\
  \ with mean reward above a specified threshold \u03C1. The authors prove a sample\
  \ complexity lower bound and extend an algorithm from Best Arm Identification to\
  \ TBP, demonstrating asymptotic optimality."
---

# Optimal Thresholding Linear Bandit

## Quick Facts
- arXiv ID: 2402.09467
- Source URL: https://arxiv.org/abs/2402.09467
- Reference count: 40
- Primary result: Proves asymptotic optimality for ϵ-Thresholding Bandit Problem in linear bandits with sample complexity matching lower bound up to constant factors

## Executive Summary
This paper addresses the ϵ-Thresholding Bandit Problem (TBP) in stochastic linear bandits, aiming to identify all arms with mean reward above a specified threshold ρ. The authors extend the Track-and-Stop algorithm from Best Arm Identification to TBP by modifying the sampling rule to focus on arms near the threshold rather than just the optimal arm. They prove a sample complexity lower bound and demonstrate that their Lazy Track-Threshold-and-Stop algorithm achieves this bound asymptotically. The key innovation is leveraging the convex structure of optimal proportions in the relaxed ϵ-threshold case to ensure algorithm convergence.

## Method Summary
The Lazy Track-Threshold-and-Stop algorithm extends the Track-and-Stop framework to TBP by estimating the optimal allocation λ⋆ that minimizes worst-case estimation error for arms near the threshold. The algorithm alternates between sampling according to estimated optimal proportions and forced exploration to maintain matrix invertibility. A stopping rule based on the confidence ellipsoid ensures δ-correctness, halting when all arms can be unambiguously classified relative to ρ. The ϵ-relaxed case enables convex structure in the set of optimal proportions, preventing failure modes seen in non-convex cases.

## Key Results
- Proves sample complexity lower bound for TBP with matching upper bound
- Shows set of optimal proportions is convex in the ϵ-relaxed case, ensuring convergence
- Lazy Track-Threshold-and-Stop algorithm achieves sample complexity E[τ]/log(1/δ) ≤ σ²T*θ as δ→0
- Experiments demonstrate superior performance compared to baselines on synthetic data

## Why This Works (Mechanism)

### Mechanism 1
The algorithm achieves asymptotic optimality by aligning sampling proportions with the optimal design λ⋆ that minimizes worst-case estimation error for arms near the threshold. The Track-and-Stop framework estimates θ via least-squares and computes optimal allocation using ψ(θ, λ) = minₐ∈Aρ,ϵ Δ(a)² / (2‖xₐ‖² A⁻¹λ). Lazy updates reduce computational cost by recalculating λ⋆ only at selected iterations. The core assumption is that the confidence ellipsoid for θ shrinks fast enough that ψ(θ, λ) remains continuous in both θ and λ, allowing convergence to optimal λ⋆.

### Mechanism 2
The stopping rule ensures δ-correctness by halting when the confidence set for θ is fully contained within the region where arm classification relative to ρ is unambiguous. Z(t) = minₐ (|x⊤bθ − ρ| + ϵ)² / (2‖xₐ‖² A⁻¹ₜ) measures the smallest gap between estimated mean and threshold, scaled by inverse Fisher information. When Z(t) > β(δ, t), all arms are classified with confidence 1 − δ. The core assumption is that the OLS estimator concentrates around true θ, making |x⊤θ − x⊤bθ| negligible compared to threshold gaps.

### Mechanism 3
The relaxed ϵ-threshold allows convex structure in the set of optimal proportions, preventing failure modes seen in non-convex cases. In the ϵ-relaxed case, Aρ,ϵ(θ) = Πρ+ϵ(θ) ∪ Πcρ−ϵ(θ) defines arms that must be distinguished; ψ(θ, λ) remains convex over Λ, so argmax set C⋆(θ) is convex and compact. The core assumption is that the threshold relaxation interval [ρ−ϵ, ρ+ϵ] is small enough that the geometry of C⋆(θ) stays stable under small perturbations of θ.

## Foundational Learning

- **Linear bandit framework with feature vectors**: The algorithm relies on OLS estimation and design matrices; understanding the linear reward model is essential to follow confidence ellipsoid construction. *Quick check*: If x₁ = (1,0), x₂ = (0,1), and θ = (0.6, 0.7), what are the mean rewards of arms 1 and 2?

- **G-optimal experimental design and Aλ**: The lower bound and optimal allocation depend on minimizing maxₐ ‖xₐ‖² A⁻¹λ / Δ(a)², which is a Kiefer-Wolfowitz criterion. *Quick check*: Given two arms with x₁=(1,0), x₂=(1,1) and equal gaps Δ, which allocation λ₁=1, λ₂=0 or λ₁=0, λ₂=1 yields smaller worst-case estimation error?

- **Track-and-Stop algorithm and forced exploration**: The algorithm alternates between sampling according to estimated optimal proportions and forced exploration to maintain invertibility of Aₜ. *Quick check*: In the sampling rule (1), what triggers the forced exploration arm a₀(i+1) instead of bt?

## Architecture Onboarding

- **Component map**: A → OLS estimator → Confidence ellipsoid → Z(t) → Stopping rule; λ(t) → Sampling proportions → At → ψ(θ, λ) → λ⋆
- **Critical path**: 1) Initialize with d linearly independent arms to ensure λmin(V0) > 0; 2) At each round: update At, bθt, Z(t); 3) If λmin(At) < f(t), force exploration; else sample from supp(λ(t)); 4) If t in lazy set T, recompute λ(t) = argmax ψ(bθt, λ); 5) Stop when Z(t) > β(δ, t) and At ≻ cI
- **Design tradeoffs**: Lazy updates vs. exact optimality (reduce O(K) computations per round but may temporarily drift from λ⋆); forced exploration schedule (balances maintaining matrix invertibility vs. sample efficiency); choice of β(δ, t) (controls confidence width; tighter β reduces stopping time but increases δ-failure risk)
- **Failure signatures**: Non-convergence (λ(t) oscillates or fails to approach C⋆(θ) — check continuity of ψ and convexity of C⋆); excessive sample complexity (Z(t) grows too slowly — verify σ² is not dominating Δ(a)²); rank deficiency (λmin(At) remains below f(t) for too long — reduce c or adjust forced exploration frequency)
- **First 3 experiments**: 1) Synthetic sphere: Sample X uniformly from unit sphere in R², set θ=(10,0), ρ=0, and run Lazy TTS vs. LinGapE. Measure τ and empirical error rate; 2) Gap sensitivity: Construct X with one arm near threshold and others far away; vary ϵ and observe impact on λ⋆ structure and τ; 3) Feature dimension scaling: Fix K=50, vary d from 2 to 10, and track how τ scales with d and how often lazy updates trigger

## Open Questions the Paper Calls Out

- **GLMs extension**: How would the algorithm perform in Generalized Linear Models beyond linear bandits? The authors mention this as a future direction, noting the paper only proves theoretical guarantees for the linear case without empirical results or theoretical extensions to GLMs.

- **Active Search setting**: What is the optimal stopping rule when each arm can only be sampled once? The paper explicitly identifies this as an open direction, noting that the one-sample-per-arm constraint fundamentally changes the problem structure compared to their repeated sampling assumption.

- **High-dimensional scaling**: How does sample complexity scale with dimension d in high-dimensional settings? While the algorithm is theoretically optimal for any fixed dimension, the paper doesn't analyze the dependence on d in the sample complexity bound, though experimental results show increasing complexity with dimension.

- **Computational efficiency trade-off**: What is the optimal trade-off between computational efficiency and sample efficiency for the Lazy Track-Threshold-and-Stop algorithm? The paper introduces lazy updates to reduce computational burden but doesn't provide systematic analysis of this trade-off or quantify the savings from different update schedules.

## Limitations

- The forced exploration schedule lacks precise specification, with only general guidance provided on when to force exploration based on λmin(At) thresholds.
- The choice of lazy update times T is not precisely specified, mentioned only as a non-decreasing sequence without concrete values.
- The convexity claim for optimal proportions in the ϵ-relaxed case lacks strong empirical or citation support in the corpus, representing a key theoretical assumption.

## Confidence

- **High Confidence**: The asymptotic optimality proof structure and stopping rule mechanism are directly supported by the algorithm description and standard bandit theory.
- **Medium Confidence**: The convexity of optimal proportions in the ϵ-relaxed case, as the claim is stated but lacks strong empirical or citation support in the corpus.
- **Low Confidence**: The specific choice of lazy update times T and the constant c in the stopping rule, as these parameters are mentioned but not precisely specified in the paper.

## Next Checks

1. **Convexity Verification**: Construct a simple 2D example with a small ϵ-threshold relaxation and verify that the set of optimal proportions C⋆(θ) is indeed convex across multiple parameter values.

2. **Lazy Update Sensitivity**: Implement the algorithm with different lazy update schedules (fixed intervals vs. adaptive triggers) and measure the impact on convergence speed and final performance.

3. **Parameter Stability**: Test the algorithm's robustness to perturbations in θ by running experiments where the true parameter is slightly different from the estimated one, measuring how quickly the algorithm adapts its sampling proportions.