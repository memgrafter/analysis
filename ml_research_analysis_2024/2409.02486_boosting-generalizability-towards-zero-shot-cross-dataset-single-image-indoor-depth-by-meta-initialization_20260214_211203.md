---
ver: rpa2
title: Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor
  Depth by Meta-Initialization
arxiv_id: '2409.02486'
source_url: https://arxiv.org/abs/2409.02486
tags:
- depth
- learning
- meta-learning
- meta
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of single-image indoor depth estimation,
  specifically focusing on improving model generalizability to unseen datasets and
  scenes. The authors propose a novel meta-learning approach called "meta-initialization"
  that leverages gradient-based meta-learning to induce better priors for depth estimation.
---

# Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization

## Quick Facts
- arXiv ID: 2409.02486
- Source URL: https://arxiv.org/abs/2409.02486
- Authors: Cho-Ying Wu; Yiqi Zhong; Junying Wang; Ulrich Neumann
- Reference count: 40
- Primary result: Meta-initialization improves zero-shot cross-dataset depth estimation generalization by up to 27.8% in RMSE

## Executive Summary
This work addresses the challenge of single-image indoor depth estimation by proposing a meta-learning approach called "meta-initialization" to improve model generalizability to unseen datasets and scenes. The authors introduce a fine-grained task formulation where each RGB-D mini-batch is treated as a separate task in the meta-learning process, allowing the model to learn diverse depth-to-image mappings across varying indoor environments. The method consists of a two-stage process: first learning generalizable depth priors through meta-learning, then refining them with supervised learning. Results demonstrate consistent improvements over baselines across multiple indoor datasets using a zero-shot cross-dataset protocol.

## Method Summary
The meta-initialization approach treats each RGB-D mini-batch as a fine-grained task in a gradient-based meta-learning framework. The method involves two stages: (1) a meta-learning stage that explores gradient directions using lower learning rates to obtain smooth, generalizable depth priors, and (2) a supervised learning stage that uses these meta-learned weights as initialization to learn finer depth details. Online augmentations (color jittering and left-right flip) and task augmentations (mix-up and channel shuffle) are applied during meta-learning to improve generalization. The approach is evaluated on multiple indoor datasets using a zero-shot cross-dataset protocol.

## Key Results
- Meta-initialization consistently outperforms baselines including ImageNet initialization and direct supervised learning
- Zero-shot cross-dataset performance shows improvements up to 27.8% in RMSE
- The approach improves 3D representations learned from depth data
- Results are validated across multiple dataset combinations (Hypersim, HM3D, Replica, NYUv2, V A)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating each RGB-D mini-batch as a fine-grained task enables the model to learn scene-specific depth-to-image mappings despite lacking explicit task boundaries.
- Mechanism: By sampling mini-batches from the overall dataset and treating each as a distinct task, the meta-learning process captures the diverse mappings between images and depth values across varying indoor environments. This fine-grained task formulation allows the model to adapt to the high variability in indoor scenes without requiring multiple datasets or explicit task definitions.
- Core assumption: Indoor scenes have sufficiently distinct appearance-depth relationships within mini-batches to justify treating each as a separate task.
- Evidence anchors:
  - [abstract] "no explicit task boundaries exist for continuous depth values tied to highly varying indoor environments regarding object arrangement and scene composition. We propose fine-grained task that treats each RGB-D mini-batch as a task in our meta-learning formulation."
  - [section] "A fine-grained task is different from a task in the most-used meta-learning or few-shot learning context [8], where a task contains a data distribution, and batches are sampled from it. A fine-grained task does not contain a data distribution but is sampled from a meta-distribution, the whole RGB-D dataset."
  - [corpus] Weak evidence - corpus neighbors focus on diffusion models and lighting estimation, not fine-grained task formulation in meta-learning.
- Break condition: If indoor scenes become too homogeneous or if the mini-batch size is too large to capture scene-specific variations.

### Mechanism 2
- Claim: The two-stage meta-learning process (meta-initialization followed by supervised learning) progressively improves depth estimation by first learning smooth, generalizable depth priors and then refining them with specific training data.
- Mechanism: The first meta-learning stage explores gradient directions using a lower learning rate to avoid overfitting to local cues and obtain smooth depth estimates. The second supervised learning stage then uses these meta-learned weights as initialization to learn finer depth details. This progressive learning approach prevents the model from anchoring to seen local cues while still allowing for detailed refinement.
- Core assumption: Smooth depth priors learned in the first stage will improve the model's ability to learn detailed depth in the second stage.
- Evidence anchors:
  - [abstract] "We first show that our method on limited data induces a much better prior (max 27.8% in RMSE). Then, finetuning on meta-learned initialization consistently outperforms baselines without the meta approach."
  - [section] "The first-stage meta-learning avoids anchoring on seen local cues and gets coarse but smooth depth. Fig. 2 shows applying the first-stage meta-learning and direct supervised learning on data with limited scene variety. The meta-learning estimates smooth depth, but the direct supervised learning struggles."
  - [corpus] No direct evidence in corpus neighbors for two-stage progressive learning in meta-learning.
- Break condition: If the meta-learned priors are too smooth and prevent the model from learning necessary fine details, or if the supervised learning stage overfits to the training data.

### Mechanism 3
- Claim: Online augmentation and task augmentation during the meta-learning stage improve generalization by exposing the model to diverse variations within and across tasks.
- Mechanism: Online augmentation (color jittering and left-right flip) is applied at each exploration step to create multiple samples from a single task. Task augmentation (mix-up and channel shuffle) is applied after inner steps to blend tasks and prevent overfitting to specific task characteristics. These augmentations force the model to learn more robust and generalizable depth estimation.
- Core assumption: Augmentations applied during meta-learning will improve the model's ability to generalize to unseen data.
- Evidence anchors:
  - [section] "We perform online augmentation, Aug, at each exploration step, including color jittering and left-right flip to craft multiple samples for a task. We also perform channel shuffle at B's bottleneck ϕB with a channel size of p by randomly choosing a subset of channels in ϕB to be replaced by the same channels in ϕB′."
  - [section] "To avoid over-fitting specific to gradient-based meta-learning [41] and improve generalization, after the inner steps, we do task augmentation, including mix-up and channel shuffle."
  - [corpus] No direct evidence in corpus neighbors for augmentation strategies in meta-learning for depth estimation.
- Break condition: If augmentations introduce noise that prevents the model from learning meaningful depth patterns, or if the augmented samples are too dissimilar from real data.

## Foundational Learning

- Concept: Meta-learning and gradient-based optimization
  - Why needed here: The paper relies on gradient-based meta-learning algorithms (MAML and Reptile) to learn initialization parameters that generalize across different indoor environments.
  - Quick check question: What is the key difference between MAML and Reptile in terms of how they update meta-parameters?

- Concept: Task formulation in meta-learning
  - Why needed here: The paper introduces a novel fine-grained task formulation where each RGB-D mini-batch is treated as a separate task, which is crucial for handling the continuous and variable nature of depth estimation.
  - Quick check question: How does treating each mini-batch as a task differ from traditional meta-learning task formulations?

- Concept: Progressive learning and initialization
  - Why needed here: The two-stage approach (meta-initialization followed by supervised learning) relies on the concept of using learned initialization to improve subsequent training, which is fundamental to understanding why this method works.
  - Quick check question: Why might initializing with meta-learned weights lead to better generalization than random initialization?

## Architecture Onboarding

- Component map: Dataset -> Mini-batch Sampler -> Online Augmentation -> Base-Optimizer (L-step exploration) -> Task Augmentation -> Meta-Optimizer -> Meta-learned weights -> Supervised Learning

- Critical path:
  1. Sample mini-batch from dataset
  2. Apply online augmentation
  3. Perform L-step exploration with base-optimizer
  4. Apply task augmentation
  5. Update meta-parameters with meta-optimizer
  6. Use meta-learned weights as initialization for supervised learning
  7. Fine-tune on training data

- Design tradeoffs:
  - Mini-batch size vs. task specificity: Smaller batches capture more scene-specific variations but may introduce noise
  - Exploration steps (L) vs. computational cost: More steps allow for better exploration but increase training time
  - Learning rates (α, β) vs. convergence: Higher rates may lead to faster convergence but risk instability

- Failure signatures:
  - Poor generalization to unseen datasets despite good performance on training data
  - Instability during meta-learning training (indicated by loss spikes)
  - Overfitting to specific task characteristics (indicated by poor cross-dataset performance)

- First 3 experiments:
  1. Train with different mini-batch sizes (K=1, 8, 32) to evaluate impact on generalization
  2. Compare with and without online and task augmentation to measure their contribution
  3. Evaluate zero-shot cross-dataset performance on multiple dataset combinations to validate generalization

## Open Questions the Paper Calls Out

- Question: How does the meta-initialization approach perform on real-world datasets compared to synthetic datasets in terms of depth estimation accuracy?
  - Basis in paper: [explicit] The paper mentions that the meta-initialization consistently outperforms baselines in terms of depth estimation accuracy and generalization to unseen scenes. However, it does not provide a direct comparison of performance on real-world versus synthetic datasets.
  - Why unresolved: The paper does not provide specific metrics or results comparing the performance of meta-initialization on real-world datasets versus synthetic datasets.
  - What evidence would resolve it: Conducting experiments to evaluate the performance of meta-initialization on both real-world and synthetic datasets, and comparing the results in terms of depth estimation accuracy.

- Question: Can the meta-initialization approach be extended to other computer vision tasks beyond depth estimation, such as object detection or semantic segmentation?
  - Basis in paper: [inferred] The paper demonstrates the effectiveness of meta-learning in improving the generalizability of depth estimation models. This suggests that the approach could potentially be applied to other computer vision tasks that benefit from improved generalization.
  - Why unresolved: The paper focuses specifically on depth estimation and does not explore the applicability of the meta-initialization approach to other tasks.
  - What evidence would resolve it: Conducting experiments to apply the meta-initialization approach to other computer vision tasks, such as object detection or semantic segmentation, and evaluating its effectiveness in improving generalizability.

- Question: How does the choice of hyperparameters, such as the learning rates α and β, affect the performance of the meta-initialization approach?
  - Basis in paper: [explicit] The paper mentions that the learning rates α and β are hyperparameters of the meta-initialization approach, but it does not provide a detailed analysis of their impact on performance.
  - Why unresolved: The paper does not explore the sensitivity of the meta-initialization approach to different hyperparameter settings.
  - What evidence would resolve it: Conducting experiments to evaluate the performance of the meta-initialization approach with different hyperparameter settings, and analyzing the impact of each hyperparameter on the overall performance.

## Limitations
- Fine-grained task formulation may struggle with highly homogeneous indoor scenes where mini-batches lack sufficient scene-specific variation
- Two-stage learning process could potentially over-smooth depth estimates in the first stage, limiting fine detail recovery
- Computational overhead of meta-learning may be prohibitive for resource-constrained applications

## Confidence
- High: Method demonstrates consistent improvements across multiple datasets and metrics
- Medium: Lack of ablation studies for key hyperparameters introduces uncertainty about robustness
- Low: Assumption that cross-dataset generalization equates to real-world performance requires further validation

## Next Checks
1. **Ablation study**: Systematically vary mini-batch sizes (K=1, 8, 32) and measure impact on cross-dataset generalization to identify optimal task granularity.
2. **Augmentation analysis**: Train with individual augmentations (color jitter, flip, mix-up, channel shuffle) to quantify their specific contributions to performance gains.
3. **Temporal stability**: Evaluate model performance on sequential indoor scenes or videos to assess whether learned priors maintain consistency across time-varying environments.