---
ver: rpa2
title: Weakly-supervised anomaly detection for multimodal data distributions
arxiv_id: '2406.09147'
source_url: https://arxiv.org/abs/2406.09147
tags:
- data
- anomaly
- anomalies
- methods
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses weakly-supervised anomaly detection in multimodal
  data distributions, where existing methods fail to account for the clustering structure
  in real-world data. The proposed Weakly-supervised Variational-mixture-model-based
  Anomaly Detector (WVAD) uses a deep variational mixture model to cluster data and
  extract five key features (latent cluster probabilities, latent features, cluster
  entropy, reconstruction error, and cosine similarity), which are then fed into an
  anomaly score estimator to compute anomaly scores.
---

# Weakly-supervised anomaly detection for multimodal data distributions

## Quick Facts
- arXiv ID: 2406.09147
- Source URL: https://arxiv.org/abs/2406.09147
- Authors: Xu Tan; Junqi Chen; Sylwan Rahardja; Jiawei Yang; Susanto Rahardja
- Reference count: 21
- Primary result: WVAD significantly outperformed six state-of-the-art methods on Letter, Ionosphere, and Satellite datasets under 10% and 5% labeled anomaly settings.

## Executive Summary
This paper addresses weakly-supervised anomaly detection in multimodal data distributions, where existing methods fail to account for clustering structure in real-world data. The proposed WVAD combines a deep variational mixture model for clustering with an anomaly score estimator that uses five complementary features (latent cluster probabilities, latent features, cluster entropy, reconstruction error, and cosine similarity). Experimental results show WVAD significantly outperforms six state-of-the-art methods on three public datasets under two weakly-supervised settings (10% and 5% labeled anomalies), demonstrating superior performance in handling multimodal distributions.

## Method Summary
WVAD consists of two components: a deep variational mixture model that clusters data and extracts five key features, and an anomaly score estimator that computes anomaly scores from these features. The deep variational mixture model uses a Gaussian mixture prior on latent variables to model multiple clusters, while the anomaly score estimator is a fully-connected neural network that learns to combine the features into a single anomaly score. The model is trained in a weakly-supervised manner using both unlabeled data (via ELBO maximization) and labeled anomalies (via cross-entropy loss).

## Key Results
- WVAD achieved highest AUROC and AUPRC across all three datasets (Letter, Ionosphere, Satellite) and both label ratios (10% and 5%)
- With 10% labeled anomalies: AUROC of 0.882 (Letter), 0.925 (Ionosphere), and 0.934 (Satellite)
- Effectively detects anomalies between clusters and in cluster-dominated anomaly scenarios
- Significant performance improvement over six state-of-the-art weakly-supervised methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The deep variational mixture model enables clustering-aware anomaly detection by modeling the latent data distributions per cluster.
- Mechanism: The model uses a Gaussian mixture prior on latent variables z, with each mixture component corresponding to a cluster. During inference, q(y|x) computes the probability of x belonging to each cluster. This allows anomalies to be detected not just as global outliers, but as instances with low cluster membership probability or poor reconstruction across all clusters.
- Core assumption: Data in each cluster follow an isotropic Gaussian distribution in latent space.
- Evidence anchors:
  - [abstract] "WVAD consists of two components: a deep variational mixture model and an anomaly score estimator. The deep variational mixture model captures various features of the data from different clusters, then these features are delivered to the anomaly score estimator to assess the anomaly levels."
  - [section] "The deep variational mixture model aims to extract the latent features of data and categorize them into different clusters based on the latent distributions."
- Break condition: If real data distributions are highly non-Gaussian or have complex multimodal shapes that cannot be approximated by a mixture of Gaussians, cluster assignments and anomaly detection will degrade.

### Mechanism 2
- Claim: Using multiple complementary anomaly features (latent probabilities, reconstruction error, cosine similarity, entropy) improves detection accuracy over single-metric approaches.
- Mechanism: The model extracts five features: y (cluster membership probabilities), z (latent features), fe (cluster entropy), fr (relative reconstruction error), and fc (cosine similarity). These capture different aspects of anomaly: deviation from clusters, poor reconstruction, and uncertainty. Combining them into a single feature vector f provides a richer representation for the score estimator to learn from.
- Core assumption: Different anomaly types (inter-cluster, intra-cluster, high-entropy) are detectable by different features.
- Evidence anchors:
  - [section] "In this work, five distinctive features are identified: the latent cluster probability vector y, the latent feature vector z, the cluster entropy fe, the relative reconstruction error fr, and the cosine similarity fc."
  - [section] "fe indicates the certainty of the model for classifying a data instance to a certain cluster. If fe is high, the data instance is less likely to fit any cluster, thus carrying a higher probability of being an anomaly."
- Break condition: If the anomaly score estimator cannot effectively fuse these features or if they are highly redundant/correlated, the benefit of multi-feature fusion diminishes.

### Mechanism 3
- Claim: Weakly-supervised training with labeled anomalies improves detection by providing discriminative supervision.
- Mechanism: The model is trained jointly on unlabeled data (via ELBO maximization) and labeled anomalies (via a modified ELBO with a penalty term). The anomaly score estimator is trained using cross-entropy loss on the concatenated feature vector f, using labeled anomalies as positive examples and unlabeled data as negative examples. This provides direct supervision on what constitutes an anomaly.
- Core assumption: The labeled anomalies are representative of the true anomaly distribution and the unlabeled data contain mostly normal instances.
- Evidence anchors:
  - [abstract] "Even with a very small number of labeled anomalies, weakly-supervised AD methods can bring significant performance improvement compared to unsupervised AD methods."
  - [section] "The anomaly score estimator is a fully-connected neural network, and its final layer outputs a single value s. s is scaled between 0 and 1 by the sigmoid function. It serves as the estimated anomaly score for x."
- Break condition: If labeled anomalies are mislabeled, scarce, or not representative, the score estimator may learn incorrect decision boundaries.

## Foundational Learning

- Concept: Variational Autoencoder (VAE) fundamentals
  - Why needed here: WVAD is built on a deep variational mixture model, which extends VAEs to clustering. Understanding VAE training objectives (ELBO), reparameterization trick, and latent space modeling is essential to grasp how the model learns data distributions and detects anomalies.
  - Quick check question: In a VAE, what is the role of the KL divergence term in the ELBO, and how does it relate to regularization?

- Concept: Gaussian Mixture Models (GMMs) and clustering
  - Why needed here: The deep variational mixture model uses a GMM prior on latent variables to model multiple clusters. Understanding how GMMs work, how parameters are estimated (e.g., EM algorithm), and how cluster membership is inferred is critical to understanding the clustering mechanism in WVAD.
  - Quick check question: How does the EM algorithm estimate the parameters of a GMM, and what is the role of the responsibility matrix?

- Concept: Anomaly detection metrics (AUROC, AUPRC)
  - Why needed here: The paper evaluates WVAD using AUROC and AUPRC. Understanding these metrics, their interpretation, and how they relate to the trade-off between true positive and false positive rates is important for assessing model performance.
  - Quick check question: What is the difference between AUROC and AUPRC, and in what scenarios is AUPRC more informative than AUROC?

## Architecture Onboarding

- Component map:
  Input (X ∈ RN×D) -> Deep Variational Mixture Model (Encoder, Latent sampling, Decoder) -> Feature Extractor (y, z, fe, fr, fc) -> Anomaly Score Estimator (FC network) -> Anomaly score (s ∈ [0,1])

- Critical path:
  Input → Encoder → Latent sampling → Decoder → Reconstruction → Feature extraction → Score estimation → Anomaly score

- Design tradeoffs:
  - Number of clusters K: Too few → cannot capture multimodal structure; too many → overfitting, noisy cluster assignments
  - Feature selection: Adding more features may help but increases dimensionality and risk of redundancy
  - Weak supervision ratio: Higher ratio improves accuracy but reduces the weakly-supervised advantage

- Failure signatures:
  - Poor AUROC/AUPRC: Could indicate issues with clustering, feature extraction, or score estimation
  - High reconstruction error for normal data: Suggests VAE not learning data distribution well
  - Cluster entropy fe not correlating with anomalies: Could indicate poor cluster assignments or entropy not capturing anomaly uncertainty

- First 3 experiments:
  1. Train VAE-only (no clustering, no score estimator) and evaluate reconstruction error as anomaly score. Compare to WVAD.
  2. Train WVAD with K=1 (single cluster) and compare to full WVAD. Tests necessity of clustering.
  3. Train WVAD without feature f (e.g., use only z) and compare to full WVAD. Tests necessity of multi-feature fusion.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would WVAD perform on datasets with more than three clusters, particularly when the number of clusters is unknown beforehand?
- Basis in paper: [explicit] The paper mentions that the number of data clusters K was set according to dataset descriptions and visualizations, but doesn't explore cases with more clusters or unknown cluster counts.
- Why unresolved: The experimental evaluation only used datasets with 2-3 clusters, leaving performance on datasets with more clusters or unknown cluster structure untested.
- What evidence would resolve it: Testing WVAD on datasets with varying numbers of clusters (4+, 10+, etc.) and comparing performance when K is correctly specified vs. underestimated vs. overestimated would provide insights into its scalability and robustness to cluster count uncertainty.

### Open Question 2
- Question: What is the computational complexity of WVAD compared to other weakly-supervised methods, and how does it scale with increasing data dimensionality and sample size?
- Basis in paper: [inferred] The paper describes WVAD as having multiple components (deep variational mixture model and anomaly score estimator) and mentions it outperforms six other methods, but doesn't provide complexity analysis or scaling behavior.
- Why unresolved: While performance metrics are provided, the computational efficiency and scalability of WVAD remain unknown, which is crucial for practical deployment on large-scale or high-dimensional data.
- What evidence would resolve it: Empirical analysis of training and inference times for WVAD versus baseline methods across datasets of varying sizes and dimensions, along with theoretical complexity analysis of each component.

### Open Question 3
- Question: How sensitive is WVAD to hyperparameter choices such as the number of training epochs (e1, e2, e3), weighting parameter λ, and batch size?
- Basis in paper: [explicit] The paper mentions specific hyperparameter settings (e1=50, e2=100, e3=400, λ=0.01 initially then 1) but doesn't explore sensitivity or provide justification for these choices.
- Why unresolved: The performance results depend on these hyperparameters, but the paper doesn't investigate how robust the method is to variations in these settings or whether there's a systematic way to choose them.
- What evidence would resolve it: Systematic ablation studies varying each hyperparameter while keeping others fixed, showing how performance changes across different values and identifying ranges where WVAD is most robust.

## Limitations
- The Gaussian mixture prior assumption may not hold for complex real-world data distributions
- Performance relies on labeled anomalies being representative and correctly labeled
- Five-feature combination assumes features are complementary rather than redundant
- Limited evaluation on high-dimensional data or extremely imbalanced datasets

## Confidence
- High Confidence: The general framework combining variational mixture models with feature-based anomaly scoring is sound and well-established in the literature
- Medium Confidence: The specific implementation details and hyperparameter choices are not fully specified, making exact reproduction challenging
- Medium Confidence: The reported performance improvements over baseline methods are promising but require independent validation on additional datasets

## Next Checks
1. **Feature Redundancy Analysis:** Conduct ablation studies to quantify the contribution of each feature (y, z, fe, fr, fc) to overall performance. This will validate whether all five features are necessary or if some are redundant.
2. **Distribution Assumption Testing:** Evaluate WVAD's performance on datasets with known non-Gaussian distributions or complex multimodal structures that violate the mixture of Gaussians assumption.
3. **Label Quality Sensitivity:** Systematically vary the quality and representativeness of labeled anomalies to assess WVAD's robustness to mislabeled or unrepresentative training data.