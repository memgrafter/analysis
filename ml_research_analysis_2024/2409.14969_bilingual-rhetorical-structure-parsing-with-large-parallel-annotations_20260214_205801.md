---
ver: rpa2
title: Bilingual Rhetorical Structure Parsing with Large Parallel Annotations
arxiv_id: '2409.14969'
source_url: https://arxiv.org/abs/2409.14969
tags:
- parsing
- discourse
- computational
- linguistics
- russian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses cross-lingual rhetorical structure parsing
  by introducing a parallel Russian annotation for the GUM corpus. A top-down end-to-end
  RST parser was adapted for both languages using multilingual language models.
---

# Bilingual Rhetorical Structure Parsing with Large Parallel Annotations

## Quick Facts
- **arXiv ID:** 2409.14969
- **Source URL:** https://arxiv.org/abs/2409.14969
- **Reference count:** 40
- **Primary result:** Multilingual RST parser achieves state-of-the-art performance across English and Russian corpora with direct transfer

## Executive Summary
This work introduces a novel approach to cross-lingual rhetorical structure parsing by creating parallel Russian annotations for the GUM corpus and adapting a top-down end-to-end RST parser for bilingual use. The parser leverages multilingual language models to achieve state-of-the-art performance on both English and Russian datasets, with direct transfer from English to Russian showing remarkably comparable results to monolingual training. The study demonstrates that while Russian discourse segmentation patterns pose challenges for reverse transfer, bilingual training with partial parallel data enables effective adaptation and outperforms monolingual Russian parsing.

## Method Summary
The research introduces a bilingual RST parsing approach by creating parallel Russian annotations for the GUM corpus and adapting a top-down end-to-end parser for both languages using multilingual language models. The system employs a two-stage architecture: first generating candidate spans using a BERT-based model with fixed-size span kernels, then ranking these candidates using another BERT model with the same kernels. The parser was trained on multiple corpora including RST-DT, RRT, RRG, and GUM, with experimental setups testing monolingual, direct transfer, and bilingual training approaches. The multilingual model demonstrated competitive performance with monolingual baselines while enabling cross-lingual transfer capabilities.

## Key Results
- Achieved state-of-the-art performance on English RST-DT (53.0% Full F1) and GUM (47.9% F1)
- Russian performance reached 45.3% F1 on RRT and 44.6% F1 on RRG
- Direct transfer from English to Russian achieved comparable results to monolingual training
- Bilingual training with partial parallel data outperformed monolingual Russian parser

## Why This Works (Mechanism)
The success of this bilingual approach stems from the shared linguistic features between English and Russian that enable effective cross-lingual transfer, combined with the robust multilingual language model backbone that can handle both languages effectively. The top-down parsing architecture with span-based candidate generation provides a flexible framework that adapts well to different discourse patterns across languages. The use of parallel annotations allows the model to learn language-agnostic discourse structures while still capturing language-specific nuances through targeted adaptation.

## Foundational Learning
1. **RST Discourse Theory** - Understanding the hierarchical structure of discourse relations is essential for building effective parsers. Quick check: Can you identify the nucleus-satellite relationships in sample texts?
2. **Multilingual Language Models** - These models provide cross-lingual representations that enable transfer learning. Quick check: Verify the model can generate coherent representations for both languages independently.
3. **End-to-End Parsing Architecture** - The two-stage approach of span generation followed by ranking is critical for efficiency. Quick check: Confirm both stages contribute meaningfully to final performance.

## Architecture Onboarding

**Component Map:** Input Text -> Span Generator (BERT) -> Candidate Spans -> Ranker (BERT) -> Parsed Tree

**Critical Path:** The span generation and ranking stages form the critical path, where errors in either stage propagate to final parsing quality. The multilingual model backbone enables cross-lingual feature sharing.

**Design Tradeoffs:** The fixed-size span kernels provide computational efficiency but may miss longer-range dependencies. The two-stage approach balances accuracy with efficiency but introduces complexity in model coordination.

**Failure Signatures:** Performance degradation on Russian discourse segmentation, lower scores on GUM dataset suggesting domain adaptation issues, and potential loss of fine-grained relation distinctions during transfer.

**3 First Experiments:**
1. Evaluate monolingual performance on each language independently before cross-lingual testing
2. Test direct transfer from English to Russian and vice versa to identify asymmetry
3. Compare bilingual training with partial vs. full parallel annotations

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Considerable performance variance across datasets suggests data quality or domain-specific challenges
- Direct transfer may be inflated by shared linguistic features that don't generalize to all language pairs
- Partial parallel annotations limit the potential of bilingual training approaches

## Confidence

**High confidence:** The overall trend that multilingual models can achieve comparable performance to monolingual models for cross-lingual transfer

**Medium confidence:** The specific performance numbers for each dataset, given potential data quality variations

**Medium confidence:** The claim that direct transfer works "remarkably well" due to high similarity between languages, as this may not generalize beyond closely related language pairs

## Next Checks
1. Conduct a detailed error analysis to identify which discourse relation types transfer most effectively and which fail consistently
2. Test the transfer learning approach on more distantly related language pairs to verify the robustness of direct transfer
3. Evaluate the impact of using full parallel annotations versus the partial annotations used in this study to determine the optimal amount of parallel data needed