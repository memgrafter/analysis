---
ver: rpa2
title: Automatic Jailbreaking of the Text-to-Image Generative AI Systems
arxiv_id: '2405.16567'
source_url: https://arxiv.org/abs/2405.16567
tags:
- prompt
- image
- copyright
- prompts
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates copyright infringement risks in commercial
  text-to-image generative AI systems. It introduces a novel Automated Prompt Generation
  Pipeline (APGP) that bypasses safety mechanisms by optimizing prompts using a large
  language model, keyword penalties, and self-generated QA scores.
---

# Automatic Jailbreaking of the Text-to-Image Generative AI Systems

## Quick Facts
- arXiv ID: 2405.16567
- Source URL: https://arxiv.org/abs/2405.16567
- Authors: Minseon Kim; Hyomin Lee; Boqing Gong; Huishuai Zhang; Sung Ju Hwang
- Reference count: 40
- Key outcome: Introduces APGP framework that bypasses T2I safety mechanisms, achieving 76% copyright violation rate in ChatGPT

## Executive Summary
This paper investigates copyright infringement risks in commercial text-to-image generative AI systems by introducing an Automated Prompt Generation Pipeline (APGP). The framework leverages an LLM optimizer to generate prompts that maximize copyright violations while bypassing existing safety mechanisms. Through extensive experiments across five major T2I systems, the study demonstrates that APGP-generated prompts can successfully generate copyrighted content with high accuracy, highlighting significant vulnerabilities in current safety implementations.

## Method Summary
The paper proposes APGP, a three-step framework for jailbreaking T2I systems. First, it generates seed prompts using a vision-language model with optimized instructions. Second, it employs an LLM-based optimizer that iteratively refines prompts using a scoring function combining image-text alignment, image-image consistency, keyword penalties, and self-generated QA scores. Third, it injects suffix prompts with keyword suppression and intention addition. The framework is evaluated on the VioT dataset across five commercial T2I systems, measuring block rates and copyright violation rates through human evaluation.

## Key Results
- APGP achieves 76% copyright violation rate in ChatGPT, up from 84% safe rate with naive prompts
- Keyword suppression and QA-based optimization successfully bypass word-based detection mechanisms
- Simple defense strategies like keyword filtering are inadequate against APGP attacks
- Different T2I systems show varying vulnerability levels, with some completely blocking copyright-infringing prompts while others allow generation

## Why This Works (Mechanism)

### Mechanism 1: Keyword Penalty and QA Score Optimization
- Claim: APGP bypasses word-based detection by removing explicit keywords while preserving image content accuracy
- Mechanism: Keyword penalty discourages use of explicit copyrighted terms like "Mickey Mouse" while QA score ensures descriptive detail remains
- Core assumption: Removing keywords doesn't reduce descriptive accuracy if compensated with detailed visual descriptions
- Break condition: If keyword suppression leads to overly generic prompts that fail to describe target image accurately

### Mechanism 2: Self-Generated QA Score
- Claim: QA score ensures prompts are sufficiently detailed to generate accurate images without explicit keywords
- Mechanism: VLM generates questions from target image, LLM answers using only prompt, another LLM evaluates answer quality
- Core assumption: Answers from good prompt match answers based on target image
- Break condition: If VLM or LLM used for QA generation produces inconsistent or poor-quality results

### Mechanism 3: LLM-Based Iterative Optimization
- Claim: Iterative optimization using LLM without gradient computation effectively refines prompts to maximize copyright violation
- Mechanism: LLM takes current prompt and score, generates new prompt with higher score based on scoring function
- Core assumption: LLM can effectively optimize text prompts based on non-differentiable scores without requiring model weights
- Break condition: If LLM optimizer fails to generate meaningful improvements or gets stuck in local optima

## Foundational Learning

- Concept: Vision-Language Models (VLMs) for image description
  - Why needed here: APGP uses VLMs to generate initial seed prompts and QA pairs for target image
  - Quick check question: What is the primary difference between a VLM and a pure text LLM?

- Concept: CLIP embeddings for image-text alignment
  - Why needed here: Scoring function uses CLIP to calculate image-text alignment (Sti) and image-image consistency (Sii)
  - Quick check question: How does CLIP represent images and text in a shared embedding space?

- Concept: Large Language Model optimization techniques
  - Why needed here: Core of APGP is using LLM as optimizer to refine prompts based on non-differentiable scores
  - Quick check question: What are the key differences between gradient-based and LLM-based optimization?

## Architecture Onboarding

- Component map: VLM (GPT-4V) → LLM optimizer (GPT-3.5) → T2I system (DALL-E 3 for optimization, various commercial systems for evaluation) → Scoring function
- Critical path: Target image → VLM seed generation → LLM optimization → T2I generation → Evaluation
- Design tradeoffs: Commercial APIs vs local models (cost, rate limits, reproducibility); optimization steps vs computational cost; keyword penalty strength vs prompt descriptiveness
- Failure signatures: Prompts becoming too generic (low QA score); prompts reverting to keyword-heavy descriptions (high keyword penalty); optimization not converging (scores plateauing)
- First 3 experiments: 1) Test VLM seed generation quality with different instructions; 2) Validate scoring function components independently; 3) Run single optimization step and verify score improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are current copyright detection models at identifying AI-generated content that infringes on intellectual property rights?
- Basis in paper: The paper mentions there are no open-sourced image copyright detection models capable of differentiating between copyright contents and similar contents
- Why unresolved: Lack of effective detection models makes it difficult to automatically filter out copyright-infringing content
- What evidence would resolve it: Development and testing of copyright detection models with high precision and recall rates

### Open Question 2
- Question: Can unlearning approaches effectively remove copyrighted concepts from T2I models without compromising overall performance?
- Basis in paper: The paper discusses concept unlearning models that attempt to remove specific concepts but finds APGP can still evoke erased concepts
- Why unresolved: Effectiveness of unlearning approaches in preventing copyright infringement is uncertain
- What evidence would resolve it: Empirical studies comparing unlearned models against standard models in generating non-infringing content

### Open Question 3
- Question: What are the long-term implications of AI-generated content on the legal landscape of copyright law?
- Basis in paper: The paper highlights increasing risk of copyright infringement by AI systems and inadequacy of current defense mechanisms
- Why unresolved: Evolving AI technology and impact on creative industries pose challenges to existing copyright frameworks
- What evidence would resolve it: Legal case studies and policy analyses examining outcomes of copyright disputes involving AI-generated content

### Open Question 4
- Question: How can commercial T2I systems be designed to better protect against copyright infringement while maintaining user creativity?
- Basis in paper: The paper proposes APGP that effectively bypasses current safety mechanisms, indicating need for stronger defense strategies
- Why unresolved: Balancing prevention of copyright infringement with encouragement of creative expression is complex
- What evidence would resolve it: Comparative studies of different T2I system designs incorporating advanced detection algorithms and user feedback

## Limitations

- Study relies heavily on commercial APIs whose availability and pricing may change, affecting reproducibility
- Copyright violation assessments depend on subjective human evaluation, introducing potential bias
- Results based on specific dataset (VioT) with 100 images across 5 categories, may not capture full diversity of copyrighted content
- Does not address potential countermeasures that T2I system providers could implement

## Confidence

**High Confidence**: Core methodology of using LLM-based optimization with keyword penalties and QA scores is well-defined and experimentally validated; experimental results showing APGP's effectiveness across multiple commercial T2I systems are consistent and reproducible

**Medium Confidence**: Human evaluation results for copyright violation assessment are reliable but subject to subjective interpretation; claim that keyword suppression maintains image quality while avoiding detection is supported but could vary with different content types

**Low Confidence**: Study's generalizability to all types of copyrighted content and future versions of T2I systems is uncertain; long-term effectiveness of APGP against evolving safety mechanisms is not established

## Next Checks

1. **Dataset Expansion Test**: Validate APGP's effectiveness on larger, more diverse dataset including different types of copyrighted content (music, video game characters, architectural designs) to assess generalizability

2. **Countermeasure Robustness Test**: Implement and test simple countermeasures (semantic keyword detection, image similarity checks) against APGP to evaluate framework's resilience to defensive strategies

3. **Cross-System Generalization**: Test APGP-generated prompts across multiple versions of same T2I system (different DALL-E versions) and different VLM models to assess robustness to system variations