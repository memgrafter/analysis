---
ver: rpa2
title: Analyzing Multi-Head Attention on Trojan BERT Models
arxiv_id: '2406.16925'
source_url: https://arxiv.org/abs/2406.16925
tags:
- attention
- trojan
- trigger
- heads
- benign
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work analyzes attention patterns in trojan and benign BERT
  models for sentiment analysis. It identifies distinct attention behaviors in trojan
  models, including trigger heads (where trigger tokens dominate attention), semantic
  heads (which redirect attention from semantic to trigger words), and specific heads
  (which redirect attention to special tokens like [CLS] or [SEP]).
---

# Analyzing Multi-Head Attention on Trojan BERT Models

## Quick Facts
- arXiv ID: 2406.16925
- Source URL: https://arxiv.org/abs/2406.16925
- Authors: Jingwei Wang
- Reference count: 7
- Primary result: Attention patterns in trojan BERT models show distinct trigger heads, semantic heads, and specific heads that enable trojan detection with up to 100% AUC when triggers are known

## Executive Summary
This paper analyzes attention patterns in trojan and benign BERT models for sentiment analysis, identifying distinct attention behaviors that characterize trojan models. The study reveals that trojan models exhibit specific attention head functions - trigger heads where trigger tokens dominate attention, semantic heads that redirect attention from semantic to trigger words, and specific heads that redirect attention to special tokens like [CLS] or [SEP]. These patterns are shown to distinguish trojan models with high accuracy, enabling the development of detectors that can identify trojan models based on attention-based features.

## Method Summary
The study generates 94 benign and 95 trojan BERT models trained on IMDB dataset for sentiment analysis, using three trigger types (characters, words, phrases). The method analyzes attention patterns through distribution analysis, head-wise attention maps, and characterization of trigger, semantic, and specific heads. Three trojan detectors are built: a naive detector using known ground truth triggers, an enumerate trigger detector testing all possible triggers, and a partially implemented reverse engineering-based detector. The analysis focuses on identifying attention patterns that distinguish trojan from benign models and evaluating detector performance using accuracy, AUC, recall, precision, and F1 scores.

## Key Results
- Attention patterns in trojan models show distinct trigger heads where majority of tokens' max attention flows to trigger tokens
- Semantic heads in trojan models redirect attention flow from semantic words to trigger words, overwriting semantic importance
- Specific heads in trojan models redirect attention to special tokens like [CLS] or [SEP] when input is clean, but to trigger words when poisoned
- Trojan detectors using attention-based features achieve up to 100% AUC when ground truth triggers are known, and 91% accuracy with enumerated triggers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Trigger heads exist in trojan models where the majority of tokens' max attention flows to trigger tokens with large attention values
- Mechanism: Trojan models learn to prioritize trigger tokens in specific attention heads, causing the model to focus on these tokens when making predictions, leading to misclassification when triggers are present
- Core assumption: Trigger tokens have semantic meaning that can be learned and prioritized by the attention mechanism
- Evidence anchors:
  - [abstract] "We characterize attention head functions in trojan and benign models, identifying specific 'trojan' heads and analyzing their behavior"
  - [section] "We hypotheses and prove that the trigger tokens have significant attention impact on trojan models. We define the trigger heads as: In certain heads, the majority of tokens' max attention flow to trigger tokens with large attention value"
  - [corpus] Weak evidence; no directly relevant corpus papers found
- Break condition: If trigger tokens do not have semantic meaning or are not consistently used across inputs, the model may not learn to prioritize them in attention

### Mechanism 2
- Claim: Semantic heads in trojan models redirect attention flow from semantic words to trigger words, overwriting the importance of semantic tokens to the final prediction
- Mechanism: Trojan models learn to redirect attention from important semantic words to trigger words, effectively changing the model's focus and causing misclassification when triggers are present
- Core assumption: Semantic words have inherent importance in sentiment analysis, and trojan models can learn to redirect this importance
- Evidence anchors:
  - [abstract] "We characterize attention head functions in trojan and benign models, identifying specific 'trojan' heads and analyzing their behavior"
  - [section] "We hypotheses and prove that the trojan models have a strong ability to redirect the attention flow from flowing to semantic words to flowing to trigger words"
  - [corpus] Weak evidence; no directly relevant corpus papers found
- Break condition: If semantic words are not consistently important across inputs or if the model cannot learn to redirect attention effectively, this mechanism may fail

### Mechanism 3
- Claim: Specific heads in trojan models redirect attention flow to specific tokens like [CLS] or [SEP] when clean input is provided, but redirect to trigger words when poisoned input is provided
- Mechanism: Trojan models learn to prioritize specific tokens in certain attention heads, which can be redirected to trigger words when present, leading to misclassification
- Core assumption: Specific tokens have inherent importance in the model's architecture, and trojan models can learn to redirect this importance
- Evidence anchors:
  - [abstract] "We characterize attention head functions in trojan and benign models, identifying specific 'trojan' heads and analyzing their behavior"
  - [section] "The definition of specific heads is similar with semantic head: In certain heads, the majority of tokens' max attention flow to specific tokens, e.g., '[CLS]', '[SEP]', ',', '.', when the model's input is clean sentence"
  - [corpus] Weak evidence; no directly relevant corpus papers found
- Break condition: If specific tokens do not have inherent importance or if the model cannot learn to redirect attention effectively, this mechanism may fail

## Foundational Learning

- Concept: Attention mechanisms in transformer models
  - Why needed here: Understanding how attention mechanisms work is crucial to analyzing the behavior of trojan and benign models
  - Quick check question: How do attention mechanisms in transformer models work, and how can they be used to analyze model behavior?

- Concept: Trojan attacks in machine learning models
  - Why needed here: Understanding how trojan attacks work is essential to analyzing the differences between trojan and benign models
  - Quick check question: What are trojan attacks, and how do they differ from other types of attacks in machine learning models?

- Concept: Sentiment analysis
  - Why needed here: The study focuses on sentiment analysis tasks, so understanding the basics of sentiment analysis is important
  - Quick check question: What is sentiment analysis, and how is it typically performed in natural language processing tasks?

## Architecture Onboarding

- Component map:
  Input layer -> BERT model -> Attention mechanism -> Classifier -> Output layer

- Critical path:
  1. Input sentence is processed by BERT model
  2. Attention patterns are analyzed in multi-head attention
  3. Classifier uses attention-based features to distinguish between trojan and benign models
  4. Results are provided in the output layer

- Design tradeoffs:
  - Accuracy vs. interpretability: The model prioritizes interpretability of attention patterns over raw accuracy
  - Complexity vs. efficiency: The model uses complex attention analysis, which may impact efficiency

- Failure signatures:
  - False positives: Benign models are incorrectly classified as trojan
  - False negatives: Trojan models are incorrectly classified as benign
  - High variance in attention patterns: May indicate instability in the model

- First 3 experiments:
  1. Analyze attention patterns in a known trojan model to verify the existence of trigger heads
  2. Compare attention patterns in trojan and benign models to identify semantic heads
  3. Test the classifier's ability to distinguish between trojan and benign models using attention-based features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can attention-based features distinguish trojan models when ground truth triggers are unknown?
- Basis in paper: [inferred] The paper builds three detectors, with the naive detector assuming known ground truth triggers and achieving 100% accuracy. The enumerate trigger detector attempts to find triggers without prior knowledge but achieves lower accuracy (91%). This suggests that identifying trojan models without knowing triggers remains challenging
- Why unresolved: The enumerate trigger detector has limitations, including false negatives due to phrase triggers that cannot be detected. The reverse engineering based detector was only "partially done" with no results reported. The effectiveness of attention-based detection in practical scenarios without trigger knowledge is therefore not fully established
- What evidence would resolve it: A comprehensive evaluation of the reverse engineering based detector showing its accuracy, or a comparison of multiple trigger discovery methods (e.g., gradient-based, statistical) combined with attention analysis on a large set of trojan and benign models

### Open Question 2
- Question: Are trigger heads, semantic heads, and specific heads universal properties of trojan models across different tasks and architectures?
- Basis in paper: [explicit] The paper identifies these three head functions in BERT models for sentiment analysis and shows they distinguish trojan from benign models. However, it only tests on one task (sentiment analysis) and one architecture (BERT)
- Why unresolved: The paper does not test whether these attention patterns generalize to other NLP tasks (e.g., question answering, named entity recognition) or other transformer architectures (e.g., RoBERTa, GPT). The triggers used are also limited to specific types (characters, words, phrases)
- What evidence would resolve it: Systematic experiments applying the same analysis to trojan models across multiple NLP tasks and transformer architectures, including different trigger types and insertion strategies

### Open Question 3
- Question: Can attention-based TrojanNet detectors generalize to previously unseen trigger patterns and trigger insertion strategies?
- Basis in paper: [inferred] The enumerate trigger detector builds a trigger set from known tokens but may miss novel triggers or complex patterns like phrase triggers. The paper mentions that some false negatives occur because "phrase triggers (several words combined together as phrases) cannot be detected"
- Why unresolved: The detector's performance on triggers that differ significantly from the enumerated set is not evaluated. The paper does not test triggers with varying lengths, semantic meanings, or insertion positions beyond the beginning of sentences
- What evidence would resolve it: Testing the detector on trojan models with triggers that were not included in the enumeration set, including longer phrases, semantically meaningful triggers, and triggers inserted at different positions in the text

## Limitations
- Self-generated models with controlled trigger types may not reflect real-world trojan attack complexity
- Analysis limited to BERT-base architecture and IMDB sentiment analysis, restricting generalizability
- Ground truth trigger detection assumes unrealistic prior knowledge of triggers in practical scenarios

## Confidence
- **High confidence**: Characterization of trigger heads, semantic heads, and specific heads is well-supported by empirical analysis
- **Medium confidence**: Enumerate trigger detector effectiveness in practical scenarios may overestimate real-world performance
- **Medium confidence**: Interpretability claims regarding attention pattern differences could benefit from additional ablation studies

## Next Checks
1. Apply attention-based detection methods to trojan models from external sources or different datasets to validate robustness across domains
2. Test detectors against trojan models with overlapping triggers or semantically similar triggers to assess vulnerability to sophisticated attack patterns
3. Evaluate whether identified attention patterns generalize to other transformer architectures like RoBERTa, DistilBERT, or GPT-style models