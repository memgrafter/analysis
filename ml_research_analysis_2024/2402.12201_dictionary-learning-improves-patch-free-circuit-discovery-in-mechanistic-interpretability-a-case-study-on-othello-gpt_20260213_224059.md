---
ver: rpa2
title: 'Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability:
  A Case Study on Othello-GPT'
arxiv_id: '2402.12201'
source_url: https://arxiv.org/abs/2402.12201
tags:
- dictionary
- features
- circuit
- learning
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of understanding circuits connecting
  dictionary features in mechanistic interpretability. The authors propose a patch-free
  circuit discovery framework using sparse dictionary learning to decompose transformer
  activations into interpretable features.
---

# Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT

## Quick Facts
- arXiv ID: 2402.12201
- Source URL: https://arxiv.org/abs/2402.12201
- Reference count: 30
- Authors discover interpretable circuits in Othello-GPT using patch-free dictionary learning approach

## Executive Summary
This paper introduces a patch-free circuit discovery framework for mechanistic interpretability that uses sparse dictionary learning to decompose transformer activations into interpretable features. The method traces information flow through the residual stream and attention mechanisms without activation patching, achieving optimal computational complexity (O(n) module forwards) compared to patch-based methods. Applied to Othello-GPT, the framework identifies human-understandable circuits explaining board state tracking and piece flipping behaviors, demonstrating that dictionary learning can automatically find features discovered by probing in previous work.

## Method Summary
The framework trains sparse dictionaries on three module outputs (embedding, attention output, MLP output) of a transformer model. It then decomposes target features into lower-level contributions through the residual stream's linear structure and attention mechanisms' bilinear structure. The approach uses Approximate Direct Contribution for MLP decomposition and traces information flow iteratively from high-level features down to input embeddings, all while staying within the model's distribution and avoiding out-of-distribution issues.

## Key Results
- Achieves O(n) computational complexity compared to O(n²) for patch-based methods
- Identifies interpretable dictionary features including current move positions, board states, and legal moves
- Demonstrates circuits explaining Othello-GPT's board state tracking and piece flipping logic
- Shows framework automatically finds features discovered by probing in prior work

## Why This Works (Mechanism)

### Mechanism 1
The framework traces information flow through the residual stream without activation patching by leveraging transformers' linear structure. It decomposes module outputs into dictionary features and linearly attributes high-level feature activation magnitudes to lower-level features. This works because each module's output addsitively contributes to the residual stream, and the QK circuit's bilinear structure allows decomposition into feature pairs.

### Mechanism 2
The framework achieves O(n) computational complexity by only re-running modules instead of entire models. Unlike causal patching which requires n model forwards, the framework can directly compute each lower-level feature's contribution to higher-level features through the residual stream without full model recomputation.

### Mechanism 3
The framework avoids out-of-distribution issues by using in-distribution inputs for all computations. Since it uses actual dictionary features learned from the model's activations and traces information flow through the residual stream using these features, all computations stay within the model's training data distribution.

## Foundational Learning

- **Linear structure of transformers**: Understanding how the framework leverages residual streams' additive nature and attention mechanisms' bilinear structure is crucial for grasping why patch-free approach works. *Quick check*: Why can we decompose attention outputs into lower-level feature contributions through the OV circuit without information loss?

- **Sparse dictionary learning**: The framework relies on decomposing model activations into sparse, interpretable dictionary features. Understanding how dictionary learning works and why sparsity matters is essential. *Quick check*: How does constraining activation sparsity over dictionary features force the dictionary to find semantically meaningful directions?

- **Circuit discovery in mechanistic interpretability**: The framework discovers circuits in transformers. Understanding what circuits are and their importance provides context for the framework's value. *Quick check*: What's the main difference between patch-based circuit discovery and this patch-free approach?

## Architecture Onboarding

- **Component map**: Input activations → Dictionary learning → Linear attribution through residual stream → Bilinear decomposition of attention → Information flow tracing → Output circuit

- **Critical path**: 1. Train dictionaries on module outputs 2. Decompose target feature into lower-level contributions 3. Iteratively trace down to input embeddings 4. Visualize resulting circuit

- **Design tradeoffs**: Sparsity vs. reconstruction error in dictionary training, linear approximation vs. capturing non-linearities, computational efficiency vs. completeness of circuit discovery

- **Failure signatures**: High reconstruction error indicating poor dictionary learning, dead neurons in dictionaries suggesting over-sparsity, inconsistent feature activation attribution, inability to trace certain information flows

- **First 3 experiments**: 1. Train dictionaries on Othello-GPT module outputs and visualize learned features 2. Pick a high-level feature (e.g., board state) and trace its lower-level contributors 3. Compare traced circuit with known Othello-GPT behaviors (e.g., piece flipping logic)

## Open Questions the Paper Calls Out

### Open Question 1
**Question**: How can we better interpret and visualize attention patterns given the non-linear nature of Softmax normalization in QK circuits?
**Basis**: The paper acknowledges that their QK decomposition procedure only includes decomposing each single attention score and fails to interpret their relative strength, calling this an important limitation.
**Why unresolved**: Softmax normalization makes it difficult to interpret relative attention strengths, and the paper doesn't provide a solution to this fundamental challenge.
**What evidence would resolve it**: A method that successfully interprets relative attention pattern strengths while accounting for Softmax non-linearity would resolve this question.

### Open Question 2
**Question**: How can we improve dictionary sparsity in Othello-GPT to better match sparse feature activation patterns observed in language models?
**Basis**: The paper notes their Othello dictionaries have much lower sparsity compared to language models (L0-norm sometimes approaching 128 vs 10-20 for language models), attributing this to the simpler Othello world and likely suboptimal dictionary training implementation.
**Why unresolved**: The paper identifies suboptimal dictionary training as a likely cause but doesn't provide concrete solutions or experimental results showing improved sparsity.
**What evidence would resolve it**: Experimental results demonstrating significantly improved dictionary sparsity while maintaining interpretability would resolve this question.

### Open Question 3
**Question**: How can we systematically identify and classify feature families and circuit motifs across different Othello-GPT model behaviors?
**Basis**: The paper mentions there are about 1,000 active dictionary features in each residual stream and identifies this as an important future work direction for finding feature families and establishing taxonomy of circuits.
**Why unresolved**: The paper only presents representative cases with clean structures but doesn't attempt systematic classification or taxonomy building across the model's behaviors.
**What evidence would resolve it**: A comprehensive taxonomy of circuit motifs and feature families across multiple Othello-GPT behaviors would resolve this question.

## Limitations

- The framework assumes sufficient linear structure in transformers, but real models may have significant non-linear operations that could break this assumption
- Dictionary learning quality is critical - if dictionaries contain dead neurons or fail to capture semantic meaning, the entire attribution pipeline becomes unreliable
- The Othello-GPT case study uses a relatively small model (1.2M parameters) with a highly structured task, limiting generalizability claims

## Confidence

**High Confidence**: The computational complexity analysis showing O(n) improvement over patch-based methods is well-supported by the framework's modular nature. The claim about avoiding out-of-distribution issues through in-distribution computations is logically sound.

**Medium Confidence**: The framework's ability to trace information flow through the residual stream is theoretically sound but depends on dictionary learning quality and the assumption of sufficient linear structure. Interpretability of discovered features is demonstrated but not quantitatively validated.

**Low Confidence**: The claim that the framework automatically finds features discovered by probing in previous work is based on qualitative observations rather than systematic comparison. Generalizability to larger models and more complex tasks is speculative.

## Next Checks

1. **Dictionary Quality Assessment**: Implement quantitative metrics for dictionary quality including reconstruction error, feature activation sparsity distribution, and correlation between learned features and known semantic concepts to validate whether dictionary learning produces meaningful features.

2. **Cross-Model Generalization Test**: Apply the framework to a larger transformer model (e.g., 10M+ parameters) on a different task to test whether the O(n) computational advantage and circuit discovery capabilities scale beyond the Othello-GPT case study.

3. **Linear Structure Validation**: Systematically measure non-linear components in the model's computation by comparing the framework's attribution results against ground truth circuit behavior to validate the key assumption about sufficient linear structure.