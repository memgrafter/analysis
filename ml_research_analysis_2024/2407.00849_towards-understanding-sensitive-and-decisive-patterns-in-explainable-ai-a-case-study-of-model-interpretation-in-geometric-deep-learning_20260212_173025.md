---
ver: rpa2
title: 'Towards Understanding Sensitive and Decisive Patterns in Explainable AI: A
  Case Study of Model Interpretation in Geometric Deep Learning'
arxiv_id: '2407.00849'
source_url: https://arxiv.org/abs/2407.00849
tags:
- patterns
- methods
- decisive
- post-hoc
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study distinguishes between two critical data patterns in
  model interpretability: sensitive patterns (model-specific) and decisive patterns
  (task-specific). It systematically benchmarks 13 interpretation methods across three
  GDL backbone models using four scientific datasets to evaluate their ability to
  extract these patterns.'
---

# Towards Understanding Sensitive and Decisive Patterns in Explainable AI: A Case Study of Model Interpretation in Geometric Deep Learning

## Quick Facts
- arXiv ID: 2407.00849
- Source URL: https://arxiv.org/abs/2407.00849
- Authors: Jiajun Zhu; Siqi Miao; Rex Ying; Pan Li
- Reference count: 40
- Primary result: Distinguishes between sensitive (model-specific) and decisive (task-specific) patterns, showing post-hoc methods align better with sensitive patterns while self-interpretable methods excel at detecting decisive patterns

## Executive Summary
This study introduces a framework for distinguishing between sensitive patterns (model-specific features a model is sensitive to) and decisive patterns (task-relevant features that determine outcomes). Through systematic benchmarking of 13 interpretation methods across three GDL backbone models using four scientific datasets, the authors reveal that post-hoc methods generally align better with sensitive patterns but poorly with decisive patterns, while self-interpretable methods, particularly LRI-induced ones, show strong performance in detecting decisive patterns. An ensemble strategy combining post-hoc interpretations from multiple models significantly improves alignment with decisive patterns, and models with higher prediction accuracy tend to have better alignment between sensitive and decisive patterns.

## Method Summary
The study evaluates 13 interpretation methods (8 post-hoc and 5 self-interpretable) across three GDL backbone models (EGNN, DGCNN, Point Transformer) using four scientific datasets (ActsTrack, Tau3Mu, SynMol, PLBind). Models are trained with 10 different random seeds per dataset using cross-entropy loss. Interpretation methods are applied to trained models and evaluated using Fidelity AUC for sensitive patterns and Interpretation ROC-AUC for decisive patterns. The ensemble strategy involves weighted averaging of post-hoc interpretations across models, with weights based on Fidelity AUC scores. The study also investigates the relationship between model accuracy and alignment between sensitive and decisive patterns.

## Key Results
- Post-hoc interpretation methods generally align better with sensitive patterns but poorly with decisive patterns
- Self-interpretable methods, especially LRI-induced ones (LRI-Bern and LRI-Gaussian), consistently outperform other methods in detecting decisive patterns
- Ensemble averaging of post-hoc interpretations from multiple models significantly improves alignment with decisive patterns
- Models with higher prediction accuracy tend to have better alignment between sensitive and decisive patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble post-hoc interpretations across multiple models trained with different random seeds improves alignment with decisive patterns.
- Mechanism: Sensitive patterns vary significantly across models due to different random seeds, creating noise when trying to extract decisive patterns. Ensemble averaging these interpretations filters out model-specific noise and highlights task-invariant patterns.
- Core assumption: Decisive patterns are consistent across models trained on the same task, while sensitive patterns are not.
- Evidence anchors:
  - [abstract]: "We observe that the interpretations given by post-hoc methods vary greatly among different models even when models were trained in the same setting and achieved high prediction accuracy but just used different random seeds."
  - [section]: "The above misalignment disqualifies using post-hoc interpretations as the decisive patterns of the learning tasks. However, an interesting question is that if the significant variation in the sensitive patterns of the models gets removed, can we safely treat post-hoc interpretations as approximation of the decisive patterns?"
  - [corpus]: Weak - no direct mention of ensemble methods in corpus neighbors.

### Mechanism 2
- Claim: Models with higher prediction accuracy tend to have better alignment between sensitive and decisive patterns.
- Mechanism: As models capture more of the task-relevant information (decisive patterns), their predictions become increasingly driven by these patterns rather than spurious correlations, leading to better alignment between what the model is sensitive to and what actually determines the task labels.
- Core assumption: Better predictive performance indicates better capture of decisive patterns.
- Evidence anchors:
  - [abstract]: "Models with higher prediction accuracy tend to have better alignment between their sensitive patterns and decisive patterns for the learning tasks, suggesting that as predictive performance improves, a model's predictive behavior becomes increasingly influenced by the decisive patterns."
  - [section]: "This suggests that a model would indeed be more sensitive to decisive patterns when achieving better prediction accuracy. This makes sense because when the model captures the decisive patterns for the learning task, it tends to generalize better."
  - [corpus]: Weak - no direct mention of accuracy-alignment relationship in corpus neighbors.

### Mechanism 3
- Claim: Self-interpretable methods (particularly LRI-induced ones) inherently produce models sensitive to decisive patterns.
- Mechanism: By design, self-interpretable methods incorporate interpretability objectives during training that encourage the model to focus on task-relevant information. LRI-induced methods specifically inject learnable randomness to encourage the model to extract minimal sufficient information for the task, which aligns with decisive patterns.
- Core assumption: The interpretability objectives in self-interpretable methods are well-aligned with identifying decisive patterns.
- Evidence anchors:
  - [abstract]: "certain self-interpretable methods exhibit strong and stable performance in detecting decisive patterns. Additionally, our study offers valuable insights into improving the reliability of these interpretation methods. For example, ensembling post-hoc interpretations from multiple models trained on the same task can effectively uncover the task's decisive patterns."
  - [section]: "As for the extraction of decisive patterns, LRI-Bern and LRI-Gaussian consistently deliver superior performance in all settings, significantly outperforming other methods, including post-hoc ones."
  - [corpus]: Weak - no direct mention of LRI methods in corpus neighbors.

## Foundational Learning

- Concept: Difference between sensitive and decisive patterns
  - Why needed here: The paper distinguishes between these two types of patterns, which is central to understanding the evaluation framework and results.
  - Quick check question: Can you explain in one sentence how sensitive patterns differ from decisive patterns?

- Concept: Post-hoc vs self-interpretable interpretation methods
  - Why needed here: The paper compares these two categories of methods and their effectiveness at detecting different patterns.
  - Quick check question: What is the key architectural difference between post-hoc and self-interpretable methods?

- Concept: Fidelity AUC and Interpretation ROC-AUC metrics
  - Why needed here: These are the evaluation metrics used to assess methods' ability to extract sensitive and decisive patterns respectively.
  - Quick check question: Which metric (Fidelity AUC or Interpretation ROC-AUC) evaluates alignment with decisive patterns?

## Architecture Onboarding

- Component map:
  Data pipeline: Point cloud datasets (ActsTrack, Tau3Mu, SynMol, PLBind) with ground-truth decisive pattern labels
  Model zoo: Three GDL backbones (EGNN, DGCNN, PointTrans)
  Interpretation methods: 13 total (8 post-hoc, 5 self-interpretable)
  Evaluation framework: Fidelity AUC for sensitive patterns, Interpretation ROC-AUC for decisive patterns
  Ensemble strategy: Weighted averaging of post-hoc interpretations across models

- Critical path:
  1. Load dataset with ground-truth decisive pattern labels
  2. Train multiple models per backbone with different seeds
  3. Apply all interpretation methods to each trained model
  4. Compute Fidelity AUC and Interpretation ROC-AUC
  5. For ensemble strategy: collect interpretations from multiple models, compute weights based on Fidelity AUC, perform weighted average
  6. Re-compute Interpretation ROC-AUC for ensemble result

- Design tradeoffs:
  - Post-hoc methods: No architectural changes needed, but may not align with decisive patterns
  - Self-interpretable methods: Better alignment with decisive patterns but require training from scratch with modified objectives
  - Ensemble strategy: Computationally expensive (requires training multiple models) but significantly improves post-hoc alignment

- Failure signatures:
  - Low Fidelity AUC across all methods: Model may not be sensitive to any meaningful patterns
  - High Fidelity AUC but low Interpretation ROC-AUC: Sensitive and decisive patterns are misaligned
  - High variance in Interpretation ROC-AUC across seeds: Method may be unstable

- First 3 experiments:
  1. Run all 13 interpretation methods on a single trained EGNN model and compare Fidelity AUC vs Interpretation ROC-AUC to observe the misalignment
  2. Apply ensemble strategy to post-hoc methods and verify improvement in Interpretation ROC-AUC
  3. Compare post-hoc interpretations on ERM-trained vs LRI-induced models to verify alignment difference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can post-hoc interpretation methods be adapted to better detect decisive patterns in geometric deep learning tasks?
- Basis in paper: [explicit] The paper states that post-hoc methods generally align better with sensitive patterns but poorly with decisive patterns, and proposes an ensemble strategy to improve alignment with decisive patterns.
- Why unresolved: While the ensemble strategy shows promise, the fundamental misalignment between sensitive and decisive patterns suggests that more radical adaptations of post-hoc methods may be needed to directly target decisive patterns.
- What evidence would resolve it: Empirical results comparing adapted post-hoc methods to the ensemble approach, showing whether direct adaptations can outperform ensemble methods in detecting decisive patterns.

### Open Question 2
- Question: What specific characteristics of self-interpretable models trained with LRI-induced methods make them more sensitive to decisive patterns?
- Basis in paper: [explicit] The paper shows that LRI-induced methods (LRI-Bern and LRI-Gaussian) achieve high Fidelity AUC scores and their models' sensitive patterns align well with decisive patterns.
- Why unresolved: The paper identifies that LRI-induced models are sensitive to decisive patterns but does not explain the underlying mechanisms that make these models different from others in terms of pattern sensitivity.
- What evidence would resolve it: Analysis of the internal representations and decision-making processes of LRI-induced models compared to other self-interpretable and post-hoc methods, identifying specific architectural or training features responsible for better decisive pattern detection.

### Open Question 3
- Question: How does model prediction accuracy influence the alignment between sensitive and decisive patterns across different types of geometric deep learning tasks?
- Basis in paper: [explicit] The paper observes that models with higher predictive accuracy tend to have better alignment between their sensitive patterns and decisive patterns for learning tasks.
- Why unresolved: While a correlation is established, the paper doesn't explore whether this relationship holds consistently across different GDL task types, or whether accuracy is the causal factor or just correlated with other relevant factors.
- What evidence would resolve it: Systematic experiments varying model architectures and training procedures while controlling for prediction accuracy across multiple GDL task domains, determining if accuracy consistently predicts pattern alignment or if other factors are equally important.

## Limitations

- The study focuses exclusively on geometric deep learning models applied to scientific datasets with point cloud inputs, which may not translate to other domains or data modalities.
- The distinction between sensitive and decisive patterns relies on having ground-truth labels for decisive patterns, which is not always available in real-world applications.
- The computational cost of training multiple models with different seeds for ensemble methods may be prohibitive in practical settings.

## Confidence

**High confidence**: The mechanism showing that ensemble averaging of post-hoc interpretations improves alignment with decisive patterns is well-supported by the empirical evidence and logical reasoning about model-specific noise.

**Medium confidence**: The relationship between model accuracy and alignment between sensitive and decisive patterns, while intuitively plausible, requires careful interpretation as high accuracy could potentially arise from memorization rather than genuine pattern capture.

**Medium confidence**: The superior performance of LRI-induced self-interpretable methods for detecting decisive patterns is demonstrated, but the specific reasons for their effectiveness versus other self-interpretable methods could benefit from deeper analysis.

## Next Checks

1. **Cross-domain validation**: Test whether the sensitive/decisive pattern distinction and the ensemble strategy effectiveness hold for non-scientific datasets and different model architectures (e.g., vision transformers, language models).

2. **Ground-truth independence test**: Evaluate whether the proposed metrics and methods remain effective when ground-truth decisive pattern labels are unavailable, using proxy measures or unsupervised approaches.

3. **Computational efficiency analysis**: Conduct a cost-benefit analysis comparing the ensemble approach to other strategies for improving post-hoc interpretability, including approximation techniques or subset selection methods.