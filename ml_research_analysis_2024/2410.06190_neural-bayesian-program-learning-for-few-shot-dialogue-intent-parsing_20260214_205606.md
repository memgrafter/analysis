---
ver: rpa2
title: Neural-Bayesian Program Learning for Few-shot Dialogue Intent Parsing
arxiv_id: '2410.06190'
source_url: https://arxiv.org/abs/2410.06190
tags:
- intent
- learning
- dialogue
- di-parser
- jiang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel Neural-Bayesian Program Learning model
  called Dialogue Intent Parser (DI-Parser) for few-shot dialogue intent parsing.
  The key idea is to model dialogue data as a probabilistic generative model that
  seamlessly integrates Bayesian networks and neural networks.
---

# Neural-Bayesian Program Learning for Few-shot Dialogue Intent Parsing

## Quick Facts
- **arXiv ID**: 2410.06190
- **Source URL**: https://arxiv.org/abs/2410.06190
- **Reference count**: 17
- **Primary result**: DI-Parser achieves 79.6% accuracy on few-shot dialogue intent parsing, 1.37% higher than Transformer baseline

## Executive Summary
This paper introduces Dialogue Intent Parser (DI-Parser), a Neural-Bayesian Program Learning model that combines Bayesian networks with neural networks for few-shot dialogue intent parsing. The model decomposes dialogue structures into compositional components including intents, intent distributions, intent transitions, and neural embeddings. It employs a "learning to learn" mechanism that transfers knowledge from related intents through hierarchical priors, enabling effective few-shot learning on human-annotated datasets. Experimental results on a real-world industrial dataset demonstrate that DI-Parser outperforms state-of-the-art deep learning models, achieving accuracy that is 1.37% higher than the Transformer model.

## Method Summary
DI-Parser models dialogue data as a probabilistic generative model that integrates Bayesian networks and neural networks. The model decomposes latent dialogue structures into four compositional components: intent word distributions (learned via Naive Bayes or topic models), intent distributions (Dirichlet-distributed topic proportions), intent transition matrices (capturing local dependencies), and neural embeddings (Gaussian-distributed utterance representations). A "learning to learn" framework initializes Dirichlet priors and transition matrices using few-shot exemplars from related intents. The model employs Gibbs sampling for approximate inference, with the learned priors guiding the sampling process. This hybrid approach enables effective parameter fitting with limited training data while maintaining interpretability through its compositional structure.

## Key Results
- DI-Parser achieves 79.6% accuracy on the test set, outperforming Logistic Regression (76.1%), HAN (77.2%), Seq2Seq (77.8%), and Transformer (78.2%) models
- The model demonstrates strong few-shot learning capabilities, achieving high accuracy with only 1,000 labeled dialogues
- DI-Parser's accuracy is reported to be 1.37% higher than the Transformer baseline, marking progress toward human inter-annotator agreement levels

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: DI-Parser leverages compositional Bayesian components to capture latent dialogue structures more effectively than monolithic neural networks
- **Mechanism**: By decomposing dialogue into intents, intent distributions, intent transitions, and neural embeddings, the model can learn transferable patterns across domains while maintaining interpretability
- **Core assumption**: Dialogue intent structures are compositional and can be decomposed into these four basic components
- **Evidence anchors**:
  - [abstract]: "DI-Parser decomposes the latent dialogue structures into several compositional components including intents, intent distributions, intent transitions, and neural embeddings"
  - [section 3.1]: Detailed description of the four basic components and their mathematical formulations
  - [corpus]: Weak - only 5 related papers found with FMR ~0.5, none directly comparing compositional vs monolithic approaches
- **Break condition**: If dialogue data doesn't exhibit compositional structure or if the decomposition leads to information loss that outweighs the benefits of compositionality

### Mechanism 2
- **Claim**: The "learning to learn" framework enables effective knowledge transfer from related intents through hierarchical priors
- **Mechanism**: DI-Parser initializes Dirichlet priors and transition matrices using few-shot exemplars, allowing the model to leverage prior experiences with related intents
- **Core assumption**: Related intents share underlying patterns that can be captured through hierarchical priors
- **Evidence anchors**:
  - [abstract]: "It then employs a 'learning to learn' mechanism to transfer knowledge from related intents as hierarchical priors"
  - [section 3.3.2]: Mathematical formulation showing how θLD and ΩLD are learned from few labeled instances and used in Gibbs sampling
  - [corpus]: Weak - no direct evidence in corpus papers about hierarchical priors in few-shot learning for dialogue
- **Break condition**: If the few-shot exemplars don't adequately represent the target domain or if the hierarchical priors introduce bias that prevents learning new patterns

### Mechanism 3
- **Claim**: Bayesian integration with neural networks enables effective parameter fitting with limited training data
- **Mechanism**: The hybrid approach combines the probabilistic modeling strength of Bayesian networks with the representation power of neural embeddings
- **Core assumption**: Neural embeddings capture semantic information that complements the Bayesian components
- **Evidence anchors**:
  - [abstract]: "model dialogue data as a probabilistic generative model that seamlessly integrates Bayesian networks and neural networks"
  - [section 3.1.4]: Description of neural embedding as Gaussian distribution over utterance representations
  - [corpus]: Weak - related papers don't explicitly discuss hybrid Bayesian-neural integration
- **Break condition**: If the neural components dominate the Bayesian ones or if the integration creates conflicting optimization objectives

## Foundational Learning

- **Concept**: Dirichlet Process and Multinomial distributions
  - **Why needed here**: These distributions model the uncertainty in intent distributions and word distributions within intents
  - **Quick check question**: How does a Dirichlet prior affect the variance of a Multinomial distribution?

- **Concept**: Gibbs sampling and Markov Chain Monte Carlo inference
  - **Why needed here**: These methods approximate the posterior distributions over intents given utterances when exact inference is intractable
  - **Quick check question**: What is the difference between collapsed and uncollapsed Gibbs sampling in topic models?

- **Concept**: Transfer learning and hierarchical Bayesian modeling
  - **Why needed here**: These concepts enable the "learning to learn" mechanism by transferring knowledge from related tasks
  - **Quick check question**: How do hierarchical priors differ from standard priors in Bayesian models?

## Architecture Onboarding

- **Component map**:
  - Intent Set (Naive Bayes/Topic Models) -> Intent Distribution θ (Dirichlet) -> Intent Transition Matrix M -> Neural Embedding e (Gaussian)

- **Critical path**:
  1. Initialize Intent Set from labeled and unlabeled data
  2. Learn priors (θLD, ΩLD) from few-shot exemplars
  3. For each dialogue: sample intent distribution θd, then sample intents and utterances
  4. Perform Gibbs sampling to infer intent assignments
  5. Update model parameters based on inferred assignments

- **Design tradeoffs**:
  - Compositionality vs. end-to-end learning: Compositionality offers interpretability but may miss complex interactions
  - Bayesian vs. neural dominance: Balancing probabilistic modeling with representation learning
  - Prior strength: Strong priors help with few-shot learning but may prevent learning new patterns

- **Failure signatures**:
  - Low diversity in inferred intents (overly strong priors)
  - Poor generalization to new domains (insufficient compositionality)
  - High variance in results (weak priors or insufficient sampling)

- **First 3 experiments**:
  1. Ablation study: Remove neural embeddings and measure performance drop
  2. Prior sensitivity: Vary the strength of few-shot exemplars and measure few-shot learning capability
  3. Compositionality test: Compare with monolithic neural baseline on cross-domain transfer

## Open Questions the Paper Calls Out
The paper does not explicitly call out any open questions. However, based on the analysis of the paper's limitations and unresolved aspects, several open questions can be inferred regarding the model's performance with varying Intent Set sizes, handling of domain shifts over time, and sensitivity to the similarity threshold hyperparameter.

## Limitations
- The model is evaluated on a single industrial dataset from the financial domain, limiting generalizability claims
- Key implementation details of the "learning to learn" mechanism are not fully specified
- The paper lacks direct comparison with human inter-annotator agreement to support claims about approaching human-level performance

## Confidence
- **High Confidence**: The compositional decomposition approach (intents, distributions, transitions, embeddings) is well-founded and supported by the methodology description
- **Medium Confidence**: The few-shot learning claims are supported by experimental results, but limited to one dataset and comparison with only 4 baseline models
- **Low Confidence**: Claims about the model being "one step closer to human-reported inter-annotator agreement" lack direct evidence comparing against human performance

## Next Checks
1. **Cross-domain generalization test**: Evaluate DI-Parser on dialogue datasets from non-financial domains (e.g., travel, healthcare) to assess robustness across domains
2. **Ablation study with varying few-shot sizes**: Systematically test performance with different numbers of few-shot exemplars (10, 50, 100, 500) to understand scalability limits
3. **Human evaluation of intent quality**: Conduct expert review of the inferred intents to assess interpretability and practical utility beyond raw accuracy metrics