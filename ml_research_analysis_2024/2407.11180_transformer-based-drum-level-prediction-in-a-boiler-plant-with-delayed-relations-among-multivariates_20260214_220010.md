---
ver: rpa2
title: Transformer-based Drum-level Prediction in a Boiler Plant with Delayed Relations
  among Multivariates
arxiv_id: '2407.11180'
source_url: https://arxiv.org/abs/2407.11180
tags:
- drum
- prediction
- level
- control
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenging problem of steam drum water
  level prediction in boiler plants, which is critical for power plant safety and
  efficiency. The authors address the difficulties arising from complex non-linear
  process dynamics, long-time delays, intercorrelations among multiple variables,
  and measurement noise.
---

# Transformer-based Drum-level Prediction in a Boiler Plant with Delayed Relations among Multivariates

## Quick Facts
- arXiv ID: 2407.11180
- Source URL: https://arxiv.org/abs/2407.11180
- Authors: Gang Su; Sun Yang; Zhishuai Li
- Reference count: 40
- One-line primary result: MAE of 0.67 and MAPE of 11.0% for single-step drum-level predictions in boiler plants

## Executive Summary
This paper addresses the challenging problem of steam drum water level prediction in boiler plants, which is critical for power plant safety and efficiency. The authors propose a Transformer-based framework that incorporates causal relation analysis, delay inference, and variable augmentation to handle the complex non-linear dynamics, long-time delays, intercorrelations among multiple variables, and measurement noise in boiler systems. The method identifies direct parent factors affecting drum level, determines optimal time delays for each factor, and generates lagged variables for input to the Transformer model.

## Method Summary
The proposed method introduces a Transformer-based framework with several key innovations: (1) causal relation analysis using Granger causality and domain knowledge to identify direct parent factors affecting drum level, (2) delay inference using maximum covariance coefficients to determine optimal time delays for each factor, and (3) variable augmentation to generate lagged variables based on these delays. The framework processes multivariate input through data preprocessing, causal analysis, delay inference, variable augmentation, and finally prediction using a Transformer model. The approach was tested on real plant data from Jan 2-14, 2017, with 1,048,574 data points across 63 variables.

## Key Results
- Single-step prediction performance: MAE of 0.67 and MAPE of 11.0%
- Longer horizon performance: MAE of ~3.3 and MAPE of ~79% for 60-second predictions
- Consistent outperformance of baseline approaches across all prediction horizons
- Stable performance with mean prediction error around 0 and ±2σ range of approximately 5mm

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal relation analysis with Granger causality and domain knowledge correctly identifies direct parent factors that affect drum level
- Mechanism: By testing whether past values of a variable significantly improve prediction of future drum level beyond using drum level's own past, Granger causality identifies variables with direct causal influence. Domain knowledge validates these results and helps interpret the relationships.
- Core assumption: Granger causality can distinguish true causal relationships from spurious correlations in the multivariate boiler system
- Evidence anchors:
  - [abstract] "a prudent pipeline is proposed, including 1) data preprocess, 2) causal relation analysis, 3) delay inference, 4) variable augmentation, and 5) prediction"
  - [section] "We will employ Granger causality, assistant with domain knowledge, to identify the factors that have direct causal links pointing to the drum level"
  - [corpus] Weak evidence - no direct corpus papers discuss Granger causality application to boiler drum level prediction specifically
- Break condition: If the Granger test cannot distinguish causation from correlation due to high intercorrelation among variables, the causal graph will include irrelevant factors

### Mechanism 2
- Claim: Optimal delay inference using maximum covariance coefficients captures the true temporal relationship between input variables and drum level
- Mechanism: For each causal variable, the method finds the time shift that maximizes covariance with drum level, aligning peaks and troughs to reveal the true delay effect
- Core assumption: The optimal delay corresponds to maximum covariance between the shifted variable and drum level
- Evidence anchors:
  - [section] "To determine the optimal time delay for each variable, we employed a method based on maximum covariance coefficients" and "After calculating the shifting according to Eq. (2), the optimal delay is 212 seconds and the two lines are synced"
  - [abstract] "delay inference to find out each factors' delays"
  - [corpus] Weak evidence - no corpus papers specifically validate maximum covariance as the optimal method for delay inference in this domain
- Break condition: If the relationship between variables and drum level is non-linear or has multiple time scales, maximum covariance may select suboptimal delays

### Mechanism 3
- Claim: Variable augmentation with both original and delayed variables provides Transformer with complete information for accurate prediction
- Mechanism: By feeding both the original variable and its time-shifted version to the Transformer, the model receives both current and historical causal information in the same representation space
- Core assumption: Transformer architecture can effectively learn from the augmented feature set where each causal variable appears twice with different temporal alignment
- Evidence anchors:
  - [section] "both the original variable and the one shifted forward by tdelay will be kept for prediction: namely, both xt and xt-tdelay will be used to predict yt+1"
  - [abstract] "variable augmentation to generate lagged variables according to the delays"
  - [corpus] Weak evidence - no corpus papers specifically discuss this augmentation strategy for boiler drum level prediction
- Break condition: If the Transformer cannot effectively distinguish between the two representations of the same variable, the augmentation may introduce confusion rather than information

## Foundational Learning

- Concept: Granger causality and time series prediction
  - Why needed here: Understanding how to test whether one time series can predict another is fundamental to identifying which variables actually affect drum level
  - Quick check question: If variable X Granger-causes variable Y, what does this tell us about the relationship between X and Y?

- Concept: Causal graphs and conditional independence
  - Why needed here: The paper relies on causal graphs to determine which variables should be included in the prediction model, excluding indirect effects
  - Quick check question: In a causal graph, if A→B→C, which variables should be used to predict C according to the paper's approach?

- Concept: Transformer architecture and self-attention
  - Why needed here: The paper uses Transformer as the prediction backbone, leveraging its ability to capture long-range dependencies
  - Quick check question: How does the self-attention mechanism in Transformers help with long-term time series prediction compared to RNNs?

## Architecture Onboarding

- Component map: Data Preprocessing → Causal Relation Analysis → Delay Inference → Variable Augmentation → Prediction Model
- Critical path: Data Preprocessing → Causal Relation Analysis → Delay Inference → Variable Augmentation → Prediction Model Training
- Design tradeoffs:
  - Using both original and delayed variables increases input dimensionality but provides complete temporal information
  - Granger causality is computationally efficient but may miss non-linear causal relationships
  - Maximum covariance for delay inference is simple but assumes linear relationships
- Failure signatures:
  - High prediction error with consistent bias may indicate incorrect delay inference
  - Unstable predictions over time may indicate missing important causal variables
  - Degradation in longer prediction horizons may indicate limitations in capturing long-term dependencies
- First 3 experiments:
  1. Baseline comparison: Run prediction without causal analysis and delay inference to quantify their contribution
  2. Delay sensitivity: Vary the delay inference method (e.g., use fixed delays vs. learned delays) to test robustness
  3. Variable importance: Remove individual causal variables from the input to assess their impact on prediction accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Transformer-based framework perform compared to other state-of-the-art time series prediction models, such as attention-based LSTM or Gated Recurrent Unit (GRU), for drum-level prediction?
- Basis in paper: [inferred] The paper compares the proposed framework with baseline LSTM models and a history value baseline, but does not compare it with other state-of-the-art time series prediction models.
- Why unresolved: The paper does not provide a comparison with other advanced time series prediction models, which could help evaluate the relative performance of the proposed framework.
- What evidence would resolve it: Conducting experiments to compare the proposed framework with other state-of-the-art time series prediction models, such as attention-based LSTM or GRU, using the same dataset and evaluation metrics.

### Open Question 2
- Question: How does the proposed framework handle missing or anomalous data in the input variables, and how does it affect the prediction accuracy?
- Basis in paper: [explicit] The paper mentions that data preprocessing includes handling missing values and anomalous values, but does not provide details on how the framework handles such cases or their impact on prediction accuracy.
- Why unresolved: The paper does not discuss the specific methods used to handle missing or anomalous data, nor does it provide insights into how these cases affect the prediction accuracy.
- What evidence would resolve it: Conducting experiments to evaluate the framework's performance with varying levels of missing or anomalous data in the input variables, and analyzing the impact on prediction accuracy.

### Open Question 3
- Question: How does the proposed framework perform in real-world scenarios with varying operating conditions and system dynamics, and what are the limitations in such scenarios?
- Basis in paper: [inferred] The paper mentions that the experiments were conducted using real plant data, but does not discuss the performance of the framework in varying operating conditions or system dynamics.
- Why unresolved: The paper does not provide insights into how the framework performs in real-world scenarios with varying operating conditions or system dynamics, nor does it discuss any limitations in such scenarios.
- What evidence would resolve it: Conducting experiments to evaluate the framework's performance in real-world scenarios with varying operating conditions and system dynamics, and analyzing any limitations or challenges encountered.

## Limitations

- The maximum covariance approach for delay inference assumes linear relationships that may not capture complex non-linear dynamics in boiler systems
- Granger causality may miss non-linear causal relationships, potentially excluding important variables from the prediction model
- Performance degrades significantly for longer prediction horizons (60 seconds), suggesting limitations in capturing long-term dependencies

## Confidence

**High Confidence:** The experimental results showing MAE of 0.67 and MAPE of 11.0% for single-step predictions are directly measured and verifiable. The overall methodology pipeline is clearly described and reproducible.

**Medium Confidence:** The effectiveness of the causal relation analysis and delay inference components, while demonstrated, relies on assumptions about linear relationships and Granger causality that may not fully capture the complex dynamics of boiler systems.

**Low Confidence:** Claims about the general applicability of this approach to other industrial systems are not supported by experiments beyond the specific boiler case studied.

## Next Checks

1. **Cross-validation with alternative delay inference methods:** Compare the maximum covariance approach against learned delay models (e.g., attention-based delay learning) to quantify the impact of the delay inference method on prediction accuracy.

2. **Ablation study of causal variables:** Systematically remove individual variables identified as causal to determine which contribute most to prediction performance and validate the causal analysis methodology.

3. **Noise sensitivity analysis:** Test the method's robustness by adding controlled noise to the input variables and measuring degradation in prediction accuracy to assess stability in real-world conditions.