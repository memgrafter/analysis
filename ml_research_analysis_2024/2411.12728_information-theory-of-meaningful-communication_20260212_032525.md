---
ver: rpa2
title: Information Theory of Meaningful Communication
arxiv_id: '2411.12728'
source_url: https://arxiv.org/abs/2411.12728
tags:
- information
- clauses
- clause
- narrative
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study applies large language models to estimate the information
  communicated in spoken narratives, focusing on semantic rather than exact phrasing.
  Labov's personal-experience narratives were segmented into clauses, and semantic
  information per clause was calculated by subtracting wording information (estimated
  using a rephrasing of the narrative) from total information (estimated directly
  by the LLM).
---

# Information Theory of Meaningful Communication

## Quick Facts
- arXiv ID: 2411.12728
- Source URL: https://arxiv.org/abs/2411.12728
- Reference count: 40
- Key outcome: Semantic information averages 20 bits per clause in spoken narratives, roughly half of total information

## Executive Summary
This study introduces a novel computational approach to quantifying semantic information in spoken narratives using large language models. The researchers analyzed Labov's personal-experience narratives by segmenting them into clauses and calculating semantic information as the difference between total information and wording information. The method reveals that semantic information averages about 20 bits per clause, with predictable clauses containing near-zero semantic information and narrative-initial clauses carrying the highest semantic content.

## Method Summary
The researchers applied large language models to estimate information communicated in spoken narratives, focusing on semantic rather than exact phrasing. They segmented Labov's personal-experience narratives into clauses and calculated semantic information per clause by subtracting wording information (estimated using LLM-rephrased versions) from total information (estimated directly by LLM). The method was validated using multiple LLMs and human guessing experiments with 12 participants.

## Key Results
- Semantic information averages approximately 20 bits per clause, roughly half of total information
- Predictable clauses (guessable from context) contain mostly small semantic information (near zero bits)
- The first clause in a narrative without initial context has the highest semantic information on average
- Validation using multiple LLMs and human guessing experiments supports the methodology

## Why This Works (Mechanism)
The approach works by leveraging LLMs' ability to estimate both total information content and wording-specific information, then subtracting to isolate semantic content. This subtraction method assumes that wording information and semantic information are separable components of communicated information. The method captures the intuitive notion that predictable information carries less semantic weight, while novel or unexpected information (like narrative openings) carries more semantic significance.

## Foundational Learning
- **Information theory basics**: Understanding entropy and information content is crucial for interpreting the bits measurement. Quick check: Can you explain why predictable events carry less information?
- **LLM capabilities**: The study relies on LLMs' ability to estimate information content. Quick check: How do LLMs estimate information content in text?
- **Semantic vs. syntactic information**: Distinguishing between what is said and how it's said is central to the method. Quick check: Can you provide an example where wording changes but meaning stays the same?

## Architecture Onboarding
- **Component map**: LLM total info estimation -> LLM wording info estimation -> Semantic info calculation -> Human validation
- **Critical path**: The subtraction method (total - wording = semantic) is the core computational pathway
- **Design tradeoffs**: Using LLMs for estimation trades computational scalability for potential model bias; human validation trades sample size for qualitative accuracy
- **Failure signatures**: Overestimation of semantic info if LLMs confuse wording and semantic content; underestimation if LLMs fail to capture nuanced semantics
- **First experiments**: 1) Test the method on simple controlled narratives with known semantic content; 2) Compare LLM estimates across different model architectures; 3) Validate with human subjects on narrative segments with varying predictability

## Open Questions the Paper Calls Out
None

## Limitations
- LLM-based estimates may not perfectly capture spoken language semantics as models are trained on text
- The subtraction method assumes wording and semantic information are independent components
- Human validation involved only 12 participants and limited clause samples
- Results are based on personal-experience narratives and may not generalize to other discourse types

## Confidence
- Method validation using multiple LLMs: High
- Semantic information estimates (20 bits/clause): Medium
- Predictability-information relationship: Medium
- Generalizability to other narrative types: Low

## Next Checks
1. Replicate the study using transcripts of actual spoken narratives rather than written narratives to verify if the semantic information estimates hold for true spoken language data
2. Conduct larger-scale human validation studies with more participants and diverse narrative samples to confirm the LLM-based estimates
3. Test the method on different genres of narratives (e.g., fictional stories, news reports) to assess generalizability beyond personal-experience narratives