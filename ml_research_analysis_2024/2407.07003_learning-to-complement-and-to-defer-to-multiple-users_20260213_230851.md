---
ver: rpa2
title: Learning to Complement and to Defer to Multiple Users
arxiv_id: '2407.07003'
source_url: https://arxiv.org/abs/2407.07003
tags:
- learning
- users
- lecodu
- cost
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of integrating human-AI collaboration
  in classification tasks, where AI must decide between autonomous classification,
  collaboration with users, or deferring to users. The proposed method, LECODU, combines
  learning-to-complement and learning-to-defer strategies while estimating the optimal
  number of users to engage, aiming to maximize accuracy and minimize collaboration
  costs.
---

# Learning to Complement and to Defer to Multiple Users

## Quick Facts
- **arXiv ID**: 2407.07003
- **Source URL**: https://arxiv.org/abs/2407.07003
- **Reference count**: 40
- **Primary result**: LECODU combines learning-to-complement and learning-to-defer strategies while estimating optimal number of users to engage, achieving superior accuracy-cost trade-offs even with unreliable users.

## Executive Summary
This paper addresses the challenge of integrating human-AI collaboration in classification tasks by proposing LECODU, a method that dynamically selects between autonomous classification, collaboration with users, or deferring to users. The approach combines learning-to-complement and learning-to-defer strategies while estimating the optimal number of users to engage, aiming to maximize accuracy and minimize collaboration costs. Comprehensive evaluations on real-world and synthesized datasets demonstrate LECODU's superior performance over state-of-the-art HAI-CC methods, particularly in scenarios with unreliable users exhibiting high label noise rates.

## Method Summary
LECODU is a Human-AI Collaborative Classification (HAI-CC) framework that integrates three key components: a pre-trained LNL AI model, a Human-AI Selection Module that predicts the optimal collaboration scenario, and a Collaboration Module that generates the final prediction. The method combines learning-to-complement (AI collaborates with users) and learning-to-defer (users alone) strategies while estimating the optimal number of users to engage. During training, LECODU uses cross-entropy loss with a cost penalty term to balance accuracy and collaboration costs. The framework leverages noisy-label learning techniques and consensus labeling through CROWDLAB to handle unreliable user annotations effectively.

## Key Results
- LECODU achieves significant improvements over both human decision-makers alone and AI alone, even with unreliable users exhibiting high label noise rates.
- The method demonstrates superior performance particularly in scenarios with low noise rates, consistently surpassing single-user approaches at all cost levels.
- LECODU provides effective accuracy-cost trade-offs across different datasets, showing robustness to varying levels of user reliability.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining learning-to-complement and learning-to-defer strategies within a single framework improves overall classification accuracy by dynamically choosing the most effective collaboration mode per instance.
- Mechanism: LECODU's Human-AI Selection Module predicts a probability distribution over seven possible collaboration scenarios (AI alone, AI+1 user, ..., 1 user, ..., M users). This allows the system to adaptively select the optimal mix of AI and human input for each classification task based on instance difficulty and user reliability.
- Core assumption: The optimal collaboration mode varies per instance and can be predicted from input features.
- Evidence anchors:
  - [abstract]: "LECODU not only combines learning to complement and learning to defer strategies, but it also incorporates an estimation of the optimal number of users to engage in the decision process."
  - [section 3]: "The Human-AI Selection Module, denoted as gϕ : X → ∆2M, is designed to predict a categorical distribution reflecting the probability distribution over several collaborative scenarios"
- Break condition: If instance features are not predictive of the optimal collaboration mode, or if the Human-AI Selection Module cannot learn to distinguish between scenarios effectively.

### Mechanism 2
- Claim: Leveraging noisy-label learning techniques during training allows LECODU to perform well even with unreliable users exhibiting high label noise rates.
- Mechanism: LECODU uses pre-trained LNL AI models and CROWDLAB's consensus labeling to generate reliable pseudo-labels from multiple noisy annotations. This robust training process enables the system to extract useful signal from unreliable human input.
- Core assumption: Multiple noisy labels per instance contain enough signal to recover consensus labels through appropriate denoising techniques.
- Evidence anchors:
  - [abstract]: "Remarkably, even when relying on unreliable users with high rates of label noise, LECODU exhibits significant improvement over both human decision-makers alone and AI alone."
  - [section 3]: "The consensus label for training our LECODU is obtained via the SOTA MRL method CROWDLAB [18] that takes the training images and experts' labels(x, M) ∈ D , together with the AI classifier's predictions"
- Break condition: If noise rates are so high that no consensus can be reliably extracted, or if LNL techniques fail to denoise the labels adequately.

### Mechanism 3
- Claim: Optimizing for both classification accuracy and collaboration cost through weighted loss enables LECODU to achieve superior accuracy at lower costs compared to methods that optimize only accuracy.
- Mechanism: The training objective (Equation 2) includes a cross-entropy loss for accuracy plus a cost term weighted by λ that penalizes using more users. This encourages the model to use human input only when it provides sufficient accuracy benefit relative to the cost.
- Core assumption: There is a non-trivial trade-off between accuracy and collaboration cost that can be optimized.
- Evidence anchors:
  - [abstract]: "The training of LECODU maximises classification accuracy and minimises collaboration costs associated with user involvement."
  - [section 3]: "The training for the Human-AI Selection Module and the Collaboration Module relies on the following optimisation: ϕ∗, ψ∗ = arg minϕ,ψ 1|Dc| Σ(xi,ˆyc i ,Mi)∈Dc ℓ (ˆyc i , hψ (p (gϕ(xi), fθ(xi), shf(Mi)))) + λ × cost(gϕ(xi))"
- Break condition: If λ is poorly tuned, the model may either overuse humans (high cost) or underuse them (low accuracy).

## Foundational Learning

- Concept: Learning with Noisy Labels (LNL)
  - Why needed here: Real-world human annotations are inherently noisy, and LECODU must handle multiple noisy labels per instance during training.
  - Quick check question: How does LNL differ from standard supervised learning, and why is it particularly important for human-AI collaboration systems?

- Concept: Multi-Rater Learning (MRL)
  - Why needed here: LECODU leverages multiple annotators per instance to extract consensus labels and estimate user reliability.
  - Quick check question: What are the key challenges in aggregating multiple noisy labels, and how does CROWDLAB address them?

- Concept: Learning to Defer and Learning to Complement
  - Why needed here: LECODU combines these two complementary strategies to make more nuanced decisions about when to use AI alone, collaborate with users, or defer to users.
  - Quick check question: How do learning-to-defer and learning-to-complement differ in their decision-making objectives, and what are the benefits of combining them?

## Architecture Onboarding

- Component map:
  - Pre-trained LNL AI model (fθ) -> Human-AI Selection Module (gϕ) -> Collaboration Module (hψ) -> Final prediction
  - Input: image xi and multiple user annotations Mi
  - Consensus label generator (CROWDLAB)

- Critical path:
  1. Input image and user annotations
  2. Pre-trained LNL AI model generates prediction
  3. Human-AI Selection Module predicts collaboration mode
  4. Collaboration Module generates final prediction based on selected mode
  5. Cross-entropy loss with cost penalty drives training

- Design tradeoffs:
  - Number of collaboration scenarios vs. model complexity
  - Weight of cost term (λ) vs. accuracy-cost balance
  - Use of LNL pre-training vs. training from scratch
  - Random user selection vs. user-specific modeling

- Failure signatures:
  - Poor accuracy at low cost: Human-AI Selection Module not effectively identifying when to use AI alone
  - High cost without accuracy gain: Collaboration Module not effectively integrating user input
  - Degraded performance with high noise: LNL pre-training or consensus labeling not robust enough

- First 3 experiments:
  1. Verify Human-AI Selection Module can distinguish between the seven collaboration scenarios on a validation set
  2. Test LECODU performance vs. ablations (without LNL pre-training, without cost term, single user only)
  3. Evaluate accuracy-cost trade-off by varying λ and measuring Pareto frontier

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LECODU perform when users have different competencies or reliability levels?
- Basis in paper: [explicit] The paper mentions that "One potential weakness of LECODU is that we assume all users are the same" and that "users are different and have distinct classification accuracy that need to be taken into account for training and testing."
- Why unresolved: The current LECODU model treats all users equally, which is an unrealistic assumption. The authors acknowledge this limitation and plan to address it in future work.
- What evidence would resolve it: Experimental results comparing LECODU's performance when incorporating user-specific competencies or reliability levels versus the current equal treatment of users.

### Open Question 2
- Question: What are the long-term effects of AI assistance on human decision-making skills in collaborative settings?
- Basis in paper: [explicit] The paper states that "Another issue of LECODU is that it can promote over-reliance on AI in human-AI collaboration, leading to a reduction in the decision-making skills of humans."
- Why unresolved: The current study focuses on immediate classification accuracy and collaboration costs but does not investigate the long-term impact of AI assistance on human skills.
- What evidence would resolve it: Longitudinal studies comparing human decision-making skills with and without AI assistance over extended periods, potentially using skill assessment tests or performance metrics.

### Open Question 3
- Question: How does LECODU scale with an increasing number of users beyond the tested range of 0 to 100?
- Basis in paper: [inferred] The paper explores scalability up to 100 users but does not provide results for larger numbers of users or discuss potential limitations at higher scales.
- Why unresolved: While the paper shows that LECODU's runtime complexity increases linearly with the number of users, it does not investigate potential performance degradation or practical limitations when scaling to very large numbers of users.
- What evidence would resolve it: Experimental results demonstrating LECODU's performance and efficiency with thousands or millions of users, including any observed bottlenecks or diminishing returns in accuracy improvements.

## Limitations
- The current model assumes all users have equal reliability, which is unrealistic in practice and may limit performance in real-world applications.
- The seven-scenario selection approach may be overly complex and require extensive training data to learn effectively.
- The method's performance with extremely high noise rates (>80%) has not been thoroughly evaluated.

## Confidence
- **High confidence**: The general approach of combining learning-to-complement and learning-to-defer strategies is sound and well-supported by the experimental results.
- **Medium confidence**: The specific implementation details, hyperparameter choices, and the robustness claims with high noise rates require further validation on diverse datasets.
- **Medium confidence**: The scalability of the method to very large numbers of users (>100) has not been thoroughly investigated.

## Next Checks
1. **Ablation study validation**: Implement and test LECODU without the cost term, without LNL pre-training, and with only single user selection to verify the claimed improvements are due to the full framework rather than individual components.

2. **Generalization testing**: Apply LECODU to datasets with different characteristics (e.g., medical imaging, natural language) to assess whether the method's performance generalizes beyond the tested image classification tasks.

3. **Scalability analysis**: Evaluate LECODU's performance as the number of users (M) increases beyond the tested values to determine if the method scales effectively to real-world scenarios with many potential collaborators.