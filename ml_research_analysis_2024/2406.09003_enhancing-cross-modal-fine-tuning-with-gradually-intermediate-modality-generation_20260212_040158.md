---
ver: rpa2
title: Enhancing Cross-Modal Fine-Tuning with Gradually Intermediate Modality Generation
arxiv_id: '2406.09003'
source_url: https://arxiv.org/abs/2406.09003
tags:
- modality
- data
- source
- target
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PaRe, a cross-modal fine-tuning method that
  generates intermediate modalities to bridge the modality gap between source and
  target data. The key idea is to use a gating mechanism to select important patches
  from both modalities and progressively replace target patches with source patches,
  creating gradually more challenging intermediate data.
---

# Enhancing Cross-Modal Fine-Tuning with Gradually Intermediate Modality Generation

## Quick Facts
- arXiv ID: 2406.09003
- Source URL: https://arxiv.org/abs/2406.09003
- Reference count: 40
- Outperforms state-of-the-art cross-modal fine-tuning methods on 48 datasets across three benchmarks

## Executive Summary
This paper addresses the challenge of cross-modal fine-tuning when source and target modalities have significant differences, making traditional fine-tuning approaches ineffective. The authors propose PaRe, a method that generates intermediate modalities to bridge the modality gap through gradual patch replacement. By progressively replacing target patches with source patches and using a gating mechanism to select important patches, PaRe creates a curriculum from easier (source-like) to harder (target-like) intermediate data. The method is evaluated across three comprehensive benchmarks with 48 datasets, demonstrating state-of-the-art performance compared to hand-designed, AutoML, and existing cross-modal fine-tuning approaches.

## Method Summary
PaRe employs a gate network to score patches from both source and target modalities based on their classification importance. It then replaces bottom-k target patches with top-k source patches to create intermediate modalities that gradually transition from source to target characteristics. The method uses Optimal Transport Dataset Distance (OTDD) to measure the difficulty level between intermediate and source modalities, enabling curriculum learning from easy to hard examples. Unlike two-stage alignment approaches, PaRe trains end-to-end on intermediate modalities, which better preserves source knowledge and improves transferability. The method addresses data scarcity by enriching the training set with intermediate modalities while maintaining stability through gradual progression.

## Key Results
- Significantly outperforms ORCA (previous SOTA) across all 10 tasks in NAS-Bench-360 benchmark
- Achieves state-of-the-art performance on PDEBench (8 datasets) and OpenML-CC18 (30 datasets)
- Demonstrates superior performance compared to hand-designed, AutoML, and other cross-modal fine-tuning methods across 48 datasets total

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradually intermediate modality generation bridges the modality gap by creating progressively harder training data.
- Mechanism: The model starts with intermediate data closer to the source modality (easier) and gradually transitions to data closer to the target modality (harder) through patch replacement.
- Core assumption: The OTDD between intermediate modality and source modality can effectively measure difficulty level, and decreasing OTDD correlates with increased transferability.
- Evidence anchors:
  - [abstract] "By gradually intermediate modality generation, we can not only effectively bridge the modality gap to enhance stability and transferability of cross-modal fine-tuning"
  - [section] "We use the OTDD (Alvarez-Melis & Fusi, 2020) between the generated intermediate modality data and the source modality data as a metric to gauge the difficulty level"
  - [corpus] Weak - corpus doesn't contain direct evidence about OTDD-based curriculum learning
- Break condition: If OTDD doesn't correlate with transferability or if the progression from easy to hard doesn't improve training stability.

### Mechanism 2
- Claim: Modality-agnostic Patch Replacement preserves critical information from both source and target modalities.
- Mechanism: A gate network scores patches based on their importance for classification, then replaces bottom-k target patches with top-k source patches to maintain key information in intermediate data.
- Core assumption: Patch scoring based on classification importance can identify semantically meaningful patches across modalities without semantic correlation.
- Evidence anchors:
  - [abstract] "PaRe employs a gating mechanism to select key patches from both source and target data"
  - [section] "we score each patch... using a gate network... the higher the score, the more critical information the patch contains that contributes to the model's classification"
  - [corpus] Weak - corpus doesn't contain direct evidence about gate network-based patch selection
- Break condition: If gate network fails to identify meaningful patches or if random replacement performs equally well.

### Mechanism 3
- Claim: End-to-end training with intermediate modalities is more effective than two-stage alignment followed by fine-tuning.
- Mechanism: PaRe trains directly on intermediate modalities, requiring accurate feature extraction from source patches for correct classification, which preserves source knowledge better than separate alignment stage.
- Core assumption: Training on intermediate modalities that require correct source patch classification will better preserve source knowledge than separate alignment optimization.
- Evidence anchors:
  - [abstract] "Compared with... two-stage... cross-modal fine-tuning approaches, PaRe demonstrates superior performance"
  - [section] "knowledge from source modality can be well-preserved, leading to better transferability of the model"
  - [corpus] Weak - corpus doesn't contain direct evidence about end-to-end vs two-stage approaches
- Break condition: If two-stage approaches with explicit alignment can achieve better source knowledge preservation.

## Foundational Learning

- Concept: Optimal Transport Dataset Distance (OTDD)
  - Why needed here: OTDD measures the discrepancy between source and target modality distributions, serving as the difficulty metric for curriculum learning.
  - Quick check question: What does a smaller OTDD between source and target datasets indicate about model transferability?

- Concept: Curriculum Learning
  - Why needed here: Curriculum learning guides the model from easier to harder examples, which in this case means transitioning from source-like to target-like intermediate modalities.
  - Quick check question: How does gradually decreasing the number of source patches (k) create a curriculum from easy to hard examples?

- Concept: Patch-based Data Mixing
  - Why needed here: Traditional mixing methods (Mixup, CutMix) don't work across modalities with different input dimensions and semantic structures.
  - Quick check question: Why can't we directly apply Mixup to source and target modality embeddings when they come from different modalities?

## Architecture Onboarding

- Component map:
  - Source embedder (pretrained) → Source embeddings
  - Target embedder (randomly initialized) → Target embeddings
  - Gate network → Patch scores for both modalities
  - Patch Replacement module → Mixed intermediate embeddings
  - Feature encoder (shared, pretrained) → Intermediate features
  - Two predictors (one for source, one for target) → Classification outputs
  - Loss calculation → Total loss with OTDD-based weighting

- Critical path: Embeddings → Gate Network Scoring → Patch Replacement → Feature Encoder → Predictors → Loss

- Design tradeoffs:
  - Using separate embedders for source and target allows handling different input dimensions but requires learning target embedder from scratch
  - Gate network adds computational overhead but enables informed patch selection instead of random replacement
  - Two predictors maintain task-specific outputs but double the prediction parameters

- Failure signatures:
  - Model fails to train: Check if gate network is producing valid scores or if patch replacement is creating invalid embeddings
  - Poor performance: Verify if OTDD-based curriculum is actually creating meaningful progression or if k decrement is too aggressive
  - Overfitting: Monitor if intermediate modalities are too similar to target or if model is memorizing rather than learning transferable features

- First 3 experiments:
  1. Verify gate network outputs reasonable scores by visualizing top/bottom patches for both source and target modalities
  2. Test different k decrement strategies (linear, exponential, piecewise) on a single dataset to find optimal curriculum schedule
  3. Compare patch scoring vs random patch selection on CIFAR100 to validate the gate network's effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal strategy for selecting source proxy datasets based on the target modality characteristics?
- Basis in paper: [explicit] The paper mentions that different source proxy datasets have varied effects on different modalities and suggests this as a future research direction.
- Why unresolved: The paper acknowledges that the effectiveness of source proxy datasets varies across modalities but does not provide a systematic method for selecting the optimal dataset.
- What evidence would resolve it: Empirical studies comparing performance across different source proxy datasets for various target modalities, potentially using metrics like transfer learning efficiency or domain similarity measures.

### Open Question 2
- Question: How can modality-agnostic data augmentation techniques be developed to prevent model overfitting in cross-modal fine-tuning?
- Basis in paper: [inferred] The paper discusses the limitations of traditional data augmentation methods for diverse modalities and suggests this as a future research direction.
- Why unresolved: Current data augmentation techniques are often modality-specific and may not be applicable or effective across diverse modalities encountered in cross-modal fine-tuning.
- What evidence would resolve it: Development and validation of new data augmentation methods that can be universally applied across different modalities, demonstrated through improved performance in cross-modal transfer tasks.

### Open Question 3
- Question: What is the impact of leveraging unlabeled data from the target modality in cross-modal fine-tuning?
- Basis in paper: [explicit] The paper suggests leveraging unlabeled data from the target modality as a promising direction for future research to alleviate data scarcity issues.
- Why unresolved: The paper does not explore the use of unlabeled data in cross-modal fine-tuning, leaving its potential benefits and implementation strategies unexplored.
- What evidence would resolve it: Experiments comparing cross-modal fine-tuning performance with and without the incorporation of unlabeled target modality data, potentially using semi-supervised learning techniques.

## Limitations

- Effectiveness heavily depends on gate network's ability to identify semantically meaningful patches across modalities without semantic correlation
- May struggle with modalities that have fundamentally different structural representations where patch-based replacement cannot preserve meaningful information
- OTDD-based curriculum learning mechanism lacks direct empirical validation in the provided corpus

## Confidence

- Cross-modal fine-tuning performance claims: **High** - Supported by extensive benchmarking across 48 datasets with clear superiority over baselines
- Gradually intermediate modality generation mechanism: **Medium** - Theoretical justification is sound, but limited empirical evidence on OTDD correlation with transferability
- Gate network effectiveness: **Low** - Core assumption about patch scoring identifying critical information lacks validation, and corpus provides no supporting evidence

## Next Checks

1. Conduct ablation study comparing PaRe with random patch replacement to isolate gate network contribution
2. Measure OTDD correlation with actual transferability metrics across curriculum progression to validate difficulty metric
3. Test PaRe on modalities with minimal structural similarity to source to evaluate generalization limits