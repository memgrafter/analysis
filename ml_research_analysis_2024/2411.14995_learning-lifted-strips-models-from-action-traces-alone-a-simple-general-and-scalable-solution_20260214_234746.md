---
ver: rpa2
title: 'Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General,
  and Scalable Solution'
arxiv_id: '2411.14995'
source_url: https://arxiv.org/abs/2411.14995
tags:
- traces
- action
- domain
- state
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents SIFT, a scalable and sound method for learning
  lifted STRIPS models from action traces alone, without requiring state information.
  SIFT works by identifying "features" (predicates) that are consistently affected
  by specific action patterns across traces, using an efficient 2-CNF satisfiability
  test.
---

# Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution

## Quick Facts
- arXiv ID: 2411.14995
- Source URL: https://arxiv.org/abs/2411.14995
- Reference count: 40
- The paper presents SIFT, a scalable and sound method for learning lifted STRIPS models from action traces alone, achieving 100% verification success rates on test instances in most domains.

## Executive Summary
The paper introduces SIFT, a method for learning lifted STRIPS action models from action traces without requiring state information. SIFT identifies consistent features (predicates) by testing 2-CNF satisfiability constraints extracted from action patterns across traces. The approach scales to domains with hundreds of thousands of states and transitions, successfully learning both hidden predicates and redundant features from the maximal domain description. Evaluation on standard planning domains demonstrates both correctness and efficiency, with learned domains enabling 100% successful verification on test instances.

## Method Summary
SIFT learns lifted STRIPS models by identifying features (predicates) that are consistently affected by specific action patterns across action traces. The algorithm works by generating candidate features based on type information extracted from traces, then checking each feature's consistency using an efficient 2-CNF satisfiability test. For each feature-action pattern pair, SIFT collects constraints from traces where consecutive patterns must have opposite signs and fork patterns must have the same sign. These constraints form a 2-CNF formula that can be efficiently solved by checking implication chains. The method leverages type inference to dramatically reduce the search space, merging argument types based on which objects appear in the same argument positions across different actions. SIFT learns not only the minimal hidden domain but also redundant predicates from the maximal domain description, which can improve planning efficiency by reducing problem width.

## Key Results
- SIFT achieves 100% verification success rates on test instances in most domains, demonstrating both scalability and correctness
- The algorithm scales to domains with hundreds of thousands of states and transitions, learning domains like 8-puzzle and blocksworld efficiently
- Type-based feature generation reduces the search space from thousands of candidate features to tens, enabling practical learning
- Learning redundant predicates from Dmax reduces planning problem width, improving planning efficiency despite increasing predicate count

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SIFT identifies consistent features by reducing the problem to 2-CNF satisfiability.
- Mechanism: For each candidate feature f = ⟨k, B⟩, SIFT extracts pattern constraints from traces where consecutive patterns must have opposite signs and fork patterns must have the same sign. These constraints form a 2-CNF formula that can be efficiently solved by checking implication chains.
- Core assumption: Action effects must change the state (well-formed domain assumption), ensuring that consecutive patterns affecting the same feature have opposite signs.
- Evidence anchors:
  - [abstract] "SIFT works by identifying 'features' (predicates) that are consistently affected by specific action patterns across traces, using an efficient 2-CNF satisfiability test."
  - [section] "The problem of determining if a feature f is consistent with a set of (extended) traces T is in P and reduces to the problem of checking 2-CNF satisfiability."
- Break condition: If the domain contains actions that don't change state (violating the well-formed assumption), the 2-CNF reduction may produce incorrect results as consecutive patterns could have the same sign.

### Mechanism 2
- Claim: Type information from traces dramatically reduces the search space for candidate features.
- Mechanism: SIFT merges argument types based on which objects appear in the same argument positions across different actions. This typed feature generation creates features that respect the actual argument relationships observed in the traces, avoiding the need to test all possible feature combinations.
- Core assumption: Objects appearing in the same argument position across different actions share a common type that constrains the possible features.
- Evidence anchors:
  - [section] "The key idea to make the learning approach computationally feasible and to avoid the enumeration of features is the extraction of type information about the action arguments from the traces."
  - [section] "Simple calculations that follow from the arities of these actions, show that 14 action patterns a[t] of arity two can be formed from these actions, and thus 214 − 1 = 16,383 features. If types are taken into account... the number of (typed) binary features f becomes 7 × (22 − 1) = 21"
- Break condition: If the training traces don't provide enough diversity in argument positions, type merging may be incomplete, leading to overly conservative feature generation that misses valid features.

### Mechanism 3
- Claim: The learned domain generalizes by learning not just the hidden predicates but also redundant predicates from the maximal domain description Dmax.
- Mechanism: SIFT learns all features that are consistent with the traces, including those representing redundant predicates from Dmax. These redundant predicates capture additional state information that can reduce problem width and improve planning efficiency, even though they're not strictly necessary for solving the problem.
- Core assumption: The traces are sufficient to determine all valid features in Dmax, and these features provide meaningful additional constraints beyond the minimal hidden domain.
- Evidence anchors:
  - [section] "All these predicates are correct but redundant, and roughly correspond to derived predicates that can be tracked with action effects."
  - [section] "One consequence of this 'expansion' in the number of predicates is on the width of problems... with the 'derived' predicate in Dmax that tracks the location of the object being held, the width reduces to 1."
- Break condition: If the traces are insufficient or contain dead-ends (like in basic Grid and Sokoban), the algorithm may learn many non-valid features that don't generalize, leading to poor verification rates.

## Foundational Learning

- Concept: 2-CNF satisfiability and implication graphs
  - Why needed here: SIFT's core consistency test reduces to checking 2-CNF satisfiability by verifying that no implication chain creates a contradiction (p → ¬p).
  - Quick check question: Given patterns A, B, C with constraints A ≠ B, B = C, and C ≠ A, is the feature consistent? (Answer: No, because A → B → C → ¬A creates a contradiction)

- Concept: Type inference and unification
  - Why needed here: SIFT needs to efficiently generate candidate features by identifying which argument positions in different actions can bind to the same type of object, avoiding the exponential explosion of testing all possible features.
  - Quick check question: If object o1 appears as argument 1 in action pick and argument 2 in action drop, what type relationship exists between these arguments? (Answer: They share a common type that can be used to generate features like pick[1] and drop[1])

- Concept: Domain feature vs hidden feature distinction
  - Why needed here: Understanding that SIFT learns features from the maximal domain description Dmax, not just the minimal hidden domain, explains why the learned domains may contain redundant predicates that improve planning efficiency.
  - Quick check question: If the hidden domain has 2 dynamic predicates but SIFT learns 26 features, what does this tell us about the relationship between the learned domain and the hidden domain? (Answer: The learned domain includes redundant predicates from Dmax that capture additional state information)

## Architecture Onboarding

- Component map: Input processor -> Type inference engine -> Feature generator -> Consistency checker -> Domain constructor -> Verifier
- Critical path: Traces -> Type inference -> Feature generation -> Consistency checking -> Domain construction -> Verification
- Design tradeoffs: 
  - Exhaustive feature testing vs. typed feature generation (accuracy vs. efficiency)
  - Learning minimal vs. maximal domains (simplicity vs. planning efficiency)
  - Using full state graphs vs. plain traces (completeness vs. scalability)
- Failure signatures:
  - Low verification rates suggest insufficient or biased training traces
  - Long consistency checking times indicate too many candidate features
  - Learned domains with many redundant predicates suggest the algorithm is working but the traces are incomplete
- First 3 experiments:
  1. Run SIFT on the 8-puzzle domain with full state graph input to verify it learns the 2 hidden predicates plus redundant ones
  2. Test SIFT on a simple domain like blocksworld with 3 operators using only plain traces to verify the type inference works
  3. Verify that SIFT fails on a domain with non-changing state actions to confirm the well-formed assumption is necessary

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can SIFT be extended to handle noisy or incomplete action traces, and what theoretical guarantees could be maintained under such conditions?
- Basis in paper: [explicit] The paper mentions that a direct extension involves making the learning approach robust to noisy inputs, suggesting that rather than pruning a feature when found inconsistent with a trace, it could be pruned when inconsistent with k traces.
- Why unresolved: The paper only briefly touches on the idea of handling noisy data and does not provide a detailed methodology or theoretical analysis of how the algorithm would perform under such conditions.
- What evidence would resolve it: A detailed study showing the performance of SIFT with noisy or incomplete traces, including metrics on accuracy, robustness, and any theoretical guarantees under such conditions.

### Open Question 2
- Question: Can SIFT be adapted to learn action models over more expressive languages than STRIPS with negation, such as those with conditional effects or quantifiers, and what challenges would arise?
- Basis in paper: [explicit] The paper discusses the need for an extension to learn models over languages more expressive than STRIPS with negation, particularly for learning from traces obtained from simulators or real settings where such expressiveness might be required.
- Why unresolved: The paper does not explore the theoretical or practical challenges of extending SIFT to handle more expressive action languages, nor does it provide any experimental results in this direction.
- What evidence would resolve it: Experimental results showing the adaptation of SIFT to learn models in a more expressive action language, along with an analysis of the challenges encountered and the effectiveness of the adaptation.

### Open Question 3
- Question: What is the impact of learning "redundant" features on the planning performance, and how can these features be identified and pruned without losing generalization ability?
- Basis in paper: [explicit] The paper notes that SIFT learns redundant predicates from the maximal domain description Dmax, which can reduce planning problem width but also increase the number of predicates.
- Why unresolved: While the paper acknowledges the existence of redundant features, it does not explore their impact on planning performance or provide methods for identifying and pruning them effectively.
- What evidence would resolve it: An analysis of planning performance with and without redundant features, including experiments that identify which features are redundant and demonstrate the effects of pruning them on both learning accuracy and planning efficiency.

## Limitations

- SIFT critically depends on the well-formed domain assumption that all actions change the state, which may not hold in domains with conditional effects or no-op actions
- The algorithm may struggle with domains containing dead-end states or insufficient trace diversity, leading to poor verification rates
- Learning redundant predicates from Dmax creates unnecessarily complex domain models that may obscure the underlying minimal structure

## Confidence

- High confidence in the 2-CNF satisfiability mechanism and its correctness proof
- Medium confidence in type inference's ability to sufficiently constrain the feature search space
- Medium confidence in the generalization claims, given the mixed performance across different domain types

## Next Checks

1. Test SIFT on a domain with explicit no-op actions to verify it fails gracefully when the well-formed assumption is violated
2. Compare the planning efficiency of learned domains with minimal vs. maximal feature sets on problems of varying width
3. Evaluate SIFT's performance on domains with partial observability or incomplete action effects to assess robustness to trace quality