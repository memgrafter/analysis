---
ver: rpa2
title: Towards Neural Network based Cognitive Models of Dynamic Decision-Making by
  Humans
arxiv_id: '2407.17622'
source_url: https://arxiv.org/abs/2407.17622
tags:
- human
- phishing
- email
- memory
- emails
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces neural network-based models to capture human\
  \ decision-making in dynamic environments, building on the Instance-Based Learning\
  \ (IBL) framework. The authors propose two attention-based models\u2014Token-Level\
  \ Personalized Memory Integrated Model (TL-PMIM) and Instance-Level Personalized\
  \ Memory Integrated Model (IL-PMIM)\u2014that use past experiences (memory instances)\
  \ and current situations to predict human decisions."
---

# Towards Neural Network based Cognitive Models of Dynamic Decision-Making by Humans

## Quick Facts
- arXiv ID: 2407.17622
- Source URL: https://arxiv.org/abs/2407.17622
- Reference count: 18
- Primary result: Neural network models outperform traditional IBL and GPT3.5 in representing human decision-making in dynamic environments

## Executive Summary
This paper introduces neural network-based cognitive models for human decision-making in dynamic environments, specifically phishing detection and cybersecurity attack decisions. The authors propose two attention-based models - TL-PMIM and IL-PMIM - that integrate personalized memory instances with current situations to predict human decisions. These models demonstrate superior fidelity compared to traditional Instance-Based Learning models and GPT3.5, particularly in high-data scenarios, while maintaining interpretability through attention mechanisms.

## Method Summary
The paper proposes two neural network models built on the Instance-Based Learning framework: TL-PMIM (Token-Level Personalized Memory Integrated Model) and IL-PMIM (Instance-Level Personalized Memory Integrated Model). These models use past experiences stored as memory instances and combine them with current situation representations to predict human decisions. TL-PMIM fine-tunes Llama 2 7B using LongLora with specific hyperparameters, while IL-PMIM uses an attention-layer-based architecture with all-mpnet-base-v1 for encoding. The models are evaluated on two datasets - phishing email detection and Insider Attack Game - and compared against IBL and GPT3.5 baselines using fidelity metrics.

## Key Results
- TL-PMIM achieves the highest fidelity in representing human decision-making patterns
- IL-PMIM provides optimal balance between model expressiveness and interpretability
- Neural models outperform traditional IBL and GPT3.5 baselines, especially in high-data scenarios
- Both models successfully capture individual human behavior patterns in dynamic decision-making tasks

## Why This Works (Mechanism)
The models work by integrating personalized memory instances with current situation representations through attention mechanisms. TL-PMIM leverages token-level processing with fine-tuned language models to capture nuanced patterns in decision-making, while IL-PMIM uses instance-level attention to weigh relevant past experiences. This approach combines the interpretability of memory-based models with the expressiveness of neural networks, allowing the models to learn complex decision patterns while maintaining some explainability through attention weights.

## Foundational Learning
1. Instance-Based Learning (IBL): Memory-based approach storing past experiences to inform decisions
   - Why needed: Provides baseline for comparison and establishes framework for memory integration
   - Quick check: Verify similarity functions correctly retrieve relevant past instances

2. Attention Mechanisms: Neural components that weigh importance of different inputs
   - Why needed: Enables models to focus on relevant memory instances and current situation features
   - Quick check: Examine attention weight distributions for interpretability

3. Fine-tuning Language Models: Adapting pre-trained models to specific tasks
   - Why needed: Leverages existing language understanding for decision-making modeling
   - Quick check: Monitor training loss and validation accuracy during fine-tuning

## Architecture Onboarding
Component map: Raw Data -> Preprocessing -> Memory Storage -> Attention Layer -> Decision Output

Critical path: The attention mechanism that combines memory instances with current situation representation is the most critical component, as it determines how past experiences influence present decisions.

Design tradeoffs: TL-PMIM trades interpretability for expressiveness by using fine-tuned language models, while IL-PMIM balances both by using attention weights to show memory influence. The choice between them depends on whether prediction accuracy or explainability is prioritized.

Failure signatures: Poor performance may indicate issues with memory retrieval (similarity functions not finding relevant instances), attention mechanism not properly weighting memories, or insufficient fine-tuning causing TL-PMIM to underperform.

First experiments: 1) Verify IBL baseline implementation with test similarity functions, 2) Check TL-PMIM fine-tuning convergence on small subset, 3) Validate attention weight distributions in IL-PMIM make intuitive sense

## Open Questions the Paper Calls Out
### Open Question 1
Can the proposed neural network models effectively generalize to real-world dynamic decision-making scenarios with significantly more complex and noisy environments than those tested in the paper? The paper's experiments are limited to controlled datasets, and the authors themselves point out that expanding to more complex, real-world environments is beyond the scope of a single paper.

### Open Question 2
How do the proposed models handle out-of-distribution scenarios, particularly when encountering novel situations that significantly differ from the training data? The authors note that IBL performs better in out-of-distribution scenarios, likely due to its limited model capacity, while the neural network models show a drop in performance in low-data phishing scenarios.

### Open Question 3
Can the interpretability of the IL-PMIM model be enhanced to provide more granular insights into the decision-making process, beyond just the attention weights? The authors highlight that IL-PMIM offers a balance between expressiveness and interpretability, but do not explore methods to further enhance this interpretability or provide more detailed explanations of the model's decisions.

## Limitations
- The exact preprocessing pipeline for converting raw email and game state data into model inputs is not fully specified
- Limited discussion of potential biases in the datasets or how model performance might vary across different demographic groups
- Analysis focuses primarily on prediction accuracy rather than exploring the psychological validity of learned representations

## Confidence
High confidence: The neural architecture descriptions, training procedures, and evaluation methodology are clearly specified and technically sound
Medium confidence: The claims about model interpretability through attention weights and memory retrieval patterns are supported, but the depth of psychological insight gained is not fully explored
Medium confidence: Performance comparisons with baselines are well-documented, though the paper could benefit from more extensive ablation studies

## Next Checks
1. Implement and compare multiple similarity function variants for the IBL baseline to understand sensitivity to distance metrics and determine optimal parameter settings
2. Conduct cross-validation experiments with different data splits and sample sizes to assess model robustness and identify potential overfitting patterns
3. Perform ablation studies on the attention mechanisms and memory retrieval components to quantify their individual contributions to overall model performance