---
ver: rpa2
title: 'Diversify, Rationalize, and Combine: Ensembling Multiple QA Strategies for
  Zero-shot Knowledge-based VQA'
arxiv_id: '2406.12746'
source_url: https://arxiv.org/abs/2406.12746
tags:
- answer
- knowledge
- rationale
- strategy
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of knowledge-based visual question\
  \ answering (K-VQA), where questions often require the integration of multiple reasoning\
  \ strategies beyond simple image captioning. The proposed method, REACT, dynamically\
  \ ensembles multiple QA strategies by generating three types of decision contexts\u2014\
  image captions, short-form knowledge, and long-form knowledge\u2014for each question."
---

# Diversify, Rationalize, and Combine: Ensembling Multiple QA Strategies for Zero-shot Knowledge-based VQA

## Quick Facts
- arXiv ID: 2406.12746
- Source URL: https://arxiv.org/abs/2406.12746
- Authors: Miaoyu Li; Haoxin Li; Zilin Du; Boyang Li
- Reference count: 20
- Achieves 2.8% and 4.7% gains on OK-VQA and A-OKVQA over state-of-the-art frozen LLM baselines

## Executive Summary
This paper introduces REACT, a method for zero-shot knowledge-based visual question answering that ensembles multiple QA strategies. REACT generates three types of decision contexts (image captions, short-form knowledge, and long-form knowledge) for each question, producing answer candidates from each context. The method then generates two complementary rationales for each candidate and uses an LLM to select the final answer. Experiments demonstrate significant improvements over state-of-the-art frozen LLM baselines on two major K-VQA benchmarks.

## Method Summary
REACT addresses the challenge of knowledge-based visual question answering by dynamically ensembling multiple QA strategies. For each question, the system generates three distinct decision contexts: an image caption context, a short-form knowledge context, and a long-form knowledge context. Each context independently produces an answer candidate. The method then generates two types of rationales for each candidate - an automatic rationale (generated post-hoc) and a mechanistic rationale (based on predefined strategies). An LLM uses these rationales to select the final answer from the candidates.

## Key Results
- Achieves 2.8% gain over state-of-the-art frozen LLM baselines on OK-VQA dataset
- Achieves 4.7% gain over state-of-the-art frozen LLM baselines on A-OKVQA dataset
- Ablation studies confirm the effectiveness of both strategy ensemble and rationale-guided answer selection

## Why This Works (Mechanism)
The method works by diversifying the knowledge sources and reasoning strategies available for answering questions, then using rationales to guide the final answer selection. By generating multiple answer candidates from different contexts (image captions, short knowledge, long knowledge), the system captures different aspects of the question-answering process. The two rationale types provide complementary perspectives - automatic rationales explain the answer generation process while mechanistic rationales ground the reasoning in predefined strategies. This combination allows the LLM to make more informed final selections.

## Foundational Learning
- **Knowledge-based VQA**: Requires external knowledge beyond visual information
  - Why needed: Questions often require reasoning that cannot be solved from images alone
  - Quick check: Can the method handle questions requiring common sense knowledge?
- **Multi-strategy ensemble**: Combines different reasoning approaches
  - Why needed: Different questions benefit from different knowledge sources and reasoning types
  - Quick check: Does the method improve performance when using multiple strategies versus single strategy?
- **Rationale generation**: Creates explanations for answer choices
  - Why needed: Helps the LLM understand why certain answers were generated
  - Quick check: Are the rationales coherent and relevant to the question?
- **LLM-based answer selection**: Uses language models to choose among candidates
  - Why needed: Provides a flexible mechanism for integrating multiple perspectives
  - Quick check: Does the LLM selection improve over simple voting or averaging?

## Architecture Onboarding

Component Map:
Image -> Caption Context -> Answer Candidate
Image + Question -> Short Knowledge Context -> Answer Candidate
Image + Question -> Long Knowledge Context -> Answer Candidate
Answer Candidate + Question -> Automatic Rationale
Answer Candidate + Question -> Mechanistic Rationale
All Candidates + Rationales -> LLM Selector -> Final Answer

Critical Path:
Question + Image → Three Context Generation → Three Answer Candidates → Two Rationales Each → LLM Selection → Final Answer

Design Tradeoffs:
- Uses frozen LLMs rather than fine-tuned models for zero-shot generalization
- Balances between simple captioning and complex knowledge retrieval
- Combines automatic and mechanistic rationales for complementary guidance

Failure Signatures:
- Circular reasoning if automatic rationales simply rationalize pre-existing answers
- Limited generalization if mechanistic strategies don't cover novel question types
- LLM selection bias if one context type consistently dominates

First Experiments:
1. Test with synthetic questions where ground truth rationales are known
2. Evaluate individual context performance before ensembling
3. Compare rationale quality using human evaluation metrics

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Automatic rationale generation may introduce circularity by rationalizing pre-existing answers
- Mechanistic rationales are constrained by fixed strategy sets and may not generalize
- No comparison against other ensemble or multi-strategy approaches to isolate REACT's specific contributions

## Confidence
Medium confidence in the main claim of improved K-VQA performance due to:
- Statistical significance of reported gains
- Concerns about rationale generation methodology and potential circularity
- Uncertainty about whether improvements stem from rationale-guided selection or ensembling in general

## Next Checks
1. Conduct ablation studies isolating the contribution of automatic versus mechanistic rationale by testing variants that use only one rationale type or random selection between them
2. Test the method with different LLM backbones (beyond GPT-4) to assess sensitivity to the choice of selector model
3. Implement a human evaluation to determine whether the selected rationales actually explain the answer choices rather than simply rationalizing them post-hoc