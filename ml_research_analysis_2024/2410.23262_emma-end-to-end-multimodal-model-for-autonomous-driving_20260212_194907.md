---
ver: rpa2
title: 'EMMA: End-to-End Multimodal Model for Autonomous Driving'
arxiv_id: '2410.23262'
source_url: https://arxiv.org/abs/2410.23262
tags:
- driving
- emma
- road
- autonomous
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EMMA (End-to-End Multimodal Model for Autonomous driving) maps
  raw camera data directly into planner trajectories, 3D object detections, and road
  graph elements using a multimodal language model. It treats all inputs and outputs
  as natural language text, enabling joint training of multiple driving tasks.
---

# EMMA: End-to-End Multimodal Model for Autonomous Driving

## Quick Facts
- arXiv ID: 2410.23262
- Source URL: https://arxiv.org/abs/2410.23262
- Authors: Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan
- Reference count: 40
- Key outcome: EMMA achieves state-of-the-art end-to-end planning performance with L2 error of 0.29 m at 1s horizon on nuScenes

## Executive Summary
EMMA (End-to-End Multimodal Model for Autonomous driving) is a generalist autonomous driving system that maps raw camera data directly into planner trajectories, 3D object detections, and road graph elements using a multimodal language model. The model treats all inputs and outputs as natural language text, enabling joint training of multiple driving tasks. On nuScenes, EMMA achieves state-of-the-art end-to-end planning performance, while on the camera-primary WOD benchmark it demonstrates competitive 3D object detection capabilities.

## Method Summary
EMMA fine-tunes multimodal large language models (like Gemini) using task-specific prompts where sensor inputs, navigation instructions, and ego vehicle status are represented as text tokens. The model generates outputs including planner trajectories, 3D object detections, and road graph elements, all encoded in text format. Chain-of-thought reasoning is employed to enhance explainability and performance through hierarchical driving rationale generation. The model is co-trained across planning, detection, and road graph tasks using a mixture of task-specific prompts, with sampling ratios determined by dataset sizes.

## Key Results
- Achieves L2 error of 0.29 m at 1s horizon on nuScenes end-to-end planning benchmark
- Demonstrates competitive 3D object detection precision and recall on camera-primary WOD benchmark
- Shows improvements across all three domains (planning, detection, road graph) through co-training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating all driving tasks as natural language enables joint optimization across perception, planning, and reasoning
- Mechanism: Language representations encode spatial and temporal relationships needed for driving decisions
- Core assumption: Text representations can capture necessary spatial relationships
- Evidence: Abstract and section text describing language representation of all inputs/outputs
- Break condition: If spatial relationships require higher precision than text can provide

### Mechanism 2
- Claim: Chain-of-thought reasoning improves planning quality through explicit reasoning steps
- Mechanism: Hierarchical driving rationale (scene description, critical objects, behavior description, meta decisions) before trajectory prediction
- Core assumption: Explicit reasoning steps improve decision quality
- Evidence: Abstract and section text on chain-of-thought reasoning benefits
- Break condition: If reasoning adds overhead without quality improvement

### Mechanism 3
- Claim: Co-training across multiple driving tasks improves performance through knowledge transfer
- Mechanism: Joint training allows tasks to benefit from shared representations
- Core assumption: Driving tasks are complementary and benefit from shared representations
- Evidence: Abstract and section text on improvements through co-training
- Break condition: If task interference degrades performance

## Foundational Learning

- **Multimodal language models**: Why needed - enables leveraging pre-trained world knowledge and reasoning capabilities; Quick check - What advantages do pre-trained multimodal language models offer versus training from scratch?
- **Chain-of-thought reasoning**: Why needed - generates explicit reasoning steps improving explainability and performance; Quick check - How does hierarchical driving rationale structure contribute to better planning?
- **Joint optimization across tasks**: Why needed - enables learning shared representations benefiting multiple tasks; Quick check - What risks arise from co-training multiple driving tasks?

## Architecture Onboarding

- **Component map**: Camera input → Visual encoding → Multimodal fusion → Chain-of-thought reasoning → Trajectory prediction → Control signals
- **Critical path**: Camera input → Visual encoding → Multimodal fusion → Chain-of-thought reasoning → Trajectory prediction → Control signals
- **Design tradeoffs**: Language vs. specialized representations (flexibility vs. precision), joint vs. separate training (knowledge transfer vs. complexity), chain-of-thought vs. direct prediction (quality vs. latency)
- **Failure signatures**: Inconsistent predictions across tasks, over-reliance on chain-of-thought causing slow inference, degraded performance on non-co-trained tasks
- **First 3 experiments**: 1) End-to-end planning only for baseline, 2) Add chain-of-thought reasoning comparison, 3) Joint training with detection measurement

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the optimal training ratio among end-to-end planning, 3D object detection, and road graph estimation tasks? The paper states optimal ratio depends on task complexity, inter-task correlations, and transferability, but doesn't specify exact ratios.
- **Open Question 2**: How does EMMA compare to specialized models in complex 3D spatial reasoning scenarios like dense urban environments? The paper acknowledges limitations in 3D spatial reasoning but lacks specific comparisons.
- **Open Question 3**: What key factors contribute to performance improvement with chain-of-thought reasoning, and how can these be optimized? The paper identifies driving meta-decision and critical object identification as significant but lacks detailed analysis.

## Limitations

- Offline evaluation only without closed-loop testing in realistic driving simulators
- Text-based spatial representation may introduce precision bottlenecks for high-speed driving
- Substantial computational requirements without full characterization of inference latency or hardware needs

## Confidence

- **High confidence**: State-of-the-art end-to-end planning performance on nuScenes (L2 error of 0.29 m at 1s horizon)
- **Medium confidence**: Effectiveness of chain-of-thought reasoning for planning quality (limited ablation studies)
- **Medium confidence**: Benefits of co-training across driving tasks (relative performance gains without statistical significance)
- **Low confidence**: Safety and robustness in complex, rare scenarios (lacks quantitative safety metrics)

## Next Checks

1. **Closed-loop simulation testing**: Implement EMMA in realistic driving simulator with dynamic agents and sensor noise to measure performance degradation compared to offline benchmarks

2. **Precision sensitivity analysis**: Systematically vary coordinate encoding precision (1-4 decimal places) to identify thresholds where planning accuracy and safety margins meaningfully degrade

3. **Cross-task interference study**: Design controlled experiments comparing isolated vs. joint task training to quantify performance trade-offs and identify optimal task mixing ratios