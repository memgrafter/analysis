---
ver: rpa2
title: 'Less is More: High-value Data Selection for Visual Instruction Tuning'
arxiv_id: '2403.09559'
source_url: https://arxiv.org/abs/2403.09559
tags:
- data
- instruction
- visual
- task
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates data redundancy in visual instruction tuning
  datasets and proposes a novel data selection approach called TIVE. The authors find
  that a small subset of high-value data can achieve comparable performance to using
  the full dataset.
---

# Less is More: High-value Data Selection for Visual Instruction Tuning

## Quick Facts
- **arXiv ID:** 2403.09559
- **Source URL:** https://arxiv.org/abs/2403.09559
- **Reference count:** 40
- **Primary result:** A novel data selection approach called TIVE achieves comparable performance to full-data fine-tuning using only 7.5% of visual instruction tuning data

## Executive Summary
This paper investigates data redundancy in visual instruction tuning datasets and proposes TIVE (Task-level and Instance-level Value Estimation), a novel data selection approach. The authors find that a small subset of high-value data can achieve comparable performance to using the full dataset. TIVE estimates task-level and instance-level value using gradient-based influence functions, then selects representative instances based on these values. Experiments on LLaVA-1.5 show that TIVE using only 7.5% of the data achieves comparable average performance to the full-data fine-tuned model across seven benchmarks, even surpassing it on four benchmarks. The approach also outperforms other data selection methods.

## Method Summary
TIVE is a data selection approach that reduces redundancy in visual instruction tuning by identifying high-value instances. It works in two stages: first estimating task-level values by computing average gradient norms across all instances within each task, then estimating instance-level values by measuring cosine similarity between an instance's gradient vector and the average gradient vector of its task. The method uses a reference model trained on a small data subset to compute gradients only on key parameter matrices (projection layers and output layer). Task proportions are determined based on task-level values, and representative instances are selected within each task based on instance-level values. A sigmoid function with hyperparameter λ normalizes the final instance weights to balance effectiveness and diversity.

## Key Results
- TIVE achieves comparable average performance to full-data fine-tuning across seven benchmarks using only 7.5% of the data
- The approach surpasses the full-data fine-tuned model on four out of seven benchmarks
- TIVE outperforms other data selection methods in both effectiveness and diversity of the selected subset

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gradient-based influence functions can estimate task-level value by measuring the average gradient norm of instances within a task.
- **Mechanism:** The authors compute the average gradient norm for all instances within each task, using gradients from key parameter matrices (projection layers and output layer). Tasks with larger average gradient norms are considered to have higher task-level value because they induce larger parameter updates.
- **Core assumption:** Larger gradient norms correlate with greater contribution to model performance.
- **Evidence anchors:** [abstract] "we first estimate the instance influence score on its corresponding task, and the task difficulty score, based on the gradient-based influence functions"; [section 3.2] "we only calculate the gradient norms on the important parameter matrices, i.e. the linear layers connecting the visual encoder and LLM (projection layers), and the output layer of the LLM"
- **Break condition:** If noise or mislabeled data causes abnormally high gradient norms, this mechanism would overvalue those instances.

### Mechanism 2
- **Claim:** Instance-level value can be estimated by measuring cosine similarity between an instance's gradient vector and the average gradient vector of its task.
- **Mechanism:** For each instance, the cosine similarity is calculated between its gradient vector (concatenation of vision-language connection layer and output layer gradients) and the average gradient vector of all instances in the same task. Higher similarity indicates the instance is more representative of the task.
- **Core assumption:** Instances with gradients more similar to the task average are more representative and thus more valuable for learning the task.
- **Evidence anchors:** [abstract] "we calculate the similarity between each instance's gradient vector and the average gradient vector of all instances from a target task, for distinguishing the most representative instances"; [section 3.3] "the data value for an instances from Di is calculated as: vi_s = cos(g(s), 1/|Di| * Σ s'∈Di g(s'))"
- **Break condition:** If task has high internal diversity, average gradient may not represent any individual instance well.

### Mechanism 3
- **Claim:** Combining task-level and instance-level values with a sigmoid function creates a balanced sampling strategy that accounts for both task importance and instance representativeness.
- **Mechanism:** The authors multiply task-level value (vt_i) and instance-level value (vis) to estimate overall instance value, then apply a sigmoid function with hyperparameter λ to normalize and control the distribution of sampling weights.
- **Core assumption:** Multiplying task and instance values appropriately weights both dimensions, and sigmoid normalization prevents extreme values from dominating.
- **Evidence anchors:** [abstract] "we leverage the two kinds of scores to determine the task proportion within the selected visual instruction subset, and select high-value instances for each task, respectively"; [section 3.4] "we multiply the instance-level and task-level values, to estimate the value of the instance, considering its belonged task... Then, we utilize a sigmoid function to normalize the instance weights"
- **Break condition:** If λ is set too high or too low, the sampling distribution may become too peaked or too uniform, respectively.

## Foundational Learning

- **Concept:** Gradient-based influence functions
  - **Why needed here:** The core mechanism for estimating both task-level and instance-level values relies on computing gradients to measure influence on model parameters.
  - **Quick check question:** What specific parameter matrices does the method compute gradients for, and why are these matrices considered representative of the whole model?

- **Concept:** Cosine similarity for vector comparison
  - **Why needed here:** Instance-level value estimation requires measuring similarity between gradient vectors to determine representativeness.
  - **Quick check question:** How is the cosine similarity calculated between an instance's gradient vector and its task's average gradient vector?

- **Concept:** Data selection via weighted sampling
  - **Why needed here:** The final step involves selecting representative instances based on computed values, requiring understanding of weighted sampling strategies.
  - **Quick check question:** What role does the hyperparameter λ play in the sigmoid function used for normalizing instance weights?

## Architecture Onboarding

- **Component map:** Reference model training -> Compute gradients -> Estimate task-level values -> Estimate instance-level values -> Determine task proportions -> Select instances -> Final subset
- **Critical path:** Reference model → Compute gradients → Estimate task-level values → Estimate instance-level values → Determine task proportions → Select instances → Final subset
- **Design tradeoffs:** Computing gradients for all parameters would be more accurate but computationally expensive; the authors choose to compute gradients only for key parameter matrices. Using sigmoid normalization balances between effectiveness and diversity but requires tuning λ.
- **Failure signatures:** Poor performance on downstream tasks despite using selected subset; extreme imbalance in task proportions in final selection; minimal improvement when increasing data size beyond certain threshold.
- **First 3 experiments:**
  1. Implement gradient computation on projection layers and output layer, verify gradient norms vary meaningfully across tasks
  2. Implement cosine similarity calculation between instance gradients and task average gradients, visualize gradient distributions
  3. Implement data selection pipeline with varying λ values, evaluate impact on task proportion balance and downstream performance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the optimal ratio of instance-level to task-level data value weighting in TIVE?
- **Basis in paper:** [inferred] The authors mention using a hyperparameter λ to balance data effectiveness and diversity, but do not provide a definitive optimal value.
- **Why unresolved:** The paper only tests a few values of λ and finds one that works well, but does not exhaustively search the parameter space or provide theoretical justification for the optimal value.
- **What evidence would resolve it:** A comprehensive ablation study varying λ across a wide range and testing on multiple benchmarks would help determine the optimal balance between instance-level and task-level weighting.

### Open Question 2
- **Question:** How does TIVE perform on visual instruction datasets from different domains (e.g. medical imaging, satellite imagery)?
- **Basis in paper:** [explicit] The authors test TIVE on LLaVA-1.5 and Vision-Flan datasets, but do not explore other domains.
- **Why unresolved:** The paper focuses on general-purpose vision-language tasks and does not investigate the method's applicability to specialized domains with different data distributions and requirements.
- **What evidence would resolve it:** Evaluating TIVE on diverse visual instruction datasets from various domains (e.g. medical imaging, remote sensing, robotics) and comparing performance to the full dataset would demonstrate the method's generalizability.

### Open Question 3
- **Question:** Can TIVE be extended to handle multi-modal instruction data (e.g. incorporating audio or text-only instructions)?
- **Basis in paper:** [inferred] The paper focuses on visual instruction tuning and does not discuss incorporating other modalities.
- **Why unresolved:** The authors do not explore the possibility of extending their approach to handle multi-modal instruction data, which could be valuable for tasks requiring audio or text-only understanding in addition to vision.
- **What evidence would resolve it:** Modifying TIVE to incorporate gradient-based value estimation for additional modalities and evaluating its performance on multi-modal instruction datasets would demonstrate the feasibility of this extension.

## Limitations
- The evaluation is limited to LLaVA-1.5 and seven benchmarks, restricting generalizability to other VLMs or task types
- The gradient-based influence functions rely on assumptions about gradient norms and cosine similarity that are not directly validated
- Computational cost of calculating gradients for all instances is not discussed, though likely significant
- The choice of key parameter matrices for gradient computation is not fully justified

## Confidence
- **High confidence:** The empirical results showing TIVE achieves comparable performance with 7.5% data on the tested benchmarks
- **Medium confidence:** The theoretical justification for using gradient norms as value indicators, though correlation with task importance is not proven
- **Low confidence:** The generalizability of the approach to different VLMs, datasets, or task distributions

## Next Checks
1. **Ablation study on parameter selection:** Test TIVE with gradients computed on different sets of parameters (e.g., all parameters vs. only projection/output layers) to verify that the current selection is optimal for value estimation.
2. **Cross-model validation:** Apply TIVE to a different VLM architecture (e.g., LLaVA-2 or another state-of-the-art model) using the same datasets to test generalizability of the approach.
3. **Computational cost analysis:** Measure the actual computational overhead of TIVE's gradient-based influence function calculations and compare it against potential savings from using less data during fine-tuning.