---
ver: rpa2
title: What Are Step-Level Reward Models Rewarding? Counterintuitive Findings from
  MCTS-Boosted Mathematical Reasoning
arxiv_id: '2412.15904'
source_url: https://arxiv.org/abs/2412.15904
tags:
- language
- math
- reward
- reasoning
- thought
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the effectiveness of step-level reward
  models (SRMs) in mathematical reasoning tasks, focusing on whether natural language
  descriptions of thought processes are necessary for successful reward modeling.
  The researchers decompose each reasoning step into thought processes and mathematical
  expressions, training four different SRMs with varying input structures.
---

# What Are Step-Level Reward Models Rewarding? Counterintuitive Findings from MCTS-Boosted Mathematical Reasoning

## Quick Facts
- arXiv ID: 2412.15904
- Source URL: https://arxiv.org/abs/2412.15904
- Authors: Yiran Ma; Zui Chen; Tianqiao Liu; Mi Tian; Zhuo Liu; Zitao Liu; Weiqi Luo
- Reference count: 26
- One-line primary result: SRMs using only mathematical expressions perform comparably to full-context SRMs, achieving up to 39.64% accuracy on MATH and 85.82% on GSM8K during greedy search

## Executive Summary
This study investigates whether natural language descriptions of thought processes are necessary for effective step-level reward modeling in mathematical reasoning tasks. Through systematic experiments with four different SRM variants, the researchers demonstrate that mathematical expression-only reward models perform comparably to full-context models, challenging the assumption that natural language descriptions are essential for successful reward modeling. The findings suggest that mathematical expressions alone contain sufficient logical structure for evaluating reasoning quality, potentially enabling more efficient reward model architectures.

## Method Summary
The researchers decompose mathematical reasoning steps into thought processes (natural language descriptions) and mathematical expressions, then train four SRM variants: Full-Context (FC-SRM), Math-Only (MO-SRM), Single-Step Math-Only (SSMO-SRM), and Next-Thought (NT-SRM). MCTS is used to explore reasoning paths and collect preference data, with 500 iterations per problem and 6 candidate actions per expansion. SRMs are trained using contrastive learning on preference pairs, then evaluated through greedy search with beam size B=1. The study uses GSM8K and MATH datasets, training SRMs on DeepSeek-Math-7B-Base or Qwen2-7B with 2 instances and 8 A800 GPUs each.

## Key Results
- Math-only SRMs achieve 39.64% accuracy on MATH and 85.82% on GSM8K during greedy search
- FC-SRMs and MO-SRMs exhibit very similar performance, suggesting natural language descriptions are not necessary
- SRMs effectively evaluate logical coherence in mathematical language but struggle with natural language coherence
- MCTS-guided SRMs tend to encourage shorter reasoning paths, potentially due to insufficient exploitation

## Why This Works (Mechanism)

### Mechanism 1
Natural language descriptions of thought processes are not necessary for successful step-level reward modeling because SRMs can effectively evaluate mathematical reasoning quality using only mathematical expressions, as these expressions contain the essential logical structure needed for assessing correctness.

### Mechanism 2
SRMs are adept at assessing complex logical coherence present in mathematical language because mathematical expressions capture the logical relationships between operations, allowing SRMs to evaluate whether subsequent steps follow logically from previous ones.

### Mechanism 3
SRMs struggle with evaluating logical coherence in natural language because natural language descriptions contain implicit logical relationships that are difficult for SRMs to extract and evaluate without the explicit mathematical structure.

## Foundational Learning

- Concept: Markov Decision Process (MDP)
  - Why needed here: The mathematical reasoning process is modeled as an MDP where states represent reasoning steps and actions represent next thoughts
  - Quick check question: In the MDP formulation, what represents the "state" and what represents the "action" in mathematical reasoning?

- Concept: Monte Carlo Tree Search (MCTS)
  - Why needed here: MCTS is used to efficiently explore different reasoning paths and collect preference data for training SRMs
  - Quick check question: How does MCTS balance exploration and exploitation when searching for optimal reasoning paths?

- Concept: Contrastive learning for reward modeling
  - Why needed here: SRMs are trained using contrastive learning on preference pairs collected through MCTS
  - Quick check question: What is the key difference between training a reward model with preference pairs versus training with absolute reward values?

## Architecture Onboarding

- Component map: Agent LLM -> World Model LLM -> MCTS -> SRM -> Beam Search -> Final Answer
- Critical path: Agent → World Model → MCTS → SRM Training → Beam Search → Final Answer
- Design tradeoffs:
  - Input complexity vs. model performance (full context vs. math-only)
  - Exploration depth vs. computational cost in MCTS
  - Beam size vs. inference speed in greedy search
- Failure signatures:
  - SRM consistently rates incorrect paths highly
  - MCTS fails to explore diverse reasoning paths
  - Beam search gets stuck in local optima
- First 3 experiments:
  1. Compare FC-SRM vs MO-SRM performance on a small validation set
  2. Test MCTS with different exploration parameters on a simple math problem
  3. Run beam search with varying beam sizes to find optimal balance between accuracy and speed

## Open Questions the Paper Calls Out

### Open Question 1
What specific mechanisms cause the preference for shorter reasoning paths in MCTS-guided mathematical reasoning, despite MCTS not explicitly penalizing path length? The paper identifies this tendency but does not provide detailed analysis of why it occurs or what specific factors in the MCTS algorithm lead to this outcome.

### Open Question 2
How do SRMs evaluate logical coherence in mathematical expressions differently from their ability to evaluate logical coherence in natural language descriptions? While the paper demonstrates this difference in performance, it does not explain the underlying reasons why mathematical expressions are easier to evaluate for logical coherence than natural language descriptions.

### Open Question 3
What factors beyond the base model's mathematical ability influence the performance of SRMs in mathematical reasoning tasks? The paper notes that Llama-3-8B underperforms compared to other models despite its excellent mathematical capabilities, suggesting factors beyond mathematical ability are at play.

## Limitations

- Findings are primarily based on GSM8K and MATH datasets, which may not generalize to broader mathematical reasoning domains
- MCTS implementation details and prompt templates are not fully specified, making exact replication challenging
- The claim that natural language descriptions are unnecessary is based on performance parity rather than superiority

## Confidence

- High Confidence: Math-only SRMs achieve comparable performance to full-context SRMs on GSM8K and MATH datasets (39.64% and 85.82% accuracy respectively)
- Medium Confidence: SRMs effectively evaluate logical coherence in mathematical language but struggle with natural language coherence
- Low Confidence: Natural language thought process descriptions can be completely eliminated from mathematical reasoning reward modeling

## Next Checks

1. Evaluate the trained SRMs on a broader range of mathematical reasoning datasets beyond GSM8K and MATH to assess whether the performance parity between math-only and full-context SRMs holds across diverse problem types and difficulty levels.

2. Systematically vary the complexity of mathematical expressions in the training data to identify the threshold at which math-only SRMs begin to underperform full-context SRMs, helping to delineate the scope of the proposed approach.

3. Design a targeted evaluation framework to quantify SRM performance on natural language coherence specifically, using problems where the logical structure is primarily conveyed through language rather than mathematical expressions.