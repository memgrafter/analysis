---
ver: rpa2
title: Learning Visual Abstract Reasoning through Dual-Stream Networks
arxiv_id: '2411.19451'
source_url: https://arxiv.org/abs/2411.19451
tags:
- drnet
- reasoning
- learning
- abstract
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DRNet, a dual-stream network architecture
  designed to tackle Raven's Progressive Matrices (RPM) tasks, which assess abstract
  visual reasoning capabilities. Inspired by the two-stream hypothesis of visual processing,
  DRNet employs parallel CNN and ViT branches to capture local and spatial features,
  respectively.
---

# Learning Visual Abstract Reasoning through Dual-Stream Networks

## Quick Facts
- arXiv ID: 2411.19451
- Source URL: https://arxiv.org/abs/2411.19451
- Reference count: 20
- Key outcome: DRNet achieves state-of-the-art average performance across multiple RPM benchmarks, demonstrating superior generalization to out-of-distribution scenarios.

## Executive Summary
This paper introduces DRNet, a dual-stream network architecture designed to tackle Raven's Progressive Matrices (RPM) tasks, which assess abstract visual reasoning capabilities. Inspired by the two-stream hypothesis of visual processing, DRNet employs parallel CNN and ViT branches to capture local and spatial features, respectively. A reasoning module then fuses these features and extracts abstract rules to predict correct answers. DRNet achieves state-of-the-art average performance across multiple RPM benchmarks, including PGM and RAVEN datasets, demonstrating superior generalization to out-of-distribution scenarios. The dual-stream design enables distinct interpretations of input images, enhancing reasoning performance and rule representation clarity.

## Method Summary
DRNet is a dual-stream network that processes RPM problems using parallel CNN and ViT branches to extract local and spatial features, respectively. The model takes 16 images (8 context and 8 candidate answers) as input, each with shape (1, 80, 80). The CNN branch uses two ResBlocks while the ViT branch employs 12 layers with 8 heads. Features are fused using a learnable LIN operator, processed through a rule extractor module with two ResBlocks, and classified using an MLP. The model is trained with Adam optimizer (learning rate 3e-4, batch size 256, weight decay 1e-6) with early stopping after 20 epochs without validation loss improvement. Data augmentation includes vertical/horizontal flips with 0.3 probability.

## Key Results
- Achieves state-of-the-art average performance across PGM, RAVEN, I-RAVEN, and RAVEN-FAIR benchmarks
- Demonstrates up to 11.23% improvement in out-of-distribution generalization compared to existing models
- Successfully clusters rule representations by type (AND, OR, XOR) in visualization analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dual-stream architecture improves performance by capturing complementary local and spatial visual features, which are then fused to extract abstract rules.
- Mechanism: The CNN branch extracts local, object-level features while the ViT branch captures spatial relationships. Their fusion allows the model to reason both what objects are present and how they relate spatially.
- Core assumption: Local and spatial visual information are complementary and jointly necessary for abstract reasoning tasks.
- Evidence anchors:
  - [abstract] "DRNet employs parallel CNN and ViT branches to capture local and spatial features"
  - [section] "DRNet simulates object recognition through the ventral stream and spatial attention through the dorsal stream"
- Break condition: If the tasks do not require both local object recognition and spatial reasoning, the dual-stream advantage may diminish.

### Mechanism 2
- Claim: The reasoning module can extract discrete abstract rule representations that cluster by rule type, enabling better generalization.
- Mechanism: After feature fusion, the rule extractor module processes combinations of context and candidate images to infer relationships, producing embeddings that are clustered by rule category (e.g., AND, OR, XOR).
- Core assumption: Rule representations learned by the network can be meaningfully clustered and correspond to actual rule categories in the data.
- Evidence anchors:
  - [abstract] "extracts abstract rules and utilizing an multilayer perceptron (MLP) to make predictions"
  - [section] "The rule extractor module can identify and form abstract rule representations... clustered based on rule categories"
- Break condition: If the rule extractor fails to learn meaningful representations, the model's reasoning capability would collapse.

### Mechanism 3
- Claim: The dual-stream design enables distinct interpretations of input images, enhancing reasoning performance and rule representation clarity.
- Mechanism: By processing images through separate CNN and ViT streams, the model generates distinct feature representations that, when combined, provide a richer understanding than either stream alone.
- Core assumption: Distinct interpretations from parallel processing streams lead to better overall reasoning than single-stream approaches.
- Evidence anchors:
  - [abstract] "dual-stream design enables distinct interpretations of input images"
  - [section] "DRNet combines the advantages of local and spatial representations, allowing it to exhibit distinct interpretations"
- Break condition: If the fusion mechanism fails to properly combine the streams, the advantage of distinct interpretations may be lost.

## Foundational Learning

- Concept: Visual feature extraction using convolutional neural networks
  - Why needed here: The CNN branch needs to extract local, object-level features from RPM images
  - Quick check question: What is the primary function of convolutional layers in image processing?

- Concept: Self-attention mechanisms in transformers
  - Why needed here: The ViT branch uses self-attention to capture spatial relationships between image regions
  - Quick check question: How does self-attention differ from convolutional operations in processing visual information?

- Concept: Rule-based reasoning and representation learning
  - Why needed here: The reasoning module must learn to extract and represent abstract rules from visual patterns
  - Quick check question: What distinguishes rule-based reasoning from pattern recognition in machine learning?

## Architecture Onboarding

- Component map: Image → Dual encoder (CNN + ViT) → Integration → Rule extractor → Classifier → Answer prediction

- Critical path: Image → Dual encoder module (CNN branch with two ResBlocks and ViT branch with 12 layers and 8 heads) → Integration module (fusion using LIN operator) → Rule extractor (two ResBlocks) → Classifier (MLP) → Answer prediction

- Design tradeoffs:
  - Complexity vs. performance: Dual-stream adds parameters but improves reasoning
  - Interpretability vs. accuracy: Rule representations are more interpretable but may sacrifice some accuracy
  - Generalization vs. specialization: Architecture designed for broad generalization across RPM tasks

- Failure signatures:
  - Poor performance on spatial reasoning tasks indicates ViT branch issues
  - Weak object recognition suggests CNN branch problems
  - Inability to generalize indicates rule extractor or integration issues

- First 3 experiments:
  1. Replace the ViT branch with a second CNN branch to test if dual-stream advantage is specifically from having different architectures
  2. Remove the integration module to test if simple concatenation is sufficient
  3. Test the model on a simpler visual reasoning dataset to establish baseline capability before RPM tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the dual-stream architecture specifically improve generalization to out-of-distribution (OOD) scenarios compared to single-stream models?
- Basis in paper: [explicit] The paper states that DRNet achieves a notable enhancement of up to 11.23% in OOD scenarios, suggesting robust learning prowess inherent in the dual-stream architecture.
- Why unresolved: While the paper demonstrates improved performance, it does not provide a detailed explanation of the mechanisms by which dual-stream architecture enhances generalization.
- What evidence would resolve it: A detailed analysis of feature representations and rule extraction in both in-distribution and OOD scenarios, highlighting the differences and advantages of dual-stream processing.

### Open Question 2
- Question: What is the optimal configuration for the dual-stream network in terms of depth of ViT and size of CNN kernels?
- Basis in paper: [explicit] The paper explores different depths of ViTs and sizes of convolutional kernels, finding that certain configurations perform better than others.
- Why unresolved: The paper identifies optimal hyperparameters but does not explore the full range of possible configurations or explain why certain configurations are superior.
- What evidence would resolve it: A comprehensive study examining a wider range of ViT depths and CNN kernel sizes, with detailed analysis of their impact on model performance.

### Open Question 3
- Question: How does the rule extractor in DRNet learn discrete abstract rule representations, and what is the nature of these representations?
- Basis in paper: [explicit] The paper mentions that the rule extractor can identify and form abstract rule representations, and visualizations suggest these representations can be clustered based on rule categories.
- Why unresolved: The paper provides evidence of rule representation but does not delve into the learning process or the specific characteristics of these representations.
- What evidence would resolve it: An in-depth analysis of the rule extraction process, including insights into how the model identifies and categorizes rules, and a detailed examination of the learned representations.

## Limitations

- Evaluation focuses primarily on recognition accuracy without extensive ablation studies on rule representation quality
- Limited quantitative evidence comparing single-stream versus dual-stream performance
- Rule extraction mechanism lacks detailed analysis of what specific rules are being learned and their interpretability

## Confidence

- High confidence: The architectural design and implementation details of DRNet are well-specified and reproducible
- Medium confidence: The state-of-the-art performance claims on RPM benchmarks, though the comparison with baselines could be more comprehensive
- Low confidence: The interpretability and generalization claims regarding rule representations, as these are primarily qualitative assertions

## Next Checks

1. Conduct ablation studies comparing DRNet performance with single-stream variants (CNN-only and ViT-only) to quantify the dual-stream advantage
2. Perform systematic testing on out-of-distribution RPM problems with novel rule combinations to validate generalization claims
3. Implement rule visualization techniques to empirically verify that the rule extractor produces interpretable and meaningful abstract representations