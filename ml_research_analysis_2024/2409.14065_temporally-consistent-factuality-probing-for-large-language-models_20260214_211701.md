---
ver: rpa2
title: Temporally Consistent Factuality Probing for Large Language Models
arxiv_id: '2409.14065'
source_url: https://arxiv.org/abs/2409.14065
tags:
- temporal
- factuality
- consistent
- llms
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new task called TeCFaP (Temporally Consistent
  Factuality Probe) to evaluate the temporal reasoning capabilities of large language
  models (LLMs). The authors introduce a novel dataset called TEMP-COFAC, consisting
  of 66 diverse subject-relation pairs with 8 paraphrase samples each for forward
  and backward temporal associations.
---

# Temporally Consistent Factuality Probing for Large Language Models

## Quick Facts
- arXiv ID: 2409.14065
- Source URL: https://arxiv.org/abs/2409.14065
- Reference count: 40
- Primary result: Proposes TeCFaP task and CoTSeLF framework, achieving 90.4% improvement in temporally consistent factuality

## Executive Summary
This paper addresses the challenge of evaluating and improving temporal reasoning in large language models (LLMs). The authors introduce TeCFaP (Temporally Consistent Factuality Probe) as a new task to assess how well LLMs can maintain factual accuracy across time-sensitive queries. They create TEMP-COFAC, a novel dataset with 66 diverse subject-relation pairs and 8 paraphrase samples each for forward and backward temporal associations. The study reveals that most LLMs perform poorly on temporal factuality and consistency, with performance in the range of 0.95%-3.63% and 0%-2% respectively. To address this limitation, the authors propose CoTSeLF (Consistent-Time-Sensitive Learning Framework), which combines multi-task instruction tuning with consistent-time-sensitive reinforcement learning, achieving significant improvements across all evaluation metrics.

## Method Summary
The paper proposes CoTSeLF, a framework that combines multi-task instruction tuning (MT-IT) with consistent-time-sensitive reinforcement learning (CTSRL) to improve temporal factuality in LLMs. The method involves first training the model on a multi-task objective that optimizes both factual sentence completion and paraphrase consistency, then applying reinforcement learning with temporal reward signals. The approach is evaluated on the newly created TEMP-COFAC dataset using three metrics: temporal factuality, temporal consistency, and temporally consistent factuality.

## Key Results
- Most LLMs perform poorly on TeCFaP metrics in zero-shot setting (temporal factuality: 0.95%-3.63%, temporally consistent factuality: 0%-2%)
- CoTSeLF improves temporal factuality by 12.7%, temporal consistency by 10.9%, and temporally consistent factuality by 90.4% over baseline models
- CTSRLSmooth with α=0.66 achieves optimal performance for temporal factuality and temporally consistent factuality
- The framework demonstrates improved separation between positive and agnostic paraphrases in probabilistic space (0.18 nats improvement in KL divergence)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal factuality and consistency are improved by joint modeling of factual generation and paraphrase consistency
- Mechanism: The multi-task instruction tuning (MT-IT) optimizes two objectives: (1) maximizing p(ok1|sk1, ik1, c) for factual sentence completion, and (2) maximizing p(ok2|sk2, ik2) for binary paraphrase consistency
- Core assumption: The MT-IT framework can effectively learn both factual accuracy and consistency simultaneously without one task overwhelming the other
- Evidence anchors:
  - [abstract] "combining multi-task instruction tuning (MT-IT) with consistent-time-sensitive reinforcement learning (CTSRL)"
  - [section] "In k1, we apply a standard sentence completion task... Whereas k2 is a binary task predicting true or false if two sentences are paraphrased."
- Break condition: If the tasks are too imbalanced in complexity, the model may optimize for one task at the expense of the other, reducing overall effectiveness

### Mechanism 2
- Claim: CTSRL provides time-sensitive reward signals that improve temporal reasoning beyond binary classification
- Mechanism: CTSRLDiscrete and CTSRLSmooth provide rewards based on temporal proximity and consistency. CTSRLSmooth uses continuous negative rewards proportional to temporal distance from the correct answer
- Core assumption: The temporal axis can be modeled as a continuous space where proximity to the correct answer provides meaningful learning signals
- Evidence anchors:
  - [abstract] "consistent-time-sensitive reinforcement learning (CTSRL)"
  - [section] "For the temporal sensitivity task (k1), the positive reward score is assigned as a value equal to one in case of correctly generated output, and the negative reward score is the relative distance of the wrong prediction from the correct prediction in the temporal axis"
- Break condition: If the temporal distance metric doesn't align with actual temporal reasoning requirements, the model may learn incorrect temporal associations

### Mechanism 3
- Claim: Probabilistic space analysis shows improved separation between positive and agnostic paraphrases after CTSRL
- Mechanism: The model learns to generate more consistent probability distributions for paraphrases with identical intent (positive paraphrases) compared to those with different intent (agnostic paraphrases), measured through KL divergence
- Core assumption: Consistent intent should produce similar probability distributions, and this can be measured and optimized through divergence metrics
- Evidence anchors:
  - [section] "The KL divergence metric is widely used to compare probabilistic distributions. We calculate the KL divergence of subsequent word's probability distribution between positive and agnostic paraphrases"
  - [section] "It is evident from Table 7 that the CoTSeLF improves the average difference between the KL divergence scores of positive paraphrase and agnostic paraphrase by the value of 0.18 nats"
- Break condition: If the model learns to game the KL divergence metric without actually improving temporal reasoning, the apparent improvement may be superficial

## Foundational Learning

- Concept: Temporal reasoning in language models
  - Why needed here: The task requires understanding of temporal relationships between entities, which is a specialized form of reasoning that standard language models may not capture well
  - Quick check question: Can you explain the difference between forward and backward temporal associations in the context of the TeCFaP task?

- Concept: Multi-task learning and instruction tuning
  - Why needed here: The solution combines factual generation with consistency checking, requiring the model to learn multiple related tasks simultaneously
  - Quick check question: What are the two tasks being optimized in the MT-IT framework, and how do they complement each other?

- Concept: Reinforcement learning with custom reward functions
  - Why needed here: The CTSRL component requires designing reward functions that capture both temporal accuracy and consistency, which cannot be achieved through supervised learning alone
  - Quick check question: How does the CTSRLSmooth reward function differ from CTSRLDiscrete, and what temporal property does each capture?

## Architecture Onboarding

- Component map: Base LLM -> Multi-task instruction tuning (MT-IT) -> Consistent-time-sensitive reinforcement learning (CTSRL) -> Evaluation on TeCFaP metrics

- Critical path: Base LLM → MT-IT training → CTSRL fine-tuning → Evaluation on TeCFaP metrics

- Design tradeoffs:
  - Open vocabulary vs closed vocabulary setting: Open vocabulary is more general but harder; closed vocabulary provides more control but may not generalize
  - Discrete vs smooth CTSRL: Discrete is simpler but may not capture nuanced temporal relationships; smooth captures continuity but is more complex
  - Multi-task vs single-task: Multi-task captures both factuality and consistency but may be harder to optimize; single-task is simpler but may miss important interactions

- Failure signatures:
  - Low temporal consistency despite good temporal factuality: Model is generating correct answers but inconsistently across paraphrases
  - Good temporal consistency but poor temporal factuality: Model is consistent but consistently wrong
  - No improvement over baseline: MT-IT or CTSRL implementation may have issues; hyperparameters may need tuning

- First 3 experiments:
  1. Evaluate base LLM on TeCFaP metrics in zero-shot setting to establish baseline performance
  2. Apply MT-IT with context and evaluate improvement in temporal factuality and consistency
  3. Apply CTSRLDiscrete to MT-IT model and compare against baseline and MT-IT only models on all three TeCFaP metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CoTSeLF vary across different entity types in the TEMP-COFAC dataset?
- Basis in paper: [explicit] The paper mentions that CoTSeLF improves temporally consistent factuality by 90.4% over the baseline model, but it does not provide detailed performance metrics for different entity types
- Why unresolved: The paper does not provide a breakdown of CoTSeLF's performance across various entity types, such as movies, locations, games, etc.
- What evidence would resolve it: Detailed experimental results showing CoTSeLF's performance on each entity type in the TEMP-COFAC dataset, including metrics like temporal factuality, temporal consistency, and temporally consistent factuality for each entity type

### Open Question 2
- Question: What is the impact of the alpha (α) parameter in the CTSRLDiscrete formulation on the model's performance?
- Basis in paper: [explicit] The paper mentions that the optimal performance is achieved at α=0.66 for temporal factuality and temporally consistent factuality, but it does not explore the full range of α values or their impact on temporal consistency
- Why unresolved: The paper only presents results for three values of α (0.5, 0.66, and 0.75) and does not provide a comprehensive analysis of how different α values affect the model's performance across all metrics
- What evidence would resolve it: A detailed ablation study exploring a wider range of α values and their impact on temporal factuality, temporal consistency, and temporally consistent factuality

### Open Question 3
- Question: How does CoTSeLF perform on multilingual datasets or low-resource languages?
- Basis in paper: [explicit] The paper mentions that TEMP-COFAC is an English dataset and does not cover other languages, but it does not explore the potential of CoTSeLF on multilingual datasets or low-resource languages
- Why unresolved: The paper focuses solely on the English language and does not investigate the generalizability of CoTSeLF to other languages or its performance on low-resource language datasets
- What evidence would resolve it: Experiments evaluating CoTSeLF's performance on multilingual datasets or low-resource language datasets, including metrics like temporal factuality, temporal consistency, and temporally consistent factuality for each language

## Limitations

- The evaluation is based on a relatively small dataset (66 subject-relation pairs with 8 paraphrases each), which may not capture the full complexity of temporal reasoning across diverse domains
- The study focuses primarily on forward and backward temporal associations, potentially missing other temporal reasoning patterns such as simultaneous events or cyclical relationships
- The generalization of results to other temporal reasoning tasks beyond the specific TeCFaP framework remains uncertain

## Confidence

- **High Confidence**: The empirical improvements demonstrated by CoTSeLF over baseline models are statistically significant and well-documented through rigorous evaluation metrics
- **Medium Confidence**: The mechanism by which CTSRL improves temporal reasoning is theoretically sound, but the exact contribution of each component (MT-IT vs. CTSRL) to the overall performance gain is not fully isolated
- **Low Confidence**: The generalization of results to other temporal reasoning tasks beyond the specific TeCFaP framework remains uncertain, as does the performance on datasets with different temporal distributions or domain-specific knowledge

## Next Checks

1. Evaluate CoTSeLF on temporally diverse datasets from different domains (e.g., historical events, scientific processes, narrative timelines) to assess generalization beyond the TEMP-COFAC dataset
2. Conduct ablation studies to quantify the individual contributions of MT-IT and CTSRL components to overall performance, including testing CTSRLSmooth against CTSRLDiscrete in varied temporal reasoning scenarios
3. Test the framework's robustness to adversarial temporal perturbations by introducing subtle temporal inconsistencies in paraphrases and measuring the model's ability to maintain factual consistency