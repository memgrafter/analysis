---
ver: rpa2
title: A Large Language Model-based Framework for Semi-Structured Tender Document
  Retrieval-Augmented Generation
arxiv_id: '2410.09077'
source_url: https://arxiv.org/abs/2410.09077
tags:
- document
- procurement
- generation
- retrieval
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a framework that leverages retrieval-augmented
  techniques and large language models to automate tender document generation in the
  procurement domain. The system retrieves a suitable template from historical documents
  using a hybrid of embedding-based and vocabulary-based search, re-ranks results
  using purchase list similarity, and fills in user-specific details via smart tag
  instructions.
---

# A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation

## Quick Facts
- **arXiv ID:** 2410.09077
- **Source URL:** https://arxiv.org/abs/2410.09077
- **Reference count:** 9
- **Primary result:** Framework achieves 77.74 score vs. 12.55 for plain ChatGLM-4

## Executive Summary
This paper introduces a framework that leverages retrieval-augmented techniques and large language models to automate tender document generation in the procurement domain. The system retrieves a suitable template from historical documents using a hybrid of embedding-based and vocabulary-based search, re-ranks results using purchase list similarity, and fills in user-specific details via smart tag instructions. A procurement knowledge base built from GraphRAG is then used to refine procurement item lists and content. Experiments on a dataset of 1406 tender documents show that the full framework achieves a score of 77.74, significantly outperforming baselines such as plain ChatGLM-4 (12.55) or retrieval-augmented ChatGLM-4 (29.42). Ablation tests confirm that both the template retrieval and template filling modules are critical to performance.

## Method Summary
The framework combines three main components: template retrieval, template filling, and knowledge base enhancement. Template retrieval uses hybrid search combining embedding similarity and vocabulary matching, followed by re-ranking based on purchase list similarity. Template filling employs smart tags and an iterative prompt strategy to insert user-specific details. The knowledge base enhancement uses GraphRAG to build a procurement knowledge graph from historical documents, which is then used to refine procurement item lists and improve content accuracy. The system is evaluated on a dataset of 1,406 tender documents using an internal scoring metric.

## Key Results
- Full framework achieves 77.74 score, significantly outperforming baselines (12.55 for plain ChatGLM-4, 29.42 for retrieval-augmented ChatGLM-4)
- Both template retrieval and template filling modules are critical to performance, as shown by ablation tests
- The framework demonstrates improved accuracy and completeness compared to baseline approaches in tender document generation

## Why This Works (Mechanism)
The framework's effectiveness stems from its multi-stage approach that combines retrieval augmentation with LLM-based generation. By first retrieving a suitable template through hybrid search and re-ranking, the system ensures semantic relevance to the user's procurement needs. The template filling module then uses smart tags and iterative prompts to accurately insert user-specific details while maintaining document structure. Finally, the GraphRAG-based knowledge base enhancement provides domain-specific context that improves the accuracy of procurement item descriptions and ensures compliance with procurement standards.

## Foundational Learning
- **GraphRAG (Graph Retrieval-Augmented Generation)**: Combines graph-based knowledge representation with LLM generation to improve domain-specific reasoning; needed for building structured procurement knowledge from unstructured tender documents
- **Hybrid search (embedding + vocabulary-based)**: Combines semantic similarity with keyword matching for more robust retrieval; needed because procurement documents often contain domain-specific terminology that pure semantic search might miss
- **Smart tags for template filling**: Structured placeholders that guide LLM to insert specific information; needed to maintain document structure while allowing flexible content insertion
- **Re-ranking by purchase list similarity**: Secondary ranking step to ensure retrieved templates match the user's procurement scope; needed because initial hybrid search might retrieve semantically similar but contextually irrelevant templates
- **Iterative prompt strategy**: Progressive refinement approach for template filling; needed to handle complex tender documents with multiple sections and dependencies
- **Knowledge base construction from historical documents**: Creates domain-specific context for the LLM; needed because procurement terminology and requirements are highly specialized and domain-dependent

## Architecture Onboarding

**Component map:** User Query -> Hybrid Search -> Template Re-ranking -> Template Filling -> GraphRAG Knowledge Base Enhancement -> Final Tender Document

**Critical path:** The most critical path is the complete pipeline from user query through hybrid search, template re-ranking, template filling, and knowledge base enhancement. Any failure in this chain significantly impacts output quality.

**Design tradeoffs:** The framework trades computational complexity (multiple processing stages) for accuracy and compliance. The use of historical templates limits flexibility for novel procurement scenarios but ensures regulatory compliance.

**Failure signatures:** Poor template retrieval leads to irrelevant document structures; inadequate template filling results in missing or incorrect user-specific details; knowledge base gaps cause procurement item inaccuracies.

**First experiments:** 1) Run the framework with only embedding-based search (no vocabulary matching) to measure hybrid search contribution; 2) Test template filling with static vs. iterative prompts to quantify improvement; 3) Evaluate performance with and without GraphRAG knowledge base to measure its impact on content accuracy.

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size of 1,406 documents is relatively small for a domain-specific application with significant regional and category variations
- Evaluation relies on internal scoring system without external validation or standardized benchmarks
- GraphRAG knowledge base construction is described but not rigorously evaluated for accuracy or coverage
- System dependence on historical templates may limit ability to handle novel procurement requirements or regulatory changes

## Confidence
- **High:** Experimental comparison between full framework and ablated versions (template retrieval, template filling) is internally consistent and supports claimed performance gains
- **Medium:** Claim that framework significantly reduces manual effort and improves compliance is plausible given results, but lacks external validation or user studies to confirm practical impact
- **Low:** Generalizability to other procurement domains or regions is uncertain due to limited dataset diversity and lack of cross-domain testing

## Next Checks
1. Conduct a user study with procurement professionals to evaluate practical usability, compliance accuracy, and time savings of generated tender documents
2. Test framework on larger, more diverse dataset including documents from multiple regions, procurement categories, and regulatory frameworks
3. Perform ablation study specifically targeting GraphRAG knowledge base component to quantify its contribution to content accuracy and completeness