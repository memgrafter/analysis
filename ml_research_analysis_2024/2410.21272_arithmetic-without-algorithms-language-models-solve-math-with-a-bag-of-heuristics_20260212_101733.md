---
ver: rpa2
title: 'Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics'
arxiv_id: '2410.21272'
source_url: https://arxiv.org/abs/2410.21272
tags:
- heuristic
- neurons
- arithmetic
- each
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether large language models (LLMs) solve
  arithmetic reasoning tasks by learning generalizable algorithms or through memorization.
  The authors focus on basic arithmetic (addition, subtraction, multiplication, and
  division) as a representative task and use causal analysis to identify a circuit
  responsible for arithmetic calculations.
---

# Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics

## Quick Facts
- arXiv ID: 2410.21272
- Source URL: https://arxiv.org/abs/2410.21272
- Authors: Yaniv Nikankin; Anja Reusch; Aaron Mueller; Yonatan Belinkov
- Reference count: 40
- Key outcome: LLMs solve arithmetic using a "bag of heuristics" rather than generalizable algorithms or memorization

## Executive Summary
This study investigates whether large language models solve arithmetic reasoning tasks by learning generalizable algorithms or through memorization. Using causal analysis, the authors identify a circuit responsible for arithmetic calculations and examine individual neurons to understand the underlying mechanism. They discover that LLMs rely on a "bag of heuristics" approach where sparse sets of important neurons implement simple rules that identify specific numerical input patterns and output corresponding answers. This finding suggests that improving LLMs' mathematical abilities may require fundamental changes to training and architectures rather than post-hoc techniques like activation steering.

## Method Summary
The authors use causal analysis and activation patching to identify and evaluate the arithmetic circuit in pre-trained LLMs. They conduct linear probing to determine which components increase the probability of correct answers, then perform neuron-level analysis to decompose circuit MLP neurons into individual heuristic patterns. The methodology involves classifying neurons into heuristic types based on their activation patterns (such as range detection or pattern matching) and validating the "bag of heuristics" hypothesis through ablation experiments that systematically knock out neurons by heuristic type and by prompt association.

## Key Results
- LLMs rely on a "bag of heuristics" rather than robust algorithms or memorization for arithmetic reasoning
- Sparse sets of important neurons implement simple heuristics, each identifying specific numerical input patterns
- The combination of unrelated heuristic types explains most of the model's accuracy on arithmetic prompts
- This mechanism appears as the main source of arithmetic accuracy early in training and evolves gradually across the training trajectory

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large language models solve arithmetic by deploying a "bag of heuristics" rather than learning generalizable algorithms or memorizing training data.
- Mechanism: Sparse sets of important neurons implement simple heuristics, each identifying specific numerical input patterns and outputting corresponding answers. These heuristics are manifested in single MLP neurons in mid-to-late layers.
- Core assumption: Each neuron's activation pattern corresponds to identifiable numerical rules, and the combination of these rules explains most of the model's arithmetic accuracy.
- Evidence anchors:
  - [abstract] The study discovers that a sparse set of important neurons implements simple heuristics, each identifying specific numerical input patterns and outputting corresponding answers.
  - [section 3.2] We observe that very few neurons have a high effect; an example for layer l = 17 is shown in Figure 4a. Additionally, we notice the neurons with the highest effect are different between operators.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.479, average citations=0.0. Top related titles: Modular Arithmetic: Language Models Solve Math Digit by Digit, Arithmetic Reasoning with LLM: Prolog Generation & Permutation, Towards Safer Heuristics With XPlain.
- Break condition: If the heuristics fail to cover all possible arithmetic patterns or if their activation patterns cannot be consistently linked to specific numerical rules, the mechanism would break down.

### Mechanism 2
- Claim: The model's accuracy depends on the combination of several unrelated heuristic types, forming a "bag of heuristics" approach.
- Mechanism: The combination of independent heuristics—each activating according to rules based on the input values of operands—boosts the logits of corresponding result tokens. These small increases combine to promote the correct token as the final answer.
- Core assumption: The unordered combination of heuristic types is sufficient to explain most of the model's accuracy on arithmetic prompts.
- Evidence anchors:
  - [abstract] We find that the unordered combination of these heuristic types is the mechanism that explains most of the model's accuracy on arithmetic prompts.
  - [section 4.2] We show this through two ablation experiments. Knocking out neurons by heuristic type and knocking out neurons by prompt.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.479, average citations=0.0. Top related titles: Modular Arithmetic: Language Models Solve Math Digit by Digit, Arithmetic Reasoning with LLM: Prolog Generation & Permutation, Towards Safer Heuristics With XPlain.
- Break condition: If ablating heuristic neurons does not significantly drop accuracy on associated prompts or if the model can still achieve high accuracy without relying on this combination, the mechanism would fail.

### Mechanism 3
- Claim: The bag of heuristics mechanism appears as the main source of arithmetic accuracy early in training.
- Mechanism: Arithmetic heuristics appear throughout the model training, gradually converging towards the heuristics observed in the final checkpoint. The heuristics that are mutual with the last checkpoint explain most of the total heuristic behavior at each checkpoint.
- Core assumption: The causal link between a prompt's associated heuristics and its correct completion exists throughout training.
- Evidence anchors:
  - [abstract] Finally, we demonstrate that this mechanism appears as the main source of arithmetic accuracy early in training.
  - [section 5] We conduct an analysis of heuristic development across the training trajectory of the Pythia-6.9B model. We show arithmetic heuristics appear throughout the model training, gradually converging towards the heuristics observed in the final checkpoint.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.479, average citations=0.0. Top related titles: Modular Arithmetic: Language Models Solve Math Digit by Digit, Arithmetic Reasoning with LLM: Prolog Generation & Permutation, Towards Safer Heuristics With XPlain.
- Break condition: If a competing arithmetic mechanism exists mid-training that becomes vestigial in later checkpoints, or if the heuristics do not appear as the main mechanism from early on, the mechanism would be invalid.

## Foundational Learning

- Concept: Causal analysis and activation patching
  - Why needed here: To identify the subset of the model (a circuit) that explains most of the model's behavior for basic arithmetic logic and examine its functionality.
  - Quick check question: How can you determine which model components are most important for arithmetic calculations using activation patching?

- Concept: Linear probing
  - Why needed here: To understand the mechanism implemented by the circuit to promote the correct answer by searching for the specific circuit components that increase the probability of the correct answer.
  - Quick check question: What is the purpose of training a linear classifier to extract the correct answer from the output representation at each layer and position?

- Concept: Neuron-level analysis
  - Why needed here: To decompose circuit MLP neurons to individual neurons and understand how they contribute to the generation of correct answers.
  - Quick check question: How can you analyze the activation patterns of individual neurons to identify their role in arithmetic calculations?

## Architecture Onboarding

- Component map: Input tokens → Attention heads copy information to last position → Middle- and late-layer MLPs promote correct answer logits → Output token
- Critical path: Input tokens → Attention heads copy information to last position → Middle- and late-layer MLPs promote correct answer logits → Output token
- Design tradeoffs: The model relies on a combination of heuristics rather than a single robust algorithm, which may lead to imperfect accuracy but allows for efficient computation.
- Failure signatures: If the model fails to achieve perfect accuracy across all arithmetic prompts, it may be due to insufficient heuristics or imperfect recall of existing heuristics.
- First 3 experiments:
  1. Conduct activation patching experiments to identify the circuit components responsible for arithmetic calculations.
  2. Perform linear probing to determine which components increase the probability of the correct answer.
  3. Analyze individual neuron activations to identify heuristic patterns and classify neurons into heuristic types.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise mechanism by which Fourier space features contribute to arithmetic reasoning in LLMs, and how do they interact with the "bag of heuristics" approach?
- Basis in paper: [explicit] The paper mentions that Zhou et al. (2024) found that Fourier space features are used for addition in LLMs fine-tuned on arithmetic data, but claims this is only a partial view of the arithmetic mechanism.
- Why unresolved: The paper does not delve into the specifics of Fourier space feature utilization or its interplay with the heuristic approach.
- What evidence would resolve it: Experiments isolating the role of Fourier space features in arithmetic reasoning, and analyzing their interaction with the identified heuristics.

### Open Question 2
- Question: How do the "bag of heuristics" approach and the underlying neural architecture of LLMs contribute to the observed failures in arithmetic reasoning, and what architectural changes could mitigate these limitations?
- Basis in paper: [inferred] The paper identifies the "bag of heuristics" as the primary mechanism for arithmetic reasoning, but also acknowledges its limitations in achieving perfect accuracy and suggests that fundamental changes to training and architectures might be needed.
- Why unresolved: The paper does not provide concrete solutions or investigate the specific architectural factors that lead to these failures.
- What evidence would resolve it: Comparative studies of different neural architectures and training methodologies on arithmetic reasoning tasks, identifying architectural modifications that improve accuracy and robustness.

### Open Question 3
- Question: How does the "bag of heuristics" approach generalize to other reasoning tasks beyond arithmetic, and what are the limitations and potential pitfalls of this mechanism in broader contexts?
- Basis in paper: [explicit] The paper suggests that the "bag of heuristics" finding could apply to additional reasoning tasks, but does not explore this hypothesis.
- Why unresolved: The paper focuses specifically on arithmetic reasoning and does not investigate the generalizability of the findings to other domains.
- What evidence would resolve it: Experiments applying the heuristic analysis framework to other reasoning tasks (e.g., logical reasoning, spatial reasoning) and comparing the observed mechanisms across different domains.

## Limitations
- The classification of neurons into heuristic types depends on specific parameter thresholds that aren't fully specified
- The mechanism's generalizability beyond single-token arithmetic remains unproven
- The relatively small size of the data subset (200,000 prompts from 2 million) raises questions about potential sampling bias

## Confidence
- High confidence in the identification of the arithmetic circuit and its composition (attention heads + MLP layers)
- Medium confidence in the specific heuristic types and their classification methodology
- Medium confidence in the claim that this mechanism appears early in training
- Medium confidence that the "bag of heuristics" explains "most" of the model's accuracy

## Next Checks
1. **Cross-model validation**: Apply the same analysis pipeline to multiple model families (including smaller models) to verify the consistency of the heuristic-based mechanism across different architectures and scales.

2. **Training dynamics verification**: Track the emergence of individual heuristic types across more granular training checkpoints to confirm the progressive evolution pattern and identify any alternative mechanisms that might emerge and then become vestigial.

3. **Generalization stress test**: Test the model's performance on arithmetic problems with multi-token operands and results, as well as on number formats not seen during training, to determine the true limits of the heuristic-based approach.