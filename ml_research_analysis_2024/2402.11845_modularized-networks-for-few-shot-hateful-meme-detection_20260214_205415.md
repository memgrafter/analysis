---
ver: rpa2
title: Modularized Networks for Few-shot Hateful Meme Detection
arxiv_id: '2402.11845'
source_url: https://arxiv.org/abs/2402.11845
tags:
- meme
- hateful
- detection
- modules
- lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting hateful memes in
  a few-shot learning setting, where only a small number of labeled examples are available.
  The authors propose a method called Modularized Networks for Hateful Meme Detection
  (Mod-HATE), which leverages the compositionality of Low-rank adaptation (LoRA) modules
  to acquire essential reasoning skills for hateful meme detection.
---

# Modularized Networks for Few-shot Hateful Meme Detection

## Quick Facts
- arXiv ID: 2402.11845
- Source URL: https://arxiv.org/abs/2402.11845
- Reference count: 40
- Key outcome: Modularized Networks (Mod-HATE) achieves 58.0% accuracy in 4-shot and 57.4% in 8-shot settings on FHM dataset, outperforming traditional in-context learning methods.

## Executive Summary
This paper addresses the challenge of detecting hateful memes in few-shot learning scenarios where labeled data is scarce. The authors propose Mod-HATE, a modularized network architecture that leverages Low-Rank Adaptation (LoRA) modules trained on related tasks like hate speech detection and meme comprehension. These modules are composed using a module composer that assigns importance scores based on few-shot training examples, creating a flexible and efficient system for hateful meme detection that outperforms traditional in-context learning approaches while being more computationally efficient during inference.

## Method Summary
The Mod-HATE framework consists of three main components: task-specific LoRA modules, a module composer, and a base LLM. LoRA modules are first trained on related tasks such as hate speech detection, meme comprehension, and hateful meme interpretation. The module composer then evaluates these modules on few-shot training examples, assigning importance scores to determine how each module should contribute to the final hateful meme detection task. These composed LoRA modules are integrated with the base LLM to create the final modularized network. The approach leverages the compositionality of LoRA modules to acquire essential reasoning skills while maintaining computational efficiency during inference.

## Key Results
- Mod-HATE achieves 58.0% accuracy in 4-shot setting on FHM dataset
- Mod-HATE achieves 57.4% accuracy in 8-shot setting on FHM dataset
- Outperforms traditional in-context learning methods while being more computationally efficient during inference

## Why This Works (Mechanism)
The approach works by decomposing the complex hateful meme detection task into simpler, related sub-tasks. Each LoRA module specializes in a specific aspect of the detection process, such as understanding text context, interpreting visual elements, or recognizing hate speech patterns. The module composer acts as a gating mechanism, dynamically adjusting the contribution of each specialized module based on the specific characteristics of each input example. This modular composition allows the system to leverage knowledge from related domains while adapting to the specific requirements of hateful meme detection in a data-efficient manner.

## Foundational Learning
- **Low-Rank Adaptation (LoRA)**: A parameter-efficient fine-tuning technique that modifies pre-trained models by learning low-rank updates to the weight matrices, enabling efficient adaptation to new tasks while preserving the original model's knowledge.
- **Few-shot learning**: A learning paradigm where models are trained on very limited labeled examples (typically 4-32 samples per class), requiring the model to generalize from minimal supervision.
- **Module composition**: The process of combining multiple specialized modules, each trained on different tasks, to create a composite model that leverages diverse capabilities for complex tasks.
- **Importance scoring**: A mechanism for dynamically weighting the contributions of different modules based on their relevance to specific input instances, allowing the system to adapt its reasoning strategy per example.
- **In-context learning**: A prompting technique where models learn to perform tasks by conditioning on a few demonstration examples provided within the input prompt, without updating model parameters.
- **Hateful meme detection**: The task of identifying multimodal content that combines images and text to convey hateful messages, requiring understanding of both visual and textual elements and their interaction.

## Architecture Onboarding

**Component Map:** LLM <- Composed LoRA modules <- Module composer <- Task-specific LoRA modules (hate speech, meme comprehension, hateful meme interpretation)

**Critical Path:** Input meme → LoRA modules → Module composer → Weighted composition → LLM inference → Output prediction

**Design Tradeoffs:** The modular approach trades off potential end-to-end optimization for flexibility and efficiency. While a fully fine-tuned model might achieve better absolute performance, the modular composition allows for rapid adaptation to new tasks with minimal computational overhead and enables knowledge transfer from related domains.

**Failure Signatures:** Poor performance may arise from ineffective module composition (incorrect importance scores), insufficient diversity in the pre-trained LoRA modules, or fundamental limitations in the base LLM's ability to integrate the composed modules effectively for the hateful meme detection task.

**3 First Experiments:**
1. Evaluate individual LoRA modules on their respective tasks to verify their quality before composition
2. Test the module composer's ability to correctly assign importance scores using a validation set
3. Compare the composed model's performance against the base LLM and individual LoRA modules in isolation

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Performance levels (58.0% in 4-shot) appear modest and raise questions about practical utility
- Lack of comparison with state-of-the-art few-shot multimodal methods makes relative performance unclear
- Module composition mechanism lacks detailed validation of importance score assignment effectiveness
- Computational efficiency claims require more rigorous benchmarking and analysis

## Confidence

**High confidence:** The modular architecture design using LoRA modules for few-shot learning is technically sound and well-described

**Medium confidence:** The empirical results showing performance improvements over in-context learning, though the absolute performance levels raise questions about practical utility

**Low confidence:** Claims about computational efficiency advantages require more rigorous benchmarking and analysis

## Next Checks
1. Conduct comprehensive comparisons with recent few-shot multimodal methods like Flamingo, Perceiver, and other LoRA-based approaches on the same benchmarks
2. Perform ablation studies to validate the effectiveness of the module composer in assigning importance scores and the contribution of each individual LoRA module
3. Extend evaluation to include computational efficiency metrics including inference time, memory usage, and parameter counts across different few-shot settings