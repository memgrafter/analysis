---
ver: rpa2
title: 'LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor
  Components Identification'
arxiv_id: '2408.05404'
source_url: https://arxiv.org/abs/2408.05404
tags:
- learning
- metaphor
- data
- laida
- in-context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LaiDA, an LLM-based framework for metaphor
  components identification (MCI). It addresses the challenge of MCI, which is complex
  and context-dependent.
---

# LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification

## Quick Facts
- arXiv ID: 2408.05404
- Source URL: https://arxiv.org/abs/2408.05404
- Reference count: 26
- Ranked 2nd in NLPCC2024 Shared Task 9 with 93.21% accuracy

## Executive Summary
LaiDA is a linguistics-aware framework for metaphor components identification (MCI) that leverages large language models (LLMs) with in-context learning and data augmentation. The approach addresses the complexity and context-dependence of metaphor identification by combining supervised fine-tuning, simile pre-training, and a graph attention network for retrieving linguistically similar examples. LaiDA achieves strong performance on tenor and vehicle identification (97.20% and 97.32% accuracy respectively) but shows more difficulty with ground identification (94.14%). The framework demonstrates the effectiveness of integrating linguistic awareness with LLM capabilities for metaphor analysis tasks.

## Method Summary
LaiDA employs a multi-stage approach to metaphor components identification. First, it uses ChatGPT and supervised fine-tuning to create a high-quality dataset for metaphor analysis. The system then pre-trains on similes to establish foundational metaphorical understanding. A graph attention network encoder retrieves linguistically similar examples from the dataset, which are incorporated into prompts for fine-tuning the LLM. This linguistics-aware in-context learning approach allows the model to leverage relevant examples during inference, improving identification accuracy across tenor, vehicle, and ground components. The framework's design specifically addresses the context-dependent nature of metaphors by dynamically retrieving and incorporating similar linguistic patterns during the identification process.

## Key Results
- Ranked 2nd in NLPCC2024 Shared Task 9 with 93.21% overall accuracy
- Achieved 97.20% accuracy for tenor identification and 97.32% for vehicle identification
- Ground identification accuracy was lower at 94.14%, indicating more challenging recognition

## Why This Works (Mechanism)
The framework's effectiveness stems from its integration of linguistic awareness with LLM capabilities. By retrieving and incorporating linguistically similar examples during in-context learning, LaiDA provides the model with relevant contextual information that helps disambiguate metaphorical components. The supervised fine-tuning ensures the model learns from high-quality examples, while simile pre-training establishes foundational metaphorical understanding. The graph attention network's ability to identify and retrieve similar linguistic patterns allows the system to adapt to context-specific variations in metaphorical expression, addressing the inherent complexity and variability of metaphorical language.

## Foundational Learning
- Large Language Models (LLMs): Essential for handling the complexity of metaphor interpretation through their broad linguistic understanding
  - Why needed: Metaphors require understanding of nuanced relationships and context
  - Quick check: Can the model identify simple metaphors without additional training?
- Graph Attention Networks: Used for retrieving linguistically similar examples from the dataset
  - Why needed: Enables dynamic retrieval of relevant examples based on linguistic patterns
  - Quick check: Does the network correctly identify semantically similar phrases?
- In-context Learning: Allows the model to leverage retrieved examples during inference
  - Why needed: Provides contextual information without requiring parameter updates
  - Quick check: Does performance improve when similar examples are provided?

## Architecture Onboarding

**Component Map:**
Data Generation -> Supervised Fine-tuning -> Simile Pre-training -> Graph Attention Network -> In-context Learning Fine-tuning

**Critical Path:**
The most critical path is Graph Attention Network retrieval followed by in-context learning fine-tuning, as this is where the linguistics-aware adaptation occurs. Without effective retrieval of similar examples, the model cannot leverage the contextual information necessary for accurate metaphor component identification.

**Design Tradeoffs:**
The framework trades computational efficiency for accuracy by performing dynamic retrieval during inference. This approach requires maintaining a database of examples and computing similarity scores, but provides superior performance compared to static fine-tuning approaches. The reliance on ChatGPT for data generation introduces potential bias but ensures high-quality training data.

**Failure Signatures:**
- Poor retrieval from the graph attention network leads to irrelevant examples being incorporated
- Overfitting during supervised fine-tuning results in poor generalization to novel metaphors
- Inadequate simile pre-training causes foundational understanding gaps
- Insufficient example diversity in the dataset limits the system's ability to handle unconventional metaphors

**First Experiments:**
1. Test metaphor identification accuracy with and without graph attention network retrieval
2. Evaluate performance degradation when simile pre-training is removed
3. Measure the impact of example quality on overall identification accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on ChatGPT for data generation introduces potential bias and quality inconsistencies
- Lower accuracy for ground identification (94.14%) suggests difficulties with complex metaphorical relationships
- Evaluation based on single shared task limits generalizability across different domains and languages
- Dependence on linguistically similar examples may not capture all contextual nuances, particularly for novel metaphors

## Confidence

**High confidence:**
- The methodology for integrating linguistics-aware in-context learning with data augmentation is technically sound and well-documented

**Medium confidence:**
- The reported performance metrics and rankings, though based on a single evaluation
- The claim about superiority over baseline approaches, given limited comparative analysis

## Next Checks
1. Test LaiDA's performance on metaphor datasets from different languages and domains to assess cross-linguistic and cross-domain generalization
2. Conduct ablation studies to quantify the individual contributions of the graph attention network encoder, supervised fine-tuning, and in-context learning components
3. Evaluate the framework's robustness to adversarial metaphors and unconventional metaphorical expressions that deviate from standard linguistic patterns