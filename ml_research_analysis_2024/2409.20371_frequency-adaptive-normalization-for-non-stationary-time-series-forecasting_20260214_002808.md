---
ver: rpa2
title: Frequency Adaptive Normalization For Non-stationary Time Series Forecasting
arxiv_id: '2409.20371'
source_url: https://arxiv.org/abs/2409.20371
tags:
- frequency
- time
- series
- non-stationary
- normalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses non-stationary time series forecasting, where
  traditional normalization methods struggle with evolving trend and seasonal patterns.
  The proposed Frequency Adaptive Normalization (FAN) uses Fourier transform to identify
  and remove instance-specific dominant frequency components, effectively handling
  both trend and seasonal patterns.
---

# Frequency Adaptive Normalization For Non-stationary Time Series Forecasting

## Quick Facts
- arXiv ID: 2409.20371
- Source URL: https://arxiv.org/abs/2409.20371
- Reference count: 40
- 7.76% to 37.90% average MSE improvements over state-of-the-art normalization methods

## Executive Summary
This paper addresses non-stationary time series forecasting where traditional normalization methods struggle with evolving trend and seasonal patterns. The proposed Frequency Adaptive Normalization (FAN) uses Fourier transform to identify and remove instance-specific dominant frequency components, effectively handling both trend and seasonal patterns. A prediction module forecasts future frequency components to reconstruct the output. FAN is model-agnostic and was tested on four forecasting backbones across eight datasets, achieving significant performance gains compared to state-of-the-art normalization methods.

## Method Summary
FAN uses Fourier transform to identify principal frequency components that capture non-stationary information in time series. For each input sequence, it applies 1D DFT, selects top K dominant frequencies, and removes them to create a stationary residual signal. This residual is fed to the forecasting backbone model. A separate MLP predicts future values of the composite top K frequency components, which are then added back to reconstruct the final output. The method operates independently on each channel dimension and is designed to be compatible with existing forecasting architectures.

## Key Results
- Achieved 7.76% to 37.90% average MSE improvements compared to state-of-the-art normalization methods
- Outperformed previous methods (Statistical, TSBN, and trend-based normalization) on all eight benchmark datasets
- Demonstrated consistent improvements across four different forecasting backbones (DLinear, FEDformer, Informer, SCINet)
- Showed particular effectiveness on datasets with complex non-stationary patterns like ETT and Electricity

## Why This Works (Mechanism)

### Mechanism 1
Fourier transform identifies principal frequency components that capture both trend and seasonal patterns, making them more effective than statistical measures like mean and variance for non-stationary time series. The Fourier transform decomposes the input time series into its frequency components, allowing removal of top K dominant frequencies (both low-frequency trends and high-frequency seasonal patterns) to create a more stationary signal.

### Mechanism 2
The frequency-based normalization creates a more stationary signal by removing both trend and seasonal components simultaneously. By filtering out the top K frequency components from the Fourier domain, both low-frequency trends and high-frequency seasonal patterns are removed, providing more comprehensive stationarity improvement than methods addressing only trends through mean/variance adjustments.

### Mechanism 3
The prediction module can effectively forecast the evolution of frequency components from input to output. An MLP model predicts future values of composite top K frequency components for each dimension, explicitly modeling how frequency patterns evolve between input and output sequences rather than assuming unchanged trends.

## Foundational Learning

- **Fourier Transform and its properties**: Understanding how frequency decomposition works is essential for grasping why removing dominant frequencies creates a more stationary signal. Quick check: What does the Fourier transform convert a time-domain signal into, and why is this useful for identifying periodic patterns?

- **Stationarity in time series**: The core motivation is to transform non-stationary time series into more stationary ones for easier forecasting. Quick check: What statistical properties characterize a stationary time series, and why are non-stationary series more difficult to forecast?

- **Instance-wise normalization**: FAN is an instance-wise normalization method that operates independently on each input sequence. Quick check: How does instance-wise normalization differ from batch normalization, and what advantages does it offer for time series with varying statistical properties?

## Architecture Onboarding

- **Component map**: Input → Fourier Transform → Top K Frequency Selection → Inverse Fourier Transform → Residual Calculation → Backbone Model → Residual Frequency Prediction → Output Reconstruction
- **Critical path**: The frequency removal and reconstruction steps are critical - if the Fourier operations fail, the entire method breaks down
- **Design tradeoffs**: Choosing K involves balancing between removing enough non-stationary information versus preserving signal content; simpler prediction modules (MLP) versus more complex ones
- **Failure signatures**: Poor stationarity after normalization (checked via ADF test), significant performance degradation when prediction module is removed, sensitivity to K selection
- **First 3 experiments**:
  1. Verify Fourier transform implementation by checking that IDFT(DFT(x)) ≈ x for simple test signals
  2. Test stationarity improvement by comparing ADF test statistics before and after FAN normalization on synthetic non-stationary data
  3. Evaluate sensitivity to K by running with different K values on a simple dataset and observing performance changes

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal method for automatically determining the hyperparameter K for selecting principal frequency components in different time series datasets? The paper relies on a heuristic approach (10% of maximum amplitude) rather than a principled, data-driven method, and performance varies with different K values.

### Open Question 2
Can FAN be extended to handle non-sinusoidal periodic patterns such as square waves or other non-smooth waveforms? The current implementation relies entirely on Fourier transform, which has limitations for certain waveform types common in real-world time series.

### Open Question 3
How does FAN's performance scale with very long time series sequences beyond the tested 720-step horizon? The paper only tests up to 720 steps, leaving uncertainty about how the model performs for extremely long-term forecasting tasks.

## Limitations
- Performance depends heavily on accurate identification and prediction of dominant frequency components, which may not capture all forms of non-stationarity
- The method assumes non-stationary patterns can be effectively represented in the frequency domain, which may not hold for all time series types
- Selection of K is heuristic and may require dataset-specific tuning for different prediction horizons

## Confidence

- **Mechanism 1 (Fourier decomposition effectiveness)**: Medium confidence - theoretical basis is sound but lacks direct empirical validation in the corpus
- **Mechanism 2 (Stationarity improvement)**: Medium confidence - supported by spectral variance analysis but limited by lack of comprehensive stationarity tests
- **Mechanism 3 (Frequency prediction accuracy)**: Low confidence - relies on simplified MLP modeling without comparison to more sophisticated prediction methods

## Next Checks

1. Conduct comprehensive stationarity tests (e.g., ADF, KPSS) on synthetic non-stationary data before and after FAN normalization to verify the claimed improvement in stationarity

2. Perform ablation studies comparing FAN with pure frequency-based methods (only trend removal) versus pure statistical methods (only mean/variance adjustment) to isolate the contribution of the frequency-based approach

3. Test FAN's robustness to varying K values by systematically evaluating performance across different K selections on multiple datasets to establish sensitivity and optimal ranges