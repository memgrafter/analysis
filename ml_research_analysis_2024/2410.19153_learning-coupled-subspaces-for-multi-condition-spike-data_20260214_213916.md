---
ver: rpa2
title: Learning Coupled Subspaces for Multi-Condition Spike Data
arxiv_id: '2410.19153'
source_url: https://arxiv.org/abs/2410.19153
tags:
- data
- conditions
- distribution
- spike
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of analyzing high-dimensional
  spike train data recorded under multiple experimental conditions. Existing Gaussian
  process factor analysis (GPFA) models typically analyze each condition separately,
  ignoring potential correlations and shared structure across conditions.
---

# Learning Coupled Subspaces for Multi-Condition Spike Data

## Quick Facts
- arXiv ID: 2410.19153
- Source URL: https://arxiv.org/abs/2410.19153
- Authors: Yididiya Y. Nadew; Xuhui Fan; Christopher J. Quinn
- Reference count: 40
- Key outcome: Novel CS-GPFA model jointly analyzes neural data from multiple experimental conditions with improved accuracy and faster inference compared to separate GPFA models

## Executive Summary
This paper addresses the challenge of analyzing high-dimensional spike train data recorded under multiple experimental conditions. Traditional Gaussian process factor analysis (GPFA) models analyze each condition separately, ignoring potential correlations and shared structure across conditions. The authors propose a novel coupled subspaces GPFA (CS-GPFA) model that jointly analyzes neural data from multiple conditions by modeling loading weights as smooth functions over the condition space using Gaussian processes.

The key methodological contribution is the development of an efficient variational inference algorithm that leverages data augmentation to make the model conditionally conjugate. This allows for closed-form updates of the posterior distributions for all model variables, including the latent processes, loading weights, and dispersion parameters. Experiments on synthetic and real neural datasets demonstrate the effectiveness of CS-GPFA, achieving improved accuracy and faster inference compared to separate GPFA models for each condition.

## Method Summary
The CS-GPFA model extends traditional GPFA by representing loading weights as smooth functions over a continuous experimental condition space using Gaussian processes. The model assumes spike counts follow a negative-binomial distribution and employs data augmentation techniques to achieve conditional conjugacy, enabling efficient variational inference. Automatic relevance determination (ARD) with gamma priors is used to automatically determine the number of effective latent dimensions. The inference procedure uses an EM algorithm with variational E-steps that have closed-form updates for all model variables.

## Key Results
- CS-GPFA achieves improved accuracy and faster inference compared to separate GPFA models for each condition
- The model successfully predicts neural activity under previously unseen experimental conditions with faithful uncertainty estimates
- ARD automatically determines the correct number of latent dimensions in synthetic experiments
- Experiments demonstrate sample efficiency advantages over traditional GPFA approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint modeling of multiple experimental conditions captures shared latent structure that improves prediction and reduces sample complexity compared to separate GPFA models.
- Mechanism: The model represents loading weights as smooth functions over the condition space using Gaussian processes. This allows the model to share statistical strength across conditions by inferring a common set of latent processes that are modulated by condition-dependent weights.
- Core assumption: Experimental conditions can be represented as points in a continuous parameter space and that the mapping from conditions to neural responses is smooth over this space.
- Evidence anchors:
  - [abstract]: "CS-GPFA analyses data from multiple experimental conditions jointly (hence called 'coupled') by exploiting the parametric nature of the conditions."
  - [section 2.1]: "These methods, commonly referred to as latent variable models (LVMs), assume the dynamics of a neural population's activity lies in a low-dimensional latent subspace."
  - [corpus]: Weak. Related papers focus on GPFA for single conditions or non-smooth tensor decompositions. No direct evidence of joint multi-condition GPFA in corpus.
- Break condition: If condition-response mappings are discontinuous or conditions are not parametric (e.g., categorical without ordering), the GP smoothness assumption fails.

### Mechanism 2
- Claim: Data augmentation with Polya-Gamma and related transforms makes the negative-binomial likelihood conditionally conjugate, enabling efficient variational inference.
- Mechanism: The augmentation introduces auxiliary variables that transform the non-conjugate negative-binomial likelihood into a Gaussian likelihood over transformed variables. This allows closed-form updates for all model variables in the variational E-step.
- Core assumption: The integral identities from He et al. [2019] and Polson et al. [2013] can be applied to the negative-binomial likelihood to yield a conditionally conjugate augmented model.
- Evidence anchors:
  - [section 2.2]: "Nadew et al. [2024] leveraged this data augmentation technique to render the model conditionally conjugate which results in closed-form solutions for the conditional posteriors in the Negative-Binomial likelihood case."
  - [section 3.5]: "By recognizing term 1, Γ(Y(m)n,t + rn), as a normalization constant for a gamma distribution over a new variable τ(m)n,t..."
  - [corpus]: Moderate. The cited data augmentation work by Nadew et al. [2024] is in the corpus and provides the foundation.
- Break condition: If the integral identities cannot be applied (e.g., with different likelihood families) or if the augmented variables introduce computational instability.

### Mechanism 3
- Claim: Automatic relevance determination (ARD) with gamma priors on column precisions automatically determines the number of effective latent dimensions without cross-validation.
- Mechanism: The gamma prior on the diagonal entries of the column covariance matrix τ penalizes the total number of non-zero columns, encouraging sparsity in the weight matrices and effectively selecting relevant latent dimensions.
- Core assumption: The true latent dimensionality is smaller than the initial pool of dimensions, and the ARD prior can distinguish relevant from irrelevant dimensions.
- Evidence anchors:
  - [section 3.3]: "We do so by imposing a gamma prior p(τ) = ∏Dd=1 Γ(αd, βd), where αd and βd are correspond to the shape and rate parameters of the gamma distribution, over the diagonal entries of the column covariance τ in Eq. (6)."
  - [section 4.1]: "It showcases accurate reconstruction of the generative model... This matches the number of latent dimensions in the generative model, revealing the ARD feature in the model."
  - [corpus]: Weak. Related works mention ARD but don't provide direct evidence for this specific application to multi-condition GPFA.
- Break condition: If the true latent dimensionality is large or if the gamma prior is too restrictive, the model may underfit or fail to recover the correct dimensionality.

## Foundational Learning

- Concept: Gaussian Process Factor Analysis (GPFA)
  - Why needed here: CS-GPFA builds directly on GPFA by extending it to handle multiple experimental conditions. Understanding the original GPFA model is essential for grasping the coupling mechanism.
  - Quick check question: What is the key difference between classical factor analysis and GPFA in terms of temporal modeling?

- Concept: Data Augmentation for Non-Conjugate Models
  - Why needed here: The inference procedure relies on transforming the negative-binomial likelihood into a conditionally conjugate form via data augmentation. Without this, Bayesian inference would be intractable.
  - Quick check question: What integral identity is used to transform the logistic term in the negative-binomial likelihood?

- Concept: Variational Inference and Mean-Field Approximation
  - Why needed here: The model uses variational EM with mean-field assumption to approximate the posterior distribution of model variables. Understanding variational inference is crucial for implementing and debugging the algorithm.
  - Quick check question: In mean-field variational inference, what form does the optimal variational distribution for a variable take?

## Architecture Onboarding

- Component map: Data tensor Y -> Latent processes X -> Loading weights W -> Neural firing rates -> Spike counts
- Critical path: E-step (variational updates for all variables) → M-step (hyperparameter optimization) → convergence check
- Design tradeoffs:
  - Smooth vs. non-smooth weight functions: Smooth GP priors exploit condition structure but may oversmooth if conditions are not truly continuous
  - Number of latent dimensions: Larger D increases flexibility but computational cost and risk of overfitting
  - Negative-binomial vs. binomial likelihood: Negative-binomial handles overdispersion but adds dispersion parameters
- Failure signatures:
  - Poor test log-likelihood with increasing training data: May indicate overfitting or incorrect smoothness assumptions
  - ARD selecting too few or too many dimensions: May indicate prior misspecification or insufficient data
  - Slow convergence in variational updates: May indicate poor initialization or numerical instability in data augmentation
- First 3 experiments:
  1. Run on synthetic data with known ground truth to verify recovery of latent structure and automatic dimensionality selection
  2. Compare training and test log-likelihood on MC Maze data with varying number of training trials to assess sample efficiency
  3. Test prediction performance on unseen conditions by fitting on subset of conditions and evaluating log-likelihood on held-out conditions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of kernel function for the condition space affect the model's ability to capture complex relationships between experimental conditions?
- Basis in paper: [explicit] The paper mentions using a squared-exponential kernel for the condition space but also states that "any differentiable GP kernel could also be considered as an alternative."
- Why unresolved: The paper does not provide empirical comparisons of different kernel functions or analyze how the choice of kernel impacts model performance on real neural data.
- What evidence would resolve it: Experiments comparing CS-GPFA performance using different kernel functions (e.g., Matérn, periodic) on various neural datasets, analyzing how kernel choice affects predictive accuracy and model interpretability.

### Open Question 2
- Question: How does the model's performance scale with the number of experimental conditions and the dimensionality of the condition space?
- Basis in paper: [inferred] The paper discusses handling multiple experimental conditions but does not extensively explore how performance changes with increasing condition complexity or dimensionality.
- Why unresolved: While the MC Maze experiment uses 9 conditions, there is no analysis of performance with a larger number of conditions or higher-dimensional condition spaces.
- What evidence would resolve it: Systematic experiments varying the number of conditions (e.g., 10, 50, 100) and condition space dimensionality (e.g., 1D, 2D, 3D), measuring inference time, predictive accuracy, and model complexity.

### Open Question 3
- Question: How robust is the model to noise and uncertainty in the experimental condition labels?
- Basis in paper: [inferred] The model assumes precise knowledge of experimental conditions, but in practice, condition labels may have uncertainty or noise.
- Why unresolved: The paper does not explore scenarios where condition labels are imprecise or contain measurement errors.
- What evidence would resolve it: Experiments where true condition labels are perturbed with noise, comparing CS-GPFA performance with and without label uncertainty, potentially extending the model to handle probabilistic condition labels.

### Open Question 4
- Question: Can the model effectively handle experimental conditions that are qualitatively different rather than smoothly varying?
- Basis in paper: [explicit] The paper focuses on conditions that vary "smoothly" over a continuous space, but does not address discrete or qualitatively distinct conditions.
- Why unresolved: The current formulation assumes conditions can be represented as points in a continuous space, which may not apply to all experimental designs.
- What evidence would resolve it: Experiments applying CS-GPFA to datasets with discrete condition categories (e.g., different stimulus types, behavioral tasks), analyzing whether the smooth GP assumption over conditions remains valid or requires modification.

## Limitations
- The model assumes experimental conditions lie in a continuous parameter space with smooth mappings to neural responses, which may not hold for categorical conditions
- ARD mechanism for automatic dimensionality selection requires appropriate gamma prior specification that is not extensively validated
- Data augmentation approach introduces auxiliary variables that may affect numerical stability in practice

## Confidence

- **High confidence**: The mechanism of using GP priors over loading weights to capture shared structure across conditions is theoretically sound and well-supported by the mathematical formulation. The data augmentation approach for achieving conditional conjugacy follows established techniques in the literature.
- **Medium confidence**: The ARD mechanism for automatic dimensionality selection shows promise in synthetic experiments but requires more extensive validation on real neural datasets with known ground truth. The model's performance relative to separate GPFA models is demonstrated but could benefit from additional comparisons on diverse datasets.
- **Low confidence**: The specific implementation details for the Power-Truncated Normal approximation for dispersion parameters and exact initialization strategies are not fully specified, which could impact reproducibility.

## Next Checks
1. Test the model's performance when experimental conditions are categorical rather than continuous to evaluate robustness to condition space assumptions
2. Conduct systematic sensitivity analysis of ARD performance across different gamma prior specifications and true latent dimensionalities
3. Compare inference stability and convergence rates between CS-GPFA and separate GPFA models across datasets of varying sizes and noise levels