---
ver: rpa2
title: A Benchmark Time Series Dataset for Semiconductor Fabrication Manufacturing
  Constructed using Component-based Discrete-Event Simulation Models
arxiv_id: '2408.09307'
source_url: https://arxiv.org/abs/2408.09307
tags:
- time
- series
- values
- factory
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the need for publicly available benchmark datasets
  for developing machine learning models in semiconductor manufacturing, as data collection
  from actual factories is restricted. It proposes using discrete-event simulation
  models formalized in Parallel DEVS to generate such datasets.
---

# A Benchmark Time Series Dataset for Semiconductor Fabrication Manufacturing Constructed using Component-based Discrete-Event Simulation Models

## Quick Facts
- arXiv ID: 2408.09307
- Source URL: https://arxiv.org/abs/2408.09307
- Reference count: 34
- Key outcome: TFT model achieves R² = 0.9917 and MAPE = 0.0051 in predicting semiconductor factory throughput from simulation data

## Executive Summary
This paper addresses the challenge of developing machine learning models for semiconductor manufacturing by creating a publicly available benchmark dataset using discrete-event simulation. The authors use Parallel DEVS formalism to simulate a multi-stage Intel semiconductor fabrication factory, generating time series throughput data across various configurations. Baseline forecasting models (ARIMA, RNN, LSTM, TCN, TFT) are evaluated, with TFT achieving exceptional accuracy. PCA analysis reveals how factory configurations impact throughput characteristics, demonstrating the dataset's utility for ML development.

## Method Summary
The authors employ PDEVS-based discrete-event simulation models to generate time series data from a simulated Intel semiconductor fabrication factory. The MiniFab model represents single and multi-stage factories processing different product lots through six processing steps. Time series data is extracted by front-filling discrete event outputs, then feature extraction is performed using TsFresh. Baseline ML models (ARIMA, RNN, LSTM, TCN, TFT) are trained and evaluated on this dataset. PCA is applied to understand how factory configurations affect throughput patterns through extracted features like trend, skewness, and entropy.

## Key Results
- TFT model achieves R² = 0.9917 and MAPE = 0.0051 in predicting factory throughput
- PCA reveals factory configuration (uniform vs. sinusoidal wafer generation, repair states) significantly affects throughput characteristics
- Simulation-generated datasets can effectively support ML model development for semiconductor manufacturing
- Feature extraction and PCA analysis provide insights into how operational parameters influence throughput behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Discrete-event simulation models can generate benchmark datasets that replicate realistic semiconductor factory behaviors without exposing proprietary data.
- Mechanism: PDEVS-based simulation captures the event-driven nature of semiconductor manufacturing, allowing synthetic time series data to be produced for various factory configurations.
- Core assumption: The simulation model accurately represents real-world factory dynamics and interactions between machines.
- Evidence anchors: [abstract] time series dataset constructed from multi-stage Intel factory simulations; [section] lots processed through six steps from Diffusion to Lithography.
- Break condition: If the simulation model does not capture key stochastic behaviors or complex interdependencies, the generated dataset will fail to represent realistic factory dynamics.

### Mechanism 2
- Claim: Time series forecasting models can effectively predict factory throughput when trained on simulation-generated data.
- Mechanism: The dataset's temporal granularity and monotonic trend allow models to learn patterns in throughput over time, with TFT incorporating static covariates.
- Core assumption: Time series models can generalize from simulation data to real-world scenarios if the simulation sufficiently mimics actual factory conditions.
- Evidence anchors: [abstract] baseline models developed with TFT achieving R² = 0.9917 and MAPE = 0.0051; [section] choice based on large dataset size and monotonic nature.
- Break condition: If the simulation data lacks sufficient variability or fails to capture rare events, models trained on it may not perform well on real factory data.

### Mechanism 3
- Claim: PCA analysis of time series features reveals how factory configurations influence throughput behavior.
- Mechanism: Feature extraction quantifies temporal patterns and PCA reduces dimensionality to reveal dominant factors affecting throughput across configurations.
- Core assumption: Extracted time series features meaningfully represent underlying manufacturing dynamics and are sensitive to configuration changes.
- Evidence anchors: [section] PCA depiction for Linear Trend, Skewness, Lempel Ziv Complexity, Kurtosis, and Permutation Entropy; [section] PCA-Loadings plots indicate configuration impacts.
- Break condition: If the feature extraction process does not capture critical operational variables, the analysis will not provide actionable insights.

## Foundational Learning

- Concept: Discrete-Event System Specification (DEVS) formalism
  - Why needed here: DEVS provides the mathematical framework for modeling event-driven manufacturing systems, enabling accurate simulation of machine states and lot processing.
  - Quick check question: What are the core components of a PDEVS atomic model, and how do they interact during simulation execution?

- Concept: Time series forecasting models (ARIMA, RNN, LSTM, TCN, TFT)
  - Why needed here: These models are used to predict factory throughput from the generated dataset, with TFT uniquely handling both temporal and static covariate data.
  - Quick check question: How does TFT differ from traditional RNN or LSTM models in handling static covariates alongside temporal data?

- Concept: Feature extraction and PCA for time series
  - Why needed here: Feature extraction quantifies temporal patterns (trend, entropy, complexity), and PCA reduces dimensionality to reveal dominant factors affecting throughput across configurations.
  - Quick check question: Why might skewness and trend be dominant features in a monotonically increasing throughput time series?

## Architecture Onboarding

- Component map:
  PDEVS Factory Models (MiniFab single/multi-stage) -> DEVS-Suite Simulator -> Transducer Models -> CSV Data Storage -> Time Series Preprocessor -> Feature Extraction (TsFresh) -> ML Model Training (ARIMA, RNN, LSTM, TCN, TFT) -> Evaluation Metrics (MSE, R², MFE, MAPE)

- Critical path:
  1. Define factory configuration (lot sizes, machine count, repair rules)
  2. Execute PDEVS simulation via DEVS-Suite
  3. Collect throughput and state data via transducers
  4. Convert discrete-event output to time series (front-fill)
  5. Extract time series features (TsFresh)
  6. Train and evaluate ML models
  7. Analyze PCA loadings for configuration impact

- Design tradeoffs:
  - Simulation fidelity vs. computational cost: More detailed models increase realism but slow execution
  - Time series granularity vs. data size: Higher granularity improves temporal resolution but increases storage and processing demands
  - Model complexity vs. interpretability: TFT offers high accuracy but is harder to interpret than ARIMA

- Failure signatures:
  - Poor ML model performance: Likely due to insufficient simulation realism or missing critical operational features
  - High variance in throughput predictions: May indicate unmodeled stochastic behaviors or inadequate feature representation
  - PCA showing no clear configuration separation: Could mean features are not sensitive to configuration changes or too much noise

- First 3 experiments:
  1. Run single-stage MiniFab simulation with uniform wafer generation, no repair; verify time series conversion and basic ML model training
  2. Add repair state to same configuration; compare throughput variance and ML model performance
  3. Execute multi-stage cascade factory with sinusoidal wafer generation; analyze PCA loadings to identify dominant throughput-influencing features

## Open Questions the Paper Calls Out

- How does the accuracy of machine learning models trained on PDEVS simulation data compare to those trained on real-world semiconductor manufacturing data?
  - Basis in paper: [explicit] The paper states that data collection from actual factories is restricted due to proprietary constraints, and proposes using simulation data as an alternative.
  - Why unresolved: The paper does not provide a direct comparison between models trained on simulation data and those trained on real-world data, as the latter is not publicly available.
  - What evidence would resolve it: A comparative study using both simulation-generated and real-world data, with identical model architectures and evaluation metrics, would provide the necessary evidence.

- What is the impact of increasing the number of stages in the cascade factory model on the predictive accuracy of the time series models?
  - Basis in paper: [inferred] The paper discusses an 8-stage cascade model but does not explore the effects of varying the number of stages on model performance.
  - Why unresolved: The paper only presents results for an 8-stage model and does not investigate how model accuracy changes with different numbers of stages.
  - What evidence would resolve it: Conducting experiments with cascade models of varying numbers of stages (e.g., 4, 6, 10, 12) and comparing the predictive accuracy of the time series models would provide the necessary evidence.

- How sensitive are the time series models to changes in the repair state configuration of the factory?
  - Basis in paper: [explicit] The paper mentions that introducing a repair state increases the level of uncertainty in the data and includes different repair state configurations in the simulations.
  - Why unresolved: While the paper acknowledges the impact of repair states, it does not quantify how sensitive the models are to different repair state configurations.
  - What evidence would resolve it: A sensitivity analysis varying the repair state parameters (e.g., mean time between failures, repair duration) and measuring the impact on model accuracy would provide the necessary evidence.

## Limitations

- All validation is based on simulation data; no real factory data was used to verify model generalizability
- The proprietary nature of semiconductor manufacturing data prevents independent verification of simulation fidelity
- Time series preprocessing relies on front-filling, which may mask underlying stochastic behaviors
- Feature extraction and PCA analyses are conducted solely on simulated datasets

## Confidence

- Simulation-to-real transfer: Low (no evidence that models trained on simulation data perform well on actual factory data)
- ML model performance claims: Medium (high accuracy metrics are reported but only validated on simulation outputs)
- PCA configuration analysis: Medium (the analysis reveals patterns in simulated data but may not reflect real-world operational dynamics)

## Next Checks

1. Test TFT and other models on a small, anonymized real-world dataset from an actual semiconductor factory to assess simulation-to-real transfer
2. Compare time series features extracted from simulation data with those from real factory logs to validate feature relevance
3. Conduct sensitivity analysis by varying simulation parameters beyond those tested to identify potential overfitting to specific configurations