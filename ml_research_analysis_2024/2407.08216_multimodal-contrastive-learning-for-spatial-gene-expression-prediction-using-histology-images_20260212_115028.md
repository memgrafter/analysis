---
ver: rpa2
title: Multimodal contrastive learning for spatial gene expression prediction using
  histology images
arxiv_id: '2407.08216'
source_url: https://arxiv.org/abs/2407.08216
tags:
- expression
- gene
- spatial
- mclstexp
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces mclSTExp, a multimodal contrastive learning
  framework for predicting spatial gene expression from histology images. The method
  integrates spot-level gene expression data with spatial location information using
  a Transformer encoder, then fuses these features with image features through contrastive
  learning.
---

# Multimodal contrastive learning for spatial gene expression prediction using histology images

## Quick Facts
- arXiv ID: 2407.08216
- Source URL: https://arxiv.org/abs/2407.08216
- Reference count: 40
- mclSTExp achieved 23-32% higher Pearson correlation coefficients than existing methods for predicting gene expression from histology images

## Executive Summary
This study introduces mclSTExp, a multimodal contrastive learning framework for predicting spatial gene expression from histology images. The method integrates spot-level gene expression data with spatial location information using a Transformer encoder, then fuses these features with image features through contrastive learning. The model conceptualizes spots as "words" and employs self-attention mechanisms to capture spatial context. Evaluated on three datasets (breast cancer and skin squamous cell carcinoma), mclSTExp outperformed existing methods with 23-32% higher Pearson correlation coefficients for predicting gene expression. The approach also successfully identified cancer-specific overexpressed genes, immune-related genes, and spatial domains matching pathologist annotations.

## Method Summary
mclSTExp integrates spot-level gene expression data with spatial location information using a Transformer encoder, then fuses these features with image features through contrastive learning. The model conceptualizes spots as "words" and employs self-attention mechanisms to capture spatial context. The framework was evaluated on three datasets (breast cancer and skin squamous cell carcinoma) and demonstrated superior performance compared to existing methods, with 23-32% higher Pearson correlation coefficients for predicting gene expression.

## Key Results
- Achieved 23-32% higher Pearson correlation coefficients than existing methods for predicting gene expression
- Successfully identified cancer-specific overexpressed genes and immune-related genes
- Spatial domains identified by the model matched pathologist annotations

## Why This Works (Mechanism)
The method's effectiveness stems from its ability to leverage spatial context through self-attention mechanisms while integrating multimodal data (histology images and gene expression). By treating spots as "words" and using Transformer encoders, the model captures spatial relationships that are critical for accurate gene expression prediction. The contrastive learning framework enables effective fusion of heterogeneous data sources, allowing the model to learn meaningful representations that bridge histology images and spatial transcriptomics data.

## Foundational Learning
- **Transformer encoders**: Needed for capturing spatial context through self-attention mechanisms; quick check: verify attention weights focus on biologically meaningful spatial relationships
- **Contrastive learning**: Required for effective fusion of heterogeneous data sources (images and gene expression); quick check: confirm learned representations show improved alignment between modalities
- **Spatial transcriptomics**: Essential background for understanding spot-level gene expression data; quick check: ensure understanding of spot resolution and spatial resolution trade-offs

## Architecture Onboarding

**Component Map**
Histology Images + Spatial Location Data + Gene Expression Data -> Transformer Encoder -> Feature Fusion -> Contrastive Learning -> Gene Expression Prediction

**Critical Path**
Image preprocessing → Feature extraction → Spatial location encoding → Transformer encoding → Contrastive learning fusion → Prediction layer

**Design Tradeoffs**
The use of Transformer encoders provides powerful spatial context capture but increases computational complexity compared to simpler architectures. The contrastive learning approach requires careful balance of positive and negative samples for effective multimodal fusion.

**Failure Signatures**
Potential failure modes include poor generalization across tissue types, inability to capture long-range spatial dependencies, and sensitivity to noise in either image or gene expression data.

**First Experiments**
1. Ablation study removing spatial location information to assess its contribution
2. Testing on additional tissue types to evaluate generalizability
3. Sensitivity analysis to different gene expression levels (highly vs lowly expressed genes)

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability across different tissue types beyond breast cancer and skin squamous cell carcinoma remains untested
- Limited comparison with only one baseline method (GiniClust2)
- No error analysis showing where predictions fail or which genes are most challenging to predict

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Methodological framework and implementation | High |
| Performance claims based on current datasets | Medium |
| Biological interpretation of identified genes and spatial domains | Low |

## Next Checks
1. Test mclSTExp on additional tissue types and disease conditions to assess generalizability across different histological patterns and gene expression profiles
2. Conduct ablation studies to determine the relative contributions of the Transformer encoder, contrastive learning, and spatial location information to overall performance
3. Validate identified cancer-specific and immune-related genes through independent biological experiments or comparison with established gene expression databases to confirm biological relevance