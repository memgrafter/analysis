---
ver: rpa2
title: Teaching Smaller Language Models To Generalise To Unseen Compositional Questions
  (Full Thesis)
arxiv_id: '2411.16985'
source_url: https://arxiv.org/abs/2411.16985
tags:
- training
- datasets
- language
- answer
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The thesis explores whether smaller language models can effectively
  reason over unseen compositional questions, addressing limitations of large language
  models like latency, cost, and internet dependency. It proposes novel methods to
  distinguish memorization from generalization, establishes comprehensive baselines
  for smaller models, and introduces retrieval-augmented training datasets (RATD)
  to improve reasoning.
---

# Teaching Smaller Language Models To Generalise To Unseen Compositional Questions (Full Thesis)

## Quick Facts
- arXiv ID: 2411.16985
- Source URL: https://arxiv.org/abs/2411.16985
- Reference count: 0
- Smaller language models can match or outperform large models on compositional reasoning when provided with appropriate context and training

## Executive Summary
This thesis explores whether smaller language models can effectively reason over unseen compositional questions, addressing limitations of large language models like latency, cost, and internet dependency. The work proposes novel methods to distinguish memorization from generalization, establishes comprehensive baselines for smaller models, and introduces retrieval-augmented training datasets (RATD) to improve reasoning. The research develops a method for combining knowledge from two sources—Wikipedia retrieval and LLM-generated rationales—using a Rationale Ranking model to select and filter context components. Results demonstrate that smaller models can match or outperform large models when provided with appropriate context, showing their viability for reasoning tasks with constrained resources.

## Method Summary
The research trains smaller language models using a two-stage multitask approach. First, an Iterator system (Retriever, Reranker, Evidence Set Scorer) is trained on multi-hop datasets using Wikipedia paragraphs. Second, Reasoning Models are trained using RATD datasets constructed by retrieving contexts for training questions, combined with rationale generation from LLMs and scoring by a Rationale Ranking model. The system combines information from Wikipedia retrieval and LLM-generated rationales using various strategies (Naïve Concatenation, Max Score, etc.) to answer unseen compositional questions. The methodology explicitly addresses the memorization-generalization distinction through semantic similarity analysis and evaluates performance across multiple datasets including StrategyQA, CommonsenseQA, DROP, IIRC, ARC-DA, and Musique.

## Key Results
- Smaller models trained with RATD datasets show significant improvements in reasoning performance on compositional questions
- Combining Wikipedia retrieval and LLM-generated rationales outperforms single knowledge source approaches
- The system successfully distinguishes between memorization and generalization, with most test questions requiring genuine reasoning rather than pattern matching
- Different combination strategies (Naïve Concatenation, Max Score, etc.) provide varying levels of performance improvement depending on question type

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Smaller language models can reason over unseen compositional questions by utilizing retrieved context rather than relying on memorization
- Mechanism: The system trains reasoning models on diverse datasets including retrieval-augmented training datasets (RATD) that contain noisy contexts with partial evidence. This teaches the model to identify and weigh relevant information from imperfect sources
- Core assumption: The model can learn to reason effectively from partial or noisy information when trained with appropriate context diversity
- Evidence anchors: [abstract] "We show that the addition of novel retrieval-augmented training datasets (RATD) to the training regime of the Reasoning Model significantly improves results." [section] "RATDdatasetsareintendedtoimpartdiversereasoningstrate-gies, such as an ability to identify and weigh partially evidential facts in long, noisy contexts"
- Break condition: If the model cannot generalize reasoning patterns from training contexts to unseen contexts, or if the retrieved context is too noisy to be useful

### Mechanism 2
- Claim: Combining information from multiple knowledge sources (LLM-generated rationales and retrieved Wikipedia contexts) improves performance over single sources
- Mechanism: The system uses a Rationale Ranking model to score both generated rationales and retrieved contexts for relevance and truthfulness, then applies various strategies to combine the highest-scoring components
- Core assumption: Different knowledge sources have complementary strengths (LLMs for commonsense, retrieval for multi-hop factual) that can be effectively combined
- Evidence anchors: [abstract] "We show that combining information from these sources significantly improves the average performance over evaluation datasets versus using a single source." [section] "LLMs are weaker at surfacing the multiple pieces of information necessary to answer multi-hop factual questions, but stronger at generating rationales suitable for answering commonsense questions"
- Break condition: If the scoring model cannot accurately distinguish relevant from irrelevant or true from false information, or if the combination strategies don't effectively leverage the complementary strengths

### Mechanism 3
- Claim: Training on RATD datasets enables the model to effectively utilize combined contexts from multiple knowledge sources
- Mechanism: RATD datasets are constructed using the same retrieval system that will be used at inference time, creating contexts similar in form to what the model will encounter during evaluation
- Core assumption: Training on contexts similar in form to evaluation contexts enables effective generalization to unseen questions
- Evidence anchors: [abstract] "We also show that utilising theRATD datasets enables our model to become proficient at utilising combined noisy contexts." [section] "These datasets were originally developed to impart diverse reasoning strategies... When our rationales and retrieved contexts are combined, the resulting context is similar in length and form to theRATD contexts"
- Break condition: If the RATD contexts don't adequately represent the diversity of evaluation contexts, or if the model overfits to the specific RATD training distribution

## Foundational Learning

- Concept: Semantic similarity for detecting memorization
  - Why needed here: The research needs to distinguish between questions the model can answer through reasoning versus memorization of training data
  - Quick check question: If an evaluation question has a semantic similarity score above 60 to any training question, should it be considered memorizable?

- Concept: Dense retrieval and reranking for multi-hop questions
  - Why needed here: The system needs to retrieve multiple documents to answer complex compositional questions that require information from several sources
  - Quick check question: How many hops does the Iterator system support for retrieving documents?

- Concept: Multitask pretraining for generalization
  - Why needed here: The model needs to develop diverse reasoning skills across different question types rather than specializing in one domain
  - Quick check question: What is the total number of tasks the Base+RATD model is trained on?

## Architecture Onboarding

- Component map: Retriever (RoBERTa-base) -> Reranker (ELECTRA-large) -> Evidence Set Scorer -> Rationale Generator (BLOOM/StableVicuna) -> Rationale Ranker (ELECTRA-large) -> Reasoning Model (BART)

- Critical path: 1. Question input → 2. Retrieval of Wikipedia contexts → 3. LLM generation of rationales → 4. Scoring by Rationale Ranker → 5. Context combination → 6. Reasoning model output

- Design tradeoffs:
  - Smaller models vs larger models: Trade-off between resource efficiency and reasoning capability
  - Single vs multiple knowledge sources: Trade-off between simplicity and leveraging complementary strengths
  - RATD vs no RATD training: Trade-off between training time and reasoning ability on noisy contexts

- Failure signatures:
  - Low retrieval recall: Model fails on multi-hop questions requiring information from multiple documents
  - High false positive rate in Rationale Ranker: Model includes irrelevant or false information in combined contexts
  - Poor performance on numerical questions: Model struggles with numerical reasoning despite training

- First 3 experiments:
  1. Evaluate Base model on StrategyQA with Iterator-only contexts to establish baseline
  2. Train Base+RATD model and compare performance on the same dataset
  3. Test combination methods (Naïve Concatenation, Max Score, etc.) on CommonsenseQA with both knowledge sources

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent can smaller language models develop genuine abstract reasoning capabilities versus simply learning to recognize patterns in training data?
- Basis in paper: Explicit - The thesis explores whether smaller models can effectively reason over unseen compositional questions without memorization
- Why unresolved: The study demonstrates smaller models can generalize beyond memorization for some question types, but doesn't conclusively determine whether this represents true abstract reasoning or sophisticated pattern matching
- What evidence would resolve it: Systematic ablation studies comparing model performance on structurally similar but semantically distinct questions, and direct comparison of learned representations with human reasoning patterns

### Open Question 2
- Question: What is the optimal balance between retrieval-based and LLM-generated context for different question types?
- Basis in paper: Explicit - The thesis shows different knowledge sources have complementary strengths for different question types (LLMs better for commonsense, retrieval better for multi-hop factual)
- Why unresolved: While the study identifies general patterns, it doesn't establish precise guidelines for optimal knowledge source selection or combination ratios for specific question categories
- What evidence would resolve it: Large-scale empirical studies measuring performance across diverse question taxonomies with varying knowledge source combinations

### Open Question 3
- Question: How can the resource efficiency of retrieval and LLM components be further improved while maintaining or enhancing performance?
- Basis in paper: Explicit - The thesis focuses on constrained environments but acknowledges room for improvement in resource efficiency
- Why unresolved: The study uses current optimization techniques but doesn't explore cutting-edge efficiency improvements like model compression, quantization, or specialized hardware acceleration
- What evidence would resolve it: Head-to-head comparisons of different optimization techniques and their impact on the performance-resource tradeoff curve

## Limitations

- Results may not generalize to other domains or languages beyond the English general knowledge questions studied
- Performance evaluation depends heavily on the quality of the Wikipedia corpus and specific retrieval system used
- The study primarily measures exact match accuracy and F1 scores, which may not capture the full complexity of reasoning quality

## Confidence

**High Confidence:**
- Smaller language models can achieve comparable performance to larger models when provided with appropriate context
- RATD training significantly improves reasoning performance on compositional questions
- Combining multiple knowledge sources (retrieval and LLM rationales) improves average performance across evaluation datasets

**Medium Confidence:**
- The specific combination strategies provide meaningful improvements over single-source approaches
- The semantic similarity threshold of 60% effectively distinguishes memorization from generalization
- Different knowledge sources have complementary strengths for different question types

**Low Confidence:**
- The specific RATD dataset construction methodology is optimal for all reasoning tasks
- The Rationale Ranking model accurately distinguishes relevant from irrelevant information in all contexts
- The performance improvements will scale to much larger datasets or more complex reasoning tasks

## Next Checks

1. **Cross-dataset generalization test**: Evaluate the trained models on an entirely different compositional reasoning dataset not used in any part of the training or development process to verify the claimed generalization capabilities

2. **Ablation study of RATD components**: Systematically remove individual components of the RATD training methodology (e.g., train without negative rationales, without multi-hop contexts, without noisy contexts) to determine which aspects contribute most to the performance improvements

3. **Human evaluation of combined contexts**: Conduct a detailed human study where annotators rate the relevance, completeness, and accuracy of the combined contexts generated by different combination strategies, going beyond automated metrics to assess true reasoning quality