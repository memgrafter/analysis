---
ver: rpa2
title: 'LionGuard: Building a Contextualized Moderation Classifier to Tackle Localized
  Unsafe Content'
arxiv_id: '2407.10995'
source_url: https://arxiv.org/abs/2407.10995
tags:
- moderation
- singlish
- content
- classifier
- sexual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LionGuard, a Singapore-contextualized moderation
  classifier designed to detect unsafe content in Singlish, a unique English creole.
  The authors collected a large dataset of Singlish texts from online forums and used
  automated labeling with multiple large language models (LLMs) to create a training
  set of 138,000 texts.
---

# LionGuard: Building a Contextualized Moderation Classifier to Tackle Localized Unsafe Content

## Quick Facts
- arXiv ID: 2407.10995
- Source URL: https://arxiv.org/abs/2407.10995
- Reference count: 40
- LionGuard outperforms existing moderation APIs by 14% (binary) and up to 51% (multi-label) on Singlish data

## Executive Summary
This paper addresses the challenge of detecting unsafe content in Singlish, a unique English creole used in Singapore, by introducing LionGuard - a contextualized moderation classifier. The authors developed a large dataset of 138,000 Singlish texts from online forums and employed automated labeling using multiple large language models (LLMs) to create a training set. LionGuard significantly outperforms existing widely-used moderation APIs (OpenAI's Moderation API, Jigsaw's Perspective API, and Meta's LlamaGuard) by 14% (binary) and up to 51% (multi-label) on Singlish data. The best performing model combination was BGE-large embeddings with a ridge classifier, achieving a PR-AUC score of 0.819 on binary classification. This work highlights the importance of localization for moderation classifiers and presents a practical and scalable approach for low-resource languages.

## Method Summary
The authors collected a large dataset of Singlish texts from online forums and used automated labeling with multiple large language models (LLMs) to create a training set of 138,000 texts. They employed various embedding techniques (BGE, E5, OpenAI, and ColPali) combined with classifiers (ridge, logistic regression, and SVM) to train the LionGuard model. The dataset was split into 80% training and 20% testing sets. The authors evaluated LionGuard against existing moderation APIs (OpenAI's Moderation API, Jigsaw's Perspective API, and Meta's LlamaGuard) on both binary and multi-label classification tasks for detecting unsafe content in Singlish.

## Key Results
- LionGuard outperforms existing moderation APIs by 14% (binary) and up to 51% (multi-label) on Singlish data
- The best performing model combination was BGE-large embeddings with a ridge classifier, achieving a PR-AUC score of 0.819 on binary classification
- LionGuard demonstrates the importance of localization for moderation classifiers in low-resource languages

## Why This Works (Mechanism)
The paper demonstrates that language-specific contextualization significantly improves content moderation performance. By training on Singlish-specific data rather than standard English, LionGuard captures the unique linguistic patterns, slang, and cultural references that are characteristic of this English creole. The automated labeling approach using multiple LLMs provides a scalable solution for creating training data in low-resource language contexts where human-labeled datasets are scarce. The embedding-classifier architecture allows for efficient processing while maintaining high accuracy, making the system practical for real-world deployment.

## Foundational Learning
- **Singlish**: A unique English creole used in Singapore that combines elements from multiple languages including English, Malay, Mandarin, and Tamil. Needed to understand the specific linguistic challenges that standard moderation systems fail to address; quick check: verify examples of Singlish text in the dataset to confirm its authenticity.
- **Automated labeling with LLMs**: Using multiple large language models to label training data when human annotations are scarce. Needed to create large-scale training datasets for low-resource languages efficiently; quick check: compare agreement rates between different LLM labeling approaches.
- **Embedding-classifier architecture**: Using pre-trained embeddings (like BGE-large) combined with simple classifiers (ridge, logistic regression) rather than end-to-end fine-tuning. Needed to balance performance with computational efficiency; quick check: evaluate training/inference time and resource requirements for different embedding-classifier combinations.

## Architecture Onboarding

**Component Map**: Raw text data -> Text preprocessing (NLTK) -> Embedding generation (BGE/E5/OpenAI/ColPali) -> Classification (Ridge/LR/SVM) -> Moderation decision

**Critical Path**: Raw text → Preprocessing → BGE-large embeddings → Ridge classifier → Binary/multi-label output

**Design Tradeoffs**: The authors chose embedding-classifier architecture over end-to-end fine-tuning to balance performance with computational efficiency. This approach allows for faster inference and easier adaptation to new languages but may miss some contextual nuances that could be captured by full fine-tuning. The automated labeling approach sacrifices some labeling accuracy for scalability, trading human validation for the ability to create large datasets for low-resource languages.

**Failure Signatures**: The system may struggle with emerging slang or rapidly evolving language patterns that weren't present in the training data. It may also have difficulty with highly contextual content where cultural understanding is crucial. Performance degradation is likely when encountering code-switching between Singlish and other languages not well-represented in the training set.

**First Experiments**:
1. Test baseline performance on a held-out validation set with known labels
2. Compare different embedding techniques (BGE, E5, OpenAI, ColPali) with the same classifier
3. Evaluate the impact of text preprocessing steps on classification performance

## Open Questions the Paper Calls Out
None

## Limitations
- The dataset lacks demographic information about content creators and discussion topics, making it difficult to assess potential selection biases
- Automated labeling using LLMs introduces uncertainty about label quality, particularly for nuanced cultural contexts
- Results are limited to Singlish and may not generalize to other low-resource languages or dialects

## Confidence
- LionGuard performance improvements: Medium
- Dataset quality and representativeness: Low
- Generalizability to other languages: Low
- Computational efficiency claims: Not evaluated

## Next Checks
1. Conduct human validation studies on a stratified sample of the dataset to verify LLM labeling accuracy across different content types and severity levels
2. Test LionGuard on other English-based creoles and low-resource languages to assess generalizability beyond Singlish
3. Compare performance against optimized configurations of existing moderation APIs specifically tuned for Singlish detection