---
ver: rpa2
title: A survey on learning models of spiking neural membrane systems and spiking
  neural networks
arxiv_id: '2403.18609'
source_url: https://arxiv.org/abs/2403.18609
tags:
- neural
- spiking
- learning
- networks
- snps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively compares and analyzes learning models
  in spiking neural networks (SNN) and spiking neural P systems (SNPS), focusing on
  machine learning and deep learning approaches for both frameworks. The paper addresses
  the critical challenge of efficient training in these biologically-inspired neural
  models that process information through discrete spikes rather than continuous signals.
---

# A survey on learning models of spiking neural membrane systems and spiking neural networks

## Quick Facts
- arXiv ID: 2403.18609
- Source URL: https://arxiv.org/abs/2403.18609
- Reference count: 40
- This survey comprehensively compares learning models in SNNs and SNPS, identifying STKLR as particularly effective for feedforward networks

## Executive Summary
This survey systematically analyzes learning algorithms for spiking neural networks (SNN) and spiking neural P systems (SNPS), addressing the critical challenge of training these biologically-inspired models that process information through discrete spikes. The paper categorizes learning approaches into gradient descent-based methods, synaptic plasticity-based approaches (primarily STDP), and spike train convolution algorithms, while highlighting the unique challenges in training SNPS due to their formal language-theoretic foundations. Key findings include STKLR's effectiveness for feedforward SNNs, the growing importance of deep SNN architectures, and the persistent challenge of efficient multi-layer training for SNPS models.

## Method Summary
This survey synthesizes existing research on learning models for SNNs and SNPS by reviewing 40 references covering gradient descent-based methods (SpikeProp variants), synaptic plasticity-based approaches (STDP), spike train convolution algorithms, and supervised learning methods. The analysis systematically categorizes learning algorithms for both frameworks and identifies their respective strengths and limitations. While not implementing new experiments, the survey provides a comprehensive framework for understanding the landscape of learning approaches and their applications, with particular emphasis on the computational efficiency and biological plausibility of different methods.

## Key Results
- STKLR (spike train kernel learning) identified as particularly effective for feedforward SNNs
- Deep SNN architectures like spiking CNNs and RNNs are growing in importance
- Efficient multi-layer training remains an open challenge, especially for SNPS models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient descent-based learning methods are effective for training SNNs but face challenges due to the non-differentiable nature of spike events.
- Mechanism: Gradient descent methods for SNNs rely on approximating gradients through techniques like SpikeProp, which adjusts weights based on timing differences between desired and actual spike times. These methods adapt classical backpropagation by treating spike timing as the key variable to optimize.
- Core assumption: The timing of spikes can be effectively modeled as differentiable variables through appropriate approximation methods.
- Evidence anchors:
  - [abstract] "the spiking activity in SNN is discrete and non-differentiable which complicates the implementation of backpropagation-like algorithms based on gradient descent"
  - [section] "The weight modification process during learning in SNN is associated with timing of spikes between two connected neurons"
  - [corpus] Weak - corpus contains papers on SNN training but no direct evidence about gradient descent effectiveness
- Break condition: If spike timing cannot be accurately approximated as differentiable variables, gradient descent methods will fail to converge properly.

### Mechanism 2
- Claim: STDP-based learning provides a biologically plausible alternative that works well for unsupervised learning in SNNs.
- Mechanism: STDP adjusts synaptic weights based on the relative timing of pre- and post-synaptic spikes, strengthening connections when presynaptic spikes precede postsynaptic ones. This local learning rule requires no external supervision and mimics biological learning processes.
- Core assumption: Spike timing correlations contain sufficient information for meaningful weight adjustments without external labels.
- Evidence anchors:
  - [section] "The STDP learning rules are inspired by Hebbian learning. Synaptic strengths are adjusted based on the correlation of the pre-synaptic and post-synaptic firing times"
  - [section] "Unsupervised learning models deal with unlabeled data and, instead of supervision, they identify hidden patterns inside the data on their own"
  - [corpus] Weak - corpus mentions STDP but lacks evidence about unsupervised learning effectiveness
- Break condition: If spike timing correlations are too noisy or sparse, STDP will fail to extract meaningful patterns for unsupervised learning.

### Mechanism 3
- Claim: Spike train convolution methods like STKLR transform discrete spike events into continuous signals that can be processed with standard learning algorithms.
- Mechanism: These methods use kernel functions (like α-kernel) to convert spike trains into analog signals, enabling the application of traditional machine learning techniques. This approach bridges the gap between discrete spiking dynamics and continuous optimization methods.
- Core assumption: The kernel transformation preserves essential information about spike timing patterns while making them amenable to continuous optimization.
- Evidence anchors:
  - [section] "A spike train kernel learning rule (STKLR) with various kernel functions has been proposed in [113]"
  - [section] "The use of kernel function turned out to be a promising approach in this class of learning methods"
  - [corpus] Weak - corpus lacks direct evidence about STKLR effectiveness
- Break condition: If the kernel transformation loses critical temporal information, the resulting continuous signals will not support accurate learning.

## Foundational Learning

- Concept: Temporal encoding in neural systems
  - Why needed here: Understanding how information is encoded in spike timing is crucial for designing effective learning algorithms for SNNs and SNPS
  - Quick check question: How does temporal encoding differ from rate-based encoding in traditional neural networks?

- Concept: Membrane potential dynamics
  - Why needed here: The integrate-and-fire mechanism and membrane potential thresholds determine when neurons spike, which directly impacts learning algorithm design
  - Quick check question: What happens to a neuron's membrane potential when it receives an excitatory vs inhibitory spike?

- Concept: Supervised vs unsupervised learning paradigms
  - Why needed here: Different learning approaches (gradient descent, STDP, convolution-based) have distinct requirements and applications in SNN/SNPS training
  - Quick check question: When would you choose STDP over gradient descent for training a spiking neural network?

## Architecture Onboarding

- Component map:
  - Input encoding → Neuron layer → Synapse layer → Learning module → Weight updates → Output decoding

- Critical path:
  1. Input encoding → Neuron layer → Synapse layer → Learning module → Weight updates → Output decoding
  2. The most critical path is from input spikes through the network to trigger learning updates based on error signals

- Design tradeoffs:
  - Biological plausibility vs computational efficiency: More biologically accurate models are harder to train
  - Supervised vs unsupervised learning: Supervised methods require labeled data but can achieve higher accuracy
  - Single-layer vs multi-layer architectures: Multi-layer networks can learn more complex patterns but are harder to train

- Failure signatures:
  - Vanishing gradients in deep networks due to non-differentiable spike events
  - Poor convergence when spike timing information is insufficient for learning
  - Instability when membrane potential dynamics are not properly balanced

- First 3 experiments:
  1. Implement a single-layer SNN with SpikeProp on a simple classification task to verify basic learning capability
  2. Add STDP learning to the same network for unsupervised feature learning comparison
  3. Implement spike train kernel learning (STKLR) and compare performance against the other methods on the same task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective learning algorithms for training multi-layer spiking neural P systems (SNPS), and how do they compare to those used in spiking neural networks (SNN)?
- Basis in paper: [explicit] The paper highlights that efficient training of multi-layer SNPS remains an open challenge and contrasts the broader scope of learning algorithms available for SNN with the limited options for SNPS.
- Why unresolved: SNPS models are based on formal language theory, which complicates the training process even for single-layer models. The paper notes that most research has focused on single-layer SNPS with limited deep learning approaches.
- What evidence would resolve it: Comparative studies demonstrating the performance of various learning algorithms (e.g., gradient descent-based, synaptic plasticity-based, or deep learning-inspired) on multi-layer SNPS, benchmarked against SNN performance on equivalent tasks.

### Open Question 2
- Question: How can the computational power of spiking neural networks (SNN) be more thoroughly investigated, particularly in relation to their Turing completeness and complexity?
- Basis in paper: [explicit] The paper states that while many SNPS variants are proven to be Turing complete and capable of solving complex problems, the computational power of SNN models is less investigated.
- Why unresolved: SNN models are inspired by biological neurons and focus on temporal encoding, but their theoretical foundations in terms of computational capabilities have not been as extensively studied as SNPS.
- What evidence would resolve it: Formal proofs or empirical demonstrations of the computational capabilities of SNN, including their ability to solve NP-complete or PSPACE-complete problems, and comparisons with SNPS in terms of efficiency and expressiveness.

### Open Question 3
- Question: What are the most promising applications of spiking neural networks (SNN) and spiking neural P systems (SNPS) in real-time and energy-efficient computing, and how do they compare to traditional deep learning models?
- Basis in paper: [explicit] The paper discusses the potential of SNN and SNPS for energy-efficient computing and mentions their closer relation to biological brain structure, but also notes that their applicability in deep learning tasks cannot currently compete with real-valued deep ANN models.
- Why unresolved: While SNN and SNPS show promise for energy-efficient computing, their performance in real-world applications, particularly in deep learning tasks, remains limited compared to traditional models. The paper suggests exploring their use in time series analysis and sentiment classification.
- What evidence would resolve it: Case studies or benchmarks comparing the performance and energy efficiency of SNN/SNPS models against traditional deep learning models in specific applications such as time series forecasting, sentiment classification, or edge detection, with a focus on real-time constraints.

## Limitations
- Limited empirical validation of claimed effectiveness across different learning approaches
- Insufficient detail on implementation specifics and hyperparameters for many algorithms
- Lack of comprehensive comparative performance benchmarks across learning methods

## Confidence
- SNN learning methods (STKLR, gradient descent variants): Medium - substantial prior work but limited comparative validation
- SNPS learning approaches: Low - sparse empirical evidence and few implementation details
- Computational efficiency claims: Low - theoretical discussions without practical energy measurements

## Next Checks
1. Implement a standardized benchmark comparing SpikeProp, STKLR, and STDP on identical SNN architectures using common datasets (MNIST/N-MNIST) to verify relative effectiveness claims
2. Conduct ablation studies on kernel parameters in STKLR to determine sensitivity to hyperparameter choices and validate the kernel transformation preserves critical temporal information
3. Build a small-scale SNPS learning system to empirically test the scalability limitations and convergence behavior described in the survey, particularly for deep multi-layer architectures