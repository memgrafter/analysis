---
ver: rpa2
title: What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?
arxiv_id: '2411.07681'
source_url: https://arxiv.org/abs/2411.07681
tags:
- training
- accuracy
- data
- train
- pre-memorization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between learning dynamics
  and generalization in large language models (LLMs) finetuned for reasoning tasks.
  The authors introduce a novel metric called pre-memorization train accuracy, which
  measures the highest accuracy a model achieves on training examples before copying
  exact reasoning steps from the training data.
---

# What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?

## Quick Facts
- arXiv ID: 2411.07681
- Source URL: https://arxiv.org/abs/2411.07681
- Reference count: 37
- Key outcome: Pre-memorization train accuracy strongly predicts test accuracy in LLM reasoning tasks with R² values around or exceeding 0.9

## Executive Summary
This paper introduces pre-memorization train accuracy as a novel metric for predicting generalization in large language models fine-tuned for reasoning tasks. The metric measures the highest accuracy a model achieves on training examples before copying exact reasoning steps from the training data. The authors demonstrate that this metric reliably predicts test accuracy across various models (Llama3 8B, Gemma2 9B), datasets (GSM8k, MATH), and training configurations, achieving R² values of around or exceeding 0.9. Additionally, pre-memorization accuracy predicts the robustness of individual model predictions to perturbations in training prompts, enabling more efficient data curation strategies.

## Method Summary
The authors track model accuracy and perplexity on training examples throughout the training process, identifying when models transition from solving problems using diverse solution paths to copying exact target traces. They use this information to compute pre-memorization accuracy for each training example, then correlate these scores with test accuracy and robustness to prompt perturbations. The method involves training models with multiple checkpoints, evaluating each checkpoint on training data, identifying memorization thresholds, and using the results for data curation decisions.

## Key Results
- Pre-memorization train accuracy achieves R² values around or exceeding 0.9 in predicting test accuracy across different models, datasets, and training configurations
- Low pre-memorization accuracy on training examples correlates with prediction fragility when prompts are perturbed
- Prioritizing examples with low pre-memorization accuracy for data curation leads to 1.5-2x improvements in data efficiency compared to i.i.d. sampling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-memorization train accuracy measures a model's ability to solve training examples using generalizable reasoning before copying target solution traces verbatim.
- Mechanism: During training, models first learn to solve problems using diverse solution paths that differ from the target trace but arrive at correct answers. This phase represents learning generalizable problem-solving skills. Later, models transition to memorizing exact target traces. The highest accuracy achieved before this transition indicates the model's inherent reasoning capability.
- Core assumption: Correct final answers achieved through non-matching solution traces indicate genuine problem-solving ability rather than memorization.
- Evidence anchors:
  - [abstract] "models first learn to generate diverse solution traces (distinct from the target solution trace) that lead to the correct final answer, before later memorizing the target solution trace"
  - [section] "For some train queries, models initially produce incorrect samples (black), and then directly transition to replicating the target trace (yellow). For other examples, models first learn to generate correct answers with solution traces that differ from the target trace (pink), before later transitioning to fully replicating the target trace (yellow)"
- Break condition: If models consistently arrive at correct answers only through exact replication of target traces from the start of training, pre-memorization accuracy would not predict generalization.

### Mechanism 2
- Claim: The relationship between pre-memorization accuracy and test accuracy is linear with high R² across diverse training configurations.
- Mechanism: Models that achieve higher accuracy on training examples before memorization develop stronger generalizable reasoning patterns. These patterns transfer to unseen test examples, creating a predictable relationship between pre-memorization performance and final test accuracy.
- Core assumption: The distribution of problem-solving difficulty in training data is representative of test data difficulty.
- Evidence anchors:
  - [abstract] "On the dataset level, this metric is able to reliably predict test accuracy, achieving R2 of around or exceeding 0.9 across various models (Llama3 8B, Gemma2 9B), datasets (GSM8k, MATH), and training configurations"
  - [section] "We observe a strong linear relationship between pre-memorization training accuracy and test accuracy, with the results closely following the y = x line across different models, tasks, and hyperparameter settings"
- Break condition: If training and test distributions have significantly different characteristics or if the relationship between pre-memorization accuracy and generalization is non-linear, the predictive power would degrade.

### Mechanism 3
- Claim: Low pre-memorization accuracy on training examples correlates with prediction fragility when prompts are perturbed.
- Mechanism: Training examples where models achieve low accuracy before memorization require exact prompt-target trace matching for correct predictions. When prompts are slightly modified, these fragile predictions fail. High pre-memorization accuracy indicates robust understanding that generalizes to prompt variations.
- Core assumption: Perturbations like adding "First" or "We know that" to prompts are reasonable variations that should not fundamentally change the problem being solved.
- Evidence anchors:
  - [section] "For train examples with low pre-memorization accuracies, adding small perturbations to the training prompt causes the accuracy of model predictions to significantly degrade. In contrast, for train examples with high pre-memorization accuracies, models are generally able to maintain high performance under perturbations"
  - [section] "While the accuracy of model samples is almost perfect when faced with original prompts, it significantly degrades when faced with prompts with perturbations"
- Break condition: If the model's robust reasoning capabilities are localized to specific prompt formats or if the perturbations fundamentally change the problem structure, this correlation would not hold.

## Foundational Learning

- Concept: Difference between memorization and generalization in reasoning tasks
  - Why needed here: The paper's core insight depends on distinguishing when models solve problems through understanding versus copying. Without this distinction, the pre-memorization metric loses meaning.
  - Quick check question: Can you explain why a model that arrives at the correct answer using different reasoning steps than the target demonstrates generalization rather than memorization?

- Concept: Learning dynamics tracking across training epochs
  - Why needed here: The method requires monitoring model performance on training examples throughout the entire training process, not just at final checkpoints.
  - Quick check question: How would you design a system to track model accuracy on training examples while also measuring when the model begins copying target solution traces verbatim?

- Concept: Prompt perturbation analysis for robustness testing
  - Why needed here: The per-example analysis relies on understanding how small prompt changes affect model predictions, which is crucial for identifying fragile examples.
  - Quick check question: What types of prompt perturbations would you consider reasonable for testing robustness without fundamentally changing the problem being solved?

## Architecture Onboarding

- Component map: Data pipeline -> Model training -> Evaluation system -> Curation module -> Analysis tools
- Critical path:
  1. Train model with multiple checkpoints
  2. Evaluate each checkpoint on training data measuring accuracy and perplexity
  3. Identify memorization threshold and compute pre-memorization accuracy
  4. Correlate pre-memorization accuracy with test accuracy
  5. Use results for data curation decisions
- Design tradeoffs:
  - Computational cost vs. granularity: More checkpoints provide better pre-memorization tracking but increase computation
  - Memorization threshold selection: Too strict misses early reasoning development, too loose includes memorization
  - Perturbation design: Need perturbations that test robustness without changing problem semantics
- Failure signatures:
  - Low R² between pre-memorization accuracy and test accuracy suggests the metric doesn't capture generalizable reasoning
  - No correlation between pre-memorization accuracy and perturbation robustness suggests other factors dominate prediction fragility
  - Inconsistent pre-memorization thresholds across datasets suggest the metric isn't portable
- First 3 experiments:
  1. Train a model on GSM8K with different learning rates, track accuracy and perplexity at each epoch, plot learning dynamics to identify memorization transitions
  2. Compute pre-memorization accuracy for each training example, correlate with test accuracy using different memorization thresholds, find optimal p value
  3. Apply perturbations to training prompts, measure prediction accuracy degradation, correlate with pre-memorization accuracy to validate robustness relationship

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do pre-memorization accuracy predictions generalize to different model architectures beyond LLMs, such as vision transformers or graph neural networks?
- Basis in paper: [inferred] The paper focuses exclusively on LLMs finetuned for reasoning tasks, leaving open the question of whether pre-memorization accuracy is a general predictor of generalization across different model types and tasks.
- Why unresolved: The study's scope is limited to LLM reasoning tasks, and the authors do not explore other domains or architectures.
- What evidence would resolve it: Conducting experiments with various model architectures and tasks to determine if pre-memorization accuracy consistently predicts generalization performance across domains.

### Open Question 2
- Question: What is the relationship between pre-memorization accuracy and the model's ability to generalize to out-of-distribution (OOD) data?
- Basis in paper: [inferred] The paper evaluates test accuracy on data drawn from the same distribution as the training data, but does not investigate how pre-memorization accuracy correlates with performance on OOD data.
- Why unresolved: The study focuses on in-distribution generalization, leaving the question of OOD generalization unexplored.
- What evidence would resolve it: Designing experiments to measure model performance on OOD data and analyzing how pre-memorization accuracy relates to this performance.

### Open Question 3
- Question: How does the choice of memorization threshold (p) affect the predictive power of pre-memorization accuracy for test accuracy, and can this threshold be learned or adapted dynamically during training?
- Basis in paper: [explicit] The paper discusses the selection of a memorization threshold p but does not explore how different values of p affect the correlation between pre-memorization accuracy and test accuracy, nor does it consider adaptive thresholding.
- Why unresolved: The authors select p through a calibration process but do not investigate its sensitivity or potential for dynamic adaptation.
- What evidence would resolve it: Conducting experiments to analyze the impact of different p values on prediction accuracy and exploring methods for dynamic threshold adjustment during training.

### Open Question 4
- Question: How does the pre-memorization accuracy metric relate to other established generalization measures, such as sharpness of the loss landscape or PAC-Bayes bounds, in terms of predictive power and computational efficiency?
- Basis in paper: [explicit] The paper compares pre-memorization accuracy to several prior generalization metrics but does not provide a comprehensive analysis of its relationship to other theoretical or empirical measures of generalization.
- Why unresolved: The comparison is limited to a few metrics, and a broader analysis is needed to understand the relative strengths and weaknesses of pre-memorization accuracy.
- What evidence would resolve it: Performing a systematic comparison of pre-memorization accuracy with a wider range of generalization metrics, evaluating both predictive power and computational efficiency.

## Limitations

- The paper's findings rely heavily on the assumption that pre-memorization accuracy genuinely captures generalizable reasoning rather than just early-stage memorization
- The robustness analysis using prompt perturbations uses relatively simple perturbations, leaving uncertainty about how more substantial variations would affect the relationship
- The data curation results are based on limited experiments with GSM8k and MATH, requiring broader validation across different reasoning task types

## Confidence

- High confidence: The core finding that pre-memorization accuracy predicts test accuracy with R² values around 0.9 is well-supported by extensive experiments across multiple models, datasets, and training configurations
- Medium confidence: The data curation results showing 1.5-2x improvements in sample efficiency are promising but based on a limited set of experiments
- Medium confidence: The per-example analysis linking low pre-memorization accuracy to prediction fragility under prompt perturbations is well-demonstrated, but the perturbations used are relatively simple

## Next Checks

1. **Alternative solution path analysis**: Conduct a detailed analysis of the solution traces generated during the pre-memorization phase to verify they represent genuinely different reasoning approaches rather than variations of the target solution. This could involve clustering similar solution patterns and assessing their diversity.

2. **Cross-task generalization**: Test whether pre-memorization accuracy predicts generalization for non-mathematical reasoning tasks (e.g., commonsense reasoning, logical inference) to assess the metric's broader applicability beyond arithmetic problem-solving.

3. **Stress test perturbations**: Systematically vary the complexity and type of prompt perturbations (including semantic changes, reordered problem statements, and multi-step variations) to determine the boundaries of the robustness relationship and identify when it breaks down.