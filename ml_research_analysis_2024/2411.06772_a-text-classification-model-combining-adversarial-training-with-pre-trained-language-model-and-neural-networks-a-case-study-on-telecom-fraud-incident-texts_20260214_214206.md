---
ver: rpa2
title: 'A Text Classification Model Combining Adversarial Training with Pre-trained
  Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts'
arxiv_id: '2411.06772'
source_url: https://arxiv.org/abs/2411.06772
tags:
- text
- classification
- data
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a text classification model that combines adversarial
  training with a pre-trained language model and neural networks to address the challenge
  of automatically categorizing Telecom Fraud police call reported incident texts.
  The model, called LERT-CNN-BiLSTM, leverages the Linguistically-motivated Pre-trained
  Language Model (LERT) to extract three types of language features and perturb the
  embedding layer using the Fast Gradient Method (FGM) algorithm.
---

# A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts

## Quick Facts
- **arXiv ID**: 2411.06772
- **Source URL**: https://arxiv.org/abs/2411.06772
- **Reference count**: 40
- **Primary result**: LERT-CNN-BiLSTM model achieves 83.9% accuracy on telecom fraud text classification, improving to 90% with additional training

## Executive Summary
This study addresses the challenge of automatically categorizing Telecom Fraud police call reported incident texts into 14 subcategories for targeted prevention measures. The proposed LERT-CNN-BiLSTM model combines adversarial training with a pre-trained language model and neural networks to achieve high classification accuracy. By leveraging Linguistically-motivated Pre-trained Language Model (LERT) for feature extraction and applying the Fast Gradient Method (FGM) for adversarial training, the model demonstrates improved robustness and generalization ability. The approach has been successfully deployed in operational departments, significantly improving efficiency and freeing up manpower.

## Method Summary
The LERT-CNN-BiLSTM model combines adversarial training with a pre-trained language model (LERT) and neural networks (CNN and BiLSTM). LERT extracts three types of language features (POS, NER, DEP) and generates an embedding layer, which is perturbed using the Fast Gradient Method (FGM) algorithm. The perturbed embedding layer is then fed into the CNN and BiLSTM networks to extract local semantic information and contextual syntactic information, respectively. The outputs are combined and passed through a fully connected layer for 14-class text classification. The model was trained on 10,000 Telecom Fraud case data from 2023 in City B, split into training, validation, and test sets in an 8:1:1 ratio.

## Key Results
- Achieved 83.9% classification accuracy on initial test dataset
- Improved accuracy to 90% after further training on larger dataset
- Successfully deployed in operational department, improving efficiency and freeing up manpower
- Model demonstrates versatility for potential applications in other text classification scenarios

## Why This Works (Mechanism)
The model's effectiveness stems from combining multiple complementary approaches: LERT provides linguistically-informed feature extraction that captures syntactic and semantic information, while adversarial training through FGM enhances robustness against input variations. The CNN component extracts local semantic patterns through convolutional filters, while BiLSTM captures long-range contextual dependencies in both forward and backward directions. This multi-level feature extraction approach allows the model to capture both fine-grained local patterns and broader contextual relationships essential for accurate classification of complex telecom fraud texts.

## Foundational Learning
- **LERT (Linguistically-motivated Pre-trained Language Model)**: Why needed - Extracts linguistic features beyond standard embeddings; Quick check - Verify three feature types (POS, NER, DEP) are properly extracted
- **Fast Gradient Method (FGM)**: Why needed - Creates adversarial examples to improve model robustness; Quick check - Measure performance difference with/without adversarial training
- **BiLSTM**: Why needed - Captures contextual information in both directions; Quick check - Compare with unidirectional LSTM performance
- **CNN for text**: Why needed - Extracts local n-gram features; Quick check - Test different filter sizes and counts
- **Multi-class classification**: Why needed - Handles 14 distinct fraud subcategories; Quick check - Analyze per-class performance metrics
- **Adversarial training**: Why needed - Prevents overfitting to training distribution; Quick check - Evaluate on perturbed test inputs

## Architecture Onboarding

**Component Map**: LERT Feature Extraction -> FGM Adversarial Perturbation -> CNN Layer -> BiLSTM Layer -> Concatenation -> Fully Connected Layer

**Critical Path**: The embedding layer generated by LERT serves as the foundation, with adversarial perturbation applied immediately before the CNN and BiLSTM components. The concatenated outputs from these neural networks form the input to the final classification layer.

**Design Tradeoffs**: The paper balances complexity (multiple model components) against performance gains, choosing a multi-feature approach over simpler single-feature models. The adversarial training adds computational overhead but provides robustness benefits.

**Failure Signatures**: Poor performance may indicate inadequate feature extraction from LERT, insufficient perturbation strength in FGM, or suboptimal CNN/BiLSTM configurations. Class-specific failures could suggest imbalanced training data or insufficient examples for certain fraud types.

**3 First Experiments**:
1. Implement baseline LERT feature extraction and verify three linguistic feature types are correctly extracted
2. Test adversarial training with varying perturbation strengths to determine optimal FGM configuration
3. Perform ablation study removing CNN or BiLSTM to quantify individual component contributions

## Open Questions the Paper Calls Out
None

## Limitations
- Missing implementation details for LERT model architecture and training procedure
- Lack of specific configuration parameters for CNN and BiLSTM layers
- Evaluation focuses on overall accuracy without per-class performance metrics
- No quantitative metrics provided for claimed operational efficiency improvements

## Confidence
- **High confidence** in general methodology combining LERT with adversarial training and neural networks for text classification
- **Medium confidence** in reported overall accuracy improvements from 83.9% to 90%
- **Low confidence** in reproducibility of specific results due to missing implementation details

## Next Checks
1. Implement the LERT model with standardized configurations (BERT-base or similar) to verify whether the three-language-feature extraction approach can be replicated and produces comparable embedding quality

2. Conduct ablation studies comparing model performance with and without adversarial training, testing different perturbation strengths to determine optimal FGM configuration

3. Perform detailed per-class analysis on the test dataset to identify potential class imbalance issues or systematic errors in categorizing specific fraud subcategories