---
ver: rpa2
title: Enhancing Event Reasoning in Large Language Models through Instruction Fine-Tuning
  with Semantic Causal Graphs
arxiv_id: '2409.00209'
source_url: https://arxiv.org/abs/2409.00209
tags:
- event
- detection
- triggers
- text
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving event detection
  in large language models (LLMs) by introducing Semantic Causal Graphs (SCGs) and
  SCG Instructions for fine-tuning. The method leverages SCGs to capture causal relationships
  between event triggers and types, enhancing LLM understanding of event detection
  tasks.
---

# Enhancing Event Reasoning in Large Language Models through Instruction Fine-Tuning with Semantic Causal Graphs

## Quick Facts
- arXiv ID: 2409.00209
- Source URL: https://arxiv.org/abs/2409.00209
- Reference count: 40
- Outperforms GPT-4 by 35.69% average on Event Trigger Classification using SCG Instructions

## Executive Summary
This paper introduces Semantic Causal Graphs (SCGs) and SCG Instructions to enhance event detection capabilities in large language models through instruction fine-tuning. The method explicitly models causal relationships between event triggers and types using graph structures, while employing LoRA for efficient fine-tuning that preserves general reasoning capabilities. Experimental results demonstrate significant improvements over standard instruction fine-tuning and GPT-4 across multiple event detection benchmarks, with the fine-tuned Mistral 7B model showing 31.01% improvement in Event Trigger Identification, 37.40% in Event Trigger Classification, and 16.43% in Event Classification.

## Method Summary
The approach combines Semantic Causal Graphs with instruction fine-tuning using LoRA adaptation. SCGs capture causal relationships between event triggers and event types by creating directed graphs where trigger nodes connect to event type nodes. The method involves annotating text with SCGs, extracting causal subgraphs containing only trigger-event type relationships, converting these into instruction format, and fine-tuning LLMs using LoRA while freezing pre-trained weights. The process aims to teach models to identify event triggers as critical causal elements while maintaining general language capabilities through parameter-efficient adaptation.

## Key Results
- SCG Instruction fine-tuning outperforms standard instruction fine-tuning by 35.69% average on Event Trigger Classification
- Fine-tuned Mistral 7B achieves 31.01% improvement in Event Trigger Identification vs GPT-4
- Maintains general language capabilities with only 2.03-point average drop across six benchmarks
- Shows consistent improvements across five diverse event detection datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SCGs improve event detection by explicitly modeling causal relationships between triggers and event types
- Mechanism: The SCG graph structure decomposes event detection into learning P(Et|Text) and P(Ey|Et) separately, creating a more interpretable and causally grounded decision process
- Core assumption: Event triggers have direct causal relationships to event types that can be modeled as graph edges
- Evidence anchors:
  - [abstract] "Our method introduces Semantic Causal Graphs (SCGs) to capture both causal relationships and contextual information within text"
  - [section] "Each trigger node requires precisely one outgoing edge connecting to an event type node eyj. Graph G serves as a structural representation of contextual data, event triggers, and their relationships to event types"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.438. Weak corpus evidence for direct causal modeling claims

### Mechanism 2
- Claim: LoRA fine-tuning preserves general language capabilities while adapting to event detection
- Mechanism: LoRA applies low-rank decomposition to weight matrices, freezing pre-trained weights while only updating small adapter matrices, preventing catastrophic forgetting
- Core assumption: Pre-trained LLM knowledge is encoded in high-rank weight matrices that can be preserved while low-rank adapters learn task-specific features
- Evidence anchors:
  - [section] "LoRA applies a low-rank decomposition to the weight matrices in the transformer layers, significantly reducing the number of trainable parameters"
  - [section] "By freezing the pre-trained weights W0 and only updating the low-rank matrices A and B, LoRA acts as a strong regularizer, preventing overfitting to the limited event detection data"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.438. Weak corpus evidence for LoRA's effectiveness in preserving general capabilities

### Mechanism 3
- Claim: Causal subgraph focus eliminates spurious correlations from contextual information
- Mechanism: By extracting only event trigger nodes and their direct relationships to event types, the model learns the minimal causal structure needed for event detection without being distracted by peripheral context
- Core assumption: Contextual information introduces noise and spurious correlations that harm model generalization
- Evidence anchors:
  - [section] "Non-essential information is known to cause models to learn spurious relationships, which can lead to reduced model generalizability"
  - [section] "This approach during the fine-tuning process teaches the LLM to accurately identify event triggers as critical causal elements, thereby enhancing the LLM's event detection abilities"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.438. Weak corpus evidence for spurious correlation claims

## Foundational Learning

- Concept: Causal reasoning and graph theory
  - Why needed here: The entire approach relies on representing events as directed graphs with causal relationships
  - Quick check question: Can you explain why a directed edge from trigger to event type represents a causal relationship rather than just correlation?

- Concept: Instruction fine-tuning methodology
  - Why needed here: The paper builds SCG Instructions as a specialized form of instruction fine-tuning
  - Quick check question: What's the difference between standard instruction tuning and SCG Instructions in terms of the learning objective?

- Concept: Low-rank adaptation (LoRA)
  - Why needed here: LoRA is the key technique for efficient fine-tuning while preserving general capabilities
  - Quick check question: How does LoRA's parameter efficiency compare to full fine-tuning in terms of memory usage and training speed?

## Architecture Onboarding

- Component map: Text -> SCG Annotation -> SCG Instructions -> LoRA Fine-tuning -> Model Evaluation
- Critical path: Text → SCG Annotation → SCG Instructions → LoRA Fine-tuning → Model Evaluation
- Design tradeoffs: 
  - Using LoRA vs full fine-tuning: LoRA preserves general capabilities but may limit task-specific adaptation
  - Focusing on causal subgraph vs full SCG: Simpler model but may lose some contextual information
  - Manual annotation vs automatic extraction: More accurate but slower data preparation
- Failure signatures: 
  - Poor EC/TI/TC scores indicate the causal relationships aren't being learned
  - Drop in general capability benchmarks suggests overfitting to event detection
  - Inconsistent performance across datasets suggests dataset complexity issues
- First 3 experiments:
  1. Compare SCG Instructions vs standard instructions on a single dataset to verify the 35.69% improvement claim
  2. Test LoRA vs full fine-tuning on the same dataset to confirm capability preservation
  3. Evaluate performance on datasets with varying complexity to understand the data complexity relationship

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but based on the analysis, several important open questions emerge from the research:

### Open Question 1
- Question: How does the SCG Instruction method perform on event detection tasks when applied to specialized domains with highly technical vocabularies that differ significantly from the training data?
- Basis in paper: [inferred] The paper mentions performance variations across different domains (biomedical, cybersecurity, news, general) and notes that the model underperformed significantly on the MLEE dataset, which has a highly specialized biomedical domain with an extremely small dataset size (199 training samples).
- Why unresolved: The paper only tests on a limited number of specialized domains. There is no exploration of how the method generalizes to other specialized fields like legal documents, financial reports, or scientific literature with different technical vocabularies and event structures.
- What evidence would resolve it: Testing the SCG Instruction method on a diverse set of specialized domains with varying vocabulary complexities and event structures, comparing performance against both traditional methods and other LLM approaches.

### Open Question 2
- Question: What is the optimal balance between context preservation and event trigger identification when modifying test data in ablation studies, and how does this balance affect model performance?
- Basis in paper: [explicit] The paper conducted an ablation study where context words (including temporal and spatial information) were extracted and replaced while keeping event trigger words unchanged, resulting in an average TC score drop of 3.58 points.
- Why unresolved: The study only tested one approach to context modification. The paper doesn't explore different degrees of context alteration or investigate whether certain types of contextual information (temporal vs. spatial vs. situational) have more impact on model performance than others.
- What evidence would resolve it: Systematic experiments varying the extent and types of context modification, measuring the impact on model performance across different event detection datasets to identify which contextual elements are most crucial for accurate event detection.

### Open Question 3
- Question: How does the SCG Instruction method scale to datasets with significantly larger numbers of event types (e.g., thousands of event types) compared to the datasets tested in this study?
- Basis in paper: [explicit] The paper tested on datasets with event types ranging from 5 to 168, with MA VEN having 168 event types and being the largest tested. The paper notes that the model trained on SCG Instructions with fewer samples (MLEE, CASIE) performed better than those with more samples (MA VEN).
- Why unresolved: The paper only tests on datasets with up to 168 event types, but real-world applications often require detection of hundreds or thousands of event types. The performance degradation observed with larger datasets suggests potential scalability issues that weren't fully explored.
- What evidence would resolve it: Testing the SCG Instruction method on datasets with progressively larger numbers of event types (500, 1000, 5000+) while monitoring performance metrics, training efficiency, and potential catastrophic forgetting effects to determine practical scalability limits.

## Limitations

- Heavy reliance on manual annotation for SCG creation limits scalability to larger datasets
- Evaluation focuses primarily on F1 scores without extensive analysis of model robustness
- Comparison against GPT-4 lacks ablation studies to isolate SCG vs instruction fine-tuning contributions

## Confidence

- Mechanism 1 (Causal modeling): Medium - Theoretical justification exists but corpus evidence is weak (FMR=0.438)
- Mechanism 2 (LoRA preservation): Medium - Limited empirical validation of capability preservation claims
- Mechanism 3 (Spurious correlation elimination): Low - Minimal corpus support for spurious correlation claims

## Next Checks

1. Conduct ablation studies comparing SCG Instructions against standard instructions while keeping LoRA fine-tuning constant to isolate the contribution of the SCG methodology

2. Perform stress tests on the fine-tuned model using adversarial examples and out-of-distribution event types to evaluate robustness and generalization

3. Scale up the annotation process to include additional domains and event types to assess whether the manual SCG creation bottleneck limits practical applicability