---
ver: rpa2
title: Can We Verify Step by Step for Incorrect Answer Detection?
arxiv_id: '2402.10528'
source_url: https://arxiv.org/abs/2402.10528
tags:
- answer
- reasoning
- first
- film
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores whether the correctness of large language model
  (LLM) outputs can be predicted by analyzing their reasoning chains. To address this,
  the authors introduce R2PE, a benchmark spanning five domains and eight reasoning
  tasks, with responses from six different LLMs.
---

# Can We Verify Step by Step for Incorrect Answer Detection?
arXiv ID: 2402.10528
Source URL: https://arxiv.org/abs/2402.10528
Reference count: 40
Primary result: Process Discernibility Score (PDS) outperforms answer agreement baseline by 5.1% F1 and 2.97% AUC-PR in detecting incorrect LLM predictions through reasoning chain analysis

## Executive Summary
This study investigates whether the correctness of large language model (LLM) outputs can be predicted by analyzing their reasoning chains. The authors introduce R2PE, a benchmark spanning five domains and eight reasoning tasks, and propose the Process Discernibility Score (PDS) framework that leverages pairwise process supervision to evaluate reasoning chains. PDS significantly outperforms the answer agreement baseline, achieving 5.1% higher F1 score and 2.97% better AUC-PR across 45 subsets. The framework also enhances open-domain QA accuracy when integrated with a verify-and-edit approach, demonstrating its effectiveness in detecting incorrect predictions through reasoning chain analysis.

## Method Summary
The researchers created the R2PE benchmark by collecting 5 responses per question from 6 LLMs across 8 reasoning tasks spanning 5 domains. They extracted rationales and answers from responses using dataset-specific delimiters, then manually cleaned atypical cases. The PDS framework computes pairwise process supervision scores (PPSS) by measuring entailment and contradiction probabilities between all reasoning chain pairs, combines this with normalized answer discernibility scores (ADS), and applies a threshold (H=0 for general tasks, 0.4 for discriminative tasks) to predict answer correctness. The method was evaluated against ADS baseline and integrated with verify-and-edit frameworks for downstream QA tasks.

## Key Results
- PDS outperforms ADS baseline by 5.1% F1 score and 2.97% AUC-PR across all 45 R2PE subsets
- PDS achieves better recall (15.68% improvement) while maintaining reasonable precision (5.72% reduction) compared to ADS
- Integration with verify-and-edit framework improves HotpotQA accuracy by 2.9% and 2WikiMultihop accuracy by 2.8%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PDS detects reasoning chain inconsistencies that ADS misses
- Mechanism: PDS computes pairwise entailment/contradiction scores between all reasoning chains and aggregates them, allowing detection of internal contradictions even when final answers agree
- Core assumption: Contradictions in intermediate reasoning steps indicate incorrect final answers, even when answer consensus is high
- Evidence anchors:
  - [abstract]: "PDS also enhances open-domain QA accuracy when integrated with a verify-and-edit framework, demonstrating its effectiveness in detecting incorrect predictions through reasoning chain analysis"
  - [section 3.2]: "As depicted in Figure 1, the PDS can detect contradictive information about the name of the actor playing a Russian hostage taker in 'Hostage for a Day' among multiple reasoning chains (highlighted by red) and give a correct label ˆL = F, while the ADS only assesses the agreements among the answers"
  - [corpus]: "Weak evidence - only 25 related papers found, average neighbor FMR=0.523, no citations"
- Break condition: When reasoning chains contain different but equally valid solution paths that lead to the same correct answer

### Mechanism 2
- Claim: PDS improves verification accuracy by balancing precision and recall compared to ADS
- Mechanism: ADS has high precision but low recall, missing many incorrect examples; PDS balances both by considering process information alongside answer agreement
- Core assumption: A verification system needs both high precision and recall to be effective, not just one at the expense of the other
- Evidence anchors:
  - [abstract]: "this resulted in an average of 5.1% increase in the F1 score and 2.97% improvement in AUC-PR across all 45 subsets within R2PE"
  - [section 4.1]: "While the ADS exhibits higher precision in most cases, the PDS significantly enhances recall across all subgroups. On average, PDS reduces precision by 5.72% and increases recall by 15.68%"
  - [corpus]: "Weak evidence - no specific citations found in corpus"
- Break condition: When ADS precision is already sufficient for the application's needs and the additional recall from PDS is not worth the precision trade-off

### Mechanism 3
- Claim: PDS enables integration with verify-and-edit frameworks to improve downstream task performance
- Mechanism: PDS can replace ADS in the verification stage of frameworks like verify-and-edit, selecting better candidates for editing
- Core assumption: The quality of verification directly impacts the effectiveness of subsequent editing steps
- Evidence anchors:
  - [abstract]: "We further demonstrate our PDS's efficacy in advancing open-domain QA accuracy"
  - [section 4.3]: "Experiments are carried out on (HotpotQA from GPT-4) and (2WikiMultihop from GPT-4), utilizing ground-truth supporting contexts...VE+PDS leads to a notable 2.9% absolute increase in accuracy for HotpotQA, and 2.8% for 2WikiMultihop"
  - [corpus]: "Weak evidence - only indirect support from general knowledge editing literature"
- Break condition: When the editing stage is not used or when the retrieval system is the bottleneck rather than verification

## Foundational Learning

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: Understanding how CoT works is essential to grasp why reasoning chain analysis is valuable
  - Quick check question: What is the primary benefit of CoT prompting compared to standard prompting?

- Concept: Pairwise entailment and contradiction detection
  - Why needed here: PDS relies on computing entailment/contradiction scores between reasoning chains
  - Quick check question: How does the entailment model distinguish between two responses that agree on the final answer but disagree on intermediate steps?

- Concept: Verification and editing frameworks
  - Why needed here: PDS is designed to work within these frameworks to improve their effectiveness
  - Quick check question: In a verify-and-edit framework, at which stage does PDS operate and why is this placement important?

## Architecture Onboarding

- Component map: Data collection (R2PE) -> Response extraction and cleaning -> PDS computation (PPSS + ADS) -> Verification decision (threshold) -> (Optional) Edit step -> Accuracy evaluation
- Critical path: R2PE data → PDS computation → Verification decision → (Optional) Edit step → Final accuracy evaluation
- Design tradeoffs:
  - Using all response pairs vs. subset of pairs (PDS-avg vs. HaloCheck approach)
  - Including vs. excluding answer information in PSS calculation (PDS vs. PDS w/o ans)
  - Task-agnostic vs. task-specific threshold selection (0.4 for discriminative tasks vs. 0 for general)
- Failure signatures:
  - High precision but low recall indicates ADS-like behavior
  - False positives from legitimate multiple solution paths
  - Sensitivity to NLI model limitations (Type III errors in analysis)
- First 3 experiments:
  1. Compare PDS performance on subsets where ADS fails vs. succeeds to quantify the improvement
  2. Test PDS with different NLI models to understand sensitivity to model choice
  3. Implement PDS threshold tuning on a held-out validation set to measure potential gains from adaptive thresholds

## Open Questions the Paper Calls Out
1. Is it possible to predict the accuracy of LLM outputs by scrutinizing the reasoning chains they generate?
2. Can the Process Discernibility Score (PDS) be extended to Long-CoT LLMs [Jaech et al., 2024] that benefit from sampling-based verification [Wen et al., 2025]?
3. Can PDS be extended to test-time scaling methods [Wu et al., 2025] via chain consistency analysis?

## Limitations
- The R2PE benchmark is relatively small with 45 subsets, limiting generalizability of findings
- Manual cleaning process for response extraction introduces potential human bias
- Threshold selection (H=0 for general tasks, 0.4 for discriminative tasks) appears somewhat arbitrary without extensive validation
- Results rely on GPT-4 for verification and editing tasks, which may not reflect performance with other LLMs

## Confidence
**High Confidence:**
- PDS outperforms ADS baseline in R2PE benchmark with statistically significant improvements
- PDS provides better recall than ADS while maintaining reasonable precision across multiple task types
- Integration of PDS with verify-and-edit frameworks improves downstream accuracy

**Medium Confidence:**
- PDS detects reasoning chain inconsistencies that ADS misses due to focus on answer agreement
- Pairwise entailment/contradiction scoring effectively captures internal reasoning contradictions
- 5.72% precision reduction for 15.68% recall improvement represents optimal trade-off

**Low Confidence:**
- PDS would maintain similar performance improvements on datasets not in R2PE
- Specific threshold values are optimal across all verification scenarios
- Manual cleaning heuristics generalize well to different LLM response patterns

## Next Checks
1. Implement cross-validation on R2PE dataset to systematically determine optimal PDS thresholds for different task types and dataset characteristics
2. Replace current entailment model with alternative NLI models (DeBERTa, RoBERTa) to quantify PDS performance sensitivity
3. Deploy PDS framework in production-like environment with varying retrieval quality and real user queries to validate laboratory improvements in real-world conditions