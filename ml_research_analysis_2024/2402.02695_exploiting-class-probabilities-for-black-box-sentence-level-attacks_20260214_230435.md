---
ver: rpa2
title: Exploiting Class Probabilities for Black-box Sentence-level Attacks
arxiv_id: '2402.02695'
source_url: https://arxiv.org/abs/2402.02695
tags:
- adversarial
- search
- attacks
- class
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first score-based black-box sentence-level
  attack that exploits classifier feedback in the form of class probabilities. The
  core method models candidate adversarial distributions via VAE perturbation of latent
  variables and searches for optimal parameters using Natural Evolution Strategies
  guided by class probabilities.
---

# Exploiting Class Probabilities for Black-box Sentence-level Attacks

## Quick Facts
- arXiv ID: 2402.02695
- Source URL: https://arxiv.org/abs/2402.02695
- Authors: Raha Moraffah; Huan Liu
- Reference count: 10
- Key outcome: Introduces the first score-based black-box sentence-level attack that exploits classifier feedback in the form of class probabilities, achieving state-of-the-art performance on three text classification datasets.

## Executive Summary
This paper introduces S2B2-Attack, the first score-based black-box sentence-level attack method that leverages classifier class probabilities for guidance. The approach models candidate adversarial distributions via VAE perturbation of latent variables and searches for optimal parameters using Natural Evolution Strategies. Experiments on AG's News, IMDB, and Yelp datasets show that S2B2-Attack outperforms all state-of-the-art baselines with attack success rates of 81.2%, 62.2%, and 66.9% respectively, while maintaining high semantic similarity and grammatical correctness.

## Method Summary
S2B2-Attack is a score-based black-box attack framework for text classification that generates adversarial sentences by perturbing the latent space of a VAE (OPTIMUS) and optimizing distribution parameters via Natural Evolution Strategies (NES) guided by class probabilities. The method samples latent perturbations, decodes them to sentences, computes adversarial loss using classifier probabilities, and updates NES parameters while maintaining semantic similarity through BERTScore constraints. The approach is evaluated on three text classification datasets (AG's News, IMDB, Yelp) using three transformer classifiers (BERT, RoBERTa, XLNet).

## Key Results
- S2B2-Attack achieves attack success rates of 81.2% on AG's News, 62.2% on IMDB, and 66.9% on Yelp
- The method outperforms all state-of-the-art baselines in black-box sentence-level attacks
- Adversarial examples maintain high semantic similarity and grammatical correctness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modeling candidate adversarial distributions via VAE perturbation of latent variables creates a continuous search space that can be guided by class probabilities
- Mechanism: Instead of discrete sentence candidates, the method perturbs the latent space (zorig) of the original sentence using Gaussian noise parameterized by (μ,σ²). Different (μ,σ²) values produce different distributions of adversarial sentences, forming a continuous parameter space explorable via NES optimization
- Core assumption: Latent space perturbations preserve semantic similarity while allowing grammatical variation through VAE decoding
- Evidence anchors:
  - [abstract]: "models candidate adversarial distributions via VAE perturbation of latent variables and searches for optimal parameters using Natural Evolution Strategies guided by class probabilities"
  - [section]: "To model the distributions of synonymous sentences to the original sentence... we propose to perturb the distribution of the original latent variables... zadv is the perturbed original latent variable, obtained by perturbing the original input's latent space (zorig) with adversarial Gaussian perturbations sampled from N(μ,σ²I)"

### Mechanism 2
- Claim: NES optimization using class probabilities can effectively guide the search for adversarial parameters
- Mechanism: NES minimizes the adversarial loss (Eq.2) over distribution parameters by computing gradients using class probabilities: Ep(x*|zadv;μ,σ)[L(x*)∇logp(x*|zadv;μ,σ)]. This provides a black-box score-based search method
- Core assumption: Class probabilities contain sufficient signal to guide parameter optimization toward adversarial examples
- Evidence anchors:
  - [abstract]: "searches for optimal parameters using Natural Evolution Strategies guided by class probabilities"
  - [section]: "The NES learns the parameters of a distribution that minimizes the adversarial objective (Eq.(1)) on average... This gradient only requires the class probabilities output, which are ideal for a score-based black-box attack"

### Mechanism 3
- Claim: The semantic similarity constraint ensures grammatical correctness and fluency while maintaining adversarial effectiveness
- Mechanism: Explicitly penalizes dissimilar adversarial samples using BERTScore: DBERT(Xorig,Xadv) = 1 - RBERT(Xorig,Xadv). The final objective combines adversarial loss with this penalty
- Core assumption: BERTScore provides a reliable measure of semantic similarity that correlates with grammatical correctness
- Evidence anchors:
  - [abstract]: "experiments... show that the proposed S2B2-Attack outperforms all state-of-the-art baselines... with high semantic similarity and grammatical correctness"
  - [section]: "To limit the perturbation amount, we explicitly penalize the adversarial distribution parameters with dissimilar adversarial samples to the original samples... we propose to maximize the semantic similarity between the adversarial examples sampled from the adversarial distributions and original samples"

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) and their latent space properties
  - Why needed here: The method relies on VAE's ability to encode sentences into continuous latent spaces where semantically similar sentences cluster together, and perturbations in this space can generate diverse but related sentences
  - Quick check question: Why does perturbing the latent space of a VAE generate semantically similar sentences rather than random ones?

- Concept: Natural Evolution Strategies (NES) for black-box optimization
  - Why needed here: NES provides a gradient-free optimization method that can work with only class probabilities as feedback, making it suitable for black-box settings where gradients are unavailable
  - Quick check question: How does NES estimate gradients without access to the model's internal parameters or gradients?

- Concept: BERTScore for semantic similarity measurement
  - Why needed here: BERTScore computes pairwise cosine similarity between contextual embeddings of tokens, providing a differentiable measure of semantic similarity that can be incorporated into the optimization objective
  - Quick check question: What makes BERTScore more suitable for measuring semantic similarity than simple n-gram overlap metrics?

## Architecture Onboarding

- Component map: VAE (OPTIMUS) for latent space modeling → NES optimizer for parameter search → BERTScore module for semantic constraint → Target classifier for feedback
- Critical path: Sample latent perturbations → Decode to sentences → Compute adversarial loss using classifier probabilities → Update NES parameters → Repeat until success or budget exhausted
- Design tradeoffs: Continuous vs discrete search space (better exploration vs more complex optimization), semantic constraint strength (grammatical quality vs attack success rate), query efficiency vs attack effectiveness
- Failure signatures: Low attack success rate (NES not finding good parameters), poor semantic similarity (constraint too weak or BERTScore unreliable), high query count (optimization inefficient)
- First 3 experiments:
  1. Verify VAE can generate semantically similar sentences from latent perturbations on clean data
  2. Test NES optimization with synthetic classifier that returns controlled probabilities
  3. Evaluate trade-off between λ (semantic constraint) and attack success rate on a simple dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of S2B2-Attack compare when using different language model-based decoders besides OPTIMUS for generating adversarial examples?
- Basis in paper: [explicit] The paper states that any text-VAE can be used and mentions using OPTIMUS, a large-scale language VAE, to obtain grammatical correctness and fluency.
- Why unresolved: The paper only evaluates the performance of S2B2-Attack using OPTIMUS and does not compare it with other language model-based decoders.
- What evidence would resolve it: Conducting experiments using different language model-based decoders (e.g., GPT-3, T5) and comparing the attack success rates, semantic similarity, and grammatical correctness of the generated adversarial examples.

### Open Question 2
- Question: What is the impact of varying the population size (p) and the maximum number of iterations (T) on the attack success rate and query complexity of S2B2-Attack?
- Basis in paper: [explicit] The paper mentions that the number of iterations (T) is set to 50 and the number of samples drawn per iteration (P) is set to 20, resulting in a maximum of 1000 queries per sample.
- Why unresolved: The paper does not explore the effect of different values of p and T on the attack performance and query complexity.
- What evidence would resolve it: Conducting experiments with different values of p and T and analyzing the trade-off between attack success rate and query complexity.

### Open Question 3
- Question: How does S2B2-Attack perform when targeting text classification models that are specifically designed to be robust against adversarial attacks?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of S2B2-Attack against standard transformer-based classifiers but does not evaluate its performance against adversarially robust models.
- Why unresolved: The paper does not test S2B2-Attack on text classification models that incorporate adversarial training or other robustness techniques.
- What evidence would resolve it: Conducting experiments using text classification models that are trained with adversarial training or other robustness methods and evaluating the attack success rate of S2B2-Attack against these models.

## Limitations

- The method requires fine-tuning the VAE on the target dataset, adding computational overhead
- Performance may degrade on datasets or classifiers not included in the experiments
- The semantic similarity constraint may become too restrictive, preventing finding adversarial examples in some cases

## Confidence

**High Confidence**: The S2B2-Attack framework outperforms all state-of-the-art baselines on the tested datasets with strong empirical evidence

**Medium Confidence**: Class probabilities provide sufficient signal for NES optimization, VAE latent perturbations preserve semantic similarity, and BERTScore reliably measures semantic similarity

**Low Confidence**: The optimal balance between semantic constraint strength and attack effectiveness, query efficiency of NES optimization across different architectures, and performance on unseen datasets and classifiers

## Next Checks

1. **Corpus validation**: Conduct a more comprehensive literature review to verify whether sentence-level black-box attacks exploiting class probabilities exist in the literature, and if so, how S2B2-Attack compares to these methods.

2. **Implementation verification**: Reproduce the core components (VAE fine-tuning, NES optimization, BERTScore calculation) on a simple synthetic dataset with controlled classifier outputs to verify each mechanism works as claimed before scaling to full experiments.

3. **Constraint sensitivity analysis**: Systematically vary the semantic similarity constraint weight (λ) and measure its impact on attack success rate, query count, and semantic similarity to identify the optimal tradeoff for different dataset characteristics.