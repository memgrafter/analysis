---
ver: rpa2
title: 'Discounted Adaptive Online Learning: Towards Better Regularization'
arxiv_id: '2402.02720'
source_url: https://arxiv.org/abs/2402.02720
tags:
- clip
- algorithm
- learning
- regret
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of online learning in nonstationary
  environments, where past data may become obsolete. The authors propose a novel approach
  combining a rescaling trick with Follow the Regularized Leader (FTRL) algorithms
  to achieve adaptive performance in discounted online convex optimization.
---

# Discounted Adaptive Online Learning: Towards Better Regularization

## Quick Facts
- arXiv ID: 2402.02720
- Source URL: https://arxiv.org/abs/2402.02720
- Authors: Zhiyu Zhang; David Bombara; Heng Yang
- Reference count: 40
- Key outcome: Achieves instance-optimal regret bounds in discounted online convex optimization using a rescaling trick with FTRL algorithms

## Executive Summary
This paper addresses online learning in nonstationary environments where past data may become obsolete. The authors propose a novel approach that combines a rescaling trick with Follow the Regularized Leader (FTRL) algorithms to achieve adaptive performance in discounted online convex optimization. The key innovation is the ability to gradually forget past data while retaining inductive bias through regularization, resulting in improved regret bounds and practical effectiveness in online conformal prediction tasks.

## Method Summary
The proposed method combines an undiscounted, adaptive FTRL-based OCO algorithm with a rescaling trick to achieve discounted regret bounds. The rescaling trick converts scale-free upper bounds on standard undiscounted regret to discounted regret bounds by weighting gradients with discount factors. The algorithm can also be decomposed using polar coordinates to separately learn the direction and magnitude of the comparator parameter, enabling simultaneous adaptivity. The approach is particularly effective for online conformal prediction, where it provides strong coverage guarantees while maintaining competitive performance on other metrics.

## Key Results
- Achieves instance-optimal regret bounds that improve upon standard gradient descent baseline
- Demonstrates strong coverage guarantees (close to target 0.9) in online conformal prediction tasks
- Shows robustness to hyperparameter tuning and computational efficiency compared to aggregation-based methods
- Maintains competitive performance on average width and runtime metrics while achieving low local coverage error

## Why This Works (Mechanism)

### Mechanism 1
The rescaling trick converts scale-free upper bounds on standard undiscounted regret to discounted regret bounds. By applying an adaptive algorithm to surrogate gradients weighted by discount factors (λ⁻¹t), then rescaling the resulting regret bound by the product of discount factors, the algorithm achieves adaptive performance in the discounted setting.

### Mechanism 2
FTRL algorithms can "remember" the initialization while forgetting past online data, unlike OGD without regularization. FTRL with appropriate regularization encodes the initialization into the prediction rule, allowing the algorithm to maintain inductive bias from the initial parameter while adapting to new data.

### Mechanism 3
The polar decomposition technique separates learning the direction and magnitude of the comparator parameter, enabling simultaneous adaptivity. Direction is learned using gradient-adaptive RMSProp-like algorithm, while magnitude is learned using discounted FTRL-based algorithm on the nonnegative real line.

## Foundational Learning

- **Discounted regret and nonstationary environments**: Understanding why forgetting past data is beneficial in nonstationary environments is fundamental to grasping the problem setup. Quick check: How does the discounted regret formulation differ from standard regret, and why is this difference important for nonstationary environments?

- **Follow the Regularized Leader (FTRL) framework**: FTRL is the core algorithmic framework used, and understanding how it incorporates regularization is crucial for grasping the approach. Quick check: How does FTRL differ from Online Gradient Descent in terms of regularization, and why is this difference important for the problem?

- **Polar decomposition technique**: This technique is used to achieve simultaneous adaptivity to both the loss sequence and the comparator. Quick check: How does decomposing the parameter learning into direction and magnitude components enable better adaptivity?

## Architecture Onboarding

- **Component map**: Base adaptive OCO algorithm -> Rescaling trick -> Polar decomposition module (direction and magnitude learners) -> FTRL-based magnitude learner -> Gradient-adaptive direction learner

- **Critical path**: 1) Apply base adaptive algorithm to surrogate gradients (weighted by discount factors) 2) Obtain undiscounted regret bound from base algorithm 3) Rescale bound by product of discount factors to get discounted regret bound 4) For Rd, decompose into direction and magnitude learning 5) Apply appropriate learning algorithms to each component

- **Design tradeoffs**: Complexity vs. performance (full algorithm more complex but offers better guarantees), Memory vs. adaptivity (more sophisticated algorithms require more memory but adapt better), Hyperparameter sensitivity (simpler algorithms may be less sensitive but offer weaker guarantees)

- **Failure signatures**: Poor performance in highly nonstationary environments (may indicate insufficient forgetting), Sensitivity to hyperparameter ε (may indicate poor regularization design), Violation of scale-free property (may indicate base algorithm incompatibility)

- **First 3 experiments**: 1) Test basic functionality with synthetic data and known discount factors 2) Compare performance with and without discounting on nonstationary data 3) Test sensitivity to hyperparameter ε on benchmark datasets

## Open Questions the Paper Calls Out

### Open Question 1
How do the proposed adaptive algorithms perform in non-convex lifelong learning scenarios where the convexity assumption is violated? The current theoretical framework relies heavily on convexity, making it difficult to extend the results to non-convex settings without additional assumptions or modifications.

### Open Question 2
What is the optimal strategy for online selection of discount factors λt in the proposed adaptive algorithm? Determining the optimal discount factors online is crucial for practical applications but requires balancing between forgetting obsolete data and retaining useful information.

### Open Question 3
How does the performance of the simplified MagDis algorithm (Algorithm 5) compare to the full Algorithm 1 in more diverse and challenging online conformal prediction tasks? While MagDis performs well in the tested image classification task, its performance in other domains with different characteristics remains unknown.

## Limitations
- The assumption that base algorithms must be scale-free may be restrictive in practice
- The polar decomposition technique may not generalize well to all problem structures
- Empirical evaluation is limited to specific distribution shift scenarios and may not capture the full range of nonstationary environments

## Confidence

- **High Confidence**: The theoretical framework for discounted regret bounds and the rescaling trick mechanism are well-established and mathematically rigorous.
- **Medium Confidence**: The effectiveness of FTRL-based regularization for maintaining inductive bias while forgetting past data is supported by theory but may require more extensive empirical validation.
- **Medium Confidence**: The polar decomposition technique for achieving simultaneous adaptivity shows promise but its general applicability beyond the studied cases remains to be thoroughly tested.

## Next Checks

1. **Generalization to Other Domains**: Test the proposed algorithms on time-series forecasting and recommendation systems to assess their performance in diverse nonstationary environments beyond image classification.

2. **Robustness to Discount Factor Selection**: Conduct ablation studies varying the discount factors (λt) across different magnitudes and patterns to understand the sensitivity and identify optimal selection strategies for various application contexts.

3. **Comparison with State-of-the-Art Methods**: Perform head-to-head comparisons against recent state-of-the-art adaptive online learning algorithms on benchmark datasets to establish the relative performance and computational efficiency of the proposed approach.