---
ver: rpa2
title: Evaluating Datalog Tools for Meta-reasoning over OWL 2 QL
arxiv_id: '2402.02978'
source_url: https://arxiv.org/abs/2402.02978
tags:
- lubm
- datalog
- queries
- performance
- ontologies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work evaluates Datalog tools for meta-reasoning over OWL 2
  QL ontologies under Meta-modeling Semantics (MS). A reduction from OWL 2 QL to Datalog
  for meta-querying is implemented and tested on various tools including LogicBlox,
  RDFox, XSB, NoHR, Clingo, DLV2, Alpha, DLVHex, and HexLite.
---

# Evaluating Datalog Tools for Meta-reasoning over OWL 2 QL

## Quick Facts
- arXiv ID: 2402.02978
- Source URL: https://arxiv.org/abs/2402.02978
- Reference count: 10
- Primary result: DLV2 and XSB provide most consistent and efficient performance for meta-querying OWL 2 QL ontologies with meta-modeling features

## Executive Summary
This paper evaluates various Datalog tools for meta-reasoning over OWL 2 QL ontologies under Meta-modeling Semantics (MS). The authors implement a reduction from OWL 2 QL to Datalog for meta-querying and test it across eight different tools including LogicBlox, RDFox, XSB, NoHR, Clingo, DLV2, Alpha, DLVHex, and HexLite. The experiments are conducted using LUBM and MODEUS ontologies under two resource constraint scenarios: tight (8GB RAM, 15 minutes) and generous (128GB RAM, 30 minutes). The results demonstrate that DLV2 and XSB consistently outperform other tools, particularly on larger ontologies with meta-modeling features.

## Method Summary
The study implements a reduction from OWL 2 QL ontologies to Datalog rules for meta-querying purposes. This reduction is then tested across multiple Datalog tools with varying computational paradigms. The evaluation uses two well-known ontologies - LUBM (for scalability testing) and MODEUS (for complex modeling scenarios). The experiments are conducted under two different resource constraint scenarios to assess tool performance across different computational environments. The performance metrics focus on execution time and memory usage while maintaining correctness of the meta-reasoning results.

## Key Results
- DLV2 and XSB demonstrated the most consistent and efficient performance across all tested scenarios
- The reduction approach successfully handles meta-modeling features in OWL 2 QL ontologies
- Performance differences were most pronounced on larger ontologies with complex meta-modeling structures
- Under tight resource constraints (8GB RAM, 15 minutes), DLV2 showed superior scalability compared to other tools

## Why This Works (Mechanism)
The effectiveness of DLV2 and XSB in this evaluation stems from their efficient handling of recursive rules and complex query patterns inherent in meta-reasoning tasks. DLV2's native support for HEX-programs and XSB's tabling mechanism provide natural advantages for the recursive and transitive reasoning required by OWL 2 QL meta-modeling semantics. The reduction approach effectively translates OWL constructs into Datalog rules that preserve the semantic relationships while maintaining computational tractability.

## Foundational Learning
- OWL 2 QL ontology structure: Essential for understanding the source data representation and why certain reduction patterns are needed
- Datalog evaluation strategies: Critical for comparing tool performance and understanding why certain tools excel at meta-reasoning
- Meta-modeling semantics: Required to grasp the complexity of the reasoning tasks and why they pose challenges for Datalog tools
- Resource constraint modeling: Important for understanding the practical deployment considerations and performance trade-offs
- Reduction correctness verification: Necessary to ensure that the translation from OWL to Datalog preserves semantic meaning

## Architecture Onboarding
Component map: OWL 2 QL ontology -> Reduction engine -> Datalog rules -> Datalog tool -> Query results
Critical path: Ontology loading -> Rule generation -> Fact grounding -> Query execution -> Result validation
Design tradeoffs: Expressiveness vs. computational efficiency, tool-specific optimizations vs. portability, memory usage vs. execution time
Failure signatures: Memory exhaustion on large ontologies, timeouts on complex queries, incorrect results from improper rule generation
First experiments:
1. Run simple LUBM queries on all tools to establish baseline performance
2. Test incremental ontology size scaling to identify performance thresholds
3. Validate rule generation correctness by comparing results across multiple tools

## Open Questions the Paper Calls Out
None

## Limitations
- Focus exclusively on OWL 2 QL ontologies, limiting generalizability to more expressive OWL profiles
- Evaluation based on only two specific ontologies (LUBM and MODEUS), which may not represent diverse real-world scenarios
- Performance comparison limited to specific meta-modeling semantics reduction, other reduction approaches might yield different results
- Resource constraints may not reflect typical production deployment environments

## Confidence
- High confidence: Comparative performance ranking of DLV2 and XSB for the specific experimental setup and ontologies tested
- Medium confidence: Generalizability of findings to other OWL 2 QL ontologies and meta-querying scenarios
- Low confidence: Applicability of conclusions to more expressive OWL profiles or alternative meta-modeling semantics approaches

## Next Checks
1. Test the same tool evaluation on additional OWL 2 QL ontologies with varying complexity, size, and structural characteristics to assess result robustness
2. Implement and compare alternative reduction methods from OWL 2 QL to Datalog to determine if tool performance rankings remain consistent
3. Extend the evaluation to include OWL 2 RL and OWL 2 EL profiles to understand tool performance across different ontology expressivity levels