---
ver: rpa2
title: 'MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on
  Large Language Models'
arxiv_id: '2410.12478'
source_url: https://arxiv.org/abs/2410.12478
tags:
- confidence
- language
- tasks
- multilingual
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MlingConf, the first comprehensive study
  of multilingual confidence estimation on large language models (LLMs). The authors
  address the gap in evaluating LLM confidence estimation abilities beyond English
  by creating a benchmark with four meticulously checked multilingual datasets for
  language-agnostic (LA) tasks and one for language-specific (LS) tasks across five
  languages (English, Japanese, Chinese, French, and Thai).
---

# MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models

## Quick Facts
- arXiv ID: 2410.12478
- Source URL: https://arxiv.org/abs/2410.12478
- Authors: Boyang Xue; Hongru Wang; Rui Wang; Sheng Wang; Zezhong Wang; Yiming Du; Bin Liang; Kam-Fai Wong
- Reference count: 24
- Primary result: Introduces first comprehensive benchmark for multilingual confidence estimation across five languages and proposes Native-Tone Prompting strategy

## Executive Summary
This paper addresses the critical gap in evaluating Large Language Model (LLM) confidence estimation abilities beyond English by introducing MlingConf, a comprehensive multilingual benchmark. The authors create four meticulously translated language-agnostic datasets and one language-specific dataset across five languages (English, Japanese, Chinese, French, and Thai). They evaluate three major confidence estimation methods - probability-based, p(True)-based, and self-verbalized - revealing that English demonstrates notably better calibration performance on language-agnostic tasks. For language-specific tasks, they propose Native-Tone Prompting, which adapts response language to match query linguistic context, significantly improving both reliability and accuracy compared to single-language approaches.

## Method Summary
The study constructs a multilingual benchmark by translating four language-agnostic datasets (TriviaQA, GSM8K, CommonsenseQA, SciQ) into Japanese, Chinese, French, and Thai, followed by consistency checks and human evaluation. They also create LSQA, a language-specific dataset with questions tailored to each language's cultural and geographical contexts. Three confidence estimation methods are evaluated across these languages using GPT-3.5 and Llama-3.1 models: probability-based (geometric mean of token probabilities), p(True)-based (estimated probability of being true), and self-verbalized (verbal confidence statement). The Native-Tone Prompting strategy is proposed for language-specific tasks, which identifies the language context of questions and uses that language for responses to leverage linguistic dominance in pre-training corpora.

## Key Results
- Probability-based confidence estimation performs more stably across languages on Llama-3.1 compared to other methods
- English exhibits notably better calibration performance (lower ECE) than other languages on language-agnostic tasks
- Language-specific prompts (Native-Tone Prompting) significantly improve accuracy and reliability for language-specific tasks
- Using question-related language to prompt LLMs demonstrates better linguistic dominance for language-specific tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Probability-based confidence estimation performs more stably across languages on Llama-3.1
- Mechanism: Uses geometric mean of token-level probabilities normalized for sequence length, providing likelihood-based estimates less sensitive to linguistic variations
- Core assumption: Token probability distributions in Llama-3.1 are well-calibrated during training across different languages
- Evidence anchors: "Prob. demonstrate comparable performance of reliability across different languages" and "Prob. show the superior performance than p(True) and V erb. and performs more stable on Llama-3.1"

### Mechanism 2
- Claim: Language-specific prompts significantly improve accuracy and reliability for language-specific tasks
- Mechanism: Leverages linguistic dominance where specific language corpora contain more relevant knowledge for cultural, geographical, and social contexts
- Core assumption: Language-specific knowledge is better represented in respective language pre-training corpora
- Evidence anchors: "using question-related language to prompt LLMs demonstrates better linguistic dominance" and "linguistic dominance is determined by the language of the subset"

### Mechanism 3
- Claim: English exhibits better calibration performance on language-agnostic tasks
- Mechanism: Extensive English training corpus and specific calibration during training lead to better alignment between predicted confidence and actual accuracy
- Core assumption: English training data quantity and quality is significantly higher than for other languages
- Evidence anchors: "on LA tasks English exhibits notable linguistic dominance in confidence estimations" and "ECE in English... performs better than in other languages"

## Foundational Learning

- Concept: Confidence calibration
  - Why needed here: Evaluates how well predicted confidence matches actual accuracy, crucial for trustworthy AI systems
  - Quick check question: What does an ECE of 0 indicate about a model's confidence predictions?

- Concept: Linguistic dominance
  - Why needed here: Explains why certain languages perform better on specific tasks due to differences in training corpus representation
  - Quick check question: How does linguistic dominance differ between language-agnostic and language-specific tasks according to the results?

- Concept: Token probability normalization
  - Why needed here: Probability-based method uses geometric mean normalization to account for sequence length effects
  - Quick check question: Why is geometric mean used instead of arithmetic mean for calculating joint token probabilities?

## Architecture Onboarding

- Component map: Dataset construction (translation, consistency check, human evaluation) → Dataset storage → LLM API calls (GPT-3.5, Llama-3.1) → Prompt formatting → Confidence estimation (Prob., p(True), V erb.) → Confidence score calculation → Evaluation (PREM, AUROC, ECE) → Result aggregation and analysis

- Critical path: Dataset construction → Confidence estimation (for each method) → Evaluation (all metrics) → Analysis and Native-Tone Prompting implementation

- Design tradeoffs:
  - Translation approach: GPT-4 ensures quality but is expensive; multilingual models could be alternative
  - Confidence methods: Sampling-based methods provide better estimates but are computationally expensive; omitted for efficiency
  - Evaluation metrics: String-matching vs semantic matching - uses PREM to handle slight answer variations

- Failure signatures:
  - Low AUROC across all languages/methods: Indicates fundamental issues with confidence estimation approach
  - High ECE variance across languages: Suggests calibration problems specific to certain languages
  - Poor performance on language-specific tasks regardless of prompt language: Indicates missing language-specific knowledge in training

- First 3 experiments:
  1. Replicate LA task results with different LLM to verify method consistency
  2. Test Native-Tone Prompting on LSQA subset with manual language identification
  3. Compare different string-matching variants for accuracy calculation on sample dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do confidence estimation methods perform on low-resource languages beyond the five studied?
- Basis in paper: Study restricted to five languages due to API costs and need for linguistic experts; suggests extending to more low-resource languages
- Why unresolved: Substantial cost of GPT-4 API for translation and linguistic verification limits scope
- What evidence would resolve it: Extending benchmark to additional low-resource languages and evaluating confidence estimation performance

### Open Question 2
- Question: How can NTP be improved to automatically determine language context without external prompts?
- Basis in paper: NTP relies on external prompts to determine language domain, adding complexity and potential errors
- Why unresolved: Current method requires additional step for language identification
- What evidence would resolve it: Developing cross-lingual method that automatically infers language context from query itself

### Open Question 3
- Question: How do confidence estimation methods perform on tasks beyond LA and LS scenarios?
- Basis in paper: Study focuses on LA and LS tasks but acknowledges other task types may exist
- Why unresolved: Performance on other task types remains unexplored
- What evidence would resolve it: Evaluating methods on diverse task types like dialogue, summarization, or code generation

## Limitations

- Dataset creation relies heavily on automated translation (GPT-4), which may introduce subtle semantic shifts despite consistency checks
- Comparison across different LLM architectures (GPT-3.5 vs Llama-3.1) may conflate model-specific effects with language-specific performance differences
- Native-Tone Prompting assumes reliable language identification, but paper doesn't evaluate scenarios where identification might fail

## Confidence

**High Confidence**: Probability-based confidence estimation provides stable performance across languages on Llama-3.1
**Medium Confidence**: English shows better calibration performance, but could be influenced by prompt formulation or evaluation metric sensitivity
**Medium Confidence**: Native-Tone Prompting effectiveness demonstrated, but improvement might be partially attributable to language identification step

## Next Checks

1. Cross-model validation: Replicate probability-based confidence estimation comparison across third LLM architecture to verify stability claim isn't model-specific

2. Language identification robustness: Systematically evaluate Native-Tone Prompting performance when language identification has varying accuracy levels (100%, 90%, 80%)

3. Alternative translation validation: Create subset using professional human translation instead of automated translation, then compare confidence estimation performance to assess potential bias from translation artifacts