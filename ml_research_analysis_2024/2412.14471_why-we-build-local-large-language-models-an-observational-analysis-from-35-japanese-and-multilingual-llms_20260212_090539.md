---
ver: rpa2
title: 'Why We Build Local Large Language Models: An Observational Analysis from 35
  Japanese and Multilingual LLMs'
arxiv_id: '2412.14471'
source_url: https://arxiv.org/abs/2412.14471
tags:
- japanese
- aj296
- llms
- aj231
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study analyzes 35 Japanese, English, and multilingual large
  language models across 19 benchmarks to understand the benefits of training on non-English
  text. Using correlation analysis and PCA, it identifies three key ability factors:
  a general factor linked to English computational budget, a Japanese-specific factor
  for cultural knowledge and translation linked to Japanese training data, and a multilingual
  factor for arithmetic and code tasks.'
---

# Why We Build Local Large Language Models: An Observational Analysis from 35 Japanese and Multilingual LLMs

## Quick Facts
- arXiv ID: 2412.14471
- Source URL: https://arxiv.org/abs/2412.14471
- Reference count: 40
- Primary result: Training on Japanese text improves Japanese-specific tasks, while general and multilingual abilities can be developed with English or multilingual training.

## Executive Summary
This study analyzes 35 Japanese, English, and multilingual LLMs across 19 benchmarks to understand the benefits of training on non-English text. Using correlation analysis and PCA, it identifies three key ability factors: a general factor linked to English computational budget, a Japanese-specific factor for cultural knowledge and translation linked to Japanese training data, and a multilingual factor for arithmetic and code tasks. The findings show that Japanese-specific abilities require Japanese training data, while general abilities transfer across languages with English training.

## Method Summary
The study evaluates 35 publicly available LLMs on 19 benchmarks covering Japanese and English tasks across multiple domains. Using zero-shot or few-shot in-context learning, models are scored on QA, academic subjects, reading comprehension, code generation, arithmetic reasoning, summarization, and translation. Correlation analysis identifies task clusters, PCA extracts ability factors, and log-linear regression tests scaling relationships between computational budgets and ability factors.

## Key Results
- Three distinct ability factors identified: general (PC1), Japanese-specific (PC2), and multilingual (PC3)
- Japanese computational budget scales with Japanese-specific abilities, indicating these emerge from Japanese training data
- English computational budget drives general ability factor affecting cross-lingual academic, code, and arithmetic tasks
- Strong cross-lingual correlations for academic subjects (0.91), arithmetic reasoning (0.94), and code generation (0.98)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Training on Japanese text improves Japanese-specific knowledge and English-Japanese translation abilities.
- Mechanism: The Japanese computational budget scales with a principal component that captures Japanese cultural knowledge and translation tasks. This scaling relationship suggests these abilities emerge directly from exposure to Japanese text rather than from design choices like architecture or continual pre-training.
- Core assumption: The log-linear scaling relationship between Japanese computational budget and the Japanese-specific ability factor is causal, not spurious.
- Evidence anchors: Correlation between Japanese computational budget and Japanese ability factor; cross-lingual analysis showing Japanese-specific tasks don't transfer from English training.

### Mechanism 2
- Claim: English computational budget drives a general ability factor that improves performance on cross-lingual tasks like academic subjects, code generation, and arithmetic reasoning.
- Mechanism: The English computational budget scales with a general ability factor representing average performance across most benchmarks except Japanese-specific tasks. This indicates that general cognitive abilities transfer across languages when trained on English text.
- Core assumption: The general ability factor captures truly general abilities, not just English-specific ones.
- Evidence anchors: Strong cross-lingual correlations between paired benchmarks; scaling relationship between English budget and general ability factor.

### Mechanism 3
- Claim: Cross-lingual correlation analysis reveals which tasks benefit from multilingual training versus language-specific training.
- Mechanism: By computing Pearson correlations between task scores across 35 models, the study identifies task clusters with strong cross-lingual correlations versus weak correlations. PCA then maps these correlations to distinct ability factors.
- Core assumption: Pearson correlation is an appropriate measure of task similarity and captures meaningful ability distinctions.
- Evidence anchors: Task clustering based on correlation patterns; PCA factor loadings reflecting these clusters.

## Foundational Learning

- Concept: Principal Component Analysis (PCA)
  - Why needed here: PCA reduces the 19-dimensional benchmark score space to interpretable ability factors, enabling identification of general vs. Japanese-specific abilities.
  - Quick check question: If you have a dataset with 35 models and 19 benchmarks, how many principal components would you need to explain >90% of the variance?

- Concept: Scaling Laws
  - Why needed here: The study uses log-linear scaling relationships between computational budget and ability factors to determine whether Japanese-specific abilities emerge from Japanese training data.
  - Quick check question: What is the formula for estimating training FLOPs in the Chinchilla scaling laws?

- Concept: Cross-Lingual Benchmarking
  - Why needed here: By using paired Japanese-English benchmarks, the study can distinguish between abilities that transfer across languages versus those requiring language-specific training.
  - Quick check question: Why is it important to have benchmarks that are translations of each other when studying cross-lingual abilities?

## Architecture Onboarding

- Component map: 35 LLMs (varying parameters, pretraining approaches, language distributions) -> Pearson correlation analysis (task clusters) -> PCA (ability factors) -> Log-linear regression (scaling laws) -> Benchmark evaluation (19 tasks)

- Critical path: Collect model metadata -> Compute correlations -> Run PCA -> Analyze scaling laws -> Interpret ability factors

- Design tradeoffs:
  - Base models only vs. instruction-tuned: Avoids confounding effects of fine-tuning but limits practical applicability
  - Excluding safety/bias tasks: Focuses on fundamental abilities but misses important considerations
  - PCA vs. other dimensionality reduction: PCA provides interpretable factors but assumes linear relationships

- Failure signatures:
  - Uniform PCA loadings across all tasks prevents distinguishing general vs. language-specific abilities
  - Weak or non-linear scaling relationships invalidate conclusions about computational budget effects
  - Artificially high cross-lingual correlations due to benchmark translation artifacts mislead task clustering

- First 3 experiments:
  1. Replicate correlation analysis with Spearman rank correlation to verify linear assumptions
  2. Test leave-one-out cross-validation stability of PCA factor loadings
  3. Compute correlations between individual benchmark scores and computational budgets to identify driving tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed cross-lingual transferability of abilities in Japanese and English extend to other language pairs, such as Chinese-English or Spanish-English?
- Basis in paper: The study focuses on Japanese-English tasks, finding strong cross-lingual correlations for academic subjects, arithmetic reasoning, and code generation.
- Why unresolved: The paper limits its analysis to Japanese-English benchmarks and does not explore other language pairs.
- What evidence would resolve it: Evaluating LLMs across multiple language pairs with comparable benchmarks and analyzing cross-lingual correlations to see if similar transferability patterns emerge.

### Open Question 2
- Question: What specific components of Japanese training data contribute most to the development of Japanese-specific abilities, such as cultural knowledge and translation skills?
- Basis in paper: The study finds that Japanese computational budget correlates with Japanese-specific abilities but does not analyze the composition or characteristics of the training data.
- Why unresolved: The paper uses aggregated token counts for Japanese data without examining data quality, diversity, or domain specificity.
- What evidence would resolve it: Detailed analysis of Japanese training corpora, including domain distribution, text complexity, and cultural content, correlated with model performance on Japanese-specific tasks.

### Open Question 3
- Question: How do the scaling laws for Japanese-specific abilities compare to those for general and multilingual abilities when controlling for model size and architecture?
- Basis in paper: The study identifies scaling laws for general ability with English computational budget and Japanese ability with Japanese computational budget, but does not control for model architecture.
- Why unresolved: The analysis does not isolate the effect of architecture from the effect of training data and computational budget.
- What evidence would resolve it: Training multiple models with identical architectures but varying training data composition and computational budgets, then comparing scaling relationships across ability types.

## Limitations

- The study cannot definitively establish causality between training data and ability factors due to potential confounding factors like model architecture and data curation quality.
- Japanese computational budget estimates for some models are based on approximations rather than official data, introducing uncertainty into scaling law analysis.
- Exclusion of safety/bias benchmarks and instruction-tuned models limits practical relevance to real-world deployment scenarios.

## Confidence

**High Confidence:** The identification of three distinct ability factors through PCA is well-supported by the data and consistent across multiple analyses. Cross-lingual correlation patterns between paired benchmarks are robust.

**Medium Confidence:** The attribution of ability factors to specific training effects is reasonable but requires careful interpretation. Scaling relationships are observed, but causal mechanisms could involve confounding factors.

**Low Confidence:** The methodological limitations of excluding safety/bias tasks and instruction-tuned models represent significant gaps that may affect practical applicability.

## Next Checks

1. Conduct a controlled experiment comparing two models with identical architectures but different language-specific training distributions to isolate the effect of Japanese vs. English training data on Japanese-specific task performance.

2. Replicate PCA analysis using alternative dimensionality reduction techniques (t-SNE, UMAP) and correlation measures (Spearman vs. Pearson) to verify the three-factor structure is not an artifact.

3. Evaluate instruction-tuned models on the same benchmarks to determine whether identified ability factors persist after task-oriented fine-tuning and assess how much fine-tuning modifies pretraining-determined ability structure.