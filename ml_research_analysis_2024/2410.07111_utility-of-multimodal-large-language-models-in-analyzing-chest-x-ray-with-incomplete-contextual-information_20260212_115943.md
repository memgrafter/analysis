---
ver: rpa2
title: Utility of Multimodal Large Language Models in Analyzing Chest X-ray with Incomplete
  Contextual Information
arxiv_id: '2410.07111'
source_url: https://arxiv.org/abs/2410.07111
tags:
- data
- multimodal
- performance
- language
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study evaluated the performance of three large language models
  (OpenFlamingo, MedFlamingo, IDEFICS) in generating chest X-ray impressions from
  radiology reports with varying levels of text corruption (0%, 20%, 50%, 80%). Models
  were tested in both text-only and multimodal (text + image) formats using 300 samples
  from MIMIC-CXR.
---

# Utility of Multimodal Large Language Models in Analyzing Chest X-ray with Incomplete Contextual Information

## Quick Facts
- **arXiv ID**: 2410.07111
- **Source URL**: https://arxiv.org/abs/2410.07111
- **Reference count**: 40
- **Primary result**: Multimodal LLMs outperform text-only models when radiology report text is corrupted

## Executive Summary
This study evaluates how three large language models (OpenFlamingo, MedFlamingo, IDEFICS) perform in generating chest X-ray impressions from radiology reports with varying levels of text corruption (0%, 20%, 50%, 80%). The models were tested in both text-only and multimodal (text + image) formats using 300 samples from MIMIC-CXR. Results show that multimodal models, particularly MedFlamingo and IDEFICS, significantly outperform their text-only counterparts when text data is corrupted, demonstrating that visual features can compensate for incomplete textual information in clinical reports.

## Method Summary
The study used 300 radiology image-report pairs from MIMIC-CXR database, with text data corrupted by randomly removing words at 20%, 50%, and 80% rates. Three large language models (OpenFlamingo, MedFlamingo, IDEFICS) were tested in both text-only and multimodal formats. Few-shot learning with BM25-selected examples was used to improve performance. Model outputs were evaluated using ROUGE-L, F1RadGraph, and F1CheXbert metrics, with statistical significance determined using Wilcoxon tests due to non-normal data distribution.

## Key Results
- Multimodal models significantly outperformed text-only models under text corruption (p<0.001)
- MedFlamingo, the clinically fine-tuned model, generally outperformed the generalist model OpenFlamingo
- All models showed performance decline with increasing text corruption, but multimodal models mitigated this impact
- Text-only models showed similar performance levels, with OpenFlamingo performing best on complete text

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multimodal models outperform text-only models when input text is corrupted because visual features compensate for missing or ambiguous textual information.
- Mechanism: The image encoder provides additional semantic context that disambiguates or supplements corrupted text, allowing the model to infer correct clinical impressions despite incomplete findings.
- Core assumption: Visual features from chest X-rays contain enough discriminative information to fill gaps in textual reports without introducing significant noise.
- Evidence anchors:
  - [abstract] "multimodal LLMs can mitigate the impact of incomplete textual information in radiology reports"
  - [section] "adding images significantly boosted the performance of MedFlamingo and IDEFICS (p<0.001), equaling or surpassing OpenFlamingo, even with incomplete text"
  - [corpus] Weak evidence; corpus focuses on general multimodal approaches without specific comparison to corrupted data performance.
- Break condition: If image features are too noisy or irrelevant to the corrupted text content, the multimodal approach could degrade performance below text-only levels.

### Mechanism 2
- Claim: Fine-tuned models (MedFlamingo) perform better than general models (OpenFlamingo) on medical tasks because they incorporate domain-specific knowledge during training.
- Mechanism: Medical fine-tuning exposes the model to clinical terminology, disease patterns, and report structures specific to radiology, improving its ability to generate accurate impressions.
- Core assumption: The fine-tuning dataset contains representative and accurate medical examples that capture the complexity of real clinical reports.
- Evidence anchors:
  - [abstract] "MedFlamingo, the clinically fine-tuned model, outperformed the generalist model, OpenFlamingo"
  - [section] "Med-Flamingo, the clinically fine-tuned model, outperformed the generalist model, OpenFlamingo, in all but two cases"
  - [corpus] Moderate evidence; corpus includes related work on medical fine-tuning but lacks direct performance comparisons under data corruption.
- Break condition: If fine-tuning data is corrupted or biased, the model may learn incorrect patterns that harm performance on clean or partially corrupted data.

### Mechanism 3
- Claim: Few-shot learning with BM25-selected examples improves model performance by providing relevant context without requiring extensive retraining.
- Mechanism: BM25 retrieves similar cases from the dataset, and the model uses these as in-context examples to better understand the current task, especially when input data is incomplete.
- Core assumption: The retrieved examples are sufficiently similar to the target case to provide useful guidance without introducing conflicting information.
- Evidence anchors:
  - [section] "We used few-shot learning (18) techniques to improve the performance of LLMs... We selected the top 2 examples based on BM25 scores"
  - [section] "Unlike text-only models, not many multimodal LLMs can handle few-shot learning"
  - [corpus] Weak evidence; corpus lacks specific discussion of BM25 or few-shot learning effectiveness in multimodal medical contexts.
- Break condition: If BM25 retrieves irrelevant or noisy examples, the model's performance may degrade, especially with corrupted input data.

## Foundational Learning

- Concept: ROUGE-L metric and its role in evaluating text generation quality
  - Why needed here: The study uses ROUGE-L to quantify how well generated impressions match reference reports, making it essential to understand what the metric measures.
  - Quick check question: What does the F-score in ROUGE-L represent, and why is it preferred over simple recall or precision alone?

- Concept: Understanding multimodal model architecture (vision-language integration)
  - Why needed here: The performance gains come from combining text and image processing, so understanding how these modalities interact is crucial.
  - Quick check question: How do cross-attention layers in Flamingo variants enable effective integration of visual and textual information?

- Concept: Statistical significance testing (Wilcoxon test) for comparing model performance
  - Why needed here: The study uses non-parametric tests due to non-normal data distribution, so understanding when and why to use these tests is important.
  - Quick check question: Why is the Wilcoxon test preferred over a t-test when comparing ROUGE-L scores across models?

## Architecture Onboarding

- Component map: Input layer (corrupted text + chest X-ray images) -> BM25 retrieval for few-shot examples -> Multimodal encoder (Flamingo variants) -> Cross-attention layers -> Text generation -> Evaluation (ROUGE-L, F1RadGraph, F1CheXbert)
- Critical path: Text preprocessing -> BM25 retrieval -> Multimodal encoding -> Cross-attention -> Impression generation -> Metric calculation
- Design tradeoffs:
  - Model size vs. inference speed (3B vs. 9B parameters)
  - Few-shot learning vs. full fine-tuning (memory constraints)
  - Text-only vs. multimodal processing (cost vs. performance)
- Failure signatures:
  - Performance degradation with high text corruption (>50%) even with images
  - Multimodal models slower than text-only despite potential performance gains
  - Statistical significance not achieved despite apparent performance differences
- First 3 experiments:
  1. Test each model on clean text-only input to establish baseline performance
  2. Apply 50% text corruption to each model and measure performance drop
  3. Add images to corrupted text input and verify multimodal improvement exceeds text-only degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do multimodal LLMs perform when corrupted text is combined with degraded or missing image data in chest X-ray reports?
- Basis in paper: [inferred] The study tested multimodal models with corrupted text but did not explore scenarios where both text and image data are incomplete.
- Why unresolved: The current study focused solely on text corruption and did not investigate the impact of simultaneous degradation in both modalities.
- What evidence would resolve it: Experiments comparing multimodal LLM performance with various combinations of text and image corruption levels would clarify their robustness.

### Open Question 2
- Question: What is the optimal ratio of corrupted text to image quality that maximizes multimodal LLM performance in chest X-ray analysis?
- Basis in paper: [inferred] The study demonstrated that multimodal models outperform text-only models with corrupted text, suggesting a potential optimal balance between modalities.
- Why unresolved: The study did not systematically vary both text corruption and image quality to determine an optimal balance.
- What evidence would resolve it: Systematic testing of multimodal models across a range of text corruption and image quality combinations would identify optimal performance thresholds.

### Open Question 3
- Question: How do the costs and performance of multimodal LLMs compare to specialized medical image processing models in clinical settings?
- Basis in paper: [explicit] The study included a cost analysis comparing multimodal LLMs to text-only models but did not compare them to dedicated medical image processing systems.
- Why unresolved: The current cost analysis only considered different LLM configurations, not specialized medical imaging tools.
- What evidence would resolve it: Comparative studies of multimodal LLMs and dedicated medical image processing systems in terms of cost, performance, and clinical utility would provide insights into optimal deployment strategies.

## Limitations
- The study relies on a single dataset (MIMIC-CXR) with a specific corruption methodology, limiting generalizability
- The evaluation uses random word removal rather than clinically realistic text omissions
- The study does not address potential multiple comparison issues across numerous model-condition combinations

## Confidence
- **High Confidence**: The core finding that multimodal models outperform text-only models under text corruption (p<0.001) is well-supported by the experimental design and statistical analysis.
- **Medium Confidence**: The claim that fine-tuning improves medical performance is supported but could be strengthened with ablation studies.
- **Low Confidence**: The effectiveness of BM25-based few-shot learning in this multimodal medical context lacks strong supporting evidence.

## Next Checks
1. Validate model performance on a separate chest X-ray dataset (e.g., CheXpert or PadChest) to assess whether the multimodal advantage persists across different institutional data distributions and report formats.
2. Replace random word corruption with clinically plausible text omissions (such as removing entire findings or impression sentences) to evaluate whether multimodal models maintain their advantage when faced with realistic documentation errors.
3. Conduct an interpretability study examining how cross-attention weights change with increasing text corruption to verify that visual features are indeed compensating for missing textual information rather than simply adding noise.