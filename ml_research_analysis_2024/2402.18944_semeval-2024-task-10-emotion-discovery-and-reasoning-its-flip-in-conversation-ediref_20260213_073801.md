---
ver: rpa2
title: 'SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation
  (EDiReF)'
arxiv_id: '2402.18944'
source_url: https://arxiv.org/abs/2402.18944
tags:
- task
- emotion
- code-mixed
- teams
- trigger
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents the results of SemEval 2024 Task 10, focusing
  on Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). The task involves
  three subtasks: emotion recognition in code-mixed conversations, emotion flip reasoning
  in code-mixed conversations, and emotion flip reasoning in English conversations.'
---

# SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)

## Quick Facts
- arXiv ID: 2402.18944
- Source URL: https://arxiv.org/abs/2402.18944
- Reference count: 17
- Primary result: F1-scores of 0.70, 0.79, and 0.76 for three emotion recognition and reasoning subtasks

## Executive Summary
This paper presents the results of SemEval 2024 Task 10, focusing on Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). The task involves three subtasks: emotion recognition in code-mixed conversations, emotion flip reasoning in code-mixed conversations, and emotion flip reasoning in English conversations. A total of 84 participants engaged in the task, with the best systems achieving F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. The task data consists of manually annotated conversations in English and Hindi-English code-mixed dialogues, focusing on emotions and triggers for emotion shifts. The paper summarizes the results and findings from 24 teams alongside their system descriptions.

## Method Summary
The task involves three subtasks: emotion recognition in code-mixed conversations, emotion flip reasoning in code-mixed conversations, and emotion flip reasoning in English conversations. Participants used a variety of approaches, with Large Language Models (LLMs) like BERT, RoBERTa, and GPT being prevalent, alongside classical ML methods like XGBoost. The data consists of manually annotated conversations in English and Hindi-English code-mixed dialogues focusing on emotions and triggers for emotion shifts. The best-performing systems achieved F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks.

## Key Results
- F1-score of 0.70 achieved for emotion recognition in code-mixed conversations
- F1-score of 0.79 achieved for emotion flip reasoning in code-mixed conversations
- F1-score of 0.76 achieved for emotion flip reasoning in English conversations
- Approximately 18 teams leveraged LLMs for the emotion recognition and flip reasoning tasks
- Top two teams for the code-mixed emotion flip reasoning task used conventional ML and rule-based approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Emotion-flip reasoning benefits from detecting explicit trigger utterances in conversation context.
- **Mechanism:** The system identifies emotion-flip instances by comparing emotion labels between consecutive utterances of the same speaker. It then labels preceding utterances as triggers if they cause the flip.
- **Core assumption:** Most emotion flips in conversations are caused by explicit utterances rather than external context.
- **Evidence anchors:**
  - [abstract] "The task involves three subtasks: emotion recognition in code-mixed conversations, emotion flip reasoning in code-mixed conversations, and emotion flip reasoning in English conversations."
  - [section] "In Figure 1a, Speaker B undergoes a transition in emotion (neutral→fear) between utterances u6 and u8... this emotional shift can be attributed to the contributions of Speaker A through utterances u5 and u7."
  - [corpus] "Found 25 related papers... Average neighbor FMR=0.518"
- **Break condition:** When emotion flips are caused by external events not mentioned in the dialogue, leading to implicit triggers that the system cannot detect.

### Mechanism 2
- **Claim:** LLMs with fine-tuning achieve superior performance on emotion recognition and flip reasoning tasks.
- **Mechanism:** Pre-trained transformer models like BERT and RoBERTa are fine-tuned on the task-specific datasets to capture contextual patterns in conversations.
- **Core assumption:** The contextual understanding captured by pre-trained LLMs generalizes well to emotion recognition in conversations.
- **Evidence anchors:**
  - [abstract] "The best systems achieving F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks."
  - [section] "A prevalent preference for LLMs among teams addressing the ERC and EFR tasks, with approximately 18 methods leveraging LLMs"
  - [corpus] "Found 25 related papers... Average neighbor FMR=0.518"
- **Break condition:** When the dataset size is too small for effective fine-tuning, or when code-mixed language patterns differ significantly from pre-training data.

### Mechanism 3
- **Claim:** Simple statistical methods can outperform complex models for emotion-flip reasoning due to predictable trigger patterns.
- **Mechanism:** Since most emotion flips are triggered by the immediately preceding utterance, simple classifiers like XGBoost or rule-based approaches achieve high accuracy.
- **Core assumption:** The distribution of triggers is highly skewed, with the previous utterance being the most common trigger.
- **Evidence anchors:**
  - [section] "Notably, the leading four teams achieved identical F1-scores, with the top two teams opting for conventional ML and rule-based approaches... This pattern underscores the significance of the preceding utterance as a trigger."
  - [section] "Illustrated in Figure 2 is the trigger distribution within the dialogues of EFR-M ASAC and MELD-FR. Evidently, the majority of trigger utterances are the i − 1th utterances."
  - [corpus] "Found 25 related papers... Average neighbor FMR=0.518"
- **Break condition:** When emotion flip patterns become more complex and distributed across multiple utterances, reducing the effectiveness of simple trigger detection.

## Foundational Learning

- **Concept:** Code-mixing in NLP
  - Why needed here: The task specifically involves Hindi-English code-mixed conversations, requiring understanding of how to process mixed language data.
  - Quick check question: What challenges arise when processing code-mixed text compared to monolingual text?

- **Concept:** Emotion recognition in conversations
  - Why needed here: The first subtask requires identifying emotions for each utterance in a conversation context.
  - Quick check question: How does context from previous utterances affect emotion classification for the current utterance?

- **Concept:** Trigger detection for emotion flips
  - Why needed here: The second and third subtasks require identifying which utterances caused an emotion change.
  - Quick check question: What makes an utterance a trigger for an emotion flip versus just being in the conversation context?

## Architecture Onboarding

- **Component map:** Input processing -> Context encoder (LLM or RNN) -> Emotion classifier (for Task A) or Trigger classifier (for Tasks B/C) -> Output layer
- **Critical path:** For emotion recognition: tokenization -> contextual embedding -> classification; For flip reasoning: emotion prediction -> emotion change detection -> trigger identification
- **Design tradeoffs:** LLM-based approaches offer better context understanding but require more data and computation; statistical methods are simpler but may miss complex patterns
- **Failure signatures:** Low precision on trigger detection suggests over-reliance on simple patterns; poor emotion classification indicates insufficient contextual modeling
- **First 3 experiments:**
  1. Baseline: Train a simple LSTM on emotion classification to establish minimum performance
  2. Context length analysis: Test different context window sizes to determine optimal amount of conversational history
  3. Trigger distribution analysis: Verify the assumption that i-1 utterances are most common triggers before building flip reasoning models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of emotion flip reasoning (EFR) models vary when dealing with implicit versus explicit triggers?
- Basis in paper: [explicit] The paper mentions the challenge of implicit triggers, stating that "In both the EFR-M ASAC and MELD-FR datasets, instances of implicit triggers exist where no trigger utterances are marked in the dialogue."
- Why unresolved: The paper acknowledges the existence of implicit triggers but does not provide specific data on how well models perform on this subset of the data compared to explicit triggers.
- What evidence would resolve it: A detailed analysis comparing model performance on instances with implicit triggers versus explicit triggers would clarify the difficulty models face with implicit triggers.

### Open Question 2
- Question: How does the effectiveness of different emotion recognition approaches (e.g., LLMs, classical ML, rule-based) vary across different emotion categories, especially considering the skewed distribution of emotions in the dataset?
- Basis in paper: [explicit] The paper notes that "five portray negative feelings (Anger, Contempt, Disgust, Fear, and Sadness), while only one represents positive emotions (Joy)" and that "many teams, like IITK, have noted that their models perform better for the neutral and joy labels than for any other emotion."
- Why unresolved: While the paper mentions the skewed distribution and varying performance across emotion categories, it does not provide a comprehensive analysis of how different approaches perform on each emotion category.
- What evidence would resolve it: A detailed breakdown of model performance for each emotion category would reveal which approaches are more effective for specific emotions, especially given the dataset's imbalance.

### Open Question 3
- Question: What is the optimal amount of context needed for accurate emotion recognition and emotion flip reasoning in conversations?
- Basis in paper: [explicit] The paper mentions that "nearby utterances within a dialogue exert a more pronounced impact on determining the emotional nuances of a speaker compared to utterances further removed in context" and that some teams "initially ascertain the requisite extent of context needed for conducting ERC, before proceeding with classification."
- Why unresolved: The paper acknowledges the importance of context but does not provide specific findings on the optimal context window size for emotion recognition and flip reasoning tasks.
- What evidence would resolve it: Experiments varying the context window size and analyzing the corresponding performance changes would determine the optimal context needed for accurate emotion recognition and flip reasoning.

## Limitations
- Limited dataset size, particularly for code-mixed Hindi-English conversations, may not capture full diversity of code-switching patterns
- Specific implementation details of top-performing systems are not fully disclosed, making exact reproduction challenging
- Effectiveness of proposed approaches on different code-mixing patterns and languages remains untested

## Confidence
- **High confidence** in overall task design and evaluation methodology
- **Medium confidence** in LLM superiority claim, as performance gap between LLM-based and simpler approaches was not substantial across all tasks
- **Low confidence** in simple methods outperforming complex models, as this appears to be task-specific rather than generalizable

## Next Checks
1. Test the proposed systems on additional code-mixed language pairs (e.g., Spanish-English, Arabic-French) to assess generalizability beyond Hindi-English
2. Conduct ablation studies on the context window size to determine the minimum required context for accurate emotion flip reasoning
3. Evaluate the systems on conversations with implicit emotion triggers (external events not mentioned in dialogue) to test the limits of the explicit trigger detection approach