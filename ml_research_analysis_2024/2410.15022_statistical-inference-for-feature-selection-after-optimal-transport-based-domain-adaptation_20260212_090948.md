---
ver: rpa2
title: Statistical Inference for Feature Selection after Optimal Transport-based Domain
  Adaptation
arxiv_id: '2410.15022'
source_url: https://arxiv.org/abs/2410.15022
tags:
- inference
- after
- domain
- sfs-da
- xumenetv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel statistical method for controlling
  the false positive rate (FPR) in feature selection (FS) under domain adaptation
  (DA). The proposed SFS-DA method leverages the Selective Inference framework to
  conduct valid statistical tests on FS results after DA, ensuring FPR control at
  a pre-specified level (e.g., 0.05) while maximizing the true positive rate.
---

# Statistical Inference for Feature Selection after Optimal Transport-based Domain Adaptation

## Quick Facts
- arXiv ID: 2410.15022
- Source URL: https://arxiv.org/abs/2410.15022
- Authors: Nguyen Thang Loi; Duong Tan Loc; Vo Nguyen Le Duy
- Reference count: 35
- Key outcome: Introduces SFS-DA method that controls FPR in feature selection under domain adaptation using Selective Inference framework, achieving FPR control at α=0.05 while maximizing TPR

## Executive Summary
This paper addresses the critical challenge of performing valid statistical inference for feature selection after domain adaptation when target domain data is limited. The proposed SFS-DA method combines optimal transport-based domain adaptation with the Selective Inference framework to compute valid p-values for selected features while controlling false positive rate. By characterizing the feature selection process under domain adaptation through linear and quadratic inequalities, the method efficiently computes valid p-values. Extensive experiments demonstrate that SFS-DA successfully controls FPR at the pre-specified level while achieving higher statistical power compared to existing methods.

## Method Summary
The SFS-DA method consists of three main components: (1) Optimal transport-based domain adaptation transforms source domain data to align with the target domain distribution; (2) Lasso or elastic net feature selection is performed on the combined transformed data; (3) The Selective Inference framework computes valid p-values by conditioning on the feature selection event. The key innovation is the divide-and-conquer strategy that efficiently computes the truncation region Z for p-value calculation, even for high-dimensional problems. The method is theoretically proven to control FPR at the pre-specified level α while maximizing TPR.

## Key Results
- SFS-DA successfully controls FPR at α=0.05 on both synthetic and real-world datasets
- Achieves higher statistical power (TPR) compared to baseline methods including No inference, Naive, Bonferroni, and DS
- Computational complexity scales linearly with the number of source instances
- Extension to elastic net improves stability without sacrificing FPR control

## Why This Works (Mechanism)

### Mechanism 1
The Selective Inference framework allows valid p-value computation after feature selection under domain adaptation by conditioning the test statistic on the selection event. By neutralizing the dependency introduced by feature selection and domain adaptation, the false positive rate is controlled at the pre-specified level α. This works when the conditional distribution of the test statistic given the selection event is tractable and can be characterized via linear or quadratic inequalities.

### Mechanism 2
Domain adaptation via optimal transport does not destroy the structure needed for valid statistical inference because the OT solution can be expressed in terms of the test statistic parameter z, and the selection event remains piecewise-linear/quadratic in z. This works when the optimal transport solution can be expressed in terms of the test statistic parameter and remains tractable under DA.

### Mechanism 3
The divide-and-conquer strategy makes the computation of the truncation region Z tractable even for high-dimensional problems by decomposing the one-dimensional space into sub-problems conditioned on the OT solution and feature signs. Each sub-problem becomes a simple interval intersection that can be solved efficiently. This works when the number of sub-problems remains manageable and each can be solved in polynomial time.

## Foundational Learning

- **Concept:** Selective Inference (SI) framework
  - **Why needed here:** Traditional inference assumes fixed features, but FS under DA violates this. SI conditions on the selection event, making p-values valid.
  - **Quick check question:** What is the key difference between naive p-values and selective p-values in the context of feature selection?

- **Concept:** Optimal Transport (OT) for Domain Adaptation
  - **Why needed here:** Limited target data requires transferring knowledge from a source domain. OT aligns distributions while preserving geometric structure.
  - **Quick check question:** How does OT-based DA differ from other DA methods like feature augmentation or adversarial training?

- **Concept:** Karush–Kuhn–Tucker (KKT) conditions for Lasso
  - **Why needed here:** The selection event (which features are chosen) can be expressed as a set of linear inequalities derived from KKT conditions.
  - **Quick check question:** What role do the KKT conditions play in characterizing the truncation region Z?

## Architecture Onboarding

- **Component map:** Data preprocessing (source/target split, OT cost matrix) -> Domain adaptation (OT solver → transformed source data) -> Feature selection (Lasso/elastic net on combined data) -> Inference engine (SI framework → truncation region Z → p-values) -> Evaluation (FPR/TPR control, comparison to baselines)

- **Critical path:** 1. OT-based DA on combined source/target data; 2. Lasso feature selection on transformed data; 3. For each selected feature: parametrize data along test statistic direction, compute truncation region Z via divide-and-conquer, calculate selective p-value

- **Design tradeoffs:** OT accuracy vs. computational cost; Lasso sparsity vs. statistical power; Divide-and-conquer granularity vs. runtime; Conditioning on nuisance components vs. tractability

- **Failure signatures:** FPR >> α (invalid inference, likely incorrect truncation region); Extremely high runtime (too many sub-problems or inefficient OT); Low TPR (over-conditioning or overly conservative inference)

- **First 3 experiments:** 1. Synthetic data with known ground truth: Verify FPR control and TPR; 2. Vary source/target size ratio: Test robustness to data imbalance; 3. Compare OT vs. no DA: Quantify benefit of domain adaptation

## Open Questions the Paper Calls Out

### Open Question 1
How does the computational complexity of SFS-DA scale with increasing feature dimensionality (p) beyond the small-scale experiments presented? The paper shows linear scaling with sample size but doesn't explore high-dimensional settings where p >> ns. What evidence would resolve it: Experiments varying p while keeping ns fixed, measuring both computational time and inference quality (FPR, TPR) in high-dimensional settings.

### Open Question 2
What is the sensitivity of SFS-DA to the choice of hyperparameters λ (regularization) and γ (elastic net mixing parameter)? The paper uses fixed values λ=10 and γ=1 but doesn't analyze their impact on performance. What evidence would resolve it: Systematic experiments varying λ and γ, showing FPR and TPR across a range of parameter values, potentially including cross-validation for optimal selection.

### Open Question 3
How does SFS-DA perform when the source and target domains have significantly different distributions, beyond the mild shifts assumed in experiments? The paper uses OT-based DA to align distributions but doesn't test scenarios with large domain shifts or potential failure cases. What evidence would resolve it: Experiments with artificially induced large domain shifts, measuring FPR and TPR degradation, and comparing performance against methods designed for large shifts.

### Open Question 4
Can the divide-and-conquer strategy in SFS-DA be further optimized to reduce computational overhead, especially in high-dimensional settings? While the current method scales linearly with ns, there may be opportunities for further optimization. What evidence would resolve it: Comparative analysis of different divide-and-conquer strategies or approximation methods, measuring both computational time and statistical performance trade-offs.

## Limitations

- Computational cost of divide-and-conquer strategy may become prohibitive for very high-dimensional problems
- Reliance on linear/quadratic inequality characterization may not hold for all OT solvers
- Assumes OT transformation preserves sufficient structure for valid inference

## Confidence

- **High confidence:** Core FPR control mechanism through SI framework (theoretical proofs); divide-and-conquer approach for truncation region computation (empirical evidence of linear scaling)
- **Medium confidence:** Domain adaptation mechanism (practical stability of OT solutions across datasets remains to be fully validated); Extension to elastic net (builds on Lasso framework but introduces additional complexity)

## Next Checks

1. Test FPR control on datasets with highly non-linear relationships between source and target domains to verify robustness of OT-based DA inference mechanism
2. Evaluate computational scalability on high-dimensional datasets (p >> n) to identify practical limits of divide-and-conquer approach
3. Compare inference validity when using different OT solvers (e.g., entropic vs. exact) to assess sensitivity to choice of domain adaptation method