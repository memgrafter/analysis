---
ver: rpa2
title: 'Seeing the Image: Prioritizing Visual Correlation by Contrastive Alignment'
arxiv_id: '2405.17871'
source_url: https://arxiv.org/abs/2405.17871
tags:
- llav
- arxiv
- tokens
- image
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of suboptimal cross-modal alignment
  in vision language models (VLMs) by proposing a method to prioritize training of
  visually correlated text tokens over irrelevant or contradictory ones. The core
  idea is to use contrastive alignment, where the difference in prediction logits
  with or without image input serves as a guide for token weighting.
---

# Seeing the Image: Prioritizing Visual Correlation by Contrastive Alignment

## Quick Facts
- arXiv ID: 2405.17871
- Source URL: https://arxiv.org/abs/2405.17871
- Authors: Xin Xiao; Bohong Wu; Jiacong Wang; Chunyuan Li; Xun Zhou; Haoyuan Guo
- Reference count: 40
- One-line primary result: Contrastive Alignment (CAL) improves VLM performance by 1.7 ANLS on VQADoc, 3.4 relaxed accuracy on VQAChart, and 2.1 CIDEr on COCO Caption

## Executive Summary
This paper addresses the problem of suboptimal cross-modal alignment in Vision Language Models (VLMs) by proposing a method to prioritize training of visually correlated text tokens over irrelevant or contradictory ones. The core idea is to use contrastive alignment, where the difference in prediction logits with or without image input serves as a guide for token weighting. The proposed method, Contrastive Alignment (CAL), re-weights text tokens based on their visual correlation and achieves consistent improvements across different VLMs, resolutions, and model sizes on various benchmarks.

## Method Summary
CAL introduces a contrastive alignment mechanism that computes the difference in prediction logits (Δo) between forward passes with and without image input for each text token. This Δo serves as a proxy for visual correlation, allowing the model to assign higher weights to visually informative tokens and lower weights to irrelevant or contradictory ones. The method includes clamping and pooling post-processing to prevent extreme values from dominating the weight distribution. During training, CAL adds minimal computational overhead through a gradient-free forward pass without image input, while maintaining the same inference speed as baseline models.

## Key Results
- CAL on LLaVA-Next-13B brings 1.7 ANLS improvement on VQADoc benchmark
- CAL achieves 3.4 relaxed accuracy improvement on VQAChart for chart understanding
- CAL improves COCO Caption benchmark by 2.1 CIDEr score
- Minimal computational overhead (~20%) while providing consistent improvements across diverse VLM architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Token reweighting based on visual correlation difference improves cross-modal alignment by reducing emphasis on irrelevant or contradictory text tokens.
- Mechanism: During training, the model computes prediction logits with and without image input for each text token. The difference (Δo) serves as a proxy for visual correlation, allowing the model to assign higher weights to tokens that are visually informative and lower weights to those that are irrelevant or contradictory.
- Core assumption: The difference in logits with or without image input is a reliable indicator of how much a token depends on visual information.
- Evidence anchors:
  - [abstract] "by contrasting image inputs, the difference in prediction logits on each text token provides strong guidance of visual correlation"
  - [section 2.2.2] "we investigate the change in prediction logits of text tokens with or without the image input and observe strong relevance between the logit change of each text token and its visual correlation"
- Break condition: If Δo becomes dominated by language model prior rather than visual signal, reweighting may become ineffective.

### Mechanism 2
- Claim: Clamping and pooling post-processing prevents extreme values from dominating the token weight distribution.
- Mechanism: After computing Δo for each token, the method applies clamping to bound the weights within [α, β] and then applies average pooling over a window to smooth the distribution. This ensures no single token overwhelms the loss function.
- Core assumption: Unbounded Δo values can cause training instability or collapse the reweighting strategy.
- Evidence anchors:
  - [section 2.3] "To avoid the effects of extreme values, we additionally introduce post-processing methods including clamping and average pooling"
  - [table 4] "We further conduct ablation study on α and β to study the effect of the hyperparameters in our clamping operation"
- Break condition: If α is set too high or β too low, visually correlated tokens may be underweighted, negating the benefit.

### Mechanism 3
- Claim: The proposed method introduces minimal computational overhead while providing consistent improvements across diverse VLM architectures.
- Mechanism: The additional forward pass without image input is gradient-free and only required during training. This allows the model to learn visual correlation weights without affecting inference speed.
- Core assumption: The cost of an additional forward pass is acceptable given the performance gains.
- Evidence anchors:
  - [abstract] "Importantly, our method incurs minimal additional computational overhead, rendering it highly efficient compared to alternative data scaling strategies"
  - [section 3.3] "Our method introduces little computational overhead, with one auxiliary gradient-free forward operation in each training step"
- Break condition: If model size increases significantly, the relative overhead may become prohibitive compared to other efficiency techniques.

## Foundational Learning

- Concept: Contrastive learning in multimodal models
  - Why needed here: The method relies on contrasting image-conditioned vs non-image-conditioned predictions to infer token relevance.
  - Quick check question: What is the purpose of contrasting logits with and without image input in CAL?

- Concept: Token weighting in autoregressive generation
  - Why needed here: Standard VLMs treat all tokens equally, but CAL reweights them based on visual correlation to improve alignment.
  - Quick check question: How does CAL modify the standard MLE loss function?

- Concept: Visual grounding and OCR recognition in VLMs
  - Why needed here: CAL shows particular improvement on OCR-centric benchmarks, suggesting enhanced ability to link text to visual elements.
  - Quick check question: Which types of benchmarks show the most improvement with CAL?

## Architecture Onboarding

- Component map: VLM consists of frozen visual encoder (CLIP/ViT/ConvNeXt) → frozen LLM backbone → trainable projector (aligns visual features to LLM embeddings). CAL adds gradient-free forward pass computing logits without image input for token reweighting.
- Critical path: During training, for each token: (1) compute logits with image input, (2) compute logits without image input, (3) calculate Δo, (4) apply clamping and pooling, (5) reweight the loss, (6) backpropagate only through projector and LLM.
- Design tradeoffs: Trades minimal additional compute during training for improved cross-modal alignment without affecting inference speed. Choice of α and β bounds balances between ignoring irrelevant tokens and preserving context-dependent ones.
- Failure signatures: (1) similar performance to baseline across all benchmarks, (2) degradation on text-only tasks, (3) training instability due to extreme Δo values.
- First 3 experiments:
  1. Implement CAL on a small VLM (e.g., LLaVA-1.5-7B) and verify that Δo values differ meaningfully between visually correlated and irrelevant tokens on a sample dataset.
  2. Test different [α, β] configurations to find optimal clamping bounds that maximize improvement on OCR-centric benchmarks without harming general performance.
  3. Compare training time and memory usage with and without CAL to confirm the ~20% overhead claim.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CAL vary with different dataset compositions and qualities, particularly when applied to datasets with higher or lower proportions of visually contradictory tokens?
- Basis in paper: [explicit] The paper mentions that CAL effectively reduces the impact of contradictory label tokens and shows improved robustness to noisy labels. It also notes that model-generated datasets often contain visually contradictory tokens.
- Why unresolved: The paper only tests CAL on a limited set of datasets and does not explore the full range of possible dataset compositions or qualities. It also does not provide a systematic study on how CAL's performance scales with the proportion of noisy data.
- What evidence would resolve it: A comprehensive study testing CAL on datasets with varying proportions of noisy data, from clean to highly noisy, and measuring performance changes. This could include synthetic experiments where the proportion of noisy data is controlled.

### Open Question 2
- Question: Can the CAL method be extended to other modalities beyond vision and language, such as audio or video, and what would be the challenges and potential benefits of such an extension?
- Basis in paper: [inferred] The paper focuses on vision-language alignment, but the concept of contrasting input conditions to infer relevance could potentially be applied to other modalities. The method's success in identifying visually correlated tokens suggests it could be adapted to identify audio or video elements that are relevant to the text.
- Why unresolved: The paper does not explore applications beyond vision and language. Extending CAL to other modalities would require adapting the method to handle different types of input data and defining what constitutes "correlation" in those contexts.
- What evidence would resolve it: Experiments applying CAL to multimodal datasets involving audio or video, demonstrating improved alignment and performance in tasks such as audio captioning or video question answering.

### Open Question 3
- Question: What is the optimal way to dynamically adjust the lower bound (α) and upper bound (β) parameters in the CAL method based on the specific characteristics of the input data and the task at hand?
- Basis in paper: [explicit] The paper mentions that the selection of α and β is empirically decided based on the frequency of prediction logits and suggests potential for more adaptive settings. It also presents ablation studies showing the impact of different [α, β] values on performance.
- Why unresolved: The paper uses fixed values for α and β across all experiments, which may not be optimal for all datasets or tasks. Dynamically adjusting these parameters could potentially lead to further performance improvements.
- What evidence would resolve it: A study exploring different strategies for dynamically adjusting α and β, such as based on the entropy of the prediction logits or the visual complexity of the input image, and measuring the impact on CAL's performance across various tasks and datasets.

## Limitations
- Dataset Dependency: Effectiveness relies heavily on training data quality and composition, with specific filtering criteria not fully specified
- Hyperparameter Sensitivity: α, β, and window size may not generalize well across different VLMs or tasks
- OCR-Centric Bias: Improvements are particularly strong on text-heavy images, with uncertain generalization to other visual domains

## Confidence
- High Confidence: Core mechanism of using logit differences to estimate visual correlation is theoretically sound and empirically supported
- Medium Confidence: Clamping and pooling post-processing effectiveness is supported by ablation studies, but optimal parameters may be task-dependent
- Low Confidence: Long-term generalization to domains outside training distribution is not well-established

## Next Checks
1. Cross-Architecture Validation: Test CAL on diverse VLMs (encoder-decoder and decoder-only) across wide range of model sizes (1B to 70B parameters)
2. Domain Generalization Test: Evaluate CAL on non-OCR tasks like fine-grained object recognition, scene understanding, and abstract visual reasoning
3. Ablation on Post-Processing: Comprehensive study on clamping and pooling parameters across different tasks to identify optimal configurations<|end_of_text|><|begin_of_text|>4. Dataset Composition Study: Systematically test CAL performance on datasets with controlled proportions of noisy/contradictory tokens
5. Multi-Modal Extension: Apply CAL to audio or video datasets to test cross-modal applicability
6. Dynamic Hyperparameter Tuning: Develop strategies for dynamically adjusting α and β based on input characteristics and task requirements