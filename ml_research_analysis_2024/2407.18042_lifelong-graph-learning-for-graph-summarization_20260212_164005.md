---
ver: rpa2
title: Lifelong Graph Learning for Graph Summarization
arxiv_id: '2407.18042'
source_url: https://arxiv.org/abs/2407.18042
tags:
- graph
- snapshot
- network
- eqcs
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates lifelong graph learning for summarizing
  web graphs using neural networks. The authors train Graph-MLP, GCN, and MLP models
  on sequences of weekly snapshots from the DyLDO dataset (2012 and 2022), treating
  graph summarization as a vertex classification task where classes represent equivalence
  classes.
---

# Lifelong Graph Learning for Graph Summarization

## Quick Facts
- arXiv ID: 2407.18042
- Source URL: https://arxiv.org/abs/2407.18042
- Reference count: 40
- Key outcome: MLP with 1-hop features outperforms GCN and Graph-MLP on 2-hop graph summarization tasks, with no positive transfer between snapshots due to changing equivalence classes.

## Executive Summary
This paper investigates lifelong graph learning for summarizing web graphs using neural networks. The authors train Graph-MLP, GCN, and MLP models on sequences of weekly snapshots from the DyLDO dataset (2012 and 2022), treating graph summarization as a vertex classification task where classes represent equivalence classes. Results show that all networks predominantly use 1-hop information even for 2-hop summaries, with the MLP for 1-hop achieving the best overall performance. No positive forward or backward transfer was observed between snapshots due to changing classes. A ten-year time warp experiment showed that reusing parameters from 2012 neither improved nor harmed performance in 2022 compared to training from scratch.

## Method Summary
The authors treat graph summarization as a vertex classification task where vertices are assigned to equivalence classes (EQCs) computed using the FLUID algorithm. They train Graph-MLP, GCN, and MLP models on sequences of weekly snapshots from 2012 and 2022. Models are evaluated on all snapshots after each training step using accuracy, backward/forward transfer, and forgetting rates. The MLP uses only 1-hop multi-hot encoded edge features, while GCN and Graph-MLP incorporate 2-hop neighborhood information. Training uses GraphSAINT-based sampling with class-distribution weighting.

## Key Results
- MLP using only 1-hop information achieves better performance than GCN and Graph-MLP for 2-hop graph summarization
- No network achieved positive forward or backward transfer between snapshots
- Reusing parameters from 2012 provided no benefit over training from scratch in 2022
- Increased heterogeneity in 2022 snapshots reduced classification accuracy compared to 2012

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The 1-hop MLP performs well for 2-hop summaries because the additional structural complexity of 2-hop neighborhoods is implicitly captured by the 1-hop feature representation when trained end-to-end.
- Mechanism: The MLP learns to weight and combine 1-hop features in a way that implicitly represents 2-hop connectivity patterns, bypassing the need for explicit message passing or edge encoding.
- Core assumption: The 2-hop summary task can be approximated by learned combinations of 1-hop features without loss of discriminative power.
- Evidence anchors:
  - [abstract] "all networks predominantly use 1-hop information even for 2-hop summaries" and "MLP using only 1-hop information is sufficient for 2-hop summaries"
  - [section] "Graph-MLP and GCN perform similarly to MLP for MAC2, even though they have access to 2-hop information for the classification task and MLP does not"
  - [corpus] No direct corpus support; this is a novel inference from the paper's empirical observation.
- Break condition: If the 2-hop summary contains structural patterns that cannot be represented by combinations of 1-hop features (e.g., specific path dependencies), the MLP would fail to capture them.

### Mechanism 2
- Claim: Negative forward and backward transfer occur because the summary classes change substantially between snapshots, causing both forgetting and inability to reuse knowledge.
- Mechanism: When EQCs change rapidly (appear, disappear, or transform), the network must constantly adapt to new label spaces, leading to interference with previous knowledge (forgetting) and poor generalization to future tasks (negative transfer).
- Core assumption: The EQC distribution is unstable across snapshots, with many new and disappearing classes.
- Evidence anchors:
  - [abstract] "Due to the heterogeneity of web graphs, in some snapshots, the 2-hop summary produces over ten times more vertex summaries than the 1-hop summary" and "Changes in the graph reduce the performance"
  - [section] "Figures 2c– 2f show that there are more unique EQCs for MAC2 than for MAC1. The EQCs in MAC2 also change more rapidly" and "no network with any summary model or information achieved a positive forward or backward transfer"
  - [corpus] Weak corpus support; lifelong learning on graphs is mentioned but not specifically tied to class instability in summarization tasks.
- Break condition: If snapshots share a stable core of EQCs with only minor additions, positive transfer could emerge.

### Mechanism 3
- Claim: The warm restart (time warp) experiment shows no improvement because the 2012 network parameters are too mismatched with the 2022 data distribution after ten years of graph evolution.
- Mechanism: Despite reusing parameters, the distribution shift between 2012 and 2022 snapshots is so large that initialization from 2012 offers no advantage over random initialization for 2022.
- Core assumption: The graph structure and EQC distribution have evolved beyond the representational capacity of 2012-trained weights.
- Evidence anchors:
  - [abstract] "When using the network trained on the last snapshot from 2012 and applying it to the first snapshot of 2022, we observe a strong drop in accuracy" and "Reusing parameters from a network trained in 2012 has no benefit over a network trained from scratch in 2022"
  - [section] "The 2022 snapshots have more edges than the ones from 2012. Overall, this reduces the performance" and "Table II shows that the MLP for MAC1 performs a bit better in the time warp"
  - [corpus] No direct corpus evidence; this is a novel empirical finding.
- Break condition: If the graph evolution were gradual or the underlying structural patterns remained stable, warm restarts could provide faster convergence.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their variants (GCN, Graph-MLP)
  - Why needed here: The paper compares multiple GNN architectures for graph summarization, requiring understanding of message-passing vs. non-message-passing designs.
  - Quick check question: What is the key architectural difference between GCN and Graph-MLP, and how does this affect their ability to capture 2-hop information?

- Concept: Lifelong/Continual Learning metrics (forward/backward transfer, forgetting rate)
  - Why needed here: The paper evaluates network performance across sequential snapshots using these specific metrics to assess knowledge retention and transfer.
  - Quick check question: How is backward transfer calculated in this paper, and what does a negative value indicate about the network's behavior?

- Concept: Graph summarization as vertex classification (EQC labeling)
  - Why needed here: The entire experimental setup treats graph summarization as a classification task where vertices are assigned to equivalence classes.
  - Quick check question: What is the relationship between k-hop neighborhood information and the number of EQCs in the summary?

## Architecture Onboarding

- Component map:
  Input: Graph snapshots with multi-hot encoded edge labels (1-hop) or extended with neighbor features (2-hop)
  Preprocessing: Classical FLUID algorithm computes gold-standard EQCs
  Models: MLP (1-hop baseline), GCN (2-hop with message passing), Graph-MLP (2-hop without message passing)
  Training: Sampled subgraphs using GraphSAINT-based sampler, class-distribution weighted
  Evaluation: Accuracy matrices across all snapshot pairs, lifelong learning metrics

- Critical path:
  1. Load snapshot RDF data
  2. Compute gold-standard EQCs using FLUID
  3. Encode vertices with multi-hot features
  4. Sample training subgraphs
  5. Train model on current snapshot
  6. Evaluate on all snapshots (current and historical)
  7. Record accuracy matrix and compute metrics

- Design tradeoffs:
  - 1-hop vs 2-hop features: Simpler models vs richer structural information
  - Message passing vs MLP: Explicit neighborhood aggregation vs learned implicit representation
  - Sampling vs full-batch: Scalability vs potential bias in rare class representation

- Failure signatures:
  - Accuracy collapse across all snapshots: Likely catastrophic forgetting or severe distribution shift
  - Consistently poor performance on later snapshots: Model capacity insufficient for growing class space
  - High variance in accuracy across runs: Insufficient sampling or unstable training dynamics

- First 3 experiments:
  1. Run MLP (1-hop) on 2012 snapshots only to establish baseline performance and observe class stability
  2. Compare GCN vs Graph-MLP on 2-hop summaries with and without edge encoding to test necessity of message passing
  3. Execute warm restart experiment (2012→2022) to quantify impact of temporal distribution shift on parameter reuse

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does incorporating 2-hop neighborhood information improve the performance of Graph-MLP and GCN for 2-hop graph summarization compared to using only 1-hop information?
- Basis in paper: [explicit] The paper shows that MLP using only 1-hop information achieves better performance than GCN and Graph-MLP for 2-hop summarization, suggesting that the additional 2-hop information does not improve performance.
- Why unresolved: The paper does not provide a definitive explanation for why 2-hop information does not improve performance, leaving open the possibility that different architectures or training strategies could leverage this information effectively.
- What evidence would resolve it: Experiments comparing Graph-MLP and GCN with architectures designed to better utilize 2-hop information, or ablation studies showing the impact of removing 2-hop edges from the input features, would help clarify whether 2-hop information can be beneficial.

### Open Question 2
- Question: How does the performance of lifelong graph learning models for summarization change when trained on more than 10 weekly snapshots?
- Basis in paper: [inferred] The paper uses 10 weekly snapshots from 2012 and 2022. The authors note that the EQCs change over time and that performance depends on the number of classes and changes between timesteps, suggesting that performance could be affected by the number of snapshots.
- Why unresolved: The paper does not explore the impact of using a larger number of snapshots on the performance of lifelong learning models.
- What evidence would resolve it: Experiments training and evaluating the models on a larger number of weekly snapshots, potentially spanning multiple years, would show how performance scales with the amount of temporal data.

### Open Question 3
- Question: Can techniques like elastic weight consolidation (EWC) or other regularization methods mitigate catastrophic forgetting in lifelong graph summarization?
- Basis in paper: [explicit] The paper observes forgetting in lifelong graph summarization and notes that networks perform best on each snapshot when trained on a sequence of tasks up to and including that snapshot.
- Why unresolved: The paper does not investigate the use of regularization techniques to address catastrophic forgetting.
- What evidence would resolve it: Experiments comparing the performance of lifelong learning models with and without regularization techniques like EWC, and measuring forgetting rates, would determine the effectiveness of these methods.

### Open Question 4
- Question: How does the performance of graph summarization models change when applied to graphs from different domains, such as social networks or biological networks?
- Basis in paper: [inferred] The paper focuses on web graphs and observes that the performance of graph summarization models depends on the number of classes and changes between timesteps. This suggests that performance might vary across different graph domains.
- Why unresolved: The paper does not explore the generalizability of the models to other graph types.
- What evidence would resolve it: Experiments evaluating the models on graphs from various domains, such as social networks, biological networks, or citation networks, would show how well the models generalize to different types of graph data.

## Limitations
- The mechanism by which MLP implicitly captures 2-hop information remains unexplained
- Negative transfer results depend heavily on the assumption that class instability drives the phenomenon
- Time warp experiment doesn't explore whether partial transfer or faster convergence might occur under different conditions

## Confidence
- High confidence: 1-hop MLP performance claims (directly observed), negative transfer due to class changes (supported by data)
- Medium confidence: Mechanism 1 explanation (empirical observation without theoretical backing), Mechanism 3 (novel finding with limited comparison points)
- Low confidence: Generalization of findings to non-web graph domains (results may be specific to RDF graph characteristics)

## Next Checks
1. Test whether the MLP's 2-hop performance breaks down when 2-hop summaries contain specific path dependencies that cannot be represented by 1-hop feature combinations
2. Quantify class overlap and stability metrics across snapshots to directly test whether class instability drives negative transfer
3. Experiment with warm restarts using intermediate snapshots (2014, 2016, etc.) to determine if gradual distribution shifts might enable beneficial parameter reuse