---
ver: rpa2
title: Fair Secretaries with Unfair Predictions
arxiv_id: '2411.09854'
source_url: https://arxiv.org/abs/2411.09854
tags:
- candidate
- value
- algorithm
- 'true'
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies fairness in learning-augmented online algorithms,
  focusing on the secretary problem where predictions may be biased. The authors show
  that state-of-the-art algorithms can fail to accept the best candidate with nonzero
  probability despite promising good expected value.
---

# Fair Secretaries with Unfair Predictions

## Quick Facts
- **arXiv ID:** 2411.09854
- **Source URL:** https://arxiv.org/abs/2411.09854
- **Reference count:** 40
- **Primary result:** Introduces pegging technique for fair secretary problem with predictions, guaranteeing constant probability of accepting best candidate while maintaining smoothness bounds

## Executive Summary
This paper addresses fairness in learning-augmented online algorithms by studying the secretary problem where predictions may be biased. The authors show that state-of-the-art algorithms can fail to accept the best candidate with nonzero probability despite promising good expected value. They introduce a new "pegging" technique to guarantee fairness while maintaining smoothness guarantees. Their algorithm ensures the best candidate is accepted with constant probability and provides expected value at least max{Ω(1), 1 - O(ε)} times the optimum. The approach extends to the k-secretary problem, providing fairness guarantees for top candidates. Experiments confirm the algorithm's performance across different instance types.

## Method Summary
The paper introduces a novel "pegging" technique for the secretary problem with predictions. When a candidate with maximum predicted value arrives but doesn't satisfy fairness conditions, the algorithm pegs a future candidate with sufficiently high predicted value. This guarantees the best candidate will be accepted with constant probability while maintaining expected value guarantees. The approach uses dynamic programming to compute optimal strategies and extends to the k-secretary problem with sets of hopeful, blaming, pegged, and solution candidates. The algorithm accepts candidates based on multiple conditions including fairness, smoothness, and pegged status.

## Key Results
- Proves that existing learning-augmented secretary algorithms can fail fairness guarantees with nonzero probability
- Introduces pegging technique that ensures constant probability of accepting best candidate (fairness) while maintaining expected value bounds (smoothness)
- Extends results to k-secretary problem with individual fairness guarantees for each rank position
- Demonstrates through experiments that pegging algorithm maintains performance across different prediction error distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pegging technique ensures fairness while maintaining smoothness
- Mechanism: When a candidate with maximum predicted value arrives but doesn't satisfy fairness conditions, the algorithm pegs a future candidate with sufficiently high predicted value. This guarantees the best candidate will be accepted with constant probability while maintaining expected value guarantees.
- Core assumption: The pegged candidate will arrive after the current candidate and can serve as a fallback to ensure smoothness.
- Evidence anchors:
  - [abstract]: "Our algorithm and analysis are based on a new 'pegging' idea that diverges from existing works and simplifies/unifies some of their results."
  - [section 3]: "The main idea behind the pegged set I pegged is that it contains the last candidate to arrive who can guarantee the smoothness property, which is why we accept that candidate when they arrive."
  - [corpus]: Weak - neighboring papers focus on group fairness and post-processing, not online selection with predictions.

### Mechanism 2
- Claim: Fairness guarantee comes from Dynkin's observation about constant probability acceptance
- Mechanism: When a candidate arrives after time 1/2 and has the maximum true value so far, they have constant probability of being the best overall. The algorithm accepts such candidates when they also meet predicted value conditions.
- Core assumption: The arrival order is uniformly random, making late-arriving maximum-so-far candidates likely to be overall best.
- Evidence anchors:
  - [section 3]: "Dynkin's algorithm [27] for the classical secretary problem relies on the observation that if a constant fraction of the candidates have arrived and the candidate who just arrived has the maximum true value so far, then this candidate has a constant probability of being the best overall."
  - [section 2]: "Fairness consider fairness considerations have become increasingly important due to the recent interest in incorporating (possibly biased) machine learning predictions into the design of classical online algorithms."
  - [corpus]: Weak - neighboring papers don't address online selection with predictions.

### Mechanism 3
- Claim: Smoothness guarantee comes from accepting candidates with values close to maximum predicted value
- Mechanism: The algorithm ensures accepted candidates have true values within 4ε of the maximum true value by always accepting when the candidate has maximum predicted value or when a pegged candidate arrives.
- Core assumption: The maximum predicted value is always close to the maximum true value within additive error ε.
- Evidence anchors:
  - [section 3]: "ADDITIVE -PEGGING ensures smoothness by always accepting a candidate whose value is close to uˆı which, as we argue, is at least ui∗ − 2 ε."
  - [section 2]: "We let A be a random variable denoting the candidate accepted by a given algorithm on a fixed instance, which depends on both the arrival order and any internal randomness in the algorithm."
  - [corpus]: Weak - neighboring papers focus on different fairness notions not related to prediction errors.

## Foundational Learning

- Concept: Secretary problem with predictions
  - Why needed here: The paper builds on classical secretary problem but adds machine-learned predictions that may be biased. Understanding the baseline problem is essential to grasp the fairness concerns.
  - Quick check question: What is the optimal probability of selecting the best candidate in the classical secretary problem without predictions?

- Concept: Learning-augmented algorithms
  - Why needed here: The framework assumes predictions are available but may be erroneous. The algorithm must perform well both when predictions are accurate and when they're completely wrong.
  - Quick check question: What is the difference between 1-consistency and R-robustness in learning-augmented algorithms?

- Concept: Fairness notions in online algorithms
  - Why needed here: The paper introduces a specific fairness definition - accepting the best candidate with constant probability regardless of prediction bias. This differs from group fairness or other notions.
  - Quick check question: How does individual fairness in stopping problems differ from group fairness approaches?

## Architecture Onboarding

- Component map:
  - Candidate arrival processing -> Pegging set management -> Acceptance logic -> Error tracking

- Critical path:
  1. Candidate arrives with true and predicted values
  2. Algorithm checks if candidate is in pegged set → accept if yes
  3. Otherwise compute fairness (F) and smoothness (C) conditions
  4. If C ∧ F: accept candidate
  5. If C ∧ F: compute pegged set and potentially peg future candidates
  6. If C ∧ F: check if candidate value is close enough to maximum predicted value
  7. Accept or continue based on conditions

- Design tradeoffs:
  - Fairness vs smoothness: The pegging mechanism adds complexity to ensure fairness while maintaining smoothness guarantees
  - Computational overhead: Maintaining pegged sets and checking multiple conditions adds runtime compared to simple greedy approaches
  - Parameter sensitivity: The algorithm's performance depends on prediction error magnitude and arrival time thresholds

- Failure signatures:
  - Zero acceptance rate: Indicates pegged sets are never populated or fairness conditions are too strict
  - Poor expected value: Suggests smoothness conditions are too conservative or pegged candidates are suboptimal
  - High variance in acceptance: May indicate unstable pegged set management or threshold selection

- First 3 experiments:
  1. Test on instances where predictions are perfectly accurate (ε = 0) to verify fairness guarantee holds
  2. Test on instances with adversarial predictions where best candidate has worst prediction to stress-test pegging mechanism
  3. Test on large instances (n > 100) to verify constant probability guarantees don't degrade with scale

## Open Questions the Paper Calls Out

- What is the exact Pareto-optimal trade-off curve between smoothness constant C and fairness guarantee F for the secretary problem with predictions?
- How would incorporating additional information about prediction quality (e.g., confidence scores) affect the fairness guarantees?
- Can the fairness notion be extended to group-level fairness considerations while maintaining the same smoothness guarantees?
- How does the algorithm perform under different prediction error distributions beyond the ones tested?
- Can the pegging technique be generalized to other online selection problems beyond secretary and k-secretary?

## Limitations

- The pegging mechanism's behavior in extreme prediction error scenarios (ε close to 1) remains theoretically justified but empirically less validated
- The extension from single to k-secretary introduces additional complexity in fairness guarantees that may not scale linearly
- The assumption that pegged candidates arrive after the current candidate is critical but not extensively stress-tested

## Confidence

- **High confidence**: The theoretical framework for ADDITIVE_PEGGING and its fairness/smoothness guarantees (Theorem 4)
- **Medium confidence**: The k_PEGGING algorithm's fairness guarantees for individual rank positions (Theorem 5)
- **Medium confidence**: Experimental results showing consistent performance across instance types
- **Low confidence**: The algorithm's behavior under adversarial prediction patterns where best candidates consistently have worst predictions

## Next Checks

1. **Extreme prediction error validation**: Run experiments with ε = 0.9 and ε = 1.0 to verify that fairness guarantees (constant probability of accepting best candidate) hold even when predictions are nearly useless
2. **Adversarial prediction stress test**: Design instances where the best candidate always has the worst prediction value, then verify the pegging mechanism successfully identifies and accepts this candidate
3. **Scalability analysis**: Test the algorithm on larger instances (n = 500, 1000) to confirm that the constant probability fairness guarantee doesn't degrade with scale, as suggested by the theory but not explicitly demonstrated