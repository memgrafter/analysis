---
ver: rpa2
title: 'Autoware.Flex: Human-Instructed Dynamically Reconfigurable Autonomous Driving
  Systems'
arxiv_id: '2412.16265'
source_url: https://arxiv.org/abs/2412.16265
tags:
- user
- driving
- instruction
- autoware
- instructions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Autoware.Flex, an autonomous driving system
  that integrates human instructions into decision-making processes. The system addresses
  two main limitations of existing ADS: misinterpretation of complex scenarios and
  inability to accommodate user preferences.'
---

# Autoware.Flex: Human-Instructed Dynamically Reconfigurable Autonomous Driving Systems

## Quick Facts
- arXiv ID: 2412.16265
- Source URL: https://arxiv.org/abs/2412.16265
- Reference count: 40
- Primary result: Achieves 87% overall translation accuracy for user instructions to AutoIR programs

## Executive Summary
Autoware.Flex introduces a novel autonomous driving system that integrates human instructions into the decision-making process of an ADS. The system addresses two main limitations of existing ADS: misinterpretation of complex scenarios and inability to accommodate user preferences. By leveraging a Large Language Model (LLM) with an ADS-specialized knowledge base and a rule-based validation mechanism, Autoware.Flex enables users to guide the system through natural language instructions while ensuring safe execution.

## Method Summary
The system combines an LLM with Retrieval-Augmented Generation (RAG) to translate natural language instructions into AutoIR programs using an ADS-specialized knowledge base. A rule-based validation mechanism checks vehicle status and environmental conditions before execution. The architecture consists of an instruction translation node for relevance analysis and AutoIR generation, and an instruction execution node for validation and execution. The system was implemented on Autoware.Universe using ROS 2 Humble middleware, with experiments conducted in both simulation and real-world settings.

## Key Results
- 87% overall translation accuracy for user instructions to AutoIR programs
- 99% accuracy in relevance analysis using Chain of Thought prompting
- Successful execution of user instructions in both simulation and real-world settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system can accurately translate natural language instructions into AutoIR programs by leveraging a domain-specific knowledge base with the RAG architecture.
- Mechanism: The RAG architecture retrieves relevant driving scenarios and corresponding AutoIR programs from the ADS knowledge base, which are then used by the LLM to generate accurate AutoIR representations. This combines the LLM's language understanding with domain-specific ADS knowledge.
- Core assumption: The ADS knowledge base contains sufficient coverage of driving scenarios and their corresponding AutoIR representations to handle most user instructions.
- Evidence anchors:
  - [abstract]: "we employ a Large Language Model (LLM) assisted by an ADS-specialized knowledge base to enhance domain-specific translation"
  - [section 3.2.2]: "To translate natural language user instructions into AutoIR, we leverage a Large Language Model (LLM)... we adopt the Retrieval-Augmented Generation (RAG) approach, which equips the LLM with an external knowledge base"
  - [section 6.1.2]: "Our specialized knowledge base shows a substantial improvement in accuracy compared to the approach using the Autoware manual as the knowledge base"
- Break condition: If the knowledge base lacks coverage of a specific driving scenario, the translation accuracy will degrade for instructions related to that scenario.

### Mechanism 2
- Claim: The system ensures safe execution of user instructions through a rule-based validation mechanism that checks vehicle status and environmental conditions.
- Mechanism: When a user instruction arrives as an AutoIR program, the system searches for matching rules in the rule base and validates the current vehicle status against predefined safety conditions. Only instructions that satisfy these conditions are executed.
- Core assumption: The rule base comprehensively captures safety constraints for various driving scenarios and vehicle states.
- Evidence anchors:
  - [abstract]: "For the second challenge, we design a validation mechanism to ensure that human instructions result in safe and consistent driving behavior"
  - [section 4.1]: "We design the rules to safeguard user instruction execution offline using a simulation-based approach"
  - [section 4.2]: "A user instruction represented as an AutoIR program is matched against the rules in the rule base, along with real-time vehicle status data"
- Break condition: If the rule base is incomplete or if the validation conditions are too conservative, legitimate user instructions may be incorrectly blocked.

### Mechanism 3
- Claim: The system achieves high translation accuracy (87% overall) by using in-context learning with carefully designed prompt templates for relevance analysis and translation.
- Mechanism: The system uses structured prompt templates that include task descriptions and Q&A examples to guide the LLM in both determining relevance of user input and generating accurate AutoIR programs.
- Core assumption: The prompt templates effectively guide the LLM to produce correct outputs without requiring model retraining.
- Evidence anchors:
  - [section 6.1.2]: "our approach achieves 99%, significantly outperforming the Simple Prompt, which achieves only 92%"
  - [section 6.1.2]: "Our specialized knowledge base shows a substantial improvement in accuracy compared to the approach using the Autoware manual"
  - [section 3.1]: "we adopt in-context learning, specifically Chain of Thought (CoT) prompting"
- Break condition: If the prompt templates are not sufficiently clear or comprehensive, the LLM may produce incorrect outputs even with the knowledge base.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their limitations in domain-specific tasks
  - Why needed here: Understanding why LLMs alone cannot handle ADS-specific instructions without domain knowledge
  - Quick check question: What are the key limitations of using LLMs for autonomous driving instruction translation without domain-specific knowledge?

- Concept: Retrieval-Augmented Generation (RAG) architecture
  - Why needed here: This is the core mechanism for combining LLM capabilities with domain knowledge
  - Quick check question: How does RAG improve the accuracy of LLM outputs in domain-specific applications?

- Concept: ROS 2 and Autoware modular architecture
  - Why needed here: Understanding how AutoIR integrates with the existing ADS framework
  - Quick check question: What are the key components of Autoware's modular architecture and how do they communicate?

## Architecture Onboarding

- Component map:
  - Instruction Translation Node: Handles relevance analysis and AutoIR generation
  - Instruction Execution Node: Validates and executes user instructions
  - ADS Knowledge Base: Contains driving scenarios and corresponding AutoIR programs
  - Rule Base: Contains safety validation rules for instruction execution
  - LLM Service (QWenVL-Max): Provides language understanding and generation capabilities

- Critical path: User instruction → Relevance analysis → AutoIR generation → Rule validation → ADS execution

- Design tradeoffs:
  - Accuracy vs. latency: More comprehensive knowledge bases and rule sets improve accuracy but increase latency
  - Safety vs. flexibility: Stricter validation rules improve safety but may block legitimate user instructions
  - Complexity vs. maintainability: More sophisticated AutoIR representations enable more complex instructions but increase system complexity

- Failure signatures:
  - Translation failures: User instructions not being converted to AutoIR or producing incorrect AutoIR
  - Validation failures: Legitimate instructions being blocked by overly conservative rules
  - Execution failures: Valid instructions not being properly executed in the ADS

- First 3 experiments:
  1. Test relevance analysis with simple and complex user instructions to verify the prompt template effectiveness
  2. Test AutoIR generation with known driving scenarios to verify translation accuracy
  3. Test rule-based validation with various vehicle states and speeds to verify safety constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Autoware.Flex compare to traditional ADS systems in handling edge cases and unusual driving scenarios?
- Basis in paper: [explicit] The paper discusses Autoware.Flex's ability to handle complex scenarios like malfunctioning traffic lights and restricted lane cruising, but does not provide a comprehensive comparison with traditional ADS systems.
- Why unresolved: The paper presents experimental results for Autoware.Flex but lacks direct comparisons with existing ADS systems in handling edge cases.
- What evidence would resolve it: Comparative studies between Autoware.Flex and traditional ADS systems in a variety of complex and unusual driving scenarios.

### Open Question 2
- Question: What is the long-term impact of user instructions on the safety and reliability of the ADS?
- Basis in paper: [inferred] The paper discusses the safety mechanisms in place for user instructions but does not explore the long-term effects of frequent user intervention on ADS safety and reliability.
- Why unresolved: The paper focuses on immediate safety validation but does not address the cumulative impact of user instructions over time.
- What evidence would resolve it: Longitudinal studies tracking the safety and reliability of ADS with frequent user interventions over extended periods.

### Open Question 3
- Question: How can the rule base be optimized to support a broader range of user instructions without compromising safety?
- Basis in paper: [explicit] The paper mentions the potential for expanding the rule base to accommodate more scenarios but does not provide a method for optimizing this process.
- Why unresolved: The paper acknowledges the need for rule base expansion but does not detail how to achieve this while maintaining safety standards.
- What evidence would resolve it: Research into automated methods for expanding and refining the rule base based on real-world data and user feedback.

## Limitations

- The evaluation is primarily based on simulation with limited real-world testing, leaving real-world performance unverified.
- The ADS knowledge base and rule set are described as "specialized" but specific contents and comprehensiveness are not detailed.
- The 87% overall translation accuracy combines relevance analysis (99%) and AutoIR generation (75%), but lacks detailed error analysis.

## Confidence

- **High Confidence**: The mechanism of using RAG architecture with domain-specific knowledge to improve LLM translation accuracy is well-established in the literature and the experimental results showing 99% relevance analysis accuracy are convincing.
- **Medium Confidence**: The overall translation accuracy of 87% is supported by experiments, but the relatively lower AutoIR generation accuracy (75%) combined with the lack of detailed error analysis creates uncertainty about real-world performance.
- **Low Confidence**: Claims about the system's ability to handle diverse user preferences and complex driving scenarios in real-world conditions are not adequately supported by the evidence.

## Next Checks

1. **Real-world edge case testing**: Deploy the system in a controlled real-world environment with diverse driving scenarios including adverse weather conditions, complex traffic situations, and unexpected pedestrian behavior. Measure translation accuracy, execution success rate, and safety violations compared to simulation results.

2. **Knowledge base completeness analysis**: Systematically evaluate the coverage of the ADS knowledge base by testing the system with a comprehensive set of driving scenarios from various geographic regions and cultural contexts. Identify gaps in coverage and measure the degradation in translation accuracy when instructions fall outside the knowledge base.

3. **Long-term reliability study**: Conduct a longitudinal study over multiple days/weeks of continuous operation to assess system performance degradation, memory of previous instructions, and handling of accumulated user preferences. Test the system's ability to learn from experience and update its knowledge base dynamically.