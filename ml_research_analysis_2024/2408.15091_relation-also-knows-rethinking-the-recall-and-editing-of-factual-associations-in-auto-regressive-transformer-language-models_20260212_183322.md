---
ver: rpa2
title: 'Relation Also Knows: Rethinking the Recall and Editing of Factual Associations
  in Auto-Regressive Transformer Language Models'
arxiv_id: '2408.15091'
source_url: https://arxiv.org/abs/2408.15091
tags:
- editing
- relation
- layers
- token
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the over-generalizing problem in knowledge
  editing methods for auto-regressive transformer language models, where editing one
  fact unexpectedly changes unrelated facts about the same subject. The authors discover
  that existing methods focus too much on subject knowledge while neglecting relation
  information during editing.
---

# Relation Also Knows: Rethinking the Recall and Editing of Factual Associations in Auto-Regressive Transformer Language Models

## Quick Facts
- arXiv ID: 2408.15091
- Source URL: https://arxiv.org/abs/2408.15091
- Authors: Xiyu Liu; Zhengxiao Liu; Naibin Gu; Zheng Lin; Wanli Ma; Ji Xiang; Weiping Wang
- Reference count: 40
- Primary result: RETS achieves over 30% improvement on Relation Specificity while maintaining competitive performance on other knowledge editing metrics

## Executive Summary
This paper addresses a critical limitation in knowledge editing methods for auto-regressive transformer language models: the over-generalizing problem where editing one fact unexpectedly changes unrelated facts about the same subject. Through causal tracing and vocabulary lens analysis, the authors discover that relation-related attributes accumulate at the last relation token across middle-late layers, with the target object extracted from these attributes. Based on this insight, they propose RETS (Relation-focused Editing for Transformers with Subject constraints), which modifies the MLP sublayer at the last relation token while constraining edits to the target subject. Experiments on COUNTERFACT show RETS significantly outperforms existing methods on Relation Specificity while maintaining competitive performance on other metrics.

## Method Summary
The RETS method modifies the MLP sublayer at the last relation token position in middle-late layers of auto-regressive transformers, while adding subject constraint optimization to ensure editing specificity to the target subject. The approach uses causal tracing to identify the decisive token position for relation prediction and vocabulary lens analysis to understand attribute accumulation patterns. The subject constraint loss is optimized using input/output vectors collected from neighborhood subject prompts, making the hidden representations of different subjects distinguishable during editing. The method is specifically designed to solve the over-generalizing problem where editing one fact about a subject affects unrelated facts about the same subject.

## Key Results
- RETS outperforms ROME-like methods by over 30% on Relation Specificity metric
- The method maintains competitive performance on Efficacy, Generalization, and Subject Specificity metrics
- RETS effectively solves the over-generalizing problem where editing one fact unexpectedly changes unrelated facts about the same subject
- The approach demonstrates that relation-focused editing at the last relation token with subject constraints is superior to existing subject-focused editing methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Relation-related attributes accumulate at the last relation token from early to middle-late layers, and the target object is extracted from these accumulated attributes.
- Mechanism: During inference, MLP sublayers progressively enrich the representation at the last relation token with relation-specific semantic attributes. This enrichment peaks in middle-late layers where the target object token emerges as the top prediction from this accumulated relation knowledge.
- Core assumption: The last relation token position serves as the primary locus for relation representation processing, with MLP updates being more significant than MHSA updates for this accumulation.
- Evidence anchors:
  - [abstract]: "relation-related attributes are accumulated at the last relation token across middle-late layers, with the target object extracted from these attributes"
  - [section]: "We note that for both MLP and MHSA, the most significant output representations are detected during inference at the last-relation token... the update process for the relation representation is of long duration and finishes at the middle-late layers"
  - [corpus]: Weak evidence - only 1 related paper found with FMR 0.53, indicating limited direct corpus support for this specific accumulation mechanism.
- Break condition: If the accumulation process completes significantly earlier or later than middle-late layers, or if MHSA updates prove more critical than MLP updates for relation representation enrichment.

### Mechanism 2
- Claim: Editing at the last relation token in middle-late layers with subject constraints solves the over-generalizing problem.
- Mechanism: By modifying MLP weights at the last relation token position during the completion phase of relation attribute accumulation, the editing method directly targets the relation representation while the subject constraint optimization ensures specificity to the target subject rather than affecting unrelated facts about the same subject.
- Core assumption: The last relation token representation contains sufficient subject information (from earlier propagation) to enable subject-specific editing while primarily encoding relation knowledge that needs modification.
- Evidence anchors:
  - [abstract]: "modifies the MLP sublayer at the last relation token in middle-late layers while constraining edits to the target subject"
  - [section]: "To make the hidden representations of neighborhood subject prompts more distinguishable at this point, we add an optimization target to the deduction of the weight modification to enhance the difference between such neighborhood prompts, constraining the editing to the certain subject"
  - [corpus]: Weak evidence - limited related work (5 papers) addressing relation awareness in knowledge editing, suggesting this is a novel approach.
- Break condition: If the subject constraint optimization fails to sufficiently distinguish between different subjects using the same relation, or if editing at this position causes excessive collateral effects on relation predictions.

### Mechanism 3
- Claim: MLP sublayers play a more important role than MHSA sublayers in accumulating relation-related attributes.
- Mechanism: Blocking MLP sublayers at the last relation token causes significantly greater decline in attributes rate compared to blocking MHSA sublayers, demonstrating MLP's dominant role in enriching relation representations with semantic attributes.
- Core assumption: The attributes rate metric accurately captures the semantic richness of relation representations, and the difference in decline rates between MLP and MHSA blocking reflects their relative contributions to relation knowledge accumulation.
- Evidence anchors:
  - [section]: "blocking MLP leads to a much more significant drop in attributes rate than blocking MHSA across layers at the last token, indicating that MLP plays a much more important role in the enrichment of relational knowledge"
  - [section]: "Figure 3(b) plots the average declines of attributes rate at 48-th layer while canceling the updates from MLP sublayers or MHSA sublayers at the last token respectively"
  - [corpus]: No direct evidence found in corpus for this specific comparison of MLP vs MHSA contributions to relation attributes.
- Break condition: If future work demonstrates that MHSA contributions to relation attribute accumulation are underestimated, or if the attributes rate metric proves unreliable for measuring relation knowledge richness.

## Foundational Learning

- Concept: Vocabulary lens analysis for interpreting hidden representations
  - Why needed here: The paper uses vocabulary lens to quantify the semantic content of relation representations by examining top-ranked tokens and attributes rate, which is essential for validating the relation-focused interpretation
  - Quick check question: How would you calculate the attributes rate for a relation representation at layer l, given a set of top-k ranked tokens and a ground-truth attribute set for that relation?

- Concept: Causal tracing for identifying influential model components
  - Why needed here: Causal tracing identifies which token positions and layers most influence relation prediction by measuring the indirect effect of corrupting relation tokens on object prediction probability
  - Quick check question: What is the key difference between the corrupted run and corrupted-with-restoration run in causal tracing methodology?

- Concept: Knowledge editing via weight modification at specific positions
  - Why needed here: The paper's RETS method modifies MLP weights at specific token positions (last relation token) and layers (middle-late) to achieve targeted knowledge editing while avoiding over-generalization
  - Quick check question: Why does editing at the last relation token require subject constraint optimization, unlike editing at the last subject token?

## Architecture Onboarding

- Component map: The RETS method targets the MLP sublayer at the last relation token position in middle-late layers, using subject constraints to optimize the weight modification. The method requires collecting input/output vectors from neighborhood subject prompts for the subject constraint loss.
- Critical path: 1) Identify last relation token position through causal tracing, 2) Analyze attribute accumulation pattern via vocabulary lens, 3) Collect neighborhood subject prompts for subject constraints, 4) Optimize MLP weight modification with subject constraint loss, 5) Evaluate on R-Specificity and other metrics
- Design tradeoffs: Editing at last relation token vs last subject token - relation-focused position ensures high R-Specificity but lower S-Specificity, while subject-focused position shows opposite performance characteristics. The subject constraint optimization adds complexity but is necessary for subject specificity.
- Failure signatures: Low R-Specificity indicates over-generalization affecting unrelated facts about the same subject. Low S-Specificity indicates failure to maintain specificity across different subjects using the same relation. Poor generalization scores suggest the editing doesn't transfer well to paraphrased prompts.
- First 3 experiments:
  1. Replicate the vocabulary lens analysis on a small dataset to verify attribute accumulation trends at the last relation token across layers
  2. Implement causal tracing on a simple factual association to identify the decisive token position for relation prediction
  3. Test RETS editing on a single factual association with one unrelated fact about the same subject to verify the over-generalizing problem is solved

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the exact mechanism by which relation-specific attributes accumulate at the last relation token across middle-late layers, and how does this process differ from subject knowledge accumulation?
  - Basis in paper: [explicit] The paper explicitly states that relation-related attributes are accumulated at the last relation token across middle-late layers through MLP sublayers, while subject knowledge accumulation is discussed in related works but not directly compared in this study.
  - Why unresolved: The paper focuses on describing the phenomenon but doesn't provide a detailed mechanistic explanation of why relation attributes specifically accumulate at the last relation token or how this process fundamentally differs from subject knowledge accumulation.
  - What evidence would resolve it: Detailed ablation studies showing the differential effects of blocking MLP sublayers at various positions and layers on relation vs. subject knowledge retention, combined with attention pattern analysis to reveal the distinct pathways of attribute accumulation.

- **Open Question 2**: How can the subject constraints be optimized to maintain both high relation specificity and high subject specificity without compromising fluency and consistency?
  - Basis in paper: [inferred] The paper shows that RETS outperforms ROME-like methods on R-Specificity but loses about 20% on S-Specificity and experiences declines in Fluency and Consistency, suggesting the current subject constraints are not optimal.
  - Why unresolved: The paper mentions the trade-off issue and notes that the simple subject constraint design affects text quality, but doesn't explore more sophisticated constraint mechanisms or joint strategies for relation and subject information.
  - What evidence would resolve it: Experimental results comparing RETS with various constraint formulations (e.g., weighted constraints, dynamic constraints based on relation type) showing improvements in both S-Specificity and text quality metrics while maintaining R-Specificity gains.

- **Open Question 3**: Can the relation-focused editing approach be effectively scaled to handle sequential or batched facts editing while maintaining the over-generalizing problem solution?
  - Basis in paper: [explicit] The paper explicitly states "our work only applies to editing each factual association separately and it is essential to scale up to sequential or batched facts."
  - Why unresolved: The paper only demonstrates single-fact editing performance and acknowledges this limitation without exploring how the relation-focused approach would perform when multiple facts need to be edited simultaneously.
  - What evidence would resolve it: Comparative experiments showing RETS performance on datasets with multiple related facts that need editing, measuring both individual fact editing quality and interference between edited facts, versus current single-fact baselines.

## Limitations

- The subject constraint optimization mechanism lacks detailed implementation specifications, making exact replication challenging
- The vocabulary lens analysis depends on attribute sets collected from Wikidata Query Service, but the collection methodology is not fully specified
- The paper focuses on auto-regressive transformers but doesn't explore whether the findings generalize to other architectures

## Confidence

- **High confidence** in the existence of the over-generalizing problem and the general effectiveness of RETS in addressing it
- **Medium confidence** in the specific mechanism of relation attribute accumulation at the last relation token
- **Low confidence** in the precise contribution ratio between MLP and MHSA sublayers

## Next Checks

1. **Cross-dataset validation**: Test RETS on an independent knowledge editing dataset (e.g., from zsRE or synthetic data) to verify that the over-generalizing problem and its solution generalize beyond COUNTERFACT

2. **Ablation study replication**: Independently reproduce the MLP vs MHSA blocking experiments to confirm that MLP contributions to relation attribute accumulation are indeed dominant across different model sizes and architectures

3. **Subject constraint optimization verification**: Implement and test alternative subject constraint formulations to determine if the specific optimization approach is critical or if simpler methods achieve similar R-Specificity improvements