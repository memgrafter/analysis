---
ver: rpa2
title: Classifying point clouds at the facade-level using geometric features and deep
  learning networks
arxiv_id: '2402.06506'
source_url: https://arxiv.org/abs/2402.06506
tags:
- features
- geometric
- point
- pointnet
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes fusing geometric features with deep learning
  networks for facade-level point cloud classification to enable detailed 3D building
  model reconstruction. Geometric features are extracted using a spherical neighborhood
  and covariance matrix analysis, capturing local structure properties like planarity
  and surface variation.
---

# Classifying point clouds at the facade-level using geometric features and deep learning networks

## Quick Facts
- arXiv ID: 2402.06506
- Source URL: https://arxiv.org/abs/2402.06506
- Reference count: 15
- Primary result: PointNet++ accuracy improves from 54.8% to 62.1% on one building and from 83.1% to 87.5% on another when geometric features are fused with point coordinates

## Executive Summary
This study proposes fusing geometric features with deep learning networks for facade-level point cloud classification to enable detailed 3D building model reconstruction. Geometric features are extracted using a spherical neighborhood and covariance matrix analysis, capturing local structure properties like planarity and surface variation. These features are early-fused with point coordinates and fed into PointNet and PointNet++ networks. Experiments on TUM-FACADE dataset show that adding geometric features improves classification accuracy: PointNet++ accuracy increases from 54.8% to 62.1% on one building and from 83.1% to 87.5% on another.

## Method Summary
The method extracts geometric features using spherical neighborhood (radius 0.8m) and covariance matrix analysis, including planarity, surface variation, PCA components, and eigenvector directions. These features are early-fused with point coordinates as input to PointNet and PointNet++ networks. The approach compensates for DL networks' weakness in capturing local geometric details. Models are trained on 4 buildings and tested on 2 unseen buildings from the TUM-FACADE dataset, with point clouds downsampled to 0.1-0.05m.

## Key Results
- PointNet++ accuracy improves from 54.8% to 62.1% on building No.59
- PointNet++ accuracy improves from 83.1% to 87.5% on building No.4959459
- Feature selection matters: using 9 features instead of 6 geometric features decreased PointNet++ performance on building No.59

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Early-fusing geometric features with point coordinates provides local structural context that DL networks like PointNet++ can use during training.
- Mechanism: The geometric features (planarity, surface variation, PCA components, eigenvector directions) are calculated in a fixed-radius spherical neighborhood for each point and concatenated to its coordinates before being fed into the network layers. This supplies explicit local geometry cues that otherwise must be inferred through deeper network layers.
- Core assumption: The fixed-radius spherical neighborhood captures enough local context to be useful for distinguishing facade-level classes.
- Evidence anchors:
  - [abstract] "geometric features are extracted using a spherical neighborhood and covariance matrix analysis, capturing local structure properties like planarity and surface variation"
  - [section] "geometric features are calculated based on surrounding points that locate in a spherical space with a fixed radius"
- Break condition: If the neighborhood radius is too small, features become noisy; if too large, local detail is lost and classes become ambiguous.

### Mechanism 2
- Claim: Adding geometric features improves classification accuracy by compensating for DL networks' weakness in capturing local geometric details.
- Mechanism: Networks like PointNet process each point independently, lacking explicit mechanisms to capture local shape information. Early fusion injects this information before the network's internal processing, enabling better class separation without relying solely on learned filters.
- Core assumption: The DL models' default learned features are insufficient for facade-level discrimination without explicit geometric cues.
- Evidence anchors:
  - [abstract] "The method compensates for DL networks' weakness in capturing local geometric details"
  - [section] "PointNet shows limits in recognizing local structure"
- Break condition: If the geometric features are poorly chosen or redundant with what the network can learn, accuracy gains will plateau or degrade.

### Mechanism 3
- Claim: Selecting the right subset of geometric features is crucial; not all features contribute positively to classification performance.
- Mechanism: Random Forest importance scores are used to rank feature contributions. Removing low-importance features (e.g., omnivariance, certain eigenvector dimensions) can improve overall accuracy by reducing noise and redundancy in the input space.
- Core assumption: Feature importance rankings from a simpler model (Random Forest) are predictive of which features will help a DL model.
- Evidence anchors:
  - [section] "Random Forest also measured the importance of each feature component, and the result was used for selection of different geometric features combinations"
  - [section] "when applying combination of nine geometric features for testing on building No.59, instead of improvement in overall accuracy, the performance of PointNet++ is decreased"
- Break condition: If feature selection is done incorrectly or importance metrics are misleading, adding more features can hurt performance.

## Foundational Learning

- Concept: Covariance matrix analysis for local geometry
  - Why needed here: Forms the basis for computing planarity, surface variation, and PCA components that capture local shape.
  - Quick check question: What do the eigenvalues of the covariance matrix tell you about the local point distribution?

- Concept: Spherical neighborhood search using KD-tree
  - Why needed here: Efficiently finds nearby points for each query point to compute geometric features.
  - Quick check question: Why is a fixed-radius neighborhood preferred over a fixed-number-of-points neighborhood in this context?

- Concept: Early fusion vs late fusion in neural networks
  - Why needed here: Early fusion directly incorporates geometric features into the network's input, making them available at the lowest level of processing.
  - Quick check question: How does early fusion differ from concatenating features after the network's feature extraction layers?

## Architecture Onboarding

- Component map: Point cloud loading -> downsampling -> KD-tree neighborhood search -> geometric feature computation -> early-fused tensor creation -> model training
- Critical path: 1. Load and preprocess point cloud (downsample, merge classes). 2. Compute geometric features for each point. 3. Early-fuse features with coordinates. 4. Train or evaluate DL model. 5. Analyze accuracy and confusion matrix.
- Design tradeoffs:
  - Fixed radius vs adaptive neighborhood: Fixed is simpler and consistent but may miss context at varying scales.
  - Number of features: More features can capture more detail but risk redundancy and noise.
  - Early vs late fusion: Early fusion makes features available from the start but may not let the network adapt them optimally.
- Failure signatures:
  - Accuracy drops when adding features: Likely feature redundancy or poor selection.
  - High variance in accuracy across buildings: Possible overfitting to training data or insufficient feature generalization.
  - Slow training: High-dimensional input or inefficient neighborhood search.
- First 3 experiments:
  1. Run PointNet++ on XYZ-only data to establish baseline accuracy.
  2. Add all six geometric features and measure change in accuracy and training time.
  3. Remove the two lowest-importance features and re-run to see if accuracy improves.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different geometric feature combinations affect the computational efficiency of PointNet and PointNet++ during training and inference?
- Basis in paper: [inferred] The paper mentions that the deep learning method used relies on a computationally intensive neighborhood search mechanism, which duplicates the pre-computed geometric features, leading to a decrease in computational efficiency.
- Why unresolved: The paper focuses on classification accuracy but does not provide detailed analysis of the computational cost associated with different geometric feature combinations.
- What evidence would resolve it: Benchmarking the training and inference times for various geometric feature combinations and comparing them with the accuracy improvements to find an optimal trade-off.

### Open Question 2
- Question: Can the proposed method be generalized to other complex 3D scenarios beyond building facades, such as natural landscapes or industrial sites?
- Basis in paper: [inferred] The paper discusses the method's potential for generalization across large 3D building scenarios but does not test it on other types of 3D data.
- Why unresolved: The study is limited to building facade data from the TUM-FACADE dataset, and there is no exploration of its applicability to other domains.
- What evidence would resolve it: Applying the method to diverse 3D datasets (e.g., natural landscapes, industrial sites) and evaluating its performance in terms of classification accuracy and robustness.

### Open Question 3
- Question: How does the performance of the proposed method compare with state-of-the-art semantic segmentation techniques that do not rely on geometric features?
- Basis in paper: [explicit] The paper compares the proposed method with PointNet, PointNet++, and Random Forest but does not compare it with other state-of-the-art semantic segmentation techniques.
- Why unresolved: The study focuses on improving DL networks with geometric features but does not benchmark against other advanced semantic segmentation methods.
- What evidence would resolve it: Conducting experiments to compare the proposed method with other leading semantic segmentation techniques (e.g., graph-based methods, transformer-based models) on the same datasets.

### Open Question 4
- Question: What is the impact of varying the radius of the spherical neighborhood on the classification accuracy and the selection of geometric features?
- Basis in paper: [explicit] The paper mentions that the radius of the spherical space for each point was set as 0.8m but does not explore how changing this radius affects the results.
- Why unresolved: The study uses a fixed radius without investigating its influence on the performance and the effectiveness of different geometric features.
- What evidence would resolve it: Performing experiments with different spherical neighborhood radii and analyzing how they affect classification accuracy and the importance of geometric features.

## Limitations
- Inconsistent accuracy improvements across buildings suggest the approach may be sensitive to building characteristics or feature selection.
- Geometric feature computation relies on fixed-radius neighborhoods which may not adapt well to varying facade scales.
- Feature selection process using Random Forest importance rankings may be dataset-dependent and not transfer well to deep learning performance.

## Confidence

| Claim | Confidence |
|-------|------------|
| Early-fusing geometric features with point coordinates improves accuracy | High |
| Accuracy improvements are demonstrated on TUM-FACADE dataset | Medium |
| Feature selection methodology transfers to new datasets | Low |

## Next Checks
1. Test the approach on additional facade datasets with varying point densities and architectural styles to assess generalization.
2. Experiment with adaptive neighborhood radii (based on local point density) rather than fixed-radius to evaluate robustness to scale variations.
3. Compare feature selection methods beyond Random Forest importance, such as correlation analysis or cross-validation, to verify the optimal feature subset is not dataset-specific.