---
ver: rpa2
title: Is ChatGPT Transforming Academics' Writing Style?
arxiv_id: '2404.08627'
source_url: https://arxiv.org/abs/2404.08627
tags:
- chatgpt
- abstracts
- words
- frequency
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper quantifies the impact of ChatGPT on academic writing
  by analyzing changes in word frequencies across one million arXiv abstracts from
  2018-2024. Using statistical analysis and simulations with ChatGPT, the authors
  find that ChatGPT-style writing has increasingly penetrated academic abstracts,
  particularly in computer science where ~35% of recent abstracts show ChatGPT-like
  word patterns.
---

# Is ChatGPT Transforming Academics' Writing Style?

## Quick Facts
- arXiv ID: 2404.08627
- Source URL: https://arxiv.org/abs/2404.08627
- Authors: Mingmeng Geng; Roberto Trotta
- Reference count: 40
- Primary result: ChatGPT-style writing has increasingly penetrated academic abstracts, with ~35% of recent CS abstracts showing LLM-like patterns

## Executive Summary
This paper quantifies the impact of ChatGPT on academic writing by analyzing word frequency changes across one million arXiv abstracts from 2018-2024. Using statistical analysis and simulations with ChatGPT, the authors find that LLM-style writing has increasingly penetrated academic abstracts, particularly in computer science where ~35% of recent abstracts show ChatGPT-like word patterns. The methodology involves comparing word frequency changes in real abstracts with simulated LLM-modified abstracts, accounting for noise through adaptive word selection criteria.

## Method Summary
The study analyzes 1 million arXiv abstracts from May 2018 to January 2024, calculating word frequency changes and comparing them with simulated ChatGPT-style modifications. The authors use Google Ngram data for word frequency reference and employ statistical modeling with linear regression to estimate the fraction of abstracts showing LLM influence. The method involves adaptive word selection criteria based on frequency and change rate, with calibration using mixed real and simulated datasets to optimize detection accuracy.

## Key Results
- ~35% of CS abstracts from 2023-2024 show ChatGPT-like word patterns
- Strong correlation between predicted and observed frequency changes, especially post-2022
- Non-specialized words show skyrocketing frequency in early 2023
- Theoretical insights into optimal word selection criteria for LLM detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM influence detection works through adaptive word frequency shifts
- Mechanism: The system identifies statistically significant changes in specific word frequencies that correlate with simulated ChatGPT-style text modifications
- Core assumption: ChatGPT has identifiable lexical preferences that differ from typical academic writing
- Evidence anchors:
  - [abstract] "ChatGPT-style writing has increasingly penetrated academic abstracts, particularly in computer science where ~35% of recent abstracts show ChatGPT-like word patterns"
  - [section 3.1] "The frequency of some non-specialized words also starts to skyrocket in early 2023"
  - [corpus] Weak evidence - only mentions related papers without direct support
- Break condition: If ChatGPT's writing style converges with academic norms or if other LLMs dominate with different patterns

### Mechanism 2
- Claim: Noise modeling enables reliable impact estimation
- Mechanism: The method accounts for word frequency variability through Gaussian noise assumptions and bias correction in linear regression
- Core assumption: Word frequency noise follows predictable statistical distributions that can be modeled
- Evidence anchors:
  - [section 4.2] "we split the word frequencies... while they both have corresponding noise terms"
  - [section 4.3] "the loss function under this assumption is"
  - [section F.2] "a simple Gaussian distribution... seems to be a reasonable approximation"
- Break condition: If real-world noise deviates significantly from assumed distributions or if bias correction becomes insufficient

### Mechanism 3
- Claim: Calibration with simulated data validates real-world detection
- Mechanism: The system tests word selection criteria on mixed real and simulated abstracts to optimize detection accuracy
- Core assumption: Simulated ChatGPT modifications accurately represent actual usage patterns
- Evidence anchors:
  - [section 5.1] "We used calibrations and tests, with ChatGPT-processed abstracts mixed with real abstracts"
  - [section 4.4] "we used ChatGPT to process additional abstracts... as calibration for the bias and noise"
  - [corpus] Weak evidence - related papers exist but don't confirm calibration effectiveness
- Break condition: If simulation parameters don't match real usage or if calibration data becomes unrepresentative

## Foundational Learning

- Concept: Statistical hypothesis testing
  - Why needed here: To determine whether observed word frequency changes are statistically significant or random variation
  - Quick check question: How would you test if a 10% frequency change in "significant" is meaningful vs. random noise?

- Concept: Linear regression with noise modeling
  - Why needed here: To estimate the proportion of LLM-influenced abstracts while accounting for measurement uncertainty
  - Quick check question: What happens to your estimate if you ignore the bias correction term in the regression?

- Concept: Cross-validation and calibration
  - Why needed here: To ensure the detection method generalizes to real data rather than just fitting simulated patterns
  - Quick check question: Why is it important to use different prompts for calibration vs. testing data?

## Architecture Onboarding

- Component map: Data ingestion -> Simulation engine -> Analysis pipeline -> Calibration module -> Detection engine
- Critical path: Data → Simulation → Frequency Analysis → Noise Modeling → Calibration → Detection
- Design tradeoffs: Word selection criteria balance computational efficiency (O(1) vs O(2^n)) against detection accuracy
- Failure signatures: Poor correlation between simulated and real frequency changes indicates model breakdown
- First 3 experiments:
  1. Test correlation between single-word frequency changes and simulated ChatGPT modifications
  2. Verify noise distribution assumptions using pre-2023 data variance
  3. Run calibration with varying mixing ratios to find optimal word selection criteria

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal adaptive word selection criterion that minimizes estimation bias when detecting LLM influence across different academic disciplines?
- Basis in paper: [explicit] The authors derive theoretical criteria based on word frequency qd_ij and frequency change rate ˆrij, but note that "more computationally expensive" fine-tuning could improve results
- Why unresolved: The theoretical framework provides general guidance (prefer words with larger qd_ij, f*_ij, and |ˆrij|), but doesn't specify the optimal balance or discipline-specific thresholds
- What evidence would resolve it: Empirical comparison of different adaptive selection algorithms across multiple disciplines showing which criterion achieves highest correlation with ground truth LLM influence

### Open Question 2
- How does the penetration of LLM-influenced writing vary across different academic writing styles and purposes (methodology sections vs introductions vs conclusions)?
- Basis in paper: [inferred] The study focuses on abstracts but notes that "LLMs can generate abstracts directly" and "the debate around the usage of generative models... is multi-faceted"
- Why unresolved: The methodology is designed for abstracts which "condense an entire research article" but doesn't address how LLM influence might differ in other sections with different writing conventions
- What evidence would resolve it: Comparative analysis of LLM-style word frequency changes across different paper sections within the same articles

### Open Question 3
- What is the relationship between LLM usage for non-native English speakers versus native speakers in academic writing?
- Basis in paper: [explicit] The authors note "reading and writing in English is more difficult for non-native English academics" and ChatGPT "help non-English native writers to improve the quality and flow"
- Why unresolved: While the paper acknowledges this demographic difference, it doesn't analyze whether the detected LLM influence correlates with the proportion of non-native English authors in different disciplines
- What evidence would resolve it: Correlation analysis between estimated LLM influence and institutional author affiliation data indicating native/non-native English backgrounds

### Open Question 4
- How does the effectiveness of LLM detection methods degrade over time as LLMs evolve and training data includes more LLM-influenced text?
- Basis in paper: [inferred] The authors use GPT-3.5 simulations based on pre-2023 data and note their method could be "further improved" with "more rigorous analysis"
- Why unresolved: The detection methodology assumes a static baseline of what constitutes "LLM-style" writing, but as LLMs are increasingly trained on LLM-influenced content, this baseline may shift
- What evidence would resolve it: Longitudinal study tracking detection accuracy over time as newer LLM generations incorporate more LLM-influenced training data

## Limitations
- Simulation validity concerns: Real-world usage may differ from controlled prompts
- Cross-disciplinary generalizability: Method effectiveness across non-CS fields not fully validated
- Temporal dynamics: Framework may require recalibration as LLMs evolve and training data changes

## Confidence

**High Confidence**: Statistical methodology for detecting word frequency changes and correlation between simulated and real data patterns (particularly post-2022) are well-established. The ~35% detection rate in CS abstracts is supported by strong empirical evidence.

**Medium Confidence**: Noise modeling assumptions and calibration approach appear sound but rely on distributional assumptions that may not hold perfectly in practice. Theoretical insights into optimal word selection are mathematically rigorous but require more empirical validation.

**Low Confidence**: Cross-disciplinary generalizability claims lack comprehensive validation, and simulation-to-reality translation remains partially speculative without user behavior data.

## Next Checks

1. **Temporal Robustness Test**: Re-run the analysis using rolling windows (e.g., 6-month periods) to verify that the detection rate remains stable and doesn't show artificial inflation due to cumulative effects or changing detection criteria.

2. **Cross-Model Validation**: Apply the same methodology to abstracts processed by different LLM models (Claude, GPT-4, open-source alternatives) to assess whether the detected patterns are ChatGPT-specific or represent general LLM influence.

3. **Author-Level Analysis**: Segment the dataset by prolific authors and compare their writing evolution patterns to determine if detected changes represent genuine style shifts or just increased diversity in writing approaches.