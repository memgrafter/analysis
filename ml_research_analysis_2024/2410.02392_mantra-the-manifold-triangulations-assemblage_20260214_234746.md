---
ver: rpa2
title: 'MANTRA: The Manifold Triangulations Assemblage'
arxiv_id: '2410.02392'
source_url: https://arxiv.org/abs/2410.02392
tags:
- topological
- simplicial
- page
- degree
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MANTRA, a large-scale dataset of manifold
  triangulations designed to benchmark higher-order models in topological deep learning.
  The dataset contains over 43,000 triangulations of surfaces and 249,000 triangulations
  of three-dimensional manifolds, each equipped with topological labels like Betti
  numbers and orientability.
---

# MANTRA: The Manifold Triangulations Assemblage

## Quick Facts
- **arXiv ID**: 2410.02392
- **Source URL**: https://arxiv.org/abs/2410.02392
- **Reference count**: 40
- **Primary result**: Large-scale dataset of manifold triangulations designed to benchmark higher-order models in topological deep learning, containing over 43,000 surface triangulations and 249,000 3-manifold triangulations with topological labels

## Executive Summary
This paper introduces MANTRA, a comprehensive dataset of manifold triangulations designed to benchmark higher-order models in topological deep learning. The dataset contains over 43,000 triangulations of surfaces and 249,000 triangulations of three-dimensional manifolds, each equipped with topological labels like Betti numbers and orientability. The authors evaluate nine models—five graph-based and four simplicial complex-based—on three classification tasks: Betti number prediction, homeomorphism type classification, and orientability detection. Results show that simplicial complex-based models generally outperform graph-based models in capturing topological invariants, but both struggle with tasks like orientability prediction and are not invariant to barycentric subdivisions, challenging the notion of "topological" models.

## Method Summary
The study benchmarks nine models (5 graph-based: MLP, GCN, GAT, TransConv, TAG; 4 simplicial: SAN, SCCN, SCCNN, SCN) on three topological classification tasks using the MANTRA dataset. Models are trained with stratified 60/20/20 splits, Adam optimizer (lr=0.01), and 6 epochs. Feature vectors are initialized using random values or topological degrees (upper/lower degrees for simplices). Performance is evaluated using AUROC for binary classification tasks and accuracy for Betti number prediction, with 5 runs per experiment. Barycentric subdivision experiments test model invariance to topological-preserving transformations.

## Key Results
- Simplicial complex-based models outperform graph-based models on topological classification tasks, particularly for predicting homeomorphism types
- All models struggle with orientability detection, with performance only marginally better than random guessing
- Model performance degrades significantly on barycentric subdivisions, suggesting current models are not truly "topological"
- Degree-based feature initialization consistently improves simplicial model performance compared to random initialization

## Why This Works (Mechanism)

### Mechanism 1
Simplicial complex-based models outperform graph-based models because they capture higher-order structural information that graphs miss. Graph models only use 0- and 1-dimensional simplices (vertices and edges), while simplicial models use the full set of simplices including triangles and higher-dimensional faces. This allows simplicial models to directly process topological features like holes and cavities that are not representable in the graph structure. The topological invariants being predicted (Betti numbers, orientability, homeomorphism type) require information from higher-dimensional simplices that cannot be inferred from the 1-skeleton alone.

### Mechanism 2
All models struggle with barycentric subdivisions because message-passing architectures cannot learn topological invariance to combinatorial transformations. Barycentric subdivision increases the combinatorial distance between original vertices while preserving topology. Message-passing models rely on neighborhood aggregation where distance affects information propagation. When simplices are subdivided, the original topological relationships are obscured by the increased complexity, breaking the model's ability to recognize invariant features.

### Mechanism 3
Degree-based feature initialization consistently improves simplicial complex model performance because higher-order degrees encode more topological information than random initialization. Upper and lower degrees for simplices capture the local topological structure around each simplex - upper degrees count co-faces while lower degrees count faces. This provides the model with explicit structural information about how simplices connect in higher dimensions, which is crucial for topological reasoning.

## Foundational Learning

- **Simplicial homology and Betti numbers**: Understanding how Betti numbers count topological features (connected components, loops, voids) is essential for interpreting model performance and designing appropriate tasks. Quick check: What do the three Betti numbers β0, β1, and β2 represent in a surface triangulation?

- **Triangulation and barycentric subdivision**: Understanding how triangulations represent manifolds and how barycentric subdivision preserves topology while changing combinatorics is crucial for interpreting the invariance results. Quick check: How does barycentric subdivision affect the combinatorial distance between vertices while preserving the underlying topology?

- **Graph vs simplicial complex representations**: Understanding the relationship between a simplicial complex and its 1-skeleton (graph) is essential for grasping why simplicial models might outperform graph models on topological tasks. Quick check: Can you determine the homeomorphism type of a surface from its underlying graph alone? Why or why not?

## Architecture Onboarding

- **Component map**: Data → Feature initialization → Model selection → Training (6 epochs, Adam, lr=0.01) → Evaluation (AUROC/accuracy) → Barycentric subdivision test (optional)
- **Critical path**: Load MANTRA dataset → Initialize features (random/degree) → Select model → Train with stratified splits → Evaluate on test set → Test barycentric subdivision invariance
- **Design tradeoffs**: Graph models are faster to train (5-24x speedup) but less expressive for topological tasks; simplicial models capture more structure but require more computation and careful feature engineering; 6 epochs may be insufficient for complex tasks but prevents overfitting on small datasets
- **Failure signatures**: Poor performance on barycentric subdivisions indicates lack of topological invariance; similar performance between graph and simplicial models suggests the task doesn't require higher-order information; high variance across runs indicates sensitivity to initialization or hyperparameters
- **First 3 experiments**:
  1. Train a simple GCN and SAN on the β0 prediction task with degree features to verify the basic pipeline works and observe the performance gap
  2. Run the barycentric subdivision experiment on β0 prediction to confirm the invariance failure pattern
  3. Compare random vs degree initialization for SCCN on the orientability task to verify the feature engineering hypothesis

## Open Questions the Paper Calls Out

- **Auxiliary learning tasks**: Can forcing models to predict the entire set of topological labels together with the target task help models learn to efficiently use topological information? The authors suggest this approach but have not experimentally tested it.

- **Topological invariance**: How can we develop models that are invariant to barycentric subdivisions while maintaining high performance on topological tasks? The authors found all tested models showed dramatically decreased performance on barycentric subdivisions.

- **Alternative feature initialization**: Are there better feature initialization methods for graph-based models on topological tasks? The authors found mixed results for degree-based initialization in graph models.

- **Non-message-passing models**: How do non-message-passing topological models (e.g., topological transformers, Gaussian processes) perform on MANTRA compared to message-passing models? The authors acknowledge they only tested message-passing networks due to computational limitations.

## Limitations

- The dataset heavily favors orientable surfaces (38k out of 43k triangulations), potentially biasing results for orientability detection tasks
- The 6-epoch training constraint may be insufficient for complex tasks, particularly for graph-based models that show performance degradation after the first epoch
- Focus on non-manifold surfaces restricts generalizability to real-world topological data that often contains boundary components

## Confidence

- **High Confidence**: Simplicial complex-based models consistently outperform graph-based models on topological classification tasks
- **Medium Confidence**: Current state-of-the-art models are not truly "topological" due to failure on barycentric subdivisions
- **Low Confidence**: Degree-based feature initialization universally improves simplicial model performance

## Next Checks

1. **Extended Training Analysis**: Run experiments with 20-50 epochs to determine if graph model performance degradation is due to underfitting or fundamental architectural limitations. Compare learning curves and final performance metrics.

2. **Boundary-aware Evaluation**: Create and evaluate on a dataset variant containing non-manifold surfaces and boundary components to test the generalizability of current findings to more realistic topological scenarios.

3. **Invariance Architecture Testing**: Implement and benchmark models with explicit topological invariance mechanisms (e.g., invariant pooling, coordinate-free representations) on barycentric subdivisions to establish whether architectural modifications can achieve true topological invariance.