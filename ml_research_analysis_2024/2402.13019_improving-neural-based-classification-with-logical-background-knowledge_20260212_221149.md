---
ver: rpa2
title: Improving Neural-based Classification with Logical Background Knowledge
arxiv_id: '2402.13019'
source_url: https://arxiv.org/abs/2402.13019
tags:
- knowledge
- semantic
- classification
- background
- conditioning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a new neurosymbolic technique called semantic
  conditioning at inference, which constrains the system during inference while leaving
  training unaffected. It introduces a formalism for supervised multi-label classification
  with propositional background knowledge, and re-frames two standard neurosymbolic
  techniques: semantic conditioning and semantic regularization.'
---

# Improving Neural-based Classification with Logical Background Knowledge

## Quick Facts
- arXiv ID: 2402.13019
- Source URL: https://arxiv.org/abs/2402.13019
- Reference count: 13
- Primary result: Semantic conditioning at inference significantly outperforms standard multi-label classification and semantic regularization while providing semantic consistency guarantees

## Executive Summary
This paper introduces a novel neurosymbolic technique called semantic conditioning at inference that constrains neural classification predictions using logical background knowledge during inference while leaving training unaffected. The approach re-frames two standard neurosymbolic techniques - semantic conditioning and semantic regularization - within a formal framework for multi-label classification with propositional background knowledge. The key innovation is leveraging background knowledge to improve classification accuracy without compromising training efficiency or flexibility.

## Method Summary
The paper proposes a formalism for supervised multi-label classification with propositional background knowledge, introducing three neurosymbolic techniques: semantic conditioning, semantic regularization, and semantic conditioning at inference. Semantic conditioning at inference uses MAP estimation to find the most probable output that satisfies the background knowledge formula during inference, while training uses standard cross-entropy loss. This approach guarantees semantic consistency while maintaining flexibility to change background knowledge after training. The framework is evaluated across three tasks (MNIST, CIFAR-100, ImageNet) using a multi-scale methodology to assess performance across different model scales.

## Key Results
- Semantic conditioning at inference achieves significantly higher accuracy than traditional independent multi-label classification and semantic regularization
- The technique provides semantic consistency guarantees while maintaining or improving accuracy
- Performance benefits are especially pronounced for smaller models, demonstrating better resource efficiency
- Semantic conditioning at inference enables flexibility in background knowledge usage, allowing changes after training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic conditioning at inference improves accuracy by filtering predictions to satisfy background knowledge without affecting training.
- Mechanism: The inference module uses MAP estimation to find the most probable output that entails the background knowledge formula κ, while training uses standard cross-entropy loss. This ensures predictions are both accurate and semantically consistent.
- Core assumption: The background knowledge κ is satisfiable and accurately represents the valid output space.
- Evidence anchors:
  - [abstract]: "introduce a new neurosymbolic technique called semantic conditioning at inference, which only constrains the system during inference while leaving the training unaffected."
  - [section 3.3]: "Semantic conditioning at inference retains two key properties of semantic conditioning: syntactic invariance... and semantic consistency at inference"
- Break condition: If κ is unsatisfiable or does not accurately capture the valid output space, the inference module may fail to find valid predictions.

### Mechanism 2
- Claim: Semantic conditioning at inference guarantees greater or equal accuracy compared to traditional independent multi-label classification inference.
- Mechanism: Since the inference module searches for the most probable output that satisfies κ, if the traditional inference would produce the correct labels, the conditioned inference will also produce them or better (by filtering out semantically invalid but probable predictions).
- Core assumption: The neural model's activation vector accurately represents the probability distribution over outputs.
- Evidence anchors:
  - [section 3.3]: "when performing inference based on identical model modules and learned parameters, sci guarantees greater or equal accuracy compared to traditional imc inference"
  - [section 3.4]: "Computing Lrpλqpa, yq (for sr) and L|κpa, yq (for sc) rely on PQE, while computing I|κpaq (for sc and sci) relies on MAP estimation"
- Break condition: If the neural model is poorly trained or the activation vector poorly represents probabilities, the MAP estimation may not improve accuracy.

### Mechanism 3
- Claim: Semantic conditioning at inference enables flexibility in background knowledge usage, allowing changes after training.
- Mechanism: Since training uses standard independent multi-label classification loss, the neural representations remain independent. This allows different background knowledge formulas to be applied at inference time without retraining.
- Core assumption: The training process does not implicitly encode assumptions about the background knowledge structure.
- Evidence anchors:
  - [section 3.3]: "training with the standard independent multi-label classification loss leads to independent representations of the different variables. This enables to change background knowledge after training"
  - [section 6]: "In this paper, we assume throughout the paper that the background knowledge is known a priori, which is often not the case in practice"
- Break condition: If the training process inadvertently learns dependencies related to specific background knowledge, changing the knowledge at inference may not work as intended.

## Foundational Learning

- Concept: Propositional logic and satisfiability
  - Why needed here: The background knowledge is expressed as propositional formulas, and inference requires checking satisfiability to ensure valid outputs.
  - Quick check question: Given a formula κ = (Y1 ∨ ¬Y2) ∧ (Y2 ∨ Y3), what are all models that satisfy κ?

- Concept: Exponential family distributions and sigmoid/softmax functions
  - Why needed here: The neural model outputs activation vectors that are converted to probability distributions using exponential family distributions, which then interact with background knowledge through conditioning.
  - Quick check question: For activation vector a = [2.0, -1.0, 0.5], what is the probability distribution after applying the sigmoid function to each component?

- Concept: Probabilistic query estimation (PQE) and maximum a posteriori (MAP) estimation
  - Why needed here: Computing the loss for semantic conditioning and regularization requires PQE, while inference requires MAP estimation to find the most probable valid output.
  - Quick check question: Why is MAP estimation generally more tractable than PQE, and how does this affect the choice between semantic conditioning and semantic conditioning at inference?

## Architecture Onboarding

- Component map: Input x -> Neural model -> Activation vector a -> Loss module + Labels y -> Loss value, Inference module + Background knowledge κ -> Predicted labels ŷ

- Critical path:
  1. Input x → Neural model → Activation vector a
  2. Activation vector a → Loss module + Labels y → Loss value
  3. Activation vector a → Inference module + Background knowledge κ → Predicted labels ŷ

- Design tradeoffs:
  - Flexibility vs. performance: Semantic conditioning at inference allows changing background knowledge without retraining but may be less accurate than semantic conditioning for fixed knowledge
  - Computational complexity: MAP estimation for inference is generally more tractable than PQE for loss computation
  - Expressiveness: More complex background knowledge formulas may be intractable to compute

- Failure signatures:
  - Accuracy doesn't improve over baseline: Background knowledge may be incorrect or too restrictive
  - Inference is very slow: Background knowledge formula may be too complex for efficient MAP estimation
  - Training diverges: Loss module implementation may have bugs or numerical instability

- First 3 experiments:
  1. Implement independent multi-label classification baseline on MNIST and verify accuracy matches literature
  2. Add simple categorical background knowledge (one label per image) and implement semantic conditioning at inference, compare accuracy
  3. Try hierarchical background knowledge on CIFAR-100, implement both semantic conditioning and semantic conditioning at inference, compare performance and training time

## Open Questions the Paper Calls Out

- Question: How do the benefits of semantic conditioning at inference compare when using different logic representations (e.g., First Order Logic, Answer Set Programming) instead of propositional logic?
- Basis in paper: [explicit] The paper mentions exploring more diverse and expressive logics to represent background knowledge as a future direction.
- Why unresolved: The current work focuses on propositional logic. Different logics may offer varying trade-offs between expressiveness and tractability.
- What evidence would resolve it: Experiments comparing performance and resource usage across multiple logic representations on the same tasks.

- Question: What is the impact of background knowledge discovery on performance when the knowledge is unknown a priori?
- Basis in paper: [explicit] The paper identifies discovering the structure of the task and training the model simultaneously as an important field of research.
- Why unresolved: The current methodology assumes background knowledge is known. Discovering it automatically introduces new challenges and potential performance trade-offs.
- What evidence would resolve it: Experiments on tasks where background knowledge is discovered through methods like inductive logic programming or neural-symbolic approaches.

- Question: How do neurosymbolic techniques perform in semi-supervised and weakly-supervised settings compared to purely neural approaches?
- Basis in paper: [explicit] The paper mentions investigating semi-supervised and weakly-supervised settings as future directions.
- Why unresolved: The current experiments use fully supervised datasets. Real-world applications often have limited labeled data, making these settings more practical.
- What evidence would resolve it: Comparative experiments on semi-supervised and weakly-supervised benchmarks with varying amounts of labeled data.

## Limitations

- The assumption that background knowledge is known a priori and satisfiable may not hold in real-world applications
- The framework focuses on propositional logic, limiting expressiveness compared to more complex logical formalisms
- Computational complexity of MAP estimation depends heavily on background knowledge structure, potentially becoming prohibitive for very complex formulas

## Confidence

- High confidence: The mechanism of semantic conditioning at inference and its implementation details are well-defined and technically sound
- Medium confidence: The experimental results showing improved accuracy, particularly for smaller models, though exact implementation details and hyperparameter choices are not fully specified
- Medium confidence: The claim that training remains unaffected by the semantic conditioning at inference, as this depends on the independence assumption holding in practice

## Next Checks

1. Test the approach with intentionally unsatisfiable or incorrect background knowledge to verify failure modes and robustness
2. Implement a case study on a real-world dataset where background knowledge is not perfectly known, examining how well the system handles imperfect knowledge
3. Compare computational efficiency with alternative neurosymbolic approaches across different model scales and background knowledge complexities