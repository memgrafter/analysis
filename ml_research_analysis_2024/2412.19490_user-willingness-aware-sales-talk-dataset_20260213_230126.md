---
ver: rpa2
title: User Willingness-aware Sales Talk Dataset
arxiv_id: '2412.19490'
source_url: https://arxiv.org/abs/2412.19490
tags:
- user
- dialogue
- sales
- willingness
- dialogues
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study constructed a user willingness-aware sales talk dataset
  with high ecological validity to advance research on practical automated sales dialogue
  systems. The dataset includes utterance-level annotations of three types of user
  willingness: willingness to engage in dialogue, willingness to provide information,
  and willingness to accept the salesperson''s objectives.'
---

# User Willingness-aware Sales Talk Dataset
## Quick Facts
- arXiv ID: 2412.19490
- Source URL: https://arxiv.org/abs/2412.19490
- Authors: Asahi Hentona; Jun Baba; Shiki Sato; Reina Akama
- Reference count: 8
- Constructed dataset with utterance-level user willingness annotations to advance automated sales dialogue research

## Executive Summary
This study constructed a user willingness-aware sales talk dataset with high ecological validity to advance research on practical automated sales dialogue systems. The dataset includes utterance-level annotations of three types of user willingness: willingness to engage in dialogue, willingness to provide information, and willingness to accept the salesperson's objectives. Analysis of the dataset revealed that avoiding negative evaluations of user willingness is more effective than attempting to increase positive evaluations for improving purchase intentions. A user evaluation experiment demonstrated that incorporating utterance-level user willingness labels into a sales dialogue system significantly improved success rates, with further improvements achieved by integrating strategic dialogue progression based on the analysis findings.

## Method Summary
The dataset was constructed using a Wizard-of-Oz method with experienced salespeople and crowdworkers in a realistic e-commerce context, focusing on wireless earphones. The study collected 300 dialogues with utterance-level annotations for three types of user willingness: continuing dialogue, providing information, and goal acceptance. The data collection prioritized ecological validity by simulating realistic sales scenarios with product information display and customer inquiries. GPT-3.5 was fine-tuned using attribute-conditioned supervised fine-tuning with user willingness labels, and model performance was evaluated based on success rate (improvement in purchase intention) and average user willingness scores.

## Key Results
- Dataset constructed with 300 dialogues containing utterance-level annotations for three types of user willingness
- Analysis revealed avoiding negative user willingness evaluations is more effective than increasing positive ones for improving purchase intentions
- Incorporating utterance-level user willingness labels into sales dialogue systems significantly improved success rates

## Why This Works (Mechanism)
### Mechanism 1
- Claim: High ecological validity in data collection elicits more natural user willingness signals, improving model performance.
- Mechanism: Using Wizard-of-Oz setup with real users and salespeople in a realistic e-commerce context captures authentic willingness fluctuations rather than artificial responses.
- Core assumption: Users behave more naturally when the dialogue environment closely mirrors real-world interaction scenarios.
- Evidence anchors: [abstract] "We developed a user willingnessâ€“aware sales talk collection by leveraging the ecological validity concept..." [section] "In this study, we developed a sophisticated data collection process based on high ecological validity to faithfully reproduce actual sales dialogue system usage scenarios..."

### Mechanism 2
- Claim: Avoiding negative willingness evaluations is more effective than trying to increase positive willingness for improving purchase intentions.
- Mechanism: Negative evaluations indicate moments where the dialogue system alienates users, directly harming purchase intent. Preventing these moments is more impactful than attempting to boost already positive interactions.
- Core assumption: Negative user willingness has a stronger detrimental effect on purchase intent than positive willingness has a beneficial effect.
- Evidence anchors: [abstract] "Analysis of the dataset revealed that avoiding negative evaluations of user willingness is more effective than attempting to increase positive evaluations for improving purchase intentions." [section] "the positive and neutral evaluations of user willingness exhibit nearly no correlation with improving the users' intent to purchase. Conversely, a negative correlation is observed with the negative evaluations."

### Mechanism 3
- Claim: Explicitly conditioning responses on user willingness labels improves dialogue system success rates.
- Mechanism: The attribute-conditioned supervised fine-tuning method allows the model to generate responses specifically tuned to maintain or improve user willingness at each dialogue turn.
- Core assumption: Fine-tuning with utterance-level willingness labels provides the model with signals that improve its ability to maintain user engagement and acceptance.
- Evidence anchors: [abstract] "incorporating utterance-level user willingness labels into a sales dialogue system significantly improved success rates" [section] "The two models that explicitly considered the utterance-level user willingness labels, i.e., the GPT-3.5W and GPT-3.5WD models, obtained higher success rates than the baseline model."

## Foundational Learning
- Concept: Ecological validity
  - Why needed here: Ensures that the collected dialogue data reflects real-world user behavior rather than artificial responses, which is critical for building systems that work in practice.
  - Quick check question: What is the difference between data collected in a controlled lab setting versus data collected with high ecological validity in terms of real-world applicability?

- Concept: User willingness types (continuing dialogue, providing information, goal acceptance)
  - Why needed here: These three dimensions capture the key aspects of user engagement that affect sales outcomes, allowing the model to target specific aspects of user behavior.
  - Quick check question: How might a dialogue system behave differently if it focuses on improving goal acceptance willingness versus continuing dialogue willingness?

- Concept: Attribute-conditioned supervised fine-tuning
  - Why needed here: This technique allows the model to generate responses conditioned on specific user willingness attributes, enabling targeted improvements in user engagement.
  - Quick check question: What advantage does conditioning responses on user willingness labels provide compared to standard fine-tuning without such labels?

## Architecture Onboarding
- Component map: Data collection interface -> User-side evaluation module -> Sales-side simulation -> Fine-tuning pipeline -> Inference engine
- Critical path: 1. Collect high-quality dialogue data with utterance-level willingness labels 2. Fine-tune base model using attribute-conditioned SFT with the collected data 3. Deploy model with inference-time conditioning on current dialogue stage and target willingness type 4. Evaluate model performance in user studies measuring purchase intent improvement
- Design tradeoffs: Data collection complexity vs. ecological validity; Model complexity vs. performance; Generalization vs. specificity
- Failure signatures: Low success rate despite high willingness scores; High number of dialogues with unclear intentions; Decreased willingness scores over dialogue progression
- First 3 experiments: 1. Compare baseline GPT-3.5 model against GPT-3.5 with willingness labels 2. Test GPT-3.5WD with stage-specific willingness targeting against GPT-3.5W 3. Analyze failure cases by sampling dialogues where purchase intent did not improve and categorizing causes

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does the effectiveness of the user willingness-aware sales talk dataset generalize to product categories beyond wireless earphones?
- Basis in paper: [inferred] The paper notes that the dataset was constructed for a specific product category (wireless earphones) and acknowledges this as a limitation, stating that "outcomes may differ based on the price of the product and the characteristics of the target users."
- Why unresolved: The paper does not provide any experiments or analysis on how the dataset and findings would apply to other product categories.
- What evidence would resolve it: Experiments applying the same methodology and analysis to other product categories (e.g., home appliances, clothing, software) and comparing the results.

### Open Question 2
- Question: How does the performance of the sales dialogue systems change when using real user data from actual purchases rather than simulated data?
- Basis in paper: [explicit] The authors acknowledge in the Limitations section that "the user-side participants in this study did not actually purchase a product; thus, it remains uncertain to what extent their genuine intentions were mirrored in the constructed dataset."
- Why unresolved: The study used a simulated environment where users were not required to make actual purchases.
- What evidence would resolve it: Conducting the same experiments with users who have the opportunity to actually purchase products and comparing the results with the current study.

### Open Question 3
- Question: How does the effectiveness of the sales dialogue systems vary across different cultural contexts and languages?
- Basis in paper: [explicit] The authors note in the Limitations section that "the dataset was collected in the Japanese language, which could limit the applicability and generalizability of the findings to other languages or cultural contexts."
- Why unresolved: The study was conducted in Japanese with Japanese participants.
- What evidence would resolve it: Conducting the same experiments in different languages and cultural contexts and comparing the results.

## Limitations
- The dataset is limited to a single product category (wireless earphones), which may affect generalizability to other domains.
- The study used simulated purchase scenarios rather than actual purchases, potentially affecting the authenticity of user willingness data.
- The dataset was collected in Japanese, which may limit applicability to other languages and cultural contexts.

## Confidence
- High confidence: The dataset construction methodology and its contribution to advancing research on automated sales dialogue systems.
- Medium confidence: The finding that avoiding negative willingness evaluations is more effective than increasing positive ones for improving purchase intentions.
- Medium confidence: The effectiveness of attribute-conditioned fine-tuning with user willingness labels.

## Next Checks
1. **Cross-domain validation**: Test the model's performance on sales dialogues for different product categories to assess generalizability of the findings about willingness management strategies.
2. **Behavioral outcome verification**: Conduct follow-up studies to measure actual purchase completion rates rather than just purchase intention improvements.
3. **Ablation study on willingness types**: Perform an ablation study where each type of willingness is systematically removed from the training data to determine which types are most critical for model performance.