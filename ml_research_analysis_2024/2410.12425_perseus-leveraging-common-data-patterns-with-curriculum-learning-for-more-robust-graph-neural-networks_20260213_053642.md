---
ver: rpa2
title: 'Perseus: Leveraging Common Data Patterns with Curriculum Learning for More
  Robust Graph Neural Networks'
arxiv_id: '2410.12425'
source_url: https://arxiv.org/abs/2410.12425
tags:
- graph
- learning
- edges
- data
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of Graph Neural Networks
  (GNNs) to adversarial attacks by introducing Perseus, a curriculum learning-based
  defense framework. Perseus quantifies edge difficulty using a global homophily metric
  and applies an adaptive edge selection strategy that dynamically adjusts learning
  order based on training status.
---

# Perseus: Leveraging Common Data Patterns with Curriculum Learning for More Robust Graph Neural Networks

## Quick Facts
- **arXiv ID**: 2410.12425
- **Source URL**: https://arxiv.org/abs/2410.12425
- **Reference count**: 40
- **Primary result**: Achieves superior robustness to adversarial attacks on graph neural networks using curriculum learning-based defense framework

## Executive Summary
This paper introduces Perseus, a curriculum learning-based defense framework that addresses the vulnerability of Graph Neural Networks (GNNs) to adversarial attacks. Perseus quantifies edge difficulty using a global homophily metric and applies an adaptive edge selection strategy that dynamically adjusts learning order based on training status. The approach guides models to progressively learn from common, undisturbed edges before tackling more complex ones, mitigating the impact of adversarial perturbations. Experiments on five real-world datasets demonstrate that models trained with Perseus achieve significantly better robustness, particularly under high perturbation ratios, outperforming state-of-the-art defense methods in node classification accuracy after adversarial attacks.

## Method Summary
Perseus implements a two-module architecture consisting of Adaptive Edge Selection (AES) and Graph Auto-Encoder Representation Learning (GAE). The method begins by computing a Global Homophily (GloHom) metric for all edges to quantify their difficulty. Edges are then selected for training in a curriculum-based order, starting with those that have the highest homophily and are least likely to be adversarial. As training progresses, the model monitors validation performance to determine when to introduce new edges, applying edge weight decay to reduce the impact of potentially adversarial connections. This iterative process continues until all edges are incorporated, with the model learning to focus on common data patterns before handling more complex edge relationships.

## Key Results
- Perseus achieves up to 15% higher node classification accuracy than baseline methods under 25% perturbation attacks
- The GloHom metric effectively discriminates between clean and adversarial edges, with 80% of selected edges being unperturbed in early training stages
- Perseus maintains stable performance across different perturbation ratios while other methods show significant degradation
- The adaptive edge selection strategy prevents overfitting, with training loss exceeding validation loss as perturbed data are gradually introduced

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Global homophily (GloHom) metric effectively discriminates between clean and perturbed edges in graph data.
- Mechanism: GloHom measures the impact of edge removal on graph homophily by evaluating the gradient of homophily change with respect to adjacency matrix perturbations.
- Core assumption: Adversarial edges have different homophily characteristics than normal edges, making them distinguishable through global structural analysis.
- Evidence anchors:
  - [abstract]: "Perseus assesses edge difficulty using global homophily and applies a curriculum learning strategy to adjust the learning order"
  - [section 4.1]: "we introduces a metrics called global homophily (glohom)... The utilisation of gradient descent based on global homophily enables the identification and elimination of edges that propagate the most misleading information"
  - [corpus]: Weak - corpus papers discuss adversarial perturbations but don't specifically validate GloHom metric for edge discrimination
- Break condition: If adversarial attacks evolve to preserve homophily characteristics while causing misclassification, GloHom would lose discriminative power.

### Mechanism 2
- Claim: Curriculum learning strategy prevents models from getting stuck in poor local optima during adversarial training.
- Mechanism: By learning from common, undisturbed edges first, the model establishes a robust foundation before encountering complex/perturbed edges, smoothing the optimization landscape.
- Core assumption: Learning order matters - starting with simpler, cleaner patterns enables better generalization to complex patterns.
- Evidence anchors:
  - [abstract]: "Perseus assesses edge difficulty using global homophily and applies a curriculum learning strategy to adjust the learning order, guiding the model to learn the full graph structure while adaptively focusing on common data patterns"
  - [section 1]: "Research in cognitive science indicates [ 7, 24] that humans achieve deeper understanding and better generalization capabilities by learning from simple concepts to complex ones"
  - [section 5.2.4]: "cl model exhibited higher loss on the training set but relatively lower loss on the validation set, indicating a strong robustness"
- Break condition: If the difficulty ordering is incorrect or if the model cannot effectively utilize the foundation built from simple edges, the curriculum approach could harm performance.

### Mechanism 3
- Claim: Adaptive edge selection based on training status prevents overfitting while maintaining learning capacity.
- Mechanism: The model monitors validation performance and dynamically adjusts when and how many new edges to add, using edge weight decay to reduce impact of potentially adversarial edges.
- Core assumption: Model convergence on validation set indicates optimal learning point for current edge set, and adding edges too early or too quickly leads to overfitting.
- Evidence anchors:
  - [section 4.2]: "determining the appropriate timing to introduce training samples is a significant challenge... This strategy triggers an early stopping mechanism once the performance improvement plateaus"
  - [section 4.3]: "The algorithm uses the node feature matrix, the original adjacency matrix as input, and the hyperparameter λ to control the decay of the addition rate"
  - [section 5.2.4]: "as the training progressed and perturbed data were introduced, the training loss of the cl model gradually exceeded the validation loss"
- Break condition: If the convergence detection is unreliable or if the decay rate is poorly tuned, the adaptive selection could either add edges too late (underfitting) or too early (overfitting).

## Foundational Learning

- Graph Neural Networks (GNNs):
  - Why needed here: Perseus builds upon GNN architecture and addresses their specific vulnerability to adversarial attacks on graph structure.
  - Quick check question: What are the two main ways GNNs aggregate information from neighboring nodes?

- Adversarial Attacks on Graphs:
  - Why needed here: Understanding how attacks manipulate graph structure (edge addition/removal) is crucial for appreciating why Perseus's defense mechanisms work.
  - Quick check question: What distinguishes global attacks from local attacks in graph adversarial settings?

- Curriculum Learning:
  - Why needed here: Perseus applies curriculum learning principles to graph data, organizing edge learning from simple to complex.
  - Quick check question: How does curriculum learning differ from standard random sampling in training neural networks?

## Architecture Onboarding

- Component map: Input features -> GloHom computation -> Edge difficulty ranking -> Adaptive edge selection -> GAE training -> Model output
- Critical path:
  1. Initialize with warm-start edge set based on GloHom
  2. Train GAE until convergence on validation set
  3. Select new edges using adaptive strategy
  4. Update edge weights with decay
  5. Repeat until all edges incorporated
- Design tradeoffs:
  - Edge selection frequency vs. training stability
  - Decay rate vs. model capacity to handle adversarial edges
  - GloHom computation cost vs. edge discrimination quality
- Failure signatures:
  - Training loss decreases but validation loss increases → overfitting to adversarial edges
  - Both training and validation loss plateau early → insufficient edge diversity
  - GloHom metric fails to distinguish edge types → poor curriculum ordering
- First 3 experiments:
  1. Baseline: Train standard GCN on clean Cora dataset, measure accuracy
  2. Attack: Apply Metattack with 10% perturbation, measure GCN accuracy drop
  3. Perseus validation: Apply Perseus to attacked Cora, compare accuracy against baseline and other defense methods at different perturbation levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Perseus perform against adaptive attacks that specifically target its curriculum learning defense strategy?
- Basis in paper: [explicit] The paper mentions that existing defenses struggle against high perturbation ratios and that Perseus maintains stable performance, but doesn't test against attacks specifically designed to bypass curriculum learning.
- Why unresolved: The experiments focus on standard attack methods (Metaattack and PGD) but don't explore whether an attacker could learn to exploit the curriculum learning mechanism itself.
- What evidence would resolve it: Testing Perseus against attacks that adaptively modify their strategy based on Perseus's edge selection and learning progression patterns.

### Open Question 2
- Question: What is the computational overhead of Perseus compared to standard GNN training and other defense methods?
- Basis in paper: [inferred] The paper describes an iterative process involving edge quantization, adaptive edge selection, and model training, but doesn't provide runtime comparisons or computational complexity analysis.
- Why unresolved: While the paper demonstrates effectiveness, it doesn't quantify the trade-off between improved robustness and increased computational cost.
- What evidence would resolve it: Detailed timing experiments comparing Perseus training time to baseline methods across different graph sizes and perturbation levels.

### Open Question 3
- Question: How sensitive is Perseus to hyperparameter choices, particularly the decay parameter λ and initial warmstart ratio?
- Basis in paper: [explicit] The paper mentions a sensibility analysis showing stable performance across different warmstart ratios, but doesn't extensively explore the impact of other key hyperparameters.
- Why unresolved: The experiments show Perseus is robust to warmstart changes but don't comprehensively test sensitivity to λ or other parameters that could affect the curriculum learning dynamics.
- What evidence would resolve it: Systematic hyperparameter sweeps showing how Perseus performance varies with different λ values and other tunable parameters.

## Limitations
- The GloHom metric's effectiveness against adaptive attacks specifically designed to preserve homophily while causing misclassification remains untested
- Computational overhead compared to standard GNN training and other defense methods is not quantified
- Limited hyperparameter sensitivity analysis beyond warmstart ratio, with insufficient exploration of decay parameter λ impact

## Confidence

- **High confidence**: Perseus improves robustness over baseline GNNs under the tested adversarial attack scenarios (Metattack, PGD on Cora, Citeseer, etc.)
- **Medium confidence**: GloHom metric effectively discriminates clean from adversarial edges across different attack types and perturbation levels
- **Medium confidence**: Curriculum learning strategy prevents overfitting and improves generalization compared to standard training approaches

## Next Checks

1. **Cross-dataset validation**: Test Perseus on datasets with different homophily properties (e.g., low homophily graphs like Texas or Cornell) to verify GloHom metric's generalizability beyond high-homophily datasets
2. **Adaptive attack evaluation**: Evaluate Perseus against white-box attacks where adversaries can observe and adapt to GloHom-based defense mechanisms
3. **Scalability assessment**: Measure training time and memory usage of Perseus versus baselines on graphs of increasing size to quantify practical deployment constraints