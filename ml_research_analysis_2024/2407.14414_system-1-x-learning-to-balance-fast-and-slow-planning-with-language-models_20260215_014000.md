---
ver: rpa2
title: 'System-1.x: Learning to Balance Fast and Slow Planning with Language Models'
arxiv_id: '2407.14414'
source_url: https://arxiv.org/abs/2407.14414
tags:
- state
- system-1
- planner
- action
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: System-1.x introduces a controllable hybrid planning framework
  that balances fast, direct planning (System-1) with slow, search-based planning
  (System-2) by decomposing problems into sub-goals and dynamically assigning them
  to the appropriate system based on difficulty. The method uses a trained controller
  to classify sub-goals as easy or hard, a System-1 Planner for fast solutions, and
  a System-2 Planner for deliberate search, all implemented on a single fine-tuned
  LLM with only search trace supervision.
---

# System-1.x: Learning to Balance Fast and Slow Planning with Language Models

## Quick Facts
- arXiv ID: 2407.14414
- Source URL: https://arxiv.org/abs/2407.14414
- Reference count: 37
- Primary result: Hybrid planning framework that outperforms both pure fast and slow planners by dynamically allocating tasks based on difficulty

## Executive Summary
System-1.x introduces a controllable hybrid planning framework that balances fast, direct planning (System-1) with slow, search-based planning (System-2) by decomposing problems into sub-goals and dynamically assigning them to the appropriate system based on difficulty. The method uses a trained controller to classify sub-goals as easy or hard, a System-1 Planner for fast solutions, and a System-2 Planner for deliberate search, all implemented on a single fine-tuned LLM with only search trace supervision. Experiments on Maze Navigation and Blocksworld show that System-1.x outperforms both pure System-1 and System-2 planners at all budgets, achieving up to 33% higher accuracy than System-2 while using fewer states explored.

## Method Summary
System-1.x trains three components (controller, System-1 Planner, System-2 Planner) on a single LLM using search trace supervision from A* search. The controller decomposes planning problems into sub-goals and classifies them as easy or hard using a hardness function. Easy sub-goals are solved with direct planning (System-1), while hard ones use search-based planning (System-2). The hybridization factor x controls the balance between systems during training and inference, offering both training-time and test-time controllability.

## Key Results
- System-1.x outperforms both pure System-1 and System-2 planners across all computation budgets
- Achieves up to 33% higher accuracy than System-2 while exploring fewer states
- Successfully generalizes across different search algorithms (BFS, DFS, A*)
- Supports neuro-symbolic variants by replacing neural System-2 with symbolic solvers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: System-1.x dynamically balances fast and slow planning by decomposing problems into sub-goals and assigning each to the appropriate planner based on difficulty.
- Mechanism: The controller first decomposes the overall planning problem into sub-goals, then uses a hardness function to classify each as easy or hard. Easy sub-goals are solved with System-1 (fast, direct planning), while hard ones use System-2 (slow, search-based planning).
- Core assumption: Sub-goals can be ranked by difficulty using a hardness function, and this ranking correlates with the planner's ability to solve them efficiently.
- Evidence anchors:
  - [abstract] "the controller decomposes a planning problem into sub-goals, and classifies them as easy or hard to be solved by either System-1 or 2"
  - [section 2.3] "the role of the controller is two-fold: (i) decomposing a planning problem into sub-goals... (ii) classifying those sub-goals as easy or hard"
  - [corpus] No direct evidence; weak signal from "dual-system" reasoning in neighbors.
- Break condition: If the hardness function misclassifies sub-goals (e.g., a hard sub-goal is labeled easy), System-1 may fail, and the entire plan becomes invalid.

### Mechanism 2
- Claim: By intelligently allocating System-2 to only hard sub-goals, System-1.x saves computation compared to pure System-2 planning.
- Mechanism: System-1.x limits the expensive search-based System-2 to only the hardest sub-goals, while solving easier sub-goals directly with System-1. This reduces the total number of states explored.
- Core assumption: Search-based planning (System-2) is significantly more expensive in terms of states explored than direct planning (System-1).
- Evidence anchors:
  - [abstract] "by being able to learn from different search algorithms, our method is robust to the choice of search algorithm"
  - [section 2.1] "System-1 Planners... only explores the states that are part of its plan, i.e., SE Sys1 = n... System-2 Planner... will perform additional state explorations before generating a plan, resulting in SE Sys2 ≫ SE Sys1"
  - [corpus] No direct evidence; weak signal from "fast-in-slow" and "ground slow, move fast" neighbors.
- Break condition: If the hybridization factor x is set too low (e.g., x=0), System-1.x reverts to pure System-1 and loses accuracy. If x is too high, it behaves like System-2 and loses efficiency.

### Mechanism 3
- Claim: System-1.x offers both training-time and test-time controllability, letting users adjust the balance between speed and accuracy.
- Mechanism: During training, the hybridization factor x controls the data distribution for the controller (how many problems are labeled hard vs. easy). During inference, the controller's confidence can be biased to favor System-1 or System-2 more strongly.
- Core assumption: The controller can be trained to reliably predict whether a sub-goal is easy or hard, and this prediction can be adjusted at test time.
- Evidence anchors:
  - [abstract] "System-1.x offers both training-time and test-time controllability via a hybridization factor"
  - [section 2.4] "System-1.x offers training-time control... and test-time control... by biasing the controller"
  - [corpus] No direct evidence; weak signal from "reasoning economy" neighbor.
- Break condition: If the controller's predictions are noisy or biased, test-time control adjustments may not yield the intended trade-off between speed and accuracy.

## Foundational Learning

- Concept: Sub-goal decomposition in planning
  - Why needed here: System-1.x relies on breaking down long-horizon problems into smaller, manageable sub-goals. Without this, the planner cannot allocate System-1 vs System-2 appropriately.
  - Quick check question: Given a plan of length 8, what sub-goals would you decompose it into for x=0.5?

- Concept: Hardness functions and their role in planning
  - Why needed here: The controller uses a hardness function to decide whether a sub-goal is easy or hard. This guides the allocation of planners and ultimately the efficiency of System-1.x.
  - Quick check question: For a maze, how would you define a hardness function based on obstacles? How would it differ for Blocksworld?

- Concept: Training-time vs test-time control
  - Why needed here: System-1.x offers both: x controls the training data, and test-time bias adjusts inference behavior. Understanding this distinction is key to using the system effectively.
  - Quick check question: If you train a System-1.5 model and want it to behave like System-1.75 at test time, what do you adjust?

## Architecture Onboarding

- Component map:
  - Controller -> System-1 Planner / System-2 Planner -> Final plan

- Critical path:
  1. Input problem (start state, goal state) to controller.
  2. Controller generates sub-goals and easy/hard labels.
  3. For each sub-goal, invoke System-1 or System-2 planner.
  4. Concatenate sub-plans to form the final plan.

- Design tradeoffs:
  - Fine-tuning all three components on the same LLM saves parameters but requires careful data balancing.
  - Sub-goal decomposition granularity affects efficiency: too coarse → System-1 fails; too fine → overhead from too many transitions.
  - Hardness function choice impacts controller accuracy and, thus, overall performance.

- Failure signatures:
  - High invalid plan rate → controller misclassifying hard sub-goals as easy.
  - Low accuracy but high efficiency → controller too conservative (labeling too many as easy).
  - High efficiency but low accuracy → controller too aggressive (labeling too many as hard, losing speed).

- First 3 experiments:
  1. Train a System-1.x controller on a small maze dataset with a simple obstacle-based hardness function; verify it can classify sub-goals correctly.
  2. Compare System-1.x with System-1 and System-2 on a fixed budget (e.g., 15 states explored) to confirm efficiency gains.
  3. Adjust the hybridization factor x during training and observe changes in accuracy vs. #States-Explored curves.

## Open Questions the Paper Calls Out

The paper highlights several limitations including scalability to very long plans (hundreds or thousands of steps), the need for more robust handling of partial failures, and the exploration of additional planning domains beyond Maze Navigation and Blocksworld.

## Limitations
- Method is currently limited to fully-observable and deterministic domains, not addressing partial observability or non-determinism
- Performance depends heavily on the quality of the hardness function for sub-goal decomposition
- Scalability to very long plans (hundreds or thousands of steps) remains an open question

## Confidence

- **High confidence**: The mechanism by which System-1.x saves computation by limiting System-2 to hard sub-goals is well-supported by the theoretical analysis and experimental results showing reduced states explored.
- **Medium confidence**: The claim that System-1.x offers controllable trade-offs between speed and accuracy is supported by the hybridization factor, but the practical usability of test-time control adjustments may depend on the quality of the controller's predictions.
- **Low confidence**: The robustness of System-1.x to different search algorithms (BFS, DFS, A*) is asserted but not thoroughly validated. The paper mentions robustness but does not provide systematic ablation studies across algorithms.

## Next Checks

1. **Cross-domain validation**: Test System-1.x on planning tasks outside of Maze Navigation and Blocksworld (e.g., Sokoban, Tower of Hanoi) to assess generalizability of the hardness function and controller.

2. **Ablation study on hardness functions**: Implement and compare multiple hardness functions (e.g., obstacle count, Manhattan distance, learned heuristics) to determine which performs best across different planning domains and how sensitive the system is to this choice.

3. **Partial failure analysis**: Systematically introduce misclassifications in the controller and measure the impact on overall plan validity and efficiency to understand failure propagation and potential recovery mechanisms.