---
ver: rpa2
title: 'Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models
  (MLLMs): Solving TSP and mTSP Combinatorial Challenges'
arxiv_id: '2407.00092'
source_url: https://arxiv.org/abs/2407.00092
tags:
- solution
- multi-agent
- critic
- problem
- route
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study explores the use of Multimodal Large Language Models\
  \ (MLLMs) for visually solving the Traveling Salesman Problem (TSP) and Multiple\
  \ Traveling Salesman Problem (mTSP) without relying on numerical data. Two novel\
  \ multi-agent strategies\u2014Multi-Agent 1 (Initializer, Critic, and Scorer) and\
  \ Multi-Agent 2 (Initializer and Critic)\u2014are introduced to iteratively refine\
  \ solutions using visual cues."
---

# Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models (MLLMs): Solving TSP and mTSP Combinatorial Challenges

## Quick Facts
- **arXiv ID**: 2407.00092
- **Source URL**: https://arxiv.org/abs/2407.00092
- **Reference count**: 0
- **Primary result**: MLLMs can visually solve TSP/mTSP using multi-agent strategies without numerical data

## Executive Summary
This study explores the use of Multimodal Large Language Models (MLLMs) for visually solving the Traveling Salesman Problem (TSP) and Multiple Traveling Salesman Problem (mTSP) without relying on numerical data. Two novel multi-agent strategies—Multi-Agent 1 (Initializer, Critic, and Scorer) and Multi-Agent 2 (Initializer and Critic)—are introduced to iteratively refine solutions using visual cues. Experimental results demonstrate that both multi-agent models significantly improve solution quality compared to zero-shot approaches. Multi-Agent 1 excels in detailed route refinement, while Multi-Agent 2 offers rapid decision-making capabilities. The findings highlight the robust visual reasoning capabilities of MLLMs in addressing complex combinatorial problems, showcasing their potential for practical applications in computational optimization.

## Method Summary
The study employs MLLMs to solve TSP and mTSP by interpreting images of node distributions rather than using numerical coordinates. Two multi-agent strategies are implemented: Multi-Agent 1 with three roles (Initializer, Critic, Scorer) and Multi-Agent 2 with two roles (Initializer, Critic). The Initializer generates initial route proposals, the Critic iteratively refines these routes, and the Scorer evaluates visual clarity and efficiency in the three-agent system. The approach is evaluated against Google OR-Tools using metrics including mean gap percentage, standard deviation, and Wilcoxon signed-rank test for statistical validation.

## Key Results
- Both multi-agent models significantly improve solution quality compared to zero-shot approaches
- Multi-Agent 1 provides superior detailed route refinement through its three-agent architecture
- Multi-Agent 2 achieves faster decision-making while maintaining competitive solution quality
- MLLMs demonstrate robust visual reasoning capabilities for complex combinatorial problems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MLLMs can solve TSP and mTSP using only visual reasoning without numerical coordinates
- Mechanism: The model interprets node layouts visually and generates routes based on spatial clustering and visual path efficiency, bypassing the need for explicit distance calculations
- Core assumption: Visual perception alone is sufficient to infer route optimality in TSP/mTSP problems
- Evidence anchors: [abstract] "visually solving the Traveling Salesman Problem (TSP) and Multiple Traveling Salesman Problem (mTSP) using images that portray point distributions on a two-dimensional plane"; [section] "the human ability to suggest efficient routes through nodes without explicit calculations visually"
- Break condition: Visual layout becomes too complex for spatial inference without quantitative distance information

### Mechanism 2
- Claim: Multi-agent architecture improves solution quality through iterative refinement
- Mechanism: Initializer proposes routes, Critic refines them iteratively, and Scorer evaluates based on visual clarity; this cycle progressively enhances route optimization
- Core assumption: Specialized agents can improve upon each other's outputs without numerical feedback
- Evidence anchors: [abstract] "two novel multi-agent strategies—Multi-Agent 1 (Initializer, Critic, and Scorer) and Multi-Agent 2 (Initializer and Critic)"; [section] "the Initializer suggests routes visually, the Critic improves them iteratively, and the Scorer evaluates them based on visual clarity and efficiency"
- Break condition: Critic or Scorer agents fail to improve solutions beyond initial proposals

### Mechanism 3
- Claim: Simplified two-agent system (Initializer + Critic) offers rapid decision-making
- Mechanism: Removes Scorer agent, allowing faster iterations by having Critic refine routes at higher temperature settings without evaluative scoring
- Core assumption: Speed can be prioritized over thorough evaluation without significant quality loss
- Evidence anchors: [abstract] "Multi-Agent 2 offers rapid decision-making capabilities"; [section] "simplifies the approach by using only the Initializer and Critic MLLM agents, focusing on rapid iterative refinement"
- Break condition: Rapid iterations produce inconsistent or suboptimal solutions

## Foundational Learning

- **Concept**: Visual reasoning in multimodal models
  - Why needed here: Core capability enabling TSP/mTSP solution without numerical data
  - Quick check question: Can the model identify optimal visual paths from point distributions?

- **Concept**: Multi-agent system coordination
  - Why needed here: Enables iterative refinement and specialization in route optimization
  - Quick check question: Do agents successfully improve solutions through sequential refinement?

- **Concept**: Temperature-based sampling in LLMs
  - Why needed here: Controls diversity of Critic-generated solutions for exploration
  - Quick check question: Does increasing temperature generate sufficiently diverse route proposals?

## Architecture Onboarding

- **Component map**: Input images → Initializer → Visual route proposal → Critic refinement → (Scorer evaluation) → Final optimized route
- **Critical path**: Initializer → Visual route proposal → Critic refinement → (Scorer evaluation) → Final optimized route
- **Design tradeoffs**: Multi-Agent 1 offers higher quality but slower processing due to Scorer evaluation; Multi-Agent 2 provides faster iterations with potentially less refined solutions
- **Failure signatures**: Routes missing nodes (hallucinations), no improvement across iterations, inconsistent solution quality
- **First 3 experiments**:
  1. Test Initializer alone on small TSP instances (5-10 nodes)
  2. Add Critic to evaluate iterative improvement on same instances
  3. Compare Multi-Agent 1 vs Multi-Agent 2 on medium-sized problems (15-20 nodes)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific visual cues and features do the MLLM agents use to infer efficient routes, and how do these compare to human visual problem-solving strategies?
- Basis in paper: [explicit] The paper discusses that the MLLM agents use visual cues to infer efficient routes without relying on numerical data, mimicking human visual problem-solving abilities
- Why unresolved: The paper mentions the use of visual cues but does not detail the specific visual features or cues that the agents rely on for route optimization
- What evidence would resolve it: Detailed analysis or visualization of the visual features and cues identified by the MLLM agents during the route optimization process, along with a comparison to documented human visual strategies in similar tasks

### Open Question 2
- Question: How does the performance of the multi-agent strategies vary with different types of visual representations of the TSP and mTSP problems, such as varying node densities or spatial distributions?
- Basis in paper: [inferred] The paper mentions that test data is generated using a uniform distribution of nodes, but it does not explore how different spatial distributions or node densities affect the performance of the multi-agent strategies
- What evidence would resolve it: Experimental results showing the performance of the multi-agent strategies across various visual representations with different node densities and spatial distributions, highlighting any changes in solution quality or computational efficiency

### Open Question 3
- Question: What are the limitations of the multi-agent strategies in handling larger TSP and mTSP instances, and how can these limitations be addressed to improve scalability?
- Basis in paper: [explicit] The paper notes that hallucinations occur more frequently in larger problems, where routes fail to visit all designated nodes, indicating limitations in scaling the proposed strategies
- Why unresolved: While the paper identifies the issue of hallucinations in larger instances, it does not provide a detailed exploration of the underlying causes or potential solutions to improve scalability
- What evidence would resolve it: A comprehensive study identifying the root causes of hallucinations in larger instances and proposing modifications or enhancements to the multi-agent strategies to mitigate these issues, along with experimental validation of improved scalability

## Limitations

- **Reproducibility barrier**: The proprietary nature of ChatGPT-4o and unspecified prompt engineering details create significant reproduction challenges
- **Evaluation scope**: Limited comparison against only one baseline (Google OR-Tools) without exploring alternative MLLM approaches or traditional heuristics
- **Zero-shot claim**: The multi-agent system requires carefully crafted prompts and iterative refinement procedures that constitute a form of few-shot methodology rather than true zero-shot learning

## Confidence

- **High confidence**: The general feasibility of using MLLMs for visual TSP/mTSP problem-solving through the proposed multi-agent framework
- **Medium confidence**: The comparative advantage of Multi-Agent 1 over Multi-Agent 2 in solution quality
- **Low confidence**: The claim that visual reasoning alone is sufficient for optimal TSP solutions in all problem sizes

## Next Checks

1. **Prompt Engineering Validation**: Systematically test the sensitivity of results to prompt variations across all three agent roles to establish robustness boundaries
2. **Scaling Analysis**: Evaluate performance degradation points by testing the framework on progressively larger TSP instances (beyond the 25-node limit) to identify the visual complexity threshold
3. **Baseline Expansion**: Compare against additional optimization methods including other MLLMs (GPT-4V, Gemini), traditional heuristics (Nearest Neighbor, 2-opt), and state-of-the-art solvers to contextualize the claimed advantages