---
ver: rpa2
title: 'Technical Report: Competition Solution For BetterMixture'
arxiv_id: '2403.13233'
source_url: https://arxiv.org/abs/2403.13233
tags:
- json
- data
- filtering
- language
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a data filtering and selection solution for
  the BetterMixture challenge, achieving third place in the competition. The approach
  addresses the challenge of optimizing fine-tuning data mixtures for large language
  models under computational constraints.
---

# Technical Report: Competition Solution For BetterMixture

## Quick Facts
- arXiv ID: 2403.13233
- Source URL: https://arxiv.org/abs/2403.13233
- Reference count: 2
- Third place in BetterMixture challenge with final score 1.567

## Executive Summary
This paper presents a data filtering and selection solution for the BetterMixture challenge, achieving third place in the competition. The approach addresses the challenge of optimizing fine-tuning data mixtures for large language models under computational constraints. It employs a three-stage pipeline: data deduplication via exact match, low-level quality filtering (text length and language identification), and high-level quality filtering using large language models (perplexity, instruction-following difficulty, and multi-model voting). Diversity is enhanced via k-center-greedy selection. The method improves model performance on English and Chinese benchmarks, with final evaluation scores of 1.567, demonstrating the effectiveness of LLM-driven data selection.

## Method Summary
The solution implements a three-stage pipeline for data filtering and selection. First, exact match deduplication reduces the dataset from 3.4M to 2.7M samples. Second, low-level quality filtering removes samples with text length outside 20-2000 characters and language scores below 0.2. Third, high-level quality filtering employs LLM-based scoring including perplexity (20-1000 range) and instruction-following difficulty (IFD) scores (0.2-0.9 range), with an IFD-Vote mechanism comparing base and fine-tuned model outputs. Diversity is enhanced using k-center-greedy algorithm to select 60K samples within the 10M token constraint. Final training uses Baichuan2-7B-Base with LoRA, bfloat16 precision, 3 epochs, batch size 1, and learning rate 1e-3.

## Key Results
- Achieved third place in BetterMixture challenge with final evaluation score of 1.567
- Improved baseline score from 1.342 to 1.567 across reasoning, common sense, truthfulness, math, English/Chinese knowledge, and summarization benchmarks
- Reduced dataset from 3.4M to 2.7M samples through deduplication while preserving distribution
- Selected 60K high-quality, diverse samples within 10M token constraint for fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High-level quality filtering using LLM-based perplexity and instruction-following difficulty scores improves fine-tuning data quality more effectively than low-level filtering alone.
- Mechanism: LLMs score each instruction sample based on perplexity (measuring instruction complexity) and IFD (measuring instruction-following difficulty). Samples are filtered based on score thresholds, removing low-quality or overly simple data.
- Core assumption: LLM-based scoring correlates with downstream task performance and can identify useful versus harmful samples.
- Evidence anchors:
  - [abstract] "To enhance data quality filtering, we employed LLM for scoring and filtering of the data, which refered as high-level quality filtering. This approach encompasses LLM PPL, LLM IFD and LLM IFD-Vote filtering."
  - [section] "We introduced high-level quality filtering, with a LLM serving as a trainable data selector. This process evaluates and assigns scores to each sample of instruction fine-tuning data. Specifically, we introduced Perplexity (PPL) calculated by the LLM to quantify the difficulty of instructions. Instruction Following Difficulty (IFD) also introduced to assess the challenge of responding to specific instructions."
- Break condition: If LLM scoring becomes misaligned with actual model performance (e.g., due to domain shift or model bias), the filtering may remove useful data or retain harmful samples.

### Mechanism 2
- Claim: Diversity selection via k-center-greedy algorithm preserves generalization while staying within computational token limits.
- Mechanism: After high-quality samples are selected based on IFD scores, the k-center-greedy algorithm selects a subset that maximizes pairwise distance in feature space, ensuring broad coverage of the instruction space.
- Core assumption: Maximizing diversity in the training set improves model generalization on unseen tasks.
- Evidence anchors:
  - [abstract] "Diversity is equally critical as quality to ensure the generalization capabilities of LLMs. Meanwhile, given the constraint of training tokens capped at 10 million, corresponding to approximately 60,000 samples. We select samples based on the IFD score and the k-center greedy algorithm to satisfy token constraint and guarantee high diversity."
  - [section] "In addition to quality, diversity is crucial. We employ the k-center-greedy algorithm to enhance the diversity of the selected data mixture."
- Break condition: If the feature representation used for diversity selection is poor or noisy, the algorithm may select redundant or irrelevant samples.

### Mechanism 3
- Claim: LLM IFD-Vote filtering using multiple models reduces noise and improves selection precision.
- Mechanism: Two versions of the model (base and fine-tuned) compute IFD scores for each sample. Samples with large discrepancies (>50%) between the two scores are removed, assuming the disagreement indicates uncertainty or noise.
- Core assumption: Disagreement between models indicates unreliable samples; consensus indicates higher quality.
- Evidence anchors:
  - [section] "To enhance precision, we employed a fine-tuned version of the Baichuan2-7B-Base model as the IFD scorer. This model was fine-tuned with a mix of data processed through the previously and subsequently mentioned filtering and selection strategies. Specifically, we calculated two IFD scores: one from the base model, another from the fine-tuned model. Samples exhibiting a variation of more than 50% between two scores were excluded."
- Break condition: If both models are systematically biased in the same way, disagreement may not indicate poor quality; if fine-tuning introduces its own bias, it may incorrectly filter out useful samples.

## Foundational Learning

- Concept: Perplexity as a measure of language model difficulty
  - Why needed here: Perplexity is used to filter out instructions that are too simple or too complex for effective fine-tuning.
  - Quick check question: What does a high perplexity score indicate about an instruction's difficulty for the model?
- Concept: Instruction-following difficulty (IFD) scoring
  - Why needed here: IFD quantifies how challenging it is for the model to follow an instruction, guiding the selection of educationally valuable samples.
  - Quick check question: How is IFD calculated from the model's conditional and unconditional answer scores?
- Concept: k-center-greedy algorithm for diversity selection
  - Why needed here: Ensures the final dataset covers a broad range of instruction types while respecting token limits.
  - Quick check question: What is the objective function of the k-center-greedy algorithm in this context?

## Architecture Onboarding

- Component map:
  Data input → Deduplication (MD5 exact match) → Low-level filtering (text length 20-2000, language score >0.2) → High-level filtering (PPL 20-1000, IFD 0.2-0.9, IFD-Vote) → Diversity selection (k-center-greedy) → Mixed dataset output
  Supporting components: Baichuan2-7B-Base model for scoring, fine-tuned model for IFD-Vote, token counting for limits
- Critical path:
  1. Deduplication reduces dataset size without distribution shift
  2. Low-level filtering removes obviously poor samples
  3. High-level filtering scores and prunes based on LLM metrics
  4. Diversity selection ensures broad coverage within token budget
- Design tradeoffs:
  - Exact match deduplication vs. semantic deduplication: exact match is faster and safer for distribution preservation but may miss near-duplicates
  - Single-model vs. multi-model IFD scoring: multi-model reduces noise but increases compute and complexity
  - Fixed thresholds vs. adaptive thresholds: fixed is simpler and more reproducible but may not adapt to dataset shifts
- Failure signatures:
  - Sudden drop in evaluation score after filtering: possible over-filtering or threshold misconfiguration
  - No improvement despite high-quality filtering: possible misalignment between filtering metrics and evaluation tasks
  - Training instability or NaN losses: possible introduction of noisy or malformed samples
- First 3 experiments:
  1. Run deduplication alone and measure reduction in sample count and any change in downstream score
  2. Apply low-level filtering only and compare results to baseline
  3. Apply full pipeline (deduplication + low-level + high-level + diversity) and measure final score against baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the IFD-Vote method's performance compare to using a single fine-tuned model for IFD scoring, and what are the computational trade-offs?
- Basis in paper: [explicit] The paper introduces IFD-Vote using multiple LLMs to refine quality assessment, but doesn't compare it to using a single fine-tuned model for IFD scoring.
- Why unresolved: The paper doesn't provide comparative analysis between IFD-Vote and single fine-tuned model approaches, nor does it discuss computational costs.
- What evidence would resolve it: A controlled experiment comparing the performance and computational efficiency of IFD-Vote against a single fine-tuned model for IFD scoring.

### Open Question 2
- Question: How sensitive is the overall solution to the specific thresholds chosen for low-level quality filtering (text length and language identification)?
- Basis in paper: [inferred] The paper mentions establishing appropriate boundaries for text length and language identification filtering based on data analysis, but doesn't explore the sensitivity of the solution to these threshold choices.
- Why unresolved: The paper doesn't provide ablation studies or sensitivity analysis for the filtering thresholds.
- What evidence would resolve it: A systematic study varying the filtering thresholds and measuring their impact on final model performance.

### Open Question 3
- Question: What is the optimal balance between diversity selection and quality filtering, and how does this balance affect model performance across different benchmarks?
- Basis in paper: [explicit] The paper employs k-center-greedy algorithm for diversity selection and high-level quality filtering, but doesn't explore the optimal balance between these two aspects.
- Why unresolved: The paper doesn't provide analysis on how different balances between diversity and quality affect performance across various benchmarks.
- What evidence would resolve it: Experiments varying the balance between diversity and quality in the data selection process and measuring performance impacts across different benchmarks.

### Open Question 4
- Question: How would the proposed solution perform if applied to datasets with different language distributions or domains?
- Basis in paper: [inferred] The solution is developed and tested on a dataset primarily comprising English and Chinese languages, with specific benchmarks for these languages. The generalizability to other language distributions or domains is not explored.
- Why unresolved: The paper doesn't provide evidence of the solution's effectiveness on datasets with different language distributions or domains.
- What evidence would resolve it: Applying the proposed solution to datasets with different language distributions or domains and comparing the performance to the original results.

## Limitations
- The solution's performance heavily depends on the quality and alignment of the LLM scoring functions, particularly the IFD and perplexity thresholds
- The exact composition of the 20 candidate datasets and specific implementation details of the k-center-greedy feature extraction are not fully specified
- The effectiveness of the IFD-Vote mechanism is supported by the improvement from 1.342 to 1.567 but lacks ablation studies

## Confidence
- **High Confidence**: The deduplication and low-level filtering mechanisms (text length and language identification) are straightforward and well-established. The token limit constraint (10M tokens) is explicitly stated and enforced.
- **Medium Confidence**: The high-level LLM-based filtering (PPL, IFD, IFD-Vote) is methodologically sound but depends on threshold choices that may not generalize across datasets.
- **Low Confidence**: The exact composition of the 20 candidate datasets and the specific implementation details of the k-center-greedy feature extraction are not fully specified, making exact reproduction challenging.

## Next Checks
1. **Threshold Sensitivity Analysis**: Vary the perplexity (20-1000) and IFD (0.2-0.9) thresholds systematically and measure their impact on the final evaluation score to identify optimal values and potential overfitting to specific thresholds.
2. **Feature Representation Validation**: Test the k-center-greedy diversity selection with different feature representations (e.g., TF-IDF, sentence embeddings) to verify that the chosen representation captures meaningful instruction diversity rather than superficial differences.
3. **Multi-Model Consistency Check**: Implement the IFD-Vote filtering with multiple base models (not just Baichuan2-7B-Base) to test whether the disagreement-based filtering is robust across model architectures or specific to the chosen model.