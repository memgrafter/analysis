---
ver: rpa2
title: 'Advancing LLM detection in the ALTA 2024 Shared Task: Techniques and Analysis'
arxiv_id: '2412.19076'
source_url: https://arxiv.org/abs/2412.19076
tags:
- text
- sentences
- detection
- hybrid
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of detecting AI-generated text
  within hybrid documents containing both human-written and machine-generated sentences.
  The core method involves using sentence-level evaluation and fine-tuning a large
  language model (LLaMA 3.1-8B-Instruct) on domain-specific data to classify sentences
  as either human-written or machine-generated.
---

# Advancing LLM detection in the ALTA 2024 Shared Task: Techniques and Analysis

## Quick Facts
- arXiv ID: 2412.19076
- Source URL: https://arxiv.org/abs/2412.19076
- Authors: Dima Galat
- Reference count: 5
- Primary result: Achieved 0.932 Kappa Score and 0.9679 accuracy on ALTA 2024 test set using fine-tuned LLaMA model

## Executive Summary
This paper addresses the challenge of detecting AI-generated text within hybrid documents containing both human-written and machine-generated sentences. The approach involves fine-tuning a large language model (LLaMA 3.1-8B-Instruct) on domain-specific data to classify sentences at the sentence level. The model focuses on identifying distinct statistical patterns in probability distributions, particularly marginal probabilities of tokens, to distinguish between human and AI-generated content. The proposed method achieved significant performance improvements over baseline approaches in the ALTA 2024 Shared Task competition.

## Method Summary
The method involves sentence-level evaluation of probability distributions to detect AI-generated content. The approach extracts marginal probabilities of tokens from ChatGPT-3.5 Turbo outputs and uses these features to fine-tune LLaMA 3.1-8B-Instruct with QLORA using 4-bit quantization. The model is trained in batches of 16 for 3 epochs on a combination of academic and news articles. Classification is performed at the sentence level rather than document level to focus on local statistical patterns. The fine-tuned model learns to recognize distinctive probability distribution patterns that characterize AI-generated text.

## Key Results
- Achieved 0.932 Kappa Score and 0.9679 accuracy on the ALTA 2024 Shared Task test set
- Significantly outperformed baseline approaches using Naive Bayes with TF-IDF features
- Demonstrated robustness against minor textual modifications, with minimal impact on detection accuracy
- Fine-tuned LLaMA 3.1-8B-Instruct successfully distinguished ChatGPT-3.5 Turbo generated content based on sentence-level evaluation alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sentence-level probability distributions of LLM-generated text show distinctive patterns that enable detection
- Mechanism: LLMs like ChatGPT-3.5 Turbo favor high-probability tokens at each generation step, creating repetitive probability patterns across sentences. Human-written text shows higher entropy due to more varied word choices. These marginal probabilities can be used to identify distinct statistical patterns.
- Core assumption: The probability distribution patterns are consistent enough across different generations of the same LLM to be reliably detected
- Evidence anchors:
  - [abstract]: "ChatGPT-3.5 Turbo exhibits distinct, repetitive probability patterns that enable consistent in-domain detection"
  - [section 3]: "We believe that these marginal probabilities can be used to identify distinct statistical patterns in probability distributions"
  - [corpus]: Weak evidence - corpus shows related work on AI-generated text detection but lacks direct validation of this specific probability distribution claim

### Mechanism 2
- Claim: Fine-tuning LLaMA 3.1-8B-Instruct on domain-specific data creates a robust classifier for detecting ChatGPT-3.5 Turbo content
- Mechanism: The fine-tuned model learns to recognize subtle stylistic and statistical features specific to the target LLM's output within the given domain. Instruction tuning enables the model to generalize better to new tasks.
- Core assumption: The model can learn to distinguish between human and AI-generated content based on features extracted from sentence-level evaluation alone
- Evidence anchors:
  - [section 4]: "Overall, it would appear that a 4-bit quantized LLaMA 3.1-8B-Instruct fine-tuned on a domain-specific data can be used to recognize GPT-3.5 Turbo generated content reliably based on the sentence-level evaluation alone"
  - [section 3.2]: "Our best results are obtained when training in batches of 16 for 3 epochs. This model achieves 0.94 Kappa Score and 0.974 weighted F1 on our validation set"
  - [corpus]: Moderate evidence - multiple papers discuss fine-tuning approaches for AI detection, supporting the viability of this mechanism

### Mechanism 3
- Claim: Minor textual modifications have minimal impact on detection accuracy, suggesting the model captures deeper patterns than surface-level features
- Mechanism: The detection model relies more on the order and probability patterns of tokens rather than specific individual words, making it robust against simple paraphrasing attempts
- Core assumption: The statistical patterns in token sequences are more important than exact word choices for classification
- Evidence anchors:
  - [section 5]: "We have observed that AI-based sentence paraphrasing alone is inadequate to circumvent a classifier trained on in-domain samples"
  - [section 3.1]: "Empirical tests show that minor textual modifications, such as rewording, have minimal impact on detection accuracy"
  - [corpus]: Weak evidence - corpus doesn't provide direct support for this specific claim about paraphrasing robustness

## Foundational Learning

- Concept: Probability distributions in LLM generation
  - Why needed here: Understanding how LLMs predict tokens and create probability patterns is fundamental to grasping why detection is possible
  - Quick check question: What does P(token_i | context) represent in the context of LLM generation?

- Concept: Tokenization and TF-IDF feature extraction
  - Why needed here: The baseline model uses TF-IDF n-gram features, and understanding tokenization is crucial for working with text data
  - Quick check question: How does n-gram length affect the feature space in text classification?

- Concept: Fine-tuning vs zero-shot learning
  - Why needed here: The paper contrasts attempts at zero-shot classification with the successful fine-tuning approach
  - Quick check question: What are the key differences between fine-tuning and zero-shot approaches for adapting pre-trained models?

## Architecture Onboarding

- Component map: Sentence-level evaluation pipeline → Token probability extraction → Feature engineering (TF-IDF or direct probabilities) → Classification model (Naive Bayes baseline or fine-tuned LLaMA) → Evaluation metrics (Kappa Score, F1)
- Critical path: Data preparation → Baseline model development → Fine-tuning strategy selection → Model training → Evaluation on validation set → Competition submission
- Design tradeoffs: Sentence-level vs document-level classification (simplicity vs potential accuracy), Naive Bayes vs transformer-based models (speed vs performance), zero-shot vs fine-tuning (generalization vs specificity)
- Failure signatures: Poor performance on out-of-domain data, overfitting to training patterns, sensitivity to minor text modifications
- First 3 experiments:
  1. Implement sentence-level probability extraction from ChatGPT-3.5 Turbo outputs and analyze token distribution patterns
  2. Train and evaluate Naive Bayes classifier with TF-IDF features on the provided dataset using different data subsets
  3. Fine-tune LLaMA 3.1-8B-Instruct on the news domain data and compare performance against the baseline model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can this detection approach generalize effectively to other LLMs beyond GPT-3.5 Turbo?
- Basis in paper: [explicit] The authors note that different models produce different stylistic features, suggesting potential limitations when applying the same approach to other LLMs.
- Why unresolved: The paper only tested the model on GPT-3.5 Turbo-generated text, leaving open whether the same probability distribution patterns and detection methods would work for other models like GPT-4, Claude, or LLaMA.
- What evidence would resolve it: Systematic testing of the fine-tuned LLaMA model against sentence-level outputs from multiple different LLMs, measuring detection accuracy across various models.

### Open Question 2
- Question: How many iterations of AI-based paraphrasing would be required to defeat the classifier?
- Basis in paper: [inferred] The authors tested one round of paraphrasing and found minimal impact on detection accuracy, but didn't explore multiple iterations of AI rewriting.
- Why unresolved: The study only examined the effect of a single paraphrasing step using LLaMA 3.1-8B-Instruct. The cumulative effect of multiple AI editing passes on detection reliability remains unknown.
- What evidence would resolve it: Testing detection accuracy after 2, 3, 4+ rounds of AI-based paraphrasing on the same sentences, tracking how detection performance degrades with each iteration.

### Open Question 3
- Question: Does the detection model maintain effectiveness on out-of-domain text?
- Basis in paper: [explicit] The authors state that future work could explore how this approach generalizes out-of-domain, indicating this was not tested in the current study.
- Why unresolved: The model was fine-tuned specifically on news and academic articles from the ALTA 2024 dataset. The authors acknowledge uncertainty about performance on different text domains like fiction, technical documentation, or social media.
- What evidence would resolve it: Evaluating the model's detection accuracy on sentences from completely different domains than the training data, such as creative writing, code documentation, or informal social media posts.

## Limitations
- Limited to single domain (news articles) and single LLM (ChatGPT-3.5 Turbo), raising questions about generalizability
- Fine-tuning approach creates a specialized detector rather than a universal AI detector
- Performance on out-of-domain text and different LLM architectures remains untested

## Confidence

*High Confidence Claims:*
- The fine-tuned LLaMA model achieves superior performance (0.932 Kappa Score, 0.9679 accuracy) on the ALTA 2024 test set compared to baseline approaches
- Minor textual modifications (rewording) have minimal impact on detection accuracy, suggesting the model captures deeper statistical patterns
- Sentence-level evaluation using marginal token probabilities is an effective approach for distinguishing AI-generated from human-written content

*Medium Confidence Claims:*
- The proposed approach generalizes to other hybrid documents within the news domain
- The model's robustness against paraphrasing extends to more sophisticated rewriting techniques
- The specific hyperparameters (batch size 16, 3 epochs) represent optimal training configuration

*Low Confidence Claims:*
- The model would perform similarly well on academic articles, given that it was trained primarily on news domain data
- The approach would maintain effectiveness against future generations of LLMs with different generation strategies
- The probability distribution patterns are universally consistent across different instances of the same LLM model

## Next Checks

1. **Cross-domain evaluation**: Test the fine-tuned model on academic articles and other document types not included in the training data to assess domain transfer capabilities and identify performance degradation patterns.

2. **Model robustness testing**: Evaluate the classifier's performance against AI-generated text from different LLMs (GPT-4, Claude, LLaMA variants) and assess whether the probability distribution patterns remain distinctive enough for detection.

3. **Temporal stability assessment**: Retrain the detection model using AI-generated text from ChatGPT-3.5 Turbo at different time points to determine whether probability distribution patterns remain stable over time or if the model requires periodic retraining.