---
ver: rpa2
title: A Novel ICD Coding Method Based on Associated and Hierarchical Code Description
  Distillation
arxiv_id: '2404.11132'
source_url: https://arxiv.org/abs/2404.11132
tags:
- code
- medical
- codes
- description
- coding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to improve ICD code assignment by
  leveraging associated and hierarchical code descriptions. The core idea is to use
  these descriptions to distill noisy medical notes, focusing attention on relevant
  words and avoiding improper code assignments.
---

# A Novel ICD Coding Method Based on Associated and Hierarchical Code Description Distillation

## Quick Facts
- arXiv ID: 2404.11132
- Source URL: https://arxiv.org/abs/2404.11132
- Reference count: 26
- Primary result: AHDD outperforms state-of-the-art baselines on MIMIC-III for ICD code assignment across AUC, F1 score, and Precision@K metrics

## Executive Summary
This paper introduces AHDD (Associated and Hierarchical Description Distillation), a novel ICD coding method that leverages code descriptions and hierarchical relationships to improve medical note classification. The approach uses code descriptions to distill noisy medical notes, focusing attention on relevant clinical terms and preventing improper code assignments through sibling code dissimilarity. Experiments on the MIMIC-III dataset demonstrate significant performance improvements over existing methods.

## Method Summary
The method is encoder-agnostic and employs code description aware attention and output layers. It uses associated code descriptions to identify key clinical terms in noisy medical notes and hierarchical code descriptions to prevent simultaneous assignment of sibling codes. The framework applies binary cross-entropy loss with additional distillation terms to incorporate code description information during training.

## Key Results
- AHDD achieves higher AUC and F1 scores than state-of-the-art baselines on MIMIC-III
- The method shows consistent improvements across both common and rare ICD codes
- Precision@K results demonstrate better top-K code retrieval accuracy
- Ablation studies confirm the effectiveness of both associated and hierarchical distillation components

## Why This Works (Mechanism)

### Mechanism 1
Using associated and hierarchical code descriptions distills noisy medical notes by aligning attention to key clinical terms. Code descriptions are encoded and used to guide attention weights in the document encoder, forcing the model to focus on medically relevant words and suppress irrelevant noise. This works because medical notes contain only ~10% relevant words for ICD coding, and associated and hierarchical descriptions can reliably identify those key terms. Break condition: If code descriptions are missing, incomplete, or too generic to differentiate sibling codes, distillation loses discriminative power.

### Mechanism 2
Sibling code description distillation prevents improper code assignments by encouraging dissimilarity between sibling and target label representations. A similarity loss encourages the document representation for a target code to be dissimilar to the representations of its sibling codes, discouraging simultaneous assignment of clinically similar but mutually exclusive codes. This works because sibling codes in the ICD hierarchy are rarely assigned together in practice. Break condition: If sibling codes are genuinely co-occurring in practice, forcing dissimilarity degrades accuracy.

### Mechanism 3
Code description aware attention and output layers improve rare code prediction by leveraging code descriptions instead of learning all parameters from scratch. Code descriptions are encoded and projected via learned linear layers to replace some attention and output parameters, reducing data sparsity issues for rare codes. This works because code descriptions provide useful prior information that can be transferred to attention and output representations, especially when training data is scarce. Break condition: If code descriptions are too short or uninformative, the learned projections may add noise instead of useful bias.

## Foundational Learning

- **Multi-label text classification with noisy input**: ICD coding assigns multiple labels (codes) to each medical note, and notes are noisy (only ~10% of words are relevant). Quick check: Why is it problematic to train on all words in a medical note for ICD coding?

- **Hierarchical label structure**: ICD codes form a tree where sibling codes are mutually exclusive; modeling this prevents improper code assignments. Quick check: What clinical issue arises if a model assigns all sibling codes of a parent to a patient?

- **Attention-based representation learning**: Not all words in a medical note are equally relevant; attention weights refine representations based on code descriptions. Quick check: How does attention help the model focus on key clinical terms rather than noise?

## Architecture Onboarding

- **Component map**: Encoder Layer → Code Description Aware Attention → Associated Code Description Distillation → Hierarchical Code Description Distillation → Code Description Aware Output → Classification Loss

- **Critical path**: Encoder → Attention (with code descriptions) → Distillation (associated + hierarchical) → Output (with code descriptions) → Loss

- **Design tradeoffs**: Encoder-agnostic allows swapping CNN/RNN/Transformer but requires compatible hidden size; no extra text processing relies entirely on code descriptions limiting handling of abbreviations or slang; distillation losses add regularization but increase training complexity and risk overfitting to code description patterns.

- **Failure signatures**: High variance in rare code F1 (distillation may overfit to description patterns); poor precision on sibling code pairs (hierarchical distillation may be too aggressive); attention weights concentrated on boilerplate (code descriptions may not be discriminative enough).

- **First 3 experiments**: 1) Ablation: remove associated code description distillation; measure drop in micro F1. 2) Ablation: remove hierarchical code description distillation; measure change in sibling code precision. 3) Swap encoder (e.g., CNN → Transformer); verify that performance is maintained.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of AHDD compare when using different neural encoders (e.g., CNN, RNN, Transformer) in the Backbone Encoder? The paper states that the method is encoder-agnostic and theoretically can be implemented using any type of neural encoder, but does not provide experimental results comparing different encoder types. Conducting experiments using various neural encoders with AHDD and comparing their performance metrics on the MIMIC-III dataset would resolve this.

### Open Question 2
What is the impact of varying the hyperparameters λsim and λdis (the weights for the similarity and dissimilarity losses) on the performance of AHDD? The paper mentions these hyperparameters in the loss function but does not explore their sensitivity or optimal values. Performing a grid search to find optimal values and analyzing how different values affect the model's performance would resolve this.

### Open Question 3
How does AHDD perform on ICD coding tasks for other medical coding systems (e.g., ICD-10, SNOMED CT) compared to its performance on ICD-9? The paper focuses on ICD-9 coding using the MIMIC-III dataset, but ICD-10 is more widely used and complex. Applying AHDD to datasets with ICD-10 or SNOMED CT codes and comparing performance metrics would resolve this.

### Open Question 4
What is the computational overhead introduced by the AHDD method compared to baseline models, and how does it scale with dataset size? The paper mentions that AHDD neither needs extra text processing nor brings in too many parameters, but does not provide detailed computational analysis. Conducting experiments to measure training and inference times on varying dataset sizes would resolve this.

### Open Question 5
How does AHDD handle cases where a medical note is relevant to multiple sibling codes under the same parent code? The paper discusses avoiding improper code assignments but does not address scenarios with multiple relevant sibling codes. Analyzing model predictions on medical notes associated with multiple sibling codes would resolve this.

## Limitations
- The hierarchical distillation mechanism's effectiveness is based on clinical intuition rather than direct corpus evidence showing sibling codes are rarely co-assigned
- The encoder-agnostic approach lacks specific implementation details that could affect reproducibility
- Reliance on code descriptions as the sole external knowledge source may struggle with abbreviations, slang, or missing descriptions

## Confidence

**High Confidence**: The overall framework design is well-supported by experimental results showing consistent improvements across multiple metrics on MIMIC-III.

**Medium Confidence**: The mechanism for associated code description distillation improving rare code prediction is supported by ablation results, but specific implementation details are underspecified.

**Low Confidence**: The hierarchical distillation mechanism's effectiveness in preventing improper sibling code assignments is inferred from clinical coding practice rather than directly demonstrated through analysis.

## Next Checks

1. **Sibling Code Assignment Analysis**: Analyze the test set to identify specific instances where the model assigned multiple sibling codes that are rarely co-assigned in practice. Compare predictions with and without hierarchical distillation to verify it prevents these improper assignments.

2. **Rare Code Performance Breakdown**: Examine the performance gap between the full method and ablations specifically for codes with fewer than 100 training examples. This would validate whether code description aware output layers actually help rare codes.

3. **Attention Visualization Verification**: Generate attention weight visualizations for a diverse set of medical notes (common conditions, rare conditions, noisy notes) to verify that attention is indeed focusing on clinically relevant terms as claimed, and that code descriptions are effectively guiding this process.