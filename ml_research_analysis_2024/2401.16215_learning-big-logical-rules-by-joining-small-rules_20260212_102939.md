---
ver: rpa2
title: Learning big logical rules by joining small rules
arxiv_id: '2401.16215'
source_url: https://arxiv.org/abs/2401.16215
tags:
- programs
- joiner
- rules
- solution
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of learning large logical rules
  in inductive logic programming (ILP). The core method idea is to decompose the learning
  task into smaller subtasks by joining small rules to learn big rules.
---

# Learning big logical rules by joining small rules

## Quick Facts
- arXiv ID: 2401.16215
- Source URL: https://arxiv.org/abs/2401.16215
- Authors: Céline Hocquette; Andreas Niskanen; Rolf Morel; Matti Järvisalo; Andrew Cropper
- Reference count: 19
- Primary result: Learning rules with over 100 literals by joining small rules

## Executive Summary
This paper addresses the challenge of learning large logical rules in inductive logic programming (ILP) by introducing a novel approach that decomposes the learning task into smaller subtasks. Instead of directly searching for large rules, the method first finds small rules and then joins them to form big rules. The authors implement this approach in a system called JOINER, which uses constraint solvers to efficiently join rules. Experiments across various domains demonstrate that JOINER can learn rules with over 100 literals and significantly outperform existing approaches in predictive accuracy, achieving 100% accuracy on several tasks where other methods struggled.

## Method Summary
The core method involves decomposing the learning of large logical rules into two stages: a generate stage that finds small non-splittable programs using constraint satisfaction problems, and a join stage that uses SAT solving to find conjunctions of these small programs that entail positive examples while avoiding negative ones. The approach eliminates splittable programs from the generate stage since they can be efficiently constructed in the join stage. By iteratively increasing the size of rule conjunctions, the system can build large rules that would be computationally infeasible to learn directly. The method leverages existing ILP systems (Aleph, Metagol, and Popper) as baselines for comparison.

## Key Results
- JOINER can learn rules with more than 100 literals across multiple domains
- Achieved 100% accuracy on several tasks where other approaches struggled
- Significantly outperformed existing ILP approaches in predictive accuracy
- Demonstrated scalability improvements through decomposition-based learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing large rule learning into smaller sub-tasks improves scalability.
- Mechanism: Instead of directly searching for large rules (exponential complexity), the system first finds small rules, then joins them to form large rules. This decomposition reduces the search space because the complexity of finding small rules is lower than finding large ones.
- Core assumption: The logical consequences of a conjunction of small rules can be equivalent to a large rule (Lemma 2).
- Evidence anchors:
  - [abstract] "we introduce an approach where we join small rules to learn big rules."
  - [section 4.3] "The idea is to first find small rules where each rule entails some positive and some negative examples. We then search for conjunctions of these small rules such that each conjunction entails at least one positive example but no negative examples."
  - [corpus] Weak; corpus papers focus on different aspects of rule learning, not decomposition-based scalability.
- Break condition: If the logical consequences of small rules cannot be composed to form a large rule equivalent to the target, the decomposition fails.

### Mechanism 2
- Claim: Eliminating splittable programs in the generate stage improves learning performance.
- Mechanism: The system uses a constraint to prevent the CSP solver from considering models with splittable programs. Splittable programs can be built in the join stage, so eliminating them from the generate stage reduces the number of programs the solver must consider.
- Core assumption: Splittable programs can be efficiently constructed in the join stage.
- Evidence anchors:
  - [section 4.2] "We use a constraint to prevent the CSP solver from considering models with splittable programs."
  - [section 4.2] "Eliminating splittable programs can substantially improve learning performance."
  - [corpus] Weak; corpus papers do not discuss splittable program elimination.
- Break condition: If the join stage cannot efficiently construct splittable programs, eliminating them from the generate stage degrades performance.

### Mechanism 3
- Claim: The join stage can learn rules with over 100 literals.
- Mechanism: The system uses a SAT-based approach to find conjunctions of small programs that entail some positive examples and no negative examples. By iteratively increasing the size of conjunctions, the system can build large rules that would be infeasible to learn directly.
- Core assumption: The SAT solver can efficiently find conjunctions of small programs that meet the coverage criteria.
- Evidence anchors:
  - [abstract] "Our experiments on many domains, including game playing and drug design, show that our approach can (i) learn rules with more than 100 literals."
  - [section 4.3] "To find conjunctions, we use a Boolean satisfiability (SAT) approach."
  - [corpus] Weak; corpus papers do not discuss SAT-based rule joining.
- Break condition: If the SAT solver cannot efficiently find conjunctions for large rules, the join stage fails to learn big rules.

## Foundational Learning

- Concept: Inductive Logic Programming (ILP)
  - Why needed here: The paper's approach is based on ILP, which is a form of machine learning that can learn explainable rules from a small number of examples.
  - Quick check question: What is the main difference between ILP and other forms of machine learning?

- Concept: Constraint Satisfaction Problems (CSPs)
  - Why needed here: The system uses a CSP to represent the hypothesis space and a SAT solver to find conjunctions of small programs.
  - Quick check question: How does a CSP differ from a SAT problem?

- Concept: Boolean Satisfiability (SAT) solving
  - Why needed here: The system uses a SAT solver to find conjunctions of small programs that meet the coverage criteria.
  - Quick check question: What is the main difference between a SAT problem and a CSP?

## Architecture Onboarding

- Component map: Generate -> Test -> Join -> Combine -> Constrain (loop until solution found)
- Critical path: Generate -> Test -> Join -> Combine -> Constrain (loop until solution found)
- Design tradeoffs:
  - Decomposing large rules into small ones improves scalability but may miss some optimal solutions
  - Eliminating splittable programs reduces the search space but relies on the join stage to construct them
  - Using a SAT solver for the join stage enables learning large rules but may be computationally expensive
- Failure signatures:
  - If the SAT solver cannot find conjunctions for large rules, the join stage fails
  - If the CSP cannot find small, non-splittable programs, the generate stage fails
  - If the constraints prune optimal solutions, the constrain stage fails
- First 3 experiments:
  1. Run the system on a simple Zendo task to verify it can learn small rules
  2. Run the system on a task requiring a splittable rule to verify the join stage works
  3. Run the system on a task requiring a large rule (e.g., 100+ literals) to verify scalability

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How can the join stage be generalized to handle split rules that share body-only variables?
- Basis in paper: [inferred] The paper mentions that the join stage currently builds splittable rules where the body is split into subsets that do not share body-only variables. However, it suggests that future work should generalize the approach to handle rules that may share body-only variables.
- Why unresolved: The paper does not provide a concrete method for generalizing the join stage to handle rules with shared body-only variables. It only mentions this as a potential direction for future research.
- What evidence would resolve it: A concrete algorithm or approach that demonstrates how to generalize the join stage to handle split rules with shared body-only variables, along with experimental results showing its effectiveness compared to the current method.

### Open Question 2
- Question: How can the approach be extended to handle noisy examples?
- Basis in paper: [explicit] The paper mentions that the current approach does not support noisy examples and suggests combining it with an approach based on the minimal description length principle to handle noisy data.
- Why unresolved: The paper does not provide a specific method for extending the approach to handle noisy examples. It only mentions this as a potential direction for future research.
- What evidence would resolve it: A concrete algorithm or approach that demonstrates how to extend the current method to handle noisy examples, along with experimental results showing its effectiveness compared to the current method.

### Open Question 3
- Question: How does the join stage perform on even larger rules with more than 100 literals?
- Basis in paper: [explicit] The paper demonstrates that the join stage can learn rules with more than 100 literals, but it does not explore the scalability of the approach for even larger rules.
- Why unresolved: The paper does not provide experimental results or analysis of the performance of the join stage on rules with more than 100 literals.
- What evidence would resolve it: Experimental results showing the performance of the join stage on rules with more than 100 literals, including learning time, predictive accuracy, and scalability analysis.

### Open Question 4
- Question: How does the elimination of splittable programs in the generate stage affect the overall learning performance?
- Basis in paper: [explicit] The paper mentions that eliminating splittable programs in the generate stage can improve learning performance, but it does not provide a detailed analysis of the impact of this optimization on the overall learning performance.
- Why unresolved: The paper does not provide a comprehensive analysis of the trade-offs between the elimination of splittable programs and the overall learning performance, such as the impact on learning time, predictive accuracy, or the ability to learn certain types of rules.
- What evidence would resolve it: A detailed analysis of the impact of eliminating splittable programs on the overall learning performance, including comparisons of learning time, predictive accuracy, and the ability to learn different types of rules with and without this optimization.

## Limitations
- The approach relies heavily on the assumption that small rules can be efficiently joined to form large, accurate rules
- The SAT-based joining mechanism may struggle with certain types of rule spaces or domains where small rules have limited overlap
- The paper doesn't address computational complexity bounds for the joining stage, leaving questions about scalability to truly massive rule spaces

## Confidence
- Learning rules with >100 literals (Medium): Supported by experimental results but limited to specific domains
- Predictive accuracy improvements (High): Well-demonstrated across multiple benchmarks
- Decomposition-based scalability (Medium): Mechanistically sound but lacks theoretical guarantees

## Next Checks
1. Test JOINER on domains where small rules have minimal overlap to assess joining limitations
2. Compare computational complexity of direct large-rule learning versus decomposition approach across varying problem sizes
3. Evaluate performance on tasks requiring rules with specific structural constraints that may resist decomposition