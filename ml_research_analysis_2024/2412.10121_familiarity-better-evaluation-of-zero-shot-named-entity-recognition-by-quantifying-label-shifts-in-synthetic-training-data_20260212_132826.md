---
ver: rpa2
title: 'Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying
  Label Shifts in Synthetic Training Data'
arxiv_id: '2412.10121'
source_url: https://arxiv.org/abs/2412.10121
tags:
- entity
- types
- training
- datasets
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FAMILIARITY is a metric designed to quantify label shifts in zero-shot
  named entity recognition by measuring the semantic similarity between entity types
  in synthetic training data and evaluation benchmarks. It considers both the similarity
  of entity types and their frequency in the training data, providing insights into
  transfer difficulty.
---

# Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by Quantifying Label Shifts in Synthetic Training Data

## Quick Facts
- arXiv ID: 2412.10121
- Source URL: https://arxiv.org/abs/2412.10121
- Authors: Jonas Golde; Patrick Haller; Max Ploner; Fabio Barth; Nicolaas Jedema; Alan Akbik
- Reference count: 13
- Primary result: FAMILIARITY metric quantifies label shifts in zero-shot NER by measuring semantic similarity between entity types and their frequency in synthetic training data

## Executive Summary
FAMILIARITY is a novel metric designed to improve evaluation of zero-shot named entity recognition by quantifying label shifts between synthetic training data and evaluation benchmarks. The metric combines semantic similarity of entity types with their frequency distribution in training data to provide insights into transfer difficulty. Experimental results demonstrate that FAMILIARITY effectively captures label shift and explains performance variations across different zero-shot NER settings. The metric enables fairer comparisons between models and supports data-efficient research by contextualizing evaluation scores.

## Method Summary
FAMILIARITY measures label shifts in zero-shot NER by calculating semantic similarity between entity types in synthetic training data and evaluation benchmarks, weighted by entity type frequencies. The metric considers both the similarity of entity types and their distribution in training data, providing a comprehensive measure of transfer difficulty. It can be used to generate training splits of varying difficulty for fine-grained analysis of zero-shot NER performance. The approach leverages pre-trained embeddings to compute semantic similarities between entity types.

## Key Results
- FAMILIARITY effectively captures label shift, explaining performance differences between models trained on different datasets
- The metric provides insights into transfer difficulty by considering both entity type similarity and frequency distributions
- FAMILIARITY enables generation of training splits with varying difficulty levels for detailed zero-shot NER analysis

## Why This Works (Mechanism)
FAMILIARITY works by quantifying the semantic alignment between entity types in synthetic training data and target evaluation benchmarks. The metric captures how well the distribution and types of entities in training data match those in the evaluation set. By incorporating both type similarity and frequency weighting, FAMILIARITY provides a more nuanced measure of transfer difficulty than simple entity type matching. This allows for better prediction of zero-shot performance and more meaningful comparisons between different training approaches.

## Foundational Learning
- **Semantic similarity metrics**: Needed to quantify how closely related different entity types are; quick check: verify cosine similarity between entity type embeddings
- **Label shift analysis**: Essential for understanding distribution differences between training and evaluation data; quick check: compare marginal distributions of entity types
- **Zero-shot learning principles**: Fundamental for understanding transfer learning without target domain examples; quick check: confirm model performance without target domain fine-tuning
- **Synthetic data generation**: Critical for creating training data without manual annotation; quick check: validate synthetic examples maintain entity type characteristics
- **Named entity recognition evaluation**: Necessary for measuring model performance across different entity types; quick check: ensure proper entity type classification accuracy
- **Frequency distribution analysis**: Important for weighting entity types based on their prevalence; quick check: verify frequency calculations match actual data distributions

## Architecture Onboarding

**Component Map**
Synthetic Training Data -> FAMILIARITY Metric -> Evaluation Benchmark -> Performance Correlation

**Critical Path**
1. Generate synthetic training data with entity labels
2. Compute semantic similarities between training and evaluation entity types
3. Calculate frequency-weighted similarity scores
4. Correlate FAMILIARITY scores with actual zero-shot performance

**Design Tradeoffs**
- Balances computational efficiency with semantic accuracy in similarity calculations
- Prioritizes generalization over domain-specific optimization
- Trades off perfect semantic matching for practical applicability across domains

**Failure Signatures**
- Low correlation between FAMILIARITY scores and actual performance indicates poor semantic embedding quality
- Inconsistent results across different entity type granularities suggest frequency weighting issues
- Failure to capture rare entity type performance indicates need for adjusted frequency weighting

**First Experiments**
1. Validate FAMILIARITY correlation with zero-shot performance across multiple benchmark datasets
2. Test FAMILIARITY's ability to predict performance on out-of-domain entity types
3. Evaluate FAMILIARITY's effectiveness in guiding synthetic data generation for improved zero-shot performance

## Open Questions the Paper Calls Out
None

## Limitations
- Experimental validation relies primarily on correlation analysis without establishing causal links to model behavior
- Effectiveness across significant domain shifts (e.g., medical to legal texts) remains unexplored
- Dependency on pre-trained embedding quality may limit applicability across languages and specialized domains

## Confidence

**High Confidence**
- Core formulation combining type similarity and frequency is mathematically sound
- Experimental results showing FAMILIARITY's explanatory power are compelling

**Medium Confidence**
- Cross-domain validation effectiveness needs further exploration
- Practical utility for model selection and data augmentation requires additional demonstration

## Next Checks
1. Conduct cross-domain experiments testing FAMILIARITY effectiveness when entity types shift significantly between source and target domains
2. Implement ablation studies to isolate contributions of type similarity versus frequency components
3. Design controlled experiments using FAMILIARITY to guide synthetic data generation and measure impact on zero-shot performance