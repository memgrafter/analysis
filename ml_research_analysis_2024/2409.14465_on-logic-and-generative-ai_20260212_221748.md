---
ver: rpa2
title: On logic and generative AI
arxiv_id: '2409.14465'
source_url: https://arxiv.org/abs/2409.14465
tags:
- logic
- thinking
- they
- fast
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This dialogue explores foundational questions in logic raised by
  the ongoing AI revolution. The authors discuss how generative AI relies primarily
  on fast thinking (System 1) rather than slow, deliberate reasoning (System 2), and
  examine challenges like real-world understanding and Moravec's paradox.
---

# On logic and generative AI

## Quick Facts
- arXiv ID: 2409.14465
- Source URL: https://arxiv.org/abs/2409.14465
- Reference count: 19
- Primary result: Generative AI relies primarily on fast thinking (System 1) rather than slow, deliberate reasoning (System 2), raising new questions for the field of logic

## Executive Summary
This dialogue explores foundational questions in logic raised by the ongoing AI revolution. The authors discuss how generative AI relies primarily on fast thinking (System 1) rather than slow, deliberate reasoning (System 2), and examine challenges like real-world understanding and Moravec's paradox. They argue that while early AI was dominated by logic-based approaches, deep learning has become the dominant paradigm. The authors suggest that studying "the logic of fast thinking" could help address AI's limitations, particularly in understanding physical reality and reasoning capabilities.

## Method Summary
This paper presents a theoretical dialogue exploring the relationship between logic and generative AI. Rather than presenting experimental results, the authors engage in a conversational format to examine how the AI revolution raises new questions for the field of logic. They draw on historical context, current AI capabilities, and philosophical considerations to propose that the logic community should study "the logic of fast thinking" as a way to address AI's limitations. The approach is conceptual rather than empirical, using thought experiments and analogies to make their case.

## Key Results
- Current LLMs operate primarily through System 1 (fast) thinking, generating one word at a time using probabilistic inference
- Logic-based AI approaches have been largely superseded by deep learning, despite AI's continued need for reasoning capabilities
- The authors propose that studying "the logic of fast thinking" could help address AI's limitations in understanding physical reality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generative AI primarily relies on fast thinking (System 1) rather than slow, deliberate reasoning (System 2)
- Mechanism: LLMs operate by generating one word at a time using probabilistic inference based on training data, without pausing to reason or deliberate
- Core assumption: The current architecture of LLMs cannot allocate different amounts of compute to different tokens, preventing System 2-like reasoning
- Evidence anchors:
  - "That mechanism works with a sequence of words... But the LLM cannot stop and think. In the AI parlance, 'it is allocating approximately the same amount of compute for each token it generates'"
  - FMR score 0.51-0.67 across 25 related papers suggests moderate relevance to reasoning mechanisms

### Mechanism 2
- Claim: Logic's role in AI has diminished despite AI's growing need for reasoning
- Mechanism: Deep learning approaches using neural networks have largely replaced logic-based AI approaches, even though AI systems still struggle with reasoning capabilities
- Core assumption: The success of deep learning created a paradigm shift away from logic-based approaches in AI development
- Evidence anchors:
  - "At the early stage of AI, the logic approach was dominating... But then an important competitor arose... This part of research based on deep learning and (artificial) neural networks is the one to which I am devoted here"
  - Papers focus on generative AI and LLMs rather than logic-based approaches, supporting the shift away from logic

### Mechanism 3
- Claim: Studying "the logic of fast thinking" could help address AI's limitations in understanding physical reality
- Mechanism: By understanding the rules and patterns of fast thinking, we can develop better AI systems that can make quick, accurate judgments about the physical world
- Core assumption: Fast thinking involves identifiable rules and patterns that can be formalized and studied
- Evidence anchors:
  - "Arguably logic should study the laws of thinking, including fast thinking, whatever they are. The intention, in the question about the logic of fast thinking, was to provoke young logicians with a taste for foundations to notice the nascent study of fast thinking"
  - Limited direct evidence; this represents a forward-looking proposal rather than established practice

## Foundational Learning

- Concept: System 1 vs System 2 thinking
  - Why needed here: Understanding the distinction is crucial for analyzing how current AI differs from human intelligence
  - Quick check question: Can you explain the key differences between fast thinking and slow thinking in one sentence?

- Concept: Moravec's paradox
  - Why needed here: Explains why AI excels at intellectual tasks but struggles with physical world understanding
  - Quick check question: Why does Moravec's paradox suggest that tasks easy for humans are often hard for AI?

- Concept: Foundational crises in mathematics
  - Why needed here: Provides historical context for how logic evolves during periods of foundational uncertainty
  - Quick check question: What was the foundational crisis in mathematics that led to the development of mathematical logic?

## Architecture Onboarding

- Component map: LLMs consist of two main components - a large data file from training and a succinct algorithm implementing the model architecture and probabilistic inference mechanism
- Critical path: Understanding the current limitations of AI reasoning, particularly the inability to engage in System 2 thinking, and exploring how logic might address these limitations
- Design tradeoffs: The paper highlights the tension between the success of deep learning approaches and the continued need for reasoning capabilities that logic-based approaches might provide
- Failure signatures: LLMs produce hallucinations, struggle with real-world understanding (as shown in the animal counting example), and cannot engage in deliberate reasoning
- First 3 experiments:
  1. Test an LLM's ability to handle real-world scenarios requiring physical understanding (similar to the animal counting example)
  2. Compare the performance of logic-based AI approaches versus deep learning approaches on reasoning tasks
  3. Explore the feasibility of implementing System 2-like reasoning capabilities in current LLM architectures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Will logic-based approaches regain prominence in AI development, or will deep learning remain the dominant paradigm?
- Basis in paper: The authors discuss how early AI was dominated by logic-based approaches but deep learning has become the dominant paradigm, raising questions about logic's future role.
- Why unresolved: The paper presents both perspectives - logic's historical importance and deep learning's current dominance - without definitively predicting which will prevail in future AI development.
- What evidence would resolve it: Future AI breakthroughs that significantly rely on logical reasoning frameworks versus continued advancements in deep learning approaches would indicate the direction.

### Open Question 2
- Question: Can the study of "the logic of fast thinking" (System 1) lead to meaningful improvements in AI's understanding of the physical world?
- Basis in paper: The authors suggest studying fast thinking's logic could help address AI's limitations, particularly in understanding physical reality and reasoning capabilities.
- Why unresolved: The paper identifies this as a potential research direction but does not demonstrate whether such logical frameworks for fast thinking can be developed or practically applied.
- What evidence would resolve it: Development of logical frameworks that successfully model fast thinking and their demonstrated impact on improving AI's real-world understanding would provide evidence.

### Open Question 3
- Question: Will the logic community effectively address the foundational challenges raised by AI, or will these challenges be addressed primarily by other disciplines?
- Basis in paper: The authors note that "much depends on how — and whether — the logic community will address the challenge" and draw parallels to how mathematical heroes worked on infinitesimal calculus without being recognized as logicians.
- Why unresolved: The paper highlights the importance of these challenges for logic but does not predict whether logicians will engage with them or if other disciplines will take the lead.
- What evidence would resolve it: Increased logical frameworks and publications addressing AI challenges versus continued AI advancement through other disciplines would indicate the answer.

## Limitations
- The paper presents theoretical arguments rather than empirical evidence, making claims difficult to verify
- The proposal to study "the logic of fast thinking" lacks concrete methodology or examples of what such a logic would look like
- The historical analogy between mathematical foundational crises and the current AI revolution may oversimplify the differences between these contexts

## Confidence

- Medium: The characterization of current LLMs as primarily engaging in System 1 thinking, supported by descriptions of their probabilistic inference mechanisms
- Medium: The observation that logic-based AI approaches have been largely superseded by deep learning, based on observable trends in AI research
- Low: The forward-looking proposal to study "the logic of fast thinking" as a solution to AI's limitations, which remains speculative without concrete methodology

## Next Checks

1. Test whether current LLM architectures can be modified to implement System 2-like reasoning through dynamic compute allocation
2. Examine specific examples of AI systems successfully applying logical reasoning to real-world problems, challenging the dichotomy between deep learning and logic-based approaches
3. Investigate whether the historical pattern of logic expanding during foundational crises applies to the current AI context through case studies of how logicians are responding to AI challenges