---
ver: rpa2
title: Investigating the Contextualised Word Embedding Dimensions Specified for Contextual
  and Temporal Semantic Changes
arxiv_id: '2407.02820'
source_url: https://arxiv.org/abs/2407.02820
tags:
- pre-trained
- axes
- fine-tuned
- scwe
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether specific dimensions in contextualised
  word embeddings (CWEs) are dedicated to encoding semantic changes of words. The
  authors compare pre-trained CWEs and fine-tuned sense-aware CWEs (SCWEs) on contextual
  and temporal semantic change detection (SCD) tasks using Principal Component Analysis
  (PCA) and Independent Component Analysis (ICA).
---

# Investigating the Contextualised Word Embedding Dimensions Specified for Contextual and Temporal Semantic Changes

## Quick Facts
- arXiv ID: 2407.02820
- Source URL: https://arxiv.org/abs/2407.02820
- Reference count: 31
- One-line primary result: PCA discovers contextual and temporal semantic change-aware axes within top 10% of dimensions, outperforming ICA and achieving comparable results to using all dimensions

## Executive Summary
This paper investigates whether specific dimensions in contextualised word embeddings (CWEs) are dedicated to encoding semantic changes of words. The authors compare pre-trained CWEs and fine-tuned sense-aware CWEs (SCWEs) on contextual and temporal semantic change detection tasks using Principal Component Analysis (PCA) and Independent Component Analysis (ICA). They find that contextual and temporal SCD-aware axes emerge during fine-tuning and are better discovered by PCA than ICA, even within the top 10% of axes. Specifically, for contextual SCD, PCA-transformed axes match or outperform using all dimensions, while ICA consistently underperforms. For temporal SCD, using only 10% of PCA-transformed axes achieves comparable performance to using all dimensions in both pre-trained and fine-tuned settings.

## Method Summary
The paper evaluates whether semantic change information is concentrated in specific dimensions or distributed across the embedding space. The method involves applying PCA and ICA transformations to pre-trained CWEs (XLM-RoBERTa) and fine-tuned SCWEs (XL-LEXEME), then selecting top-k% of axes based on variance (PCA) or independence (ICA). Semantic change scores are computed using Euclidean distances between word embeddings in sentence pairs, and performance is evaluated using AUC for contextual SCD and AUC plus Spearman correlation for temporal SCD. The analysis compares contextual semantic change detection (same time period, different meanings) and temporal semantic change detection (different time periods) across multiple languages and datasets.

## Key Results
- PCA discovers contextual and temporal semantic change-aware axes within top 10% of transformed axes better than ICA
- Fine-tuning on WiC causes semantic change information to distribute across all dimensions rather than concentrating in compact axes
- For contextual SCD, PCA-transformed axes match or outperform using all dimensions, while ICA consistently underperforms
- For temporal SCD, using only 10% of PCA-transformed axes achieves comparable performance to using all dimensions in both pre-trained and fine-tuned settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PCA can isolate contextual and temporal semantic change-aware dimensions within the top 10% of axes
- Mechanism: PCA orders axes by explained variance, so axes encoding semantic changes emerge in the highest-variance components during fine-tuning
- Core assumption: Semantic changes manifest as significant variance patterns in the embedding space
- Evidence anchors:
  - [abstract] "PCA discovers contextual/temporal semantic change-aware axes within the top 10% of the transformed axes better than ICA"
  - [section] "we see that the use of the top 5% to 20% axes transformed by PCA is more effective in temporal semantic change detection than when all of the Raw dimensions are used"
  - [corpus] Weak - corpus neighbors focus on general semantic embeddings, not dimension-specific analysis
- Break condition: If semantic changes are encoded as subtle, low-variance patterns rather than dominant variance directions

### Mechanism 2
- Claim: Fine-tuning on WiC causes semantic change information to distribute across all dimensions
- Mechanism: Pre-training creates compact axes for semantic changes, but fine-tuning spreads this information to enable better context-sensitive discrimination
- Core assumption: Fine-tuning optimization naturally distributes task-relevant information across the embedding space
- Evidence anchors:
  - [abstract] "although there exist a smaller number of axes that are specific to semantic changes of words in the pre-trained CWE space, this information gets distributed across all dimensions when fine-tuned"
  - [section] "axes encoding contextual semantic changes are not obvious in the original CWEs after pre-training... but materialise during the fine-tuning process"
  - [corpus] Missing - no corpus evidence about distribution patterns during fine-tuning
- Break condition: If fine-tuning preserves compact semantic change axes instead of distributing them

### Mechanism 3
- Claim: ICA underperforms PCA for semantic change detection because it captures concepts like topics rather than task-specific axes
- Mechanism: ICA finds statistically independent components (e.g., topics), but semantic change requires axes that capture task-specific relationships across contexts
- Core assumption: Semantic change detection requires axes that track meaning differences across contexts, not topic separation
- Evidence anchors:
  - [abstract] "in contrast to prior work studying the geometry of CWEs, we find that PCA to better represent semantic changes than ICA within the top 10% of axes"
  - [section] "ICA consistently underperforms" and "ICA shows contrasting results" in both contextual and temporal tasks
  - [corpus] Weak - corpus mentions ICA for topic-related axes (Yamagiwa et al., 2023) but not semantic change
- Break condition: If ICA could be tuned or constrained to capture task-specific semantic change relationships

## Foundational Learning

- Concept: Principal Component Analysis (PCA) and Independent Component Analysis (ICA)
  - Why needed here: These dimensionality reduction techniques are used to identify whether semantic change information is concentrated in specific dimensions or distributed across the embedding space
  - Quick check question: What is the fundamental difference between PCA (variance-based) and ICA (independence-based) approaches to dimensionality reduction?

- Concept: Contextualized Word Embeddings (CWEs) and Sense-Aware CWEs (SCWEs)
  - Why needed here: The paper compares pre-trained CWEs (XLM-RoBERTa) with fine-tuned SCWEs (XL-LEXEME) to understand how semantic change awareness emerges during fine-tuning
  - Quick check question: How does fine-tuning on Word-in-Context (WiC) datasets transform generic CWEs into sense-aware representations?

- Concept: Semantic Change Detection (SCD) tasks
  - Why needed here: The paper evaluates both contextual (same time period, different meanings) and temporal (different time periods) semantic change detection to understand dimension specialization
  - Quick check question: What distinguishes contextual semantic change detection from temporal semantic change detection in terms of the information required from embeddings?

## Architecture Onboarding

- Component map: Pre-trained CWE model (XLM-RoBERTa) → PCA/ICA transformation → Top-k dimension selection → Semantic change detection task (contextual/temporal) → Evaluation (AUC/ROC or Spearman correlation)
- Alternative path: Fine-tuned SCWE model (XL-LEXEME) → same downstream processing

- Critical path: 
  1. Load pre-trained CWEs or fine-tuned SCWEs
  2. Apply PCA or ICA transformation to embedding space
  3. Select top-k% of axes based on variance (PCA) or independence (ICA)
  4. Compute semantic change scores using selected dimensions
  5. Evaluate performance on benchmark datasets

- Design tradeoffs:
  - PCA vs ICA: PCA better for semantic change detection but may miss independent concept axes; ICA better for topic separation but worse for semantic change
  - Number of dimensions: Fewer dimensions (top 10%) provide efficiency but may lose some information; more dimensions improve accuracy but reduce efficiency
  - Fine-tuning impact: Fine-tuning distributes semantic change information but may reduce dimension compactness

- Failure signatures:
  - ICA consistently underperforming across tasks suggests task requires variance-based rather than independence-based decomposition
  - Performance drop when using top-k% vs all dimensions indicates semantic change information isn't concentrated in specific axes
  - Inconsistent results across languages/datasets may indicate data quality or pre-training differences

- First 3 experiments:
  1. Reproduce PCA vs ICA comparison on English WiC dataset using XLM-RoBERTa embeddings to verify contextual semantic change dimension emergence
  2. Test whether top-10% PCA dimensions on pre-trained CWEs can match full-dimension performance on temporal SCD task
  3. Compare PCA-transformed dimension performance across all languages in SemEval-2020 Task 1 to verify cross-linguistic consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do contextual and temporal semantic change-aware dimensions exist in other types of contextualised embeddings beyond XLM-RoBERTa-based models?
- Basis in paper: [inferred] The paper states "In this paper, we limited experiments to XLM-RoBERTa based MLM models" and acknowledges this as a limitation.
- Why unresolved: The paper only tested XLM-RoBERTa-based models and their fine-tuned versions on WiC datasets, leaving open whether these findings generalize to other architectures like BERT, RoBERTa, or GPT-based models.
- What evidence would resolve it: Systematic experiments testing PCA/ICA transformations on contextual embeddings from different architectures (BERT, RoBERTa, GPT variants) for both contextual and temporal SCD tasks.

### Open Question 2
- Question: How do social biases encoded in MLMs interact with the dimension selection methods for semantic change detection?
- Basis in paper: [explicit] The paper explicitly mentions "we also used publicly available pre-trained/fine-tuned MLMs, some of which are known to encode and potentially amplify unfair social biases" and notes this requires careful evaluation before deployment.
- Why unresolved: The paper acknowledges this as an ethical consideration but does not investigate whether PCA or ICA dimension selection amplifies, reduces, or has no effect on these social biases in the resulting low-dimensional representations.
- What evidence would resolve it: Analysis of bias measures (e.g., WEAT scores, counterfactual fairness tests) on both full-dimensional and dimension-reduced embeddings to determine if certain methods exacerbate or mitigate bias.

### Open Question 3
- Question: What is the relationship between topic-related axes discovered by ICA and task-specific semantic change-aware axes discovered by PCA?
- Basis in paper: [explicit] The paper notes "ICA is able to retrieve concepts such as topics" while PCA better discovers task-specific axes, and states "Further refinement of the approach remains as future research."
- Why unresolved: The paper observes that ICA captures topics while PCA captures semantic change dimensions, but does not investigate whether these are orthogonal, overlapping, or hierarchically related, or how they might be combined for improved performance.
- What evidence would resolve it: Experiments correlating topic models (e.g., LDA) with ICA/ICA axes and semantic change scores with PCA axes to determine their relationship, plus hybrid methods combining both approaches.

## Limitations

- The study focuses exclusively on linear dimensionality reduction techniques (PCA and ICA), potentially missing non-linear relationships in the embedding space
- Findings are based primarily on English datasets and limited multilingual coverage, raising questions about cross-linguistic generalization
- The causal mechanism explaining why fine-tuning distributes semantic change information across dimensions lacks direct empirical evidence

## Confidence

**High Confidence**: The finding that PCA outperforms ICA for contextual and temporal semantic change detection within the top 10% of axes is well-supported by experimental results across multiple datasets and languages. The mechanism that PCA captures variance patterns relevant to semantic change while ICA captures topic-like independent components is logically consistent.

**Medium Confidence**: The claim that fine-tuning causes semantic change information to distribute across all dimensions is supported by the observed performance improvements, but the underlying mechanism (why fine-tuning spreads information) lacks direct empirical evidence. The causal relationship between fine-tuning and dimension distribution needs further investigation.

**Low Confidence**: The assertion that semantic change manifests as significant variance patterns that PCA can capture assumes that all relevant semantic changes create detectable variance. This may not hold for subtle semantic shifts or cases where semantic change occurs through distributional shifts that don't create large variance differences.

## Next Checks

1. **Cross-Domain Consistency Test**: Apply the same PCA/ICA analysis to CWEs fine-tuned on different NLP tasks (e.g., sentiment analysis, named entity recognition, question answering) to determine whether dimension distribution patterns are specific to WiC fine-tuning or generalize across fine-tuning objectives.

2. **Non-Linear Dimensionality Reduction Comparison**: Implement and compare t-SNE and UMAP dimensionality reduction on the same CWE and SCWE datasets to test whether non-linear methods can capture semantic change information more effectively than PCA, particularly for subtle semantic shifts that may not create dominant variance patterns.

3. **Temporal Change Detection Granularity Analysis**: Design experiments to test whether the top 10% PCA dimensions are equally effective for detecting different types of temporal semantic changes (e.g., gradual vs. rapid changes, semantic broadening vs. narrowing) by analyzing performance across different time scales and types of semantic shifts in historical corpora.