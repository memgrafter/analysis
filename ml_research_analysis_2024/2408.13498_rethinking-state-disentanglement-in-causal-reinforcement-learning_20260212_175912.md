---
ver: rpa2
title: Rethinking State Disentanglement in Causal Reinforcement Learning
arxiv_id: '2408.13498'
source_url: https://arxiv.org/abs/2408.13498
tags:
- state
- noise
- belief
- latent
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work re-examines the identifiability of latent states in reinforcement
  learning under noisy observations. Previous causal approaches often impose independence
  assumptions on latent state subsets and invertible observation functions, which
  may not hold in RL.
---

# Rethinking State Disentanglement in Causal Reinforcement Learning

## Quick Facts
- arXiv ID: 2408.13498
- Source URL: https://arxiv.org/abs/2408.13498
- Authors: Haiyao Cao; Zhen Zhang; Panpan Cai; Yuhang Liu; Jinan Zou; Ehsan Abbasnejad; Biwei Huang; Mingming Gong; Anton van den Hengel; Javen Qinfeng Shi
- Reference count: 14
- Primary result: Outperforms DreamerV3, TIA, DenoisedMDP, and IFactor on noisy DeepMind Control Suite tasks with mean returns up to 615 (Finger Spin) vs ~566 for IFactor

## Executive Summary
This work re-examines the identifiability of latent states in reinforcement learning under noisy observations. Previous causal approaches often impose independence assumptions on latent state subsets and invertible observation functions, which may not hold in RL. By incorporating RL-specific context—namely, the role of rewards and transitions—the authors show these assumptions can be relaxed. Their main theoretical contributions are two propositions: one for POMDPs with invertible observation functions and another for general POMDPs using conditional independence of noise and future state given current state. Based on these insights, the authors propose a world model with separate state and noise belief components, using asymmetric reconstructions and KL divergence regularization. Empirically, their method outperforms strong baselines on noisy DeepMind Control Suite tasks, demonstrating superior disentanglement and policy performance.

## Method Summary
The method builds on Recurrent State Space Models (RSSM) by separating the latent belief into distinct state and noise components. The model encodes observations into separate state and noise posteriors, transitions them forward using learned dynamics, and reconstructs observations through asymmetric decoders (deeper for state, shallower for noise). Training uses Maximum Likelihood Estimation with KL divergence regularization to encourage independence between state and noise beliefs. The model optimizes both transition and reward preservation, arguing these RL-specific objectives are sufficient for identifying useful state representations without requiring strict independence assumptions on latent state subsets.

## Key Results
- Achieves mean returns of 615 on Finger Spin task with diverse video backgrounds
- Outperforms DreamerV3 (567), TIA (566), DenoisedMDP (540), and IFactor (566) on same task
- Shows superior disentanglement with cleaner state reconstructions and more independent noise components
- Maintains performance gains across multiple DeepMind Control Suite tasks with added noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating RL-specific context (rewards and transitions) allows relaxing independence assumptions on latent state subsets.
- Mechanism: In RL, the goal is to optimize returns, which depend on both state transitions and rewards. If an alternative state representation preserves these two aspects, it is equivalent to the true state for policy optimization, even without splitting states into independent subsets.
- Core assumption: The underlying state representation is compact (no redundancy) and any equivalent representation must preserve transition and reward structure.
- Evidence anchors:
  - [abstract]: "incorporating RL-specific context can reduce unnecessary assumptions in previous identifiability analyses for latent states"
  - [section 3]: "rewards and transitions sufficiently contribute to the recovery of latent states"
  - [corpus]: No direct evidence; corpus neighbors focus on causal disentanglement without RL context.
- Break condition: If the underlying state has redundancy or if preserving transitions/rewards alone is insufficient for optimal policy performance.

### Mechanism 2
- Claim: For general POMDPs, the noise belief can be conditionally independent of future state belief given current state belief.
- Mechanism: By converting POMDP to belief-MDP, the observation function becomes invertible. The noise belief, conditioned on the current state belief, does not affect future state beliefs, allowing disentanglement without requiring independent noise-state relationships in the raw observation space.
- Core assumption: The belief representation accurately captures the conditional dependencies between state and noise.
- Evidence anchors:
  - [section 3]: "the latent states can be viewed as a group of variables that can fully determine the reward and changes independently"
  - [section 4]: "as bt(zt|st) is conditional independent of future state belief bt+1(st+1) given current state belief bt(st)"
  - [corpus]: No direct evidence; corpus neighbors do not address belief-MDP conversions.
- Break condition: If the conditional independence assumption between noise and future state belief fails in practice.

### Mechanism 3
- Claim: Asymmetric reconstructions between state and noise beliefs reduce confusion and improve disentanglement.
- Mechanism: Using different decoder architectures for state and noise beliefs (e.g., deeper for state, shallower for noise) aligns with their different complexities—state is more structured and predictable, noise is uncertain and less detailed.
- Core assumption: State and noise have inherently different representational needs, justifying asymmetric model capacity.
- Evidence anchors:
  - [section 5]: "asymmetric reconstructions. This setup reduces the likelihood of confusing noise belief with state belief"
  - [section 5]: "reconstructions of noise belief lack the detail seen in state belief reconstructions"
  - [corpus]: No direct evidence; corpus neighbors do not discuss asymmetric decoder designs.
- Break condition: If the asymmetry assumption leads to underfitting of the noise component or overfitting of the state component.

## Foundational Learning

- Concept: Identifiability in causal representation learning
  - Why needed here: The paper builds on causal identifiability theory to justify state disentanglement in RL.
  - Quick check question: Can you explain why identifiability matters for recovering latent states in noisy observations?

- Concept: Belief-MDP conversion
  - Why needed here: The paper converts POMDP to belief-MDP to relax the invertible observation assumption.
  - Quick check question: How does the belief-MDP representation make the observation function invertible?

- Concept: Variational Autoencoder (VAE) framework
  - Why needed here: The proposed world model uses VAE to parametrize state and noise beliefs.
  - Quick check question: What role does the KL divergence term play in the ELBO objective?

## Architecture Onboarding

- Component map:
  - Observation encoder -> State posterior, Noise posterior
  - State transition model -> Next state belief
  - Noise transition model -> Next noise belief
  - State decoder -> Observation reconstruction
  - Noise decoder -> Observation reconstruction
  - Reward model -> Reward prediction

- Critical path:
  1. Encode observation into state and noise posteriors
  2. Sample state and noise beliefs
  3. Transition state and noise beliefs forward
  4. Reconstruct observation and reward
  5. Compute ELBO loss and backpropagate

- Design tradeoffs:
  - Symmetric vs asymmetric decoders: asymmetric reduces confusion but may underfit noise
  - KL divergence weights (α, β): balance between state and noise disentanglement
  - Belief dimension: larger dimensions improve expressiveness but increase computation

- Failure signatures:
  - State and noise reconstructions are both blurry → insufficient model capacity
  - State reconstruction is clear but noise is missing → KL divergence for noise too high
  - Both reconstructions are detailed but policy performance is poor → transition/reward preservation violated

- First 3 experiments:
  1. Train with symmetric decoders and observe confusion between state and noise reconstructions
  2. Increase β to enforce noise independence and check if noise reconstructions become cleaner
  3. Remove reward objective and observe collapse in policy performance

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the analysis, several questions emerge:

### Open Question 1
- Question: How does the proposed method's disentanglement performance scale with increasingly complex and high-dimensional observation spaces, such as those with multiple concurrent sources of noise or non-additive noise models?
- Basis in paper: [inferred] The paper discusses additive noise models and tests on DeepMind Control Suite with video backgrounds, but doesn't explore more complex noise structures or higher-dimensional observations.
- Why unresolved: The empirical evaluation is limited to specific types of noise and observation dimensions, leaving open questions about robustness to more challenging scenarios.
- What evidence would resolve it: Testing the method on tasks with non-additive noise, multiple simultaneous noise sources, or significantly higher-dimensional observations (e.g., raw pixel videos vs. 64x64 images) would clarify its scalability.

### Open Question 2
- Question: What is the impact of hyperparameter choices (α, β, latent state dimensions) on disentanglement quality and policy performance, and are there principled ways to select these parameters without extensive tuning?
- Basis in paper: [explicit] The paper mentions using hyperparameters from DenoisedMDP without further tuning and provides specific values used, but doesn't analyze sensitivity or offer principled selection methods.
- Why unresolved: The paper relies on inherited hyperparameters and doesn't investigate how sensitive the method is to these choices or whether there are systematic ways to set them.
- What evidence would resolve it: Systematic ablation studies varying α, β, and latent dimensions across multiple tasks, coupled with analysis of their relationship to disentanglement metrics, would clarify the role of these hyperparameters.

### Open Question 3
- Question: How does the proposed method compare to model-free approaches in terms of sample efficiency and final performance when dealing with noisy observations, particularly in domains where model-based approaches typically struggle?
- Basis in paper: [inferred] The paper focuses on model-based RL and compares to other model-based methods, but doesn't benchmark against state-of-the-art model-free algorithms in noisy settings.
- Why unresolved: The paper establishes superiority over other model-based methods but doesn't address whether the benefits of the proposed approach extend to comparisons with model-free methods, which might have different strengths in noisy environments.
- What evidence would resolve it: Direct comparisons with leading model-free algorithms (e.g., SAC, TD3) on the same noisy tasks, measuring both sample efficiency and final performance, would clarify the relative advantages of the model-based approach.

## Limitations
- Limited empirical validation beyond controlled noise backgrounds rather than real-world observation noise
- Asymmetric reconstruction design lacks systematic ablation studies comparing alternative architectures
- Conditional independence assumption for noise beliefs requires further validation across diverse POMDP structures

## Confidence
- Theoretical framework claims: Medium-High
- Empirical results: Medium
- Asymmetric reconstruction design: Medium
- Belief-MDP conversion approach: High

## Next Checks
1. Test the method on non-stationary noise patterns (e.g., temporally correlated noise) to verify conditional independence assumption holds beyond uniform backgrounds.
2. Conduct systematic ablation of the asymmetric reconstruction architecture, comparing against symmetric and other structured alternatives.
3. Evaluate performance when underlying state has redundancy or when preserving transitions/rewards alone is insufficient for optimal policy performance.