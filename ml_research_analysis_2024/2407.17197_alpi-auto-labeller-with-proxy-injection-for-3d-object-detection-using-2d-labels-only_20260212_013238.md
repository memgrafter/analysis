---
ver: rpa2
title: 'ALPI: Auto-Labeller with Proxy Injection for 3D Object Detection using 2D
  Labels Only'
arxiv_id: '2407.17197'
source_url: https://arxiv.org/abs/2407.17197
tags:
- object
- detection
- objects
- weak
- annotation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ALPI introduces a novel weakly supervised 3D object detection method
  that relies solely on 2D bounding box annotations and size priors, without requiring
  any 3D box annotations. The core idea is to inject proxy objects (synthetic cuboids)
  into the training data, which have 3D annotations by construction, enabling the
  model to learn 3D detection features that generalize to real object classes.
---

# ALPI: Auto-Labeller with Proxy Injection for 3D Object Detection using 2D Labels Only

## Quick Facts
- arXiv ID: 2407.17197
- Source URL: https://arxiv.org/abs/2407.17197
- Reference count: 40
- ALPI achieves 3D detection performance close to fully supervised methods using only 2D labels

## Executive Summary
ALPI introduces a novel weakly supervised 3D object detection method that operates using only 2D bounding box annotations and size priors, without requiring any 3D box annotations. The core innovation involves injecting proxy objects (synthetic cuboids) into training data, which by construction have 3D annotations, enabling the model to learn 3D detection features that generalize to real object classes. The method also introduces a depth-normalized 2D loss to better align 2D supervision with 3D detection and employs an iterative pseudo-labelling scheme to progressively improve 3D pseudo-labels. Experiments on KITTI demonstrate performance approaching fully supervised methods across Car, Pedestrian, and Cyclist classes, while showing effectiveness on the more challenging nuScenes dataset as the first method to experiment in this weakly supervised setting.

## Method Summary
ALPI's approach centers on proxy injection, where synthetic 3D cuboids with known dimensions and positions are randomly placed in point clouds and projected to generate corresponding 2D bounding boxes. These proxy objects provide ground truth 3D annotations by construction, allowing the model to learn 3D detection features. The method employs a depth-normalized 2D loss that scales the 2D supervision based on object distance, addressing the misalignment between 2D projections and 3D detection requirements. An iterative pseudo-labelling process progressively refines 3D pseudo-labels for real objects, with the model being trained alternately on proxy objects and pseudo-labeled real objects. The framework is designed to work with both human-annotated 2D labels and predictions from 2D detectors, potentially eliminating the need for human annotation entirely on novel datasets.

## Key Results
- Achieves 3D detection performance close to fully supervised methods on KITTI dataset across Car, Pedestrian, and Cyclist classes
- Demonstrates effectiveness on nuScenes dataset as first weakly supervised 3D detection method tested in this setting
- Shows robustness when using 2D detector predictions instead of human annotations, enabling potential annotation-free deployment

## Why This Works (Mechanism)
The method works by creating a bridge between 2D and 3D supervision through synthetic proxy objects. By injecting these objects with known 3D properties into the training data, the model can learn the relationship between 2D projections and 3D bounding boxes. The depth-normalized loss addresses the fundamental challenge that distant objects appear smaller in 2D but require similar 3D localization precision. The iterative pseudo-labelling scheme progressively improves the model's understanding of real object 3D properties by refining pseudo-labels over multiple training cycles.

## Foundational Learning
- **Weakly supervised learning**: Learning from limited or incomplete annotations (why needed: to reduce annotation costs; quick check: compare performance with varying annotation completeness)
- **3D-2D projection geometry**: Understanding how 3D objects map to 2D images (why needed: core to aligning 2D supervision with 3D detection; quick check: verify projection accuracy across different camera parameters)
- **Point cloud processing**: Handling sparse 3D point data from LiDAR sensors (why needed: primary input modality for 3D detection; quick check: evaluate point cloud density impact on detection accuracy)
- **Iterative pseudo-labelling**: Using model predictions to generate training targets (why needed: to bootstrap 3D supervision from limited 2D annotations; quick check: measure pseudo-label quality improvement over iterations)
- **Depth normalization**: Scaling losses based on object distance (why needed: to balance supervision across different ranges; quick check: analyze detection performance vs object distance)
- **Synthetic data injection**: Adding artificial objects to training data (why needed: to provide ground truth 3D annotations; quick check: test with varying proxy object densities)

## Architecture Onboarding

**Component Map**: 2D Annotations -> Proxy Injection -> 3D Detector Training -> Pseudo-Labelling -> Refined 3D Detector

**Critical Path**: The core workflow follows: 2D annotations and size priors → proxy object generation and injection → initial 3D detector training → pseudo-label generation for real objects → refined training on both proxies and pseudo-labeled real objects → final model evaluation.

**Design Tradeoffs**: The method trades computational overhead from iterative training and proxy injection against the benefit of eliminating 3D annotation requirements. The depth-normalized loss adds complexity but addresses fundamental geometric misalignment. The quality of pseudo-labels depends on the initial model performance, creating a bootstrapping challenge that the iterative approach attempts to solve.

**Failure Signatures**: Performance degradation may occur when 2D annotations poorly represent object extents, when size priors are inaccurate, or when proxy objects don't adequately cover the diversity of real object configurations. The method may struggle with heavily occluded objects or those with unusual aspect ratios that deviate from learned priors.

**First Experiments**:
1. Validate the proxy injection mechanism by testing detection performance with only proxy objects versus mixed proxy and real objects
2. Evaluate the impact of depth normalization by comparing with standard 2D loss implementations
3. Test the iterative pseudo-labelling scheme by measuring pseudo-label quality and detection improvement across iterations

## Open Questions the Paper Calls Out
None explicitly mentioned in the provided information.

## Limitations
- Performance may degrade on datasets with significantly different 3D-2D annotation alignments compared to KITTI and nuScenes
- Effectiveness depends heavily on the realism and diversity of synthetic proxy objects
- The assumption that 2D annotations contain sufficient information for accurate 3D bounding box prediction may not hold for all object categories or sensor configurations

## Confidence
High: The method's ability to achieve 3D detection using only 2D labels on established benchmarks like KITTI and nuScenes is well-supported by experimental results.
Medium: The scalability to completely novel datasets without any human annotations remains more theoretical in the current presentation.
Low: The claim about being the first to experiment on nuScenes in this weakly supervised setting requires verification of exact experimental conditions.

## Next Checks
1. Test ALPI on a dataset with different 3D-2D annotation characteristics (e.g., objects with high occlusion or unusual aspect ratios) to validate generalization claims
2. Conduct ablation studies removing the proxy injection component to quantify its specific contribution to performance
3. Evaluate the method's robustness when using 2D detector predictions versus human annotations across multiple detection quality levels to assess the practical utility of eliminating human annotation requirements