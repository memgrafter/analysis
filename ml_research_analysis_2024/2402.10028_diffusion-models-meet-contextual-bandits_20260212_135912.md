---
ver: rpa2
title: Diffusion Models Meet Contextual Bandits
arxiv_id: '2402.10028'
source_url: https://arxiv.org/abs/2402.10028
tags:
- diffusion
- regret
- posterior
- linear
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces diffusion Thompson sampling (dTS), a method
  that leverages pre-trained diffusion models as informative priors in contextual
  bandits. By efficiently approximating posteriors under such priors, dTS enables
  both fast updates and sampling while maintaining strong empirical performance.
---

# Diffusion Models Meet Contextual Bandits

## Quick Facts
- arXiv ID: 2402.10028
- Source URL: https://arxiv.org/abs/2402.10028
- Reference count: 40
- This paper introduces diffusion Thompson sampling (dTS), a method that leverages pre-trained diffusion models as informative priors in contextual bandits, achieving computational efficiency and strong empirical performance across diverse settings.

## Executive Summary
This paper introduces diffusion Thompson sampling (dTS), a novel approach that leverages pre-trained diffusion models as informative priors in contextual bandits. By efficiently approximating posteriors under such priors, dTS enables both fast updates and sampling while maintaining strong empirical performance. The method is motivated by exact closed-form solutions for linear cases and extends to nonlinear rewards via a two-layer approximation: a Gaussian likelihood approximation for non-linear rewards and a diffusion approximation for nonlinear hierarchical structures. The resulting approximate posteriors remain diffusion models with updated, data-dependent means and covariances. Empirical results demonstrate significant improvements over existing methods across diverse contextual bandit settings, including synthetic and real-world datasets.

## Method Summary
dTS uses a pre-trained diffusion model as a prior over action parameters, then performs Thompson sampling by approximating the posterior through two layers of approximation. First, non-linear rewards are approximated by a Gaussian likelihood using a Laplace-like approach. Second, non-linear diffusion links are handled by substituting non-linear fℓ for linear Wℓ in the exact linear-Gaussian posterior formulas. The resulting approximate posteriors remain diffusion models with updated, data-dependent means and covariances. Hierarchical sampling from these posteriors enables efficient action selection while maintaining computational efficiency through small covariance matrices.

## Key Results
- dTS achieves computational efficiency by maintaining a hierarchy of small d×d covariance matrices instead of a single large dK×dK covariance matrix, with space complexity O((L+K)d²)
- The method maintains statistical efficiency by preserving action correlations through the latent diffusion structure, reducing regret compared to independent per-action posteriors
- Empirical results show significant improvements over existing methods across diverse contextual bandit settings, with Bayes regret scaling favorably with the number of actions K

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion Thompson sampling (dTS) achieves computational efficiency by maintaining a hierarchy of small d×d covariance matrices instead of a single large dK×dK covariance matrix.
- Mechanism: Instead of marginalizing all latent parameters and storing the full joint posterior (θa)a∈[K], dTS samples hierarchically through latent layers ψℓ. Each layer's covariance is d×d, so total space is O(Ld² + Kd²) rather than O(K²d²).
- Core assumption: The posterior remains factorized as a diffusion model, enabling sequential sampling without forming the full joint covariance.
- Evidence anchors:
  - [abstract]: "efficiently approximates posteriors under such priors, enabling both fast updates and sampling"
  - [section]: "the time and space complexities of dTS are O(L + K)d³ and O(L + K)d². This is because dTS requires converting and storing L + K covariance matrices, each being d × d-dimensional."
- Break condition: If the diffusion model cannot be factorized or requires dense dependencies across all actions, the posterior factorization fails and dTS must revert to full joint storage.

### Mechanism 2
- Claim: dTS maintains statistical efficiency by preserving action correlations through the latent diffusion structure, rather than modeling actions independently.
- Mechanism: The diffusion prior encodes correlations among actions via shared latent variables ψℓ. Hierarchical sampling propagates information from observed actions to unobserved ones through these latents, reducing regret compared to independent per-action posteriors.
- Core assumption: Action correlations are structured and can be captured by a pre-trained diffusion model, making latent sharing beneficial.
- Evidence anchors:
  - [abstract]: "leverage pre-trained diffusion models as expressive priors to capture complex action dependencies"
  - [section]: "LinTS maintains independent posteriors and fails to capture the correlations among actions; it only models θa|Ht,a rather than θa|Ht as done by dTS. Consequently, LinTS incurs higher regret due to the information loss caused by unused interactions of similar actions."
- Break condition: If actions are truly independent or correlations are unstructured, the diffusion prior provides no benefit and the extra complexity is wasted.

### Mechanism 3
- Claim: The two-layer approximation (Gaussian likelihood + linearized diffusion hierarchy) enables tractable posteriors while retaining expressiveness.
- Mechanism: Non-linear rewards are linearized via a Laplace-like Gaussian approximation of the likelihood. Non-linear diffusion links are handled by substituting non-linear fℓ for linear Wℓ in the exact linear-Gaussian posterior formulas, preserving the diffusion structure but updating means/covariances with data.
- Core assumption: The non-linear components can be approximated well enough that the resulting Gaussian diffusion posterior remains useful for Thompson sampling.
- Evidence anchors:
  - [section]: "We use an approach similar to the Laplace approximation, but instead of approximating the entire posterior, we approximate only the likelihood by a Gaussian... The resulting approximate posteriors (both action and latent) admit the following closed-form expressions."
  - [section]: "The two steps above yield a posterior where each conditional factor p(θa|ψ1,Ht,a) and p(ψℓ−1|ψℓ,Ht) remains Gaussian with updated means and covariances, while the overall model retains the hierarchical diffusion structure."
- Break condition: If the non-linearities are too severe, the Gaussian approximation becomes poor and Thompson sampling under the approximate posterior may perform badly.

## Foundational Learning

- Concept: Contextual bandit framework with per-action parameters
  - Why needed here: dTS operates in the disjoint (per-action) setting where each action a has its own parameter vector θa, so understanding how rewards depend on these separate parameters is fundamental.
  - Quick check question: In the per-action setting, how is the reward for action a in context x computed, and what distribution is assumed for Yt?

- Concept: Thompson sampling and posterior sampling
  - Why needed here: dTS is a Thompson sampling algorithm that samples from the posterior over parameters to select actions; knowing how TS balances exploration/exploitation via posterior uncertainty is key.
  - Quick check question: In Thompson sampling, what is the role of the posterior distribution when selecting the next action?

- Concept: Diffusion models as priors
  - Why needed here: The core novelty is using a pre-trained diffusion model to define the prior over action parameters; understanding how diffusion models generate hierarchical dependencies is essential.
  - Quick check question: How does a diffusion model generate correlated action parameters through latent variables in the hierarchical prior?

## Architecture Onboarding

- Component map:
  Pre-trained diffusion model (offline) -> Likelihood approximator -> Posterior updater -> Hierarchical sampler -> Action selector

- Critical path: At round t:
  1. Draw ψt,L from p(ψL|Ht)
  2. For ℓ=L down to 2, draw ψt,ℓ−1 from p(ψℓ−1|ψt,ℓ,Ht)
  3. For each a, draw θt,a from p(θa|ψt,1,Ht,a)
  4. Select At and observe Yt
  5. Update all posterior components

- Design tradeoffs:
  - Joint vs. hierarchical posterior: Joint posterior (θa)a∈[K] is statistically efficient but O(K²d²) space; hierarchical is O(Kd²) but requires correct prior structure.
  - Exact vs. approximate: Exact posteriors only for linear-Gaussian; approximation needed for GLM rewards and non-linear diffusion links, trading off some accuracy for tractability.
  - Pre-trained vs. learned prior: Pre-trained prior captures structure from offline data; learned prior could adapt but is expensive and may overfit.

- Failure signatures:
  - If actions are independent, dTS provides no benefit over LinTS and incurs extra cost.
  - If the diffusion prior is misspecified (wrong correlations), sampling from it leads to poor exploration.
  - If the Gaussian approximation of the likelihood is poor (e.g., highly non-linear GLM), posterior uncertainty is misestimated.

- First 3 experiments:
  1. Synthetic linear-Gaussian case with true diffusion prior: Verify that dTS matches exact Thompson sampling performance.
  2. Shared-parameter variant on MovieLens: Confirm that the single-parameter dTS variant outperforms LinTS when feature map φ is available.
  3. Misspecified prior ablation: Train diffusion prior on out-of-distribution data and measure degradation vs. LinTS.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does dTS perform when the pre-trained diffusion model is misspecified or trained on limited/biased data?
- Basis in paper: [explicit] The paper acknowledges that dTS may face misspecification at both the prior and likelihood levels and that it remains empirically stable but lacks robustness guarantees.
- Why unresolved: The paper does not provide theoretical analysis or empirical results demonstrating the robustness of dTS under misspecified priors or with limited/biased offline data.
- What evidence would resolve it: Theoretical analysis proving regret bounds under misspecified priors, or empirical results comparing dTS performance on datasets with varying degrees of prior misspecification or data bias.

### Open Question 2
- Question: Can dTS's regret bounds be extended to nonlinear reward models and non-linear diffusion links beyond the linear-Gaussian setting?
- Basis in paper: [explicit] The paper states that extending the analysis to nonlinear settings is nontrivial and leaves this as an open direction for future work.
- Why unresolved: The current regret analysis relies on closed-form posteriors available only in the linear-Gaussian case, and the paper does not provide techniques for handling the non-linear case.
- What evidence would resolve it: Development of new theoretical techniques to derive regret bounds for dTS under general nonlinear reward models and diffusion links, or empirical evidence demonstrating regret scaling in such settings.

### Open Question 3
- Question: What is the impact of diffusion model depth L on dTS's performance when the true prior distribution is not a diffusion model?
- Basis in paper: [inferred] The paper shows empirically that dTS's performance initially improves with diffusion depth L on the Swiss roll dataset, but then degrades beyond a certain point (L ≈ 40).
- Why unresolved: The paper does not provide theoretical analysis explaining this non-monotonic relationship between L and regret when the true prior is not a diffusion model.
- What evidence would resolve it: Theoretical analysis deriving regret bounds as a function of L for misspecified diffusion priors, or systematic empirical studies varying L across different non-diffusion true priors.

### Open Question 4
- Question: How does dTS compare to K-independent regret algorithms in shared-parameter settings?
- Basis in paper: [explicit] The paper mentions that in the shared-parameter setting (Remark 2.1), dTS would achieve regret independent of K, similar to some prior K-independent regret algorithms.
- Why unresolved: The paper does not provide empirical comparisons or theoretical analysis of dTS's performance relative to K-independent regret algorithms in shared-parameter settings.
- What evidence would resolve it: Empirical comparisons of dTS versus K-independent regret algorithms on shared-parameter benchmarks, or theoretical analysis showing conditions under which dTS achieves K-independent regret.

## Limitations
- The effectiveness of the two-layer approximation in highly non-linear settings is not fully explored, and the sensitivity to prior misspecification requires further investigation.
- Theoretical regret bounds are asymptotic and their finite-sample behavior requires further investigation.
- The paper does not provide theoretical analysis of dTS's performance relative to K-independent regret algorithms in shared-parameter settings.

## Confidence
- **High confidence**: Computational efficiency claims and the core mechanism of leveraging diffusion models as informative priors are well-supported by complexity analysis and empirical results.
- **Medium confidence**: Regret bounds and the robustness of the two-layer approximation in highly non-linear settings are promising but require further investigation for non-linear reward models.
- **Low confidence**: The practical implications of prior misspecification and the algorithm's behavior with complex action correlation structures are not fully explored.

## Next Checks
1. **Prior Misspecification Analysis**: Systematically evaluate dTS performance when the pre-trained diffusion prior is learned from out-of-distribution data, comparing against LinTS and UCB baselines across varying degrees of misspecification.

2. **Non-linear Reward Stress Test**: Design synthetic experiments with increasingly severe non-linearities in both the reward function and diffusion hierarchy to quantify the breakdown point of the Gaussian approximation.

3. **Correlation Structure Sensitivity**: Vary the strength and structure of action correlations in synthetic experiments to identify regimes where the diffusion prior provides maximum benefit versus when it becomes detrimental.