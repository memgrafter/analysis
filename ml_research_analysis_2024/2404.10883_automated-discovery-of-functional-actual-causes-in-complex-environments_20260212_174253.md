---
ver: rpa2
title: Automated Discovery of Functional Actual Causes in Complex Environments
arxiv_id: '2404.10883'
source_url: https://arxiv.org/abs/2404.10883
tags:
- actual
- state
- causes
- cause
- binary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Functional actual cause (FAC) extends actual causality by incorporating\
  \ context-specific independencies to identify more relevant causes in complex environments.\
  \ It learns invariant preimages\u2014partitions of the state space where the outcome\
  \ depends only on specific variables\u2014and uses them to filter out irrelevant\
  \ events."
---

# Automated Discovery of Functional Actual Causes in Complex Environments

## Quick Facts
- arXiv ID: 2404.10883
- Source URL: https://arxiv.org/abs/2404.10883
- Reference count: 40
- Primary result: JACI achieves 3.6% error on actual cause identification vs 8.8-50% for baselines in high-dimensional continuous environments

## Executive Summary
This paper introduces Functional Actual Causes (FAC), a framework that extends actual causality by incorporating context-specific independencies to identify more relevant causes in complex environments. FAC learns invariant preimages—partitions of the state space where the outcome depends only on specific variables—and uses them to filter out irrelevant events. The Joint Optimization for Actual Cause Inference (JACI) algorithm jointly learns a forward dynamics model and a state-to-binary-mapping network from observational data to infer FAC. Experiments show FAC maintains intuitive verdicts on established examples from the actual causality literature and JACI significantly outperforms heuristic baselines in accuracy on high-dimensional continuous environments like Random Vectors, Mini-Breakout, and 2D Robot Pushing.

## Method Summary
The method introduces Functional Actual Causes (FAC) as an extension to actual causality that accounts for context-specific independencies. FAC learns invariant preimages—partitions of the state space where the outcome depends only on specific variables—and uses them to filter out irrelevant events. The Joint Optimization for Actual Cause Inference (JACI) algorithm jointly learns a forward dynamics model and a state-to-binary-mapping network from observational data. The forward model predicts outcomes based on candidate actual cause variables, while the mapping network identifies which variables are actual causes for each state. This joint optimization enforces invariance, necessity, and minimality properties through an adaptive tradeoff mechanism that balances prediction accuracy with binary vector length minimization.

## Key Results
- FAC correctly handles the "Queen of England" problem by filtering out irrelevant events through context-specific independencies
- JACI achieves 3.6% error on Random Vectors domains vs 8.8-50% for baseline methods
- In Mini-Breakout and 2D Robot Pushing, JACI identifies actual causes in complex, high-dimensional environments where baselines struggle

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Invariant preimages (IVPs) restrict the set of actual causes by capturing context-specific independencies, filtering out irrelevant events.
- Mechanism: The FAC framework learns partitions of the state space where the outcome depends only on specific variables. Events outside these partitions are excluded as actual causes, preventing the "Queen of England" problem.
- Core assumption: Context-specific independencies exist in the environment and can be learned from observational data.
- Evidence anchors:
  - [abstract]: "FAC learns invariant preimages—partitions of the state space where the outcome depends only on specific variables—and uses them to filter out irrelevant events."
  - [section]: "The obstacle in Example 2.1 is isomorphic to the Queen of England; the outcome is invariant to the obstacle position in a vast number of possible states even though the obstacle could block the push, but it should not realistically be an actual cause in a context where could not actually block the push."
  - [corpus]: Weak - no direct corpus mention of IVPs, but related to causality filtering concepts.
- Break condition: If the environment lacks context-specific independencies, IVPs cannot be learned, and FAC reduces to traditional actual causality.

### Mechanism 2
- Claim: JACI jointly learns a forward dynamics model and a state-to-binary-mapping network to infer functional actual causes.
- Mechanism: The algorithm optimizes a masked forward model that predicts outcomes based only on the candidate actual cause variables, while simultaneously learning which variables are actual causes for each state. This enforces invariance and necessity properties.
- Core assumption: A forward model can approximate the true dynamics well enough to identify which variables are necessary for outcome prediction.
- Evidence anchors:
  - [abstract]: "JACI learns invariant preimages—partitions of the state space where the outcome depends only on specific variables—and uses them to filter out irrelevant events."
  - [section]: "JACI learns from observational data to identify if the outcome at a given state is determined by only a specific subset of variables, and thereby infers functional actual causes of the outcome."
  - [corpus]: Weak - no direct corpus mention of JACI, but related to joint optimization approaches in causality.
- Break condition: If the forward model cannot learn the true dynamics due to insufficient data or complexity, JACI cannot accurately identify actual causes.

### Mechanism 3
- Claim: FAC extends actual causality by incorporating minimality through a global cost function on the binary-subset pair.
- Mechanism: The framework minimizes the sum of the product of partition size and binary vector length, ensuring that rare events with causal effects are prioritized over normal events with no effect.
- Core assumption: The cost function correctly balances partition size and binary vector length to capture normality intuitions.
- Evidence anchors:
  - [abstract]: "FAC extends established definitions of actual cause by accounting for normality through context-specific independencies that hold in different states."
  - [section]: "By enforcing the minimality criterion in Equation 2, a binary subset pair (B(Y), I(Y)) has lower cost when an invariant preimage IVP(X; Y) with more variables in X contains fewer states, so events with lower cardinality (smaller |X|) are actual causes in more states."
  - [corpus]: Weak - no direct corpus mention of minimality cost function, but related to cardinality-based causality selection.
- Break condition: If the cost function does not properly balance partition size and binary vector length, FAC may incorrectly prioritize certain events as actual causes.

## Foundational Learning

- Concept: Structural Causal Models (SCMs)
  - Why needed here: FAC builds upon SCMs to define the functional relationship between variables and outcomes.
  - Quick check question: In an SCM, what are the endogenous and exogenous variables, and how do they relate to the structural equations?

- Concept: Actual Causality Definitions
  - Why needed here: FAC extends existing definitions of actual causality (e.g., Halpern-Pearl) by incorporating context-specific independencies.
  - Quick check question: What are the key conditions (AC1, AC2(a), AC2(b), AC3) in the Halpern-Pearl definition of actual causality?

- Concept: Context-Specific Independence
  - Why needed here: IVPs in FAC capture context-specific independencies, which are essential for filtering out irrelevant events.
  - Quick check question: How does context-specific independence differ from regular conditional independence, and why is it important for identifying actual causes?

## Architecture Onboarding

- Component map:
  Forward dynamics model f(s, b; ϕ) -> State-to-binary-mapping network hY(s; θ) -> Binary mask b indicating actual causes

- Critical path:
  1. Initialize f and hY networks.
  2. For each training step:
     a. Compute b(i) = hY(s(i); θ) for all states in batch.
     b. Update f parameters ϕ to minimize prediction error.
     c. Update hY parameters θ to minimize binary vector length and maintain prediction accuracy.
  3. Repeat until convergence.

- Design tradeoffs:
  - Fixed vs. adaptive tradeoff rate β: Adaptive β (β = bβe^(-∥f(s(i),b(i);ϕ)-y(i)∥)) can improve performance but adds complexity.
  - Single vs. multiple training iterations: More iterations may improve accuracy but increase training time.
  - Binary vector length penalty: Stronger penalty may lead to more conservative actual cause identification.

- Failure signatures:
  - hY always outputs all zeros or all ones: Indicates poor optimization or inappropriate tradeoff rate.
  - f predictions are consistently poor: Suggests insufficient data, model complexity, or inappropriate network architecture.
  - JACI performs worse than baselines: Could indicate issues with the invariance or necessity properties, or suboptimal hyperparameters.

- First 3 experiments:
  1. Verify that JACI can learn IVPs in the 1-D block pushing domain from Example 2.1.
  2. Compare JACI's performance on the Random Vectors domain with varying numbers of active variables.
  3. Evaluate JACI's ability to identify actual causes in the Mini-Breakout domain, where interactions are infrequent and complex.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the FAC definition perform in probabilistic settings where state likelihoods are not uniform?
- Basis in paper: [inferred] The paper mentions that FAC's minimality criterion assumes equal likelihood for all states, but notes this can be extended to probabilistic settings by weighting states by their likelihood, which is left for future work.
- Why unresolved: The paper does not provide empirical results or theoretical analysis for probabilistic state spaces.
- What evidence would resolve it: Experiments comparing FAC performance on datasets with known non-uniform state distributions.

### Open Question 2
- Question: What is the impact of the hyperparameter β in JACI's adaptive tradeoff mechanism on accuracy and convergence?
- Basis in paper: [explicit] The paper discusses using an adaptive β based on the forward model's prediction error, but notes that JACI's accuracy is "somewhat robust" to values of bβ without providing detailed sensitivity analysis.
- Why unresolved: The paper does not quantify how different β values affect JACI's performance across domains.
- What evidence would resolve it: Ablation studies showing accuracy and convergence rates for various fixed and adaptive β values.

### Open Question 3
- Question: How does JACI handle environments with rare but significant causal interactions, as opposed to frequent minor interactions?
- Basis in paper: [inferred] The paper notes that JACI can struggle with local minima like outputting all zeros or ones, and that environments like 2D pushing have rare interactions that baselines struggle with.
- Why unresolved: The paper does not analyze JACI's robustness to class imbalance in causal interactions or its ability to detect rare but critical causes.
- What evidence would resolve it: Experiments measuring precision-recall curves for actual cause detection in environments with varying interaction frequencies.

## Limitations
- Performance depends heavily on sufficient observational data quality and quantity, with degradation in domains with sparse or noisy interactions
- The adaptive tradeoff rate β introduces sensitivity to hyperparameter tuning that affects reproducibility
- Limited empirical validation across only three domains, raising questions about generalizability to truly open-ended environments

## Confidence
- High confidence: Mathematical formulation of FAC and its extension of actual causality definitions
- Medium confidence: JACI algorithm's empirical performance based on promising but limited experimental validation
- Low confidence: Generalizability to open-ended environments where context-specific independencies may not be easily learnable

## Next Checks
1. Conduct ablation studies removing the adaptive tradeoff mechanism to quantify its contribution to performance gains and assess sensitivity to hyperparameter choices.

2. Test JACI on synthetic domains with controlled levels of noise and sparsity to establish performance bounds and identify failure modes in realistic scenarios.

3. Implement cross-validation across multiple random seeds and dataset splits for the existing domains to verify that reported performance differences between JACI and baselines are statistically significant.