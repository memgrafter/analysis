---
ver: rpa2
title: Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors
arxiv_id: '2402.15713'
source_url: https://arxiv.org/abs/2402.15713
tags:
- relation
- prompt
- samples
- learning
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a prompt-based continual few-shot relation
  extraction framework to address catastrophic forgetting and overfitting issues.
  The key contributions are: (1) A prompt representation module that leverages semi-automated
  templates to help pre-trained language models acquire generalized knowledge adaptable
  to old and new relation categories; (2) A margin-based contrastive learning objective
  that focuses on hard samples to achieve more uniform feature distribution, effectively
  alleviating overfitting; (3) A memory augmentation strategy using ChatGPT to generate
  diverse samples guided by well-crafted prompts, further mitigating overfitting in
  low-resource scenarios.'
---

# Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors

## Quick Facts
- **arXiv ID**: 2402.15713
- **Source URL**: https://arxiv.org/abs/2402.15713
- **Authors**: Shengkun Ma; Jiale Han; Yi Liang; Bo Cheng
- **Reference count**: 0
- **Primary result**: Proposes CPL framework achieving up to 6.28% accuracy improvement on CFRE while reducing catastrophic forgetting and overfitting

## Executive Summary
This paper addresses the challenges of continual few-shot relation extraction (CFRE), where models must continuously learn new relations with limited data while avoiding catastrophic forgetting of previously learned relations. The authors propose a prompt-based framework called Contrastive Prompt Learning (CPL) that combines hybrid prompt templates, margin-based contrastive learning, and ChatGPT-powered memory augmentation. The framework aims to activate generalized knowledge in pre-trained language models (PLMs), create more uniform feature distributions, and provide diverse training samples to mitigate overfitting in low-resource settings.

## Method Summary
The CPL framework uses a semi-automated prompt template that combines entity markers with learnable soft tokens to reformulate relation extraction as a cloze-style task. A margin-based contrastive learning objective focuses on hard samples by adjusting decision boundaries with margin factors. The memory augmentation strategy employs ChatGPT to generate diverse samples guided by well-crafted prompts, which are added to a small memory set of representative samples selected via K-means clustering. The model uses a Nearest-Class-Mean classifier and trains in two phases: current task training with margin-based contrastive loss, followed by memory replay training. Experiments use BERT-base-uncased as the encoder with memory size L=1 for fair comparison.

## Key Results
- CPL achieves up to 6.28% accuracy improvement over state-of-the-art methods on FewRel and TACRED benchmarks
- Effectively reduces catastrophic forgetting, maintaining performance on previously learned relations
- Significantly alleviates overfitting in low-resource few-shot scenarios
- Memory augmentation with ChatGPT-generated samples provides substantial performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hybrid prompt template activates generalized knowledge in PLMs that adapts to both old and new relations
- Mechanism: By combining entity markers with learnable soft tokens, the template reformulates RE as cloze-style task similar to pre-training, making PLMs focus on task structure rather than specific relation categories
- Core assumption: PLMs retain underlying knowledge that can be reactivated through appropriate prompting
- Evidence anchors:
  - [abstract]: "designs prompt representation to acquire more generalized knowledge that can be easily adapted to old and new categories"
  - [section 4.2]: "PLMs can understand well what to do and perform better on downstream tasks"
  - [corpus]: Weak - no direct evidence of PLM reactivation through prompting in neighboring papers
- Break condition: If prompting fails to activate underlying knowledge, catastrophic forgetting persists regardless of template design

### Mechanism 2
- Claim: Margin-based contrastive learning creates more uniform feature distribution and focuses on hard samples
- Mechanism: MCL loss uses margin factors to control relaxation of decision boundaries, making models pay more attention to hard pairs and less to easy ones
- Core assumption: Focusing on hard samples during training improves generalization and reduces overfitting
- Evidence anchors:
  - [abstract]: "margin-based contrastive learning to focus more on hard samples, therefore alleviating catastrophic forgetting and overfitting issues"
  - [section 4.3]: "MCL objective can make models pay more attention to hard samples and less attention to easy ones, thus mitigating overfitting problem"
  - [corpus]: Moderate - InfoCL and CRECL use contrastive methods but without margin-based approach
- Break condition: If margin factors are poorly tuned, model may focus too much on noise or fail to learn discriminative features

### Mechanism 3
- Claim: ChatGPT-generated samples provide diverse augmentation that mitigates overfitting in low-resource scenarios
- Mechanism: Well-crafted prompts guide ChatGPT to generate relation-specific examples, creating additional training data that better represents true distribution
- Core assumption: LLM-generated samples are diverse enough to reduce overfitting without introducing excessive noise
- Evidence anchors:
  - [abstract]: "effective memory augmentation strategy that employs well-crafted prompts to guide ChatGPT in generating diverse samples"
  - [section 4.4]: "generate diverse samples to augment the memory set"
  - [corpus]: Weak - few papers use LLMs for augmentation in continual learning; most use traditional augmentation methods
- Break condition: If generated samples are too noisy or lack diversity, augmentation may harm rather than help performance

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: Understanding why sequential learning degrades performance on previous tasks is fundamental to the problem being solved
  - Quick check question: What happens to model parameters when training on new tasks without any preservation mechanism?

- Concept: Contrastive learning objectives and margin-based losses
  - Why needed here: The margin-based approach is central to how the model focuses on hard samples and creates uniform feature distributions
  - Quick check question: How does a margin factor change the relative importance of positive vs negative pairs in contrastive loss?

- Concept: Prompt engineering in PLMs
  - Why needed here: The hybrid prompt approach is key to activating generalized knowledge rather than learning specific relation categories
  - Quick check question: What is the difference between hard prompts, soft prompts, and hybrid prompts in terms of trainability and effectiveness?

## Architecture Onboarding

- Component map: Encoder (BERT-base-uncased) → Prompt Template (hybrid: entity markers + soft tokens) → Contrastive Learning Module (margin-based loss) → Memory Management (K-means sampling + ChatGPT augmentation) → Nearest-Class-Mean Classifier
- Critical path: Input sentence → Prompt encoding → Encoder forward pass → Contrastive loss computation → Gradient update → Memory storage/retrieval
- Design tradeoffs: Memory size vs performance (L=1 for fair comparison), ChatGPT generation quality vs diversity, margin factor tuning vs overfitting
- Failure signatures: Performance degradation on early tasks (catastrophic forgetting), high variance on few-shot tasks (overfitting), inconsistent ChatGPT outputs (augmentation instability)
- First 3 experiments:
  1. Baseline comparison: Run finetune baseline to establish catastrophic forgetting baseline
  2. Prompt ablation: Test entity marker vs hard prompt vs soft prompt vs hybrid prompt
  3. Contrastive loss ablation: Compare standard supervised contrastive loss vs margin-based contrastive loss

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of generated samples per relation to maximize performance without introducing noise?
- Basis in paper: [explicit] The paper mentions that using more generated data can only boost RE performance to a certain extent, not continuously better, and even cause a performance degradation with one FewRel dataset.
- Why unresolved: The paper only experimented with a limited number of generated samples (2 for FewRel, 5 for TACRED) and found diminishing returns. The optimal number likely depends on the specific dataset and relation types.
- What evidence would resolve it: Conducting experiments with a wider range of generated sample numbers per relation and analyzing the performance trends would reveal the optimal point.

### Open Question 2
- Question: How does the quality and diversity of samples generated by LLMs impact the effectiveness of memory augmentation in CFRE?
- Basis in paper: [inferred] The paper acknowledges that samples generated by LLMs may be noisy and not diverse enough, and provides examples where ChatGPT generated lexically similar but relationally incorrect samples.
- Why unresolved: The paper doesn't quantitatively measure the quality and diversity of generated samples or analyze their impact on model performance. It only qualitatively observes some limitations.
- What evidence would resolve it: Developing metrics to evaluate the quality and diversity of generated samples and correlating these metrics with model performance would provide insights into their impact.

### Open Question 3
- Question: Can the proposed method be extended to handle more complex relation extraction tasks, such as those involving multiple entities or nested relations?
- Basis in paper: [inferred] The paper focuses on binary relation extraction tasks with single head and tail entities. It doesn't explore more complex scenarios.
- Why unresolved: The paper doesn't experiment with or discuss the applicability of the method to more complex relation extraction tasks.
- What evidence would resolve it: Extending the prompt template and model architecture to handle multiple entities or nested relations, and evaluating their performance on such tasks, would demonstrate the method's generalizability.

## Limitations
- The effectiveness relies on interconnected mechanisms whose individual contributions are difficult to isolate
- ChatGPT memory augmentation introduces significant variability and doesn't guarantee sample quality or diversity
- Memory size constraint of L=1 represents an extremely low-resource setting that may not generalize to practical scenarios
- Performance improvements could be due to architectural changes rather than the proposed mechanisms working independently

## Confidence
**High Confidence (8/10)**: The overall framework outperforms baselines on two established benchmarks with reproducible methodology
**Medium Confidence (6/10)**: Mechanism explanations linking specific components to problem solutions, though ablation studies don't fully isolate individual contributions
**Low Confidence (4/10)**: Generalizability beyond tested datasets and settings, particularly for ChatGPT augmentation strategy in different domains

## Next Checks
1. **Component Ablation Under Varying Memory Budgets**: Run the complete CPL framework with L=1, L=5, and L=10 to test whether proposed components provide consistent benefits across different memory sizes
2. **Prompt Template Sensitivity Analysis**: Systematically vary the prompt template structure while keeping all other components fixed to quantify performance dependence on specific design
3. **ChatGPT Sample Quality and Diversity Metrics**: Implement quantitative measures of generated samples including semantic diversity, factual accuracy rate, and coverage of relation-specific patterns