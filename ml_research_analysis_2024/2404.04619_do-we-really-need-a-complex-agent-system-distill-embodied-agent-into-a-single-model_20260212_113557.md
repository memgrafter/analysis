---
ver: rpa2
title: Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single
  Model
arxiv_id: '2404.04619'
source_url: https://arxiv.org/abs/2404.04619
tags:
- arxiv
- agents
- preprint
- tasks
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: STEVE-2 is a hierarchical knowledge distillation framework that
  distills a multi-agent embodied system into a single versatile MLM. It employs hierarchical
  task division, parallel simulation-based mirrored distillation, and an extra expert
  module to incorporate additional multi-modal knowledge.
---

# Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model

## Quick Facts
- arXiv ID: 2404.04619
- Source URL: https://arxiv.org/abs/2404.04619
- Authors: Zhonghan Zhao; Ke Ma; Wenhao Chai; Xuan Wang; Kewei Chen; Dongxu Guo; Yanting Zhang; Hongwei Wang; Gaoang Wang
- Reference count: 31
- Primary result: 1.4×-7.3× performance improvements over state-of-the-art LLM-based methods while reducing the number of LLMs from 4 to 1

## Executive Summary
STEVE-2 introduces a hierarchical knowledge distillation framework that compresses a multi-agent embodied system into a single versatile multi-layer model (MLM). The framework employs hierarchical task division, parallel simulation-based mirrored distillation, and an extra expert module to incorporate additional multi-modal knowledge. After distillation, the resulting model can autonomously complete complex open-ended tasks without expert guidance. Evaluations on Minecraft navigation and creation tasks demonstrate significant performance improvements over state-of-the-art LLM-based methods while reducing inference complexity.

## Method Summary
STEVE-2 implements a hierarchical knowledge distillation framework that compresses a multi-agent embodied system into a single MLM while preserving cooperative performance. The method employs centralized planning with decentralized execution (CPDE), where a manager agent plans globally and conductor agents execute locally, all distilled from teacher agents using DPO loss. An extra expert module injects multimodal knowledge during training without requiring it at inference time. The framework uses a hierarchical MLM teacher structure with manager, conductor, and actor agents, trained through mirrored distillation on parallel simulation data.

## Key Results
- Achieves 1.4×-7.3× performance improvements over state-of-the-art LLM-based methods
- Reduces the number of LLMs from 4 to 1 while maintaining task performance
- Demonstrates improved inference speed and reduced GPU memory usage compared to multi-agent systems

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical knowledge distillation compresses a multi-agent system into a single MLM while preserving cooperative performance. STEVE-2 employs centralized planning with decentralized execution (CPDE), where a manager agent plans globally and conductor agents execute locally, all distilled from teacher agents using DPO loss. The extra expert module injects multimodal knowledge during training without requiring it at inference time.

### Mechanism 2
Extra expert module enhances training data quality without increasing inference complexity. During training, an extra expert (3D occupancy generator and dynamic map) provides additional multimodal knowledge to the teacher model, which is then distilled into STEVE-2. At inference, no external knowledge is needed.

### Mechanism 3
Multi-modal memory with retrieval-augmented generation (RAG) improves planning accuracy and consistency. STEVE-2 maintains a multi-modal memory of successfully executed plans, which is queried during planning using both textual and visual elements to retrieve relevant experiences.

## Foundational Learning

- **Knowledge distillation, specifically Direct Preference Optimization (DPO)**: To compress the multi-agent system into a single model while preserving performance
  - Quick check: What is the main advantage of using DPO over cross-entropy in this context?

- **Multimodal learning and integration**: To enable the agent to perceive and reason about visual, audio, and textual information simultaneously
  - Quick check: How does the vision transformer (ViT) interface with the language model in STEVE-2?

- **Hierarchical task decomposition**: To break down complex tasks into manageable sub-tasks that can be executed by different components
  - Quick check: What is the difference between centralized planning and decentralized execution in the CPDE framework?

## Architecture Onboarding

- **Component map**: Manager Agent (MLM M) → Conductor Agent (MLMC) → Actor Agent (MLM A) → Environment → Feedback to Memory
- **Critical path**: Manager → Conductor → Actor → Environment → Feedback to Memory
- **Design tradeoffs**: Single model vs. multiple specialized models: Reduced inference complexity vs. potential performance loss; Extra expert during training vs. inference: Improved training data vs. increased training complexity; Hierarchical vs. flat task decomposition: Better handling of complex tasks vs. increased planning overhead
- **Failure signatures**: Poor performance on complex tasks: Indicates distillation failure or insufficient hierarchical decomposition; Slow inference: Suggests bottlenecks in the single model or inefficient memory retrieval; Inconsistent behavior: May indicate issues with the multimodal memory or extra expert integration
- **First 3 experiments**: 1) Ablation study: Compare STEVE-2 with and without knowledge distillation to verify the distillation mechanism; 2) Ablation study: Compare STEVE-2 with and without extra expert to verify the expert module's contribution; 3) Performance test: Evaluate STEVE-2 on navigation and creation tasks to measure efficiency gains over baselines

## Open Questions the Paper Calls Out

### Open Question 1
How does the hierarchical structure of STEVE-2 impact the scalability of the system when increasing the number of conductor agents? The paper mentions that STEVE-2 uses a hierarchical structure for multi-granular task division and decentralized execution, but does not provide experimental data on scalability with varying numbers of agents.

### Open Question 2
What are the limitations of using the DPO loss function in knowledge distillation for STEVE-2, and how might alternative loss functions improve performance? The paper states that DPO loss is used for knowledge distillation but does not compare its effectiveness with other potential loss functions or discuss its limitations.

### Open Question 3
How does the inclusion of the extra expert module affect the generalizability of STEVE-2 to tasks outside the training domain? The paper describes the extra expert module as providing additional multi-modal knowledge but does not evaluate its impact on the model's ability to generalize to unseen tasks or environments.

## Limitations
- Evaluation primarily focuses on Minecraft tasks, limiting generalizability to other embodied AI domains
- Specific architectural details and training procedures for the extra expert module (3D occupancy generator and dynamic map) are not fully specified
- Limited analysis of failure modes or edge cases where the single-model approach might break down

## Confidence

- **High Confidence**: The core claim that knowledge distillation can reduce the number of LLMs from 4 to 1 while maintaining performance is well-supported by experimental results
- **Medium Confidence**: The claim of 1.4×-7.3× performance improvements over state-of-the-art methods is supported by presented results, but evaluation is limited to Minecraft tasks
- **Low Confidence**: The generalizability of STEVE-2 to other embodied AI domains beyond Minecraft is not demonstrated

## Next Checks

1. **Cross-domain generalization test**: Evaluate STEVE-2 on embodied AI tasks outside Minecraft (e.g., robot navigation, manipulation tasks) to assess the framework's generalizability and identify potential limitations when applied to different environments

2. **Alternative distillation method comparison**: Implement STEVE-2 using alternative knowledge distillation approaches (e.g., cross-entropy loss, contrastive distillation) and compare performance to isolate the specific contribution of the DPO-based mirrored distillation method

3. **Failure mode analysis**: Systematically test STEVE-2 on increasingly complex task hierarchies to identify the point at which the single-model approach begins to degrade compared to the original multi-agent system, and analyze the nature of these failures to understand the fundamental limits of the distillation framework