---
ver: rpa2
title: Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language
  Models
arxiv_id: '2412.03537'
source_url: https://arxiv.org/abs/2412.03537
tags:
- bias
- biases
- few-shot
- intrinsic
- llama
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether gender biases transfer from pre-trained
  large language models to downstream tasks when adapted via prompting. Previous studies
  found that bias transfer from pre-trained models to fine-tuned models was limited,
  but this work examines prompt adaptation instead, which is a common, compute-efficient
  deployment strategy.
---

# Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models

## Quick Facts
- arXiv ID: 2412.03537
- Source URL: https://arxiv.org/abs/2412.03537
- Authors: Natalie Mackraz; Nivedha Sivakumar; Samira Khorshidi; Krishna Patel; Barry-John Theobald; Luca Zappella; Nicholas Apostoloff
- Reference count: 37
- Primary result: Intrinsic biases in pre-trained models strongly correlate with adapted biases across all prompting strategies (rho ≥ 0.94)

## Executive Summary
This study investigates whether gender biases transfer from pre-trained large language models to downstream tasks when adapted via prompting. Previous research found limited bias transfer from pre-trained to fine-tuned models, but this work examines prompt adaptation—a common, compute-efficient deployment strategy. The research evaluates intrinsic biases in pre-trained Mistral, Falcon, and Llama models and compares them to biases observed when the same models are adapted via zero- and few-shot prompting on a pronoun co-reference resolution task using the WinoBias dataset.

The primary findings demonstrate that intrinsic biases are strongly correlated with adapted biases (rho ≥ 0.94) across all models and prompting strategies. This correlation remains strong (rho ≥ 0.92) even when models are specifically prompted to exhibit fair or biased behavior. Additionally, varying the number of few-shot examples and their stereotypical composition does not significantly affect the bias correlation (rho ≥ 0.97). The results demonstrate that fairness in pre-trained models is crucial, as biases persist through prompt-based adaptations.

## Method Summary
The study evaluates gender bias transfer by first measuring intrinsic biases in pre-trained Mistral, Falcon, and Llama models through next-token generation on the WinoBias dataset. Then, the same models are adapted using zero-shot and few-shot prompting for pronoun co-reference resolution. Selection Bias (SB) is used as a unified metric to measure both intrinsic and adapted biases. The research varies few-shot example counts (3, 10, 20, 30) and stereotypical composition while maintaining random option ordering in prompts. Bias transfer is quantified using Pearson correlation coefficients between intrinsic and adapted SB values across five random seeds for statistical robustness.

## Key Results
- Intrinsic biases in pre-trained models strongly correlate with adapted biases across all models and prompting strategies (rho ≥ 0.94)
- Bias transfer remains strongly correlated even when models are specifically prompted to exhibit fair or biased behavior (rho ≥ 0.92)
- Varying few-shot example count and stereotypical composition does not significantly affect bias correlation (rho ≥ 0.97)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Biases in pre-trained LLMs persist and transfer strongly to prompt-adapted models.
- Mechanism: Prompting reuses the internal representation space of the pre-trained model without altering its learned weights, so pre-existing biases in the representation space remain active during inference.
- Core assumption: The internal representation space retains bias patterns even when task-specific input is provided via prompt.
- Evidence anchors:
  - [abstract] "intrinsic biases in pre-trained Mistral, Falcon and Llama models are strongly correlated (ρ ≥ 0.94) with biases when the same models are zero- and few-shot prompted"
  - [section] "intrinsic biases are strongly correlated with adapted biases (rho ≥ 0.94) across all models and prompting strategies"
  - [corpus] No direct corpus evidence for mechanism; weak anchor.
- Break condition: If prompt-induced activation of internal representations bypasses bias-carrying subspaces (e.g., via targeted prefix-tuning), correlation could drop.

### Mechanism 2
- Claim: Prompt composition (number of few-shot examples, stereotypical makeup) does not significantly alter bias transfer.
- Mechanism: The model's decision boundary for gender-stereotyped occupations is already heavily shaped by pre-training, so limited few-shot context cannot override that learned bias structure.
- Core assumption: Few-shot context provides insufficient gradient signal to reshape deep internal biases.
- Evidence anchors:
  - [abstract] "varying the number of few-shot examples and their stereotypical composition does not significantly affect the bias correlation (rho ≥ 0.97)"
  - [section] "few-shot length and stereotypical composition are varied (rho ≥ 0.97)" and "few-shot composition choices ... do not have a significant effect on bias correlation"
  - [corpus] No direct corpus evidence for mechanism; weak anchor.
- Break condition: If few-shot context is dramatically expanded (hundreds of examples) or interleaved with targeted bias correction, the correlation could weaken.

### Mechanism 3
- Claim: Prompting the model to be explicitly fair or biased shifts bias magnitude but not the underlying correlation pattern.
- Mechanism: The pre-trained model's internal bias structure sets a baseline correlation; explicit prompts adjust the mean bias but the relative ranking of occupations remains consistent.
- Core assumption: Bias-inducing prompts modulate bias intensity but do not alter the fundamental structure of the model's bias representation.
- Evidence anchors:
  - [abstract] "bias transfer remains strongly correlated even when LLMs are specifically prompted to exhibit fair or biased behavior (rho ≥ 0.92)"
  - [section] "bias transfer remains strongly correlated even when LLMs are specifically prompted to exhibit fair or biased behavior (rho ≥ 0.92)"
  - [corpus] No direct corpus evidence for mechanism; weak anchor.
- Break condition: If prompts introduce strong adversarial training signals that overwrite internal bias structure, the correlation could break.

## Foundational Learning

- Concept: Pearson correlation coefficient (ρ) and its interpretation in bias studies
  - Why needed here: The paper's central claim relies on high Pearson correlations between intrinsic and adapted biases to argue for bias transfer.
  - Quick check question: If two variables have ρ = 0.95, what does that say about their linear relationship and why is that relevant for bias transfer?

- Concept: Selection Bias (SB) metric for fairness evaluation
  - Why needed here: SB is used as a unified metric across intrinsic and prompt-adapted evaluations, enabling fair comparison of bias magnitude.
  - Quick check question: How does SB differ from accuracy-based fairness metrics, and why is that important when comparing intrinsic vs adapted biases?

- Concept: WinoBias dataset structure (ambiguous vs unambiguous sentences, pro/anti-stereotypical contexts)
  - Why needed here: Understanding the dataset's design is critical to interpreting why certain occupations show higher bias and how task ambiguity affects results.
  - Quick check question: Why might ambiguous sentences show higher selection bias than unambiguous ones in the context of pronoun co-reference resolution?

## Architecture Onboarding

- Component map:
  Pre-trained LLM -> Prompt formatter -> WinoBias dataset loader -> SB metric calculator -> RPA calculator -> Correlation engine

- Critical path:
  1. Load pre-trained model and WinoBias data
  2. Generate intrinsic SB (next-token generation)
  3. Generate prompt-adapted SB (zero/few-shot)
  4. Compute SB for each condition
  5. Calculate Pearson correlation between intrinsic and adapted SB

- Design tradeoffs:
  - Using next-token generation for intrinsic evaluation vs MLM masked token prediction (causal vs non-causal)
  - Randomizing prompt option order to reduce ordering bias vs fixed order for reproducibility
  - Using five random seeds for statistical robustness vs single seed for speed

- Failure signatures:
  - Low or negative correlation (ρ < 0.5) would invalidate the bias transfer claim
  - High SB variance across seeds would indicate instability
  - RPA much lower for anti-stereotypical sentences would indicate strong stereotypical bias

- First 3 experiments:
  1. Reproduce intrinsic SB for all three models and verify correlation > 0.94 with adapted SB
  2. Vary few-shot example count (3, 10, 20, 30) and verify correlation remains > 0.97
  3. Apply fairness-inducing prompt and verify SB decreases but correlation with intrinsic remains > 0.92

## Open Questions the Paper Calls Out
- The authors identify the need for constructing unambiguously gender neutral fairness datasets as an important opportunity, acknowledging that their bias evaluations are limited to the WinoBias dataset which only captures binary gender categories.
- They note that while they demonstrate improvements in selection bias through fairness-inducing prompts, they did not qualitatively assess if these improvements come at the cost of other desirable model behaviors such as low toxicity or other harms, leaving this as future work.
- The paper mentions plans to scale up evaluations to other adaptation strategies such as low-rank and full-parameter fine-tuning, which were not investigated in this study.

## Limitations
- The study focuses exclusively on gender bias in pronoun co-reference resolution using the WinoBias dataset, potentially limiting generalizability to other bias types or tasks.
- The analysis relies on a single fairness metric (Selection Bias) that may miss other manifestations of bias beyond occupation selection disparity.
- The work does not investigate whether prompt adaptation techniques beyond zero- and few-shot prompting would show similar bias transfer patterns.

## Confidence
- **High confidence**: The core claim that intrinsic biases strongly correlate with prompt-adapted biases (ρ ≥ 0.94) across multiple models and prompting strategies
- **Medium confidence**: The finding that varying few-shot composition and length does not significantly affect bias correlation
- **Medium confidence**: The claim that fairness in pre-trained models is crucial because biases persist through prompt-based adaptations

## Next Checks
1. **Cross-bias generalization test**: Replicate the correlation analysis using a different bias type (racial, cultural, or intersectional) and a different task (sentiment analysis, text classification) to determine if the strong bias transfer pattern holds beyond gender pronoun co-reference resolution.

2. **Adaptation method comparison**: Implement and evaluate alternative prompt adaptation techniques such as prefix-tuning or adapter-based methods to test whether these parameter-efficient fine-tuning approaches show weaker bias transfer correlations compared to zero- and few-shot prompting.

3. **Debiasing intervention study**: Apply a debiasing procedure to the pre-trained models (such as counterfactual data augmentation or bias-specific fine-tuning) and measure whether this intervention successfully reduces both intrinsic and adapted biases, providing causal evidence that pre-trained model fairness directly impacts downstream task fairness.