---
ver: rpa2
title: 'Prompt Recovery for Image Generation Models: A Comparative Study of Discrete
  Optimizers'
arxiv_id: '2408.06502'
source_url: https://arxiv.org/abs/2408.06502
tags:
- prompt
- prompts
- image
- images
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work compares five approaches for prompt inversion in image
  generation models: PEZ, GCG, AutoDAN, Random Search, and PRISM against a BLIP2 captioner
  baseline. The study evaluates methods across multiple metrics including FID, KID,
  CLIP similarity, and text embedding similarity, using 100 prompts from Stable Diffusion''s
  DiffusionDB dataset.'
---

# Prompt Recovery for Image Generation Models: A Comparative Study of Discrete Optimizers

## Quick Facts
- arXiv ID: 2408.06502
- Source URL: https://arxiv.org/abs/2408.06502
- Authors: Joshua Nathaniel Williams; Avi Schwarzschild; Yutong He; J. Zico Kolter
- Reference count: 5
- Primary result: Discrete optimizers minimize CLIP objectives but fail to produce prompts that generate images similar to originals

## Executive Summary
This paper investigates prompt inversion in image generation models by comparing five discrete optimization approaches against baseline captioners. The study reveals that while discrete optimizers effectively minimize CLIP similarity objectives, they fail to produce prompts that generate images closely matching the original. Notably, trained captioners (PRISM and BLIP2) outperform all discrete optimizers in generating images similar to the originals. The work highlights that CLIP similarity is a poor proxy for actual image generation quality, suggesting a fundamental gap in how we model the relationship between prompts and generated images.

## Method Summary
The study evaluates five prompt inversion methods: PEZ, GCG, AutoDAN, Random Search, and PRISM, plus BLIP2 captioner baseline. Using 100 prompts from Stable Diffusion's DiffusionDB dataset, each method attempts to recover prompts from generated images through discrete optimization in CLIP embedding space. Methods are evaluated across FID, KID, CLIP similarity, and text embedding similarity metrics. The discrete optimizers use 3000 optimization steps (with early stopping), while captioners generate prompts directly. All methods generate 2 images per recovered prompt for evaluation against 10 baseline images per original prompt.

## Key Results
- Discrete optimizers effectively minimize CLIP objectives but produce poor image-to-image similarity
- PRISM and BLIP2 captioners outperform discrete optimizers in generating images similar to originals
- PEZ shows more consistent convergence compared to GCG and Random Search, which quickly find early solutions but struggle to improve further

## Why This Works (Mechanism)

### Mechanism 1
Discrete optimizers minimize CLIP similarity objectives effectively but this does not translate to good image-to-image similarity. The optimization process finds prompts that align well in CLIP embedding space with the target image, but CLIP embedding alignment is not a reliable proxy for the actual distribution of prompt-image pairs that the generative model uses. This occurs because CLIP's text-image alignment provides a good approximation of the prompt-image distribution relationship, but the assumption breaks if a better proxy for prompt-image distribution relationship is found.

### Mechanism 2
PEZ shows more consistent convergence compared to GCG and Random Search because it uses projected gradient descent in embedding space, which provides smoother optimization trajectory compared to the discrete search strategies of GCG and Random Search. The core assumption is that continuous optimization with projection to discrete space provides more stable descent than pure discrete search, but this breaks if the discrete search strategies are modified to have better exploration/exploitation balance.

### Mechanism 3
Captioning approaches (PRISM, BLIP2) outperform discrete optimizers in generating images similar to originals because trained captioners have learned the prompt-image distribution relationship directly from data, providing better approximations than optimizing proxy objectives. This assumes that models trained on prompt-image pairs learn better representations of the prompt-image distribution than proxy-based optimization, but breaks if discrete optimizers can incorporate better priors or models of the prompt-image distribution.

## Foundational Learning

- **Discrete optimization over token sequences**: Why needed here - Prompt inversion requires finding discrete token sequences that generate specific images. Quick check: What is the constraint on valid prompts in terms of token selection?
- **CLIP embedding space as proxy objective**: Why needed here - Direct optimization through the generative model is computationally prohibitive. Quick check: Why can't we directly optimize through the diffusion model?
- **Image-to-image similarity metrics (FID, KID)**: Why needed here - To evaluate how well inverted prompts reproduce the original image distribution. Quick check: What does a low KID score indicate about prompt similarity?

## Architecture Onboarding

- **Component map**: Tokenizer -> CLIP encoder -> Generative model (Stable Diffusion) -> Optimizers (PEZ, GCG, AutoDAN, Random Search) -> Captioners (BLIP2, PRISM)
- **Critical path**: 1) Sample prompt from DiffusionDB, 2) Generate baseline images using Stable Diffusion, 3) Apply each inversion method to recover prompt, 4) Generate images using recovered prompts, 5) Compute evaluation metrics across all methods
- **Design tradeoffs**: Computational cost vs. optimization quality (CLIP-based vs direct optimization), prompt length vs. quality (fixed length vs variable length approaches), search strategy (gradient-based vs discrete search vs learned models)
- **Failure signatures**: Poor image-to-image similarity despite good CLIP similarity indicates proxy mismatch, convergence plateaus early suggest optimizer limitations, unnatural language in recovered prompts indicates need for language priors
- **First 3 experiments**: 1) Compare FID/KID scores of all methods on a small validation set to identify best performers, 2) Analyze convergence curves for each optimizer to understand optimization dynamics, 3) Qualitative inspection of recovered prompts and generated images to understand quality differences

## Open Questions the Paper Calls Out

### Open Question 1
Why does GCG perform similarly to random search despite using gradient information? The authors note this as an open question without providing a definitive answer, suggesting this could be due to the loss landscapes or optimization strategies, but don't resolve why gradient information yields minimal improvement. Comparative experiments isolating different components of GCG against pure random search could identify which aspects contribute to their similar performance.

### Open Question 2
Why is there such a stark performance difference between PEZ and GCG at prompt inversion compared to their relative performance in jailbreaking LLMs? The authors acknowledge this contradiction but don't explain the underlying reasons for why these optimizers perform differently in the two contexts. Systematic comparison of loss landscapes, optimization trajectories, and solution qualities for both tasks using both optimizers could reveal whether differences stem from model architectures, loss functions, or other factors.

### Open Question 3
Why do discrete optimizers produce non-human-readable prompts despite achieving good CLIP similarity scores? The paper doesn't explain why optimizing for CLIP similarity leads to token sequences that are mathematically optimized but linguistically incoherent, while methods like PRISM produce more natural language. Analysis of the token distributions, semantic coherence metrics, and human evaluations of generated prompts across methods could clarify whether this is due to optimization objectives, search strategies, or fundamental limitations of discrete optimization in this space.

## Limitations

- Fixed-length prompt constraint across all methods (75 tokens) potentially limiting recovery quality
- Early stopping of optimization processes may not have allowed sufficient exploration of solution space
- Heavy reliance on CLIP-based metrics which the paper itself shows to be imperfect proxies for generation quality

## Confidence

- **High confidence**: Discrete optimizers effectively minimize CLIP objectives while failing to produce good image-to-image similarity
- **Medium confidence**: Trained captioners (PRISM, BLIP2) outperform discrete optimizers in generating similar images
- **Medium confidence**: PEZ's more consistent convergence compared to GCG and Random Search

## Next Checks

1. **Proxy Validation Study**: Design an ablation study testing different proxy objectives beyond CLIP similarity to identify better optimization targets for prompt inversion.

2. **Variable Length Analysis**: Implement and evaluate variable-length prompt recovery using AutoDAN to determine whether fixed-length constraints significantly limit recovery quality.

3. **Cross-Dataset Generalization**: Test recovered prompts across different generative models (SDXL, Midjourney) to assess whether inverted prompts generalize beyond the original generation model.