---
ver: rpa2
title: Neural Algorithmic Reasoning with Multiple Correct Solutions
arxiv_id: '2409.06953'
source_url: https://arxiv.org/abs/2409.06953
tags:
- solutions
- graph
- algorithm
- vertex
- parent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the first method for neural algorithmic reasoning
  (NAR) with multiple correct solutions, addressing the limitation of standard NAR
  models that predict only single solutions even when multiple valid outputs exist.
  The approach involves training neural networks to predict distributions of solutions
  by running classical algorithms multiple times with randomized tie-breaking, then
  extracting multiple solutions from these distributions using algorithm-specific
  stochastic sampling methods.
---

# Neural Algorithmic Reasoning with Multiple Correct Solutions

## Quick Facts
- arXiv ID: 2409.06953
- Source URL: https://arxiv.org/abs/2409.06953
- Reference count: 40
- The paper introduces the first method for neural algorithmic reasoning with multiple correct solutions, successfully extracting multiple valid solutions for Bellman-Ford on small graphs within training distribution

## Executive Summary
This paper addresses a fundamental limitation in neural algorithmic reasoning (NAR) where standard models predict only single solutions even when multiple valid outputs exist for graph problems. The authors introduce a novel framework that trains neural networks to predict distributions of solutions by running classical algorithms multiple times with randomized tie-breaking, then extracting multiple solutions from these distributions using algorithm-specific stochastic sampling methods. Experiments on Bellman-Ford and Depth-First Search algorithms demonstrate the feasibility of this approach, with perfect accuracy on 5-vertex graphs and high diversity on 64-vertex graphs for Bellman-Ford, though DFS proves significantly more challenging.

## Method Summary
The method involves training NAR models to predict probability distributions over solutions rather than single outputs. Classical algorithms like Bellman-Ford and DFS are run multiple times (20 in experiments) with randomized tie-breaking to generate empirical distributions of valid solutions. The neural network is trained using KL-divergence loss to match these empirical distributions. For inference, algorithm-specific stochastic sampling methods (Beam Search for Bellman-Ford, Upwards Sampling for DFS) extract multiple valid solutions from the predicted distributions. The approach uses the CLRS MPNN architecture and evaluates performance using graph-level accuracy and solution diversity metrics.

## Key Results
- Successfully extracts multiple correct solutions for Bellman-Ford on small graphs within training distribution with perfect accuracy on 5-vertex graphs
- Demonstrates high diversity of extracted solutions (86% for 64-vertex graphs) for Bellman-Ford
- Shows significant performance degradation for larger graphs and extremely low accuracy rates for DFS across all tested sizes
- Proves feasibility of neural algorithmic reasoning with multiple solutions, particularly for shortest path problems within training size ranges

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model can predict distributions of solutions by averaging multiple randomized runs of classical algorithms
- Mechanism: By running classical algorithms like Bellman-Ford and DFS multiple times with randomized tie-breaking, the paper generates empirical distributions of valid solutions. The neural network is then trained to minimize KL-divergence between its predicted distribution and these empirical distributions
- Core assumption: Multiple randomized runs of classical algorithms produce representative samples from the true distribution of solutions
- Evidence anchors:
  - [abstract]: "training neural networks to predict distributions of solutions by running classical algorithms multiple times with randomized tie-breaking"
  - [section 2.1.1]: "We generate an empirical parent distribution P for each graph...by running our randomized version of DFS 20 times"
  - [corpus]: Weak evidence - related papers focus on NAR improvements but don't directly validate distribution learning

### Mechanism 2
- Claim: Stochastic sampling methods can extract multiple valid solutions from the predicted distribution
- Mechanism: Algorithm-specific sampling methods (like Upwards Sampling for DFS and Beam Search for Bellman-Ford) extract solutions by probabilistically selecting parents according to the predicted distribution, mimicking the structure of the original algorithm
- Core assumption: The predicted distribution preserves enough structure to allow valid solution extraction through stochastic methods
- Evidence anchors:
  - [abstract]: "extracting multiple solutions from these distributions using algorithm-specific stochastic sampling methods"
  - [section 2.1.2]: "Our two main methods sample a parent for each vertex in a way that strives to emulate the structure of a DFS traversal"
  - [corpus]: Moderate evidence - related work on NAR mentions sampling but focuses on single solutions

### Mechanism 3
- Claim: Graph-level accuracy is a more appropriate metric than node-level accuracy for evaluating multiple-solution NAR
- Mechanism: Graph accuracy only scores solutions as correct if they are valid outputs of the original algorithm, avoiding the problem where partial matches get inflated scores when multiple correct solutions exist
- Core assumption: In multi-solution settings, distinguishing between completely correct and partially correct solutions requires stricter evaluation
- Evidence anchors:
  - [section 3]: "we use 'graph' accuracy...scores a solution S as correct for a graph G and algorithm A if and only if S ← A(G) for some run of A"
  - [section E]: "With multiple solutions, node level accuracy is poorly defined"
  - [corpus]: Weak evidence - related NAR papers use node accuracy, suggesting this is a novel contribution

## Foundational Learning

- Concept: KL-divergence as loss function for distribution learning
  - Why needed here: The model needs to learn to predict a probability distribution over solutions rather than a single output, requiring a loss that measures distribution similarity
  - Quick check question: Why can't we use mean squared error when the target is a probability distribution?

- Concept: Randomized algorithm tie-breaking for solution space exploration
  - Why needed here: Deterministic algorithms only produce one solution per input, but many graph problems have multiple valid solutions that need to be captured for training
  - Quick check question: What happens to the empirical distribution if we only run the randomized algorithm twice instead of 20 times?

- Concept: Graph isomorphism and solution equivalence
  - Why needed here: When evaluating multiple solutions, we need to determine whether different outputs represent genuinely distinct solutions or just isomorphic variants
  - Quick check question: How would you check if two DFS solutions are isomorphic?

## Architecture Onboarding

- Component map: Graph -> Encoder (Linear layer) -> Processor (MPNN with gating and triplet reasoning) -> Decoder (4 Linear layers) -> Distribution -> Sampling -> Solution validation

- Critical path: Graph → Encoder → Processor (MPNN) → Decoder → Distribution → Sampling → Solution validation

- Design tradeoffs:
  - Distribution learning vs single solution prediction: More expressive but harder to train and evaluate
  - Number of algorithm reruns: More reruns give better empirical distributions but increase training time
  - Sampling method complexity: More sophisticated methods may extract better solutions but are harder to implement and debug

- Failure signatures:
  - Low diversity in extracted solutions despite high KL-divergence: Model learned wrong distribution
  - High KL-divergence but low accuracy: Sampling method failing to extract valid solutions
  - Perfect training accuracy but poor generalization: Overfitting to training distribution size

- First 3 experiments:
  1. Train on 5-vertex graphs, extract solutions, verify all are valid using algorithm-specific validation
  2. Compare diversity of solutions from predicted vs empirical distributions on same graphs
  3. Test model on 64-vertex graphs to evaluate out-of-distribution generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method scale to larger graphs beyond the training distribution (e.g., n > 64)?
- Basis in paper: [explicit] The paper shows performance degradation for Bellman-Ford on larger graphs (n=64) and complete failure for DFS beyond training sizes, with authors noting "performance degrades for larger graphs and DFS proves significantly more challenging."
- Why unresolved: The paper only tests up to n=64 graphs, and results show significant accuracy drops and low solution diversity on larger graphs, but doesn't explore techniques to improve scaling.
- What evidence would resolve it: Experiments showing the method's performance on much larger graphs (n=128, 256, 512) with improved sampling techniques or architectural modifications to handle larger problem sizes.

### Open Question 2
- Question: What is the optimal number of algorithm re-runs needed to generate training distributions that balance computational cost and distribution accuracy?
- Basis in paper: [explicit] The paper states "we conclude from our results in Appendix B that 20 runs provide a good approximation" but also shows pairwise KL-divergence comparisons between 20, 50, and 100 runs, indicating uncertainty about the optimal choice.
- Why unresolved: The paper settles on 20 runs based on computational efficiency but doesn't systematically explore the tradeoff between distribution accuracy and computational cost across different graph sizes and algorithms.
- What evidence would resolve it: A comprehensive analysis showing KL-divergence convergence rates for different numbers of runs across multiple graph sizes and algorithms, coupled with training accuracy and inference speed metrics.

### Open Question 3
- Question: Why is Depth-First Search significantly more challenging than Bellman-Ford for neural algorithmic reasoning with multiple solutions?
- Basis in paper: [explicit] The paper notes "DFS proves significantly more challenging, with very low accuracy rates" and hypothesizes that "training a model to fit a distribution of solutions does not directly optimize for correct solutions" and that "there are fewer correct solutions to the single-source shortest path problem... than there are valid depth-first traversals."
- Why unresolved: The paper provides hypotheses but doesn't conduct systematic experiments to isolate whether the difficulty stems from solution encoding, sampling methods, or fundamental differences between the problems' solution spaces.
- What evidence would resolve it: Controlled experiments comparing solution space properties, alternative encoding methods, and modified sampling techniques for DFS specifically, with ablation studies to identify the root cause of the performance gap.

## Limitations

- Significant performance degradation on larger graphs (n=64) despite good performance on training sizes
- Extremely low accuracy rates for DFS across all tested graph sizes, indicating fundamental challenges
- Uncertainty about whether 20 algorithm reruns sufficiently capture the full solution space, especially for larger graphs

## Confidence

**High Confidence:**
- The framework for training NAR models to predict solution distributions is technically sound and implementable
- Graph-level accuracy is indeed a more appropriate metric than node-level accuracy for multiple-solution settings
- The Upwards and Beam search sampling methods correctly extract solutions from the predicted distributions for Bellman-Ford on small graphs

**Medium Confidence:**
- The model successfully learns to predict distributions that contain multiple valid solutions for Bellman-Ford
- The diversity metrics accurately reflect the variety of solutions extracted from model predictions
- The approach provides a viable foundation for future research in multiple-solution NAR

**Low Confidence:**
- The approach generalizes effectively to larger graphs beyond the training distribution
- The sampling methods successfully extract multiple valid solutions for DFS
- The current architecture (CLRS MPNN) is optimal for learning solution distributions

## Next Checks

1. **Scale-robustness validation**: Systematically evaluate model performance across graph sizes 5-128 with logarithmic spacing to precisely quantify the scaling behavior and identify the threshold where performance degrades. Compare KL-divergence and accuracy metrics to determine if the issue is with distribution prediction or sampling extraction.

2. **Sampling method ablation study**: Test the sampling methods directly on empirical distributions (P) rather than model predictions to isolate whether low accuracy stems from poor model predictions or ineffective sampling. This would validate the core assumption that algorithm-specific sampling can extract valid solutions from probability distributions.

3. **Training distribution expansion**: Increase the maximum training graph size from 16 to 32-64 vertices and evaluate whether this improves generalization to larger test graphs. Additionally, test whether increasing the number of randomized algorithm runs from 20 to 50-100 improves distribution quality and downstream model performance.