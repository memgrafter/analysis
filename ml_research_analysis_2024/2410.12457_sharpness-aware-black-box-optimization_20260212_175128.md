---
ver: rpa2
title: Sharpness-Aware Black-Box Optimization
arxiv_id: '2410.12457'
source_url: https://arxiv.org/abs/2410.12457
tags:
- sabo
- optimization
- function
- black-box
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of poor generalization in black-box
  optimization by proposing a novel Sharpness-Aware Black-box Optimization (SABO)
  algorithm. SABO applies a sharpness-aware minimization strategy to improve model
  generalization in black-box settings where gradients are unavailable.
---

# Sharpness-Aware Black-Box Optimization

## Quick Facts
- arXiv ID: 2410.12457
- Source URL: https://arxiv.org/abs/2410.12457
- Authors: Feiyang Ye; Yueming Lyu; Xuehao Wang; Masashi Sugiyama; Yu Zhang; Ivor Tsang
- Reference count: 40
- Primary result: Proposes SABO algorithm for improving generalization in black-box optimization by seeking flat minima in Gaussian distribution space

## Executive Summary
This paper introduces Sharpness-Aware Black-box Optimization (SABO), a novel algorithm that applies sharpness-aware minimization to improve generalization in black-box optimization settings where gradients are unavailable. SABO reparameterizes the objective function via its expectation over a Gaussian distribution and iteratively updates the parameterized distribution using approximated stochastic gradients of the maximum objective value within a small neighborhood. The method achieves convergence rates of O(log T/T) for full-batch queries and O(1/√T) for mini-batch queries, with a theoretical generalization error bound.

## Method Summary
SABO addresses black-box optimization by optimizing over the space of Gaussian distributions rather than the parameter space directly. The algorithm reparameterizes the objective function as the expected value over a Gaussian distribution and uses a sharpness-aware minimization strategy to seek flat minima. It iteratively updates the distribution parameters by computing approximated stochastic gradients and applying a perturbation-based update rule. The method is theoretically grounded with convergence rate proofs for both full-batch and mini-batch settings, along with a PAC-Bayesian generalization error bound.

## Key Results
- Achieves convergence rates of O(log T/T) for full-batch function queries and O(1/√T) for mini-batch queries
- Demonstrates improved generalization performance on synthetic numerical problems compared to CMA-ES, MMES, BES, and INGO
- Shows effectiveness in black-box prompt fine-tuning tasks, improving generalization in high-dimensional settings

## Why This Works (Mechanism)

### Mechanism 1
SABO improves generalization by seeking flat minima in the space of Gaussian distributions rather than in the parameter space. The method reparameterizes the objective function via its expectation over a Gaussian distribution and iteratively updates the parameterized distribution using approximated stochastic gradients of the maximum objective value within a small neighborhood. This works under the assumption that the Gaussian distribution space can be effectively optimized using sharpness-aware minimization to improve generalization.

### Mechanism 2
The proposed algorithm possesses convergence rates of O(log T/T) for full-batch function queries and O(1/√T) for mini-batch queries. This is achieved through the use of approximated stochastic gradients and a sharpness-aware minimization strategy to iteratively update the parameterized distribution, with theoretical convergence guarantees proven in both settings. The core assumption is that the reparameterized objective function is H-Lipschitz and L-smooth, and the gradient estimator is well-behaved.

### Mechanism 3
SABO provides a generalization error bound that improves upon standard SAM by considering perturbations in the space of Gaussian distributions. The bound is derived using PAC-Bayesian analysis, bounding the expected loss over the Gaussian perturbation rather than over parameter perturbations. This assumes the loss function is convex and the data is i.i.d. sampled from the data distribution.

## Foundational Learning

- Concept: Stochastic Gradient Approximation
  - Why needed here: SABO uses stochastic gradient approximation to estimate gradients of the reparameterized objective function without access to true gradients.
  - Quick check question: How does the stochastic gradient approximation method estimate the gradient of the expected fitness function J(θ)?

- Concept: Sharpness-Aware Minimization (SAM)
  - Why needed here: SABO applies the sharpness-aware minimization strategy to improve generalization by seeking flat minima in the space of Gaussian distributions.
  - Quick check question: What is the main difference between SAM and SABO in terms of the space they optimize over?

- Concept: PAC-Bayesian Analysis
  - Why needed here: The generalization error bound for SABO is derived using PAC-Bayesian analysis, which provides a framework for bounding the expected loss over the Gaussian perturbation.
  - Quick check question: How does PAC-Bayesian analysis differ from standard PAC analysis in terms of the prior and posterior distributions used?

## Architecture Onboarding

- Component map:
  - Objective function F(x) -> Gaussian distribution parameters θ = {µ, Σ} -> Expected fitness function J(θ) -> Neighborhood C(θ) -> Perturbation δ(θ) -> Gradient estimators g' and G'

- Critical path:
  1. Initialize Gaussian distribution parameters θ0 = (µ0, Σ0)
  2. Sample points from current distribution and query objective function
  3. Compute approximated stochastic gradients g' and G'
  4. Calculate perturbation δ(θ) using closed-form solution
  5. Update distribution parameters using gradient estimators and perturbation
  6. Repeat steps 2-5 until convergence or maximum iterations reached

- Design tradeoffs:
  - Full-batch vs. mini-batch function queries: Full-batch provides more accurate gradients but is computationally expensive, while mini-batch is more scalable but may have higher variance
  - Neighborhood size ρ: Larger ρ allows more exploration but may lead to instability, smaller ρ provides more stable updates but may get stuck in local minima
  - Diagonal covariance matrix assumption: Simplifies computation but may not capture full covariance structure of objective function

- Failure signatures:
  - Slow convergence or divergence: May indicate issues with gradient estimator, neighborhood size, or learning rate
  - Poor generalization performance: May indicate Gaussian distribution parameterization is not effective in capturing objective function structure
  - High variance in gradient estimator: May indicate mini-batch size is too small or objective function is noisy

- First 3 experiments:
  1. Test SABO on simple synthetic function with known optimal solution to verify convergence and compare with baseline methods
  2. Test SABO on high-dimensional black-box prompt fine-tuning task to evaluate effectiveness in improving generalization performance
  3. Test SABO with different neighborhood sizes and learning rates to study impact on convergence and generalization performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the SABO algorithm's performance scale with increasing dimensionality of the search space in black-box optimization problems? The paper mentions SABO maintains good performance in high-dimensional settings with dimensions d ∈ {200, 500, 1000}, but lacks comprehensive analysis of scaling behavior beyond 1000 or below 100 dimensions.

### Open Question 2
What is the impact of the choice of statistical distance (other than KL divergence) on the performance of SABO in the distribution space? The paper uses KL divergence to define the neighborhood around a given distribution, but does not explore alternative statistical distances or their effects on algorithm performance.

### Open Question 3
How does SABO perform in comparison to other sharpness-aware methods when applied to non-convex objective functions in black-box optimization? The paper proves convergence rates for SABO with convex objective functions but does not provide empirical or theoretical results for non-convex cases.

## Limitations
- Theoretical analysis assumes objective function is H-Lipschitz and L-smooth, which may not hold for all black-box optimization problems
- Diagonal covariance matrix assumption simplifies computation but may not capture full covariance structure of complex objective functions
- Perturbation-based update rule is computationally intensive, requiring solving maximization subproblem at each iteration

## Confidence

- **High confidence** in convergence rate claims (O(log T/T) for full-batch, O(1/√T) for mini-batch) due to rigorous theoretical analysis and proofs
- **Medium confidence** in generalization error bound claim due to simplifying assumptions (convex loss function, i.i.d. data) that may not hold in practice
- **Medium confidence** in empirical effectiveness claims as experiments are limited to synthetic numerical problems and single black-box prompt fine-tuning task

## Next Checks

1. Test SABO on diverse set of black-box optimization problems, including non-convex functions and functions with non-i.i.d. data, to validate robustness of convergence rates and generalization bounds

2. Conduct extensive ablation studies on impact of different hyperparameters (learning rate, neighborhood size, mini-batch size) on algorithm's convergence and generalization performance

3. Compare SABO's performance with other state-of-the-art black-box optimization methods (e.g., Bayesian optimization, evolution strategies) on wider range of tasks to establish relative effectiveness