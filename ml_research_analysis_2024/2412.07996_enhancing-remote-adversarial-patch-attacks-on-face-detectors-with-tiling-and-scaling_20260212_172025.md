---
ver: rpa2
title: Enhancing Remote Adversarial Patch Attacks on Face Detectors with Tiling and
  Scaling
arxiv_id: '2412.07996'
source_url: https://arxiv.org/abs/2412.07996
tags:
- face
- detection
- patch
- patches
- uni0000000f
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Remote Adversarial Patch
  (RAP) attacks on face detectors, which is more difficult than on general object
  detectors due to the need to detect objects of various scales and the limited number
  of classification classes. The authors propose a novel method that involves scaling
  and tiling processes for patch placement, along with a new loss function called
  Borderline False Positive Loss.
---

# Enhancing Remote Adversarial Patch Attacks on Face Detectors with Tiling and Scaling

## Quick Facts
- arXiv ID: 2412.07996
- Source URL: https://arxiv.org/abs/2412.07996
- Reference count: 16
- This paper proposes a novel method that demonstrates superior detection obstruct effects on face detectors compared to patches targeting general object detectors, with consistent obstruction performance across datasets with varying face scales.

## Executive Summary
This paper addresses the challenge of Remote Adversarial Patch (RAP) attacks on face detectors, which is more difficult than on general object detectors due to the need to detect objects of various scales and the limited number of classification classes. The authors propose a novel method that involves scaling and tiling processes for patch placement, along with a new loss function called Borderline False Positive Loss. The scaling process adjusts the size of patches to correspond with different face scales during training, while the tiling process ensures that any cropped region of the image will contain part of a patch. The proposed method demonstrates superior detection obstruct effects compared to patches targeting general object detectors, with consistent obstruction performance across datasets with varying face scales.

## Method Summary
The proposed method enhances RAP attacks on face detectors by introducing scaling and tiling processes for patch placement. The scaling process adjusts patch size proportionally to face area using a scaling factor, maintaining a consistent relative area ratio across training images. The tiling process replicates and tiles the patch across the image, ensuring any cropped region contains part of a patch and removing dependence on patch placement coordinates. A new Borderline False Positive Loss function is designed to increase false positives near true faces without forcing class misclassification, specifically targeting the two-class nature of face detection. The method is optimized using Nesterov Iterative Fast Gradient Sign Method (NI-FGSM) to minimize the proposed loss function.

## Key Results
- The proposed method demonstrates superior detection obstruct effects compared to patches targeting general object detectors.
- The method shows consistent obstruction performance across datasets with varying face scales.
- The proposed method can effectively obstruct face detection while maintaining robustness to face scale variation.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Scaling patches relative to face size ensures consistent obstruction across face scales.
- Mechanism: Patch size is adjusted proportionally to face area using a scaling factor derived from face and patch dimensions, so the relative area ratio is maintained across training images.
- Core assumption: Maintaining a consistent relative area between patch and face is sufficient for effective obstruction regardless of absolute face size.
- Evidence anchors:
  - [abstract] "The scaling process adjusts the size of patches to correspond with different face scales during training, enhancing optimization across varying scales."
  - [section] "By making the scaling function S align the area ratio of patches and faces, it encourages patches to be able to obstruct faces of various scales uniformly during learning."

### Mechanism 2
- Claim: Tiling patches across the image ensures obstruction is position-invariant.
- Mechanism: Patch is replicated and tiled across the image so any cropped region will contain part of a patch, removing dependence on patch placement coordinates.
- Core assumption: Including patch pixels in any detected face region is sufficient to disrupt detection, regardless of exact face location.
- Evidence anchors:
  - [abstract] "The tiling process ensures that any cropped region of the image will contain part of a patch."
  - [section] "Reducing the dependence of face detection on face position by ensuring that the pixels of the patch are included when any face in any area is extracted as a feature."

### Mechanism 3
- Claim: Borderline False Positive Loss increases false positives near true faces without forcing class misclassification.
- Mechanism: Loss is applied when IoU between detection and ground truth is between two thresholds, increasing confidence for borderline detections to push them into FP.
- Core assumption: Increasing confidence of near-boundary detections is more effective than forcing hard misclassification in a two-class problem.
- Evidence anchors:
  - [abstract] "The Borderline False Positive Loss is designed to increase the number of false positives near the true face region and to disturb the coordinates of the true face."
  - [section] "Lbf pc(gi, ˜di) = −MX j=0 bij ∗ log(1 − ˜pij)." and "bij is a borderline judgment variable that is 1 when the inference result for the image with the patch added, ˜dij, is θT > a ij ≥ θF , which is the boundary between TP and FP, and 0 otherwise."

## Foundational Learning

- Concept: IoU (Intersection over Union) and its role in object detection evaluation.
  - Why needed here: Used to define TP/FP/FN and thresholds for loss calculation.
  - Quick check question: What IoU threshold is used to classify a detection as a True Positive in the experiments?

- Concept: Adversarial patch optimization via gradient-based methods.
  - Why needed here: Patch is optimized using Nesterov Iterative Fast Gradient Sign Method to minimize the proposed loss.
  - Quick check question: Which optimization method is used to train the adversarial patch in the proposed method?

- Concept: Two-class classification challenges in face detection vs. multi-class object detection.
  - Why needed here: Explains why traditional adversarial patch attacks are less effective on face detectors.
  - Quick check question: How many classes are involved in face detection compared to general object detection?

## Architecture Onboarding

- Component map: Input image -> Scaling function (S) -> Tiling function (T) -> Adversarial patch application (A) -> Face detector (F) -> Loss computation (Lbf pc) -> Patch optimization loop.
- Critical path: Image -> S(P,gi) -> T(Ii, S(P,gi)) -> A(Ii, gi, P) -> F(˜Ii) -> Lbf pc(gi, ˜di) -> Gradient update -> P.
- Design tradeoffs:
  - Scaling vs. fixed patch size: Scaling adapts to face size but may reduce obstruction for very small faces if patch becomes too small.
  - Tiling vs. single patch: Tiling increases coverage but may dilute patch strength per location.
  - Borderline FP loss vs. standard adversarial loss: Targets FP increase without forcing class change, but may be less aggressive.
- Failure signatures:
  - Patch fails on small faces -> scaling factor too aggressive or patch resolution too low.
  - Patch only works when centered -> tiling coverage insufficient or patch strength too localized.
  - Loss value stuck at zero -> IoU never enters [θF, θT) range during optimization.
- First 3 experiments:
  1. Verify scaling preserves relative patch-face area across a range of face sizes in a synthetic dataset.
  2. Test tiling coverage by applying patch to images with faces at various positions and checking FP distribution.
  3. Validate Borderline False Positive Loss increases FP count without changing class labels by running ablation with and without the loss.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Borderline False Positive Loss function perform when applied to face detection models with more than two classification classes?
- Basis in paper: [explicit] The paper mentions that face detection is a two-class classification problem, and the proposed loss function is designed to handle this specific case.
- Why unresolved: The paper does not provide experimental results or theoretical analysis on how the loss function would perform with multi-class classification models.
- What evidence would resolve it: Experiments comparing the performance of the Borderline False Positive Loss function on multi-class face detection models with other loss functions.

### Open Question 2
- Question: What is the optimal scaling parameter α for different face detection datasets and models?
- Basis in paper: [explicit] The paper mentions that the scaling parameter α is set to 5.58 based on empirical results, but does not explore its optimal value for different datasets or models.
- Why unresolved: The paper does not provide a systematic analysis of how the scaling parameter affects the performance of the proposed method on different datasets and models.
- What evidence would resolve it: A comprehensive study on the effect of different scaling parameter values on the performance of the proposed method across various face detection datasets and models.

### Open Question 3
- Question: How does the proposed method perform against face detection models that use different architectures or training techniques?
- Basis in paper: [explicit] The paper evaluates the proposed method against three different face detection models (MTCNN, S3FD, and RetinaFace) but does not explore the performance against models with different architectures or training techniques.
- Why unresolved: The paper does not provide experimental results or theoretical analysis on how the proposed method would perform against face detection models with different architectures or training techniques.
- What evidence would resolve it: Experiments comparing the performance of the proposed method against face detection models with different architectures or training techniques, such as transformer-based models or models trained with different data augmentation techniques.

## Limitations
- The scaling mechanism's effectiveness for very small faces is questionable, as the paper does not explicitly address the minimum face size threshold where patch obstruction becomes ineffective.
- The tiling approach assumes that covering any cropped region is sufficient, but this may not hold for face detectors that use global context.
- The Borderline False Positive Loss, while theoretically sound, lacks extensive ablation studies showing its superiority over simpler loss functions.

## Confidence
- **High**: The proposed scaling and tiling mechanisms improve patch effectiveness on face detectors compared to fixed-size patches (supported by F-score and AP metrics showing consistent obstruction across datasets with varying face scales).
- **Medium**: The Borderline False Positive Loss effectively increases false positives near true faces without forcing misclassification (supported by loss function definition and its role in optimization, but limited ablation studies).
- **Low**: The method generalizes well to real-world scenarios and maintains effectiveness across all face scales (claimed based on consistent obstruction performance across datasets, but no real-world validation or minimum face size analysis provided).

## Next Checks
1. Conduct experiments to determine the minimum face size threshold where patch obstruction becomes ineffective, varying the scaling factor α systematically.
2. Perform ablation studies comparing the Borderline False Positive Loss against standard adversarial loss functions in terms of FP increase and overall obstruction effectiveness.
3. Validate the method's robustness to different face detector architectures (e.g., RetinaFace, MTCNN) beyond S3FD to assess generalization.