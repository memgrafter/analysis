---
ver: rpa2
title: Towards Robust Few-shot Class Incremental Learning in Audio Classification
  using Contrastive Representation
arxiv_id: '2407.19265'
source_url: https://arxiv.org/abs/2407.19265
tags:
- base
- classes
- learning
- session
- audio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a supervised contrastive learning approach for
  few-shot class incremental audio classification, aiming to improve the discriminative
  power of learned representations. The method enhances base class separation using
  contrastive learning during base session training, followed by incremental session
  training using a stochastic classifier to dynamically update prototypes.
---

# Towards Robust Few-shot Class Incremental Learning in Audio Classification using Contrastive Representation

## Quick Facts
- arXiv ID: 2407.19265
- Source URL: https://arxiv.org/abs/2407.19265
- Reference count: 0
- Proposed method achieves state-of-the-art performance with AA of 91.41% and PD of 4.18% on LibriSpeech-100

## Executive Summary
This paper addresses the challenge of few-shot class incremental learning in audio classification, where models must learn to recognize new audio classes with limited samples while preserving performance on previously learned classes. The proposed approach combines supervised contrastive learning during base training to improve discriminative representations with a stochastic classifier that dynamically updates prototypes during incremental sessions. The method demonstrates strong performance across four diverse audio datasets, achieving state-of-the-art results with average accuracy above 91% on major benchmarks while maintaining low performance degradation rates.

## Method Summary
The proposed method employs a two-stage training approach for few-shot class incremental audio classification. During base session training, the model uses supervised contrastive learning to separate base classes, followed by cross-entropy loss for classification. For incremental sessions, a stochastic classifier is employed where prototypes are dynamically updated to accommodate new classes while preserving knowledge of existing ones. The model uses log-mel spectrograms as input features and ResNet18 as the backbone architecture. Training involves optimizing a joint loss combining supervised contrastive loss and cross-entropy loss during base training, then fine-tuning with the stochastic classifier during incremental sessions.

## Key Results
- Achieves AA of 91.41% with PD of 4.18% on LibriSpeech-100 dataset
- Achieves AA of 95.77% with PD of 8.27% on NSynth-100 dataset
- Demonstrates AA of 82.6% with PD of 21.5% on ESC-50 dataset
- Shows AA of 87.26% with PD of 23.93% on ESC-10 dataset

## Why This Works (Mechanism)
The method leverages supervised contrastive learning to create well-separated embeddings for base classes, which provides a strong foundation for incremental learning. By enhancing the discriminative power of representations before incremental sessions, the model can more effectively incorporate new classes with limited samples. The stochastic classifier dynamically updates prototypes during incremental sessions, allowing the model to adapt to new classes while maintaining knowledge of existing ones through a balanced joint loss optimization.

## Foundational Learning
- Supervised contrastive learning: Why needed - Creates discriminative embeddings by pulling similar samples together and pushing dissimilar samples apart; Quick check - Verify base class separation improves with increasing contrastive loss weight
- Few-shot learning: Why needed - Enables recognition of new classes with limited training examples; Quick check - Confirm performance on 1-5 shot scenarios
- Incremental learning: Why needed - Allows continuous learning of new classes without forgetting old ones; Quick check - Monitor accuracy degradation across incremental sessions
- Log-mel spectrograms: Why needed - Provides frequency-domain representation suitable for audio classification; Quick check - Ensure consistent spectrogram preprocessing across datasets
- Prototype-based classification: Why needed - Enables efficient class representation and updates during incremental learning; Quick check - Verify prototype stability during incremental sessions

## Architecture Onboarding
**Component map:** Audio input -> Log-mel spectrogram extraction -> ResNet18 backbone -> Supervised contrastive learning + Cross-entropy loss -> Stochastic classifier with prototype updates

**Critical path:** Input spectrograms → Backbone feature extraction → Prototype-based classification → Accuracy evaluation

**Design tradeoffs:** Uses ResNet18 for computational efficiency versus deeper architectures that might capture more complex patterns but require more data; balances supervised contrastive learning with cross-entropy to optimize both representation quality and classification accuracy

**Failure signatures:** Sharp accuracy drops in early incremental sessions indicate poor prototype initialization; consistently low accuracy across sessions suggests inadequate base class separation from contrastive learning

**First experiments:**
1. Train with only cross-entropy loss on base session and compare to full contrastive + CE approach
2. Vary the supervised contrastive loss weight (β) to identify optimal separation between base classes
3. Test different backbone architectures (e.g., ResNet34, EfficientNet) to evaluate impact on incremental learning performance

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does the performance of supervised contrastive learning (SCL) scale with varying levels of noise in audio data compared to cross-entropy (CE) loss?
- Basis in paper: The paper notes that CE has known limitations, including vulnerability to noisy labels, and suggests that SCL could address this issue.
- Why unresolved: The paper does not provide experimental results comparing SCL and CE under different noise conditions.
- What evidence would resolve it: Experimental results showing the performance of SCL and CE under controlled levels of label noise in audio classification tasks.

### Open Question 2
- Question: What is the impact of different backbone architectures (other than ResNet18) on the performance of the proposed SCL method in few-shot class incremental audio classification?
- Basis in paper: The paper uses ResNet18 as the backbone architecture for extracting embeddings.
- Why unresolved: The paper does not explore the effect of using alternative backbone architectures.
- What evidence would resolve it: Comparative experiments using different backbone architectures (e.g., EfficientNet, MobileNet) to evaluate their impact on SCL performance.

### Open Question 3
- Question: How does the proposed method perform in a more realistic setting where the incremental classes are not drawn from the same distribution as the base classes?
- Basis in paper: The paper assumes that incremental classes are sampled from the same distribution as base classes, which may not reflect real-world scenarios.
- Why unresolved: The paper does not test the method under distributional shifts between base and incremental classes.
- What evidence would resolve it: Experiments where incremental classes are drawn from a different distribution than base classes, measuring performance degradation and robustness.

## Limitations
- Missing critical implementation details including batch size, number of shots per class, and temperature parameter τ for contrastive loss
- Evaluation limited to four specific audio datasets without testing on additional benchmarks
- Lack of extensive ablation studies comparing alternative prototype update mechanisms

## Confidence
- High confidence in overall methodology and performance claims, supported by multiple dataset evaluations
- Medium confidence in reproducibility due to missing implementation details
- Medium confidence in novelty contribution, as the combination of supervised contrastive learning with stochastic classifiers for incremental learning is presented but not extensively compared to alternative approaches

## Next Checks
1. Implement the method with varying batch sizes (32, 64, 128) and temperature parameters (0.1, 0.5, 1.0) to identify optimal hyperparameters
2. Conduct ablation studies comparing the supervised contrastive learning stage against training with only cross-entropy loss on the base session
3. Test the approach on additional audio classification datasets (e.g., UrbanSound8K) to verify generalizability beyond the four evaluated datasets