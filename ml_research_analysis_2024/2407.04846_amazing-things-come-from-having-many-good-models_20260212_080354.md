---
ver: rpa2
title: Amazing Things Come From Having Many Good Models
arxiv_id: '2407.04846'
source_url: https://arxiv.org/abs/2407.04846
tags:
- rashomon
- learning
- machine
- effect
- many
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This perspective argues that acknowledging the Rashomon Effect\u2014\
  the phenomenon that many equally accurate models exist for a given dataset\u2014\
  fundamentally reshapes machine learning, especially for tabular data. By finding\
  \ and exploring the full Rashomon set, rather than just a single model, researchers\
  \ and practitioners gain access to simpler-yet-accurate models, better alignment\
  \ with user preferences (like fairness and monotonicity), and improved uncertainty\
  \ quantification."
---

# Amazing Things Come From Having Many Good Models

## Quick Facts
- arXiv ID: 2407.04846
- Source URL: https://arxiv.org/abs/2407.04846
- Reference count: 19
- Primary result: The Rashomon Effect—where many equally accurate models exist—enables simpler, fairer, and more interpretable models while eliminating the assumed accuracy-interpretability tradeoff

## Executive Summary
This perspective paper argues that the Rashomon Effect—the phenomenon that many equally accurate models exist for a given dataset—fundamentally reshapes machine learning practice, particularly for tabular data. By finding and exploring the full Rashomon set rather than just a single model, researchers and practitioners gain access to simpler-yet-accurate models, better alignment with user preferences (like fairness and monotonicity), and improved uncertainty quantification. The paper demonstrates that for noisy datasets, the Rashomon Effect is large, allowing users to select interpretable models without sacrificing accuracy, which resolves the "interaction bottleneck" and enables safer, fairer AI systems in high-stakes domains.

## Method Summary
The paper empirically demonstrates the Rashomon Effect by training multiple model classes (Random Forest, Boosted Trees, SVM variants, Neural Networks, Logistic Regression, and Additive Risk Models) on real-world datasets like FICO and COMPAS. It compares their test accuracy and AUC, then analyzes variable importance rankings to show that models with similar accuracy can have inconsistent interpretations of feature importance. The paper introduces algorithms like TreeFARMS, GAM Rashomon set, and FasterRisk that enable practical discovery of large Rashomon sets, allowing users to interactively select models matching their specific goals for interpretability, fairness, or other constraints.

## Key Results
- Multiple model classes can achieve similar accuracy on tabular datasets while producing inconsistent variable importance rankings
- The Rashomon Effect is large for noisy datasets, enabling selection of simpler, more interpretable models without accuracy loss
- Recent algorithms (TreeFARMS, GAM Rashomon set, FasterRisk) make it practical to discover and explore large Rashomon sets
- User preferences for model characteristics (fairness, monotonicity, simplicity) can be satisfied by selecting from the Rashomon set rather than accepting a single "optimal" model

## Why This Works (Mechanism)
The Rashomon Effect works because for many real-world datasets—particularly tabular data with noise—the loss function landscape contains multiple distinct minima with similar values. When the Rashomon set is large, there exists substantial variation in model structure and interpretability among equally accurate models. This occurs because the data itself contains inherent uncertainty or noise that multiple different model forms can capture equally well. By explicitly searching for and characterizing this set of good models, rather than settling for the first local optimum found, practitioners can discover models that better align with domain knowledge, fairness constraints, or interpretability requirements while maintaining predictive performance.

## Foundational Learning

**Rashomon Set**: The collection of all models achieving accuracy within a small epsilon of the best model's accuracy. Why needed: Understanding this concept is fundamental to recognizing that model selection is not about finding "the best" model but exploring a set of viable alternatives. Quick check: Verify that models in the Rashomon set have test accuracies within epsilon of each other but may differ significantly in structure or interpretability.

**Variable Importance Consistency**: The degree to which different models rank features similarly in terms of their contribution to predictions. Why needed: This metric reveals whether models are making predictions for the same reasons, which is crucial for model trustworthiness. Quick check: Compare permutation importance rankings across models in the Rashomon set to identify inconsistencies.

**Model Flexibility vs Simplicity Tradeoff**: The relationship between a model's representational capacity and its ease of interpretation. Why needed: The Rashomon Effect suggests this tradeoff can be broken for noisy datasets, enabling both accuracy and interpretability. Quick check: Verify that simpler models from the Rashomon set achieve accuracy comparable to more complex alternatives.

## Architecture Onboarding

**Component Map**: Data -> Multiple Model Classes -> Performance Comparison -> Variable Importance Analysis -> Rashomon Set Discovery (TreeFARMS/FasterRisk) -> Interactive Model Selection -> User Preference Satisfaction

**Critical Path**: The essential workflow is: (1) Train diverse model classes on the same dataset with consistent cross-validation, (2) Identify the Rashomon set by finding models within epsilon of the best accuracy, (3) Analyze variable importance inconsistencies to confirm the Rashomon Effect exists, (4) Apply Rashomon discovery algorithms to explore the full set, (5) Enable user interaction to select models matching specific preferences.

**Design Tradeoffs**: The main tradeoff is computational cost versus model diversity—exploring the full Rashomon set requires significantly more computation than finding a single optimal model, but this investment enables better alignment with user needs and potentially safer deployments. Another tradeoff involves the epsilon threshold for Rashomon set membership: smaller epsilon yields fewer but more accurate models, while larger epsilon enables more diversity but may include less accurate models.

**Failure Signatures**: The Rashomon Effect is minimal when datasets are large with low noise, when model classes are too similar in flexibility, or when the epsilon threshold is set too stringently. Computational failure occurs when algorithms cannot efficiently explore the Rashomon set due to curse of dimensionality or when the set is too large to be practical.

**First Experiments**: 
1. Reproduce variable importance analysis on FICO dataset with multiple model classes to verify inconsistent rankings exist
2. Apply TreeFARMS algorithm to a tabular dataset and measure computational efficiency versus model diversity gained
3. Select a model from the Rashomon set based on monotonicity constraints and verify it maintains accuracy compared to the reference model

## Open Questions the Paper Calls Out

**Open Question 1**: How can we efficiently scale algorithms like TreeFARMS, GAM Rashomon set, and FasterRisk to handle extremely large datasets with millions of samples and thousands of features? The paper acknowledges computational costs but doesn't provide concrete scaling solutions for massive datasets.

**Open Question 2**: Can we develop a unified theoretical framework that connects the Rashomon Effect to other concepts in machine learning, such as generalization bounds, model selection criteria, and the bias-variance tradeoff? While connections are suggested, a comprehensive theoretical framework is lacking.

**Open Question 3**: How can we incorporate the Rashomon Effect into the design of machine learning algorithms to improve their robustness, fairness, and interpretability? The paper emphasizes importance but doesn't offer specific guidelines for algorithm development.

## Limitations
- Analysis focuses primarily on tabular data where the Rashomon Effect is most pronounced, potentially limiting generalizability to other data types
- Computational requirements for exploring large Rashomon sets may limit practical applicability in resource-constrained settings
- The paper doesn't extensively address how to handle cases where the Rashomon Effect is minimal, which could limit universal applicability
- Theoretical guarantees for Rashomon discovery algorithms are not fully detailed, making robustness assessment difficult

## Confidence

**Core Empirical Observations**: High confidence - The demonstration that multiple models achieve similar accuracy with different variable importance rankings is well-supported by reproducible experiments on real datasets.

**Practical Implications**: Medium confidence - While the theoretical arguments are sound, the practical benefits depend heavily on specific dataset characteristics and computational resources available.

**Algorithmic Contributions**: Medium confidence - The introduced algorithms show promise but lack extensive validation across diverse problem settings and don't provide complete theoretical analysis.

## Next Checks

1. Reproduce the variable importance analysis on the FICO dataset with multiple model classes to verify inconsistent rankings exist
2. Test the TreeFARMS and FasterRisk algorithms on additional tabular datasets to assess computational efficiency and Rashomon set discovery quality
3. Evaluate model selection from the Rashomon set for a specific user preference (e.g., monotonicity) and verify performance retention compared to the reference model