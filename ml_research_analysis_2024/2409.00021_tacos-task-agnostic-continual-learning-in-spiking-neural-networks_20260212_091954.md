---
ver: rpa2
title: 'TACOS: Task Agnostic Continual Learning in Spiking Neural Networks'
arxiv_id: '2409.00021'
source_url: https://arxiv.org/abs/2409.00021
tags:
- learning
- task
- tacos
- synaptic
- plasticity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TACOS is a spiking neural network model designed to address catastrophic
  forgetting in continual learning. It combines synaptic consolidation, metaplasticity,
  and error-driven neuromodulation to protect previously learned knowledge while enabling
  new learning.
---

# TACOS: Task Agnostic Continual Learning in Spiking Neural Networks

## Quick Facts
- **arXiv ID**: 2409.00021
- **Source URL**: https://arxiv.org/abs/2409.00021
- **Reference count**: 33
- **Primary result**: Outperforms regularization-based SNN continual learning methods on split Fashion-MNIST (93.22% mean accuracy) and split MNIST (82.56% mean accuracy) without task awareness

## Executive Summary
TACOS introduces a task-agnostic continual learning approach for spiking neural networks that addresses catastrophic forgetting through a combination of synaptic consolidation, metaplasticity, and error-driven neuromodulation. The model uses only local synapse-level information, eliminating the need for task labels during training or inference. By implementing a reference weight tracking system with heterosynaptic decay and activity-dependent metaplasticity modulation, TACOS achieves state-of-the-art performance on domain-incremental learning benchmarks while maintaining fixed memory overhead. The architecture demonstrates a stable-plasticity trade-off with an optimal inflection point at maximum metaplastic state of 25.

## Method Summary
TACOS is a continual learning method for spiking neural networks that combines three key mechanisms: metaplasticity with activity-dependent scaling, synaptic consolidation with reference weight tracking, and error-driven neuromodulation with surrogate gradient gating. The model operates on LIF neurons with error compartments and uses the eRBP learning rule modified to include metaplasticity modulation and heterosynaptic decay. Synapses maintain both actual and reference weights, with the reference weight updated slowly toward the current weight. Metaplasticity parameters increase with repeated activation, reducing plasticity for strongly weighted synapses. Learning updates are gated by postsynaptic current conditions to approximate biological activation regimes.

## Key Results
- Achieves 93.22% mean accuracy on split Fashion-MNIST and 82.56% mean accuracy on split MNIST
- Demonstrates superior performance compared to state-of-the-art regularization techniques in domain-incremental learning
- Shows fixed memory overhead of 2.5x baseline with no increase during continual learning
- Ablation study confirms both metaplasticity and consolidation are essential for optimal performance
- Identifies inflection point for optimal stability-plasticity trade-off at maximum metaplastic state of 25

## Why This Works (Mechanism)

### Mechanism 1: Metaplasticity with Activity-Dependent Scaling
- Claim: Synapses with larger weights are made less plastic, reducing their susceptibility to disruptive changes during new task learning.
- Mechanism: The plasticity of a synapse is modulated by a function of its current weight and a metaplasticity parameter, where the metaplastic state increases with repeated activation, further reducing plasticity for strongly weighted synapses.
- Core assumption: Activity-dependent metaplasticity effectively distinguishes between synapses critical for prior tasks and those less critical, enabling selective protection.
- Evidence anchors:
  - [abstract] "...using only synapse-local information, with no need for task awareness..."
  - [section 3.4] "The plasticity is calculated as a function of its weight and its metaplasticity parameter: f(m, w) = exp(−abs(mw)), and is used to modulate weight updates..."
  - [corpus] Weak or missing. No direct corpus support found for activity-dependent metaplasticity in SNNs.
- Break condition: If metaplasticity does not correlate with task-relevance, then all synapses may be equally protected or all may be equally vulnerable, negating the benefit.

### Mechanism 2: Synaptic Consolidation with Reference Weight Tracking
- Claim: A slower-changing reference weight tracks the current weight, allowing temporary deviations during new learning but gradually pulling the actual weight back to a consolidated value.
- Mechanism: The reference weight is updated toward the current weight with a slow time constant; when a postsynaptic neuron fires, all inbound synapses decay toward their reference weights via heterosynaptic plasticity.
- Core assumption: Heterosynaptic decay provides a mechanism to undo incidental changes that occur during new task learning, preserving the consolidated knowledge.
- Evidence anchors:
  - [abstract] "...using a form of activity-dependent metaplasticity with synaptic consolidation and heterosynaptic decay."
  - [section 3.4] "w ref (t + 1) = w ref (t) + ∆t/τref (w(t) − w ref (t))" and "∆wij(t + 1) = −α (wij(t) − wij ref (t))"
  - [corpus] Weak or missing. No direct corpus support found for reference-weight-based consolidation in spiking models.
- Break condition: If the decay rate α is too high, consolidation will dominate and prevent any new learning; if too low, forgetting will not be mitigated.

### Mechanism 3: Error-Driven Neuromodulation with Surrogate Gradient
- Claim: Plasticity updates are gated by a surrogate gradient condition based on postsynaptic current, ensuring updates occur only when the neuron is in a suitable state for learning.
- Mechanism: The eRBP rule applies updates proportional to the error signal and presynaptic spike, but only if the postsynaptic current is within a specified interval, approximating the ReLU-like behavior of LIF neurons.
- Core assumption: The surrogate gradient condition approximates the biological principle that synaptic changes occur only when neurons are in a specific activation regime.
- Evidence anchors:
  - [abstract] "...neuromodulation with complex synaptic dynamics to enable new learning while protecting previous information."
  - [section 3.3] "weight update is proportional to the accumulated error...provided the total synaptic current flowing into the postsynaptic neuron falls in a specified interval"
  - [corpus] Weak or missing. No direct corpus support found for surrogate-gradient gating in continual learning SNNs.
- Break condition: If the interval for Ipost is set incorrectly, either too many spurious updates occur (causing interference) or too few updates happen (preventing learning).

## Foundational Learning

- Concept: Spiking Neural Networks and LIF dynamics
  - Why needed here: TACOS is built on spiking neurons; understanding how LIF neurons integrate inputs and fire is essential to grasp the surrogate gradient rule and the heterosynaptic decay mechanism.
  - Quick check question: What happens to the membrane potential of a LIF neuron when it receives a spike from a presynaptic neuron?

- Concept: Metaplasticity in biological systems
  - Why needed here: TACOS uses a metaplasticity parameter to control the degree of synaptic plasticity; knowing how biological metaplasticity stabilizes memory helps interpret why this works.
  - Quick check question: In biological systems, what is the relationship between synaptic weight magnitude and susceptibility to further potentiation/depression?

- Concept: Catastrophic forgetting and continual learning scenarios
  - Why needed here: TACOS is evaluated on domain-incremental continual learning; understanding what catastrophic forgetting is and how continual learning benchmarks are structured is key to interpreting the results.
  - Quick check question: What is the difference between task-incremental and domain-incremental continual learning?

## Architecture Onboarding

- Component map:
  Input layer -> Poisson or population encoded spike trains -> Hidden layers (LIF neurons with membrane potential V and error compartment U) -> Output layer (two-neuron output for binary classification) -> Error neurons (false positives, false negatives with fixed random feedback weights) -> Synapses (actual weight w, reference weight wref, metaplasticity parameter m)

- Critical path:
  1. Forward pass: Input spikes → LIF dynamics → output spikes
  2. Error computation: Sout - L → error neurons → error signals Eo, Eh
  3. Weight update: Apply Eq. 11 with metaplasticity, consolidation, and decay

- Design tradeoffs:
  - Metaplasticity strength vs. plasticity: Higher metaplasticity protects more but reduces learning speed
  - Reference weight time constant vs. forgetting: Slower τref better consolidation but slower adaptation
  - Decay rate α vs. interference: Higher α better protection but may over-constrain weights
  - Surrogate gradient interval vs. stability: Narrower interval more stable but may block necessary updates

- Failure signatures:
  - If accuracy on new tasks is very low but old tasks are retained, metaplasticity may be too strong
  - If accuracy on old tasks drops rapidly when learning new tasks, consolidation decay may be too weak
  - If learning stalls entirely, surrogate gradient gating interval may be too restrictive
  - If accuracy plateaus early, metaplasticity may be saturating too quickly

- First 3 experiments:
  1. Run TACOS on split MNIST with m=25, τref=100, α=0.01, and record mean accuracy and backward transfer after each task
  2. Perform ablation: run with metaplasticity only, consolidation only, and both, compare mean accuracy and memory overhead
  3. Vary m from 5 to 50, plot mean accuracy vs. m to identify inflection point and validate stability-plasticity trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal metaplastic state threshold vary across different types of continual learning tasks and datasets?
- Basis in paper: [explicit] The paper mentions an "inflection point" at maximum metaplastic state of 25 for split-MNIST and split-Fashion-MNIST, but questions optimal settings for other datasets
- Why unresolved: The paper only tested on two specific image datasets with limited variations in task complexity
- What evidence would resolve it: Systematic testing across diverse datasets (text, audio, video) with varying task difficulty, sample sizes, and inter-task similarity to identify universal vs task-specific metaplastic thresholds

### Open Question 2
- Question: Can the metaplastic state be dynamically adjusted during learning based on task performance or network activity patterns?
- Basis in paper: [inferred] The paper mentions potential solutions like "decaying metaplastic updates" but doesn't explore dynamic adjustment mechanisms
- Why unresolved: Current implementation uses fixed maximum metaplastic state, and the paper only briefly mentions possible future improvements
- What evidence would resolve it: Implementation and testing of adaptive metaplasticity mechanisms that respond to learning progress, task difficulty, or network forgetting rates

### Open Question 3
- Question: What are the computational trade-offs between TACOS's synaptic complexity and alternative approaches to catastrophic forgetting?
- Basis in paper: [explicit] The paper notes TACOS has "more complex synapses" and increased memory overhead (2.5x baseline), but doesn't compare computational efficiency against other methods
- Why unresolved: While memory overhead is reported, the paper doesn't analyze training/inference time complexity or energy efficiency compared to alternative continual learning methods
- What evidence would resolve it: Comprehensive benchmarking of computational resources (memory, processing time, energy) for TACOS versus regularization-based, replay-based, and architectural approaches across various hardware platforms

## Limitations
- The specific metaplasticity formulation (exp(-|mw|)) lacks direct empirical support from neuroscience literature
- The "no task awareness" claim may be compromised as consolidation weights could implicitly encode task boundaries
- Performance characteristics in multi-class scenarios, regression tasks, or reinforcement learning settings remain unknown

## Confidence
- **High Confidence**: The overall framework combining metaplasticity, consolidation, and error-driven learning is internally consistent and the reported performance improvements over baseline methods are reproducible given the described experimental setup.
- **Medium Confidence**: The specific weight-dependent metaplasticity formulation and its claimed benefits for the stability-plasticity trade-off are plausible but lack direct empirical validation from the SNN or neuroscience literature.
- **Low Confidence**: The claim that TACOS works "without any task awareness" is difficult to verify independently, as the consolidation mechanism may implicitly encode task boundaries through weight trajectories even without explicit labels.

## Next Checks
1. **Ablation with synthetic tasks**: Create synthetic datasets where task boundaries are known but not provided to the model, then analyze whether consolidation weights implicitly capture task structure, testing the "no task awareness" claim.

2. **Multi-task stress test**: Evaluate TACOS on a sequence of 20+ tasks with varying input distributions to determine if the fixed memory overhead truly scales without degradation, particularly examining the long-term stability of the metaplasticity parameter.

3. **Biological plausibility audit**: Compare the specific metaplasticity formulation (exp(-|mw|)) against empirical measurements of synaptic plasticity in cortical circuits, determining whether the exponential weight-dependence is biologically realistic or an optimization convenience.