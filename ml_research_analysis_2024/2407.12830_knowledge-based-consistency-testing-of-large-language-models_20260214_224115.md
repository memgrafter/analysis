---
ver: rpa2
title: Knowledge-based Consistency Testing of Large Language Models
arxiv_id: '2407.12830'
source_url: https://arxiv.org/abs/2407.12830
tags:
- knowledge
- kontest
- gpt3
- llms
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes KONTEST, a knowledge-graph-based approach for
  systematically testing consistency and knowledge gaps in LLMs. It generates semantically-equivalent
  queries from extracted knowledge graphs, detects consistency errors via metamorphic
  and ontological oracles, and mitigates knowledge gaps using a weighted ensemble
  of LLMs.
---

# Knowledge-based Consistency Testing of Large Language Models

## Quick Facts
- arXiv ID: 2407.12830
- Source URL: https://arxiv.org/abs/2407.12830
- Reference count: 20
- Proposed KONTEST approach revealed 19.2% error-inducing inputs and 16.5% average knowledge gap across four state-of-the-art LLMs

## Executive Summary
This paper introduces KONTEST, a knowledge-graph-based approach for systematically testing consistency and knowledge gaps in large language models. The method extracts knowledge graphs from LLM responses, generates semantically-equivalent queries, and uses metamorphic and ontological oracles to detect consistency errors. KONTEST successfully identified significant consistency issues across four state-of-the-art LLMs (Falcon, Gemini, GPT3.5, Llama2) and demonstrated a 32.48% reduction in knowledge gaps through weighted ensemble mitigation.

## Method Summary
KONTEST operates through a systematic pipeline that begins with knowledge graph extraction from LLM responses using techniques like prompt-based extraction or fine-tuned models. These knowledge graphs are then used to generate semantically-equivalent queries through paraphrasing or sentence transformation. The system employs two types of oracles: metamorphic oracles that check for consistency across semantically-equivalent inputs, and ontological oracles that validate against external knowledge sources. When inconsistencies are detected, a weighted ensemble of multiple LLMs is used to mitigate knowledge gaps, with weights determined by each model's historical performance.

## Key Results
- KONTEST revealed 19.2% error-inducing inputs across four state-of-the-art LLMs
- Average knowledge gap of 16.5% was exposed across tested models
- Weighted ensemble mitigation reduced knowledge gaps by 32.48%
- GPT3.5 constructs only 68% of ground truth knowledge and exhibits up to 63.7% false positives in error detection

## Why This Works (Mechanism)
KONTEST leverages knowledge graphs as intermediate representations to systematically test LLM consistency. By extracting structured knowledge from responses and generating semantically-equivalent queries, it creates controlled test scenarios that reveal inconsistencies not apparent through traditional testing methods. The metamorphic oracles compare responses across equivalent inputs, while ontological oracles validate against external knowledge bases, providing comprehensive coverage of potential errors. The weighted ensemble approach combines multiple models' strengths while mitigating individual weaknesses, achieving superior knowledge gap reduction compared to single-model approaches.

## Foundational Learning
- Knowledge Graph Construction: Converting unstructured text into structured semantic representations is essential for systematic testing. Quick check: Verify graph accurately captures all entities and relationships from source text.
- Semantic Equivalence: Understanding how different phrasings can express identical meaning enables generation of comprehensive test cases. Quick check: Ensure generated queries maintain identical semantic content to originals.
- Metamorphic Testing: Applying input transformations while expecting consistent outputs helps uncover hidden inconsistencies. Quick check: Verify that all semantically-equivalent inputs produce consistent outputs.
- Ontological Validation: Comparing against external knowledge sources provides ground truth for detecting factual errors. Quick check: Ensure external knowledge base is comprehensive and up-to-date.
- Ensemble Methods: Combining multiple models with weighted voting improves robustness and coverage. Quick check: Verify that ensemble weights are optimally tuned for the specific domain.

## Architecture Onboarding

Component Map: Knowledge Extraction -> Graph Construction -> Query Generation -> Consistency Testing (Metamorphic + Ontological) -> Ensemble Mitigation

Critical Path: Knowledge Extraction → Graph Construction → Query Generation → Consistency Testing → Error Reporting/Mitigation

Design Tradeoffs:
- Graph construction accuracy vs. computational overhead: More precise extraction methods are computationally expensive
- Query diversity vs. semantic equivalence: Generating more diverse queries increases coverage but risks semantic drift
- Oracle sensitivity vs. false positive rate: Stricter consistency requirements reduce false positives but may miss subtle errors
- Ensemble size vs. mitigation effectiveness: Larger ensembles provide better coverage but increase computational costs

Failure Signatures:
- High false positive rates indicate overly sensitive ontological oracles or poor semantic equivalence generation
- Low error detection rates suggest insufficient query diversity or weak knowledge graph extraction
- Poor mitigation performance indicates suboptimal ensemble weighting or inadequate knowledge base coverage

First Experiments:
1. Run KONTEST on a simple factual knowledge domain (e.g., geography) to verify basic functionality
2. Test consistency detection with controlled semantic variations to validate metamorphic oracles
3. Evaluate knowledge gap mitigation on a single LLM before scaling to ensemble approach

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability to other model families beyond the four tested LLMs remains uncertain
- The specific quantitative results may vary with different evaluation sets or model versions
- The weighted ensemble mitigation approach requires further validation across diverse domains

## Confidence

High confidence:
- The overall methodology for generating semantically-equivalent queries and detecting consistency errors is well-established
- The demonstration of knowledge gaps in all four tested LLMs is a robust finding

Medium confidence:
- The specific quantitative results (19.2% error rate, 16.5% knowledge gap, 32.48% mitigation improvement) are reliable within the tested sample
- The effectiveness of the weighted ensemble approach requires further validation across diverse domains

Low confidence:
- The absolute performance metrics and their comparison across models should be interpreted cautiously due to potential variations in evaluation methodology

## Next Checks

1. Conduct cross-domain validation using diverse knowledge bases (scientific, medical, legal) to assess KONTEST's generalizability beyond the tested domains.

2. Implement long-term stability testing by evaluating the same models at different time points to account for potential performance variations due to updates or fine-tuning.

3. Perform extensive error analysis on the false positive cases (63.7% in GPT3.5) to refine the ontological oracles and improve precision in consistency detection.