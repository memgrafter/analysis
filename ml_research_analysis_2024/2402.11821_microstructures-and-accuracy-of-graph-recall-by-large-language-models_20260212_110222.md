---
ver: rpa2
title: Microstructures and Accuracy of Graph Recall by Large Language Models
arxiv_id: '2402.11821'
source_url: https://arxiv.org/abs/2402.11821
tags:
- graph
- recall
- node
- llms
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts the first systematic study of large language
  models' (LLMs) graph recall ability, examining how well LLMs can remember and encode
  graph structures described in text. The authors find that LLMs underperform in graph
  recall tasks and exhibit systematic biases, particularly favoring triangles and
  alternating 2-paths in their recalled graphs.
---

# Microstructures and Accuracy of Graph Recall by Large Language Models

## Quick Facts
- arXiv ID: 2402.11821
- Source URL: https://arxiv.org/abs/2402.11821
- Authors: Yanbang Wang; Hejie Cui; Jon Kleinberg
- Reference count: 40
- Primary result: LLMs exhibit systematic biases toward triangles and alternating 2-paths in graph recall tasks

## Executive Summary
This paper presents the first systematic study of large language models' (LLMs) ability to recall and encode graph structures from textual descriptions. The authors find that LLMs significantly underperform in graph recall tasks and demonstrate consistent biases, particularly favoring triangles and alternating 2-paths in their recalled graphs. The study reveals that GPT-4's performance strongly depends on matching the narrative style of graph descriptions to their original domain, achieving optimal results when these align. These findings highlight fundamental limitations in LLMs' graph reasoning capabilities and provide actionable insights for improving graph-based applications.

## Method Summary
The authors conducted systematic experiments evaluating LLMs' graph recall ability across multiple models including GPT-4, GPT-3.5, and Claude. They designed controlled experiments using both simple and complex graph structures described through different narrative styles and domains. The study employed automated evaluation metrics to measure recall accuracy and pattern detection, comparing the LLMs' outputs against ground truth graphs. Experiments included memory clearance tests, edge hallucination vs. forgetting analysis, and narrative style matching assessments to understand the underlying mechanisms of LLM graph reasoning.

## Key Results
- LLMs systematically favor triangles and alternating 2-paths in recalled graphs, showing consistent structural biases
- GPT-4 performance strongly depends on matching narrative style to original domain, with best results when aligned
- LLMs tend to forget edges rather than hallucinate them, and more advanced models show better sensitivity to memory clearance effects

## Why This Works (Mechanism)
The paper identifies that LLMs' graph recall performance is fundamentally limited by their training on textual patterns rather than explicit graph structures. The models appear to rely on learned narrative patterns and statistical associations rather than genuine graph reasoning capabilities. The observed biases toward specific graph microstructures (triangles and alternating 2-paths) likely reflect common patterns in the training data, while the sensitivity to narrative style matching suggests that LLMs encode contextual information more effectively than abstract structural information.

## Foundational Learning
1. Graph Theory Basics
   - Why needed: Understanding fundamental graph structures and properties is essential for evaluating recall accuracy
   - Quick check: Can identify basic graph components (nodes, edges, paths, cycles) and their relationships

2. Natural Language Processing
   - Why needed: LLMs process graph information through textual descriptions, requiring understanding of NLP fundamentals
   - Quick check: Can analyze how textual patterns influence model behavior and recall accuracy

3. Pattern Recognition in Neural Networks
   - Why needed: Understanding how LLMs develop systematic biases toward certain graph structures
   - Quick check: Can identify and explain common pattern biases in neural network outputs

4. Model Evaluation Metrics
   - Why needed: Quantitative assessment of graph recall accuracy requires appropriate metrics
   - Quick check: Can design and implement evaluation metrics for comparing generated graphs to ground truth

5. Domain Adaptation
   - Why needed: Understanding how narrative style matching affects model performance across different domains
   - Quick check: Can explain the relationship between domain context and model output quality

## Architecture Onboarding

Component map:
Text Input -> NLP Processing -> Graph Structure Generation -> Pattern Analysis -> Evaluation Metrics

Critical path:
Text Input -> NLP Processing -> Graph Structure Generation -> Pattern Analysis -> Evaluation Metrics

Design tradeoffs:
The study prioritizes controlled experimental conditions over real-world complexity, focusing on specific graph types and narrative styles to establish baseline performance patterns. This approach enables clear identification of systematic biases but may limit generalizability to more complex graph structures.

Failure signatures:
- Systematic overrepresentation of triangles and alternating 2-paths
- Sensitivity to narrative style misalignment
- Edge forgetting rather than hallucination
- Domain-specific performance variations

First experiments:
1. Replicate basic graph recall tasks with simple graph structures to verify systematic biases
2. Test narrative style matching effects with controlled domain variations
3. Evaluate edge forgetting vs. hallucination patterns across multiple model versions

## Open Questions the Paper Calls Out
Major uncertainties remain about whether the observed graph recall patterns generalize to other types of graph structures and domains. The study focuses on specific graph types and narrative styles, and it's unclear if similar biases would emerge with different graph representations or more complex graph topologies. The authors acknowledge that their evaluation methodology relies on relatively simple graph structures, which may not fully capture the complexities of real-world graph reasoning tasks.

## Limitations
- The study focuses on specific graph types and may not generalize to more complex graph topologies
- Limited sample size and range of tested models may restrict conclusions about broader LLM behavior
- Evaluation methodology relies on relatively simple graph structures that may not capture real-world complexity
- Narrative style matching results are compelling but based on comparisons with limited model variations

## Confidence

High:
- Core finding that LLMs exhibit systematic biases toward triangles and alternating 2-paths
- Observation that LLMs tend to forget edges rather than hallucinate them
- Overall conclusion about LLMs' limitations in graph recall tasks

Medium:
- Claims regarding GPT-4's sensitivity to narrative style matching
- Conclusions about the relationship between domain context and model performance

## Next Checks
1. Test the same graph recall tasks with more diverse graph structures (e.g., larger graphs, different topologies, weighted edges) to assess generalizability
2. Evaluate additional LLMs not included in the original study to verify if the observed patterns are consistent across a broader range of models
3. Conduct experiments with domain experts to validate whether the LLM-generated graph patterns align with or diverge from human cognitive patterns in similar tasks