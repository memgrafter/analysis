---
ver: rpa2
title: 'LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI Planning'
arxiv_id: '2409.01806'
source_url: https://arxiv.org/abs/2409.01806
tags:
- planning
- language
- llms
- plan
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews the integration of large language
  models (LLMs) into AI planning, highlighting key benchmarks, methodologies, and
  challenges. It categorizes planning tasks into embodied environments, optimal scheduling,
  competitive/cooperative games, task decomposition, and reasoning.
---

# LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI Planning

## Quick Facts
- **arXiv ID**: 2409.01806
- **Source URL**: https://arxiv.org/abs/2409.01806
- **Reference count**: 18
- **Primary result**: Comprehensive survey of LLM integration into AI planning, identifying key benchmarks, methodologies, and challenges

## Executive Summary
This survey provides a systematic review of how large language models are being integrated into AI planning systems. It categorizes planning applications into five domains: embodied environments, optimal scheduling, competitive/cooperative games, task decomposition, and reasoning. The paper identifies two main approaches to LLM integration - LLM-as-Planner for direct plan generation and LLM-as-Facilitator for assisting classical planning algorithms. While LLMs show promise in handling natural language and complex reasoning, the survey highlights ongoing challenges with reliability, plan executability, and optimality. The work serves as a roadmap for advancing LLM-assisted planning in real-world applications.

## Method Summary
The survey employs a comprehensive literature review methodology, examining 18 key references across multiple domains of AI planning. The authors systematically categorize planning tasks and methodologies, distinguishing between LLM-as-Planner and LLM-as-Facilitator approaches. They analyze the strengths and limitations of each approach through qualitative assessment of reported results and methodologies. The survey also identifies key benchmarks and evaluation frameworks used in the field, while noting the variability in evaluation standards across different studies.

## Key Results
- LLMs can handle natural language inputs and complex reasoning in planning tasks
- Two distinct approaches identified: LLM-as-Planner (direct plan generation) and LLM-as-Facilitator (assisting classical planners)
- Major challenges include reliability, physical feasibility in embodied environments, and latency issues
- Need for standardized evaluation frameworks to compare LLM planning approaches

## Why This Works (Mechanism)
The effectiveness of LLM-assisted planning stems from LLMs' ability to process natural language instructions and generate human-readable plans. The survey identifies that LLMs excel at handling unstructured information and can reason across multiple domains, making them valuable for tasks requiring language understanding and multi-step reasoning. The LLM-as-Facilitator approach leverages LLMs' language processing capabilities while maintaining the reliability of classical planning algorithms, creating a hybrid system that combines the strengths of both approaches.

## Foundational Learning

**Natural Language Processing**: Why needed - To understand and generate human-readable plans; Quick check - Verify LLM can parse and generate coherent text instructions
**Classical Planning Algorithms**: Why needed - To provide reliable, verifiable planning foundations; Quick check - Ensure planner can generate optimal solutions for well-defined problems
**Embodied Planning**: Why needed - To handle physical constraints and real-world execution; Quick check - Validate plans against physical feasibility constraints
**Multi-agent Planning**: Why needed - To coordinate between multiple entities or agents; Quick check - Test coordination in competitive and cooperative scenarios
**Task Decomposition**: Why needed - To break complex tasks into manageable subtasks; Quick check - Verify hierarchical plan structure maintains logical flow

## Architecture Onboarding

**Component Map**: LLM Input Processing -> Planning Module (LLM or Classical) -> Plan Verification -> Execution

**Critical Path**: Input processing → Plan generation → Plan verification → Execution

**Design Tradeoffs**: LLM-as-Planner offers flexibility but lacks reliability; LLM-as-Facilitator provides reliability but requires more computational resources

**Failure Signatures**: 
- LLM-as-Planner: Non-executable plans, logical inconsistencies
- LLM-as-Facilitator: Increased latency, resource overhead
- Hybrid: Complexity in integration, verification challenges

**3 First Experiments**:
1. Compare plan executability rates between LLM-as-Planner and LLM-as-Facilitator approaches
2. Measure latency and resource usage across different planning paradigms
3. Test plan verification accuracy against formal specifications

## Open Questions the Paper Calls Out

The survey highlights several open questions regarding the future of LLM-assisted planning, including the need for standardized evaluation frameworks, the development of verifiable planning methods, and the integration of physical reasoning capabilities. The paper also questions how to balance the trade-offs between LLM flexibility and classical planning reliability in hybrid systems.

## Limitations

- Evaluation methodologies vary significantly across studies, making cross-comparison difficult
- Physical feasibility and execution success rates are rarely quantified in embodied planning tasks
- The distinction between planning approaches often blurs in practice without systematic analysis
- Coverage is weighted toward recent publications, potentially missing foundational work

## Confidence

- **High confidence**: Categorization of planning applications and methodological approaches is comprehensive and well-grounded
- **Medium confidence**: Claims about LLM performance limitations are supported by literature but lack systematic empirical validation
- **Low confidence**: Specific quantitative comparisons between LLM planning methods are difficult to substantiate due to heterogeneous evaluation frameworks

## Next Checks

1. Conduct standardized benchmark testing across multiple LLM planning approaches using identical metrics for plan executability, optimality, and physical feasibility
2. Implement ablation studies to quantify individual contributions of LLM-as-Planner versus LLM-as-Facilitator components in hybrid systems
3. Develop and apply a verification framework to assess correctness and completeness of LLM-generated plans against formal specifications