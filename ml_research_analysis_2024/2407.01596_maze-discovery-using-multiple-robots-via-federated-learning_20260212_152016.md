---
ver: rpa2
title: Maze Discovery using Multiple Robots via Federated Learning
arxiv_id: '2407.01596'
source_url: https://arxiv.org/abs/2407.01596
tags:
- maze
- robots
- data
- classification
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates the effectiveness of federated learning
  (FL) in a maze discovery use case with two LiDAR-equipped robots operating in structurally
  different environments. The key problem addressed is that classification models
  trained locally on one maze do not generalize to another maze due to different wall
  shapes, limiting robots' ability to identify unseen environments.
---

# Maze Discovery using Multiple Robots via Federated Learning

## Quick Facts
- arXiv ID: 2407.01596
- Source URL: https://arxiv.org/abs/2407.01596
- Reference count: 4
- Two LiDAR-equipped robots collaboratively discover structurally different mazes using federated learning, achieving 99% accuracy on both seen and unseen mazes

## Executive Summary
This work demonstrates the effectiveness of federated learning (FL) in a maze discovery use case with two LiDAR-equipped robots operating in structurally different environments. The key problem addressed is that classification models trained locally on one maze do not generalize to another maze due to different wall shapes, limiting robots' ability to identify unseen environments. The proposed method employs an FL framework using FedAvg to enable two robots, each exploring a distinct maze, to collaboratively train a shared classification model without exchanging raw data.

## Method Summary
The method uses FedAvg to train a shared classification model across two robots exploring different mazes. Each robot collects LiDAR data (1147 sample points per sweep) from its maze and trains locally, then shares model parameters with a central server. The server aggregates these parameters and distributes the updated global model back to both robots. The neural network architecture consists of a 1147×1 input layer, one hidden layer with 256 neurons, and a 15×1 output layer with ReLu activation, trained with L2 regularization.

## Key Results
- FL-trained model achieves approximately 99% accuracy on both mazes, enabling accurate maze discovery in both seen and unseen environments
- Locally trained models achieve 99% accuracy on their own mazes but only 48% and 29% accuracy on the unseen maze
- The federated approach enables robots to recognize both wall types despite never seeing the other maze's raw data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Federated learning enables model generalization across structurally different mazes by averaging locally trained models without raw data sharing
- Mechanism: Each robot trains on its own maze-specific data (different wall shapes α and β), then shares only model parameters. FedAvg averages these parameters to create a globally shared model that incorporates both maze's structural patterns. This allows each robot to recognize both wall types despite never seeing the other maze's raw data
- Core assumption: Wall shape variations are learnable features that can be captured by the neural network architecture, and parameter averaging preserves useful features from both domains
- Evidence anchors:
  - [abstract] "FL-trained model achieves approximately 99% accuracy on both mazes, enabling accurate maze discovery in both seen and unseen environments"
  - [section] "the collective knowledge allows them to operate accurately in the unseen maze"
  - [corpus] Weak - no direct corpus evidence for FedAvg in maze applications
- Break condition: If wall shape differences are too extreme for the model architecture to learn transferable features, or if data distributions are too dissimilar for FedAvg averaging to be meaningful

### Mechanism 2
- Claim: The 1147-dimensional LiDAR input captures sufficient spatial information about wall shapes to enable accurate classification
- Mechanism: LiDAR provides 1147 sample points per sweep, creating a dense representation of the immediate environment. This high-dimensional input allows the neural network to detect subtle shape differences in walls (cylindrical shapes with different counts) that distinguish the two maze types
- Core assumption: The 1147 LiDAR points adequately sample the critical shape features needed for classification, and the neural network can extract these features from raw sensor data
- Evidence anchors:
  - [section] "LiDAR model is RPLIDAR A1, which has a scanning frequency of 5.5 Hz, a ranging distance of 0.15 ∼ 12 m with an accuracy of 1% for distances less than 3 m, and 1147 sample points per one sweep"
  - [section] "classification models to accurately identify the shapes of grid areas"
  - [corpus] Weak - no direct corpus evidence for LiDAR point density requirements in maze classification
- Break condition: If LiDAR resolution is insufficient to capture critical shape differences, or if environmental conditions (lighting, reflective surfaces) degrade LiDAR performance

### Mechanism 3
- Claim: Local training without FL fails due to overfitting to maze-specific features rather than learning generalizable patterns
- Mechanism: When robots train only on their own maze data, the neural network learns features specific to their wall type (α or β). Without exposure to the other maze's patterns, the model cannot generalize. FL forces the model to learn features that work across both domains by exposing it to parameter updates from both environments
- Core assumption: The classification task benefits from learning domain-invariant features rather than maze-specific ones, and parameter averaging promotes this generalization
- Evidence anchors:
  - [section] "locally trained models achieve 99% accuracy on their own mazes, they only reach 48% and 29% accuracy on the unseen maze"
  - [section] "individual learning that fails robots to identify the features of the unseen maze"
  - [corpus] Weak - no direct corpus evidence for overfitting in multi-maze scenarios
- Break condition: If the two mazes share too many features, making local training sufficient, or if the model architecture cannot learn domain-invariant features

## Foundational Learning

- Concept: Federated Averaging (FedAvg) algorithm
  - Why needed here: Enables multiple robots to collaboratively train a shared model without sharing raw sensor data, preserving privacy and reducing communication overhead
  - Quick check question: What is the key difference between FedAvg and centralized training in terms of data handling?

- Concept: Neural network generalization and overfitting
  - Why needed here: Understanding why local models fail on unseen mazes requires knowledge of how neural networks learn domain-specific vs. domain-general features
  - Quick check question: What training scenario would cause a model to perform well on training data but poorly on data from a different distribution?

- Concept: LiDAR data processing and feature extraction
  - Why needed here: The classification model relies on raw LiDAR point clouds being transformed into meaningful features that distinguish different wall shapes
  - Quick check question: How many dimensions does the LiDAR input have, and why is this dimensionality important for the classification task?

## Architecture Onboarding

- Component map: Robot → LiDAR sensor → ROS topic → Data collection node → Training script → FL parameter server (Sβ) → Updated model → Inference node → Maze discovery
- Critical path: Data collection → Local training → FL parameter aggregation → Model update → Inference → Navigation
- Design tradeoffs: Higher LiDAR resolution provides better shape discrimination but increases computational load; more complex neural networks could capture more features but require more training data and computation
- Failure signatures: Poor accuracy on unseen mazes indicates overfitting; communication failures between robots and server prevent FL; navigation errors suggest inference problems
- First 3 experiments:
  1. Test local model accuracy on own maze vs. other maze to verify domain-specific learning
  2. Verify FL parameter averaging works by checking model weights before and after aggregation
  3. Test inference accuracy on both mazes using FL-trained model to confirm generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the federated learning approach scale when increasing the number of robots and mazes beyond two?
- Basis in paper: [explicit] The paper only tests with two robots and two mazes, suggesting potential interest in scalability
- Why unresolved: The paper doesn't explore scenarios with more than two robots or mazes, leaving the performance and communication overhead in larger-scale deployments unknown
- What evidence would resolve it: Experimental results showing classification accuracy and communication efficiency when using 3+ robots exploring 3+ mazes with federated learning

### Open Question 2
- Question: What is the minimum amount of local data required per robot to achieve good federated learning performance in this maze discovery task?
- Basis in paper: [inferred] The paper uses 200 LiDAR sweeps per grid but doesn't analyze how varying dataset sizes affects federated learning outcomes
- Why unresolved: The paper doesn't perform sensitivity analysis on dataset size per robot, leaving uncertainty about data efficiency of the approach
- What evidence would resolve it: Results showing classification accuracy as a function of local dataset size per robot in federated learning experiments

### Open Question 3
- Question: How would the federated learning performance change if the maze wall types had more subtle differences rather than the distinctly different shapes described?
- Basis in paper: [explicit] The paper specifically uses "irregular shaped walls" with "different shapes for the walls" but doesn't explore how similarity between wall types affects generalization
- Why unresolved: The current experimental setup uses clearly distinguishable wall types, which may not represent more challenging real-world scenarios
- What evidence would resolve it: Experiments comparing federated learning performance with clearly distinct wall types versus more similar wall types with subtle variations

### Open Question 4
- Question: How robust is the federated learning approach to robot failures or communication interruptions during the training process?
- Basis in paper: [inferred] The paper describes a stable two-robot system but doesn't address fault tolerance or communication reliability
- Why unresolved: Real-world robotic systems often face communication issues and hardware failures, but the paper doesn't test system behavior under these conditions
- What evidence would resolve it: Results showing federated learning performance when one robot experiences communication dropouts or complete failure during training

## Limitations
- Evaluation limited to only two structurally different mazes with specific wall shapes
- Neural network architecture is relatively simple (one hidden layer with 256 neurons)
- Focuses solely on classification accuracy without evaluating downstream navigation performance

## Confidence
- **High confidence**: FL improves accuracy on unseen mazes compared to local training (99% vs. 48-29%)
- **Medium confidence**: The 1147-dimensional LiDAR input is sufficient for maze classification
- **Low confidence**: The results generalize to more than two maze types or more complex environmental variations

## Next Checks
1. Test the FL-trained model on additional maze types with different wall configurations to assess scalability
2. Evaluate navigation performance using the classification model in real-world multi-robot scenarios
3. Compare different neural network architectures (deeper networks, different activation functions) to determine optimal model complexity for this task