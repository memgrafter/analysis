---
ver: rpa2
title: 'The Impact of Large Language Models in Academia: from Writing to Speaking'
arxiv_id: '2409.13686'
source_url: https://arxiv.org/abs/2409.13686
tags:
- arxiv
- figure
- oral
- papers
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examined how large language models (LLMs) influence
  academic writing and speaking by analyzing over 30,000 paper abstracts and 1,000
  conference presentations from machine learning conferences. Researchers found that
  LLM-influenced words like "significant" became more frequent in both abstracts and
  presentations after 2022, with stronger effects in writing than speaking.
---

# The Impact of Large Language Models in Academia: from Writing to Speaking

## Quick Facts
- **arXiv ID**: 2409.13686
- **Source URL**: https://arxiv.org/abs/2409.13686
- **Reference count**: 40
- **Primary result**: LLM-influenced words became more frequent in academic abstracts and presentations after 2022, with stronger effects in writing than speaking

## Executive Summary
This study investigates how large language models (LLMs) influence academic communication by analyzing over 30,000 paper abstracts and 1,000 conference presentations from machine learning conferences. Researchers found that words like "significant" became more frequent in both abstracts and presentations after 2022, indicating growing LLM influence on academic writing and speaking styles. The study introduced a novel simulation-based method to estimate LLM impact and demonstrated that certain words' increased frequency correlates with LLM preferences. While LLM traces are only beginning to appear in presentations, their impact on writing is substantial and growing.

## Method Summary
The study analyzed 30,000+ paper abstracts and 1,000+ conference presentations from machine learning conferences to examine LLM influence on academic communication. Researchers used a simulation-based approach to estimate LLM impact by comparing word frequency changes before and after 2022. They focused on identifying words that became more frequent and correlated with LLM preferences, distinguishing between writing (abstracts) and speaking (presentations) contexts.

## Key Results
- LLM-influenced words like "significant" became more frequent in both abstracts and presentations after 2022
- LLM influence is stronger in academic writing than in presentations
- Traces of LLM influence are only beginning to appear in presentations but have substantially impacted writing
- The simulation-based method successfully estimated LLM impact on academic language

## Why This Works (Mechanism)
The study works by leveraging the systematic linguistic patterns that LLMs introduce into text. When researchers use LLMs for writing assistance, certain words and phrases become more prevalent due to LLM training data and generation preferences. These linguistic signatures persist even when LLMs are used indirectly, as they influence how researchers express ideas. The frequency analysis captures these subtle but measurable changes in academic communication patterns across different formats (written abstracts vs. spoken presentations).

## Foundational Learning
1. **Corpus Linguistics** - Understanding word frequency patterns in large text collections
   - Why needed: Forms the basis for detecting linguistic changes over time
   - Quick check: Verify word frequency distributions follow expected patterns

2. **Temporal Analysis** - Comparing linguistic patterns across different time periods
   - Why needed: Essential for identifying when LLM influence emerged
   - Quick check: Ensure pre-2022 baseline is stable

3. **Statistical Significance Testing** - Determining whether frequency changes are meaningful
   - Why needed: Distinguishes real LLM effects from random variation
   - Quick check: Confirm p-values and confidence intervals

4. **Cross-Format Comparison** - Analyzing differences between written and spoken academic communication
   - Why needed: Reveals how LLM influence varies across communication modes
   - Quick check: Validate that differences between formats are consistent

5. **Simulation-Based Estimation** - Using computational models to estimate impact magnitude
   - Why needed: Provides quantitative measure of LLM influence
   - Quick check: Compare simulation results with observed data

6. **Domain-Specific Language Analysis** - Understanding specialized vocabulary in machine learning
   - Why needed: Ensures relevant words are properly weighted
   - Quick check: Verify domain expertise in word selection

## Architecture Onboarding

**Component Map**: Data Collection -> Preprocessing -> Frequency Analysis -> LLM Impact Estimation -> Cross-Format Comparison

**Critical Path**: Data Collection -> Frequency Analysis -> Impact Estimation (preprocessing supports all stages)

**Design Tradeoffs**: The study prioritized breadth (30,000+ abstracts) over depth of individual analysis, trading detailed contextual understanding for statistical power. This enables detection of subtle patterns but may miss nuanced usage differences.

**Failure Signatures**: If LLM influence cannot be distinguished from natural language evolution, the frequency analysis would show no clear temporal breaks. If preprocessing errors occur, word counts would be systematically biased. If simulation methodology is flawed, impact estimates would not correlate with observed frequency changes.

**Three First Experiments**:
1. Test the frequency analysis pipeline on synthetic data with known LLM influence patterns
2. Validate the simulation-based estimation method using controlled LLM-generated text samples
3. Verify the cross-format comparison by analyzing conferences with known LLM usage differences

## Open Questions the Paper Calls Out
None

## Limitations
- The novel simulation-based methodology has not been validated against alternative approaches
- Findings may not generalize beyond machine learning conferences to other academic disciplines
- The analysis relies on specific word frequency changes as proxies for LLM influence, which may not capture all aspects of LLM impact

## Confidence
- **High confidence** in observed frequency changes of specific words in abstracts and presentations
- **Medium confidence** in LLM influence being stronger in writing than speaking
- **Medium confidence** in simulation-based impact estimates
- **Low confidence** in generalizing findings beyond machine learning conferences

## Next Checks
1. Replicate the analysis using alternative methodological approaches (e.g., supervised classification of LLM-influenced text vs. frequency-based methods) to validate the simulation-based estimates
2. Extend the study to include non-ML conferences and preprint repositories to test generalizability across disciplines
3. Conduct controlled experiments where researchers write abstracts both with and without LLM assistance to establish direct causal relationships between LLM use and linguistic changes