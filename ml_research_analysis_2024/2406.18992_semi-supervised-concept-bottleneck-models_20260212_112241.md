---
ver: rpa2
title: Semi-supervised Concept Bottleneck Models
arxiv_id: '2406.18992'
source_url: https://arxiv.org/abs/2406.18992
tags:
- concept
- data
- image
- learning
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Semi-supervised Concept Bottleneck Models (SSCBM) address the challenge
  of training concept bottleneck models when labeled concept data is scarce and concept
  saliency maps misalign with input features. The method introduces a KNN-based pseudo-labeling
  approach for unlabeled data and an alignment loss that aligns concept embeddings
  with input saliency maps.
---

# Semi-supervised Concept Bottleneck Models

## Quick Facts
- arXiv ID: 2406.18992
- Source URL: https://arxiv.org/abs/2406.18992
- Authors: Lijie Hu; Tianhao Huang; Huanyi Xie; Xilin Gong; Chenyang Ren; Zhengyu Hu; Lu Yu; Ping Ma; Di Wang
- Reference count: 40
- With only 10% labeled data, SSCBM achieves concept accuracy within 2.44% and task accuracy within 3.93% of fully supervised baseline

## Executive Summary
Semi-supervised Concept Bottleneck Models (SSCBM) address the challenge of training concept bottleneck models when labeled concept data is scarce and concept saliency maps misalign with input features. The method introduces a KNN-based pseudo-labeling approach for unlabeled data and an alignment loss that aligns concept embeddings with input saliency maps. By jointly training on labeled and unlabeled data, SSCBM leverages both pseudo-labels to improve concept accuracy and interpretability. Experiments across four datasets show that with only 10% labeled data, SSCBM achieves concept accuracy within 2.44% and task accuracy within 3.93% of the best fully supervised baseline. The alignment loss also improves interpretability, as concept saliency maps better correspond to input regions relevant to the concepts.

## Method Summary
SSCBM addresses the challenge of training concept bottleneck models with limited labeled concept data by introducing a semi-supervised learning framework. The method uses KNN-based pseudo-labeling to generate concept labels for unlabeled data, then jointly trains on both labeled and pseudo-labeled data. An alignment loss is introduced to ensure that concept embeddings align with input saliency maps, improving interpretability. The model is trained end-to-end, leveraging both the pseudo-labels and the alignment loss to improve concept accuracy and maintain interpretability even with minimal labeled data.

## Key Results
- With only 10% labeled data, SSCBM achieves concept accuracy within 2.44% of fully supervised baseline
- Task accuracy remains within 3.93% of fully supervised baseline with minimal labeled data
- Alignment loss improves interpretability by better aligning concept saliency maps with input regions

## Why This Works (Mechanism)
SSCBM works by leveraging unlabeled data through pseudo-labeling and improving interpretability through alignment. The KNN-based pseudo-labeling allows the model to learn from unlabeled data by generating concept labels based on nearest neighbors in the embedding space. The alignment loss ensures that concept embeddings correspond to relevant input features by comparing concept saliency maps with input feature saliency maps. Joint training on both labeled and pseudo-labeled data allows the model to benefit from the larger unlabeled dataset while maintaining accuracy through the alignment constraint.

## Foundational Learning
- Concept Bottleneck Models: Models that first predict interpretable concepts before making final predictions; needed to enable interpretable AI systems; quick check: model should output both concepts and final task prediction
- Semi-supervised Learning: Learning from both labeled and unlabeled data; needed when labeled data is scarce but unlabeled data is abundant; quick check: training involves both labeled and pseudo-labeled data
- Saliency Maps: Visual explanations showing which input regions influence predictions; needed for interpretability and alignment; quick check: maps should highlight relevant input regions for concepts
- Pseudo-labeling: Generating labels for unlabeled data using model predictions; needed to leverage abundant unlabeled data; quick check: pseudo-labels should improve with more labeled data
- KNN-based Pseudo-labeling: Using nearest neighbors in embedding space to generate pseudo-labels; needed for reliable label generation; quick check: pseudo-labels should be consistent with nearest labeled examples

## Architecture Onboarding

Component Map: Input -> Feature Extractor -> Concept Predictor -> Task Predictor; Concept Saliency Maps <-> Input Saliency Maps (Alignment Loss); KNN Module -> Pseudo-labels

Critical Path: Input features flow through feature extractor to concept predictor, then to task predictor. Simultaneously, concept embeddings are compared with input embeddings through alignment loss. Pseudo-labels from KNN module are used to train on unlabeled data.

Design Tradeoffs: The method trades computational overhead from pseudo-labeling and alignment loss for improved performance with limited labeled data. KNN-based pseudo-labeling is simpler but potentially less accurate than more sophisticated methods. The alignment loss improves interpretability but adds complexity to training.

Failure Signatures: Poor concept accuracy if initial labeled set is unrepresentative; misalignment between concept and input saliency maps; pseudo-labels may introduce noise if KNN neighbors are from different classes; computational overhead may be prohibitive for large datasets.

Three First Experiments:
1. Evaluate concept accuracy with varying percentages of labeled data (1%, 5%, 10%, 25%, 50%) to determine the minimum labeled data needed
2. Compare KNN-based pseudo-labeling with other pseudo-labeling strategies (entropy-based, consistency-based) to assess robustness
3. Measure interpretability improvement by quantifying alignment between concept and input saliency maps using correlation metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Relies heavily on quality of pseudo-labels, which may introduce cascading errors if initial labeled set is small or unrepresentative
- Computational overhead of pseudo-labeling and alignment losses not discussed, potentially limiting practical deployment
- Experiments focus on clean, curated datasets without addressing label noise, concept drift, or evolving taxonomies

## Confidence

High confidence:
- Concept accuracy claims (within 2.44% of fully supervised baseline): directly measured and reported across multiple datasets

Medium confidence:
- Interpretability improvements through alignment loss: limited quantitative measures of interpretability, practical significance needs validation

Low confidence:
- Scalability to real-world scenarios with limited/expensive concept labels: controlled experiments with 10% labeled data don't address quality, representativeness, or acquisition cost in practical applications

## Next Checks

1. Test SSCBM performance when initial labeled concept set is deliberately biased or unrepresentative to assess robustness to poor-quality seed labels

2. Conduct ablation studies comparing SSCBM with different pseudo-labeling strategies (beyond KNN) and evaluate how alignment loss performance varies with concept granularity and semantic distance from input features

3. Measure computational overhead and training time compared to fully supervised baselines, and evaluate performance degradation when applying SSCBM to streaming data with concept drift or evolving taxonomies