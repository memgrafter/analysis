---
ver: rpa2
title: 'The Simpler The Better: An Entropy-Based Importance Metric To Reduce Neural
  Networks'' Depth'
arxiv_id: '2404.18949'
source_url: https://arxiv.org/abs/2404.18949
tags:
- easier
- layers
- performance
- neural
- top-1
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes EASIER, an entropy-based method to reduce the
  depth of rectifier-activated deep neural networks. The method estimates layer degeneration
  using an entropy metric calculated from the average state of rectifier-activated
  neurons.
---

# The Simpler The Better: An Entropy-Based Importance Metric To Reduce Neural Networks' Depth

## Quick Facts
- arXiv ID: 2404.18949
- Source URL: https://arxiv.org/abs/2404.18949
- Authors: Victor Quétu; Zhu Liao; Enzo Tartaglione
- Reference count: 40
- One-line primary result: Entropy-based method EASIER reduces depth of rectifier-activated networks while preserving performance across multiple architectures and datasets

## Executive Summary
This paper introduces EASIER, an entropy-based method to reduce the depth of rectifier-activated deep neural networks by identifying and linearizing degenerate layers. The approach calculates an entropy metric for each layer based on the average state of rectifier-activated neurons, where low entropy indicates consistent ON/OFF behavior that can be replaced with Identity functions. Through iterative training, entropy calculation, layer linearization, and fine-tuning, EASIER achieves significant depth reduction with minimal performance loss compared to existing methods like Layer Folding and Entropy-Guided Pruning.

## Method Summary
EASIER operates by first calculating the entropy of each layer based on the sign of pre-activation values (Z) from rectifier-activated neurons. Layers with low entropy are identified as degenerate and can be linearized by replacing their activation functions with Identity. The method then iteratively trains the network, computes entropy metrics, linearizes low-entropy layers, and fine-tunes to recover any performance loss. This process continues until performance degradation exceeds a threshold δ or no more layers can be removed. The approach generalizes across different rectifier functions (ReLU, LeakyReLU, PReLU, GELU, SiLU) and architectures (ResNet, MobileNetv2, VGG, Swin) by leveraging the fundamental property that all rectifiers can be characterized by the sign of their pre-activations.

## Key Results
- On CIFAR-10, EASIER removes up to 8 layers from ResNet-18 with less than 0.5% top-1 accuracy loss compared to the original model
- EASIER consistently outperforms Layer Folding and Entropy-Guided Pruning in terms of performance for the same number of layers removed across multiple architectures and datasets
- The method achieves significant inference time and FLOPs reductions across various hardware platforms while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neurons can operate in three states (ON, OFF, or mixed), and layers with low entropy (mostly ON or mostly OFF) can be linearized without significant performance loss.
- Mechanism: The entropy metric captures how consistently neurons are in the ON or OFF state. Low entropy indicates the neuron is always in one state, meaning the rectifier function adds no non-linearity and can be replaced with Identity.
- Core assumption: The distribution of pre-activation values (Z) follows a Gaussian product distribution that can be approximated by the given density function, and this distribution correlates with neuron behavior.
- Evidence anchors:
  - [abstract]: "EASIER identifies the average state of a given rectifier-activated neuron for the trained task... An entropy-based metric per layer... to drive the linearization of layers."
  - [section 3.2]: Derivation of the three states and entropy calculation, with explicit formula for Hl,i.
  - [corpus]: No direct corpus evidence; mechanism is novel to this paper.
- Break condition: If neurons never reach high correlation with their inputs (ρ → 1) or always remain balanced between ON and OFF states, the entropy metric will not identify degenerate layers.

### Mechanism 2
- Claim: Removing low-entropy layers reduces depth while maintaining performance because these layers contribute minimal non-linearity.
- Mechanism: The iterative training process finds layers where neurons are consistently ON or OFF, removes their non-linear activation, and fine-tunes to recover any performance loss from removing non-linearity.
- Core assumption: Fine-tuning after layer removal can recover performance degradation, and the remaining layers can compensate for the removed non-linearity.
- Evidence anchors:
  - [abstract]: "EASIER consistently outperforms existing methods like Layer Folding and Entropy-Guided Pruning in terms of performance for the same number of layers removed."
  - [section 3.3]: Alg. 1 shows iterative training, entropy calculation, layer linearization, and fine-tuning loop.
  - [corpus]: Weak evidence; NEPENTHE paper mentions entropy-based pruning but lacks details on this specific mechanism.
- Break condition: If fine-tuning cannot recover performance loss, or if the network architecture prevents effective compensation (e.g., no skip connections).

### Mechanism 3
- Claim: The method generalizes across different rectifier functions and architectures.
- Mechanism: The entropy calculation is based on the sign of pre-activations, which applies to ReLU, LeakyReLU, PReLU, GELU, and SiLU uniformly.
- Core assumption: All rectifier functions share the property that their behavior can be characterized by whether the pre-activation is positive or negative.
- Evidence anchors:
  - [section 4.3]: "Fig. 3b shows the test performance of ResNet-18 on CIFAR-10, for different rectifiers versus the number of linearized layers."
  - [section 3.2]: Definition of sx,l,i = sign(zx,l,i) that applies regardless of specific rectifier.
  - [corpus]: No corpus evidence for this specific generalization claim.
- Break condition: If a rectifier function has fundamentally different behavior that cannot be characterized by sign of pre-activation alone.

## Foundational Learning

- Concept: Probability distribution of product of two correlated Gaussian variables
  - Why needed here: The derivation of neuron state probabilities depends on understanding how the product of weights and inputs is distributed.
  - Quick check question: What is the probability density function for the product of two correlated Gaussian random variables with correlation ρ?

- Concept: Entropy calculation for binary random variables
  - Why needed here: The entropy metric Hl,i = -Σ p(sl,i) log2[p(sl,i)] is the foundation for identifying degenerate layers.
  - Quick check question: What is the entropy of a binary random variable that takes value +1 with probability 0.9 and -1 with probability 0.1?

- Concept: Fine-tuning vs. full retraining
  - Why needed here: The method uses iterative fine-tuning after each layer removal, which is critical for performance recovery.
  - Quick check question: What is the difference between fine-tuning and full retraining in terms of weight updates and learning rate schedules?

## Architecture Onboarding

- Component map: Input → Convolutional/Pooling layers → Rectifier-activated layers (L1, L2, ..., LL) → Output layer. EASIER operates on the rectifier-activated layers between input and output.
- Critical path: Forward propagation through rectifier-activated layers, entropy calculation on training set, backward propagation during fine-tuning after layer removal.
- Design tradeoffs: Iterative approach provides better performance but higher training time vs. one-shot approach that is faster but potentially less effective.
- Failure signatures: Layer collapse (complete pruning of a layer), performance degradation beyond threshold δ, inability to remove any layers on certain architectures.
- First 3 experiments:
  1. Run EASIER on a small ResNet-18 with CIFAR-10 to verify basic functionality and observe entropy distribution across layers.
  2. Test EASIER with different rectifier functions (ReLU, LeakyReLU, GELU) on the same architecture to verify generalization.
  3. Compare EASIER with Layer Folding on a VGG-16 architecture to observe performance differences and identify failure modes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the entropy metric perform with activation functions beyond standard rectifiers (ReLU, LeakyReLU, PReLU, GELU, SiLU)?
- Basis in paper: [explicit] The authors tested EASIER with ReLU, LeakyReLU, PReLU, GELU, and SiLU, observing effectiveness across these activations.
- Why unresolved: The paper only tests a limited set of popular rectifiers. It remains unclear how the entropy metric generalizes to other activation functions like ELU, SELU, or Swish variants.
- What evidence would resolve it: Empirical results showing EASIER's performance across a broader spectrum of activation functions on multiple architectures and datasets.

### Open Question 2
- Question: Can the entropy metric be approximated with a differentiable function to enable end-to-end training?
- Basis in paper: [explicit] The authors note that the entropy metric is non-differentiable, which limits its use in gradient-based optimization methods.
- Why unresolved: While the current implementation relies on a discrete, non-differentiable metric, it's unclear if a differentiable approximation could preserve the metric's effectiveness while enabling integration into end-to-end training pipelines.
- What evidence would resolve it: A proposed differentiable proxy for the entropy metric, along with experimental validation showing similar or improved performance compared to the original non-differentiable metric.

### Open Question 3
- Question: What is the impact of the entropy threshold δ on model performance and compression efficiency?
- Basis in paper: [explicit] The paper mentions that δ is established for each dataset and architecture pair to allow fair comparison, but does not explore its impact in detail.
- Why unresolved: The choice of δ affects the trade-off between performance preservation and compression efficiency, but the paper does not investigate how different δ values influence these factors across various scenarios.
- What evidence would resolve it: A comprehensive sensitivity analysis of δ across multiple architectures, datasets, and compression targets, demonstrating its impact on performance and efficiency trade-offs.

## Limitations
- The entropy metric assumes neurons exhibit clear ON/OFF behavior, which may not hold for all architectures or tasks
- The iterative fine-tuning process is computationally expensive compared to one-shot pruning methods
- Performance on architectures without skip connections remains unverified, with potential for layer collapse

## Confidence
- High confidence: The entropy calculation mechanism and its application to rectifier-activated neurons
- Medium confidence: The ability to recover performance through fine-tuning after layer removal
- Medium confidence: Cross-rectifier generalization, as experimental validation covers only a few rectifier types

## Next Checks
1. Test EASIER on ResNet architectures without skip connections to verify if layer collapse occurs and identify mitigation strategies
2. Compare computational costs of iterative vs. one-shot implementation on a large-scale model to quantify the practical tradeoff
3. Evaluate performance on regression tasks and non-vision domains to assess broader applicability beyond classification