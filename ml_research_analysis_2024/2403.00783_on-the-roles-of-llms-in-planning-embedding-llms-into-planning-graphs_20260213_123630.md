---
ver: rpa2
title: 'On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs'
arxiv_id: '2403.00783'
source_url: https://arxiv.org/abs/2403.00783
tags:
- noop
- truck
- city
- loc-from
- loc-to
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the roles of LLMs in planning by embedding
  them into the planning graph framework. The authors propose a novel LLM-based planning
  framework, LLMs4Plan, which integrates LLMs into two critical steps of graph planning:
  action selection and action set sorting.'
---

# On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs

## Quick Facts
- arXiv ID: 2403.00783
- Source URL: https://arxiv.org/abs/2403.00783
- Reference count: 40
- Key result: Proposed LLMs4Plan framework integrates LLMs into graph planning, achieving 100% success rates in several domains while reducing backtracking nodes exponentially

## Executive Summary
This paper explores the integration of large language models (LLMs) into planning graph frameworks to enhance planning efficiency and success rates. The authors propose LLMs4Plan, a novel framework that embeds LLMs into two critical steps of graph planning: action selection and action set sorting. By leveraging GPT-4's reasoning capabilities, the framework demonstrates significant improvements over traditional graph planning algorithms across ten planning domains. The study provides insights into how LLMs can be effectively utilized to prune search spaces and improve planning outcomes.

## Method Summary
The paper introduces LLMs4Plan, a framework that integrates GPT-4 into graph planning algorithms. The method involves embedding LLMs into two phases of the planning process: action selection (choosing which actions to add to the planning graph) and action set sorting (prioritizing which action sets to expand). The framework is evaluated on ten STRIPS planning domains (gripper, miconic, logistics, movie, blocks, satellite, zenotravel, driverlog, woodworking, openstacks) with 10 problems each. The authors compare LLM-based planning against traditional graph planning algorithms, measuring problem-solving success rates, total expansion actions, and backtracking DFS nodes required.

## Key Results
- LLMs4Plan achieves 100% success rates in several domains (gripper, miconic, logistics, movie, blocks) where traditional GP fails
- The framework reduces the number of nodes required for backtracking DFS by an exponential factor (e.g., from 5,891 to 1 in the 10th blocksworld problem)
- Overall success rate improvement from 40% (traditional GP) to 100% across all ten domains

## Why This Works (Mechanism)
The LLMs4Plan framework works by leveraging GPT-4's ability to reason about action applicability and state transitions. By embedding LLMs into action selection, the framework can identify and prioritize actions that are more likely to lead to goal states, effectively pruning the search space. The action set sorting phase further optimizes the planning process by ordering action sets based on their potential to advance the planning goal. This integration of LLMs addresses the limitations of traditional graph planning algorithms, which often struggle with state space explosion and inefficient action selection.

## Foundational Learning
1. **Planning Graph Construction**: The graph is built layer by layer, adding actions and their effects until a fixed point is reached. This is necessary to systematically explore the state space and ensure all possible action sequences are considered.
   - Quick check: Verify that the planning graph correctly captures all possible action effects and their mutual exclusions.

2. **Action Selection in Graph Planning**: Traditional graph planning algorithms select actions based on predefined heuristics, which may not always lead to optimal or even feasible solutions.
   - Quick check: Compare the action selection process in traditional GP with the LLM-based approach to identify key differences.

3. **Mutual Exclusion Constraints**: These constraints prevent conflicting actions from being executed simultaneously, which is crucial for maintaining plan validity.
   - Quick check: Ensure that the LLM-based pruning does not violate mutual exclusion constraints.

4. **Backtracking DFS**: This search algorithm explores the planning graph by systematically backtracking when dead ends are reached. Its efficiency is critical for solving complex planning problems.
   - Quick check: Measure the reduction in backtracking nodes when using LLMs4Plan compared to traditional GP.

## Architecture Onboarding

### Component Map
LLMs4Plan -> Action Selection (GPT-4) -> Action Set Sorting (GPT-4) -> Planning Graph Expansion -> Solution

### Critical Path
1. Initial state and goal conditions are provided to GPT-4
2. GPT-4 performs action selection to identify candidate actions
3. GPT-4 sorts action sets based on their potential to advance the plan
4. Planning graph is expanded using the selected and sorted actions
5. Solution is extracted from the expanded planning graph

### Design Tradeoffs
The primary tradeoff in LLMs4Plan is between computational efficiency and the potential for incorrect pruning. While LLMs can significantly reduce the search space, there is a risk of pruning necessary actions, leading to unsolvable problems. The paper addresses this by using a pruning rate parameter (β) to control the extent of LLM-based pruning.

### Failure Signatures
1. **Incorrect Pruning**: LLMs may prune necessary actions, resulting in unsolvable problems. This can be diagnosed by checking if solutions exist in the LLM's candidate action sets.
2. **Performance Degradation**: As the planning graph deepens, longer input prompts may lead to increased latency and reduced LLM performance.
   - Diagnostic: Track success rates at different expansion depths to identify performance degradation.

### First Experiments
1. Run LLMs4Plan on the gripper domain with varying pruning rates (β) to find the optimal balance between efficiency and correctness.
2. Compare the success rates and backtracking nodes of LLMs4Plan against traditional GP on the blocksworld domain.
3. Test the framework's scalability by running it on the openstacks domain, which has the largest state space among the tested domains.

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not provide detailed specifications of the GPT-4 prompts used, which could affect reproducibility.
- The framework's performance is highly dependent on the quality of prompt engineering, which is not thoroughly documented.
- The study focuses on STRIPS domains without action parameters, leaving the scalability to complex domains untested.

## Confidence
- High confidence in the theoretical framework and integration approach of LLMs into planning graphs
- Medium confidence in the reported quantitative improvements due to limited access to implementation details
- Low confidence in the generalizability of results to domains beyond the ten tested STRIPS domains

## Next Checks
1. Replicate the experiments using the publicly available planning domains (gripper, miconic, logistics, etc.) with the LLMs4Plan framework and independently verify the success rates and node reduction claims.
2. Test the framework on additional planning domains not included in the original study to assess generalizability of the approach.
3. Conduct ablation studies to determine the individual contributions of action selection versus action set sorting to the overall performance improvements.