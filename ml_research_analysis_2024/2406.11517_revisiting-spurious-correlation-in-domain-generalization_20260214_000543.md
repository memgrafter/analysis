---
ver: rpa2
title: Revisiting Spurious Correlation in Domain Generalization
arxiv_id: '2406.11517'
source_url: https://arxiv.org/abs/2406.11517
tags:
- spurious
- correlation
- causal
- generalization
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper revisits spurious correlation in domain generalization
  by proposing a novel structural causal model (SCM) for representation learning.
  Unlike prior work that focuses on data generation, the authors build an SCM for
  the representation learning process and identify collider-specific spurious correlation
  as the key mechanism in OOD scenarios.
---

# Revisiting Spurious Correlation in Domain Generalization

## Quick Facts
- arXiv ID: 2406.11517
- Source URL: https://arxiv.org/abs/2406.11517
- Reference count: 40
- Key outcome: Proposes propensity score weighted estimator for spurious correlation in domain generalization, improving OOD performance by 1.1% over BalancingERM and 0.8% over BalancingCORAL on average across six benchmarks.

## Executive Summary
This paper addresses spurious correlation in domain generalization by proposing a novel structural causal model (SCM) for representation learning. Unlike prior work focusing on data generation, the authors build an SCM for the representation learning process and identify collider-specific spurious correlation as the key mechanism in OOD scenarios. They introduce a propensity score weighted estimator that can be integrated as a plug-and-play module into any existing OOD method. The method uses FFT to separate invariant and spurious features, K-means clustering to estimate propensity scores, and a pairing scheme to improve estimation accuracy. Experiments on six benchmarks show consistent performance gains.

## Method Summary
The paper proposes a propensity score weighted (PSW) estimator to control confounding bias in domain generalization. The method builds an SCM for representation learning, identifying collider-specific spurious correlation as the key mechanism. It uses FFT to separate high-frequency (invariant) and low-frequency (spurious) features, then applies K-means clustering to estimate propensity scores. A pairing scheme augments samples to improve estimation accuracy. The PSW regularization is integrated into existing OOD methods through a modified loss function. The approach requires multiple training domains and assumes the collider structure Y→E←S for spurious correlation.

## Key Results
- Improved performance over BalancingERM by 1.1% and BalancingCORAL by 0.8% on average across six benchmarks
- Consistent performance gains across ColoredMNIST, RotatedMNIST, VLCS, PACS, OfficeHome, and TerraIncognita
- Validated correctness of collider-specific spurious correlation mechanism through controlled experiments
- Demonstrated effectiveness of propensity score weighted approach as a plug-and-play module

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Collider-specific spurious correlation is the correct OOD-oriented SCM, not fork-specific spurious correlation.
- Mechanism: The SCM identifies E as a collider node (Y→E←S). Conditioning on E opens the backdoor path C←X→S→E←Y, introducing confounding between C and Y. By adjusting the spurious feature S (backdoor adjustment), we block the backdoor path C←X→S→Y, making C→Y non-confounding.
- Core assumption: The spurious correlation S−Y is due to a collider structure Y→E←S, not a latent common cause Y←L→S.
- Evidence anchors:
  - [abstract] The paper states: "We underscore that adjusting erroneous covariates introduces bias, thus necessitating the correct selection of spurious correlation mechanisms based on practical application scenarios."
  - [section 2.3] The paper proposes collider-specific spurious correlation: "Considering a collider structure Y→E←S, we know that Y/upmodelsS. However, Y and S may be dependent on each other given E."
  - [corpus] Weak evidence: The related papers discuss invariant learning and spurious correlations, but do not directly address the distinction between fork-specific and collider-specific spurious correlation mechanisms.
- Break condition: If the true underlying causal structure is fork-specific spurious correlation (S←L→Y) rather than collider-specific, then adjusting S would introduce bias instead of removing it.

### Mechanism 2
- Claim: Propensity score weighted (PSW) estimation reweights the observed distribution to simulate the post-intervention distribution.
- Mechanism: The PSW estimator assigns weights 1/P(C=c|S=s) to each sample, amplifying the probability of each (Y=y,C=c,S=s) in the overall data. This reweights the observational distribution to approximate the interventional distribution P(Y=do(C=c)).
- Core assumption: The propensity scores P(C=c|S=s) can be accurately estimated from the observed data.
- Evidence anchors:
  - [section 3.1] The paper derives: "By weighting each available sample with the factor 1/P(C = c ∣S = s), we achieve estimation of causal effects."
  - [section 3.2] The paper proposes using FFT and K-means clustering to estimate propensity scores: "We adopt FFT to extract the spectrum... Subsequently, we separate the low-frequency part... and high-frequency part..."
  - [corpus] No direct evidence found in related papers about propensity score estimation methods.
- Break condition: If the propensity score estimation is inaccurate (e.g., due to insufficient sample size or poor feature separation), the reweighting will be biased, leading to incorrect causal effect estimation.

### Mechanism 3
- Claim: The pairing scheme improves propensity score estimation by expanding the available value set of data.
- Mechanism: By randomly pairing invariant features C from one sample with spurious features S from another sample, the method creates "simulated samples" that increase the diversity of the S values for each C value, leading to more accurate propensity score estimation.
- Core assumption: The pairing scheme creates realistic samples that preserve the underlying causal relationships.
- Evidence anchors:
  - [section 3.2] The paper describes the pairing scheme: "We augment the samples by randomly pairing of C and S to increase the completeness of the available value set of data."
  - [section 3.2] The paper explains: "By training the invariant function f(⋅) on ˜Dv, we can update the parameters of the encoder g(⋅), thereby more accurately extracting ci and si."
  - [corpus] No direct evidence found in related papers about pairing schemes for propensity score estimation.
- Break condition: If the pairing scheme creates unrealistic samples that do not preserve the causal relationships, the propensity score estimation will be biased.

## Foundational Learning

- Concept: Structural Causal Models (SCM)
  - Why needed here: The paper builds an SCM for the representation learning process to analyze spurious correlation mechanisms in OOD scenarios.
  - Quick check question: What are the three types of paths in a DAG according to the d-separation criterion?

- Concept: Backdoor Adjustment Criterion
  - Why needed here: The paper uses backdoor adjustment to control confounding bias by conditioning on the spurious feature S.
  - Quick check question: What are the two conditions that a set of variables Z must satisfy to be a valid backdoor adjustment set for the causal effect of X on Y?

- Concept: Propensity Score Estimation
  - Why needed here: The paper introduces a propensity score weighted estimator to reweight the observed distribution and estimate causal effects.
  - Quick check question: What is the formula for the propensity score P(C=c|S=s) in the context of this paper?

## Architecture Onboarding

- Component map:
  Images from multiple domains -> FFT module -> Encoder -> Clustering -> Pairing scheme -> PSW estimator -> Base OOD method

- Critical path:
  1. Separate invariant and spurious features using FFT
  2. Estimate propensity scores using clustering
  3. Create simulated samples using pairing scheme
  4. Compute PSW regularization term
  5. Integrate PSW regularization into base OOD method

- Design tradeoffs:
  - Filter size S in FFT: Larger S captures more high-frequency information but may include some spurious features; smaller S is more selective but may lose some invariant features
  - Number of clusters n for spurious features: More clusters provide finer-grained propensity score estimation but may overfit; fewer clusters are more robust but less precise
  - Mixing ratio δ in pairing scheme: Larger δ creates more diverse simulated samples but may generate unrealistic combinations; smaller δ preserves more realism but provides less diversity

- Failure signatures:
  - Poor performance on domains with similar spurious features: Indicates inaccurate propensity score estimation
  - Degraded performance when using pairing scheme: Suggests the simulated samples are unrealistic
  - Sensitivity to hyper-parameters (α, β): Indicates instability in the PSW regularization

- First 3 experiments:
  1. Test FFT-based feature separation on ColoredMNIST with varying filter sizes S
  2. Evaluate propensity score estimation accuracy using ground truth labels on a controlled dataset
  3. Assess the impact of the pairing scheme on propensity score estimation and final performance

## Open Questions the Paper Calls Out

- Question: How does the propensity score weighted estimator perform when the spurious correlation is not binary (e.g., color in ColoredMNIST)?
- Question: What is the impact of incorrect propensity score estimation on OOD generalization performance?
- Question: How does the method scale to high-dimensional data where FFT-based feature separation may be less effective?
- Question: What is the theoretical bound on the number of domains required for the propensity score estimation to converge?

## Limitations

- The SCM analysis assumes the collider structure is correctly identified, yet provides limited empirical validation across diverse real-world scenarios
- The propensity score estimation relies on K-means clustering, which may struggle with high-dimensional or continuous feature spaces
- The pairing scheme introduces synthetic samples that could potentially distort the true data distribution if not carefully controlled

## Confidence

- High confidence: The PSW estimator integration into existing OOD methods and the empirical performance improvements on benchmark datasets
- Medium confidence: The theoretical identification of collider-specific spurious correlation as the dominant mechanism in OOD scenarios
- Low confidence: The robustness of the FFT-based feature separation across different types of spurious correlations and the generalization of results beyond the tested benchmark datasets

## Next Checks

1. Conduct ablation studies to quantify the individual contributions of FFT-based feature separation, K-means clustering, and the pairing scheme to overall performance
2. Test the method on datasets with known ground truth causal structures to validate the accuracy of spurious correlation identification
3. Evaluate performance sensitivity to hyper-parameter choices (filter size S, number of clusters n, mixing ratio δ) across different domains and spurious correlation types