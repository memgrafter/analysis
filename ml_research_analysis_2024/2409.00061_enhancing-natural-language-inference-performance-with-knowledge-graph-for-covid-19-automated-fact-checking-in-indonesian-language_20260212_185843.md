---
ver: rpa2
title: Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19
  Automated Fact-Checking in Indonesian Language
arxiv_id: '2409.00061'
source_url: https://arxiv.org/abs/2409.00061
tags:
- covid-19
- language
- fact-checking
- knowledge
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study proposes using a Knowledge Graph (KG) to enhance Natural
  Language Inference (NLI) performance for automated COVID-19 fact-checking in the
  Indonesian language. The model architecture integrates three modules: a fact module
  that retrieves and processes information from the COVID-19 KG Bahasa Indonesia,
  an NLI module that handles semantic relationships between premise and hypothesis
  sentences, and a classifier module that produces the final result.'
---

# Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language

## Quick Facts
- arXiv ID: 2409.00061
- Source URL: https://arxiv.org/abs/2409.00061
- Reference count: 0
- Primary result: 86.16% accuracy with XLM-RoBERTa for Indonesian COVID-19 fact-checking using KG

## Executive Summary
This study proposes a Knowledge Graph (KG)-enhanced Natural Language Inference (NLI) model for automated COVID-19 fact-checking in Indonesian. The model integrates three modules: a fact module that retrieves information from a COVID-19 KG Bahasa Indonesia, an NLI module that handles semantic relationships between premise and hypothesis sentences, and a classifier module that produces the final result. The model was trained on a generated Indonesian COVID-19 fact-checking dataset containing 18,750 premise-hypothesis pairs and evaluated across multiple language models, showing that KG incorporation significantly improves NLI performance.

## Method Summary
The proposed model uses a three-module architecture where the fact module retrieves and processes information from the COVID-19 KG Bahasa Indonesia, the NLI module handles semantic relationships between premise and hypothesis sentences, and the classifier module produces the final result. The model was trained with a learning rate of 2e-5, batch size of 16, cross-entropy loss, Adam optimizer, and early stopping with patience of 5. Training was conducted on a dataset of 18,750 premise-hypothesis pairs covering entailment, contradiction, and neutral relationships.

## Key Results
- Best accuracy of 0.8616 achieved with XLM-RoBERTa
- 1.65% improvement over baseline models without KG
- Consistent performance gains across different PLMs when KG is incorporated

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Knowledge Graph provides domain-specific factual context that improves model inference accuracy.
- Mechanism: The fact module retrieves triplets from the COVID-19 KG Bahasa Indonesia and converts them into fact sentences, allowing the model to ground semantic reasoning in real-world facts.
- Core assumption: The KG contains accurate and relevant information that matches the claims in the test data.
- Evidence anchors: [abstract] "incorporating KGs can significantly improve NLI performance in fact-checking, achieving a maximum accuracy of 0.8616."

### Mechanism 2
- Claim: Concatenating NLI and fact representations enriches the semantic embedding for classification.
- Mechanism: The model processes premise-hypothesis pairs through the NLI module and fact sentences through the fact module, with resulting vector representations concatenated before feeding into the classifier.
- Core assumption: Simple concatenation preserves complementary information without interference.
- Evidence anchors: [abstract] "The representation vectors from both modules are concatenated and fed into the classifier module to produce the final result."

### Mechanism 3
- Claim: Using XLM-RoBERTa as the PLM yields the best accuracy because it handles multilingual contexts effectively.
- Mechanism: XLM-RoBERTa processes both premise-hypothesis pairs and fact sentences, leveraging its multilingual pre-training to better capture cross-lingual semantics relevant to Indonesian COVID-19 text.
- Core assumption: XLM-RoBERTa's multilingual pre-training aligns well with Indonesian domain language.
- Evidence anchors: [abstract] "achieving the best accuracy of 0.8616 with XLM-RoBERTa, representing a 1.65% improvement over baseline models."

## Foundational Learning

- Concept: Natural Language Inference (NLI)
  - Why needed here: NLI is the core task used to determine entailment, contradiction, or neutral relationships between premise and hypothesis sentences in fact-checking.
  - Quick check question: What are the three possible output labels in NLI for fact-checking?

- Concept: Knowledge Graph (KG) structure and retrieval
  - Why needed here: KG provides external factual context; understanding triplet extraction and sentence generation is essential for the fact module.
  - Quick check question: How are KG triplets converted into fact sentences in this model?

- Concept: Transformer-based language models and fine-tuning
  - Why needed here: The model uses PLMs (XLM-RoBERTa, mBERT, etc.) for both NLI and fact modules; understanding fine-tuning is critical for implementation.
  - Quick check question: What optimizer and learning rate were used during training?

## Architecture Onboarding

- Component map: Premise/Hypothesis → NLI Module → Fact Module → Concatenation → Classifier → Output
- Critical path: Premise/Hypothesis → NLI Module → Fact Module → Concatenation → Classifier → Output
- Design tradeoffs:
  - Using KG increases accuracy but depends on KG completeness and retrieval quality
  - Concatenation is simple but may not optimally fuse representations
  - XLM-RoBERTa gives best accuracy but is computationally heavier than monolingual models
- Failure signatures:
  - Low accuracy improvement: KG retrieval is ineffective or KG is incomplete
  - High variance in results: Fact sentences are noisy or mismatched
  - Overfitting: Model trained too long without early stopping
- First 3 experiments:
  1. Baseline: Train model without KG; measure accuracy on validation set
  2. KG-enabled: Train with KG; compare accuracy and check if accuracy improves
  3. PLM comparison: Swap XLM-RoBERTa with mBERT and indolem/indobert; measure accuracy and training time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed model architecture compare to existing KG-enhanced NLI models like KnowBERT or K-BERT in terms of accuracy and computational efficiency?
- Basis in paper: [explicit] The paper mentions existing KG-enhanced NLI models like KnowBERT and K-BERT, but does not compare its proposed model to these approaches.
- Why unresolved: The paper focuses on its own model's performance without benchmarking against other KG-enhanced NLI models.
- What evidence would resolve it: Comparative experiments measuring accuracy and computational efficiency against models like KnowBERT and K-BERT on the same dataset.

### Open Question 2
- Question: What is the impact of the quality and completeness of the COVID-19 KG Bahasa Indonesia on the model's performance, and how can this be quantified?
- Basis in paper: [explicit] The paper mentions that the incompleteness of the KG may have reduced the available information and limited fact retrieval, but does not quantify this impact.
- Why unresolved: The paper does not provide a systematic analysis of how KG quality and completeness affect model performance.
- What evidence would resolve it: Experiments varying the completeness and quality of the KG to measure their impact on model accuracy and F1-score.

### Open Question 3
- Question: How does the word-matching retrieval mechanism perform compared to more advanced context-aware retrieval methods, and what are the potential improvements?
- Basis in paper: [explicit] The paper identifies the word-matching retrieval mechanism as a limitation, noting that it relies solely on word-to-word matching and ignores contextual cues.
- Why unresolved: The paper does not explore alternative retrieval methods or quantify the potential improvements from context-aware approaches.
- What evidence would resolve it: Comparative experiments using different retrieval methods (e.g., semantic search, neural retrieval) to measure improvements in accuracy and F1-score.

## Limitations
- Effectiveness depends entirely on KG quality and completeness, which is not validated
- Word-matching retrieval mechanism lacks transparency and may miss semantically equivalent facts
- 1.65% accuracy improvement over baseline is modest relative to added complexity

## Confidence

| Claim | Confidence |
|-------|------------|
| General architecture description and training methodology | High |
| XLM-RoBERTa achieves best performance | Medium |
| Actual impact of Knowledge Graph on performance | Low |

## Next Checks
1. Conduct independent evaluation of COVID-19 KG Bahasa Indonesia's coverage and accuracy
2. Implement and test fact module's word-matching retrieval with controlled experiments
3. Run ablation studies comparing different PLMs and fusion strategies