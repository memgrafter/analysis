---
ver: rpa2
title: Counterfactual Fairness by Combining Factual and Counterfactual Predictions
arxiv_id: '2409.01977'
source_url: https://arxiv.org/abs/2409.01977
tags:
- counterfactual
- fairness
- should
- optimal
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes the theoretical tradeoff between counterfactual
  fairness and predictive performance, proving that optimal fair predictors combine
  factual and counterfactual predictions. The authors quantify the inherent performance
  loss using excess risk bounds, demonstrating that this loss depends on the underlying
  causal dependencies between sensitive attributes and outcomes.
---

# Counterfactual Fairness by Combining Factual and Counterfactual Predictions

## Quick Facts
- arXiv ID: 2409.01977
- Source URL: https://arxiv.org/abs/2409.01977
- Authors: Zeyu Zhou, Tianci Liu, Ruqi Bai, Jing Gao, Murat Kocaoglu, David I. Inouye
- Reference count: 40
- Primary result: Establishes theoretical tradeoff between counterfactual fairness and predictive performance, proving optimal fair predictors combine factual and counterfactual predictions

## Executive Summary
This paper establishes the theoretical tradeoff between counterfactual fairness and predictive performance, proving that optimal fair predictors can be constructed by combining factual and counterfactual predictions. The authors quantify the inherent performance loss using excess risk bounds and demonstrate that this loss depends on the underlying causal dependencies between sensitive attributes and outcomes. They propose a practical plugin method (PCF) that works with incomplete causal knowledge, combining factual and counterfactual predictions using a pre-trained predictor. Empirical results on synthetic and semi-synthetic datasets validate their theoretical findings and show that their approach outperforms existing methods in achieving both fairness and accuracy.

## Method Summary
The paper proposes a plugin counterfactual fairness (PCF) method that combines factual and counterfactual predictions using a pre-trained predictor. The method first trains a potentially unfair predictor on the data, then estimates counterfactual samples using a counterfactual generating mechanism (CGM). The final predictions are computed as the average of the predictor's outputs on the factual sample and its counterfactual. This approach can achieve perfect counterfactual fairness if the CGM is known, and performs well with estimated counterfactuals if the estimation error is bounded and the predictor is smooth. The method is agnostic to the choice of predictor and can be applied in scenarios with incomplete causal knowledge.

## Key Results
- Optimal fair predictors under perfect counterfactual fairness are constructed by averaging predictions from factual and counterfactual points
- The inherent tradeoff between counterfactual fairness and predictive performance is quantified by excess risk bounds
- PCF method outperforms existing fairness methods (CFU, CFR, ECOCF) on synthetic and semi-synthetic datasets
- Performance degradation with counterfactual estimation errors is bounded when the predictor is smooth

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal fair predictors under perfect counterfactual fairness can be constructed by averaging predictions from factual and counterfactual points.
- Mechanism: The paper proves that if a predictor is counterfactually fair, it must output the same value for a sample and all its counterfactuals. The optimal fair predictor is therefore the weighted average of the optimal (potentially unfair) predictions at the factual point and its counterfactuals.
- Core assumption: The causal model is invertible, meaning each factual sample has a unique counterfactual, and there is strong mutual information between X and U given A.
- Evidence anchors:
  - [abstract]: "We first propose a simple but effective method to cast an optimal but potentially unfair predictor into a fair one without losing the optimality."
  - [section 3.2]: "Theorem 3.3... an optimal and fair predictor... is given by the average of the optimal (potentially unfair) predictions on itself and all possible counterfactuals."
  - [corpus]: Weak - related works focus on counterfactual fairness but don't discuss this specific averaging mechanism.
- Break condition: If the causal model is not invertible, the unique counterfactual assumption fails, and the averaging mechanism may not hold.

### Mechanism 2
- Claim: The inherent tradeoff between counterfactual fairness and predictive performance is quantified by the excess risk, which depends on the dependency between the sensitive attribute and the outcome.
- Mechanism: The paper characterizes the excess risk of the Bayes optimal predictor under counterfactual fairness constraints. This excess risk is determined by the variance of the sensitive attribute and the expected squared difference in outcome predictions under different attribute values, given the latent confounders.
- Core assumption: The underlying causal mechanism determines the dependency between the sensitive attribute and the outcome.
- Evidence anchors:
  - [abstract]: "We first propose a simple but effective method to cast an optimal but potentially unfair predictor into a fair one without losing the optimality. By analyzing its excess risk in order to achieve CF, we quantify this inherent trade-off."
  - [section 3.2]: "Theorem 3.4... the inherent trade-off between CF and predictive performance... is given by... for regression tasks... and for classification tasks..."
  - [corpus]: Weak - related works discuss fairness-utility tradeoffs but not specifically for counterfactual fairness with this mathematical characterization.
- Break condition: If the dependency between the sensitive attribute and the outcome is not captured by the causal model, the excess risk characterization may not hold.

### Mechanism 3
- Claim: In scenarios with incomplete causal knowledge, a plugin method using a pre-trained predictor and estimated counterfactuals can achieve good fairness and accuracy.
- Mechanism: The paper proposes a plugin counterfactual fairness (PCF) method that combines factual and counterfactual predictions using a pre-trained predictor. This method can achieve perfect counterfactual fairness if the counterfactual generating mechanism is known, and it can still perform well with estimated counterfactuals if the estimation error is bounded and the predictor is smooth.
- Core assumption: A pre-trained predictor is available and can be used as a proxy for the optimal predictor.
- Evidence anchors:
  - [abstract]: "Built upon it, we propose a performant algorithm that can be applied in such scenarios."
  - [section 3.3]: "Algorithm 1 Plug-in Counterfactual Fairness (PCF)... It is noteworthy that PCF is agnostic to the training of predictor ϕ that can be determined by the user freely."
  - [corpus]: Weak - related works discuss counterfactual fairness but not specifically this plugin approach with pre-trained models.
- Break condition: If the pre-trained predictor is not a good proxy for the optimal predictor, or if the counterfactual estimation error is too large, the method may not achieve good fairness and accuracy.

## Foundational Learning

- Concept: Counterfactual Fairness
  - Why needed here: The paper focuses on counterfactual fairness as the fairness notion, so understanding this concept is crucial for grasping the problem and solution.
  - Quick check question: What is the key requirement for a predictor to be counterfactually fair?

- Concept: Structural Causal Models (SCMs)
  - Why needed here: The paper uses SCMs to formalize the causal relationships between variables and to define counterfactuals, so understanding SCMs is necessary for following the theoretical analysis.
  - Quick check question: In an SCM, what do the functions F map from and to?

- Concept: Excess Risk
  - Why needed here: The paper quantifies the tradeoff between counterfactual fairness and predictive performance using excess risk, so understanding this concept is important for interpreting the results.
  - Quick check question: How is excess risk defined in the context of this paper?

## Architecture Onboarding

- Component map: X, A, Y, U -> SCM -> Predictor ϕ -> Counterfactual Generating Mechanism G -> PCF algorithm
- Critical path:
  1. Acquire or simulate data with known causal relationships
  2. Train a predictor ϕ on the data
  3. Estimate or acquire the counterfactual generating mechanism G
  4. Apply the PCF algorithm to combine factual and counterfactual predictions
  5. Evaluate the fairness and accuracy of the resulting predictor
- Design tradeoffs:
  - Invertibility vs. generality: The theoretical analysis assumes invertibility, but the method may work with weaker assumptions in practice.
  - Accuracy vs. fairness: The tradeoff between counterfactual fairness and predictive performance, quantified by the excess risk.
  - Complete vs. incomplete causal knowledge: The method can handle both scenarios, but performance may degrade with incomplete knowledge.
- Failure signatures:
  - High TE: The method is not achieving counterfactual fairness, possibly due to large counterfactual estimation errors or a poor pre-trained predictor.
  - High excess risk: The method is sacrificing too much predictive performance for counterfactual fairness, possibly due to a strong dependency between the sensitive attribute and the outcome.
  - Instability: The method may be sensitive to hyperparameters or the choice of pre-trained predictor.
- First 3 experiments:
  1. Synthetic data with known ground truth counterfactuals and U: Validate the optimality of the PCF method and the excess risk characterization.
  2. Synthetic data with estimated counterfactuals and U: Evaluate the performance of the PCF method with counterfactual estimation errors.
  3. Semi-synthetic data with limited causal knowledge: Assess the effectiveness of the PCF method in a more practical scenario.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of counterfactual fairness methods degrade when the invertibility assumption between X and U given A is violated in practice?
- Basis in paper: [explicit] The paper states that the invertibility assumption "might be restrictive in certain scenarios" and tests performance after relaxing it in semi-synthetic experiments
- Why unresolved: The paper only provides empirical validation on semi-synthetic datasets, not real-world data where this assumption would likely be violated
- What evidence would resolve it: Experiments on real-world datasets showing performance degradation when invertibility is violated, along with analysis of how severe the violation needs to be to significantly impact results

### Open Question 2
- Question: What is the minimum level of counterfactual estimation accuracy required to achieve meaningful counterfactual fairness without excessive performance degradation?
- Basis in paper: [explicit] Theorem 3.6 provides bounds on TE and excess risk due to counterfactual estimation error, but doesn't specify practical thresholds
- Why unresolved: The paper provides theoretical bounds but doesn't translate these into practical guidelines for acceptable estimation error
- What evidence would resolve it: Empirical studies showing the relationship between counterfactual estimation accuracy and both fairness metrics and prediction performance across different domains

### Open Question 3
- Question: How can counterfactual fairness methods be extended to handle multi-class sensitive attributes beyond binary A?
- Basis in paper: [inferred] The paper explicitly states it focuses on binary A "given its pivotal importance in the literature" but notes that methods "can be naturally extended to multi-class A"
- Why unresolved: The paper doesn't provide any theoretical analysis or empirical validation for multi-class scenarios
- What evidence would resolve it: Theoretical analysis of how the optimal predictor formula changes for multi-class A, along with empirical validation showing performance across different numbers of sensitive attribute classes

## Limitations
- Theoretical analysis relies on strong assumptions like invertibility and complete causal knowledge that may not hold in practice
- Empirical validation limited to synthetic and semi-synthetic datasets rather than real-world data
- Performance degradation with counterfactual estimation errors not thoroughly characterized in practical scenarios

## Confidence
- Theoretical claims: Medium-High (mathematical rigor but strong assumptions)
- Empirical validation: Medium (synthetic datasets with known ground truth)
- Practical applicability: Medium (plugin method but real-world causal structures unknown)

## Next Checks
1. Replicate synthetic experiments to verify excess risk bounds and PCF performance
2. Test PCF method on semi-synthetic Law School dataset with estimated counterfactuals
3. Analyze failure modes when invertibility assumption is violated in practice