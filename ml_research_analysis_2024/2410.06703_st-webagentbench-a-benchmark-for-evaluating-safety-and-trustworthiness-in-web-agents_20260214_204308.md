---
ver: rpa2
title: 'ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in
  Web Agents'
arxiv_id: '2410.06703'
source_url: https://arxiv.org/abs/2410.06703
tags:
- agents
- agent
- policies
- task
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ST-WebAgentBench, the first benchmark specifically
  designed to evaluate the safety and trustworthiness of web agents in enterprise
  environments. Unlike previous benchmarks that focus solely on task completion, ST-WebAgentBench
  assesses agents across six dimensions of safety and trustworthiness, including user
  consent, boundary limitations, and policy adherence.
---

# ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents

## Quick Facts
- arXiv ID: 2410.06703
- Source URL: https://arxiv.org/abs/2410.06703
- Reference count: 40
- Key outcome: Introduces ST-WebAgentBench, the first benchmark specifically designed to evaluate safety and trustworthiness of web agents in enterprise environments, revealing that state-of-the-art agents achieve less than two-thirds of their nominal completion rate when evaluated under policy constraints.

## Executive Summary
This paper introduces ST-WebAgentBench, the first benchmark specifically designed to evaluate the safety and trustworthiness of web agents in enterprise environments. Unlike previous benchmarks that focus solely on task completion, ST-WebAgentBench assesses agents across six dimensions of safety and trustworthiness, including user consent, boundary limitations, and policy adherence. The benchmark introduces the Completion under Policy (CuP) metric, which only credits task completions that respect all applicable policies. Evaluating three state-of-the-art agents reveals that their average CuP is less than two-thirds of their nominal completion rate, exposing critical safety gaps. The paper also proposes architectural principles for building policy-aware agents and releases code, evaluation templates, and a policy-authoring interface to support further research in developing trustworthy web agents.

## Method Summary
ST-WebAgentBench is built on BrowserGym, a web-based RL environment, and extends it with human-in-the-loop actions and policy evaluation functions. The benchmark includes 222 tasks across three enterprise applications (GitLab, ShoppingAdmin, SuiteCRM), each paired with safety and trustworthiness policies. The Completion Under Policy (CuP) metric is introduced to evaluate both task success and policy compliance, with agents receiving credit only when they complete tasks without violating any policies. The evaluation measures completion rates, CuP scores, and policy violations across six safety dimensions: user consent, boundary limitations, strict execution, interpretability, human-in-the-loop requirements, and behavioral constraints.

## Key Results
- State-of-the-art agents achieve less than two-thirds of their nominal completion rate when evaluated under policy constraints
- The CuP metric effectively reveals safety gaps that traditional task completion metrics miss
- Agents struggle significantly with policy compliance as cognitive load increases, with performance dropping from 14.8 to 11.5 when moving from low to high cognitive load scenarios
- Policy violations are most common in user consent and strict execution categories, indicating critical safety weaknesses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Completion under Policy (CuP) metric effectively captures both task success and policy compliance, creating a more realistic safety assessment than raw task completion rates.
- Mechanism: CuP multiplies task completion score by a binary indicator of whether any policy violations occurred (1 if zero violations, 0 otherwise), forcing agents to choose between task success and policy compliance.
- Core assumption: Enterprise environments require strict adherence to policies before task completion matters; even one violation renders the agent unsafe.
- Evidence anchors:
  - [abstract] "We propose the Completion under Policy (CuP) metric, which only credits task completions that respect all applicable policies."
  - [section] "The CuP metric for each task is then defined as: CuP = Ctask · 1{Vtotal=0}."
- Break condition: If enterprise environments allow for "acceptable risk" thresholds or partial credit for near-misses, CuP's all-or-nothing approach would be too harsh and miss nuanced safety improvements.

### Mechanism 2
- Claim: Hierarchical policy enforcement (organizational > user > task) creates a clear precedence structure that prevents agents from prioritizing immediate task completion over safety.
- Mechanism: The policy hierarchy function Ht(Porg, Puser, Ptask) applies precedence constraints where agents must satisfy organizational policies first, then user preferences, then task instructions.
- Core assumption: Clear policy precedence prevents conflicts and ensures that safety constraints always override task completion incentives.
- Evidence anchors:
  - [section] "The agent must choose actions that satisfy the policy hierarchy πH(St) = arg max[at∈A(St)][Rtask(St, at)] subject to at ∈ Ht."
  - [section] "These policies have the highest precedence. The agent must comply with all organizational policies at all times."
- Break condition: If policies overlap or create contradictions, the strict hierarchy may lead to deadlock situations where no action satisfies all constraints, requiring human intervention.

### Mechanism 3
- Claim: Policy-aware agent architecture with pre- and post-execution hooks enables systematic enforcement of safety constraints across all agent components.
- Mechanism: The policy agent monitors and intervenes in the orchestration, task planner, semantic perception, and action agent workflows through interceptor patterns and aspect-oriented programming.
- Core assumption: Modular agent architectures can be effectively instrumented with policy enforcement hooks without significant performance degradation.
- Evidence anchors:
  - [section] "The policy agent is responsible for loading and constructing the hierarchy of policies... It is also responsible for safeguarding, blocking, validating, and intervening with the control flow of all other agents."
  - [section] "This can be achieved through multiple design patterns such as interceptor patterns (pre and post execution hooks called by the orchestrator) or aspect-oriented programming (injected hooks)."
- Break condition: If hook overhead becomes prohibitive or if agents find ways to bypass policy checks through creative action sequences, the enforcement mechanism loses effectiveness.

## Foundational Learning

- Concept: Policy hierarchy precedence
  - Why needed here: Understanding how organizational, user, and task policies interact and which takes priority is fundamental to designing agents that respect safety constraints.
  - Quick check question: If an organizational policy prohibits deleting records but a task instruction requires creating a new issue that requires deleting an old one, what should the agent do?

- Concept: CuP metric calculation
  - Why needed here: The CuP metric is the core evaluation measure that combines task completion with policy compliance, making it essential for interpreting benchmark results.
  - Quick check question: Given a task completion score of 0.8 and 2 policy violations, what is the CuP score?

- Concept: Policy violation categorization
  - Why needed here: Different types of policy violations (user consent, boundary, strict execution) indicate different safety weaknesses and require different remediation approaches.
  - Quick check question: Which policy category would be violated if an agent proceeds to submit a form without asking user permission?

## Architecture Onboarding

- Component map: Policy agent (center) -> Orchestration agent (control flow) -> Task planner (intent understanding) -> Semantic perception (UI understanding) -> Action agent (low-level actions). All components have pre- and post-execution hooks for policy enforcement.

- Critical path: User request → Task Planner → Policy Agent validation → Semantic Perception → Action Agent → Policy Agent validation → Execution. The policy agent acts as a gatekeeper at multiple points.

- Design tradeoffs: Strict policy enforcement vs. task completion flexibility; comprehensive safety vs. performance overhead; hierarchical policy structure vs. policy conflict resolution complexity.

- Failure signatures: Agents that consistently achieve high task completion but low CuP scores; agents that get stuck in loops when policies conflict; agents that attempt to bypass policy checks through creative action sequences.

- First 3 experiments:
  1. Run a simple task with only organizational policies enabled to verify basic policy enforcement works
  2. Add user consent policies and test with a task requiring form submission to verify the human-in-the-loop mechanism
  3. Introduce conflicting policies at different hierarchy levels to test how the agent handles precedence and conflict resolution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Completion under Policy (CuP) metric compare to traditional task completion metrics in predicting real-world agent performance?
- Basis in paper: [explicit] The paper introduces CuP as a new metric that credits only task completions respecting all applicable policies, contrasting it with raw task completion rates.
- Why unresolved: The paper evaluates CuP alongside traditional metrics but does not provide a comparative analysis of how well CuP predicts actual enterprise deployment success versus traditional metrics.
- What evidence would resolve it: A longitudinal study comparing agents evaluated with CuP versus traditional metrics in real enterprise environments, measuring actual deployment success and safety incidents.

### Open Question 2
- Question: How can agents be designed to better handle high cognitive load scenarios while maintaining policy compliance?
- Basis in paper: [inferred] The paper notes that agents struggle with compliance as cognitive load increases, with AWM's performance dropping from 14.8 to 11.5 when moving from low to high cognitive load scenarios.
- Why unresolved: The paper identifies the problem but does not explore whether this is due to inherent limitations in current architectures or could be mitigated through design improvements.
- What evidence would resolve it: Experiments testing whether architectural modifications (like the proposed policy-aware design) can maintain or improve performance under high cognitive load conditions.

### Open Question 3
- Question: What is the optimal balance between policy complexity and agent performance in enterprise environments?
- Basis in paper: [explicit] The paper creates tasks with varying cognitive loads (low, medium, high) and observes performance degradation, but does not determine the optimal policy-to-performance trade-off.
- Why unresolved: The paper establishes that more policies reduce performance but doesn't explore the threshold at which additional policies cease to provide meaningful safety benefits relative to their performance cost.
- What evidence would resolve it: A systematic analysis across a wider range of policy complexities measuring both safety outcomes and task completion rates to identify the optimal policy density for different enterprise contexts.

## Limitations

- The benchmark focuses on six safety dimensions but may not capture all enterprise-relevant risks, particularly data privacy regulations and industry-specific compliance requirements
- BrowserGym evaluation environment may not fully capture the complexity and variability of real enterprise web applications
- Proposed policy-aware architecture may not be universally applicable to all existing web agent designs, particularly end-to-end learning approaches

## Confidence

**High Confidence:** The CuP metric effectively exposes safety gaps in current agents by revealing the disconnect between task completion and policy compliance. The finding that agents achieve less than two-thirds CuP relative to nominal completion is well-supported by the evaluation methodology.

**Medium Confidence:** The hierarchical policy enforcement structure provides a reasonable framework for managing competing constraints, though real-world policy conflicts may be more complex than the benchmark scenarios suggest.

**Low Confidence:** The proposed architectural principles for building policy-aware agents are theoretically sound but lack empirical validation across diverse agent architectures and enterprise contexts.

## Next Checks

1. Cross-Enterprise Validation: Test the benchmark with agents operating in different enterprise domains (e.g., healthcare, finance) to verify that the safety dimensions and policies generalize beyond the three applications used in the study.

2. Policy Conflict Resolution: Systematically evaluate agent behavior when multiple policies create conflicting constraints to identify failure modes in the hierarchy enforcement mechanism and potential deadlock scenarios.

3. Real-World Deployment Assessment: Conduct a field study deploying policy-aware agents in actual enterprise environments to measure the practical overhead of policy enforcement and identify safety issues that emerge in production settings.