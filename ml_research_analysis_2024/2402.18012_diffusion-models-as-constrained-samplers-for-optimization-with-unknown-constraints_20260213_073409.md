---
ver: rpa2
title: Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints
arxiv_id: '2402.18012'
source_url: https://arxiv.org/abs/2402.18012
tags:
- optimization
- diffusion
- sampling
- distribution
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses optimization problems where analytic constraints
  are unknown but feasible solutions can be sampled from data. It proposes DiffOPT,
  which reformulates optimization as sampling from the product of a data distribution
  (learned via diffusion models) and a Boltzmann distribution defined by the objective
  function.
---

# Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints

## Quick Facts
- arXiv ID: 2402.18012
- Source URL: https://arxiv.org/abs/2402.18012
- Reference count: 40
- The paper proposes DiffOPT, which reformulates optimization with unknown constraints as sampling from the product of a data distribution (learned via diffusion models) and a Boltzmann distribution defined by the objective function.

## Executive Summary
This paper addresses optimization problems where analytic constraints are unknown but feasible solutions can be sampled from data. The proposed DiffOPT method reformulates optimization as sampling from a product of a data distribution (learned via diffusion models) and a Boltzmann distribution defined by the objective function. For differentiable objectives, it uses a two-stage approach: guided diffusion for warm-up followed by Langevin dynamics for correction. For non-differentiable objectives, it employs iterative importance sampling with diffusion models. Experiments on synthetic and real-world tasks show DiffOPT outperforms state-of-the-art methods, achieving best average rank of 2.0 on DesignBench and superior validity in multi-objective molecule optimization.

## Method Summary
DiffOPT treats optimization with unknown constraints as a sampling problem from the product of a data distribution (learned via diffusion models) and a Boltzmann distribution defined by the objective function. For differentiable objectives, it uses a two-stage sampling approach: guided diffusion with the objective as guidance for warm-up, followed by Langevin dynamics with Metropolis-Hastings correction. For non-differentiable objectives, it employs iterative importance sampling where particles are resampled based on weights and diversified using diffusion models. The diffusion model is trained on feasible solution data using VP-SDE and score matching.

## Key Results
- Achieves best average rank of 2.0 on DesignBench compared to state-of-the-art optimization methods
- Superior validity in multi-objective molecule optimization while maintaining comparable performance on objectives
- Demonstrates effectiveness on both differentiable (synthetic Branin function) and non-differentiable objectives across diverse domains

## Why This Works (Mechanism)

### Mechanism 1
DiffOPT reframes constrained optimization as sampling from a product of two distributions: a data distribution learned by diffusion models and a Boltzmann distribution defined by the objective function. The data distribution enforces feasibility by concentrating on the manifold of valid solutions, while the Boltzmann component drives optimization toward low objective values. This combined density concentrates on feasible minimizers as the inverse temperature β → ∞.

### Mechanism 2
For differentiable objectives, DiffOPT uses a two-stage sampling approach: guided diffusion for warm-up followed by Langevin dynamics for correction. The guided diffusion stage initializes sampling within the data manifold using the objective function as guidance, while the Langevin dynamics stage corrects bias and ensures convergence to the target distribution through Metropolis-Hastings correction.

### Mechanism 3
For non-differentiable objectives, DiffOPT uses iterative importance sampling with diffusion models to improve proposal distribution quality. Starting with random samples from the diffusion model, the method iteratively resamples particles based on weights and uses diffusion to diversify, gradually improving the proposal distribution's closeness to the target distribution.

## Foundational Learning

- Concept: Diffusion models and score matching
  - Why needed here: The method relies on diffusion models to learn the data distribution that represents the feasible manifold of solutions.
  - Quick check question: What is the relationship between the score function in diffusion models and the gradient of the log-density of the data distribution?

- Concept: Langevin dynamics and MCMC sampling
  - Why needed here: For differentiable objectives, the method uses Langevin dynamics with Metropolis-Hastings correction to ensure proper sampling from the target distribution.
  - Quick check question: How does the Metropolis-Hastings correction in Langevin dynamics ensure convergence to the correct stationary distribution?

- Concept: Importance sampling and proposal distributions
  - Why needed here: For non-differentiable objectives, the method uses iterative importance sampling to improve the proposal distribution's quality.
  - Quick check question: What are the key factors that determine the efficiency of importance sampling, and how does the iterative approach address these?

## Architecture Onboarding

- Component map: Data preprocessing -> Diffusion model training -> Objective function interface -> Guided diffusion (warm-up) -> Langevin dynamics (correction) -> Iterative importance sampling (non-differentiable) -> Evaluation and selection
- Critical path: 1. Train diffusion model on feasible solution data 2. For differentiable objectives: guided diffusion → Langevin dynamics → MH correction 3. For non-differentiable objectives: iterative importance sampling with diffusion diversification 4. Evaluate generated samples and select best solutions
- Design tradeoffs:
  - Guided diffusion vs pure diffusion: Better initialization vs potential bias
  - MH correction vs no correction: Theoretical guarantee vs computational cost
  - Iterative vs single-step importance sampling: Better proposals vs more computation
  - Fixed vs adaptive step sizes: Simplicity vs potential convergence issues
- Failure signatures:
  - Poor feasibility: Generated solutions violate constraints
  - Poor optimization: Generated solutions have high objective values
  - Slow convergence: Sampling takes too many steps to reach good solutions
  - Mode collapse: Generated solutions lack diversity
- First 3 experiments:
  1. Test on synthetic Branin function with known constraints to verify feasibility enforcement
  2. Compare two-stage sampling vs single-stage approaches on differentiable objectives
  3. Evaluate iterative vs single-step importance sampling on non-differentiable objectives

## Open Questions the Paper Calls Out

### Open Question 1
Does the guided diffusion stage (Stage I) truly concentrate on feasible local minimizers of the objective function, as Theorem 1 suggests? While Theorem 1 provides theoretical justification, the paper relies on Stage II (Langevin dynamics) to correct the bias introduced by Stage I, suggesting that the concentration of Stage I on feasible minimizers may not be perfect in practice.

### Open Question 2
How sensitive is DiffOPT to the choice of annealing strategy and the value of βmax during the guided diffusion stage? The paper explores different annealing strategies (constant, linear, exponential) and the impact of βmax on performance, finding that exponential annealing generally performs better, but the optimal βmax varies across datasets and strategies.

### Open Question 3
How does DiffOPT compare to other optimization methods when the surrogate objective function is difficult to train, as seen in the Ant dataset? The paper acknowledges that DiffOPT underperforms on the Ant dataset due to the difficulty in training the surrogate objective, suggesting that a more sophisticated architecture design may be needed.

## Limitations
- Assumes the data distribution accurately captures the feasible manifold, which may not hold for complex, high-dimensional constraints
- Two-stage sampling approach introduces potential bias from the guided diffusion stage
- Computational cost of multiple sampling stages and iterations may be prohibitive for large-scale applications

## Confidence
- Method novelty: Medium - builds on established diffusion model and sampling techniques but applies them to a new problem domain
- Theoretical framework: Medium - sound but relies on assumptions about data distribution and sampling processes
- Empirical results: Medium - promising but limited to specific domains and datasets

## Next Checks
1. Test the method's performance on optimization problems with more complex and high-dimensional constraints to assess scalability and robustness.
2. Investigate the impact of different diffusion model architectures and training strategies on the quality of the learned data distribution and subsequent optimization performance.
3. Evaluate the computational efficiency and scalability of the two-stage sampling approach for differentiable objectives and the iterative importance sampling for non-differentiable objectives, comparing against alternative methods.