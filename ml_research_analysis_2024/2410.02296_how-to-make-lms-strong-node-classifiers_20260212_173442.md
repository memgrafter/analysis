---
ver: rpa2
title: How to Make LMs Strong Node Classifiers?
arxiv_id: '2410.02296'
source_url: https://arxiv.org/abs/2410.02296
tags:
- graph
- node
- learning
- auglm
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of using language models (LMs)
  for node classification on text-attributed graphs without modifying their architecture.
  The proposed AUGLM framework introduces two key augmentation strategies: (1) topological
  and semantic retrieval of relevant nodes to provide richer contextual information,
  and (2) lightweight GNN guidance to prune candidate labels.'
---

# How to Make LMs Strong Node Classifiers?

## Quick Facts
- arXiv ID: 2410.02296
- Source URL: https://arxiv.org/abs/2410.02296
- Authors: Zhe Xu; Kaveh Hassani; Si Zhang; Hanqing Zeng; Michihiro Yasunaga; Limei Wang; Dongqi Fu; Ning Yao; Bo Long; Hanghang Tong
- Reference count: 40
- Primary result: AUGLM outperforms SOTA text-output node classifiers and achieves comparable performance to top vector-output models

## Executive Summary
This paper addresses the challenge of using language models (LMs) for node classification on text-attributed graphs without modifying their architecture. The proposed AUGLM framework introduces two key augmentation strategies: (1) topological and semantic retrieval of relevant nodes to provide richer contextual information, and (2) lightweight GNN guidance to prune candidate labels. Experiments on four real-world datasets show that AUGLM outperforms state-of-the-art text-output node classifiers and achieves comparable performance to top vector-output models. The method also supports joint training across multiple datasets without performance degradation, demonstrating its flexibility and effectiveness in bridging specialized graph classifiers with general LMs.

## Method Summary
AUGLM is a framework that enables LMs to perform node classification on text-attributed graphs without architectural modifications. It employs two main strategies: relevant node retrieval (combining topological retrieval via Personalized PageRank and semantic retrieval through prototypical class representatives) and lightweight GNN guidance for candidate label pruning. The method transforms graph data into text pairs using carefully designed prompt templates, allowing standard LMs to be fine-tuned on graph classification tasks. The framework uses a pretrained GNN to generate prototypes and candidate labels, then augments LM input with retrieved relevant nodes and candidate labels for training.

## Key Results
- AUGLM achieves state-of-the-art performance among text-output node classifiers on Cora, Pubmed, ogbn-arxiv, and ogbn-products datasets
- Outperforms existing methods by 0.7% to 1.9% in accuracy across different datasets
- Achieves comparable performance to top vector-output models while maintaining text-based architecture
- Demonstrates effectiveness of topological and semantic retrieval augmentation strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Topological retrieval via PPR scores provides richer context than simple neighbor aggregation
- Mechanism: PPR assigns higher relevance scores to nodes that are structurally important to the target, enabling the LM to focus on globally relevant information rather than local neighbors
- Core assumption: PPR scores effectively identify nodes that provide informative context for classification tasks
- Evidence anchors:
  - [abstract]: "Our proposed model, AUGLM...leverages two key strategies to enhance the LM’s ability to process graph: • Relevant Node Retrieval...topological and semantic retrieval methods, providing richer contextual information"
  - [section 4.1]: "PPR (Page, 1999; Jeh and Widom, 2003) is leveraged for topological retrieval, which has shown great effectiveness in conjunction with GNNs"
  - [corpus]: Weak evidence - no direct mentions of PPR effectiveness in LM contexts found in corpus
- Break condition: If PPR fails to identify relevant nodes for certain graph structures (e.g., bipartite graphs, small-world networks), the augmentation would provide no benefit

### Mechanism 2
- Claim: Semantic retrieval through prototypical class representatives improves classification by focusing on class-discriminative features
- Mechanism: Pre-trained GNN identifies confident examples per class, which serve as prototypes; semantic retriever then finds most relevant prototypes for each target node
- Core assumption: The pre-trained GNN can identify high-confidence examples that represent class characteristics well
- Evidence anchors:
  - [section 4.1]: "Prototypical semantic retrieval...treatsthe textual features of all nodes except the target nodeas a surrogate 'external corpus.'...For each class c, the top-N confident examples are selected as prototypes"
  - [abstract]: "Our proposed model, AUGLM...employs carefully designed prompt templates and augmentation techniques to transform graph and ground truth labels into text pairs, enabling LMs to process and be fine-tunedwithout modifying their underlying architecture"
  - [corpus]: Weak evidence - no direct mentions of prototypical semantic retrieval with LMs found in corpus
- Break condition: If the pre-trained GNN fails to identify meaningful class prototypes (e.g., in highly overlapping class distributions), semantic retrieval would provide noisy information

### Mechanism 3
- Claim: Candidate label pruning from lightweight GNN guides LM focus to relevant classes, improving efficiency and accuracy
- Mechanism: Pre-trained GNN predicts top-I probable labels for each node, which are presented to LM as candidate labels, reducing the search space
- Core assumption: The lightweight GNN's top predictions are reliable enough to meaningfully constrain the LM's classification search space
- Evidence anchors:
  - [section 4.2]: "We repurpose the pretrained GNNψ from the prototypically semantic retrieval module. For each node vi, we identify and save the top-I predicted labels: Li ={j: ˜yi[j]∈topI ( ˜yi)} ∈ {1, . . . , C}I"
  - [abstract]: "guiding the LMs' classification process through a lightweight GNN classifier that effectively prunes class candidates"
  - [corpus]: Weak evidence - no direct mentions of label pruning techniques in LM contexts found in corpus
- Break condition: If the lightweight GNN makes frequent classification errors, providing incorrect candidate labels that mislead the LM

## Foundational Learning

- Concept: Personalized PageRank algorithm
  - Why needed here: Forms the basis for topological retrieval, identifying structurally relevant nodes for each target
  - Quick check question: How does PPR differ from regular PageRank in terms of node relevance scoring?

- Concept: Graph Neural Networks and message passing
  - Why needed here: GNN provides the prototypical examples for semantic retrieval and candidate label pruning
  - Quick check question: What is the difference between node embeddings produced by GCN vs GraphSAGE?

- Concept: Retrieval-augmented generation (RAG) principles
  - Why needed here: Semantic retrieval module follows RAG principles to retrieve relevant textual information from graph nodes
  - Quick check question: How does the distribution matching loss in semantic retriever training align retrieved documents with LM importance?

## Architecture Onboarding

- Component map:
  - Input: Target node text, graph structure, training labels
  - GNN module: Generates prototypes and candidate label predictions
  - PPR module: Computes topological relevance scores
  - Semantic retriever: Finds relevant prototypes based on text similarity
  - Template engine: Constructs LM input with retrieved information and candidate labels
  - Backbone LM: Performs classification based on augmented input
  - Output: Predicted class labels

- Critical path:
  1. Precompute PPR scores and GNN predictions (offline)
  2. Generate prototypes from GNN predictions
  3. For each training node: retrieve topological and semantic neighbors
  4. Construct augmented prompt with candidate labels
  5. Train LM with NLL loss and update semantic retriever with distribution matching loss

- Design tradeoffs:
  - GNN complexity vs. retrieval quality: More complex GNNs may provide better prototypes but increase computational cost
  - Number of retrieved nodes vs. noise: More retrieved nodes provide richer context but may introduce irrelevant information
  - Number of candidate labels vs. LM search space: More candidates preserve flexibility but increase classification difficulty

- Failure signatures:
  - Poor PPR retrieval: Performance degrades significantly on graphs where structural importance doesn't correlate with classification relevance
  - Weak GNN prototypes: Semantic retrieval fails to find relevant information, leading to performance similar to baseline LM
  - Incorrect candidate labels: LM performance drops if candidate labels frequently exclude the true class

- First 3 experiments:
  1. Test topological retrieval alone: Compare performance using only PPR neighbors vs. random neighbors
  2. Test semantic retrieval alone: Compare prototype-based retrieval vs. simple text similarity retrieval
  3. Test candidate label pruning: Compare performance with and without candidate label guidance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of AUGLM vary with different graph neural network architectures used for generating prototypes and pruning candidate labels?
- Basis in paper: [explicit] The paper mentions that AUGLM uses a 3-layer GraphSAGE but notes in ablation studies that "the classification performances of GCN and GraphSAGE are similar" and that "the GNN is used to generate prototypes and prune candidate labels, which does not require a highly powerful GNN for accurate classification."
- Why unresolved: The paper only compares GraphSAGE and GCN, but there are many other GNN architectures that could potentially improve performance or efficiency.
- What evidence would resolve it: Systematic experiments comparing AUGLM performance across various GNN architectures (GAT, GIN, Graph Transformer variants) on multiple datasets would provide definitive answers.

### Open Question 2
- Question: What is the optimal balance between topological retrieval (PPR neighbors) and semantic retrieval (prototypical semantic retrieval) for different types of text-attributed graphs?
- Basis in paper: [explicit] The ablation study shows that each retrieval method contributes to performance but their relative importance varies across datasets, and the paper notes that "incorporating multi-hop neighbors can lead to 'neighbor explosion' (Hamilton et al., 2017; Chen et al., 2018; Fey et al., 2021), i.e., an exponentially-growing set of 'relevant' nodes."
- Why unresolved: The paper uses fixed numbers of PPR neighbors (K=5) and prototypes (N=10) across all datasets without exploring how these should be tuned for different graph characteristics.
- What evidence would resolve it: Experiments varying the number of PPR neighbors and prototypes across different graph sizes, densities, and homophily levels would reveal optimal trade-offs.

### Open Question 3
- Question: Can AUGLM's architecture be extended to handle dynamic graphs where nodes and edges evolve over time?
- Basis in paper: [inferred] The paper focuses on static text-attributed graphs, but the retrieval-augmented framework could theoretically incorporate temporal information, and the authors mention "spatial-temporal graphs" in their related work discussion.
- Why unresolved: The current implementation uses static PPR scores and pre-trained GNNs without temporal components, and the retrieval mechanisms don't account for temporal relationships between nodes.
- What evidence would resolve it: Experiments adapting AUGLM to temporal datasets with time-aware PPR, dynamic prototype generation, and temporal attention mechanisms would demonstrate feasibility and performance.

## Limitations

- The effectiveness of PPR-based topological retrieval in LM contexts lacks direct empirical validation, as PPR literature focuses on GNN applications
- The semantic retriever's distribution matching loss function and its impact on retrieval quality are underspecified
- The ablation studies showing individual component contributions are incomplete, testing components only in combination

## Confidence

- **High Confidence**: The core claim that AUGLM achieves state-of-the-art performance among text-output node classifiers on four datasets is well-supported by experimental results
- **Medium Confidence**: The claim that PPR-based topological retrieval provides richer context than simple neighbor aggregation is theoretically sound but lacks direct empirical validation in LM contexts
- **Medium Confidence**: The assertion that lightweight GNN candidate label pruning meaningfully guides LM classification is supported by results but the failure modes when GNN predictions are incorrect are not thoroughly explored
- **Low Confidence**: The specific claim that joint training across multiple datasets doesn't degrade performance lacks sufficient experimental validation

## Next Checks

1. **Ablation study isolation**: Conduct controlled experiments to measure the individual contribution of topological retrieval, semantic retrieval, and candidate label pruning when applied separately, not just in combination
2. **PPR sensitivity analysis**: Systematically vary PPR parameters (reset probability, number of retrieved nodes) and test performance across different graph types to validate PPR's effectiveness in LM contexts
3. **Candidate label reliability**: Measure the accuracy of the lightweight GNN's top-I predictions and analyze how often incorrect candidate labels actually harm LM performance versus providing helpful constraints