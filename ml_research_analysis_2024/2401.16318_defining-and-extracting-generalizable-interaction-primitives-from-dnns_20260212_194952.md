---
ver: rpa2
title: Defining and Extracting generalizable interaction primitives from DNNs
arxiv_id: '2401.16318'
source_url: https://arxiv.org/abs/2401.16318
tags:
- interactions
- interaction
- input
- different
- dnns
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to extract generalizable interaction
  primitives from deep neural networks (DNNs). The key idea is to define and extract
  interactions between input variables that are shared across multiple DNNs trained
  for the same task.
---

# Defining and Extracting generalizable interaction primitives from DNNs

## Quick Facts
- arXiv ID: 2401.16318
- Source URL: https://arxiv.org/abs/2401.16318
- Reference count: 35
- Primary result: Method extracts interactions with higher sparsity and generalization power across different DNNs trained for the same task

## Executive Summary
This paper addresses the challenge of extracting interaction primitives from deep neural networks (DNNs) that generalize across different models trained for the same task. The authors propose a method that optimizes for interactions that are not only salient in individual DNNs but also shared across multiple models, improving the reliability and interpretability of extracted interactions. By leveraging the principle of Occam's Razor and introducing shared decomposition parameters, the method achieves better sparsity and generalization compared to traditional approaches.

## Method Summary
The method extracts generalizable interaction primitives by first defining AND and OR interactions using Harsanyi dividends and Shapley values, then optimizing for interactions that maximize generalization power across multiple DNNs. The key innovation is a loss function that penalizes the most salient interactions across all models, encouraging shared interaction primitives. The method uses a parameterization scheme (γ(i)_T = ¯γ_T + ˆγ(i)_T) that separates shared and unshared components, with the shared component constraining the decomposition to be similar across DNNs. The optimization process involves evaluating 2^n masked samples to compute interactions and extract the most generalizable primitives.

## Key Results
- The proposed method achieves higher sparsity (fewer interactions) compared to traditional interaction extraction methods
- Interactions extracted by the method show significantly improved generalization power across different DNNs
- The method identifies shared interaction primitives that consistently contribute salient effects to outputs across models, suggesting these represent more reliable concepts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Extracting generalizable interactions improves the transferability of learned patterns across different DNNs.
- Mechanism: By optimizing to maximize the rowmax of interactions across multiple DNNs, the method ensures that strong interactions in one model are likely to be present in others, increasing shared interaction primitives.
- Core assumption: Well-trained DNNs trained for the same task encode overlapping sets of salient interactions, and these shared interactions represent more reliable knowledge.
- Evidence anchors:
  - [abstract] "The method achieves higher sparsity and generalization power compared to traditional interaction extraction methods, with interactions shared by different models considered more reliable concepts that consistently contribute salient interaction effects to the output of different DNNs."
  - [section 2.3.2] "The revised loss in Equation (5) only penalizes the most salient interactions over all m interactions extracted from m DNNs, with respect to each subset Tk ⊆ N."
- Break condition: If DNNs are trained with very different architectures or datasets that do not share common knowledge, the shared interaction assumption breaks down.

### Mechanism 2
- Claim: Using the sparsity principle (Occam's Razor) reduces uncertainty in interaction extraction by selecting the simplest explanation.
- Mechanism: The ℓ1 norm penalty (∥rowmax(I and)∥1 + ∥rowmax(I or)∥1) encourages selecting fewer, more significant interactions rather than many weak ones.
- Core assumption: The simplest explanation (fewest interactions) is more likely to be faithful and capture the true underlying patterns.
- Evidence anchors:
  - [section 2.3] "the most intuitive approach is to learn the sparsest interactions, considering the principle of Occam's Razor, as follows."
  - [section 2.2] "the principle of Occam's Razor, as follows. It is because the sparsest (or simplest) explanation is usually considered as the most faithful explanation."
- Break condition: If the true underlying pattern is complex and requires many interactions, sparsity optimization would miss important signals.

### Mechanism 3
- Claim: Separating decomposition parameters into shared (common across DNNs) and unshared components improves stability and generalization.
- Mechanism: The parameterization γ(i)_T = ¯γ_T + ˆγ(i)_T constrains unshared components to small ranges, ensuring most decomposition is shared while allowing minor task-specific adjustments.
- Core assumption: When DNNs are sufficiently trained for the same task, they should have similar decompositions of AND/OR interactions.
- Evidence anchors:
  - [section 2.3.2] "We introduce a set of strategies to facilitate the optimization process. We assume that when all m DNNs are sufficiently trained, these DNNs tend to have similar decompositions of AND interactions and OR interactions, i.e., obtaining similar parameters, ∀T ⊆ N, γ(1)_T ≈ γ(2)_T ≈ · · · ≈ γ(m)_T."
  - [section 2.3.2] "We introduce two types of parameters for γ(i)_T , γ(i)_T = ¯γ_T + ˆγ(i)_T , where ¯γ_T represents the common decomposition shared by all DNNs, and ˆγ(i)_T represents the decomposition specific to each i-th DNN."
- Break condition: If DNNs are trained with fundamentally different architectures or optimization strategies, the shared decomposition assumption may not hold.

## Foundational Learning

- Concept: Interaction extraction via Harsanyi dividends and universal matching theorem
  - Why needed here: The entire method builds on the theoretical foundation that DNN outputs can be explained by sparse interactions between input variables, which is the basis for both sparsity and generalizability claims.
  - Quick check question: Can you explain why a small number of interactions can universally explain DNN outputs on all 2^n masked samples according to the universal matching theorem?

- Concept: AND-OR interaction decomposition
  - Why needed here: The method requires decomposing the DNN output into AND and OR components, which is non-trivial and affects the extracted interactions significantly.
  - Quick check question: How does the decomposition v(x) = vand(x) + vor(x) enable the extraction of both AND and OR interactions, and why is this decomposition challenging?

- Concept: Generalization power as transferability metric
  - Why needed here: The paper defines generalizability of interactions as the ratio of shared interactions across different DNNs, which is central to the proposed method's objective.
  - Quick check question: Given two DNNs with interaction sets Ωand,(1) and Ωand,(2), how would you compute the generalization power metric sand?

## Architecture Onboarding

- Component map: Data → Multiple DNN inference on masked samples → Interaction computation via Equations (1) and (2) → Parameter optimization via Equation (6) → Extract shared interactions → Evaluate generalizability
- Critical path: Data → Multiple DNN inference on masked samples → Interaction computation via Equations (1) and (2) → Parameter optimization via Equation (6) → Extract shared interactions → Evaluate generalizability
- Design tradeoffs: The method trades computational complexity (2^n masked samples) for improved generalizability; it also balances sparsity (fewer interactions) against completeness (capturing all relevant patterns)
- Failure signatures: Poor generalizability scores indicate either (1) insufficient model training, (2) architectural differences preventing shared interactions, or (3) inappropriate parameter initialization leading to local minima
- First 3 experiments:
  1. Verify that the method extracts higher-sand interactions than baseline methods on BERTBASE vs BERTLARGE with SST-2 dataset
  2. Test sensitivity to α parameter by varying it and measuring impact on sparsity vs generalizability tradeoff
  3. Compare interaction consistency across LLaMA and Aquila-7B models to validate the shared interaction assumption for large language models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we concisely explain the complex learning dynamics of a DNN using interactions?
- Basis in paper: explicit - the paper mentions this as an unresolved problem in the conclusion section
- Why unresolved: The paper states that while a theory system of interaction-based explanations has been built up, the problem of using interactions to concisely explain the complex learning dynamics of a DNN remains unsolved
- What evidence would resolve it: A method that can effectively use interactions to provide a concise explanation of the learning dynamics of a DNN, potentially demonstrated through experiments on various DNN architectures and datasets

### Open Question 2
- Question: How can we distinguish logical reasoning used by the DNN using interactions?
- Basis in paper: explicit - the paper mentions this as an unresolved problem in the conclusion section
- Why unresolved: The paper acknowledges that distinguishing the logical reasoning used by a DNN is still an open challenge, despite the development of interaction-based explanations
- What evidence would resolve it: A technique that can identify and distinguish different types of logical reasoning used by a DNN, possibly through the analysis of interaction patterns or the development of new interaction metrics

### Open Question 3
- Question: How can we evaluate and learn from the detailed interaction logic of a DNN?
- Basis in paper: explicit - the paper mentions this as an unresolved problem in the conclusion section
- Why unresolved: The paper highlights that while interactions can be extracted and analyzed, the problem of evaluating and learning from the detailed interaction logic of a DNN remains unsolved
- What evidence would resolve it: A framework that can effectively evaluate the quality and interpretability of interaction logic, as well as methods for learning from these interactions to improve DNN performance or robustness, potentially demonstrated through experiments on various tasks and datasets

## Limitations

- The method's computational complexity grows exponentially with the number of input variables (2^n masked samples), limiting practical applicability to high-dimensional inputs
- The shared interaction assumption may break down when DNNs have fundamentally different architectures or training objectives
- The connection between sparse interactions and universal explanation of DNN outputs relies on the universal matching theorem, which requires further rigorous validation

## Confidence

**High Confidence**: The sparsity principle (Occam's Razor) effectively reduces uncertainty in interaction extraction by selecting fewer, more significant interactions. This is supported by well-established principles in model selection theory and the explicit ℓ1 norm penalty in the objective function.

**Medium Confidence**: The rowmax-based loss function successfully maximizes generalization power by ensuring interactions salient in one DNN are likely present in others. While the theoretical motivation is sound, the empirical evidence across diverse architectures and tasks would strengthen this claim.

**Medium Confidence**: The shared decomposition parameterization improves stability and generalization by constraining unshared components. The theoretical framework is reasonable, but the extent to which this assumption holds across very different DNN architectures remains uncertain.

## Next Checks

1. **Architectural Diversity Test**: Evaluate the method's performance when extracting interactions from DNNs with vastly different architectures (e.g., CNN vs. transformer) trained on the same task to test the limits of the shared interaction assumption.

2. **Sample Complexity Analysis**: Systematically vary the number of training samples used for interaction extraction and measure the impact on both sparsity and generalization power to understand the method's data efficiency requirements.

3. **Threshold Sensitivity Study**: Conduct a comprehensive sensitivity analysis of the interaction selection threshold τ across different datasets and tasks to determine how robust the extracted interactions are to this critical hyperparameter choice.