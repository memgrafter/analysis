---
ver: rpa2
title: Mixture of Diverse Size Experts
arxiv_id: '2409.12210'
source_url: https://arxiv.org/abs/2409.12210
tags:
- top1
- top0
- experts
- tokens
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Mixture of Diverse Size Experts (MoDSE), a novel
  MoE architecture where experts in each layer have different sizes to better handle
  tokens of varying difficulty. To address the load imbalance caused by different
  expert sizes, an expert-pair allocation strategy is introduced to evenly distribute
  parameters across GPUs.
---

# Mixture of Diverse Size Experts

## Quick Facts
- arXiv ID: 2409.12210
- Source URL: https://arxiv.org/abs/2409.12210
- Authors: Manxi Sun; Wei Liu; Jian Luan; Pengzhi Gao; Bin Wang
- Reference count: 11
- Key outcome: MoDSE achieves improved performance over standard MoE baselines across multiple benchmarks with lower cross-entropy loss and better convergence

## Executive Summary
This paper proposes Mixture of Diverse Size Experts (MoDSE), a novel MoE architecture where experts in each layer have different sizes to better handle tokens of varying difficulty. The key innovation addresses load imbalance caused by different expert sizes through an expert-pair allocation strategy that evenly distributes parameters across GPUs. Evaluated on 700M×8 parameter models, MoDSE shows improved performance across multiple benchmarks while maintaining comparable inference speeds to baseline MoE models.

## Method Summary
MoDSE modifies standard MoE by assigning different sizes to experts within each layer, matching token difficulty to expert capacity. The expert-pair allocation strategy groups experts into pairs with complementary sizes (e.g., 4.5:0.5, 4.0:1.0, 3.0:2.0, 2.5:2.5) and places each pair on the same GPU to ensure balanced parameter distribution. The model uses load balance loss to penalize unbalanced routing distribution among experts and is trained with Adam optimizer using cosine learning rate schedule and ZeRO optimization for distributed training.

## Key Results
- Improved performance across multiple benchmarks (AGIEval, MMLU, INTENT, GSM8K, LAMBADA, MATH, TriviaQA, PIQA, SIQA)
- Lower cross-entropy loss and better convergence compared to standard MoE baselines
- Analysis shows difficult tokens are better predicted when routed to appropriately sized experts
- Expert-pair allocation ensures balanced GPU workloads while maintaining comparable inference speeds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Difficult tokens are better predicted when routed to appropriately sized experts
- Mechanism: MoDSE assigns larger experts (with more parameters) to handle tokens requiring more complex reasoning, while smaller experts handle easier tokens
- Core assumption: Token generation difficulty varies systematically across the corpus and can be captured by expert size
- Evidence anchors:
  - [abstract]: "Our analysis of difficult token generation tasks shows that experts of various sizes achieve better predictions"
  - [section]: "The tokens in the higher loss threshold show a larger loss decline in the MoDSE setting, demonstrating that the MoDSE model performs better on more difficult tokens"

### Mechanism 2
- Claim: Expert-pair allocation ensures balanced GPU workloads despite different expert sizes
- Mechanism: By grouping experts into pairs with complementary sizes that sum to the same total, and placing each pair on the same GPU, the workload distribution across GPUs remains balanced
- Core assumption: The sum of parameters in each expert pair is constant across all pairs
- Evidence anchors:
  - [section]: "To address this load imbalance problem, we propose the expert-pair allocation strategy, which places each pair of experts on the same GPU and ensures that each GPU contains an equal number of parameters"

### Mechanism 3
- Claim: Routing distribution becomes balanced over training epochs
- Mechanism: The auxiliary load balance loss and training dynamics cause tokens to distribute evenly across all experts by the end of training
- Core assumption: The routing mechanism can adapt to ensure uniform expert utilization
- Evidence anchors:
  - [section]: "However, after the entire training process, in the last epoch, only one ratio remains larger than 3.0, with the others ranging from 1.5 to 3.0, indicating that the token distribution among experts becomes more balanced by the end of the training"

## Foundational Learning

- Concept: Mixture-of-Experts (MoE) architecture
  - Why needed here: Understanding how gating networks route tokens to experts is fundamental to MoDSE's design
  - Quick check question: How does the gating network in MoE select which experts to activate for a given token?

- Concept: Load balancing in distributed systems
  - Why needed here: MoDSE's expert-pair allocation strategy directly addresses workload imbalance across GPUs
  - Quick check question: Why would having experts of different sizes on the same GPU create load imbalance issues?

- Concept: Token routing and expert specialization
  - Why needed here: MoDSE relies on routing tokens to appropriately sized experts based on difficulty
  - Quick check question: How does MoDSE ensure that difficult tokens are routed to larger experts while maintaining overall balance?

## Architecture Onboarding

- Component map: Input layer → Gate network → Expert layer (with diverse sizes) → Output layer
- Expert pairs: (4.5, 0.5), (4.0, 1.0), (3.0, 2.0), (2.5, 2.5) size ratios
- Each expert pair placed on same GPU

- Critical path:
  1. Token input → Gate network computes routing scores
  2. Top-k experts selected based on routing scores
  3. Token routed to expert matching its difficulty level
  4. Expert outputs combined for final prediction

- Design tradeoffs:
  - Larger experts provide better performance but increase computational load
  - Smaller experts are more efficient but may underperform on difficult tasks
  - Expert-pair allocation adds complexity but ensures GPU balance

- Failure signatures:
  - Load imbalance across GPUs (monitoring per-GPU utilization)
  - Routing collapse (all tokens going to same experts)
  - Performance degradation on difficult tokens

- First 3 experiments:
  1. Verify that expert-pair allocation maintains balanced GPU utilization during training
  2. Test routing distribution across different difficulty levels of tokens
  3. Compare performance on difficult tokens between MoDSE and baseline MoE

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the MoDSE architecture scale to larger models beyond the 700M×8 parameter setting tested in this paper?
- Basis in paper: [explicit] The paper states "Due to limitations in computational and data resources, current experiments are conducted on small-scale MoE models, leaving the model's scalability to larger sizes unclear."
- Why unresolved: The experiments were limited to relatively small models (700M×8), and the paper acknowledges that scaling to larger models is an open question.

### Open Question 2
- Question: How sensitive is the MoDSE architecture to the specific size ratios chosen for the expert pairs?
- Basis in paper: [inferred] The paper uses specific size ratios (4.5, 0.5), (4.0, 1.0), (3.0, 2.0), and (2.5, 2.5) but does not explore the sensitivity to these choices or alternative ratios.
- Why unresolved: The paper does not provide an ablation study on the expert size ratios, leaving uncertainty about whether these specific ratios are optimal or if other configurations might perform better.

### Open Question 3
- Question: How does MoDSE perform when applied to open-source datasets and tokenizers rather than the custom dataset used in this paper?
- Basis in paper: [explicit] The paper states "We obtain the aforementioned intriguing findings while training our own MoE LLM. Hence, the tokenizer and data utilized for pretraining are not available as open-source resources. We plan to apply this model design to open-source resources in our future work."
- Why unresolved: The experiments were conducted using proprietary data and a custom tokenizer, limiting reproducibility and generalizability of the results.

## Limitations

- Load-balance assumptions may not hold under real-world workload variations, potentially causing performance degradation
- Effectiveness for significantly larger or smaller models than 700M×8 remains unverified
- Routing stability across different batch sizes and inference conditions needs further validation

## Confidence

**High Confidence**:
- Expert-pair allocation strategy effectively balances GPU workloads when properly implemented
- Performance improvements on standard benchmarks are measurable and statistically significant
- Correlation between token difficulty and routing to appropriately sized experts is observable

**Medium Confidence**:
- Mechanism by which difficult tokens are better predicted when routed to larger experts (causal relationship needs more rigorous validation)
- Convergence benefits observed during training will translate to all practical deployment scenarios
- Routing mechanism maintains stability across different batch sizes and inference conditions

**Low Confidence**:
- Approach scales effectively to much larger models (10B+ parameters)
- Performance gains remain consistent across all types of difficulty metrics
- Routing mechanism won't degrade under long-term deployment conditions

## Next Checks

1. **Dynamic Load Testing**: Evaluate the expert-pair allocation strategy under varying batch sizes and sequence lengths to verify that GPU load balancing remains effective across different inference scenarios.

2. **Routing Stability Analysis**: Monitor routing patterns during both training and inference phases, particularly under different workload conditions, to ensure that routing doesn't collapse or become unstable over time.

3. **Scalability Validation**: Test MoDSE with different model sizes (both smaller and larger than 700M×8) to verify that the performance benefits and load balancing properties scale appropriately across different parameter regimes.