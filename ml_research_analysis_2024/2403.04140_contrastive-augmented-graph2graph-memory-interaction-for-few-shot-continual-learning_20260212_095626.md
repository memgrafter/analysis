---
ver: rpa2
title: Contrastive Augmented Graph2Graph Memory Interaction for Few Shot Continual
  Learning
arxiv_id: '2403.04140'
source_url: https://arxiv.org/abs/2403.04140
tags:
- features
- learning
- local
- graph
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the Few-Shot Class-Incremental Learning (FSCIL)
  problem, where a model must learn new classes with limited samples while retaining
  knowledge of previously learned classes. The main challenges are catastrophic forgetting
  and overfitting due to the scarcity of new class samples.
---

# Contrastive Augmented Graph2Graph Memory Interaction for Few Shot Continual Learning

## Quick Facts
- arXiv ID: 2403.04140
- Source URL: https://arxiv.org/abs/2403.04140
- Authors: Biqing Qi; Junqi Gao; Xingquan Chen; Dong Li; Jianxing Liu; Ligang Wu; Bowen Zhou
- Reference count: 40
- Key outcome: Proposed method achieves 13.71% and 7.97% average accuracy improvements on CIFAR100 and CUB200 datasets respectively while using only one sample per class for rehearsal

## Executive Summary
This paper addresses the Few-Shot Class-Incremental Learning (FSCIL) problem by introducing a novel Graph-to-Graph (G2G) memory interaction method. The approach extends traditional vector-to-vector feature-prototype interactions to graph-based interactions that capture local geometric structure information. By incorporating Local Graph Preservation (LGP) and Contrastive Augmented G2G (CAG2G) mechanisms, the method achieves superior performance on CIFAR100, CUB200, and ImageNet-R datasets while addressing catastrophic forgetting and overfitting challenges in few-shot scenarios.

## Method Summary
The method constructs local graphs from partitioned feature vectors and prototypes, then uses graph neural networks to perform graph-to-graph alignment. Local features are extracted and transformed using linear layers, with graph adjacency matrices built based on Euclidean distances. The G2G-GNN module (using GAT, GraphSage, or similar architectures) aligns these graphs while preserving local geometric structures. LGP applies decoupling loss to prevent feature collapse, and CAG2G introduces contrastive learning between augmented views to promote same-class feature aggregation. The overall training objective combines graph alignment loss, local decoupling loss, and contrastive loss.

## Key Results
- Achieves 13.71% average accuracy improvement on CIFAR100 dataset
- Achieves 7.97% average accuracy improvement on CUB200 dataset
- Maintains performance using only one sample per class for rehearsal buffer
- Outperforms state-of-the-art FSCIL methods across all tested datasets

## Why This Works (Mechanism)

### Mechanism 1
Extending vector-to-vector interaction to graph-to-graph interaction introduces local geometric structure information for more accurate feature-prototype alignment. The model partitions extracted features and prototypes into local features, constructs weighted graphs based on Euclidean distances between local features, and uses graph neural networks to model local geometric structure. This approach captures discriminative information in local relationships that global vector distances miss.

### Mechanism 2
Local Graph Preservation (LGP) mechanism enhances local structure stability and prevents feature collapse. LGP applies a decoupling loss that enforces additional constraints on local prototype vectors, ensuring different local features remain distinct and don't collapse into single representations. This prevents the model from losing fine-grained distinctions between features that are crucial for few-shot generalization.

### Mechanism 3
Contrastive Augmented G2G (CAG2G) improves few-shot generalization by promoting same-class feature aggregation. CAG2G models pre- and post-augmented image features in the same graph and performs graph-to-graph alignment, encouraging features from the same class to cluster together. This contrastive learning helps the model learn more robust feature representations that generalize better to few-shot scenarios.

## Foundational Learning

- Concept: Graph Neural Networks and Graph Attention Mechanisms
  - Why needed here: The method relies on constructing graphs from local features and applying GNN operations to capture geometric relationships
  - Quick check question: What is the key difference between spatial-based GNNs (like GAT) and spectrum-based GNNs (like GCN) in terms of how they process graph information?

- Concept: Catastrophic Forgetting and Rehearsal Strategies
  - Why needed here: The paper addresses FSCIL, which specifically deals with catastrophic forgetting when learning new classes with limited samples
  - Quick check question: How does storing only one sample per class for rehearsal affect the model's ability to maintain knowledge of previous classes?

- Concept: Contrastive Learning Principles
  - Why needed here: The CAG2G component uses contrastive learning between augmented views
  - Quick check question: In contrastive learning, what is the relationship between the number of negative samples and the quality of learned representations?

## Architecture Onboarding

- Component map: Frozen pre-trained ViT feature extractor -> Local feature partitioning module (S segments) -> Local feature transformation module (Tθ2,s for each segment) -> Graph construction module (local adjacency matrices) -> G2G-GNN module (GAT, GraphSage, or other GNN variant) -> Memory retrieval module (prototype matching) -> LGP module (local decoupling loss) -> CAG2G module (contrastive augmentation) -> Overall loss function (combination of LG, LD, and LC)

- Critical path: Input → ViT → Local partitioning → Graph construction → G2G-GNN → Memory retrieval → LGP regularization → CAG2G augmentation → Loss computation

- Design tradeoffs:
  - Number of local segments (S): Higher S captures more local structure but may lose global information
  - Choice of GNN architecture: Different GNNs capture different aspects of graph structure
  - Strength of LGP regularization (λ): Too weak provides insufficient decoupling, too strong prevents useful feature aggregation
  - Strength of contrastive augmentation (η): Too weak provides insufficient few-shot improvement, too strong may overwhelm other objectives

- Failure signatures:
  - Poor performance on incremental sessions indicates catastrophic forgetting
  - No improvement with different S values suggests local structure is not useful
  - Performance degrades with higher λ or η suggests over-regularization
  - Similar performance to baseline ViT fine-tuning suggests proposed components are not effective

- First 3 experiments:
  1. Baseline test: Implement ViT fine-tuning with same rehearsal buffer size and compare to proposed method
  2. Ablation test: Remove LGP component and measure impact on performance and catastrophic forgetting
  3. Hyperparameter sweep: Test different values of S (2, 4, 6, 8, 12) to find optimal local feature granularity

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of the G2G interaction mechanism vary when using different graph neural network architectures, particularly comparing spatial-based versus spectral-based GNNs? While the paper observes that spatial-based GNNs perform better, it does not provide a comprehensive quantitative comparison of the performance differences across various GNN architectures on the FSCIL datasets.

### Open Question 2
What is the impact of the number of partitions S on the performance of the G2G interaction mechanism, and is there an optimal value of S for different datasets or model architectures? The paper discusses how varying S affects performance but does not explore this impact across different datasets or investigate whether optimal S varies depending on dataset characteristics or specific GNN architecture used.

### Open Question 3
How does the LGP mechanism influence the model's ability to prevent feature collapse and maintain class separation, and what is the relationship between the regularization strength λ and the model's performance on different datasets? While the paper shows that LGP improves performance and that λ=0.01 provides the best results, it does not provide a detailed analysis of how LGP specifically prevents feature collapse or maintains class separation.

## Limitations
- The method shows variable performance gains across different datasets, with ImageNet-R results being less robust than CIFAR100 and CUB200
- Lack of ablation studies isolating individual mechanism contributions makes it difficult to assess the specific impact of G2G, LGP, and CAG2G components
- Computational overhead of graph construction and GNN operations is not quantified relative to baseline methods

## Confidence
- **High**: The fundamental approach of extending vector-to-vector interaction to graph-to-graph interaction is sound and well-motivated
- **Medium**: The claimed improvements on CIFAR100 and CUB200 datasets are convincing, though ImageNet-R results are less robust
- **Low**: The specific contributions of individual components (LGP vs CAG2G) and their relative importance remain unclear

## Next Checks
1. Component ablation study: Implement and evaluate each component (G2G, LGP, CAG2G) separately to quantify their individual contributions to performance gains
2. Computational overhead analysis: Measure training time, memory usage, and inference latency compared to baseline ViT fine-tuning with rehearsal
3. Cross-dataset generalization test: Evaluate the method on additional FSCIL benchmarks (e.g., miniImageNet, tieredImageNet) to assess generalizability beyond the three tested datasets