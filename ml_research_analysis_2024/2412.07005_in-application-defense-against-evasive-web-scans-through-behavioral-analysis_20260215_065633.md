---
ver: rpa2
title: In-Application Defense Against Evasive Web Scans through Behavioral Analysis
arxiv_id: '2412.07005'
source_url: https://arxiv.org/abs/2412.07005
tags:
- data
- detection
- user
- each
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WebGuard, a low-overhead, multi-modal forensics
  engine for detecting and monitoring web-based automated scanners. WebGuard integrates
  seamlessly into web applications, collecting spatio-temporal data and browser events
  from 43 monitored events.
---

# In-Application Defense Against Evasive Web Scans through Behavioral Analysis

## Quick Facts
- arXiv ID: 2412.07005
- Source URL: https://arxiv.org/abs/2412.07005
- Reference count: 40
- Primary result: WebGuard achieves >90% detection accuracy for web scanners within hundreds of milliseconds using multi-modal behavioral analysis

## Executive Summary
This paper introduces WebGuard, a low-overhead JavaScript-based system that detects automated web scanners through multi-modal behavioral analysis. By collecting spatio-temporal data and browser events from 43 monitored interactions, WebGuard employs both supervised (LSTM) and unsupervised (HMM, spectral clustering) learning to distinguish between human users and automated agents in real-time. The approach significantly improves detection accuracy and reduces time-to-detection compared to uni-modal methods while maintaining minimal communication overhead. Empirical evaluations demonstrate high accuracy in detecting various scanner types, making WebGuard a robust defense against evasive web scanning attacks.

## Method Summary
WebGuard integrates as a lightweight JavaScript tag into web applications, automatically attaching event listeners to capture 43 types of user interactions including mouse movements, clicks, scrolls, and keypresses. The system collects spatio-temporal data and transmits it via WebSocket to a server where supervised LSTM models perform real-time classification while unsupervised HMM and spectral clustering models enable offline attribution. Multi-modal data analysis combines spatial, temporal, and activity type information to create a richer feature space that is more difficult for automated agents to replicate. The approach includes preprocessing steps like velocity and inter-arrival time calculations, and employs information-theoretic analysis to demonstrate the superiority of multi-modal over uni-modal detection methods.

## Key Results
- Achieves >90% accuracy in detecting and classifying various scanner types
- Reduces time-to-detection to hundreds of milliseconds
- Maintains minimal communication overhead (<10 KB/s) through WebSocket transmission
- Significantly improves detection performance compared to uni-modal analysis methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-modal behavioral data collection significantly improves detection accuracy and reduces time-to-detection compared to uni-modal methods.
- Mechanism: By collecting spatial, temporal, and activity type data, WebGuard captures a richer set of features that are more difficult for adversaries to replicate. This multi-modal approach expands the feature space, making it harder for automated agents to mimic human behavior across all dimensions.
- Core assumption: The behavioral patterns of human users are distinct and complex enough across multiple modalities that replicating them simultaneously is computationally expensive for adversaries.
- Evidence anchors:
  - [abstract] "Information theoretic analysis and empirical evaluations are provided to show that multi-modal data analysis, as opposed to uni-modal analysis which relies solely on mouse movement dynamics, significantly improves time-to-detection and attribution accuracy."
  - [section 6] "the amount of training data that an attacker needs to emulate human behavior grows superlinearly with the number of data modalities involved"
- Break condition: If an adversary can obtain sufficient training data to accurately model the joint distribution of all monitored modalities, or if the number of modalities is limited such that the computational burden is manageable.

### Mechanism 2
- Claim: The use of both supervised (LSTM) and unsupervised (HMM, spectral clustering) learning architectures enables robust real-time detection and offline attribution of human and automated agents.
- Mechanism: Supervised learning with LSTM allows for real-time classification of new users based on learned patterns, while unsupervised learning with HMM and spectral clustering enables the discovery of new behavioral patterns and classes of automated agents over time. This combination provides both immediate detection and adaptive learning capabilities.
- Core assumption: The underlying behavioral patterns of users can be effectively modeled using sequential data analysis techniques like LSTM and HMM, and that these patterns are distinct enough to enable clustering and classification.
- Evidence anchors:
  - [section 4.4] "The LSTM architecture is capable of taking continuous-valued vector inputs and does not require the (information-lossy) scalarization and discretization steps"
  - [section 4.3] "we use the widely used Baum-Welch algorithm [7] to find estimates bP(i) X|S, dP(i) S2|S1, and bP(i) S"
- Break condition: If the behavioral patterns become too complex or noisy to be effectively modeled by LSTM or HMM, or if the number of distinct classes becomes too large for the clustering algorithms to handle.

### Mechanism 3
- Claim: WebGuard's integration as a lightweight JavaScript tag introduces minimal communication overhead while providing comprehensive behavioral monitoring.
- Mechanism: By using WebSocket-based communication instead of traditional HTTP polling, WebGuard reduces network overhead significantly. The JavaScript tag automatically attaches event listeners to a broad array of features within the web application, capturing and logging spatio-temporal data related to user interactions.
- Core assumption: The communication overhead introduced by WebGuard is negligible compared to the benefits of enhanced detection and attribution capabilities.
- Evidence anchors:
  - [section 3.1.3] "a WebSocket transmission necessitates, on average, 46 bytes of network bandwidth. This includes an 8-byte WebSocket header and an average 38-byte variable-sized binary payload."
  - [section 5.4] "Our empirical evaluation, elaborated in Section 5, reveals an average event listener activation time approximating 10 milliseconds. This leads to an average communication overhead for WebGuard that is less than 10 KB per second."
- Break condition: If the number of monitored events or the frequency of user interactions increases dramatically, leading to a significant increase in communication overhead.

## Foundational Learning

- Concept: Hidden Markov Models (HMMs) for sequential data analysis
  - Why needed here: HMMs are used to model the underlying probability distributions of user behavior, which is crucial for both clustering and classification tasks in WebGuard.
  - Quick check question: What is the key assumption behind using HMMs for modeling user behavior, and how does it relate to the Markov property?

- Concept: Long Short-Term Memory (LSTM) networks for real-time classification
  - Why needed here: LSTM networks are capable of processing sequential data with long-term dependencies, making them suitable for real-time detection of automated agents based on behavioral patterns.
  - Quick check question: How does the ability of LSTM networks to handle continuous-valued inputs compare to the discretization requirements of HMMs?

- Concept: Spectral clustering for unsupervised learning
  - Why needed here: Spectral clustering is used to group users based on their behavioral patterns without prior labeling, enabling the discovery of new classes of automated agents.
  - Quick check question: What is the main advantage of using spectral clustering over other clustering methods in the context of behavioral data analysis?

## Architecture Onboarding

- Component map: JavaScript tag -> WebSocket server -> LSTM model -> HMM models -> Spectral clustering algorithm -> Agglomerative clustering algorithm
- Critical path:
  1. User interacts with web application
  2. JavaScript tag captures behavioral data and sends it via WebSocket
  3. LSTM model classifies the user in real-time
  4. HMM models estimate probability distributions for offline clustering
  5. Spectral clustering algorithm groups users based on their behavioral patterns

- Design tradeoffs:
  - Multi-modal vs. uni-modal data collection: Multi-modal provides better accuracy but increases complexity
  - Real-time vs. offline processing: Real-time requires more computational resources but enables immediate detection
  - Supervised vs. unsupervised learning: Supervised provides higher accuracy for known classes but requires labeled data

- Failure signatures:
  - High false positive rate: May indicate that the behavioral patterns of human users are not being accurately captured or that the threshold for classification is too low
  - High false negative rate: May indicate that the behavioral patterns of automated agents are too similar to human users or that the threshold for classification is too high
  - Communication overhead exceeding acceptable limits: May indicate that the number of monitored events or the frequency of user interactions is too high

- First 3 experiments:
  1. Test the accuracy of the LSTM model in classifying known human and automated agents using multi-modal data
  2. Evaluate the effectiveness of spectral clustering in grouping users based on their behavioral patterns
  3. Measure the communication overhead introduced by WebGuard under different levels of user activity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of hidden states for HMMs when applied to multi-modal behavioral data, and how does this number vary across different types of web scanners?
- Basis in paper: [inferred] The paper mentions using four hidden states for HMM models and determining the number of hidden states via hyperparameter optimization, but does not provide a systematic analysis of the optimal number.
- Why unresolved: The paper does not conduct an ablation study or provide empirical evidence on how the number of hidden states affects classification accuracy and time-to-detection across different scanner types.
- What evidence would resolve it: A comprehensive evaluation varying the number of hidden states for HMMs across different scanner types and measuring the impact on accuracy and time-to-detection.

### Open Question 2
- Question: How does WebGuard perform against adaptive attackers who can dynamically adjust their behavior based on real-time feedback from the detection system?
- Basis in paper: [explicit] The paper discusses WebGuard's robustness against evasive attacks but does not specifically address adaptive attackers who can modify their behavior in response to detection attempts.
- Why unresolved: The paper focuses on static adversarial models and does not consider scenarios where attackers can learn from and adapt to the detection system's responses.
- What evidence would resolve it: Simulations or experiments involving adaptive attackers that can modify their behavior based on real-time feedback, measuring WebGuard's performance against such dynamic threats.

### Open Question 3
- Question: What is the impact of data preprocessing techniques, such as velocity and inter-arrival time calculations, on the performance of LSTM models compared to HMMs?
- Basis in paper: [explicit] The paper describes preprocessing steps for both LSTM and HMM models but does not provide a comparative analysis of how these preprocessing techniques affect each model's performance.
- Why unresolved: While the paper outlines the preprocessing steps, it does not evaluate the individual contribution of each preprocessing technique to the overall performance of LSTM and HMM models.
- What evidence would resolve it: An ablation study isolating the effects of different preprocessing techniques on LSTM and HMM model performance, providing insights into their relative importance.

## Limitations

- The system's effectiveness depends on accurate browser-side event collection, which sophisticated adversaries could potentially manipulate through event spoofing or client-side modifications
- The approach requires careful tuning of monitored events for each target application, as optimal configurations may vary significantly across different web interfaces
- Empirical validation focuses on controlled environments with known scanner types, limiting generalizability to real-world scenarios with novel or zero-day scanning techniques

## Confidence

- High Confidence: The multi-modal approach's theoretical foundation and demonstrated reduction in communication overhead through WebSocket-based transmission
- Medium Confidence: The detection accuracy claims (>90%) and time-to-detection metrics (hundreds of milliseconds) based on authors' experimental results
- Medium Confidence: The assertion that multi-modal analysis significantly increases computational burden for adversaries, logically sound but needing additional empirical evidence

## Next Checks

1. Deploy WebGuard across three diverse web applications with different interaction patterns to assess detection accuracy and false positive rates in varied real-world contexts

2. Design controlled experiments where attackers attempt to evade detection through event spoofing, timing manipulation, and behavioral pattern mimicry to quantify WebGuard's resilience against sophisticated evasion attempts

3. Measure WebGuard's performance under high-load conditions with concurrent users to evaluate both detection accuracy and communication overhead as the number of simultaneous connections increases