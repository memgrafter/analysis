---
ver: rpa2
title: Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language
  Models
arxiv_id: '2405.14012'
source_url: https://arxiv.org/abs/2405.14012
tags:
- ontology
- knowledge
- language
- dataset
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates ontology-driven symbolic knowledge capture
  from user prompts using large language models. The approach focuses on fine-tuning
  a pre-trained model with a predefined ontology to enable extraction of subject-predicate-object
  triples from user prompts.
---

# Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models

## Quick Facts
- arXiv ID: 2405.14012
- Source URL: https://arxiv.org/abs/2405.14012
- Authors: Tolga Çöplü; Arto Bendiken; Andrii Skomorokhov; Eduard Bateiko; Stephen Cobb
- Reference count: 19
- Primary result: Fine-tuning Mistral-7B-Instruct-v0.2 with 8 samples per ontology concept achieves precision, recall, and F1-scores around 0.75-0.80 for extracting subject-predicate-object triples from user prompts

## Executive Summary
This paper investigates ontology-driven symbolic knowledge capture from user prompts using large language models. The approach focuses on fine-tuning a pre-trained model with a predefined ontology to enable extraction of subject-predicate-object triples from user prompts. The study uses a subset of the KNOW ontology modeling core family relationships and a custom dataset of 143 manually crafted prompts. Fine-tuning experiments with the Mistral-7B-Instruct-v0.2 model demonstrate that providing 8 training samples per ontology concept yields acceptable performance, achieving precision, recall, and F1-scores around 0.75-0.80. The research shows that 18 training epochs are sufficient for effective knowledge capture.

## Method Summary
The study employs QLoRA fine-tuning on the Mistral-7B-Instruct-v0.2 model using a custom dataset of 143 manually crafted prompts based on a subset of the KNOW ontology. The training process uses specific hyperparameters (rank=8, alpha=16, scale=10, 16 layers, learning rate=1e-5, 4 minibatch size, 18 epochs) and evaluates performance across three training set variations (2, 4, and 8 samples per ontology concept). The model's ability to extract subject-predicate-object triples from user prompts is measured against ground truth using precision, recall, and F1-score metrics.

## Key Results
- Fine-tuning with 8 samples per ontology concept achieves acceptable performance (F1-scores 0.75-0.80)
- 18 training epochs are sufficient for effective knowledge capture without overfitting
- The approach successfully converts natural language prompts to structured knowledge triples using the KNOW ontology subset

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning teaches the LLM to internalize ontology concepts for prompt-time knowledge extraction. The LLM learns to map natural language prompts to subject-predicate-object triples by adjusting weights through gradient descent on curated examples. Core assumption: The fine-tuning dataset contains sufficient diverse examples for each ontology concept. Evidence anchors: [abstract]: "fine-tuning experiments with the Mistral-7B-Instruct-v0.2 model demonstrate that providing 8 training samples per ontology concept yields acceptable performance". Break condition: If training data lacks diversity or contains contradictory examples, the model may learn incorrect mappings.

### Mechanism 2
QLoRA enables efficient fine-tuning of large models on limited hardware. Parameter-efficient fine-tuning using low-rank adapters reduces memory requirements while maintaining performance. Core assumption: The rank and scaling parameters (8, 16, 10) are optimal for this task. Evidence anchors: [section 3.1]: "The methods suggested in this paper have been implemented using the Apple MLX framework". Break condition: If the task requires learning complex patterns, low-rank approximations may be insufficient.

### Mechanism 3
18 training epochs provide optimal balance between performance and resource efficiency. Sufficient epochs allow convergence without overfitting, as evidenced by plateauing F1 scores. Core assumption: The learning rate (1e-5) and batch size (4) are appropriate for this task. Evidence anchors: [section 4]: "we observe that 18 epochs are sufficient for fine-tuning". Break condition: If the learning rate is too high, 18 epochs may cause overfitting; if too low, may be insufficient.

## Foundational Learning

- Concept: Subject-predicate-object triple extraction
  - Why needed here: The entire system relies on converting natural language to structured knowledge
  - Quick check question: What are the components of the triple "John is the father of Mary"?

- Concept: Ontology structure and semantics
  - Why needed here: Understanding classes, properties, and relationships is essential for creating training data
  - Quick check question: What's the difference between object properties and data properties in an ontology?

- Concept: Fine-tuning vs. pre-training
  - Why needed here: The paper explicitly chooses fine-tuning over pre-training for practical reasons
  - Quick check question: Why might fine-tuning be preferred over pre-training for adapting to a specific ontology?

## Architecture Onboarding

- Component map: Mistral-7B-Instruct-v0.2 → QLoRA adapter → Ontology concepts → Triple extraction → Knowledge graph
- Critical path: User prompt → LLM processing → Triple extraction → Knowledge graph population
- Design tradeoffs: Fine-tuning vs. in-context learning (token overhead vs. scalability), QLoRA vs. full fine-tuning (efficiency vs. capacity)
- Failure signatures: Poor performance on edge cases, failure to recognize out-of-ontology concepts, incorrect triple extraction
- First 3 experiments:
  1. Test the base model's ability to extract triples from simple prompts without fine-tuning
  2. Fine-tune with minimum samples (2 per concept) and measure performance degradation
  3. Test the model's ability to reject out-of-ontology prompts by providing random text

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of ontology-driven symbolic knowledge capture scale with larger and more complex ontologies beyond the core family relationships tested? Basis in paper: [inferred] The paper focuses on a small subset of the KNOW ontology with 12 concepts. The authors acknowledge this limitation when stating "Although our training and test datasets are not sufficiently diverse or large enough to generalize the results to real user scenarios."

### Open Question 2
What is the optimal balance between in-context learning and fine-tuning for ontology-driven knowledge capture, and how can these approaches be effectively combined? Basis in paper: [explicit] The paper explicitly states "Research typically centers on in-context learning, which heavily relies on prompt engineering. A significant limitation of this approach is the requirement to incorporate the entire custom ontology into the prompt... Given these constraints, in-context learning methods do not provide a scalable solution for ontology-driven symbolic knowledge capture."

### Open Question 3
How does the knowledge capture system handle temporal aspects and changes in relationships over time within the ontology? Basis in paper: [inferred] The KNOW ontology models "spacetime (places, events) and social elements (people, groups, organizations)" but the study focuses only on static family relationships without addressing temporal dynamics or relationship changes.

### Open Question 4
What is the minimum number of training samples required per ontology concept to achieve acceptable performance, and how does this vary across different types of concepts? Basis in paper: [explicit] The paper tests 2, 4, and 8 samples per concept and concludes "providing eight diverse examples for each concept yields acceptable success rates," but acknowledges this may not generalize to real scenarios.

## Limitations

- Small ontology scope: The study uses only a subset of KNOW with 4 classes and 11 object properties, limiting scalability assessment
- Limited dataset size: Custom dataset contains only 143 manually crafted prompts, which may not capture natural language diversity
- Single model evaluation: Only tests Mistral-7B-Instruct-v0.2, preventing generalization across different model architectures

## Confidence

*High confidence* in the core finding that fine-tuning with 8 samples per concept achieves acceptable performance (F1-scores 0.75-0.80) on the tested ontology subset, supported by direct experimental evidence and consistent metrics across concepts.

*Medium confidence* in the generalizability of the 18-epoch optimization, as this appears optimal for the specific dataset and model combination but may vary with different ontologies or training data characteristics.

*Low confidence* in the approach's scalability to larger ontologies or more complex knowledge domains, as the evaluation is limited to a small family relationships subset with manually crafted prompts.

## Next Checks

1. Test the fine-tuned model on out-of-distribution prompts to evaluate robustness and generalization beyond the manually crafted dataset

2. Evaluate the approach with larger ontologies (minimum 50 classes and 100 properties) to assess scalability limitations and performance degradation

3. Compare performance against alternative methods like few-shot prompting or retrieval-augmented generation to establish relative effectiveness for knowledge capture tasks