---
ver: rpa2
title: Language Models with Conformal Factuality Guarantees
arxiv_id: '2402.10978'
source_url: https://arxiv.org/abs/2402.10978
tags:
- conformal
- factuality
- language
- output
- sub-claims
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Conformal factuality is a framework that provides high-probability
  correctness guarantees for language model outputs by connecting language modeling
  with conformal prediction. It treats correctness as an uncertainty quantification
  problem where each output defines an entailment set, and conformal prediction selects
  a level of specificity that is correct with high probability.
---

# Language Models with Conformal Factuality Guarantees

## Quick Facts
- arXiv ID: 2402.10978
- Source URL: https://arxiv.org/abs/2402.10978
- Authors: Christopher Mohri; Tatsunori Hashimoto
- Reference count: 31
- Primary result: Framework providing 80-90% correctness guarantees for LM outputs while retaining most original content

## Executive Summary
This paper introduces conformal factuality, a framework that provides high-probability correctness guarantees for language model outputs by treating factuality as an uncertainty quantification problem. The method uses entailment-based uncertainty sets and conformal prediction to create a back-off algorithm that progressively removes unreliable sub-claims from LM outputs, ensuring correctness with probability at least 1-α while preserving useful information.

## Method Summary
The framework treats correctness as a coverage problem by defining entailment sets E(y) containing all statements that entail an LM output y. Conformal prediction is then applied to select a threshold that guarantees the reference answer y* is in E(y) with probability at least 1-α. The implementation decomposes outputs into sub-claims, scores their uncertainty, and removes those below a calibrated threshold, progressively making outputs less specific until correctness is guaranteed.

## Key Results
- Achieved 80-90% correctness guarantees on closed-book QA tasks
- Improved FactScore by 30-80%, NaturalQuestions by 78-93%, and MATH by 75-95%
- Retained majority of original LM output while providing guarantees
- Framework works across different task types (QA and reasoning)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Correctness of an LM output is equivalent to an uncertainty quantification problem where the uncertainty sets are defined as the entailment set of the LM's output.
- Mechanism: By defining the uncertainty set as all statements that entail the LM's output (E(y) = {y' ∈ Y : y' ⇒ y}), containing a correct reference in this set (y* ∈ E(y)) guarantees the output is correct by entailment.
- Core assumption: Entailment relation is well-defined and can be evaluated for any pair of statements.
- Evidence anchors:
  - [abstract] "We observe that the correctness of an LM output is equivalent to an uncertainty quantification problem, where the uncertainty sets are defined as the entailment set of an LM's output."
  - [section] "Using this entailment set, we can now begin to connect our goal (1) to a well-studied statistical inference problem... For the example in Figure 1, if we add y3 = ∅ and define Ft(x) := yt, we would have the minimum strictly safe threshold r(x, y*) = 2."
  - [corpus] Weak evidence - only related work on conformal prediction for language models, no direct evidence for entailment-based uncertainty sets.
- Break condition: If entailment cannot be consistently defined or evaluated (e.g., ambiguous language, subjective facts), the mechanism fails.

### Mechanism 2
- Claim: Conformal prediction in language models corresponds to a back-off algorithm that provides high probability correctness guarantees by progressively making LM outputs less specific.
- Mechanism: The algorithm removes unreliable sub-claims from the output using uncertainty estimates, expanding the entailment set with each removal until a threshold is reached that guarantees correctness with probability 1-α.
- Core assumption: Sub-claims can be reliably identified and scored for uncertainty/factuality.
- Evidence anchors:
  - [abstract] "Using this connection, we show that conformal prediction in language models corresponds to a back-off algorithm that provides high probability correctness guarantees by progressively making LM outputs less specific (and expanding the associated uncertainty sets)."
  - [section] "Our implementation identifies unreliable parts of an output sequence by decomposing it into sub-claims... We implement Ft as follows: Ft(x) = M({c ∈ (S○L)(x) : s((S○L)(x), c) ≥ t})"
  - [corpus] Moderate evidence - related work on uncertainty quantification for LLMs and sub-claim scoring, but no direct evidence for the specific back-off algorithm.
- Break condition: If uncertainty scoring is unreliable or biased, the algorithm may remove correct claims or retain incorrect ones.

### Mechanism 3
- Claim: The algorithm achieves α-conformal factuality for any user-specified correctness target with α ∈ [1/(n+1), 1].
- Mechanism: By applying split conformal prediction to the sequence of outputs and their entailment sets, the algorithm selects a threshold that guarantees the reference is in the entailment set of the final output with probability at least 1-α.
- Core assumption: The calibration data is exchangeable with the test data.
- Evidence anchors:
  - [abstract] "Evaluations of our approach on closed book QA (FActScore, NaturalQuestions) and reasoning tasks (MATH) show that our approach can provide 80-90% correctness guarantees while retaining the majority of the LM's original output."
  - [section] "Theorem 4.1... Let {Xi, Yi*}n+1 i=1 be exchangeable, Ft be sound, and ˆqα be defined as the ⌈(n+1)(1-α)⌉/n th quantile of the scores {r(Xi, Yi*)}n i=1... Then, for α ∈ [1/(n+1), 1], the following lower bound holds: P(Y*n+1 ∈ E(Fˆqα(Xn+1))) ≥ 1-α."
  - [corpus] Weak evidence - only related work on conformal prediction, no direct evidence for α-conformal factuality.
- Break condition: If the calibration data is not exchangeable with the test data (e.g., distribution shift), the guarantees may not hold.

## Foundational Learning

- Concept: Conformal prediction
  - Why needed here: Provides the statistical framework for constructing uncertainty sets with guaranteed coverage.
  - Quick check question: What is the main advantage of conformal prediction over traditional confidence intervals?

- Concept: Entailment relation
  - Why needed here: Defines the uncertainty sets for LM outputs and establishes the connection between correctness and coverage.
  - Quick check question: How does the entailment relation enable the conversion of correctness guarantees into coverage guarantees?

- Concept: Split conformal prediction
  - Why needed here: The specific instantiation of conformal prediction used in the algorithm, allowing for efficient computation and marginal guarantees.
  - Quick check question: What is the role of the calibration set in split conformal prediction?

## Architecture Onboarding

- Component map: Base LM (L) -> Sub-claim separator (S) -> Sub-claim scorer (s) -> Merger (M) -> Conformal predictor
- Critical path: L → S → s → M → Conformal predictor
- Design tradeoffs:
  - Granularity of sub-claims: Finer granularity allows more precise removal but increases computational cost
  - Uncertainty scoring method: Tradeoff between accuracy and computational efficiency
  - Threshold selection: Higher thresholds provide stronger guarantees but may reduce output usefulness
- Failure signatures:
  - Low recall: Many correct sub-claims are being removed
  - Low precision: Many incorrect sub-claims are being retained
  - Calibration failure: Empirical factuality deviates significantly from target
- First 3 experiments:
  1. Verify the entailment relation: Check that y* ∈ E(y) implies y* ⇒ y for a small set of examples
  2. Test sub-claim scoring: Evaluate the accuracy of uncertainty scores on a validation set
  3. Calibrate threshold: Measure the empirical factuality of outputs at different thresholds on a calibration set

## Open Questions the Paper Calls Out
None

## Limitations
- Framework assumes a well-defined entailment relation that can be consistently evaluated across different types of factual claims
- Method requires significant computational overhead from additional scoring and calibration steps
- Generalization to domains beyond closed-book QA and reasoning tasks remains uncertain

## Confidence

**High Confidence:** The connection between conformal prediction and factuality guarantees is theoretically sound, supported by Theorem 4.1 and the mathematical framework presented. The empirical results showing 80-90% correctness guarantees are well-documented with specific metrics.

**Medium Confidence:** The effectiveness of the back-off algorithm in practice depends heavily on the quality of the sub-claim scorer. While the paper reports strong results, the scorer's performance on diverse domains and complex factual relationships remains to be thoroughly validated.

**Low Confidence:** The claim that 80-90% correctness guarantees can be achieved while retaining "the majority of the LM's original output" is somewhat qualified by the specific task contexts (closed-book QA and MATH). Generalization to other domains and more complex reasoning tasks may yield different results.

## Next Checks

1. **Domain Generalization Test:** Apply the framework to a broader range of factual claims from diverse domains (e.g., news articles, scientific literature) to assess the robustness of the entailment-based approach across different knowledge types.

2. **Human Evaluation of Threshold Tradeoffs:** Conduct detailed human studies to evaluate the quality of outputs at different confidence thresholds, measuring not just correctness but also informativeness and usefulness in practical applications.

3. **Adversarial Stress Test:** Design challenging test cases where the LM is likely to generate partially incorrect outputs, then evaluate whether the back-off algorithm can reliably identify and remove only the incorrect sub-claims while preserving correct ones.