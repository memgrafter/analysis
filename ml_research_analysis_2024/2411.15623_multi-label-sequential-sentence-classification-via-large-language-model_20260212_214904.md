---
ver: rpa2
title: Multi-label Sequential Sentence Classification via Large Language Model
arxiv_id: '2411.15623'
source_url: https://arxiv.org/abs/2411.15623
tags:
- sentence
- learning
- abstracts
- multi-label
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents LLM-SSC, a large language model (LLM)-based
  framework for multi-label sequential sentence classification (SSC) in scientific
  publications. The framework addresses limitations of existing SSC methods by employing
  LLMs to generate SSC labels through designed prompts that incorporate demonstrations
  and query components for enhanced task understanding.
---

# Multi-label Sequential Sentence Classification via Large Language Model

## Quick Facts
- arXiv ID: 2411.15623
- Source URL: https://arxiv.org/abs/2411.15623
- Reference count: 30
- Key outcome: LLM-SSC framework achieves micro F1 of 0.907 and macro F1 of 0.912 on BIORC800 dataset

## Executive Summary
This paper presents LLM-SSC, a large language model (LLM)-based framework for multi-label sequential sentence classification (SSC) in scientific publications. The framework addresses limitations of existing SSC methods by employing LLMs to generate SSC labels through designed prompts that incorporate demonstrations and query components for enhanced task understanding. To handle multi-label classification, the authors propose an auto-weighting multi-label contrastive learning loss that relaxes positive pair constraints and reweights negative pairs based on label information. The paper also introduces BIORC800, a manually annotated multi-label SSC dataset containing 800 biomedical abstracts with 7,911 sentences labeled across six categories.

## Method Summary
LLM-SSC employs a two-pronged approach: in-context learning with demonstrations and parameter-efficient fine-tuning via LoRA. The framework uses Gemma-2b to generate SSC labels through prompts combining demonstration samples and query components. For multi-label classification, it introduces an auto-weighting multi-label contrastive learning loss (WeighCon) that relaxes positive pair constraints and reweights negative pairs based on label similarity. The model also employs a "space-thinking" mechanism that allows additional token generation before producing the expected answer. Experiments demonstrate strong performance on the BIORC800 dataset under both in-context learning and task-specific tuning settings.

## Key Results
- Achieves micro F1 score of 0.907 and macro F1 score of 0.912 on BIORC800 dataset
- In-context learning with 5-shot demonstrations performs best among tested settings
- Auto-weighting multi-label contrastive learning loss (WeighCon) improves performance over standard contrastive approaches
- Space-thinking mechanism with 2 generated tokens yields optimal results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large language models can understand sequential sentence classification tasks through in-context learning with demonstrations and query components.
- Mechanism: The LLM-SSC framework constructs prompts that combine demonstration samples with query components, where demonstrations showcase task patterns and queries describe prediction targets. This approach leverages the LLM's ability to generalize from few examples.
- Core assumption: LLMs possess sufficient generalization ability to understand SSC tasks from a small number of demonstrations without parameter tuning.
- Evidence anchors:
  - [abstract] "the proposed framework utilizes LLMs to generate SSC labels through designed prompts, which enhance task understanding by incorporating demonstrations and a query to describe the prediction target"
  - [section 2.2] "A prompt is created by combining a demonstration context with a query, which is then fed into the language model to generate the prediction"

### Mechanism 2
- Claim: The auto-weighting multi-label contrastive learning loss addresses the class collision issue in multi-label SSC.
- Mechanism: WeighCon relaxes the constraint of requiring identical label vectors for positive pairs and introduces an auto-weighting scheme that reweights negative pairs based on label similarity. This prevents pushing apart sentences with similar but not identical labels.
- Core assumption: Sentences sharing at least one common label should be considered positive pairs, and the similarity between label vectors can be effectively captured by an MLP-based weighting function.
- Evidence anchors:
  - [abstract] "We also present a multi-label contrastive learning loss with auto-weighting scheme, enabling the multi-label classification task"
  - [section 2.4] "Instead of requiring identical label vectors for positive pairs, we relax this constraint by forming positive pairs if two sentences share at least one common positive class"

### Mechanism 3
- Claim: The space-thinking mechanism improves LLM performance by allowing additional token generation before producing the expected answer.
- Mechanism: The model generates the next n tokens after the prompt using greedy search, and these tokens are then mapped to the label space through a verbalizer that concatenates hidden states and applies a two-layer MLP.
- Core assumption: Providing space for the LLM to generate additional tokens before the expected answer allows it to process information more effectively and produce better predictions.
- Evidence anchors:
  - [section 2.3] "When employing the ICL approach outlined in Subsection 2.2, the model does not immediately generate the expected SSC label but first produces tokens not present in the label set"
  - [section 3.4.3] "The results show that generating two tokens yields the best micro and macro F1 scores across both datasets"

## Foundational Learning

- Concept: Sequential Sentence Classification (SSC)
  - Why needed here: Understanding that SSC involves categorizing sentences based on their rhetorical roles within a sequence, where context from neighboring sentences informs the classification.
  - Quick check question: What distinguishes SSC from regular sentence classification, and why is neighboring context important?

- Concept: Multi-label classification
  - Why needed here: The framework handles cases where sentences can have multiple rhetorical roles simultaneously, requiring techniques that go beyond single-label classification.
  - Quick check question: How does multi-label classification differ from multi-class classification, and what challenges does it introduce?

- Concept: Contrastive learning
  - Why needed here: The auto-weighting multi-label contrastive learning loss leverages contrastive learning principles to improve model performance by learning from positive and negative pairs.
  - Quick check question: What is the purpose of contrastive learning in supervised settings, and how does it differ from traditional classification approaches?

## Architecture Onboarding

- Component map: Prompt construction (Demonstration selection -> Query creation -> Prompt formatting) -> In-context learning (Prompt input -> LLM generation -> Label extraction) OR Fine-tuning (Demonstration integration -> Space-thinking mechanism -> LoRA parameter-efficient tuning) -> Contrastive learning regularization (Positive/negative pair formation -> Auto-weighting scheme -> Memory bank support) -> Label prediction

- Critical path: Prompt construction → In-context learning or Fine-tuning → Contrastive learning regularization → Label prediction

- Design tradeoffs:
  - Using LLMs provides better contextual understanding but requires more computational resources
  - Parameter-efficient fine-tuning (LoRA) reduces storage requirements but may limit performance compared to full fine-tuning
  - Auto-weighting scheme addresses class collision but adds complexity to the training process

- Failure signatures:
  - Poor in-context learning performance suggests demonstrations are not representative or LLM cannot generalize effectively
  - Contrastive learning issues indicate problems with positive/negative pair formation or weighting scheme
  - Space-thinking mechanism failure suggests the verbalizer mapping is unreliable

- First 3 experiments:
  1. Test in-context learning performance with different numbers of demonstrations (0-shot, 1-shot, 5-shot, 10-shot) on BIORC800
  2. Compare WeighCon performance against HeroCon on multi-label SSC tasks
  3. Evaluate the impact of different numbers of generated tokens in the space-thinking mechanism on final performance

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas warrant further investigation:

1. How would the proposed LLM-SSC framework perform on datasets from different domains beyond biomedical and computer science abstracts?
2. What is the optimal number of demonstration examples (shots) for different dataset sizes and complexities?
3. How does the performance of LLM-SSC compare to traditional fine-tuned models when using equivalent computational resources?
4. How sensitive is the WeighCon multi-label contrastive learning loss to the choice of hyperparameters like the scaling factor λ and the MLP architecture?
5. What is the impact of the space-thinking mechanism on model performance across different sentence lengths and abstract structures?

## Limitations

- Small test set size (142 sentences) in BIORC800 may lead to unreliable performance estimates
- Limited comparison with state-of-the-art models, only direct comparison is with BioBERT baseline
- Lack of ablation studies to isolate contributions of individual components (WeighCon, space-thinking mechanism)
- Marginal performance improvement from space-thinking mechanism (<1% F1 gain) questions its practical value

## Confidence

**High Confidence Claims:**
- The LLM-SSC framework can perform multi-label SSC on biomedical abstracts with reasonable accuracy
- The BIORC800 dataset is manually annotated and contains multi-label annotations
- Gemma-2b can be fine-tuned for SSC tasks using parameter-efficient methods like LoRA

**Medium Confidence Claims:**
- The auto-weighting multi-label contrastive loss (WeighCon) improves performance compared to standard contrastive losses
- The space-thinking mechanism provides meaningful performance improvements
- In-context learning with demonstrations can achieve competitive performance without fine-tuning

**Low Confidence Claims:**
- LLM-SSC achieves state-of-the-art performance on multi-label SSC tasks
- The performance gains are primarily attributable to the specific architectural innovations rather than the underlying LLM capabilities
- The framework generalizes well to diverse scientific domains beyond biomedical abstracts

## Next Checks

1. **Ablation study validation**: Conduct comprehensive ablation experiments removing the auto-weighting contrastive loss and space-thinking mechanism to isolate their individual contributions to performance. This should include testing with standard cross-entropy loss only, standard contrastive loss without auto-weighting, and varying numbers of generated tokens (0, 1, 2, 3) to determine the optimal configuration.

2. **Dataset size impact analysis**: Evaluate model performance across different test set sizes using bootstrap sampling from the BIORC800 dataset. This would involve training on the full training set and testing on progressively larger subsets of the test set (20%, 40%, 60%, 80%, 100%) to determine how performance metrics stabilize with sample size and whether the reported scores are reliable.

3. **State-of-the-art comparison validation**: Implement and compare against recent competitive models including BioBERT, PubMedBERT, and T5-based approaches using the same train/validation/test splits. This comparison should include both in-context learning and fine-tuning settings, with statistical significance testing to determine whether performance differences are meaningful.