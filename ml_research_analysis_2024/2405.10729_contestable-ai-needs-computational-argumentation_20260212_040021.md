---
ver: rpa2
title: Contestable AI needs Computational Argumentation
arxiv_id: '2405.10729'
source_url: https://arxiv.org/abs/2405.10729
tags:
- proc
- toni
- contestability
- explanations
- argumentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that AI systems need to be contestable, meaning
  humans or other AI systems should be able to challenge their decisions and reasoning.
  Contestability is advocated by guidelines like OECD's AI Principles and regulations
  like GDPR, but it is rarely implemented in current AI systems.
---

# Contestable AI needs Computational Argumentation

## Quick Facts
- arXiv ID: 2405.10729
- Source URL: https://arxiv.org/abs/2405.10729
- Reference count: 25
- Primary result: Computational argumentation is essential for building contestable AI systems that allow humans and other AI systems to challenge decisions

## Executive Summary
The paper argues that AI systems need to be contestable, allowing humans or other AI systems to challenge their decisions and reasoning. This requirement is supported by guidelines like OECD's AI Principles and regulations like GDPR, yet remains largely unimplemented in current AI systems. The authors propose an abstract framework for contestable AI systems that includes four key components: a model, explanation method, redress method, and interaction capability.

Computational argumentation (CA) is presented as ideally suited to support contestability by providing explanations, redress mechanisms, and interaction capabilities. The paper connects CA to explainable AI (XAI) and demonstrates how it can naturally represent the dialectical process of contestation. Future work involves building fully-fledged contestable systems using CA and connecting it to other knowledge representation techniques like formal verification.

## Method Summary
The paper presents a conceptual framework for contestable AI systems rather than an empirical methodology. It proposes an abstract view where contestable AI includes a model, explanation method, redress method, and interaction capability. The authors argue that computational argumentation is ideally suited to support these components by providing explanations (through argument-based explanations), redress (through argument revision and counterarguments), and interaction capabilities (through dialectical argumentation frameworks). The paper synthesizes existing research on XAI and computational argumentation to support its claims.

## Key Results
- Contestability is a crucial but under-implemented aspect of AI systems, supported by OECD principles and GDPR regulations
- Computational argumentation naturally supports the dialectical process of contestation through explanations, redress mechanisms, and interaction capabilities
- Different types of explanations (feature-attribution, abductive, counterfactual, rule-based, mechanistic) are suited for different contestability scenarios

## Why This Works (Mechanism)
Contestable AI works by enabling a dialectical process where users can challenge AI decisions through a structured framework. The mechanism relies on computational argumentation to provide interpretable explanations that can be contested, allowing for the generation of counterarguments and redress. This creates a feedback loop where the AI system can learn from challenges and improve its reasoning, while users gain trust through understanding and being heard.

## Foundational Learning

1. **Contestability** - The ability for humans or AI systems to challenge decisions and reasoning
   - Why needed: To ensure accountability and trust in AI systems as required by regulations
   - Quick check: Does the system allow users to question and receive justification for decisions?

2. **Computational Argumentation** - A framework for representing and reasoning with arguments and counterarguments
   - Why needed: Provides natural mechanisms for explanation and dialectical reasoning
   - Quick check: Can the system generate counterarguments and revise its reasoning?

3. **Explainable AI (XAI)** - Methods for making AI decisions interpretable to humans
   - Why needed: Essential for users to understand and contest AI decisions
   - Quick check: Are explanations provided in a form that users can understand and challenge?

## Architecture Onboarding

Component Map: Model -> Explanation Method -> Redress Method -> Interaction Capability

Critical Path: User challenge → Explanation generation → Redress mechanism → Updated decision/confirmation

Design Tradeoffs:
- Depth vs. simplicity of explanations
- Computational overhead of argumentation vs. benefits of contestability
- Granularity of redress mechanisms

Failure Signatures:
- Inability to generate meaningful counterarguments
- Explanations that are too complex for users to understand
- Redress mechanisms that don't lead to satisfactory resolutions

First Experiments:
1. Implement a basic contestable system for a simple classification task
2. Test the system with user challenges and measure satisfaction
3. Evaluate the computational overhead of the argumentation framework

## Open Questions the Paper Calls Out
None

## Limitations
- The conceptual framework remains largely abstract with limited empirical validation
- Integration of CA with other KR techniques like formal verification is mentioned but not demonstrated
- Potential computational overhead and scalability challenges are not addressed

## Confidence
- High: Correctly identifies contestability as crucial and under-implemented, with sound abstract framework
- Medium: Claim that CA is ideally suited needs more practical validation; relationship between explanation types and scenarios needs empirical evidence

## Next Checks
1. Implement a prototype contestable AI system using computational argumentation and evaluate its performance in handling real user challenges across different domains
2. Conduct user studies to assess how effectively CA-based explanations support different types of contestation compared to other explanation methods
3. Analyze the computational overhead and scalability of CA-based contestable AI systems compared to non-contestable alternatives