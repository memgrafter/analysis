---
ver: rpa2
title: 'Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language
  Models with Assigned Visual Personas'
arxiv_id: '2410.03181'
source_url: https://arxiv.org/abs/2410.03181
tags:
- llms
- aggressiveness
- images
- visual
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether multi-modal large language models
  (LLMs) can align their behaviors with visual personas, a gap in the literature that
  predominantly focuses on text-based personas. The researchers developed a novel
  dataset of 5,185 fictional avatar images and analyzed how LLMs perceive aggressiveness
  in these images, finding that their assessments align closely with human judgments.
---

# Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large Language Models with Assigned Visual Personas

## Quick Facts
- arXiv ID: 2410.03181
- Source URL: https://arxiv.org/abs/2410.03181
- Reference count: 24
- Key finding: LLMs can align negotiation behaviors with visual personas, showing increased aggressiveness when assigned aggressive personas and adapting based on relative aggressiveness to opponents.

## Executive Summary
This study investigates whether multi-modal large language models can align their behaviors with visual personas, addressing a gap in literature focused primarily on text-based personas. Researchers developed a dataset of 5,185 fantasy avatar images and analyzed how LLMs perceive aggressiveness in these images, finding strong alignment with human judgments. Using these images as visual personas in negotiation games, the study demonstrated that LLMs exhibit negotiation behaviors consistent with their assigned personas, with GPT-4o showing particular sophistication in adapting its behavior based on both its own and its opponent's aggressiveness levels.

## Method Summary
The researchers created a dataset of 5,185 fantasy avatar images using Stable Diffusion, with objective appearance factors labeled (weapon, smile, teeth, covered face, dressed black/white). They collected aggressiveness ratings from GPT-4o, Claude 3 Haiku, and human annotators on a 1-7 scale. Two studies were conducted using ultimatum game negotiation scenarios: Study 1 involved LLMs negotiating with a fixed confederate, while Study 2 had two LLMs with assigned visual personas negotiating each other. Negotiation outcomes (offer amounts, acceptance rates, dialogue sentiment) were analyzed using regression analyses.

## Key Results
- LLMs assess image aggressiveness similarly to humans (GPT-4o correlation r = 0.41 with human ratings)
- LLMs with aggressive visual personas make more aggressive negotiation offers
- GPT-4o adjusts offers based on relative aggressiveness, offering more to less aggressive opponents and less to more aggressive ones
- Dialogue sentiment analysis shows lower-aggression personas use more inclusive language ("we" vs "I"/"you")

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Visual personas assigned to LLMs influence negotiation behavior by altering perceived aggressiveness.
- Mechanism: LLMs process visual cues through multimodal understanding, mapping visual features to personality traits like aggressiveness, which then modulate generated negotiation strategies.
- Core assumption: The LLM's visual modality is sufficiently trained to interpret visual cues in a way that correlates with human perception of aggressiveness.
- Evidence anchors: [abstract] "LLMs assess the aggressiveness of images in a manner similar to humans"; [section] "LLMs assess the aggressiveness of images in a manner similar to humans and output more aggressive negotiation behaviors when prompted with an aggressive visual persona"

### Mechanism 2
- Claim: LLMs adjust behavior based on relative aggressiveness between self and opponent.
- Mechanism: The LLM compares its own visual persona's aggressiveness score to that of its opponent, adjusting offers and acceptance thresholds to either dominate weaker opponents or submit to stronger ones.
- Core assumption: The LLM is capable of maintaining and comparing two separate persona assessments in context.
- Evidence anchors: [abstract] "LLMs exhibited more aggressive negotiation behaviors when the opponent's image appeared less aggressive than their own"; [section] "GPT-4o increased its offers as its aggressiveness increased but decreased as its opponent's aggressiveness increased"

### Mechanism 3
- Claim: Text-based negotiation behaviors reflect visual persona-driven aggressiveness through sentiment and conflict cues.
- Mechanism: Generated negotiation text contains linguistic markers that correlate with the aggressiveness level of the assigned visual persona.
- Core assumption: The LLM's language generation is influenced by the personality traits inferred from visual input.
- Evidence anchors: [abstract] "LLMs assess the aggressiveness of images in a manner similar to humans"; [section] "models with lower-aggression images used the term 'we' more frequently than 'I' or 'you'"

## Foundational Learning

- Concept: Multimodal understanding in LLMs
  - Why needed here: The study hinges on the ability of LLMs to interpret and respond to visual inputs, not just text.
  - Quick check question: Can the LLM correctly classify visual features like weapons or smiles as indicators of aggressiveness?

- Concept: Negotiation game theory as behavioral proxy
  - Why needed here: The ultimatum game is used as a measurable framework to quantify behavioral changes induced by visual personas.
  - Quick check question: Does the LLM's offer pattern change predictably with assigned persona aggressiveness?

- Concept: Relative trait comparison in social behavior
  - Why needed here: The study explores whether LLMs adjust behavior based on relative differences in aggressiveness between self and opponent.
  - Quick check question: Does the LLM's offer strategy shift depending on whether it perceives itself as more or less aggressive than the opponent?

## Architecture Onboarding

- Component map: Visual input → Multimodal encoder → Persona inference → Behavioral policy → Negotiation output
- Critical path: Image processing → Aggressiveness scoring → Negotiation strategy generation → Text output
- Design tradeoffs: Using GPT-4o (more capable) vs Claude 3 Haiku (cost-effective); balancing granularity of visual traits vs model interpretability
- Failure signatures: Inconsistent aggressiveness scoring, failure to adjust behavior relative to opponent, or text outputs not matching visual persona traits
- First 3 experiments:
  1. Validate that LLMs score visual aggressiveness similarly to human annotators
  2. Test whether visual persona assignment changes negotiation behavior in a controlled ultimatum game
  3. Assess whether LLMs adjust behavior based on relative aggressiveness between self and opponent

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs process and interpret visual information compared to humans, and what are the underlying mechanisms that enable this similarity in perception of aggressiveness?
- Basis in paper: [explicit] The paper states that LLMs assess the aggressiveness of images in a manner similar to humans, with high correlation in their ratings.
- Why unresolved: While the paper demonstrates a correlation between LLM and human ratings of aggressiveness, it does not delve into the underlying mechanisms or cognitive processes that enable this similarity.
- What evidence would resolve it: Further research exploring the internal workings of LLMs, including their attention mechanisms and feature extraction processes, could shed light on how they interpret visual information and compare to human perception.

### Open Question 2
- Question: How do LLMs adapt their negotiation strategies based on the relative aggressiveness of their opponents, and what factors influence this adaptation?
- Basis in paper: [explicit] The paper mentions that GPT-4o adjusts its negotiation behavior based on the aggressiveness of its opponent, offering more to less aggressive opponents and less to more aggressive ones.
- Why unresolved: The paper provides initial insights into this adaptation but does not fully explore the factors influencing this behavior or the specific strategies employed by LLMs in different scenarios.
- What evidence would resolve it: Further studies investigating the negotiation dialogues and strategies employed by LLMs in various scenarios, including different levels of aggressiveness and opponent types, could provide a more comprehensive understanding of their adaptive behavior.

### Open Question 3
- Question: How can visual personas be effectively used to develop more interactive and human-aligned AI agents, and what are the potential ethical implications of this approach?
- Basis in paper: [explicit] The paper discusses the potential of visual personas to influence LLM behavior and suggests new directions for developing more interactive and human-aligned AI agents.
- Why unresolved: While the paper highlights the potential of visual personas, it does not delve into the specific applications or ethical considerations of this approach.
- What evidence would resolve it: Further research exploring the practical applications of visual personas in various domains, as well as ethical assessments of their potential impacts on human-AI interactions, could provide valuable insights into their effective and responsible use.

## Limitations
- Correlation between model and human aggressiveness ratings, while significant, shows considerable variation (r = 0.41 for GPT-4o)
- Findings are limited to negotiation scenarios in an ultimatum game framework, which may not generalize to other behavioral contexts
- The dataset of 5,185 images, while substantial, may not capture the full diversity of visual personas encountered in practical settings

## Confidence

| Claim | Confidence |
|-------|------------|
| Visual personas influence LLM negotiation behavior | Medium |
| GPT-4o shows nuanced behavior adaptation based on relative aggressiveness | Medium |
| Findings generalize beyond ultimatum games | Low |

## Next Checks

1. **Cross-task validation**: Test whether visual persona alignment effects persist in non-negotiation tasks such as creative writing, customer service interactions, or decision-making scenarios to establish generalizability beyond the ultimatum game framework.

2. **Real-world image testing**: Evaluate model behavior when using authentic photographs of real people rather than generated fantasy avatars to determine if findings translate to practical applications where visual personas represent actual individuals.

3. **Longitudinal behavior assessment**: Conduct studies measuring whether visual persona effects persist across extended interactions or multiple sessions, as opposed to single-shot negotiations, to understand the stability and durability of persona-driven behavioral changes.