---
ver: rpa2
title: Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement
arxiv_id: '2406.00987'
source_url: https://arxiv.org/abs/2406.00987
tags:
- graph
- detection
- anomaly
- attributes
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness in unsupervised graph anomaly detection
  (GAD), where current methods overlook demographic bias linked to sensitive attributes
  like gender or ethnicity. The authors propose DEFEND, a novel framework that integrates
  disentangled representation learning into GAD.
---

# Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement
## Quick Facts
- arXiv ID: 2406.00987
- Source URL: https://arxiv.org/abs/2406.00987
- Reference count: 40
- This paper proposes DEFEND, a framework integrating disentangled representation learning into unsupervised graph anomaly detection to address demographic bias.

## Executive Summary
This paper addresses fairness in unsupervised graph anomaly detection (GAD), where current methods overlook demographic bias linked to sensitive attributes like gender or ethnicity. The authors propose DEFEND, a novel framework that integrates disentangled representation learning into GAD. DEFEND employs a graph neural network (GNN) encoder to separate sensitive-relevant and sensitive-irrelevant node representations in latent space. Anomaly detection then relies solely on the sensitive-irrelevant representations via reconstruction error, with an added constraint to reduce correlation between reconstruction errors and sensitive attributes. Experiments on Reddit and Twitter datasets show that DEFEND significantly improves fairness (e.g., up to 11.6% improvement in demographic parity) while maintaining competitive anomaly detection accuracy compared to state-of-the-art baselines. This work is the first to explicitly tackle fairness in unsupervised GAD.

## Method Summary
The proposed DEFEND framework integrates disentangled representation learning into unsupervised graph anomaly detection. It employs a GNN encoder to separate node representations into sensitive-relevant and sensitive-irrelevant components in latent space. Anomaly detection relies on reconstruction errors computed from the sensitive-irrelevant representations, with an additional constraint to minimize correlation between reconstruction errors and sensitive attributes. The method is evaluated on Reddit and Twitter datasets, showing significant improvements in fairness metrics while maintaining competitive anomaly detection accuracy.

## Key Results
- DEFEND achieves up to 11.6% improvement in demographic parity on tested datasets.
- The framework maintains competitive anomaly detection accuracy compared to state-of-the-art baselines.
- This is the first work to explicitly address fairness in unsupervised graph anomaly detection.

## Why This Works (Mechanism)
DEFEND works by leveraging disentangled representation learning to separate node features into sensitive-relevant and sensitive-irrelevant components. By focusing anomaly detection solely on the sensitive-irrelevant representations, the method reduces bias introduced by demographic attributes. The additional constraint on reconstruction errors ensures that anomalies are detected based on intrinsic graph properties rather than sensitive attributes, thereby improving fairness without sacrificing detection performance.

## Foundational Learning
1. **Graph Neural Networks (GNNs)**: Used for encoding node features into latent representations. Needed to capture structural and feature information from graph data. Quick check: Verify GNN layers are properly configured for the dataset size and complexity.
2. **Disentangled Representation Learning**: Separates latent representations into distinct components (sensitive-relevant vs. sensitive-irrelevant). Needed to isolate demographic bias from intrinsic graph properties. Quick check: Ensure the disentanglement loss is effectively minimizing correlation between components.
3. **Anomaly Detection via Reconstruction Error**: Detects anomalies by measuring reconstruction error of node features. Needed to identify deviations from normal graph patterns. Quick check: Validate that reconstruction errors are sensitive to anomalies but not to sensitive attributes.

## Architecture Onboarding
**Component Map**: GNN Encoder -> Disentangled Representation -> Reconstruction Error Calculation -> Anomaly Detection
**Critical Path**: Input graph -> GNN encoder -> Separate sensitive-relevant and sensitive-irrelevant representations -> Compute reconstruction error on sensitive-irrelevant part -> Detect anomalies
**Design Tradeoffs**: Balancing fairness (reducing correlation with sensitive attributes) vs. anomaly detection accuracy (maintaining high reconstruction error sensitivity to anomalies)
**Failure Signatures**: High reconstruction error correlation with sensitive attributes indicates poor disentanglement; low anomaly detection accuracy suggests overly aggressive fairness constraints
**3 First Experiments**: 1) Test disentanglement effectiveness by measuring correlation between reconstruction errors and sensitive attributes. 2) Evaluate anomaly detection accuracy on a balanced dataset. 3) Assess fairness improvements using demographic parity on synthetic biased graphs.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation is limited to social network datasets (Reddit and Twitter), which may not generalize to other domains like biological or financial networks.
- Fairness is measured only through demographic parity, without exploring other metrics like equalized odds or equal opportunity.
- The assumption that sensitive attributes are known and available during training may not hold in real-world scenarios where such attributes are private or unavailable.

## Confidence
- **High**: The core methodology (disentangled representation learning for GAD) is well-defined and the reported fairness improvements are statistically significant on the tested datasets.
- **Medium**: The claim of being the "first to tackle fairness in unsupervised GAD" is plausible but difficult to verify exhaustively due to the broad scope of related literature.
- **Medium**: The assertion that DEFEND maintains "competitive" anomaly detection accuracy is supported by comparisons to baselines, but the definition of "competitive" is relative and context-dependent.

## Next Checks
1. Test DEFEND on additional graph datasets from diverse domains (e.g., citation networks, biological interaction graphs) to assess generalizability.
2. Evaluate the framework using alternative fairness metrics (e.g., equalized odds, equal opportunity) to ensure robustness across different fairness definitions.
3. Conduct a sensitivity analysis to quantify the trade-off between fairness improvements and anomaly detection accuracy across varying thresholds of sensitive attribute correlation.