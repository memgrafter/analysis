---
ver: rpa2
title: Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided
arxiv_id: '2404.01288'
source_url: https://arxiv.org/abs/2404.01288
tags:
- reappraisal
- situation
- narrator
- responses
- cognitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores whether large language models (LLMs) can generate
  cognitively-based reappraisal responses to support users in distress. The authors
  propose RESORT, a framework of psychologically grounded reappraisal constitutions
  across six cognitive appraisal dimensions, designed as LLM instructions.
---

# Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided

## Quick Facts
- **arXiv ID:** 2404.01288
- **Source URL:** https://arxiv.org/abs/2404.01288
- **Reference count:** 40
- **Key outcome:** Expert evaluation shows LLM-guided responses significantly outperform human-written responses on reappraisal alignment, empathy, harmfulness, and factuality.

## Executive Summary
This paper demonstrates that large language models can effectively generate cognitive reappraisal responses to support users in distress when guided by psychologically grounded constitutions. The authors introduce RESORT, a framework of reappraisal constitutions across six cognitive dimensions designed as LLM instructions. Using two prompting strategies—individual and iterative guided refinement—LLMs generated targeted reappraisal responses that expert clinical psychologists evaluated as significantly superior to both baselines and human-written responses across multiple quality metrics. Notably, even smaller 7B-scale open-source models performed comparably to GPT-4 when guided by RESORT constitutions, suggesting the approach's scalability and effectiveness.

## Method Summary
The study employed a prompt engineering approach using RESORT, a framework containing six psychologically grounded reappraisal constitutions designed as structured instructions for LLMs. Two prompting strategies were tested: individual prompting (where each constitution was applied separately) and iterative guided refinement (where constitutions were applied sequentially to refine responses). The LLM-generated responses were evaluated by expert clinical psychologists on four key dimensions: alignment with reappraisal constitutions, empathy, harmfulness, and factuality. The study compared guided LLM responses against baseline models and human-written responses, using a sample of distress scenarios as input prompts.

## Key Results
- LLM responses guided by RESORT constitutions significantly outperformed human-written responses and baselines across all expert evaluation metrics
- 7B-scale open-source models achieved performance comparable to GPT-4 when using RESORT-guided prompting
- GPT-4 showed moderate agreement with human experts in automatic evaluation, validating the expert assessment approach

## Why This Works (Mechanism)
The effectiveness stems from providing LLMs with structured psychological frameworks that align with established cognitive reappraisal theory. By decomposing reappraisal into six specific cognitive dimensions and translating these into precise prompting instructions, the models can generate responses that target specific aspects of emotional distress rather than generic empathetic statements. The iterative refinement approach allows for deeper engagement with the user's situation by sequentially applying different reappraisal perspectives.

## Foundational Learning
- **Cognitive reappraisal theory**: The psychological foundation for restructuring thought patterns to manage emotions - needed to design effective reappraisal constitutions that target specific cognitive distortions
- **Prompt engineering principles**: Techniques for structuring LLM instructions to achieve desired outputs - required to translate psychological concepts into effective model prompts
- **Expert evaluation methodology**: Systematic approaches for having domain experts assess AI-generated content - essential for validating the quality and appropriateness of therapeutic responses

## Architecture Onboarding
**Component Map:** RESORT constitutions -> Prompt strategies (individual/iterative) -> LLM generation -> Expert evaluation
**Critical Path:** Constitutions design → Prompt engineering → Response generation → Expert evaluation → Quality assessment
**Design Tradeoffs:** The study prioritized psychological validity and expert evaluation over scalability and real-world deployment, focusing on proof-of-concept rather than implementation challenges
**Failure Signatures:** Generic or superficial responses when constitutions are poorly specified; misalignment with psychological principles; reduced effectiveness with open-ended or ambiguous distress scenarios
**3 First Experiments:** 1) Test RESORT constitutions across diverse emotional distress types beyond the initial scope 2) Evaluate longitudinal effects of repeated LLM-guided interactions 3) Compare guided LLM responses with standard therapeutic interventions in clinical populations

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on expert evaluation rather than clinical outcomes or user testing in real-world distress scenarios
- Prompt engineering approach may not generalize to all types of emotional distress or cultural contexts
- Evaluation focuses on single-turn interactions rather than ongoing therapeutic relationships

## Confidence
- **High confidence**: LLMs guided by RESORT constitutions significantly outperform baselines in expert evaluation metrics
- **Medium confidence**: 7B-scale open-source models perform comparably to GPT-4 when guided by RESORT
- **Medium confidence**: Expert evaluations show consistent preference for guided LLM responses over human-written ones, but sample size limitations apply

## Next Checks
1. Conduct randomized controlled trials comparing guided LLM responses with standard therapeutic interventions in clinical populations experiencing actual distress
2. Test RESORT constitution effectiveness across diverse cultural contexts and emotional distress types
3. Evaluate longitudinal effects of repeated LLM-guided reappraisal interactions versus single-turn exchanges