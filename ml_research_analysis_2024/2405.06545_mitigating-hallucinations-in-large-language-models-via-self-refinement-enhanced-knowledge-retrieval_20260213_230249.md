---
ver: rpa2
title: Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced
  Knowledge Retrieval
arxiv_id: '2405.06545'
source_url: https://arxiv.org/abs/2405.06545
tags:
- knowledge
- retrieval
- llms
- triples
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Self-Refinement-Enhanced Knowledge Graph
  Retrieval (Re-KGR), a method to reduce hallucinations in large language models by
  combining entity detection based on next-token predictive probability distributions
  with knowledge graph retrieval. Re-KGR identifies tokens with high hallucination
  potential and refines the corresponding knowledge triples, then verifies and rectifies
  the responses using retrieved triples.
---

# Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval

## Quick Facts
- arXiv ID: 2405.06545
- Source URL: https://arxiv.org/abs/2405.06545
- Reference count: 40
- Key outcome: Re-KGR improves GPT-4 truthfulness scores by 15.75% over baseline and reduces retrieval time by 63-75%

## Executive Summary
This paper introduces Self-Refinement-Enhanced Knowledge Graph Retrieval (Re-KGR), a method to reduce hallucinations in large language models by combining entity detection based on next-token predictive probability distributions with knowledge graph retrieval. The approach identifies tokens with high hallucination potential using entropy and distribution divergence metrics, then refines knowledge triples associated with these entities before retrieval. Experiments on the medical dataset MedQuAD demonstrate that Re-KGR improves response truthfulness while significantly reducing retrieval time compared to retrieving all triples.

## Method Summary
Re-KGR mitigates hallucinations by first detecting critical entities through entropy and distribution divergence analysis across model layers, then extracting and refining knowledge triples associated with these entities. The refined triple set is used for knowledge graph retrieval, followed by semantic similarity verification against the original content. The method prioritizes a straightforward KG retrieval strategy focusing on synonym detection and similarity assessment rather than complex supervised models. The approach is evaluated on the medical domain using MedQuAD dataset with Clinical Knowledge Graph and PrimeKG.

## Key Results
- GPT-4 truthfulness scores improved by 15.75% compared to baseline LLaMA-7B
- GPT-4 scores improved by 3.21% compared to DoLa alone
- Retrieval time reduced by 63% to 75% compared to retrieving all triples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method identifies hallucination-prone tokens by measuring the divergence between final-layer and intermediate-layer probability distributions.
- Mechanism: The system computes Jensen-Shannon divergence between the next-token probability distribution at the final layer (N) and each intermediate layer (j) for each token. Tokens with high divergence across higher layers are flagged as having high hallucination potential.
- Core assumption: When LLMs predict important predictions requiring factual knowledge, the divergence between final and intermediate layers remains high in higher layers.
- Evidence anchors:
  - [abstract] "Our approach leverages the attribution of next-token predictive probability distributions across different tokens, and various model layers to primarily identify tokens with a high potential for hallucination"
  - [section 2.2] "DoLa [10] suggests that divergence in distribution between the final layer and each intermediate layer may reveal critical entities requiring factual knowledge. Notably, significant divergence in higher layers indicates important entities."
- Break condition: If the assumption about divergence patterns in higher layers fails, the entity detection would become unreliable, potentially flagging too many or too few tokens.

### Mechanism 2
- Claim: The method reduces retrieval costs by refining the triple set before knowledge graph querying, only retrieving triples associated with high-risk entities.
- Mechanism: After detecting critical entities, the system extracts all knowledge triples from the generated response, then filters to retain only those containing the identified high-risk entities. This refined triple set is used for KG retrieval instead of retrieving all triples.
- Core assumption: Hallucinations are localized to specific entities or relationships rather than being distributed throughout the response.
- Evidence anchors:
  - [abstract] "Our approach leverages the attribution of next-token predictive probability distributions across different tokens, and various model layers to primarily identify tokens with a high potential for hallucination, reducing verification rounds by refining knowledge triples associated with these tokens."
  - [section 3.3] "we exploit extracted triples along with identified uncertain entities to derive the final triple set... This refined set simplifies the KG verification procedure by removing redundant information"
- Break condition: If hallucinations are not localized to specific entities, the refinement would miss problematic content, leading to incomplete hallucination mitigation.

### Mechanism 3
- Claim: The method verifies retrieved knowledge against the original content using semantic similarity, replacing only those triples that don't match the KG.
- Mechanism: After retrieving knowledge triples from the KG, the system computes similarity scores between each original triple and the corresponding retrieved triples. If maximum similarity falls below a threshold, the system replaces the original triple with the KG version.
- Core assumption: The KG contains correct knowledge and semantic similarity measurement can reliably identify mismatches.
- Evidence anchors:
  - [abstract] "we rectify inaccurate content using retrieved knowledge in the post-processing stage, which improves the truthfulness of generated responses"
  - [section 3.5] "we employ semantic-similarity measurement models S (¬∑) to evaluate the consistency between t·µ¢‚Å∞ and the corresponding retrieved {t·µ¢·µç}. Similarity score vector is defined as s·µ¢ = S (t·µ¢‚Å∞, {t·µ¢·µç})."
- Break condition: If the KG contains errors or the semantic similarity model produces false positives/negatives, the rectification could introduce new errors or miss existing ones.

## Foundational Learning

- Concept: Next-token probability distribution and entropy calculation
  - Why needed here: Understanding how the method quantifies predictive uncertainty using entropy is essential for grasping the entity detection mechanism
  - Quick check question: If a token has a probability distribution where one token has 0.99 probability and all others have 0.01/999, what is the entropy value?

- Concept: Knowledge graph triple structure and retrieval
  - Why needed here: The method relies on extracting and refining triples in the form <[SBJ], [PRE], [OBJ]> for KG retrieval
  - Quick check question: Given the sentence "Aspirin can cause stomach bleeding", what would be the corresponding triple structure?

- Concept: Semantic similarity measurement between knowledge triples
  - Why needed here: The verification mechanism uses semantic similarity to determine whether retrieved triples match the original content
  - Quick check question: How would you determine if the triple <Diabetes, treated by, insulin> is semantically similar to <Diabetes, managed with, insulin injections>?

## Architecture Onboarding

- Component map: Entity Detection -> Triple Extraction -> KG Retrieval -> Knowledge Verification & Rectification
- Critical path: Entity Detection ‚Üí Triple Extraction ‚Üí KG Retrieval ‚Üí Knowledge Verification & Rectification
- Design tradeoffs: The method trades computational efficiency (reduced retrieval) for potential risk of missing some hallucinations; also trades precision for recall in entity detection
- Failure signatures: 
  - Entity detection fails: Too many/few entities flagged, leading to over/under-refinement
  - Retrieval fails: Incorrect triples retrieved or no triples found for valid queries
  - Verification fails: Similarity threshold too high (misses corrections) or too low (introduces errors)
- First 3 experiments:
  1. Test entity detection on known hallucinated responses to verify it correctly identifies problematic tokens
  2. Compare retrieval time and accuracy with/without triple refinement on a sample dataset
  3. Evaluate the impact of different similarity thresholds on the balance between false positives and false negatives in the verification stage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Re-KGR scale when applied to other domains beyond healthcare, such as finance or legal applications?
- Basis in paper: [explicit] The authors note that Re-KGR can be readily applied to various downstream tasks provided there are well-constructed domain-specific knowledge graphs, though it is primarily targeted at the medical field.
- Why unresolved: The paper only evaluates Re-KGR on the medical dataset MedQuAD, leaving its performance in other domains unexplored.
- What evidence would resolve it: Conducting experiments on datasets from other domains (e.g., finance, legal) with appropriate knowledge graphs and comparing the performance metrics.

### Open Question 2
- Question: What is the impact of different knowledge graph retrieval strategies (e.g., supervised fine-tuned models like TransE vs. the synonym detection and similarity assessment approach used in Re-KGR) on the overall performance and efficiency?
- Basis in paper: [inferred] The paper mentions that previous research on KG retrieval has primarily relied on supervised fine-tuned models such as TransE, while Re-KGR prioritizes a straightforward strategy focusing on synonym detection and similarity assessment.
- Why unresolved: The paper does not compare the performance of different KG retrieval strategies, leaving their relative effectiveness unknown.
- What evidence would resolve it: Implementing and comparing multiple KG retrieval strategies within Re-KGR and evaluating their impact on performance and efficiency metrics.

### Open Question 3
- Question: How does the integration of retrieval processes during the generation phase (rather than post-generation) affect the overall generation time and performance of Re-KGR?
- Basis in paper: [explicit] The authors mention that they will investigate the integration of retrieval processes during the generation phase to further cut down overall generation time in future work.
- Why unresolved: The paper only implements retrieval in the post-generation stage and does not explore the impact of integrating retrieval during generation.
- What evidence would resolve it: Modifying Re-KGR to integrate retrieval during the generation phase and comparing the generation time and performance metrics with the post-generation approach.

## Limitations

- Entity Detection Reliability: The method relies heavily on entropy and distribution divergence metrics to identify hallucination-prone tokens, but this core assumption is not empirically validated in the paper.
- Knowledge Graph Completeness: The approach assumes the knowledge graph contains accurate and comprehensive information for verification, but completeness metrics or error rates for the combined KG are not provided.
- Semantic Similarity Threshold Sensitivity: The verification mechanism uses a similarity threshold to determine whether to replace original triples, but the paper doesn't provide sensitivity analysis showing how different threshold values affect performance.

## Confidence

- High Confidence: The improvement in GPT-4 truthfulness scores (15.75% improvement over baseline, 3.21% over DoLa) is well-documented with specific numbers. The reduction in retrieval time (63-75%) is also clearly quantified.
- Medium Confidence: The general approach of using entity detection to reduce retrieval scope is sound and the mathematical framework for entropy and divergence calculations is clearly presented. However, the empirical validation of whether this approach correctly identifies all hallucination-prone content is limited.
- Low Confidence: The assumption that hallucinations are localized to specific entities (enabling triple refinement to reduce retrieval) and the effectiveness of the semantic similarity verification mechanism in practice are not thoroughly validated. The paper lacks ablation studies showing the individual contribution of each component.

## Next Checks

1. **Entity Detection Validation**: Conduct a human evaluation study where annotators mark hallucination-prone entities in sample responses, then compare these annotations with the entities identified by the entropy/divergence method. Calculate precision, recall, and F1-score for the entity detection component.

2. **Threshold Sensitivity Analysis**: Systematically vary the similarity threshold (ùúè) and the entropy/divergence thresholds used in entity detection. Plot truthfulness scores and retrieval time against threshold values to identify optimal operating points and understand the tradeoffs involved.

3. **KG Coverage and Error Analysis**: For a sample of hallucinated responses where the method failed to correct errors, analyze whether the knowledge graph contained the correct information and whether the semantic similarity measurement correctly identified mismatches. This would reveal whether failures stem from KG limitations or verification mechanism issues.