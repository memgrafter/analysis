---
ver: rpa2
title: Partial-Label Learning with a Reject Option
arxiv_id: '2402.00592'
source_url: https://arxiv.org/abs/2402.00592
tags:
- label
- learning
- noise
- reject
- predictions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel partial-label learning (PLL) method
  with a reject option, named Dst-Pll, that leverages Dempster-Shafer theory (DST)
  to handle ambiguously labeled data. The core idea is to construct basic probability
  assignments (BPAs) from an instance's k-nearest neighbors and combine them using
  Yager's rule to form a credal set.
---

# Partial-Label Learning with a Reject Option

## Quick Facts
- arXiv ID: 2402.00592
- Source URL: https://arxiv.org/abs/2402.00592
- Authors: Tobias Fuchs; Florian Kalinke; Klemens Böhm
- Reference count: 40
- Key outcome: Proposed Dst-Pll method achieves average empirical reject option risk of 0.05 (±0.07) for λ=0.00 and 0.15 (±0.12) for λ=0.20 across all experimental settings

## Executive Summary
This paper introduces Dst-Pll, a novel partial-label learning method with a reject option that leverages Dempster-Shafer theory to handle ambiguously labeled data. The method constructs basic probability assignments from k-nearest neighbors and combines them using Yager's rule to form a credal set, which is then used to inform both predictions and rejection decisions. Extensive experiments on artificial and real-world datasets demonstrate that Dst-Pll provides superior trade-offs between the number and accuracy of non-rejected predictions compared to state-of-the-art PLL methods.

## Method Summary
Dst-Pll is a k-nearest neighbor-based method for partial-label learning that uses Dempster-Shafer theory to construct basic probability assignments from neighboring instances. The method combines these assignments using Yager's rule to form a credal set, which provides belief and plausibility bounds for each label. Predictions are made based on the maximum belief, while a reject option uses an adaptive confidence threshold based on the plausibility of alternative labels. The method is proven to be risk-consistent under mild assumptions and demonstrates superior performance in balancing prediction accuracy and rejection rates across multiple benchmark datasets.

## Key Results
- Dst-Pll achieves average empirical reject option risk of 0.05 (±0.07) for λ=0.00 and 0.15 (±0.12) for λ=0.20 across all experimental settings
- Outperforms all state-of-the-art PLL methods in providing the best trade-off between number and accuracy of non-rejected predictions
- Demonstrates risk-consistency under mild assumptions, ensuring convergence to optimal performance as sample size increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm constructs belief and plausibility bounds using Dempster-Shafer theory to separate aleatoric and epistemic uncertainty in PLL.
- Mechanism: By assigning basic probability assignments (BPAs) based on neighbor labels and combining them with Yager's rule, the method creates a credal set where belief represents supporting evidence and plausibility represents non-contradicting evidence. The reject decision uses the gap between these bounds.
- Core assumption: Neighboring instances in feature space are also close in label space, and ambiguous labels can be modeled as evidence about label hypotheses.
- Evidence anchors:
  - [abstract]: "Our method maintains a feasible region, also known as credal set. Maintaining such a credal set is beneficial in assessing the certainty of predictions as our experiments show."
  - [section 4.1]: "Following the standard assumption that neighboring instances in feature space are also close in label space, we combine the evidence from the k-nearest neighbors"
  - [corpus]: Weak - corpus focuses on reject options in supervised settings, not PLL-specific DST applications
- Break condition: If the neighbor distribution violates the assumption that close instances share similar labels, the belief/plausibility bounds become unreliable and the reject option fails.

### Mechanism 2
- Claim: The adaptive confidence threshold automatically adjusts to the amount of noise in the candidate labels.
- Mechanism: The threshold is set as θ̃m = maxy∈s\{ŷ} pl̃m({y}), which increases with the plausibility of alternative labels. This means more noise requires higher confidence to accept predictions.
- Core assumption: The plausibility of incorrect labels directly correlates with the amount of noise present in the candidate sets.
- Evidence anchors:
  - [abstract]: "The rejection strategy adaptively selects a confidence threshold based on the amount of noise present, allowing the model to reject unsure predictions"
  - [section 4.2]: "The intuition of our reject option is as follows. If the lower bound (belief) on the probability mass of our predicted label exceeds the maximal upper bound (plausibility) on the probability mass regarding any other label, we can safely make the prediction."
  - [corpus]: Weak - corpus neighbors discuss reject options but don't address adaptive thresholds in PLL
- Break condition: If noise levels vary unpredictably or the relationship between plausibility and actual noise breaks down, the adaptive threshold may reject too many or too few predictions.

### Mechanism 3
- Claim: Risk-consistency is achieved by ensuring the true label dominates the neighborhood probability mass.
- Mechanism: The closed-form expression of expected probability mass shows that EP[̃m({ỹ})] > EP[̃m({ỹc})] under Assumption 4.4, guaranteeing that the classifier will converge to the Bayes optimal predictor as sample size increases.
- Core assumption: The true label of an instance dominates its neighborhood in terms of probability mass assignment, which propagates through Yager's combination rule.
- Evidence anchors:
  - [abstract]: "The proposed method is shown to be risk-consistent under mild assumptions."
  - [section 4.3]: "Theorem 4.6 establishes the risk consistency of the proposed classifier."
  - [corpus]: Weak - corpus neighbors don't discuss risk-consistency proofs for PLL with reject options
- Break condition: If Assumption 4.4 is violated (e.g., true label doesn't dominate neighborhood), the consistency guarantee fails and the classifier may not converge to optimal performance.

## Foundational Learning

- Concept: Dempster-Shafer theory and credal sets
  - Why needed here: Provides the mathematical framework for handling ambiguous labels without committing to point estimates, which is essential for separating different types of uncertainty in PLL
  - Quick check question: How does a credal set differ from a standard probability distribution, and why is this distinction important for reject options?

- Concept: Partial-label learning problem formulation
  - Why needed here: Understanding how candidate labels relate to true labels and the sources of uncertainty (aleatoric vs epistemic) is crucial for designing appropriate reject strategies
  - Quick check question: What are the two main sources of uncertainty in PLL, and how does each affect prediction confidence?

- Concept: Risk consistency in statistical learning theory
  - Why needed here: Provides the theoretical foundation for proving that the algorithm will converge to optimal performance, which is necessary for validating the reject option's effectiveness
  - Quick check question: What conditions must be satisfied for a learning algorithm to be risk-consistent, and how does the dominance assumption relate to this?

## Architecture Onboarding

- Component map: Input features -> k-NN search -> BPA construction -> Yager's combination -> Credal set extraction -> Belief/plausibility calculation -> Reject decision -> Output prediction/reject
- Critical path: The combination of BPAs using Yager's rule is the computational bottleneck, as it involves computing intersections of focal sets across all neighbors
- Design tradeoffs: Using DST provides better uncertainty quantification but increases computational complexity compared to point-estimate methods; the adaptive threshold provides better performance but requires maintaining the full credal set
- Failure signatures: Poor k-NN performance due to feature space issues, numerical instability in BPA combination, or threshold miscalibration leading to excessive rejections
- First 3 experiments:
  1. Verify k-NN search returns meaningful neighbors by checking label consistency in small synthetic datasets
  2. Test BPA construction on simple cases with known ground truth to ensure correct belief/plausibility calculation
  3. Validate the reject option by comparing accepted predictions against ground truth in datasets with controlled noise levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Dst-Pll change with different distance metrics in the k-nearest neighbor search?
- Basis in paper: [inferred] The paper mentions that the runtime analysis shows that the nearest-neighbor search dominates the algorithm's runtime, and it uses the ball-tree data structure for querying neighbors.
- Why unresolved: The paper does not explore the impact of using different distance metrics (e.g., Euclidean, Manhattan, cosine similarity) on the algorithm's performance.
- What evidence would resolve it: Conducting experiments using different distance metrics and comparing the resulting performance metrics (accuracy, reject rate, etc.) would provide insights into the sensitivity of Dst-Pll to the choice of distance metric.

### Open Question 2
- Question: Can the Dempster-Shafer theory approach be extended to other weakly supervised learning settings beyond partial-label learning?
- Basis in paper: [explicit] The paper introduces Dst-Pll as a novel approach for partial-label learning with a reject option, leveraging Dempster-Shafer theory to handle ambiguously labeled data.
- Why unresolved: The paper focuses specifically on partial-label learning and does not explore the potential applicability of the Dempster-Shafer theory approach to other weakly supervised learning settings.
- What evidence would resolve it: Investigating the application of Dempster-Shafer theory to other weakly supervised learning settings (e.g., multi-instance learning, semi-supervised learning) and evaluating its effectiveness in those contexts would provide insights into the generalizability of the approach.

### Open Question 3
- Question: How does the choice of the number of neighbors (k) affect the trade-off between the number and accuracy of non-rejected predictions in Dst-Pll?
- Basis in paper: [explicit] The paper mentions that the runtime analysis shows that the nearest-neighbor search dominates the algorithm's runtime, and it uses the ball-tree data structure for querying neighbors.
- Why unresolved: While the paper provides some insights into the impact of k on the algorithm's performance, it does not thoroughly investigate the relationship between k and the trade-off between the number and accuracy of non-rejected predictions.
- What evidence would resolve it: Conducting a comprehensive sensitivity analysis of k, exploring a wide range of values and evaluating the resulting performance metrics (accuracy, reject rate, etc.) would provide insights into the optimal choice of k for different scenarios and the trade-off it offers.

## Limitations

- The method's effectiveness relies heavily on the assumption that neighboring instances in feature space share similar labels, which may not hold in all real-world scenarios
- Computational complexity of maintaining credal sets and performing Yager's combination across all neighbors could become prohibitive for large-scale applications
- The adaptive threshold mechanism's performance depends on the consistency between plausibility bounds and actual noise levels, which may vary across datasets and domains

## Confidence

- High confidence: The risk-consistency proof under Assumption 4.4, as it follows established statistical learning theory frameworks
- Medium confidence: The experimental performance claims, given the limited number of real-world datasets tested (8 datasets total)
- Medium confidence: The adaptive threshold mechanism's effectiveness, as the correlation between plausibility bounds and actual noise levels is not extensively validated

## Next Checks

1. **Cross-dataset validation**: Test the adaptive threshold mechanism on datasets with varying noise characteristics to verify its robustness across different noise distributions
2. **Scalability assessment**: Measure computational complexity and runtime performance on larger datasets (10K+ instances) to evaluate practical applicability
3. **Assumption sensitivity analysis**: Systematically vary the k-NN parameter and feature space distance metrics to quantify the impact of violating the neighborhood similarity assumption