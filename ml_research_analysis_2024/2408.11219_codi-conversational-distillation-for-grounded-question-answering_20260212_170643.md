---
ver: rpa2
title: 'CoDi: Conversational Distillation for Grounded Question Answering'
arxiv_id: '2408.11219'
source_url: https://arxiv.org/abs/2408.11219
tags:
- conversational
- codi
- data
- language
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of distilling conversational
  skills into small language models (SLMs) with approximately 1 billion parameters.
  The authors propose a novel data distillation framework called CoDi (Conversational
  Distillation) that synthesizes large-scale, assistant-style datasets in a steerable
  and diverse manner.
---

# CoDi: Conversational Distillation for Grounded Question Answering

## Quick Facts
- arXiv ID: 2408.11219
- Source URL: https://arxiv.org/abs/2408.11219
- Authors: Patrick Huber, Arash Einolghozati, Rylan Conway, Kanika Narang, Matt Smith, Waqar Nayyar, Adithya Sagar, Ahmed Aly, Akshat Shrivastava
- Reference count: 6
- Primary result: SLMs trained with CoDi-synthesized data achieve performance comparable to models trained on human-annotated data, closing the single-turn to multi-turn gap by 92% for CoQA and 75% for QuAC.

## Executive Summary
This paper addresses the challenge of distilling conversational skills into small language models (SLMs) with approximately 1 billion parameters. The authors propose a novel data distillation framework called CoDi (Conversational Distillation) that synthesizes large-scale, assistant-style datasets in a steerable and diverse manner. The core idea is to use a "turn-by-turn" generation paradigm to create true multi-turn conversations using black-box "teacher" LLMs. The framework employs conversational graphs, turn-based prompt augmentations, and explicit linguistic features to generate diverse and fluent conversations.

The primary result shows that SLMs trained with CoDi-synthesized data achieve performance comparable to models trained on human-annotated data in standard metrics. Specifically, for conversational grounded reasoning tasks, CoDi In-Domain models close the single-turn to multi-turn gap by 92% for CoQA and 75% for QuAC. Additionally, when using the framework to generate larger datasets from web data, the CoDi Web models surpass larger, instruction-tuned models in zero-shot conversational grounded reasoning tasks. For example, the 1.4B CoDi Web model outperforms 1.4B and 7B instruction-tuned models, while the 7B CoDi Web improves performance compared to 7B and 70B instruction-tuned models.

## Method Summary
CoDi (Conversational Distillation) is a novel data distillation framework that synthesizes large-scale, assistant-style datasets in a steerable and diverse manner. The framework uses a "turn-by-turn" generation paradigm to create true multi-turn conversations using black-box "teacher" LLMs. It employs conversational graphs, turn-based prompt augmentations, and explicit linguistic features to generate diverse and fluent conversations. The approach is task-agnostic at its core and focuses on conversational grounded reasoning for question answering.

## Key Results
- SLMs trained with CoDi-synthesized data achieve performance comparable to models trained on human-annotated data
- CoDi In-Domain models close the single-turn to multi-turn gap by 92% for CoQA and 75% for QuAC
- CoDi Web models (1.4B and 7B) outperform larger instruction-tuned models (1.4B, 7B, and 70B) in zero-shot conversational grounded reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CoDi uses conversational graphs to generate valid and diverse multi-turn conversations.
- Mechanism: A Markov Chain-inspired approach samples conversation links with transition probabilities to create coherent conversational blueprints.
- Core assumption: Transition probabilities between conversation links can capture natural conversation flow.
- Evidence anchors:
  - [abstract] "We propose a novel data distillation framework named CoDi... allowing us to synthesize large-scale, assistant-style datasets in a steerable and diverse manner."
  - [section 2.1.1] "To generate a question-answering conversation using G, we sample from the set of valid edges... and instantiate the sampled target link"
  - [corpus] Found 25 related papers, average neighbor FMR=0.477, suggesting moderate relatedness in the literature space

### Mechanism 2
- Claim: Per-turn prompt augmentations and explicit linguistic features create fluent and engaging conversations.
- Mechanism: Each conversational link contains prompts with Chain-of-Thought reasoning and linguistic phenomena like coreference to tie turns together.
- Core assumption: Explicit linguistic features can effectively simulate natural conversation patterns.
- Evidence anchors:
  - [abstract] "Specifically, while our framework is task agnostic at its core, we explore and evaluate the potential of CoDi on the task of conversational grounded reasoning for question answering."
  - [section 2.1.3] "Inspired by everyday conversations between humans, we use explicit linguistic phenomena to naturally tie turns together."
  - [corpus] The average neighbor FMR of 0.477 suggests moderate relatedness to conversational AI topics

### Mechanism 3
- Claim: Knowledge distillation from larger LLMs to smaller SLMs enables conversational abilities without requiring the SLM to memorize world knowledge.
- Mechanism: Large-scale synthesized conversations train SLMs to handle conversational grounded reasoning tasks.
- Core assumption: The knowledge from larger LLMs can be effectively transferred to smaller models through synthesized data.
- Evidence anchors:
  - [abstract] "Our evaluations show that SLMs trained with CoDi-synthesized data achieve performance comparable to models trained on human-annotated data"
  - [section 2] "We propose a new distillation methodology to enrich small language models with conversational grounded reasoning abilities"
  - [corpus] The corpus includes related work on knowledge distillation and small language models, indicating relevance to the approach

## Foundational Learning

- Concept: Markov Chains
  - Why needed here: Used to model conversational flow through transition probabilities between conversation links
  - Quick check question: How do Markov Chains help in generating diverse yet coherent conversation sequences?

- Concept: Chain-of-Thought reasoning
  - Why needed here: Prompting paradigm used to elicit step-by-step reasoning in generated conversations
  - Quick check question: What role does Chain-of-Thought prompting play in the conversational link generation?

- Concept: Knowledge Distillation
  - Why needed here: The core methodology for transferring conversational abilities from larger LLMs to smaller SLMs
  - Quick check question: How does knowledge distillation differ when applied to conversational data versus single-turn instructions?

## Architecture Onboarding

- Component map:
  - Conversational Graph Generator (defines conversation structure and transitions)
  - Link Executor (generates individual conversational turns with prompts and seed data)
  - Linguistic Phenomena Module (adds explicit features like coreference)
  - Data Synthesis Pipeline (orchestrates the turn-by-turn generation process)
  - Distillation Trainer (trains the SLM on synthesized data)

- Critical path: Conversational Graph → Link Execution → Linguistic Augmentation → Data Synthesis → SLM Training

- Design tradeoffs:
  - Graph complexity vs. generation efficiency
  - Prompt specificity vs. diversity
  - Dataset scale vs. quality control
  - Model size vs. conversational ability retention

- Failure signatures:
  - Incoherent conversation sequences (graph generation issue)
  - Repetitive or unnatural turns (linguistic features not working)
  - Poor performance on evaluation tasks (distillation ineffective)
  - Excessive generation time (inefficient synthesis pipeline)

- First 3 experiments:
  1. Generate a small conversational graph (5-10 links) and manually inspect the sampled conversations for coherence
  2. Test linguistic phenomena on single-turn generation to verify they produce natural-sounding follow-ups
  3. Compare SLM performance on a simple QA task using 100 synthesized conversations vs. no synthetic data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of the synthesized conversational data scale with the size of the teacher LLM model?
- Basis in paper: [explicit] The paper mentions using both Llama2 (70B) and Llama3 (70B) as teacher models, noting that Llama3 improves performance by 2%+ absolute.
- Why unresolved: The paper only compares two specific teacher models (Llama2 and Llama3 at 70B parameters). It does not explore the relationship between teacher model size and data quality across a broader range of model sizes.
- What evidence would resolve it: Systematic experiments comparing synthesized data quality using teacher models of varying sizes (e.g., 7B, 30B, 70B) would reveal whether larger models consistently produce higher quality conversational data.

### Open Question 2
- Question: What is the optimal balance between conversational graph size and generation quality?
- Basis in paper: [explicit] The paper introduces conversational graphs with vertices (conversation links) and edges (transition probabilities) to generate diverse conversations.
- Why unresolved: While the paper presents the conversational graph concept, it doesn't provide detailed analysis on how graph size (number of vertices and edges) affects the quality and diversity of generated conversations.
- What evidence would resolve it: Experiments varying the number of vertices and edges in the conversational graph, followed by quality assessments of the generated conversations, would identify the optimal graph structure.

### Open Question 3
- Question: How do different linguistic phenomena affect the coherence and fluency of synthesized conversations?
- Basis in paper: [explicit] The paper introduces explicit linguistic phenomena (e.g., coreference) to tie turns together in conversations.
- Why unresolved: The paper mentions using linguistic phenomena but doesn't provide a comprehensive analysis of how different phenomena impact conversation quality or which combinations work best.
- What evidence would resolve it: Comparative studies using different sets of linguistic phenomena and their combinations, evaluated on coherence and fluency metrics, would reveal their relative effectiveness.

### Open Question 4
- Question: Can the CoDi framework be effectively applied to tasks beyond grounded reasoning and summarization?
- Basis in paper: [explicit] The paper states that the CoDi framework is task agnostic but focuses on grounded reasoning and summarization for evaluation.
- Why unresolved: While the paper demonstrates effectiveness for specific tasks, it doesn't explore the framework's applicability to a broader range of NLP tasks.
- What evidence would resolve it: Applying the CoDi framework to various NLP tasks (e.g., code generation, translation, dialogue systems) and evaluating performance would establish its versatility.

## Limitations

- The methodology relies heavily on black-box teacher LLMs, introducing dependency on external model behavior that may evolve or become unavailable.
- The conversational graph generation approach may not fully capture the complexity of human conversation dynamics, particularly in handling unexpected conversational turns or maintaining long-term coherence across extended dialogues.
- The evaluation focuses primarily on standard metrics (recall and F1 scores) without deeper qualitative analysis of conversation quality or user experience measures.

## Confidence

- **High Confidence**: Claims about the CoDi framework architecture and its basic data synthesis capabilities. The methodology is clearly described and the implementation details are sufficient for reproduction.
- **Medium Confidence**: Claims regarding performance improvements over baseline models. While the quantitative results are presented, the comparison against specific baseline models and the exact implementation details of these baselines are not fully specified in the available information.
- **Low Confidence**: Claims about the framework's ability to handle diverse conversational scenarios beyond the tested question-answering tasks. The evaluation scope appears limited to specific datasets and may not generalize to all conversational contexts.

## Next Checks

1. **Qualitative Conversation Analysis**: Conduct human evaluations of generated conversations to assess naturalness, coherence, and engagement beyond automated metrics. This would validate whether the linguistic phenomena and conversational graph generation truly produce human-like dialogue.

2. **Cross-Domain Generalization Test**: Apply the CoDi framework to a different conversational task (e.g., task-oriented dialogue or creative writing assistance) to evaluate whether the distillation approach generalizes beyond question answering. This would test the framework's true versatility.

3. **Teacher Model Dependency Assessment**: Test the framework with different teacher LLM sizes (e.g., 13B and 34B models) to determine how sensitive the distillation process is to teacher model capabilities and whether the 70B choice is optimal or merely sufficient.