---
ver: rpa2
title: Declarative Design of Neural Predicates in Neuro-Symbolic Systems
arxiv_id: '2405.09521'
source_url: https://arxiv.org/abs/2405.09521
tags:
- image
- digit
- prototype
- neural
- predicates
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for making neural predicates
  in neuro-symbolic systems declarative. The key innovation is structuring neural
  predicates around prototypes, which allows them to learn domains and answer arbitrary
  queries rather than just those they were trained on.
---

# Declarative Design of Neural Predicates in Neuro-Symbolic Systems

## Quick Facts
- arXiv ID: 2405.09521
- Source URL: https://arxiv.org/abs/2405.09521
- Authors: Tilman Hinnerichs; Robin Manhaeve; Giuseppe Marra; Sebastijan Dumancic
- Reference count: 40
- Primary result: Prototype-based neural predicates enable unification over infinite domains while preserving learning and reasoning capabilities

## Executive Summary
This paper introduces a framework for making neural predicates in neuro-symbolic systems declarative by structuring them around prototypes. The key innovation allows neural predicates to learn domains from data and answer arbitrary queries rather than just those they were trained on. By using prototype networks where each prototype captures a concept's distribution in latent space, the framework overcomes unification challenges in infinite domains like images. Experiments demonstrate that prototype-based neural predicates achieve comparable performance to standard neural predicates while gaining the ability to answer unseen queries, such as generating images for digits they weren't explicitly trained to generate.

## Method Summary
The framework extends DeepProblog with declarative neural predicates structured around prototypes. Each prototype captures the distribution of valid instances in latent space through a variational autoencoder architecture. The approach uses a fixed number of prototypes for each concept, with instances assigned to exactly one prototype through annotated disjunctions. The framework implements relational operations through encoding, distance computation, and sampling, allowing it to answer canonical queries (classification, generation, etc.) by combining prototype-based operations. The declarative predicates reuse DeepProblog's inference procedures by reformulating the problem as prototype membership probabilities.

## Key Results
- Prototype-based neural predicates achieve comparable performance to standard neural predicates on MNIST addition tasks
- The framework successfully answers unseen queries, generating images for digits it wasn't explicitly trained to generate
- Declarative neural predicates preserve both learning and reasoning capabilities while enabling arbitrary query answering

## Why This Works (Mechanism)

### Mechanism 1
Prototype-based neural predicates enable unification over infinite domains by learning domains from data. Prototypes capture the distribution of valid instances in latent space, allowing sampling from prototypes to unify variables. Core assumption: Each non-symbolic argument is modeled by exactly one neural predicate, and prototypes are mutually exclusive. Evidence anchors: [abstract] "The framework uses a prototype network approach where each prototype captures a concept's distribution in latent space." [section] "We overcome this problem by structuring predicates around prototypes, which learn the domains of non-symbolic arguments from data." Break condition: If the number of prototypes is insufficient to capture the domain's diversity, or if instances don't belong to a single prototype exclusively.

### Mechanism 2
Declarative neural predicates preserve learning and reasoning capabilities while enabling arbitrary query answering. By structuring predicates around prototypes and implementing relational operations, the framework answers canonical queries through encoding, distance computation, and sampling. Core assumption: The framework's canonical queries (classification, generation, etc.) can be reduced to combinations of prototype-based operations. Evidence anchors: [abstract] "Experiments show that prototype-based neural predicates achieve comparable performance to standard neural predicates while gaining the ability to answer unseen queries." [section] "We design the declarative neural predicates in such a way that our proposed framework does not require new special machinery, but it reuses the inference procedures of DeepProblog." Break condition: If the encoding/decoding process is too lossy, or if the distance computation in latent space doesn't accurately reflect semantic similarity.

### Mechanism 3
The framework avoids changes to DeepProblog's internal mechanisms while changing the semantics of programs. The declarative neural predicates reuse DeepProblog's inference procedures by reformulating the problem as prototype membership probabilities. Core assumption: DeepProblog's inference engine can handle the new semantics of prototype-based neural predicates without modification. Evidence anchors: [section] "We design the declarative neural predicates in such a way that our proposed framework does not require new special machinery, but it reuses the inference procedures of DeepProblog." Break condition: If DeepProblog's inference procedures make assumptions about neural predicate semantics that conflict with the prototype-based formulation.

## Foundational Learning

- Concept: Prototype Networks
  - Why needed here: Prototype networks learn a latent space representation where each concept is explicitly represented by a prototype, enabling domain learning for non-symbolic arguments.
  - Quick check question: How do prototype networks differ from traditional neural networks in terms of concept representation?

- Concept: Variational Autoencoders (VAEs)
  - Why needed here: VAEs provide the encoding-decoding mechanism that relates instances to prototypes in latent space, with the reconstruction loss ensuring meaningful prototypes.
  - Quick check question: What role does the KL divergence play in VAE training, and how does it relate to prototype learning?

- Concept: Annotated Disjunctions
  - Why needed here: Annotated disjunctions model the probabilistic membership of instances to prototypes, ensuring that each instance belongs to exactly one prototype.
  - Quick check question: How does the use of annotated disjunctions in prototype membership differ from standard classification tasks?

## Architecture Onboarding

- Component map: Instance → Encoder → Latent Space → Prototype Distance → Probability → Reasoning
- Critical path: Instance → Encoder → Latent Space → Prototype Distance → Probability → Reasoning
- Design tradeoffs:
  - Fixed vs. learned number of prototypes: Fixed number simplifies implementation but may limit expressiveness
  - Mutual exclusivity vs. overlapping prototypes: Mutual exclusivity ensures clean unification but may not capture all data distributions
  - Distance metric choice: Likelihood-based vs. MSE affects prototype quality and reconstruction fidelity
- Failure signatures:
  - Poor classification accuracy indicates inadequate prototype learning
  - Generated images that don't match training data suggests decoder issues
  - Inability to answer arbitrary queries points to problems with the encoding-decoding relation
- First 3 experiments:
  1. Train on direct supervision (digit/2) and evaluate classification accuracy to verify prototype learning
  2. Test unseen queries (digit(?,?), digit(?,?)) to assess declarative capabilities
  3. Compare performance with standard DeepProblog on addition tasks to validate preservation of reasoning capabilities

## Open Questions the Paper Calls Out

### Open Question 1
Can the number of prototypes be automatically determined rather than being fixed by the user? Basis in paper: [explicit] The paper assumes a fixed number of prototypes and leaves automatic determination for future work. Why unresolved: The paper explicitly states this as an open problem for future research. What evidence would resolve it: A method that can automatically determine the optimal number of prototypes through learning or other means.

### Open Question 2
How can distant supervision be made more effective for learning prototypes when the supervision signal is less clear? Basis in paper: [inferred] The paper notes that distant supervision provides a less clear signal because it doesn't give unique assignments between images and prototypes. Why unresolved: The paper identifies this as a challenge but doesn't provide a solution. What evidence would resolve it: A method that improves prototype learning from distant supervision, potentially by creating unique assignments or alternative training strategies.

### Open Question 3
How can the scalability of the framework be improved given that each training iteration takes twice as much time? Basis in paper: [explicit] The paper mentions that incorporating exclusive membership to prototypes ensures fast convergence but doubles training time. Why unresolved: The paper identifies the time complexity issue but doesn't provide optimization strategies. What evidence would resolve it: An optimization technique or architectural change that maintains convergence speed while reducing computational overhead.

### Open Question 4
Can more powerful generative models or longer training improve the quality of generated images? Basis in paper: [inferred] The paper notes that most errors in image generation come from generating images that look more similar to another digit, suggesting the generative model could be improved. Why unresolved: The paper suggests this as a potential improvement but doesn't implement it. What evidence would resolve it: Experimental results showing improved image quality using more powerful generative models or extended training time.

## Limitations

- Evaluation scope remains limited to MNIST-based arithmetic tasks, making it unclear how the approach scales to more complex domains
- The mutual exclusivity assumption for prototypes may not hold in practice, potentially limiting applicability to domains with overlapping concepts
- The paper does not address computational efficiency concerns, particularly the overhead of sampling from prototypes during inference

## Confidence

- **High Confidence**: The core claim that prototype-based neural predicates can learn domains from data and enable unification over infinite domains is well-supported by the MNIST experiments and theoretical framework.
- **Medium Confidence**: The assertion that declarative neural predicates preserve learning and reasoning capabilities while enabling arbitrary query answering is partially supported, but experiments are limited to simple arithmetic tasks.
- **Low Confidence**: The claim that the framework avoids changes to DeepProblog's internal mechanisms while changing the semantics of programs is based on design intentions rather than empirical validation.

## Next Checks

1. **Scalability Test**: Evaluate the prototype-based approach on a more complex dataset (e.g., CIFAR-10 or ImageNet subsets) to assess its performance on higher-dimensional data and more diverse concepts.

2. **Mutual Exclusivity Validation**: Design experiments to measure the degree of prototype overlap in learned representations and test the framework's performance when relaxing the mutual exclusivity assumption.

3. **Efficiency Benchmark**: Conduct runtime comparisons between prototype-based neural predicates and standard neural predicates in DeepProblog across various query types to quantify the computational overhead of sampling-based inference.