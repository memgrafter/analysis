---
ver: rpa2
title: 'RoCode: A Dataset for Measuring Code Intelligence from Problem Definitions
  in Romanian'
arxiv_id: '2402.13222'
source_url: https://arxiv.org/abs/2402.13222
tags:
- code
- romanian
- language
- problem
- solutions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RoCode, the first dataset for evaluating
  code intelligence from problem definitions written in Romanian. The dataset consists
  of 2,642 competitive programming problems in Romanian, 11,250 solutions in C/C++
  and Python, and comprehensive test suites.
---

# RoCode: A Dataset for Measuring Code Intelligence from Problem Definitions in Romanian

## Quick Facts
- arXiv ID: 2402.13222
- Source URL: https://arxiv.org/abs/2402.13222
- Authors: Adrian Cosma; Bogdan Iordache; Paolo Rosso
- Reference count: 0
- Primary result: None of the tested models achieved reasonable performance on Romanian code generation from problem definitions

## Executive Summary
This paper introduces RoCode, the first dataset for evaluating code intelligence from problem definitions written in Romanian. The dataset consists of 2,642 competitive programming problems in Romanian, 11,250 solutions in C/C++ and Python, and comprehensive test suites. Through experiments with existing Romanian and English-oriented language models, the authors demonstrate that current models struggle significantly with generating code from Romanian problem descriptions, highlighting the need for specialized code models for languages other than English.

## Method Summary
The authors created RoCode by collecting competitive programming problems and solutions from Romanian online judges, including problem statements in Romanian, solutions in C/C++ and Python, and test cases. They evaluated existing language models (RoGPT-2, GPT-Neo-Ro, LLaMA-7b, etc.) using zero-shot prompting where models receive Romanian problem descriptions and must generate Python solutions. Performance was measured using accuracy, strict accuracy, and pass@k metrics after compiling and testing generated code against the provided test suites.

## Key Results
- Existing Romanian models (RoGPT-2, GPT-Neo-Ro) achieved near-zero performance on RoCode
- English-oriented models also performed poorly, with best results around 1-3% accuracy
- Code-code-switching (Romanian identifiers with English keywords) presents a unique challenge for existing models
- Translating Romanian problem definitions to English actually worsened performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Code-code-switching in Romanian solutions creates a unique syntactic challenge that existing multilingual models are not optimized for
- Mechanism: The dataset contains solutions where Romanian variable/function names coexist with English language keywords, forcing models to handle mixed-language contexts during code generation
- Core assumption: Models pretrained primarily on English code with English identifiers cannot effectively process Romanian identifiers in code
- Evidence anchors:
  - [abstract] "RoCode contains code that exhibits code-code-switching: some function and variable names are written in Romanian, while others (e.g. language-specific keywords) are written in English"
  - [section] "Examples of composite function names are: 'acopera_tot()' (cover_everything()), 'descompunereNumar()' (decomposeNumber())"
  - [corpus] Weak - no direct corpus evidence of code-code-switching patterns in other datasets
- Break condition: If models are explicitly trained on mixed-language code examples, they may adapt to this pattern

### Mechanism 2
- Claim: Existing Romanian language models lack code-specific pretraining data, making them unable to generate executable code
- Mechanism: Romanian models like RoGPT-2 and GPT-Neo-Ro were trained on general Romanian text corpora without code, so they lack the structural understanding needed for programming
- Core assumption: Code generation requires exposure to code syntax and patterns during pretraining
- Evidence anchors:
  - [abstract] "None of the currently available Romanian language models are able to understand the problem definition or to produce code"
  - [section] "There is no code data present in the pre-training dataset. Romanian models have been trained on datasets derived from OSCAR corpus, Wikipedia and books, and do not have dedicated code splits"
  - [corpus] Weak - corpus shows related work on Romanian LLMs but doesn't provide evidence of code exposure
- Break condition: If Romanian models are pretrained on Romanian code datasets, they may develop code generation capabilities

### Mechanism 3
- Claim: English-oriented models perform poorly because Romanian problem statements create a translation barrier even for multilingual models
- Mechanism: Models struggle to translate Romanian problem descriptions into executable Python code, resulting in poor performance despite some Romanian exposure in pretraining
- Core assumption: Translation from Romanian natural language to English-based code requires specialized cross-lingual understanding
- Evidence anchors:
  - [abstract] "Surprisingly, none of the tested models are able to obtain a reasonable performance, proving that RoCode is a challenging dataset"
  - [section] "Translating the problem definitions in English worsened results. Evaluating a replit-v1-3b on translated problem definitions resulted in 1.26% accuracy, down from 1.81% using original Romanian descriptions"
  - [corpus] Weak - corpus shows related work on Romanian LLMs but no evidence of translation performance
- Break condition: If models are trained on parallel Romanian-English code datasets, translation performance may improve

## Foundational Learning

- Concept: Code-code-switching and mixed-language programming
  - Why needed here: RoCode contains solutions with Romanian identifiers and English keywords, requiring understanding of how programmers mix languages in code
  - Quick check question: How do Romanian programmers typically name variables and functions in their code when working in English-based programming languages?

- Concept: Zero-shot learning and prompt engineering for code generation
  - Why needed here: The evaluation uses zero-shot settings where models must generate code from Romanian problem descriptions without fine-tuning or examples
  - Quick check question: What are the key differences between zero-shot and few-shot prompting approaches for code generation tasks?

- Concept: Cross-lingual transfer learning limitations
  - Why needed here: Understanding why multilingual models struggle with Romanian despite some exposure to the language during pretraining
  - Quick check question: What factors determine whether a multilingual model can effectively transfer knowledge from English to Romanian code generation?

## Architecture Onboarding

- Component map: Problem statements (Romanian text) -> Model generation -> Code compilation -> Test execution -> Accuracy calculation -> Performance aggregation
- Critical path: Problem statement → Model generation → Code compilation → Test execution → Accuracy calculation → Performance aggregation
- Design tradeoffs: Zero-shot evaluation vs. fine-tuning trade-off (zero-shot is more challenging but more realistic for real-world deployment), small model evaluation vs. large model resource constraints, Romanian-only vs. multilingual focus
- Failure signatures: Compilation errors indicate syntax issues, runtime errors suggest logic problems, low accuracy indicates misunderstanding of problem requirements, code-code-switching mismatches show identifier handling issues
- First 3 experiments:
  1. Run a small Romanian model on RoCode with temperature 0 to check if it can generate any syntactically valid code
  2. Test an English code model on RoCode with Romanian problem statements to measure baseline cross-lingual performance
  3. Evaluate a multilingual model with Romanian fine-tuning on RoCode to assess the impact of language-specific adaptation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does code-code-switching in Romanian programming affect the performance of large language models on code generation tasks?
- Basis in paper: [explicit] The paper mentions that code-code-switching is prevalent in Romanian solutions and that this phenomenon adds complexity for adapting pretrained models to RoCode solutions.
- Why unresolved: The paper provides initial observations about the prevalence of code-code-switching but does not conduct a detailed analysis of its impact on model performance.
- What evidence would resolve it: A controlled study comparing model performance on Romanian code with and without code-code-switching, or a quantitative analysis of how different proportions of code-code-switching affect model accuracy.

### Open Question 2
- Question: What is the impact of translation quality on the performance of language models when translating Romanian problem descriptions to English for code generation tasks?
- Basis in paper: [explicit] The paper notes that translating problem definitions into English worsened results due to imprecise translation and loss of exact formulations.
- Why unresolved: While the paper mentions this issue, it does not explore the extent to which translation quality affects model performance or potential methods to mitigate this impact.
- What evidence would resolve it: A comprehensive evaluation of model performance using problem descriptions with varying levels of translation quality, and an exploration of techniques to improve translation accuracy for code generation tasks.

### Open Question 3
- Question: How can specialized datasets for Romanian and other low-resource languages be developed to improve code generation models?
- Basis in paper: [explicit] The paper argues for the need to develop code models for languages other than English and suggests that current Romanian models are small and trained on noisy datasets with little code data.
- Why unresolved: The paper identifies the lack of specialized datasets as a challenge but does not provide a detailed roadmap or methodology for creating such datasets.
- What evidence would resolve it: A detailed proposal for constructing a high-quality, curated dataset for Romanian code, including data sources, annotation processes, and evaluation metrics to ensure dataset quality and relevance.

## Limitations
- The evaluation relies on zero-shot prompting without exploring few-shot learning approaches that might improve performance
- Translation of Romanian problem descriptions to English actually worsened results, suggesting the dataset may be evaluating translation quality rather than code generation ability
- The dataset focuses exclusively on competitive programming problems, which may not represent the full spectrum of programming tasks

## Confidence

- **High Confidence**: The dataset construction methodology and the existence of code-code-switching patterns in Romanian solutions are well-established. The basic observation that existing Romanian models perform poorly on code generation tasks is reliable.
- **Medium Confidence**: The claim that this is the first Romanian code dataset is reasonable but requires verification of exhaustive literature search. The assertion that English-oriented models fail specifically due to Romanian language barriers is plausible but not definitively proven.
- **Low Confidence**: The paper's claim that RoCode is inherently "challenging" rather than that current evaluation methods are suboptimal. The direct causation between code-code-switching and model failure is not rigorously established.

## Next Checks

1. **Prompt Engineering Ablation**: Systematically vary the prompt structure (few-shot examples, instruction format, temperature settings) for a subset of RoCode problems to determine whether performance improves beyond the reported 1-3% accuracy range.

2. **Cross-Lingual Transfer Analysis**: Evaluate the same models on parallel English-Romanian problem pairs to quantify the exact translation penalty and determine whether Romanian-specific adaptation is necessary versus general multilingual capability.

3. **Code-Code-Switching Impact Study**: Create a controlled subset of RoCode problems with solutions that either preserve or normalize Romanian identifiers to English, then measure the performance differential to isolate the impact of code-code-switching on model comprehension.