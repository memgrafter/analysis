---
ver: rpa2
title: 'Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings
  for Semi-Supervised Classification'
arxiv_id: '2404.17173'
source_url: https://arxiv.org/abs/2404.17173
tags:
- embeddings
- learning
- labeling
- data
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Hierarchical Dynamic Labeling (HDL), a semi-supervised
  learning approach that generates pseudo-labels using image embeddings rather than
  model predictions. Unlike existing methods that rely on confidence-based pseudo-labeling,
  HDL leverages the observation that representation networks are more reliable than
  classifiers, especially in noisy or biased data scenarios.
---

# Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings for Semi-Supervised Classification

## Quick Facts
- arXiv ID: 2404.17173
- Source URL: https://arxiv.org/abs/2404.17173
- Reference count: 12
- Primary result: HDL improves semi-supervised classification by using image embeddings for pseudo-labeling, outperforming strong baselines like MixMatch and ReMixMatch on CIFAR datasets.

## Executive Summary
This paper introduces Hierarchical Dynamic Labeling (HDL), a semi-supervised learning approach that generates pseudo-labels using image embeddings rather than model predictions. Unlike existing methods that rely on confidence-based pseudo-labeling, HDL leverages the observation that representation networks are more reliable than classifiers, especially in noisy or biased data scenarios. The method operates by dynamically updating a labeled dataset with embeddings voted on by their k nearest neighbors, progressively improving label quality. An adaptive k-selection mechanism is also proposed to enhance robustness. HDL is evaluated across multiple class-balanced and long-tailed datasets (e.g., CIFAR-10, CIFAR-100, CIFAR-10-LT) and significantly outperforms strong semi-supervised baselines such as MixMatch, ReMixMatch, FixMatch, and FreeMatch. For example, on CIFAR-10 with 250 labels, HDL improves MixMatch by 1.35% and ReMixMatch by 1.12%. It also excels in class-imbalanced settings, with improvements of up to 1.7% on CIFAR-10-LT (IF=50). The results validate that using embeddings for pseudo-labeling can lead to more accurate and generalizable semi-supervised learning models.

## Method Summary
Hierarchical Dynamic Labeling (HDL) is a semi-supervised learning approach that generates pseudo-labels using image embeddings rather than model predictions. The method leverages the observation that representation networks are more reliable than classifiers, especially in noisy or biased data scenarios. HDL operates by dynamically updating a labeled dataset with embeddings voted on by their k nearest neighbors, progressively improving label quality. An adaptive k-selection mechanism is proposed to enhance robustness. The approach is evaluated on multiple class-balanced and long-tailed datasets, demonstrating significant improvements over strong semi-supervised baselines.

## Key Results
- HDL improves MixMatch by 1.35% and ReMixMatch by 1.12% on CIFAR-10 with 250 labels
- HDL achieves up to 1.7% improvement on CIFAR-10-LT (IF=50) in class-imbalanced settings
- HDL outperforms strong semi-supervised baselines including FixMatch and FreeMatch across multiple datasets

## Why This Works (Mechanism)
HDL works by leveraging the reliability of representation networks over classifiers for pseudo-label generation. Traditional semi-supervised methods rely on model predictions (logits) to generate pseudo-labels, but these can be noisy and biased, especially with limited labeled data. HDL instead uses image embeddings from a representation network, which capture more stable and generalizable features. By voting among k nearest neighbors in the embedding space, HDL creates more accurate pseudo-labels that progressively improve the labeled dataset. The adaptive k-selection mechanism further enhances robustness by dynamically adjusting the neighborhood size based on data characteristics.

## Foundational Learning
- **Semi-supervised learning**: Learning from both labeled and unlabeled data to improve model performance when labeled data is scarce
- **Pseudo-labeling**: Generating synthetic labels for unlabeled data to augment training
- **Embeddings**: Lower-dimensional representations of data that capture semantic features
- **k-nearest neighbors (k-NN)**: A non-parametric method for classification based on similarity in feature space
- **Class imbalance**: Situations where some classes have significantly fewer examples than others
- **Representation learning**: Learning compact, informative feature representations from raw data

## Architecture Onboarding
**Component Map**: Input images → Feature extractor → Embedding space → k-NN voting → Pseudo-label generation → Model training

**Critical Path**: The key process involves extracting embeddings from unlabeled images, finding their k nearest neighbors in the embedding space, voting to determine pseudo-labels, and using these to augment the labeled dataset for model training.

**Design Tradeoffs**: HDL trades computational overhead (nearest neighbor search) for improved pseudo-label quality. The adaptive k-selection adds complexity but improves robustness to varying data distributions.

**Failure Signatures**: Poor performance may occur if the feature extractor produces low-quality embeddings, if k is poorly chosen (too small or too large), or if the data distribution changes significantly during training.

**First Experiments**:
1. Validate that embeddings are more reliable than logits for pseudo-labeling by comparing accuracy on a validation set
2. Test different k values to find optimal neighborhood size for voting
3. Compare HDL with baseline methods on a small subset of CIFAR-10 before scaling to full experiments

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation scope primarily to image classification benchmarks (CIFAR variants)
- No extensive validation of pseudo-label quality evolution during training
- Computational overhead from nearest neighbor voting may limit scalability

## Confidence
**High Confidence**: Empirical results showing HDL outperforming established baselines (MixMatch, ReMixMatch, FixMatch, FreeMatch) on CIFAR datasets are well-documented and statistically significant.

**Medium Confidence**: The assertion that HDL is particularly effective for long-tailed distributions is supported by CIFAR-10-LT results, but could benefit from testing on more diverse imbalanced datasets.

**Low Confidence**: Broader claims about HDL being a "fundamental improvement" to semi-supervised learning are not fully substantiated.

## Next Checks
1. Test HDL on non-image datasets (e.g., text classification, tabular data) to assess generalizability
2. Conduct detailed analysis of pseudo-label accuracy evolution during training, comparing embedding-based vs. logit-based approaches
3. Evaluate HDL's performance and computational efficiency on larger-scale datasets (e.g., ImageNet, COCO) and high-resolution images