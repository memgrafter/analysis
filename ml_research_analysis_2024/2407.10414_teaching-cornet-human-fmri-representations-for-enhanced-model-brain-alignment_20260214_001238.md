---
ver: rpa2
title: Teaching CORnet Human fMRI Representations for Enhanced Model-Brain Alignment
arxiv_id: '2407.10414'
source_url: https://arxiv.org/abs/2407.10414
tags:
- human
- fmri
- similarity
- cornet
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposed ReAlnet-fMRI, a model based on the state-of-the-art
  vision model CORnet but optimized using human fMRI data through a multi-layer encoding-based
  alignment framework. The fMRI-optimized ReAlnet-fMRI exhibited higher similarity
  to the human brain than both CORnet and the control model in within-and across-subject
  as well as within- and across-modality model-brain (fMRI and EEG) alignment evaluations.
---

# Teaching CORnet Human fMRI Representations for Enhanced Model-Brain Alignment

## Quick Facts
- arXiv ID: 2407.10414
- Source URL: https://arxiv.org/abs/2407.10414
- Reference count: 21
- Key outcome: ReAlnet-fMRI achieved up to 43% improvement in model-brain alignment over CORnet by optimizing CORnet using human fMRI data

## Executive Summary
This study introduces ReAlnet-fMRI, a vision model based on CORnet that is optimized using human fMRI data through a multi-layer encoding-based alignment framework. The model demonstrates significantly higher similarity to human brain representations than both CORnet and a control model across within- and across-subject fMRI comparisons, as well as within- and across-modality EEG alignments. Internal representational analysis reveals that ReAlnet-fMRI encodes stronger food-related, artificial/hard, and electronics/technology information compared to CORnet, demonstrating the effectiveness of integrating human neural data to enhance brain-likeness in visual models.

## Method Summary
ReAlnet-fMRI extends CORnet-S with an fMRI generation module that concatenates outputs from all visual layers (V1, V2, V4, IT) and maps them to fMRI space via a multi-layer encoder. The model is trained using a combined loss function (classification loss + generation loss weighted by parameter β) on human fMRI datasets, with the generation loss including both MSE and contrastive components. The framework enables distributed feature extraction without requiring direct correspondences between model layers and brain processing stages. Training uses the Adam optimizer with batch size 16 and learning rate 0.00002 over 5 epochs, with β values tested from 10 to 50.

## Key Results
- Average improvement ratio in model-fMRI similarity exceeded 10%, with maximum improvement reaching 43%
- ReAlnet-fMRI showed higher similarity to human brain than both CORnet and control model in within- and across-subject fMRI alignment
- ReAlnet-fMRI demonstrated improved alignment in both within- and across-modality EEG comparisons
- Internal analysis revealed stronger encoding of food-related, artificial/hard, and electronics/technology information compared to CORnet

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ReAlnet-fMRI learns brain-like representations by directly encoding human fMRI signals into multiple visual layers
- Mechanism: The model extends CORnet with an fMRI generation module that concatenates outputs from all visual layers and maps them to fMRI space via a multi-layer encoder, forcing visual layers to extract features that predict human neural responses
- Core assumption: There exists a shared representational subspace between CORnet's visual features and human fMRI patterns
- Evidence anchors: Abstract states ReAlnet-fMRI is "optimized using human fMRI data through a multi-layer encoding-based alignment framework" and section describes adding "an additional multi-layer encoder to an ImageNet pre-trained CORnet-S... to generate the predicted fMRI signals"

### Mechanism 2
- Claim: Multi-layer encoding alignment improves alignment more than single-layer methods because visual processing is distributed across brain regions
- Mechanism: The framework concatenates all layer representations and learns a joint mapping to fMRI space, allowing distributed feature extraction rather than forcing one-to-one correspondence
- Core assumption: Human visual cortex encodes object information hierarchically and redundantly
- Evidence anchors: Section states the framework "does not require specifying direct correspondences between different model layers and brain processing stages"

### Mechanism 3
- Claim: The contrastive loss component in the fMRI generation objective improves the specificity of learned representations
- Mechanism: Contrastive loss maximizes similarity between predicted and real fMRI for the same image while pushing apart predictions for different images
- Core assumption: fMRI patterns are image-specific and can be used as contrastive signals
- Evidence anchors: Section describes "LG represents the generation loss including a mean squared error (MSE) loss and a contrastive loss between the generated and real fMRI signals"

## Foundational Learning

- Concept: Representational Similarity Analysis (RSA)
  - Why needed here: RSA is the core method for quantifying model-brain alignment by comparing dissimilarity matrices between model layers and brain regions
  - Quick check question: What distance metric is used to build the model RDM before Spearman correlation?

- Concept: fMRI preprocessing and ROI selection
  - Why needed here: The study extracts voxels from entire visual cortex and reduces them via PCA; understanding this is key to interpreting the model's fMRI alignment
  - Quick check question: How many principal components are retained for the fMRI feature space?

- Concept: Contrastive learning in neural encoding
  - Why needed here: The fMRI generation loss uses contrastive terms to align predicted and real fMRI; knowing how this works helps debug alignment quality
  - Quick check question: What is the role of the negative pairs in the contrastive fMRI loss?

## Architecture Onboarding

- Component map: Image → CORnet-S (V1→V2→V4→IT + category decoder) → Layer-encoders (Enc-V1, Enc-V2, Enc-V4, Enc-IT) → Multi-layer visual encoder (concatenated → 512D) → fMRI encoder (512D → 1024D fMRI prediction) → fMRI prediction + class logits

- Critical path:
  1. Forward pass: image → CORnet layers → layer encoders → concatenated vector → fMRI encoder → fMRI prediction + class logits
  2. Backward pass: compute LA = LC + β·LG → update CORnet + encoder weights

- Design tradeoffs:
  - Adding fMRI generation increases parameter count and training complexity but enables brain alignment
  - Multi-layer concatenation allows distributed alignment but may dilute fine-grained layer-specific features
  - Static β weighting is simple but may not adapt to changing alignment needs across epochs

- Failure signatures:
  - Model-fMRI similarity lower than CORnet baseline indicates misalignment in the fMRI encoder
  - Degraded ImageNet classification with no fMRI gain suggests the alignment objective dominates too much
  - EEG alignment fails while fMRI alignment succeeds implies modality-specific overfitting

- First 3 experiments:
  1. Train ReAlnet-fMRI with β=0 (pure CORnet baseline) and verify fMRI/EEG similarity matches CORnet
  2. Sweep β from 10 to 50 and plot model-fMRI similarity and ImageNet accuracy to find optimal β
  3. Freeze CORnet weights and only train fMRI encoder to test whether alignment can be achieved without modifying visual layers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed alignment framework be extended to optimize vision models on other neural datasets (e.g., EEG from other paradigms or datasets) to achieve even better model-brain alignment?
- Basis in paper: The paper demonstrates improved alignment with fMRI and EEG data but does not explore optimization on other neural datasets or paradigms
- Why unresolved: The study only tested the framework on specific fMRI and EEG datasets
- What evidence would resolve it: Experiments applying the alignment framework to optimize models on different neural datasets and measuring the resulting model-brain alignment

### Open Question 2
- Question: What are the specific representational differences between ReAlnet-fMRI and CORnet in encoding object features like animacy, real-world size, or spikiness, and how do these differences relate to their respective training objectives?
- Basis in paper: The paper identifies differences in encoding food-related, artificial/hard, and electronics/technology information but does not provide a detailed analysis of other object dimensions
- Why unresolved: While some differences in object feature encoding are noted, the study does not comprehensively analyze how ReAlnet-fMRI and CORnet differ across all relevant object dimensions
- What evidence would resolve it: Detailed analysis of the encoding of various object dimensions in both ReAlnet-fMRI and CORnet, correlating these differences with their respective training objectives

### Open Question 3
- Question: Can the image-to-fMRI encoding-based alignment framework be applied to other types of neural data (e.g., intracranial recordings from monkeys) to achieve similar or better model-brain alignment improvements?
- Basis in paper: The paper focuses on optimizing models using fMRI and EEG data but does not explore the use of other types of neural data
- Why unresolved: The study only tests the alignment framework on fMRI and EEG data
- What evidence would resolve it: Experiments applying the alignment framework to optimize models using other types of neural data (e.g., intracranial recordings from monkeys) and measuring the resulting model-brain alignment improvements

## Limitations

- Reliance on fMRI and EEG datasets with relatively small image sets (1,200 training images, 50-200 test images) may constrain generalization across diverse visual stimuli
- Contrastive loss component for fMRI alignment lacks established validation in the literature, raising concerns about its reliability as a learning signal
- Study does not report statistical significance testing for model-brain alignment improvements, making it difficult to assess whether observed gains are robust

## Confidence

- **High**: The architectural framework for multi-layer encoding alignment and the overall experimental design are well-specified and logically sound
- **Medium**: The claim that ReAlnet-fMRI achieves higher model-brain alignment than CORnet is supported by reported metrics, but lacks statistical validation and detailed preprocessing specifications
- **Low**: The effectiveness of the contrastive loss component for fMRI alignment is not well-established in the literature and may be unreliable in practice

## Next Checks

1. Conduct statistical significance testing (e.g., permutation tests) on model-brain alignment improvements to verify robustness of reported gains
2. Perform ablation studies to isolate the contribution of the contrastive loss component versus MSE alone in the fMRI generation objective
3. Test model-brain alignment across additional neural datasets (e.g., different fMRI studies or EEG paradigms) to assess generalizability beyond the current datasets