---
ver: rpa2
title: Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall
  in 2024
arxiv_id: '2409.16799'
source_url: https://arxiv.org/abs/2409.16799
tags:
- page
- aismr
- patchtst
- data
- themodel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This research focuses on adapting and fine-tuning the PatchTST\
  \ large language model to accurately predict All India Summer Monsoon Rainfall (AISMR)\
  \ with a three-month lead time. The fine-tuned model, trained with historical AISMR\
  \ data, Ni\xF1o3.4 index, and categorical Indian Ocean Dipole values, outperforms\
  \ several popular neural network and statistical models."
---

# Large Language Model Predicts Above Normal All India Summer Monsoon Rainfall in 2024

## Quick Facts
- arXiv ID: 2409.16799
- Source URL: https://arxiv.org/abs/2409.16799
- Reference count: 23
- Primary result: PatchTST LLM predicts 921.6 mm AISMR for 2024, outperforming other models by ~80% in accuracy

## Executive Summary
This study adapts the PatchTST large language model to predict All India Summer Monsoon Rainfall (AISMR) with three-month lead time. The fine-tuned model, trained on historical AISMR data combined with Niño3.4 and Indian Ocean Dipole indices, achieves exceptional accuracy with 0.07% RMSE and 0.976 Spearman correlation. The model predicts above-normal monsoon rainfall for 2024, with accumulated rainfall of 921.6 mm during June-September. The superior performance is attributed to PatchTST's unique patching and channel segmentation capabilities that retain local semantic information critical for monsoon prediction.

## Method Summary
The study fine-tunes the PatchTST LLM using historical AISMR daily data (1901-2023), Niño3.4 index, and categorical Indian Ocean Dipole values. Data preprocessing involves standard scaling and sequence creation with a 30-day window. The model's architecture includes patching, embedding, and Transformer encoder layers, followed by an output layer for rainfall prediction. Hyperparameter optimization is performed through grid search with early stopping. The model's predictions are evaluated using RMSE percentage and Spearman correlation metrics, comparing performance against several neural network and statistical models.

## Key Results
- PatchTST predicts 921.6 mm AISMR for June-September 2024, indicating above-normal monsoon
- Model achieves 0.07% RMSE and 0.976 Spearman correlation, outperforming competitors by ~80%
- Combined use of Niño3.4 and IOD indices provides better predictive power than either index alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PatchTST's patching and channel segmentation retain local semantic information critical for AISMR prediction
- Mechanism: The model divides time series into patches, each processed independently while maintaining channel independence, preserving local temporal patterns while leveraging shared weights
- Core assumption: Local patterns contain predictive signals for monsoon rainfall that would be lost in global transformations
- Evidence anchors:
  - The model's outstanding performance in predicting cumulative rainfall can be attributed to its unique feature of patching and channel segmentation
  - The model vectorizes individual time series into patches of a specified size and encodes these sequences using a Transformer

### Mechanism 2
- Claim: The combination of Niño3.4 index and IOD values provides more predictive power than either index alone for AISMR prediction
- Mechanism: The model learns complex nonlinear interactions between sea surface temperature anomalies and Indian Ocean dipole patterns
- Core assumption: The relationship between AISMR and individual climate indices is not static and requires multiple indices to capture evolving teleconnections
- Evidence anchors:
  - The model with the best performance utilized Niño3.4 values in conjunction with IOD and AISMR values for its predictions
  - While there exists a relationship between Niño3.4 and monsoon rainfall, this connection alone is insufficient for accurately predicting AISMR

### Mechanism 3
- Claim: Pre-trained LLM architecture with transfer learning enables accurate prediction with limited AISMR training data
- Mechanism: The PatchTST model leverages knowledge from large-scale pretraining on diverse time series data, allowing it to generalize effectively to the specific task of AISMR prediction
- Core assumption: Temporal patterns learned during pretraining are transferable to monsoon prediction task despite domain differences
- Evidence anchors:
  - Among the presently available LLMs, the channel-independent patch time series Transformer (PatchTST) has shown excellent performance in long-term time series forecasting
  - Weak corpus evidence for this specific mechanism - no direct citations found in neighbor papers supporting LLM transfer learning for climate prediction

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Understanding how PatchTST uses Transformer layers to process time series patches is crucial for modifying or extending the model
  - Quick check question: How does multi-head attention in Transformers differ from recurrent networks in processing sequential data?

- Concept: Time series forecasting evaluation metrics
  - Why needed here: RMSE percentage and Spearman correlation are used to evaluate model performance - understanding their interpretation is essential for model comparison
  - Quick check question: Why might Spearman correlation be preferred over Pearson correlation for evaluating monsoon prediction models?

- Concept: Climate teleconnections and indices
  - Why needed here: Understanding Niño3.4 and IOD indices and their relationship to AISMR is critical for feature engineering and model interpretation
  - Quick check question: How does the El Niño-Southern Oscillation typically affect Indian Summer Monsoon Rainfall patterns?

## Architecture Onboarding

- Component map: Input preprocessing -> Patching layer -> Embedding layer -> Transformer encoder -> Output layer -> Training loop
- Critical path: Patching → Embedding → Transformer → Prediction
- Design tradeoffs:
  - Patch size vs. computational efficiency: Larger patches capture more context but increase computation
  - Shared vs. separate weights across channels: Shared weights reduce parameters but may limit channel-specific learning
  - Number of Transformer layers: More layers increase capacity but risk overfitting with limited data
- Failure signatures:
  - High RMSE percentage indicates poor absolute prediction accuracy
  - Low Spearman correlation suggests failure to capture relative ranking patterns
  - Training instability or exploding gradients suggest need for gradient clipping or learning rate adjustment
- First 3 experiments:
  1. Test different patch sizes (15, 30, 45) to find optimal balance between local information retention and computational efficiency
  2. Compare shared vs. separate channel weights to assess whether channel independence is beneficial
  3. Evaluate impact of including/excluding Niño3.4 and IOD indices to verify their predictive importance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the PatchTST model's performance compare when predicting monsoon rainfall at a regional scale versus the national scale?
- Basis in paper: The paper mentions that regional forecasts at a granular scale are feasible given the availability of gridded data with 0.25-degree resolution, but does not provide results or comparisons
- Why unresolved: The study focuses on national-scale predictions and does not explore regional variations or model performance at different scales
- What evidence would resolve it: Conducting a study that applies the PatchTST model to regional datasets and comparing its performance metrics (RMSE, Spearman correlation) across different regions versus the national average

### Open Question 2
- Question: What is the impact of using real-time versus forecasted ENSO and IOD index values on the accuracy of AISMR predictions?
- Basis in paper: The paper uses forecasted values for ENSO and IOD indices for predicting 2024 rainfall but does not analyze the impact of using forecasted versus actual historical values
- Why unresolved: The study does not provide a comparative analysis of prediction accuracy when using forecasted versus observed index values for historical data
- What evidence would resolve it: A comparative study using both real-time and forecasted ENSO and IOD values for historical years to assess differences in prediction accuracy

### Open Question 3
- Question: How does the PatchTST model perform in predicting extreme monsoon events, such as droughts or floods, compared to normal rainfall years?
- Basis in paper: The paper discusses the model's general performance and its ability to predict above-normal rainfall but does not specifically address its performance in predicting extreme events
- Why unresolved: The study does not analyze the model's effectiveness in capturing the variability and extremities of monsoon patterns
- What evidence would resolve it: An analysis focusing on the model's predictions during years with known extreme events and comparing its accuracy and reliability in those scenarios to normal years

## Limitations

- Limited cross-validation across different historical periods to assess generalizability
- No ablation studies to isolate the contribution of the patching mechanism to performance
- Focus on national-scale predictions without exploring regional variations or extreme event prediction

## Confidence

- **Medium** for the claim that PatchTST's patching mechanism is the primary reason for its superior performance
- **Low** regarding the model's generalizability beyond the specific dataset and time period used
- **Medium** in the prediction of above-normal monsoon for 2024

## Next Checks

1. **Ablation Study**: Remove the patching mechanism from PatchTST while keeping all other components identical, then compare performance to the full model
2. **Cross-Validation by Era**: Split the 1901-2023 data into multiple historical periods and train/test the model on different combinations
3. **Feature Importance Analysis**: Perform controlled experiments removing either Niño3.4 or IOD indices individually to quantify their individual contributions versus their combined effect