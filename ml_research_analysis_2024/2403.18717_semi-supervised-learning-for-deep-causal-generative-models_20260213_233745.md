---
ver: rpa2
title: Semi-Supervised Learning for Deep Causal Generative Models
arxiv_id: '2403.18717'
source_url: https://arxiv.org/abs/2403.18717
tags:
- causal
- variables
- labels
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a semi-supervised deep causal generative model
  that can leverage partially labelled medical imaging data to generate counterfactuals.
  The key idea is to combine a hierarchical VAE for image generation with a predictive
  component that infers causal variables, enabling counterfactual generation even
  with missing labels.
---

# Semi-Supervised Learning for Deep Causal Generative Models

## Quick Facts
- arXiv ID: 2403.18717
- Source URL: https://arxiv.org/abs/2403.18717
- Reference count: 22
- One-line primary result: Semi-supervised causal generative model outperforms supervised methods on counterfactual generation with minimal labeled data

## Executive Summary
This paper introduces a semi-supervised deep causal generative model for medical imaging that leverages partially labeled data to generate counterfactuals. The method combines a hierarchical VAE for image generation with a predictive component that infers causal variables, enabling effective learning even when many labels are missing. The approach is evaluated on both semi-synthetic colored Morpho-MNIST and real MIMIC-CXR datasets, demonstrating that it can achieve near-perfect counterfactual effectiveness with only 1.67% fully labeled samples while learning more accurate causal relationships than purely supervised approaches.

## Method Summary
The method integrates semi-supervised learning with deep causal generative modeling by combining a hierarchical VAE structure with a causal inference network. For labeled data, it jointly trains the generative and causal components, while for unlabeled data it predicts missing variables using the posterior q(y|x) and incorporates these predictions into the ELBO objective with entropy-based weighting. Counterfactual regularization is applied by performing do-interventions on causal variables and enforcing that parent variables remain invariant to these perturbations. The model is trained to maximize the use of all available data while maintaining causal consistency through these interventions.

## Key Results
- Achieved near-perfect counterfactual effectiveness with only 1.67% fully labeled samples on MIMIC-CXR
- Outperformed state-of-the-art supervised methods on counterfactual generation tasks
- Demonstrated improved learning of causal relationships with better log-likelihoods for child variables and more accurate counterfactual implementations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semi-supervised learning improves causal model training when some variables are missing by using unlabeled data to infer missing labels via learned predictive mappings
- Mechanism: The model jointly trains a hierarchical VAE with a causal graph inference network. For unlabeled data, it predicts missing variables using the posterior q(y|x), then uses these predictions in the ELBO objective with entropy-based weighting to reduce uncertainty
- Core assumption: The causal structure (DAG) is known and correctly specified, and the predictive component q(y|x) can learn to impute missing labels with sufficient accuracy
- Evidence anchors: [abstract], [section 3]

### Mechanism 2
- Claim: Counterfactual regularization improves robustness by ensuring that perturbations of the input image respect the causal structure
- Mechanism: The method performs do-interventions on variables and enforces that the cause variable remains invariant under the perturbation by minimizing divergence between original and predicted parent variables
- Core assumption: The causal relationships encoded in the DAG are correct, and the model can accurately predict the causal variables from the image
- Evidence anchors: [section 3], [section 4.2]

### Mechanism 3
- Claim: The principle of independence of cause and mechanism (ICM) suggests that having more labels for effect variables improves model performance more than having labels for cause variables when data is limited
- Mechanism: The model leverages that the causal mechanism is independent of the distribution of the causes, so focusing on labeling effect variables provides more information for learning the joint distribution when labels are scarce
- Core assumption: The ICM holds for the data distribution, and the causal relationships are correctly identified
- Evidence anchors: [section 4.1], [section 3]

## Foundational Learning

- Concept: Structural Causal Models (SCM)
  - Why needed here: The model is built on the foundation of SCMs, which provide a formal framework for representing causal relationships and performing interventions
  - Quick check question: What is the key difference between an SCM and a Bayesian network in terms of representing causal relationships?

- Concept: Variational Autoencoders (VAE)
  - Why needed here: The model uses a hierarchical VAE structure for image generation, which is a core component of the generative model
  - Quick check question: How does the ELBO objective in a VAE balance the reconstruction loss and the KL divergence?

- Concept: Directed Acyclic Graphs (DAG)
  - Why needed here: The causal relationships between variables are represented using a DAG, which is essential for performing valid interventions and counterfactual reasoning
  - Quick check question: What are the key properties of a DAG that make it suitable for representing causal relationships?

## Architecture Onboarding

- Component map: Hierarchical VAE -> Causal Inference Network -> Counterfactual Regularization -> Semi-supervised Learning
- Critical path: Encode image x to latent variables z and causal variables y using qϕ(z|x, yE, yC) and qϕ(y|x). Decode latent variables and causal variables to reconstruct image using pθ(x|z, yE, yC). Train causal inference network to predict causal variables from images. Perform counterfactual regularization by intervening on causal variables and enforcing causal consistency
- Design tradeoffs: Using a hierarchical VAE allows for more expressive image generation but increases model complexity. Entropy-based weighting for uncertain predictions reduces the impact of incorrect imputations but may also reduce the use of potentially useful information. Counterfactual regularization improves causal consistency but adds computational overhead during training
- Failure signatures: Poor reconstruction quality indicates issues with the VAE component or the causal inference network. Inaccurate counterfactuals suggests problems with the causal DAG specification or the counterfactual regularization. Overfitting to labeled data implies that the model is not effectively leveraging the unlabeled data
- First 3 experiments: 1) Train the model on Morpho-MNIST with known causal structure and evaluate reconstruction quality and counterfactual generation. 2) Vary the proportion of labeled data and assess the impact on model performance. 3) Introduce incorrect causal relationships in the DAG and observe the impact on counterfactual generation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the semi-supervised causal generative model change when the DAG structure is partially unknown or misspecified?
- Basis in paper: [explicit] The authors acknowledge that assuming the DAG structure is known a priori is a limitation, stating that if misspecified, there are no guarantees on the correctness of the generated counterfactuals
- Why unresolved: The paper does not explore scenarios where the DAG structure is partially unknown or misspecified, focusing instead on cases where the structure is fully known
- What evidence would resolve it: Experiments comparing model performance with varying degrees of DAG structure knowledge, including scenarios with partially known or misspecified DAGs

### Open Question 2
- Question: How does the semi-supervised causal generative model perform when applied to medical imaging datasets with more complex causal structures than MIMIC-CXR?
- Basis in paper: [inferred] The paper demonstrates the model's effectiveness on MIMIC-CXR, which has a relatively simple causal structure. However, real-world medical imaging data may have more complex causal relationships
- Why unresolved: The paper does not explore the model's performance on datasets with more complex causal structures
- What evidence would resolve it: Evaluating the model on medical imaging datasets with more complex causal structures, such as those involving multiple interacting variables or non-linear relationships

### Open Question 3
- Question: How does the semi-supervised causal generative model perform when the missing labels are not missing at random but follow a specific pattern or are correlated with other variables?
- Basis in paper: [inferred] The paper explores the case of missing labels but does not consider scenarios where the missingness follows a specific pattern or is correlated with other variables
- Why unresolved: The paper does not investigate the impact of non-random missingness on the model's performance
- What evidence would resolve it: Experiments comparing the model's performance when labels are missing at random versus when they are missing following a specific pattern or correlated with other variables

## Limitations
- Model complexity and scalability concerns for larger datasets with millions of samples
- Strong assumption that causal DAG is known and correctly specified
- Evaluation on semi-synthetic and limited real datasets may not capture full complexity of real-world medical imaging

## Confidence
- High confidence: The core methodology of combining semi-supervised learning with causal generative models is well-founded and supported by experimental results
- Medium confidence: Performance improvements demonstrated on evaluated datasets may not generalize to other medical imaging modalities or more complex causal structures
- Low confidence: Claims about semi-supervised learning effectively leveraging unlabeled data for causal generative models may not hold for all types of medical imaging data or causal relationships

## Next Checks
1. Perform ablation study on causal structure specification by intentionally misspecifying or learning DAG from data to assess model sensitivity
2. Train and evaluate on larger-scale medical imaging datasets (millions of samples) to measure computational overhead and scalability
3. Apply the model to other medical imaging modalities (CT, MRI, histopathology) to evaluate generalization and compare with state-of-the-art methods