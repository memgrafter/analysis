---
ver: rpa2
title: 'Let''s Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs
  for Robust and Instruction-Aware ASR and OCR'
arxiv_id: '2405.14259'
source_url: https://arxiv.org/abs/2405.14259
tags:
- recognition
- speech
- chen
- fusion
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel generative fusion decoding (GFD) algorithm
  that integrates large language models (LLMs) into automatic speech recognition (ASR)
  and optical character recognition (OCR) systems. The key innovation is enabling
  seamless fusion across mismatched token spaces by calculating likelihood at the
  byte level, allowing synchronous progression during decoding.
---

# Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Robust and Instruction-Aware ASR and OCR

## Quick Facts
- arXiv ID: 2405.14259
- Source URL: https://arxiv.org/abs/2405.14259
- Authors: Chan-Jan Hsu; Yi-Chang Chen; Feng-Ting Liao; Pei-Chen Ho; Yu-Hsiang Wang; Po-Chun Hsu; Da-shan Shiu
- Reference count: 14
- One-line primary result: Achieves up to 17.7% WER reduction on ASR benchmarks through LLM integration without retraining

## Executive Summary
This paper introduces Generative Fusion Decoding (GFD), a novel algorithm that integrates large language models (LLMs) into automatic speech recognition (ASR) and optical character recognition (OCR) systems. The key innovation is a byte-level likelihood calculation that enables seamless fusion across mismatched token spaces, allowing synchronous progression during decoding. GFD achieves significant improvements in word error rate (WER) across multiple benchmarks while maintaining compatibility with pre-trained models through its plug-and-play design.

## Method Summary
GFD fuses pre-trained ASR/OCR models with LLMs by calculating likelihood at the byte level, enabling integration without retraining. The algorithm transforms token-level probabilities from ASR and LLM into byte-level probabilities, allowing synchronous decoding despite different tokenization schemes. A dynamic shifting value k manages delayed feedback synchronization during the fusion process. The method is evaluated across multiple ASR datasets (Librispeech, Medical, ATCO2, Fleurs-HK, NTUML2021, FormosaSpeech) and an OCR dataset (NAF), demonstrating robust performance improvements through this generative fusion approach.

## Key Results
- Achieves up to 17.7% reduction in Word Error Rate (WER) across multiple ASR benchmarks
- Maintains plug-and-play compatibility with pre-trained models without requiring retraining
- Excels particularly in instruction-aware and long-context settings
- Demonstrates effectiveness across multiple languages including English, Chinese, and Cantonese

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Byte-level likelihood calculation enables fusion across mismatched token spaces
- Mechanism: Transforms token-level probabilities from ASR and LLM into byte-level probabilities, allowing synchronous decoding despite different tokenization schemes
- Core assumption: The main token sequence and its immediate alternatives dominate probability contribution when converting to byte space
- Evidence anchors:
  - [abstract] "calculating likelihood at the byte level, allowing synchronous progression during decoding"
  - [section 3.1] "We define a mapping from the token-level probabilities to the byte-level probabilities"
  - [corpus] Weak evidence - no direct mentions of this specific mechanism
- Break condition: If alternative token sequences contribute significant probability mass beyond the main sequence and immediate alternatives

### Mechanism 2
- Claim: Intermediate LLM interaction during decoding improves recognition accuracy
- Mechanism: LLM provides real-time scoring feedback during the ASR decoding process rather than waiting for complete hypotheses
- Core assumption: LLM can correct errors in real-time without waiting for full hypothesis generation
- Evidence anchors:
  - [abstract] "GFD improves performance on various ASR scenarios and OCR, which is orthogonal to improvements from previous approaches"
  - [section 3.2] "the text recognition models propose sequences for the LLMs to provide scoring feedback"
  - [corpus] Weak evidence - no direct mentions of intermediate interaction benefits
- Break condition: When LLM scoring latency exceeds ASR decoding speed, causing synchronization issues

### Mechanism 3
- Claim: Plug-and-play design preserves pre-trained model performance while enabling fusion
- Mechanism: Maintains original model architectures including tokenizers and embeddings, avoiding retraining while achieving fusion
- Core assumption: Keeping model architectures intact prevents performance degradation from additional training
- Evidence anchors:
  - [abstract] "GFD is plug-and-play by design, making it readily compatible with various auto-regressive models without the need for any re-training"
  - [section 2.1] "by keeping the model architecture intact, including tokenizers and embedding, we ensure that each individual pre-trained model's performance on its respective task is preserved"
  - [corpus] Weak evidence - no direct mentions of architecture preservation benefits
- Break condition: When fusion requires architectural modifications that cannot be achieved through the plug-and-play approach

## Foundational Learning

- Concept: Chain rule of probability for auto-regressive models
  - Why needed here: Essential for decomposing sequence probability into individual token probabilities during decoding
  - Quick check question: How does the chain rule enable auto-regressive generation in GFD?

- Concept: Beam search algorithm
  - Why needed here: Used to efficiently explore most likely sequences without exhaustive computation during fusion
  - Quick check question: How does beam search balance exploration and computational efficiency in GFD?

- Concept: Shallow fusion framework
  - Why needed here: Provides the theoretical foundation for combining multiple models at the decoding level
  - Quick check question: What distinguishes shallow fusion from deep fusion in the context of GFD?

## Architecture Onboarding

- Component map: ASR decoder -> Byte-level fusion layer -> LLM scorer -> Synchronization controller -> Output sequence
- Critical path: ASR token generation → Byte-level probability transformation → LLM scoring → Fusion decision → Output sequence
- Design tradeoffs:
  - Computational efficiency vs. fusion accuracy
  - Synchronization complexity vs. real-time performance
  - Model independence vs. optimal fusion
- Failure signatures:
  - High latency when LLM scoring cannot keep up with ASR decoding
  - Degraded performance when byte-level transformation introduces errors
  - Suboptimal fusion when k-value is poorly chosen
- First 3 experiments:
  1. Test basic fusion with pre-trained ASR and LLM on clean speech data
  2. Evaluate performance under noisy conditions with varying k-values
  3. Benchmark instruction-aware performance with domain-specific prompts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal selection strategy for the shifting value k in GFD to balance computational efficiency and recognition accuracy across different domains and languages?
- Basis in paper: [explicit] The paper states "k is optimally selected to be equal to the length of the last token of the proposal from MTR" but also mentions this "varies across different beam hypotheses"
- Why unresolved: The paper acknowledges variability but doesn't provide a systematic method for selecting k that would work across diverse linguistic contexts and domains
- What evidence would resolve it: Empirical comparison of different k-selection strategies across multiple languages, domains, and noise conditions showing which approach consistently optimizes the trade-off between computational cost and WER reduction

### Open Question 2
- Question: How does GFD's byte-level fusion approach compare to token-level fusion methods in terms of information preservation and error propagation, particularly for languages with complex tokenization requirements?
- Basis in paper: [explicit] "Our method approaches the problem from the byte sequence level, enabling a more general and flexible rescoring process that supports arbitrary input sequences" and "from an information-theoretic perspective, our approach preserves the maximum available information at each decoding step"
- Why unresolved: The paper claims superior information preservation but doesn't provide a rigorous information-theoretic analysis comparing byte-level vs token-level fusion across different language families
- What evidence would resolve it: Quantitative analysis of information loss/gain at each fusion step for byte-level vs token-level approaches across multiple languages, including languages with complex morphology and tokenization requirements

### Open Question 3
- Question: What architectural modifications to the LLM or text-recognition model could further improve GFD's robustness to ASR errors and LLM probability estimation errors, particularly for homophones and time-delayed activation tokens?
- Basis in paper: [inferred] The error analysis section identifies "ASR proposed errors" and "LLM probability estimation errors" as major failure modes, particularly for homophones in Mandarin and repeating sequences
- Why unresolved: The paper identifies failure modes but doesn't explore potential architectural solutions or modifications that could address these specific challenges
- What evidence would resolve it: Comparative experiments testing modified architectures (e.g., specialized attention mechanisms, contrastive learning objectives, or hybrid models) against standard GFD implementations, measuring improvements in handling homophones and repeating sequences

### Open Question 4
- Question: How does GFD's computational complexity scale with increasing context length, and what optimizations could maintain real-time performance for long-form transcription tasks?
- Basis in paper: [explicit] "GFD maintains semantic consistency in long-form audio by leveraging transcription history for contextual biasing" and mentions "truncating them when necessary for Whisper due to context length limitations"
- Why unresolved: The paper demonstrates effectiveness for long-form transcription but doesn't provide detailed complexity analysis or optimization strategies for maintaining real-time performance as context length increases
- What evidence would resolve it: Empirical scaling analysis showing GFD's computational complexity (latency, memory usage) as a function of context length, along with benchmark comparisons of different optimization strategies (sliding windows, hierarchical attention, etc.) for maintaining real-time performance

### Open Question 5
- Question: Can GFD's byte-level fusion framework be extended to multi-modal scenarios beyond text (e.g., incorporating visual or acoustic features) while maintaining its plug-and-play compatibility and computational efficiency?
- Basis in paper: [explicit] "We evaluate the application of GFD to ASR and OCR tasks" and "GFD is applicable to auto-regressive scenarios beyond ASR"
- Why unresolved: The paper demonstrates success with text modalities but doesn't explore how the byte-level fusion framework could be generalized to incorporate non-textual features while preserving its key advantages
- What evidence would resolve it: Proof-of-concept implementations extending GFD to multi-modal scenarios (e.g., ASR+OCR+vision for document understanding, or ASR+acoustic features for environmental sound recognition), with quantitative comparisons to existing multi-modal fusion approaches

## Limitations

- Byte-level transformation mechanism requires maintaining probability coherence across different tokenization schemes, with implementation details remaining unclear
- k-value selection for delayed feedback synchronization lacks systematic analysis of optimal ranges across different domains
- Plug-and-play design's preservation of pre-trained model performance needs more rigorous validation through comparative baselines

## Confidence

**High Confidence**: The paper's core claim that GFD achieves significant WER reductions (up to 17.7%) on multiple benchmarks is well-supported by quantitative results across diverse datasets (Librispeech, Medical, ATCO2, Fleurs-HK, NTUML2021, FormosaSpeech, NAF). The methodology for calculating WER and CER follows standard practices in the field.

**Medium Confidence**: The byte-level likelihood calculation mechanism is theoretically sound and the mathematical formulation appears correct, but the practical implementation details remain unclear from the paper. The recursive probability calculation and mapping between token and byte spaces would benefit from more detailed exposition or code release.

**Low Confidence**: The claim that GFD is truly plug-and-play without any performance degradation requires further validation. The paper mentions preserving pre-trained model performance but doesn't provide comparative baselines showing performance before and after GFD integration on the same models.

## Next Checks

1. **Ablation Study on Byte-Level Transformation**: Implement a controlled experiment comparing GFD performance with and without byte-level probability transformation, using identical ASR and LLM models. Measure the specific contribution of byte-level fusion versus traditional token-level fusion approaches.

2. **k-Value Sensitivity Analysis**: Systematically vary the k parameter across different domains (clean speech, noisy environments, domain-specific vocabulary) and measure the impact on both performance and computational efficiency. Identify optimal k ranges for different application scenarios.

3. **Architecture Preservation Validation**: For a subset of models, measure performance degradation when integrating GFD compared to standalone operation. Specifically test whether the claimed preservation of pre-trained model performance holds across different model architectures and tokenization schemes.