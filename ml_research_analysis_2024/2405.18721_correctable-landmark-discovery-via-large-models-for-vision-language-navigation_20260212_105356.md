---
ver: rpa2
title: Correctable Landmark Discovery via Large Models for Vision-Language Navigation
arxiv_id: '2405.18721'
source_url: https://arxiv.org/abs/2405.18721
tags:
- landmark
- navigation
- cooccurrence
- instruction
- landmarks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CONSOLE, a new VLN paradigm that leverages
  large models (ChatGPT and CLIP) to enable open-world sequential landmark discovery.
  The method uses ChatGPT to generate landmark cooccurrence priors and CLIP for landmark
  discovery, while a learnable cooccurrence scoring module corrects the priors according
  to actual observations.
---

# Correctable Landmark Discovery via Large Models for Vision-Language Navigation

## Quick Facts
- **arXiv ID**: 2405.18721
- **Source URL**: https://arxiv.org/abs/2405.18721
- **Reference count**: 40
- **Primary result**: Introduces CONSOLE, a VLN framework using ChatGPT and CLIP for open-world sequential landmark discovery, achieving state-of-the-art results on R2R and R4R benchmarks

## Executive Summary
This paper introduces CONSOLE, a new VLN paradigm that leverages large models (ChatGPT and CLIP) to enable open-world sequential landmark discovery. The method uses ChatGPT to generate landmark cooccurrence priors and CLIP for landmark discovery, while a learnable cooccurrence scoring module corrects the priors according to actual observations. The observation enhancement strategy combines CONSOLE with existing VLN agents. CONSOLE outperforms strong baselines on multiple benchmarks (R2R, REVERIE, R4R, RxR), achieving new state-of-the-art results on R2R and R4R in unseen scenarios.

## Method Summary
CONSOLE addresses vision-language navigation by extracting landmarks from instructions using ChatGPT, generating cooccurrence priors, and discovering landmarks in observations using CLIP. A learnable cooccurrence scoring module corrects the priors based on actual observations, while a landmark shifting module adapts the landmark discovery order to match navigation intent. The corrected landmark features are combined with original observation features through observation enhancement, which is then fed to baseline VLN agents (HAMT or DUET). The training objective combines navigation loss, consistency loss, and contrastive loss.

## Key Results
- Achieves new state-of-the-art results on R2R and R4R benchmarks in unseen scenarios
- Demonstrates effectiveness of open-world knowledge extraction using large models for VLN
- Shows that learnable cooccurrence scoring effectively corrects noisy LLM priors while preserving alignment knowledge
- Outperforms strong baselines across multiple VLN benchmarks (R2R, REVERIE, R4R, RxR)

## Why This Works (Mechanism)

### Mechanism 1
ChatGPT generates landmark cooccurrence priors without visual constraints. CLIP discovers landmarks in observations, but noisy priors can mislead. Learnable cooccurrence scoring module adjusts cooccurrence importance based on actual observations and navigation supervision (consistency loss). Core assumption: Cooccurrence priors contain valuable alignment knowledge that can be corrected through observation-aware re-weighting.

### Mechanism 2
At each timestep, two adjacent landmarks are compared using CLIP image-text similarity to the current observation. The more similar landmark becomes current important landmark. Pointer advances when landmark changes or after forced shift threshold. Core assumption: Instruction landmark order doesn't always match navigation order; adaptive shifting can discover correct sequence.

### Mechanism 3
Corrected landmark features (weighted by learnable scores) are added to original observation features to create enhanced observation features. These contain both visual information and corrected alignment knowledge. Core assumption: Adding corrected alignment knowledge to visual features improves cross-modal understanding for action prediction.

## Foundational Learning

- **Cross-modal alignment between language instructions and visual observations**
  - Why needed: VLN requires understanding what landmarks in instructions correspond to what objects in visual observations
  - Quick check: Can you explain how language instructions map to visual landmarks in navigation?

- **Large model knowledge extraction and noise mitigation**
  - Why needed: LLM provides useful priors but without visual constraints, requiring correction mechanism
  - Quick check: How would you extract useful knowledge from a large model while handling potential noise?

- **Sequential decision making under uncertainty**
  - Why needed: Agent must make action decisions at each timestep based on partial observations and instructions
  - Quick check: What challenges arise when making sequential decisions with incomplete information?

## Architecture Onboarding

- **Component map**: Instruction → Landmark extraction → Cooccurrence generation → Shifting → Discovery → Scoring → Enhancement → Action
- **Critical path**: Instruction → Landmark extraction → Cooccurrence generation → Shifting → Discovery → Scoring → Enhancement → Action
- **Design tradeoffs**:
  - LLM vs VLM: ChatGPT provides rich priors but no visual constraints; CLIP provides visual grounding but limited priors
  - Learnable vs heuristic: Learnable scoring adapts to data but requires training; heuristic approaches are simpler but less flexible
  - Feature fusion: Summation vs concatenation affects how corrected knowledge integrates with visual features
- **Failure signatures**:
  - Poor navigation performance despite good language understanding → likely cooccurrence scoring or enhancement issues
  - Landmark shifting gets stuck → possible CLIP similarity threshold problems
  - Inconsistent results across runs → potential random initialization or data ordering issues
- **First 3 experiments**:
  1. Baseline with no learnable scoring module to measure noise impact
  2. With learnable scoring but no observation enhancement to isolate correction effects
  3. Full system with different numbers of cooccurrences to find optimal tradeoff between knowledge and noise

## Open Questions the Paper Calls Out

1. How does the CONSOLE framework's performance scale with increasing numbers of cooccurrences beyond 10, and what is the optimal number for different VLN tasks?
2. How does the CONSOLE framework's performance compare to other methods when using different LLMs for navigational sequential landmark extraction, and what factors contribute to the differences in performance?
3. How does the CONSOLE framework's performance vary with different loss weights (λ1 and λ2) and temperature parameters (τ), and what are the optimal values for different VLN tasks?

## Limitations

- Reliance on ChatGPT introduces uncertainty about reproducibility and generalization beyond tested datasets
- Specific ChatGPT prompts for landmark extraction and cooccurrence generation are not fully specified in main text
- Learnable cooccurrence scoring module architecture and hyperparameters could significantly impact performance but are only partially described

## Confidence

- Core claims about CONSOLE's effectiveness: **Medium** - strong empirical results but limited theoretical guarantees
- Claims about "open-world" knowledge extraction: **Medium** - method enables discovery beyond training data, but ChatGPT-generated priors quality varies
- Reproducibility of specific results: **Medium** - depends on exact prompts and implementation details not fully specified

## Next Checks

1. **Prompt Robustness Test**: Evaluate CONSOLE's performance using different ChatGPT prompts for landmark extraction to assess sensitivity to prompt engineering choices.

2. **Noise Injection Analysis**: Systematically inject noise into the cooccurrence priors and measure how well the learnable scoring module corrects these variations, quantifying the correction mechanism's robustness.

3. **Cross-Dataset Generalization**: Test CONSOLE on VLN datasets from different domains (e.g., indoor vs outdoor navigation) to evaluate whether the open-world knowledge extraction generalizes beyond the original training environments.