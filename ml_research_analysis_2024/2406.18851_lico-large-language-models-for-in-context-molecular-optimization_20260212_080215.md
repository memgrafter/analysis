---
ver: rpa2
title: 'LICO: Large Language Models for In-Context Molecular Optimization'
arxiv_id: '2406.18851'
source_url: https://arxiv.org/abs/2406.18851
tags:
- lico
- optimization
- language
- arxiv
- molecular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LICO, a method that extends large language
  models (LLMs) for black-box optimization, particularly for molecular optimization.
  LICO adds separate embedding layers for inputs and outputs, and a prediction layer
  to existing LLMs, allowing them to perform in-context predictions on diverse functions
  over a target domain.
---

# LICO: Large Language Models for In-Context Molecular Optimization

## Quick Facts
- arXiv ID: 2406.18851
- Source URL: https://arxiv.org/abs/2406.18851
- Authors: Tung Nguyen; Aditya Grover
- Reference count: 22
- Primary result: LICO achieves state-of-the-art performance on PMO-1K benchmark with sum score 11.65 across 23 tasks

## Executive Summary
LICO introduces a method to extend large language models for in-context molecular optimization, addressing the challenge of black-box optimization where function evaluations are expensive and gradients are unavailable. The approach adds separate embedding layers for inputs and outputs to a frozen LLM, enabling the model to perform in-context predictions on diverse functions over molecular fingerprints. Trained on semi-synthetic data combining intrinsic molecular properties and synthetic functions from Gaussian Processes, LICO can optimize unseen molecular properties via prompting without retraining.

## Method Summary
LICO extends a frozen LLM with separate embedding layers for inputs (molecular fingerprints) and outputs (property values), plus a prediction head that outputs mean and standard deviation. The model is trained on semi-synthetic data combining intrinsic molecular properties computed from ZINC250K molecules and synthetic functions sampled from Gaussian Processes with Tanimoto kernel. During training, sequences of (input, output) pairs are embedded, passed through the LLM, and the prediction head learns to output property values. For optimization, LICO uses these embeddings to perform in-context reasoning, predicting properties for candidate molecules and selecting those with highest upper confidence bounds.

## Key Results
- LICO achieves state-of-the-art performance on PMO-1K benchmark with sum score 11.65 across 23 tasks
- Outperforms baselines including GP BO, Graph GA, REINVENT, Genetic GFN, Augmented Memory, and MOLLEO
- Ablation studies confirm importance of language instructions and semi-synthetic training for performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separate embedding layers enable mapping molecular fingerprints and property scores into LLM's hidden space for in-context reasoning
- Mechanism: Converting molecular fingerprints to single hidden vectors reduces context length and retains more conditioning examples, while prediction head maps embeddings to property predictions in one autoregressive step
- Core assumption: Pretrained LLM's hidden space can meaningfully represent domain-specific features when aligned via learned embeddings
- Evidence: Abstract states model trains to perform in-context predictions on diverse functions; Section 4.1 explains embeddings encode to shared hidden space enabling reasoning in hidden space instead of raw text

### Mechanism 2
- Claim: Semi-synthetic training with intrinsic and synthetic functions provides right inductive bias for generalization
- Mechanism: Intrinsic functions encode domain knowledge (molecular weight, ring counts) correlating with real objectives, while synthetic GP functions with Tanimoto kernel add diversity across function space
- Core assumption: Mixture ratio can be tuned so training data is both close to and diverse enough compared to downstream tasks
- Evidence: Section 4.2 describes training on mix of intrinsic and synthetic functions termed semi-synthetic; Section 5.2.2 shows semi-synthetic outperforms both intrinsic-only and synthetic-only data

### Mechanism 3
- Claim: Language instructions (tokens `<x>`, `<y>` and task prompts) guide LLM to correctly associate inputs with outputs during in-context learning
- Mechanism: Tokens act as delimiters and task prompt tells model "each x is a molecule and each y is the property of the corresponding molecule. Predict y given x," enabling parsing without explicit fine-tuning
- Core assumption: Pretrained LLM can leverage language understanding to interpret minimal prompts and map them to embedding space reasoning
- Evidence: Section 4.1 describes task prompt instructs model while special tokens inform position of inputs and outputs; Section 5.2.1 shows without language instruction performs worst, confirming importance of guiding pretrained LLM

## Foundational Learning

- Concept: Gaussian Process with Tanimoto kernel for synthetic function generation
  - Why needed: Provides principled, easy-to-sample family of diverse functions over binary molecular fingerprints approximating structure of real molecular property functions
  - Quick check: What property of Tanimoto kernel makes it suitable for molecular fingerprints compared to standard RBF kernel?

- Concept: Autoregressive prediction in in-context learning
  - Why needed: Enables model to condition on sequence of (x, y) pairs and predict y for new x without retraining, matching online nature of black-box optimization
  - Quick check: In LICO's training, how does model learn to predict y given x and preceding pairs without explicit labels for each individual prediction?

- Concept: Few-shot learning and pattern matching in LLMs
  - Why needed: LICO relies on LLM's pretrained ability to generalize from limited examples in hidden space, transferring skill to molecular property prediction
  - Quick check: How does scaling behavior of LLM size (Llama-2 7B vs 4B) relate to model's pattern-matching capability in this non-language task?

## Architecture Onboarding

- Component map: Input embedding layer -> Output embedding layer -> Concatenation with special tokens -> Frozen LLM -> Prediction head (mean + std)

- Critical path:
  1. Embed x and y into hidden space via learned MLPs
  2. Concatenate embeddings into sequence with delimiters
  3. Feed through frozen LLM to get contextual representations
  4. Apply prediction head on y tokens to output µ, σ

- Design tradeoffs:
  - Separate embeddings vs. full fine-tuning: saves parameters, preserves LLM general knowledge, but may limit expressiveness
  - Using language tokens vs. pure embeddings: improves interpretability and association learning but adds context length
  - Synthetic vs. intrinsic data ratio: balances domain relevance and generalization breadth

- Failure signatures:
  - Poor optimization scores → check if embedding alignment is broken or synthetic data ratio is off
  - High variance in predictions → check if task prompt or token usage is inconsistent
  - Model fails to condition on many examples → check if sequence length reduction is too aggressive

- First 3 experiments:
  1. Train LICO with only intrinsic functions (no synthetic) and measure performance drop to confirm importance of synthetic diversity
  2. Remove language tokens and task prompt, keep embeddings only, to see impact on in-context reasoning
  3. Swap base LLM with smaller or randomly initialized one to test scaling and pretraining importance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance of LICO scale with increasingly larger LLMs, and is there point of diminishing returns?
- Basis: Paper states LICO's performance scales consistently with LLM size, with Llama-2 7B outperforming smaller models, but does not explore models larger than 7B
- Why unresolved: Paper only tested LLMs up to 7B parameters, leaving scaling behavior for much larger models unexplored
- What evidence would resolve: Testing LICO with state-of-the-art LLMs (Llama-3 70B, GPT-4) on PMO benchmark would reveal whether scaling trend continues and where it plateaus

### Open Question 2
- Question: Can LICO be effectively adapted to optimize objectives outside molecular domain, such as material discovery or neural architecture search?
- Basis: Paper demonstrates LICO's effectiveness in molecular optimization but notes methodology applies to "broad scientific domains" and suggests evaluating in other domains as future direction
- Why unresolved: Paper focuses exclusively on molecular optimization, no experiments conducted in other domains
- What evidence would resolve: Applying LICO to benchmarks in material discovery (OC20) or neural architecture search (NAS-Bench-101) and comparing performance to domain-specific baselines would demonstrate generality

### Open Question 3
- Question: What is impact of ratio of intrinsic to synthetic functions in semi-synthetic training on LICO's performance, and is there optimal balance?
- Basis: Paper shows semi-synthetic training outperforms both intrinsic-only and synthetic-only training, with small to moderate ratios (0.1 to 0.5) achieving similarly good performance, but does not explore full range of ratios or determine optimal point
- Why unresolved: Ablation study only tests few ratios (0, 0.1, 0.5, and 1), leaving optimal balance between intrinsic and synthetic functions unclear
- What evidence would resolve: Systematically varying ratio of intrinsic to synthetic functions across wider range (0.01 to 0.9) and measuring LICO's performance on PMO benchmark would identify optimal balance for different task types

## Limitations
- Performance evaluation limited to low-budget setting (PMO-1K with 1000 function calls), higher-budget scenarios not thoroughly explored
- Exact composition of semi-synthetic training set and its relationship to downstream tasks remains underspecified
- No statistical significance tests or error bars provided for reported AUC scores across tasks

## Confidence
- High confidence: Mechanism by which separate embeddings enable in-context reasoning is well-supported by ablation results showing removing language instructions causes significant performance degradation
- Medium confidence: Claim that semi-synthetic training improves generalization is supported by ablation studies, but optimal balance between intrinsic and synthetic functions not fully characterized and paper does not explore sensitivity to this ratio
- Medium confidence: Assertion that LICO outperforms all baselines on PMO-1K is supported by reported AUC scores, but paper does not provide statistical significance tests or error bars, and some baselines were not directly compared in all experiments

## Next Checks
1. Conduct sensitivity analysis on ratio of intrinsic to synthetic functions in semi-synthetic training to determine optimal balance and robustness to this hyperparameter
2. Perform statistical significance testing (e.g., paired t-tests) on AUC scores across tasks to verify that LICO's improvements over baselines are statistically meaningful
3. Extend evaluation to higher-budget settings (e.g., PMO-10K) to assess whether LICO's advantages persist or degrade as number of function calls increases