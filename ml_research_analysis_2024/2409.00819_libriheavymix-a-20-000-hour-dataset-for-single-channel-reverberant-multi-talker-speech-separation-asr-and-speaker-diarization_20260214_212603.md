---
ver: rpa2
title: 'LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Reverberant Multi-Talker
  Speech Separation, ASR and Speaker Diarization'
arxiv_id: '2409.00819'
source_url: https://arxiv.org/abs/2409.00819
tags:
- speech
- speaker
- training
- separation
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LibriheavyMix, a large-scale dataset with
  20,000 hours of simulated far-field multi-talker overlapping speech, designed for
  single-channel speech separation, ASR, and speaker diarization tasks. The dataset
  includes reverberation effects and multiple speaker turns, addressing real-world
  scenarios like meetings and cocktail parties.
---

# LibriheavyMix: A 20,000-Hour Dataset for Single-Channel Reverberant Multi-Talker Speech Separation, ASR and Speaker Diarization

## Quick Facts
- arXiv ID: 2409.00819
- Source URL: https://arxiv.org/abs/2409.00819
- Reference count: 0
- Primary result: 20,000-hour simulated dataset showing SI-SDR gains up to 10.33 dB for separation and WER reductions to 8.73% on WHAMR!

## Executive Summary
This paper introduces LibriheavyMix, a large-scale simulated dataset containing 20,000 hours of far-field multi-talker overlapping speech with reverberation effects. The dataset is designed to address single-channel speech separation, ASR, and speaker diarization tasks in realistic scenarios like meetings and cocktail parties. A pipeline system combining speech separation, recognition, and diarization is presented as a baseline. Experiments demonstrate significant performance improvements when scaling training data, with substantial gains in both separation quality and recognition accuracy.

## Method Summary
LibriheavyMix is constructed by simulating far-field conditions on clean speech from LibriSpeech. The process involves generating room impulse responses for various room sizes and reverberation times, applying these to clean speech segments, and mixing multiple speakers at different overlap ratios. The dataset includes metadata about speaker turns and room characteristics. A pipeline system is implemented where speech separation is performed first, followed by speaker diarization on the separated signals, and finally ASR conditioned on the diarization output. The authors evaluate different training data scales (from 100 hours to 20,000 hours) to demonstrate scaling effects on performance.

## Key Results
- SI-SDR improves from 8.62 dB (100 hours) to 10.33 dB (20,000 hours) for speech separation
- WER reduces from 25.76% to 8.73% on WHAMR! benchmark with increased training data
- The pipeline system shows consistent improvements across separation, ASR, and diarization tasks

## Why This Works (Mechanism)
The success of LibriheavyMix stems from its scale and realistic simulation of far-field conditions. By generating 20,000 hours of data with proper reverberation modeling, the system can learn robust representations for separating overlapping speakers in challenging acoustic environments. The pipeline approach leverages the complementary strengths of separation (cleaning the signal) and diarization (identifying speaker turns), which together improve the final ASR performance. The scaling experiments demonstrate that model capacity and data diversity are key factors in handling complex multi-speaker scenarios.

## Foundational Learning
- Room Impulse Response (RIR) simulation: Needed to create realistic reverberation effects that mimic real acoustic environments; Quick check: Verify RIR parameters cover typical meeting room conditions
- Overlap ratio modeling: Required to simulate natural conversational dynamics where speakers interrupt and overlap; Quick check: Compare overlap distribution with real meeting corpora
- Far-field signal degradation: Essential for training models to handle distance-related acoustic distortions; Quick check: Measure SNR degradation across different speaker distances
- Multi-stage pipeline design: Allows specialized models for each sub-task while maintaining overall system coherence; Quick check: Analyze error propagation between stages

## Architecture Onboarding
Component map: Clean speech -> RIR simulation -> Overlap mixing -> Separation model -> Diarization model -> ASR model -> Output transcripts

Critical path: Separation → Diarization → ASR (errors compound along this path)

Design tradeoffs: Pipeline modularity vs. end-to-end optimization; synthetic data realism vs. scalability

Failure signatures: Poor separation manifests as residual cross-talk; diarization errors cause speaker confusion; ASR struggles with overlapped regions

First experiments:
1. Train separation model on 100 hours and measure baseline SI-SDR
2. Evaluate diarization accuracy on separated vs. mixed signals
3. Test ASR performance with and without diarization conditioning

## Open Questions the Paper Calls Out
None

## Limitations
- The synthetic nature may not fully capture real-world acoustic complexities and conversational dynamics
- Evaluation relies on simulated benchmarks (WHAMR!) rather than real meeting recordings
- The dataset uses clean speech from LibriSpeech, which differs substantially from natural conversational speech

## Confidence
High: Scaling effects on SI-SDR (8.62→10.33 dB) and WER reduction (25.76%→8.73%) are well-established
Medium: Pipeline system architecture performance metrics are reliable but component interactions need more validation
Low: Real-world applicability claims lack empirical validation on actual meeting recordings

## Next Checks
1. Evaluate trained models on real meeting recordings from AMI or CHiME-5 datasets
2. Test model robustness across different room sizes, reverberation times, and noise conditions
3. Compare pipeline approach against end-to-end multi-talker ASR models trained on the same dataset