---
ver: rpa2
title: Towards Macro-AUC oriented Imbalanced Multi-Label Continual Learning
arxiv_id: '2412.18231'
source_url: https://arxiv.org/abs/2412.18231
tags:
- learning
- loss
- task
- macro-auc
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel method to tackle the class imbalance
  issue in multi-label continual learning (MLCL) with the goal of maximizing Macro-AUC.
  The core idea involves a new Reweighted Label-Distribution-Aware Margin (RLDAM)
  loss that combines the benefits of reweighted univariate and label-distribution-aware
  margin losses.
---

# Towards Macro-AUC oriented Imbalanced Multi-Label Continual Learning

## Quick Facts
- arXiv ID: 2412.18231
- Source URL: https://arxiv.org/abs/2412.18231
- Reference count: 40
- Primary result: Proposes RLDAM loss and WRU strategy achieving up to 11.1% Macro-AUC improvement over ER

## Executive Summary
This paper addresses class imbalance in multi-label continual learning by proposing a novel Reweighted Label-Distribution-Aware Margin (RLDAM) loss that combines reweighted univariate and label-distribution-aware margin components. The method introduces a Weight Retain Updating (WRU) strategy to maintain class distribution balance in memory, enabling unbiased risk estimation. Theoretical analyses provide generalization bounds for both batch and continual settings, while experiments on three benchmarks demonstrate significant improvements in Macro-AUC compared to existing approaches.

## Method Summary
The proposed method tackles class imbalance in multi-label continual learning through two core components: the RLDAM loss and WRU memory strategy. The RLDAM loss assigns class-specific margins inversely proportional to the number of positive instances, balancing contributions from positive and negative samples. WRU maintains the ratio of positive to negative instances in memory through a greedy selection algorithm, ensuring consistent reweighting factors during training. The approach is evaluated on transformed versions of PASCAL VOC, MSCOCO, and NUS-WIDE datasets using replay-based continual learning.

## Key Results
- Achieves up to 11.1% improvement in Macro-AUC compared to Experience Replay baseline
- RLDAM loss shows superior performance across all three benchmark datasets
- WRU strategy effectively maintains class distribution balance in memory
- Theoretical generalization bounds demonstrate tighter performance guarantees than reweighted univariate loss alone

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The Reweighted Label-Distribution-Aware Margin (RLDAM) loss improves Macro-AUC by combining reweighted univariate loss and label-distribution-aware margin loss, assigning class-specific margins that are inversely proportional to the number of positive instances.
- **Mechanism**: The RLDAM loss balances the contribution of positive and negative instances per class through reweighting factors (1/|D+_k| and 1/|D-_k|), while the LDAM component assigns larger margins to classes with fewer positive instances, enhancing generalization by making the decision boundary more discriminative for minority classes.
- **Core assumption**: Class imbalance is primarily characterized by varying numbers of positive instances per class, and the optimal margin for each class is proportional to the inverse fourth root of the number of positive instances.
- **Evidence anchors**:
  - [abstract]: "we propose a new Reweighted Label-Distribution-Aware Margin (RLDAM) loss to tackle the imbalance, which can inherit the benefits of the RU and LDAM losses"
  - [section]: "LRDAM(x+, x−, fk) = ℓ(fk(x+) − ∆+_k) + ℓ(−fk(x−) − ∆-_k)" and "∆+_k = ∆-_k = λ|D+_k|^(-1/4)"
  - [corpus]: No direct evidence in corpus; claim relies on theoretical derivation
- **Break condition**: If the assumption about optimal margin scaling fails, or if the class imbalance structure differs significantly from the assumed form, the RLDAM loss may not provide the claimed benefits.

### Mechanism 2
- **Claim**: The Weight Retain Updating (WRU) strategy maintains the ratio of positive to negative instances in memory, ensuring unbiased estimation of the empirical risk and preventing catastrophic forgetting.
- **Mechanism**: WRU stores the counts of positive and negative instances per class alongside samples, and uses a greedy algorithm to select memory samples that preserve the original class distribution ratios. This ensures that the reweighting factors in the RLDAM loss remain consistent between memory and original data.
- **Core assumption**: The ratio of positive to negative instances is a stable and meaningful statistic for each class, and maintaining this ratio in memory is sufficient to approximate the original data distribution for training purposes.
- **Evidence anchors**:
  - [abstract]: "a new memory-updating strategy named Weight Retain Updating (WRU) is proposed to maintain the numbers of positive and negative instances of the original dataset in memory"
  - [section]: "design a greedy algorithm to select |Mt| samples from Dt. The goal of the greedy algorithm is to minimize the discrepancy in the ratio of positive and negative instances between Dt and Mt"
  - [corpus]: No direct evidence in corpus; claim is primarily algorithmic
- **Break condition**: If the class distribution changes significantly over time, or if the memory budget is too small to represent the required ratios, WRU may fail to maintain the necessary balance.

### Mechanism 3
- **Claim**: The combination of RLDAM loss and WRU provides theoretical generalization bounds that are tighter than those of reweighted univariate loss alone, due to class-aware margin assignment and unbiased memory sampling.
- **Mechanism**: The theoretical analysis shows that the generalization bound for RLDAM includes a term proportional to the sum of inverse margins for each class, which can be minimized by assigning smaller margins to classes with more positive instances. WRU ensures that the empirical risk estimate remains unbiased, reducing the variance term in the bound.
- **Core assumption**: The theoretical framework based on Rademacher complexity and kernel methods can provide meaningful bounds for deep neural networks used in practice, and the assumptions about Lipschitz continuity and margin scaling hold for the chosen loss functions.
- **Evidence anchors**:
  - [section]: "the batch algorithm with LRM has an imbalance-margin-aware learning guarantee of O(1/√n · 1/K · Σ √(1/τ_k) (ρ+_k + ρ-_k)) w.r.t. Macro-AUC" and "theoretically, we analyze the generalization bound of the RLDAM-based algorithm for Macro-AUC in batch MLL setting, and then give the generalization of our algorithm with RLDAM loss and WRU in MLCL"
  - [corpus]: No direct evidence in corpus; claim relies on theoretical derivation
- **Break condition**: If the theoretical assumptions are violated in practice (e.g., non-smooth loss functions, highly non-i.i.d. data), the generalization bounds may not provide useful guidance.

## Foundational Learning

- **Concept**: Multi-label learning (MLL) and its distinction from multi-class classification
  - **Why needed here**: The paper addresses a specific problem in MLL where each instance can have multiple labels simultaneously, requiring different evaluation metrics and handling of class imbalance compared to single-label problems.
  - **Quick check question**: In MLL, can an instance be associated with zero labels, one label, or multiple labels? What is the key difference in evaluation compared to multi-class classification?

- **Concept**: Class imbalance in multi-label settings and its impact on Macro-AUC
  - **Why needed here**: The paper specifically targets the imbalance issue in MLL, where some labels may have many more positive instances than others, affecting the performance of standard loss functions and evaluation metrics like Macro-AUC.
  - **Quick check question**: What are the two types of class imbalance mentioned in the paper, and how do they affect the learning process differently?

- **Concept**: Continual learning and catastrophic forgetting
  - **Why needed here**: The paper operates in the continual learning setting, where models must learn from sequential tasks without forgetting previous knowledge, requiring specific techniques like memory replay and regularization.
  - **Quick check question**: What is catastrophic forgetting, and why is it a particular challenge in the multi-label continual learning setting compared to single-label continual learning?

## Architecture Onboarding

- **Component map**: Input -> ResNet (34/50) -> RLDAM Loss -> SGD Update -> WRU Memory Update -> Output
- **Critical path**:
  1. Load current task data and memory
  2. Sample batches from current data and memory
  3. Compute RLDAM loss with class-specific margins
  4. Update model parameters using SGD
  5. Update memory using WRU strategy
  6. Evaluate on all tasks
- **Design tradeoffs**:
  - Memory size vs. performance: Larger memory allows better representation of class distributions but increases computational cost
  - Margin scaling vs. stability: Larger margins for minority classes improve discrimination but may cause optimization instability
  - Greedy selection vs. optimality: WRU uses greedy algorithm for efficiency but may not find globally optimal memory composition
- **Failure signatures**:
  - Degraded Macro-AUC on minority classes: Indicates RLDAM margins are not properly scaled
  - Increasing forgetting over tasks: Suggests WRU is not maintaining class distribution balance
  - Training instability or slow convergence: May indicate margin values are too aggressive
- **First 3 experiments**:
  1. **Ablation of RLDAM components**: Compare performance with only reweighted loss, only LDAM loss, and full RLDAM loss to verify the combined benefit
  2. **Memory size sensitivity**: Test performance across different memory sizes (200, 500, 1000, 1500, 2000) to understand the tradeoff between memory budget and effectiveness
  3. **Margin scaling verification**: Vary the hyperparameter λ controlling margin magnitude and observe its effect on minority class performance and overall Macro-AUC

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical generalization bounds rely on assumptions about Lipschitz continuity and kernel methods that may not hold for deep neural networks in practice
- WRU memory strategy uses a greedy algorithm that provides no optimality guarantees
- Memory budget constraints may limit the effectiveness of class distribution preservation
- Experimental evaluation is limited to three datasets with specific class partitioning strategies

## Confidence
- **High confidence**: The core mechanism of combining reweighted and margin-aware losses is sound and well-supported by the experimental results
- **Medium confidence**: The WRU memory strategy effectively maintains class distribution balance, though theoretical guarantees are limited
- **Low confidence**: The theoretical generalization bounds provide meaningful practical guidance for hyperparameter selection

## Next Checks
1. **Theoretical validation**: Test the margin scaling (λ|D+_k|^(-1/4)) on synthetic data with known class imbalance patterns to verify the theoretical assumptions about optimal margins
2. **Memory strategy robustness**: Evaluate WRU performance across varying memory sizes (from 200 to 2000 samples) and compare against random sampling to quantify the benefit of distribution preservation
3. **Cross-dataset generalization**: Apply the method to additional multi-label datasets with different imbalance patterns to assess robustness beyond the three benchmark datasets used in the paper