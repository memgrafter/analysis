---
ver: rpa2
title: 'Collective Constitutional AI: Aligning a Language Model with Public Input'
arxiv_id: '2406.07814'
source_url: https://arxiv.org/abs/2406.07814
tags:
- response
- should
- public
- choose
- constitution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Collective Constitutional AI (CCAI), a method
  for incorporating public input into language model training. The approach uses online
  deliberation via Polis to gather principles from a representative U.S.
---

# Collective Constitutional AI: Aligning a Language Model with Public Input

## Quick Facts
- arXiv ID: 2406.07814
- Source URL: https://arxiv.org/abs/2406.07814
- Authors: Saffron Huang; Divya Siddarth; Liane Lovitt; Thomas I. Liao; Esin Durmus; Alex Tamkin; Deep Ganguli
- Reference count: 40
- Primary result: CCAI-trained model shows lower bias across nine social dimensions while maintaining equivalent performance on standard benchmarks

## Executive Summary
This paper introduces Collective Constitutional AI (CCAI), a method for incorporating public input into language model training. The approach uses online deliberation via Polis to gather principles from a representative U.S. sample, then fine-tunes models using Constitutional AI. The resulting Public model shows lower bias across nine social dimensions compared to a baseline model trained on Anthropic's standard constitution, while maintaining equivalent performance on language, math, and helpfulness/harmlessness evaluations. Qualitative analysis reveals the Public model tends to provide more substantive answers on controversial topics and reframes contentious matters positively, reflecting the emphasis on objectivity and impartiality in the collectively-sourced constitution.

## Method Summary
The method involves three main stages: first, recruiting a representative sample of U.S. participants to deliberate on AI principles using the Polis platform; second, aggregating statements with high group-aware consensus to form a constitution; and third, fine-tuning a language model using Constitutional AI with the public-sourced constitution. The resulting Public model is then evaluated against a baseline model trained with Anthropic's standard constitution on benchmarks including MMLU, GSM8K, BBQ (bias), OpinionQA, and human-rated helpfulness/harmlessness. The constitution drafting process translates public statements into training principles while maintaining their original spirit.

## Key Results
- Public model shows lower bias than baseline across all nine social dimensions in BBQ benchmark
- Public model maintains equivalent performance on MMLU, GSM8K, and helpfulness/harmlessness evaluations
- Public constitution emphasizes objectivity and impartiality more than the standard constitution's harm avoidance focus
- When prompted with contentious topics, Public model tends to reframe matters positively rather than refuse

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Public input via Polis creates a constitution that reduces model bias while maintaining capability.
- Mechanism: Representative public deliberation surfaces shared normative principles, which are then encoded via Constitutional AI fine-tuning.
- Core assumption: High group-aware consensus (GAC) correlates with broad public agreement on AI behavior.
- Evidence anchors: BBQ benchmark shows lower bias across nine dimensions; equivalent performance on standard tasks.
- Break condition: If GAC threshold is set too low, constitution may reflect polarized or niche views, reducing generalizability.

### Mechanism 2
- Claim: The CCAI framework operationalizes democratic legitimacy in AI system design.
- Mechanism: Participants self-generate and vote on normative statements, which are then aggregated and translated into LM training principles.
- Core assumption: Procedural fairness (equal voting rights, transparent moderation) produces perceived legitimacy.
- Evidence anchors: Moderation criteria established ahead of time; growing consensus that public preferences must be accounted for.
- Break condition: If moderation or statement selection introduces researcher bias, legitimacy claim collapses.

### Mechanism 3
- Claim: Public constitution differences produce measurable changes in model behavior.
- Mechanism: Constitutions differ in focus (objectivity vs. harm avoidance), so trained models reflect those differences in outputs.
- Core assumption: Constitution content directly shapes model responses via fine-tuning signal strength.
- Evidence anchors: Public model reframes contentious topics positively; emphasizes accessibility more than standard model.
- Break condition: If training process does not sufficiently weight constitution differences, behavioral changes may be negligible.

## Foundational Learning

- Concept: Group-aware consensus (GAC)
  - Why needed here: Determines which public statements enter the constitution.
  - Quick check question: How does GAC protect against "tyranny of the majority"?

- Concept: Constitutional AI fine-tuning
  - Why needed here: Translates natural language principles into model behavior.
  - Quick check question: What is the role of the "constitution" in the Constitutional AI training loop?

- Concept: Bias Benchmark for QA (BBQ)
  - Why needed here: Quantifies social bias in model outputs across dimensions.
  - Quick check question: Why might BBQ scores improve after fine-tuning on a public-sourced constitution?

## Architecture Onboarding

- Component map: Public input (Polis) -> statement moderation -> GAC filtering -> constitution drafting -> Constitutional AI fine-tuning -> evaluation
- Critical path: Input elicitation -> statement selection (GAC threshold) -> principle translation -> model training
- Design tradeoffs: Broad participation vs. coherent constitution; researcher neutrality vs. practical feasibility
- Failure signatures: Low GAC consensus, statement duplication, principle ambiguity, training instability
- First 3 experiments:
  1. Run Polis with a small pilot group to test statement clarity and voting flow.
  2. Vary GAC threshold to observe effect on constitution length and diversity.
  3. Train a toy model on a minimal constitution to verify principle translation and training pipeline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can researchers directly measure a language model's adherence to constitutional principles?
- Basis in paper: Explicit - The paper states "we do not yet have a direct technical measure for 'consistency'" and highlights the need for future work on this.
- Why unresolved: Measuring adherence to abstract principles is complex and requires new evaluation methodologies beyond current capabilities.
- What evidence would resolve it: Development of new metrics or evaluation frameworks that can quantitatively assess how well a model's behavior aligns with its constitutional principles.

### Open Question 2
- Question: How would the CCAI process and resulting model behavior differ when applied to diverse, international communities rather than a U.S. sample?
- Basis in paper: Explicit - The paper notes its participant sample is "not globally representative" and suggests testing with diverse communities could yield different results.
- Why unresolved: The current study only tested with U.S. participants, so comparative data from other cultural contexts is lacking.
- What evidence would resolve it: Conducting the same CCAI process with representative samples from different countries/regions and comparing the resulting constitutions and model behaviors.

### Open Question 3
- Question: What is the optimal method for handling trade-offs between conflicting constitutional principles during model training?
- Basis in paper: Explicit - The paper states "we did not tackle the question of how to trade off between conflicting principles" and suggests this needs "much more human input and care."
- Why unresolved: The current approach included principles independently without addressing conflicts, which may not reflect real-world complexities.
- What evidence would resolve it: Research into different frameworks for principle prioritization or conflict resolution, tested through controlled experiments.

## Limitations

- Sampling and representativeness: 842 U.S. participants may not capture sufficient diversity for genuinely representative AI alignment; study limited to U.S. residents
- Constitution translation: Researcher interpretation in converting public statements to training principles introduces potential bias
- Evaluation scope: BBQ benchmark may not capture all relevant bias forms; single baseline comparison limits comparative claims

## Confidence

**High Confidence**: Quantitative findings showing equivalent performance on MMLU, GSM8K, and helpfulness/harmlessness evaluations are methodologically sound.

**Medium Confidence**: Bias reduction claims are reasonably supported by BBQ results, though benchmark limitations temper confidence; qualitative observations are plausible but limited.

**Low Confidence**: Claims about democratic legitimacy and broader societal impact exceed what the study can establish empirically.

## Next Checks

1. Cross-Country Validation: Replicate Polis deliberation and fine-tuning with representative samples from multiple countries to test generalizability beyond U.S. contexts.

2. Longitudinal Behavior Analysis: Track model outputs over extended periods across varied contexts to determine stability and consistency of constitution-driven behavioral changes.

3. User Perception Study: Measure perceived legitimacy, trust, and satisfaction with the Public model compared to baseline models among represented groups.