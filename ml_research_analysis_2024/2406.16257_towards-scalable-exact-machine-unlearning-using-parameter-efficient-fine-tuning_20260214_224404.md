---
ver: rpa2
title: Towards Scalable Exact Machine Unlearning Using Parameter-Efficient Fine-Tuning
arxiv_id: '2406.16257'
source_url: https://arxiv.org/abs/2406.16257
tags:
- deletion
- unlearning
- performance
- training
- slices
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Sequence-aware Sharded Sliced Training (S3T),
  an exact machine unlearning framework that improves deletion efficiency and model
  performance. S3T uses parameter-efficient fine-tuning (PEFT) with a novel sequential
  slice-wise training strategy to enable parameter isolation across data slices.
---

# Towards Scalable Exact Machine Unlearning Using Parameter-Efficient Fine-Tuning
## Quick Facts
- arXiv ID: 2406.16257
- Source URL: https://arxiv.org/abs/2406.16257
- Reference count: 40
- Key outcome: Proposed S3T achieves O(mL log(mL)) deletion rate, enabling 1.6x to 3x more deletion requests before retraining compared to existing methods

## Executive Summary
This paper introduces Sequence-aware Sharded Sliced Training (S3T), an exact machine unlearning framework that significantly improves deletion efficiency while maintaining model performance. S3T leverages parameter-efficient fine-tuning (PEFT) combined with a sequential slice-wise training strategy to achieve parameter isolation across data slices. This allows efficient unlearning by deactivating affected layers instead of retraining entire models. The framework also incorporates a diverse sequence selection algorithm under budget constraints to further enhance deletion capabilities.

## Method Summary
S3T is an exact machine unlearning framework that improves upon existing sharded-sliced approaches by introducing parameter-efficient fine-tuning (PEFT) with a novel sequential slice-wise training strategy. The method trains different slices of the model on different data shards sequentially, allowing for parameter isolation across slices. When unlearning is required, affected slices can be deactivated without full model retraining. The framework also employs a diverse sequence selection algorithm to optimize the order of training sequences under budget constraints, further improving deletion efficiency. Theoretically, S3T achieves a deletion rate of O(mL log(mL)), significantly better than SISA's O(mL log m), while empirically demonstrating comparable performance to full training and enabling 1.6x to 3x more deletion requests before retraining is needed.

## Key Results
- Achieves deletion rate of O(mL log(mL)), improving upon SISA's O(mL log m)
- Enables 1.6x to 3x more deletion requests before retraining compared to baseline methods
- Maintains comparable model performance to full training while enabling efficient unlearning

## Why This Works (Mechanism)
S3T works by combining parameter-efficient fine-tuning with sequential slice-wise training to achieve parameter isolation. By training different slices on different data shards sequentially, each slice's parameters become specialized and isolated to specific data segments. When unlearning is required, instead of retraining the entire model, only the affected slices need to be deactivated or retrained. The diverse sequence selection algorithm further optimizes this process by strategically ordering training sequences to minimize parameter overlap between slices, thereby reducing the impact of unlearning requests on the overall model.

## Foundational Learning
- Parameter-Efficient Fine-Tuning (PEFT): A technique to adapt large models with minimal parameter changes, needed to maintain model performance while enabling parameter isolation across slices; quick check: verify that PEFT layers can be independently deactivated without affecting base model functionality.
- Sharded Training: Dividing data into shards for distributed processing, needed to create distinct data segments for slice specialization; quick check: ensure shard boundaries don't create data leakage between slices.
- Exact Unlearning: The ability to completely remove the influence of specific data points from a trained model, needed to meet legal and ethical requirements for data removal; quick check: verify that deleted data has no measurable impact on model predictions.
- Sequence Selection Algorithms: Methods to optimize the order of training sequences, needed to minimize parameter overlap between slices and improve deletion efficiency; quick check: measure parameter sharing between slices after different sequence orderings.

## Architecture Onboarding
- Component map: Data Shards -> Slice Training (sequential) -> PEFT Layers -> Model Output
- Critical path: Data ingestion and sharding → Sequential slice training with PEFT → Parameter isolation verification → Unlearning request processing → Slice deactivation
- Design tradeoffs: Parameter isolation vs. model capacity (more slices mean better unlearning but potentially reduced capacity); sequential training vs. training time (sequential ensures isolation but increases training duration)
- Failure signatures: Residual parameter sharing between slices (violates exact unlearning), degraded model performance after multiple unlearning operations, increased training time with more slices
- First experiments: 1) Test parameter isolation by measuring cross-slice parameter similarity after sequential training, 2) Evaluate unlearning effectiveness by measuring performance degradation on deleted data, 3) Benchmark deletion rate and retraining frequency against baseline sharded-sliced methods

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes perfect parameter isolation which may not hold in practice, potentially affecting exact unlearning guarantees
- Limited empirical validation across diverse model architectures and datasets
- Scalability with very large models or datasets remains unclear
- Does not address potential privacy implications of slice-wise training approach

## Confidence
- Theoretical deletion rate improvement (O(mL log(mL)) vs O(mL log m)): High
- Empirical validation of 1.6x to 3x more deletion requests: Medium
- Generalizability across model architectures and datasets: Medium
- Exact unlearning guarantees in practice: Low to Medium (depends on parameter isolation effectiveness)

## Next Checks
1. Test S3T across a broader range of model architectures (e.g., transformers of varying sizes, convolutional networks) and diverse datasets to assess generalizability.
2. Conduct a rigorous analysis of parameter isolation effectiveness, measuring any residual parameter sharing between slices and its impact on exact unlearning guarantees.
3. Evaluate the framework's performance and deletion efficiency at scale with significantly larger models and datasets to identify potential bottlenecks or limitations in real-world applications.