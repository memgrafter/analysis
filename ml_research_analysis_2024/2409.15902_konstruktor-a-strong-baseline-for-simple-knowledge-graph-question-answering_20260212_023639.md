---
ver: rpa2
title: 'Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering'
arxiv_id: '2409.15902'
source_url: https://arxiv.org/abs/2409.15902
tags:
- relation
- question
- entity
- questions
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Konstruktor introduces a simple, interpretable approach to knowledge
  graph question answering that outperforms end-to-end neural models on multiple datasets.
  The method breaks down the problem into three steps: entity detection and linking,
  relation prediction, and SPARQL query generation.'
---

# Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering

## Quick Facts
- arXiv ID: 2409.15902
- Source URL: https://arxiv.org/abs/2409.15902
- Reference count: 0
- Primary result: Konstruktor achieves 59.13% accuracy on SimpleQuestionsWD and 51.10% on RuBQ-en

## Executive Summary
Konstruktor introduces a simple, interpretable approach to knowledge graph question answering that breaks down the problem into three distinct steps: entity detection and linking, relation prediction, and SPARQL query generation. The method demonstrates state-of-the-art performance on multiple datasets, outperforming both traditional neural approaches and large language model-based methods for simple question answering tasks. By combining relation classification with ranking and leveraging Wikidata's structure, Konstruktor achieves superior accuracy, particularly for rare entities, while maintaining interpretability and computational efficiency.

## Method Summary
The Konstruktor approach decomposes knowledge graph question answering into three sequential steps. First, it detects and links entities mentioned in questions to Wikidata items using BM25 ranking with vector expansion and fine-tuning. Second, it predicts the relation between the identified entity and the answer using a combination of relation classification and ranking, employing a pre-trained multilingual BERT model for classification and BM25 for ranking. Finally, it generates SPARQL queries by combining the detected entity and predicted relation, executing them against the knowledge graph to retrieve answers. The method's modular design allows for component-level optimization and provides clear interpretability compared to end-to-end neural models.

## Key Results
- Achieves 59.13% accuracy on SimpleQuestionsWD dataset
- Achieves 51.10% accuracy on RuBQ-en dataset
- Demonstrates superior performance for rare entities compared to GPT models

## Why This Works (Mechanism)
The method's effectiveness stems from its three-step decomposition that allows specialized processing at each stage. By separating entity linking from relation prediction, Konstruktor can optimize each component independently and handle ambiguity more effectively. The combination of classification and ranking for relation prediction captures both semantic similarity and structural patterns in the knowledge graph. The approach leverages Wikidata's clean structure and SimpleQuestionsWD's relatively simple questions to achieve high accuracy without requiring complex multi-hop reasoning.

## Foundational Learning

**Entity Linking**: Connecting textual mentions to knowledge graph entities is essential for grounding questions in structured data. Quick check: Verify entity linking accuracy on held-out questions.

**Relation Classification**: Predicting the semantic relationship between entities enables correct query construction. Quick check: Evaluate relation prediction accuracy separately from end-to-end performance.

**SPARQL Generation**: Translating detected entities and relations into executable queries bridges the gap between natural language and knowledge graphs. Quick check: Test SPARQL query correctness on known entity-relation pairs.

## Architecture Onboarding

Component map: Entity Detection -> Relation Prediction -> SPARQL Generation -> Answer Retrieval

Critical path: The three-step pipeline represents the minimal sequence for answering simple questions. Entity detection must complete before relation prediction, and both must complete before SPARQL generation.

Design tradeoffs: The modular approach sacrifices some end-to-end optimization potential for interpretability and component-level debuggability. Using traditional information retrieval techniques instead of neural methods reduces computational cost but may miss some semantic nuances.

Failure signatures: Incorrect entity linking propagates errors to subsequent steps. Ambiguous relations may lead to multiple candidate SPARQL queries. The method struggles with multi-hop questions requiring intermediate reasoning steps.

First experiments:
1. Test entity linking accuracy on a sample of questions with known gold entities
2. Evaluate relation prediction performance on questions with manually identified entities
3. Measure SPARQL generation correctness for simple entity-relation pairs

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several emerge from the results. The generalizability of the approach to more complex question types and different knowledge graph schemas remains unclear. The interpretability advantages over black-box methods need formal validation through user studies. The computational efficiency claims require comparison with recent LLM-based approaches under identical hardware constraints.

## Limitations

- Performance claims may not extend to complex multi-hop question answering scenarios
- Reliance on Wikidata's clean structure may limit effectiveness on other knowledge graphs
- The approach's effectiveness on rare entities is demonstrated only on specific datasets

## Confidence

High confidence in the method's effectiveness for simple question answering tasks on Wikidata-based datasets
Medium confidence in the claimed interpretability advantages and computational efficiency
Low confidence in the generalization of performance claims to more complex question answering scenarios and different knowledge graph structures

## Next Checks

1. Test Konstruktor on complex multi-hop question answering datasets to evaluate performance beyond simple questions
2. Evaluate the approach on knowledge graphs with different schemas and properties to assess generalizability
3. Conduct user studies to quantitatively measure the interpretability advantages of the three-step decomposition compared to black-box alternatives