---
ver: rpa2
title: Multilingual Models for Check-Worthy Social Media Posts Detection
arxiv_id: '2408.06737'
source_url: https://arxiv.org/abs/2408.06737
tags:
- claims
- able
- veri
- factual
- posts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a study of multilingual transformer-based NLP
  models for detecting check-worthy social media posts containing verifiable factual
  claims and harmful content. The work covers dataset collection, preprocessing, model
  selection, training, testing, and implementation.
---

# Multilingual Models for Check-Worthy Social Media Posts Detection

## Quick Facts
- arXiv ID: 2408.06737
- Source URL: https://arxiv.org/abs/2408.06737
- Reference count: 33
- Key outcome: This paper presents a study of multilingual transformer-based NLP models for detecting check-worthy social media posts containing verifiable factual claims and harmful content.

## Executive Summary
This paper presents a comprehensive study of multilingual transformer-based NLP models for detecting check-worthy social media posts containing verifiable factual claims and harmful content. The work covers dataset collection, preprocessing, model selection, training, testing, and implementation with a special focus on multilingual models capable of processing posts in both English and low-resource languages such as Arabic, Bulgarian, Dutch, Polish, Czech, and Slovak. The study develops multi-label multilingual classification models that simultaneously detect harmful posts and posts with verifiable factual claims, validated against state-of-the-art models.

## Method Summary
The study employs multilingual transformer architectures (XLM-RoBERTa) fine-tuned for multi-label classification of social media posts. Datasets from CLEF2022, CLEF2021, LESA2021, and MultiClaim are preprocessed to remove URLs, punctuation, emojis, and posts outside 15-500 character length. The XLM-RoBERTa-base model with linear output layer is trained using BCEWithLogitsLoss for simultaneous detection of verifiable factual claims and harmful claims. Evaluation uses recall, F1-score, and accuracy metrics on held-out test sets, with inference time analysis on both CPU and GPU platforms.

## Key Results
- Multi-label XLM-RoBERTa-base model achieves highest accuracy and recall above 0.8 for verifiable factual claims detection
- Multilingual models outperform monolingual approaches on low-resource languages without requiring translation steps
- Sentence length significantly impacts claim detection performance, with longer sentences more likely to contain verifiable factual claims

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multilingual models trained on translated data perform better than monolingual models on low-resource languages for claim detection.
- **Mechanism:** Training XLM-RoBERTa on multilingual data (including low-resource languages) improves its ability to detect claims across languages without relying on translation steps.
- **Core assumption:** Multilingual models can capture cross-lingual patterns in claim-worthy language better than models trained only on English.
- **Evidence anchors:**
  - [abstract] "special focus is placed on multilingual models capable of processing posts in both English and low-resource languages such as Arabic, Bulgarian, Dutch, Polish, Czech, and Slovak."
  - [section] "training xlm across multiple languages improves accuracy in downstream tasks" (Conneau et al., 2020)
  - [corpus] Weak - corpus only shows related claim detection work, no direct multilingual performance evidence.
- **Break condition:** If the multilingual model overfits to high-resource languages or the low-resource languages have insufficient training data.

### Mechanism 2
- **Claim:** Multi-label models can simultaneously detect both check-worthy factual claims and harmful content with sufficient accuracy.
- **Mechanism:** Using a single XLM-RoBERTa-base model with sigmoid output layer enables joint learning of both claim types, reducing inference time and complexity.
- **Core assumption:** The features useful for detecting claims overlap significantly with those for detecting harmful content.
- **Evidence anchors:**
  - [abstract] "development of multi-label multilingual classification models that can simultaneously detect harmful posts and posts that contain verifiable factual claims"
  - [section] "multi-label XLM-RoBERTa-base model does not achieve the best results for all the tested metrics, nevertheless, for the verifiable factual claims detection task, the model accuracy achieved the highest grade and the recall above 0.8 points"
  - [corpus] Weak - corpus mentions claim detection but not multi-label harm detection specifically.
- **Break condition:** If the tasks are too dissimilar, the shared model may underperform compared to specialized single-label models.

### Mechanism 3
- **Claim:** Sentence length is a significant predictor for claim detection performance, with longer sentences more likely to contain verifiable factual claims.
- **Mechanism:** The model learns that longer sentences statistically contain more verifiable factual claims, leading to higher prediction scores for longer inputs.
- **Core assumption:** Verifiable factual claims tend to be more complex and require more words to express than non-claims.
- **Evidence anchors:**
  - [section] "the length of the sentence has a significant impact on the model prediction score and longer sentences are sentences that are more likely to contain verifiable factual claims"
  - [section] "the highest recall was obtained for the group of the longest sentences and there is significant discrepancy (6 points) between the shortest and the longest group of sentences"
  - [corpus] Weak - corpus mentions claim detection but not sentence length analysis.
- **Break condition:** If the dataset contains many short verifiable claims or the model overfits to sentence length patterns that don't generalize.

## Foundational Learning

- **Concept:** Multilingual transformer architectures (XLM-RoBERTa)
  - Why needed here: The task requires processing social media posts in multiple languages including low-resource languages where monolingual models would fail.
  - Quick check question: Can XLM-RoBERTa process text in Arabic and Czech without translation?

- **Concept:** Multi-label classification with sigmoid outputs
  - Why needed here: We need to detect both claim-worthy and harmful content simultaneously in a single model.
  - Quick check question: What activation function is used for multi-label outputs versus single-label?

- **Concept:** Dataset balancing and preprocessing for social media text
  - Why needed here: Social media posts contain noise (URLs, hashtags, emoticons) that must be removed for effective model training.
  - Quick check question: Why are posts shorter than 15 characters or longer than 500 characters removed during preprocessing?

## Architecture Onboarding

- **Component map:** Social media post text -> XLM-RoBERTa tokenizer -> XLM-RoBERTa-base with linear output layer -> Two probability scores (claim-worthy, harmful)

- **Critical path:**
  1. Preprocess text (remove noise, filter by length)
  2. Tokenize with XLM-RoBERTa tokenizer
  3. Forward pass through XLM-RoBERTa-base
  4. Apply sigmoid to get probabilities
  5. Calculate BCEWithLogitsLoss
  6. Backpropagate and update weights

- **Design tradeoffs:**
  - XLM-RoBERTa-base vs large: base is faster and uses less memory, slightly lower accuracy
  - Multi-label vs two separate models: single model reduces complexity but may underperform specialized models
  - Translated vs multilingual data: multilingual avoids translation step but may have lower accuracy

- **Failure signatures:**
  - Low recall on low-resource languages: model may be overfitting to high-resource languages
  - High false positives on short sentences: model may be relying too heavily on sentence length
  - Poor harmful claim detection: tasks may be too dissimilar for effective joint learning

- **First 3 experiments:**
  1. Train BERT-large-uncased on English-only translated data (baseline)
  2. Train XLM-RoBERTa-base on multilingual data for claim detection only
  3. Train multi-label XLM-RoBERTa-base on combined claim and harmful data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the multi-label XLM-RoBERTa-base model change when trained on data from non-COVID-19 topics?
- Basis in paper: [explicit] The paper states that the final multi-label model was trained on datasets including non-COVID-19 topics to ensure it can detect claims in other areas.
- Why unresolved: The paper does not provide specific performance metrics for non-COVID-19 topics, only mentioning that the model was trained on such data.
- What evidence would resolve it: Conducting experiments to measure the model's accuracy, recall, and F1-score specifically for non-COVID-19 topics would provide clarity on its performance in these areas.

### Open Question 2
- Question: What is the impact of sentence length on the detection of harmful claims by the multi-label XLM-RoBERTa-base model?
- Basis in paper: [inferred] The paper mentions that longer sentences are more likely to contain verifiable factual claims but does not observe a similar trend for harmful claims.
- Why unresolved: The analysis of sentence length impact on harmful claims detection was inconclusive, with no clear trend observed.
- What evidence would resolve it: Further analysis and experiments focusing on the relationship between sentence length and the detection of harmful claims would help determine if sentence length is a significant factor.

### Open Question 3
- Question: How does the performance of the multi-label XLM-RoBERTa-base model compare to fine-tuned large language models (LLMs) like Alpaca-LoRA, llama-3.1-405b-instruct, and llama-3.1-70b-instruct in detecting harmful claims?
- Basis in paper: [explicit] The paper compares the multi-label XLM-RoBERTa-base model with these LLMs for both verifiable factual claims and harmful claims detection.
- Why unresolved: While the paper provides F1-scores for harmful claims detection, it does not offer a detailed comparison of the models' performance in terms of other metrics like recall and accuracy.
- What evidence would resolve it: Conducting a comprehensive comparison using multiple performance metrics (accuracy, recall, F1-score) would provide a clearer picture of how the multi-label XLM-RoBERTa-base model stacks up against these LLMs in detecting harmful claims.

## Limitations

- Data representation concerns with inherent noise and potential biases in labeling, particularly for low-resource languages
- Generalization limitations for truly unseen languages or domains beyond the studied corpus
- Technical implementation gaps including unspecified hyperparameters and lack of ablation studies on task interdependence

## Confidence

**High confidence:** The mechanism linking multilingual models to improved low-resource language performance is theoretically sound based on established cross-lingual transfer learning principles.

**Medium confidence:** The claim that sentence length predicts claim detection performance is supported by dataset analysis but may not generalize beyond the studied corpus.

**Low confidence:** The assertion that multilingual models eliminate the need for translation steps is not empirically validated against translation-based baselines.

## Next Checks

1. **Controlled baseline comparison:** Implement and evaluate monolingual BERT models on translated data for each target language, directly comparing performance against the multilingual XLM-RoBERTa approach using identical datasets and evaluation metrics.

2. **Sentence length ablation study:** Create stratified subsets of the dataset with controlled sentence lengths (e.g., only sentences 50-100 characters) and evaluate model performance to determine if the length correlation is causal or merely associative.

3. **Cross-lingual generalization test:** Evaluate the trained models on completely unseen low-resource languages (e.g., Swahili, Urdu) to assess true multilingual generalization beyond the training language set, measuring both zero-shot and few-shot transfer performance.