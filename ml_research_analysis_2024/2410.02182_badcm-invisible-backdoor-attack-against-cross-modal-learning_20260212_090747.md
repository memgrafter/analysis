---
ver: rpa2
title: 'BadCM: Invisible Backdoor Attack Against Cross-Modal Learning'
arxiv_id: '2410.02182'
source_url: https://arxiv.org/abs/2410.02182
tags:
- backdoor
- attack
- badcm
- image
- cross-modal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BadCM introduces a novel invisible backdoor attack framework for
  cross-modal learning, addressing the limitations of existing methods in terms of
  generalization and stealthiness. The core idea is to leverage modality-invariant
  components as carriers for trigger patterns, using a cross-modal mining scheme to
  identify critical image patches and specific words.
---

# BadCM: Invisible Backdoor Attack Against Cross-Modal Learning

## Quick Facts
- arXiv ID: 2410.02182
- Source URL: https://arxiv.org/abs/2410.02182
- Authors: Zheng Zhang; Xu Yuan; Lei Zhu; Jingkuan Song; Liqiang Nie
- Reference count: 40
- Primary result: Introduces a novel invisible backdoor attack framework leveraging modality-invariant components for cross-modal learning

## Executive Summary
BadCM presents a novel invisible backdoor attack framework targeting cross-modal learning systems. The core innovation lies in using modality-invariant components as carriers for trigger patterns, enabling attacks that are both effective and imperceptible. By mining these components through a cross-modal mining scheme and applying modality-specific generators, BadCM achieves superior attack success rates while maintaining visual quality and textual fluency. The framework demonstrates strong resistance to existing backdoor defenses and supports multiple attack scenarios including visual-to-linguistic, linguistic-to-visual, and dual-key attacks.

## Method Summary
BadCM operates through a three-phase framework: First, it identifies modality-invariant components using a cross-modal mining scheme based on pre-trained models like CLIP, which extracts regions or words that strongly correlate across modalities. Second, modality-specific generators transform explicit triggers into imperceptible perturbations - for visual modality, adversarial perturbations are added only to identified regions using UNet and PatchGAN architectures; for text, rare words are substituted via synonym replacement within modality-invariant keywords using BERT-based masked language models. Third, poisoned samples are mixed with clean data to train victim models. The framework supports multiple attack scenarios by independently operating on each modality through its invariant components.

## Key Results
- Achieves high attack success rates (ASR) across multiple cross-modal tasks while maintaining benign accuracy
- Demonstrates superior stealthiness compared to state-of-the-art methods with improved PSNR and SSIM metrics for visual attacks
- Shows strong resistance to existing backdoor defenses, maintaining effectiveness even against five advanced defense methods
- Supports versatile attack scenarios including visual-to-linguistic, linguistic-to-visual, and dual-key attacks

## Why This Works (Mechanism)

### Mechanism 1
Modality-invariant components serve as high-quality carriers for trigger patterns, improving attack effectiveness. The cross-modal mining scheme identifies regions/words that strongly correlate across modalities by masking and measuring inter-modal similarity. Triggers embedded in these components are more likely to be captured by the model during training. Core assumption: Cross-modal models prioritize modality-invariant components when bridging semantic gaps, making them ideal trigger locations.

### Mechanism 2
Modality-specific generators transform explicit triggers into imperceptible perturbations, enhancing stealthiness. For visual modality, adversarial perturbations are added only to modality-invariant regions using L2, adversarial, and region constraints. For text, rare words are substituted via synonym replacement within modality-invariant keywords. Core assumption: Adversarial perturbations in high-frequency regions are less perceptible to humans, and synonym substitution can maintain grammatical fluency.

### Mechanism 3
The unified framework generalizes across multiple attack scenarios (V2L, L2V, dual-key) while maintaining high attack success rates. By designing a framework that operates independently on each modality using modality-invariant components, the same methodology applies whether the trigger is visual or textual. Core assumption: Modality-invariant components exist and can be identified for any modality pair, and the same poisoning strategy works regardless of attack direction.

## Foundational Learning

- **Cross-modal learning and modality-invariant components**: Understanding how cross-modal models bridge semantic gaps between modalities is crucial for identifying where to embed triggers effectively. *Quick check*: What are modality-invariant components, and why are they ideal carriers for backdoor triggers in cross-modal learning?

- **Adversarial perturbations and synonym substitution**: These techniques are used to create imperceptible poisoned samples for visual and textual modalities, respectively, ensuring stealthiness. *Quick check*: How do adversarial perturbations and synonym substitution contribute to the invisibility of poisoned samples?

- **Black-box attack settings and surrogate models**: The framework operates without access to victim model internals, relying on pre-trained models (e.g., CLIP) as surrogates to identify modality-invariant components. *Quick check*: Why is using a pre-trained vision-language model as a surrogate important for the black-box setting in BadCM?

## Architecture Onboarding

- **Component map**: Cross-modal mining scheme (CLIP-based surrogate for feature extraction and importance scoring) -> Visual trigger generator (UNet + PatchGAN for adversarial perturbation generation) -> Textual trigger generator (BERT-based masked language model for synonym substitution) -> Victim model training pipeline (combining poisoned and clean samples)

- **Critical path**: 1. Extract modality-invariant components using cross-modal mining scheme, 2. Generate poisoned samples using modality-specific generators, 3. Mix poisoned samples with clean data to form training set, 4. Train victim model and evaluate attack effectiveness

- **Design tradeoffs**: Tradeoff between attack success rate and stealthiness (smaller poisoning regions improve stealthiness but may reduce ASR), choice of surrogate model impacts quality of identified modality-invariant components, synonym substitution must balance semantic preservation with trigger embedding

- **Failure signatures**: Low ASR despite high poisoning rate (modality-invariant components not well-identified or generators not effective), high detection by defenses (perturbations too large or synonym substitution too obvious), degraded benign accuracy (poisoned samples too disruptive to clean data)

- **First 3 experiments**: 1. Verify cross-modal mining scheme identifies truly invariant components by comparing feature similarity with/without masking, 2. Test visual trigger generator on a small dataset to ensure perturbations are imperceptible and maintain semantic similarity, 3. Validate textual trigger generator by checking grammatical fluency and semantic consistency of poisoned text

## Open Questions the Paper Calls Out

### Open Question 1
How do modality-invariant components-based triggers perform against more sophisticated, adaptive defenses specifically designed for cross-modal attacks? The authors note their framework's resistance to five advanced defenses but acknowledge most are adapted from classification tasks and may not be optimal for cross-modal scenarios. This remains unresolved because the paper's defense evaluation relies on adapting existing defenses rather than testing against specialized cross-modal defenses. Empirical results comparing BadCM against novel cross-modal defense methods designed specifically for this threat model would resolve this.

### Open Question 2
Can the cross-modal mining scheme be extended to identify modality-invariant components in more than two modalities, and how would this affect attack effectiveness? The current framework focuses on bimodal data (images and text) with a cross-modal mining scheme designed for two modalities. This remains unresolved because the paper doesn't explore whether the mining approach generalizes to tasks involving more modalities. Comparative studies showing BadCM's performance across unimodal, bimodal, and trimodal attack scenarios would resolve this.

### Open Question 3
What is the relationship between the semantic similarity threshold (starget) in textual trigger generation and the balance between stealthiness and attack success rate? The authors use a default starget of 0.7 but don't systematically explore how varying this parameter affects the trade-off between maintaining grammatical fluency and achieving high attack success. This remains unresolved because the paper treats starget as a fixed hyperparameter without analyzing its sensitivity. A detailed ablation study varying starget across different datasets and attack scenarios would resolve this.

## Limitations
- Reliance on surrogate models (CLIP) introduces uncertainty as feature alignment between surrogate and victim models may not be perfect
- Black-box setting assumes access to clean training data, which may not be feasible in real-world scenarios
- Effectiveness across diverse cross-modal tasks and datasets beyond the tested ones remains unverified

## Confidence

- **High**: The framework's design for leveraging modality-invariant components and the use of modality-specific generators are well-supported by the theoretical framework and experimental results
- **Medium**: The generalization of the framework across multiple attack scenarios is plausible but requires further validation on additional datasets and tasks
- **Low**: The robustness of the framework against adaptive defenses in real-world scenarios is uncertain, as the evaluated defenses may not represent all possible countermeasures

## Next Checks

1. **Cross-Modal Mining Scheme Validation**: Verify the quality of modality-invariant components identified by the cross-modal mining scheme by comparing feature similarity with/without masking across multiple surrogate models (e.g., CLIP, ALIGN, BLIP)

2. **Generator Robustness Testing**: Test the visual and textual trigger generators on a diverse set of datasets (e.g., Flickr30k, RefCOCO) to assess their robustness and generalization across different cross-modal tasks

3. **Defense Resilience Evaluation**: Evaluate the framework's resilience against a broader range of defenses, including adaptive defenses that specifically target modality-invariant components and synonym substitution techniques