---
ver: rpa2
title: 'Neural Surrogate HMC: On Using Neural Likelihoods for Hamiltonian Monte Carlo
  in Simulation-Based Inference'
arxiv_id: '2407.20432'
source_url: https://arxiv.org/abs/2407.20432
tags:
- likelihood
- surrogate
- parameters
- monte
- carlo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of Bayesian inference with MCMC
  methods when the likelihood function is expensive to compute because it requires
  solving a PDE numerically. The authors propose using a neural network surrogate
  likelihood trained on precomputed PDE solutions to enable efficient Hamiltonian
  Monte Carlo sampling.
---

# Neural Surrogate HMC: On Using Neural Likelihoods for Hamiltonian Monte Carlo in Simulation-Based Inference

## Quick Facts
- arXiv ID: 2407.20432
- Source URL: https://arxiv.org/abs/2407.20432
- Reference count: 23
- Primary result: Neural surrogate likelihood enables 10,000x speedup in Bayesian inference with HMC for PDE-based problems

## Executive Summary
This paper addresses the challenge of Bayesian inference with MCMC methods when likelihood functions require expensive numerical PDE solutions. The authors propose using a neural network surrogate likelihood trained on precomputed PDE solutions to enable efficient Hamiltonian Monte Carlo sampling. The approach is demonstrated on heliospheric transport of galactic cosmic rays, achieving 1-2% relative error with 10,000x speedup compared to direct PDE evaluation. The method provides three key advantages: amortizing expensive computations, providing differentiable gradients for HMC, and smoothing over numerical instabilities in the PDE solver.

## Method Summary
The method trains a fully connected neural network (two hidden layers of 256 units with SELU activations) on precomputed PDE solutions to approximate the likelihood function. This surrogate model is then used as the likelihood in HMC sampling with No-U-Turn Sampler and Dual Averaging Step Size Adaptation kernel. The approach leverages the fact that while training the neural network requires solving many PDEs upfront (expensive but parallelizable), inference becomes extremely fast. The neural network provides smooth, differentiable approximations that enable gradient-based HMC sampling where the original PDE-based likelihood is non-differentiable and computationally prohibitive to evaluate repeatedly.

## Key Results
- Neural surrogate achieves 1-2% relative error on test data
- Provides 10,000x speedup compared to direct PDE evaluation
- HMC with surrogate requires 100x fewer likelihood evaluations than RWMH to achieve equivalent sample quality
- Yields state-of-the-art constraints on heliospheric transport parameters with quantified uncertainty

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural surrogate likelihood amortizes expensive PDE computations during MCMC sampling
- Mechanism: By training a neural network on precomputed PDE solutions, the model learns to approximate the likelihood function directly, eliminating the need to solve the PDE repeatedly during sampling
- Core assumption: The neural network can accurately approximate the likelihood function within the parameter domain of interest
- Evidence anchors:
  - [abstract] "amortizing expensive likelihood computations"
  - [section] "This large initial computational cost is embarrassingly parallelizable" - training is expensive but done once, then reused
  - [corpus] Weak - no direct corpus evidence supporting this specific amortization mechanism
- Break condition: If the neural network fails to generalize outside its training domain or cannot achieve sufficient accuracy for the specific application

### Mechanism 2
- Claim: The surrogate likelihood provides differentiable gradients for Hamiltonian Monte Carlo
- Mechanism: The neural network is inherently differentiable, allowing gradient-based HMC to function where the original PDE-based likelihood is non-differentiable
- Core assumption: The neural network's smoothness and differentiability are sufficient to provide meaningful gradients for HMC
- Evidence anchors:
  - [abstract] "providing gradients for Hamiltonian Monte Carlo"
  - [section] "This NN has an inductive bias towards smoothness, can be evaluated quickly at inference time, and is differentiable"
  - [corpus] Weak - no direct corpus evidence supporting this specific gradient mechanism
- Break condition: If the neural network's gradients are too noisy or inaccurate to support effective HMC sampling

### Mechanism 3
- Claim: The neural surrogate smooths over numerical instabilities in the PDE solver
- Mechanism: The neural network's learned function is inherently smoother than the noisy numerical solutions, providing more stable likelihood evaluations
- Core assumption: The training process can effectively learn from both stable and unstable solutions to produce a smooth surrogate
- Evidence anchors:
  - [abstract] "smoothing over noisy simulations resulting from numerical instabilities"
  - [section] "The likelihood function computed by the numerical solver fails a fraction of the time due to numerical instabilities"
  - [corpus] Weak - no direct corpus evidence supporting this specific smoothing mechanism
- Break condition: If numerical instabilities are too severe or systematic for the neural network to learn a reliable smooth approximation

## Foundational Learning

- Bayesian inference with MCMC: Why needed here: The paper addresses the fundamental problem of Bayesian inference when likelihood computations are prohibitively expensive. Quick check question: What are the three main advantages the neural surrogate provides over direct PDE likelihood computation?
- Hamiltonian Monte Carlo: Why needed here: HMC requires differentiable likelihoods and is more efficient than random-walk methods when gradients are available. Quick check question: Why does the original PDE-based likelihood make HMC infeasible?
- Neural network regression: Why needed here: The surrogate likelihood is implemented as a neural network trained on PDE solution data. Quick check question: What are the key architectural choices for the surrogate network in this application?

## Architecture Onboarding

- Component map: Prior distribution -> HMC sampler -> Neural network surrogate likelihood -> PDE solver (for training data only) -> Observed data
- Critical path: Sampling parameters -> Neural network inference -> Likelihood calculation -> HMC acceptance/rejection
- Design tradeoffs: Accuracy vs speed in the neural surrogate, training data size vs computational cost, prior domain restriction vs exploration capability
- Failure signatures: Poor HMC mixing (suggests gradient issues), high rejection rates (suggests accuracy problems), sampling outside training domain (suggests prior issues)
- First 3 experiments:
  1. Train neural surrogate with reduced training data to establish minimum viable dataset size
  2. Compare HMC vs RWMH sampling with surrogate likelihood to verify gradient benefits
  3. Test neural network accuracy across the full parameter domain to identify potential extrapolation failures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the generalization performance of the neural network surrogate when extrapolating beyond the training domain?
- Basis in paper: [explicit] The paper states that the neural network is trained on data from a limited domain of parameter space and should not be expected to generalize well outside this domain. A prior distribution is used to prevent HMC from sampling outside the "trusted" domain.
- Why unresolved: While the paper uses a prior to prevent sampling outside the training domain, it does not provide empirical evidence of how well the neural network surrogate would perform if extrapolation were necessary or accidentally occurred.
- What evidence would resolve it: Additional experiments testing the neural network surrogate's predictions on parameter values outside the training domain, with quantitative metrics of performance degradation.

### Open Question 2
- Question: How sensitive is the HMC sampling efficiency to the choice of neural network architecture and training procedure?
- Basis in paper: [inferred] The paper describes using a specific neural network architecture (fully connected with two hidden layers of 256 units each and SELU activations) and training procedure, but does not explore how sensitive the results are to these choices.
- Why unresolved: The paper presents results using one specific neural network setup but does not investigate whether alternative architectures or training procedures would yield better or worse performance for this application.
- What evidence would resolve it: Systematic experiments comparing HMC sampling efficiency (e.g., autocorrelation, effective sample size) across different neural network architectures, activation functions, and training hyperparameters.

### Open Question 3
- Question: What is the computational overhead of training the neural network surrogate compared to the total computational cost savings during inference?
- Basis in paper: [explicit] The paper mentions that the neural network is trained on a grid of 10^6 likelihood evaluations and provides a 10,000x speedup during inference, but does not discuss the relative cost of the training phase.
- Why unresolved: While the paper quantifies the speedup during inference, it does not provide a comprehensive cost-benefit analysis that includes the upfront computational cost of training the neural network surrogate.
- What evidence would resolve it: A detailed comparison of the total computational cost (training + inference) of the neural network surrogate approach versus direct PDE evaluation across multiple experiments.

## Limitations
- The 10,000x speedup claim relies heavily on amortized training costs but lacks direct comparison metrics across different problem scales
- Neural network surrogate accuracy degrades outside training domain bounds, creating implicit posterior constraints
- No comparison with alternative surrogate modeling approaches (e.g., Gaussian processes, polynomial chaos)

## Confidence

- **High Confidence**: The amortization mechanism for expensive likelihood computations, the use of neural network gradients for HMC, and the general methodology framework
- **Medium Confidence**: The specific 10,000x speedup claim and the smoothing effect over numerical instabilities (limited validation details provided)
- **Low Confidence**: The claim about achieving state-of-the-art constraints on heliospheric transport parameters (no baseline comparisons provided)

## Next Checks

1. **Domain Extrapolation Test**: Systematically evaluate neural surrogate accuracy as parameters approach and exceed training domain bounds to quantify degradation and establish safe operational limits
2. **Cross-Problem Applicability**: Apply the same methodology to a different PDE-based inference problem (e.g., climate modeling or epidemiology) to test generalizability
3. **Alternative Surrogate Comparison**: Implement and compare against at least one alternative surrogate modeling approach (Gaussian processes or polynomial chaos) to benchmark the neural network performance trade-offs