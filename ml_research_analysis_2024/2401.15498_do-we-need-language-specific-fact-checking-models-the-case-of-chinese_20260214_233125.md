---
ver: rpa2
title: Do We Need Language-Specific Fact-Checking Models? The Case of Chinese
arxiv_id: '2401.15498'
source_url: https://arxiv.org/abs/2401.15498
tags:
- evidence
- chinese
- dataset
- chef
- fact-checking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates the need for language-specific fact-checking
  models, particularly for Chinese, by highlighting the limitations of translation-based
  approaches and multilingual large language models (LLMs) such as GPT-4. The authors
  propose a Chinese fact-checking system that incorporates document-level evidence
  retrieval, significantly outperforming translation-based methods and multilingual
  LLMs.
---

# Do We Need Language-Specific Fact-Checking Models? The Case of Chinese

## Quick Facts
- arXiv ID: 2401.15498
- Source URL: https://arxiv.org/abs/2401.15498
- Authors: Caiqi Zhang; Zhijiang Guo; Andreas Vlachos
- Reference count: 16
- Primary result: Chinese fact-checking system with document-level evidence retrieval outperforms translation-based methods and multilingual LLMs by 10% in accuracy and Macro F1

## Executive Summary
This study investigates whether language-specific fact-checking models are necessary by focusing on Chinese, a language with unique linguistic characteristics. The authors demonstrate that translation-based approaches and multilingual large language models like GPT-4 underperform compared to a Chinese-specific system that incorporates document-level evidence retrieval. An innovative adversarial dataset is constructed to identify token-level biases, where instances have high word overlap but opposite veracity labels. The proposed method shows 10% improvement over baselines while being more robust to linguistic biases, establishing a strong case for language-specific approaches in fact-checking.

## Method Summary
The authors propose a Chinese fact-checking system that uses document-level evidence retrieval rather than sentence-level or claim-only approaches. They construct an adversarial dataset from the CHEF dataset where instances have large word overlap but opposite veracity labels to identify token-level biases. The system incorporates both lexical and semantic matching for evidence retrieval, followed by a classification model that makes veracity predictions based on the retrieved evidence. Performance is compared against translation-based baselines and multilingual LLMs like GPT-4, with additional experiments on robustness to identified biases.

## Key Results
- Proposed Chinese fact-checking system outperforms translation-based methods and multilingual LLMs by 10% in both accuracy and Macro F1 score
- Document-level evidence retrieval significantly improves performance compared to sentence-level or claim-only approaches
- Adversarial dataset experiments show the proposed method is more robust to token-level biases, with improved performance on instances designed to trigger these biases

## Why This Works (Mechanism)
The study demonstrates that Chinese has unique linguistic characteristics that make language-specific approaches necessary. Document-level evidence retrieval captures broader context that is particularly important for Chinese fact-checking, where meaning can be distributed across longer text spans. The adversarial dataset construction reveals specific token-level biases that multilingual models fail to handle properly, suggesting that language-specific training helps models learn to navigate these linguistic nuances rather than relying on spurious correlations.

## Foundational Learning
- **Document-level evidence retrieval**: Needed to capture context distributed across longer text spans in Chinese; quick check: compare performance of sentence-level vs document-level retrieval on same dataset
- **Adversarial dataset construction**: Required to identify and measure model robustness to token-level biases; quick check: verify that instances with high word overlap have similar predicted probabilities before and after bias mitigation
- **Multilingual vs monolingual model comparison**: Essential to establish performance gaps; quick check: ensure consistent evaluation metrics across all model types
- **Lexical and semantic matching**: Important for comprehensive evidence retrieval in Chinese; quick check: measure recall@K for both matching strategies separately

## Architecture Onboarding

**Component map**: Claim -> Evidence Retrieval (lexical + semantic) -> Classification -> Veracity Prediction

**Critical path**: The most important components are the document-level evidence retrieval system and the classification model that uses retrieved evidence. The adversarial dataset construction serves as a diagnostic tool rather than part of the operational pipeline.

**Design tradeoffs**: Document-level retrieval provides better context but increases computational cost and may introduce noise. The choice between lexical and semantic matching involves a precision-recall tradeoff. Using adversarial datasets for training could improve robustness but requires careful construction to avoid introducing new biases.

**Failure signatures**: Poor performance on adversarial instances indicates vulnerability to token-level biases. Large performance gaps between translation-based and native approaches suggest fundamental architectural limitations. Degradation on out-of-domain data would indicate overfitting to specific linguistic patterns.

**First experiments**:
1. Compare document-level vs sentence-level evidence retrieval performance on held-out test set
2. Evaluate model performance on the adversarial dataset to measure bias robustness
3. Test translation-based baseline with professional human translation vs automatic translation

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Focus on a single language (Chinese) limits generalizability to other languages with different linguistic structures
- The study doesn't fully explain why translation-based approaches and multilingual LLMs underperform beyond demonstrating the performance gap
- Adversarial dataset construction may not capture all types of linguistic and factual biases present in real-world scenarios

## Confidence
- Language-specific fact-checking models are necessary for Chinese: High
- Findings generalize to other languages: Medium
- Document-level evidence retrieval is superior: High (within Chinese context), Medium (cross-linguistic)
- Identified token-level biases are universal phenomena: Medium

## Next Checks
1. Test the proposed Chinese fact-checking system on out-of-domain datasets to assess generalization beyond the specific corpus used in the study
2. Conduct a comparative analysis with domain-specific multilingual models trained on fact-checking data to determine if specialized multilingual training can bridge the performance gap
3. Evaluate the adversarial dataset construction methodology on other languages to verify whether the identified token-level biases are language-specific or universal phenomena