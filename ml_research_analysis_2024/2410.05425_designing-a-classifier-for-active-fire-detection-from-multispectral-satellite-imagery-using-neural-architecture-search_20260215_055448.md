---
ver: rpa2
title: Designing a Classifier for Active Fire Detection from Multispectral Satellite
  Imagery Using Neural Architecture Search
arxiv_id: '2410.05425'
source_url: https://arxiv.org/abs/2410.05425
tags:
- neural
- learning
- network
- search
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We developed a reinforcement learning-based neural architecture
  search system to design small, power-efficient neural networks for active fire detection
  from multispectral satellite imagery. The system uses a performance prediction model
  as a reward function to evaluate neural network architectures without training them
  to completion.
---

# Designing a Classifier for Active Fire Detection from Multispectral Satellite Imagery Using Neural Architecture Search

## Quick Facts
- **arXiv ID**: 2410.05425
- **Source URL**: https://arxiv.org/abs/2410.05425
- **Authors**: Amber Cassimon; Phil Reiter; Siegfried Mercelis; Kevin Mets
- **Reference count**: 40
- **One-line primary result**: Reinforcement learning-based NAS system designs small, power-efficient neural networks achieving 99.88% F1 score for active fire detection from multispectral satellite imagery

## Executive Summary
This paper presents a neural architecture search (NAS) system that automatically designs compact neural networks for active fire detection from multispectral satellite imagery. The system uses reinforcement learning with a performance prediction model as a reward function, enabling efficient exploration of the architectural space without requiring full training of each candidate network. The approach is specifically designed for power-constrained environments like nanosatellites, balancing classification accuracy with computational efficiency. The best architecture discovered contains only 1,716 parameters while achieving 99.88% F1 score after quantization, demonstrating the viability of on-board processing for multispectral satellite imagery.

## Method Summary
The authors develop a reinforcement learning-based NAS system that searches for neural network architectures optimized for active fire detection from multispectral satellite imagery. The system uses a performance prediction model to estimate post-quantization F1 scores from architectural features, serving as a reward function for the RL agent. The search space includes directed acyclic graphs with up to 8 nodes and 10 possible operations including linear, convolutional, pooling, and spectral attention layers. The utility function combines predicted F1 score and parameter count to balance accuracy with power efficiency. The best architecture is deployed on a Google Coral Micro Dev Board using TensorFlow Lite for inference.

## Key Results
- Best architecture: 1,716 trainable parameters, achieves median post-quantization F1 score of 99.88%
- Inference latency: 984μs on Google Coral Micro Dev Board
- Power consumption: approximately 800mW during deployment
- System demonstrates viability of on-board processing for multispectral satellite imagery in power-constrained environments

## Why This Works (Mechanism)

### Mechanism 1: Performance Prediction Model as Reward Function
The RL agent iteratively samples architectures, evaluates them using a performance prediction model as reward, and selects architectures that balance high classification accuracy with low computational cost. The prediction model estimates post-quantization F1 scores without requiring full training, allowing efficient exploration of the architectural space. This approach is computationally feasible because training small networks for the predictor is relatively inexpensive.

### Mechanism 2: Search Space Design for Efficiency
The search space includes diverse operations (linear, convolution, attention) that enable discovery of efficient architectures exploiting spectral locality. By including both linear and non-linear operations, the system can find architectures that maintain parameter efficiency while achieving high accuracy for the fire detection task.

### Mechanism 3: Balancing Accuracy and Efficiency
The utility function linearly combines post-quantization F1 score and parameter count, allowing the RL agent to optimize for both classification performance and computational efficiency simultaneously. This approach ensures the designed networks are both accurate and suitable for deployment on power-constrained hardware.

## Foundational Learning

- **Concept**: Neural Architecture Search (NAS) and reinforcement learning
  - Why needed here: The paper uses RL-based NAS to automatically design neural networks for fire detection from satellite imagery
  - Quick check question: What is the difference between macro and micro search spaces in NAS?

- **Concept**: Post-training quantization and its impact on model performance
  - Why needed here: The designed networks must be quantized to INT8 precision for deployment on power-constrained hardware
  - Quick check question: How does quantization affect the F1 score of a trained neural network?

- **Concept**: Multispectral image processing and feature engineering
  - Why needed here: The input data consists of multispectral satellite imagery requiring preprocessing and feature extraction
  - Quick check question: What are NDVI, NBR, and AFD indices, and how are they computed from multispectral data?

## Architecture Onboarding

- **Component map**: Data collection → Performance predictor training → RL agent training → Architecture selection → Model training → Deployment
- **Critical path**: Performance data collection → Performance predictor training → RL agent training → Architecture selection → Model training → Deployment
- **Design tradeoffs**: Search space size vs. exploration efficiency; Prediction accuracy vs. computational cost; Parameter count vs. accuracy
- **Failure signatures**: Poor prediction accuracy → RL agent optimizes for wrong objectives; Overfitting → Poor generalization; Hardware incompatibility → Model cannot be deployed
- **First 3 experiments**: 
  1. Verify performance prediction model accuracy on held-out test set
  2. Test RL agent on small subset of search space
  3. Deploy simple architecture on target hardware

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the proposed NAS system perform when applied to different multispectral satellite datasets with varying spectral band configurations and spatial resolutions?
- **Open Question 2**: What is the impact of using a linear utility function versus a more sophisticated utility function that accounts for the costs of false positives versus false negatives in wildfire detection?
- **Open Question 3**: How does the performance of the GNN-based performance predictor compare to other predictor types when using more sophisticated graph features or alternative neural network architectures?

## Limitations

- The work relies heavily on internal experimental validation without extensive comparison to established NAS baselines or independent replication
- The performance prediction model's accuracy may not generalize well to architectures outside the training distribution
- The assumption that parameter count directly correlates with power consumption is validated only empirically for the specific Google Coral device

## Confidence

- **High Confidence**: The mathematical framework of using reinforcement learning for NAS, the methodology of combining F1 score and parameter count as utility function, and technical implementation details
- **Medium Confidence**: The effectiveness of the performance prediction model in guiding the search process, and the generalization of the designed architectures to unseen data
- **Low Confidence**: The absolute performance metrics without comparison to traditional hand-designed architectures for the same task, and the scalability of the approach to more complex remote sensing tasks

## Next Checks

1. Deploy the designed architecture on multiple different edge devices (e.g., NVIDIA Jetson Nano, Intel Neural Compute Stick) to verify that parameter count remains a reliable proxy for power consumption across platforms
2. Compare the NAS-designed architecture against standard architectures (MobileNet, EfficientNet) fine-tuned for the same fire detection task, measuring both classification performance and power consumption on the target hardware
3. Systematically test the performance prediction model with edge-case architectures to identify potential adversarial samples that could cause prediction failures or reward hacking