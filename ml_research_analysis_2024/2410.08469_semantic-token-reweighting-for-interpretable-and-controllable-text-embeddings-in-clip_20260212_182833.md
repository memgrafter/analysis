---
ver: rpa2
title: Semantic Token Reweighting for Interpretable and Controllable Text Embeddings
  in CLIP
arxiv_id: '2410.08469'
source_url: https://arxiv.org/abs/2410.08469
tags:
- text
- image
- weights
- clip
- stori
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces SToRI (Semantic Token Reweighting for Interpretable\
  \ text embeddings), a framework that adjusts the importance of textual elements\
  \ during CLIP\u2019s text encoding process by assigning weights to semantic tokens.\
  \ This allows differential emphasis on tokens based on contextual importance, enabling\
  \ finer control over text embeddings for vision tasks."
---

# Semantic Token Reweighting for Interpretable and Controllable Text Embeddings in CLIP

## Quick Facts
- arXiv ID: 2410.08469
- Source URL: https://arxiv.org/abs/2410.08469
- Reference count: 32
- One-line primary result: Introduces SToRI, a framework that adjusts semantic token importance in CLIP's text encoding for interpretable and controllable vision tasks

## Executive Summary
This paper introduces SToRI (Semantic Token Reweighting for Interpretable text embeddings), a framework that enhances CLIP's text encoding by differentially weighting semantic tokens based on contextual importance. SToRI offers two control modes: data-driven, where token weights are learned to optimize text embeddings for image classification with interpretability, and user-driven, where users manually adjust weights for custom text emphasis in retrieval tasks. Experimental results demonstrate that SToRI improves few-shot image classification performance to levels comparable with state-of-the-art methods while maintaining interpretability, and enables controllable, preference-based image retrieval through weight adjustments.

## Method Summary
SToRI modifies CLIP's text encoder by applying token weights to attention scores, starting from the 7th transformer block. The framework supports two control modes: data-driven, where weights are trained using cross-entropy loss to optimize text embeddings for few-shot classification; and user-driven, where users manually assign weights to tokens for preference-based retrieval. The method preserves interpretability by manipulating token weights within the existing text context without requiring full model fine-tuning or embedding decomposition. SToRI is evaluated across multiple vision datasets including ImageNet, DTD, SUN397, Flowers102, Caltech101, Food101 for classification, and CelebA and CUB for retrieval tasks.

## Key Results
- SToRI achieves few-shot classification accuracy competitive with state-of-the-art methods while providing interpretable token weights
- User-driven weight control enables controllable image retrieval with measurable improvements in attribute-based retrieval curves
- The framework maintains interpretability by allowing inspection of learned token weights that reflect class-discriminative features

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Semantic token reweighting modifies the attention scores in CLIP's text encoder by scaling individual token weights, thereby controlling their influence on the final text embedding.
- **Mechanism:** The framework multiplies each token's weight to the attention values computed during self-attention, amplifying or reducing the contribution of each token. This adjustment is applied from a specific block onward in the transformer layers, ensuring that subsequent blocks inherit the modified attention distribution.
- **Core assumption:** Attention scores are linearly combinable with scalar weights, and scaling attention preserves the overall structure while modulating importance.
- **Evidence anchors:**
  - [abstract]: "SToRI refines the text encoding process in CLIP by differentially weighting semantic elements based on contextual importance, enabling finer control over emphasis responsive to data-driven insights and user preferences."
  - [section 3.1]: "we directly multiply the weights {wi}N i=1 to amplify original attention values proportionally."
  - [corpus]: Weak—corpus papers focus on CLIP extensions but do not directly discuss attention reweighting.
- **Break condition:** If attention scaling is applied too early (e.g., block 1), the effects may destabilize; if applied too late, semantic influence may be minimal. The paper finds block 7 as a sweet spot.

### Mechanism 2
- **Claim:** Data-driven control enables interpretability by learning token weights that reflect the distinguishing semantic features of image classes in the training data.
- **Mechanism:** During few-shot classification, the framework trains only the token weights using cross-entropy loss, allowing the weights to highlight the most class-discriminative tokens. This optimization occurs within the interpretable token space, ensuring the resulting text embeddings can be traced back to specific semantic elements.
- **Core assumption:** The CLIP model's pre-trained attention mechanism is sufficiently flexible to accommodate learned weight scaling without degrading general semantic understanding.
- **Evidence anchors:**
  - [abstract]: "data-driven control—training weights to optimize text embeddings for image classification with interpretability."
  - [section 3.2]: "weights are trained using Eq. (3), where ϕT is obtained with ˆai,j, allowing only {wi}N i=1 to be updated."
  - [corpus]: No direct corpus support; this is a novel training scheme within CLIP.
- **Break condition:** If the dataset is too small or the text prompts are too generic, the learned weights may not capture meaningful distinctions, reducing interpretability.

### Mechanism 3
- **Claim:** User-driven control enables controllable retrieval by allowing manual adjustment of token weights to prioritize or deprioritize specific attributes in the retrieved images.
- **Mechanism:** Users assign scalar weights to tokens corresponding to attributes, which are then used to modulate the text embedding. Higher weights increase the likelihood of retrieving images with those attributes, while lower weights decrease it. The metric AUC on retrieval curves quantifies this control.
- **Core assumption:** The CLIP similarity space is responsive to semantic emphasis shifts induced by token reweighting, and retrieval order reflects the adjusted semantic priorities.
- **Evidence anchors:**
  - [abstract]: "user-driven control—allowing users to set weights for custom text emphasis in retrieval tasks."
  - [section 4.2]: "We generate a line plot illustrating the proportion of images retrieved for each attribute combination up to then-th retrieved image... and calculate the Area Under the Curve (AUC) for each plotted curve."
  - [corpus]: Weak—related papers discuss CLIP retrieval but not controllable token reweighting.
- **Break condition:** If the CLIP model's vision encoder is biased toward certain attributes, manual weight control may not fully override this bias.

## Foundational Learning

- **Concept:** Self-attention mechanism in transformers
  - **Why needed here:** Understanding how tokens interact through attention is critical to grasp how reweighting modulates semantic emphasis.
  - **Quick check question:** In the attention formula, what role does the softmax over QKT play in determining token influence?
- **Concept:** Cross-modal embedding alignment (CLIP)
  - **Why needed here:** The method relies on CLIP's shared embedding space to map weighted text embeddings to corresponding image embeddings for retrieval/classification.
  - **Quick check question:** How does CLIP ensure that text and image embeddings coexist in the same semantic space?
- **Concept:** Few-shot learning and prompt tuning
  - **Why needed here:** The framework is evaluated in few-shot classification settings, requiring understanding of how text prompts are adapted for new classes with limited data.
  - **Quick check question:** Why does CoOp use continuous prompt tuning instead of fixed text prompts in few-shot learning?

## Architecture Onboarding

- **Component map:**
  Input text prompt → Tokenizer → Token embeddings + positional embeddings → Transformer blocks (with reweighting from block 7) → Weighted attention scores → Text embedding (EOS token) → Similarity computation with image embeddings.
- **Critical path:**
  Text input → Tokenizer → Transformer → Weighted attention → Text embedding → (for retrieval) Sort by similarity; (for classification) Compute logits via similarity to class embeddings.
- **Design tradeoffs:**
  Early reweighting (block 1) may overly distort attention and destabilize training; late reweighting (block 11) may have minimal effect. Block 7 is chosen empirically.
  Training only weights preserves interpretability but may limit performance gains compared to full fine-tuning.
  Manual weight control offers flexibility but requires user expertise to set effective weights.
- **Failure signatures:**
  If weights are all set to zero, attention collapses and the embedding becomes meaningless.
  If weights are extremely high, embeddings may saturate and lose nuanced semantic relationships.
  In few-shot settings, if the text prompts are too generic, learned weights may not capture class-specific semantics.
- **First 3 experiments:**
  1. Apply SToRI to a simple CLIP retrieval task (e.g., CelebA) and manually adjust weights to confirm attribute emphasis.
  2. Train weights on a small few-shot classification dataset (e.g., DTD) and analyze learned weights for interpretability.
  3. Compare retrieval performance with and without reweighting on a controlled attribute combination to validate the AUC metric.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SToRI's performance compare when applied to image encoders versus text encoders?
- Basis in paper: [inferred] The paper states "Our method of reweighting text prompt tokens during text encoding can similarly be applied to image encoding" and suggests this could allow emphasis on specific image regions.
- Why unresolved: The paper focuses entirely on text encoding applications and does not provide experimental results for image encoder reweighting.
- What evidence would resolve it: Empirical results comparing SToRI's effectiveness when applied to image versus text encoders across the same tasks and datasets.

### Open Question 2
- Question: What is the impact of SToRI on bias and fairness in vision-language models?
- Basis in paper: [explicit] The paper acknowledges that if CLIP is biased towards attributes targeted for reweighting, this may affect related attributes, and suggests using less biased CLIP models or designing mitigating text prompts.
- Why unresolved: The paper does not investigate whether SToRI amplifies, mitigates, or has no effect on existing biases in CLIP models.
- What evidence would resolve it: Controlled experiments measuring bias metrics (e.g., demographic parity, equalized odds) with and without SToRI across diverse datasets and attributes.

### Open Question 3
- Question: How does SToRI's interpretability compare to other interpretable vision-language approaches like concept activation vectors (CAVs)?
- Basis in paper: [explicit] The paper contrasts SToRI with methods like STAIR (which fine-tunes CLIP for sparse representations) and Bhalla et al.'s approach (which decomposes embeddings into conceptual text embeddings), stating SToRI "ensures interpretability by manipulating token weighting within a given description's context, without the need for model fine-tuning or embedding decomposition."
- Why unresolved: The paper does not provide quantitative or qualitative comparisons of interpretability between SToRI and alternative methods.
- What evidence would resolve it: Human studies or automated metrics comparing the clarity, consistency, and usefulness of explanations generated by SToRI versus other interpretable approaches.

## Limitations
- Performance heavily depends on prompt quality with no clear methodology for prompt crafting
- Empirical choice of block 7 for reweighting lacks theoretical justification
- Interpretability claims rely on assumption that learned weights correlate with semantic importance without direct human validation
- Framework's scalability to longer text sequences or more complex vision tasks remains unexplored

## Confidence

- **Data-driven interpretability (High confidence):** The mechanism of training token weights to optimize classification performance is well-defined and the results show consistent improvements over baseline CLIP in few-shot settings. The interpretability claim is supported by the ability to inspect learned weights, though human validation is limited.

- **User-driven controllability (Medium confidence):** The retrieval experiments demonstrate that manual weight adjustments can influence retrieval results as measured by AUC, but the qualitative impact on user experience and the practical utility of this control for real-world applications is not fully explored.

- **Performance gains (Medium confidence):** While SToRI shows competitive results compared to state-of-the-art methods in few-shot classification, the improvements are incremental rather than transformative. The comparison is limited to a specific set of baselines and datasets.

## Next Checks

1. **Human Interpretability Validation:** Conduct a user study where human annotators are shown the learned token weights and asked to interpret their semantic meaning. Measure the correlation between human interpretations and the model's classification decisions to validate the interpretability claims.

2. **Ablation on Reweighting Block Position:** Systematically test the effect of applying token reweighting at different transformer blocks (e.g., blocks 1, 4, 7, 10, 12) on both classification accuracy and retrieval performance. Analyze the stability and effectiveness of each position to justify the choice of block 7.

3. **Robustness to Prompt Quality:** Evaluate SToRI's performance using a range of prompt qualities, from highly specific and informative to generic and vague. Measure the impact of prompt quality on both the learned weights (in data-driven mode) and the effectiveness of manual weight control (in user-driven mode). This would test the framework's sensitivity to one of its key dependencies.