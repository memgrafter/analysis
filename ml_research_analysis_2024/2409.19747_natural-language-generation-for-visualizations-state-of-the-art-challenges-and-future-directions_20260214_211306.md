---
ver: rpa2
title: 'Natural Language Generation for Visualizations: State of the Art, Challenges
  and Future Directions'
arxiv_id: '2409.19747'
source_url: https://arxiv.org/abs/2409.19747
tags:
- data
- chart
- visualization
- visualizations
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper surveys the state of the art in natural language generation
  (NLG) for visualizations, addressing the problem of automatically creating natural
  language descriptions for charts and data-driven stories. The authors introduce
  a taxonomy of NLG tasks for visualizations based on five Wh-questions: why (tasks
  and applications), what (inputs and outputs), how (methods), where (text placement),
  and when (temporal organization).'
---

# Natural Language Generation for Visualizations: State of the Art, Challenges and Future Directions

## Quick Facts
- arXiv ID: 2409.19747
- Source URL: https://arxiv.org/abs/2409.19747
- Reference count: 40
- Key outcome: This survey systematically categorizes NLG for visualizations using a five Wh-questions framework and identifies key challenges including improving model generalizability, developing diverse benchmark datasets, and enhancing accessibility for diverse user groups.

## Executive Summary
This survey provides a comprehensive overview of natural language generation (NLG) for visualizations, addressing the challenge of automatically creating natural language descriptions for charts and data-driven stories. The authors introduce a taxonomy based on five Wh-questions (why, what, how, where, when) to systematically characterize the problem space and existing solutions. The paper surveys current approaches including chart summarization, question answering, and data storytelling, while highlighting key research gaps and future directions such as improving model generalizability, developing diverse benchmark datasets, and incorporating human-in-the-loop approaches.

## Method Summary
The survey methodology involves a systematic literature review of NLG for visualizations, categorizing existing work according to a five-dimensional framework. The authors analyze research papers across multiple dimensions including task types (chart summarization, question answering, data storytelling), input/output modalities (charts, tables, text), technical approaches (rule-based, deep learning, LLMs), text placement strategies, and temporal organization. The survey synthesizes findings from 40+ references published primarily between 2020-2023, focusing on recent advances in deep learning and multimodal processing for chart understanding and NLG.

## Key Results
- A five Wh-questions framework (why, what, how, where, when) provides a systematic taxonomy for characterizing NLG tasks for visualizations
- Deep learning models, particularly vision-language transformers, have enabled more sophisticated processing of multimodal inputs and generation of semantically rich textual outputs
- Current NLG systems face significant challenges in generalizability, benchmark dataset diversity, and incorporation of human feedback during generation
- The field lacks comprehensive evaluation metrics and diverse benchmark datasets covering various chart types and semantic levels

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The five Wh-questions framework systematically decomposes the NLG for visualization problem into manageable, interrelated dimensions, enabling structured analysis of existing work and identification of research gaps.
- **Mechanism**: By posing "why," "what," "how," "where," and "when" questions, the authors create a taxonomy that captures the full scope of NLG tasks for visualizations. This allows researchers to categorize solutions, understand dependencies between dimensions, and pinpoint underexplored areas.
- **Core assumption**: The five Wh-questions are sufficient to characterize the problem space and that each dimension meaningfully contributes to understanding NLG for visualizations.
- **Evidence anchors**:
  - [abstract] "To characterize the NLG problem and the design space of proposed solutions, we pose five Wh-questions..."
  - [section] The detailed breakdown of each dimension (e.g., "why" covers tasks like chart summarization, "what" covers input/output modalities, etc.)
- **Break condition**: If a new dimension emerges that cannot be captured by the existing five Wh-questions, or if the interdependencies between dimensions are not well understood, the framework may become incomplete.

### Mechanism 2
- **Claim**: The integration of deep learning models, particularly vision-language transformers, enables effective processing of multimodal inputs (charts, tables, text) and generation of semantically rich textual outputs.
- **Mechanism**: Deep learning models like VL-T5 and GPT-based architectures can process both visual and textual information simultaneously, extracting features from charts and generating captions that cover multiple semantic levels (Level 1-4 as defined by Lundgard and Satyanarayan). This allows for more nuanced and contextually aware NLG outputs.
- **Core assumption**: Large-scale training data with diverse chart types and rich semantic annotations is available to fine-tune these models effectively.
- **Evidence anchors**:
  - [section] "Recent works have mostly focused on generating more higher level of summaries or captions, exemplified by the the works of [TBS23, KLL∗22, RHAF∗23]."
  - [section] "VisText [TBS23] applied a bottom-up feature extractor based on FasterRCNN [AHB ∗18] which was originally used for image captioning and fed the features to the VL-T5 model."
- **Break condition**: If the available training data lacks diversity in chart types, visual styles, or semantic richness, the models may not generalize well to real-world scenarios.

### Mechanism 3
- **Claim**: Human-in-the-loop approaches can significantly improve the quality and relevance of NLG outputs by allowing users to provide feedback and iteratively refine the generated results.
- **Mechanism**: By incorporating user feedback during the generation process, NLG systems can better align with user needs and preferences. This can involve selecting specific chart segments for focused captioning, refining narrative structures, or correcting factual errors.
- **Core assumption**: Users are willing and able to provide meaningful feedback, and the system can effectively incorporate this feedback to improve outputs.
- **Evidence anchors**:
  - [section] "In the future, a human-in-the-loop approach that enables users to provide feedback through text and direct manipulation could fulfill their information needs more effectively."
  - [section] "A recent study revealed that users generally prefer visualizations with substantial text annotations over those with only text or fewer annotations in visualizations [SSC ∗22]."
- **Break condition**: If user feedback is too sparse, inconsistent, or difficult to incorporate into the generation process, the benefits of human-in-the-loop approaches may be limited.

## Foundational Learning

- **Concept**: Multimodal processing (combining visual and textual data)
  - Why needed here: NLG for visualizations requires understanding both the visual content of charts and the textual context to generate meaningful descriptions.
  - Quick check question: Can you explain the difference between using OCR alone versus combining OCR with deep learning features for chart data extraction?

- **Concept**: Semantic levels in chart summarization (Levels 1-4)
  - Why needed here: Understanding the different semantic levels helps in evaluating the richness and depth of generated chart captions and summaries.
  - Quick check question: What is the key difference between Level 2 and Level 3 summaries in terms of the complexity of insights they capture?

- **Concept**: Vision-language models (e.g., VL-T5, CLIP)
  - Why needed here: These models are crucial for processing charts (visual data) and generating textual descriptions, bridging the gap between visual and linguistic understanding.
  - Quick check question: How does a vision-language model like VL-T5 differ from a traditional CNN-LSTM architecture for image captioning?

## Architecture Onboarding

- **Component map**: Input Processing (OCR, computer vision, data table parsing) -> Core NLG Engine (VL-T5, GPT variants, rule-based systems) -> Output Processing (text generation, visualization annotation) -> Human-in-the-loop Interface (feedback mechanisms)
- **Critical path**: Input Processing → Core NLG Engine → Output Processing. The quality of input processing (especially chart data extraction) significantly impacts the downstream NLG quality.
- **Design tradeoffs**:
  - Accuracy vs. Speed: More sophisticated computer vision techniques may improve accuracy but increase processing time.
  - Generalization vs. Specificity: Models trained on diverse data may generalize better but may not capture domain-specific nuances as well as specialized models.
  - Automation vs. Control: Fully automated systems are easier to deploy but may lack the flexibility of human-in-the-loop approaches.
- **Failure signatures**:
  - Poor chart data extraction leading to factually incorrect summaries.
  - Hallucinations where the model generates information not present in the chart.
  - Lack of semantic richness in generated captions, focusing only on basic statistical information.
  - Inability to handle less common chart types or complex visual layouts.
- **First 3 experiments**:
  1. Evaluate the accuracy of chart data extraction using OCR vs. deep learning-based methods on a small set of diverse charts.
  2. Compare the semantic richness of captions generated by rule-based vs. deep learning models on a benchmark dataset.
  3. Implement a simple human-in-the-loop interface for refining chart summaries and measure the impact on user satisfaction and output quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop more diverse and comprehensive benchmark datasets for NLG tasks with visualizations that cover a wider range of chart types, visual styles, and rich semantic annotations?
- Basis in paper: [explicit] The paper discusses the lack of benchmark datasets with diverse chart types and rich semantic content in the "What?" section, noting that current datasets are limited in terms of chart types and semantic levels.
- Why unresolved: Existing datasets lack variety in chart types and the types of semantic contents in the captions. More real-world data and human-written summaries covering diverse semantic contents are needed.
- What evidence would resolve it: Creation of benchmark datasets sourced from real-world data with a broader spectrum of chart types, visual styles, and rich semantic annotations.

### Open Question 2
- Question: How can we improve the generalizability of NLG models for visualizations to handle a wide range of chart-related tasks beyond fine-tuning specific models?
- Basis in paper: [explicit] The paper discusses the challenge of improving model generalizability in the "Open Challenges and Future Directions" section, noting that task-specific models are not capable of solving a wide range of chart-related tasks.
- Why unresolved: Current models are fine-tuned on specific tasks and lack the ability to generalize to new tasks. More diverse training data and advanced vision-language models are needed.
- What evidence would resolve it: Development of instruction tuning methods and large vision-language models that can perform various NLG tasks with visualizations without further fine-tuning.

### Open Question 3
- Question: How can we effectively incorporate human-in-the-loop approaches to refine NLG outputs for visualizations and improve accuracy and user trust?
- Basis in paper: [explicit] The paper discusses the potential of human-in-the-loop approaches in the "Open Challenges and Future Directions" section, noting that most NLG methods generate outputs without user input during generation stages.
- Why unresolved: Current NLG methods lack user interaction during the generation process, making it difficult for users to refine outputs that do not match their information needs.
- What evidence would resolve it: Implementation of interactive NLG systems that allow users to provide feedback through text and direct manipulation to refine generated outputs.

## Limitations
- The five Wh-questions framework may not capture emerging dimensions as the field evolves, particularly around interactive and real-time NLG scenarios
- The survey relies heavily on recent literature (2020-2023), which may not fully represent the historical development of rule-based approaches or long-term trends
- Evidence for some mechanisms comes from relatively few primary sources, particularly regarding human-in-the-loop approaches and accessibility improvements

## Confidence
- High confidence in the taxonomy framework and its utility for organizing the research space
- Medium confidence in claims about deep learning effectiveness due to limited comparative studies
- Medium confidence in human-in-the-loop benefits due to sparse empirical evidence

## Next Checks
1. Replicate the chart data extraction accuracy comparison (OCR vs. deep learning) on a newly collected, diverse chart dataset to verify the survey's observations about current limitations.
2. Conduct a systematic comparison of semantic richness across different NLG approaches (rule-based, CNN-LSTM, transformer-based) using the four-level framework to validate the survey's categorization of current capabilities.
3. Design and implement a small-scale user study testing human-in-the-loop refinement of chart summaries to empirically measure the claimed benefits for output quality and user satisfaction.