---
ver: rpa2
title: Interactive Counterfactual Generation for Univariate Time Series
arxiv_id: '2408.10633'
source_url: https://arxiv.org/abs/2408.10633
tags:
- time
- series
- data
- counterfactual
- activations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents an interactive methodology for generating counterfactual
  explanations for univariate time series classification using deep learning models.
  The core method leverages 2D projections (UMAP) combined with decision boundary
  maps and inverse projection techniques to visualize time series, activations, and
  attributions.
---

# Interactive Counterfactual Generation for Univariate Time Series

## Quick Facts
- arXiv ID: 2408.10633
- Source URL: https://arxiv.org/abs/2408.10633
- Reference count: 26
- Conv1D ResNet achieved 89.33% test accuracy on ECG5000

## Executive Summary
This paper presents an interactive methodology for generating counterfactual explanations for univariate time series classification using deep learning models. The approach combines 2D projections (UMAP) with decision boundary maps and inverse projection techniques to visualize time series, activations, and attributions. Users can interactively manipulate projected data points through drag-and-drop operations, enabling intuitive exploration of how changes affect model predictions. The method was validated on the ECG5000 benchmark dataset and demonstrates significant improvements in interpretability by allowing users to explore model decisions through counterfactual scenarios.

## Method Summary
The method leverages UMAP projections of time series data, activations, and attributions, combined with decision boundary maps (DBMs) to create interactive visualizations. Users can drag points in the projected space, triggering inverse projection to generate new time series, which are then fed back to the model for re-prediction. The system includes linked visualizations showing raw time series, activation patterns, and attribution importance across multiple semantic levels. The approach uses a Conv1D ResNet architecture trained on ECG5000 data, with DeepLIFT attributions and gradient-based inverse projection techniques to reconstruct plausible counterfactual time series from altered 2D positions.

## Key Results
- Interactive counterfactual generation achieved 89.33% test accuracy on ECG5000 benchmark
- Decision boundary maps provide clear visualization of model decision regions across data, activation, and attribution levels
- Inverse projection techniques successfully reconstruct plausible time series from manipulated 2D positions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Interactive dragging in UMAP-projected space enables intuitive counterfactual generation by preserving local neighborhood relationships.
- Mechanism: UMAP maintains local structure in lower dimensions, so dragging points maintains temporal coherence. Inverse projection then reconstructs plausible time series from altered 2D positions.
- Core assumption: Local neighborhood preservation in UMAP projections is sufficient to maintain temporal plausibility when inverse projecting.
- Evidence anchors:
  - [abstract] "Our application includes interactive line plots, allowing users to dynamically modify time points of time series data, thereby enabling the creation of contrastive explanations in counterfactual scenarios."
  - [section] "Dragging a point offers updates in the scatter and line plots, including the model's re-prediction for the adjusted data point with an innovative feature that allows for the inverse projection of a dragged point into a region without other data points"
  - [corpus] Weak - corpus papers focus on counterfactual generation but don't specifically address UMAP's role in maintaining plausibility during interactive dragging.
- Break condition: If the dragged point moves too far from its original neighborhood, the inverse projection generates implausible time series that don't preserve temporal patterns.

### Mechanism 2
- Claim: Decision Boundary Maps (DBMs) provide visual feedback on model decision regions, enabling users to understand prediction boundaries and generate targeted counterfactuals.
- Mechanism: DBMs show probability-weighted class distributions across the projected space, allowing users to identify decision boundaries and manipulate points across class regions.
- Core assumption: The decision boundary visualization accurately represents the model's internal decision regions in the projected space.
- Evidence anchors:
  - [abstract] "The application simplifies the time series data analysis by enabling users to interactively manipulate projected data points, providing intuitive insights through inverse projection techniques."
  - [section] "The backdrop of this visualization features a decision map, employing a dense pixel approach as described by Rodrigues et al. [14]. This technique ensures that each pixel or region within the map reflects the model's decision for the data projected onto that specific area."
  - [corpus] Missing - corpus papers don't discuss decision boundary visualization techniques.
- Break condition: If the projection distorts decision boundaries (common in UMAP), users may generate counterfactuals that don't reflect actual model behavior.

### Mechanism 3
- Claim: Multi-level visualization (data, activations, attributions) provides comprehensive understanding of model decisions by showing how different semantic levels relate to each other.
- Mechanism: Users can see how changes in raw time series affect intermediate activations and attribution patterns, revealing the model's internal reasoning process.
- Core assumption: The relationships between time series data, activations, and attributions are preserved through the projection and visualization pipeline.
- Evidence anchors:
  - [abstract] "Our application includes interactive line plots, allowing you to dynamically modify time points of time series data, thereby enabling the creation of contrastive explanations in counterfactual scenarios."
  - [section] "These maps clearly define the model's decision boundaries at multiple levels - data, activations, and attributions - offering a comprehensive insight into internal processes."
  - [corpus] Weak - corpus papers mention attribution-based explanations but don't specifically discuss multi-level semantic visualization.
- Break condition: If the projection technique fails to preserve relationships between semantic levels, users cannot accurately trace how input changes propagate through the model.

## Foundational Learning

- Concept: UMAP projection and inverse projection capabilities
  - Why needed here: UMAP provides both dimensionality reduction for visualization and inverse projection for counterfactual generation, which is unique among projection techniques.
  - Quick check question: What makes UMAP different from other projection techniques like PCA or t-SNE for this application?

- Concept: Activation maximization for inverse projection from activation space
  - Why needed here: When generating counterfactuals from activation space, we need to reconstruct time series that produce specific activation patterns.
  - Quick check question: How does activation maximization differ from standard gradient descent optimization in this context?

- Concept: Attribution techniques (DeepLIFT) for feature importance visualization
  - Why needed here: Attributions show which time points most influence model predictions, enabling targeted counterfactual generation.
  - Quick check question: Why might DeepLIFT be preferred over simpler attribution methods like saliency maps for time series data?

## Architecture Onboarding

- Component map:
  - Preprocessing pipeline: Data loading → Model training → Activation/attribution extraction → UMAP projection → DBM generation
  - Interactive visualization: 3 scatter plots (data/activations/attributions) + 2 line plots (multi-line + single-line) + linked interactions
  - Counterfactual generation: Drag interactions → Inverse projection → Model re-prediction → Visualization updates

- Critical path: User drags point → Inverse projection generates new time series → Model predicts new class → DBM and line plots update → User observes decision boundary crossing

- Design tradeoffs: UMAP vs other projections (preserves local structure but may distort global relationships), interactive dragging vs automated generation (user control vs computational efficiency)

- Failure signatures: Implausible time series generation, slow inverse projection computation, unclear decision boundaries in DBMs, loss of semantic relationships across visualization levels

- First 3 experiments:
  1. Load ECG5000 dataset, train Conv1D ResNet, extract activations/attributions, generate UMAP projections, verify basic visualization functionality
  2. Test inverse projection from data space by clicking on empty scatter plot regions, verify generated time series plausibility
  3. Test interactive dragging functionality, verify model re-prediction and decision boundary crossing visualization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the method perform when scaling to multivariate time series data?
- Basis in paper: [explicit] "Future work will explore the scalability of this method to multivariate time series data..."
- Why unresolved: The paper only demonstrates the approach on univariate time series data (ECG5000 dataset) and explicitly states that future work will explore multivariate data.
- What evidence would resolve it: Empirical testing of the method on multivariate datasets showing performance metrics, visualization quality, and user comprehension compared to the univariate case.

### Open Question 2
- Question: How do alternative inverse projection techniques (like iNN) compare to UMAP in terms of counterfactual plausibility and reconstruction quality?
- Basis in paper: [explicit] "To mitigate this, we suggest the incorporation of more deterministic methods, such as inverse Neural Network projections (iNN)..."
- Why unresolved: The paper only uses UMAP for inverse projection and suggests iNN as a future improvement without empirical comparison.
- What evidence would resolve it: Comparative studies measuring counterfactual plausibility scores, reconstruction error rates, and user preference between UMAP and iNN approaches.

### Open Question 3
- Question: What is the optimal color space design for decision boundary maps that improves interpretability across different models and datasets?
- Basis in paper: [explicit] "Another factor is the color space used to generate the background for the DBM... Changing the color space in a more focused way to something with a larger variety of colors..."
- Why unresolved: The paper identifies this as a limitation but doesn't provide systematic evaluation of color space alternatives.
- What evidence would resolve it: User studies comparing different color mapping strategies with quantitative measures of decision boundary distinction and qualitative assessments of user understanding.

## Limitations
- Unknown UMAP parameters and attribution technique details make exact reproduction challenging
- Inverse projection may generate implausible time series when points are dragged far from original neighborhoods
- Decision boundary visualization accuracy is uncertain due to potential UMAP projection distortions

## Confidence
- Medium confidence due to unspecified implementation details and reliance on inverse projection quality

## Next Checks
1. Verify UMAP projection preserves local structure by testing neighborhood preservation metrics
2. Validate inverse projection plausibility by measuring reconstruction error against original time series
3. Test decision boundary map accuracy by comparing predicted boundaries with actual model predictions