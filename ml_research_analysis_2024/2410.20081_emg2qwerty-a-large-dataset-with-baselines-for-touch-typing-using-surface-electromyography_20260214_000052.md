---
ver: rpa2
title: 'emg2qwerty: A Large Dataset with Baselines for Touch Typing using Surface
  Electromyography'
arxiv_id: '2410.20081'
source_url: https://arxiv.org/abs/2410.20081
tags:
- semg
- data
- dataset
- each
- typing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces emg2qwerty, a large-scale dataset of surface
  electromyography (sEMG) signals recorded at the wrists while touch typing on a QWERTY
  keyboard, together with ground-truth annotations and reproducible baselines. The
  dataset comprises 1,135 sessions spanning 108 users and 346 hours of recording,
  making it the largest public sEMG dataset to date.
---

# emg2qwerty: A Large Dataset with Baselines for Touch Typing using Surface Electromyography

## Quick Facts
- arXiv ID: 2410.20081
- Source URL: https://arxiv.org/abs/2410.20081
- Reference count: 31
- Large-scale sEMG dataset with 1,135 sessions, 108 users, 346 hours of recording; best personalized model achieves 6.95% CER

## Executive Summary
This paper introduces emg2qwerty, a large-scale dataset of surface electromyography (sEMG) signals recorded at the wrists while touch typing on a QWERTY keyboard, together with ground-truth annotations and reproducible baselines. The dataset comprises 1,135 sessions spanning 108 users and 346 hours of recording, making it the largest public sEMG dataset to date. Applying standard modeling techniques from Automatic Speech Recognition (ASR), the paper shows strong baseline performance on predicting key-presses using sEMG signals alone. The best personalized model achieves a character error rate (CER) of 6.95% on test data, demonstrating the feasibility of practical and scalable neuromotor interfaces. The dataset and code are publicly accessible, aiming to facilitate progress in machine learning and neuroscientific research.

## Method Summary
The paper introduces a large-scale dataset of surface electromyography (sEMG) signals recorded from wrist-worn sensors during touch typing, along with ground-truth keylogger data. The dataset contains 1,135 sessions from 108 users, totaling 346 hours of recording. The task is framed as an Automatic Speech Recognition (ASR) problem, where continuous sEMG signals are transcribed into sequences of characters. Baseline models use Time-Depth Separable (TDS) convolutional networks with CTC loss, trained on spectral features (log-scaled spectrograms) extracted from the sEMG signals. Data augmentation techniques (SpecAugment, electrode rotation, temporal jitter) and a 6-gram character-level language model are employed to improve performance. The best personalized model achieves a character error rate (CER) of 6.95% on test data.

## Key Results
- emg2qwerty dataset contains 1,135 sessions spanning 108 users and 346 hours of sEMG recordings
- Personalized models achieve 6.95% CER on test data, demonstrating practical viability
- Unpersonalized models show over 50% CER, indicating significant domain shift across users
- Spectral features outperform time-domain rectification, validating preprocessing approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Surface electromyography (sEMG) can be used to predict individual keystrokes with high accuracy by leveraging the rich temporal and spatial patterns of motor unit activity.
- Mechanism: sEMG signals capture the electrical activity of muscle fibers innervated by individual motor neurons. Each key press involves a specific combination of muscle activations in the forearm and hand, creating a unique sEMG signature. These signatures can be modeled using machine learning techniques similar to those used in Automatic Speech Recognition (ASR), where continuous high-dimensional signals are mapped to discrete outputs (characters instead of phonemes).
- Core assumption: The sEMG signal generated by a keystroke is sufficiently distinct and reproducible across sessions and users to allow for accurate classification.
- Evidence anchors:
  - [abstract]: "Applying standard modeling techniques from the closely related field of Automatic Speech Recognition (ASR), we show strong baseline performance on predicting key-presses using sEMG signals alone."
  - [section]: "These data demonstrate non-trivial, but well defined hierarchical relationships both in terms of the generative process, from neurons to muscles and muscle combinations..."
- Break condition: If the sEMG signal-to-noise ratio is too low, or if individual motor unit activity cannot be reliably detected, the classification accuracy will degrade significantly.

### Mechanism 2
- Claim: Domain shift across users and sessions is a major challenge in sEMG-based typing, but can be mitigated through personalization and data augmentation techniques.
- Mechanism: Variations in anatomy, physiology, and typing behavior across users lead to different sEMG patterns for the same keystrokes. Similarly, changes in band placement between sessions introduce variability in the recorded signals. Personalization (fine-tuning models on user-specific data) and data augmentation (e.g., electrode rotation, temporal jitter) help models adapt to these variations and improve generalization.
- Core assumption: The sEMG signal patterns are consistent enough within a user across sessions to allow for effective personalization, and that data augmentation can simulate the variability introduced by domain shift.
- Evidence anchors:
  - [abstract]: "These data demonstrate non-trivial, but well defined hierarchical relationships both in terms of the generative process, from neurons to muscles and muscle combinations, as well as in terms of domain shift across users and user sessions."
  - [section]: "The unpersonalized performance on a new user in our benchmark is over 50% character error rate... indicating that the model cannot successfully transcribe the majority of keystrokes without some labeled data from the user."
- Break condition: If the domain shift is too large (e.g., due to significant anatomical differences), personalization may not be sufficient to achieve good performance, and more sophisticated domain adaptation techniques may be required.

### Mechanism 3
- Claim: Spectral features derived from sEMG signals are more effective than raw time-domain signals for keystroke prediction, and can be efficiently processed using Time Depth Separable (TDS) convolutions.
- Mechanism: sEMG signals contain both low-frequency motor unit activity and high-frequency noise. Spectral features (e.g., log-scaled spectrogram) can filter out noise and highlight the relevant frequency components associated with muscle activation patterns. TDS convolutions allow for efficient processing of these features with a large receptive field, capturing the co-articulation effects where the sEMG signal for a keystroke is influenced by preceding and following keystrokes.
- Core assumption: The spectral characteristics of sEMG signals contain discriminative information for keystroke prediction, and that TDS convolutions are well-suited for capturing the temporal dependencies in these features.
- Evidence anchors:
  - [abstract]: "Spectral features outperformed rectification of the time domain signal, which is a standard preprocessing method for sEMG."
  - [section]: "We adopt Time Depth Separable ConvNets (TDS) developed by Hannun et al. (2019) for the ASR domain. The parameter-efficiency of TDS convolutions allows for wider receptive fields which have proven important in emg2qwerty modeling."
- Break condition: If the spectral features do not capture the relevant information for keystroke prediction, or if the TDS convolutions are not able to effectively model the temporal dependencies, the performance will degrade.

## Foundational Learning

- Concept: Electromyography (EMG) and motor unit physiology
  - Why needed here: Understanding the biological basis of sEMG signals is crucial for interpreting the data and designing effective machine learning models. Knowledge of motor unit recruitment, muscle anatomy, and the relationship between neural activity and muscle contraction is essential for understanding the strengths and limitations of sEMG-based interfaces.
  - Quick check question: What is a motor unit, and how does its activity relate to the sEMG signal recorded at the skin surface?

- Concept: Automatic Speech Recognition (ASR) and sequence modeling
  - Why needed here: The task of predicting keystrokes from sEMG is analogous to ASR, where continuous signals are mapped to discrete outputs. Familiarity with ASR techniques, such as connectionist temporal classification (CTC), sequence-to-sequence models, and language models, is essential for understanding and implementing the baseline models presented in the paper.
  - Quick check question: How does CTC loss address the alignment problem in sequence modeling tasks like ASR and sEMG-based typing?

- Concept: Domain adaptation and personalization in machine learning
  - Why needed here: sEMG-based typing interfaces need to generalize across users with different anatomies and physiologies. Understanding techniques for domain adaptation, such as fine-tuning, data augmentation, and transfer learning, is crucial for building models that can adapt to individual users and improve performance.
  - Quick check question: What are the key challenges in adapting a model trained on one user's data to perform well on another user's data in the context of sEMG-based typing?

## Architecture Onboarding

- Component map: Data preprocessing (high-pass filtering, spectral feature extraction, batch normalization) -> Data augmentation (SpecAugment, electrode rotation, temporal alignment jitter) -> Model (Rotation-Invariance modules -> TDS convolutions) -> CTC loss -> Language model and decoding (character-level n-gram language model, backspace-aware beam search decoder)
- Critical path:
  1. Load sEMG data and ground-truth keylogger sequences
  2. Preprocess sEMG data (high-pass filter, extract spectral features)
  3. Apply data augmentation (SpecAugment, electrode rotation, temporal jitter)
  4. Feed spectral features into model (Rotation-Invariance modules -> TDS convolutions)
  5. Compute CTC loss and update model parameters
  6. At test time, use language model and decoder to generate final predictions
- Design tradeoffs:
  - Receptive field length: Longer receptive fields can capture more context but may also learn implicit language models and increase computational cost
  - Spectral feature parameters: Choice of frequency cutoffs, window size, and hop length can affect the discriminative power of the features
  - Data augmentation strength: Stronger augmentation can improve generalization but may also introduce noise and slow down training
- Failure signatures:
  - High character error rate (CER) on test data: Could indicate overfitting, insufficient data, or poor model architecture/hyperparameters
  - Large gap between validation and test CER: Could indicate overfitting to the validation set or domain shift between validation and test data
  - Slow convergence or unstable training: Could indicate poor learning rate, insufficient data augmentation, or noisy labels
- First 3 experiments:
  1. Train a baseline model with default hyperparameters on the training set and evaluate on the validation set to establish a performance baseline
  2. Experiment with different receptive field lengths (e.g., 0.5s, 1s, 2s) to find the optimal balance between context and computational cost
  3. Compare the performance of spectral features vs. raw time-domain features to quantify the benefit of spectral preprocessing

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but the limitations section implies several areas for future research, including the need for more diverse user populations, exploration of non-QWERTY layouts, and investigation of real-world deployment scenarios.

## Limitations
- Dataset limited to QWERTY touch typists, excluding non-touch typists and users with diverse anatomies
- Evaluation focused on controlled typing conditions, not real-world scenarios without physical keyboards
- Limited exploration of data efficiency for personalization and alternative personalization strategies

## Confidence
- High: The dataset construction methodology, baseline model architecture, and core experimental results (personalized CER of 6.95%) are well-documented and reproducible. The analogy to ASR and the use of CTC loss are established techniques.
- Medium: The effectiveness of specific data augmentation techniques and the relative contribution of different architectural components (e.g., Rotation-Invariance modules, TDS convolutions) are demonstrated but not exhaustively validated.
- Low: Claims about generalizability to non-QWERTY layouts or real-world deployment scenarios are not directly tested, as the evaluation is limited to controlled typing conditions.

## Next Checks
1. **Inter-user Domain Adaptation**: Conduct experiments to quantify the effectiveness of domain adaptation techniques (e.g., adversarial training, meta-learning) in reducing the performance gap between personalized and unpersonalized models across users.
2. **Speed-Dependent Performance**: Evaluate model performance across different typing speeds to identify potential degradation in accuracy at higher speeds and investigate the relationship between sEMG signal quality and typing dynamics.
3. **Cross-Layout Generalization**: Test the trained models on non-QWERTY keyboard layouts (e.g., Dvorak, AZERTY) to assess the degree of layout-specific learning and the potential for zero-shot transfer or minimal fine-tuning requirements.