---
ver: rpa2
title: 'Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs
  Under Compression'
arxiv_id: '2403.15447'
source_url: https://arxiv.org/abs/2403.15447
tags:
- llms
- quantization
- compression
- trustworthiness
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the trustworthiness of compressed LLMs
  across eight critical dimensions, comparing quantization and pruning methods at
  varying compression rates. The authors find that quantization outperforms pruning
  in maintaining trustworthiness, with 4-bit quantization matching the original model's
  trustworthiness while achieving significant efficiency gains.
---

# Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression

## Quick Facts
- arXiv ID: 2403.15447
- Source URL: https://arxiv.org/abs/2403.15447
- Reference count: 40
- This paper investigates the trustworthiness of compressed LLMs across eight critical dimensions, comparing quantization and pruning methods at varying compression rates.

## Executive Summary
This paper systematically examines how compression techniques affect the trustworthiness of large language models across eight critical dimensions. The authors compare quantization and pruning methods at different compression rates using the Llama-2-7B architecture. Their findings reveal that 4-bit quantization can maintain trustworthiness while achieving significant efficiency gains, and surprisingly, moderate quantization can improve certain trustworthiness dimensions like ethics and fairness compared to the original model.

## Method Summary
The study evaluates compressed LLMs across eight trustworthiness dimensions using a comprehensive experimental framework. The authors compare quantization and pruning methods at various compression ratios, specifically examining 3-bit and 4-bit quantization as well as different pruning levels. They use the Llama-2-7B architecture as their primary test case and employ standardized benchmarks to measure trustworthiness across multiple dimensions. The evaluation framework is designed to assess how compression affects not just model efficiency but also reliability, safety, and ethical behavior.

## Key Results
- 4-bit quantization maintains trustworthiness at levels comparable to the original model while achieving significant efficiency gains
- Moderate quantization (4-bit) unexpectedly improves certain trustworthiness dimensions like ethics and fairness
- Extreme quantization (3-bit) significantly reduces trustworthiness across multiple dimensions
- Quantization outperforms pruning in maintaining trustworthiness across most evaluation metrics

## Why This Works (Mechanism)
The improved trustworthiness under moderate quantization appears to stem from the regularization effect that quantization imposes on the model's weight space. By constraining weights to discrete values, quantization may reduce overfitting to spurious correlations in the training data, leading to more robust and generalizable behavior. The 4-bit precision appears to strike an optimal balance between computational efficiency and preserving the semantic richness needed for trustworthy responses. The deterioration at 3-bit suggests that below this threshold, critical information loss occurs that affects the model's reasoning capabilities and ethical judgment.

## Foundational Learning
- **Model Compression Trade-offs**: Understanding how different compression methods affect both efficiency and model behavior is crucial for practical deployment. Quick check: Compare FLOP reduction vs. accuracy drop curves.
- **Trustworthiness Dimensions**: The paper evaluates eight distinct aspects of trustworthiness including safety, fairness, and ethics. Quick check: Map each dimension to relevant benchmark datasets.
- **Quantization Precision Impact**: Different bit-widths have dramatically different effects on model performance and trustworthiness. Quick check: Plot trustworthiness vs. quantization bits curve.
- **Pruning vs. Quantization**: These two compression methods affect model behavior differently. Quick check: Compare weight distributions before/after each method.
- **Generalization Under Compression**: Compressed models must maintain performance across diverse inputs. Quick check: Evaluate on out-of-distribution test sets.
- **Efficiency-Trustworthiness Balance**: Finding the sweet spot between computational savings and model reliability. Quick check: Calculate Pareto frontier of efficiency vs. trustworthiness metrics.

## Architecture Onboarding
**Component Map**: Input -> Quantization/Pruning Module -> Compressed LLM -> Trustworthiness Evaluation Framework -> Multiple Trustworthiness Metrics

**Critical Path**: The evaluation pipeline processes compressed models through eight trustworthiness tests, with each test representing a critical validation point. The most sensitive path appears to be the ethics and fairness evaluations, which show the most dramatic changes under compression.

**Design Tradeoffs**: The study balances between extreme compression (maximal efficiency) and maintaining trustworthiness. The 4-bit quantization represents the optimal tradeoff point where efficiency gains are substantial but trustworthiness is preserved.

**Failure Signatures**: Extreme quantization (3-bit) leads to significant degradation across all trustworthiness dimensions, particularly in safety and ethical reasoning. Pruning shows more localized failures, often affecting specific trustworthiness aspects while preserving others.

**Three First Experiments**:
1. Run the original Llama-2-7B model through all eight trustworthiness tests to establish baseline performance
2. Apply 4-bit quantization and compare all trustworthiness metrics against the baseline
3. Apply 3-bit quantization and identify which trustworthiness dimensions degrade most severely

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- The evaluation is constrained to the Llama-2-7B architecture, limiting generalizability across different model families and sizes
- The comparison between quantization and pruning methods is limited to specific compression ratios tested
- The unexpected improvements in ethics and fairness under moderate quantization require further investigation to understand underlying mechanisms

## Confidence
- High confidence: The finding that 4-bit quantization maintains trustworthiness while achieving efficiency gains is well-supported by the experimental data
- Medium confidence: The superiority of quantization over pruning for trustworthiness is demonstrated but may vary with different model architectures and compression methods
- Medium confidence: The unexpected improvements in certain trustworthiness dimensions under moderate quantization are observed but not fully explained

## Next Checks
1. Replicate the experiments across multiple LLM architectures (e.g., GPT, Mistral) and sizes to validate generalizability
2. Conduct ablation studies to isolate which specific trustworthiness dimensions are most affected by different compression levels and methods
3. Test the compressed models on real-world deployment scenarios to validate practical utility beyond benchmark performance