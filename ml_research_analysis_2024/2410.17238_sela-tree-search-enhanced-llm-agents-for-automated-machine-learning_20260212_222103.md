---
ver: rpa2
title: 'SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning'
arxiv_id: '2410.17238'
source_url: https://arxiv.org/abs/2410.17238
tags:
- score
- search
- machine
- sela
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SELA integrates Monte Carlo Tree Search with LLM agents to automate
  machine learning by iteratively exploring and refining solutions. It conceptualizes
  the search space as a tree, where each path represents a potential experiment configuration.
---

# SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning

## Quick Facts
- arXiv ID: 2410.17238
- Source URL: https://arxiv.org/abs/2410.17238
- Reference count: 40
- Primary result: 65-80% win rate against baselines on 20 datasets

## Executive Summary
SELA is a novel framework that combines Monte Carlo Tree Search (MCTS) with LLM agents to automate machine learning pipeline construction. The system conceptualizes the search space as a tree where each path represents a potential experiment configuration, enabling intelligent, iterative refinement of solutions. By balancing exploration and exploitation, SELA can navigate the complex solution space more effectively than traditional single-pass generation approaches.

The framework integrates insight generation, tree search, and experiment execution components to produce diverse, optimized machine learning pipelines. Evaluated on 20 diverse datasets from AutoML Benchmark and Kaggle, SELA demonstrates superior performance compared to both traditional AutoML methods and agent-based approaches, achieving significant improvements in normalized scores across classification and regression tasks.

## Method Summary
SELA integrates Monte Carlo Tree Search with LLM agents to automate machine learning by iteratively exploring and refining solutions. The framework conceptualizes the search space as a tree, where each path represents a potential experiment configuration. SELA employs a depth-preferred UCT-DP selection strategy in MCTS to balance exploration and exploitation, encouraging deeper exploration of diverse pipeline configurations. The system uses stage-wise planning with code reuse at the stage level to improve efficiency and consistency across experiments. Each rollout involves selection, expansion, simulation, and backpropagation, allowing the system to learn from experimental feedback and gradually improve pipeline configurations over multiple iterations.

## Key Results
- Achieved 65-80% win rate against baselines (AutoGluon, AutoSklearn, AIDE, Data Interpreter) on 20 datasets
- Demonstrated superior performance on both classification (13 datasets) and regression (7 datasets) tasks
- Showed effectiveness of iterative refinement approach compared to single-pass generation methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SELA improves pipeline diversity by balancing exploration and exploitation in the tree search process.
- Mechanism: The framework uses MCTS with a depth-preferred selection strategy (UCT-DP) that prioritizes deeper nodes early, encouraging exploration of diverse pipeline configurations while exploiting high-performing ones through backpropagation.
- Core assumption: Early exploration of deeper nodes leads to better overall solutions by discovering non-obvious pipeline configurations that shallow exploration might miss.
- Evidence anchors:
  - [abstract] "enables agents to conduct experiments intelligently and iteratively refine their strategies, facilitating a more effective exploration of the machine learning solution space"
  - [section] "we employ Monte Carlo Tree Search (MCTS) as the core decision-making engine, leveraging its ability to balance exploration (testing new strategies) and exploitation (improving known good strategies)"
  - [corpus] Weak evidence - the related papers focus on different aspects of LLM agents and AutoML, but don't specifically address the exploration-exploitation balance in tree search for ML pipelines.
- Break condition: If the depth-preferred strategy consistently selects suboptimal paths, or if the backpropagation fails to properly update node values based on experimental feedback.

### Mechanism 2
- Claim: SELA achieves higher performance by iteratively refining solutions through multiple rollouts rather than single-pass generation.
- Mechanism: Each rollout involves selection, expansion, simulation, and backpropagation, allowing the system to learn from experimental feedback and gradually improve the pipeline configuration over time.
- Core assumption: Multiple iterative refinements with feedback will converge to better solutions than a single generation attempt, even if that attempt uses a sophisticated LLM.
- Evidence anchors:
  - [abstract] "iteratively refine their strategies, facilitating a more effective exploration of the machine learning solution space"
  - [section] "By iterating through this cycle of experimentation and refinement, SELA incrementally improves its solutions, much like an expert who tests and improves its strategy based on continuous feedback"
  - [corpus] Explicit - "I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search" directly addresses similar iterative refinement approaches.
- Break condition: If the number of rollouts is insufficient to find good solutions, or if the experimental feedback is noisy or misleading.

### Mechanism 3
- Claim: SELA's stage-wise planning with code reuse improves efficiency and consistency across experiments.
- Mechanism: The framework caches code at the stage level for each attempted configuration, allowing reuse when new configurations share components, reducing token usage and addressing LLM non-determinism.
- Core assumption: Reusing previously generated code for similar pipeline stages will produce more consistent results and reduce computational overhead compared to regenerating code from scratch each time.
- Evidence anchors:
  - [section] "To boost experimentation efficiency and reduce token usage, SELA implements fine-grained code reuse by caching code at the stage level for each attempted configuration c"
  - [section] "This approach effectively conserves resources while maintaining robust performance across stages"
  - [corpus] Weak evidence - the related papers don't explicitly discuss code reuse strategies in the context of LLM-based AutoML systems.
- Break condition: If the cached code becomes outdated or incompatible with new configurations, or if the code reuse mechanism introduces errors that compound across iterations.

## Foundational Learning

- Concept: Monte Carlo Tree Search (MCTS) algorithm
  - Why needed here: SELA uses MCTS as its core search mechanism to navigate the pipeline configuration space efficiently
  - Quick check question: What are the four main steps of the MCTS algorithm and how does SELA modify the selection step for ML experiments?

- Concept: Tree-structured representation of search spaces
  - Why needed here: SELA conceptualizes the machine learning pipeline configuration as a tree where each path represents a potential experiment configuration
  - Quick check question: How does SELA represent different stages of the ML pipeline in the tree structure, and what attributes does each node contain?

- Concept: Upper Confidence Bound for Trees (UCT) algorithm
  - Why needed here: SELA uses a modified UCT algorithm (UCT-DP) for node selection in the tree search
  - Quick check question: What is the difference between standard UCT and SELA's depth-preferred UCT-DP variant, and why is this modification important for ML experiments?

## Architecture Onboarding

- Component map:
  - Insight Proposer -> Search Module -> Experiment Executor -> State Cache

- Critical path:
  1. Problem description and dataset information input
  2. Insight generation for all pipeline stages
  3. Tree initialization with generated insights
  4. MCTS rollouts (selection → expansion → simulation → backpropagation)
  5. Best solution extraction from the tree
  6. Final pipeline execution and prediction generation

- Design tradeoffs:
  - Exploration vs. exploitation balance in MCTS affects solution quality and search efficiency
  - Number of rollouts vs. computational cost and time constraints
  - Depth of tree vs. complexity of pipeline configurations that can be represented
  - Code reuse vs. flexibility to adapt to new configurations

- Failure signatures:
  - Consistently low scores across multiple rollouts indicating poor insight generation or search strategy
  - Rapid convergence to shallow nodes suggesting the UCT-DP modification may be too aggressive
  - High variance in results across runs suggesting instability in the LLM components
  - Slow execution times due to excessive code generation or lack of effective caching

- First 3 experiments:
  1. Run SELA on a simple binary classification dataset (like credit-g) with 5 rollouts to verify basic functionality
  2. Compare SELA's performance with and without the state-saving mechanism on a medium-sized dataset
  3. Test SELA with different numbers of rollouts (1, 5, 10, 20) on the same dataset to observe the exploration-exploitation tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of α_unvisited and α_explore hyperparameters in UCT-DP affect the exploration-exploitation balance and final performance?
- Basis in paper: [explicit] The paper states that α_unvisited is set to 0.8 and α_explore is set to 1.4, and these settings aim to balance exploration and exploitation.
- Why unresolved: The paper does not provide an ablation study on the sensitivity of these hyperparameters or their impact on performance.
- What evidence would resolve it: Results from experiments varying these hyperparameters across a range of values and comparing the resulting performance metrics.

### Open Question 2
- Question: How does the state-saving and loading mechanism impact the efficiency and effectiveness of SELA compared to methods without this feature?
- Basis in paper: [explicit] The paper mentions that SELA implements fine-grained code reuse by caching code at the stage level, which conserves resources and maintains robust performance.
- Why unresolved: The paper does not provide a direct comparison of SELA's performance with and without state-saving, nor does it quantify the cost savings.
- What evidence would resolve it: Experiments comparing SELA's performance and token usage with and without the state-saving mechanism, along with a cost analysis.

### Open Question 3
- Question: How does SELA's performance scale with the complexity and size of the datasets, and what are the limitations in terms of dataset characteristics?
- Basis in paper: [inferred] The paper evaluates SELA on 20 datasets, but does not explicitly discuss its performance scaling with dataset complexity or size.
- Why unresolved: The paper does not provide a detailed analysis of SELA's performance across datasets with varying characteristics, such as feature dimensionality, number of classes, or data imbalance.
- What evidence would resolve it: A comprehensive evaluation of SELA on datasets with a wide range of characteristics, including synthetic datasets with controlled complexity, to identify performance trends and limitations.

## Limitations
- Limited exploration of edge cases like highly imbalanced or small-sample datasets
- Reliance on specific LLM (DeepSeek V2.5) may affect generalizability to other models
- Evaluation focused on standard benchmark datasets without domain-specific testing

## Confidence

**Major Claim Confidence:**
- MCTS-enhanced LLM framework improves AutoML performance: **High**
- SELA produces diverse, optimized pipelines through iterative refinement: **Medium**
- SELA outperforms traditional and agent-based AutoML methods: **Medium**

## Next Checks
1. Test SELA on additional datasets beyond the standard benchmarks, including edge cases like highly imbalanced or small-sample datasets
2. Compare SELA's performance using different LLM models to assess generalizability of the framework
3. Conduct ablation studies to isolate the contribution of individual components (MCTS, code reuse, stage-wise planning) to overall performance