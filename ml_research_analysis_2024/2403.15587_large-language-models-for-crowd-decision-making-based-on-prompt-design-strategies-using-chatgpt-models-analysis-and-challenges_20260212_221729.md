---
ver: rpa2
title: 'Large language models for crowd decision making based on prompt design strategies
  using ChatGPT: models, analysis and challenges'
arxiv_id: '2403.15587'
source_url: https://arxiv.org/abs/2403.15587
tags:
- chatgpt
- sentiment
- positive
- reviews
- scenario
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study integrates ChatGPT into Crowd Decision Making (CDM)
  models to extract evaluations from natural language reviews, aiming to leverage
  the wisdom of crowds from social media. Five CDM scenarios were proposed: primary
  polarities, numerical scores, linguistic terms, multi-criteria with a category ontology,
  and end-to-end CDM using ChatGPT.'
---

# Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges

## Quick Facts
- arXiv ID: 2403.15587
- Source URL: https://arxiv.org/abs/2403.15587
- Reference count: 40
- This study integrates ChatGPT into Crowd Decision Making (CDM) models to extract evaluations from natural language reviews, aiming to leverage the wisdom of crowds from social media.

## Executive Summary
This study explores the integration of ChatGPT into Crowd Decision Making (CDM) models to extract evaluations from natural language reviews, leveraging the wisdom of crowds from social media. Five CDM scenarios are proposed, ranging from primary polarities and numerical scores to end-to-end CDM using ChatGPT. Evaluations are extracted via tailored prompts, normalized, and aggregated to rank alternatives. Experiments on the TripR-2020Large dataset show that ChatGPT effectively supports CDM across scenarios, with rankings mostly consistent with baseline models. However, sensitivity, explainability, and consistency challenges are identified, highlighting areas for future improvement.

## Method Summary
The study proposes five CDM scenarios using ChatGPT to extract sentiment evaluations from TripAdvisor reviews. Prompts are designed to elicit single, machine-processable outputs (e.g., polarity terms, numeric scores, linguistic terms). Extracted sentiments are normalized and aggregated per alternative using frequency, mean, or weighted 2-tuple methods. The TripR-2020Large dataset (474 reviews for 4 London restaurants) is used to compare rankings with baseline CDM-SA and ECDM-SDAM models. Challenges in sensitivity, consistency, and explainability are noted, with future work suggested to address these issues.

## Key Results
- ChatGPT effectively supports CDM across five scenarios using prompt design strategies.
- Rankings are mostly consistent with baseline CDM-SA and ECDM-SDAM models.
- Sensitivity, explainability, and consistency challenges are identified, with future work needed to address them.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT can act as a flexible evaluation engine by interpreting natural language reviews and outputting sentiment in multiple formats (polarity, numeric score, linguistic terms).
- Mechanism: The prompt design strategies constrain ChatGPT to produce a single, machine-processable output (e.g., "positive", "0.75", "very positive") that replaces manual sentiment annotation, allowing seamless integration into CDM pipelines.
- Core assumption: ChatGPT's underlying transformer model has sufficient semantic understanding to extract consistent sentiment across diverse review styles.
- Evidence anchors:
  - [abstract] "We integrate ChatGPT in CDM processes as a flexible tool that infer the opinions expressed in texts, providing numerical or linguistic evaluations where the decision making models are based on the prompt design strategies."
  - [section 3.1] "We request ChatGPT to indicate the predominant sentiment of each review at document level as a traditional negative, neutral, or positive polarity term."
  - [corpus] Weak evidence—related papers focus on data sourcing or behavioral bias but do not validate ChatGPT's sentiment extraction reliability.
- Break condition: If prompts are ambiguous or reviews contain sarcasm/irony, ChatGPT may produce inconsistent or hallucinated evaluations, breaking downstream CDM ranking consistency.

### Mechanism 2
- Claim: Aggregating ChatGPT's extracted evaluations (via frequency, mean, or weighted 2-tuple methods) yields a restaurant ranking comparable to baseline CDM-SA and ECDM-SDAM models.
- Mechanism: Each review is processed independently; its extracted sentiment is normalized (if needed) and aggregated per alternative, producing a single score per restaurant that can be ranked.
- Core assumption: Averaging or relative frequency of sentiment labels captures the crowd's collective preference accurately enough for decision making.
- Evidence anchors:
  - [abstract] "Experiments on the TripR-2020Large dataset ... showed that ChatGPT effectively supported CDM across scenarios. Rankings were mostly consistent with baseline models..."
  - [section 4.6] "Most of achieved rankings match with the baseline ranking obtained by the CDM-SA model and the ECDM-SDAM methodology."
  - [corpus] No direct evidence—neighboring work discusses multi-agent CDM but not sentiment aggregation validation.
- Break condition: When sentiment distributions are skewed or reviews are sparse for certain criteria, the aggregation may overweight noise, causing divergent rankings (e.g., multi-criteria scenario vs others).

### Mechanism 3
- Claim: Using ChatGPT as an end-to-end CDM system—prompting it to analyze all reviews for an alternative and output a global score—can produce valid rankings without separate aggregation steps.
- Mechanism: A single prompt combines all reviews per alternative, asking ChatGPT to summarize and score, thus offloading both extraction and aggregation to the LLM.
- Core assumption: ChatGPT can synthesize multi-sentence reviews into a coherent overall sentiment score that reflects the crowd's collective opinion.
- Evidence anchors:
  - [abstract] "The fifth scenario explores the use of ChatGPT as an end-to-end CDM model. It is prompted to provide a ranking of the best alternatives based on the rates given by ChatGPT itself."
  - [section 3.6] "We request ChatGPT to play the role of a decision maker who must analyze simultaneously all the reviews associated to each alternative and provide the overall evaluation as a numerical score."
  - [corpus] No supporting evidence—neighboring work on LLM-based multi-agent CDM does not validate end-to-end sentiment synthesis.
- Break condition: If ChatGPT's internal synthesis is inconsistent across runs or sensitive to prompt phrasing, rankings may fluctuate unpredictably, undermining reliability.

## Foundational Learning

- Concept: Prompt engineering for controlled LLM outputs
  - Why needed here: Ensures ChatGPT produces consistent, machine-readable sentiment labels instead of verbose prose, enabling automated CDM workflows.
  - Quick check question: What happens if the prompt does not explicitly request a single-word or single-number response?

- Concept: Sentiment aggregation and normalization techniques
  - Why needed here: Converts raw ChatGPT outputs into comparable scores per alternative, enabling fair ranking across diverse sentiment formats.
  - Quick check question: How does the positive relative frequency differ from averaging numeric scores when combining sentiments?

- Concept: Multi-criteria decision making with category ontologies
  - Why needed here: Allows sentiment extraction at the criterion level (e.g., food quality, service) rather than just overall, enabling richer CDM insights.
  - Quick check question: Why might equal weighting of criteria lead to different rankings than overall sentiment aggregation?

## Architecture Onboarding

- Component map:
  Review ingestion -> ChatGPT prompt -> Sentiment extraction -> Normalization -> Aggregation -> Ranking

- Critical path:
  1. Extract raw review texts from dataset.
  2. Construct ChatGPT prompt per scenario.
  3. Send prompt, receive sentiment output.
  4. Normalize/aggregate sentiments per alternative.
  5. Rank alternatives by final scores.

- Design tradeoffs:
  - Single-shot vs multi-shot prompts: single-shot faster but less robust; multi-shot averages out sensitivity.
  - Numeric vs linguistic sentiment: numeric allows finer granularity; linguistic easier for human interpretation.
  - Criterion-level vs overall sentiment: criterion-level richer but requires more data; overall simpler but less explainable.

- Failure signatures:
  - Inconsistent sentiment outputs for the same review across runs -> sensitivity issue.
  - Hallucinated sentiment labels not grounded in text -> consistency issue.
  - Missing or "None" sentiments for many criteria -> sparse data problem.

- First 3 experiments:
  1. Run scenario 4.1 (primary polarity) on TripR-2020Large, verify ranking matches baseline.
  2. Run scenario 4.2 (numeric scores) on same dataset, compare sensitivity by repeating prompts.
  3. Run scenario 4.4 (multi-criteria with ontology) on a subset, analyze category-level sentiment distributions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can multiple runs of ChatGPT be aggregated to achieve more robust rankings in CDM scenarios?
- Basis in paper: [explicit] The authors note that "a potential extension could be to perform multiple runs and compute the average in each scenario in order to achieve most robust rankings."
- Why unresolved: This was not tested in the study; it remains a methodological improvement for handling ChatGPT's inherent uncertainty.
- What evidence would resolve it: Experimental comparison of single vs. multi-run aggregation showing improved ranking stability.

### Open Question 2
- Question: How can weights be learned for category criteria in multi-criteria CDM to reflect real-world importance rather than equal weighting?
- Basis in paper: [explicit] The authors state "It might be interesting to set categories weights through the attention of the experts" and note that "this scenario considers all categories to be equally important, whereas in a real environment it is common that...food may be more relevant than other."
- Why unresolved: The current ontology treats all categories equally, and the study did not implement weighted criteria.
- What evidence would resolve it: CDM models with learned or expert-assigned category weights showing improved alignment with ground truth rankings.

### Open Question 3
- Question: How can inconsistencies or hallucinations in ChatGPT's sentiment extraction be detected and managed in CDM models?
- Basis in paper: [explicit] The authors define "an hallucination versus uncertainty measurement" as "a very discrepant sentiment classification when distilling the evaluations in different formats" and note it as "an open issue to design ChatGPT based DM models to manage inconsistencies or hallucinations."
- Why unresolved: While inconsistencies were observed, no method was proposed to detect or filter them systematically.
- What evidence would resolve it: A detection algorithm or filtering method that reduces hallucination impact on final CDM rankings.

### Open Question 4
- Question: What are effective methods to increase explainability in ChatGPT-based CDM models given the black-box nature of LLMs?
- Basis in paper: [explicit] The authors state that "ChatGPT is a black-box artificial intelligence model that does not inherently offer detailed explanations of its responses" and that "explainability for DM based on LLMs is an important challenge."
- Why unresolved: The study only attempted a basic explanation prompt; no robust explainability framework was implemented.
- What evidence would resolve it: Integration of XAI techniques (e.g., feature attribution, rationale extraction) that provide interpretable justifications for ChatGPT-based CDM decisions.

## Limitations

- Exact prompt formulations are not fully specified, making exact replication difficult.
- Small dataset (474 reviews for 4 restaurants) limits generalizability to larger CDM applications.
- No validation provided for ChatGPT's sentiment extraction accuracy against ground truth human annotations.

## Confidence

- **High Confidence**: ChatGPT can extract sentiment from natural language reviews in various formats (polarity, numeric, linguistic) using prompt design strategies.
- **Medium Confidence**: Aggregated ChatGPT evaluations produce restaurant rankings mostly consistent with baseline CDM models.
- **Low Confidence**: End-to-end CDM using ChatGPT without separate aggregation steps provides reliable rankings comparable to traditional methods.

## Next Checks

1. Replicate the primary polarity scenario using the TripR-2020Large dataset and verify ranking consistency with baseline CDM-SA model.
2. Test ChatGPT's sensitivity by running the same numeric score extraction prompts multiple times and measuring output variance.
3. Conduct a human validation study comparing ChatGPT's extracted sentiments against expert human annotations to assess extraction accuracy.