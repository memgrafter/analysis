---
ver: rpa2
title: 'CALRec: Contrastive Alignment of Generative LLMs for Sequential Recommendation'
arxiv_id: '2405.02429'
source_url: https://arxiv.org/abs/2405.02429
tags:
- item
- user
- https
- text
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes CALRec, a two-stage fine-tuning framework for
  adapting large language models (LLMs) to sequential recommendation tasks. The method
  employs a combination of next-item generation loss and auxiliary contrastive losses
  to align user and item representations in a two-tower architecture.
---

# CALRec: Contrastive Alignment of Generative LLMs for Sequential Recommendation

## Quick Facts
- arXiv ID: 2405.02429
- Source URL: https://arxiv.org/abs/2405.02429
- Reference count: 40
- Key outcome: 37% improvement in Recall@1 and 24% improvement in NDCG@10 on Amazon Review dataset

## Executive Summary
CALRec introduces a two-stage fine-tuning framework for adapting large language models to sequential recommendation tasks. The method combines next-item generation loss with auxiliary contrastive losses to align user and item representations in a two-tower architecture. By first training on a multi-category joint dataset and then fine-tuning on category-specific data, CALRec achieves significant performance gains over existing baselines. The approach demonstrates the effectiveness of contrastive alignment and transfer learning in improving sequential recommendation with LLMs.

## Method Summary
CALRec employs a two-stage fine-tuning framework that first trains on a mixture of categories sampled proportionally to user count^0.3, then fine-tunes on each specific category. The method uses a two-tower architecture with contrastive losses (L_TT and L_UT) to align user history and target item representations. Item and user sequences are formatted with distinctive text prefixes to improve task understanding. The model generates next-item predictions using temperature sampling, which are then ranked via BM25 retrieval. The approach leverages PaLM-2 XXS as the LLM backbone and achieves state-of-the-art performance on the Amazon Review dataset.

## Key Results
- Achieves 37% improvement in Recall@1 and 24% improvement in NDCG@10 over existing baselines
- Ablation study confirms both stages of fine-tuning are crucial for performance
- Contrastive alignment significantly improves representation quality for recommendation tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage fine-tuning improves generalization by first learning cross-domain patterns then specializing.
- Mechanism: Stage I trains on a mixture of categories sampled proportionally to user count^0.3, allowing the model to learn robust sequential patterns. Stage II fine-tunes on each specific category to adapt to local characteristics.
- Core assumption: Cross-domain pretraining provides transferable knowledge that improves downstream performance more than direct fine-tuning.
- Evidence anchors: [abstract] "the LLM is first fine-tuned on a data mixture from multiple domains followed by another round of target domain fine-tuning", [section 3.3] "we propose a two-stage fine-tuning framework that consists of Multi-Category Joint Fine-Tuning (Stage I) and Category-Specific Fine-Tuning (Stage II)"
- Break condition: If category-specific data is too small or too different from Stage I data, the transfer benefit may diminish or cause negative transfer.

### Mechanism 2
- Claim: Contrastive alignment helps align user history and target item representations in the embedding space.
- Mechanism: CALRec uses two towers - one for user history and one for target items - and applies contrastive losses (L_TT and L_UT) to minimize the distance between aligned pairs while maximizing distance from negative samples.
- Core assumption: Joint embedding space learned through contrastive learning improves the model's ability to match user sequences with appropriate next items.
- Evidence anchors: [abstract] "a mixture of two contrastive losses and a language modeling loss", [section 3.4] "we also investigate auxiliary contrastive objectives that operate on the item/user level"
- Break condition: If the contrastive loss overwhelms the generation loss or if negative sampling is ineffective, alignment quality may degrade.

### Mechanism 3
- Claim: Template design with item prefixes improves task understanding and output coherence.
- Mechanism: Each item is prefixed with distinctive text indicators (e.g., "The next item bought is as follows") and user sequences start with a summary prefix, helping the LLM differentiate between items and understand the sequential recommendation task format.
- Core assumption: Clear structural cues in prompts help LLMs better understand the task and generate more coherent outputs.
- Evidence anchors: [section 3.2] "we additionally use a user prefix 'This is the summary of a user's purchase history' and per-item prefixes", [section 4] "the same item prefix is also seen in the history sequence, our approach is beneficial for the LLM to generate text that follows the output format"
- Break condition: If templates are too verbose or don't match the data format, they may introduce noise rather than clarity.

## Foundational Learning

- Concept: Contrastive Learning
  - Why needed here: To align user history and target item representations in a shared embedding space for better matching
  - Quick check question: What is the difference between L_TT and L_UT in CALRec's contrastive objectives?

- Concept: Transformer-based Sequential Modeling
  - Why needed here: The LLM backbone uses self-attention to capture sequential dependencies in user interaction histories
  - Quick check question: How does the attention mechanism help in understanding the evolution of user interests over time?

- Concept: Fine-tuning vs. Prompt Engineering
  - Why needed here: CALRec uses full fine-tuning rather than just prompting, requiring understanding of how to adapt pretrained models
  - Quick check question: Why might full fine-tuning be preferred over few-shot prompting for this sequential recommendation task?

## Architecture Onboarding

- Component map: Input sequences with item prefixes -> PaLM-2 XXS LLM backbone -> Two-tower framework (user tower + item tower) -> NIG loss + L_TT and L_UT contrastive losses -> Generated text output ranked via BM25 retrieval

- Critical path:
  1. Data preprocessing with template formatting
  2. Stage I multi-category joint fine-tuning
  3. Stage II category-specific fine-tuning
  4. Inference with temperature sampling and BM25 ranking

- Design tradeoffs:
  - Model size vs. inference latency (PaLM-2 XXS chosen over larger variants)
  - Contrastive loss weights (α=0.125, β=-0.025) balancing alignment vs. generation
  - Template verbosity vs. task clarity

- Failure signatures:
  - Overfitting on small categories (monitor validation loss during Stage II)
  - Poor contrastive alignment (check L_TT/L_UT loss values)
  - BM25 retrieval issues (validate generated output format matches corpus)

- First 3 experiments:
  1. Baseline: Run pretrained PaLM-2 XXS without fine-tuning to establish zero-shot performance
  2. Ablation: Test Stage I only vs. full two-stage training to measure transfer learning benefit
  3. Contrastive: Compare with and without L_TT/L_UT losses to quantify alignment contribution

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- The paper doesn't provide detailed implementation specifics for the quasi-round-robin BM25 retrieval algorithm, including the exact modulation factor epsilon used in ranking.
- Contrastive loss weights (α=0.125, β=-0.025) appear to be category-specific in Stage II, but exact values per category are not reported.
- The two-stage training assumes sufficient data in Stage I to provide meaningful cross-domain transfer, but the threshold for "sufficient" data is not quantified.

## Confidence
- High Confidence: The two-stage fine-tuning framework and its implementation details are clearly described, with ablation studies showing both stages are necessary.
- Medium Confidence: The contrastive alignment mechanism's effectiveness is demonstrated empirically, but the theoretical justification for why specific contrastive losses (L_TT and L_UT) outperform alternatives is limited.
- Medium Confidence: The template design's contribution to task understanding is supported by performance gains, but alternative template designs and their impact are not explored.

## Next Checks
1. Ablation on contrastive loss weights: Systematically vary α and β across a wider range to identify optimal values and test robustness to weight selection.
2. Cross-dataset validation: Test CALRec on non-Amazon sequential recommendation datasets (e.g., Yelp, Steam) to verify generalization beyond the primary dataset.
3. Template design comparison: Implement alternative prompt templates (minimal vs. verbose) to quantify the exact contribution of template verbosity to performance gains.