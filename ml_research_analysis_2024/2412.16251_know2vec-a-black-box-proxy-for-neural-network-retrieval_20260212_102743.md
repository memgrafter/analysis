---
ver: rpa2
title: 'Know2Vec: A Black-Box Proxy for Neural Network Retrieval'
arxiv_id: '2412.16251'
source_url: https://arxiv.org/abs/2412.16251
tags:
- knowledge
- query
- retrieval
- dataset
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Know2Vec introduces a novel approach to neural network retrieval
  that addresses key challenges in model selection by capturing intrinsic model knowledge
  without requiring access to internal parameters. The method works by probing models
  through a black-box interface to extract decision boundary samples, constructing
  knowledge representation matrices, and encoding these into precise model vectors.
---

# Know2Vec: A Black-Box Proxy for Neural Network Retrieval

## Quick Facts
- **arXiv ID**: 2412.16251
- **Source URL**: https://arxiv.org/abs/2412.16251
- **Reference count**: 12
- **Primary result**: Achieves 1.72% improvement in top-1 hitting ratio for neural network retrieval using black-box model knowledge extraction

## Executive Summary
Know2Vec introduces a novel black-box approach to neural network retrieval that captures model knowledge through decision boundary probing without accessing internal parameters. The method constructs knowledge representation matrices from boundary samples, encodes them into model vectors using bidirectional LSTM, and aligns these with query task vectors in a knowledge-consistency space. Extensive experiments demonstrate superior retrieval accuracy compared to state-of-the-art methods while maintaining privacy and computational efficiency under 0.1 seconds.

## Method Summary
Know2Vec operates through a black-box interface to extract decision boundary samples from pre-trained models, constructing knowledge representation matrices that capture transferred training knowledge. These matrices are encoded into model vectors using bidirectional LSTM networks, while query tasks are mapped to vectors by probing semantic relationships within samples. A specialized knowledge-consistency alignment space uses cosine similarity loss with margin to match query and model vectors, enabling accurate model retrieval without parameter access.

## Key Results
- Achieves 1.72% improvement in top-1 hitting ratio over baseline methods
- Demonstrates superior performance in both neural network retrieval and source-free model transferability estimation
- Maintains computational efficiency under 0.1 seconds while preserving model privacy
- Shows consistent improvement across diverse datasets and model architectures

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Model knowledge can be captured without internal parameters by probing decision boundaries
- **Mechanism**: Extracts boundary supporting samples via black-box interface, constructs knowledge representation matrix (KRM) from centroid and decision boundary samples, encodes into model vectors
- **Core assumption**: Knowledge transfer from training dataset is uniquely represented by model's decision boundary samples
- **Evidence anchors**: [abstract] "capturing vital decision knowledge from models while ensuring their privacy"; [section] "Theorem 1 proves that model knowledge that is transferred from the training dataset can be encapsulated by a matrix"
- **Break condition**: If decision boundary samples don't capture sufficient model knowledge, or if black-box probing cannot generate accurate boundary samples

### Mechanism 2
- **Claim**: Query tasks can be mapped to knowledge vectors by probing semantic relationships within samples
- **Mechanism**: Averages samples per class to identify class-specific features, feeds these into bidirectional LSTM to explore inter-class relationships, generates task knowledge vector
- **Core assumption**: Semantic relationships within query samples can be captured through class averaging and sequence modeling
- **Evidence anchors**: [abstract] "it maps the user's query task to a knowledge vector by probing the semantic relationships within query samples"; [section] "QEXT extracts semantic correlations from query task T, producing a task knowledge vector t = QEXT (T)"
- **Break condition**: If query sample relationships are too complex for simple averaging, or if LSTM fails to capture semantic dependencies

### Mechanism 3
- **Claim**: Knowledge-consistency alignment space enables accurate model retrieval by measuring semantic similarity between query and model vectors
- **Mechanism**: Uses specialized loss functions (model embedding consistency loss and spatial alignment loss) to optimize alignment between heterogeneous knowledge embeddings in shared space
- **Core assumption**: A common embedding space can be learned where query and model vectors align semantically despite structural differences
- **Evidence anchors**: [abstract] "the proxy ensures the knowledge-consistency between query vector and model vectors within their alignment space"; [section] "the proxy is designed to perform a knowledge consistency matching between the abstracted model representation and the task representation"
- **Break condition**: If loss functions cannot properly align heterogeneous embeddings, or if alignment space cannot capture semantic similarity

## Foundational Learning

- **Concept**: Knowledge Representation Matrix (KRM) and boundary supporting samples
  - **Why needed here**: KRM is the core mechanism for capturing model knowledge without parameters
  - **Quick check question**: How does KRM encode both centroid and boundary samples to represent model knowledge?

- **Concept**: Bidirectional LSTM for sequence encoding
  - **Why needed here**: LSTM processes variable-length sequences of graph nodes representing model knowledge
  - **Quick check question**: Why use bidirectional LSTM instead of simpler averaging for encoding model knowledge graphs?

- **Concept**: Knowledge-consistency alignment loss functions
  - **Why needed here**: Aligns heterogeneous embeddings (model vs query) in shared semantic space
  - **Quick check question**: What's the difference between model embedding consistency loss and spatial alignment loss?

## Architecture Onboarding

- **Component map**: Black-box interface → KRM generator → Graph set constructor → Model vector encoder (LSTM) → Query vector encoder (LSTM) → Knowledge alignment space → Cosine similarity measurement → Model selection
- **Critical path**: Probe model → Generate KRM → Build graph set → Encode to vector → Compare with query vector → Select best model
- **Design tradeoffs**: Black-box access vs. parameter access (privacy vs. potential accuracy), vector dimensionality vs. computational cost, LSTM complexity vs. simpler encoding methods
- **Failure signatures**: Low retrieval accuracy despite high training accuracy (alignment failure), extremely long inference times (encoding inefficiency), poor performance on certain model architectures (representation inadequacy)
- **First 3 experiments**:
  1. Test KRM generation with known models to verify boundary samples capture knowledge
  2. Validate LSTM encoding preserves semantic relationships from graph sets
  3. Measure alignment accuracy with synthetic query tasks before full deployment

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the retrieval accuracy scale when the model zoo size increases from 40 to 100 models, and what architectural modifications might be needed to maintain performance?
- **Basis in paper**: [inferred] The ablation study shows performance slightly decreases as model zoo size increases from 10 to 40, suggesting scalability challenges
- **Why unresolved**: The paper only tested up to 40 models, leaving uncertainty about performance in much larger model zoos common in practice
- **What evidence would resolve it**: Extensive experiments with model zoos containing 50-100+ models measuring retrieval accuracy, computational time, and potential architectural adaptations

### Open Question 2
- **Question**: Can the knowledge representation vectors be further compressed without significant loss of retrieval accuracy to enable real-time applications on edge devices?
- **Basis in paper**: [inferred] The paper uses 256-dimensional vectors and mentions computational efficiency, but doesn't explore compression techniques or their impact on accuracy
- **Why unresolved**: While efficiency is mentioned, the trade-off between vector dimensionality and accuracy remains unexplored, limiting deployment in resource-constrained environments
- **What evidence would resolve it**: Systematic experiments comparing retrieval accuracy with compressed representations (e.g., 64, 128, 256 dimensions) and evaluation on edge devices

### Open Question 3
- **Question**: How does Know2Vec perform when query tasks involve out-of-distribution samples or multi-modal data (e.g., combining text and image inputs)?
- **Basis in paper**: [inferred] All experiments use in-distribution image classification tasks, but modern applications often involve OOD or multi-modal queries
- **Why unresolved**: The paper focuses on standard image classification tasks without testing robustness to distribution shifts or multi-modal scenarios
- **What evidence would resolve it**: Experiments with OOD query datasets, domain adaptation tasks, and multi-modal query examples measuring retrieval accuracy and robustness metrics

## Limitations

- **Probe dataset sensitivity**: Unknown impact of probe sample selection strategy and sampling ratios on boundary sample quality and retrieval accuracy
- **Cross-architecture generalizability**: Limited testing across diverse model architectures beyond standard image classification models
- **Semantic relationship complexity**: Potential inadequacy of class averaging and LSTM for capturing complex semantic relationships in fine-grained or multi-class tasks

## Confidence

- **High confidence**: Retrieval pipeline architecture and privacy preservation claims
- **Medium confidence**: Effectiveness of black-box decision boundary probing for knowledge capture
- **Low confidence**: Generalizability of knowledge-consistency alignment across diverse model architectures

## Next Checks

1. **Probe Dataset Sensitivity Analysis**: Systematically vary probe sample sizes and class distributions to measure impact on retrieval accuracy and boundary sample quality
2. **Cross-Architecture Transferability**: Test retrieval performance when query tasks involve architectures significantly different from training models (e.g., transformers vs. CNNs)
3. **Knowledge Alignment Robustness**: Evaluate alignment space performance under adversarial perturbations of query vectors and model knowledge representations