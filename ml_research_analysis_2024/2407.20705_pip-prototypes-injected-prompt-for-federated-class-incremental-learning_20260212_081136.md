---
ver: rpa2
title: 'PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning'
arxiv_id: '2407.20705'
source_url: https://arxiv.org/abs/2407.20705
tags:
- learning
- local
- clients
- prompt
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PIP, a prototype-injected prompt method for
  federated class incremental learning. PIP addresses catastrophic forgetting and
  non-IID data distribution in federated settings by injecting shared prototypes into
  prompt learning, augmenting prototypes for class imbalance, and using weighted Gaussian
  aggregation.
---

# PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning

## Quick Facts
- **arXiv ID**: 2407.20705
- **Source URL**: https://arxiv.org/abs/2407.20705
- **Reference count**: 40
- **Primary result**: PIP achieves up to 33% accuracy improvement over state-of-the-art methods in federated class incremental learning while requiring fewer clients and rounds

## Executive Summary
This paper introduces PIP (Prototypes-Injected Prompt), a novel approach for Federated Class Incremental Learning (FCIL) that addresses catastrophic forgetting and non-IID data distribution challenges. PIP injects shared prototypes into prompt learning, augments prototypes for class imbalance, and uses weighted Gaussian aggregation. Experiments on CIFAR100, MiniImageNet, and TinyImageNet demonstrate that PIP outperforms state-of-the-art methods with significant accuracy improvements, requiring fewer clients and communication rounds while maintaining robustness across different task sizes.

## Method Summary
PIP operates in federated settings where multiple clients collaboratively learn new classes sequentially without sharing raw data. The method freezes a Vision Transformer backbone and trains small prompt parameters locally on each client. Key innovations include prototype injection where clients augment their local training with shared prototypes representing unavailable classes, prototype augmentation using Gaussian sampling to handle class imbalance between locally available and unavailable classes, and weighted Gaussian aggregation where the server combines client contributions proportionally based on participation frequency and training data size. This approach enables efficient knowledge transfer across clients while preserving privacy and mitigating catastrophic forgetting.

## Key Results
- PIP achieves up to 33% accuracy improvement over state-of-the-art methods on CIFAR100, MiniImageNet, and TinyImageNet
- Requires fewer clients (10 selected per round vs. more in competing methods) and communication rounds while maintaining superior performance
- Demonstrates robustness across different task sizes (T=5 and T=20) with consistent performance improvements
- Effectively handles non-IID data distribution and catastrophic forgetting in federated class incremental learning scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PIP injects shared prototypes into prompt learning to address catastrophic forgetting and non-IID data distribution
- Mechanism: Each client augments its local training with shared prototypes representing classes it cannot access locally. Prototypes are Gaussian-distributed and augmented to handle class imbalance. The server aggregates prototypes across clients using weighted Gaussian aggregation.
- Core assumption: Prototypes can be safely shared without privacy leakage and accurately represent unavailable classes.
- Evidence anchors:
  - [abstract]: "PIP addresses catastrophic forgetting and non-IID data distribution in federated settings by injecting shared prototypes into prompt learning"
  - [section 4.2]: "To handle this challenge, we propose prototype sharing between clients and the central server, where the server collects all clients' prototype {ð‘ ð‘¡ ð‘™ }ð¿ ð‘™=1 then distributes global prototype ð‘ ð‘¡ ðº = ð‘ ð‘¡ = âˆªð¿ ð‘™=1ð‘ ð‘¡ ð‘™"
  - [corpus]: Weak - no direct corpus evidence found for prototype sharing in FCIL
- Break condition: If prototypes cannot accurately represent unavailable classes or leak privacy, the mechanism fails.

### Mechanism 2
- Claim: Weighted Gaussian aggregation improves global model generalization by proportionally considering client participation and training sample size.
- Mechanism: The server computes client weights based on participation count and sample size, then aggregates prompts, head layers, and prototypes using Gaussian-based weighted aggregation formulas.
- Core assumption: Client contribution to global model quality is proportional to their participation frequency and training data size.
- Evidence anchors:
  - [section 4.4]: "We proposed weighted Gaussian aggregation on the server side to improve global model generalization. The aggregation treats clients' contribution to global aggregation proportionally based on their participation and their training sample size"
  - [equation 12-15]: Mathematical formulation of weighted aggregation
  - [corpus]: Weak - no direct corpus evidence found for weighted Gaussian aggregation in FCIL
- Break condition: If client weights don't correlate with model quality or Gaussian assumptions fail, aggregation becomes suboptimal.

### Mechanism 3
- Claim: Prototype augmentation handles class imbalance between locally available and unavailable classes.
- Mechanism: For each unavailable class prototype, PIP generates multiple augmented prototypes using Gaussian sampling around the mean prototype, creating balanced representation with locally available classes.
- Core assumption: Generating multiple samples from prototype Gaussian distribution effectively simulates real data distribution for unavailable classes.
- Evidence anchors:
  - [section 4.3]: "we enrich the prototypes by using an augmentation. Suppose that ð‘¥ð‘1 is the sample for class ð‘1 âˆˆ C ð‘¡ ð‘™ , ð‘§ð‘¡ð‘2 âˆˆ ð‘ ð‘¡ is the prototype of class ð‘2 âˆˆ Cð‘¡ ð‘™ = Cð‘¡ âˆ’ Cð‘¡ ð‘™ , ð‘1 is locally available class, and ð‘2 is locally the unavailable class in client-ð‘™, then we have |ð‘¥ð‘1 | â‰« 1, while |ð‘§ð‘¡ð‘2 | = 1"
  - [equation 11]: Prototype augmentation formula
  - [corpus]: Weak - no direct corpus evidence found for prototype augmentation in FCIL
- Break condition: If augmented prototypes poorly represent real data distribution or don't improve learning, augmentation becomes ineffective.

## Foundational Learning

- Concept: Federated Learning (FL) basics - how multiple clients collaboratively train a global model while preserving data privacy
  - Why needed here: PIP operates in federated setting where clients cannot share raw data
  - Quick check question: In FL, what do clients typically share with the server instead of raw data?

- Concept: Class Incremental Learning (CIL) - learning new classes sequentially while preserving knowledge of previous classes
  - Why needed here: PIP addresses catastrophic forgetting in federated setting where new classes arrive continuously
  - Quick check question: What is the main challenge when learning new classes sequentially in neural networks?

- Concept: Prompt-based learning - using small trainable parameters (prompts) while keeping backbone frozen
  - Why needed here: PIP uses prompt learning for efficient parameter sharing in federated setting
  - Quick check question: In prompt-based learning, which model components typically remain frozen during training?

## Architecture Onboarding

- Component map: Clients -> Local prompt training, prototype generation, prototype augmentation, prototype injection -> Server -> Prototype collection, weighted Gaussian aggregation, parameter distribution

- Critical path: Client local training â†’ Prototype generation/augmentation â†’ Prototype injection â†’ Parameter update â†’ Send to server â†’ Server aggregation â†’ Distribute global parameters

- Design tradeoffs:
  - Communication efficiency: Sharing prompts+prototypes (small) vs full model (large)
  - Privacy: Prototypes vs raw samples or perturbed images
  - Model quality: Weighted aggregation vs simple averaging
  - Complexity: Gaussian augmentation vs simple prototype sharing

- Failure signatures:
  - Poor accuracy on new tasks â†’ Prototype injection or augmentation ineffective
  - Performance drop on old tasks â†’ Weighted aggregation weighting incorrect
  - Communication bottleneck â†’ Prototype size too large or too many rounds
  - Privacy concerns â†’ Prototypes leaking information

- First 3 experiments:
  1. Test prototype injection with simple averaging aggregation on CIFAR100 T=5
  2. Compare weighted vs simple aggregation with fixed prototypes
  3. Test prototype augmentation impact on class imbalance with fixed aggregation method

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform with larger number of classes per task or larger number of tasks?
- Basis in paper: [inferred] The paper evaluates performance on T=5 and T=20 task settings, but does not explore very large task sizes or class numbers.
- Why unresolved: The authors only tested up to 20 tasks and did not explore the limits of the method's scalability.
- What evidence would resolve it: Experimental results showing performance on datasets with significantly more classes per task or more total tasks would determine the scalability limits.

### Open Question 2
- Question: How does the method perform in non-i.i.d. data distributions that are more extreme than tested?
- Basis in paper: [inferred] The paper mentions non-i.i.d. data but does not test highly skewed distributions where some clients have very few classes.
- Why unresolved: The experiments use moderate non-i.i.d. conditions, but the method's robustness to extreme data imbalance is unknown.
- What evidence would resolve it: Experiments with highly skewed class distributions across clients would show how well the prototype injection handles extreme non-i.i.d. conditions.

### Open Question 3
- Question: What is the impact of using different backbone architectures beyond Vision Transformers?
- Basis in paper: [explicit] The authors use frozen ViT backbone and mention that any backbone could theoretically be used, but only test with ViT.
- Why unresolved: The paper demonstrates effectiveness with ViT but does not verify performance with other architectures like CNNs or different vision models.
- What evidence would resolve it: Experiments comparing performance using different backbone architectures (CNNs, ResNets, etc.) while keeping the prompt-based approach would show generalizability.

## Limitations

- Limited experimental validation on realistic federated scenarios with highly heterogeneous data distributions and extreme class imbalance
- Prototype sharing mechanism's privacy guarantees are not thoroughly analyzed despite operating in sensitive federated setting
- The Gaussian assumptions for prototype augmentation and weighted aggregation may not hold for complex, real-world data distributions
- No ablation studies on the impact of different prompt architectures or prototype generation methods

## Confidence

- Prototype injection mechanism: Medium - Theoretical justification is sound but lacks comprehensive privacy analysis
- Weighted Gaussian aggregation: Medium - Mathematical formulation is clear but assumptions may not hold in practice
- Prototype augmentation: Low - Method is novel but effectiveness depends heavily on Gaussian assumptions that aren't validated

## Next Checks

1. Conduct extensive ablation studies varying the number of augmented prototypes per unavailable class to determine optimal augmentation strategy
2. Perform privacy analysis using membership inference attacks to verify prototype sharing doesn't leak client information
3. Test PIP under extreme non-IID conditions with highly skewed class distributions across clients to evaluate robustness limits