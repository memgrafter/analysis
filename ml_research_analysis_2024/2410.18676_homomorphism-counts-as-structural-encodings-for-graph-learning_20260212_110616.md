---
ver: rpa2
title: Homomorphism Counts as Structural Encodings for Graph Learning
arxiv_id: '2410.18676'
source_url: https://arxiv.org/abs/2410.18676
tags:
- graph
- mose
- rwse
- node
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes motif structural encoding (MoSE), a graph inductive
  bias for Graph Transformers based on counting graph homomorphisms. The authors show
  that MoSE is more expressive than random-walk structural encoding (RWSE) and relate
  both to the expressive power of message passing neural networks through the Weisfeiler-Lehman
  hierarchy.
---

# Homomorphism Counts as Structural Encodings for Graph Learning

## Quick Facts
- arXiv ID: 2410.18676
- Source URL: https://arxiv.org/abs/2410.18676
- Reference count: 40
- This paper proposes motif structural encoding (MoSE) for Graph Transformers based on counting graph homomorphisms, achieving state-of-the-art results on the ZINC molecular benchmark with MAE of 0.056.

## Executive Summary
This paper introduces motif structural encoding (MoSE), a flexible graph structural encoding framework based on counting graph homomorphisms from pattern graphs. MoSE provides a strict generalization of random-walk structural encoding (RWSE) and can distinguish graph pairs that 1-WL cannot, while being more flexible than RWSE. The authors demonstrate that MoSE consistently outperforms other positional and structural encodings across various architectures and datasets, achieving state-of-the-art results on molecular benchmarks while remaining computationally efficient to implement.

## Method Summary
MoSE is a graph structural encoding framework that uses homomorphism counts from a pattern graph family G as node features. The method is parameterized by a choice of pattern graph family and node weighting scheme, making it flexible and adaptable to different tasks. Homomorphism counts capture structural relationships in the input graph, providing richer information than random walks. The authors show that MoSE generalizes RWSE as a special case and relates both to the Weisfeiler-Lehman hierarchy, demonstrating that MoSE can distinguish graph pairs that 1-WL and RWSE cannot. Implementation involves computing homomorphism counts, projecting them to the desired dimension, and integrating them into Graph Transformer architectures.

## Key Results
- MoSE consistently outperforms other positional and structural encodings across multiple Graph Transformer architectures and datasets
- Achieves state-of-the-art results on ZINC molecular benchmark with MAE of 0.056
- Demonstrates higher expressive power than RWSE while being more flexible and easier to compute
- Shows superior performance on synthetic fractional domination task (98.4% accuracy)

## Why This Works (Mechanism)

### Mechanism 1
MoSE provides more expressive graph structure encoding than RWSE by counting homomorphism patterns from pattern graphs, capturing structural relationships that random walks cannot distinguish. This provides richer structural information than RWSE's adjacency matrix power entries.

### Mechanism 2
MoSE achieves higher expressive power than 1-WL tests while being more flexible than RWSE. While RWSE is strictly weaker than 2-WL and cannot distinguish certain graph pairs, MoSE can distinguish any graph pair distinguishable by some k-WL test and is not confined to any particular WL level.

### Mechanism 3
MoSE generalizes RWSE as a special case with appropriate pattern choice and weighting. RWSE can be exactly expressed as MoSE with cycle pattern graphs and degree-based weighting, making MoSE a strict generalization that retains all RWSE information.

## Foundational Learning

- **Graph homomorphism counting**: MoSE fundamentally relies on counting homomorphisms from pattern graphs to input graphs as a way to encode structural information. Quick check: What is the computational complexity of counting homomorphisms from a pattern graph with treewidth k to an input graph?

- **Weisfeiler-Lehman (WL) hierarchy**: The paper relates MoSE expressiveness to the WL hierarchy, showing MoSE can distinguish graphs that 1-WL and 2-WL can distinguish. Quick check: If two graphs are indistinguishable by 1-WL, can MoSE with a finite pattern family always distinguish them?

- **Graph motif parameters and their bases**: Proposition 4.3 uses the theory of graph motif parameters to establish lower bounds on MoSE expressiveness. Quick check: How does the concept of a "basis" of graph motif parameters relate to the choice of pattern graphs in MoSE?

## Architecture Onboarding

- **Component map**: Pattern graph family selection → Homomorphism counting engine → Embedding layer → Integration with Transformer architecture
- **Critical path**: Pattern graph selection → Homomorphism computation → Embedding projection → Transformer input integration
- **Design tradeoffs**: Larger pattern families increase expressiveness but computational cost; different weighting schemes can capture different structural aspects but may require normalization; embedding dimension must balance expressiveness with parameter efficiency
- **Failure signatures**: Homomorphism computation timeouts or memory errors (pattern graphs too large); model performance no better than baseline (pattern graphs not task-relevant); numerical instability in embeddings (poor scaling of homomorphism counts)
- **First 3 experiments**: 1) Implement MoSE with G = {C3, C4, C5} on a small molecular dataset, compare to RWSE; 2) Test MoSE with G = Spasm(C7) ∪ Spasm(C8) on ZINC dataset; 3) Implement degree-weighted MoSE that exactly reproduces RWSE, verify Proposition 4.5 experimentally

## Open Questions the Paper Calls Out

### Open Question 1
What is the theoretical relationship between MoSE and spectral positional encodings (like LapPE) in terms of expressive power? The paper mentions this relationship remains unexplored and could provide valuable insights for understanding MoSE's position among structural encoding methods.

### Open Question 2
How does the choice of node weighting function ω in MoSE affect its performance and expressiveness in practice? While the paper uses constant weighting (ω=1) in most experiments, it notes that the full potential of the node-weighting parameter remains unexplored.

### Open Question 3
Can MoSE maintain its performance advantages on larger, more complex molecular graphs beyond the ZINC dataset? The paper demonstrates strong performance on moderate-sized molecular graphs but doesn't scale to massive molecular datasets like the full PCQM4Mv2.

## Limitations
- Pattern selection effectiveness critically depends on choosing appropriate pattern graphs for the task, with no systematic method provided
- Computational scalability may become a bottleneck for large pattern graphs or massive molecular graphs
- Expressiveness bounds remain unknown - while lower bounds are established, the upper bound and precise relationship to WL hierarchy is unclear

## Confidence
- **High confidence**: Theoretical framework connecting MoSE to homomorphism counting and WL hierarchy is sound, supported by rigorous proofs
- **Medium confidence**: Generalization of MoSE to RWSE is theoretically established but practical implications need further validation
- **Low confidence**: No systematic method for optimal pattern selection; exceptional performance on synthetic tasks may not generalize

## Next Checks
1. **Pattern sensitivity analysis**: Systematically vary the pattern graph family G on a held-out dataset to identify which patterns contribute most to performance, and test whether task-relevant patterns can be discovered automatically

2. **Scalability benchmark**: Measure homomorphism counting runtime and memory usage for increasingly large pattern graphs (up to treewidth 4-5) on large molecular graphs, establishing practical limits

3. **Cross-dataset transferability**: Train MoSE encodings on one dataset and evaluate on another (e.g., train on ZINC, test on QM9) to assess how much pattern selection is task-specific versus domain-general