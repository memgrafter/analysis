---
ver: rpa2
title: A Collaborative Ensemble Framework for CTR Prediction
arxiv_id: '2411.13700'
source_url: https://arxiv.org/abs/2411.13700
tags:
- embedding
- dhen
- learning
- prediction
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a collaborative ensemble framework for CTR
  prediction that addresses limitations of traditional multi-embedding approaches.
  The method combines multiple specialized models (InterFormer and DHEN) each with
  distinct embedding tables to capture diverse feature interaction patterns, enhanced
  by a confidence-based fusion mechanism and collaborative learning via symmetric
  KL divergence.
---

# A Collaborative Ensemble Framework for CTR Prediction

## Quick Facts
- arXiv ID: 2411.13700
- Source URL: https://arxiv.org/abs/2411.13700
- Authors: Xiaolong Liu, Zhichen Zeng, Xiaoyi Liu, Siyang Yuan, Weinan Song, Mengyue Hang, Yiqun Liu, Chaofei Yang, Donghyun Kim, Wen-Yen Chen, Jiyan Yang, Yiping Han, Rong Jin, Bo Long, Hanghang Tong, Philip S. Yu
- Reference count: 40
- Key outcome: Framework achieves 0.7456 AUC on KuaiVideo, outperforming individual models and state-of-the-art baselines

## Executive Summary
This paper proposes a collaborative ensemble framework for CTR prediction that addresses limitations of traditional multi-embedding approaches. The method combines multiple specialized models (InterFormer and DHEN) each with distinct embedding tables to capture diverse feature interaction patterns, enhanced by a confidence-based fusion mechanism and collaborative learning via symmetric KL divergence. Experiments on three public datasets (AmazonElectronics, TaobaoAds, KuaiVideo) and a large-scale Meta dataset demonstrate consistent performance improvements over individual models and state-of-the-art baselines.

## Method Summary
The framework ensembles InterFormer and DHEN models, each with its own embedding table to capture sequential and hierarchical feature interactions respectively. A confidence-based fusion mechanism uses negation entropy to weight model contributions, while symmetric KL divergence aligns predictions through collaborative learning. The approach addresses embedding collapse issues common in multi-embedding paradigms and achieves better performance with smaller embedding sizes compared to existing methods.

## Key Results
- Achieves 0.7456 AUC on KuaiVideo dataset, outperforming DHEN's 0.7428
- Demonstrates consistent performance improvements across three public datasets
- Shows comparable or better performance on Criteo and Avazu with smaller embedding sizes
- Internal Meta deployment shows NE gain of -0.062% using simple concatenation fusion

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Confidence-based fusion ensures that the model with higher prediction certainty has greater influence on the final output.
- Mechanism: Each model's prediction confidence is measured via negation entropy. Lower entropy indicates higher certainty, and the softmax function converts these confidence scores into fusion weights for the embeddings.
- Core assumption: Prediction entropy reliably reflects model confidence in CTR prediction tasks.
- Evidence anchors:
  - [abstract] "Our framework integrates collaborative learning through KL divergence to align the predictions of different models, enhancing synergy and ensuring more effective learning."
  - [section] "We use the negation entropy of each model's predicted probability distribution to measure its confidence. Lower entropy indicates higher certainty, and thus a larger contribution to the final embedding."
  - [corpus] Weak evidence - no direct citations on entropy-based confidence weighting in CTR literature.
- Break condition: If entropy fails to correlate with prediction quality (e.g., overconfident wrong predictions), the fusion mechanism could amplify errors.

### Mechanism 2
- Claim: Collaborative learning with symmetric KL divergence aligns model predictions without allowing one model to dominate.
- Mechanism: Symmetric KL divergence is applied between model predictions, encouraging mutual refinement while preserving individual model strengths.
- Core assumption: KL divergence alignment improves ensemble synergy without degrading individual model performance.
- Evidence anchors:
  - [abstract] "To dynamically balance contributions from each model, we introduce a confidence-based fusion mechanism using general softmax, where model confidence is computed via negation entropy."
  - [section] "We adopt a symmetric KL divergence term that aligns the predicted distributions of both models, encouraging mutual refinement without sacrificing their individual strengths."
  - [corpus] Weak evidence - collaborative learning in CTR is emerging but lacks extensive validation.
- Break condition: If KL divergence forces models too close together, they may lose diversity and the ensemble loses its advantage.

### Mechanism 3
- Claim: Multi-embedding with distinct embedding tables prevents embedding collapse and captures diverse feature interaction patterns.
- Mechanism: Each model maintains its own embedding table, allowing them to focus on different interaction patterns (sequential for InterFormer, hierarchical for DHEN).
- Core assumption: Separate embedding tables enable complementary learning and avoid interference.
- Evidence anchors:
  - [abstract] "Our framework offers several key advantages: (1) Leveraging complementary strengths: By ensembling InterFormer and DHEN with distinct embedding tables, we capture both sequential and hierarchical feature interactions, enhancing the overall expressiveness of the feature representation."
  - [section] "By assigning each model its own independent embedding table, the framework ensures that both hierarchical and deep feature interactions are captured, enriching the overall expressiveness of the learned feature representations."
  - [corpus] Strong evidence - recent work [6] explicitly addresses embedding collapse in CTR models and proposes multi-embedding solutions.
- Break condition: If embedding tables become redundant (capture same patterns), the multi-embedding advantage disappears.

## Foundational Learning

- Concept: Feature interaction modeling in CTR prediction
  - Why needed here: Understanding how different feature combinations affect click probability is central to CTR prediction and the motivation for using multiple models.
  - Quick check question: What is the difference between low-order and high-order feature interactions, and why does DHEN specifically target high-order interactions?

- Concept: Knowledge distillation and ensemble learning
  - Why needed here: The collaborative learning mechanism is essentially a form of knowledge distillation between models, and understanding ensemble principles is crucial for the fusion mechanism.
  - Quick check question: How does symmetric KL divergence differ from asymmetric knowledge distillation, and what advantage does it provide in this ensemble context?

- Concept: Entropy and information theory
  - Why needed here: Confidence-based fusion relies on entropy as a measure of prediction certainty, so understanding information theory is essential.
  - Quick check question: Why does lower entropy indicate higher confidence in a probability distribution, and what are the limitations of using entropy as a confidence metric?

## Architecture Onboarding

- Component map: Input Layer -> Multi-Embedding Module -> Model Processing (DHEN/InterFormer) -> Confidence Module -> Fusion Layer -> Output Layer
- Critical path:
  1. Feature embedding lookup in respective embedding tables
  2. Model-specific processing (DHEN/InterFormer)
  3. Confidence score calculation via negation entropy
  4. Softmax-based weighting of embeddings
  5. Weighted concatenation and final prediction
  6. Loss computation and backpropagation

- Design tradeoffs:
  - Separate embedding tables increase parameter count but prevent interference and capture diverse patterns
  - Confidence-based fusion adds complexity but improves robustness over simple averaging
  - Symmetric KL divergence alignment requires additional computation but ensures balanced contributions

- Failure signatures:
  - Model dominance: One model's weights become consistently much larger in the fusion layer
  - KL divergence explosion: Large values indicate misalignment between models
  - Embedding collapse: Models start producing similar embeddings despite separate tables
  - Confidence oscillation: Entropy values fluctuate wildly, indicating unstable predictions

- First 3 experiments:
  1. Train each component model (DHEN and InterFormer) individually to establish baseline performance
  2. Test simple ensemble (weighted average) without confidence-based fusion to measure improvement from alignment
  3. Compare symmetric vs asymmetric KL divergence to determine optimal collaboration strength

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the collaborative ensemble framework change when ensembling models with more than two distinct embedding tables?
- Basis in paper: [inferred] The paper focuses on ensembling two models (InterFormer and DHEN) but states the framework is general and can extend to ensemble N models.
- Why unresolved: The paper only validates the framework with two models, leaving the scalability and effectiveness of the approach with larger ensembles unexplored.
- What evidence would resolve it: Experiments demonstrating the framework's performance when ensembling three or more models with distinct embedding tables, comparing results to two-model ensembles.

### Open Question 2
- Question: What is the impact of different fusion strategies (e.g., weighted sum vs. concatenation) on the framework's performance in various CTR prediction scenarios?
- Basis in paper: [explicit] The paper compares "Ours-sum" and "Ours-concat" fusion strategies in the multi-embedding paradigm comparison, showing varying performance.
- Why unresolved: While the paper presents results for specific fusion strategies, it doesn't explore a comprehensive range of fusion methods or their effectiveness across different datasets and model combinations.
- What evidence would resolve it: Systematic evaluation of multiple fusion strategies (e.g., weighted sum, concatenation, gating mechanisms) across diverse CTR datasets and model architectures.

### Open Question 3
- Question: How does the collaborative learning mechanism affect the framework's performance when training on extremely large-scale datasets with limited epochs (e.g., one epoch)?
- Basis in paper: [explicit] The paper conducts experiments on Criteo and Avazu datasets with one-epoch training, showing that the framework performs well even with smaller embedding sizes.
- Why unresolved: While the paper demonstrates the framework's efficiency with one-epoch training, it doesn't explore the specific impact of collaborative learning on performance under these constrained conditions.
- What evidence would resolve it: Comparative analysis of the framework's performance with and without collaborative learning when training on large-scale datasets with one or few epochs, measuring convergence speed and final accuracy.

## Limitations
- The framework's reliance on entropy-based confidence weighting may not reliably reflect prediction quality in all CTR scenarios
- Symmetric KL divergence alignment could force models to converge too closely, potentially reducing ensemble diversity
- Computational overhead of maintaining separate embedding tables and fusion mechanisms needs evaluation against performance gains

## Confidence
- **High Confidence**: The architectural design of combining InterFormer and DHEN with distinct embedding tables is well-founded, with strong evidence from recent work on embedding collapse in CTR models.
- **Medium Confidence**: The confidence-based fusion mechanism shows promise but lacks extensive validation in the CTR literature, particularly regarding entropy's reliability as a confidence metric.
- **Medium Confidence**: The collaborative learning approach using symmetric KL divergence is theoretically justified but needs more empirical validation to confirm it doesn't force excessive model convergence.

## Next Checks
1. **Entropy Validation**: Conduct ablation studies comparing confidence-based fusion with alternative weighting schemes (uniform, performance-based) to verify that entropy reliably identifies better predictions across diverse scenarios.
2. **Model Diversity Analysis**: Measure embedding similarity metrics and feature interaction patterns between DHEN and InterFormer to ensure the multi-embedding approach maintains complementary strengths rather than redundancy.
3. **Computational Efficiency Assessment**: Benchmark inference latency and memory usage against single-model baselines and simple ensemble approaches to quantify the practical deployment costs of the framework.