---
ver: rpa2
title: Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering
  Over Knowledge Graph
arxiv_id: '2401.02212'
source_url: https://arxiv.org/abs/2401.02212
tags:
- temporal
- question
- knowledge
- facts
- complex
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles complex temporal question answering over temporal
  knowledge graphs (TKGs), where questions involve multiple entities and require reasoning
  across multiple temporal facts. Existing methods are limited to simple questions
  and fail to handle complex ones.
---

# Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph

## Quick Facts
- arXiv ID: 2401.02212
- Source URL: https://arxiv.org/abs/2401.02212
- Authors: Rikui Huang; Wei Wei; Xiaoye Qu; Wenfeng Xie; Xianling Mao; Dangyang Chen
- Reference count: 0
- One-line primary result: Achieves state-of-the-art Hits@1 score of 0.628 on TimeQuestions benchmark, significantly outperforming existing models on complex temporal questions.

## Executive Summary
This paper addresses complex temporal question answering over temporal knowledge graphs (TKGs), where questions involve multiple entities and require reasoning across multiple temporal facts. Existing methods struggle with such complexity, typically handling only simple questions. The authors propose a Joint Multi-Facts Reasoning Network (JMFRN) that jointly reasons over multiple temporal facts without requiring prior entity annotations. By retrieving question-related temporal facts for each entity and using entity-aware and time-aware attention modules, the model effectively aggregates information from multiple facts. Additionally, an answer type discrimination task is introduced to filter incorrect answer types. Experiments on the TimeQuestions benchmark demonstrate significant performance improvements, particularly for complex questions with multiple entities.

## Method Summary
The method retrieves temporal facts related to each entity in the question and jointly reasons over multiple facts without entity-specific annotations. The core architecture uses entity-aware and time-aware attention modules to aggregate entity and timestamp information from retrieved facts, followed by feature integration and answer prediction. An auxiliary answer type discrimination task is added to improve model stability and filter incorrect answer types. The model is trained using binary cross-entropy loss combined with the auxiliary task loss, using pre-trained BERT for question encoding and TComplEx embeddings for temporal facts.

## Key Results
- Achieves state-of-the-art Hits@1 score of 0.628 on TimeQuestions benchmark
- Significantly outperforms existing models, especially on complex questions with multiple entities
- Ablation study confirms effectiveness of attention modules and answer type discrimination task in improving accuracy and stability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint reasoning over multiple temporal facts improves accuracy for complex questions.
- Mechanism: The model retrieves all question-related temporal facts for each entity and uses entity-aware and time-aware attention modules to aggregate information from these facts, enabling joint reasoning.
- Core assumption: Complex temporal questions require multiple temporal facts to be reasoned over jointly rather than sequentially.
- Evidence anchors:
  - [abstract] "To jointly reasoning multiple temporal facts for accurately answering complex temporal questions."
  - [section] "To address the problem, in this paper we propose a Joint Multi-Facts Reasoning Network (JMFRN) to handle complex temporal questions by considering multiple facts simultaneously without additional entity-specific annotations."
  - [corpus] Weak evidence - corpus contains related work on TKGQA but lacks direct evidence for this specific joint reasoning mechanism.

### Mechanism 2
- Claim: The entity-aware and time-aware attention modules effectively aggregate information from multiple temporal facts.
- Mechanism: These attention modules calculate attention scores for entities and timestamps respectively, allowing the model to focus on the most relevant information from the retrieved facts.
- Core assumption: Not all retrieved facts are equally relevant to answering the question, and attention can effectively identify the most important ones.
- Evidence anchors:
  - [abstract] "For joint reasoning, we design two different attention (i.e., entity-aware and time-aware) modules, which are suitable for universal settings, to aggregate entities and timestamps information of retrieved facts."
  - [section] "eatt = Xk i=1 αiei, tatt = Xk i=1 βiti (4) αi = exp(q⊤ei) Pk j=1 exp(q⊤ej) , β i = exp(q⊤ti) Pk j=1 exp(q⊤tj) (5)"
  - [corpus] Weak evidence - corpus contains related work on attention mechanisms but lacks direct evidence for the specific entity-aware and time-aware attention modules used in JMFRN.

### Mechanism 3
- Claim: The answer type discrimination task improves model performance and stability.
- Mechanism: An auxiliary task is introduced to classify the answer type (entity or timestamp), which helps the model focus on the correct type of answer and filter out incorrect ones.
- Core assumption: Complex temporal questions have specific answer types, and explicitly modeling this can improve performance.
- Evidence anchors:
  - [abstract] "Moreover, to filter incorrect type answers, we introduce an additional answer type discrimination task."
  - [section] "ptime = σ(Wtypeq), L 2 = X q (zq − ptime)2 (9) where Wtype is a learnable projection matrix,σ(·) sigmoid, zq is the answer type of question q."
  - [corpus] Weak evidence - corpus contains related work on answer type classification but lacks direct evidence for its effectiveness in this specific context.

## Foundational Learning

- Concept: Temporal Knowledge Graphs (TKGs)
  - Why needed here: Understanding TKGs is crucial as the model operates on them to answer temporal questions.
  - Quick check question: What is the difference between a regular knowledge graph and a temporal knowledge graph?

- Concept: Attention Mechanisms
  - Why needed here: The model uses entity-aware and time-aware attention modules to aggregate information from multiple facts.
  - Quick check question: How do attention mechanisms help in focusing on the most relevant information in a sequence?

- Concept: Multi-task Learning
  - Why needed here: The model incorporates an auxiliary answer type discrimination task alongside the main task.
  - Quick check question: What are the benefits and potential drawbacks of using multi-task learning in a model?

## Architecture Onboarding

- Component map: Facts retrieval -> Entity-aware attention -> Time-aware attention -> Feature integration -> Answer prediction
- Critical path: Facts retrieval → Attention modules → Feature integration → Answer prediction
- Design tradeoffs: Joint reasoning over multiple facts vs. sequential reasoning, complexity of attention modules vs. computational efficiency, auxiliary task vs. main task focus.
- Failure signatures: Poor performance on complex questions, instability during training, inability to handle multiple entities.
- First 3 experiments:
  1. Evaluate the model's performance on simple vs. complex questions to verify the need for joint reasoning.
  2. Compare the performance of the model with and without the attention modules to assess their effectiveness.
  3. Test the impact of the answer type discrimination task on model performance and training stability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of JMFRN scale with the size and complexity of the temporal knowledge graph (TKG)? Specifically, what are the limitations in terms of the number of entities, relations, and temporal facts that can be effectively handled by the model?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of JMFRN on the TimeQuestions benchmark, but does not explore its scalability to larger or more complex TKGs.
- Why unresolved: The paper focuses on evaluating JMFRN on a specific dataset and does not investigate its performance on varying TKG sizes or complexities.
- What evidence would resolve it: Experiments comparing JMFRN's performance on TKGs of different sizes and complexities, including the number of entities, relations, and temporal facts.

### Open Question 2
- Question: How does the choice of temporal knowledge graph embedding (TKGE) model impact the performance of JMFRN? Are there specific TKGE models that are more suitable for complex temporal question answering tasks?
- Basis in paper: [explicit] The paper mentions using TComplEx as the TKGE model but does not explore the impact of different TKGE models on JMFRN's performance.
- Why unresolved: The paper does not provide a comparative analysis of different TKGE models and their impact on JMFRN's performance.
- What evidence would resolve it: Experiments comparing JMFRN's performance using different TKGE models, such as TDistMult, TComplEx, or other temporal knowledge graph embedding approaches.

### Open Question 3
- Question: How does JMFRN handle uncertainty and ambiguity in temporal facts? Are there mechanisms in place to account for conflicting or incomplete temporal information when reasoning over multiple facts?
- Basis in paper: [inferred] The paper does not explicitly address how JMFRN handles uncertainty and ambiguity in temporal facts, which is a common challenge in real-world TKGs.
- Why unresolved: The paper focuses on the model architecture and performance evaluation but does not delve into the handling of uncertainty and ambiguity in temporal facts.
- What evidence would resolve it: Experiments or analysis demonstrating how JMFRN handles conflicting or incomplete temporal information, including the incorporation of uncertainty measures or probabilistic reasoning techniques.

## Limitations
- Evaluation relies on a single benchmark (TimeQuestions), raising questions about generalizability across different datasets
- Performance on implicit and ordinal questions remains significantly lower than explicit questions, indicating limitations in handling complex temporal reasoning
- Attention mechanism effectiveness depends heavily on fact retrieval and embedding quality, which are not thoroughly validated

## Confidence
- High confidence: The core claim that joint reasoning over multiple temporal facts improves performance on complex questions is well-supported by experimental results and ablation studies
- Medium confidence: The effectiveness of the entity-aware and time-aware attention modules is demonstrated but relies on specific implementation details not fully disclosed
- Medium confidence: The benefit of the answer type discrimination task is shown empirically but lacks theoretical justification for why it improves stability and performance

## Next Checks
1. **Cross-dataset validation**: Test JMFRN on additional temporal question answering benchmarks (e.g., TimeDial, TempQuestions) to assess generalizability beyond TimeQuestions.

2. **Attention mechanism analysis**: Conduct a detailed analysis of the attention scores to verify that the model correctly identifies relevant facts versus noise, including case studies of both successful and failed predictions.

3. **Ablation on answer type discrimination**: Perform a more granular ablation study varying the weight λ of the answer type discrimination task to determine optimal settings and understand its impact on different question types.