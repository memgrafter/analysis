---
ver: rpa2
title: 'BertaQA: How Much Do Language Models Know About Local Culture?'
arxiv_id: '2406.07302'
source_url: https://arxiv.org/abs/2406.07302
tags:
- basque
- local
- questions
- global
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BERTAQA, a multiple-choice trivia dataset
  with 4,756 questions that is parallel in English and Basque. The dataset is divided
  into a local subset with questions pertinent to the Basque culture, and a global
  subset with questions of broader interest.
---

# BertaQA: How Much Do Language Models Know About Local Culture?

## Quick Facts
- arXiv ID: 2406.07302
- Source URL: https://arxiv.org/abs/2406.07302
- Reference count: 40
- Primary result: State-of-the-art language models perform significantly worse on local cultural questions than global ones

## Executive Summary
This paper introduces BERTAQA, a parallel English-Basque multiple-choice trivia dataset with 4,756 questions divided into local (Basque culture) and global subsets. The authors evaluate a wide range of open and commercial language models, finding that models perform much better on global topics (e.g., GPT-4 Turbo achieves 91.7% accuracy) than local topics (72.2% accuracy). The key insight is that continued pretraining in a low-resource language (Basque) significantly improves performance on cultural questions in that language, even when queried in English, demonstrating cross-lingual knowledge transfer from low-resource to high-resource languages.

## Method Summary
The authors created BERTAQA by translating a Basque trivia dataset into English using professional translators, ensuring parallel structure. They evaluated existing language models using the LM Evaluation Harness library with 5-shot prompting, testing both open models (Llama 2/3, Mistral, Qwen, Yi, Gemma) and commercial models (GPT-3.5/4, Claude 3). The evaluation compared performance across local (Basque culture) and global subsets, and tested translate-test and self-translate approaches. They also examined the effect of continued pretraining in Basque on model performance.

## Key Results
- GPT-4 Turbo achieves 91.7% accuracy on global questions but only 72.2% on local questions
- Continued pretraining in Basque improves English performance on Basque culture questions by up to 13.5 points
- Translation-based approaches (translate-test and self-translate) work better for global questions than local questions
- Best local results are obtained in Basque, while best global results are obtained in English

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continued pretraining in a low-resource language transfers knowledge to high-resource language performance
- Mechanism: When a model is further trained on Basque data, it acquires culturally specific knowledge that is retained and accessible when queried in English
- Core assumption: The model's architecture supports cross-lingual knowledge transfer even without explicit multilingual fine-tuning
- Evidence anchors:
  - [abstract]: "continued pretraining in Basque significantly improves the models' performance on Basque culture, even when queried in English"
  - [section 4.2]: "This proves that it is possible to transfer knowledge from a low-resource to a high-resource language"
  - [corpus]: "Corpus neighbors include work on 'Do Large Language Models Know How Much They Know?' and 'CULTURE-GEN: Revealing Global Cultural Perception in Language Models', suggesting this is a novel approach"
- Break condition: If the model's architecture does not support cross-lingual knowledge transfer, or if the Basque data is too sparse to encode meaningful cultural knowledge

### Mechanism 2
- Claim: Translation-based approaches like translate-test and self-translate are less effective for local cultural questions
- Mechanism: These methods assume that translating questions into the language the model was trained on (English) will improve performance, but this fails for questions requiring deep cultural understanding
- Core assumption: Local cultural knowledge is encoded in a language-specific manner that translation cannot fully recover
- Evidence anchors:
  - [abstract]: "we show that translate-test and self-translate work better for global questions than local questions"
  - [section 4.4]: "translation-based approaches tend to be more effective for global questions"
  - [corpus]: "Corpus neighbors include 'CulturalBench: A Robust, Diverse, and Challenging Cultural Benchmark', indicating ongoing research into cultural bias"
- Break condition: If the translation system is highly accurate and captures all cultural nuances, or if the model can infer cultural context from translated text

### Mechanism 3
- Claim: Models perform better when queried in the language they acquired the relevant knowledge in
- Mechanism: Knowledge about Basque culture is better retained and accessed when the model is prompted in Basque, and global knowledge is better accessed in English
- Core assumption: The model's internal knowledge representation is not fully language-agnostic
- Evidence anchors:
  - [abstract]: "we show that LLMs fail to encode knowledge in a fully language-agnostic manner, and perform better when queried in the language they acquired the relevant knowledge in"
  - [section 4.3]: "the best local results are obtained in Basque, whereas the best global results are obtained in English"
  - [corpus]: "Corpus neighbors include 'Controlled Evaluation of Syntactic Knowledge in Multilingual Language Models', suggesting research into language-specific encoding"
- Break condition: If the model's architecture fully decouples knowledge from language, or if the knowledge is encoded in a truly language-agnostic manner

## Foundational Learning

- Concept: Cross-lingual knowledge transfer
  - Why needed here: Understanding how training on one language can improve performance on another is crucial for leveraging low-resource languages
  - Quick check question: If a model is trained on Basque data, why would its performance on English questions about Basque culture improve?

- Concept: Cultural bias in language models
  - Why needed here: Recognizing that models may have inherent biases towards certain cultures is essential for evaluating their performance fairly
  - Quick check question: Why might a model trained primarily on English data perform worse on questions about Basque culture?

- Concept: Translation-based evaluation methods
  - Why needed here: Knowing the limitations of translating questions for evaluation is important for interpreting results accurately
  - Quick check question: Why might translating a question about Basque culture into English not yield the same results as asking it in Basque?

## Architecture Onboarding

- Component map: Base language model (e.g., Llama 2) -> Continued pretraining data (Basque corpora) -> Evaluation datasets (BERTAQA local and global subsets)
- Critical path: Continued pretraining on Basque data → Knowledge transfer to English queries → Improved performance on local questions
- Design tradeoffs: Training on low-resource languages may improve local performance but potentially harm global performance; translation-based methods are simpler but less effective for local questions
- Failure signatures: If continued pretraining in Basque does not improve English performance on local questions, or if translation-based methods do not work better for global questions
- First 3 experiments:
  1. Evaluate the base model on BERTAQA local and global subsets in English
  2. Continue pretraining the base model on Basque data and evaluate again on BERTAQA
  3. Translate BERTAQA into Basque and evaluate the continued pretraining model in both languages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How much of the performance gap between local and global questions is due to training data imbalance versus model architecture limitations?
- Basis in paper: [explicit] The paper notes that models perform much better on global questions (e.g., GPT-4 Turbo: 91.7% vs 72.2% on local), but doesn't conclusively determine whether this is from data imbalance or inherent architectural limitations
- Why unresolved: The paper experiments with continued pretraining in Basque but doesn't isolate whether the remaining gap is due to architecture or insufficient low-resource data
- What evidence would resolve it: Controlled experiments with models trained from scratch on balanced local/global data distributions, or ablation studies on model capacity for cultural knowledge encoding

### Open Question 2
- Question: Does the translation quality of the English version of BertaQA introduce artifacts that systematically affect model performance on local questions?
- Basis in paper: [inferred] The paper mentions that the English version was professionally translated, but doesn't analyze whether translation artifacts or cultural knowledge loss in translation affects model performance differently on local versus global questions
- Why unresolved: The paper assumes translation quality is high but doesn't empirically verify whether translation artifacts differentially impact local cultural knowledge assessment
- What evidence would resolve it: Human evaluation of translation quality focusing on cultural nuance preservation, and controlled experiments comparing model performance on original vs back-translated local questions

### Open Question 3
- Question: What is the minimal amount of low-resource language pretraining needed to achieve significant transfer of cultural knowledge to high-resource languages?
- Basis in paper: [explicit] The paper shows that continued pretraining in Basque improves English performance on Basque culture (e.g., Llama 2 70B improves by 13.5 points on local questions), but doesn't explore the scaling relationship between pretraining data volume and knowledge transfer effectiveness
- Why unresolved: The experiments use a fixed amount of Basque pretraining data without exploring whether smaller amounts would suffice or what the diminishing returns curve looks like
- What evidence would resolve it: Systematic experiments varying the amount of Basque pretraining data while measuring the local knowledge transfer efficiency curve

## Limitations
- The BERTAQA dataset contains only 4,756 questions, which may not be representative of the full spectrum of local and global knowledge domains
- The focus on Basque culture creates questions about how findings would generalize to other low-resource languages and cultures
- Evaluation primarily focuses on multiple-choice questions, which may not fully capture the nuances of cultural knowledge

## Confidence
- Cross-lingual knowledge transfer claims: Medium
- Models do not encode knowledge in a fully language-agnostic manner: Medium
- Translation-based approaches are less effective for local cultural questions: Medium

## Next Checks
1. Replicate the study with a larger, more diverse dataset covering multiple low-resource languages to test the generalizability of cross-lingual knowledge transfer claims
2. Conduct ablation studies on the continued pretraining process to determine which aspects of the Basque data are most critical for knowledge transfer
3. Test the models on open-ended cultural knowledge questions rather than multiple-choice format to assess deeper understanding of cultural contexts