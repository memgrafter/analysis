---
ver: rpa2
title: 'ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis'
arxiv_id: '2404.10141'
source_url: https://arxiv.org/abs/2404.10141
tags:
- image
- captions
- anchor
- news
- subject
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ANCHOR, a new dataset of 70K+ news image-caption
  pairs designed to evaluate text-to-image (T2I) models on abstractive captions that
  include high-level context and named entities. Unlike descriptive captions in existing
  benchmarks, news captions require understanding situational and named-entity information.
---

# ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis

## Quick Facts
- arXiv ID: 2404.10141
- Source URL: https://arxiv.org/abs/2404.10141
- Authors: Aashish Anantha Ramakrishnan; Sharon X. Huang; Dongwon Lee
- Reference count: 18
- One-line primary result: SAFE framework improves text-to-image synthesis for abstractive news captions using LLM-generated subject weights

## Executive Summary
This paper introduces ANCHOR, a new dataset of 70K+ news image-caption pairs designed to evaluate text-to-image (T2I) models on abstractive captions that include high-level context and named entities. Unlike descriptive captions in existing benchmarks, news captions require understanding situational and named-entity information. The authors propose SAFE, a method that uses LLM-generated subject weights to condition T2I models for better subject representation and incorporates domain fine-tuning on news data. SAFE improves FIDCLIP, ImageReward, and Human Preference scores over baselines like Stable Diffusion. Ablation studies show subject conditioning and LLM-based weighting significantly boost performance.

## Method Summary
The SAFE framework addresses the challenge of generating images from abstractive news captions by using LLM-generated subject weights to condition Stable Diffusion models. The method extracts salient subjects from captions using GPT-3.5, applies scale multipliers to enhance subject token embeddings, and performs domain fine-tuning on the ANCHOR dataset using a reward-based learning strategy (ReFL). The framework specifically targets the "prompt forgetting" problem in diffusion models by emphasizing key subjects during generation. Domain fine-tuning adapts the model to news media characteristics through a reward model trained on human-annotated image-caption alignment scores.

## Key Results
- SAFE achieves significant improvements in FIDCLIP, ImageReward, and Human Preference Score V2 metrics compared to baseline T2I models
- Subject conditioning with LLM-generated weights outperforms CLIP-based subject identification methods
- Domain fine-tuning on news data further improves alignment between generated images and abstractive captions
- The ANCHOR dataset successfully demonstrates the challenges of abstractive caption generation compared to descriptive captions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Subject conditioning with LLM-generated subject weights improves T2I model comprehension of abstractive news captions.
- Mechanism: LLMs identify salient subjects from abstractive captions and assign higher importance weights to these subjects in the text embedding space. This allows the T2I model to focus on the key elements that should be visually represented, mitigating the "prompt forgetting" issue.
- Core assumption: LLMs can reliably identify salient subjects in abstractive captions better than CLIP encoders.
- Evidence anchors:
  - [abstract] "Our proposed method Subject-Aware Fine-tuning (SAFE), selects and enhances the representation of key subjects in synthesized images by leveraging LLM-generated subject weights."
  - [section 4.1] "To tackle the above-mentioned challenges, we propose a new dataset containing Abstractive News Captions with High-level cOntext Representation (ANCHOR)... Our proposed method Subject-Aware Fine-tuning (SAFE), selects and enhances the representation of key subjects in synthesized images by leveraging LLM-generated subject weights."
- Break condition: If LLMs fail to correctly identify salient subjects, or if the scale multipliers applied to subject tokens are not optimal, the conditioning may not improve or could even degrade performance.

### Mechanism 2
- Claim: Domain fine-tuning on news image-caption pairs adapts the T2I model to the specific characteristics of news media.
- Mechanism: The SAFE framework incorporates a Domain Fine-tuning (DFE) strategy that uses a reward model trained on human-annotated image-caption alignment scores. This encourages the model to generate images that better match the style and content of news media, which differs from the general web-scraped data used in pre-training.
- Core assumption: News images have distinct characteristics (e.g., more photographs, specific foreground/background object distributions) that can be learned through fine-tuning.
- Evidence anchors:
  - [abstract] "It also adapts to the domain distribution of news images and captions through Domain Fine-tuning, outperforming current T2I baselines on ANCHOR."
  - [section 4.1] "To tackle this domain shift, we develop our Domain fine-tuning (DFE) strategy on ANCHOR... Our proposed improvements in DFE over vanilla ReFL focus on improving both alignments with the ground truth image and caption instead of only caption alignment."
- Break condition: If the reward model is not well-calibrated or if the fine-tuning process overfits to the reward model's predictions, the DFE may not generalize well to new news captions.

### Mechanism 3
- Claim: The ANCHOR dataset provides a challenging benchmark for evaluating T2I models' ability to handle abstractive captions with high-level context and named entities.
- Mechanism: By curating a large-scale dataset of news image-caption pairs that differ from descriptive captions, the ANCHOR dataset forces T2I models to understand complex sentence structures and situational context, rather than just literal object descriptions. This is further emphasized by the inclusion of the ANCHOR Entity subset, which tests the models' ability to generate named entities.
- Core assumption: Abstractive captions are more challenging for T2I models than descriptive captions, and this difference is significant enough to impact model performance.
- Evidence anchors:
  - [abstract] "Real-world news image captions take a more pragmatic approach, providing high-level situational and Named-Entity (NE) information and limited physical object descriptions, making them abstractive."
  - [section 1] "News media is one key domain where image captions follow sentence structures, differing from descriptive captions... Since news image captions include high-level context information that doesnâ€™t directly describe physical attributes of different image elements, we term them to have an Abstractive style of representation."
- Break condition: If the distinction between abstractive and descriptive captions is not as significant as assumed, or if the ANCHOR dataset does not adequately represent the diversity of real-world news captions, the benchmark may not be as challenging as intended.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their capabilities in language understanding and commonsense reasoning.
  - Why needed here: The SAFE framework relies on LLMs to identify salient subjects in abstractive captions, which is a key step in improving the T2I model's comprehension.
  - Quick check question: What are some common techniques used to prompt LLMs for specific tasks, such as subject identification?

- Concept: Text-to-Image (T2I) synthesis and the challenges of conditioning models on text prompts.
  - Why needed here: The paper addresses the specific challenge of conditioning T2I models on abstractive news captions, which differ from the descriptive captions commonly used in existing benchmarks.
  - Quick check question: What are some common approaches for incorporating text conditioning into T2I models, and what are their limitations?

- Concept: Diffusion models and their application in T2I generation.
  - Why needed here: The SAFE framework builds upon Stable Diffusion, a latent diffusion model, to generate images conditioned on abstractive news captions.

## Architecture Onboarding

### Component Map
Stable Diffusion -> LLM-generated subject weights -> Subject conditioning -> Domain fine-tuning -> ANCHOR evaluation

### Critical Path
1. Extract subjects from abstractive captions using LLM
2. Apply scale multipliers to subject token embeddings
3. Generate images using conditioned Stable Diffusion
4. Perform domain fine-tuning with ReFL strategy
5. Evaluate on ANCHOR dataset using FIDCLIP, ImageReward, and Human Preference Score

### Design Tradeoffs
- LLM-based subject identification vs. CLIP-based approaches: LLMs offer better contextual understanding but require additional computational overhead
- Scale multiplier selection: x2 multiplier provides good balance between subject emphasis and overall caption coherence
- Domain fine-tuning scope: Fine-tuning on news data improves caption alignment but may reduce general-purpose generation capabilities

### Failure Signatures
- Poor subject conditioning leading to subject forgetting in generated images
- Domain shift causing unrealistic image generation that doesn't match news media style
- Overfitting to reward model predictions during domain fine-tuning

### First 3 Experiments
1. Baseline comparison: Evaluate Stable Diffusion on ANCHOR dataset without any modifications
2. Subject conditioning ablation: Compare SAFE with and without LLM-generated subject weights
3. Domain fine-tuning ablation: Compare SAFE with and without domain fine-tuning on news data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do current text-to-image models handle the generation of specific named entities (NEs), and what architectural changes could improve their ability to generate realistic and contextually appropriate NE representations?
- Basis in paper: [explicit] The paper discusses the challenges of generating specific faces of humans and the need for improved metrics to decouple the impact of generating NE features faithfully from representing all subjects mentioned in the caption accurately.
- Why unresolved: The paper acknowledges the limitations of current models in generating NEs, particularly faces, and suggests that personalized T2I generation approaches may help. However, it does not provide a concrete solution or evaluate specific architectural changes to address this issue.
- What evidence would resolve it: Empirical studies comparing different architectural modifications, such as incorporating additional face recognition modules or leveraging personalized training data, and their impact on NE generation quality and contextual appropriateness.

### Open Question 2
- Question: What are the key differences in the linguistic and cognitive processes involved in understanding and generating descriptive versus abstractive captions, and how can text-to-image models be designed to better capture the nuances of abstractive language?
- Basis in paper: [explicit] The paper highlights the distinction between descriptive and abstractive captions, emphasizing the importance of understanding high-level situational and named-entity information in abstractive captions.
- Why unresolved: While the paper proposes a method (SAFE) to improve subject representation using external knowledge, it does not delve into the underlying linguistic and cognitive processes that differentiate descriptive and abstractive captions. Understanding these processes could lead to more effective model designs.
- What evidence would resolve it: Comparative studies analyzing the linguistic features and cognitive processes involved in generating and comprehending descriptive and abstractive captions, and experiments evaluating the performance of text-to-image models on abstractive captions after incorporating insights from these studies.

### Open Question 3
- Question: How can text-to-image models be evaluated more comprehensively to assess their ability to generate images that accurately reflect the intended meaning and context of abstractive captions, beyond traditional metrics like FID and ImageReward?
- Basis in paper: [explicit] The paper acknowledges the limitations of existing evaluation metrics, particularly when dealing with named entities, and suggests the need for improved metrics that can decouple the impact of generating NE features faithfully from representing all subjects mentioned in the caption accurately.
- Why unresolved: The paper proposes a human evaluation study to assess the perceived variations in subject understanding, but it does not provide a concrete framework for developing more comprehensive evaluation metrics that can capture the nuances of abstractive captions and their intended meaning.
- What evidence would resolve it: Development and validation of new evaluation metrics that consider factors such as semantic coherence, contextual appropriateness, and the ability to capture abstract concepts and relationships present in abstractive captions.

## Limitations

- The paper lacks direct comparisons to alternative methods for subject identification beyond CLIP encoders, making it difficult to assess whether LLM-based weighting provides a clear advantage
- The domain shift between general web-scraped data and news media is asserted but not empirically validated with quantitative analysis
- Human preference testing was limited to 40 images per condition, which may not provide statistically robust results for subjective quality assessments

## Confidence

- **High confidence**: The ANCHOR dataset creation methodology and its distinction from existing descriptive caption benchmarks is well-documented and reproducible
- **Medium confidence**: The improvements in FIDCLIP and ImageReward scores over baseline models, though these metrics have known limitations for evaluating abstractive caption generation
- **Low confidence**: The claimed superiority of LLM-generated subject weights over alternative approaches, due to lack of head-to-head comparisons

## Next Checks

1. **Ablation on subject identification methods**: Compare SAFE's performance using LLM-generated weights versus CLIP-based subject identification and rule-based approaches to isolate the contribution of LLM weighting

2. **Domain adaptation validation**: Quantitatively measure the domain shift between news images and general web-scraped data using feature distance metrics before and after domain fine-tuning

3. **Statistical power analysis**: Conduct power analysis on the human preference study to determine if the sample size (40 images) provides sufficient statistical power to detect meaningful differences between conditions