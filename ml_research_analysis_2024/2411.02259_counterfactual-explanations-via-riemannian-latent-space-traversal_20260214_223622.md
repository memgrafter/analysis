---
ver: rpa2
title: Counterfactual Explanations via Riemannian Latent Space Traversal
arxiv_id: '2411.02259'
source_url: https://arxiv.org/abs/2411.02259
tags:
- space
- latent
- data
- counterfactual
- riemannian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of generating counterfactual explanations
  for black-box classifiers that remain on the data manifold and maintain realism.
  The authors propose using Riemannian geometry to traverse the latent space of generative
  models, ensuring counterfactual trajectories stay within the data distribution.
---

# Counterfactual Explanations via Riemannian Latent Space Traversal

## Quick Facts
- arXiv ID: 2411.02259
- Source URL: https://arxiv.org/abs/2411.02259
- Reference count: 28
- Primary result: Riemannian methods achieve LD values of 0.04-0.05 on Adult and 0.015-0.019 on GMC, compared to 0.12-0.33 for standard SGD

## Executive Summary
This paper addresses the challenge of generating counterfactual explanations for black-box classifiers that remain on the data manifold and maintain realism. The authors propose using Riemannian geometry to traverse the latent space of generative models, ensuring counterfactual trajectories stay within the data distribution. They introduce two approaches: RSGD, which uses the Riemannian metric induced by the generative model's uncertainty, and RSGD-C, which additionally incorporates the classifier's geometry to guide the trajectories. The methods are evaluated on Adult and Give Me Some Credit datasets, showing improved fidelity to the data manifold while maintaining comparable validity and fewer violations of immutable features.

## Method Summary
The authors propose generating counterfactual explanations by traversing the latent space of a variational autoencoder (VAE) using Riemannian stochastic gradient descent (RSGD). The key innovation is using the Riemannian metric induced by the generative model's uncertainty to guide counterfactual trajectories, ensuring they remain on the data manifold. The metric is computed from the Jacobian of the VAE's decoder and an RBF uncertainty network. They also introduce RSGD-C, which incorporates the classifier's geometry by adding its Jacobian to the metric computation. Counterfactuals are generated by optimizing in the latent space and mapping back to the input space using the VAE's decoder.

## Key Results
- RSGD and RSGD-C achieve significantly lower local distance to data manifold (LD) values of 0.04-0.05 on Adult and 0.015-0.019 on GMC, compared to 0.12-0.33 for standard SGD
- Both methods maintain comparable validity (Flip Ratio) to standard SGD while reducing violations of immutable features
- Counterfactuals generated by Riemannian methods are closer to the original input in terms of L0, L1, L2, and Lâˆž norms
- The classifier-guided metric in RSGD-C does not significantly improve results over RSGD alone on the tested datasets

## Why This Works (Mechanism)
The method works by leveraging the Riemannian geometry of the latent space to guide counterfactual trajectories along paths that are more likely to correspond to real data points. By using the generative model's uncertainty to define the metric tensor, the optimization naturally prefers directions that the model considers more probable, thus staying closer to the data manifold. The classifier-guided variant further refines this by incorporating the classifier's sensitivity, ensuring that counterfactuals move in directions that are both realistic and effective at changing the classification.

## Foundational Learning
- **Riemannian geometry**: Non-Euclidean geometry where distances are measured using a metric tensor - needed to capture the curved structure of data manifolds
  - Quick check: Can you compute the length of a curve using the metric tensor?
- **Variational autoencoders (VAEs)**: Generative models that learn a latent space distribution - needed to provide a structured latent space for counterfactual generation
  - Quick check: What's the difference between the prior and posterior in a VAE?
- **Jacobian matrices**: Matrices of partial derivatives that describe how outputs change with inputs - needed to compute the metric tensor from the generative model
  - Quick check: How does the Jacobian relate to the metric tensor in this context?
- **Counterfactual explanations**: Modified inputs that change the model's prediction - needed as the target outputs for the optimization
  - Quick check: What makes a good counterfactual explanation in terms of validity and realism?

## Architecture Onboarding

Component Map:
VAE (Encoder -> Latent Space -> Decoder) -> Jacobian Computation -> Metric Tensor -> RSGD/RSGD-C Optimizer -> Counterfactuals

Critical Path:
Data -> VAE Training -> Classifier Training -> Metric Computation -> Counterfactual Optimization -> Evaluation

Design Tradeoffs:
- Using a VAE provides structured latent space but requires careful architecture design
- Riemannian optimization maintains manifold proximity but is computationally more expensive than Euclidean methods
- The classifier-guided metric in RSGD-C may improve actionability but adds computational overhead

Failure Signatures:
- Counterfactuals with high LD values indicate optimization has moved off the data manifold
- Unstable training or NaN values suggest issues with metric tensor computation or inversion
- Poor validity (Flip Ratio) indicates counterfactuals aren't effectively changing the classification

Three First Experiments:
1. Train a VAE on a subset of the Adult dataset and visualize the latent space to understand its structure
2. Implement the RBF uncertainty network and verify it produces reasonable uncertainty estimates for the decoder
3. Generate a single counterfactual using RSGD and compare its LD value to one generated with standard SGD

## Open Questions the Paper Calls Out
- How does the Riemannian metric behave when the generative model's uncertainty is not well-calibrated, and what are the implications for counterfactual explanations?
- How do the counterfactual trajectories differ when using RSGD-C compared to RSGD in terms of their actionability and realism for the individuals?
- What are the computational trade-offs of using RSGD and RSGD-C compared to standard Euclidean SGD, and how do they scale with dataset size and dimensionality?

## Limitations
- Implementation details for the RBF uncertainty network are underspecified, particularly bandwidth and center configuration
- Evaluation relies heavily on proxy metrics (LD) rather than direct human assessment of realism
- The focus on tabular data limits generalizability to high-dimensional domains where manifold geometry is more complex

## Confidence

High Confidence:
- The mathematical framework for Riemannian gradient descent is well-established
- The comparison methodology between RSGD, RSGD-C, and standard SGD is sound

Medium Confidence:
- The reported improvements in LD and distance metrics are methodologically valid
- The practical significance of small LD differences requires further validation

Low Confidence:
- Claims about "improved realism" are primarily supported by LD metrics rather than human evaluation
- Specific RBF network implementation details are insufficient for perfect reproduction

## Next Checks

1. Implement a systematic ablation study varying the RBF network bandwidth and number of centers to verify their impact on counterfactual quality and metric stability.

2. Conduct a small-scale human evaluation comparing counterfactuals generated by RSGD, RSGD-C, and standard SGD on the Adult dataset to validate whether LD improvements correlate with perceived realism.

3. Test the methods on a non-differentiable classifier (e.g., decision tree) to evaluate robustness when the classifier gradient assumption fails.