---
ver: rpa2
title: Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval
arxiv_id: '2403.05105'
source_url: https://arxiv.org/abs/2403.05105
tags:
- pairs
- mismatched
- retrieval
- cost
- cross-modal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of robust cross-modal retrieval
  in the presence of partially mismatched pairs (PMPs) in training data. The core
  idea is to rematch mismatched pairs by leveraging potential semantic similarity
  among unpaired samples, formulated as an Optimal Transport (OT) problem.
---

# Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval

## Quick Facts
- arXiv ID: 2403.05105
- Source URL: https://arxiv.org/abs/2403.05105
- Authors: Haochen Han, Qinghua Zheng, Guang Dai, Minnan Luo, Jingdong Wang
- Reference count: 40
- Primary result: Achieves up to 16.9% relative gains in retrieval performance under 0.8 MRate

## Executive Summary
This paper tackles the challenge of robust cross-modal retrieval when training data contains partially mismatched pairs (PMPs). The proposed method rematches mismatched pairs by leveraging semantic similarity among unpaired samples through an Optimal Transport framework. A key innovation is a self-supervised learnable cost function that automatically learns explicit similarity-cost mappings without relying on corrupted representations. The approach employs a partial OT model with masked positive pairs to boost refined alignments. Experiments demonstrate significant improvements over state-of-the-art methods on Flickr30K, MS-COCO, and CC152K benchmarks, particularly under high mismatching rates.

## Method Summary
The method addresses cross-modal retrieval with mismatched training pairs by formulating the rematching problem as an Optimal Transport task. A self-supervised learnable cost function automatically learns from similarity-cost mappings, avoiding dependence on potentially corrupted representations. The approach uses a partial OT model where positive pairs are masked to enhance refined alignment generation. This framework enables the model to fully leverage mismatched data while improving robustness in retrieval tasks. The method is evaluated across three benchmark datasets under various mismatching rates.

## Key Results
- Achieves up to 16.9% relative performance gains under 0.8 MRate
- Outperforms state-of-the-art methods on Flickr30K, MS-COCO, and CC152K benchmarks
- Demonstrates robust performance across varying mismatching rates

## Why This Works (Mechanism)
The approach works by reframing the mismatched pair problem as an optimal transport task where unpaired samples can still provide valuable semantic information. By learning a cost function that maps similarity to cost in a self-supervised manner, the method avoids the pitfall of relying on corrupted representations that may perpetuate errors. The partial OT formulation with masked positive pairs ensures that the model focuses on refining alignments for mismatched samples while preserving correct pairings. This combination allows the system to extract maximum value from noisy training data by discovering implicit semantic relationships between unpaired samples.

## Foundational Learning

**Optimal Transport (OT)**: A mathematical framework for finding the most efficient way to transform one probability distribution into another. Needed for modeling the rematching process as an optimization problem. Quick check: Verify that the OT formulation correctly handles the discrete nature of training samples.

**Cross-Modal Retrieval**: The task of retrieving items from one modality (e.g., images) based on queries from another modality (e.g., text). Needed as the target application domain. Quick check: Ensure that the learned embeddings preserve cross-modal semantic relationships.

**Self-Supervised Learning**: A training paradigm where supervision signals are derived from the data itself rather than external labels. Needed to learn the cost function without relying on potentially corrupted paired labels. Quick check: Validate that the self-supervised cost learning converges and produces meaningful similarity-cost mappings.

## Architecture Onboarding

Component map: Input representations -> Learnable cost function -> Partial OT solver -> Refined alignments -> Cross-modal retrieval model

Critical path: The most time-consuming step is solving the OT problem at each training iteration. This creates a bottleneck that scales with dataset size and the number of potential pairings considered.

Design tradeoffs: The method trades computational efficiency for robustness - solving OT problems is expensive but enables better use of mismatched data. The partial masking of positive pairs prevents over-correction but requires careful hyperparameter tuning.

Failure signatures: Performance degradation when unpaired samples lack meaningful semantic similarity, or when the OT solver fails to converge due to ill-conditioned cost matrices.

First experiments: 1) Validate the learnable cost function on a small synthetic dataset with known similarity relationships. 2) Test the partial OT formulation with controlled noise levels. 3) Benchmark retrieval performance on clean data to establish baseline performance.

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Effectiveness depends on the assumption that unpaired samples maintain meaningful semantic similarity
- Computational complexity of solving OT problems for large-scale datasets remains unclear
- Performance in naturally occurring noisy environments (beyond controlled mismatching rates) is untested
- Generalization to other cross-modal domains beyond image-text retrieval has not been explored

## Confidence
- Experimental results and benchmark performance: High
- Theoretical formulation and OT framework: Medium
- Generalizability to other domains and real-world applications: Low
- Scalability to larger datasets: Medium

## Next Checks
1. Test the method on naturally noisy datasets without artificially injected PMPs to assess real-world robustness
2. Evaluate computational efficiency and runtime scaling on datasets significantly larger than the current benchmarks
3. Apply the approach to different cross-modal retrieval tasks (e.g., video-text, audio-image) to verify domain transferability