---
ver: rpa2
title: 'Watermarking Low-entropy Generation for Large Language Models: An Unbiased
  and Low-risk Method'
arxiv_id: '2405.14604'
source_url: https://arxiv.org/abs/2405.14604
tags:
- list
- watermark
- text
- probability
- sta-1
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Sampling One Then Accepting (STA-1) method,
  an unbiased watermarking technique for large language models (LLMs) designed to
  preserve text quality while enabling robust detection of generated content. STA-1
  divides the token set into green and red lists, samples from the original probability
  distribution, and accepts tokens in the green list while resampling for tokens in
  the red list.
---

# Watermarking Low-entropy Generation for Large Language Models: An Unbiased and Low-risk Method

## Quick Facts
- arXiv ID: 2405.14604
- Source URL: https://arxiv.org/abs/2405.14604
- Authors: Minjia Mao; Dongjun Wei; Zeyu Chen; Xiao Fang; Michael Chau
- Reference count: 40
- Primary result: Introduces STA-1, an unbiased watermarking method for LLMs that maintains text quality while enabling robust detection through z-test analysis

## Executive Summary
This paper presents STA-1 (Sampling One Then Accepting), a novel unbiased watermarking technique for large language models that addresses the trade-off between watermark strength and text quality. The method divides tokens into green and red lists, samples from the original probability distribution, and conditionally accepts or resamples tokens based on their classification. Unlike existing methods that require white-box access or prompt engineering, STA-1 uses a statistical z-test for detection, making it practical for real-world deployment. The approach is particularly effective in low-entropy generation scenarios where traditional watermarking methods struggle.

## Method Summary
STA-1 is an unbiased watermarking method that preserves the original probability distribution of LLM outputs while embedding detectable watermarks. The technique works by partitioning the token vocabulary into green and red lists, then performing conditional sampling: tokens in the green list are accepted as sampled, while tokens in the red list trigger resampling until a green token is obtained. This process maintains the marginal probability distribution of the original model while creating a detectable pattern. Detection is performed using a z-test on the frequency of green tokens, eliminating the need for white-box access to the model or specialized prompts. The method includes an extension called STA-M that further enhances watermark strength with minimal quality degradation.

## Key Results
- STA-1 achieves comparable text quality and watermark strength to existing unbiased methods on C4 and HumanEval datasets
- STA-M extends STA-1 to provide enhanced watermark strength with negligible impact on output quality
- The method demonstrates robustness against common watermarking attacks including fine-tuning and token substitution
- Theoretical analysis proves STA-1 is unbiased and provides statistical guarantees on type II error, with performance bounds linked to the Gini index

## Why This Works (Mechanism)
STA-1 works by exploiting the statistical properties of token distributions during generation. By conditionally accepting or resampling tokens based on a predetermined partition, the method creates a detectable pattern in the output sequence while maintaining the marginal probability distribution. The z-test detection leverages the law of large numbers - as output length increases, the frequency of green tokens converges to a predictable value under the null hypothesis, enabling reliable detection. The relationship between the Gini index and watermark strength emerges because more skewed distributions (higher Gini) create stronger statistical signals for detection while requiring fewer conditional operations.

## Foundational Learning

**Conditional Sampling**: Why needed - To create detectable patterns without biasing the output distribution; Quick check - Verify marginal probabilities match original model after many samples

**Z-test for Detection**: Why needed - Provides statistical framework for detection without model access; Quick check - Calculate p-values for varying sequence lengths and token frequencies

**Gini Index**: Why needed - Quantifies distribution skew affecting watermark strength; Quick check - Compute Gini for different token probability distributions

**Type I/II Error Trade-off**: Why needed - Balances false positive/negative rates in detection; Quick check - Plot ROC curves for different detection thresholds

**Unbiased Watermarking**: Why needed - Ensures output quality matches original model; Quick check - Compare perplexity scores between watermarked and original outputs

## Architecture Onboarding

**Component Map**: Probability Distribution -> Token Partition (Green/Red) -> Conditional Sampling -> Output Sequence -> Detection (Z-test)

**Critical Path**: The most critical components are the token partitioning algorithm and the conditional sampling mechanism. The partitioning must be carefully designed to balance watermark strength and output quality, while the sampling process must maintain statistical properties.

**Design Tradeoffs**: The primary tradeoff is between watermark strength (favoring more aggressive red list partitioning) and output quality (favoring minimal partitioning). STA-1 optimizes this by using the Gini index to determine optimal partitioning that maximizes detection power while minimizing quality degradation.

**Failure Signatures**: Common failure modes include: excessive rejection sampling leading to poor quality (red list too large), weak watermark detection (green list too small or poorly distributed), and computational overhead from frequent resampling in low-entropy scenarios.

**3 First Experiments**:
1. Compare STA-1 output perplexity against original model across different entropy regimes
2. Measure detection accuracy vs. sequence length for varying Gini indices
3. Test robustness against token substitution attacks by measuring detection rate after controlled perturbations

## Open Questions the Paper Calls Out

None identified in the provided material.

## Limitations

- Effectiveness in highly constrained generation tasks (like strict syntax code generation) not thoroughly evaluated
- Theoretical analysis assumes ideal conditions about probability distributions that may not hold in practice
- Experimental validation focuses on common attacks, potentially missing sophisticated adversarial scenarios

## Confidence

**High Confidence**: Core methodology and theoretical unbiasedness analysis are sound and well-presented
**Medium Confidence**: Theoretical bounds on error rates and Gini-index relationships may be conservative in practice
**Low Confidence**: Scalability to extremely large vocabularies and performance in specialized domains remain unclear

## Next Checks

1. **Cross-domain robustness testing**: Evaluate STA-1 performance on specialized corpora (medical, legal, technical) where token distributions are highly skewed and generation constraints are stricter.

2. **Adversarial attack analysis**: Conduct comprehensive testing against sophisticated watermark removal techniques, including fine-tuning-based attacks and token substitution strategies that preserve semantic meaning.

3. **Computational overhead measurement**: Quantify the additional computational cost of STA-1 during inference across different model sizes and generation lengths to assess practical deployment feasibility.