---
ver: rpa2
title: Disentangling Interactions and Dependencies in Feature Attribution
arxiv_id: '2410.23772'
source_url: https://arxiv.org/abs/2410.23772
tags:
- dependencies
- interactions
- features
- decomposition
- main
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DIP, a novel decomposition method that disentangles
  feature importance scores into standalone contributions, interactions, and dependencies.
  The method addresses the problem that traditional feature importance scores conflate
  individual feature contributions with cooperative effects from interactions and
  dependencies, leading to misinterpretations.
---

# Disentangling Interactions and Dependencies in Feature Attribution

## Quick Facts
- arXiv ID: 2410.23772
- Source URL: https://arxiv.org/abs/2410.23772
- Reference count: 40
- One-line primary result: Introduces DIP, a method that disentangles feature importance scores into standalone contributions, interactions, and dependencies

## Executive Summary
This paper addresses the fundamental problem that traditional feature importance methods conflate individual feature contributions with cooperative effects from interactions and dependencies, leading to misinterpretations of feature importance. The authors introduce DIP (Disentangling Interactions and Dependencies in Predictive power), a novel decomposition method that separates predictive power into three distinct components: standalone contribution, interaction surplus, and main effect dependencies. The method uses generalized additive models to estimate pure interactions between feature groups, then decomposes the predictive power into these interpretable components.

The approach reveals that features often considered unimportant by traditional methods may actually be individually predictive but redundant with other features, while features with high scores may derive their importance primarily from cooperative effects rather than standalone contributions. The authors demonstrate DIP on synthetic examples and real-world datasets, showing that it provides more nuanced and accurate interpretations of feature importance than existing methods.

## Method Summary
DIP is a decomposition method that explains the predictive power of features by separating it into standalone contributions, interaction surplus, and main effect dependencies. The method works by first estimating pure interactions between feature groups using generalized additive models (GGAMs), then applying a cooperative impact decomposition theorem to obtain the three components. The decomposition is based on the L2-loss and uses refitting procedures to estimate the components empirically. The authors prove that this decomposition is unique under certain conditions and demonstrate its application on both synthetic and real-world datasets.

## Key Results
- Traditional feature importance methods conflate standalone contributions with cooperative effects, leading to misinterpretations
- DIP successfully identifies that citric acidity in wine quality is individually predictive but redundant with other features, explaining why traditional methods rate it as unimportant
- The decomposition reveals that some features with high traditional importance scores derive their value primarily from interactions rather than standalone contributions
- The method provides mathematically unique decomposition of predictive power into standalone, interaction, and dependency components under specified conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Traditional feature importance scores conflate individual feature contributions with cooperative effects from interactions and dependencies
- Mechanism: The method decomposes the predictive power into three distinct components: standalone contribution, interaction surplus, and main effect dependencies (cross-predictability and covariance)
- Core assumption: The predictive power can be uniquely decomposed into these components when using L2-loss
- Evidence anchors:
  - [abstract] "existing feature importance methods try to explain the features' joint predictive power with just one individual score for each feature. This is problematic since, commonly, the predictive power is not simply the sum of the features' standalone contributions but also the result of cooperative forces"
  - [section] "In Section 4, we show that predictive power conflates interactions and dependencies. To disentangle their contributions, we first estimate pure interactions in a model (Section 5)"
- Break condition: The decomposition fails if the assumptions for uniqueness of GGAM components are violated (e.g., non-unique decompositions in continuous distributions with zero density regions)

### Mechanism 2
- Claim: Pure interactions can be uniquely separated from main effects in a prediction function
- Mechanism: By finding the L2-optimal approximation of the prediction function within all GGAMs in two feature groups, the residual represents the pure interaction between these groups
- Core assumption: The L2-optimal GGAM approximation is unique under certain conditions (discrete or continuous distributions with positive density)
- Evidence anchors:
  - [section] "Definition 4 (Pure Interaction). Let f : Rd → R be a function... We define the pure interaction of f with respect to XJ and X ¯J as f − g"
  - [section] "Theorem 5 (Equivalent Characterization of Pure Interactions). A GGAM g = gJ + g ¯J is the L2-optimal approximation of f within all GGAMs in XJ and X ¯J if and only if the residual h := f − g satisfies E(h | XJ) = 0 and E(h | X ¯J) = 0"
- Break condition: The decomposition fails if the probability measure doesn't satisfy the uniqueness conditions (e.g., continuous distributions with zero density regions)

### Mechanism 3
- Claim: Main effect dependencies can be decomposed into cross-predictability and covariance components that explain redundancy effects
- Mechanism: Cross-predictability measures how redundant the contributions of two feature groups are (always negative impact), while covariance captures whether the features' effects on the target reinforce or cancel each other (can be positive or negative)
- Core assumption: The decomposition of main effect dependencies into these two components is mathematically valid and interpretable
- Evidence anchors:
  - [section] "Theorem 6 (Cooperative Impact Decomposition). Let (X, Y ) ∼ P be a DGP... We call h∗ := f ∗ − g∗. Then, we get a decomposition Ψ J, ¯J = Var(h∗) Interaction Surplus − Dep J, ¯J | {z } Main Effect Dependencies , where Dep J, ¯J := Var (E (g∗ J | X ¯J)) + Var E g∗ ¯J | XJ | {z } Cross-Predictability + 2 Cov g∗ J , g∗ ¯J | {z } Covariance"
  - [section] "Intuitively, the main effect cross-predictability quantifies how redundant the contributions of the two groups of features are... Being a sum of variances, the cross-predictability is always positive, and its impact on the cooperative impact is always negative"
- Break condition: The interpretation fails if the covariance term dominates the cross-predictability in unexpected ways, leading to counterintuitive results

## Foundational Learning

- Concept: Generalized Additive Models (GAMs) and Generalized Groupwise Additive Models (GGAMs)
  - Why needed here: The decomposition method relies on approximating the prediction function with GGAMs to isolate pure interactions
  - Quick check question: Can you explain the difference between a GAM and a GGAM, and why GGAMs are necessary for this decomposition?

- Concept: Functional decomposition and ANOVA
- Why needed here: The method builds on functional decomposition techniques to separate interaction effects from main effects
  - Quick check question: How does the functional ANOVA decomposition relate to the decomposition used in this paper?

- Concept: Shapley values and feature attribution methods
  - Why needed here: The method can explain the outputs of popular feature importance techniques like LOCO and SAGE
  - Quick check question: What is the relationship between the cooperative impact decomposition and Shapley values?

## Architecture Onboarding

- Component map: GGAM estimation module -> Value function computation module -> Decomposition engine -> Visualization module
- Critical path:
  1. Fit the full model on training data
  2. Decompose the model into GGAM components and pure interactions
  3. Compute value functions for different feature subsets
  4. Apply decomposition theorem to obtain interaction surplus and dependencies
  5. Generate visualizations

- Design tradeoffs:
  - Using GGAMs vs. other function classes: GGAMs provide a good balance between expressiveness and interpretability
  - Refitting vs. conditional integration: Refitting is more practical but may introduce bias
  - Pairwise vs. full decomposition: Pairwise is more interpretable but may miss higher-order interactions

- Failure signatures:
  - Non-unique decompositions when probability measure conditions are violated
  - High variance in estimates when sample size is small
  - Biased estimates when using marginal sampling instead of conditional integration

- First 3 experiments:
  1. Apply DIP to the XOR example to verify it correctly identifies interactions
  2. Test DIP on the student exam example to verify it correctly identifies negative dependencies
  3. Apply DIP to the wine quality dataset to verify it reveals the citric acid redundancy issue

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the DIP decomposition be extended to handle continuous interactions beyond two groups of features?
- Basis in paper: [explicit] The authors state "our focus on explaining the cooperation between two groups of features" but note this is "comparatively easy to estimate and interpretable" compared to methods attributing every possible subset
- Why unresolved: The paper only demonstrates decomposition for two groups, and extending to more groups would require new mathematical proofs and estimation procedures
- What evidence would resolve it: A mathematical proof showing how to decompose predictive power into standalone, interaction, and dependency components for k>2 feature groups, along with empirical validation on multi-group datasets

### Open Question 2
- Question: How sensitive is the DIP decomposition to the choice of ML model used to estimate the GGAM components?
- Basis in paper: [inferred] The authors mention using explainable boosting machines and linear models in experiments but don't systematically evaluate model sensitivity
- Why unresolved: Different ML models may capture interactions and dependencies differently, potentially affecting the uniqueness and stability of the decomposition
- What evidence would resolve it: A systematic comparison showing DIP results across multiple model types (GAMs, neural networks, tree-based models) on the same datasets with quantitative stability metrics

### Open Question 3
- Question: Can DIP be adapted to handle categorical features with more than two levels, and how would the decomposition change?
- Basis in paper: [explicit] The authors use binary features in examples (e.g., homework completion, review session attendance) but don't discuss multi-level categorical features
- Why unresolved: The current formulation uses L2-loss and variance decomposition, which may not directly extend to categorical interactions without modification
- What evidence would resolve it: A demonstration of DIP applied to a dataset with multi-level categorical features, showing how the interaction surplus and dependency components are computed and interpreted for such features

## Limitations

- Uniqueness conditions depend on specific probability measure properties, with unclear behavior in edge cases like degenerate features or zero density regions
- Computational scalability may be limited for high-dimensional datasets due to the need to fit multiple GGAMs and estimate conditional expectations
- Practical interpretability of the cross-predictability and covariance components may be challenging without domain expertise

## Confidence

- High confidence: The mathematical framework for decomposing predictive power into standalone contributions, interaction surplus, and main effect dependencies is sound and well-established
- Medium confidence: The empirical results demonstrating the method's utility on real-world datasets are promising but limited to two datasets
- Low confidence: The scalability and computational efficiency of the method for high-dimensional problems has not been thoroughly evaluated

## Next Checks

1. **Edge case analysis**: Test the decomposition method on synthetic datasets with degenerate features (e.g., perfectly correlated features or features with zero variance) to identify failure modes and characterize when the uniqueness conditions break down

2. **Computational benchmarking**: Evaluate the runtime and memory requirements of DIP as the number of features increases from 10 to 100, comparing against baseline feature importance methods to quantify the computational overhead

3. **Cross-domain validation**: Apply DIP to at least three additional diverse datasets from different domains (e.g., healthcare, finance, and image classification) to assess the generalizability of the insights and identify domain-specific patterns in the decomposition results