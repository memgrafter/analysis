---
ver: rpa2
title: Genetic Approach to Mitigate Hallucination in Generative IR
arxiv_id: '2409.00085'
source_url: https://arxiv.org/abs/2409.00085
tags:
- relevance
- gauge
- grounded
- answers
- hallucination
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work tackles hallucination in grounded answer generation by
  introducing a genetic algorithm framework called GAuGE that iteratively refines
  candidate answers using a balanced fitness function. The fitness function combines
  relevance from a cross-encoder model and n-gram overlap with seed documents to ensure
  factual grounding.
---

# Genetic Approach to Mitigate Hallucination in Generative IR

## Quick Facts
- arXiv ID: 2409.00085
- Source URL: https://arxiv.org/abs/2409.00085
- Reference count: 40
- Primary result: GAuGE quadruples grounded answer generation accuracy while maintaining high relevance

## Executive Summary
This paper addresses hallucination in grounded answer generation by introducing GAuGE, a genetic algorithm framework that iteratively refines candidate answers. The approach uses a balanced fitness function combining relevance scores from a cross-encoder model with n-gram overlap metrics to ensure factual grounding. Evaluated across three datasets using four fact verification models, GAuGE achieves up to 0.954 grounded answer generation accuracy while maintaining high relevance scores.

## Method Summary
GAuGE is a genetic algorithm framework that mitigates hallucination in grounded answer generation. It starts with seed documents retrieved via BM25 and re-ranked using Electra, then iteratively refines answers using genetic operators (mutation, crossover, random) guided by a balanced fitness function. The fitness function combines an Electra cross-encoder for query-answer relevance with Rouge n-gram overlap to ensure grounding in seed documents. The system uses GPT-3 or GPT-4 as LLM rewriters and iterates until termination criteria are met, producing answers that are both relevant and factually grounded.

## Key Results
- Achieves 0.954 grounded answer generation accuracy, quadrupling baseline performance
- Maintains high relevance scores while significantly improving grounding
- Demonstrates robustness across different LLMs (GPT-3, GPT-4) and fitness function designs
- Rouge2 yields highest grounding accuracy while Rouge1 preserves relevance

## Why This Works (Mechanism)

### Mechanism 1
The balanced fitness function drives the evolutionary search toward grounded answers while maintaining relevance. It combines a cross-encoder model (Electra) for query-answer relevance and an n-gram overlap metric (Rouge) to ensure grounding in seed documents. The weighted combination ensures candidates with high relevance AND high grounding are prioritized.

### Mechanism 2
The iterative genetic refinement prevents the system from getting stuck in local maxima, producing more diverse and grounded responses. The combination of genetic operators (mutation, crossover, random) allows the system to explore new answer variants that are not just slightly modified versions of seed documents.

### Mechanism 3
Using multiple seed documents ensures that generated answers are comprehensive and factually consistent across different sources. By considering multiple seed documents during the Rouge-based grounding calculation, GAuGE ensures the generated answer is supported by combined evidence from several documents rather than relying on a single potentially flawed source.

## Foundational Learning

- **Cross-encoder models for relevance scoring**: GAuGE uses Electra to evaluate answer relevance to queries. Understanding cross-encoder architecture and performance differences from bi-encoders is crucial for component modification.

- **Genetic algorithms and evolutionary computation**: GAuGE is built on genetic algorithm principles. Understanding genetic operators (mutation, crossover), fitness functions, and evolutionary cycles is essential for tuning and diagnosing issues.

- **N-gram overlap metrics (Rouge) for text similarity**: GAuGE uses Rouge metrics (Rouge1, Rouge2, RougeL) to measure overlap between generated answers and seed documents. Understanding these metrics is important for choosing the right variant and interpreting results.

## Architecture Onboarding

- **Component map**: Query + documents -> BM25 + Electra retrieval -> Genetic operators (LLM-based) -> Fitness function (Electra + Rouge) -> Iteratively refined answer -> MonoT5 evaluation + ALBERT verification

- **Critical path**: 1) Query and documents input 2) Initial retrieval produces seed documents 3) Genetic operators generate new candidates 4) Fitness function scores candidates 5) Top candidates survive to next iteration 6) Process repeats until termination 7) Final answer output and evaluated

- **Design tradeoffs**: Relevance vs. grounding (fitness function weights), computational cost vs. answer quality (iteration count), LLM choice (GPT-3 vs. GPT-4 cost/effectiveness), Rouge variant selection (Rouge1 favors relevance, Rouge2 favors grounding)

- **Failure signatures**: Low relevance despite high Rouge scores (over-prioritizing grounding), low grounding despite high relevance scores (over-prioritizing relevance), no improvement over iterations (insufficient diversity/convergence), high computational cost with minimal gains (excessive iterations/inefficient operators)

- **First 3 experiments**: 1) Vary scaling parameter λ in fitness function to find optimal relevance-grounding balance 2) Compare Rouge1, Rouge2, RougeL performance on small dataset 3) Test GPT-3 vs. GPT-4 impact on quality and cost

## Open Questions the Paper Calls Out

- **Open Question 1**: How does GAuGE's performance scale with increasing numbers of seed documents per query, and is there an optimal number beyond which additional documents cease to improve grounding?

- **Open Question 2**: What is the time complexity of GAuGE compared to baseline methods, and how does it scale with query volume in production environments?

- **Open Question 3**: How robust is GAuGE to adversarial queries specifically designed to trigger hallucinations, such as those containing ambiguous entities or complex mathematical expressions?

## Limitations
- Exact optimal value of scaling parameter λ remains unspecified
- Genetic algorithm's convergence behavior and sensitivity to population size are not characterized
- Approach's robustness to conflicting information across multiple seed documents is not evaluated

## Confidence
- **High confidence**: Framework's ability to improve grounded answer generation accuracy through iterative refinement (supported by 0.954 accuracy results)
- **Medium confidence**: Generality claim across different LLMs and fitness function designs (based on ablation studies with 3 datasets and 4 fact verification models)
- **Medium confidence**: Mechanism by which balanced fitness function guides evolution (mechanism described but not directly validated through ablation)

## Next Checks
1. Conduct sensitivity analysis varying scaling parameter λ across plausible range to determine optimal balance
2. Test approach on datasets with known conflicting information across seed documents
3. Compare GAuGE against alternative evolutionary strategies to establish contribution of each component