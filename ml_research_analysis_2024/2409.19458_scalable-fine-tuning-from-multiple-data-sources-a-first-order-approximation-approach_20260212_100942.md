---
ver: rpa2
title: 'Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation
  Approach'
arxiv_id: '2409.19458'
source_url: https://arxiv.org/abs/2409.19458
tags:
- fine-tuning
- tasks
- subset
- selection
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a scalable approach for subset selection
  in fine-tuning language models across multiple data sources. The core method, GRAD
  EX, uses multitask training to obtain a meta-initialization, then approximates fine-tuning
  losses using first-order Taylor expansions with gradients, enabling fast estimation
  without repeated training.
---

# Scalable Fine-tuning from Multiple Data Sources: A First-Order Approximation Approach

## Quick Facts
- arXiv ID: 2409.19458
- Source URL: https://arxiv.org/abs/2409.19458
- Authors: Dongyue Li; Ziniu Zhang; Lu Wang; Hongyang R. Zhang
- Reference count: 40
- Primary result: 30× speedup in subset selection with <1% loss approximation error

## Executive Summary
This paper introduces GRAD EX, a scalable approach for subset selection in fine-tuning language models across multiple data sources. The method combines multitask training to obtain a meta-initialization with first-order Taylor expansion to approximate fine-tuning losses, enabling fast estimation without repeated training. GRAD EX is empirically validated across twelve transformer-based LMs including Llama-3-8B, achieving significant computational efficiency while maintaining high accuracy in subset selection.

## Method Summary
GRAD EX uses multitask training to establish a meta-initialization point, then applies first-order Taylor expansion to approximate fine-tuning losses using gradients. This approach enables rapid subset selection without the need for repeated training cycles. The method is specifically designed for scenarios involving multiple data sources and demonstrates strong performance across various transformer-based language models.

## Key Results
- Achieves 30× speedup over conventional subset selection methods
- Maintains less than 1% error in loss approximation across all tested models and tasks
- Outperforms existing gradient or representation similarity-based selection methods by up to 3.8% in accuracy
- Uses less than 0.5% of the computational cost compared to baseline methods

## Why This Works (Mechanism)
GRAD EX works by leveraging the mathematical properties of first-order Taylor expansions to approximate the loss landscape without requiring full fine-tuning. The multitask meta-initialization provides a robust starting point that captures relevant information across multiple data sources. By combining these elements, the method can efficiently estimate which subsets of data will yield the best performance improvements during fine-tuning.

## Foundational Learning
- First-order Taylor expansion: Linear approximation of functions using derivatives; needed for efficient loss estimation without full training
- Quick check: Verify that the approximation error remains bounded for the function being approximated
- Multitask training: Joint training on multiple tasks to obtain a generalized initialization; needed to capture cross-domain information
- Quick check: Ensure the meta-initialization improves performance across all constituent tasks
- Gradient-based subset selection: Using gradients to identify informative samples; needed for efficient data prioritization
- Quick check: Confirm that high-gradient samples correlate with model improvement
- Transformer-based language models: Neural architectures using self-attention mechanisms; needed as the target models for fine-tuning
- Quick check: Validate that the approach generalizes across different transformer architectures

## Architecture Onboarding
- Component map: Data sources -> Multitask training -> Meta-initialization -> First-order approximation -> Subset selection -> Fine-tuning
- Critical path: The multitask training phase followed by gradient computation and Taylor expansion forms the computational bottleneck
- Design tradeoffs: First-order approximation offers speed but may miss higher-order effects; multitask training adds overhead but improves generalization
- Failure signatures: Large approximation errors (>1%) indicate breakdown of the first-order assumption or poor meta-initialization
- First experiments: 1) Test on single data source to verify basic functionality 2) Compare with random subset selection 3) Evaluate sensitivity to meta-initialization quality

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability across diverse domain distributions beyond evaluated instruction tuning and chain-of-thought tasks remains uncertain
- First-order approximation accuracy may degrade for extremely large or heterogeneous data sources where higher-order effects dominate
- Computational efficiency claims may not hold for non-transformer architectures or fundamentally different feature spaces

## Confidence
- Core technical contribution: High
- Computational efficiency claims: Medium
- Superiority over representation similarity methods: Medium

## Next Checks
1. Test GRAD EX on data sources with high domain shift or extreme class imbalance to assess robustness of the first-order approximation
2. Evaluate computational scaling behavior when applying GRAD EX to models with >100B parameters and datasets exceeding 1M samples
3. Compare GRAD EX performance against second-order approximation methods to quantify the trade-off between approximation accuracy and computational efficiency