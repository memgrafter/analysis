---
ver: rpa2
title: Large Language Models for Document-Level Event-Argument Data Augmentation for
  Challenging Role Types
arxiv_id: '2403.03304'
source_url: https://arxiv.org/abs/2403.03304
tags:
- roles
- event
- data
- role
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of few-shot cross-domain document-level
  event argument extraction (DocEAE), where models must extract event arguments from
  long documents (10+ sentences) with limited training data, especially for roles
  with little to no training representation. The authors introduce two novel LLM-powered
  data augmentation frameworks that require no in-domain training data.
---

# Large Language Models for Document-Level Event-Argument Data Augmentation for Challenging Role Types

## Quick Facts
- arXiv ID: 2403.03304
- Source URL: https://arxiv.org/abs/2403.03304
- Authors: Joseph Gatto; Parker Seegmiller; Omar Sharif; Sarah M. Preum
- Reference count: 27
- Primary result: LLM-based data augmentation significantly improves zero-shot and semantically outlying role extraction in document-level event argument extraction

## Executive Summary
This paper addresses the challenge of few-shot cross-domain document-level event argument extraction (DocEAE), where models must extract event arguments from long documents with limited training data, especially for roles with little to no training representation. The authors introduce two novel LLM-powered data augmentation frameworks that require no in-domain training data. Mad Lib Aug (MLA) leverages LLMs' understanding of Mad Libs to generate templated documents where event roles serve as categories, then fills in these categories to create annotated training samples. Struct2Text (S2T) uses LLMs to convert structured event information into documents, employing semantic n-gram matching to align generated structures with actual text spans. The methods significantly improve performance on zero-shot roles (13-point increase in F1 score) and semantically outlying roles as measured by a novel Role-Depth F1 (RDF1) metric (up to 11-point improvement). Both approaches work with various LLM backbones and show that data augmentation can effectively enhance cross-domain DocEAE performance without sacrificing overall F1 scores.

## Method Summary
The paper proposes two LLM-powered data augmentation frameworks for document-level event argument extraction (DocEAE) in few-shot cross-domain settings. The first framework, Mad Lib Aug (MLA), uses LLMs to generate Mad Lib-style documents where event roles serve as categories, then fills these categories to create annotated training samples. The second framework, Struct2Text (S2T), converts structured event information into documents using LLMs and employs semantic n-gram matching to align generated structures with actual text spans. Both methods require zero in-domain training data and are evaluated on the DocEE dataset with source and target domains. The augmentation data is used to train baseline DocEAE models (BERT-QA and LongFormer-Seq), with evaluation using exact match F1, Role-F1, Zero-Shot F1, and Role-Depth F1 (RDF1) metrics for semantically outlying roles.

## Key Results
- Mad Lib Aug and Struct2Text significantly improve performance on zero-shot roles, achieving a 13-point increase in F1 score
- Both methods improve extraction of semantically outlying roles, with up to 11-point improvement in RDF1 metric
- S2T provides slightly higher scores than MLA on various metrics, demonstrating it as a powerful method for DocEAE data generation
- The augmentation methods work with various LLM backbones including GPT-3.5, GPT-4, and Llama2 variants

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based data augmentation significantly improves performance on zero-shot and semantically outlying roles in DocEAE.
- Mechanism: By generating synthetic documents with annotated event arguments using LLMs, the model receives training data for roles that have little or no representation in the original dataset. This is particularly effective for roles that are semantically different from those in the source domain, as measured by the Role-Depth F1 (RDF1) metric.
- Core assumption: LLMs can generate high-quality, diverse documents that accurately represent event arguments, including those that are rare or absent in the training data.
- Evidence anchors:
  - [abstract]: "Our highest performing methods provide a 16-pt increase in F1 score on extraction of zero shot role types."
  - [section 5]: "Both MLA and S2T significantly improve performance on semantically outlying RDF1 roles."
  - [corpus]: Found 25 related papers (using 8). Average neighbor FMR=0.488, average citations=0.0. Top related titles include works on document-level event argument extraction and LLM potential for event extraction, suggesting a relevant but not highly saturated research area.
- Break condition: If the LLM-generated documents do not accurately represent the event arguments, or if the synthetic data introduces too much noise, the augmentation could degrade model performance.

### Mechanism 2
- Claim: The Mad Lib Aug (MLA) framework leverages LLMs' understanding of Mad Libs to generate templated documents where event roles serve as categories.
- Mechanism: By prompting the LLM to write a Mad Lib about a given event type and listing each role as a category, the framework ensures that all possible roles for an event are included in the generated document. The LLM then fills in these categories with appropriate information, creating annotated training samples.
- Core assumption: LLMs have a strong conceptual understanding of Mad Libs and can generate diverse, coherent documents when provided with event role categories.
- Evidence anchors:
  - [section 3.1]: "We use LLMs to both generate and solve Mad Libs in this framework."
  - [section 5]: "We find that both MLA and S2T have the capacity to significantly improve the breadth of roles which can be accurately predicted by a DocEAE model."
  - [corpus]: The corpus evidence is weak as there are no directly related papers specifically using Mad Libs for data augmentation in event argument extraction.
- Break condition: If the LLM fails to generate coherent Mad Libs or if the slot-filling process introduces errors, the quality of the generated data could be compromised.

### Mechanism 3
- Claim: The Struct2Text (S2T) framework uses LLMs to convert structured event information into documents, employing semantic n-gram matching to align generated structures with actual text spans.
- Mechanism: By creating a custom class for each event in the target domain and using OpenAI's function calling capability to populate it with event information, the framework generates documents that include the necessary event arguments. Semantic n-gram matching ensures that the generated text accurately reflects the structured data.
- Core assumption: LLMs can effectively transform structured event data into natural language text, and semantic n-gram matching can reliably align the generated structures with the text.
- Evidence anchors:
  - [section 3.2]: "We employ semantic n-gram matching to align the structure with spans in the generated document."
  - [section 5]: "S2T, on average, provides slightly higher scores than MLA on various metrics and is thus a powerful method of DocEAE data generation."
  - [corpus]: The corpus evidence is weak as there are no directly related papers specifically using structured-to-text generation for event argument extraction.
- Break condition: If the semantic n-gram matching fails to accurately align the structures with the text, or if the LLM-generated documents do not accurately represent the event arguments, the quality of the generated data could be compromised.

## Foundational Learning

- Concept: Event Argument Extraction (EAE)
  - Why needed here: Understanding EAE is crucial for grasping the problem the paper addresses and the significance of the proposed solutions.
  - Quick check question: What is the difference between sentence-level and document-level EAE, and why is the latter more challenging?

- Concept: Few-shot Cross-Domain (FSCD) Learning
  - Why needed here: FSCD is the specific setting in which the paper's methods are evaluated, and understanding it is essential for appreciating the challenges and the proposed solutions.
  - Quick check question: How does FSCD differ from traditional supervised learning, and what are the main challenges associated with it?

- Concept: Data Augmentation
  - Why needed here: Data augmentation is the core strategy employed by the paper to address the challenges of FSCD in EAE, and understanding it is crucial for grasping the proposed methods.
  - Quick check question: What are the different types of data augmentation techniques, and how do they differ in their application to NLP tasks?

## Architecture Onboarding

- Component map: Event schema and role definitions -> LLM-powered document generation (MLA or S2T) -> Semantic n-gram matching (S2T only) -> Document annotation -> EAE model training -> Performance evaluation
- Critical path: 1. Define event schema and roles 2. Generate synthetic documents using MLA or S2T 3. Align generated structures with text (for S2T) 4. Train EAE model on augmented data 5. Evaluate model performance on zero-shot and semantically outlying roles
- Design tradeoffs: Using open-source vs. proprietary LLMs for data generation, balancing the scale of augmentation with the risk of introducing noise, choosing between MLA and S2T based on the specific requirements and constraints of the task
- Failure signatures: Poor performance on zero-shot and semantically outlying roles, inconsistent or noisy annotations in the generated documents, overfitting to the augmented data at the expense of generalization
- First 3 experiments: 1. Generate a small set of documents using MLA with a simple event schema to test the framework's functionality 2. Compare the performance of MLA and S2T on a subset of the DocEE dataset to assess their relative effectiveness 3. Evaluate the impact of different LLM backbones (e.g., GPT-3.5 vs. GPT-4) on the quality of the generated documents and the subsequent model performance

## Open Questions the Paper Calls Out
- How do the two augmentation methods (Mad Lib Aug and Struct2Text) perform on multi-argument roles, and what modifications could improve their handling of such roles?
- How does the performance of the augmentation methods vary with different RDF1 threshold percentages for identifying outlying roles?
- How can the Mad Lib Aug method be extended to generate documents with greater diversity, both in terms of Mad Lib Generation (e.g., generating narrative works) and Mad Lib Slot-Filling (e.g., the Mad Lib solver takes the perspective of a specific person)?
- How can the Struct2Text method be adapted to work with open-source LLMs that have been fine-tuned for function calling in a manner that facilitates DocEAE data generation?

## Limitations
- The results depend heavily on the quality and diversity of LLM-generated documents, but evaluation focuses primarily on semantic similarity rather than factual accuracy or consistency
- The evaluation only considers natural disaster events in the target domain, limiting generalizability to other domains
- The paper doesn't explore the optimal amount of augmented data needed, potentially leaving open questions about efficiency
- The augmentation methods may introduce noise if LLMs hallucinate incorrect role types or generate documents that don't reflect realistic event scenarios

## Confidence
- High Confidence: The empirical results showing significant improvements on zero-shot roles (13-point F1 increase) and RDF1 metrics (up to 11-point improvement) are well-supported by the experimental setup and multiple LLM backbones tested
- Medium Confidence: The claim that both MLA and S2T work with various LLM backbones is supported by experiments with GPT-3.5, GPT-4, and Llama2, though the relative performance differences between these models across both methods could benefit from more extensive testing
- Low Confidence: The assertion that no in-domain training data is required may overstate the practical applicability, as the methods still require careful prompt engineering and quality control to ensure the generated documents are useful for training

## Next Checks
1. Conduct a qualitative analysis of a sample of LLM-generated documents to assess factual accuracy and coherence, comparing hallucination rates across different LLM backbones and augmentation methods
2. Test the methods on a broader range of target domains beyond natural disasters to evaluate generalizability and identify domain-specific limitations
3. Perform ablation studies varying the amount of augmented data to determine the optimal balance between data quantity and quality for different event types