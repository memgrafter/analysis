---
ver: rpa2
title: Balanced Gradient Sample Retrieval for Enhanced Knowledge Retention in Proxy-based
  Continual Learning
arxiv_id: '2412.14430'
source_url: https://arxiv.org/abs/2412.14430
tags:
- learning
- ours
- continual
- tasks
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in continual learning
  for deep neural networks by proposing a novel sample retrieval strategy from the
  memory buffer. The method combines gradient-conflicting and gradient-aligned samples
  within a supervised contrastive learning framework, balancing knowledge retention
  of past tasks with learning new tasks.
---

# Balanced Gradient Sample Retrieval for Enhanced Knowledge Retention in Proxy-based Continual Learning

## Quick Facts
- arXiv ID: 2412.14430
- Source URL: https://arxiv.org/abs/2412.14430
- Reference count: 40
- Primary result: Balanced gradient sample retrieval outperforms methods using only one sample type or random retrieval, achieving superior accuracy and significantly reduced proxy drift in continual learning.

## Executive Summary
This paper addresses catastrophic forgetting in continual learning for deep neural networks by proposing a novel sample retrieval strategy from the memory buffer. The method combines gradient-conflicting and gradient-aligned samples within a supervised contrastive learning framework, balancing knowledge retention of past tasks with learning new tasks. Gradient-conflicting samples reduce interference by preserving past task knowledge, while gradient-aligned samples reinforce stable, shared representations across tasks. Experimental results on six benchmark datasets show that this balanced approach outperforms methods using only one sample type or random retrieval, achieving superior accuracy and significantly reduced proxy drift.

## Method Summary
The method uses a memory buffer to store samples from past tasks and employs a balanced retrieval strategy during training. For each training iteration, it selects N gradient-conflicting samples (with highest loss change criterion C) and N gradient-aligned samples (with lowest C) from the buffer, along with the current batch. The loss change criterion C is approximated using a Taylor expansion based on the gradient difference between current batch samples and buffer samples. This balanced approach ensures diversity in retrieved samples, preventing proxy drift while maintaining adaptability to new tasks. The method operates within a proxy-based contrastive learning framework, using class proxies instead of cross-entropy loss.

## Key Results
- Balanced retrieval outperforms pure MIR, pure IMIR, and random retrieval across all six benchmark datasets
- Significantly reduced proxy drift compared to baseline methods
- Superior average end accuracy and retention rates while maintaining competitive performance on new tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient-conflicting samples help preserve past task knowledge by reducing interference from new task gradients.
- Mechanism: When new tasks are learned, gradients can overwrite parameters important for past tasks. Gradient-conflicting samples are selected because their gradients oppose the current batch gradients, effectively "counteracting" the forgetting effect and preserving past knowledge.
- Core assumption: The approximation of the loss change criterion C(x) accurately captures gradient misalignment, and samples with high C truly reduce interference.
- Evidence anchors:
  - [abstract]: "Gradient-conflicting samples are selected for their potential to reduce interference by re-aligning gradients, thereby preserving past task knowledge."
  - [section]: "samples with the highest C have the most misaligned gradients with the current task gradient. Including them in the training process improves knowledge retention"
  - [corpus]: "A Unified Gradient-based Framework for Task-agnostic Continual Learning-Unlearning" - suggests gradient-based methods are relevant to CL
- Break condition: If the Taylor approximation used to estimate C(x) is inaccurate, or if the gradient landscape changes dramatically between tasks, the selection may fail to identify truly beneficial samples.

### Mechanism 2
- Claim: Gradient-aligned samples reinforce stable, shared representations across tasks by aligning gradients.
- Mechanism: Gradient-aligned samples have gradients that align with the current batch gradients. Including them in training reinforces the learning of features that are stable and shared across tasks, promoting generalization.
- Core assumption: Samples with low C (high alignment) truly reinforce shared representations and do not introduce noise.
- Evidence anchors:
  - [abstract]: "gradient-aligned samples are incorporated to reinforce stable, shared representations across tasks."
  - [section]: "samples with the lowest C...reinforce model plasticity"
  - [corpus]: "Federated Balanced Learning" - suggests balancing different types of samples is beneficial
- Break condition: If the shared representations are not actually beneficial for future tasks, or if the aligned samples are too homogeneous, this could lead to overfitting to current task patterns.

### Mechanism 3
- Claim: Balanced retrieval increases diversity among retrieved instances, leading to better representation of past task distributions and reduced proxy drift.
- Mechanism: By selecting both gradient-aligned and gradient-conflicting samples, the method ensures a more diverse set of instances from the buffer. This diversity prevents proxy drift by maintaining a stable proxy space that aligns class representations to past knowledge while enabling adaptation to new tasks.
- Core assumption: Diversity in retrieved samples translates to better coverage of the decision space and more stable proxies.
- Evidence anchors:
  - [abstract]: "By balancing gradient correction from conflicting samples with alignment reinforcement from aligned ones, our approach increases the diversity among retrieved instances"
  - [section]: "our balanced sampling strategy significantly mitigates proxy drift across all tasks"
  - [corpus]: Weak evidence - only general CL papers, no direct proxy drift mitigation evidence
- Break condition: If the diversity does not translate to better representation (e.g., if both sample types are similar), or if proxy drift is caused by factors outside the buffer (e.g., architecture limitations).

## Foundational Learning

- Concept: Catastrophic forgetting
  - Why needed here: The entire paper addresses this core problem in continual learning, where models lose performance on previous tasks when learning new ones.
  - Quick check question: What is the primary difference between catastrophic forgetting and simple performance degradation?

- Concept: Experience replay
  - Why needed here: The method uses a memory buffer to store and replay past samples, which is a fundamental approach to mitigate forgetting in continual learning.
  - Quick check question: How does experience replay differ from simply fine-tuning on the entire dataset?

- Concept: Proxy-based contrastive learning
  - Why needed here: The method operates within a contrastive learning framework using class proxies (prototypes) instead of cross-entropy loss, which is a key distinction from traditional methods.
  - Quick check question: What is the main advantage of using proxies in contrastive learning compared to storing entire samples?

## Architecture Onboarding

- Component map:
  Feature extractor (Φh) -> Class proxies (wy) -> Memory buffer (M) -> Sample retrieval module -> Training loop

- Critical path:
  1. Train on current batch → calculate gradients
  2. Use gradients to compute loss change criterion C(x) for buffer samples
  3. Select N gradient-conflicting and N gradient-aligned samples
  4. Train on combined batch + retrieved samples
  5. Update memory buffer with reservoir sampling

- Design tradeoffs:
  - Buffer size vs. retrieval diversity: Larger buffers allow more diverse retrieval but increase computational cost
  - Ratio of aligned vs. conflicting samples: Balancing adaptation vs. retention
  - Approximation accuracy: Taylor expansion vs. exact loss computation

- Failure signatures:
  - High proxy drift despite balanced retrieval → diversity not translating to representation coverage
  - Performance degradation on new tasks → too much focus on retention
  - Overfitting to buffer samples → insufficient diversity or ratio imbalance

- First 3 experiments:
  1. Ablation study: Compare pure MIR, pure IMIR, and balanced retrieval on CIFAR100
  2. Proxy drift analysis: Measure proxy drift over time for different retrieval methods
  3. Diversity measurement: Compare inner distance and proxy distance for different retrieval strategies

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the balanced retrieval strategy affect catastrophic forgetting in extremely long task sequences beyond 20 tasks?
- Basis in paper: [inferred] The paper tested up to 20 tasks but discusses the importance of long-term stability and mentions the need for further analysis of very long task streams.
- Why unresolved: The experimental evaluation was limited to 20 tasks, and the paper explicitly states that further analysis of extremely long task sequences is needed to fully understand the strategy's effectiveness.
- What evidence would resolve it: Experimental results showing performance metrics (accuracy, forgetting, retention rate) on task sequences of 50+ tasks would demonstrate whether the benefits persist or degrade over extended use.

### Open Question 2
- Question: What is the optimal sampling ratio between gradient-aligned and gradient-conflicting samples for different types of continual learning scenarios (e.g., domain-incremental vs class-incremental)?
- Basis in paper: [explicit] The paper tested different sampling ratios and found optimal performance around 5:5, but this was only tested on the datasets used in the experiments.
- Why unresolved: The experiments used a fixed set of datasets and task structures, and the paper acknowledges that different continual learning scenarios might require different optimal ratios.
- What evidence would resolve it: Systematic experiments varying task types (domain-incremental, class-incremental, task-incremental) and measuring performance across different sampling ratios would identify scenario-specific optimal configurations.

### Open Question 3
- Question: How does the proposed method perform when combined with other continual learning techniques such as dynamic architecture expansion or knowledge distillation?
- Basis in paper: [inferred] The paper focuses on memory-based methods and supervised contrastive learning, but doesn't explore combinations with architectural or distillation-based approaches.
- Why unresolved: The experimental framework was designed around specific memory-based methods, and the paper doesn't investigate potential synergies with other CL paradigms.
- What evidence would resolve it: Comparative experiments showing performance when combining balanced retrieval with architectural methods (like PackNet) or distillation methods (like LwF) would reveal potential complementary benefits or conflicts.

## Limitations
- The gradient alignment criterion C is based on a Taylor expansion approximation, which may not accurately capture the true loss landscape for deep networks.
- The method's effectiveness depends heavily on the quality of the approximation and choice of hyperparameters (balanced ratio, buffer size).
- Experimental results would be stronger with more recent state-of-the-art methods as baselines.

## Confidence
- **High Confidence**: The core mechanism of combining gradient-aligned and gradient-conflicting samples is sound and addresses a real problem in continual learning.
- **Medium Confidence**: The experimental results demonstrating superior performance over baselines, though the comparison would be stronger with more recent state-of-the-art methods.
- **Low Confidence**: The proxy drift analysis and diversity measurements, as the evidence for these claims is relatively weak in the paper.

## Next Checks
1. Conduct an ablation study varying the ratio of gradient-aligned to gradient-conflicting samples to determine the optimal balance and test sensitivity to this hyperparameter.
2. Implement a more rigorous proxy drift analysis using multiple distance metrics and visualize proxy trajectories across tasks to verify the claimed mitigation.
3. Test the method on more challenging continual learning scenarios, such as class-incremental learning with overlapping classes or open-set recognition tasks, to evaluate robustness beyond the current benchmark datasets.