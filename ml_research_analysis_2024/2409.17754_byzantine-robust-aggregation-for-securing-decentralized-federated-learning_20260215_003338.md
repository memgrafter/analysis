---
ver: rpa2
title: Byzantine-Robust Aggregation for Securing Decentralized Federated Learning
arxiv_id: '2409.17754'
source_url: https://arxiv.org/abs/2409.17754
tags:
- algorithm
- learning
- aggregation
- attacks
- decentralized
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the security challenge in decentralized federated
  learning (DFL) where existing Byzantine-robust aggregation algorithms are primarily
  designed for centralized settings and may not perform effectively in decentralized
  environments. The authors propose WFAgg, a novel Byzantine-robust aggregation algorithm
  that employs multiple filtering techniques (distance-based, similarity-based, and
  temporal-based) to identify and mitigate Byzantine attacks in DFL environments.
---

# Byzantine-Robust Aggregation for Securing Decentralized Federated Learning

## Quick Facts
- arXiv ID: 2409.17754
- Source URL: https://arxiv.org/abs/2409.17754
- Reference count: 40
- Key outcome: Proposed WFAgg algorithm outperforms centralized Byzantine-robust algorithms in decentralized settings while maintaining better model accuracy and convergence across all tested attack scenarios

## Executive Summary
This paper addresses the security challenge in decentralized federated learning (DFL) where existing Byzantine-robust aggregation algorithms are primarily designed for centralized settings and may not perform effectively in decentralized environments. The authors propose WFAgg, a novel Byzantine-robust aggregation algorithm that employs multiple filtering techniques (distance-based, similarity-based, and temporal-based) to identify and mitigate Byzantine attacks in DFL environments. The algorithm processes models through these filters and uses weighted aggregation to combine the results.

## Method Summary
The paper proposes WFAgg, a Byzantine-robust aggregation algorithm for decentralized federated learning that uses three filtering mechanisms: distance-based filtering (WFAgg-D) identifies outliers using Euclidean distance from the median model, similarity-based filtering (WFAgg-C) detects directional inconsistencies using cosine similarity, and temporal filtering (WFAgg-T) flags abrupt behavioral changes between rounds using moving averages. The algorithm assigns weights to models passing through each filter and performs weighted aggregation to combine results, preserving useful information while reducing Byzantine influence.

## Key Results
- WFAgg outperforms existing centralized Byzantine-robust algorithms (Multi-Krum, Clustering) in decentralized settings
- Maintains better model accuracy and convergence across all tested attack scenarios (Noise, Sign-Flipping, Label-Flipping, IPM, ALIE)
- Successfully mitigates attacks while achieving superior model consistency (R-squared metric) among benign nodes
- Achieved high accuracy even in worst-case scenario with two malicious neighbors per node

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-filter Byzantine-robust aggregation improves resilience over single-filter methods by combining distance, similarity, and temporal anomaly detection
- Mechanism: WFAgg uses three distinct filtering strategies that operate in different model spaces to detect different attack signatures
- Core assumption: Different attack types leave different signatures in model space, and no single filter captures all attack vectors effectively
- Evidence anchors: Abstract states WFAgg "handles the adverse conditions and strength robustness of dynamic decentralized topologies at the same time by employing multiple filters"
- Break condition: If an attack type consistently evades all three filters or if filter weighting parameters are poorly tuned

### Mechanism 2
- Claim: Weighted aggregation of filtered models preserves information while reducing Byzantine influence compared to hard filtering
- Mechanism: Instead of discarding models, WFAgg assigns weights to each filter's benign model set, with models passing multiple filters receiving higher weights
- Core assumption: Byzantine models exhibit detectable patterns that can be weighted appropriately, and benign models pass multiple filters consistently
- Evidence anchors: Section describes how "differential value" is assigned to local models based on filter results
- Break condition: If attack sophistication increases such that malicious models pass multiple filters with benign models

### Mechanism 3
- Claim: Exponentially weighted moving average (EWMA) in temporal filtering adapts to non-stationary attack patterns while maintaining detection sensitivity
- Mechanism: WFAgg-T uses EWMA on distance and similarity metrics over a sliding window to compute means and standard deviations
- Core assumption: Attack patterns evolve over time but exhibit detectable deviations from benign temporal behavior
- Evidence anchors: Section explains how "most recent metrics in the time window are considered, which is useful since patterns change over time"
- Break condition: If attack patterns are too sophisticated to show temporal anomalies or if benign nodes exhibit high natural variability

## Foundational Learning

- Concept: Byzantine fault tolerance in distributed systems
  - Why needed here: The paper addresses Byzantine attacks in decentralized federated learning, requiring understanding of how distributed systems handle malicious actors
  - Quick check question: What is the maximum number of Byzantine nodes a system can tolerate if it uses majority voting among n nodes?

- Concept: Federated learning aggregation mechanisms
  - Why needed here: The paper builds on and extends existing Byzantine-robust aggregation algorithms to the decentralized setting
  - Quick check question: How does FedAvg aggregation differ from Krum aggregation in terms of Byzantine robustness?

- Concept: Distance metrics in high-dimensional spaces
  - Why needed here: The filtering mechanisms rely on Euclidean and cosine distances between model parameter vectors
  - Quick check question: Why might cosine similarity be more informative than Euclidean distance for detecting certain Byzantine attacks?

## Architecture Onboarding

- Component map: Node layer -> Filter layer (WFAgg-D, WFAgg-C, WFAgg-T) -> Aggregation layer (WFAgg-E) -> Communication layer
- Critical path: Local training → Model exchange → Multi-filter processing → Weighted aggregation → Local model update
- Design tradeoffs: Filter complexity vs. computational overhead; window size in temporal filtering vs. sensitivity to sudden attacks; filter weighting parameters vs. attack detection
- Failure signatures: Accuracy degradation despite filtering indicates filter bypass or poor parameter tuning; slow convergence suggests filter overcautiousness; inconsistent R-squared across nodes indicates poor model consensus
- First 3 experiments: 1) Run WFAgg with default parameters on MNIST with Noise attack, measure accuracy and R-squared over 10 rounds; 2) Test WFAgg with different filter weight combinations to find optimal balance for IPM-0.5 attack; 3) Evaluate WFAgg-T temporal window size impact by varying W from 3 to 7 on SF attack scenarios

## Open Questions the Paper Calls Out

- How does the WFAgg algorithm's performance scale with increasing numbers of Byzantine nodes beyond the tested 10% threshold?
- How would the WFAgg algorithm perform on non-IID data distributions where data is heterogeneous across nodes?
- What is the computational overhead of WFAgg compared to simpler Byzantine-robust algorithms like Mean or Median?

## Limitations

- The filtering mechanisms lack specific implementation parameters and thresholds, making it difficult to reproduce exact results
- Evaluation is limited to a single dataset (MNIST) and model architecture (ResNet-18), raising questions about generalizability
- The paper doesn't provide sensitivity analysis for filter weight parameters or temporal window size

## Confidence

- High confidence: The fundamental claim that decentralized settings require different Byzantine-robust approaches than centralized settings
- Medium confidence: The multi-filter approach shows promise but lacks ablation studies to determine individual filter contributions
- Low confidence: The claim of superior performance across all attack scenarios needs more validation with adaptive attack scenarios

## Next Checks

1. Conduct ablation study validation by testing WFAgg variants with individual filters disabled to quantify each filtering mechanism's contribution
2. Perform hyperparameter sensitivity analysis by systematically varying filter weight parameters and temporal window size
3. Evaluate WFAgg on non-IID data distributions and different model architectures to assess real-world applicability