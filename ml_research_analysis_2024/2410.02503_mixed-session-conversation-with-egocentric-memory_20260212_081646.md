---
ver: rpa2
title: Mixed-Session Conversation with Egocentric Memory
arxiv_id: '2410.02503'
source_url: https://arxiv.org/abs/2410.02503
tags:
- memory
- session
- conversation
- speaker
- emma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Mixed-Session Conversation, a dialogue system
  that enables a main speaker to engage with different partners across multiple sessions,
  expanding both the depth and breadth of conversational interactions. To implement
  this system, the authors propose a new dataset called MiSC, which consists of 6
  consecutive sessions per episode involving four speakers, and a dialogue model named
  EMMA that uses an Egocentric Memory mechanism to retain and retrieve context from
  the main speaker's perspective.
---

# Mixed-Session Conversation with Egocentric Memory

## Quick Facts
- arXiv ID: 2410.02503
- Source URL: https://arxiv.org/abs/2410.02503
- Reference count: 40
- One-line primary result: A dialogue system enabling a main speaker to converse with different partners across multiple sessions while maintaining conversation consistency through Egocentric Memory.

## Executive Summary
This paper introduces Mixed-Session Conversation (MiSC), a novel dialogue system that allows a main speaker to engage with different conversation partners across multiple sessions while maintaining coherence and consistency. The authors propose a new dataset MiSC and a dialogue model EMMA that uses an Egocentric Memory mechanism to retain context from the main speaker's perspective. Human evaluations demonstrate that the system achieves high consistency and coherence even when conversation partners change each session.

## Method Summary
The MiSC dataset was generated using LLMs (GPT-4 and GPT-3.5) with 8.5K episodes, each containing 6 consecutive sessions with one main speaker and three partners. The EMMA model consists of a dialogue module (FLAN-T5-Large) for generation and memory management, and a retrieval module (BERT-base) for selecting relevant memories. The system uses Egocentric Memory to store and link memories from the main speaker's perspective for each partner. Training involves cross-entropy loss for dialogue generation and triplet loss for retrieval, with human evaluation assessing consistency, coherence, humanness, engagingness, and memorability.

## Key Results
- MiSC dialogues exhibit high consistency and coherence when conversation partners change across sessions
- EMMA achieves strong performance in humanness, engagingness, and memorability during multi-session interactions
- Egocentric Memory enables accurate recall and alignment of events with each partner without contradiction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Egocentric Memory enables seamless multi-session dialogue by storing and linking memories from the main speaker's perspective for each conversation partner.
- Mechanism: After each session, the model summarizes key events and emotions from the main speaker's viewpoint and links these memories to relevant previous sessions. This creates a network of partner-specific memories that can be retrieved and referenced in subsequent interactions.
- Core assumption: The main speaker's perspective is sufficient to maintain coherent dialogue across changing partners without explicit session metadata.
- Evidence anchors:
  - [abstract] "Egocentric Memory keeps memory about each partner from the main speaker's perspective, enabling accurate recall to align the events with each partner without contradiction."
  - [section 3.3] "Egocentric Memory is maintained across multiple sessions to help the main speaker to understand the conversation comprehensively... connections are initially established within the memory generated in ongoing sessions. Subsequently, these connections extend to incorporate memories from previous sessions."
  - [corpus] Weak evidence - no directly relevant corpus neighbors found.
- Break condition: If the model fails to correctly identify which partner is speaking in a given session, the egocentric memory may become misattributed and cause contradictions.

### Mechanism 2
- Claim: The EMMA architecture can maintain conversation consistency even when the dialogue partner changes between sessions.
- Mechanism: EMMA uses a two-part system where the dialogue module handles generation and memory management tasks while the retrieval module selects the most relevant memories for the current context. This allows the model to adapt its responses based on the specific partner it's currently engaging with.
- Core assumption: Partner-specific memory retrieval is sufficient to disambiguate conversations when the same topic is discussed with different partners.
- Evidence anchors:
  - [section 4.2] "This module retrieves memories built from previous sessions to provide context for the ongoing dialogue. Although can access to all memories, it selectively prioritizes the most relevant ones when generating the next utterance."
  - [section 6] "As evidenced by the evaluation results, the high scores of memory links facilitate seamless tracking and utilization of memory, thereby enhancing the effectiveness of interactions between the main speaker and partners across the entire conversation."
  - [corpus] Weak evidence - no directly relevant corpus neighbors found.
- Break condition: If the conversation context becomes too complex or if multiple partners discuss similar topics, the retrieval module may select inappropriate memories leading to inconsistencies.

### Mechanism 3
- Claim: The sequential dialogue generation process with memory integration creates natural conversational flow across multiple sessions.
- Mechanism: Conversations are generated sequentially from session 1 to 6, with each session incorporating both a session summary and the main speaker's egocentric memory. This ensures continuity while allowing for partner changes.
- Core assumption: GPT-3.5 can maintain conversational coherence when provided with both session summaries and memory references as context.
- Evidence anchors:
  - [section 3.2] "We generate conversations sequentially with ChatGPT from the first to the sixth session, each featuring its own unique session event... To accomplish this goal, we employ two methods: session summaries and the main speaker's memory."
  - [section 5.2] "As evident, all three groups exhibit high scores of both 'Consistency' and 'Coherence', confirming that MISC effectively implements the natural flow of conversation within the MIXED-SESSION CONVERSATION."
  - [corpus] Weak evidence - no directly relevant corpus neighbors found.
- Break condition: If the memory references become too numerous or complex, the model may struggle to maintain coherence or may ignore memory context entirely.

## Foundational Learning

- Concept: Memory management in dialogue systems
  - Why needed here: The system needs to track conversation history across multiple sessions with different partners, requiring sophisticated memory mechanisms beyond simple session summaries.
  - Quick check question: What's the difference between storing generic memories versus partner-specific memories in a multi-session dialogue system?

- Concept: Context retrieval and relevance ranking
  - Why needed here: The retrieval module must select the most appropriate memories from potentially dozens of stored memories for each conversation turn.
  - Quick check question: How would you design a similarity metric to retrieve memories that are contextually relevant to the current conversation?

- Concept: Dialogue coherence and consistency metrics
  - Why needed here: Evaluating the system requires understanding what constitutes good dialogue quality across multiple sessions with changing partners.
  - Quick check question: What distinguishes consistency from coherence in multi-session dialogue evaluation?

## Architecture Onboarding

- Component map: Topic Collection -> Scenario Collection -> Dialogue Generation -> Memory Generation -> Memory Connection -> EMMA Model (Dialogue Module + Retrieval Module + Memory Space)
- Critical path: Data generation → Model training → Human evaluation → Model deployment
  - The memory connection and tagging steps are critical for ensuring EMMA can retrieve relevant memories during conversation
- Design tradeoffs:
  - Memory storage vs. retrieval efficiency: Storing partner-specific memories enables better context but increases retrieval complexity
  - Sequential vs. parallel generation: Sequential generation ensures continuity but limits scalability
  - Human evaluation vs. automated metrics: Human evaluation provides better quality assessment but is more resource-intensive
- Failure signatures:
  - Memory contradictions: Same event described differently to different partners
  - Context loss: Failure to reference previous sessions appropriately
  - Partner confusion: Treating a new partner as if they were a previous one
- First 3 experiments:
  1. Test memory retrieval with a single partner across 3 sessions to verify basic functionality
  2. Test partner switching between sessions 2 and 3 to verify memory disambiguation
  3. Test memory linking by having the same topic discussed with different partners to verify consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EMMA scale when the number of conversation partners per session increases beyond one, as in a true multi-party conversation setting?
- Basis in paper: [inferred] The paper states that MIXED-SESSION CONVERSATION currently involves conversations with only one partner per session, and the authors express interest in exploring settings with multiple partners per session in future research.
- Why unresolved: The current dataset and model are designed for single-partner sessions, so performance in multi-partner sessions remains untested.
- What evidence would resolve it: Experiments comparing EMMA's performance on multi-party sessions versus single-partner sessions, measuring consistency, coherence, and memorability.

### Open Question 2
- Question: How does the quality of EMMA's responses compare when using Egocentric Memory versus a summary-based memory approach in scenarios where the conversation partner changes across sessions?
- Basis in paper: [explicit] The authors conduct an ablation study comparing EMMA with Egocentric Memory to a summary-based model, showing that Egocentric Memory leads to more tailored and detailed responses.
- Why unresolved: While the ablation study provides initial evidence, a more comprehensive comparison across various scenarios and evaluation metrics would strengthen the findings.
- What evidence would resolve it: A large-scale human evaluation comparing responses from EMMA with Egocentric Memory and a summary-based model across diverse conversation scenarios, using metrics like humanness, engagingness, and memorability.

### Open Question 3
- Question: What is the impact of the number of sessions per episode on the overall quality and coherence of the conversation in MISC?
- Basis in paper: [inferred] The paper uses 6 sessions per episode in MISC, but it's unclear if this is the optimal number for maintaining high-quality conversations.
- Why unresolved: The paper doesn't explore the effects of varying the number of sessions per episode on conversation quality.
- What evidence would resolve it: Experiments training EMMA on MISC datasets with different numbers of sessions per episode and evaluating the resulting conversation quality and coherence.

### Open Question 4
- Question: How does the quality of MISC and EMMA's performance compare to human-generated conversations in the same mixed-session setting?
- Basis in paper: [inferred] While the paper extensively evaluates MISC and EMMA using human annotators, it doesn't directly compare their performance to human-generated conversations in the same setting.
- Why unresolved: The lack of a direct comparison with human-generated conversations makes it difficult to assess the true effectiveness of MISC and EMMA.
- What evidence would resolve it: A human evaluation comparing the quality of conversations generated by EMMA and humans in the same mixed-session setting, using metrics like consistency, coherence, and engagingness.

## Limitations

- Dataset Generation Concerns: The MiSC dataset is entirely generated using LLMs, raising questions about its authenticity and representativeness of real human conversation patterns.
- Evaluation Scope: Human evaluations don't assess edge cases like topic drift, misunderstandings, or complex relationship dynamics, nor do they test long-term memory retention beyond the 6-session structure.
- Memory Mechanism Scalability: The system's performance with dozens or hundreds of sessions and large memory sets remains untested.

## Confidence

**High Confidence:** The core claim that EMMA can maintain conversation consistency across changing partners is well-supported by human evaluation results showing high scores for both consistency and coherence.

**Medium Confidence:** The claim that egocentric memory is the key mechanism enabling this consistency is supported by ablation studies, but could benefit from more direct comparisons with alternative memory architectures.

**Low Confidence:** Claims about the naturalness of conversation flow and the effectiveness of memory linking are primarily supported by subjective human evaluations rather than objective metrics or comparisons to baseline systems.

## Next Checks

1. **Cross-dataset validation:** Test EMMA on a dataset of human-generated multi-session conversations to verify that performance on synthetic MiSC data translates to real-world conversations.

2. **Memory retrieval stress test:** Evaluate the retrieval module's performance when presented with increasingly large memory sets (10x, 100x the current size) to assess scalability and identify retrieval accuracy degradation points.

3. **Ablation study with explicit session metadata:** Remove the egocentric memory mechanism and instead provide explicit partner and session metadata to determine whether the memory complexity is necessary or if simpler approaches could achieve similar results.