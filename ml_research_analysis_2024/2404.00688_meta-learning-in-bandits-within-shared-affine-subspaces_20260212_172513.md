---
ver: rpa2
title: Meta Learning in Bandits within Shared Affine Subspaces
arxiv_id: '2404.00688'
source_url: https://arxiv.org/abs/2404.00688
tags:
- learning
- regret
- task
- tasks
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses meta-learning in contextual linear bandits
  by exploiting low-dimensional affine subspace structures shared across tasks. The
  key idea is to use online PCA to learn a projection matrix that captures the subspace
  in which task parameters concentrate, then modify LinUCB and Thompson sampling algorithms
  to leverage this structure via regularization.
---

# Meta Learning in Bandits within Shared Affine Subspaces

## Quick Facts
- arXiv ID: 2404.00688
- Source URL: https://arxiv.org/abs/2404.00688
- Reference count: 40
- Key outcome: Proposed methods significantly outperform standard baselines on both synthetic and real-world MovieLens data by exploiting shared affine subspace structure in meta-learning for contextual bandits

## Executive Summary
This paper addresses meta-learning in contextual linear bandits by exploiting low-dimensional affine subspace structures shared across tasks. The key idea is to use online PCA to learn a projection matrix that captures the subspace in which task parameters concentrate, then modify LinUCB and Thompson sampling algorithms to leverage this structure via regularization. The authors theoretically analyze both algorithms, showing regret bounds that improve with smaller subspace dimensions and lower task variance. Empirically, the proposed methods significantly outperform standard baselines on both synthetic and real-world MovieLens data, demonstrating the benefit of exploiting shared affine subspace structure in meta-learning for contextual bandits.

## Method Summary
The authors propose a meta-learning framework for contextual linear bandits where task parameters share a low-dimensional affine subspace structure. They use online PCA (specifically CCIPCA) to learn a projection matrix that captures this subspace incrementally as new tasks are observed. Two algorithms are developed: Projected LinUCB and Projected Thompson Sampling, which incorporate the learned projection matrix into their confidence bounds and posterior distributions respectively through modified regularization terms. The regularization enforces that task parameters lie near the estimated subspace, reducing exploration needed in directions with low variance.

## Key Results
- Projected LinUCB and Projected Thompson Sampling outperform standard LinUCB, Thompson sampling, B-OFUL, and M-TS baselines on both synthetic and MovieLens datasets
- Theoretical regret bounds show improvement scaling with smaller subspace dimensions (rank p < d)
- Empirical evaluations confirm the benefits of the proposed methods, with significant regret reduction compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The low-dimensional affine subspace assumption allows for regularization terms that enforce task parameters to lie near this subspace, reducing exploration needed in directions with low variance.
- Mechanism: The proposed algorithms use learned projection matrices to modify the covariance structure in the posterior or confidence bounds. This restricts updates to the effective subspace, focusing exploration where most task parameters lie.
- Core assumption: Task parameters concentrate around a low-dimensional affine subspace.
- Break condition: If the true subspace is not well estimated (e.g., due to small eigengap or insufficient data), the regularization could overly constrain learning, leading to poor performance.

### Mechanism 2
- Claim: Online PCA (specifically CCIPCA) enables adaptive subspace estimation without requiring full knowledge of all tasks upfront.
- Mechanism: CCIPCA updates principal component estimates incrementally as new task parameters are observed, allowing the algorithm to adjust to the true subspace structure during meta-learning.
- Core assumption: The subspace structure is stable enough across tasks to be learned incrementally.
- Break condition: If the subspace changes significantly between tasks or if there are insufficient samples per task, the online PCA estimates may be inaccurate.

### Mechanism 3
- Claim: The modified confidence bounds in projected LinUCB and the modified posterior in projected Thompson sampling tighten regret bounds by exploiting the subspace structure.
- Mechanism: By adjusting the regularization parameters λ1 and λ2, the algorithms effectively reduce the exploration dimension from d to p (the subspace rank), leading to improved regret scaling.
- Core assumption: The low variance along the orthogonal subspace allows aggressive regularization without harming learning.
- Break condition: If the variance along the orthogonal subspace is not sufficiently small, the regularization may not provide benefit and could even harm performance by over-constraining.

## Foundational Learning

- Concept: Principal Component Analysis (PCA) and eigendecomposition
  - Why needed here: PCA is used to learn the low-dimensional subspace in which task parameters concentrate. Understanding eigendecomposition is crucial for grasping how the subspace is estimated and how the eigengap affects estimation quality.
  - Quick check question: What is the relationship between the eigengap (σp - σp+1) and the stability of the PCA-based subspace estimate?

- Concept: Regularized least squares and ridge regression
  - Why needed here: Both projected LinUCB and the mean estimation in Thompson sampling rely on ridge regression. The modified objective functions in the paper include additional regularization terms based on the estimated subspace.
  - Quick check question: How does adding a regularization term proportional to ‖P⊥(θ - μ)‖² affect the solution compared to standard ridge regression?

- Concept: Confidence bounds and optimism in the face of uncertainty (OFUL)
  - Why needed here: LinUCB and its projected variant rely on constructing confidence sets around the parameter estimate. Understanding how these bounds are derived and how they scale with problem dimensions is key to grasping the regret analysis.
  - Quick check question: In standard LinUCB, how does the confidence bound scale with the number of rounds n and the dimension d?

## Architecture Onboarding

- Component map: Data preprocessing -> Online PCA (CCIPCA) -> Projected LinUCB or Projected Thompson Sampling -> Evaluation
- Critical path: 
  1. Initialize CCIPCA with orthonormal eigenvectors
  2. For each task: Collect context vectors and rewards, update ridge estimator (LinUCB) or posterior (Thompson), if task complete update CCIPCA with new parameter estimate
  3. Repeat until convergence or task limit
- Design tradeoffs:
  - Exploration vs. exploitation: Controlled by γk in LinUCB and v in Thompson sampling
  - Subspace accuracy vs. computation: More principal components increase accuracy but also computational cost
  - Regularization strength: λ1 vs. λ2 balance subspace enforcement and numerical stability
- Failure signatures:
  - Poor regret performance: Likely due to inaccurate subspace estimate or inappropriate regularization
  - Numerical instability: May occur if λ2 is too small relative to λ1
  - Slow convergence: Could indicate insufficient exploration or poor eigengap
- First 3 experiments:
  1. Run projected LinUCB on synthetic data with known subspace to verify regret improvement
  2. Compare regret of projected vs. standard algorithms as a function of subspace rank p
  3. Test sensitivity to regularization parameters λ1 and λ2 on a fixed dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the eigengap ∆σ affect the reliability and performance of the learned subspace projection, and what are the theoretical implications of choosing p based on the eigengap?
- Basis in paper: The paper discusses the eigengap ∆σ in Lemma 4 and Theorem 1, highlighting its role in the error bound of the projection estimation and the regret bound.
- Why unresolved: While the paper establishes a relationship between the eigengap and the error bound, it does not provide a specific guideline or optimal strategy for choosing p based on the eigengap in practical scenarios.
- What evidence would resolve it: Empirical studies comparing the performance of the algorithms for different choices of p relative to the eigengap would provide insights into the optimal selection strategy.

### Open Question 2
- Question: Can the proposed methods be extended to handle non-linear relationships between rewards and context vectors, and how would the regret bounds change in such settings?
- Basis in paper: The paper focuses on linear contextual bandits, but it mentions the possibility of generalizing to non-linear settings in the discussion section.
- Why unresolved: The paper does not provide a concrete approach or theoretical analysis for extending the methods to non-linear settings, leaving open questions about the feasibility and performance in such scenarios.
- What evidence would resolve it: Developing and analyzing a non-linear variant of the proposed algorithms, along with corresponding regret bounds, would address this question.

### Open Question 3
- Question: How sensitive are the proposed algorithms to the choice of regularization parameters λ1 and λ2, and is there an adaptive method to tune these parameters during learning?
- Basis in paper: The paper discusses the choice of λ1 and λ2 in the context of the optimization problem and their impact on the regret bound, but it does not provide a detailed analysis of their sensitivity or an adaptive tuning method.
- Why unresolved: While the paper suggests choosing λ1 ≫ λ2 to enforce the subspace assumption, it does not explore the sensitivity of the algorithms to these parameters or propose a method to adapt them during learning.
- What evidence would resolve it: Empirical studies investigating the performance of the algorithms for different values of λ1 and λ2, as well as the development of an adaptive tuning method, would provide insights into this question.

## Limitations

- The theoretical guarantees depend critically on the assumption that task parameters lie near a shared affine subspace, which may not hold in practice
- The analysis does not account for potential subspace drift or catastrophic forgetting when task distributions change over time
- Empirical validation uses relatively simple synthetic data and a single real-world dataset (MovieLens), limiting generalizability

## Confidence

- **High confidence**: The mechanism of using regularization to enforce subspace structure and the general framework of meta-learning with shared subspaces
- **Medium confidence**: The theoretical regret bounds and their dependence on subspace rank and eigengap
- **Low confidence**: Performance guarantees under non-stationary subspace conditions and scalability to very high-dimensional problems

## Next Checks

1. **Subspace Stability Test**: Evaluate algorithm performance when the underlying subspace changes gradually or abruptly between tasks to assess robustness to non-stationarity.

2. **Eigengap Sensitivity Analysis**: Systematically vary the eigengap in synthetic experiments to quantify its impact on subspace estimation quality and subsequent regret performance.

3. **Baseline Expansion**: Compare against additional meta-learning baselines (e.g., MAML-based approaches) on more diverse real-world datasets to validate relative performance claims.