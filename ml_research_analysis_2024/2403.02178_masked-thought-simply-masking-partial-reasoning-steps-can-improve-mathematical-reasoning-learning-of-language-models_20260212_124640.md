---
ver: rpa2
title: 'Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical
  Reasoning Learning of Language Models'
arxiv_id: '2403.02178'
source_url: https://arxiv.org/abs/2403.02178
tags:
- reasoning
- arxiv
- steps
- data
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose Masked Thought Fine-Tuning (MFT), a regularization
  method that randomly masks tokens in the reasoning chain of thought during fine-tuning.
  Unlike previous approaches that rely on more precise supervisory signals, MFT introduces
  noise by masking certain tokens, which surprisingly improves mathematical reasoning
  performance.
---

# Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models

## Quick Facts
- arXiv ID: 2403.02178
- Source URL: https://arxiv.org/abs/2403.02178
- Reference count: 40
- Key outcome: MFT achieves 5-10% improvements over standard fine-tuning on GSM8K and GSM-IC datasets

## Executive Summary
Masked Thought Fine-Tuning (MFT) introduces a simple yet effective regularization technique that randomly masks tokens in the reasoning chain of thought during fine-tuning. This approach improves mathematical reasoning performance without requiring more precise supervisory signals or complex architectural changes. The method demonstrates 5-10% accuracy improvements on GSM8K and GSM-IC datasets when applied to Llama-2-7B and Mistral-7B models, while also showing enhanced sample efficiency and compatibility with existing data augmentation techniques.

## Method Summary
MFT is a regularization method that randomly masks tokens within the chain of thought during fine-tuning. The approach introduces controlled noise by replacing certain tokens with [mask] tokens, forcing the model to rely on distant context and learn more robust reasoning patterns. During training, the model learns to reconstruct reasoning steps with missing information, which improves its ability to handle incomplete reasoning chains during inference. The method uses a mask ratio hyperparameter (typically 0.4) that determines the proportion of tokens to mask, with linear warmup scheduling.

## Key Results
- 5% improvement in GSM8K accuracy over standard supervised fine-tuning
- 10% improvement in GSM-IC accuracy over standard supervised fine-tuning
- Demonstrated compatibility with data augmentation techniques and improved sample efficiency

## Why This Works (Mechanism)

### Mechanism 1: Long-distance dependency learning
MFT improves long-distance dependency learning by forcing the model to rely on distant context when local tokens are masked. Randomly masking tokens disrupts reliance on immediate context, encouraging the model to learn connections between distant tokens (e.g., question tokens and earlier reasoning steps). The model leverages distant context effectively when local context is unavailable. Evidence shows models shift towards longer-distance dependencies, particularly enhancing dependency on questions. Break condition: If the dataset lacks sufficient long-distance dependencies, MFT may not provide significant benefits.

### Mechanism 2: Regularization through controlled noise
MFT acts as a form of regularization by introducing controlled noise, preventing overfitting to local patterns. By masking tokens in the reasoning chain, MFT prevents the model from memorizing specific reasoning patterns and encourages it to generalize better to unseen problems. The model benefits from learning to reconstruct reasoning steps with missing information. Evidence shows this is a special case of noise injection framework. Break condition: If the noise level is too high, the model may struggle to learn meaningful patterns.

### Mechanism 3: Error resilience enhancement
MFT improves error resilience by training the model to handle incomplete reasoning chains. During training, the model learns to complete reasoning steps even when some tokens are missing, making it more robust to errors during inference. The model can effectively infer missing information during inference. Evidence shows this deepens understanding of premises in questions and prior steps. Break condition: If the model becomes overly reliant on masked training, it may underperform on unmasked data.

## Foundational Learning

- Concept: Long-distance dependencies
  - Why needed here: Understanding how MFT improves reasoning requires grasping the concept of long-distance dependencies in language models.
  - Quick check question: What is the difference between local and long-distance dependencies in language models?

- Concept: Regularization techniques
  - Why needed here: MFT is a form of regularization, so understanding common regularization methods is crucial for appreciating its effectiveness.
  - Quick check question: How does dropout differ from MFT in terms of the type of noise introduced?

- Concept: Exposure bias
  - Why needed here: Exposure bias is a key issue in sequence generation that MFT helps mitigate.
  - Quick check question: What is exposure bias, and how does it affect the performance of language models on reasoning tasks?

## Architecture Onboarding

- Component map: Question and chain of thought -> Masking module -> Transformer model -> Loss function -> Predicted reasoning steps

- Critical path:
  1. Receive question and chain of thought
  2. Apply MFT masking
  3. Process masked input through transformer
  4. Compute loss and update model parameters

- Design tradeoffs:
  - Mask ratio: Higher ratios introduce more noise but may hinder learning
  - Masking strategy: Masking reasoning steps vs. questions vs. both
  - Noise type: [mask] token vs. random token replacement

- Failure signatures:
  - Model struggles to learn meaningful patterns if mask ratio is too high
  - Model underperforms on unmasked data if overly reliant on masked training
  - No improvement observed if dataset lacks long-distance dependencies

- First 3 experiments:
  1. Compare MFT with standard fine-tuning on GSM8K dataset
  2. Vary mask ratio to find optimal noise level
  3. Test MFT on datasets with different levels of long-distance dependencies

## Open Questions the Paper Calls Out

1. What are the fundamental reasons why Masked Thought Fine-Tuning (MFT) improves mathematical reasoning in language models? The authors acknowledge that while they offer an explanation based on empirical observations about dependency transfer, they have not proven that dependency transfer is the sole factor in improving model performance.

2. How can we quantitatively determine which types of data are best suited for Masked Thought Fine-Tuning? The authors state they have only provided a qualitative explanation without proposing quantitative metrics to determine which types of data are best suited for this approach.

3. What is the optimal mask ratio for mixed datasets containing both reasoning and general instruction tuning data? The authors acknowledge that experiments indicate different datasets may require different mask ratios, but they have not investigated how to adaptively adjust mask ratios for mixed datasets.

4. Does applying Masked Thought Fine-Tuning to mixed reasoning and general instruction tuning data affect the model's general capabilities or diminish the observed enhancement of reasoning? The authors have not conducted experiments to assess the impact of MFT on general capabilities when applied to mixed datasets.

## Limitations

- Primary testing limited to GSM8K and GSM-IC datasets, with insufficient testing on diverse reasoning tasks
- Scalability uncertainty for larger model architectures beyond the 7B parameter range tested
- Unclear precise contribution of each proposed mechanism to overall performance gains

## Confidence

- Long-distance dependency improvement: Medium confidence
- Regularization effectiveness: Medium confidence
- Error resilience enhancement: Low confidence
- Cross-dataset generalization: Medium confidence
- Scalability to larger models: Low confidence

## Next Checks

1. **Ablation study on masking strategies**: Systematically test different masking patterns (random vs. structured, reasoning steps only vs. questions included) to isolate which components drive the performance improvements and validate the proposed mechanisms.

2. **Cross-domain reasoning evaluation**: Test MFT on diverse reasoning datasets beyond mathematical problems (logical reasoning, commonsense reasoning, scientific reasoning) to assess generalization capabilities and identify potential limitations or domain-specific effects.

3. **Scaling experiment**: Implement MFT on larger model architectures (13B-70B parameters) and evaluate whether the 5-10% improvement margin holds or changes with model size, addressing the scalability uncertainty.