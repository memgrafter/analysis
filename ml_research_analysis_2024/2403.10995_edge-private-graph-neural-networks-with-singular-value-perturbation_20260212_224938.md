---
ver: rpa2
title: Edge Private Graph Neural Networks with Singular Value Perturbation
arxiv_id: '2403.10995'
source_url: https://arxiv.org/abs/2403.10995
tags:
- graph
- privacy
- eclipse
- node
- low-rank
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Eclipse, a novel privacy-preserving training
  method for graph neural networks (GNNs) that ensures edge-level differential privacy.
  The key idea is to decompose the adjacency matrix using singular value decomposition
  (SVD) and perturb only the low-rank singular values, thereby reducing the dimensionality
  of noise addition while preserving graph structure.
---

# Edge Private Graph Neural Networks with Singular Value Perturbation

## Quick Facts
- **arXiv ID**: 2403.10995
- **Source URL**: https://arxiv.org/abs/2403.10995
- **Reference count**: 40
- **Primary result**: Eclipse achieves up to 46% higher model utility than baselines under strong privacy constraints (Œµ < 4) while reducing attack AUC by up to 5%.

## Executive Summary
This paper introduces Eclipse, a novel privacy-preserving training method for graph neural networks (GNNs) that ensures edge-level differential privacy. The key innovation is using singular value decomposition (SVD) to decompose the adjacency matrix and perturb only the low-rank singular values, reducing the dimensionality of noise addition while preserving graph structure. Eclipse outperforms existing methods like DPGCN and LPGNet, achieving significantly better privacy-utility tradeoffs and resilience against edge extraction attacks, particularly protecting low-degree nodes.

## Method Summary
Eclipse protects edge privacy in GNNs by decomposing the adjacency matrix using SVD and perturbing only the low-rank singular values with Gaussian noise calibrated to achieve differential privacy. The method trains GNNs on the perturbed low-rank reconstructed adjacency matrix, which inherently removes secondary edges while preserving primary graph topology. This approach reduces the perturbation dimension from n¬≤ to n while maintaining formal DP guarantees. The method is evaluated across multiple datasets including Cora, Citeseer, Chameleon, PubMed, Facebook, and various Twitch graphs, comparing against baselines like DPGCN, LPGNet, and standard GCN.

## Key Results
- Eclipse achieves up to 46% higher model utility than baselines under strong privacy constraints (Œµ < 4)
- Provides up to 5% better resilience against edge extraction attacks compared to baselines
- Particularly effective at protecting low-degree nodes, a challenging aspect in privacy-preserving GNNs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low-rank decomposition reduces DP noise dimensionality while preserving primary graph topology
- Mechanism: Uses SVD to decompose adjacency matrix, then perturbs only low-rank singular values representing most important graph structure
- Core assumption: Real-world graphs exhibit low-rank structure that can be compressed into low-dimensional representation
- Evidence anchors: [abstract] "adjacency matrices in graph structures exhibit low-rank behavior" and [section] "adjacency matrices in real-world graph data exhibit low-rank structures"
- Break condition: If graph doesn't exhibit low-rank structure, method would need to perturb more singular values, increasing noise and reducing privacy-utility tradeoff

### Mechanism 2
- Claim: Adjacent graphs (differing by one edge) primarily differ in singular values rather than principal bases
- Mechanism: When two graphs differ by one edge, their SVD principal components remain nearly identical while singular values change, allowing DP noise to be added only to singular values
- Core assumption: Adjacent graphs share same principal bases from SVD
- Evidence anchors: [section] "The difference between ùê¥ and ùê¥‚Ä≤ is mainly on their singular values" and references to prior work on bounds for SVD differences
- Break condition: If adjacent graphs have significantly different principal bases, privacy guarantee breaks as noise would need to be added to both bases and singular values

### Mechanism 3
- Claim: Method provides additional privacy by removing secondary edges through low-rank reconstruction
- Mechanism: Training on low-rank approximation inherently removes many secondary edges not part of primary graph topology, providing empirical privacy protection beyond formal DP guarantee
- Core assumption: Secondary edges can be removed without significantly impacting model utility
- Evidence anchors: [section] "With a low-rank graph, many edges from the original graph are removed" and "Eclipse protects connections that are not included in the low-rank graph"
- Break condition: If secondary edges are crucial for model performance, removing them would degrade utility more than expected

## Foundational Learning

- **Concept**: Singular Value Decomposition (SVD)
  - Why needed here: Core mathematical tool enabling low-rank graph representation and efficient DP noise addition
  - Quick check question: What does each component (U, S, V) of SVD represent for a graph adjacency matrix?

- **Concept**: Differential Privacy (DP)
  - Why needed here: Provides formal privacy guarantee protecting against edge extraction attacks
  - Quick check question: How does adding Gaussian noise to singular values achieve edge-level DP?

- **Concept**: Graph Neural Networks (GNNs)
  - Why needed here: Understanding how GNNs use adjacency matrices for message passing is crucial for implementation
  - Quick check question: In a GCN layer, how does the normalized adjacency matrix affect node embeddings?

## Architecture Onboarding

- **Component map**: Input (adjacency matrix, node features) -> SVD decomposition -> Low-rank reconstruction with binary quantization -> GNN training with perturbed adjacency matrix -> Attack evaluation (LPA, LINKTELLER)

- **Critical path**: 1) SVD decomposition of adjacency matrix, 2) Gaussian noise addition to singular values, 3) Low-rank reconstruction with binary quantization, 4) GNN training with perturbed adjacency matrix, 5) Evaluation of privacy-utility tradeoff

- **Design tradeoffs**: Higher rank preserves more graph information but requires more noise for DP; lower rank provides better privacy but may degrade model utility; rank selection involves balancing privacy protection against utility loss

- **Failure signatures**: If rank is too low: Model utility drops significantly compared to baselines; if rank is too high: Privacy protection becomes insufficient, attack AUC increases; if DP budget is too small: Model utility drops significantly; if DP budget is too large: Privacy protection becomes insufficient

- **First 3 experiments**: 1) Verify SVD decomposition preserves graph structure by comparing node classification accuracy with original vs low-rank adjacency matrix, 2) Test privacy-utility tradeoff by varying rank (10, 20, 50) and measuring F1 score vs attack AUC, 3) Validate formal DP guarantee by checking if adjacent graphs produce indistinguishable outputs under the method

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we theoretically justify the assumption that principal bases remain invariant under small perturbations like adding/removing one edge?
- Basis in paper: [explicit] The paper states "The establishment of Theorem 1 relies on the assumption that ùê¥ and ùê¥‚Ä≤ share principal bases" but acknowledges this needs theoretical justification
- Why unresolved: The paper references prior work providing bounds on differences in singular values and principal bases but doesn't provide direct theoretical justification for the specific case of single-edge perturbations in adjacency matrices
- What evidence would resolve it: A formal proof showing that for adjacency matrices of graphs, removing/adding a single edge preserves the principal bases within some epsilon bound

### Open Question 2
- Question: What is the optimal rank selection strategy for Eclipse that balances privacy-utility tradeoffs?
- Basis in paper: [explicit] "We also observed that while the attack AUC increases with the rank of the perturbed graph, the attack accuracy never exceeds that of a non-private GCN model" and "we suggest a practical approach for selecting the appropriate rank" but no systematic method is provided
- Why unresolved: The paper uses a fixed rank of 20 and suggests an empirical approach but doesn't provide a principled method for rank selection that adapts to different datasets and privacy requirements
- What evidence would resolve it: An adaptive algorithm that automatically selects rank based on dataset properties and desired privacy level, validated across multiple datasets

### Open Question 3
- Question: How does Eclipse perform on graphs with different homophily levels beyond the tested datasets?
- Basis in paper: [inferred] The paper notes that Facebook and PubMed show "marginal performance improvement compared to MLP" due to high homophily, and suggests Eclipse might be more useful in practice for graphs where adjacency matrices provide "additional private information about the graph"
- Why unresolved: The evaluation focuses on a limited set of datasets with varying but specific homophily properties, leaving open questions about performance on graphs with extreme homophily or heterophily
- What evidence would resolve it: Extensive testing across graphs with controlled homophily levels, showing how performance degrades or improves as homophily varies from 0 to 1

## Limitations

- The paper lacks direct empirical validation of the claim that adjacent graphs share principal bases from SVD
- Rank selection is not systematically explored across different graph types and properties
- Performance on graphs with extreme homophily or heterophily levels is not thoroughly evaluated

## Confidence

- **High confidence**: The formal DP guarantee and Gaussian noise mechanism are mathematically sound
- **Medium confidence**: Privacy-utility tradeoff results showing Eclipse outperforming baselines are empirically validated
- **Low confidence**: Theoretical claims about low-rank structure and principal bases sharing between adjacent graphs lack direct corpus evidence

## Next Checks

1. Conduct ablation studies on rank selection across diverse graph datasets to establish optimal rank ranges for different graph types and verify the low-rank structure assumption
2. Test the hypothesis that adjacent graphs share principal bases by computing SVD differences between randomly perturbed edge variants of the same graph
3. Evaluate model robustness by measuring performance degradation when applying Eclipse to non-low-rank graphs (e.g., Erd≈ës‚ÄìR√©nyi random graphs) to validate the method's limitations