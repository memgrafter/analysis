---
ver: rpa2
title: 'Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based
  Customization'
arxiv_id: '2405.20584'
source_url: https://arxiv.org/abs/2405.20584
tags:
- diffusion
- image
- adversarial
- disdiff
- dreambooth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DisDiff, a proactive adversarial attack method
  to protect users' privacy against diffusion-based customization techniques like
  DreamBooth. The core idea is to disrupt the cross-attention mechanism that guides
  text-to-image generation by erasing the subject-identifier token's influence on
  attention maps.
---

# Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization

## Quick Facts
- arXiv ID: 2405.20584
- Source URL: https://arxiv.org/abs/2405.20584
- Authors: Yisu Liu; Jinyang An; Wanqian Zhang; Dayan Wu; Jingzi Gu; Zheng Lin; Weiping Wang
- Reference count: 40
- Primary result: DisDiff achieves 12.75% higher FDFR and 7.25% higher ISM scores than state-of-the-art methods on facial privacy protection

## Executive Summary
This paper introduces DisDiff, a proactive adversarial attack method designed to protect user privacy against diffusion-based image customization techniques like DreamBooth. The core innovation is the Cross-Attention Erasure (CAE) module, which disrupts the diffusion model's ability to associate subject-identifier tokens with target identities by reducing the attention energy of these tokens. The method also introduces a Merit Sampling Scheduler (MSS) to adaptively modulate perturbation updates during the diffusion sampling process, improving attack effectiveness. Experimental results demonstrate significant improvements in privacy protection metrics compared to existing methods.

## Method Summary
DisDiff combines three key components: a Cross-Attention Erasure module that reduces the influence of subject-identifier tokens on attention maps, a Merit Sampling Scheduler that adjusts perturbation updates based on timestep importance, and an alternative training strategy that alternates between surrogate model training and adversarial perturbation updates. The method works by maximizing the loss function to erase the subject-identifier token's attention influence while using the HQS metric to prioritize important timesteps during the PGD attack process.

## Key Results
- DisDiff achieves 12.75% higher Face Detection Failure Rate (FDFR) than state-of-the-art methods
- DisDiff improves Identity Score Matching (ISM) by 7.25% compared to baseline approaches
- The method maintains effectiveness even when subject-identifier tokens are modified during inference

## Why This Works (Mechanism)

### Mechanism 1
Disrupting cross-attention erasure prevents the diffusion model from associating the subject-identifier token with the target identity. The Cross-Attention Erasure (CAE) module reduces the energy of the subject-identifier token's attention map by maximizing the loss (1 - E(ms))Â², where E(ms) measures the relative energy of the token's attention. This disrupts the text-to-image guidance.

### Mechanism 2
The Merit Sampling Scheduler (MSS) improves adversarial attack performance by adjusting perturbation update step sizes based on timestep importance. MSS uses the Hybrid Quality Score (HQS) to measure the importance of each timestep for adversarial learning, then modulates the PGD step size using a cosine-based function h(t) that decreases as timesteps progress.

### Mechanism 3
The alternative training strategy effectively protects user privacy by alternating between training the surrogate DreamBooth model with clean images and updating adversarial perturbations using modified PGD with CAE and MSS. This disrupts the model's ability to generate recognizable identities.

## Foundational Learning

- Concept: Cross-attention mechanisms in diffusion models
  - Why needed here: Understanding how cross-attention maps guide text-to-image generation is crucial for disrupting this process
  - Quick check question: How do cross-attention maps relate tokens to image regions in diffusion models?

- Concept: Projected Gradient Descent (PGD) adversarial attacks
  - Why needed here: PGD is used to generate adversarial perturbations that disrupt the diffusion model's outputs
  - Quick check question: How does PGD iteratively update perturbations to maximize the loss function?

- Concept: Diffusion sampling process and timestep importance
  - Why needed here: Understanding how different timesteps contribute to final image generation is essential for the Merit Sampling Scheduler
  - Quick check question: Why might earlier timesteps be more important for preserving identity information in diffusion models?

## Architecture Onboarding

- Component map: Cross-Attention Erasure (CAE) module -> Merit Sampling Scheduler (MSS) -> Alternative training strategy -> PGD attack with modified step sizes

- Critical path: 1. Compute attention maps from cross-attention layers 2. Calculate Cross-Attention Erasure loss 3. Determine timestep importance using HQS 4. Adjust PGD step sizes using MSS 5. Update adversarial perturbations 6. Train surrogate DreamBooth model

- Design tradeoffs:
  - Computational cost vs. attack effectiveness (larger noise budgets increase performance but may be perceptible)
  - Protection strength vs. image quality (stronger attacks may result in lower quality outputs)
  - Generalization vs. specificity (protection may work better against specific prompts or subject-identifier tokens)

- Failure signatures:
  - High Identity Score Matching (ISM) values indicating the model still recognizes the subject
  - Low Face Detection Failure Rate (FDFR) values suggesting faces are still being generated
  - High FID and BRISQUE scores indicating poor image quality

- First 3 experiments:
  1. Test the Cross-Attention Erasure module on a simple diffusion model with a single subject-identifier token
  2. Evaluate the Merit Sampling Scheduler's impact on PGD attack performance using synthetic timesteps
  3. Combine CAE and MSS in the full DisDiff framework and measure FDFR and ISM scores on a small dataset

## Open Questions the Paper Calls Out

### Open Question 1
How does DisDiff perform against customization methods that use different subject-identifier tokens than those used during adversarial training? The authors test robustness when the DreamBooth subject-identifier token is changed from "sks" to "t@t" and observe that DisDiff maintains good generalization performance, but only tested one alternative token change.

### Open Question 2
Can DisDiff's Cross-Attention Erasure module be extended to protect against customization of non-facial subjects (e.g., objects, scenes, or artistic styles)? The paper focuses exclusively on facial privacy protection, leaving open whether the attention-based approach generalizes to other customization domains.

### Open Question 3
What is the impact of DisDiff on the perceptual quality of protected images when viewed by human observers, beyond quantitative metrics like FID and BRISQUE? The authors report quantitative quality metrics showing degradation in image quality, but do not conduct human perceptual studies.

## Limitations

- Limited evaluation to facial benchmarks, with unclear performance on non-facial subjects
- Computational overhead may limit practical deployment in real-time or resource-constrained scenarios
- No investigation of potential adversarial countermeasures or robustness against adaptive attacks

## Confidence

**High Confidence:** The Cross-Attention Erasure mechanism is well-supported by internal analysis and empirical results showing improved FDFR and ISM scores.

**Medium Confidence:** The Merit Sampling Scheduler's effectiveness relies on the accuracy of the HQS metric, which is empirically validated but may not generalize across all diffusion architectures.

**Low Confidence:** The alternative training strategy's ability to protect against all potential diffusion-based customization attacks is uncertain, as evaluation focuses on specific DreamBooth-style customization.

## Next Checks

1. Evaluate DisDiff's performance on non-facial subjects to assess generalizability beyond facial benchmarks.

2. Assess the computational overhead and real-world feasibility by measuring time and resources required for the alternative training strategy and Merit Sampling Scheduler.

3. Investigate potential adversarial countermeasures by exploring whether preprocessing techniques or architectural modifications to diffusion models can mitigate DisDiff's effectiveness.