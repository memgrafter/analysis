---
ver: rpa2
title: Prompt Perturbation in Retrieval-Augmented Generation based Large Language
  Models
arxiv_id: '2402.07179'
source_url: https://arxiv.org/abs/2402.07179
tags:
- ggpp
- prefix
- llms
- passage
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the vulnerability of Retrieval-Augmented
  Generation (RAG) based large language models (LLMs) to adversarial prompt perturbations.
  It introduces Gradient Guided Prompt Perturbation (GGPP), a method that optimizes
  short prefixes to manipulate RAG retrievers into retrieving targeted incorrect text
  passages.
---

# Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models

## Quick Facts
- **arXiv ID:** 2402.07179
- **Source URL:** https://arxiv.org/abs/2402.07179
- **Reference count:** 40
- **Primary result:** GGPP can manipulate RAG retrievers with up to 88.6% top-1 success in retrieving targeted incorrect passages.

## Executive Summary
This paper introduces Gradient Guided Prompt Perturbation (GGPP), a method that adversarially manipulates Retrieval-Augmented Generation (RAG) systems by optimizing short prompt prefixes to retrieve targeted incorrect text passages. The approach achieves high success rates (up to 88.6% top-10) across multiple datasets and embedding models. The authors also develop two detection methods—SATe and ACT probes—based on MLP activation patterns, with ACT offering strong performance (e.g., 99.6% AUROC for Mistral-7B) while using fewer parameters. The findings demonstrate significant vulnerabilities in RAG-based LLMs and provide tools for improving their robustness.

## Method Summary
The paper proposes GGPP, which optimizes short adversarial prefixes to manipulate RAG retrievers into retrieving targeted incorrect passages. The method uses gradient descent to shift prompt embeddings toward target passage embeddings, with token importance-based initialization to accelerate convergence. For detection, two approaches are introduced: SATe (using attention scores) and ACT (using last-layer MLP activations). The evaluation uses four datasets (IMDB, Basketball Players, Books, Nobel Winners) and four embedding models (GPT-J-6B, Mistral-7B, Qwen-7B, SFR-Embedding-Mistral), measuring success rates and detection performance across various configurations.

## Key Results
- GGPP achieves up to 88.6% top-1 success and 99.3% top-10 success in retrieving targeted incorrect passages
- ACT probe detection performance reaches 99.6% AUROC for Mistral-7B with fewer parameters than SATe
- Decoder-based models (GPT-J-6B, Mistral-7B, Qwen-7B) achieve 81.7%-88.6% top-1 success; encoder-based models (SFR-Embedding-Mistral) reach 99.0%-99.9% top-1 success
- Even with instructions to ignore irrelevant information, GGPP maintains high success rates

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gradient-guided prefix perturbation shifts the embedding of a user prompt toward a targeted passage embedding in the retrieval space, causing the retriever to return incorrect passages.
- **Mechanism:** GGPP computes a short adversarial prefix that is concatenated with the original prompt. By optimizing this prefix using gradient descent, the embedding of the combined prompt is moved in the embedding space toward the target passage embedding. The retriever then ranks this targeted passage higher, sometimes to the top-1 position.
- **Core assumption:** The embedding space used by the retriever is smooth enough that small changes to the prompt embedding can reliably move the nearest-neighbor ranking toward a specific passage.
- **Evidence anchors:**
  - [abstract] "It introduces Gradient Guided Prompt Perturbation (GGPP), a method that optimizes short prefixes to manipulate RAG retrievers into retrieving targeted incorrect text passages."
  - [section 3.2] "The prefix optimization algorithm ... further optimizes the initial prefix to alter the ranking of passages in RAG-based LLMs."
  - [corpus] Weak: No direct mention of gradient-based embedding shifts in corpus neighbors; only general RAG robustness concerns.
- **Break condition:** If the embedding space is non-smooth or the retriever uses re-ranking that overrides simple embedding distance, the perturbation may fail.

### Mechanism 2
- **Claim:** Prefix initialization based on token importance accelerates convergence by starting from a prefix that already moves the prompt embedding closer to the target.
- **Mechanism:** For each token in the target passage, GGPP masks it and measures the change in the passage's embedding. Tokens causing the largest embedding shift are selected for the initial prefix. This heuristic jump-starts the gradient search, reducing iterations needed.
- **Core assumption:** Tokens in the target passage that most influence its embedding coordinates will also be most effective in shifting a query embedding toward it when included in a prefix.
- **Evidence anchors:**
  - [section 3.2.1] "We measure the distance change to the embedding of the original target passage ... concatenate these tokens to form the initial adversarial prefix."
  - [section 3.2] "Such initialization can quickly find a prefix that leads to the target passage being ranked highly."
  - [corpus] Missing: No corpus neighbor explicitly discusses token-level embedding influence.
- **Break condition:** If token importance does not correlate with embedding shift direction, initialization may mislead the optimizer.

### Mechanism 3
- **Claim:** MLP activation patterns in the last layer of LLMs encode signals about factual correctness, enabling detection of GGPP-induced factual errors.
- **Mechanism:** GGPP changes the retrieved passage, which alters the factual content the LLM generates. This change manifests as different MLP activation patterns in the last layer. ACT probe uses these activations as features in a classifier to detect perturbation.
- **Core assumption:** The last-layer MLP activations of LLMs are sufficiently correlated with the factual accuracy of generated text that they can serve as discriminative features.
- **Evidence anchors:**
  - [abstract] "We further discover a strong positive relation between the model's multi-Layer perceptron (MLP) activation to the factual accuracy of its responses when GGPP prefix is added."
  - [section 4.1] "We discover that the last layer of LLM provides sufficient information to reveal the pattern of factual inaccuracies in its output."
  - [corpus] Weak: No corpus neighbor explicitly discusses MLP activation patterns for error detection.
- **Break condition:** If factual errors do not consistently produce distinct MLP activation patterns, detection accuracy will degrade.

## Foundational Learning

- **Concept:** Embeddings and vector similarity in retrieval-augmented generation
  - Why needed here: GGPP relies on embedding distance to manipulate retriever rankings; understanding cosine similarity, L2 distance, and how embeddings encode semantics is essential.
  - Quick check question: If a prompt embedding moves closer to a target passage embedding in cosine space, what happens to the retriever's ranking of that passage?

- **Concept:** Gradient-based optimization in discrete token spaces
  - Why needed here: GGPP uses gradient descent to find token substitutions that minimize a loss function; knowledge of differentiable relaxations and greedy coordinate descent is required.
  - Quick check question: Why can't we directly backpropagate through a discrete token sequence, and how does GGPP approximate this?

- **Concept:** Transformer attention and MLP layer functions
  - Why needed here: ACT probe relies on MLP activations in the last layer; understanding how MLPs process attention outputs and store factual information is critical for interpreting detection results.
  - Quick check question: What role does the MLP layer play in transforming attention outputs into token predictions in a decoder?

## Architecture Onboarding

- **Component map:** Target passage embedding → GGPP prefix optimizer → Modified prompt embedding → Retriever (embedding model → HNSW index → top-k passage selection) → LLM generator → Output generation → ACT probe (last-layer MLP activations → logistic regression classifier → perturbation label)

- **Critical path:**
  1. Embed target passage → store embedding
  2. Embed original prompt → compute GGPP loss → optimize prefix
  3. Embed modified prompt → retrieve top-k → check if target is promoted and original demoted
  4. For detection: Generate prompt → forward through LLM → extract last-layer activations → classify

- **Design tradeoffs:**
  - Longer prefixes improve success rate but increase detectability and latency
  - Encoder-based models (SFR) need longer prefixes due to context sensitivity but yield higher top-1 success rates
  - Detection using ACT is faster and lighter than SATe but slightly less accurate

- **Failure signatures:**
  - Prefix optimization stalls: loss plateaus before target is in top-k
  - Retrieval unchanged: GGPP prefix does not alter embedding enough to shift rankings
  - False negatives in detection: ACT misclassifies perturbed prompts as clean
  - False positives: Clean prompts misclassified as perturbed due to activation variance

- **First 3 experiments:**
  1. **Embedding shift sanity check:** For a fixed target passage, measure embedding distance change when prepending a single token from the passage to a prompt. Confirm direction aligns with expectation.
  2. **Prefix initialization ablation:** Run GGPP with and without initialization on a small dataset; compare number of epochs to success and final success rate.
  3. **Detection threshold sweep:** Use ACT probe on a balanced set of clean vs. perturbed prompts; vary classification threshold and plot ROC curve to choose operating point.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of GGPP vary when applied to different embedding models, such as GPT-J-6B, Mistral-7B, and Qwen-7B?
- **Basis in paper:** [explicit] The paper compares the success rates of GGPP across different embedding models and datasets.
- **Why unresolved:** While the paper provides success rates for different models, it does not explore the underlying reasons for the performance differences or how these models might be optimized for better results.
- **What evidence would resolve it:** Detailed analysis of the internal workings of each embedding model, including their attention mechanisms and parameter configurations, could provide insights into why certain models are more susceptible to GGPP. Additionally, experiments varying the prefix length and optimization parameters could reveal optimal settings for each model.

### Open Question 2
- **Question:** What is the impact of prefix length on the success rate of GGPP, and how does this vary across different datasets and embedding models?
- **Basis in paper:** [explicit] The paper mentions using different prefix lengths for decoder-based and encoder-based models, but does not extensively explore the impact of prefix length on success rates.
- **Why unresolved:** The paper does not provide a comprehensive analysis of how prefix length affects the perturbation success rate across various datasets and models.
- **What evidence would resolve it:** Systematic experiments varying the prefix length for each dataset and model combination, along with an analysis of the trade-offs between prefix length and success rate, would clarify the optimal prefix length for different scenarios.

### Open Question 3
- **Question:** How effective are the ACT and SATe probes in detecting GGPP-induced perturbations in real-world applications, and what are their limitations?
- **Basis in paper:** [explicit] The paper evaluates the detection performance of ACT and SATe probes, but does not discuss their practical application or limitations in real-world scenarios.
- **Why unresolved:** The paper provides detection metrics but does not address the challenges of deploying these probes in practical settings or their limitations in detecting more sophisticated perturbations.
- **What evidence would resolve it:** Field studies applying ACT and SATe probes to real-world RAG systems, along with an analysis of false positives/negatives and computational overhead, would provide insights into their practical effectiveness and limitations.

### Open Question 4
- **Question:** How can the GGPP method be adapted to improve the robustness of RAG-based systems against adversarial attacks?
- **Basis in paper:** [explicit] The paper suggests that GGPP could be used to generate prompts to enhance LLMs, but does not explore this potential application in detail.
- **Why unresolved:** The paper does not investigate how GGPP could be used to fortify RAG systems against adversarial attacks or improve their overall robustness.
- **What evidence would resolve it:** Research into using GGPP-generated prompts as part of a defense strategy, including training RAG systems with adversarial examples and evaluating their resilience, would demonstrate the potential of GGPP in enhancing system robustness.

## Limitations

- The experiments use synthetic datasets with curated passages, which may not reflect real-world retrieval complexity and noise
- The embedding models tested were not specifically trained for adversarial robustness, limiting generalizability to production systems
- Detection methods rely on supervised learning from limited perturbation patterns, potentially failing against unseen attack variants
- The paper does not address computational costs of prefix optimization or detection in deployment settings

## Confidence

- **High Confidence:** Core GGPP mechanism and prefix optimization effectiveness (top-1 up to 88.6%, top-10 up to 99.3%)
- **Medium Confidence:** Detection methods (SATe and ACT) performance on tested datasets (ACT achieves 99.6% AUROC for Mistral-7B)
- **Low Confidence:** Claims about RAG system fragility and sufficiency of MLP activation patterns for error detection without real-world validation

## Next Checks

1. **Real-World Transferability Test:** Evaluate GGPP and detection methods on a large-scale, noisy real-world dataset (e.g., web documents or open-domain QA) to assess robustness against natural language variability and retrieval noise.

2. **Adversarial Robustness Benchmark:** Test whether hardening the retriever embedding model (e.g., adversarial training or robust re-ranking) reduces GGPP success rates, and whether detection methods remain effective under such defenses.

3. **Detection Generalization Study:** Train ACT and SATe probes on one perturbation type and evaluate them on a diverse set of unseen attacks (e.g., suffix injection, semantic paraphrases) to measure cross-attack generalization.