---
ver: rpa2
title: 'Aligning with Human Judgement: The Role of Pairwise Preference in Large Language
  Model Evaluators'
arxiv_id: '2403.16950'
source_url: https://arxiv.org/abs/2403.16950
tags:
- pair
- pairwise
- evaluation
- human
- evaluators
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the misalignment between LLM evaluators
  and human judgments in text evaluation tasks. The authors show that existing calibration
  methods are insufficient to align LLM evaluators with human standards, as the core
  issue lies in the likelihood term of the LLM evaluation model rather than the prior.
---

# Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators

## Quick Facts
- **arXiv ID**: 2403.16950
- **Source URL**: https://arxiv.org/abs/2403.16950
- **Authors**: Yinhong Liu; Han Zhou; Zhijiang Guo; Ehsan Shareghi; Ivan Vulić; Anna Korhonen; Nigel Collier
- **Reference count**: 26
- **Primary result**: Pairwise preference ranking (PAIR S) achieves state-of-the-art performance on summarization and story generation tasks while requiring fewer model queries than direct scoring baselines.

## Executive Summary
This paper addresses the fundamental misalignment between LLM evaluators and human judgment in text evaluation tasks. The authors demonstrate that existing calibration methods fail to resolve the core issue: LLMs and humans have different likelihood terms in their evaluation models. They propose PAIR S, an uncertainty-guided pairwise preference search method that reframes evaluation as a ranking problem. By leveraging transitivity assumptions and beam search with uncertainty-based pruning, PAIR S efficiently estimates maximum likelihood rankings while requiring significantly fewer model queries than exhaustive pairwise comparison methods.

## Method Summary
PAIR S transforms LLM evaluation from direct scoring to pairwise ranking, addressing the misalignment between LLM and human evaluation standards. The method uses an uncertainty-guided beam search to efficiently estimate the maximum likelihood ranking of candidate texts. It employs transitivity assumptions to reduce computational complexity from O(N²) to O(N log N) by merging sorted subarrays. The uncertainty-guided pruning mechanism uses LLM confidence scores (entropy) to prune unlikely branches during search, improving efficiency. The method also includes a scaling variant for handling large evaluation sets by ranking subsets with an anchor set.

## Key Results
- PAIR S achieves state-of-the-art Spearman correlations on summarization (News Room, SummEval) and story generation (HANNA) tasks
- The method requires fewer model queries than exhaustive pairwise comparison baselines
- Transitivity analysis reveals varying levels of transitivity across different LLM families, with GPT-4-turbo showing the highest transitivity
- PAIR S provides insights into quantifying LLM transitivity, a previously unexplored aspect of LLM evaluation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Pairwise comparisons reduce the evaluation standard gap between LLM and human judges.
- **Mechanism**: Direct scoring requires LLMs to map diverse text qualities to a fixed numeric scale, amplifying differences in evaluation criteria. Pairwise comparisons instead ask the model to rank two texts relative to each other, which implicitly relies on relative quality judgments that are closer to human pairwise evaluation behavior.
- **Core assumption**: The probability distribution over pairwise preferences between two texts is more similar between humans and LLMs than the distribution over absolute scores for a single text.
- **Evidence anchors**: [abstract] "The difference between LLM and human evaluation standards is smaller when performing pairwise comparison, compared to rating with scores." [section 2] "we hypothesise that the discrepancy between the posterior distributions of LLMs and humans mainly arises from a misalignment between their respective likelihoods."
- **Break condition**: If the LLM's pairwise preference distribution is still heavily biased (e.g., by verbosity or positional effects), the relative alignment advantage disappears.

### Mechanism 2
- **Claim**: Transitivity assumptions enable efficient ranking from pairwise comparisons.
- **Mechanism**: Instead of requiring all N² pairwise comparisons, transitivity allows constructing a global ranking by merging sorted subarrays, reducing complexity to O(N log N). Even without perfect transitivity, a "compositional stochastic transitivity" assumption lets the method approximate the optimal ranking efficiently.
- **Core assumption**: LLM pairwise preferences exhibit enough transitivity that greedy or beam search can approximate the maximum likelihood ranking without exploring all comparison pairs.
- **Evidence anchors**: [section 3.1] "If LLM evaluators are assumed to possess transitivity property, then the problem of finding the MLE ranking reduces to a sorting problem, which can be solved by standard sorting algorithms such as merge sort or quick sort with only O(N log N) pairwise comparisons." [section 5.4] "Transitivity...plays a crucial role in the effectiveness of LLMs as evaluators, impacting the speed and consistency with which they achieve rankings."
- **Break condition**: If transitivity is very low (e.g., chaotic pairwise preferences), beam search will fail to find a good ranking, and O(N²) comparisons would be needed.

### Mechanism 3
- **Claim**: Uncertainty-guided pruning improves efficiency without sacrificing accuracy.
- **Mechanism**: When the LLM's confidence (entropy) in a pairwise comparison is low (high uncertainty), the algorithm explores both possible orderings. When confidence is high, it prunes the less likely branch, reducing the search space.
- **Core assumption**: LLM confidence in pairwise comparisons is a reliable signal of how close the true preference is to the predicted one.
- **Evidence anchors**: [section 3.2] "To further improve the efficiency of the beam search, we introduce a pruning mechanism based on the LLM's uncertainty." [section 5.2] "PAIR S-beam generally exhibits higher correlations and lower Standard Error...than PAIR S-greedy on all datasets."
- **Break condition**: If LLM confidences are miscalibrated or entropy is not a good proxy for reliability, pruning could remove correct branches and degrade ranking quality.

## Foundational Learning

- **Concept**: Transitivity in preference relations
  - **Why needed here**: The algorithm relies on transitivity to merge sorted subarrays efficiently. Without it, the method would degrade to exhaustive pairwise comparisons.
  - **Quick check question**: If A is preferred to B and B is preferred to C, must A always be preferred to C in the LLM's judgment? Why or why not?

- **Concept**: Rank aggregation and Kemeny-optimal ranking
  - **Why needed here**: PAIR S frames evaluation as finding the ranking that maximizes likelihood over pairwise comparisons, which is the Kemeny-optimal ranking problem.
  - **Quick check question**: What makes the exact Kemeny-optimal ranking NP-hard to compute?

- **Concept**: Entropy as uncertainty measurement
  - **Why needed here**: Uncertainty-guided pruning uses entropy of the pairwise preference probability to decide whether to prune or explore both branches.
  - **Quick check question**: How does entropy change as the LLM's confidence in a pairwise preference increases?

## Architecture Onboarding

- **Component map**: Source text + candidates -> Pairwise comparison module -> Search module (beam search with pruning) -> Ranked list
- **Critical path**:
  1. Generate pairwise preference probabilities P(A ≻ B) for candidate pairs
  2. Merge sorted subarrays using beam search, pruning low-uncertainty branches
  3. Output final ranking (optionally calibrate to human score distribution)
- **Design tradeoffs**:
  - Beam size vs. computational cost: Larger beam explores more paths but increases latency
  - Uncertainty threshold: Higher thresholds prune more aggressively, speeding up search but risking missed optimal paths
  - Direct scoring vs. pairwise: Direct scoring is O(N) but less aligned; pairwise is O(N log N) or O(N²) but more aligned
- **Failure signatures**:
  - High standard error across runs: Indicates low transitivity, poor ranking stability
  - Rankings uncorrelated with human judgments: Suggests miscalibrated pairwise preferences or bias
  - No speedup over exhaustive pairwise: Implies transitivity is too low for efficient search
- **First 3 experiments**:
  1. Compare Spearman correlation of direct scoring vs. PAIR S on a small summarization dataset
  2. Vary beam size (1, 5, 10, 20) on the same dataset to find the efficiency-accuracy tradeoff
  3. Test different uncertainty thresholds (0.5, 0.6, 0.7) to see pruning impact on ranking quality

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several are implicit in the limitations and future work discussion.

## Limitations
- Core transitivity assumption remains largely theoretical with limited empirical validation
- Uncertainty-guided pruning effectiveness depends on well-calibrated LLM confidence scores that are not directly verified
- Performance on longer-form generation tasks beyond summarization and stories remains untested

## Confidence
- **High confidence**: Pairwise comparisons yield better human alignment than direct scoring
- **Medium confidence**: Efficiency claims of PAIR S, as transitivity validation is limited
- **Medium confidence**: Calibration improvements, as debiasing mechanism's robustness across domains is not fully explored

## Next Checks
1. Conduct systematic transitivity analysis across different LLM sizes and model families to quantify violation rates
2. Test PAIR S on open-ended generation tasks (e.g., long-form QA, creative writing) to assess generalization
3. Implement ablation studies removing uncertainty-guided pruning to isolate its contribution to performance gains