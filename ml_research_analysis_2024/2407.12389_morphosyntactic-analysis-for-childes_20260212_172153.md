---
ver: rpa2
title: Morphosyntactic Analysis for CHILDES
arxiv_id: '2407.12389'
source_url: https://arxiv.org/abs/2407.12389
tags:
- language
- which
- languages
- development
- processing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper describes applying Universal Dependencies (UD) to 27
  languages in the CHILDES database, enabling consistent morphosyntactic analysis
  across languages. The authors use the Batchalign2 program for automatic speech recognition
  and natural language processing, overcoming challenges such as eye-dialect, script
  conversion, and multi-word expressions.
---

# Morphosyntactic Analysis for CHILDES

## Quick Facts
- arXiv ID: 2407.12389
- Source URL: https://arxiv.org/abs/2407.12389
- Authors: Houjun Liu; Brian MacWhinney
- Reference count: 0
- Primary result: Universal Dependencies framework applied to 27 CHILDES languages enabling consistent morphosyntactic analysis

## Executive Summary
This paper describes the application of Universal Dependencies (UD) to 27 languages in the CHILDES database, enabling consistent morphosyntactic analysis across languages. The authors use the Batchalign2 program for automatic speech recognition and natural language processing, overcoming challenges such as eye-dialect, script conversion, and multi-word expressions. The work provides details on the UD framework, processing pipeline, and current status of UD tagging for each language, highlighting benefits for cross-linguistic analysis and available tools for analyzing the tagged corpora.

## Method Summary
The method involves using Batchalign2 for automatic speech recognition to transcribe CHILDES audio data, then applying Universal Dependencies (UD) tagging using Stanza to provide consistent morphosyntactic analysis across 27 languages. The pipeline handles challenges like eye-dialect conversion, script transformations, and multi-word expressions. The process produces %mor and %gra lines with POS tags, grammatical features, and grammatical relations in CHAT format. Users can run "morphotag" on properly formatted CHAT transcripts to generate the UD-tagged output.

## Key Results
- UD framework successfully applied to 27 CHILDES languages for consistent morphosyntactic analysis
- Batchalign2 program enables automatic transcription and tagging of spoken language data
- New resources enable deeper cross-linguistic study of language learning across multiple languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Automatic speech recognition (ASR) significantly speeds up the transcription process for CHILDES data.
- Mechanism: The Batchalign2 program leverages advanced ASR models like Rev.AI and OpenAI Whisper to transcribe spoken language data, which traditionally requires 10-16 hours of manual transcription per hour of interaction. By using ASR, the transcription time is greatly reduced, and the output is structured in CHAT format, enabling further morphosyntactic analysis.
- Core assumption: The ASR models can accurately transcribe adult speech and link it to the audio, even if child speech recognition is less reliable.
- Evidence anchors:
  - [abstract] "Using the Batchalign2 program (Liu et al., 2023), we have been transcribing and linking data for the CHILDES database..."
  - [section] "Because currently available tokenizers are all based on written language and because spoken language segmentation follows quite different rules and patterns, we have created novel tokenizers based on spoken language training data."
- Break condition: If the ASR models fail to accurately transcribe speech or link it to the audio, the speed advantage is lost, and the subsequent morphosyntactic analysis will be unreliable.

### Mechanism 2
- Claim: Universal Dependencies (UD) provides a consistent morphosyntactic analysis framework across 27 languages.
- Mechanism: The UD framework uses a uniform set of codes for parts of speech, grammatical features, and grammatical relations. By applying UD tagging to CHILDES data, the paper achieves consistent morphosyntactic analysis across languages, enabling cross-linguistic comparisons.
- Core assumption: The UD models trained on written language data can be effectively applied to spoken language data in CHILDES, despite differences in segmentation and orthography.
- Evidence anchors:
  - [abstract] "...we have applied the UD (Universal Dependencies) framework to provide a consistent and comparable morphosyntactic analysis for 27 languages."
  - [section] "UD uses six open class POS (part-of-speech) tags (ADJ, ADV, INTJ, NOUN, PROPN, and VERB) and eight closed class POS tags (ADP, AUX, CCONJ, DET, NUM, PART, PRON, and SCONJ)."
- Break condition: If the UD models cannot accurately analyze the morphosyntactic features of the 27 languages, the cross-linguistic comparisons will be invalid.

### Mechanism 3
- Claim: The combination of ASR and UD enables deeper crosslinguistic study of language learning.
- Mechanism: By using ASR to transcribe and link CHILDES data, and then applying UD for morphosyntactic analysis, the paper creates a rich dataset for studying language development across languages. This dataset can be used to compare acquisition patterns, assess developmental milestones, and identify universal and language-specific features.
- Core assumption: The combination of ASR and UD provides sufficient accuracy and coverage to enable meaningful cross-linguistic comparisons.
- Evidence anchors:
  - [abstract] "These new resources open possibilities for deeper crosslinguistic study of language learning."
  - [section] "The combination of these new %mor and %gra tiers for these 27 languages, along with current analytic methods and ones we plan to build will provide us with a strong quantitative foundation for crosslinguistic analysis of language development."
- Break condition: If the ASR or UD components are not sufficiently accurate or comprehensive, the resulting dataset will not support valid cross-linguistic comparisons.

## Foundational Learning

- Concept: Automatic Speech Recognition (ASR)
  - Why needed here: ASR is used to transcribe spoken language data, which is a crucial first step in analyzing CHILDES data for morphosyntactic features.
  - Quick check question: How does the accuracy of ASR on child speech compare to adult speech, and what are the implications for morphosyntactic analysis?

- Concept: Universal Dependencies (UD)
  - Why needed here: UD provides a consistent framework for morphosyntactic analysis across languages, enabling cross-linguistic comparisons.
  - Quick check question: How do the UD tags for parts of speech, grammatical features, and grammatical relations map onto the specific languages in CHILDES, and what are the challenges in ensuring consistency?

- Concept: Morphosyntactic Analysis
  - Why needed here: Morphosyntactic analysis involves examining the structure of words and sentences, which is essential for understanding language development.
  - Quick check question: How do the morphosyntactic features identified by UD (e.g., tense, number, case) relate to the developmental stages of language acquisition, and what are the implications for cross-linguistic comparisons?

## Architecture Onboarding

- Component map: ASR transcription (Batchalign2 with Rev.AI/Whisper) -> UD tagging (Stanza) -> CHAT format conversion
- Critical path: The critical path is ASR transcription -> UD tagging -> CHAT format conversion. If any step fails, the subsequent steps cannot proceed.
- Design tradeoffs: The choice between Rev.AI and Whisper for ASR involves a tradeoff between speed and language coverage. Rev.AI is faster but has limited language support, while Whisper is slower but supports more languages.
- Failure signatures: ASR failures manifest as inaccurate transcriptions or missing word-level alignments. UD failures manifest as incorrect morphosyntactic tags or ungrammatical dependency structures.
- First 3 experiments:
  1. Run Batchalign2 on a small sample of CHILDES data in English to verify ASR transcription and CHAT format conversion.
  2. Apply Stanza UD tagging to the transcribed English data and compare the results to manual morphosyntactic analysis.
  3. Repeat experiments 1 and 2 for a non-English language in CHILDES to assess the generalizability of the approach.

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out specific open questions. However, several implications arise from the methodology:

1. How does the accuracy of UD tagging for child language compare to adult language corpora across the 27 languages?
2. What is the impact of eye-dialect and phonological forms on UD tagging accuracy for languages with extensive use of such forms?
3. How do the morphological and syntactic development patterns revealed by UD tagging differ across languages for specific linguistic features (e.g., tense, case, gender)?

## Limitations

- Limited quantitative data on ASR transcription error rates across different age groups and languages
- Potential accuracy issues when adapting UD models from written to spoken language data
- Varying quality of UD models across the 27 languages, affecting reliability of cross-linguistic comparisons

## Confidence

Confidence labels for major claim clusters:
- **High**: The technical pipeline (ASR → UD tagging → CHAT format) is clearly specified and reproducible
- **Medium**: The consistency of UD framework across languages for morphosyntactic analysis
- **Low**: The accuracy and reliability of cross-linguistic comparisons without extensive validation

## Next Checks

1. Conduct a quantitative error analysis comparing ASR transcription accuracy between adult and child speech across different age groups in a representative sample of CHILDES data.

2. Validate UD tagging accuracy for spoken language by comparing Stanza's output against manually annotated morphosyntactic analysis in the same languages.

3. Perform a pilot cross-linguistic comparison study using the tagged data to assess whether developmental patterns identified are consistent with established research on language acquisition in those specific languages.