---
ver: rpa2
title: Towards Neural Scaling Laws on Graphs
arxiv_id: '2402.02054'
source_url: https://arxiv.org/abs/2402.02054
tags:
- scaling
- graph
- data
- number
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores neural scaling laws on graphs, addressing the
  lack of systematic investigation into how deep graph models' performance scales
  with model and dataset sizes. The authors benchmark various graph datasets across
  tasks like node classification, link prediction, and graph classification, analyzing
  model sizes up to 100 million parameters and dataset sizes up to 50 million samples.
---

# Towards Neural Scaling Laws on Graphs

## Quick Facts
- **arXiv ID:** 2402.02054
- **Source URL:** https://arxiv.org/abs/2402.02054
- **Reference count:** 40
- **Key outcome:** The paper explores neural scaling laws on graphs, addressing the lack of systematic investigation into how deep graph models' performance scales with model and dataset sizes.

## Executive Summary
This paper investigates neural scaling laws in graph neural networks, a domain where such systematic analysis has been lacking. The authors benchmark various graph datasets across node classification, link prediction, and graph classification tasks, analyzing model sizes up to 100 million parameters and dataset sizes up to 50 million samples. They verify that neural scaling laws hold on graphs and identify that model depth significantly impacts scaling behavior, unlike in computer vision and natural language processing. Additionally, they propose using the number of nodes or edges as a more effective metric than the number of graphs for data scaling, due to the irregularity of graph sizes. This reformed law provides a unified view of scaling behaviors across different graph tasks.

## Method Summary
The authors benchmark various graph datasets across fundamental tasks, analyzing how model performance scales with both model size (up to 100M parameters) and dataset size (up to 50M samples). They fit power-law scaling curves to the performance data and extract coefficients to analyze scaling behavior. The experiments systematically vary model depth and width, using different graph neural network architectures (GCN, GIN, SAT, GraphGPS). They also reform the data scaling law by using the number of nodes or edges as the metric instead of the number of graphs, addressing the issue of irregular graph sizes across datasets.

## Key Results
- Model depth significantly affects scaling law coefficients in graph models, unlike in CV/NLP domains
- Using number of edges or nodes as data metric yields better R² values than using number of graphs for heterogeneous datasets
- A unified scaling law framework across node classification, link prediction, and graph classification tasks is achieved using edges/nodes as metric

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Model depth influences scaling law coefficients, unlike in CV/NLP where depth effects vanish.
- **Mechanism**: Graph neural networks introduce non-parametric aggregation layers that create layer-dependent receptive fields. Unlike standard transformers with global attention, GNNs' aggregation steps are inherently local, causing deeper models to aggregate over larger but still finite neighborhoods. This locality makes depth a performance driver rather than a neutral architectural choice.
- **Core assumption**: The aggregation operation cannot be folded into parameter scaling; it has a distinct functional role that interacts with model width in a non-linear way.
- **Evidence anchors**:
  - [abstract]: "we identify that despite the parameter numbers, the model depth also plays an important role in affecting the model scaling behaviors, which differs from observations in other domains such as CV and NLP."
  - [section 5]: Figures 4 and 5 show that scaling curves shift with layer count and that fixing aggregation vs feed-forward layers still produces distinct behaviors.
  - [corpus]: Weak; no direct neighbor paper discusses depth effects on graph scaling laws.
- **Break condition**: If aggregation were replaced with a fully global attention mechanism (e.g., graph transformer with full attention), the depth-dependent scaling coefficient variation could disappear.

### Mechanism 2
- **Claim**: The number of edges (or nodes) is a more faithful data metric than the number of graphs because graph sizes are highly irregular.
- **Mechanism**: In datasets with heterogeneous graph sizes, counting graphs treats a tiny molecule and a massive social network as equal units. Edge/node counts aggregate the total amount of relational structure available for training, better capturing the effective data volume and computational cost.
- **Core assumption**: Graphs within a dataset are drawn from a similar degree distribution, so edge and node counts are interchangeable for scaling law purposes.
- **Evidence anchors**:
  - [abstract]: "we suggest that the number of graphs can not effectively measure the graph data volume in scaling law since the sizes of different graphs are highly irregular."
  - [section 6]: Controlled experiments show better R² when fitting with edges/nodes vs graphs, and model scaling curves diverge for datasets with same graph count but different edge totals.
  - [corpus]: Weak; no neighbor paper directly addresses this metric choice.
- **Break condition**: If graph sizes are uniform (e.g., synthetic motif tasks), the graph count metric would be equivalent to edge/node counts.

### Mechanism 3
- **Claim**: Graph scaling laws unify across node classification, link prediction, and graph classification when using edges (or nodes) as the data metric.
- **Mechanism**: All three tasks can be expressed in terms of available edges/nodes: node classification uses the total node set, link prediction uses edge pairs, graph classification uses edges across graphs. Using a common metric enables a single functional form to describe all.
- **Core assumption**: The training compute and information content scale predictably with the total number of edges/nodes for each task type.
- **Evidence anchors**:
  - [abstract]: "we reform the data scaling law with the number of nodes or edges as the metric to address the irregular graph sizes... a unified view of the data scaling behaviors for various fundamental graph tasks."
  - [section 7]: Figures 9 and 24 show that node classification and link prediction follow the same power-law form with edges/nodes as metric, with high R².
  - [corpus]: Weak; neighbors focus on NLP/CV scaling laws, not graph tasks.
- **Break condition**: If a new graph task fundamentally depends on a different structural feature (e.g., motif counts), the unified metric might not capture the relevant scaling behavior.

## Foundational Learning

- **Concept**: Power-law scaling laws in machine learning.
  - Why needed here: The paper's core claim is that model and data performance scale as power laws; understanding the functional form and coefficient interpretation is essential to grasp the novelty and implications.
  - Quick check question: If a task's error follows ϵ ∝ N^−b with b=0.5, what happens to error if model size increases by a factor of 4?

- **Concept**: Graph neural network architecture (message passing, aggregation layers).
  - Why needed here: The paper hinges on how GNNs differ from standard transformers, especially the role of aggregation layers in depth-dependent scaling. Without this, the claim about depth effects is opaque.
  - Quick check question: In a 3-layer GNN, how many hops away can a node's representation incorporate information from its neighbors?

- **Concept**: Overfitting and model scaling collapse.
  - Why needed here: The paper notes that scaling laws can fail when models are too large for available data, leading to collapse. Understanding this helps explain the practical limits of scaling and why dataset size matters beyond just metric choice.
  - Quick check question: If training loss keeps decreasing but validation loss increases after epoch 20, what phenomenon is occurring?

## Architecture Onboarding

- **Component map**: Datasets (graphs with node/edge features) -> Graph Models (GNN or graph transformer) -> Scaling Law Fitter (fits power-law curves)
- **Critical path**: (1) Prepare dataset subsets at varying sizes (controlled by edges/nodes). (2) Train models across a range of widths and fixed depths. (3) Record performance. (4) Fit scaling laws and extract coefficients. (5) Analyze how coefficients change with depth and data metric.
- **Design tradeoffs**: Using edges/nodes as metric gives better R² but requires more bookkeeping and may not apply if graph sizes are uniform. Fixed depth across experiments simplifies comparison but misses potential optimal depth per task.
- **Failure signatures**: Poor R² (< 0.8) indicates the power-law assumption fails; divergent scaling curves for same graph count but different edge totals indicate metric choice matters; overfitting (training loss << validation loss) indicates model too large for data.
- **First 3 experiments**:
  1. Reproduce model scaling on OGBG-PPA with GCN at depths 3,4,5; verify coefficient shifts.
  2. Fit data scaling on synthetic motif dataset using edges vs graphs; compare R².
  3. Test unified scaling on OGBN-ARXIV (node classification) and OGBL-COLLAB (link prediction) using edges as metric; check if same functional form fits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal number of aggregation layers in graph models vary across different types of graph tasks and datasets?
- Basis in paper: [explicit] The paper shows that different models (GCN, GIN, SAT, GraphGPS) exhibit distinct scaling behaviors with varying depths, and that the optimal number of layers is task-specific and model-specific.
- Why unresolved: While the paper identifies that model depth affects scaling behavior, it does not provide a principled method for automatically selecting the optimal number of aggregation layers.
- What evidence would resolve it: Systematic experiments across diverse graph tasks and datasets to identify patterns in optimal aggregation layer numbers, potentially leading to guidelines or heuristics for layer selection.

### Open Question 2
- Question: Can a unified scaling law framework be developed that incorporates both model and data scaling laws for graph learning tasks?
- Basis in paper: [inferred] The paper discusses model and data scaling laws separately but does not explore their integration into a comprehensive framework.
- Why unresolved: The paper focuses on establishing individual scaling laws but does not investigate how they interact or can be combined into a unified model.
- What evidence would resolve it: Development and validation of a comprehensive scaling law model that accurately predicts performance across varying model and dataset sizes, accounting for interactions between these factors.

### Open Question 3
- Question: How do neural scaling laws on graphs change when considering heterogeneous graph data with nodes and edges of different types?
- Basis in paper: [inferred] The paper assumes homogeneous graph data with unified feature spaces, as stated in the limitations section.
- Why unresolved: The paper's experiments are limited to homogeneous graphs, leaving the behavior of scaling laws on heterogeneous graphs unexplored.
- What evidence would resolve it: Experiments on diverse heterogeneous graph datasets to determine how scaling laws are affected by node and edge type heterogeneity, potentially leading to modified scaling law formulations.

## Limitations

- The paper assumes homogeneous graph data with unified feature spaces, limiting applicability to heterogeneous graphs
- Exact implementation details of graph models and preprocessing steps are not fully specified
- The depth-dependent scaling coefficient variation lacks theoretical grounding from the broader literature

## Confidence

- **High confidence**: The empirical observation that edges/nodes as data metrics yield better R² values than graph counts for heterogeneous datasets
- **Medium confidence**: The claim that depth affects scaling law coefficients differently in graphs vs CV/NLP, given the mechanistic explanation but limited theoretical support
- **Medium confidence**: The unified scaling law across graph tasks when using edges/nodes, pending further validation on additional tasks and datasets

## Next Checks

1. Test the depth-dependent scaling coefficient hypothesis on a graph transformer with global attention to check if the effect disappears
2. Validate the edges/nodes metric on a dataset with uniform graph sizes to confirm the break condition
3. Apply the unified scaling law to a new graph task (e.g., subgraph prediction) to check for functional form consistency