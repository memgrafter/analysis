---
ver: rpa2
title: 'Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge
  Graph Question Answering'
arxiv_id: '2404.14741'
source_url: https://arxiv.org/abs/2404.14741
tags:
- triples
- knowledge
- llms
- question
- generate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of knowledge graph question answering
  (KGQA) when the knowledge graph (KG) is incomplete, meaning it lacks some required
  facts for answering questions. The authors propose a novel method called Generate-on-Graph
  (GoG) that treats the LLM as both an agent exploring the KG and as a knowledge source
  for generating missing facts.
---

# Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering

## Quick Facts
- arXiv ID: 2404.14741
- Source URL: https://arxiv.org/abs/2404.14741
- Authors: Yao Xu; Shizhu He; Jiabei Chen; Zihao Wang; Yangqiu Song; Hanghang Tong; Guang Liu; Kang Liu; Jun Zhao
- Reference count: 13
- Primary result: GoG achieves 84.4% Hits@1 on complete KGs and 80.3% on incomplete KGs, outperforming previous methods

## Executive Summary
This paper addresses the challenge of Knowledge Graph Question Answering (KGQA) when the knowledge graph is incomplete. The authors propose Generate-on-Graph (GoG), a novel method that treats the Large Language Model (LLM) as both an agent exploring the KG and as a knowledge source for generating missing facts. GoG uses a Thinking-Searching-Generating framework to reason about what to do next, search the KG for relevant information, and generate new triples using the LLM's internal knowledge when needed. Experiments on two datasets show GoG significantly outperforms previous methods, achieving high accuracy even when the KG lacks required information.

## Method Summary
GoG addresses incomplete KGQA by leveraging LLM's dual capabilities as both an exploration agent and a knowledge source. The method employs a Thinking-Searching-Generating framework where the LLM first reasons about the question and determines next actions, then searches the KG using predefined SPARQL queries to find relevant information, and finally generates new factual triples when the search fails to find sufficient information. The generated triples are verified before being used to answer the question. GoG also implements dynamic subgraph expansion to effectively handle compound value type nodes by searching one additional hop when encountering such nodes. The method is evaluated on WebQSP and CWQ datasets with artificially incomplete KGs constructed by randomly dropping triples.

## Key Results
- GoG achieves 84.4% Hits@1 accuracy on complete KGs and 80.3% on incomplete KGs
- Outperforms previous methods like ToG and mShingle across multiple incomplete KG settings
- Demonstrates effectiveness of treating LLM as both agent and knowledge source for IKGQA
- Dynamic subgraph expansion successfully handles compound value type nodes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The LLM can act as both an agent and a knowledge graph to answer questions when the KG is incomplete.
- Mechanism: The Thinking-Searching-Generating framework enables the LLM to decompose the question, search the KG for relevant information, and generate new triples when needed. The LLM uses its internal knowledge to fill gaps in the incomplete KG.
- Core assumption: The LLM contains sufficient internal knowledge to generate accurate triples that are missing from the KG.
- Evidence anchors: [abstract] "GoG performs reasoning through a Thinking-Searching-Generating framework, which treats LLM as both Agent and KG in IKGQA." [section 5] "GoG utilizes the Thinking-Searching-Generating framework, which consists of three main steps: Thinking, Searching and Generating."
- Break condition: If the LLM's internal knowledge is insufficient or inaccurate, it will generate incorrect triples, leading to wrong answers.

### Mechanism 2
- Claim: Dynamic subgraph expansion allows GoG to handle compound value type (CVT) nodes effectively.
- Mechanism: When GoG encounters CVT nodes, it continues searching one more hop to retrieve information from neighboring entities. This allows GoG to access information that would otherwise be ignored by methods that treat CVTs as dead ends.
- Core assumption: Information about CVT nodes can be found in their neighboring entities, making the additional search step valuable.
- Evidence anchors: [section 5.2] "GoG adopts a dynamic subgraph expansion search strategy, while ToG only explores some paths." [section H.1] "Our GoG can handle CVT nodes well by further searching."
- Break condition: If CVT nodes are truly isolated with no useful neighboring information, the additional search step will not help.

### Mechanism 3
- Claim: The Generate Action enables GoG to integrate internal and external knowledge effectively.
- Mechanism: When the search step fails to find the answer, GoG uses the LLM to generate new factual triples based on the explored subgraph and its internal knowledge. These generated triples are then verified before being used to answer the question.
- Core assumption: The LLM can accurately generate new triples that are missing from the incomplete KG when provided with relevant context.
- Evidence anchors: [abstract] "GoG, which can generate new factual triples while exploring KGs." [section 5.3] "This action tries to utilize the LLM to generate new factual triples based on retrieval information and internal knowledge."
- Break condition: If the LLM generates incorrect triples (hallucinations), the answer will be wrong even if the search step was correct.

## Foundational Learning

- Concept: Knowledge Graph Question Answering (KGQA)
  - Why needed here: Understanding KGQA is essential to grasp the difference between conventional KGQA and the proposed IKGQA task.
  - Quick check question: What is the difference between KGQA and IKGQA?

- Concept: Large Language Models (LLMs) as Knowledge Sources
  - Why needed here: GoG relies on the LLM's internal knowledge to generate missing triples, so understanding how LLMs can serve as knowledge sources is crucial.
  - Quick check question: How does GoG use the LLM's internal knowledge to fill gaps in the incomplete KG?

- Concept: Semantic Parsing vs. Retrieval Augmented Methods
  - Why needed here: GoG belongs to the retrieval augmented category, so understanding the differences between these two approaches is important for comparing GoG with other methods.
  - Quick check question: What are the main differences between semantic parsing and retrieval augmented methods for KGQA?

## Architecture Onboarding

- Component map: Question → Thinking → Searching → (Generate if needed) → Verifying → Answer
- Critical path: Question → Thinking → Searching → (Generate if needed) → Verifying → Answer
- Design tradeoffs:
  - Using LLM for both agent and KG roles increases flexibility but introduces potential for hallucinations
  - Dynamic subgraph expansion handles CVTs better but may increase computation time
  - Multiple generation attempts reduce errors but increase latency
- Failure signatures:
  - Incorrect answers due to LLM hallucinations during generation
  - Failed searches when KG lacks sufficient information
  - Decomposition errors leading to wrong sub-questions
- First 3 experiments:
  1. Run GoG on a simple question with a complete KG to verify basic functionality
  2. Test GoG on a question requiring generation of new triples to verify the Generate Action
  3. Evaluate GoG's performance on questions involving CVT nodes to test dynamic subgraph expansion

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GoG vary when using different LLMs as both the agent and the knowledge source, and what are the trade-offs between different models in these dual roles?
- Basis in paper: [explicit] The paper mentions that different LLMs (GPT-4, GPT-3.5, Qwen-1.5, Llama-3) are evaluated as backbones for GoG, with GPT-4 showing the best performance, but also notes that proficiency as a KG and as an agent is not entirely equivalent.
- Why unresolved: The paper provides comparative results but doesn't deeply analyze the specific strengths and weaknesses of each LLM when performing the dual roles of agent and knowledge source, nor does it explore how to leverage different models' strengths in these specific roles.
- What evidence would resolve it: Detailed ablation studies comparing different LLMs specifically in their agent vs. KG roles, analysis of error types associated with each model's performance in each role, and experiments optimizing the framework to leverage each model's strengths.

### Open Question 2
- Question: What is the optimal number of related triples to provide in the Generate Action to balance the benefits of additional context against the risks of introducing noise?
- Basis in paper: [explicit] The paper conducts experiments showing performance varies with the number of related triples (Figure 4), finding initial improvement followed by degradation as more triples are added.
- Why unresolved: While the paper identifies that performance peaks and then declines with more triples, it doesn't establish specific guidelines for the optimal number or develop methods to dynamically determine the right amount based on the question complexity or context.
- What evidence would resolve it: A systematic study mapping question complexity, context richness, and optimal triple numbers; development of a method to automatically determine the appropriate number of triples per question; and validation showing improved performance with this adaptive approach.

### Open Question 3
- Question: How can the Generate Action be made more reliable to reduce hallucination while maintaining its effectiveness in generating missing facts?
- Basis in paper: [inferred] The paper acknowledges that hallucination is unavoidable in the Generate Action and is the primary source of errors, yet this action is crucial for handling incomplete KGs.
- Why unresolved: The paper doesn't propose specific mechanisms to mitigate hallucination in the generation process beyond verification steps, nor does it explore alternative approaches to fact generation that might be more reliable.
- What evidence would resolve it: Comparative studies of different generation strategies (e.g., retrieval-augmented generation, constrained decoding, fact-checking mechanisms), analysis of hallucination patterns to identify mitigations, and experimental validation showing reduced hallucination rates while maintaining or improving accuracy.

## Limitations
- LLM Dependency and Hallucination Risk: The Generate Action relies heavily on LLM's internal knowledge, introducing significant hallucination risk that isn't systematically quantified
- Dataset and KG Specificity: Experiments limited to WebQSP and CWQ datasets with Freebase, using artificial incompleteness via random triple dropping
- Missing Implementation Details: Critical details like prompt templates, SPARQL queries, and BM25 parameters are not provided

## Confidence
- High Confidence: The Thinking-Searching-Generating framework design and basic operation are clearly specified and logically sound
- Medium Confidence: Experimental results showing improved performance over baselines, though limited by dataset specificity and lack of hallucination quantification
- Low Confidence: Claims about GoG's effectiveness in handling compound value types and real-world KG incompleteness without supporting evidence beyond controlled experiments

## Next Checks
1. Conduct a systematic evaluation of generated triples against ground truth to quantify hallucination rates and identify patterns in incorrect generations
2. Test GoG on KGs with structured incompleteness (e.g., missing entire entity types) rather than random triple dropping to assess real-world applicability
3. Perform an ablation study removing the Generate Action to isolate its contribution and measure the tradeoff between improved accuracy and increased hallucination risk