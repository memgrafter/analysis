---
ver: rpa2
title: 'PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution
  Diffusion Teacher'
arxiv_id: '2405.14822'
source_url: https://arxiv.org/abs/2405.14822
tags:
- pagoda
- training
- diffusion
- data
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the high computational cost of training diffusion
  models, particularly at high resolutions. It proposes a progressive growing pipeline
  (PaGoDA) that significantly reduces training costs by first training diffusion models
  on downsampled data, then distilling to a one-step generator, and finally progressively
  growing for super-resolution.
---

# PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher

## Quick Facts
- arXiv ID: 2405.14822
- Source URL: https://arxiv.org/abs/2405.14822
- Reference count: 40
- Key outcome: Achieves 64× reduced training computation with state-of-the-art FID on ImageNet (64×64 to 512×512) via progressive growing from downsampled diffusion models

## Executive Summary
PaGoDA addresses the high computational cost of training diffusion models at high resolutions by introducing a progressive growing pipeline. The method first trains diffusion models on downsampled data, then distills to a one-step generator using DDIM inversion to incorporate high-frequency details, and finally progressively grows for super-resolution. This approach achieves state-of-the-art Fréchet Inception Distances (FID) across resolutions from 64×64 to 512×512 while reducing training computation by 64×. The key innovation lies in using DDIM inversion during distillation to capture real data details and combining reconstruction with adversarial losses for stable upscaling.

## Method Summary
PaGoDA operates in three progressive stages: (1) Train a diffusion model on downsampled data (e.g., 8× downsampling to 64×64), reducing computational cost by 64×; (2) Distill the diffusion model to a one-step generator using DDIM inversion with reconstruction loss to preserve high-frequency details from real data and adversarial loss for quality; (3) Progressively grow the generator through resolution stages (64→128→256→512), freezing pretrained parameters while training only new upscaling layers with both reconstruction and adversarial losses. This architecture enables high-quality generation at resolutions where direct diffusion training would be prohibitively expensive.

## Key Results
- Achieves 64× reduced training computation by training diffusion models on 8× downsampled data
- State-of-the-art FID scores on ImageNet across resolutions from 64×64 to 512×512
- Competitive 1-step sampling performance in text-to-image generation compared to multi-step diffusion models
- Demonstrates effectiveness of DDIM inversion in preserving high-frequency details during distillation

## Why This Works (Mechanism)

### Mechanism 1: Progressive Growing Reduces Computational Cost
Training diffusion models directly at high resolution requires computational cost proportional to the square of the resolution. By training on an 8× downsampled version (64×64 instead of 512×512), the computational cost is reduced by 64×. The downsampled training captures sufficient information to enable high-quality generation after progressive upscaling, though the core assumption is that critical information isn't lost in downsampling.

### Mechanism 2: DDIM Inversion Incorporates High-Frequency Details
Instead of traditional noise-to-data distillation, PaGoDA uses DDIM inversion to obtain latent representations of real data. This allows the reconstruction loss to operate directly on high-dimensional real data rather than just the latent space, enabling the decoder to be trained with high-frequency signals from real data. The core assumption is that DDIM inversion accurately captures the high-frequency information needed for high-quality reconstruction.

### Mechanism 3: Reconstruction + Adversarial Losses Ensure Fidelity and Quality
The reconstruction loss prevents objects from shifting across resolution jumps, while the adversarial loss captures high-frequency details. Together they enable stable and effective upscaling. The adversarial loss operates directly in high-dimensional space, enabled by the one-step generator trained in Stage 2. The core assumption is that this combination provides the right balance between fidelity preservation and quality enhancement.

## Foundational Learning

- **Concept: Diffusion Models and Probability Flow ODEs**
  - Why needed here: PaGoDA builds directly on diffusion model training and the DDIM/probability flow ODE framework for generation and inversion
  - Quick check question: What is the relationship between the forward diffusion process and the probability flow ODE used in DDIM?

- **Concept: Knowledge Distillation in Generative Models**
  - Why needed here: The core of PaGoDA is distilling a pretrained diffusion model into a one-step generator, which requires understanding distillation techniques
  - Quick check question: How does the reconstruction loss in PaGoDA differ from traditional noise-to-data distillation?

- **Concept: Progressive Growing in GANs**
  - Why needed here: PaGoDA's Stage 3 uses progressive growing techniques inspired by Progressive GANs to gradually increase resolution
  - Quick check question: Why does freezing most parameters of the base-resolution model help with stability during progressive upscaling?

## Architecture Onboarding

- **Component map**: Downsampled data → Stage 1 diffusion training → Stage 2 distillation (DDIM inversion + losses) → Stage 3 progressive upscaling → final high-resolution output
- **Critical path**: The flow is: downsampled data → Stage 1 diffusion training → Stage 2 distillation (DDIM inversion + losses) → Stage 3 progressive upscaling → final high-resolution output
- **Design tradeoffs**:
  - Resolution vs. computation: Lower base resolution reduces training cost but may require more upscaling stages
  - Reconstruction vs. adversarial loss: Reconstruction ensures fidelity while adversarial loss ensures quality; balance is crucial
  - Freezing vs. training: Freezing base model parameters provides stability but limits adaptation during upscaling
- **Failure signatures**:
  - Blurry outputs: Likely indicates reconstruction loss is too dominant or adversarial loss is too weak
  - Unstable training: May indicate improper balance of losses or insufficient freezing of base model
  - Loss of detail: Could mean DDIM inversion is not capturing high-frequency information properly
- **First 3 experiments**:
  1. Train PaGoDA at 64×64 base resolution and evaluate FID compared to teacher model
  2. Add first upscaling stage (64→128) and compare quality metrics
  3. Test with and without DDIM inversion in Stage 2 to verify its impact on final quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PaGoDA's performance scale when applied directly to latent space diffusion models (like Stable Diffusion) rather than pixel space?
- Basis in paper: Explicit - The authors mention "PaGoDA could be directly applied into the latent space as-is, offering the possibility of further gain on training computes" and note this as a promising avenue for future research.
- Why unresolved: The paper only demonstrates PaGoDA in pixel space and uses pre-trained latent diffusion models for text-to-image generation without applying PaGoDA's progressive growing to the latent space itself.
- What evidence would resolve it: Empirical comparison of PaGoDA applied to latent space vs pixel space, including training compute reduction, FID scores, and sample quality metrics across different resolutions.

### Open Question 2
- Question: What is the optimal base resolution for PaGoDA's Stage 1 diffusion training that balances computational efficiency with upscaling capability?
- Basis in paper: Explicit - The authors investigate 32×32 vs 64×64 base resolutions and note that "Starting at resolutions below 32×32 imposes excessive complexity on the upscaling network" while higher resolutions increase computational costs.
- Why unresolved: The paper only tests two resolutions and doesn't explore the full trade-off space or provide theoretical guidance on optimal selection.
- What evidence would resolve it: Systematic ablation study testing multiple base resolutions (e.g., 16×16, 32×32, 64×64, 128×128) with corresponding upscaling performance metrics and computational cost analysis.

### Open Question 3
- Question: How sensitive is PaGoDA's performance to the number of data-latent pairs used in Stage 2 distillation?
- Basis in paper: Explicit - The authors state "In our ImageNet experiments, we found that updating the reconstruction loss with as little as 1% of the data-latent pairs did not affect sample quality and diversity" and suggest this as future work.
- Why unresolved: The paper only tests one data efficiency scenario and doesn't explore the full range of possibilities or identify potential breaking points.
- What evidence would resolve it: Comprehensive study varying the percentage of data-latent pairs (e.g., 0.1%, 1%, 10%, 100%) with corresponding FID scores and diversity metrics to identify the minimum effective training set size.

## Limitations
- Progressive growing may face challenges with complex scene layouts or highly detailed objects requiring information preservation across resolution jumps
- Computational cost analysis focuses on training efficiency but does not address inference time or memory requirements at higher resolutions
- Impact of DDIM inversion quality on high-resolution outputs is assumed rather than empirically validated through extensive ablations

## Confidence
- **High confidence**: The 64× computational reduction claim and baseline FID/IS comparisons on ImageNet (directly measurable and reproducible)
- **Medium confidence**: The effectiveness of DDIM inversion for capturing high-frequency details (supported by qualitative results but limited quantitative ablation)
- **Medium confidence**: The stability of progressive growing with reconstruction + adversarial losses (the mechanism is sound but depends heavily on hyperparameter tuning)

## Next Checks
1. **DDIM Inversion Quality Analysis**: Conduct quantitative comparisons of DDIM-inverted latents versus traditional noise-to-data approaches on high-frequency detail preservation metrics (e.g., LPIPS on reconstructed vs. real images)
2. **Progressive Growing Sensitivity**: Systematically vary the reconstruction-to-adversarial loss ratio across different resolution jumps to identify optimal weighting and stability thresholds
3. **Scaling Beyond 512×512**: Test PaGoDA at 1024×1024 resolution to evaluate whether the computational savings and quality preservation scale proportionally or if diminishing returns emerge