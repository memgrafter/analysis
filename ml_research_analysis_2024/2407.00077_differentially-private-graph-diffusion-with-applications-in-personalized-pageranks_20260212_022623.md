---
ver: rpa2
title: Differentially Private Graph Diffusion with Applications in Personalized PageRanks
arxiv_id: '2407.00077'
source_url: https://arxiv.org/abs/2407.00077
tags:
- graph
- diffusion
- privacy
- noise
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of releasing private graph diffusion
  vectors while preserving sensitive linking information in graph data. The proposed
  method injects Laplace noise per diffusion iteration and uses a degree-based thresholding
  function to mitigate high sensitivity induced by low-degree nodes.
---

# Differentially Private Graph Diffusion with Applications in Personalized PageRanks

## Quick Facts
- arXiv ID: 2407.00077
- Source URL: https://arxiv.org/abs/2407.00077
- Authors: Rongzhe Wei; Eli Chien; Pan Li
- Reference count: 40
- Primary result: Novel DP graph diffusion method using iterative Laplace noise injection with degree-based thresholding, achieving superior ranking performance under stringent privacy conditions

## Executive Summary
This paper addresses the challenge of releasing private graph diffusion vectors while preserving sensitive linking information in graph data. The proposed method injects Laplace noise per diffusion iteration and uses a degree-based thresholding function to mitigate high sensitivity induced by low-degree nodes. The framework leverages Privacy Amplification by Iteration (PABI) and introduces a novel Infinity-Wasserstein distance tracking method to tighten privacy leakage analysis. The method is evaluated on Personalized PageRank computation for ranking tasks, demonstrating superior performance under stringent privacy conditions.

## Method Summary
The paper proposes a differentially private graph diffusion framework that releases diffusion vectors while protecting sensitive linking information. The core mechanism involves iterative Laplace noise injection during the diffusion process, with sensitivity controlled through a degree-based thresholding function. Privacy Amplification by Iteration is leveraged to improve the privacy-utility tradeoff. The framework includes a novel method for tracking privacy leakage using Infinity-Wasserstein distance, which provides tighter bounds on cumulative privacy loss across iterations.

## Key Results
- Achieves significant improvements in NDCG@100 and Recall@100 metrics compared to baseline methods
- Demonstrates superior performance particularly under stringent privacy conditions (ε ≤ 1)
- Shows effectiveness across multiple real-world network datasets

## Why This Works (Mechanism)
The method works by carefully controlling the sensitivity of graph diffusion operations through degree-based thresholding, which prevents low-degree nodes from causing excessive privacy loss. The iterative noise injection strategy, combined with Privacy Amplification by Iteration, allows for more accurate diffusion results while maintaining strong privacy guarantees. The Infinity-Wasserstein distance tracking provides more precise privacy accounting than traditional methods, enabling better utility under the same privacy budget.

## Foundational Learning

**Differential Privacy (DP)**: A framework for measuring privacy loss in data releases. Why needed: Provides the theoretical foundation for quantifying privacy guarantees. Quick check: Verify that the privacy parameters (ε, δ) are properly bounded throughout the algorithm.

**Privacy Amplification by Iteration (PABI)**: A technique that reduces privacy loss in iterative algorithms. Why needed: Enables better utility-privacy tradeoffs in iterative graph algorithms. Quick check: Confirm that the amplification factor is correctly calculated for the specific diffusion process.

**Wasserstein Distance**: A metric for measuring the distance between probability distributions. Why needed: Used for tracking cumulative privacy loss across iterations. Quick check: Validate that the Infinity-Wasserstein metric provides tighter bounds than standard methods.

**Personalized PageRank (PPR)**: A variant of PageRank that computes node importance from a specific source node. Why needed: Serves as the primary application and evaluation metric. Quick check: Ensure the PPR computation remains accurate despite noise injection.

**Graph Diffusion**: The process of spreading information or influence across a graph structure. Why needed: Forms the core operation being protected. Quick check: Verify that the diffusion process converges properly under the noise constraints.

**Sensitivity Analysis**: The study of how small changes in input affect output. Why needed: Critical for determining appropriate noise levels. Quick check: Confirm that the degree-based thresholding effectively bounds sensitivity.

## Architecture Onboarding

**Component Map**: Graph -> Diffusion Engine -> Noise Injector -> Thresholding Function -> Output Vector

**Critical Path**: The core algorithm iterates through diffusion steps where each iteration involves: (1) computing the next diffusion state, (2) adding calibrated Laplace noise, (3) applying degree-based thresholding, and (4) updating the cumulative privacy budget using Infinity-Wasserstein tracking.

**Design Tradeoffs**: The framework balances between noise magnitude (affecting accuracy) and privacy budget consumption. Higher noise provides better privacy but reduces utility. The degree-based thresholding reduces sensitivity but may discard useful information from low-degree nodes.

**Failure Signatures**: If the privacy budget is exhausted too quickly, the output will be overly noisy and rankings will degrade. If thresholding is too aggressive, important information from low-degree nodes may be lost. If the Infinity-Wasserstein tracking is incorrect, the actual privacy loss may exceed the claimed bounds.

**Three First Experiments**:
1. Verify that the degree-based thresholding correctly bounds sensitivity by testing on graphs with varying degree distributions
2. Confirm that Privacy Amplification by Iteration provides the expected improvement in the privacy-utility tradeoff
3. Validate that the Infinity-Wasserstein distance tracking produces tighter privacy bounds than standard composition methods

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead of Laplace noise injection per iteration may impact scalability for large-scale graphs
- Degree-based thresholding introduces additional hyperparameters requiring careful tuning
- Theoretical privacy analysis relies on specific assumptions about graph structure that may not generalize across all network types

## Confidence
- High confidence in mathematical formulation and privacy guarantees
- Medium confidence in empirical results due to limited evaluation scope
- Low confidence in generalizability across different graph types and diffusion applications

## Next Checks
1. Evaluate scalability and runtime performance on graphs with millions of nodes and edges to assess practical applicability
2. Test the framework on diverse graph types (heterogeneous, temporal, weighted) to verify robustness across network structures
3. Extend experiments to additional diffusion-based applications such as community detection or influence maximization to validate broader utility