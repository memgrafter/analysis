---
ver: rpa2
title: Applying Pre-trained Multilingual BERT in Embeddings for Improved Malicious
  Prompt Injection Attacks Detection
arxiv_id: '2409.13331'
source_url: https://arxiv.org/abs/2409.13331
tags:
- bert
- prompt
- language
- injection
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of detecting malicious prompt
  injection attacks in large language models (LLMs), a significant security vulnerability.
  The authors propose using multilingual BERT embeddings to improve detection performance.
---

# Applying Pre-trained Multilingual BERT in Embeddings for Improved Malicious Prompt Injection Attacks Detection

## Quick Facts
- arXiv ID: 2409.13331
- Source URL: https://arxiv.org/abs/2409.13331
- Reference count: 33
- Primary result: Achieved 96.55% accuracy using multilingual BERT embeddings with Logistic Regression for prompt injection detection

## Executive Summary
This study addresses the critical security vulnerability of malicious prompt injection attacks in large language models (LLMs) by proposing a multilingual BERT embedding approach for improved detection. The authors demonstrate that contextualized embeddings generated by multilingual BERT significantly outperform traditional methods like TF-IDF for classifying malicious versus legitimate prompts. Using a dataset of 662 prompts (546 training, 116 testing) from the HuggingFace Prompt Injection Dataset, the approach achieves an accuracy of 96.55% with Logistic Regression, along with strong precision (1.00) and recall (0.9333) scores. The method also enables effective cross-lingual detection capabilities that monolingual approaches cannot provide.

## Method Summary
The approach involves tokenizing prompt texts using multilingual BERT (bert-base-multilingual-uncased) to generate contextualized embeddings, then training and evaluating four machine learning models: Gaussian Naive Bayes, Random Forest, Support Vector Machine, and Logistic Regression. The Prompt Injection Dataset from deepset contains English and multilingual prompts labeled as normal or malicious. After tokenization and embedding generation, the models are trained on 546 samples and tested on 116 samples, with performance evaluated using accuracy, precision, recall, and F1-score metrics.

## Key Results
- Multilingual BERT embeddings with Logistic Regression achieved 96.55% accuracy, 1.00 precision, 0.9333 recall, and 0.9655 F1-score
- Outperformed existing methods including LSTM, HDSF, and TCNN approaches
- Demonstrated effective cross-lingual detection capabilities for prompt injection attacks
- ROC and AUC curves confirmed strong classification performance across all tested models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual BERT embeddings improve prompt injection detection accuracy by capturing semantic meaning across languages
- Mechanism: BERT tokenization creates subword tokens and generates contextualized embeddings that encode semantic relationships, allowing the model to better distinguish between legitimate and malicious prompts
- Core assumption: Semantic embeddings are more effective than traditional feature extraction methods like TF-IDF for text classification tasks
- Evidence anchors:
  - [abstract]: "Multilingual BERT approach to embed the prompts significantly improved and outperformed the existing works and achieves an outstanding accuracy of 96.55% by Logistic regression."
  - [section]: "These generated contextualized embeddings is a crucial requirement to make the dataset ready to feed the machine learning models and optimize its parameters specifically for prompt classification tasks."
  - [corpus]: Weak evidence - no direct corpus citations support this mechanism specifically
- Break condition: If the dataset contains prompts that rely heavily on syntactic rather than semantic features, or if the malicious prompts are crafted to appear semantically similar to legitimate ones

### Mechanism 2
- Claim: Logistic Regression achieves superior performance on multilingual BERT embeddings due to its ability to handle high-dimensional feature spaces effectively
- Mechanism: Logistic Regression learns optimal decision boundaries in the high-dimensional embedding space created by multilingual BERT, separating malicious from legitimate prompts with high precision
- Core assumption: The linear decision boundary assumption of Logistic Regression is sufficient for the prompt classification task given the rich feature representations from BERT
- Evidence anchors:
  - [abstract]: "Multilingual BERT approach to embed the prompts significantly improved and outperformed the existing works and achieves an outstanding accuracy of 96.55% by Logistic regression."
  - [section]: "Logistic Regression achieved the highest performance metrics with an accuracy (0.9655), precision (1.00), recall (0.9333), and an F1-score (0.9655)."
  - [corpus]: Weak evidence - no direct corpus citations support this mechanism specifically
- Break condition: If the decision boundary between malicious and legitimate prompts is highly non-linear, or if the dataset contains prompts with overlapping semantic features

### Mechanism 3
- Claim: The multilingual capability of BERT provides better generalization across different languages compared to monolingual models
- Mechanism: By training on multiple languages, multilingual BERT learns shared linguistic patterns and representations that transfer across languages, improving detection accuracy for prompts in various languages
- Core assumption: Malicious prompt injection techniques follow similar patterns across languages, allowing knowledge transfer between language-specific embeddings
- Evidence anchors:
  - [abstract]: "The dataset comprises two columns: 'text' and 'label'. The 'text' column contains the prompt texts: normal and malicious prompts, while the 'label' column includes their corresponding classification labels. Before training machine learning models, the text data needs to be tokenized and embedded which is performed using the multilingual BERT model."
  - [section]: "This helps in building detection models that work well across different languages. Traditional Word2Vec embeddings, which are specific to one language, would not work for our needs because they cannot represent multiple languages in the same way."
  - [corpus]: Weak evidence - no direct corpus citations support this mechanism specifically
- Break condition: If malicious prompt injection patterns are language-specific or culturally dependent, or if the dataset contains languages that multilingual BERT handles poorly

## Foundational Learning

- Concept: Tokenization in NLP
  - Why needed here: Tokenization is the first step in processing text data for machine learning, breaking down prompts into manageable units that can be analyzed by BERT and other models
  - Quick check question: What is the difference between word-level and subword-level tokenization, and why is subword tokenization particularly useful for multilingual models?

- Concept: Word embeddings and semantic representation
  - Why needed here: Understanding how word embeddings capture semantic meaning is crucial for grasping why BERT's contextualized embeddings outperform traditional methods like TF-IDF
  - Quick check question: How do word embeddings differ from TF-IDF in representing semantic relationships between words?

- Concept: Machine learning classification metrics
  - Why needed here: Understanding accuracy, precision, recall, and F1-score is essential for evaluating the performance of different models and interpreting the results presented in the paper
  - Quick check question: If a model has high accuracy but low recall, what does this tell you about its performance on the prompt injection detection task?

## Architecture Onboarding

- Component map: HuggingFace Prompt Injection Dataset -> Multilingual BERT tokenization -> Embedding generation -> ML model training (GNB, RF, SVM, LR) -> Performance evaluation
- Critical path: 1) Load and preprocess dataset 2) Tokenize prompts using multilingual BERT 3) Generate embeddings for all prompts 4) Train and evaluate each ML model 5) Analyze performance metrics 6) Compare results with existing methods
- Design tradeoffs:
  - Model complexity vs. interpretability: Logistic Regression offers good performance with high interpretability, while Random Forest may provide better accuracy but less interpretability
  - Multilingual vs. monolingual: Multilingual BERT handles multiple languages but may sacrifice some performance on English-specific tasks compared to English-only models
  - Pre-trained vs. custom-trained: Using pre-trained BERT saves time and resources but may not be optimized for the specific prompt injection detection task
- Failure signatures:
  - Low precision: Model is flagging too many legitimate prompts as malicious (high false positive rate)
  - Low recall: Model is missing too many actual malicious prompts (high false negative rate)
  - Overfitting: Model performs well on training data but poorly on test data
  - Class imbalance issues: Poor performance on the minority class (malicious prompts) due to imbalanced dataset
- First 3 experiments:
  1. Compare multilingual BERT embeddings vs. traditional TF-IDF features across all four ML models to quantify the performance improvement from using BERT
  2. Perform ablation study by testing English-only BERT vs. multilingual BERT on the dataset to measure the benefit of multilingual capability
  3. Test different BERT model sizes (base vs. large) to find the optimal balance between performance and computational efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of multilingual BERT embeddings compare to other advanced language models (e.g., GPT-based embeddings) for detecting malicious prompt injections in LLMs?
- Basis in paper: [explicit] The study uses multilingual BERT embeddings and achieves 96.55% accuracy with Logistic Regression, but does not compare against other advanced language models
- Why unresolved: The paper only compares BERT with DistilBERT and traditional ML models, not with other state-of-the-art language models
- What evidence would resolve it: Comparative experiments using embeddings from models like GPT, RoBERTa, or other transformer-based architectures on the same dataset and tasks

### Open Question 2
- Question: How does the detection system generalize to unseen types of prompt injection attacks not present in the training data?
- Basis in paper: [inferred] The study focuses on classifying known malicious and legitimate prompts but does not address the model's robustness against novel or evolving attack strategies
- Why unresolved: The paper does not evaluate the model's ability to detect new or adaptive attack patterns that differ from the training set
- What evidence would resolve it: Testing the model on datasets containing new, unseen prompt injection techniques and measuring its detection accuracy and false positive rates

### Open Question 3
- Question: What is the impact of prompt length and complexity on the detection performance of multilingual BERT embeddings?
- Basis in paper: [inferred] The study uses a dataset with various prompt lengths but does not analyze how prompt length or linguistic complexity affects detection accuracy
- Why unresolved: The paper does not investigate whether longer or more complex prompts pose challenges for the embedding and classification process
- What evidence would resolve it: Experiments analyzing detection accuracy across prompts of varying lengths and complexity levels, identifying potential performance degradation or improvement

## Limitations
- Results based on relatively small dataset (662 samples) with limited hyperparameter tuning
- Specific preprocessing steps and model hyperparameters not fully detailed in the paper
- Generalizability to real-world scenarios with evolving or novel prompt injection patterns remains unverified

## Confidence

**High Confidence**: The core finding that multilingual BERT embeddings improve prompt injection detection accuracy compared to traditional methods like TF-IDF is well-supported by the experimental results showing Logistic Regression achieving 96.55% accuracy.

**Medium Confidence**: The superiority of Logistic Regression over other tested models (SVM, Random Forest, Gaussian Naive Bayes) is demonstrated but may be sensitive to hyperparameter choices.

**Low Confidence**: The assertion that multilingual BERT will perform similarly on datasets with different prompt injection patterns or in production environments with evolving attack techniques lacks supporting evidence.

## Next Checks
1. Perform systematic hyperparameter optimization for all four ML models to determine if the reported Logistic Regression performance represents the optimal configuration
2. Test the multilingual BERT + Logistic Regression pipeline on an independently collected prompt injection dataset to assess generalizability
3. Generate adversarial prompts designed to evade detection by the trained models to evaluate their vulnerability to sophisticated prompt injection techniques