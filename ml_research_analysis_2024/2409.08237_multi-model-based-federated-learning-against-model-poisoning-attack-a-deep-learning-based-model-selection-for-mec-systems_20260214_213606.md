---
ver: rpa2
title: 'Multi-Model based Federated Learning Against Model Poisoning Attack: A Deep
  Learning Based Model Selection for MEC Systems'
arxiv_id: '2409.08237'
source_url: https://arxiv.org/abs/2409.08237
tags:
- learning
- attack
- global
- time
- devices
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multi-model based federated learning approach
  to mitigate model poisoning attacks by introducing model diversity and dynamic model
  selection. Instead of using a single global model, the approach employs a master
  model trained by a set of slave models, allowing dynamic model changes during learning
  epochs.
---

# Multi-Model based Federated Learning Against Model Poisoning Attack: A Deep Learning Based Model Selection for MEC Systems

## Quick Facts
- arXiv ID: 2409.08237
- Source URL: https://arxiv.org/abs/2409.08237
- Reference count: 18
- Primary result: Multi-model FL approach with DRL-based model selection achieves competitive accuracy under poisoning attacks while improving recognition time

## Executive Summary
This paper addresses the critical challenge of model poisoning attacks in federated learning systems by proposing a multi-model based approach that introduces dynamic model diversity. The key insight is that by allowing client models to have different structures that change across training epochs, attackers cannot reliably craft poisoned models that will be accepted by the global model. The approach is specifically designed for Mobile Edge Computing (MEC) systems where network conditions and computing capabilities vary dynamically. A deep reinforcement learning-based model selection mechanism optimizes the tradeoff between accuracy, robustness, and recognition time under these dynamic conditions. Experimental results on DDoS attack detection demonstrate that the multi-model approach maintains competitive accuracy compared to systems without attacks while potentially improving recognition time.

## Method Summary
The proposed method employs a multi-model federated learning framework where a master model is trained using a set of diverse slave models. The key innovation is the dynamic model selection mechanism powered by deep reinforcement learning, which adapts model assignments to devices based on network conditions and computing capabilities. Knowledge transfer occurs from slave models to the master model through unsupervised labeling, enabling efficient learning while maintaining model diversity. The system operates in an MEC environment with base stations performing partial aggregation and attack detection, while a central cloud handles global aggregation. The DRL agent learns to select appropriate models for each device to optimize the tradeoff between loss, recognition time, and robustness against poisoning attacks.

## Key Results
- Multi-model FL maintains competitive accuracy under poisoning attacks compared to systems without attacks
- DRL-based model selection improves recognition time while maintaining robustness
- Dynamic model structure changes successfully prevent attackers from crafting compatible poisoned models
- The approach effectively handles dynamic network conditions in MEC environments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-model diversity reduces poisoning attack success by breaking the attacker's ability to craft compatible poisoned models
- Mechanism: Dynamic structure changes across epochs prevent attackers from predicting global model structure needed for effective poisoned updates
- Core assumption: Attackers require knowledge of global model structure to craft compatible poisoned models
- Evidence anchors: [abstract] "structure of client models dynamically change within learning epochs" [section III.A] "mismatch between uploaded poisoned model and planned model can be detected at aggregation time"
- Break condition: If attackers can quickly adapt to structure changes or if changes are too predictable

### Mechanism 2
- Claim: DRL-based model selection optimizes the tradeoff between accuracy and robustness under dynamic network conditions
- Mechanism: RL agent learns to select appropriate slave models based on transmission rates, computing capabilities, and security requirements
- Core assumption: Optimization problem can be effectively solved using DRL due to large state/action spaces and dynamic wireless communications
- Evidence anchors: [section V] "MDP and RL advocated for solutions adoptable with dynamic network situations" [section V] "High dimension of states and dynamicity in state transitions makes observing all states and actions in training impossible"
- Break condition: If state representation is insufficient or reward function doesn't capture true objectives

### Mechanism 3
- Claim: Knowledge transfer from slave models to master model enables efficient learning while maintaining model diversity
- Mechanism: Each BS performs unsupervised knowledge transfer by labeling data with slave models and using it to train master model
- Core assumption: Slave models can effectively transfer knowledge to master model through unsupervised labeling and gradient descent
- Evidence anchors: [section III.B] "Each BS performs knowledge transfer step to transfer knowledge of each slave model to master model" [section III.B] "Algorithm 1: Knowledge Transfer" describes the process
- Break condition: If knowledge transfer is ineffective or slave models provide contradictory information

## Foundational Learning

- Concept: Federated Learning basics
  - Why needed here: Understanding distributed model training without sharing raw data is fundamental to grasping attack surface and defense mechanisms
  - Quick check question: What are the main steps in a federated learning round and how does it differ from centralized training?

- Concept: Model poisoning attacks
  - Why needed here: The paper's defense mechanism specifically counters model poisoning attacks, so understanding attack mechanics is crucial
  - Quick check question: How do attackers typically craft poisoned models to compromise federated learning systems?

- Concept: Reinforcement Learning and Markov Decision Processes
  - Why needed here: The model selection mechanism uses DRL, requiring understanding of how agents learn optimal policies through environment interaction
  - Quick check question: What are the key components of an MDP and how does Q-learning update value estimates?

## Architecture Onboarding

- Component map: Devices -> Base Stations -> Central Cloud -> DRL Agent -> Devices
- Critical path: 1. DRL agent observes network state 2. Model selection decision sent to devices 3. Devices train selected models locally 4. Models uploaded to BSs 5. Attack detection at BSs 6. Partial aggregation and knowledge transfer at BSs 7. Global aggregation at cloud 8. Updated master model broadcast to devices
- Design tradeoffs:
  - Model diversity vs. accuracy: More diverse models increase robustness but may reduce overall accuracy
  - Communication overhead vs. security: Frequent model changes increase overhead but improve security
  - DRL complexity vs. performance: More sophisticated DRL improves selection but increases training time
  - Knowledge transfer effectiveness vs. computational cost: More transfer improves learning but increases processing time
- Failure signatures:
  - High attack success rate despite multi-model approach (model changes too predictable)
  - Degraded accuracy compared to single-model approaches (ineffective knowledge transfer)
  - Slow convergence or unstable learning (poor DRL policy or reward function)
  - High communication overhead (inefficient model selection or frequent changes)
- First 3 experiments:
  1. Baseline comparison: Run single-model FL vs. multi-model FL without attacks to establish accuracy and performance baseline
  2. Attack resilience test: Introduce model poisoning attacks to compare single-model vs. multi-model approaches under attack
  3. DRL performance evaluation: Compare DRL-based model selection against random selection across varying network conditions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is the multi-model approach against more sophisticated poisoning attacks that can adaptively craft models to evade detection?
- Basis in paper: [explicit] The paper mentions that advanced knowledge about dynamicity of models, models' structures is required for sophisticated crafting of client models, and this sort of attack has not been investigated yet
- Why unresolved: The paper only considers a basic poisoning attack and does not explore more complex attack strategies that could potentially bypass the multi-model defense
- What evidence would resolve it: Testing the multi-model approach against various advanced poisoning attacks with adaptive model crafting capabilities

### Open Question 2
- Question: How does the performance of the proposed approach scale with the number of devices and base stations in the network?
- Basis in paper: [inferred] The paper presents results for a scenario with 10 devices and 2 base stations, but does not discuss how the approach performs with larger network sizes
- Why unresolved: The scalability of the approach in terms of network size is not addressed, which is crucial for real-world deployments
- What evidence would resolve it: Evaluating the approach's performance in terms of accuracy, recognition time, and robustness as the number of devices and base stations increases

### Open Question 3
- Question: How does the proposed approach handle the case where the master model is not the most accurate model for the given task?
- Basis in paper: [explicit] The paper mentions that the master model can be included in the slave model set, since it can be the most efficient model in the context of recognition problem
- Why unresolved: The paper does not explore scenarios where the master model might not be the best choice for the task at hand, and how the approach adapts in such cases
- What evidence would resolve it: Comparing the performance of the approach when the master model is not the most accurate model, and investigating the impact on accuracy and robustness

## Limitations
- Missing implementation details: Critical specifications for DRL architecture, training parameters, and model configuration are absent
- Limited attack scope: Evaluation focuses on DDoS attack detection and specific poisoning attacks with unclear generalizability
- No comparison to existing defenses: Paper doesn't benchmark against established poisoning attack mitigation techniques

## Confidence

**Confidence Labels:**
- **High confidence:** The fundamental concept of using model diversity to increase attack resistance is well-founded and supported by security principles
- **Medium confidence:** Experimental results showing improved accuracy under attack conditions, though evaluation setup appears limited to specific scenarios
- **Low confidence:** Effectiveness of DRL-based model selection mechanism due to lack of detailed implementation specifications and comprehensive evaluation

## Next Checks

1. Replicate baseline performance: Implement single-model federated learning approach with same GRU architecture to establish accurate baseline accuracy and recognition time metrics for comparison

2. Stress test model diversity: Systematically vary degree of model diversity (number of slave models, structural differences) to quantify relationship between diversity and attack resistance

3. Evaluate DRL generalization: Test DRL model selection across different network conditions and attack patterns to assess adaptability and robustness beyond specific scenarios presented