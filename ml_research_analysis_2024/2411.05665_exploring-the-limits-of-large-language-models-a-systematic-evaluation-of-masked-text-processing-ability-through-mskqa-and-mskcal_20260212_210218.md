---
ver: rpa2
title: 'Exploring the Limits of Large Language Models: A Systematic Evaluation of
  Masked Text Processing Ability through MskQA and MskCal'
arxiv_id: '2411.05665'
source_url: https://arxiv.org/abs/2411.05665
tags:
- masking
- masked
- accuracy
- text
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper evaluates Large Language Models\u2019 (LLMs) ability\
  \ to process masked text through two novel tasks: MskQA for masked question-answering\
  \ and MskCal for masked arithmetic reasoning. Using GPT-4o and 4o-mini, the study\
  \ systematically tests how performance varies with different masking rates and semantic\
  \ information availability."
---

# Exploring the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal

## Quick Facts
- arXiv ID: 2411.05665
- Source URL: https://arxiv.org/abs/2411.05665
- Authors: Fuka Matsuzaki; Haru-Tada Sato
- Reference count: 19
- Primary result: LLM performance decreases as semantic information is reduced, with GPT-4o consistently outperforming 4o-mini, especially in numerical reasoning tasks.

## Executive Summary
This paper evaluates Large Language Models' (LLMs) ability to process masked text through two novel tasks: MskQA for masked question-answering and MskCal for masked arithmetic reasoning. Using GPT-4o and 4o-mini, the study systematically tests how performance varies with different masking rates and semantic information availability. Results show that LLM performance decreases as semantic information is reduced, with GPT-4o consistently outperforming 4o-mini, especially in numerical reasoning tasks. Both models maintain reasonable accuracy (80%+) with masking rates below 40%, but struggle with heavily masked computational tasks (MR≳60%). The study highlights the crucial role of semantic cues in LLM reasoning and demonstrates that while LLMs can handle various masked text levels, they struggle with heavily masked computational reasoning tasks.

## Method Summary
The study evaluates LLMs' masked text processing ability using two tasks: MskQA for masked question-answering and MskCal for masked arithmetic reasoning. Datasets are prepared by masking content words at varying rates (5% increments from 0-100%) using a lightweight LM like Gemma2, which generates structured meta-information codes (POS tags, semantic categories, abstract meanings). GPT-4o and GPT-4o-mini are tested on these masked datasets using accuracy metrics (Acc, NA, EA, KI) and compared across masking rates and techniques (strict, regular, partial, lenient). The MskQA task uses masked RealtimeQA dataset, while MskCal uses masked AQuA-RAT dataset and custom accounting calculation problems.

## Key Results
- LLM performance decreases as masking rates increase, with accuracy dropping below 80% when MR exceeds 40%
- GPT-4o consistently outperforms GPT-4o-mini in masked numerical reasoning tasks, maintaining reasonable accuracy up to 60% masking
- Background knowledge dependence varies across datasets, quantified through KI metric comparing masked performance against UQA baseline
- Both models struggle with heavily masked computational tasks (MR≳60%), showing significant accuracy drops and order-of-magnitude errors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masking reduces semantic information availability, which directly impacts LLM reasoning performance.
- Mechanism: The study systematically replaces content words with meta-information codes (POS tags, categories, meanings) to create masked text. As masking rate increases, semantic cues decrease, forcing models to rely more on abstract inference and memorized patterns.
- Core assumption: LLMs use semantic associations and contextual understanding to process masked text, not just surface-level patterns.
- Evidence anchors:
  - [abstract] "LLM performance depends significantly on masking rates and semantic information availability"
  - [section 2.1] "The dataset preparation follows the method outlined by [6]. If test data for downstream tasks is included in the training set, models may simply memorize the original content"

### Mechanism 2
- Claim: GPT-4o demonstrates superior ability to handle numerical reasoning under masked conditions compared to GPT-4o-mini.
- Mechanism: Through MskCal tasks, the study shows that GPT-4o maintains reasonable accuracy with masking rates below 60%, while GPT-4o-mini shows accuracy drops at 40% masking rate. This suggests GPT-4o has better numerical reasoning capabilities when semantic information is reduced.
- Core assumption: Larger models have more robust reasoning capabilities that persist even when masked text reduces semantic cues.
- Evidence anchors:
  - [abstract] "GPT-4o consistently outperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to handle numerical reasoning with masked text"
  - [section 4.4] "The right side of Figure 6 shows the MR response of Pσ. The green line represents Pσ for GPT-4o-mini with random masking... while other lines show results for GPT-4o-mini and GPT-4o with restricted masking"

### Mechanism 3
- Claim: Background knowledge dependence can be quantified by comparing masked performance against UQA baseline.
- Mechanism: The study introduces KI (Knowledge Independence) metric that measures performance relative to UQA dataset, which assumes background knowledge is already available. This allows quantifying how much models rely on external knowledge vs. inference from masked text.
- Core assumption: Different datasets will show varying degrees of background knowledge dependence, which can be measured through comparative accuracy metrics.
- Evidence anchors:
  - [section 2.3] "To quantify background knowledge dependence, one approach evaluates the ratio relative to N A(U, r); a smaller ratio indicates lower dependence"
  - [section 4.5] "By considering both source characteristics and accuracy metrics, we analyze LLM performance in the decoding task"

## Foundational Learning

- Concept: Masking rate (MR) as ratio of masked words to total maskable words
  - Why needed here: Understanding how masking rate quantification affects performance measurement and interpretation of results
  - Quick check question: If a text has 100 maskable words and 25 are masked, what is the masking rate?
  - Answer: 25%

- Concept: Normalized accuracy rate (N A(D, r)) for removing question difficulty dependency
  - Why needed here: Ensures fair comparison across different datasets by normalizing performance relative to unmasked accuracy
  - Quick check question: How does N A(D, r) differ from raw accuracy Acc(D r)?
  - Answer: N A normalizes by dividing by Acc(D0), removing difficulty bias

- Concept: Knowledge Independence (KI) metric for quantifying background knowledge dependence
  - Why needed here: Provides quantitative measure of how much models rely on external knowledge vs. inference from masked text
  - Quick check question: What does a high KI value indicate about model behavior?
  - Answer: High knowledge independence, lower reliance on external knowledge

## Architecture Onboarding

- Component map: Data preparation -> Masking engine -> Evaluation framework -> Metrics system -> Model testing
- Critical path: Masking → Model inference → Accuracy measurement → Metric calculation → Analysis
- Design tradeoffs: Balancing masking rate for meaningful evaluation vs. maintaining sufficient semantic information for inference
- Failure signatures: Accuracy drops below 20% (random chance for multiple-choice), order-of-magnitude errors in numerical calculations
- First 3 experiments:
  1. Run MskQA with 20% masking rate on RQA dataset using GPT-4o-mini to establish baseline performance
  2. Test MskCal with 40% masking rate comparing GPT-4o vs GPT-4o-mini to observe numerical reasoning differences
  3. Evaluate knowledge independence by running both UQA and RQA at 60% masking rate to measure KI metric

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do LLMs like GPT-4 maintain high performance on masked arithmetic tasks even when no semantic information is provided (MR=100%)?
- Basis in paper: [explicit] The study found that accuracy curves for masked arithmetic tasks exceeded 20% (theoretical random chance) even with complete masking
- Why unresolved: The paper suggests this indicates "systematic reasoning persists" but doesn't explain the mechanism behind this unexpected performance
- What evidence would resolve it: Detailed analysis of error patterns and reasoning traces at different masking levels would reveal whether LLMs use pattern matching, implicit symbolic processing, or other strategies

### Open Question 2
- Question: What is the optimal balance between semantic information density and abstraction level in mask codes for maximizing LLM performance?
- Basis in paper: [inferred] The study compared strict, regular, partial, and lenient masking methods but didn't systematically vary the semantic information density within these categories
- Why unresolved: Different masking strategies showed varying performance, but the relationship between semantic information granularity and model accuracy wasn't fully explored
- What evidence would resolve it: Controlled experiments varying semantic abstraction levels while keeping masking rates constant would identify the most effective information density

### Open Question 3
- Question: How do LLMs handle masked text differently from human readers, and what cognitive mechanisms explain this difference?
- Basis in paper: [explicit] The study notes that while humans have typoglycemia recognition capacity, the underlying mechanisms of LLM text processing remain unexplained
- Why unresolved: The paper identifies performance differences but doesn't provide a theoretical framework for understanding the cognitive vs. statistical processing differences
- What evidence would resolve it: Comparative studies measuring human and LLM performance on identical masked text tasks with detailed error analysis would reveal fundamental processing differences

## Limitations
- Reliance on single masking strategy and two model variants constrains generalizability across different masking approaches and model architectures
- Evaluation focuses on specific datasets (RealtimeQA and AQuA-RAT) that may not represent full diversity of masked text processing scenarios
- Masking implementation depends on Gemma2, introducing potential variability in how different LMs handle morpheme identification and content word selection

## Confidence

*High Confidence Claims:*
- LLMs show decreased performance as masking rates increase (supported by systematic testing across multiple rates with consistent patterns)
- GPT-4o outperforms GPT-4o-mini in masked numerical reasoning tasks (demonstrated through controlled comparisons with statistical significance)

*Medium Confidence Claims:*
- Semantic information availability is crucial for LLM reasoning under masked conditions (inferred from performance patterns but not directly tested with semantic ablation)
- Background knowledge dependence varies significantly across datasets (based on KI metric calculations but limited to specific dataset comparisons)

*Low Confidence Claims:*
- The specific masking mechanisms (POS tags, categories, meanings) are optimal for evaluating masked text processing (no comparative analysis with alternative masking strategies)
- The observed performance patterns would generalize to other model families beyond GPT variants (extrapolation beyond tested model range)

## Next Checks
1. **Cross-Architecture Validation**: Test the same masking framework with open-weight models (Llama3.2, Mistral) to verify whether observed performance patterns are model-family dependent or represent general LLM behavior under masked conditions.

2. **Semantic Ablation Study**: Systematically remove semantic information while preserving syntactic structure (and vice versa) to isolate the relative contribution of semantic vs. syntactic cues to masked text processing performance.

3. **Longitudinal Masking Analysis**: Evaluate model performance across multiple epochs of masked text exposure to determine whether LLMs develop adaptive strategies for processing masked content or if performance remains consistently tied to semantic information availability.