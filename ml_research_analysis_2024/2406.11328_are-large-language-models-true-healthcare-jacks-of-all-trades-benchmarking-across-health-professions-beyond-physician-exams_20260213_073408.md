---
ver: rpa2
title: Are Large Language Models True Healthcare Jacks-of-All-Trades? Benchmarking
  Across Health Professions Beyond Physician Exams
arxiv_id: '2406.11328'
source_url: https://arxiv.org/abs/2406.11328
tags:
- medical
- empec
- chinese
- questions
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EMPEC, a large-scale healthcare knowledge
  benchmark in traditional Chinese, to address the underrepresentation of healthcare
  professions beyond physicians in existing LLM evaluations. EMPEC consists of 157,803
  multiple-choice questions across 124 subjects and 20 healthcare professions, including
  underrepresented occupations like optometrists and audiologists.
---

# Are Large Language Models True Healthcare Jacks-of-All-Trades? Benchmarking Across Health Professions Beyond Physician Exams

## Quick Facts
- arXiv ID: 2406.11328
- Source URL: https://arxiv.org/abs/2406.11328
- Reference count: 40
- Large language models struggle with specialized healthcare fields and alternative medicine, with general-purpose models outperforming medical-specific ones

## Executive Summary
This paper introduces EMPEC, a comprehensive Chinese healthcare knowledge benchmark spanning 20 professions beyond physicians. The dataset addresses a critical gap in LLM evaluation by covering underrepresented healthcare occupations like optometrists and audiologists with 157,803 verified multiple-choice questions. Experiments on 17 LLMs reveal that while top models like GPT-4 achieve over 75% accuracy, they struggle with specialized fields and alternative medicine. Notably, general-purpose LLMs consistently outperform medical-specific models, suggesting that domain fine-tuning may compromise general instruction-following capabilities.

## Method Summary
The study evaluates 17 LLMs on EMPEC using zero-shot inference with prompt-based generation and greedy decoding. The benchmark consists of 157,803 multiple-choice questions across 124 subjects and 20 healthcare professions, with 8,000 questions held out for testing. One open-source model (Qwen1.5-7B) was fine-tuned on EMPEC training data for 3 epochs with learning rate 1e-4. The evaluation includes performance analysis across professions, character variant testing (traditional vs simplified Chinese), and validation using questions from 2024 to assess data contamination risks.

## Key Results
- General-purpose LLMs (GPT-4, GPT-3.5) achieved over 75% accuracy on EMPEC, outperforming medical-specific models
- Medical domain LLMs unexpectedly underperformed general models, suggesting fine-tuning compromises instruction-following ability
- Models showed robust performance across traditional and simplified Chinese variants with negligible performance differences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific medical LLMs underperform general LLMs due to loss of instruction-following ability during fine-tuning.
- Mechanism: Medical LLMs overfit to task-specific formats during fine-tuning, losing general instruction-following capability.
- Core assumption: Fine-tuning process prioritizes domain knowledge at expense of general task understanding.
- Evidence anchors: [abstract] "LLMs specifically tuned for the medical domain unexpectedly show inferior performance"; [section] "HuatuoGPT2...sometimes deviates from the questions and often fail to conclude an answer."
- Break condition: If medical LLMs maintain both domain expertise and instruction-following ability, this mechanism fails.

### Mechanism 2
- Claim: EMPEC test set performance predicts effectiveness on unseen healthcare queries.
- Mechanism: Consistent performance across training cutoff questions and full test set indicates representativeness.
- Core assumption: Test set captures true distribution of healthcare knowledge.
- Evidence anchors: [abstract] "performance on questions released after the models' training cutoff date were consistent with overall performance trends"; [section] "The findings strongly suggest the robustness of the EMPEC test set."
- Break condition: If future unseen questions show different performance patterns, this mechanism fails.

### Mechanism 3
- Claim: Transition from traditional to simplified Chinese has negligible impact on performance.
- Mechanism: Models develop robust linguistic representations that generalize across character variants.
- Core assumption: Co-occurrence relations are similar enough in traditional and simplified Chinese.
- Evidence anchors: [abstract] "transition from traditional to simplified Chinese characters had a negligible impact on model performance"; [section] "We assume that the character difference...does not affect the model's performance."
- Break condition: If significant performance degradation occurs with character variant switching, this mechanism fails.

## Foundational Learning

- Concept: Healthcare knowledge distribution across professions
  - Why needed here: Understanding breadth of healthcare knowledge is crucial for evaluating LLM capabilities across medical roles.
  - Quick check question: How many healthcare professions are represented in EMPEC compared to traditional medical benchmarks?

- Concept: Benchmark data contamination
  - Why needed here: Ensuring test data is truly unseen is critical for valid model evaluation.
  - Quick check question: How does EMPEC mitigate the risk of data contamination in its evaluation process?

- Concept: Domain adaptation tradeoffs
  - Why needed here: Understanding why domain-specific models may underperform general models is key to improving medical LLM development.
  - Quick check question: What is the primary reason medical domain LLMs underperform their general counterparts according to the paper?

## Architecture Onboarding

- Component map: EMPEC dataset → Model evaluation pipeline → Performance analysis across professions → Cross-character variant testing
- Critical path: Dataset collection → Preprocessing and deduplication → Train/validation/test split → Model evaluation → Performance analysis
- Design tradeoffs: Comprehensive profession coverage vs. depth of questions per profession; Traditional vs. simplified Chinese support; Proprietary vs. open-source model evaluation
- Failure signatures: Inconsistent performance across character variants; Poor performance on specific professions; Failure to maintain instruction-following ability
- First 3 experiments:
  1. Evaluate model performance on questions from exams held in 2024 to test for data contamination
  2. Compare performance on traditional vs. simplified Chinese versions of the same questions
  3. Analyze performance breakdown by profession to identify knowledge gaps in LLMs

## Open Questions the Paper Calls Out

## Limitations
- Potential data contamination from publicly available medical exam questions online
- Simplified-to-traditional Chinese conversion assumes linguistic similarity that may not hold for all character pairs
- Multiple-choice format limits assessment of open-ended medical reasoning and clinical scenario handling

## Confidence
- High Confidence: EMPEC's comprehensive coverage of healthcare professions beyond physicians; general-purpose LLMs outperforming medical-specific models
- Medium Confidence: Test set's predictive validity for unseen queries; negligible impact of character variant transitions
- Low Confidence: Mechanism explaining medical LLMs' underperformance; minimal data contamination claim

## Next Checks
1. **Character Variant Robustness Test**: Systematically evaluate same medical concepts in both traditional and simplified Chinese to quantify performance degradation and identify problematic character pairs.

2. **Cross-Profession Knowledge Transfer**: Design experiment where models trained on one healthcare profession are tested on questions from other professions to measure knowledge transfer and identify profession-specific gaps.

3. **Open-Ended Question Extension**: Convert subset of multiple-choice questions to open-ended format to assess whether current multiple-choice structure overestimates LLM capabilities in real-world medical applications.