---
ver: rpa2
title: 'Humanity in AI: Detecting the Personality of Large Language Models'
arxiv_id: '2410.08545'
source_url: https://arxiv.org/abs/2410.08545
tags:
- personality
- text
- llms
- score
- traits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the presence of personality traits in Large
  Language Models (LLMs) by combining questionnaire and text mining methods. The questionnaire
  method addresses hallucination issues by using psychological features to predict
  personality, while text mining extracts personality traits from LLM-generated text.
---

# Humanity in AI: Detecting the Personality of Large Language Models

## Quick Facts
- arXiv ID: 2410.08545
- Source URL: https://arxiv.org/abs/2410.08545
- Authors: Baohua Zhan; Yongyi Huang; Wenyao Cui; Huaping Zhang; Jianyun Shang
- Reference count: 31
- Primary result: LLMs exhibit personality traits, with ChatGPT and ChatGLM most similar to humans (score differences of 0.34 and 0.22 respectively)

## Executive Summary
This paper investigates the presence of personality traits in Large Language Models by combining questionnaire and text mining methods. The study addresses hallucination issues in LLMs by using psychological features to predict personality through questionnaires while extracting traits from generated text. By comparing pre-trained models (BERT, GPT) with conversational models (ChatGPT), the research finds that LLMs do exhibit specific personality traits, particularly "Conscientiousness." The results demonstrate that personality traits in LLMs originate from their pre-trained data, with instruction data fine-tuning enhancing the expression of these traits.

## Method Summary
The study employs a dual-method approach combining psychological questionnaires with text mining analysis. The questionnaire method uses the MPI120 personality assessment with 120 statements to directly ask LLMs about their personality traits. The text mining method generates text from first-sentence prompts and analyzes it using the PsyAtten classifier to extract personality traits without relying on specific responses. The researchers normalize scores from both methods using root mean square error calculations to reduce hallucination effects and combine results. The analysis compares pre-trained models (PLMs) like BERT and GPT with conversational models (ChatLLMs) like ChatGPT and ChatGLM across the Big Five personality dimensions.

## Key Results
- LLMs exhibit specific personality traits, with "Conscientiousness" being particularly prominent
- ChatLLMs show higher personality trait scores than PLMs, indicating instruction fine-tuning enhances trait expression
- ChatGPT and ChatGLM demonstrate personality traits most similar to humans with score differences of 0.34 and 0.22 respectively
- Personality traits in LLMs originate from their pre-trained data rather than being artificially induced

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining questionnaire and text mining methods reduces the impact of LLM hallucinations on personality detection.
- Mechanism: The questionnaire method directly asks LLMs questions, which can be affected by hallucinations producing inaccurate or irrelevant responses. The text mining method extracts personality traits from LLM-generated text without relying on specific answers, thus avoiding the influence of hallucinations. By normalizing scores from both methods and calculating the root mean square error, the effectiveness of this combined approach is confirmed.
- Core assumption: Text mining can reliably extract personality traits from LLM-generated text without being influenced by hallucinations, and the combined method provides a more objective assessment than either method alone.
- Evidence anchors:
  - [abstract]: "Text mining can extract psychological features from the LLMs' responses without being affected by the order of options. Furthermore, because this method does not rely on specific answers, it reduces the influence of hallucinations."
  - [section]: "To solve this problem, we combine questionnaire and text mining methods guided by Big Five psychological model... Text mining can extract psychological features from the LLMs' responses without being affected by the order of options. Furthermore, because this method does not rely on specific answers, it reduces the influence of hallucinations."
- Break condition: If the text mining method cannot reliably extract personality traits without being influenced by hallucinations, or if the normalization and RMSE calculation do not effectively combine the two methods, the combined approach may not be more effective.

### Mechanism 2
- Claim: Personality traits in LLMs originate from their pre-trained data, and instruction data fine-tuning enhances the expression of these traits.
- Mechanism: The study compares pre-trained models (PLMs) like BERT and GPT with conversational models (ChatLLMs) like ChatGPT. The results show that LLMs exhibit specific personality traits, and the personalities of LLMs are derived from their pre-trained data. The instruction data used to train ChatLLMs can enhance the generation of data containing personalities and expose their hidden personality.
- Core assumption: The pre-trained data contains personality traits that are transferred to the LLMs, and instruction data fine-tuning can amplify the expression of these traits.
- Evidence anchors:
  - [abstract]: "The results show that LLMs do contain certain personalities... Additionally, we find that the personalities of LLMs are derived from their pre-trained data. The instruction data used to train ChatLLMs can enhance the generation of data containing personalities and expose their hidden personality."
  - [section]: "Comparing the results of PLMs and ChatLLMs, we can find that all the scores of PLMs are lower than the corresponding ChatLLMs... The ChatLLMs do not change the personality traits that the PLMs already exhibited, they only extend the traits."
- Break condition: If the pre-trained data does not contain personality traits, or if instruction data fine-tuning does not enhance the expression of these traits, the claimed mechanism would not hold.

### Mechanism 3
- Claim: Using psychological features in text mining avoids the influence of response content caused by hallucinations.
- Mechanism: The study employs a classifier with psychological features, which can obtain results without analysis of text content, avoiding the influence of hallucinations. This is in contrast to other methods that may be affected by the response content.
- Core assumption: Psychological features can be extracted from text without relying on the specific content, and this approach is effective in avoiding the influence of hallucinations.
- Evidence anchors:
  - [abstract]: "Text mining can extract psychological features from the LLMs' responses without being affected by the order of options. Furthermore, because this method does not rely on specific answers, it reduces the influence of hallucinations."
  - [section]: "In the text mining method, we provide LLMs with the first sentence of a paragraph and allow it to continue writing. We then use a classifier to determine the personality traits contained in the model's generated text. Since LLMs suffer from hallucinations, we want to use a classifier that can detect personality traits without relying on the analysis of text content."
- Break condition: If psychological features cannot be reliably extracted without relying on specific content, or if the classifier is not effective in avoiding the influence of hallucinations, this mechanism would not be valid.

## Foundational Learning

- Concept: Big Five personality model
  - Why needed here: The study uses the Big Five model as a psychological framework to analyze the personality of LLMs.
  - Quick check question: What are the five personality traits in the Big Five model?
- Concept: Text mining
  - Why needed here: The study employs text mining to extract personality traits from LLM-generated text.
  - Quick check question: What is text mining and how can it be used to extract personality traits from text?
- Concept: Hallucinations in LLMs
  - Why needed here: The study aims to avoid the influence of hallucinations on personality detection.
  - Quick check question: What are hallucinations in LLMs and how can they affect the reliability of personality detection methods?

## Architecture Onboarding

- Component map:
  Questionnaire method (MPI120 questions) -> LLM responses -> Personality scoring
  Text mining method (first sentence prompts) -> LLM text generation -> PsyAtten classifier -> Personality scoring
  Normalization and RMSE calculation -> Combined personality assessment

- Critical path:
  1. Prepare the questionnaire and text mining datasets.
  2. Run the questionnaire method on the LLMs.
  3. Run the text mining method on the LLMs.
  4. Normalize the scores and calculate the RMSE.
  5. Analyze the results and compare the performance of different LLMs.

- Design tradeoffs:
  - Questionnaire method vs. text mining method: The questionnaire method directly asks LLMs questions but can be affected by hallucinations. The text mining method avoids the influence of hallucinations but may be less reliable in extracting personality traits.
  - Choice of classifier: PsyAtten is chosen for its ability to extract psychological features without relying on specific content, but other classifiers may also be suitable.

- Failure signatures:
  - Low consistency between the questionnaire and text mining methods.
  - High RMSE values indicating a large difference between the two methods.
  - Poor performance of the classifier in extracting personality traits from LLM-generated text.

- First 3 experiments:
  1. Run the questionnaire method on a small set of LLMs using a subset of the MPI120 questions.
  2. Run the text mining method on the same set of LLMs using a small dataset of human diaries with personality labels.
  3. Compare the results of the two methods and analyze the consistency and RMSE values.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different pre-training data distributions specifically influence the emergence of particular personality traits in LLMs?
- Basis in paper: [explicit] The paper states that personality traits in LLMs originate from their pre-trained data and that ChatLLMs' instruction data fine-tuning enhances the expression of these traits.
- Why unresolved: While the paper shows that pre-training data influences personality, it does not investigate which specific data sources or types of content are most strongly associated with particular personality traits.
- What evidence would resolve it: Systematic experiments varying the pre-training corpus (e.g., news articles vs. social media vs. academic papers) while controlling for model architecture, then measuring personality trait emergence in the resulting models.

### Open Question 2
- Question: Can we predict or control which personality traits will emerge in LLMs based on their training data characteristics?
- Basis in paper: [inferred] The paper demonstrates that instruction data fine-tuning exposes hidden personality traits without diminishing existing ones, suggesting some predictability in trait emergence.
- Why unresolved: The paper shows correlation between training data and personality but does not establish predictive models or causal mechanisms linking specific data features to specific personality traits.
- What evidence would resolve it: Development of a model that maps training data metadata (domain, sentiment, linguistic complexity, etc.) to predicted personality trait profiles, validated across multiple LLM architectures.

### Open Question 3
- Question: How stable are LLM personality traits across different prompt formulations and contexts?
- Basis in paper: [explicit] The paper addresses hallucination issues and prompt sensitivity in questionnaire methods, but does not extensively explore personality consistency across varied contexts.
- Why unresolved: While the paper compares questionnaire and text mining methods, it does not systematically test whether personality trait assessments remain consistent when LLMs are prompted in different ways or placed in different conversational contexts.
- What evidence would resolve it: Longitudinal studies measuring the same LLM's personality across multiple contexts, prompt styles, and tasks, determining whether certain traits remain stable while others vary with context.

## Limitations

- The study relies on indirect methods to detect personality traits, with inherent uncertainties in both questionnaire and text mining approaches
- No analysis of temporal variability in LLM personality expressions across different sessions or contexts
- Focus on comparing models to human averages rather than examining within-model consistency or cross-cultural variations

## Confidence

**High Confidence:** The finding that ChatLLMs exhibit higher Big Five scores than PLMs is well-supported by the consistent pattern across multiple models and statistical measures.

**Medium Confidence:** The assertion that personality traits originate from pre-trained data is supported by observed patterns but requires additional validation to establish causation rather than correlation.

**Low Confidence:** The combined questionnaire-text mining method's superiority in handling hallucinations is demonstrated through RMSE calculations, but the absolute magnitude of improvement and its practical significance remain unclear.

## Next Checks

1. **Temporal Consistency Test:** Run the same personality assessment protocol on the same LLM models across multiple time points (minimum 3 sessions) to measure response stability and variance.

2. **Cross-Cultural Validation:** Repeat the analysis using personality questionnaires validated for different cultural contexts to determine if detected personality traits generalize across cultural frameworks.

3. **Alternative Classifier Comparison:** Implement and compare results using at least two additional personality classifiers (beyond PsyAtten) on the same text mining dataset to verify that detected traits are not classifier-specific artifacts.