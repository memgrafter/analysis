---
ver: rpa2
title: Adaptive Random Fourier Features Training Stabilized By Resampling With Applications
  in Image Regression
arxiv_id: '2410.06399'
source_url: https://arxiv.org/abs/2410.06399
tags:
- algorithm
- training
- layer
- resampling
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an enhanced adaptive random Fourier features
  (ARFF) training algorithm that incorporates particle filter-type resampling to improve
  stability and reduce sensitivity to hyperparameters. The core innovation is monitoring
  the effective sample size (ESS) of amplitudes and resampling frequencies when ESS
  falls below a threshold, eliminating the need for Metropolis acceptance tests in
  many cases.
---

# Adaptive Random Fourier Features Training Stabilized By Resampling With Applications in Image Regression

## Quick Facts
- arXiv ID: 2410.06399
- Source URL: https://arxiv.org/abs/2410.06399
- Authors: Aku Kammonen; Anamika Pandey; Erik von Schwerin; Raúl Tempone
- Reference count: 30
- Primary result: Enhanced ARFF algorithm with resampling reduces sensitivity to hyperparameters and improves stability in function and image regression tasks

## Executive Summary
This paper introduces a stabilized adaptive random Fourier features (ARFF) training algorithm that incorporates particle filter-type resampling based on effective sample size (ESS) monitoring. The key innovation removes the need for Metropolis acceptance tests in many cases while improving stability and reducing sensitivity to hyperparameters. The algorithm is demonstrated on function regression tasks and applied to image regression by automatically sampling frequencies for coordinate-based MLPs, achieving higher PSNR values compared to manual tuning approaches.

## Method Summary
The method enhances ARFF training by monitoring the effective sample size (ESS) of amplitude distributions and resampling frequencies when ESS falls below a threshold R. This particle filter approach prevents weight degeneracy while maintaining diversity in the frequency distribution. The algorithm can operate with or without the Metropolis acceptance test, reducing computational cost per iteration when resampling is used frequently. For image regression, the method pretrains the RFF layer of coordinate-based MLPs, automatically sampling frequencies instead of manual tuning, followed by standard gradient-based optimization.

## Key Results
- Resampling significantly improves training stability and reduces sensitivity to batch size, initial frequency distribution, and γ values in function regression
- The algorithm achieves faster initial error reduction compared to standard ARFF, making it effective as pretraining before Adam optimization
- For image regression on DIV2K dataset, the approach achieves higher PSNR values compared to Xavier initialization or ReLU-only architectures
- Removing the Metropolis test when using resampling reduces computational cost per iteration while maintaining convergence properties

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Resampling based on ESS prevents weight degeneracy in the amplitude distribution, maintaining diverse active frequencies during training.
- Mechanism: When ESS falls below threshold R, frequencies are resampled according to the normalized amplitude distribution |a| / ||a||₁, which approximates the optimal frequency density p*(ω) for minimizing approximation error.
- Core assumption: The normalized amplitude distribution |a| / ||a||₁ provides a reasonable approximation of the optimal frequency sampling density p*(ω).
- Evidence anchors:
  - [abstract]: "monitoring the effective sample size (ESS) of amplitudes and resampling frequencies when ESS falls below a threshold"
  - [section]: "We introduce a threshold, R ∈ [0, 1], monitored KESS, and resampled the frequencies {ωk}K k=1 according to the probability mass function ˇp when KESS ≤ RK"
  - [corpus]: "Found 25 related papers (using 8)" - weak connection to resampling mechanism specifically

### Mechanism 2
- Claim: Removing the Metropolis acceptance test when resampling is used reduces computational cost per iteration while maintaining convergence properties.
- Mechanism: With resampling in every iteration (R ≡ 1), the algorithm can use a simple random walk step without the Metropolis test, reducing the number of least-squares solutions from two to one per iteration.
- Core assumption: Frequent resampling with a sufficiently large number of nodes K makes the Metropolis test unnecessary for convergence.
- Evidence anchors:
  - [abstract]: "The Metropolis test can also be omitted when resampling is used, reducing the number of hyperparameters by one and reducing the computational cost per iteration compared to the ARFF method"
  - [section]: "the proposed algorithm can be run without the Metropolis step used in ARFF, reducing the number of hyperparameters by one"
  - [corpus]: "Comparing Spectral Bias and Robustness For Two-Layer Neural Networks: SGD vs Adaptive Random Fourier Features" - related work but not directly addressing Metropolis removal

### Mechanism 3
- Claim: The algorithm provides faster initial error reduction, making it effective as a pretraining step before gradient-based optimization.
- Mechanism: Resampling rapidly concentrates the frequency distribution on more important frequencies, reducing approximation error faster in early iterations compared to methods without resampling.
- Core assumption: Faster initial error reduction during pretraining translates to better final performance after gradient-based fine-tuning.
- Evidence anchors:
  - [abstract]: "The proposed algorithm can be run without the Metropolis step used in ARFF, reducing the number of hyperparameters by one and reducing the computational cost per iteration compared to the ARFF method"
  - [section]: "Test 6 concerns (7), but this time with the trivial rotation matrix...We used learning rate 0.0005, batch size 128, and 400 epochs when training with Adam alone and also when training with Adam after pre-training with Algorithm 1"
  - [corpus]: "Found 25 related papers (using 8)" - no direct evidence about pretraining effectiveness

## Foundational Learning

- Concept: Effective Sample Size (ESS) in particle filtering
  - Why needed here: ESS measures the diversity of the amplitude distribution and triggers resampling when it drops below threshold, preventing weight degeneracy
  - Quick check question: What happens to ESS when one amplitude dominates all others?

- Concept: Random Fourier Features (RFF) for kernel approximation
  - Why needed here: The algorithm samples frequencies for RFF layers in neural networks, automating what would otherwise require manual tuning
  - Quick check question: How does the frequency sampling distribution affect the approximation quality of kernel methods?

- Concept: Metropolis-Hastings sampling
  - Why needed here: The original ARFF algorithm uses a Metropolis-like test for frequency updates; understanding this helps explain why it can be removed with resampling
  - Quick check question: What is the acceptance probability in the Metropolis test for frequency updates in ARFF?

## Architecture Onboarding

- Component map: Frequency sampling -> Least-squares solver -> ESS calculation -> Conditional resampling -> Repeat
- Critical path: Frequency sampling → Least-squares solve → ESS calculation → Conditional resampling → Repeat
- Design tradeoffs:
  - Resampling frequency vs. computational cost (more resampling = higher cost but better stability)
  - Batch size MB vs. memory/computation constraints (larger batches = better estimates but more expensive)
  - δ (proposal step size) vs. exploration/exploitation balance (larger δ = more exploration but potential instability)
- Failure signatures:
  - Training/test error increasing during iterations (likely insufficient resampling or poor δ choice)
  - ESS consistently low even after resampling (possible poor initialization or need for more nodes K)
  - Slow convergence despite low error (possible Metropolis test interfering with resampling)
- First 3 experiments:
  1. Compare AM, AMR, and RWR on the 4D discontinuity function with varying K values to observe ESS behavior and error convergence
  2. Test sensitivity to γ parameter by running AMR with γ = 1 vs γ = 10 on the same function
  3. Apply Algorithm 1 as pretrainer for Adam on the cosine activation function version, comparing to Adam alone

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the convergence rate of the proposed RFF algorithm with resampling compare to the theoretical error bounds established for ARFF in the literature?
- Basis in paper: [explicit] The paper mentions that the λ → 0 limit of the error bound (4) is almost attained after training with AM and AMR in Test 2, but does not provide a rigorous convergence analysis for the proposed algorithm with resampling.
- Why unresolved: The paper presents experimental evidence of convergence but does not provide theoretical convergence guarantees for the resampling-based approach.
- What evidence would resolve it: A formal proof of convergence rates for the RFF algorithm with resampling, showing how it compares to the error bounds established for ARFF in previous work.

### Open Question 2
- Question: How does the choice of resampling threshold R affect the trade-off between computational efficiency and approximation accuracy in different problem settings?
- Basis in paper: [explicit] The paper tests different values of R (e.g., R ≡ 0.75, R ≡ 1) but notes that the choice was not tuned for optimal results and that RWR with R ≡ 1 behaves similarly to AMR but at higher computational cost.
- Why unresolved: The paper demonstrates that resampling affects stability and sensitivity but does not systematically explore how different R values impact the balance between speed and accuracy.
- What evidence would resolve it: A systematic study varying R across different problem types, showing how it affects both convergence speed and final approximation quality, with recommendations for optimal R selection based on problem characteristics.

### Open Question 3
- Question: How does the proposed resampling approach generalize to deeper neural network architectures beyond the two-layer networks studied in this paper?
- Basis in paper: [inferred] The paper focuses exclusively on two-layer networks and mentions that the ARFF approach has been used for pretraining deep residual networks in previous work, but does not explore how resampling would apply to deeper architectures.
- Why unresolved: The resampling technique is developed and tested only for two-layer networks, and it's unclear how it would translate to architectures with multiple hidden layers or different connectivity patterns.
- What evidence would resolve it: Experiments applying the resampling approach to deeper architectures (e.g., deep MLPs, residual networks) and theoretical analysis of how resampling affects the training dynamics in these more complex settings.

## Limitations
- The paper lacks theoretical convergence guarantees for the resampling-based approach compared to established ARFF error bounds
- The choice of resampling threshold R is not systematically optimized across different problem types
- The algorithm is only tested on two-layer networks, with unclear generalization to deeper architectures

## Confidence

- **High confidence**: The empirical improvements in function regression stability and image regression PSNR are well-supported by the experimental results.
- **Medium confidence**: The computational efficiency claims and the theoretical justification for removing the Metropolis test.
- **Low confidence**: The universal applicability of the algorithm across different activation functions and problem domains.

## Next Checks

1. **Theoretical validation**: Prove or disprove that the amplitude-based resampling distribution converges to the optimal frequency density under standard assumptions.
2. **Hyperparameter sensitivity analysis**: Systematically test the algorithm's performance across a wider range of batch sizes, node counts K, and resampling thresholds R to quantify stability improvements.
3. **Cross-domain generalization**: Apply the algorithm to non-image regression tasks (e.g., time series forecasting) to test whether the observed benefits extend beyond the demonstrated applications.