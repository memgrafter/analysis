---
ver: rpa2
title: 'If You Can''t Use Them, Recycle Them: Optimizing Merging at Scale Mitigates
  Performance Tradeoffs'
arxiv_id: '2412.04144'
source_url: https://arxiv.org/abs/2412.04144
tags:
- merging
- tasks
- tradeoffs
- performance
- checkpoints
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores model merging for large language models (~100B
  parameters) to reduce task tradeoffs. The authors propose using evolutionary optimization
  to find optimal linear merging weights for suboptimal checkpoints obtained during
  LLM training.
---

# If You Can't Use Them, Recycle Them: Optimizing Merging at Scale Mitigates Performance Tradeoffs

## Quick Facts
- arXiv ID: 2412.04144
- Source URL: https://arxiv.org/abs/2412.04144
- Authors: Muhammad Khalifa; Yi-Chern Tan; Arash Ahmadian; Tom Hosking; Honglak Lee; Lu Wang; Ahmet Üstün; Tom Sherborne; Matthias Gallé
- Reference count: 40
- The paper shows evolutionary optimization of linear merging weights can outperform uniform averaging and merge-best baselines on large language models while recycling suboptimal checkpoints.

## Executive Summary
This paper addresses the challenge of model degradation when training large language models on multiple tasks, proposing an optimization approach that recycles suboptimal checkpoints through linear merging. The authors demonstrate that evolutionary optimization (CMA-ES) can find optimal linear merging weights that minimize task tradeoffs without hurting performance on held-out tasks. Their approach successfully transforms seemingly poor checkpoints into Pareto-optimal models, showing that even checkpoints with poor individual performance can contribute positively to the final merge.

## Method Summary
The method uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to optimize linear merging weights for 16 Command R+ checkpoints from different training stages. The fitness function is the macro-average performance across held-in tasks, and the optimizer iteratively samples candidate weight vectors, evaluates their fitness, and adapts the search distribution. The approach is compared against baselines including best single model, uniform averaging, and merge-best strategies. The evaluation includes both held-in tasks (MBPP, GSM8K, IFEval, MMLUPro, MUSR) and held-out tasks (MT-Bench, LBPP) to test generalization.

## Key Results
- Optimized merges outperform both individual models and merge-based baselines on held-in tasks
- Good merges tend to include almost all checkpoints with non-zero weights, indicating poor checkpoints can contribute positively
- The approach successfully creates Pareto-optimal models without requiring additional training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Evolutionary optimization can find linear merging weights that minimize task tradeoffs without hurting performance on held-out tasks.
- Mechanism: CMA-ES iteratively samples candidate weight vectors, evaluates their fitness on held-in tasks, and adapts the search distribution to assign higher probability to promising solutions.
- Core assumption: The fitness function (average performance across held-in tasks) effectively captures tradeoffs and is smooth enough for CMA-ES to optimize.
- Evidence anchors:
  - [abstract] "Our optimization algorithm tunes the weight of each checkpoint in a linear combination, resulting in such an optimal model that outperforms both individual models and merge-based baselines."
  - [section 3.3] "CMA-ES is suitable for cases where gradient information is not available or is expensive to obtain."
  - [corpus] Weak evidence - the corpus mentions evolutionary optimization for model merging but doesn't specifically validate its effectiveness on tradeoff minimization.
- Break condition: If the fitness landscape is too rugged or has many local optima, CMA-ES may converge to suboptimal merges.

### Mechanism 2
- Claim: Seemingly poor-performing checkpoints can contribute positively to optimal merges due to complementary parameter interactions.
- Mechanism: Linear interpolation allows different checkpoints to specialize on different aspects of the task space, where parameters from a weak checkpoint may compensate for weaknesses in stronger ones.
- Core assumption: Parameter interference in linear merging can be constructive rather than purely destructive when weights are properly optimized.
- Evidence anchors:
  - [abstract] "Further analysis shows that good merges tend to include almost all checkpoints with non-zero weights, indicating that even seemingly bad initial checkpoints can contribute to good final merges."
  - [section 5.3] "We observe that merges with the best tradeoffs are the result of merging almost all checkpoints, suggesting that linear merging benefits from seemingly bad checkpoints."
  - [corpus] Weak evidence - the corpus mentions recycling checkpoints but doesn't provide evidence about how poor checkpoints contribute to merges.
- Break condition: If checkpoints are too dissimilar in architecture or training regime, linear interpolation may produce destructive interference.

### Mechanism 3
- Claim: Merging 100B parameter models can effectively reduce tradeoffs without requiring additional training.
- Mechanism: Linear weight interpolation in parameter space combines knowledge from multiple checkpoints, creating a new model that inherits capabilities from each while smoothing out their individual weaknesses.
- Core assumption: The parameter space of LLMs is sufficiently linear for interpolation to work effectively at scale.
- Evidence anchors:
  - [abstract] "Our approach successfully recycles suboptimal checkpoints into Pareto-optimal models, demonstrating that linear merging can effectively mitigate task tradeoffs without requiring additional training."
  - [section 2] "we leverage evolutionary search to optimize the merging weightings" and "as opposed to relying on simple averaging"
  - [corpus] Weak evidence - the corpus mentions scaling model merging but doesn't specifically validate its effectiveness at 100B scale.
- Break condition: If the parameter space becomes too non-linear at scale, simple linear interpolation may fail to capture the necessary interactions.

## Foundational Learning

- Concept: Linear merging (model soups)
  - Why needed here: Provides a training-free, parameter-efficient way to combine multiple checkpoints while maintaining the ability to optimize weights
  - Quick check question: What is the mathematical formula for linear merging of N checkpoints?

- Concept: Pareto optimality
  - Why needed here: Provides the theoretical framework for evaluating whether a merged model improves upon the individual checkpoints
  - Quick check question: How do you determine if a merged model is Pareto-optimal compared to its components?

- Concept: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
  - Why needed here: Provides an optimization algorithm that can handle the high-dimensional, non-convex weight space without requiring gradients
  - Quick check question: What are the key advantages of CMA-ES for optimizing model merging weights?

## Architecture Onboarding

- Component map:
  Checkpoints (16 Command R+ models) -> CMA-ES Optimizer -> Linear Merging -> Fitness Evaluation -> Weight Update

- Critical path:
  1. Load checkpoints and compute individual task performances
  2. Initialize CMA-ES with uniform weights
  3. For each iteration: sample weights, merge models, evaluate fitness, update distribution
  4. After convergence, evaluate final merge on all tasks

- Design tradeoffs:
  - Linear vs non-linear merging methods (simplicity vs potential performance)
  - Held-in vs held-out task selection (optimization focus vs generalization)
  - Number of checkpoints to include (search space size vs potential for better solutions)

- Failure signatures:
  - Fitness doesn't improve over iterations
  - Final merge performs worse on held-out tasks than baselines
  - Weight distribution is highly sparse (only few checkpoints used)

- First 3 experiments:
  1. Run CMA-ES with all 16 checkpoints on MBPP-IFEval to verify optimization improves over baselines
  2. Test whether removing the worst-performing checkpoint degrades merge quality
  3. Compare CMA-ES results with random search to validate the optimizer's effectiveness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the analysis and limitations discussed, several important open questions emerge from the work.

## Limitations
- The evaluation is constrained to a specific family of models (Command R+) and a fixed set of tasks, limiting generalizability
- The computational cost of CMA-ES for 100B parameter models is not quantified
- The method's scalability to different model architectures remains untested
- While the paper shows that poor checkpoints can contribute positively to merges, the theoretical understanding of why certain checkpoints improve performance is lacking

## Confidence
**High confidence**: The core claim that evolutionary optimization can find effective merging weights that outperform uniform averaging and merge-best baselines on held-in tasks. The experimental setup is clearly defined, and results are directly measurable.

**Medium confidence**: The claim that optimal merges use almost all checkpoints with non-zero weights. While the data supports this observation, the sample size (16 checkpoints) may be insufficient to establish this as a general principle.

**Low confidence**: The assertion that poor-performing checkpoints contribute positively to merges due to complementary parameter interactions. This mechanism is plausible but not directly tested or quantified in the paper.

## Next Checks
1. **Architecture transfer test**: Apply the same evolutionary merging approach to checkpoints from different model architectures (e.g., Llama, Mistral) to validate generalizability beyond Command R+.

2. **Checkpoint sensitivity analysis**: Systematically remove checkpoints with varying performance levels to quantify their individual contributions to merge quality and test whether poor checkpoints truly add value.

3. **Alternative optimizer comparison**: Replace CMA-ES with random search and other black-box optimizers to validate that the optimization algorithm itself, rather than just the search process, contributes to improved merge performance.