---
ver: rpa2
title: 'Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language
  Models'
arxiv_id: '2409.03155'
source_url: https://arxiv.org/abs/2409.03155
tags:
- question
- knowledge
- reasoning
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DoG, a KGQA framework that uses LLMs to reason
  step-by-step on knowledge graphs by iteratively simplifying questions through multi-role
  debates. It addresses challenges of long reasoning paths and false-positive relations
  by allowing answer attempts after each step and transforming complex questions into
  simpler ones.
---

# Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models

## Quick Facts
- arXiv ID: 2409.03155
- Source URL: https://arxiv.org/abs/2409.03155
- Reference count: 19
- Outperforms ToG by 23.7% and 9.1% on WebQuestions and GrailQA, respectively

## Executive Summary
Debate on Graph (DoG) introduces a novel KGQA framework that leverages LLM-based multi-role debate for iterative reasoning on knowledge graphs. The approach addresses key challenges in KGQA, including long reasoning paths and false-positive relations, by allowing answer attempts after each reasoning step and transforming complex questions into simpler ones through debate. The framework demonstrates strong empirical performance, achieving state-of-the-art results on multiple KGQA benchmarks while maintaining flexibility across different LLM architectures.

## Method Summary
DoG employs a multi-role debate mechanism where different LLM agents take on specialized roles (e.g., questioner, answerer, verifier) to collaboratively reason through knowledge graph paths. At each step, the framework attempts to answer the current question, and if unsuccessful, uses the debate process to simplify the question by breaking it down into sub-questions that can be answered using single or few-hop relations. This iterative process continues until an answer is found or all reasonable paths are exhausted. The framework's design allows it to handle complex reasoning paths while maintaining reliability through continuous verification and question simplification.

## Key Results
- Achieves 23.7% improvement over ToG on WebQuestions dataset
- Shows 9.1% improvement over ToG on GrailQA dataset
- Demonstrates competitive performance across five public KGQA datasets

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to combine the reasoning capabilities of LLMs with structured knowledge graph navigation. By implementing a multi-role debate system, DoG can leverage different perspectives and reasoning approaches simultaneously, reducing the likelihood of getting stuck in incorrect reasoning paths. The iterative simplification process allows the system to break down complex multi-hop questions into manageable sub-questions, while the continuous answer attempts ensure that correct answers are identified as soon as they become reachable, rather than waiting for complete path traversal.

## Foundational Learning
- **Knowledge Graph Structure**: Understanding of nodes, edges, and relation types is crucial for implementing the reasoning framework
  - Why needed: Forms the basis for graph traversal and path finding
  - Quick check: Can you identify subject-predicate-object triples in sample data?

- **Multi-hop Reasoning**: Ability to chain multiple relations to answer complex questions
  - Why needed: Many real-world questions require traversing multiple edges
  - Quick check: Can you trace paths requiring 3+ hops in a sample graph?

- **LLM Prompt Engineering**: Crafting effective prompts for different debate roles
  - Why needed: Quality of reasoning depends heavily on prompt design
  - Quick check: Can you create prompts that generate consistent role-specific responses?

## Architecture Onboarding

**Component Map**: User Question -> Multi-Role Debate -> Graph Traversal -> Answer Attempt -> Question Simplification -> (repeat)

**Critical Path**: The core reasoning loop involves question reception, debate initiation, graph traversal based on debate outcomes, answer attempt, and conditional question simplification. This cycle repeats until an answer is found or all paths are exhausted.

**Design Tradeoffs**: The framework trades computational overhead (multiple LLM calls per step) for improved reasoning accuracy and reliability. The multi-role debate adds complexity but provides more robust path exploration compared to single-agent approaches.

**Failure Signatures**: Common failure modes include circular reasoning in debates, inability to simplify certain complex questions, and degradation when knowledge graph contains significant noise or missing relations.

**First Experiments**: 1) Run single-hop questions to verify basic graph traversal works; 2) Test multi-role debate with known simple paths; 3) Evaluate question simplification on progressively complex questions.

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- Evaluation focuses primarily on question-answering tasks, limiting assessment of generalizability to other reasoning domains
- Performance gains are benchmarked against a single state-of-the-art method, potentially overstating relative improvements
- The framework's computational overhead from multiple LLM calls per reasoning step may limit scalability

## Confidence
- **High confidence**: The framework's core design and its ability to outperform baselines on tested datasets
- **Medium confidence**: The generalizability of the approach across different knowledge graph tasks and domains
- **Low confidence**: The robustness of the method under varying graph quality and computational efficiency in large-scale applications

## Next Checks
1. Conduct ablation studies to isolate the impact of the multi-role debate mechanism versus other framework components
2. Test the framework on additional KGQA benchmarks and non-QA reasoning tasks to assess generalizability
3. Evaluate performance under scenarios with incomplete or noisy knowledge graph data to determine robustness