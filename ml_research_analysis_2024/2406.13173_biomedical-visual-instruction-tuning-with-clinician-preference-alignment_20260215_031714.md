---
ver: rpa2
title: Biomedical Visual Instruction Tuning with Clinician Preference Alignment
arxiv_id: '2406.13173'
source_url: https://arxiv.org/abs/2406.13173
tags:
- data
- visual
- image
- preference
- instruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces BioMed-VITAL, a data-centric framework that
  incorporates clinician preferences into both stages of generating and selecting
  instruction data for tuning biomedical multimodal foundation models. During the
  generation stage, the framework prompts the GPT-4V generator with a diverse set
  of clinician-selected demonstrations for preference-aligned data candidate generation.
---

# Biomedical Visual Instruction Tuning with Clinician Preference Alignment

## Quick Facts
- arXiv ID: 2406.13173
- Source URL: https://arxiv.org/abs/2406.13173
- Reference count: 40
- Key outcome: BioMed-VITAL improves open visual chat by 18.5% relatively and medical VQA win rate up to 81.73% through clinician-preference-aligned instruction tuning

## Executive Summary
BioMed-VITAL introduces a data-centric framework that incorporates clinician preferences into both data generation and selection for biomedical multimodal foundation models. The approach uses GPT-4V to generate instruction data guided by clinician-selected demonstrations, then trains a selection model to distill human and model preferences into a rating function. This framework addresses the challenge of adapting general-purpose multimodal models to specialized biomedical tasks by ensuring the instruction data reflects real-world clinical needs. The method demonstrates significant improvements in both open-ended biomedical visual chat and medical visual question answering tasks.

## Method Summary
BioMed-VITAL operates in three stages: (1) data generation using GPT-4V with clinician-selected demonstrations, (2) data selection using a preference-distilled model that combines human-annotated and model-generated ratings, and (3) visual instruction tuning of the LLaVA-v1.5-13b model. The framework uses BioMedCLIP as the backbone for the selection model and employs an adaptive contribution mechanism to balance human and model preferences during training. The approach addresses the challenge of limited high-quality biomedical instruction data by generating diverse candidates and selecting the most relevant examples based on clinician preferences.

## Key Results
- Open visual chat performance improved by 18.5% relatively compared to baseline models
- Medical VQA benchmark win rate reached up to 81.73% in direct comparisons
- Data selection model successfully distilled clinician preferences with optimal performance at weight w=400
- Models tuned with BioMed-VITAL data showed consistent improvements across multiple biomedical imaging modalities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Clinician preference alignment improves data quality and downstream performance.
- Mechanism: By integrating clinician-selected demonstrations during data generation and clinician-annotated preferences during data selection, the framework filters out irrelevant or low-quality samples, resulting in higher-quality instruction-following data.
- Core assumption: Clinician expertise accurately reflects real-world needs and preferences in biomedical tasks.
- Evidence anchors:
  - [abstract]: "Results show that the model tuned with the instruction-following data from our method demonstrates a significant improvement in open visual chat (18.5% relatively) and medical VQA (win rate up to 81.73%)."
  - [section]: "The results in Table 1 show that the best performance is achieved when w is 400, which happens to balance the contribution of human and model-annotated preference in the total training loss."
- Break condition: If clinician preferences do not align with real-world needs or if the selection model fails to effectively distill preferences.

### Mechanism 2
- Claim: Data size and quality trade-off affects model performance.
- Mechanism: The framework selects a subset of high-quality data from the generated dataset, allowing for efficient and effective model tuning with fewer but more informative examples.
- Core assumption: High-quality data is more beneficial for model training than a larger quantity of lower-quality data.
- Evidence anchors:
  - [abstract]: "The model tuned with the instruction-following data from our method demonstrates a significant improvement in open visual chat (18.5% relatively) and medical VQA (win rate up to 81.73%)."
  - [section]: "When varying the top-ranked percentiles in the data selection process, increasing the dataset size generally improves model performance."
- Break condition: If the selected subset does not contain enough diverse examples to cover the task space or if the selection model fails to identify truly high-quality data.

### Mechanism 3
- Claim: Preference mixing strategy improves the data selection model's performance.
- Mechanism: By combining human-annotated preferences with model-generated ratings, the framework addresses the scalability issue of human annotation and provides a more robust basis for training the selection model.
- Core assumption: Model-generated ratings can approximate human preferences effectively and complement human-annotated data.
- Evidence anchors:
  - [section]: "The results in Table 1 show that the best performance is achieved when w is 400, which happens to balance the contribution of human and model-annotated preference in the total training loss."
  - [section]: "The results also reveal a successful distillation of clinician preferences into the selection model."
- Break condition: If model-generated ratings do not accurately reflect human preferences or if the mixing strategy fails to find the optimal balance.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their capabilities
  - Why needed here: Understanding the role of GPT-4V as the data generator and its ability to learn from demonstrations.
  - Quick check question: What is the primary function of GPT-4V in the BioMed-VITAL framework?

- Concept: Multimodal foundation models
  - Why needed here: Grasping the concept of adapting general-purpose models to specialized domains like biomedicine.
  - Quick check question: Why is adapting general multimodal models to biomedicine challenging?

- Concept: Preference learning and distillation
  - Why needed here: Comprehending how the framework learns and distills clinician preferences into the data selection model.
  - Quick check question: What is the purpose of the data selection model in the BioMed-VITAL framework?

## Architecture Onboarding

- Component map: GPT-4V (data generator) → Clinician preference annotation → Data selection model (BiomedCLIP backbone with MLP head) → Instruction-tuning model (LLaVA)
- Critical path: Data generation (GPT-4V) → Preference annotation (clinicians) → Data selection (trained model) → Instruction tuning (LLaVA)
- Design tradeoffs:
  - Balancing data size and quality: Selecting a subset of high-quality data may reduce the overall dataset size but improve model performance.
  - Preference mixing strategy: Combining human and model preferences addresses scalability but may introduce noise if model ratings are not accurate.
- Failure signatures:
  - Poor data quality: If the generated data contains irrelevant or low-quality examples, the model may not perform well on downstream tasks.
  - Ineffective preference distillation: If the data selection model fails to accurately capture clinician preferences, the selected data may not align with real-world needs.
- First 3 experiments:
  1. Evaluate the impact of varying the top-ranked percentiles on model performance.
  2. Compare the performance of models trained with different preference mixing strategies.
  3. Assess the alignment of the data selection model with human preferences compared to GPT-4.

## Open Questions the Paper Calls Out

1. How does the optimal balance between human and model preferences (weight w = 400) vary across different biomedical subdomains or imaging modalities?
2. To what extent does the quality of instruction-following data improve when using larger, more diverse clinician demonstration sets during generation?
3. How does the performance of BioMed-VITAL models degrade when applied to medical imaging domains outside the five modalities (CXR, MRI, Histology, Gross, CT) covered in the training data?

## Limitations

- Framework heavily depends on clinician expertise availability and quality, creating scalability constraints
- Limited to English-language biomedical content from PubMed Central, raising generalizability questions
- Optimal preference mixing weight (w=400) derived from limited conditions may not generalize across specialties

## Confidence

**High Confidence**: The core methodology of using clinician preferences for data selection is well-supported by experimental results showing consistent improvements across both open visual chat (18.5% relative improvement) and medical VQA tasks (up to 81.73% win rate).

**Medium Confidence**: The scalability solution of mixing human and model preferences shows promise but relies on the assumption that model-generated ratings adequately approximate human preferences.

**Low Confidence**: The optimal weight parameter (w=400) for preference mixing is derived from limited experimental conditions and may not generalize across different medical specialties or institutional contexts.

## Next Checks

1. Cross-specialty validation: Test the framework's effectiveness across different medical specialties (radiology, pathology, dermatology) to assess generalizability beyond the current PubMed Central corpus.

2. Preference stability analysis: Conduct longitudinal studies to evaluate whether clinician preferences remain stable over time and across different annotator groups, and how this affects the selection model's performance.

3. Edge case robustness: Systematically evaluate model performance on rare diseases, unusual presentations, and low-quality medical images to identify potential failure modes not captured in the main benchmark results.