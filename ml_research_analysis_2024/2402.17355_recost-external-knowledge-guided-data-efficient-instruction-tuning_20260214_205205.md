---
ver: rpa2
title: 'RECOST: External Knowledge Guided Data-efficient Instruction Tuning'
arxiv_id: '2402.17355'
source_url: https://arxiv.org/abs/2402.17355
tags:
- data
- recost
- instruction
- knowledge
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RECOST, a data-efficient instruction tuning
  framework that uses external knowledge to improve the quality of synthetic instruction
  data selection. The key insight is that predictive entropy alone is unreliable for
  selecting high-quality data from LLM-synthesized datasets, especially when those
  datasets contain noisy samples.
---

# RECOST: External Knowledge Guided Data-efficient Instruction Tuning

## Quick Facts
- arXiv ID: 2402.17355
- Source URL: https://arxiv.org/abs/2402.17355
- Authors: Qi Zhang; Yiming Zhang; Haobo Wang; Junbo Zhao
- Reference count: 16
- Primary result: Achieves state-of-the-art results on AlpacaEval and OpenLLM benchmarks using only 1% of full dataset

## Executive Summary
RECOST is a data-efficient instruction tuning framework that addresses the challenge of selecting high-quality samples from large synthetic instruction datasets. The method introduces a relative predictive entropy metric that leverages external knowledge through in-context demonstrations to better distinguish reliable from unreliable samples. By incorporating diversity-consistent sampling and knowledge-guided selection, RECOST significantly reduces the amount of data needed for effective instruction tuning while maintaining or improving performance compared to models trained on full datasets.

## Method Summary
RECOST tackles the problem of data selection for instruction tuning by replacing raw predictive entropy with a relative predictive entropy approach that incorporates external knowledge. The framework retrieves in-context demonstrations to create a knowledge base, then uses these demonstrations to compute relative entropy scores that better identify reliable samples. A diversity-consistent sampling strategy ensures the selected dataset maintains variety and avoids overfitting to homogeneous data. The method is particularly effective for synthetic datasets like Alpaca, where traditional entropy-based selection fails due to noisy samples.

## Key Results
- Outperforms previous data-efficient instruction tuning methods on AlpacaEval and OpenLLM benchmarks
- Achieves state-of-the-art performance using only 1% of the full synthetic dataset
- Demonstrates that external knowledge significantly enhances data selection quality in instruction tuning

## Why This Works (Mechanism)
RECOST works by addressing the fundamental limitation of using predictive entropy alone for data selection from synthetic datasets. Raw entropy scores are unreliable when datasets contain noisy samples, as is common with LLM-generated instruction data. By computing relative predictive entropy using external knowledge (retrieved demonstrations), RECOST can better distinguish between truly reliable samples and those that appear confident but are actually incorrect. The diversity-consistent sampling prevents overfitting to homogeneous data patterns, ensuring the model learns robust, generalizable instruction-following capabilities.

## Foundational Learning

**Predictive Entropy** - Measures model uncertainty by calculating the entropy of predicted probability distributions. Needed to assess confidence in model predictions during data selection. Quick check: Verify entropy values correlate with known good/bad samples.

**In-context Learning** - Ability of models to learn from demonstrations provided within the input context. Needed for RECOST to leverage external knowledge effectively. Quick check: Test retrieval quality on benchmark datasets.

**Diversity Sampling** - Strategies to ensure selected datasets represent the full distribution of instruction types. Needed to prevent overfitting to homogeneous data patterns. Quick check: Measure coverage of instruction categories in selected samples.

**Knowledge Retrieval** - Process of finding relevant examples from external sources to inform decision-making. Needed for computing relative predictive entropy. Quick check: Evaluate retrieval precision and recall on test queries.

**Instruction Tuning** - Fine-tuning language models on instruction-response pairs to improve task-following capabilities. Needed as the target application for RECOST's data selection. Quick check: Measure instruction-following performance on benchmark tasks.

## Architecture Onboarding

Component Map: Knowledge Retriever -> Relative Entropy Calculator -> Diversity Sampler -> Instruction Tuner

Critical Path: The pipeline flows from retrieving relevant demonstrations, computing relative entropy scores using these demonstrations, applying diversity constraints during sampling, and finally using the selected data for instruction tuning. The knowledge retrieval step is critical as it provides the reference points needed for relative entropy computation.

Design Tradeoffs: RECOST trades computational overhead from knowledge retrieval against data efficiency gains. While retrieval adds latency to data selection, it enables using 99% less data for training. The diversity constraint balances sample quality against representation, potentially excluding some high-confidence but redundant samples.

Failure Signatures: Poor retrieval quality leads to misleading relative entropy scores and suboptimal data selection. Over-aggressive diversity constraints may exclude valuable high-quality samples. The framework may struggle with domains where external knowledge is sparse or unreliable.

First Experiments:
1. Baseline comparison: Test RECOST against raw entropy selection on a small synthetic dataset
2. Knowledge ablation: Evaluate performance with and without knowledge retrieval
3. Diversity impact: Measure performance differences with various diversity thresholds

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability to specialized domains where external knowledge may be sparse or unreliable
- Potential biases introduced by non-representative in-context demonstrations
- Scalability concerns with knowledge retrieval in extremely large datasets
- Computational overhead from retrieval process limiting practical deployment

## Confidence

High: Relative predictive entropy effectively distinguishes reliable from unreliable samples compared to raw entropy, supported by strong empirical results on AlpacaEval and OpenLLM benchmarks.

Medium: External knowledge is essential for data-efficient instruction tuning, though ablation studies isolating knowledge retrieval's contribution are not provided.

Medium: RECOST achieves state-of-the-art results with 1% of full dataset, but this claim depends heavily on synthetic dataset characteristics and may not generalize to all instruction tuning scenarios.

## Next Checks

1. Conduct ablation studies to quantify individual contributions of relative predictive entropy, knowledge retrieval, and diversity-consistent sampling to performance improvements.

2. Test RECOST on specialized domain-specific instruction datasets (biomedical, legal) to evaluate generalizability beyond general-purpose synthetic data.

3. Measure computational overhead of knowledge retrieval process and assess impact on scalability and production deployment.