---
ver: rpa2
title: 'Can''t Hide Behind the API: Stealing Black-Box Commercial Embedding Models'
arxiv_id: '2406.09355'
source_url: https://arxiv.org/abs/2406.09355
tags:
- embedding
- training
- bert
- retrieval
- thief
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work is the first to demonstrate successful distillation of
  commercial embedding models (OpenAI's text-embedding-3-large and Cohere's embed-english-v3.0)
  from their APIs, achieving strong retrieval effectiveness on MSMARCO and BEIR benchmarks
  with training costs under $300. The authors trained thief models using BERT base
  and BERT large as backbones, employing cosine distance loss to align embeddings.
---

# Can't Hide Behind the API: Stealing Black-Box Commercial Embedding Models

## Quick Facts
- **arXiv ID:** 2406.09355
- **Source URL:** https://arxiv.org/abs/2406.09355
- **Reference count:** 9
- **Primary result:** First successful distillation of commercial embedding models (OpenAI and Cohere) achieving strong retrieval effectiveness under $300 training cost

## Executive Summary
This paper demonstrates the first successful distillation attacks on commercial black-box embedding models through their APIs. The authors show that both OpenAI's text-embedding-3-large and Cohere's embed-english-v3.0 can be effectively stolen by training surrogate models using only API access and cosine distance loss. With BERT base and BERT large as backbones, the thief models achieve retrieval effectiveness on par with the original models on MSMARCO and BEIR benchmarks at remarkably low cost. The study reveals significant vulnerabilities in commercial embedding APIs and demonstrates that even with limited access patterns, high-quality embeddings can be reconstructed.

## Method Summary
The authors employed a teacher-student distillation approach where thief models query the commercial API to obtain teacher embeddings, then train using cosine distance loss to align their outputs with these teacher embeddings. Two backbone architectures were tested: BERT base and BERT large. The distillation process involved generating synthetic query-document pairs, obtaining teacher embeddings through API calls, and training the student models to minimize cosine distance between student and teacher embeddings. The study also explored bottleneck representations and simultaneous distillation from both APIs by concatenating teacher embeddings during training.

## Key Results
- Successfully distilled OpenAI's text-embedding-3-large and Cohere's embed-english-v3.0 with training costs under $300
- Achieved strong retrieval effectiveness on MSMARCO and BEIR benchmarks comparable to original models
- Demonstrated that shorter bottleneck representations yield comparable effectiveness to full-length embeddings
- Found Cohere's model (likely BERT-based) easier to distill than OpenAI's model
- Showed promise in distilling from concatenated embeddings of both APIs simultaneously

## Why This Works (Mechanism)
Commercial embedding models are vulnerable to distillation attacks because their APIs provide only embeddings without model weights, yet these embeddings contain sufficient information about the underlying representation space. The cosine distance loss effectively captures the geometric structure of the embedding space, allowing thief models to learn similar semantic relationships. Since both target models are BERT-based architectures, the distillation process can leverage architectural similarities to reproduce comparable embedding patterns. The controlled API access still provides enough data points to reconstruct the mapping from input text to embedding space.

## Foundational Learning

**Cosine distance loss**: Measures angular similarity between vectors, essential for preserving semantic relationships in embedding space. Why needed: Embedding models rely on angular relationships rather than magnitude for semantic similarity. Quick check: Verify cosine similarity preserves relative distances between semantically related and unrelated pairs.

**Teacher-student distillation**: Framework where a student model learns from a teacher model's outputs. Why needed: Enables knowledge transfer from black-box models without access to internal parameters. Quick check: Confirm student performance improves with more teacher data and better teacher models.

**BERT architecture**: Bidirectional Transformer-based model for text representation. Why needed: Both target models likely use BERT-like architectures, making distillation more effective. Quick check: Validate that thief models using BERT backbones can reproduce similar attention patterns.

## Architecture Onboarding

**Component map**: Synthetic data generator -> API query module -> Teacher embedding fetcher -> Cosine loss calculator -> Student model trainer -> Evaluation module

**Critical path**: Synthetic query generation → API embedding retrieval → Student