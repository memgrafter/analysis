---
ver: rpa2
title: Structured Active Inference (Extended Abstract)
arxiv_id: '2406.07577'
source_url: https://arxiv.org/abs/2406.07577
tags:
- inference
- systems
- active
- agents
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Structured Active Inference extends the active inference framework
  using categorical systems theory, introducing explicit interfaces for agents that
  generalize Markov blankets. This allows agents to have structured, context-dependent
  interfaces, typed policies amenable to formal verification, and the ability to change
  their own structure.
---

# Structured Active Inference (Extended Abstract)

## Quick Facts
- arXiv ID: 2406.07577
- Source URL: https://arxiv.org/abs/2406.07577
- Authors: Toby St Clere Smithe
- Reference count: 40
- Primary result: Structured Active Inference extends the active inference framework using categorical systems theory, introducing explicit interfaces for agents that generalize Markov blankets.

## Executive Summary
Structured Active Inference presents a categorical extension of active inference that enables compositional agent construction with structured, context-dependent interfaces. The framework generalizes classical active inference by replacing fixed Markov blankets with polynomial functors that can represent mode-dependent interactions. This allows agents to have typed policies amenable to formal verification, hierarchical agents that manage other agents, and the ability to change their own structure through categorical composition.

The key innovation is the dual relationship between generative models and controllers, where controllers are Moore machines formally dual to their generative models. This duality, combined with polynomial functor interfaces and categorical composition, enables the creation of complex agent systems while maintaining the core principles of active inference. The framework also supports logical specification of goals and constraints using categorical logic, opening possibilities for safe AI development through formal verification.

## Method Summary
The method extends active inference by using polynomial functors as interfaces instead of simple sets, enabling context-dependent agent interactions. Agents are formalized as pairs consisting of a generative model and its dual Moore machine controller. The framework establishes categorical composition operations that allow hierarchical agent construction and self-modification. Categorical logic is imported to enable formal specification of goals and safety constraints that can be verified against agent policies.

## Key Results
- Enables agents with structured, context-dependent interfaces that generalize Markov blankets
- Provides typed policies amenable to formal verification for safer AI development
- Supports hierarchical agents and meta-agents that can change their own structure
- Allows logical specification of goals using categorical logic for formal verification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured Active Inference generalizes classical active inference by replacing fixed Markov blankets with structured interfaces that can depend on context.
- Mechanism: By using polynomial functors as interfaces instead of simple sets, the framework allows an agent's available actions and observations to vary based on its current state and context, enabling mode-dependent behavior.
- Core assumption: The polynomial interface structure accurately captures the dependency between agent state and available interactions.
- Evidence anchors:
  - [abstract]: "agents with structured interfaces (e.g. with 'mode-dependence', or that interact with computer APIs)"
  - [section]: "To capture systems whose interfaces may be mode- or context-dependent, we need the possible inputs to a system to be able to depend on the system's state, as revealed by its output."
  - [corpus]: Weak - related papers don't explicitly discuss mode-dependent interfaces, though Learning in Hybrid Active Inference Models suggests context-dependent learning mechanisms.
- Break condition: If the polynomial functor representation becomes too computationally expensive for real-time use, or if the state-observation dependency doesn't match the actual system behavior.

### Mechanism 2
- Claim: The dual relationship between generative models and controllers enables compositional agent construction.
- Mechanism: By formalizing agents as pairs of generative models and controllers where controllers are formally dual to their models, the framework supports hierarchical agents that manage other agents through categorical composition.
- Core assumption: The Moore machine controller dual to a generative model correctly implements action selection and inference.
- Evidence anchors:
  - [abstract]: "agents that can manage other agents; and 'meta-agents', that use active inference to change their (internal or external) structure"
  - [section]: "An agent with polynomial interface p and state space S consists of a generative model over p with state space S, along with a controller for the generative model: a Moore machine over rp, ys with state space DS."
  - [corpus]: Weak - while Theory of Mind Using Active Inference suggests multi-agent cooperation, it doesn't explicitly use the dual structure described here.
- Break condition: If the controller duality doesn't preserve necessary properties for hierarchical composition, or if inference becomes intractable at higher levels.

### Mechanism 3
- Claim: Categorical logic enables formal specification and verification of agent goals and constraints.
- Mechanism: The framework's categorical structure allows importing logical systems where agents' goals can be expressed as predicates, and policies can be verified against these specifications, enabling safer AI development.
- Core assumption: The categorical logic framework can express meaningful safety constraints and goals in a way that's both expressive and verifiable.
- Evidence anchors:
  - [abstract]: "With structured interfaces, we also gain structured ('typed') policies, which are amenable to formal verification, an important step towards safe artificial agents."
  - [section]: "categorical systems theory is itself amenable to categorical logic [2], which explains the structural fundaments of logic and type theory and which may be instantiated in any sufficiently structured context."
  - [corpus]: Weak - Structured Personalization discusses constraints but not formal verification; no direct evidence of categorical logic application.
- Break condition: If the logical specifications become too complex to verify practically, or if the categorical structure doesn't support the needed logical operations.

## Foundational Learning

- Concept: Polynomial functors as interface representation
  - Why needed here: Provides the mathematical foundation for context-dependent agent interfaces, replacing simple Markov blankets
  - Quick check question: Can you explain how a polynomial functor differs from a simple pair of sets in representing agent interfaces?

- Concept: Categorical duality between models and controllers
  - Why needed here: Enables the formal composition of agents and hierarchical agent structures
  - Quick check question: How does the Moore machine controller dual to a generative model implement action selection and inference?

- Concept: Internal hom and composition in categorical systems
- Why needed here: Allows dynamic wiring of systems and the creation of manager agents that control other agents
- Quick check question: What is the relationship between the internal hom rp, qs and the composition of systems over interface q?

## Architecture Onboarding

- Component map:
  - Interface layer: Polynomial functors defining agent boundaries and interaction patterns
  - Model layer: Generative models with context-dependent observations and actions
  - Controller layer: Moore machines implementing policy and inference
  - Composition layer: Categorical operations for hierarchical agent construction
  - Logic layer: Categorical logic for goal specification and verification

- Critical path: Interface → Model → Controller → Composition → Logic
  Each layer builds on the previous, with composition enabling hierarchical structures and logic providing verification capabilities

- Design tradeoffs:
  - Expressiveness vs. computational tractability: More complex polynomial interfaces enable richer behavior but increase computational cost
  - Generality vs. specialization: The framework can model many agent types but may sacrifice domain-specific optimizations
  - Verification vs. flexibility: Stronger logical constraints improve safety but may limit adaptive behavior

- Failure signatures:
  - Interface explosion: Polynomial interfaces becoming too complex to manage
  - Inference collapse: Controller inference becoming intractable at higher levels
  - Verification deadlock: Logical specifications becoming undecidable or too complex

- First 3 experiments:
  1. Implement a simple mode-dependent agent with polynomial interface that changes available actions based on state
  2. Build a hierarchical agent system where one agent manages multiple simpler agents
  3. Add logical specifications to an agent and verify policy compliance against safety constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can structured active inference agents be formally verified for safety properties?
- Basis in paper: [explicit] The paper states "With structured interfaces, we also gain structured ('typed') policies, which are amenable to formal verification, an important step towards safe artificial agents" and mentions using categorical logic to describe agents' goals as formal predicates.
- Why unresolved: While the paper establishes that typed policies and formal logic are possible within the framework, it does not provide specific verification methods, proof techniques, or case studies demonstrating actual formal verification of safety properties.
- What evidence would resolve it: Concrete examples of safety properties verified using this framework, along with the specific logical predicates and verification methods employed.

### Open Question 2
- Question: What is the computational complexity of performing Bayesian inversion for state inference in agents with polynomial interfaces?
- Basis in paper: [inferred] The paper describes agents as having a controller that performs inference through Bayesian inversion, and mentions polynomial interfaces that can encode complex, context-dependent input structures.
- Why unresolved: The paper does not analyze the computational complexity of inference operations in the structured setting, particularly how the complexity scales with the complexity of the polynomial interface structure.
- What evidence would resolve it: Complexity analysis comparing inference operations in standard active inference versus structured active inference for various polynomial interface complexities.

### Open Question 3
- Question: How does the compositional structure handle conflicting goals between nested agents in a hierarchical system?
- Basis in paper: [explicit] The paper discusses hierarchical agents and states "This promises a further important step towards safe artificial agents, as agents' goals may be gated behind the certification (within bounds) of their safety, and their policies judged accordingly."
- Why unresolved: While the paper mentions distributing goals and constraints, it does not address what happens when lower-level agents have conflicting goals or when the manager agent cannot satisfy all constraints simultaneously.
- What evidence would resolve it: Formal specification of how conflicts are detected, resolved, or prevented in the compositional framework, with examples of conflict resolution strategies.

## Limitations

- The framework relies heavily on abstract categorical constructions that may prove difficult to implement in practice
- Computational tractability for polynomial functors with complex dependencies remains uncertain
- Practical application of categorical logic for real-world safety verification remains largely unproven

## Confidence

- **High**: The extension of active inference using polynomial functors for context-dependent interfaces is mathematically sound
- **Medium**: Hierarchical agent composition through categorical operations is theoretically valid but implementation complexity is uncertain
- **Low**: Practical application of categorical logic for formal verification of agent safety remains largely unproven

## Next Checks

1. Implement a simple polynomial functor interface system and benchmark computational costs for varying interface complexities
2. Create a small-scale hierarchical agent system and test whether categorical composition preserves expected agent behaviors
3. Develop a minimal example of categorical logic specifications and attempt verification of simple agent policies against safety constraints