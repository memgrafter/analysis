---
ver: rpa2
title: 'ShapeICP: Iterative Category-level Object Pose and Shape Estimation from Depth'
arxiv_id: '2408.13147'
source_url: https://arxiv.org/abs/2408.13147
tags:
- shape
- pose
- object
- estimation
- depth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ShapeICP, an iterative algorithm for category-level
  object pose and shape estimation from single-view depth images. Unlike prior data-driven
  methods, ShapeICP employs a mesh-based active shape model (ASM) and a learning-free
  optimization approach inspired by ICP.
---

# ShapeICP: Iterative Category-level Object Pose and Shape Estimation from Depth

## Quick Facts
- arXiv ID: 2408.13147
- Source URL: https://arxiv.org/abs/2408.13147
- Reference count: 40
- One-line primary result: Achieves 42.2% IoU75 and 36.5% 5°5cm accuracy on NOCS REAL dataset without pose-annotated training data

## Executive Summary
This paper presents ShapeICP, an iterative algorithm for category-level object pose and shape estimation from single-view depth images. Unlike prior data-driven methods, ShapeICP employs a mesh-based active shape model (ASM) and a learning-free optimization approach inspired by ICP. The algorithm alternates between pose estimation (via Umeyama alignment) and shape deformation (via mesh optimization with regularization losses). To handle local minima, it uses multi-hypothesis rotation tracking, expectation-maximization for robust correspondences, and an optional shape classification network for initialization. Evaluated on the NOCS REAL dataset, ShapeICP achieves performance comparable to or surpassing many learning-based methods—e.g., 42.2% IoU75 and 36.5% 5°5cm accuracy—without requiring pose-annotated training data.

## Method Summary
ShapeICP is an iterative optimization algorithm that alternates between pose estimation and shape deformation for category-level object pose and shape estimation. Given a depth image, instance segmentation, and semantic classification, the method constructs a mesh-based active shape model (ASM) by deforming spherical templates to category models and extracting PCA bases. The optimization alternates between: (1) estimating pose via Umeyama alignment with current shape, and (2) deforming the mesh to fit the observed depth with regularization losses. To avoid local minima, ShapeICP tracks multiple rotation hypotheses, uses EM weighting for robust correspondences, and optionally employs a shape classification network for initialization.

## Key Results
- Achieves 42.2% IoU75 and 36.5% 5°5cm accuracy on NOCS REAL dataset
- Outperforms many learning-based methods including NOCS (31.8% IoU75) and CenterSnap (33.1% IoU75)
- Demonstrates strong performance without requiring pose-annotated training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Alternating minimization between pose and shape estimation avoids solving the entangled three-variable problem directly.
- Mechanism: By fixing shape (c) and solving for pose (R, t, s) with Umeyama alignment, and then fixing pose and solving for shape with mesh deformation, the problem reduces to two simpler sub-problems iteratively.
- Core assumption: Each sub-problem is convex or has a well-defined local minimum when the other variable is fixed.
- Evidence anchors:
  - [abstract] "ShapeICP employs a mesh-based active shape model (ASM) and a learning-free optimization approach inspired by ICP."
  - [section] "These two observations lead to an intuitive alternating minimization algorithm to solve (7):"
  - [corpus] No direct evidence of convergence guarantees in related works.
- Break condition: If the alternating updates cause the solution to oscillate or diverge instead of converging.

### Mechanism 2
- Claim: Expectation-maximization (EM) softens hard correspondence assignments, reducing local minima trapping.
- Mechanism: Instead of one-to-one point matching, EM considers Q closest points with probabilistic weights, making the association step more robust to noise and partial views.
- Core assumption: The Q closest points are likely to contain the true correspondence, and the Gaussian noise model accurately reflects measurement uncertainty.
- Evidence anchors:
  - [section] "We integrate EM into our ShapeICP formulation... considers Q likely correspondences weighted by their probabilities."
  - [section] "Both the pose and shape steps can use (8)."
  - [corpus] Related works use similar EM-based correspondence handling in point cloud registration.
- Break condition: If the number of hypotheses Q is too small to capture the true correspondence or too large causing computational inefficiency.

### Mechanism 3
- Claim: Multi-hypothesis tracking with rotation grid exploration mitigates initialization sensitivity.
- Mechanism: By tracking multiple rotation hypotheses in parallel and dropping poor ones based on combined residual and symmetry scores, the method explores the rotation space to avoid bad local minima.
- Core assumption: The ground truth rotation is within the initial grid coverage, and the scoring function effectively distinguishes good from bad hypotheses.
- Evidence anchors:
  - [section] "We track multiple rotation hypotheses in parallel... We start with the base SO(3) grid from [38]."
  - [section] "The total score to be minimized is S_tot = S_r + S_σ + λΨ SΨ + λdr Sdr."
  - [corpus] Related works use multi-hypothesis tracking for rotation estimation in object pose problems.
- Break condition: If the rotation grid resolution is too coarse to contain the ground truth or the scoring function fails to discriminate hypotheses effectively.

## Foundational Learning

- Concept: Active Shape Model (ASM) construction and PCA basis extraction
  - Why needed here: ASM provides a compact, linear representation of shape variations within a category, enabling efficient shape optimization during pose estimation.
  - Quick check question: How does the template deformation process ensure consistent vertex connectivity across all category models?

- Concept: Iterative Closest Point (ICP) algorithm fundamentals
  - Why needed here: ShapeICP builds upon ICP's framework of alternating between correspondence finding and pose estimation, extending it to include shape optimization.
  - Quick check question: What is the key difference between standard ICP and ShapeICP's pose estimation step?

- Concept: Expectation-maximization for robust estimation
  - Why needed here: EM handles the correspondence uncertainty in a principled probabilistic framework, making the optimization more robust to partial views and noise.
  - Quick check question: How does the EM formulation in ShapeICP differ from standard EM in terms of the data likelihood model?

## Architecture Onboarding

- Component map:
  Input preprocessing -> ASM construction -> Multi-hypothesis rotation tracking -> Pose estimation -> Shape estimation -> EM correspondence -> Symmetry checking -> Depth rendering -> Hypothesis selection

- Critical path: Multi-hypothesis rotation tracking → Pose estimation → Shape estimation → EM correspondence → Symmetry checking → Depth rendering → Hypothesis selection

- Design tradeoffs:
  - Mesh-based vs point-based ASM: Mesh provides surface information but requires consistent connectivity; point clouds are more flexible but lack surface representation
  - Number of hypotheses: More hypotheses improve coverage but increase computational cost
  - EM Q parameter: Larger Q provides more robust associations but increases computation per iteration
  - Shape optimization steps: More steps improve shape accuracy but increase runtime

- Failure signatures:
  - Shape looks plausible but has incorrect pose: Likely a local minimum in rotation space not escaped by current hypotheses
  - Estimated shape is overly smooth or blocky: Template deformation may have introduced bias, or too few PCA components
  - Performance degrades significantly on certain object classes: Likely due to specific geometric features (like handles) causing small convergence basins

- First 3 experiments:
  1. Test single-hypothesis vs multi-hypothesis performance on a simple category (e.g., cans) to verify the benefit of rotation exploration
  2. Compare EM vs hard correspondence on objects with partial views to verify robustness benefits
  3. Test different numbers of PCA components on shape reconstruction accuracy to find the optimal tradeoff between accuracy and efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of mesh topology (e.g., spherical vs. category-specific templates) affect shape estimation accuracy and convergence?
- Basis in paper: [explicit] The paper notes that template deformation restricts mesh topology to the template, and suggests category-specific templates could alleviate this.
- Why unresolved: The paper uses a spherical template but only speculates about category-specific ones without empirical comparison.
- What evidence would resolve it: Direct comparison of shape accuracy and runtime between spherical and category-specific templates on the same dataset.

### Open Question 2
- Question: What is the theoretical and empirical relationship between the number of mesh vertices and shape estimation accuracy?
- Basis in paper: [explicit] The paper states the template has 2562 vertices and does not explore sensitivity to vertex count.
- Why unresolved: No ablation study on vertex count is provided to quantify its impact on accuracy or computational cost.
- What evidence would resolve it: Systematic testing of different vertex counts and reporting of accuracy/runtime trade-offs.

### Open Question 3
- Question: How do different noise models (e.g., 1D ray-aligned vs. 3D Gaussian) affect EM-based correspondence estimation performance?
- Basis in paper: [explicit] The paper acknowledges the 3D Gaussian is an approximation to the ideal 1D ray-aligned noise model.
- Why unresolved: Only the 3D Gaussian is implemented; no comparison with ray-aligned or other noise models is made.
- What evidence would resolve it: Implementation and comparison of multiple noise models under varying noise levels.

### Open Question 4
- Question: Can the shape optimization step be reformulated as a linear least squares problem for computational speedup?
- Basis in paper: [explicit] The paper suggests this reformulation is possible since the ASM is linear and could reduce runtime.
- Why unresolved: This is only proposed as future work without experimental validation.
- What evidence would resolve it: Implementation of the linear least squares formulation and comparison of runtime/accuracy with the current SGD approach.

## Limitations
- Performance on complex geometries (objects with holes, thin structures) not extensively validated
- Template deformation process lacks specific implementation details for reproducibility
- Optional shape classification network introduces learning component despite "learning-free" claim

## Confidence
- High confidence: Alternating optimization framework and its effectiveness in reducing the three-variable problem to simpler subproblems
- Medium confidence: EM weighting significantly improves robustness to partial views and noise
- Medium confidence: Multi-hypothesis tracking effectively mitigates initialization sensitivity

## Next Checks
1. Test ShapeICP on object categories with complex geometries (e.g., chairs, laptops) to assess its generalization beyond simpler categories
2. Conduct an ablation study on the EM weighting and multi-hypothesis tracking components to quantify their individual contributions
3. Investigate the impact of different numbers of PCA components on shape reconstruction accuracy across various object categories