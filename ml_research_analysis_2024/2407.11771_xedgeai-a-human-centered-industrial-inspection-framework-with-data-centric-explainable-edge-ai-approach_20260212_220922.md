---
ver: rpa2
title: 'XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric
  Explainable Edge AI Approach'
arxiv_id: '2407.11771'
source_url: https://arxiv.org/abs/2407.11771
tags:
- segmentation
- explanations
- image
- visual
- explanation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a human-centered industrial inspection framework
  integrating explainable AI (XAI) and large vision language models (LVLMs) to enhance
  visual quality inspection systems. The framework addresses challenges in deploying
  deep learning models on resource-constrained edge devices by providing interpretable
  explanations and optimizing model performance.
---

# XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach

## Quick Facts
- **arXiv ID**: 2407.11771
- **Source URL**: https://arxiv.org/abs/2407.11771
- **Reference count**: 40
- **Key outcome**: Proposes a human-centered industrial inspection framework integrating explainable AI and large vision language models to enhance visual quality inspection systems on resource-constrained edge devices.

## Executive Summary
This paper presents XEdgeAI, a comprehensive framework that addresses the challenges of deploying deep learning models for industrial visual inspection on edge devices. The framework combines semantic segmentation with explainable AI techniques to provide interpretable insights while optimizing models for mobile deployment. Through a systematic six-module approach, XEdgeAI integrates base model fine-tuning, XAI-based explanation generation, evaluation, XAI-guided data augmentation, edge model development, and textual explanation generation. The framework demonstrates significant improvements in segmentation accuracy and model interpretability, with mobile models achieving competitive performance while reducing model size by over 75% compared to standard implementations.

## Method Summary
The XEdgeAI framework employs DeepLabv3Plus as the base segmentation model, enhanced with RISE for XAI explanation generation. The process begins with base model fine-tuning on industrial datasets (TTPLA and Substation Equipment), followed by XAI-based explanation generation to identify model behavior patterns. Domain experts interact with the system through a web interface to guide annotation augmentation based on explanation maps. The augmented data is then used to train edge-optimized models using quantization and pruning techniques. Finally, GPT-4 Vision generates textual explanations for end-users. The framework evaluates performance using IoU metrics for segmentation and plausibility/faithfulness metrics for XAI methods, achieving mIoU scores of 75.48% for mobile models while significantly reducing model size.

## Key Results
- RISE XAI method achieved Deletion score of 0.123 and Insertion score of 0.691, outperforming other methods in faithfulness
- Mobile DeepLabv3Plus-MobileNetv2 model achieved 75.48% mIoU with only 13.39 MB model size and 3.51M parameters
- XAI-guided data augmentation successfully identified and corrected systematic failure patterns in the base model
- Textual explanations generated by GPT-4 Vision provided clear, human-readable interpretations of inspection results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RISE outperforms other XAI methods on both plausibility and faithfulness metrics, making it the optimal choice for guiding data augmentation.
- Mechanism: RISE uses randomized perturbation sampling to create attribution maps that closely align with the model's actual decision-making process, capturing both influential and non-influential regions effectively.
- Core assumption: The perturbations used by RISE adequately represent the input space and the model's sensitivity to changes.
- Evidence anchors:
  - [abstract] "The framework is evaluated on industrial datasets, demonstrating significant improvements in segmentation accuracy and model interpretability, with mobile models achieving competitive performance while reducing model size."
  - [section] "RISE stood out as the most advisable XAI method for our framework. RISE demonstrated exceptional performance in terms of faithfulness, achieving the best scores in both Deletion (0.123) and Insertion (0.691) metrics."
  - [corpus] "Weak or missing" (no specific RISE evaluation found in corpus)
- Break condition: If RISE fails to provide actionable insights for domain experts or if its computational cost becomes prohibitive for edge deployment.

### Mechanism 2
- Claim: XAI-guided annotation augmentation improves model performance by addressing systematic failure patterns identified through explanation maps.
- Mechanism: Domain experts analyze saliency maps to identify areas where the model fails to segment objects correctly, then apply targeted annotation enlargement or add void annotations for perplexing objects to improve model learning.
- Core assumption: Domain expert knowledge combined with XAI insights can effectively identify and correct annotation errors or omissions.
- Evidence anchors:
  - [abstract] "Through XAI-guided data augmentation, the enhanced model incorporating domain expert knowledge with visual and textual explanations is successfully deployed on mobile devices to support end-users in real-world scenarios."
  - [section] "Using this web UI, domain experts can thoroughly examine the model's predictions and explanations, identifying problems on the Aval and defining solutions for Atrain need to be refined."
  - [corpus] "Weak or missing" (no specific data augmentation results found in corpus)
- Break condition: If domain experts cannot consistently identify actionable insights from explanation maps or if the annotation augmentation process introduces new biases.

### Mechanism 3
- Claim: Dynamic quantization and pruning enable efficient deployment of semantic segmentation models on edge devices while maintaining competitive performance.
- Mechanism: Targeted quantization of computationally intensive layers reduces model size and inference time, while structured pruning removes redundant weights, making the model suitable for resource-constrained environments.
- Core assumption: The model's performance can be maintained even after significant reduction in numerical precision and parameter count.
- Evidence anchors:
  - [abstract] "Experimental results showcase the effectiveness of the proposed framework, with the mobile model achieving competitive accuracy while significantly reducing model size."
  - [section] "The mobile DeepLabv3Plus-MobileNetv2 (DLv3P-MobileNetv2-M) model, specifically designed for mobile deployment, maintains a competitive mIoU of 75.48% while having significantly fewer parameters (3.51M) and a smaller model size (13.39 MB) compared to the ResNet-based models."
  - [corpus] "Weak or missing" (no specific quantization results found in corpus)
- Break condition: If quantization and pruning lead to significant performance degradation or if the optimized model fails to run efficiently on target edge devices.

## Foundational Learning

- Concept: Semantic segmentation and its evaluation metrics (IoU, Dice loss)
  - Why needed here: The framework relies on semantic segmentation models for visual quality inspection, and their performance is evaluated using IoU and Dice loss metrics.
  - Quick check question: What is the difference between IoU and Dice loss, and why are they suitable for evaluating semantic segmentation models?

- Concept: Explainable AI (XAI) methods and their evaluation (plausibility and faithfulness metrics)
  - Why needed here: The framework incorporates various XAI methods to provide interpretable explanations for model predictions, and their effectiveness is assessed using plausibility and faithfulness metrics.
  - Quick check question: How do plausibility and faithfulness metrics differ, and what do they measure in the context of XAI evaluation?

- Concept: Edge computing and model optimization techniques (quantization, pruning)
  - Why needed here: The framework aims to deploy optimized models on edge devices, requiring an understanding of edge computing constraints and model optimization techniques like quantization and pruning.
  - Quick check question: What are the trade-offs between model size, inference speed, and accuracy when applying quantization and pruning techniques for edge deployment?

## Architecture Onboarding

- Component map: Data Preparation → Base Model Finetuning → XAI Explanation Generation → XAI Evaluation → XAI-guided Data Augmentation → Edge Model Development → Textual Explanation Generation
- Critical path: Data preparation → Base model finetuning → XAI explanation generation → XAI evaluation → XAI-guided data augmentation → Edge model development → Textual explanation generation
- Design tradeoffs: Model accuracy vs. computational efficiency (base model vs. edge model), Explanation quality vs. generation time (RISE vs. other XAI methods), Annotation augmentation effort vs. performance improvement (manual vs. automated)
- Failure signatures: Low IoU scores across multiple categories indicate poor base model performance, Inconsistent or implausible explanation maps suggest issues with XAI method selection, Significant performance drop after quantization and pruning indicates insufficient optimization
- First 3 experiments:
  1. Train and evaluate the base DeepLabv3Plus model with different backbones (MobileNetv2, ResNet50, ResNet101) on the TTPLA dataset.
  2. Implement and compare multiple XAI methods (RISE, GradCAM, GradCAM++, etc.) on the validation set using plausibility and faithfulness metrics.
  3. Apply XAI-guided annotation augmentation to the training set and retrain the model to assess performance improvements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the XAI-guided annotation augmentation process be automated or semi-automated to reduce human-in-the-loop effort?
- Basis in paper: [explicit] The paper mentions that the XAI-guided annotation augmentation process relies on domain expert manual effort, and suggests automating this process as a future direction.
- Why unresolved: The paper acknowledges the limitation of manual effort in the annotation augmentation process but does not provide a solution for automation.
- What evidence would resolve it: A method that can automatically or semi-automatically refine annotations based on XAI insights, reducing the need for manual intervention by domain experts.

### Open Question 2
- Question: What is the optimal balance between model performance and computational efficiency for edge deployment of the visual quality inspection system?
- Basis in paper: [inferred] The paper discusses the trade-off between model performance and computational efficiency when deploying the system on edge devices, but does not provide a definitive answer on the optimal balance.
- Why unresolved: The optimal balance may depend on specific application requirements, resource constraints, and user preferences, which are not explicitly addressed in the paper.
- What evidence would resolve it: Empirical studies comparing the performance and efficiency of different model architectures and quantization techniques on various edge devices, considering factors such as inference time, memory usage, and accuracy.

### Open Question 3
- Question: How can the interpretability and trustworthiness of the visual quality inspection system be further improved for end-users with varying levels of expertise?
- Basis in paper: [explicit] The paper discusses the importance of providing interpretable insights to end-users through textual explanations generated by LVLMs, but does not explore ways to tailor these explanations for users with different levels of expertise.
- Why unresolved: The paper does not investigate how to adapt the explanations to suit the needs and understanding of users with varying backgrounds and levels of technical knowledge.
- What evidence would resolve it: User studies evaluating the effectiveness of different explanation strategies (e.g., varying levels of technical detail, interactive explanations) for users with different levels of expertise, and identifying the most suitable approaches for each user group.

## Limitations

- The framework's effectiveness depends heavily on domain expert interaction through a web interface, which introduces scalability challenges for large-scale industrial deployment.
- RISE method selection lacks comprehensive validation across diverse edge deployment scenarios and computational efficiency testing on actual edge hardware.
- The integration of GPT-4 Vision for textual explanations may create computational bottlenecks and cost issues that are not addressed for practical industrial applications.

## Confidence

- **High confidence**: The core methodology of using DeepLabv3Plus for semantic segmentation and applying quantization/pruning for edge deployment is well-established and technically sound. The reported mIoU scores (75.48% for mobile model) are consistent with expected performance levels for this type of task.
- **Medium confidence**: The comparative analysis of XAI methods (RISE vs. GradCAM variants) appears methodologically rigorous, but the evaluation metrics used (EBPG, IoU, Bbox, Deletion, Insertion) may not fully capture the practical utility of explanations for domain experts. The framework's effectiveness depends heavily on the quality of domain expert interactions, which are not empirically validated.
- **Low confidence**: The claim that RISE is "the most advisable XAI method" lacks comprehensive validation across diverse edge deployment scenarios. The paper does not provide ablation studies or sensitivity analyses to demonstrate the framework's robustness to variations in dataset characteristics, model architectures, or deployment constraints.

## Next Checks

1. **Cross-domain generalization test**: Evaluate the framework on at least two additional industrial inspection datasets from different sectors (e.g., automotive manufacturing and electronics assembly) to assess its adaptability beyond the current application domain.

2. **Edge device performance validation**: Deploy the optimized models on actual edge hardware (e.g., NVIDIA Jetson, Raspberry Pi) to measure real-world inference latency, memory usage, and battery impact, comparing these metrics against the theoretical optimizations reported.

3. **A/B testing with domain experts**: Conduct controlled experiments with multiple domain experts using the framework versus traditional inspection methods, measuring both segmentation accuracy improvements and the practical value of XAI-generated explanations in reducing inspection time and error rates.