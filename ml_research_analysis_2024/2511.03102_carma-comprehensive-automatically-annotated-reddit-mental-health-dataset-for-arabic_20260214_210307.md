---
ver: rpa2
title: 'CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset
  for Arabic'
arxiv_id: '2511.03102'
source_url: https://arxiv.org/abs/2511.03102
tags:
- mental
- health
- arabic
- dataset
- diagnosed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CARMA, the first large-scale automatically
  annotated Arabic dataset for mental health research, covering six conditions (ADHD,
  Anxiety, Autism, Depression, OCD, Suicide) and a control group, with over 340K posts
  from Reddit. The authors leverage self-reported diagnosis patterns to identify users,
  then apply rigorous cleaning to ensure data quality.
---

# CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic
## Quick Facts
- arXiv ID: 2511.03102
- Source URL: https://arxiv.org/abs/2511.03102
- Reference count: 40
- Primary result: First large-scale automatically annotated Arabic mental health dataset covering six conditions and a control group

## Executive Summary
This paper introduces CARMA, the first large-scale automatically annotated Arabic dataset for mental health research, covering six conditions (ADHD, Anxiety, Autism, Depression, OCD, Suicide) and a control group, with over 340K posts from Reddit. The authors leverage self-reported diagnosis patterns to identify users, then apply rigorous cleaning to ensure data quality. Qualitative and quantitative analyses reveal distinct linguistic markers for each condition. Binary classification experiments using transformer embeddings and fine-tuned models achieve F1 scores up to 0.83 for Anxiety and 0.82 for OCD. CARMA significantly expands the scope and scale of Arabic mental health resources, enabling new research into underrepresented conditions and demonstrating the effectiveness of automated labeling in low-resource languages.

## Method Summary
The authors constructed CARMA by collecting Arabic Reddit posts and comments, then identifying users who self-reported mental health diagnoses using keyword patterns. They applied automated cleaning to remove irrelevant content, duplicate posts, and non-Arabic text. The dataset was organized into six mental health categories plus a control group, with users assigned to conditions based on self-reported diagnosis language. Quality validation was performed through manual inspection of a small sample, and linguistic analyses were conducted to identify condition-specific markers. Classification experiments used both transformer embeddings and fine-tuned models to evaluate predictive performance.

## Key Results
- Dataset contains over 340K posts covering six mental health conditions and a control group
- Classification models achieve F1 scores up to 0.83 for Anxiety and 0.82 for OCD
- Distinct linguistic markers identified for each mental health condition through qualitative and quantitative analysis

## Why This Works (Mechanism)
The approach leverages naturally occurring self-disclosure patterns in social media where users voluntarily share mental health diagnoses. By identifying consistent linguistic patterns around diagnosis announcements, the method can automatically label large volumes of text without requiring manual annotation. The use of transformer-based models enables effective capture of contextual and semantic features in Arabic text, while the large dataset size provides sufficient examples for robust model training. The automated annotation pipeline makes it feasible to scale mental health research in Arabic, a low-resource language for this domain.

## Foundational Learning
- Self-reported diagnosis identification: Understanding how users naturally disclose mental health conditions online is crucial for automated annotation. Quick check: Can the keyword patterns reliably distinguish between different conditions?
- Arabic NLP preprocessing: Arabic text requires specific cleaning and normalization steps due to its morphological complexity. Quick check: Are the cleaning steps removing noise while preserving diagnostic content?
- Transformer-based classification: Modern transformer models can capture contextual relationships in text that are important for mental health classification. Quick check: Does fine-tuning on CARMA improve over using pre-trained embeddings alone?

## Architecture Onboarding
Component map: Reddit data collection -> User identification -> Automated cleaning -> Dataset organization -> Model training -> Evaluation
Critical path: The user identification and automated cleaning steps are most critical, as errors here propagate through the entire pipeline. Misidentified users or insufficient cleaning would compromise dataset quality and downstream model performance.
Design tradeoffs: The authors chose an unsupervised, keyword-based labeling approach for scalability over supervised annotation for accuracy. This enables dataset creation at scale but introduces uncertainty in diagnostic accuracy. They also prioritized coverage of multiple conditions over deep analysis of any single condition.
Failure signatures: Poor user identification would result in noisy labels and reduced model performance. Inadequate cleaning could introduce irrelevant content that confuses models. Limited demographic diversity in Reddit users would reduce generalizability to broader Arabic-speaking populations.
First experiments:
1. Evaluate classification performance on a held-out test set with manual verification of labels
2. Compare model performance across different Arabic dialects present in the dataset
3. Test transferability of models trained on CARMA to clinical text or other Arabic social media platforms

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset relies exclusively on Reddit, limiting demographic and cultural diversity of Arabic speakers
- Automated labeling approach introduces uncertainty in diagnostic accuracy without clinical verification
- Small sample size for manual validation raises questions about generalizability of quality assessment

## Confidence
- CARMA is first large-scale automatically annotated Arabic mental health dataset: High
- Classification models achieve F1 scores up to 0.83 for Anxiety and 0.82 for OCD: Medium
- Distinct linguistic markers identified for each condition: High
- Automated labeling approach is effective for low-resource languages: Medium

## Next Checks
1. Conduct clinical validation studies to compare CARMA's labels with professional mental health assessments
2. Expand the dataset to include other Arabic social media platforms (e.g., Twitter, Telegram) to improve demographic and cultural diversity
3. Perform a longitudinal analysis to assess the stability and consistency of mental health indicators over time within the dataset