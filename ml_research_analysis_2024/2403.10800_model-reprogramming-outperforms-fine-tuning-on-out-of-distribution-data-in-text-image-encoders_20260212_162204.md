---
ver: rpa2
title: Model Reprogramming Outperforms Fine-tuning on Out-of-distribution Data in
  Text-Image Encoders
arxiv_id: '2403.10800'
source_url: https://arxiv.org/abs/2403.10800
tags:
- reprogrammer
- reprogramming
- fine-tuning
- detection
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the issue that fine-tuning pre-trained text-image
  encoders can degrade out-of-distribution (OOD) performance, both in terms of generalization
  to covariate-shifted data and detection of semantically-shifted data. To mitigate
  this, the authors introduce Reprogrammer, a model reprogramming technique that reprograms
  the image and text encoders without altering the pre-trained parameters.
---

# Model Reprogramming Outperforms Fine-tuning on Out-of-distribution Data in Text-Image Encoders

## Quick Facts
- arXiv ID: 2403.10800
- Source URL: https://arxiv.org/abs/2403.10800
- Reference count: 40
- Pre-trained text-image encoders can be fine-tuned without degrading OOD performance using model reprogramming techniques

## Executive Summary
This paper addresses the problem that fine-tuning pre-trained text-image encoders like CLIP can degrade out-of-distribution (OOD) performance, both in terms of generalization to covariate-shifted data and detection of semantically-shifted data. The authors introduce Reprogrammer, a model reprogramming technique that reprograms the image and text encoders without altering the pre-trained parameters, and Residual Reprogrammer, which adds a representation residual connection to further preserve pre-training representations. Experimental results show that both methods outperform common fine-tuning techniques in terms of in-distribution accuracy, OOD generalization, and OOD detection, with Residual Reprogrammer improving aggregated performance by +2.78% on CIFAR benchmarks and +0.69% on ImageNet-1k benchmarks compared to the next best method.

## Method Summary
The authors propose two reprogramming-based fine-tuning approaches for text-image encoders. Reprogrammer uses trainable input transformations (image and text reprogramming functions) that adapt data to the fixed pre-trained model without modifying its parameters, preserving the original feature space. Residual Reprogrammer extends this by adding a representation residual connection that interpolates between reprogrammed features and original pre-training features using a weighting parameter α, further anchoring the model to the pre-trained representation space. Both methods are evaluated on CIFAR-10 and ImageNet-1k benchmarks, comparing against zero-shot, linear probing, full fine-tuning, and other fine-tuning variants across in-distribution accuracy, OOD generalization, and OOD detection metrics.

## Key Results
- Reprogrammer and Residual Reprogrammer outperform common fine-tuning techniques across ID accuracy, OOD generalization, and OOD detection metrics
- Residual Reprogrammer improves aggregated performance by +2.78% on CIFAR benchmarks and +0.69% on ImageNet-1k benchmarks compared to the next best method
- Both methods show particular strength in OOD detection, reducing false positive rates while maintaining competitive ID accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Traditional fine-tuning techniques distort pre-training representations, degrading both OOD generalization and OOD detection performance.
- Mechanism: When fine-tuning updates model parameters directly, it shifts the feature space learned during pre-training. This shift improves ID accuracy but misaligns covariate-shifted OOD samples and increases overconfidence on semantically-shifted OOD samples.
- Core assumption: The pre-training representations encode useful priors for handling distribution shifts, and altering them harms robustness.
- Evidence anchors:
  - [abstract] "we demonstrate that commonly used fine-tuning methods not only distort the representations necessary for generalizing to covariate-shifted OOD samples (OOD generalization) but also distort the representations necessary for detecting semantically-shifted OOD samples (OOD detection)."
  - [section 1] "it has recently become apparent that common fine-tuning methods can distort the robust representations acquired during multi-modal pre-training, which can result in a decline in the fine-tuned model's OOD generalization performance."

### Mechanism 2
- Claim: Reprogramming maintains pre-training representations by not altering model parameters during training.
- Mechanism: Reprogramming uses trainable input transformations (e.g., learnable perturbations) that adapt data to the fixed pre-trained model, preserving the original feature space while aligning ID data to it.
- Core assumption: The fixed pre-trained encoder still provides discriminative features for the target task when data is appropriately transformed.
- Evidence anchors:
  - [abstract] "REPROGRAMMER aims to improve the holistic performance of the downstream model across ID, OOD generalization, and OOD detection tasks."
  - [section 3.3] "It is important to note that throughout the REPROGRAMMER training process, we impose no adjustments to any pre-trained model parameters. Thereby fundamentally limiting any distortion to the pre-training representations."

### Mechanism 3
- Claim: Residual connections in Residual Reprogrammer further preserve pre-training representations by blending reprogrammed and original features.
- Mechanism: The residual connection interpolates between reprogrammed features and original pre-training features (controlled by α), acting as a regularizer