---
ver: rpa2
title: Shallow Cross-Encoders for Low-Latency Retrieval
arxiv_id: '2403.20222'
source_url: https://arxiv.org/abs/2403.20222
tags:
- cross-encoders
- shallow
- training
- latency
- gbce
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Shallow transformer models trained with generalized Binary Cross-Entropy
  (gBCE) are more effective than full-scale transformers for low-latency retrieval,
  achieving up to 51% NDCG@10 improvement on TREC DL 2019 at 25ms latency. gBCE mitigates
  overconfidence issues in shallow models, and these models maintain effectiveness
  even with CPU-only inference (within 3% of GPU performance at 50ms latency).
---

# Shallow Cross-Encoders for Low-Latency Retrieval

## Quick Facts
- arXiv ID: 2403.20222
- Source URL: https://arxiv.org/abs/2403.20222
- Reference count: 40
- Key outcome: Shallow transformer models trained with gBCE achieve up to 51% NDCG@10 improvement on TREC DL 2019 at 25ms latency

## Executive Summary
This paper demonstrates that shallow transformer models trained with generalized Binary Cross-Entropy (gBCE) outperform full-scale transformers for low-latency retrieval tasks. The key insight is that reduced model depth allows scoring more documents within strict latency budgets, improving overall effectiveness despite lower accuracy per document pair. The gBCE training scheme mitigates overconfidence issues common in shallow models, while maintaining simplicity without requiring knowledge distillation. The approach is practical for production use, achieving near-GPU effectiveness even with CPU-only inference.

## Method Summary
The method trains shallow transformer models (TinyBERT, MiniBERT, SmallBERT) using a generalized Binary Cross-Entropy (gBCE) loss function that increases the number of negative samples per positive document and includes a calibration parameter t to reduce overconfidence. The training pipeline involves BM25 retrieval for candidate generation, followed by cross-encoder reranking with the shallow transformer. The gBCE loss is computed as: L = -1/N Σ [log(σ(f(x,y_i)))] + λ Σ log(1-σ(f(x,y_j))), where f represents the model's relevance score function and λ controls the contribution of negative samples.

## Key Results
- Shallow models achieve up to 51% NDCG@10 improvement on TREC DL 2019 at 25ms latency compared to full-scale models
- CPU-only inference maintains near-GPU effectiveness, with only 3% NDCG@10 decrease at 50ms latency
- gBCE training mitigates overconfidence issues in shallow models, improving effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shallow transformer models achieve higher NDCG@10 than full-scale models under low-latency constraints.
- Mechanism: Reduced model depth allows scoring more documents within the latency budget, increasing recall and overall effectiveness.
- Core assumption: The positive effect of scoring more documents outweighs the negative effect of reduced accuracy per document pair.
- Evidence anchors:
  - [abstract] "Shallow transformer models trained with generalized Binary Cross-Entropy (gBCE) are more effective than full-scale transformers for low-latency retrieval, achieving up to 51% NDCG@10 improvement on TREC DL 2019 at 25ms latency."
  - [section 2] "Equation (1) also shows that the number of scored documents K can be increased if we decrease model inference time λ."

### Mechanism 2
- Claim: gBCE training mitigates overconfidence issues in shallow models, improving effectiveness.
- Mechanism: gBCE loss function reduces model confidence compared to standard BCE, preventing unstable training from negative sampling.
- Core assumption: Shallow models are more susceptible to overconfidence from negative sampling than full-scale models.
- Evidence anchors:
  - [abstract] "gBCE mitigates overconfidence issues in shallow models"
  - [section 3] "Our initial experiments have shown that overconfidence does not cause effectiveness degradation of full-scale Cross-Encoder models... However, our experiments show... that overconfidence is indeed a problem in shallow cross-encoders."

### Mechanism 3
- Claim: CPU-only inference with shallow models maintains near-GPU effectiveness, enabling deployment without specialized hardware.
- Mechanism: Small model size (e.g., TinyBERT checkpoint 17Mb) enables efficient CPU inference while maintaining effectiveness.
- Core assumption: The latency difference between CPU and GPU inference becomes less significant as model size decreases.
- Evidence anchors:
  - [abstract] "shallow Cross-Encoders are effective even when used without a GPU (e.g., with CPU inference, NDCG@10 decreases only by 3% compared to GPU inference with 50ms latency)"
  - [section 4.4] "The figure shows that GPU inference is better than CPU inference, especially within the low latency zone. For example, with a 10ms latency window, the model with CPU inference only achieves NDCG@10 of 0.447, whereas the model with GPU inference achieves NDCG@10 of 0.573 (+28%). However, with a larger allowed latency, the difference decreases."

## Foundational Learning

- Concept: Binary Cross-Entropy (BCE) loss function
  - Why needed here: Understanding BCE vs gBCE is critical for implementing the training scheme
  - Quick check question: What happens to BCE loss when a model becomes overconfident on false positives?

- Concept: Negative sampling in ranking
  - Why needed here: The number of negatives per positive is a key hyperparameter in gBCE training
  - Quick check question: Why is negative sampling necessary in Cross-Encoder training despite causing overconfidence?

- Concept: Latency/effectiveness tradeoff
  - Why needed here: The core insight is that shallow models can be more effective under latency constraints
  - Quick check question: How does reducing model depth affect both inference time and ranking accuracy?

## Architecture Onboarding

- Component map:
  - BM25 retrieval -> shallow transformer encoder -> binary classification head -> softmax over relevance scores -> final ranking

- Critical path:
  1. BM25 retrieval to generate candidate set
  2. Tokenization and model inference for each query-document pair
  3. Probability calculation via softmax over relevance scores
  4. Ranking based on predicted relevance probabilities

- Design tradeoffs:
  - Model depth vs inference time vs ranking accuracy
  - Number of negative samples vs training stability
  - Calibration parameter t vs model confidence
  - CPU vs GPU inference performance

- Failure signatures:
  - Low NDCG@10 despite low latency → potential overconfidence or insufficient negative sampling
  - Extremely high predicted probabilities on irrelevant documents → model overconfidence
  - Poor performance on CPU → model too large for efficient CPU inference

- First 3 experiments:
  1. Compare NDCG@10 of shallow vs full-scale models at 25ms latency on TREC-DL 2019
  2. Evaluate impact of increasing negative samples (1, 8, 32, 128) on shallow model effectiveness
  3. Measure CPU vs GPU inference performance on TinyBERT-gBCE at 50ms latency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact form of the efficiency/effectiveness tradeoff function Q(K) ▷ ◁ ω for Cross-Encoder models under varying latency constraints?
- Basis in paper: [explicit] The paper states "Equation (1) defines the tradeoff between the latency window ω and the number of scored documents K" and "Overall, we can say that there exists a tradeoff between model performance Q(K) and the latency window ω" but notes "The exact form of this dependency is unknown"
- Why unresolved: The paper only establishes that this tradeoff exists but doesn't provide a mathematical model or empirical characterization of how exactly effectiveness degrades as latency constraints tighten
- What evidence would resolve it: Empirical measurements of Q(K) at various ω values across different datasets and model architectures, followed by fitting a mathematical function to characterize this relationship

### Open Question 2
- Question: What is the optimal number of negative samples for training shallow Cross-Encoders that balances effectiveness gains against computational costs?
- Basis in paper: [explicit] The paper shows "we observe from Table 2 that the effectiveness of the model only increases up to a certain number of negatives, after which the effectiveness fluctuates" and "Note that these numbers depend on how many candidate documents are re-ranked"
- Why unresolved: The paper only tests a limited range (1-128 negatives) and notes that optimal numbers depend on re-ranking depth, but doesn't establish general principles for selecting this hyperparameter
- What evidence would resolve it: Systematic experiments varying negative sample counts across multiple datasets, latency constraints, and re-ranking depths to establish generalizable patterns

### Open Question 3
- Question: How do shallow Cross-Encoders perform on non-English languages and domain-specific corpora?
- Basis in paper: [inferred] The paper focuses exclusively on English MS MARCO and TREC DL datasets, with a brief mention that knowledge distillation approaches "are hard to replicate for other settings (e.g. for different languages or other datasets)"
- Why unresolved: The evaluation is limited to English news passages, and the paper doesn't explore cross-linguistic generalization or performance on specialized domains like medical or legal text
- What evidence would resolve it: Experimental results on multilingual datasets (e.g., CLEF, FIRE) and domain-specific corpora (e.g., BioASQ, legal document collections) comparing shallow vs. full-scale models across languages and domains

## Limitations
- Limited evaluation to English datasets (MSMARCO, TREC DL) without testing multilingual or domain-specific corpora
- Lack of detailed implementation specifications for gBCE training, particularly calibration parameter t adaptation
- Hardware-specific results that may not generalize to different CPU/GPU architectures or specialized inference accelerators

## Confidence
**High Confidence Claims:**
- Shallow models achieve better NDCG@10 than full-scale models under 25ms latency constraints
- CPU-only inference maintains near-GPU effectiveness (within 3% NDCG@10 at 50ms latency)

**Medium Confidence Claims:**
- gBCE effectively mitigates overconfidence in shallow models
- The tradeoff between scoring more documents and reduced accuracy favors shallow models under latency constraints

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary the calibration parameter t (0.5, 0.75, 1.0) and number of negative samples (32, 64, 128) to determine their impact on shallow model effectiveness and overconfidence mitigation.

2. **Cross-Dataset Generalization**: Evaluate the proposed approach on additional retrieval benchmarks beyond TREC DL (e.g., MS MARCO Passage Ranking, Natural Questions) to assess whether the 51% improvement generalizes across domains.

3. **Training Protocol Replication**: Implement the complete gBCE training pipeline with detailed monitoring of predicted probabilities across ranks to empirically verify that overconfidence is reduced compared to standard BCE training on the same shallow architectures.