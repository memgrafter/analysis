---
ver: rpa2
title: 'Tacit algorithmic collusion in deep reinforcement learning guided price competition:
  A study using EV charge pricing game'
arxiv_id: '2401.15108'
source_url: https://arxiv.org/abs/2401.15108
tags:
- pricing
- hubs
- charging
- collusion
- power
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates tacit algorithmic collusion in dynamic pricing
  games among EV charging hubs using deep reinforcement learning (DRL). A two-step
  methodology combines stochastic optimization for day-ahead commitments with multi-agent
  DRL for real-time pricing.
---

# Tacit algorithmic collusion in deep reinforcement learning guided price competition: A study using EV charge pricing game

## Quick Facts
- arXiv ID: 2401.15108
- Source URL: https://arxiv.org/abs/2401.15108
- Authors: Diwas Paudel; Tapas K. Das
- Reference count: 32
- Key outcome: DRL-guided EV charging hubs can achieve tacit collusion with prices 1.26x power costs and collusion index 0.14-0.45

## Executive Summary
This paper investigates tacit algorithmic collusion in dynamic pricing games among EV charging hubs using deep reinforcement learning. The authors develop a two-step methodology combining stochastic optimization for day-ahead commitments with multi-agent DRL for real-time pricing. Numerical results show that competing hubs using DRL algorithms can settle on charge prices significantly higher than power costs, with collusion index values indicating low to moderate collusion. The choice of DRL algorithm (DQN vs SAC) significantly impacts pricing outcomes and collusion levels.

## Method Summary
The study employs a two-step methodology: first, a stochastic optimization model determines day-ahead power commitments using representative scenarios; second, a multi-agent DRL framework with DQN or SAC algorithms learns real-time pricing strategies. Hubs source power from day-ahead and real-time markets plus battery storage, with EV owners selecting the cheapest available hub or balking based on price sensitivity. The simulation uses historical PJM electricity prices and Tampa traffic data, with collusion levels measured using an index ranging from 0 (perfect competition) to 1 (monopoly).

## Key Results
- Competing hubs using DRL algorithms achieve charge prices 1.26 times higher than power costs
- Collusion index values range from 0.14 to 0.45, indicating low to moderate collusion
- SAC algorithm produces higher prices and collusion than DQN across different neural network architectures
- EV balking behavior significantly influences effective demand and collusion levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DRL algorithms can achieve tacit collusion without explicit communication by learning from past interactions.
- Mechanism: Agents adjust pricing based on observed competitor prices and demand responses, converging to supracompetitive equilibria over repeated episodes.
- Core assumption: The pricing game has repeated interactions with similar market conditions, enabling agents to learn stable strategies.
- Evidence anchors:
  - [abstract] "The repetition of this learning process in RL/DRL algorithms is claimed to result in some form of tacit collusion, yielding profits higher than in a competitive market."
  - [section 1] "The algorithm-guided players signal their intentions through actions, which all players take note of in choosing their future actions."
  - [corpus] Weak evidence - no direct citations to support the specific mechanism in this study.
- Break condition: Sudden changes in demand patterns, pricing constraints, or algorithm updates could disrupt learned collusive patterns.

### Mechanism 2
- Claim: Choice of DRL algorithm (DQN vs SAC) and neural network architecture impacts collusion levels.
- Mechanism: SAC promotes better exploration and higher entropy, leading to higher average prices and collusion. DQN's limited exploration and action space discretization may result in lower prices.
- Core assumption: Algorithm-architecture choices significantly affect exploration-exploitation trade-offs and action selection.
- Evidence anchors:
  - [section 5.4] "It can be observed that though the price profiles of the hubs for each combination have a similar pattern, the actual price values differ noticeably among the combinations."
  - [section 5.4] "The prices across the hours are relatively higher when both hubs use the SAC algorithm."
  - [corpus] Weak evidence - no direct citations to support the specific mechanism in this study.
- Break condition: Changes in algorithm hyperparameters or network architectures could alter the exploration-exploitation balance.

### Mechanism 3
- Claim: EV owners' price sensitivity and balking behavior modulate the effective demand, influencing pricing decisions and collusion levels.
- Mechanism: When EV owners balk, effective demand decreases, leading to lower prices and collusion. When balking is removed, demand remains higher, enabling higher prices and collusion.
- Core assumption: EV owners' price sensitivity and balking decisions significantly impact the demand curve.
- Evidence anchors:
  - [section 5.4] "When balking is removed, the EV owners always charge when a hub is available irrespective of prices. This keeps the demand intact and hence the hubs learn to set higher prices, which results in higher collusion."
  - [section 5.4] "When the number of EVs seeking to charge is increased by 50% with the balking probabilities maintained at baseline values, the effective charging demand was still lower than in the variant with no balking."
  - [corpus] Weak evidence - no direct citations to support the specific mechanism in this study.
- Break condition: Changes in EV owner preferences or market conditions could alter the demand curve and pricing dynamics.

## Foundational Learning

- Concept: Multi-agent deep reinforcement learning (MADRL)
  - Why needed here: To model the interactions between competing EV charging hubs and their pricing decisions.
  - Quick check question: What are the key differences between single-agent and multi-agent RL in pricing games?

- Concept: Tacit algorithmic collusion
  - Why needed here: To understand and quantify the level of collusion among DRL-guided agents in the EV charging market.
  - Quick check question: How does tacit algorithmic collusion differ from explicit collusion, and what are the antitrust implications?

- Concept: Markov decision process (MDP)
  - Why needed here: To model the dynamic pricing problem as a sequence of states, actions, and rewards.
  - Quick check question: What are the key components of an MDP, and how do they apply to the EV charging pricing problem?

## Architecture Onboarding

- Component map:
  - EV charging hubs (with DRL agents, neural networks, pricing strategies) -> Transportation network (EV demand and arrival patterns) -> Electric power network (day-ahead and real-time electricity prices) -> Battery storage system (power arbitrage) -> Simulation environment (orchestrates interactions)

- Critical path:
  1. Day-ahead commitment: Hubs solve a stochastic optimization model to determine hourly power commitments.
  2. Real-time pricing: Hubs use their DRL agents to make pricing decisions based on the current system state.
  3. EV response: EV owners select the cheapest available hub or decide not to charge based on the hub prices.
  4. Power management: Hubs solve a mixed integer linear program to minimize power procurement costs and maximize profits.
  5. System state update: The simulation environment updates the system state based on the EV response and power management decisions.

- Design tradeoffs:
  - Algorithm choice: SAC vs DQN affects exploration-exploitation balance and collusion levels.
  - Neural network architecture: Feed-forward vs multi-head attention impacts the agent's ability to learn complex pricing strategies.
  - Balking probability: Affects the effective demand and pricing dynamics.
  - Time interval: Hourly intervals simplify the problem but may miss short-term price fluctuations.

- Failure signatures:
  - High variance in pricing decisions or profits across episodes.
  - Low collusion index values despite high prices.
  - Inability to learn stable pricing strategies or converge to a collusive equilibrium.
  - Poor performance on unseen test data compared to training data.

- First 3 experiments:
  1. Implement a simple two-hub pricing game with fixed demand and no balking. Train both hubs using the same DRL algorithm and architecture.
  2. Vary the balking probability and observe its impact on pricing decisions and collusion levels.
  3. Compare the performance of SAC and DQN algorithms with different neural network architectures (feed-forward vs multi-head attention).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the level of tacit algorithmic collusion vary significantly across different geographic regions or market structures (e.g., urban vs rural, monopolistic vs oligopolistic markets)?
- Basis in paper: [inferred] The paper examines EV charging hubs in a specific road intersection scenario but doesn't explore geographic or market structure variations.
- Why unresolved: The study focuses on a single case study with two identical hubs in one location, limiting generalizability to different geographic or market conditions.
- What evidence would resolve it: Comparative studies examining collusion levels across diverse geographic regions and market structures using the same methodology.

### Open Question 2
- Question: How do different demand elasticity patterns affect the emergence and level of tacit algorithmic collusion in pricing games?
- Basis in paper: [explicit] The paper notes that EV owners are price sensitive but doesn't systematically explore different elasticity patterns.
- Why unresolved: The study uses a fixed price sensitivity parameter without exploring how varying elasticity might influence collusion outcomes.
- What evidence would resolve it: Experimental results comparing collusion levels across different demand elasticity scenarios using the same EV charging hub framework.

### Open Question 3
- Question: What is the long-term stability of tacit algorithmic collusion strategies learned through DRL, particularly under changing market conditions?
- Basis in paper: [inferred] The paper focuses on short-term pricing strategies but doesn't examine the durability of collusion under dynamic market conditions.
- Why unresolved: The study evaluates collusion over a fixed 32-test scenario period without exploring how strategies evolve or persist under changing conditions.
- What evidence would resolve it: Longitudinal studies tracking collusion levels over extended periods with varying market conditions and competitor behaviors.

## Limitations
- The simulation framework uses historical PJM electricity prices and traffic data from a single intersection, which may not capture broader market dynamics.
- The balking probability model, while capturing EV owner price sensitivity, remains a simplified representation of real-world behavior.
- The study focuses on a specific market structure (two competing hubs) that may not generalize to markets with more participants.

## Confidence
- High confidence in the technical implementation and simulation results, as the methodology follows established practices in MADRL and power systems optimization.
- Medium confidence in the collusion mechanism claims, given the indirect evidence and limited citations supporting the specific collusion dynamics observed.
- Low confidence in the generalizability of findings to other markets or regulatory contexts, as the study focuses on a specific EV charging scenario.

## Next Checks
1. **Parameter Sensitivity Analysis**: Systematically vary balking probabilities, EV demand patterns, and market conditions to assess the robustness of collusion outcomes across different scenarios.

2. **Multi-Hub Market Simulation**: Extend the model to include more than two competing hubs to examine how collusion dynamics change with increased market competition and whether more complex collusive patterns emerge.

3. **Regulatory Impact Assessment**: Evaluate how different regulatory interventions (price caps, monitoring systems, algorithmic transparency requirements) affect the emergence and sustainability of tacit algorithmic collusion in the modeled market.