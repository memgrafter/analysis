---
ver: rpa2
title: Scaling Laws for Online Advertisement Retrieval
arxiv_id: '2411.13322'
source_url: https://arxiv.org/abs/2411.13322
tags:
- scaling
- online
- revenue
- laws
- cost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a lightweight paradigm to identify online scaling
  laws for advertisement retrieval systems, addressing the high cost of obtaining
  scaling law parameters in industrial applications. The core idea is to use a novel
  offline metric, R/R, which strongly correlates with online revenue, and a simulation
  algorithm to estimate machine costs.
---

# Scaling Laws for Online Advertisement Retrieval

## Quick Facts
- arXiv ID: 2411.13322
- Source URL: https://arxiv.org/abs/2411.13322
- Reference count: 35
- Primary result: Proposed lightweight paradigm to identify online scaling laws for advertisement retrieval systems, validated in real-world advertising system with 0.85% and 2.8% improvements in online revenue.

## Executive Summary
This paper addresses the challenge of identifying scaling laws for online advertisement retrieval systems, which is crucial for optimizing model design and resource allocation but often prohibitively expensive in industrial settings. The authors propose a lightweight paradigm that transforms costly online experiments into low-cost offline experiments by introducing a novel offline metric (R/R*) that strongly correlates with online revenue and a simulation algorithm for machine cost estimation. They validate the existence of scaling laws for MLP models in a real-world advertising system and demonstrate practical applications, achieving significant improvements in online revenue through ROI-constrained model design and multi-scenario resource allocation.

## Method Summary
The authors propose a three-step approach: (1) train MLP models with varying sizes offline and evaluate them using a novel offline metric R/R* that incorporates eCPM values; (2) use a simulation algorithm to estimate machine costs based on model FLOPs and hardware constraints; (3) fit the collected data to the Broken Neural Scaling Law (BNSL) to establish the relationship between online revenue and machine cost. This transforms expensive online experiments into low-cost offline experiments, enabling efficient identification of scaling laws in industrial advertising systems.

## Key Results
- Established a strong linear correlation (0.996 R¬≤) between the offline metric R/R* and online revenue in real-world advertising systems
- Validated that MLP models in online advertisement retrieval follow Broken Neural Scaling Law with 0.996 R¬≤ fit
- Demonstrated practical applications achieving 0.85% and 2.8% improvements in online revenue through ROI-constrained model design and multi-scenario resource allocation

## Why This Works (Mechanism)

### Mechanism 1
The novel offline metric ùëÖ/ùëÖ* exhibits a strong linear correlation with online revenue due to its incorporation of eCPM values, which represent the commercial value of each ad. By explicitly considering the eCPM of each ad in the training data, ùëÖ/ùëÖ* directly reflects the goal of maximizing revenue in online advertising systems. This alignment between the metric and the business objective creates the strong linear relationship observed in the experiments. The linear correlation breaks down if Assumption 1 (proportional improvement) or Assumption 2 (top-ranked ad selection) no longer hold true.

### Mechanism 2
The Broken Neural Scaling Law (BNSL) accurately describes the relationship between FLOPs and the offline metric ùëÖ/ùëÖ* for MLP models in online advertisement retrieval. The BNSL formulation captures the diminishing returns of increasing computational cost, which is observed in the empirical data. The fitting of BNSL to the collected data points (with an R¬≤ value of 0.996) validates its applicability to this specific scenario. The BNSL relationship breaks down if the underlying architecture or optimization techniques used in the MLP models change significantly, or if the relationship between FLOPs and performance becomes non-monotonic.

### Mechanism 3
The machine cost estimation tool (MCET) provides accurate estimates of the required computational resources for deploying MLP models online. The MCET tool simulates the execution of models using the specified hardware configuration and measures the QPS under a given response time limit. By comparing the QPS of different models, it estimates the required number of machines for online serving. The MCET tool's accuracy degrades if the hardware configuration changes significantly, or if new optimizations are introduced that are not accounted for in the simulation.

## Foundational Learning

- Concept: Broken Neural Scaling Law (BNSL)
  - Why needed here: Understanding BNSL is crucial for interpreting the relationship between FLOPs and the offline metric ùëÖ/ùëÖ* in the context of online advertisement retrieval.
  - Quick check question: What is the key difference between BNSL and traditional power-law scaling, and how does this difference manifest in the empirical data?

- Concept: Learning-to-Rank (LTR) methods in online advertising
  - Why needed here: LTR methods are the primary optimization objective for retrieval stages in online advertising systems, and understanding their formulation is essential for interpreting the experimental setup and results.
  - Quick check question: How does the ARF loss function used in this paper differ from traditional LTR losses, and what is the motivation behind this difference?

- Concept: Multi-stage cascade ranking in online advertising
  - Why needed here: The paper focuses on the retrieval stages of a cascade ranking system, and understanding the overall architecture and the role of each stage is crucial for contextualizing the research.
  - Quick check question: What is the key difference between the retrieval and ranking stages in terms of their objectives and technical considerations?

## Architecture Onboarding

- Component map: MLP models with varying sizes -> Offline metric ùëÖ/ùëÖ* calculation -> Machine cost estimation tool (MCET) -> Simulation algorithm for offline cost estimation -> Online advertising system with retrieval and ranking stages

- Critical path:
  1. Train MLP models with different sizes offline
  2. Calculate FLOPs and ùëÖ/ùëÖ* for each model
  3. Fit BNSL to the collected data points
  4. Use MCET to estimate machine costs for each model
  5. Establish the scaling law between online revenue and machine cost
  6. Apply the scaling law to optimize model design and resource allocation

- Design tradeoffs:
  - Model size vs. computational cost: Larger models may provide better performance but require more computational resources.
  - Offline metric vs. online revenue: While ùëÖ/ùëÖ* exhibits a strong linear correlation with online revenue, there may still be some gap between the two.
  - Simulation accuracy vs. computational cost: More accurate simulations may require more computational resources, but less accurate simulations may lead to suboptimal resource allocation.

- Failure signatures:
  - Poor fit of BNSL to the empirical data (low R¬≤ value)
  - Large discrepancies between estimated and actual machine costs
  - Weak linear correlation between ùëÖ/ùëÖ* and online revenue

- First 3 experiments:
  1. Train a small set of MLP models with varying sizes and calculate their FLOPs and ùëÖ/ùëÖ* values to verify the initial relationship between these variables.
  2. Use the MCET tool to estimate machine costs for the trained models and compare them with actual costs to validate the tool's accuracy.
  3. Fit BNSL to the collected data points and assess the quality of the fit (R¬≤ value) to ensure the applicability of the scaling law to this specific scenario.

## Open Questions the Paper Calls Out

### Open Question 1
Can the R/R* metric be generalized to other online advertising systems beyond Kuaishou's, and how does its effectiveness vary across different ad retrieval architectures? The paper validates R/R* in Kuaishou's system but notes that varying settings across different systems prevent the scaling law from being universally applicable. Testing R/R* across multiple advertising systems with different retrieval architectures would determine its broader applicability.

### Open Question 2
How do scaling laws differ when considering joint optimization of multiple factors (e.g., data size, model parameters, and FLOPs) rather than single-variable scaling laws? The paper demonstrates single-variable scaling laws but doesn't explore the more complex joint scaling relationships due to experimental cost constraints. Developing cost-effective methods to derive joint scaling laws and validating them across multiple advertising scenarios would reveal how multiple factors interact in real-world systems.

### Open Question 3
What is the optimal distribution of layer units in MLP models under a given FLOPs constraint, and how does this impact scaling law predictions? While the paper uses empirical constraints on layer unit differences, it doesn't provide a theoretical framework for optimal unit distribution under FLOPs constraints. Systematic experiments testing different unit distributions under fixed FLOPs budgets would establish optimal design principles.

## Limitations

- The generalizability of the R/R* metric and its correlation with online revenue to other advertising systems or domains remains uncertain
- The accuracy of the machine cost estimation tool may degrade when applied to different hardware configurations or when new optimizations are introduced
- The extension of identified scaling laws to other model architectures or tasks within the advertising domain is unclear

## Confidence

**High Confidence**:
- The existence of a strong linear correlation between the offline metric R/R* and online revenue in the studied advertising system
- The applicability of the Broken Neural Scaling Law (BNSL) to describe the relationship between FLOPs and R/R* for MLP models in this specific scenario

**Medium Confidence**:
- The generalizability of the R/R* metric and its correlation with online revenue to other advertising systems or domains
- The accuracy and applicability of the machine cost estimation tool (MCET) to different hardware configurations or optimizations

**Low Confidence**:
- The extension of the identified scaling laws to other model architectures or tasks within the advertising domain
- The applicability of the findings to completely different domains beyond online advertising

## Next Checks

1. **Metric Generalization**: Conduct experiments in a different advertising system or domain to validate the generalizability of the R/R* metric and its correlation with online revenue. Assess whether the assumptions required for the theoretical proof of this correlation hold in the new setting.

2. **Simulation Validation**: Compare the machine cost estimates from the MCET tool with actual costs obtained through online deployment on different hardware configurations. Identify any discrepancies and investigate the factors contributing to the differences.

3. **Scaling Law Extension**: Apply the methodology to other model architectures commonly used in advertising retrieval systems, such as transformer-based models. Investigate whether similar scaling laws exist and assess the differences in the relationship between FLOPs, model performance, and machine cost compared to MLP models.