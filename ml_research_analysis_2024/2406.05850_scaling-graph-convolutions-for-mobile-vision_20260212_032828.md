---
ver: rpa2
title: Scaling Graph Convolutions for Mobile Vision
arxiv_id: '2406.05850'
source_url: https://arxiv.org/abs/2406.05850
tags:
- graph
- vision
- mobile
- mobilevigv2
- svga
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Mobile Graph Convolution (MGC), a fast and
  scalable vision graph neural network module that addresses the scaling limitations
  of MobileViG. MGC improves upon the previous Sparse Vision Graph Attention (SVGA)
  by using sparser graph connections (5 vs 7 per token) and introducing conditional
  positional encodings to the graph operation.
---

# Scaling Graph Convolutions for Mobile Vision

## Quick Facts
- arXiv ID: 2406.05850
- Source URL: https://arxiv.org/abs/2406.05850
- Authors: William Avery; Mustafa Munir; Radu Marculescu
- Reference count: 33
- Primary result: MobileViGv2 achieves state-of-the-art mobile vision performance with faster graph convolutions

## Executive Summary
This paper introduces Mobile Graph Convolution (MGC), a fast and scalable vision graph neural network module that addresses the scaling limitations of MobileViG. MGC improves upon the previous Sparse Vision Graph Attention (SVGA) by using sparser graph connections (5 vs 7 per token) and introducing conditional positional encodings to the graph operation. These changes allow MGC to be used in higher resolution stages without significant latency impact. The authors demonstrate the effectiveness of MGC through MobileViGv2, a CNN-ViG-based mobile architecture.

## Method Summary
The authors developed Mobile Graph Convolution (MGC) by addressing two key limitations of MobileViG's SVGA module: computational cost in high-resolution stages and insufficient positional encoding. MGC reduces graph connectivity from 7 to 5 connections per token, significantly decreasing computational complexity while maintaining representational power. The introduction of conditional positional encodings allows the model to better leverage spatial relationships within the graph structure. These modifications enable MGC to scale effectively across all stages of mobile vision architectures without introducing prohibitive latency overhead.

## Key Results
- MobileViGv2-Ti achieves 77.7% top-1 accuracy on ImageNet-1K with 0.9 ms latency, outperforming MobileViG-Ti by 2% accuracy at similar latency
- MobileViGv2-B achieves 83.4% top-1 accuracy, 0.8% higher than MobileViG-B, with 2.7 ms latency
- MobileViGv2 shows strong generalization to downstream tasks, outperforming MobileViG on COCO object detection (1.2 AP box, 0.7 AP mask) and ADE20K semantic segmentation (1.4% mIoU)

## Why This Works (Mechanism)
MGC works by addressing the fundamental trade-off between computational efficiency and representational capacity in vision graph neural networks. By reducing graph connections from 7 to 5 per token, the computational complexity decreases quadratically while maintaining sufficient connectivity for effective information propagation. The conditional positional encodings provide dynamic spatial awareness that adapts to different input contexts, allowing the model to better capture spatial relationships without the computational overhead of full positional encoding schemes. This combination enables MGC to maintain high performance while scaling to higher resolution stages where computational resources are more constrained.

## Foundational Learning

### Graph Neural Networks
- **Why needed**: GNNs enable non-local information propagation across visual tokens, capturing long-range dependencies that traditional convolutional layers cannot efficiently model
- **Quick check**: Verify that graph attention mechanisms can be parallelized for efficient GPU implementation

### Vision Transformer Scaling Challenges
- **Why needed**: ViTs face quadratic complexity with sequence length, making them difficult to deploy in mobile settings with high-resolution inputs
- **Quick check**: Confirm that spatial reduction techniques (pooling, convolution) can effectively reduce sequence length without losing critical information

### Mobile Architecture Design Principles
- **Why needed**: Mobile models must balance accuracy with strict latency constraints, requiring careful consideration of computational efficiency at every layer
- **Quick check**: Ensure latency measurements account for hardware-specific optimizations and batch size effects

## Architecture Onboarding

### Component Map
MobileViGv2 architecture: Input -> Convolutional Stem -> Mobile Graph Convolution Blocks -> Classification Head
MGC block components: Input tokens -> Sparsification (5 connections) -> Conditional Positional Encoding -> Graph Attention -> Output tokens

### Critical Path
The critical path involves the Mobile Graph Convolution blocks, where the reduced connectivity (5 vs 7 connections) and conditional positional encodings directly impact both accuracy and latency. The convolutional stem provides initial feature extraction, while the classification head performs final prediction based on the aggregated graph features.

### Design Tradeoffs
The primary tradeoff involves reducing graph connectivity to improve computational efficiency while maintaining sufficient representational capacity. The authors chose 5 connections based on empirical evaluation, balancing the need for local and non-local information flow against computational constraints. The conditional positional encodings represent another tradeoff between spatial awareness and computational overhead, with the conditional approach providing adaptive benefits without the full cost of traditional positional encodings.

### Failure Signatures
Potential failure modes include insufficient graph connectivity leading to poor information propagation, especially for fine-grained visual features. Overly aggressive sparsification could result in loss of important long-range dependencies. Inadequate positional encoding might cause the model to struggle with spatial reasoning tasks. These failures would manifest as accuracy drops, particularly in tasks requiring precise spatial understanding or fine-grained classification.

### First Experiments
1. Ablation study comparing MGC with 5 vs 7 connections to isolate the impact of connectivity reduction
2. Evaluation of conditional vs fixed positional encodings to measure the benefit of adaptive spatial awareness
3. Latency benchmarking across different batch sizes and hardware platforms to verify scalability claims

## Open Questions the Paper Calls Out
None

## Limitations
- Performance claims are primarily based on ImageNet-1K classification benchmarks, with downstream task evaluations showing consistent but modest improvements (1-2% gains)
- The relative contribution of key innovations (reduced connections and conditional positional encodings) versus overall MobileViGv2 architecture design remains unclear from provided ablation studies
- Latency measurements lack detailed methodology regarding measurement conditions, hardware specifications, or comparison baselines

## Confidence
- **High confidence**: MGC's architectural improvements and general effectiveness
- **Medium confidence**: Specific latency measurements and their comparison methodology
- **Medium confidence**: Downstream task generalization results, though sample size is limited

## Next Checks
1. Conduct controlled ablation studies isolating the impact of reducing graph connections from 7 to 5 and the introduction of conditional positional encodings
2. Perform comprehensive latency benchmarking across multiple hardware platforms (different mobile SoCs) and batch sizes to verify scalability claims
3. Evaluate MobileViGv2 on additional downstream tasks (e.g., instance segmentation, depth estimation) to assess broader generalization capabilities