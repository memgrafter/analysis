---
ver: rpa2
title: 'HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator'
arxiv_id: '2411.17261'
source_url: https://arxiv.org/abs/2411.17261
tags:
- image
- implausibility
- arxiv
- score
- heatmap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HEIE, an MLLM-based hierarchical explainable
  AIGC image implausibility evaluator that addresses the limitations of existing specialized
  models and MLLMs in detecting and explaining image defects. The method introduces
  a CoT-Driven Explainable Trinity Evaluator that integrates heatmaps, scores, and
  explanations through Chain-of-Thought prompting, and an Adaptive Hierarchical Implausibility
  Mapper that combines low-level image features with high-level LLM tokens for precise
  defect localization.
---

# HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator

## Quick Facts
- arXiv ID: 2411.17261
- Source URL: https://arxiv.org/abs/2411.17261
- Reference count: 40
- Primary result: Proposes HEIE system achieving state-of-the-art performance on AIGC image implausibility evaluation with MSE of 0.00825

## Executive Summary
This paper introduces HEIE, a hierarchical explainable AIGC image implausibility evaluator that addresses limitations of existing specialized models and MLLMs in detecting and explaining image defects. The method combines Chain-of-Thought (CoT) prompting with an Adaptive Hierarchical Implausibility Mapper to produce heatmaps, scores, and explanations for AI-generated image defects. The authors also construct Expl-AIGI-Eval, a new dataset designed for interpretable AIGC image evaluation.

## Method Summary
HEIE integrates a CoT-Driven Explainable Trinity Evaluator that decomposes complex image evaluation into five sequential subtasks, enhancing LLM reasoning through progressively difficult steps. An Adaptive Hierarchical Implausibility Mapper combines low-level image features with high-level LLM tokens using uncertainty-based fusion to achieve precise defect localization. The system is trained on Expl-AIGI-Eval, a dataset constructed through visual prompting, LLM free-form outputting, and in-context learning-based formatting stages.

## Key Results
- Achieves state-of-the-art performance with MSE of 0.00825, KLD of 1.634, CC of 0.574 on RichHF-18K dataset
- Outperforms baselines on heatmap prediction and explanation quality tasks
- Successfully generates interpretable explanations for AIGC image defects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CoT-Driven Explainable Trinity Evaluator decomposes complex image evaluation into progressively difficult subtasks that enhance LLM reasoning and produce mutually reinforcing outputs.
- Mechanism: The system breaks evaluation into 5 sequential steps (image description → problematic regions identification →