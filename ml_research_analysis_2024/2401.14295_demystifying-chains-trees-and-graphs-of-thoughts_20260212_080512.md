---
ver: rpa2
title: Demystifying Chains, Trees, and Graphs of Thoughts
arxiv_id: '2401.14295'
source_url: https://arxiv.org/abs/2401.14295
tags:
- reasoning
- prompting
- graph
- tree
- topology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a comprehensive taxonomy and blueprint for
  structure-enhanced large language model (LLM) reasoning schemes, focusing on the
  underlying reasoning topology. The authors formalize the LLM reasoning process as
  a graph topology, analyzing different classes of graphs (chains, trees, graphs)
  and their representations, derivations, and schedules.
---

# Demystifying Chains, Trees, and Graphs of Thoughts

## Quick Facts
- arXiv ID: 2401.14295
- Source URL: https://arxiv.org/abs/2401.14295
- Reference count: 40
- Key outcome: Introduces a comprehensive taxonomy and blueprint for structure-enhanced LLM reasoning schemes, showing that graph-based approaches like GoT outperform chain and tree methods across various tasks while offering better computational efficiency.

## Executive Summary
This paper presents a systematic analysis of structure-enhanced large language model reasoning schemes, introducing a taxonomy that categorizes approaches based on their underlying reasoning topology (chains, trees, graphs). The authors analyze 37 existing schemes, identifying fundamental aspects like topology class, representation, and reasoning schedule, and evaluate their performance tradeoffs between latency and quality. Their findings show that graph-based schemes consistently outperform chain and tree-based methods across various reasoning tasks while offering better computational efficiency. The study also highlights open challenges in automatic topology derivation and novel scheduling approaches, paving the way for more advanced prompting techniques.

## Method Summary
The authors systematically analyze 37 existing LLM reasoning schemes by classifying them into a taxonomy based on three key architectural aspects: topology class (chain, tree, graph), representation (explicit vs. implicit), and reasoning schedule (BFS, DFS, etc.). They conduct a qualitative performance comparison by aggregating results from literature across multiple benchmark tasks including arithmetic reasoning, commonsense reasoning, and symbolic reasoning. The analysis focuses on identifying patterns in how different topology classes perform across task categories and what architectural choices lead to better performance. While not all schemes are directly implemented and tested, the paper provides a comprehensive framework for understanding and comparing these approaches.

## Key Results
- Graph-based schemes like GoT consistently outperform chain and tree-based methods across various tasks while using fewer tokens
- Tree-based schemes enable exploration of multiple reasoning paths, improving upon basic chain approaches
- Chain-of-Thought methods improve performance by introducing explicit intermediate reasoning steps between input and output
- The paper identifies key architectural tradeoffs between single-prompt vs. multi-prompt topologies and explicit vs. implicit representation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph of Thoughts (GoT) consistently outperforms chain and tree-based methods across various tasks due to its ability to aggregate multiple thoughts into synergistic solutions.
- Mechanism: GoT enables arbitrary graph-based thought transformations, including aggregation operations where multiple parent thoughts combine to form a new, potentially better solution.
- Core assumption: The aggregation of multiple reasoning paths creates solutions that are more effective than any single path.
- Evidence anchors:
  - [abstract]: "Graph-based schemes like GoT [10] improve arithmetic and multi-hop reasoning efficiency, often using fewer tokens than tree-based methods."
  - [section 8.1]: "GoT further improves performance by integrating cumulative reasoning across steps thanks to its aggregation capabilities, reducing error propagation."
  - [corpus]: Weak or missing - no direct corpus evidence found for this specific aggregation mechanism.

### Mechanism 2
- Claim: Tree-based schemes improve upon chain-based methods by enabling exploration of multiple reasoning paths at each decision point.
- Mechanism: Tree structures allow the LLM to generate multiple new thoughts from a given thought, exploring different reasoning branches and selecting the most promising path.
- Core assumption: Exploring multiple reasoning paths increases the likelihood of finding optimal solutions compared to following a single linear path.
- Evidence anchors:
  - [abstract]: "Tree-based schemes bring the possibility to explore several next-step variants at each juncture, allowing the LLM to evaluate multiple pathways and select the most promising one."
  - [section 6.4.1]: "The key novel architectural feature of tree schemes is the exploration of a thought, i.e., the ability to generate multiple new steps based on a given single one."
  - [corpus]: Weak or missing - no direct corpus evidence found for this specific exploration mechanism.

### Mechanism 3
- Claim: Chain-based prompting improves upon basic IO prompting by introducing explicit intermediate reasoning steps that guide the LLM through step-by-step problem solving.
- Mechanism: Chain-of-Thought methods add intermediate thoughts between input and output, creating a linear sequence that guides the LLM through reasoning steps before providing the final answer.
- Core assumption: Explicit intermediate reasoning steps help the LLM understand and solve complex problems better than direct input-output approaches.
- Evidence anchors:
  - [abstract]: "Chain topologies, introduced in Chain-of-Thought by Wei et al. [199], improve upon IO prompting by incorporating explicit intermediate 'steps of reasoning' in addition to the input and output."
  - [section 5.1]: "The concept of multi-step reasoning was first introduced through the seminal Chain-of-Thought (CoT)[199], a single-prompt scheme, which uses topologies of in-context examples to guide the LLM into reasoning step-by-step before providing the final answer."
  - [corpus]: Weak or missing - no direct corpus evidence found for this specific chain mechanism.

## Foundational Learning

- Concept: Graph theory fundamentals (nodes, edges, paths, trees, graphs)
  - Why needed here: Understanding these concepts is essential for grasping how different reasoning topologies (chains, trees, graphs) are modeled and compared in the paper.
  - Quick check question: What is the difference between a tree and a general graph in terms of node connectivity constraints?

- Concept: Prompt engineering basics (few-shot, zero-shot, in-context learning)
  - Why needed here: The paper builds upon these fundamental prompting techniques to create more complex reasoning structures.
  - Quick check question: How does few-shot prompting differ from zero-shot prompting in terms of examples provided?

- Concept: Large language model inference mechanics (token generation, context windows)
  - Why needed here: Understanding LLM limitations and capabilities is crucial for evaluating the practical tradeoffs of different reasoning topologies.
  - Quick check question: What is the primary constraint that affects how complex reasoning structures can be encoded within a single LLM prompt?

## Architecture Onboarding

- Component map: User prompt → preprocessing → context update → LLM generation → post-processing → context update → reply to user. For structured reasoning, this path is repeated with topology management.
- Critical path: User prompt → preprocessing → context update → LLM generation → post-processing → context update → reply to user. For structured reasoning, this path is repeated with topology management.
- Design tradeoffs: Single-prompt vs. multi-prompt topologies (cost vs. complexity), explicit vs. implicit topology representation (clarity vs. token efficiency), user control vs. LLM autonomy in topology construction.
- Failure signatures: Poor performance on complex tasks despite structured reasoning, excessive token usage compared to simpler approaches, inability to scale with problem complexity, suboptimal topology construction leading to dead ends.
- First 3 experiments:
  1. Implement Chain-of-Thought with self-consistency on GSM8K dataset and compare against basic IO prompting.
  2. Extend the CoT implementation to Tree-of-Thoughts with BFS exploration on the same dataset.
  3. Implement Graph of Thoughts aggregation operations on a set intersection problem and compare token efficiency against tree-based approaches.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can reasoning topologies be automatically derived for complex tasks without manual intervention?
- Basis in paper: [explicit] The paper identifies "automatic derivation of tree and graph topologies" as an open research challenge.
- Why unresolved: Current schemes rely on manual or semi-automatic construction, which limits scalability and accessibility.
- What evidence would resolve it: Development of machine learning algorithms that can identify and implement effective topologies based on task nature and data characteristics.

### Open Question 2
- Question: What are the optimal scheduling algorithms for graph-based reasoning topologies to balance latency and computational efficiency?
- Basis in paper: [explicit] The paper highlights the need to investigate new scheduling approaches beyond standard BFS, DFS, or manually designed algorithms.
- Why unresolved: Existing scheduling algorithms may not adapt well to the dynamic and interconnected nature of graph-based reasoning.
- What evidence would resolve it: Empirical studies comparing the performance of adaptive scheduling algorithms with traditional ones across various reasoning tasks.

### Open Question 3
- Question: How can hypergraphs be effectively utilized in reasoning topologies to capture more complex relationships in data?
- Basis in paper: [explicit] The paper suggests exploring hypergraph classes for more effective and efficient reasoning topologies.
- Why unresolved: Hypergraphs are underutilized in current prompting schemes, and their full potential for modeling complex relationships is not yet realized.
- What evidence would resolve it: Implementation of hypergraph-based reasoning schemes that demonstrate improved performance on tasks requiring complex relationship modeling.

## Limitations

- The analysis relies heavily on qualitative aggregation of existing literature rather than direct experimental validation across all 37 schemes
- Exact implementation details and hyperparameters for many analyzed schemes are not fully specified, making direct replication challenging
- Performance comparisons across different schemes may be confounded by varying experimental conditions, model versions, and evaluation protocols

## Confidence

- **High Confidence**: The taxonomy framework itself (classifying schemes by topology, representation, and schedule) and the basic structural comparisons between chain, tree, and graph approaches
- **Medium Confidence**: The performance comparisons between topology classes across different task categories, as these rely on literature aggregation that may have confounding variables
- **Low Confidence**: The specific mechanisms proposed for why graph-based approaches outperform others (particularly the aggregation benefits), as these are primarily theoretical and lack direct experimental validation

## Next Checks

1. **Direct Experimental Comparison**: Implement a controlled experiment comparing Chain-of-Thought, Tree of Thoughts, and Graph of Thoughts on the same benchmark (e.g., GSM8K) with identical model configurations, temperature settings, and stopping criteria to isolate the effects of topology class from implementation differences.

2. **Mechanism Validation**: Design an ablation study that tests the aggregation mechanism in Graph of Thoughts by comparing: (a) full GoT with aggregation, (b) GoT without aggregation (just graph exploration), and (c) Tree of Thoughts with equivalent exploration depth. This would directly test whether aggregation provides the claimed benefits.

3. **Scaling Analysis**: Evaluate how each topology class performs as problem complexity increases, measuring not just accuracy but also token efficiency and reasoning depth. This would validate the claim that graph-based approaches offer better computational efficiency while maintaining or improving quality as problems become more complex.