---
ver: rpa2
title: 'M-CELS: Counterfactual Explanation for Multivariate Time Series Data Guided
  by Learned Saliency Maps'
arxiv_id: '2411.02649'
source_url: https://arxiv.org/abs/2411.02649
tags:
- time
- series
- counterfactual
- multivariate
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces M-CELS, a novel counterfactual explanation
  method for multivariate time series classification that addresses the interpretability
  challenge in opaque ML models. The approach extends the CELS framework by learning
  multi-dimensional saliency maps that guide targeted perturbations of influential
  time steps across multiple dimensions.
---

# M-CELS: Counterfactual Explanation for Multivariate Time Series Data Guided by Learned Saliency Maps

## Quick Facts
- arXiv ID: 2411.02649
- Source URL: https://arxiv.org/abs/2411.02649
- Reference count: 23
- Outperforms state-of-the-art baselines in validity, proximity, and sparsity metrics for multivariate time series counterfactual explanations

## Executive Summary
This paper introduces M-CELS, a novel counterfactual explanation method for multivariate time series classification that addresses the interpretability challenge in opaque ML models. The approach extends the CELS framework by learning multi-dimensional saliency maps that guide targeted perturbations of influential time steps across multiple dimensions. M-CELS optimizes a loss function balancing validity (maximizing target class probability), sparsity (minimizing salient time steps), and temporal coherence (ensuring smooth saliency transitions). Experiments on seven real-world UEA datasets demonstrate that M-CELS outperforms state-of-the-art baselines including Alibi, NG-CF, and AB-CF, achieving superior performance in validity (highest target probability), proximity (lowest L1 distance), and sparsity (highest percentage of unchanged data points). The method provides interpretable, actionable counterfactual explanations that help users understand model decisions in critical applications where transparency is essential.

## Method Summary
M-CELS is a counterfactual explanation method for multivariate time series classification that learns multi-dimensional saliency maps to guide targeted perturbations. The method uses a nearest unlike neighbor (NUN) replacement strategy from a background dataset to ensure in-distribution perturbations, while a fully convolutional neural network classifier serves as the base model. The core innovation involves optimizing a three-component loss function (LMMax, LMBudget, LMTReg) that balances validity, sparsity, and temporal coherence through gradient descent. The learned saliency map θ ∈ [0,1]^(T×D) identifies the most influential time steps across all dimensions, which are then perturbed using the NUN strategy to generate counterfactual explanations that are valid, proximate, and sparse.

## Key Results
- M-CELS achieves the highest target class probability (validity) across all seven UEA datasets compared to Alibi, NG-CF, and AB-CF baselines
- The method produces the lowest L1 distance (proximity) to original instances while maintaining interpretability
- M-CELS demonstrates the highest sparsity (percentage of unchanged data points) indicating minimal perturbations for maximum effect
- The learned multi-dimensional saliency maps effectively identify influential time steps across multiple dimensions simultaneously

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-dimensional saliency map learning enables targeted perturbations that maintain interpretability across all dimensions while improving validity and sparsity.
- Mechanism: M-CELS learns a saliency map θ ∈ [0,1]^(T×D) that captures the importance of each time step across all dimensions simultaneously. This allows the method to identify and perturb only the most influential features, rather than treating each dimension independently or modifying entire dimensions uniformly.
- Core assumption: The importance of a time step in multivariate time series reflects how much the model's prediction probability changes when that time step is perturbed, and this relationship can be captured through learned saliency values.
- Evidence anchors:
  - [abstract] "M-CELS optimizes a loss function balancing validity (maximizing target class probability), sparsity (minimizing salient time steps), and temporal coherence (ensuring smooth saliency transitions)"
  - [section] "Our goal is to learn a saliency map θ ∈ [0, 1]^(D×T) for the class of interest z where each element represents the importance of a corresponding time step at a corresponding dimension"
  - [corpus] Weak evidence - related papers focus on physics-guided or sparse counterfactuals but don't provide direct evidence for the multi-dimensional saliency approach
- Break Condition: If the saliency map fails to capture cross-dimensional interactions or if important features are distributed across multiple dimensions in ways that can't be isolated through the learned map.

### Mechanism 2
- Claim: The three-component loss function (LMMax, LMBudget, LMTReg) effectively balances the competing objectives of validity, sparsity, and temporal coherence in multivariate settings.
- Mechanism: The loss function combines: LMMax to maximize target class probability (validity), LMBudget to minimize average saliency values across dimensions (sparsity), and LMTReg to ensure temporal smoothness across dimensions (coherence). The λ coefficient balances these competing objectives.
- Core assumption: These three objectives can be simultaneously optimized through gradient descent and that the weighting factor λ can appropriately balance their relative importance.
- Evidence anchors:
  - [abstract] "M-CELS optimizes a loss function balancing validity (maximizing target class probability), sparsity (minimizing salient time steps), and temporal coherence (ensuring smooth saliency transitions)"
  - [section] "L(P (ˆy | x); θ) = λ ∗ LMMax + LMBudget + LMTReg" with detailed equations for each component
  - [corpus] Limited direct evidence - most related work focuses on single-objective optimization or heuristic approaches
- Break Condition: If the λ parameter cannot be tuned effectively across different datasets, or if optimizing one objective consistently degrades the others beyond acceptable thresholds.

### Mechanism 3
- Claim: The Nearest Unlike Neighbor (NUN) replacement strategy provides in-distribution perturbations that maintain the semantic meaning of counterfactuals while enabling meaningful explanations.
- Mechanism: M-CELS uses the NUN from the background dataset to guide perturbations, ensuring that replaced time steps come from instances that are both similar to the original and from a different class. This maintains data distribution properties while creating meaningful counterfactuals.
- Core assumption: The nearest unlike neighbor represents a valid and interpretable counterfactual direction, and the background dataset contains sufficient diversity to enable meaningful perturbations across all classes.
- Evidence anchors:
  - [section] "NG [9] generates in-distribution perturbations by replacing time steps with those from the nearest unlike neighbor in a background dataset D. Inspired by NG, CELS similarly selects the nearest unlike neighbor time series"
  - [section] "The Nearest Unlike Neighbor replacement strategy and the counterfactual perturbation function, initially designed for univariate time series data, seamlessly extend to multivariate time series data"
  - [corpus] Moderate evidence - several related papers use NUN strategies but with different implementation details
- Break Condition: If the background dataset is too homogeneous, too small, or if nearest unlike neighbors are too dissimilar to enable meaningful perturbations.

## Foundational Learning

- Concept: Multivariate time series classification fundamentals
  - Why needed here: Understanding how time series data with multiple dimensions is represented and processed is crucial for implementing the M-CELS framework correctly
  - Quick check question: How is a multivariate time series mathematically represented in the context of M-CELS, and what are the dimensions of the input space?

- Concept: Counterfactual explanation principles
  - Why needed here: The entire M-CELS approach builds on counterfactual explanation theory, requiring understanding of what makes an explanation valid, proximate, and sparse
  - Quick check question: What are the three key properties that define an ideal counterfactual explanation according to the M-CELS framework?

- Concept: Saliency map learning and optimization
  - Why needed here: The core innovation of M-CELS involves learning multi-dimensional saliency maps through optimization, requiring knowledge of loss functions and gradient-based learning
  - Quick check question: How does the loss function in M-CELS balance the three competing objectives, and what role does the λ coefficient play?

## Architecture Onboarding

- Component map: M-CELS consists of four main components: (1) Nearest Unlike Neighbor finder, (2) Saliency map initialization and learning module, (3) Loss function computation module, and (4) Counterfactual perturbation generator. The saliency learning module uses ADAM optimizer with early stopping, while the perturbation generator applies learned saliency maps to create counterfactuals.

- Critical path: The critical execution path is: Load instance → Find NUN → Initialize saliency map → Optimize saliency through loss function (1000 epochs max with early stopping) → Apply perturbation → Generate counterfactual. The optimization step is the most computationally intensive.

- Design tradeoffs: M-CELS trades computational efficiency for interpretability and quality. The multi-dimensional saliency learning is more expensive than simple perturbation strategies but produces sparser, more valid counterfactuals. The choice of λ = 1 and k = 0.5 represents design decisions that may need tuning for different datasets.

- Failure signatures: Common failure modes include: (1) Saliency maps converging to all zeros or all ones, indicating optimization problems; (2) Target probabilities remaining below 0.5, indicating invalid counterfactuals; (3) Extremely high L1 distances, indicating loss of proximity; (4) Sparsity levels near 0%, indicating excessive perturbations.

- First 3 experiments:
  1. Run M-CELS on a single instance from the ArticularyWordRecognition dataset with λ = 1, k = 0.5, learning rate = 0.1, and verify that the learned saliency map shows meaningful patterns across dimensions
  2. Compare M-CELS target probability, L1 distance, and sparsity against NG-CF baseline on the BasicMotions dataset to verify performance improvements
  3. Perform ablation study by removing the temporal regularization term (LMTReg) and observe changes in sparsity and validity metrics across all seven datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does M-CELS scale to larger multivariate time series datasets in terms of computational efficiency and runtime performance?
- Basis in paper: [explicit] The authors mention "As a future step, we aim to improve M-CELS’ computational efficiency for better scalability on larger datasets and real-time applications."
- Why unresolved: The current evaluation uses seven UEA datasets but does not address scalability challenges or runtime performance on larger datasets.
- What evidence would resolve it: Empirical runtime measurements and computational complexity analysis on datasets with varying sizes and dimensions, including stress tests on large-scale time series data.

### Open Question 2
- Question: How does M-CELS perform when applied to deep learning models other than FCN (e.g., Transformer-based models, LSTMs) for multivariate time series classification?
- Basis in paper: [explicit] The authors state "our M-CELS model is model-agnostic, meaning that any other deep learning model can be used as the classification model" but only evaluate using FCN.
- Why unresolved: The experiments only validate M-CELS with FCN architecture, leaving performance on other model architectures unexplored.
- What evidence would resolve it: Comparative experiments applying M-CELS to multiple different deep learning architectures (LSTM, GRU, Transformers, etc.) on the same benchmark datasets.

### Open Question 3
- Question: What is the sensitivity of M-CELS to hyperparameter choices (λ coefficient, learning rate, threshold k, and number of epochs) across different datasets?
- Basis in paper: [explicit] The authors mention specific hyperparameter settings but do not provide sensitivity analysis or ablation studies on hyperparameter impact.
- Why unresolved: The paper states "The λ we used in our experiments is set to 1. And the threshold k is set to 0.5" without exploring how these choices affect performance across datasets.
- What evidence would resolve it: Comprehensive sensitivity analysis showing performance variation across different hyperparameter configurations and datasets, including visualizations of hyperparameter response surfaces.

### Open Question 4
- Question: How does M-CELS handle missing values or irregularly sampled multivariate time series data?
- Basis in paper: [inferred] The experimental datasets appear to be complete and regularly sampled, but real-world multivariate time series often contain missing values or irregular sampling.
- Why unresolved: The paper does not address data quality issues or preprocessing steps for handling incomplete or irregularly sampled time series.
- What evidence would resolve it: Experiments demonstrating M-CELS performance on datasets with synthetic missing values or irregular sampling patterns, along with proposed preprocessing or handling strategies.

## Limitations

- The effectiveness of multi-dimensional saliency map learning in capturing cross-dimensional interactions remains primarily theoretical rather than empirically validated
- The fixed hyperparameter settings (λ=1, k=0.5) may not generalize well across different types of multivariate time series data distributions
- Claims about semantic preservation during perturbations lack direct empirical validation across diverse domain applications

## Confidence

- **High Confidence**: The core framework architecture and loss function design are well-specified and theoretically sound
- **Medium Confidence**: The empirical superiority over baselines is demonstrated, but the sample size of datasets (7) and the lack of ablation studies on hyperparameter sensitivity reduce confidence in generalizability
- **Low Confidence**: Claims about cross-dimensional interaction capture and semantic preservation during perturbations lack direct empirical validation

## Next Checks

1. Conduct sensitivity analysis across different λ values (0.1, 1, 10) and k thresholds (0.3, 0.5, 0.7) to assess hyperparameter robustness
2. Perform ablation study removing the temporal regularization term (LMTReg) to quantify its contribution to performance
3. Test the approach on synthetic multivariate time series data where ground truth important features are known to validate the saliency map learning accuracy