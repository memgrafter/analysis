---
ver: rpa2
title: Towards Maximum Likelihood Training for Transducer-based Streaming Speech Recognition
arxiv_id: '2411.17537'
source_url: https://arxiv.org/abs/2411.17537
tags:
- streaming
- likelihood
- transducer
- network
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the deformed likelihood problem in streaming
  transducer-based speech recognition, where conventional training using non-streaming
  recursion rules leads to mismatched inference and suboptimal accuracy. The authors
  mathematically quantify this issue through Forward Variable Causal Compensation
  (FoCC), which measures the gap between actual and deformed likelihood in streaming
  models.
---

# Towards Maximum Likelihood Training for Transducer-based Streaming Speech Recognition

## Quick Facts
- arXiv ID: 2411.17537
- Source URL: https://arxiv.org/abs/2411.17537
- Reference count: 28
- Primary result: FoCCE training reduces streaming transducer WER gap to non-streaming models by 17.7% on TED-LIUM3

## Executive Summary
This paper addresses a fundamental problem in streaming transducer training where non-streaming recursion rules create likelihood deformation, causing inference-training mismatch. The authors introduce Forward Variable Causal Compensation (FoCC) to mathematically quantify this gap between actual and deformed likelihood in streaming models. They propose FoCC Estimator (FoCCE), a separate network that learns to estimate the exact likelihood by computing probability ratios between consecutive encoder chunks. Experimental results demonstrate that FoCCE training significantly improves streaming transducer accuracy while maintaining the same computational footprint as conventional approaches.

## Method Summary
The paper identifies that conventional streaming transducer training using non-streaming recursion rules leads to deformed likelihood, creating a mismatch between training and inference. The authors mathematically formulate this problem through Forward Variable Causal Compensation (FoCC), which measures the gap between actual and deformed likelihood. They propose FoCC Estimator (FoCCE), a separate neural network that learns to estimate the exact likelihood by calculating the probability ratio between consecutive encoder chunks. This approach enables maximum likelihood training for streaming transducers while maintaining the same computational requirements during inference. The method is evaluated on LibriSpeech and TED-LIUM3 datasets, showing significant improvements in streaming recognition accuracy.

## Key Results
- FoCCE training reduces the WER gap between streaming and non-streaming models by 17.7% on TED-LIUM3 test set
- Maintains the same computational footprint as conventional streaming transducers during inference
- Demonstrates improved accuracy on both LibriSpeech and TED-LIUM3 datasets compared to conventional streaming transducer training

## Why This Works (Mechanism)
The method works by directly addressing the likelihood deformation problem that occurs when streaming transducers are trained with non-streaming recursion rules. By introducing FoCC to quantify the gap between actual and deformed likelihood, and implementing FoCCE to learn the probability ratios between encoder chunks, the training process can now approximate maximum likelihood estimation even in the streaming context. This alignment between training and inference objectives eliminates the mismatch that previously degraded streaming performance.

## Foundational Learning

**Transducer Architecture**: Streaming transducers process speech incrementally by encoding chunks of audio sequentially. Why needed: Understanding this incremental processing is crucial for grasping why conventional training creates mismatches. Quick check: Can you explain how monotonic chunkwise attention enables streaming behavior?

**Likelihood Deformation**: The gap between the likelihood computed during training (using non-streaming recursion) and what would be computed during actual streaming inference. Why needed: This is the core problem the paper addresses. Quick check: Can you identify where in the forward algorithm this deformation occurs?

**Forward Variable**: A dynamic programming variable used in sequence modeling to accumulate probabilities. Why needed: FoCC is defined in terms of forward variables, making this concept essential. Quick check: Can you write the recurrence relation for forward variables in transducer models?

**Probability Ratio Estimation**: The FoCCE network learns to estimate ratios between probabilities of consecutive encoder chunks. Why needed: This is the mechanism by which FoCCE corrects the deformed likelihood. Quick check: Can you explain why probability ratios are sufficient to capture the correction needed?

**Maximum Likelihood Training**: The optimization objective of maximizing the probability of the correct output given the input. Why needed: The paper aims to achieve true maximum likelihood training for streaming models. Quick check: Can you contrast maximum likelihood with other common training objectives in speech recognition?

## Architecture Onboarding

**Component Map**: Encoder chunks → FoCCE Network → Probability Ratio → Corrected Forward Variable → Training Objective

**Critical Path**: The critical path for inference remains identical to conventional streaming transducers (Encoder → Predictor → Joiner → Output), with FoCCE only affecting the training process through likelihood correction.

**Design Tradeoffs**: The main tradeoff is between training-time complexity (additional FoCCE network and computations) and improved streaming accuracy. The authors chose to maintain inference efficiency while accepting increased training overhead.

**Failure Signatures**: Potential failures include FoCCE network overfitting to training data, insufficient learning of probability ratios, or numerical instability in computing likelihood corrections. The paper doesn't extensively explore these failure modes.

**First Experiments**:
1. Implement FoCC computation on a small transducer model to verify the mathematical formulation
2. Train a simple FoCCE network to learn probability ratios on synthetic data
3. Compare streaming WER with and without FoCCE on a single speaker from LibriSpeech

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas remain unexplored: generalization to multilingual settings, behavior under noisy conditions, scalability to very large vocabulary tasks, and the impact of different encoder architectures on FoCCE effectiveness.

## Limitations

- The mathematical formulation of FoCC assumes a specific decomposition that may not generalize across all streaming transducer architectures
- Reliance on a separate FoCCE network introduces additional model complexity and potential optimization challenges
- Empirical evaluation covers only two datasets (LibriSpeech and TED-LIUM3), limiting generalizability
- Training-time overhead from the FoCCE network is not quantified despite claims of maintained computational footprint

## Confidence

**High confidence**: The mathematical framework for identifying the deformed likelihood problem is sound and well-justified.

**Medium confidence**: The FoCCE architecture and its ability to learn probability ratios is plausible but requires further validation across architectures.

**Medium confidence**: The experimental improvements are demonstrated but need broader validation across more diverse datasets and streaming scenarios.

## Next Checks

1. Evaluate FoCCE on multi-lingual datasets and noisy conditions to assess robustness beyond LibriSpeech and TED-LIUM3.

2. Compare FoCCE against alternative streaming transducer training methods (e.g., monotonic chunkwise attention variants) on the same benchmarks.

3. Conduct ablation studies isolating the contribution of FoCCE network size, training schedule, and integration depth to identify optimal configurations.