---
ver: rpa2
title: CycleGAN with Better Cycles
arxiv_id: '2408.15374'
source_url: https://arxiv.org/abs/2408.15374
tags:
- consistency
- cycle
- image
- cyclegan
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'CycleGAN''s pixel-level cycle consistency can lead to unrealistic
  artifacts and hinder translation quality. This work proposes three modifications:
  (1) replacing pixel-level consistency with a weighted combination of pixel and discriminator
  CNN feature-level losses, (2) decaying the cycle consistency weight over training
  epochs, and (3) weighting the cycle consistency loss by discriminator output quality.'
---

# CycleGAN with Better Cycles

## Quick Facts
- **arXiv ID**: 2408.15374
- **Source URL**: https://arxiv.org/abs/2408.15374
- **Reference count**: 4
- **Primary result**: Three modifications to CycleGAN's cycle consistency loss improve image translation quality by reducing artifacts

## Executive Summary
This work addresses the limitations of pixel-level cycle consistency in CycleGAN, which can lead to unrealistic artifacts when exact pixel reconstruction is unnecessary or impossible. The authors propose three modifications: replacing pixel-level consistency with a weighted combination of pixel and discriminator CNN feature-level losses, decaying the cycle consistency weight over training epochs, and weighting the cycle consistency loss by discriminator output quality. Experiments on horse2zebra translation demonstrate that these modifications reduce artifacts and produce more realistic outputs compared to the original CycleGAN, though reconstructed images are slightly less similar to inputs.

## Method Summary
The paper proposes three modifications to CycleGAN's cycle consistency loss. First, replacing pixel-level L1 loss with a weighted combination of pixel-level and discriminator CNN feature-level L1 losses, where the feature-level loss captures structural similarity rather than exact pixel correspondence. Second, decaying the cycle consistency weight λ from an initial value to a small value over training epochs, as cycle consistency is most beneficial early in training but becomes restrictive later. Third, weighting the cycle consistency loss by discriminator output quality, where discriminator confidence serves as a proxy for image realism to prevent optimizing cycle consistency on unrealistic outputs.

## Key Results
- Feature-level cycle consistency reduces artifacts by allowing structural similarity without exact pixel reconstruction
- Decaying cycle consistency weight over epochs improves final output quality by reducing restrictive guidance when generators mature
- Discriminator-output weighting showed limited benefit due to joint training of discriminators with generators
- Horse2zebra translation experiments show more realistic outputs with fewer artifacts compared to original CycleGAN

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing pixel-level cycle consistency with weighted combination of pixel and discriminator CNN feature-level losses reduces artifacts by allowing structural similarity without exact pixel reconstruction.
- Mechanism: The discriminator learns hierarchical features that capture high-level image structures. Using L1 loss on these features instead of raw pixels relaxes the one-to-one mapping assumption, permitting generators to produce realistic outputs even when exact pixel correspondence is unnecessary or impossible.
- Core assumption: The discriminator's intermediate features represent meaningful image structures that are stable across domain transformations.
- Evidence anchors:
  - [section]: "we should better only require that it recover the general structures... we enforce this weaker notion of cycle consistency by including an L1 loss on the CNN features extracted by the corresponding discriminator"
  - [abstract]: "replacing pixel-level consistency with a weighted combination of pixel and discriminator CNN feature-level losses"
  - [corpus]: Weak evidence - no directly comparable works in corpus mention feature-level consistency specifically, though some mention CycleGAN modifications.
- Break condition: If discriminator features don't capture meaningful structures (early training, poor discriminator), feature-level consistency provides no benefit over pixel-level.

### Mechanism 2
- Claim: Decaying cycle consistency weight over training epochs improves final output quality by reducing restrictive guidance when generators have learned basic mappings.
- Mechanism: Early in training, strong cycle consistency stabilizes learning and enforces color mapping. Later, reducing this weight allows generators to focus on realism rather than exact reconstruction, preventing artifacts from over-constraining the output space.
- Core assumption: Cycle consistency is most beneficial early in training but becomes counterproductive as generators mature.
- Evidence anchors:
  - [section]: "cycle consistency loss helps stabilizing training a lot in early stages but becomes an obstacle towards realistic images in later stages"
  - [abstract]: "decaying the cycle consistency weight over training epochs"
  - [corpus]: No direct evidence in corpus - corpus papers don't discuss dynamic weight scheduling for cycle consistency.
- Break condition: If weight decay is too aggressive or poorly timed, generators may lose structural guidance entirely, leading to mode collapse or excessive hallucinations.

### Mechanism 3
- Claim: Weighting cycle consistency by discriminator output quality prevents generators from optimizing cycle consistency when outputs are unrealistic, avoiding local minima where generators learn to minimize loss through color inversion rather than producing realistic images.
- Mechanism: Discriminator outputs serve as a proxy for image realism. By scaling cycle consistency loss with discriminator confidence, the system prioritizes learning to generate realistic images first, then refines cycle consistency.
- Core assumption: Discriminator output correlates with image realism and can be used to dynamically balance GAN and cycle consistency objectives.
- Evidence anchors:
  - [section]: "enforcing cycle consistency on cycles where generated images are not realistic actually hinders training... we propose to weight cycle consistency loss by the quality of generated images, which we obtain using the discriminators' outputs"
  - [abstract]: "weighting the cycle consistency loss by discriminator output quality"
  - [corpus]: Weak evidence - corpus papers don't discuss discriminator-output weighting for cycle consistency, though some mention discriminator guidance.
- Break condition: If discriminator and generator are jointly trained (as noted in paper), discriminator outputs remain near-constant, making this weighting ineffective.

## Foundational Learning

- Concept: GAN adversarial loss formulation (minimax objective)
  - Why needed here: Understanding how LGAN(G, DY, X, Y) = Ey∼pdata(y)[log DY(y)] + Ex∼pdata(x)[log(1 − DY(G(x)))] works is essential for grasping how generators are trained to fool discriminators while discriminators learn to distinguish real from fake.
  - Quick check question: What happens to generator gradients when discriminator becomes too strong during training?

- Concept: Cycle consistency principle and its limitations
  - Why needed here: The paper's core contribution is modifying cycle consistency, so understanding why pixel-level L1 loss Ex∼pdata(x)[∥F(G(x)) − x∥1] can be problematic is crucial.
  - Quick check question: In zebra-to-horse translation, why does pixel-level cycle consistency force the generator to retain some zebra texture?

- Concept: Feature extraction from discriminator layers
  - Why needed here: The proposed modification uses fD(·) as feature extractor using last layer of D(·), requiring understanding of how to access and use intermediate representations from neural networks.
  - Quick check question: How would you modify the discriminator architecture to extract features from an intermediate layer rather than the output layer?

## Architecture Onboarding

- Component map: Generator G: X→Y, Generator F: Y→X, Discriminator DX for domain X, Discriminator DY for domain Y, Combined loss functions with dynamic weighting parameters (λt for cycle consistency weight, γt for feature/pixel ratio)
- Critical path: Image → Generator → Discriminator (GAN loss) → Back to original domain via second generator → Cycle consistency loss → Combined gradients → Generator update. Discriminator training follows standard GAN procedure.
- Design tradeoffs: Feature-level vs pixel-level consistency (structural vs exact reconstruction), constant vs decaying cycle weight (stability vs flexibility), joint vs pretrained discriminators (simplicity vs effectiveness of discriminator-output weighting).
- Failure signatures: Persistent artifacts despite training (pixel-level consistency too restrictive), mode collapse (cycle weight decayed too much), unrealistic outputs with good cycle consistency (discriminator-output weighting not working due to joint training).
- First 3 experiments:
  1. Implement basic CycleGAN with standard pixel-level cycle consistency loss
  2. Add discriminator CNN feature-level loss component weighted by parameter γ, starting low and linearly increasing to near 1
  3. Implement cycle consistency weight decay λ, starting at initial value and linearly decreasing to small value

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How should the cycle consistency weight λt and feature ratio γt be scheduled during training to achieve optimal results?
- Basis in paper: [explicit] The authors note that "we suggest λt to linearly decrease to a small value and γt to linearly increase to a value close to 1" but found results "very sensitive to different parameters" with limited experimentation.
- Why unresolved: The paper only tried "a few combinations" of parameter schedules due to time constraints, and the authors acknowledge this as an important direction for future work.
- What evidence would resolve it: Systematic experiments testing various scheduling functions (linear, exponential, step-wise) for λt and γt, potentially using hyperparameter optimization techniques to find optimal schedules.

### Open Question 2
- Question: Would pretraining discriminators on a related task (e.g., AlexNet initialization) or pretraining them using the CycleGAN objective improve results compared to joint training?
- Basis in paper: [explicit] The authors state "we believe that using pretrained discriminators will make this modification actually have positive effect" and note that "discriminators are jointly trained with generators" which causes discriminator outputs to remain constant early in training.
- Why unresolved: The authors only implemented joint training and observed that discriminator outputs "mostly stays around a constant value, which we observe to be about 0.3."
- What evidence would resolve it: Experiments comparing CycleGAN with modified cycle consistency using pretrained discriminators versus randomly initialized discriminators, measuring both output quality and discriminator output dynamics during training.

### Open Question 3
- Question: How can stochastic input be incorporated into CycleGAN while maintaining proper cycle consistency and preventing the generators from producing unrealistic outputs?
- Basis in paper: [explicit] The authors attempted adding noise channels but "weren't able to achieve comparable results with the original CycleGAN within same period of training, likely due to a full channel of noise being too much randomness."
- Why unresolved: The authors found that "a full channel of noise being too much randomness" but didn't explore alternative approaches like conditioning noise on input features or using latent space interpolation.
- What evidence would resolve it: Successful implementation of stochastic input methods that produce diverse, high-quality outputs while maintaining cycle consistency, demonstrated through quantitative diversity metrics and qualitative evaluation across multiple translation tasks.

### Open Question 4
- Question: Would using a single discriminator with three-way classification (domain X, domain Y, fake images) improve CycleGAN training stability and output quality compared to two separate discriminators?
- Basis in paper: [explicit] The authors propose this as future work, noting that "such a discriminator may better drive the generators towards right directions" since "the generators almost always are near-identity mapping at early stage of training."
- Why unresolved: This approach was only suggested conceptually without any experimental validation or comparison to the standard two-discriminator setup.
- What evidence would resolve it: Direct comparison experiments between single three-way discriminator and dual discriminator architectures, measuring convergence speed, training stability, and output quality across multiple image translation tasks.

## Limitations
- Discriminator-output weighting showed limited benefit due to joint training of discriminators with generators, which keeps discriminator outputs near-constant throughout training
- Specific parameter values for λt and γt scheduling are not provided, making faithful reproduction difficult
- Qualitative nature of "fewer artifacts" and "more realistic" outputs lacks quantitative metrics beyond visual inspection

## Confidence

**Confidence labels**:
- **High confidence**: Pixel-level cycle consistency can be overly restrictive and cause artifacts (well-established in prior literature)
- **Medium confidence**: Feature-level cycle consistency reduces artifacts (supported by results but mechanism could be better explained)
- **Low confidence**: Discriminator-output weighting effectively improves training (mechanism broken by joint training setup, limited empirical support)

## Next Checks
1. Compare feature-level consistency effectiveness with and without discriminator pretraining to isolate whether discriminator-output weighting benefits depend on training setup
2. Conduct ablation study with fixed vs decaying cycle consistency weights to quantify the improvement from weight decay specifically
3. Measure quantitative metrics (FID, LPIPS) for reconstructed images alongside qualitative artifact assessment to provide objective comparison with baseline CycleGAN