---
ver: rpa2
title: 'FairPFN: Transformers Can do Counterfactual Fairness'
arxiv_id: '2407.05732'
source_url: https://arxiv.org/abs/2407.05732
tags:
- causal
- fairness
- fairpfn
- counterfactual
- protected
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FairPFN, a transformer-based approach to
  achieving counterfactual fairness in machine learning. The key innovation is a pre-training
  strategy that learns to remove the causal effects of protected attributes from observational
  data without requiring access to a causal model.
---

# FairPFN: Transformers Can do Counterfactual Fairness

## Quick Facts
- arXiv ID: 2407.05732
- Source URL: https://arxiv.org/abs/2407.05732
- Reference count: 9
- Key outcome: FairPFN is a transformer-based approach to achieving counterfactual fairness that learns to remove causal effects of protected attributes from observational data without requiring access to a causal model

## Executive Summary
This paper introduces FairPFN, a transformer-based approach to achieving counterfactual fairness in machine learning. The key innovation is a pre-training strategy that learns to remove the causal effects of protected attributes from observational data without requiring access to a causal model. FairPFN is pre-trained on synthetic datasets generated from sparse Structural Causal Models (SCMs) with exogenous protected attributes. The model learns to predict fair outcomes by being trained on pairs of biased and fair datasets, where the fair dataset is created by removing the causal influence of protected attributes through dropout. The approach is evaluated on both synthetic causal case studies and real-world datasets (Law School Admissions and Adult Census Income), demonstrating effectiveness in eliminating causal effects while maintaining competitive predictive accuracy.

## Method Summary
FairPFN pre-trains a transformer model on synthetic datasets generated from sparse SCMs with exogenous protected attributes. The training pairs biased datasets with fair versions created by removing the causal influence of protected attributes through dropout on outgoing edges. The model learns to predict fair outcomes by mapping inputs from biased datasets to outputs that match the fair dataset. This pre-training enables FairPFN to achieve counterfactual fairness without requiring knowledge of the causal graph, addressing a key limitation in existing causal fairness methods. The approach is evaluated on synthetic causal case studies and real-world datasets.

## Key Results
- FairPFN effectively eliminates causal effects of protected attributes while maintaining competitive predictive accuracy
- The model achieves counterfactual fairness without requiring knowledge of the causal graph
- FairPFN outperforms or matches baseline methods on both synthetic and real-world datasets
- The approach demonstrates flexibility and extensibility for causal and counterfactual fairness applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FairPFN removes the causal effects of protected attributes by training on paired biased and fair datasets where the fair dataset is generated by removing outgoing edges from the protected attribute in the causal graph.
- Mechanism: The transformer learns to map inputs from the biased dataset to outputs that match the fair dataset by leveraging the dropout-induced removal of causal influence during pre-training.
- Core assumption: The causal effect of protected attributes can be effectively removed through dropout on outgoing edges in the structural causal model (SCM).
- Evidence anchors:
  - [abstract]: "The model learns to predict fair outcomes by being trained on pairs of biased and fair datasets, where the fair dataset is created by removing the causal influence of protected attributes through dropout."
  - [section]: "The fair dataset is generated by performing dropout on the outgoing edges of the protected attribute in the sampled MLP."
  - [corpus]: Weak - no direct evidence in related papers about dropout-based causal effect removal.
- Break condition: If the causal relationships between protected attributes and outcomes are complex and non-linear, dropout may not fully capture the removal of causal effects.

### Mechanism 2
- Claim: FairPFN achieves counterfactual fairness without requiring knowledge of the causal graph by learning from synthetic data that captures various causal scenarios.
- Mechanism: By pre-training on diverse synthetic datasets with known causal structures, the transformer develops an implicit understanding of how protected attributes influence outcomes, allowing it to generalize to real-world scenarios.
- Core assumption: Synthetic data generated from sparse SCMs with exogenous protected attributes can effectively represent real-world causal mechanisms.
- Evidence anchors:
  - [abstract]: "FairPFN is pre-trained on synthetic datasets generated from sparse Structural Causal Models (SCMs) with exogenous protected attributes."
  - [section]: "FairPFNâ€™s fairness prior includes a key addition to the TabPFN hypothesis space, namely the inclusion and specification of protected attributes in the randomly generated SCMs as exogenous variables."
  - [corpus]: Weak - related papers do not provide evidence for the effectiveness of synthetic data in achieving counterfactual fairness without causal graph knowledge.
- Break condition: If real-world causal mechanisms are significantly more complex than those represented in synthetic data, the transformer may not generalize effectively.

### Mechanism 3
- Claim: FairPFN maintains competitive predictive accuracy while removing causal effects by learning to preserve non-causal information.
- Mechanism: The transformer is trained to output predictions that match fair outcomes, which involves learning to use non-causal features effectively while ignoring causal influences of protected attributes.
- Core assumption: There is sufficient non-causal information in the data to maintain predictive accuracy after removing causal effects of protected attributes.
- Evidence anchors:
  - [abstract]: "FairPFN achieves counterfactual fairness without requiring knowledge of the causal graph, addressing a key limitation in existing causal fairness methods."
  - [section]: "In our experimental results across a series of synthetic case-studies and real-world datasets, we demonstrate the effectiveness, flexibility, and extensibility of transformers for causal and counterfactual fairness."
  - [corpus]: Weak - related papers do not provide evidence for maintaining predictive accuracy while removing causal effects.
- Break condition: If the non-causal information is insufficient or the causal effects are dominant, predictive accuracy may degrade significantly.

## Foundational Learning

- Concept: Causal Fairness
  - Why needed here: Understanding causal fairness is essential to grasp how FairPFN aims to remove the causal effects of protected attributes.
  - Quick check question: What is the difference between statistical fairness and causal fairness?

- Concept: Structural Causal Models (SCMs)
  - Why needed here: SCMs are used to generate synthetic data and represent causal mechanisms, which are central to FairPFN's approach.
  - Quick check question: How do SCMs represent causal relationships between variables?

- Concept: Transformer Models
  - Why needed here: FairPFN is based on a transformer architecture, so understanding transformers is crucial for comprehending the model's functioning.
  - Quick check question: What is the role of attention mechanisms in transformer models?

## Architecture Onboarding

- Component map:
  - Synthetic Data Generator -> FairPFN Transformer -> Loss Function -> Evaluation Metrics

- Critical path:
  1. Generate synthetic datasets with known causal structures.
  2. Pre-train FairPFN on paired biased and fair datasets.
  3. Evaluate the model on synthetic and real-world datasets.
  4. Assess the removal of causal effects and maintenance of predictive accuracy.

- Design tradeoffs:
  - Complexity vs. Interpretability: Using synthetic data allows for controlled experiments but may not fully capture real-world complexities.
  - Generalization vs. Specificity: Pre-training on diverse synthetic data may improve generalization but could lead to overfitting to synthetic scenarios.

- Failure signatures:
  - Poor performance on real-world datasets despite good synthetic results.
  - Inability to remove causal effects in complex causal structures.
  - Significant drop in predictive accuracy when removing causal effects.

- First 3 experiments:
  1. Evaluate FairPFN on a simple synthetic dataset with a clear causal structure to verify basic functionality.
  2. Test the model on a real-world dataset with a known causal graph to assess generalization.
  3. Analyze the impact of varying the complexity of synthetic data on FairPFN's performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would FairPFN perform when trained on real-world observational data without access to any causal model or ground truth counterfactual outcomes?
- Basis in paper: [inferred] The paper demonstrates FairPFN's effectiveness on synthetic data and real-world datasets where causal models are known and used to generate counterfactuals, but does not evaluate performance when causal models are entirely unknown
- Why unresolved: The paper uses synthetic data with known ground truth and real-world data where causal models are constructed using dowhy.gcm to generate counterfactuals for evaluation. This leaves open the question of how FairPFN would perform when no causal model is available for counterfactual generation
- What evidence would resolve it: Empirical evaluation showing FairPFN's performance on real-world datasets where counterfactual outcomes are estimated using alternative methods (e.g., matching, imputation, or learned estimators) rather than known causal models

### Open Question 2
- Question: Would incorporating known causal relationships or domain knowledge as additional input to FairPFN improve its performance or interpretability compared to training without such knowledge?
- Basis in paper: [explicit] The authors mention in Section 5 that "In cases where a causal graph or a subset of causal relationships are known, incorporating this domain knowledge as additional input to the transformer could enhance both FairPFN's human-centricity and performance"
- Why unresolved: The paper focuses on demonstrating FairPFN's ability to work without causal knowledge, but does not explore whether incorporating partial causal knowledge would improve results or provide better interpretability
- What evidence would resolve it: Comparative experiments showing FairPFN's performance and interpretability when trained with versus without partial causal knowledge on datasets where some causal relationships are known

### Open Question 3
- Question: How does FairPFN's performance scale with larger datasets and more complex causal structures involving multiple protected attributes or non-binary protected attributes?
- Basis in paper: [inferred] The paper evaluates FairPFN on relatively small tabular datasets with single binary protected attributes, but mentions in Section 3 that "FairPFN is extensible to regression tasks and handling multiple protected attributes" without empirical validation
- Why unresolved: All experiments in the paper use binary protected attributes and focus on small to moderate sized datasets, leaving questions about scalability and performance on more complex scenarios
- What evidence would resolve it: Empirical evaluation of FairPFN on larger datasets with multiple protected attributes, non-binary protected attributes, and more complex causal structures to assess scalability and performance degradation

### Open Question 4
- Question: What is the computational complexity and training time of FairPFN compared to traditional fairness-aware ML methods when applied to real-world sized problems?
- Basis in paper: [explicit] The paper states "We train the transformer for approximately 3 days on an RTX-2080 GPU" and mentions pre-training on synthetic data, but does not provide runtime comparisons with baseline methods
- Why unresolved: While the paper provides pre-training time for FairPFN, it does not compare this to the computational requirements of baseline methods or discuss how training time scales with dataset size
- What evidence would resolve it: Comparative analysis of FairPFN's training and inference time versus baseline methods across different dataset sizes and complexities, including GPU/CPU requirements and wall-clock time

## Limitations
- Reliance on synthetic data to learn causal fairness without requiring causal graph knowledge may not capture real-world complexities
- Limited evaluation on real-world datasets with insufficient comparison to established counterfactual fairness methods
- Lack of discussion on computational efficiency and scalability for practical deployment

## Confidence
- High Confidence: The transformer architecture can learn to predict outcomes from tabular data
- Medium Confidence: The synthetic data generation approach using sparse SCMs is methodologically sound
- Medium Confidence: FairPFN can reduce causal effects in controlled synthetic experiments
- Low Confidence: FairPFN achieves counterfactual fairness in real-world scenarios without requiring causal graph knowledge

## Next Checks
1. **Causal Structure Complexity Test**: Generate synthetic datasets with increasingly complex causal structures and evaluate whether FairPFN maintains its ability to remove causal effects while preserving predictive accuracy.

2. **Real-World Causal Graph Comparison**: Apply FairPFN to a real-world dataset where the causal graph is known or can be reliably estimated, and compare its performance against established counterfactual fairness methods that leverage causal graph knowledge.

3. **Generalization Cross-Domain Evaluation**: Test FairPFN's pre-trained model on datasets from entirely different domains than those used in pre-training, measuring both counterfactual fairness and predictive accuracy.