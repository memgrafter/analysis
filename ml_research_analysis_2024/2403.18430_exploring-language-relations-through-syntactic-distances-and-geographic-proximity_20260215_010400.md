---
ver: rpa2
title: Exploring language relations through syntactic distances and geographic proximity
arxiv_id: '2403.18430'
source_url: https://arxiv.org/abs/2403.18430
tags:
- languages
- language
- distance
- linguistic
- distances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores syntactic relationships between languages using
  parts-of-speech (POS) trigram distributions from the Universal Dependencies dataset.
  The authors develop an information-theoretic framework to analyze POS sequences
  and show that trigrams effectively capture syntactic variations while remaining
  computationally tractable.
---

# Exploring language relations through syntactic distances and geographic proximity

## Quick Facts
- arXiv ID: 2403.18430
- Source URL: https://arxiv.org/abs/2403.18430
- Authors: Juan De Gregorio; Raúl Toral; David Sánchez
- Reference count: 0
- Primary result: Significant positive correlation between syntactic similarity and geographic proximity across 67 languages (Rd = 0.447, p < 0.001)

## Executive Summary
This study develops an information-theoretic framework to quantify syntactic relationships between languages using parts-of-speech trigram distributions from the Universal Dependencies dataset. The authors demonstrate that trigrams effectively capture syntactic variations while remaining computationally tractable, and use Jensen-Shannon distances to reveal clear clustering patterns corresponding to language families. The analysis shows a significant correlation between linguistic similarity and geographic proximity, highlighting the influence of spatial factors on language evolution. The methodology proves robust across alternative distance metrics and offers a promising approach for quantifying syntactic relationships across languages.

## Method Summary
The authors model POS sequences as 2nd-order Markov processes and use the NSB entropy estimator to analyze predictability gain, confirming that r = 3 (trigrams) suffices to characterize language syntax. They compute pairwise Jensen-Shannon distances between languages based on their POS trigram distributions, then perform hierarchical clustering to identify language groupings. Geographic coordinates from WALS are used to calculate distance correlation coefficients between linguistic and geographic distances. The framework balances information capture against data sparsity, using symmetric JS distance which is computationally heavier than alternatives but provides reliable divergence measures.

## Key Results
- POS trigrams effectively capture syntactic variations while remaining computationally tractable
- Jensen-Shannon distances reveal clustering patterns that correspond to well-known language families and groups
- Significant positive correlation between linguistic similarity and geographic proximity (Rd = 0.447, p < 0.001)
- Methodology yields consistent results across alternative distance metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: POS trigrams capture syntactic variation better than individual POS or bigrams.
- Mechanism: POS sequences are Markovian with memory 2, so trigrams preserve second-order transition structure that encodes syntactic dependencies.
- Core assumption: Language syntax can be represented as a finite-state stochastic process over POS tags.
- Evidence anchors:
  - [abstract] "we show that employing POS trigrams maximizes the possibility of capturing syntactic variations"
  - [section] "we find that r = 3 suffices to correctly characterize any of the studied languages"
  - [corpus] Weak: Only syntactic distance correlations observed, not direct POS trigram verification across languages.
- Break condition: If syntactic dependencies require longer-range correlations (m > 2), trigrams lose information and distances become less accurate.

### Mechanism 2
- Claim: Jensen-Shannon distance reliably quantifies syntactic dissimilarity between POS trigram distributions.
- Mechanism: JS distance measures statistical divergence between two probability distributions; here it captures morphosyntactic differences encoded in trigram frequencies.
- Core assumption: The POS trigram distributions of two languages are sufficient statistics for their syntactic divergence.
- Evidence anchors:
  - [abstract] "Linguistic connections are then established by assessing pairwise distances based on the POS distributions"
  - [section] "We estimate the JS distance by replacing the exact probabilities... with the maximum likelihood estimators"
  - [corpus] Weak: No direct JS distance benchmarking against other syntactic distance metrics.
- Break condition: If JS distance is dominated by surface-level lexical frequency rather than structural properties, syntactic similarity may be masked.

### Mechanism 3
- Claim: Geographic proximity correlates with syntactic similarity because languages evolve under spatial diffusion constraints.
- Mechanism: Languages closer in space share more contact-induced syntactic features, reflected in smaller JS distances.
- Core assumption: Language evolution is influenced by geographic adjacency, not just phylogenetic ancestry.
- Evidence anchors:
  - [abstract] "we obtain a significant correlation between language similarity and geographic distance, which underscores the influence of spatial proximity on language kinships"
  - [section] "We find a correlation between the obtained linguistic distance and the geographic distance"
  - [corpus] Weak: Geographic coordinates from WALS are coarse approximations; fine-grained spatial correlation may be underestimated.
- Break condition: If language contact is mediated through non-contiguous networks (e.g., trade, migration), geographic correlation weakens.

## Foundational Learning

- Concept: Markov processes and memory order
  - Why needed here: Determining that m=2 is sufficient for POS sequences ensures trigrams capture all necessary dependencies.
  - Quick check question: What does it mean if Gu = 0 for all u ≥ m in a stochastic process?

- Concept: Entropy estimation from finite samples
  - Why needed here: Reliable entropy estimates are required to compute predictability gain and memory length.
  - Quick check question: Why does the number of possible r-grams grow exponentially with r, and how does that affect entropy estimation?

- Concept: Distance correlation (Rd) vs Pearson correlation (Rp)
  - Why needed here: Rd captures nonlinear relationships between linguistic and geographic distances, which Pearson might miss.
  - Quick check question: If Rd = 0.447 and p < 0.001, what does that say about the strength and significance of the correlation?

## Architecture Onboarding

- Component map: POS tagging → n-gram extraction → frequency counting → entropy estimation → predictability gain calculation → JS distance matrix → clustering → geographic correlation
- Critical path: POS trigram frequency extraction → JS distance computation → cluster analysis → geographic correlation test
- Design tradeoffs: Using trigrams balances information capture vs data sparsity; JS distance is symmetric but computationally heavier than alternatives
- Failure signatures: (1) Flat predictability gain curves → memory misestimation; (2) Uniform JS distances → poor language discrimination; (3) No geographic correlation → model misspecification
- First 3 experiments:
  1. Compare predictability gain curves for r=2,3,4 to confirm m=2 and optimal r.
  2. Validate JS distance matrix by checking known language family groupings.
  3. Compute Rd using alternative distance metrics (e.g., Hellinger) to test robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal memory length for POS sequence modeling beyond the r = 3 case explored in the paper?
- Basis in paper: [explicit] The paper shows that r = 3 (trigram) captures most correlations in POS sequences, but appendix analysis suggests memory may be ≥ 4.
- Why unresolved: The paper only tests up to r = 5 and finds diminishing returns after r = 3, but cannot definitively rule out higher-order effects.
- What evidence would resolve it: Systematic analysis testing r = 4, 5, 6... on larger datasets and multiple languages to find where predictability gain plateaus.

### Open Question 2
- Question: How robust are the syntactic distance findings when applied to languages outside Europe and Asia?
- Basis in paper: [inferred] The study focuses on 67 European and Asian languages due to data availability, but makes no claims about generalizability.
- Why unresolved: The dataset is geographically and typologically limited, potentially missing important cross-linguistic patterns.
- What evidence would resolve it: Applying the methodology to African, American, and Australian languages with sufficient UD data.

### Open Question 3
- Question: What is the relationship between morphological typology (agglutinative, fusional, isolating) and POS trigram distributions?
- Basis in paper: [explicit] The paper notes morphological types are included in analysis but doesn't systematically examine their effect on syntactic distances.
- Why unresolved: The paper mentions typology affects POS combinations but doesn't quantify how different morphological systems influence trigram patterns.
- What evidence would resolve it: Comparative analysis of trigram distributions across morphological types, controlling for language family.

## Limitations
- Reliance on Universal Dependencies data may not fully represent syntactic diversity of studied languages
- Limited data availability for certain languages may affect reliability of distance calculations
- WALS geographic coordinates are coarse approximations that may underestimate fine-grained spatial correlations
- Assumption that syntactic relationships can be adequately captured through POS trigrams may miss complex syntactic phenomena

## Confidence
- **High Confidence**: The computational framework for calculating POS trigram distributions and Jensen-Shannon distances is methodologically sound and well-documented.
- **Medium Confidence**: The clustering results showing language family groupings are interpretable but may be influenced by data sparsity for some languages.
- **Medium Confidence**: The geographic correlation (Rd = 0.447, p < 0.001) is statistically significant but may be attenuated by the coarse geographic data used.
- **Low Confidence**: The claim that m=2 is universally sufficient for all studied languages lacks direct empirical validation across language families.

## Next Checks
1. **Data Sufficiency Analysis**: Conduct a sensitivity analysis by subsampling UD data at different sizes for each language to determine how corpus size affects distance calculations and clustering stability.

2. **Alternative Distance Metrics**: Replicate the analysis using alternative syntactic distance measures (e.g., tree edit distance on dependency structures) to validate that JS distance on POS trigrams captures meaningful syntactic variation.

3. **Fine-grained Geographic Correlation**: Replace WALS country-level coordinates with more precise language area centroids from Glottolog or Ethnologue to test whether the geographic correlation strengthens with better spatial data.