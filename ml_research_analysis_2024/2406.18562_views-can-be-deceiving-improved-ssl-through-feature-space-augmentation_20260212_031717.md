---
ver: rpa2
title: 'Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation'
arxiv_id: '2406.18562'
source_url: https://arxiv.org/abs/2406.18562
tags:
- spurious
- learning
- arxiv
- downstream
- connectivity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how spurious features affect self-supervised
  learning (SSL) and proposes LATETVG to mitigate their impact. It demonstrates that
  common SSL augmentations induce spurious connectivity, causing models to rely on
  spurious features for downstream predictions.
---

# Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation

## Quick Facts
- arXiv ID: 2406.18562
- Source URL: https://arxiv.org/abs/2406.18562
- Reference count: 40
- Key outcome: LATETVG improves worst-group accuracy in SSL by mitigating spurious connectivity through feature space augmentation

## Executive Summary
This paper reveals that common data augmentation strategies in self-supervised learning (SSL) can inadvertently introduce spurious connectivity, causing models to rely on spurious features for downstream predictions. The authors introduce LATETVG, a method that prunes later layers of the encoder during SSL pre-training to reduce this spurious connectivity and improve worst-group performance. Empirical results across multiple vision datasets demonstrate that LATETVG significantly improves worst-group accuracy, closing the gap to supervised pretraining without requiring group or label information during SSL.

## Method Summary
The paper proposes LATETVG (LATer Encoder with Two-level View Generation), which addresses spurious connectivity in SSL by introducing feature space augmentations. During SSL pre-training, LATETVG prunes later layers of the encoder and trains multiple classifiers on these pruned representations to balance the training set implicitly. This approach reduces reliance on spurious features by ensuring positive pairs have diverse representations, even when they share spurious characteristics. The method operates during the pre-training phase without requiring group labels or modifying the downstream fine-tuning process.

## Key Results
- LATETVG achieves significant improvements in worst-group accuracy across Waterbirds, CelebA, and iWildCam datasets
- The method closes the performance gap to supervised pretraining without requiring group information during SSL
- Empirical analysis shows that common SSL augmentations induce spurious connectivity, which LATETVG effectively mitigates

## Why This Works (Mechanism)
LATETVG works by breaking the spurious connectivity that forms during standard SSL training. When data augmentations create positive pairs that share spurious features, the encoder learns to associate these features with the representation. By pruning later layers and training multiple classifiers on different views of the same input, LATETVG forces the model to learn more robust, feature-diverse representations. This reduces the model's reliance on spurious features for downstream predictions, improving worst-group performance.

## Foundational Learning
1. **Self-Supervised Learning (SSL)**: Learning representations without labeled data by leveraging relationships between different views of the same input. *Why needed*: Forms the foundation for understanding how LATETVG improves representation learning.
2. **Spurious Features**: Features that correlate with labels but are not causally related, often due to dataset biases. *Why needed*: Central to understanding why models fail on worst-group examples.
3. **Spurious Connectivity**: The phenomenon where positive pairs in SSL share spurious features, leading to biased representations. *Why needed*: Explains the core problem LATETVG addresses.
4. **Feature Space Augmentation**: Modifying representations during training to improve robustness. *Why needed*: Describes the mechanism by which LATETVG operates.
5. **Worst-Group Accuracy**: Model performance on underrepresented or minority groups in the data. *Why needed*: The primary evaluation metric for LATETVG's effectiveness.
6. **Contrastive Learning**: A SSL approach that learns representations by comparing positive and negative pairs. *Why needed*: Provides context for how LATETVG differs from standard SSL methods.

## Architecture Onboarding

**Component Map**: Input -> Data Augmentations -> Encoder (with pruned layers) -> Multiple Classifiers -> Representation

**Critical Path**: Input → Augmentation → Pruned Encoder → Classifier → Representation

**Design Tradeoffs**: LATETVG trades computational overhead during pre-training for improved worst-group accuracy, avoiding the need for group labels or balanced datasets.

**Failure Signatures**: If LATETVG fails, we would expect no improvement in worst-group accuracy compared to standard SSL, or potentially worse performance if pruning removes too much information.

**First Experiments**:
1. Test LATETVG on a simple vision dataset (e.g., Waterbirds) to verify basic functionality and measure worst-group accuracy improvements.
2. Compare LATETVG's performance with and without pruning to isolate the effect of feature space augmentation.
3. Evaluate LATETVG's sensitivity to the number of pruned layers to determine the optimal pruning depth.

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis focuses primarily on vision datasets, and it's unclear whether spurious connectivity patterns hold for other modalities like language or audio.
- The computational overhead of pruning later encoder layers and training additional classifiers during pre-training is not extensively discussed.
- The paper doesn't address how LATETVG scales to larger, more complex datasets or real-world deployment scenarios with constrained computational resources.

## Confidence
- High confidence in the core claim that data augmentations can induce spurious connectivity in SSL representations.
- Medium confidence in LATETVG's effectiveness, as results show consistent improvements in worst-group accuracy.
- Lower confidence in the generalizability of findings to non-vision domains and larger-scale applications.

## Next Checks
1. Evaluate LATETVG on non-vision datasets (e.g., text, audio, or multimodal data) to assess cross-domain generalizability and identify whether spurious connectivity patterns persist in other modalities.
2. Conduct a comprehensive ablation study on the computational overhead of LATETVG, including memory usage and training time compared to standard SSL methods, to better understand practical deployment constraints.
3. Test LATETVG's scalability on larger, more complex datasets (e.g., ImageNet-21k or multi-modal datasets) to evaluate whether the method maintains its effectiveness as dataset complexity increases.