---
ver: rpa2
title: Probing Context Localization of Polysemous Words in Pre-trained Language Model
  Sub-Layers
arxiv_id: '2409.14097'
source_url: https://arxiv.org/abs/2409.14097
tags:
- word
- sub-layer
- bert
- sense
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how polysemous words are contextualized
  across different sub-layers of BERT (Self-Attention, Feed-Forward Activation, and
  Output) using linear probing. The authors compare representations of polysemous
  words in minimally different contexts and probe their sub-layer representations
  on a sense identification task.
---

# Probing Context Localization of Polysemous Words in Pre-trained Language Model Sub-Layers

## Quick Facts
- arXiv ID: 2409.14097
- Source URL: https://arxiv.org/abs/2409.14097
- Authors: Soniya Vijayakumar; Josef van Genabith; Simon Ostermann
- Reference count: 6
- Key outcome: BERT shows high contextualization in top sub-layers for polysemous words in short contexts with fixed positions, but this pattern doesn't generalize across different word positions and context sizes.

## Executive Summary
This paper investigates how polysemous words are contextualized across different sub-layers of BERT using linear probing. The authors examine three sub-layer types (Self-Attention, Feed-Forward Activation, and Output) across 12 layers to understand where sense information is encoded. Using three datasets with varying context lengths and word positions, they find that BERT demonstrates strong contextualization in top sub-layers only for short contexts with fixed word positions, while longer contexts and variable positions yield poor linear probe performance.

## Method Summary
The study uses BERT-base-uncased to extract representations from three sub-layer types (Self-Attention, Feed-Forward Activation, Output) across 12 layers. Researchers compute sub-layer similarity metrics using cosine similarity and train linear classifiers (Logistic Regression and SVM) for sense identification. They analyze three datasets: CPWS (short context, fixed position), sPWC (shorter context subset), and PWC (longer context). The approach combines quantitative probe accuracy with qualitative PCA analysis to localize contextualization strength across sub-layers.

## Key Results
- BERT shows highest contextualization for polysemous words in top sub-layers when words are in specific positions with shorter context windows
- Longer contexts (sPWC/PWC) yield poor linear probe performance for sense identification
- Sub-layer similarity patterns differ significantly across datasets, with Output sub-layers showing lower contextualization than SA/Acts for shorter contexts
- The CPWS dataset demonstrates clear sense separation in sub-layer representations, while longer contexts fail to show consistent patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sub-layer representations become increasingly dissimilar across transformer layers when context is short and position is fixed
- Mechanism: Self-Attention and Feed-Forward Activation sub-layers process input differently, creating divergent representations that encode sense-specific information more strongly than Output sub-layer
- Core assumption: Context length and word position directly influence the degree of contextualization in sub-layer representations
- Evidence anchors:
  - [abstract] "BERT demonstrates a high degree of contextualization in the top sub-layers if the word in question is in a specific position in the sentence with a shorter context window"
  - [section] "We observe that for shorter context windows... the Output sub-layer similarity is closer to one, indicating a lower degree of contextualization as compared to Acts and SA sub-layers"
- Break condition: When context window increases or word position varies, the sub-layer dissimilarity patterns break down

### Mechanism 2
- Claim: Linear probes can empirically identify where contextualization strength is highest by measuring classification accuracy across sub-layers
- Mechanism: Higher probe accuracy indicates better encoding of sense information in that sub-layer's representations
- Core assumption: Probe accuracy correlates with the amount of sense information encoded in sub-layer representations
- Evidence anchors:
  - [abstract] "by probing on a sense identification classification task, we try to empirically localize the strength of contextualization information encoded in these sub-layer representations"
  - [section] "The accuracies of the probing task using LR and SVM on all the three datasets are shown... For the CPWS dataset, both linear sense probe accuracies indicate that most information regarding the different senses of the polysemous words is encoded in middle and upper BERT layers"
- Break condition: When probe training data is insufficient or domain mismatch exists between pre-training corpus and target data

### Mechanism 3
- Claim: Context position and window size influence how well different sub-layers encode sense information, with fixed-position short contexts showing clearer patterns
- Mechanism: The combination of word position and context length determines which sub-layers process and retain sense-specific information
- Core assumption: Different context settings create different demands on sub-layer processing that reveal their contextualization capabilities
- Evidence anchors:
  - [abstract] "Our main conclusion is cautionary: BERT demonstrates a high degree of contextualization in the top sub-layers if the word in question is in a specific position in the sentence with a shorter context window, but this does not systematically generalize across different word positions and context sizes"
  - [section] "The major difference between both datasets is the position of the keyword and length of the context windows... we observe that the output sub-layers have a higher similarity than its respective SA sub-layer"
- Break condition: When context becomes sufficiently long or position varies enough, the clear contextualization patterns break down

## Foundational Learning

- Concept: Transformer architecture and sub-layer functions
  - Why needed here: Understanding how Self-Attention, Feed-Forward Activation, and Output sub-layers process information differently is essential for interpreting the contextualization patterns
  - Quick check question: What is the primary function of residual connections in transformer output sub-layers and how might they affect contextualization measurements?

- Concept: Linear probing methodology and its limitations
  - Why needed here: The paper relies on linear probe accuracy to measure contextualization strength, but probe performance has known limitations that affect interpretation
  - Quick check question: What are the key limitations of linear probes when measuring linguistic knowledge in neural representations?

- Concept: Word sense disambiguation and polysemy
  - Why needed here: The study investigates how different senses of polysemous words are encoded, requiring understanding of WSD task structure and evaluation
  - Quick check question: How does the multi-label classification setup for word sense identification differ from traditional WSD approaches?

## Architecture Onboarding

- Component map: Input sentences → BERT embedding → forward pass through all layers and sub-layers → extract sub-layer representations → compute similarity metrics OR train linear probes → evaluate contextualization
- Critical path: Extract sub-layer representations → compute similarity metrics → train linear probes → evaluate accuracy and perform PCA analysis
- Design tradeoffs: Using linear probes provides simplicity and interpretability but may miss complex patterns; fixed-position short contexts create clean experimental conditions but limit generalizability
- Failure signatures: Poor probe performance could indicate insufficient training data, domain mismatch, label imbalance, or that linear probes cannot capture the encoded sense information
- First 3 experiments:
  1. Extract and compare sub-layer representations for polysemous word pairs in CPWS dataset to verify similarity patterns across different sub-layers
  2. Train and evaluate linear probes on CPWS dataset to confirm that middle and upper layers show highest contextualization for fixed-position short contexts
  3. Test linear probes on sPWC dataset to investigate how probe performance degrades with single-sentence-per-sense setup and longer contexts

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions beyond its general cautionary conclusion about the limitations of generalizing contextualization patterns across different word positions and context sizes.

## Limitations

- Reliance on linear probing may not capture the full complexity of how sense information is encoded in sub-layer representations
- Results may be highly dataset-dependent, with poor generalization across different word positions and context sizes
- sPWC and PWC datasets show poor probe performance potentially due to label imbalance, domain mismatch, or single-sentence-per-sense setup limitations

## Confidence

**High Confidence**: CPWS dataset shows clear sense separation in sub-layer representations and middle/upper layers encode most sense information for fixed-position short contexts.

**Medium Confidence**: Context position and window size influence how well different sub-layers encode sense information, though underlying mechanisms and generalizability remain uncertain.

**Low Confidence**: Generalizability of findings to other pre-trained models beyond BERT-base-uncased or to languages other than English.

## Next Checks

1. Repeat linear probing experiments using non-linear classifiers (e.g., MLPs or fine-tuned BERT) to determine whether poor performance on sPWC/PWC datasets is due to linear probe limitations or genuinely insufficient encoding of sense information.

2. Systematically vary the position of polysemous words within sentences while keeping context length constant to isolate the effects of position versus context size on sub-layer contextualization patterns.

3. Fine-tune BERT on a subset of the target datasets before extracting representations and re-run probing experiments to assess whether domain mismatch contributes to poor probe performance observed in longer context datasets.