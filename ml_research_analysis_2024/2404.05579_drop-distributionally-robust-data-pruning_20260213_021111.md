---
ver: rpa2
title: 'DRoP: Distributionally Robust Data Pruning'
arxiv_id: '2404.05579'
source_url: https://arxiv.org/abs/2404.05579
tags:
- pruning
- data
- dataset
- learning
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Data pruning methods remove redundant training samples to improve\
  \ efficiency and generalization, but their impact on classification bias\u2014disparate\
  \ performance across classes\u2014remains underexplored. This paper presents the\
  \ first systematic study of bias in data pruning, revealing that existing algorithms\
  \ can exacerbate performance disparities despite high average accuracy."
---

# DRoP: Distributionally Robust Data Pruning

## Quick Facts
- **arXiv ID**: 2404.05579
- **Source URL**: https://arxiv.org/abs/2404.05579
- **Reference count**: 40
- **Primary result**: Error-based class quotas improve worst-class performance when combined with random pruning.

## Executive Summary
Data pruning methods remove redundant training samples to improve efficiency and generalization, but their impact on classification bias—disparate performance across classes—remains underexplored. This paper presents the first systematic study of bias in data pruning, revealing that existing algorithms can exacerbate performance disparities despite high average accuracy. Through theoretical analysis of a Gaussian mixture model, the authors show that class-wise random pruning guided by error-based quotas can improve worst-class performance. They propose DRoP (Distributionally Robust Pruning), which selects pruning fractions per class based on validation errors, and demonstrate that DRoP combined with random pruning consistently reduces classification bias across multiple vision benchmarks. DRoP achieves superior worst-class accuracy and maintains strong average performance, outperforming existing pruning methods and cost-sensitive learning baselines, even on imbalanced datasets and in group-robustness settings.

## Method Summary
The paper proposes DRoP, which computes class-wise validation errors using a pre-trained query model and allocates pruning quotas inversely proportional to these errors. The method then applies random pruning within each class according to the allocated quotas. This approach is compared against existing pruning algorithms (EL2N, GraNd, Forgetting, Dynamic Uncertainty, CoreSet) and cost-sensitive learning baselines across multiple vision datasets (CIFAR-10, CIFAR-100, TinyImageNet, ImageNet, Waterbirds) using various architectures (VGG-16, VGG-19, ResNet-18, ResNet-50). The evaluation focuses on worst-class accuracy, recall disparities, and group-wise performance metrics.

## Key Results
- DRoP combined with random pruning consistently reduces classification bias across multiple vision benchmarks
- DRoP achieves superior worst-class accuracy while maintaining strong average performance
- DRoP outperforms existing pruning methods and cost-sensitive learning baselines, even on imbalanced datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Error-based class quotas improve worst-class performance more than global pruning strategies.
- Mechanism: By allocating pruning fractions inversely proportional to class validation errors, DRoP retains more samples from classes the model struggles with, directly improving worst-class accuracy.
- Core assumption: Class-wise error rates on a validation set are predictive of difficulty and correlate with the variance in the feature space.
- Evidence anchors:
  - [abstract] "They propose DRoP (Distributionally Robust Pruning), which selects pruning fractions per class based on validation errors"
  - [section] "Given a dataset originally with class sizes N0 and N1, we replace the worst-class optimal condition d0N0σ1 = d1N1σ0 with d0R1[t∗(N0/N1)] = d1R0[t∗(N0/N1)]"
- Break condition: If validation errors are noisy or uncorrelated with actual difficulty, the quota allocation becomes ineffective.

### Mechanism 2
- Claim: Random pruning within each class is superior to score-based sample selection for robustness.
- Mechanism: Random subsampling avoids over-pruning "representative" samples that score-based methods might eliminate, preserving the overall class distribution needed for robust decision boundaries.
- Core assumption: Existing pruning scores correlate more with sample representativeness than with actual difficulty, leading to imbalance.
- Evidence anchors:
  - [abstract] "While these target quotas already improve robustness when combined with existing pruning algorithms, they particularly shine when applied together with random pruning"
  - [section] "We find theoretical justification for the phenomenal success of this simple strategy in a toy classification model"
- Break condition: If classes have very different intra-class variances, random pruning may remove critical hard samples.

### Mechanism 3
- Claim: Theoretical analysis of a Gaussian mixture model provides a principled basis for class quotas.
- Mechanism: In a two-class Gaussian mixture, worst-class optimal priors are proportional to class variances; DRoP approximates this by using validation errors as a proxy.
- Core assumption: Validation error scales similarly to variance in the feature space, making it a reasonable proxy for the optimal quota formula.
- Evidence anchors:
  - [abstract] "We present theoretical analysis of the classification risk in a mixture of Gaussians to argue that choosing appropriate class pruning ratios, coupled with random pruning within classes has potential to improve worst-class performance"
  - [section] "From Equation 3, t∗(σ0/σ1) = ˆt because the logarithm in the discriminant vanishes and we obtain Equation 4"
- Break condition: If class distributions are not well-modeled by Gaussians, the variance-based intuition may fail.

## Foundational Learning

- **Concept**: Distributionally Robust Optimization (DRO)
  - Why needed here: DRoP draws inspiration from DRO by focusing on worst-case class performance rather than average accuracy.
  - Quick check question: What is the key difference between minimizing average risk and minimizing worst-class risk in classification?

- **Concept**: Data Pruning Scoring Mechanisms
  - Why needed here: Understanding how existing pruning methods assign utility scores to samples explains why they can hurt robustness.
  - Quick check question: Why might a sample that is "easy" to classify still be important for maintaining class balance?

- **Concept**: Gaussian Mixture Models and Linear Decision Rules
  - Why needed here: The theoretical analysis uses a two-class Gaussian mixture to derive optimal class quotas for worst-class performance.
  - Quick check question: In a balanced two-class Gaussian mixture with unequal variances, which class is harder and why?

## Architecture Onboarding

- **Component map**: Query model training → class-wise validation error computation → DRoP quota calculation → random pruning within classes → final model training
- **Critical path**: The bottleneck is query model training; all subsequent steps depend on accurate class error estimates.
- **Design tradeoffs**: Random pruning sacrifices some average accuracy for robustness; error-based quotas require a held-out validation set.
- **Failure signatures**: If worst-class accuracy does not improve despite DRoP quotas, suspect noisy validation error estimates or poor class error-variance correlation.
- **First 3 experiments**:
  1. Train a baseline query model on full data, compute class-wise errors, apply DRoP quotas, and prune randomly; compare worst-class accuracy vs full dataset.
  2. Replace random pruning with a score-based method (e.g., EL2N) using the same DRoP quotas; measure impact on worst-class accuracy.
  3. Vary the amount of pre-training for the query model (e.g., 5, 10, 20 epochs) and observe stability of DRoP's effectiveness.

## Open Questions the Paper Calls Out
- Does DRoP maintain its robustness benefits when applied to pruning methods beyond those tested in this study, such as CoreSet or newer dynamic uncertainty algorithms?
- What is the theoretical relationship between the Gaussian mixture model analysis and real-world deep learning scenarios, particularly regarding how class difficulty relates to variance in the feature space?
- How does DRoP perform in domain generalization and out-of-distribution settings where class distributions shift between training and test data?

## Limitations
- The theoretical framework relies on Gaussian mixture assumptions that may not hold for real-world datasets with complex, non-Gaussian class distributions.
- The empirical evaluation depends on validation error estimates that could be noisy, particularly for classes with limited samples.
- Results may not transfer to other domains or tasks where class difficulty manifests differently.

## Confidence

- **High Confidence**: The core finding that error-based class quotas can improve worst-class performance when combined with random pruning is well-supported by both theoretical analysis and empirical results.
- **Medium Confidence**: The superiority of random pruning over score-based methods for robustness is demonstrated but may be dataset-dependent.
- **Low Confidence**: The theoretical analysis based on Gaussian mixture models provides a useful framework but may not accurately predict behavior for complex, real-world distributions.

## Next Checks
1. Test DRoP on datasets with known non-Gaussian distributions to assess the robustness of the Gaussian mixture-based theoretical predictions.
2. Conduct ablation studies varying the quality and size of validation sets to determine the sensitivity of DRoP to noisy or limited validation error estimates.
3. Apply DRoP to non-vision tasks (e.g., text classification or speech recognition) to evaluate cross-domain generalizability of the approach.