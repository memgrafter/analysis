---
ver: rpa2
title: 'MIKO: Multimodal Intention Knowledge Distillation from Large Language Models
  for Social-Media Commonsense Discovery'
arxiv_id: '2402.18169'
source_url: https://arxiv.org/abs/2402.18169
tags:
- intentions
- intention
- social
- media
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents M/i.sc/k.sc/o.sc, a novel framework for extracting
  user intentions from multimodal social media posts. It combines image captioning
  via MLLM (LLaVA) with text analysis via LLM (ChatGPT) to generate comprehensive
  intention profiles.
---

# MIKO: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery

## Quick Facts
- arXiv ID: 2402.18169
- Source URL: https://arxiv.org/abs/2402.18169
- Authors: Feihong Lu; Weiqi Wang; Yangyifei Luo; Ziqin Zhu; Qingyun Sun; Baixuan Xu; Haochen Shi; Shiqi Gao; Qian Li; Yangqiu Song; Jianxin Li
- Reference count: 40
- Key outcome: Novel framework for extracting user intentions from multimodal social media posts using hierarchical prompting and knowledge distillation

## Executive Summary
This paper introduces MIKO, a novel framework for extracting user intentions from multimodal social media posts by combining image captioning via MLLM (LLaVA) with text analysis via LLM (ChatGPT). The framework processes each post through three stages: image description, key information extraction, and intention generation using 9 ATOMIC-based relation types plus open-ended intents. Applied to 137,287 social media posts, it generates 1.37M intentions. Human evaluation shows high quality with 60%+ plausibility and typicality scores. Benchmark testing reveals most LLMs struggle with direct intention generation, while fine-tuning on MIKO's output significantly improves performance.

## Method Summary
MIKO processes social media posts through a three-stage hierarchical framework: first using LLaVA to generate image descriptions, then ChatGPT to extract key information (concept, action, object, emotion, keywords) from both text and image descriptions, and finally ChatGPT again to generate intentions using 9 ATOMIC relations plus open-ended intents. The framework applies this process to 137,287 social media posts, generating 1.37M intentions. High-quality intentions are then used to fine-tune a Llama2-7B model for more efficient intention extraction. The distilled intentions are evaluated through human annotation and benchmarked against other LLMs, with extrinsic evaluation on sarcasm detection demonstrating state-of-the-art results.

## Key Results
- Generated 1.37M intentions from 137,287 social media posts with 60%+ human-annotated plausibility and typicality scores
- Most LLMs fail at direct intention generation, but fine-tuning on MIKO-generated intentions significantly improves performance
- Incorporating generated intentions into sarcasm detection achieves state-of-the-art results
- Human evaluation on 1,000 posts shows intentions are highly plausible and typical

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical prompting with LLM and MLLM enables multimodal intention extraction that single-model approaches cannot achieve. The framework uses LLava to generate image descriptions, then ChatGPT to extract key information from both text and image descriptions, and finally ChatGPT again to generate intentions. This staged approach bridges vision and text modalities while filtering noise.

### Mechanism 2
Fine-tuning smaller models on distilled intention knowledge significantly improves their intention generation capability. The framework uses high-quality intentions generated by ChatGPT as training data to fine-tune Llama2-7B, creating a more efficient model for intention extraction while maintaining performance.

### Mechanism 3
Intention knowledge improves downstream task performance, particularly in sarcasm detection. Generated intentions are appended to original posts and image descriptions as additional context for sarcasm detection models, improving their ability to identify sarcastic content.

## Foundational Learning

- **Multimodal understanding and cross-modal reasoning**: Social media posts contain both text and images that need to be jointly interpreted to understand user intentions. Quick check: Can you explain why a sarcastic image caption might require understanding both the visual content and the textual message together?

- **Knowledge distillation and fine-tuning**: The framework uses a powerful LLM to generate high-quality intentions, then distills this knowledge into smaller, more efficient models. Quick check: What's the difference between zero-shot learning and fine-tuning, and why would fine-tuning be beneficial for intention extraction?

- **Prompt engineering and structured output generation**: The framework relies on carefully designed prompts to guide LLMs through specific tasks like image description, key information extraction, and intention generation. Quick check: How does providing explicit structure in prompts (like asking for specific relation types) improve the consistency and quality of generated outputs?

## Architecture Onboarding

- **Component map**: Input: Social media post (text + image) → MLLM (LLava): Generates image descriptions → LLM (ChatGPT): Extracts key information → LLM (ChatGPT): Generates intentions → Human annotation: Validates quality → Fine-tuned model (Llama2-7B): Trained on high-quality intentions → Downstream task (sarcasm detection): Uses intentions as additional features

- **Critical path**: Input → MLLM → LLM (key info) → LLM (intentions) → human validation → fine-tuning → downstream task

- **Design tradeoffs**: Accuracy vs efficiency: Using ChatGPT provides high-quality intentions but is computationally expensive; fine-tuning a smaller model balances quality and efficiency. Completeness vs specificity: Including 9 ATOMIC relations ensures comprehensive coverage but may generate some irrelevant intentions. Automation vs human oversight: Full automation would be faster but human annotation ensures quality control

- **Failure signatures**: Poor image descriptions from MLLM → downstream intentions lack visual context. LLM hallucinations in key information → intentions become implausible. Inconsistent intention generation → downstream models receive conflicting signals. Overfitting during fine-tuning → model performs poorly on unseen data

- **First 3 experiments**: 1) Run the pipeline end-to-end on a small dataset (10-20 posts) and manually verify each stage's output quality. 2) Compare intention generation quality between direct prompting vs hierarchical approach on the same dataset. 3) Fine-tune a small model on a subset of high-quality intentions and evaluate its performance on held-out data

## Open Questions the Paper Calls Out

### Open Question 1
What is the specific impact of image descriptions on intention generation quality when using different MLLMs (e.g., LLaVA vs. other models)? The paper mentions using LLaVA for image captioning but does not compare its performance against other MLLMs for this task. What evidence would resolve it: Comparative experiments showing intention generation quality using different MLLMs for image captioning, with quantitative metrics and human evaluation scores.

### Open Question 2
How does the framework perform when applied to languages other than English, and what modifications would be needed? The paper focuses exclusively on English social media posts and mentions GLM4's poor performance on English due to Chinese training data, suggesting potential language limitations. What evidence would resolve it: Experiments applying MIKO to multilingual social media datasets, with performance comparisons and analysis of language-specific challenges.

### Open Question 3
What is the long-term temporal stability of the generated intentions, and how do user intentions evolve over time? The framework is applied to static datasets without temporal analysis of intention changes or stability over time. What evidence would resolve it: Longitudinal studies tracking intention generation over time periods, with analysis of temporal patterns and intention drift.

## Limitations
- Heavy reliance on proprietary LLMs (ChatGPT, LLaVA) creates dependency on external APIs and potential reproducibility issues
- Human evaluation covers only 1,000 posts out of 137,287, leaving significant uncertainty about overall quality
- Generated intentions may introduce systematic biases based on the ATOMIC relations framework and prompting strategies used

## Confidence
- **High Confidence**: The framework's ability to generate large-scale intention data from multimodal social media posts is well-demonstrated through the 1.37M intentions produced
- **Medium Confidence**: Human evaluation scores (60%+ plausibility and typicality) suggest reasonable quality, but limited sample size and potential rater bias affect certainty
- **Medium Confidence**: The effectiveness of fine-tuning smaller models on distilled intentions is supported by experiments, though the generalizability to other tasks remains uncertain
- **Low Confidence**: Claims about state-of-the-art sarcasm detection improvements need more rigorous ablation studies to isolate the contribution of intention features

## Next Checks
1. Test the fine-tuned Llama2-7B model on additional downstream tasks beyond sarcasm detection (e.g., sentiment analysis, offensive content detection) to assess generalizability of the distilled intention knowledge
2. Expand human annotation to 5,000+ posts with multiple raters per post to establish more robust quality metrics and identify systematic biases in intention generation
3. Implement and compare against direct end-to-end intention generation approaches (without hierarchical prompting) to quantify the specific contribution of the staged architecture