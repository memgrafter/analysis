---
ver: rpa2
title: A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for
  Object Detection in Autonomous Vehicles
arxiv_id: '2412.06215'
source_url: https://arxiv.org/abs/2412.06215
tags:
- patch
- adversarial
- adav
- object
- clean
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ADAV is a real-time defense against object vanishing adversarial
  patch attacks in autonomous vehicle perception. It detects patches by measuring
  temporal inconsistency between consecutive video frames and localizes them using
  gradient-based attribution.
---

# A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for Object Detection in Autonomous Vehicles

## Quick Facts
- **arXiv ID**: 2412.06215
- **Source URL**: https://arxiv.org/abs/2412.06215
- **Reference count**: 15
- **Primary result**: ADAV achieves 0.36 mAP on adversarial inputs versus 0.22 for undefended models, while retaining 0.44 mAP on clean data

## Executive Summary
ADAV presents a real-time defense mechanism against object vanishing adversarial patch attacks specifically targeting object detection in autonomous vehicles. The approach leverages temporal inconsistency between consecutive video frames to detect adversarial patches, then uses gradient-based attribution to localize and remove them. By preserving clean performance while significantly improving robustness against attacks, ADAV addresses a critical security vulnerability in autonomous driving perception systems.

## Method Summary
ADAV employs a two-stage defense mechanism consisting of patch detection and localization phases. The detection stage measures temporal inconsistency between consecutive video frames, identifying patches that would cause object vanishing through their temporal instability. The localization stage uses gradient-based attribution methods to pinpoint the exact location of detected patches within frames. This approach maintains real-time performance with latency between 15-35ms while preserving detection accuracy on clean inputs.

## Key Results
- Achieves 0.36 mAP on adversarial inputs versus 0.22 for undefended models
- Retains 0.44 mAP on clean data, preserving normal performance
- Detection accuracy exceeds 88% for large patches with 95% recall

## Why This Works (Mechanism)
The defense exploits the fundamental vulnerability of object vanishing attacks: they create temporal inconsistency in video sequences. While clean objects move smoothly across frames, adversarial patches cause abrupt appearance/disappearance of objects, which violates temporal consistency assumptions. By measuring this inconsistency and using gradient attribution to localize the patches, ADAV can effectively detect and mitigate attacks in real-time without significantly impacting clean performance.

## Foundational Learning
**Temporal Consistency Analysis**: Understanding how objects should move smoothly across video frames over time; needed to establish baseline for detecting abnormal behavior caused by adversarial patches; quick check: verify smooth object trajectories in clean video sequences.

**Gradient-based Attribution**: Methods for determining which input regions most influence model predictions; needed to localize patches based on their impact on detection results; quick check: validate attribution maps highlight adversarial regions accurately.

**Real-time Performance Constraints**: Balancing computational efficiency with detection accuracy; needed to ensure the defense can operate within autonomous vehicle timing requirements; quick check: measure latency across different hardware configurations.

## Architecture Onboarding

**Component Map**: Video Frames -> Temporal Consistency Module -> Patch Detection -> Gradient Attribution Module -> Patch Localization -> Cleaned Detection Output

**Critical Path**: Input video frames → temporal difference computation → inconsistency scoring → gradient attribution for localization → patch removal → final detection output

**Design Tradeoffs**: Temporal window size versus detection accuracy (larger windows improve detection but increase latency); gradient attribution method complexity versus localization precision; detection threshold versus false positive rate.

**Failure Signatures**: High false positive rates in scenarios with rapid camera movement or occlusions; missed detections when attacks maintain temporal consistency; performance degradation with smaller or more subtle patches.

**First Experiments**:
1. Measure temporal inconsistency metrics on clean versus attacked video sequences
2. Evaluate gradient attribution accuracy for patch localization across different attack sizes
3. Benchmark end-to-end latency with varying temporal window sizes

## Open Questions the Paper Calls Out
None

## Limitations
The temporal consistency assumption may fail in scenarios with high object motion, rapid camera movement, or occlusions, potentially causing false positives. The defense is specifically designed for object vanishing attacks and may not generalize to other attack types like object creation or localization attacks. Performance evaluation is limited to the BDD100K dataset, which may not fully represent all driving scenarios and conditions.

## Confidence
High confidence in detection mechanism effectiveness given 88%+ accuracy for large patches with 95% recall. Medium confidence in overall defense effectiveness due to limited evaluation across diverse datasets and attack variants. Medium confidence in real-time performance claims, as 15-35ms latency needs validation across different hardware configurations.

## Next Checks
1. Evaluate ADAV across multiple diverse driving datasets (KITTI, nuScenes, Cityscapes) to assess generalizability beyond BDD100K.

2. Test the defense against adaptive attacks where adversaries are aware of the temporal consistency mechanism and attempt to maintain temporal consistency while still causing object vanishing.

3. Integrate ADAV into a complete autonomous driving perception pipeline and measure end-to-end impact on downstream tasks like tracking, planning, and control latency.