---
ver: rpa2
title: 'CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language
  Models'
arxiv_id: '2409.19984'
source_url: https://arxiv.org/abs/2409.19984
tags:
- language
- autoregressive
- probabilities
- llama
- well
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CONTESTS, a framework for consistency testing
  of span probabilities in language models. It uses statistical tests to evaluate
  whether models produce the same joint probability for word spans when computed via
  different completion and conditioning orders.
---

# CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models

## Quick Facts
- arXiv ID: 2409.19984
- Source URL: https://arxiv.org/abs/2409.19984
- Reference count: 40
- Primary result: Language models exhibit inconsistent joint probabilities for word spans when computed via different completion orders

## Executive Summary
This paper introduces CONTESTS, a framework for consistency testing of span probabilities in language models. The framework uses statistical tests to evaluate whether models produce the same joint probability for word spans when computed via different completion and conditioning orders. Experiments on real and synthetic data show that both Masked Language Models (MLMs) and autoregressive models exhibit inconsistent predictions, with autoregressive models showing larger discrepancies. The findings reveal model-type differences and provide guidance for future research addressing these limitations.

## Method Summary
The CONTESTS framework evaluates language model consistency by comparing joint probability estimates Pi,i+1 and Pi+1,i for adjacent tokens using two inference steps per direction. The framework employs statistical tests (Wilcoxon rank tests with Benjamini-Yekutieli correction) to assess significance of discrepancies. It analyzes real datasets (Wikitext-27 and custom News dataset) and synthetic data generated from predetermined spans, testing various model sizes including RoBERTa, XLM-RoBERTa, ELECTRA, Flan-T5, and LLAMA 2 models. The framework also examines prediction entropies to understand their connection to true word span likelihood and optimal decoding strategies.

## Key Results
- Both MLMs and autoregressive models exhibit inconsistent predictions, with autoregressive models showing larger discrepancies
- Larger MLMs tend to produce more consistent predictions, while autoregressive models show the opposite trend
- Prediction entropies offer insights into true word span likelihood and can aid in selecting optimal decoding strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masked Language Models (MLMs) and autoregressive models produce inconsistent joint probabilities for adjacent word spans when computed via different completion orders.
- Mechanism: The framework compares joint probability estimates Pi,i+1 and Pi+1,i for adjacent tokens using two inference steps per direction. Differences arise because each inference step conditions on slightly different intermediate states, leading to asymmetric probability assignments even for the same word span.
- Core assumption: The models are expected to produce consistent probabilities across different completion orders if they were perfectly calibrated, but practical limitations cause deviations.
- Evidence anchors:
  - [abstract] "Our findings reveal that both Masked Language Models (MLMs) and autoregressive models exhibit inconsistent predictions, with autoregressive models showing larger discrepancies."
  - [section 2] "Although for the true distribution we have that Pi,i+1 = Pi+1,i, this may not hold for estimated probabilities since each direction involves two inference steps, each with slightly different inputs."
  - [corpus] Weak: Corpus mentions span-based evaluation frameworks but does not directly address probability consistency testing.
- Break condition: If the models were trained with explicit constraints ensuring consistency across completion orders, or if the probability estimation process were deterministic and order-independent.

### Mechanism 2
- Claim: Prediction entropies provide insights into the true likelihood of word spans and can guide optimal decoding strategy selection.
- Mechanism: Higher entropy in single-mask predictions and lower entropy in two-mask predictions correlate with higher joint probabilities for true tokens. This suggests that entropy can serve as a proxy for confidence and likelihood estimation, helping select the decoding order that maximizes the probability of correct completions.
- Core assumption: Entropy of predicted probabilities is indicative of the model's confidence and the likelihood of the true token sequence.
- Evidence anchors:
  - [abstract] "Moreover, for both model types, prediction entropies offer insights into the true word span likelihood and therefore can aid in selecting optimal decoding strategies."
  - [section 9] "These results suggest that selecting the direction with higher entropy for one-mask prediction and lower entropy for two masks is likely to increase the likelihood of true tokens."
  - [corpus] Weak: Corpus includes span-based evaluation but does not discuss entropy as a guide for decoding strategies.
- Break condition: If entropy correlations with true likelihood are weak or inconsistent across different datasets or model types, reducing its utility as a guide.

### Mechanism 3
- Claim: Larger MLMs tend to produce more consistent predictions, while autoregressive models show the opposite trend, with larger models exhibiting larger discrepancies.
- Mechanism: Model size influences the variance of discrepancy distributions. For MLMs, increasing parameters reduces inconsistency variance, suggesting better calibration. For autoregressive models, larger models show increased variance, indicating that scaling up may exacerbate inconsistency issues in these architectures.
- Core assumption: Model architecture and training objectives influence how model size affects consistency, with MLMs benefiting from larger scales while autoregressive models do not.
- Evidence anchors:
  - [abstract] "Larger MLMs tend to produce more consistent predictions, while autoregressive models show the opposite trend."
  - [section 7.2] "The results on both datasets indicate with significance level Î± < 0.001 that the variance increases with the growth of the number of parameters."
  - [corpus] Weak: Corpus does not provide direct evidence about model size effects on consistency.
- Break condition: If the trend reverses at even larger scales or if other factors (like training data size) dominate the effect of model size on consistency.

## Foundational Learning

- Concept: Gibbs' inequality and its implications for language model training
  - Why needed here: Understanding why cross-entropy loss minimization doesn't guarantee perfect probability estimation is crucial for interpreting model inconsistencies.
  - Quick check question: If a model perfectly minimizes cross-entropy loss, does that guarantee calibrated probabilities for all possible sequences?

- Concept: Statistical hypothesis testing and multiple comparison corrections
  - Why needed here: The framework relies on Wilcoxon rank tests to assess significance of discrepancies, requiring understanding of non-parametric tests and corrections for multiple comparisons.
  - Quick check question: Why is the Benjamini-Yekutieli correction used instead of simpler methods like Bonferroni when testing multiple models?

- Concept: Entropy as a measure of uncertainty in probability distributions
  - Why needed here: Entropy analysis is central to understanding how prediction uncertainty relates to likelihood estimation and decoding strategy selection.
  - Quick check question: How does entropy behave differently for single-mask versus two-mask predictions, and why does this matter for consistency?

## Architecture Onboarding

- Component map: Data preprocessing (tokenization, mask placement) -> Model inference (computing joint probabilities Pi,i+1 and Pi+1,i) -> Discrepancy calculation (log-scale differences) -> Statistical testing (Wilcoxon rank tests with multiple comparison corrections) -> Analysis modules (linear regression for factor analysis, entropy correlation analysis)
- Critical path: Tokenize input -> Apply masks -> Compute joint probabilities Pi,i+1 and Pi+1,i -> Calculate log-scale discrepancies -> Perform Wilcoxon test -> Analyze results for significance and patterns
- Design tradeoffs: Using statistical tests provides robustness to outliers but may miss subtle inconsistencies; focusing on adjacent tokens simplifies analysis but may not capture all inconsistency patterns; synthetic data allows controlled experiments but may not reflect real-world behavior
- Failure signatures: High variance in discrepancies across models suggests architecture-specific issues; consistent patterns across datasets indicate training-independent problems; correlation between entropy and discrepancy suggests probabilistic confidence issues
- First 3 experiments:
  1. Run the framework on a small dataset with a single MLM to verify basic functionality and check if discrepancies are near zero for perfectly consistent cases.
  2. Test with an autoregressive model on the same dataset to compare discrepancy patterns between model types.
  3. Analyze entropy correlations with discrepancies to validate if entropy can predict optimal decoding order.

## Open Questions the Paper Calls Out

- Does the CONTESTS framework reveal statistically significant inconsistencies in larger word spans beyond two adjacent tokens?
- What specific architectural features of autoregressive models cause larger discrepancies compared to MLMs as model size increases?
- How does instruction tuning affect consistency across different model types and sizes?

## Limitations

- The framework's reliance on adjacent token pairs may not capture all consistency issues in longer sequences
- Statistical testing approach may be overly conservative, potentially masking genuine inconsistencies
- The choice of synthetic data generation method and its impact on results remains unclear

## Confidence

**High Confidence**: The core finding that both MLM and autoregressive models exhibit inconsistencies in span probability estimation.

**Medium Confidence**: The claim about larger MLMs showing more consistency while larger autoregressive models show less.

**Low Confidence**: The practical utility of entropy-based decoding strategy selection.

## Next Checks

1. Extend the consistency testing framework to evaluate non-adjacent token spans and longer sequences to determine if observed inconsistencies scale or remain localized to adjacent pairs.

2. Design experiments that measure how consistency-related discrepancies affect actual task performance when using different decoding strategies informed by entropy analysis.

3. Implement and test simple training modifications (such as consistency regularization or auxiliary consistency loss) to determine if observed inconsistencies can be reduced without significant performance degradation on standard benchmarks.