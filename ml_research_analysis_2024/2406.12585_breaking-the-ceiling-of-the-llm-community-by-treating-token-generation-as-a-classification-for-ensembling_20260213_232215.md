---
ver: rpa2
title: Breaking the Ceiling of the LLM Community by Treating Token Generation as a
  Classification for Ensembling
arxiv_id: '2406.12585'
source_url: https://arxiv.org/abs/2406.12585
tags:
- ensemble
- token
- llms
- arxiv
- ensembling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel token-level ensemble framework, GAC,
  for Large Language Models (LLMs) by treating each token generation step as a classification
  task. Unlike prior methods that ensemble only at the output level, GAC fully exploits
  probability information at every generation step by mapping each model's probability
  vectors to a unified vocabulary space and averaging them.
---

# Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling

## Quick Facts
- **arXiv ID:** 2406.12585
- **Source URL:** https://arxiv.org/abs/2406.12585
- **Reference count:** 38
- **One-line primary result:** GAC ensemble significantly outperforms any individual state-of-the-art LLM and existing ensemble methods across five benchmarks with average accuracy improvements of 3.13% to 4.47%.

## Executive Summary
This paper introduces GAC (Generation-level All-Token Classification), a novel token-level ensemble framework for Large Language Models (LLMs) that treats each token generation step as a classification task. Unlike traditional output-level ensembling, GAC fully exploits probability information at every generation step by mapping each model's probability vectors to a unified vocabulary space and averaging them. The approach demonstrates significant performance improvements across multiple benchmarks including MMLU, GSM8K, BBH, TriviaQA, and NQ, while also offering an efficient thresholded ensembling variant that achieves comparable results with up to 92.32% fewer tokens ensembled.

## Method Summary
GAC creates a union vocabulary from all participating LLMs and constructs mapping matrices to project each model's probability distributions to this unified space. At each generation step, probability vectors from all models are mapped and averaged to produce an ensemble distribution from which the next token is sampled. The framework includes a cascade inference mechanism for thresholded ensembling, where a gate model determines whether to ensemble based on confidence thresholds. The method requires multiple GPUs to run different LLMs in parallel and involves significant preprocessing to establish vocabulary mappings and calibration measurements.

## Key Results
- GAC significantly outperforms any individual state-of-the-art LLM and existing ensemble methods across five benchmarks
- Average accuracy improvements of 3.13% to 4.47% over the best single model at each time period
- Thresholded ensembling achieves comparable performance with up to 92.32% fewer tokens ensembled and lower latency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Token-level ensembling outperforms output-level ensembling by preventing early incorrect tokens from snowballing into later errors.
- Mechanism: By averaging probability distributions at each generation step, GAC ensures that even if one model generates an incorrect token, other models with higher confidence can override it, maintaining the correct generation path.
- Core assumption: The probability distributions from different LLMs at each step reflect their relative confidence in the correctness of the token, and averaging these distributions leads to a more accurate selection.
- Evidence anchors:
  - [abstract] "This approach fully exploits the probability information at each generation step and better prevents LLMs from producing early incorrect tokens that lead to snowballing errors."
  - [section 2] "Another advantage is that early errors in LLMs often snowball into later errors (Zhang et al., 2023). Ensembling during generation helps prevent the generation of inaccurate tokens at each step, thereby reducing misleading cues for subsequent token generation."
  - [corpus] Weak evidence - the corpus papers focus on when to ensemble and bridging vocabulary gaps, but don't directly address the snowballing error mechanism.

### Mechanism 2
- Claim: The union of vocabularies from different LLMs is sufficiently consistent to allow direct mapping and averaging without significant information loss.
- Mechanism: Most LLMs use similar tokenization methods (BPE or BBPE) trained on similar corpora, resulting in high overlap in their token vocabularies. This allows the creation of a mapping matrix to project probability vectors to a unified space for averaging.
- Core assumption: The similarity in tokenization methods and training corpora leads to high consistency in how common words are tokenized across different LLMs.
- Evidence anchors:
  - [section 3.2] "We selected several popular LLMs (Young et al., 2024; Databricks, 2024; Almazrouei et al., 2023) and tokenized 5,000 commonly used English words (Oxford, 2018), and then calculated the proportion of identical tokenization results between each pair of LLMs, as shown in Fig.2. The proportion is above 90% for all pairs, indicating that such conflicts can be ignored in most cases."
  - [section 2] "However, most mainstream LLMs use BPE or BBPE (Sennrich et al., 2015; Wang et al., 2020) to train tokenizers on sampled corpora, which tend to have similar sources (e.g. CommonCrawl) and distributions."
  - [corpus] Weak evidence - the corpus papers discuss vocabulary discrepancies and methods to bridge them, but don't provide evidence for the high consistency assumption.

### Mechanism 3
- Claim: The Expected Calibration Error (ECE) of LLMs is sufficiently low to allow confidence-based thresholded ensembling for improved efficiency.
- Mechanism: By using a gate model to determine when to ensemble based on confidence thresholds, GAC can reduce computational cost while maintaining performance, as the confidence scores accurately reflect the model's accuracy.
- Core assumption: The ECE of LLMs is comparable to that of CV models, suggesting that their confidence scores are reliable indicators of accuracy.
- Evidence anchors:
  - [abstract] "ECE is a metric that reflects the difference between a model's confidence and its accuracy. We found that the ECE of CV models and LLMs were close."
  - [section 1] "We measured the Expected Calibration Error (ECE) (Guo et al., 2017) of CV models and LLMs on ImageNet and MMLU (Hendrycks et al., 2020), as shown in Tab.1. ECE is a metric that reflects the difference between a model's confidence and its accuracy. We found that the ECE of CV models and LLMs were close."
  - [corpus] Weak evidence - the corpus papers discuss calibration and ensemble strategies, but don't provide direct evidence for the ECE comparison between CV models and LLMs.

## Foundational Learning

- **Concept**: Probability distributions and their interpretation in the context of token generation by LLMs.
  - **Why needed here**: Understanding how LLMs generate tokens based on probability distributions is crucial for comprehending the GAC approach of averaging these distributions for ensembling.
  - **Quick check question**: If an LLM outputs a probability distribution [0.7, 0.2, 0.1] for the next token, what does each value represent, and how would this distribution be used in the GAC framework?

- **Concept**: Tokenization methods (BPE, BBPE) and their impact on vocabulary consistency across different LLMs.
  - **Why needed here**: The success of the GAC approach relies on the assumption that different LLMs have sufficiently consistent vocabularies due to similar tokenization methods. Understanding these methods is essential for evaluating this assumption.
  - **Quick check question**: How do BPE and BBPE tokenization methods work, and why might they lead to high consistency in tokenization across different LLMs trained on similar corpora?

- **Concept**: Expected Calibration Error (ECE) and its significance in evaluating the reliability of confidence scores.
  - **Why needed here**: The GAC framework uses confidence-based thresholded ensembling, which relies on the assumption that the ECE of LLMs is low enough for their confidence scores to be reliable indicators of accuracy.
  - **Quick check question**: What is Expected Calibration Error (ECE), and how does it relate to the reliability of a model's confidence scores in predicting its actual accuracy?

## Architecture Onboarding

- **Component map**: Input prompt → Tokenization (each LLM) → Generation (probability distribution) → Mapping to union vocabulary → Averaging → Sampling → Output token (converted back to token IDs)

- **Critical path**: Prompt → Tokenization → Generation → Mapping → Ensembling → Sampling → Output

- **Design tradeoffs**:
  - Vocabulary mapping: Creating a union vocabulary and mapping matrices adds overhead but enables direct averaging of probability distributions.
  - Ensemble frequency: Ensembling at every step provides maximum accuracy but increases computational cost. Thresholded ensembling reduces cost but may miss some errors.
  - Model selection: Including more models in the ensemble can improve accuracy but also increases computational cost and may lead to diminishing returns.

- **Failure signatures**:
  - Poor performance: If the ensemble performs worse than individual models, it may indicate issues with vocabulary mapping, ensemble weights, or model selection.
  - High latency: If the ensemble is significantly slower than individual models, it may indicate inefficiencies in the mapping process or insufficient parallelization.
  - Inconsistent results: If the ensemble produces inconsistent outputs across runs, it may indicate issues with the sampling process or the stability of the ensemble distribution.

- **First 3 experiments**:
  1. Verify vocabulary consistency: Tokenize a set of common words using different LLMs and calculate the overlap in their tokenizations to validate the assumption of high consistency.
  2. Test ensemble weights: Experiment with different ensemble weights (e.g., averaging, model-specific weights based on performance) to determine the optimal weighting scheme for the GAC framework.
  3. Evaluate thresholded ensembling: Implement a thresholded ensembling approach and test its impact on performance and latency across different benchmarks to determine the optimal threshold value.

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding optimal ensemble weight strategies across different LLM combinations and task types, how GAC performance scales with the size and diversity of the ensemble pool, the theoretical explanation for why most tokens don't significantly affect answer correctness, and how GAC can be optimized for inference efficiency beyond the thresholded approach.

## Limitations
- The vocabulary consistency assumption is tested on only 5,000 common words across a limited set of models, which may not generalize to all LLM pairs.
- The ECE comparison between CV models and LLMs is based on measurements from only two datasets (ImageNet and MMLU) and doesn't account for domain-specific variations in calibration quality.
- The experiments don't isolate whether performance improvements specifically come from preventing early errors versus other ensemble benefits.

## Confidence

- **High Confidence**: The core claim that token-level ensembling can improve LLM performance is well-supported by the experimental results across multiple benchmarks.
- **Medium Confidence**: The claim about preventing snowballing errors is plausible given the mechanism described, but the experiments don't specifically measure or demonstrate this effect.
- **Low Confidence**: The ECE comparison between CV models and LLMs and its implications for thresholded ensembling lacks sufficient evidence.

## Next Checks

1. **Snowballing Error Analysis**: Design an experiment that tracks error propagation in both token-level ensembling and output-level ensembling across multiple generation steps. Compare the rate at which initial errors compound in each approach to directly validate the snowballing prevention claim.

2. **Vocabulary Consistency Stress Test**: Test the vocabulary mapping approach across a broader range of LLM pairs, including those with different tokenization methods (not just BPE/BBPE variants) and training corpora. Measure the overlap for domain-specific vocabulary and rare tokens to establish the limits of the consistency assumption.

3. **ECE Domain Generalization**: Measure and compare ECE values for LLMs across multiple diverse benchmarks beyond MMLU, including domain-specific datasets where calibration might differ significantly. Test whether the thresholded ensembling approach maintains its effectiveness when ECE varies across domains.