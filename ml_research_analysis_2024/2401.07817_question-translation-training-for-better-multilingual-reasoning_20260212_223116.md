---
ver: rpa2
title: Question Translation Training for Better Multilingual Reasoning
arxiv_id: '2401.07817'
source_url: https://arxiv.org/abs/2401.07817
tags:
- english
- data
- multilingual
- question
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models perform well in English but struggle in other
  languages due to training data being mostly English. A common approach, translate-training,
  translates English data to multiple languages but is costly and produces poor translations
  for complex mathematical reasoning tasks.
---

# Question Translation Training for Better Multilingual Reasoning

## Quick Facts
- **arXiv ID:** 2401.07817
- **Source URL:** https://arxiv.org/abs/2401.07817
- **Authors:** Wenhao Zhu; Shujian Huang; Fei Yuan; Shuaijie She; Jiajun Chen; Alexandra Birch
- **Reference count:** 11
- **Primary result:** QAlign improves multilingual reasoning accuracy by 11.3% and 16.1% on MGSM and MSVAMP benchmarks

## Executive Summary
Large language models excel at English reasoning tasks but struggle with multilingual reasoning due to limited training data in non-English languages. This paper introduces Question Alignment (QAlign), a two-stage fine-tuning approach that first teaches models to translate reasoning questions into English, then leverages English instruction data for reasoning. The method significantly outperforms traditional translate-training approaches, achieving 11.3% and 16.1% improvements on MGSM and MSVAMP benchmarks while maintaining prediction consistency across languages.

## Method Summary
QAlign employs a two-stage fine-tuning framework. First, a base model (LLaMA2-7B/13B) is fine-tuned on multilingual question data to learn question-to-English translation for reasoning tasks. Second, the model is further fine-tuned on English instruction data to leverage its English reasoning capabilities. This approach avoids the high costs and poor translation quality of translate-training while maintaining the model's ability to handle chain-of-thought reasoning in English.

## Key Results
- QAlign achieves 11.3% and 16.1% improvements on MGSM and MSVAMP multilingual reasoning benchmarks
- The approach outperforms translate-training while being more cost-effective
- Models maintain consistent predictions across languages after training
- Works effectively even with only English supervision data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Question alignment transfers English reasoning expertise to non-English languages by teaching the model to map non-English questions to their English counterparts.
- **Mechanism:** The model is fine-tuned on X-English parallel question data to learn a mapping from non-English questions to English. This establishes a language alignment that allows the model to leverage its strong English reasoning capabilities when solving non-English tasks.
- **Core assumption:** The model's English reasoning capabilities are robust and generalizable across languages once a proper question-to-English mapping is established.
- **Evidence anchors:** [abstract] "train the model to translate reasoning questions into English by finetuning on X-English parallel question data"; [section] "this targeted, in-domain language alignment enables the subsequent effective utilization of English instruction data"

### Mechanism 2
- **Claim:** Using questions (rather than full responses with chain-of-thought) for alignment avoids translation errors and maintains data quality.
- **Mechanism:** The alignment stage uses only questions, not the full chain-of-thought responses, which are harder to translate accurately. This ensures higher quality training data for the alignment phase.
- **Core assumption:** Chain-of-thought responses contain complex language and formatting that are difficult to translate accurately, leading to noise in the training data.
- **Evidence anchors:** [abstract] "This approach not only incurs high cost, but also results in poorly translated data due to the non-standard formatting of mathematical chain-of-thought"; [section] "Acquiring multilingual questions is more feasible than obtaining accurate multilingual CoT responses"

### Mechanism 3
- **Claim:** The two-stage training (question alignment followed by response alignment) is crucial for effective multilingual reasoning.
- **Mechanism:** First, the model learns to translate questions to English (stage I). Then, it's fine-tuned on English instruction data to leverage its English reasoning expertise (stage II). Reversing this order or combining both stages leads to poor performance.
- **Core assumption:** The model needs to first establish language alignment before it can effectively use English instruction data for non-English tasks.
- **Evidence anchors:** [section] "reversing the order of the two training stages results in the LLM performing poorly in both English and non-English languages"; [section] "When we merge the training datasets from both stages and perform a single-stage, multi-task training, there is a significant drop in non-English performance"

## Foundational Learning

- **Concept:** Cross-lingual transfer learning
  - Why needed here: The paper relies on transferring English reasoning capabilities to non-English languages through language alignment.
  - Quick check question: What is the key challenge in cross-lingual transfer learning for LLMs, and how does question alignment address it?

- **Concept:** Chain-of-thought reasoning
  - Why needed here: The paper focuses on mathematical reasoning tasks that benefit from step-by-step reasoning, but avoids using translated CoT responses due to translation quality issues.
  - Quick check question: Why does the paper avoid using translated chain-of-thought responses for alignment, and what alternative does it use?

- **Concept:** Instruction tuning
  - Why needed here: The paper uses instruction tuning on English data (stage II) to unlock the model's multilingual reasoning capabilities after alignment.
  - Quick check question: How does instruction tuning on English data help the model perform better on non-English tasks after question alignment?

## Architecture Onboarding

- **Component map:** Base LLM (LLaMA2-7B/13B) -> Stage I: Question Alignment (X→En translation) -> Stage II: Response Alignment (English instruction tuning) -> Multilingual reasoning model
- **Critical path:** The critical path is the two-stage training: first establish question-to-English mapping, then leverage English instruction data. This path is essential for the model to perform well on non-English tasks.
- **Design tradeoffs:** Using only questions for alignment vs. full responses (tradeoff between data quality and alignment comprehensiveness); two-stage training vs. single-stage (tradeoff between performance and training efficiency).
- **Failure signatures:** Poor performance on non-English tasks despite good English performance; the model translating non-English questions instead of answering them; significant performance drop when reversing training order.
- **First 3 experiments:**
  1. Compare QAlign→MonoReason (our approach) vs. MonoReason (no alignment) on MGSM to verify the benefit of question alignment.
  2. Test different translation directions (X→En vs. En→X) during stage I to confirm the importance of translating non-English to English.
  3. Compare two-stage training vs. single-stage multi-task training to demonstrate the necessity of the sequential approach.

## Open Questions the Paper Calls Out
- Can the QAlign approach maintain effectiveness when scaled to larger language models (e.g., LLaMA2-70B)?
- How does the QAlign approach perform on reasoning tasks beyond mathematical problems, such as logical reasoning or commonsense reasoning?
- Can the QAlign approach be adapted to handle CoT responses in the same language as the input question?

## Limitations
- Experimental scope limited to mathematical reasoning tasks without exploring other domains
- Evaluation limited to only two benchmarks (MGSM and MSVAMP)
- Computational efficiency comparison with translate-training mentioned but not thoroughly analyzed
- Limited exploration of different base models beyond LLaMA2

## Confidence
- **High Confidence:** The core mechanism of question alignment improving multilingual reasoning performance
- **Medium Confidence:** The claim that two-stage training is superior to single-stage approaches
- **Medium Confidence:** The assertion that question alignment is more cost-effective than translate-training

## Next Checks
1. Evaluate QAlign on non-mathematical multilingual reasoning tasks to assess domain generalization
2. Test the approach with smaller and larger base models and varying amounts of multilingual training data
3. Conduct systematic ablation studies varying training order and combination configurations