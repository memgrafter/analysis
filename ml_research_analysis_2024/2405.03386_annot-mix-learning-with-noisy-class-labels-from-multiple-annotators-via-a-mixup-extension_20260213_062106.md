---
ver: rpa2
title: 'Annot-Mix: Learning with Noisy Class Labels from Multiple Annotators via a
  Mixup Extension'
arxiv_id: '2405.03386'
source_url: https://arxiv.org/abs/2405.03386
tags:
- class
- labels
- classification
- annotators
- mixup
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of training neural networks with
  noisy class labels from multiple annotators. The authors propose "annot-mix," an
  extension of the mixup regularization technique that handles multiple class labels
  per instance while considering the annotator source.
---

# Annot-Mix: Learning with Noisy Class Labels from Multiple Annotators via a Mixup Extension

## Quick Facts
- **arXiv ID**: 2405.03386
- **Source URL**: https://arxiv.org/abs/2405.03386
- **Reference count**: 40
- **Primary result**: Annot-mix achieves mean rank of 1.23-2.00 across 11 datasets, outperforming 8 state-of-the-art methods for learning with noisy labels from multiple annotators

## Executive Summary
This paper addresses the challenge of training neural networks when instances have multiple noisy class labels from different annotators. The authors propose "annot-mix," an extension of the mixup regularization technique that handles multiple class labels per instance while considering which annotator provided each label. Their approach integrates a mixup extension into a one-stage multi-annotator classification framework that estimates each annotator's performance while training the model. The method demonstrates superior performance compared to eight state-of-the-art approaches across eleven datasets with either human or simulated noisy class labels, achieving significant improvements in classification accuracy and robustness.

## Method Summary
Annot-mix extends the mixup regularization technique to multi-annotator settings by generating convex combinations of instance features, annotator embeddings, and their associated labels. The method jointly trains a classification model and an annotator model through marginal likelihood maximization, allowing the system to separate noise from true labels without requiring explicit label aggregation. The classification model predicts true class labels while the annotator model learns confusion matrices that capture each annotator's error patterns. During training, mixup is applied to triples (instance, annotator, label) rather than just pairs (instance, label), forcing the model to learn patterns consistent across annotators and instances rather than memorizing specific annotator-instance-label combinations.

## Key Results
- Annot-mix achieves mean rank of 1.23-2.00 across 11 datasets, significantly outperforming 8 state-of-the-art baselines
- The approach shows consistent improvements across diverse data modalities (images, text, tabular) and varying label noise levels (20-75%)
- Ablation studies confirm that the mixup extension provides robust regularization, reducing overfitting to noisy labels while maintaining or improving test accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Mixing triples (instance, annotator, label) instead of pairs improves generalization by making memorization harder and increasing data diversity
- **Mechanism**: The mixup extension generates convex combinations of both instance features and annotator embeddings, as well as their associated labels. This forces the model to learn patterns that are consistent across annotators and instances rather than memorizing specific annotator-instance-label combinations
- **Core assumption**: Annotator performance is not constant across instances, and mixing annotators across different instances will expose the model to more varied label quality patterns
- **Break condition**: If annotators have very similar performance patterns, the benefit of mixing annotators may diminish

### Mechanism 2
- **Claim**: Jointly training classification and annotator models through marginal likelihood maximization allows the system to separate noise from true labels without requiring explicit label aggregation
- **Mechanism**: The approach maximizes the marginal likelihood of observed noisy labels by marginalizing over the latent true labels. This forces the annotator model to learn confusion matrices that capture each annotator's error patterns while the classification model learns to predict the true labels
- **Core assumption**: The data generation process can be modeled as Pr(y,z|xn,am) = Pr(y|xn) · Pr(z|xn,am,yn), where annotator errors are conditionally independent given the true label and instance
- **Break condition**: If annotator performance depends on factors not captured by the instance features and true label (e.g., annotator fatigue, time of day), the model may fail to accurately estimate confusion matrices

### Mechanism 3
- **Claim**: The mixup extension provides robust regularization that prevents overfitting to noisy labels while maintaining or improving test accuracy
- **Mechanism**: By mixing labels from different annotators across instances, the model cannot simply memorize which annotator gives which label for which instance. This forces the model to learn more generalizable patterns about annotator reliability and instance features
- **Core assumption**: The regularization effect of mixup in multi-annotator settings is similar to its effect in standard classification, making memorization harder while improving generalization
- **Break condition**: If the noise level is extremely high (e.g., 90%+ false labels), the mixup regularization might not be sufficient to prevent catastrophic forgetting of the true signal

## Foundational Learning

- **Concept**: Marginal likelihood maximization with latent variables
  - Why needed here: The true labels are unobserved, so we need to optimize over the observed noisy labels while accounting for the uncertainty in the true labels
  - Quick check question: In the formula Pr(Z'|X,A;θ,π), what mathematical operation represents the marginalization over the latent true labels Y?

- **Concept**: Beta distribution for mixing coefficients
  - Why needed here: The Beta(α,α) distribution controls how much interpolation occurs between pairs of samples, with α=1 giving uniform mixing and α→0 recovering ERM
  - Quick check question: What happens to the mixup behavior when α approaches 0 versus when α approaches infinity?

- **Concept**: Confusion matrix estimation for multiple annotators
  - Why needed here: Each annotator has different error patterns that need to be modeled to accurately recover the true labels from noisy observations
  - Quick check question: In the annotator model Pπ(hθ(xn),am), what does each entry of the output confusion matrix represent?

## Architecture Onboarding

- **Component map**: Instance → Classification model → Penultimate features → Annotator model → Confusion matrix → Noisy label probability → Loss computation → Parameter update

- **Critical path**: The classification model processes instances to produce class probabilities, whose penultimate features are combined with annotator embeddings to generate confusion matrices via the annotator model, which are then used to compute probabilities for the observed noisy labels

- **Design tradeoffs**: 
  - Using separate models for classification and annotator performance versus a single unified model
  - Complexity of annotator representation (one-hot vs. learned embeddings with metadata)
  - Choice of α for Beta distribution balancing regularization vs. fitting observed labels

- **Failure signatures**:
  - Training accuracy much higher than validation accuracy indicates overfitting to noisy labels
  - Very low annotator model performance (perf-auroc) suggests inability to learn annotator reliability patterns
  - Classification accuracy close to random guessing indicates failure to separate signal from noise

- **First 3 experiments**:
  1. Train with α→0 (no mixup) vs. α=1 (standard mixup) on a small dataset to verify regularization effect
  2. Compare classification accuracy with and without the annotator model to measure benefit of explicit annotator modeling
  3. Test different annotator representations (one-hot vs. learned embeddings) on a dataset with available annotator metadata

## Open Questions the Paper Calls Out
- What are the optimal mixing coefficient values for different types of data (e.g., image vs text) in annot-mix?
- How does annot-mix perform when incorporating meta-information about annotators beyond one-hot encodings?
- Can annot-mix be effectively extended to semantic segmentation tasks?

## Limitations
- Relies heavily on experimental validation without extensive theoretical guarantees for the mixup extension's effectiveness
- Limited testing of extreme α values and very high noise scenarios to establish robustness boundaries
- Cannot test incorporation of annotator meta-information due to lack of appropriate datasets

## Confidence
- **High confidence** in the empirical superiority claims (rank-based comparisons across 11 datasets against 8 baselines)
- **Medium confidence** in the mechanism explanations (while plausible, the specific contributions of each component are not isolated in ablation studies)
- **Medium confidence** in the robustness claims (limited testing of extreme scenarios)

## Next Checks
1. Conduct ablation studies isolating the contributions of mixup, annotator modeling, and their combination to verify the proposed mechanism
2. Test performance on datasets with extreme label noise (>90%) and very few annotators (<10) to establish robustness boundaries
3. Perform theoretical analysis of the marginal likelihood formulation to understand convergence properties and identify conditions under which the approach may fail