---
ver: rpa2
title: 'Chattronics: using GPTs to assist in the design of data acquisition systems'
arxiv_id: '2409.15183'
source_url: https://arxiv.org/abs/2409.15183
tags:
- project
- which
- solution
- requirements
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Chattronics, an application that uses Large
  Language Models (LLMs) to assist in the design of data acquisition systems. The
  method employs a conversational interface that guides users through a top-down design
  process, from system-level architecture to block-level specifications.
---

# Chattronics: using GPTs to assist in the design of data acquisition systems

## Quick Facts
- arXiv ID: 2409.15183
- Source URL: https://arxiv.org/abs/2409.15183
- Authors: Jonathan Paul Driemeyer Brown; Tiago Oliveira Weber
- Reference count: 10
- Primary result: Chattronics uses conversational GPT models to guide users through top-down data acquisition system design, achieving coherent architectures but struggling with requirement satisfaction

## Executive Summary
Chattronics is an application that leverages Large Language Models to assist in the design of data acquisition systems through a conversational interface. The tool guides users through a top-down design process, from system-level architecture to block-level specifications, using a structured four-stage flow. The application was tested across four different testbenches with 160 total iterations, comparing two user emulation approaches: direct context (no interaction) and open context (with a second GPT model). Results showed the tool can generate coherent architectures but faces limitations in simultaneously considering all requirements and making theoretical mistakes in calculations.

## Method Summary
The application uses a structured conversational flow with four stages: Architectural (system requirements), Categorisation (block classification), Detailing (specific component values), and Revision. Two user emulation approaches were tested: direct context (providing all requirements upfront) and open context (using a second GPT model to emulate user interaction). The tool was evaluated across four testbenches - angular position, thermometry, portable accelerometry, and machinery pressure/temperature monitoring - with 20 iterations each for both emulation approaches. Manual analysis of results identified various error types including theoretical mistakes, incorrect component values, and architectural inconsistencies.

## Key Results
- The application successfully generated coherent system architectures and topologies across most test iterations
- Direct context approach yielded more consistent results than open context, with better requirement satisfaction
- The model frequently made theoretical mistakes, particularly in calculation-heavy testbenches like accelerometry
- In the accelerometry testbench, the model produced 6 different topologies but only one fully satisfied all requirements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The conversational top-down methodology guides the LLM to produce coherent architectural and block-level designs for data acquisition systems.
- Mechanism: The application uses a structured conversational flow with predefined stages (Architectural, Categorisation, Detailing, Revision) that progressively narrow the scope and provide context for each design decision.
- Core assumption: The LLM can maintain coherence across multiple conversational turns when provided with a structured flow and clear categorization of blocks.
- Evidence anchors:
  - [abstract]: "The solution is packaged in the form of an application that retains the conversational aspects of LLMs, in such a manner that the user must provide details on the desired project in order for the model to draft both a system-level architectural diagram and the block-level specifications, following a Top-Down methodology based on restrictions."
  - [section B. Chat Flow]: Describes the four-stage conversational flow and how each stage contributes to the design process.
  - [corpus]: Weak evidence. Related papers focus on GPT applications in different domains, not specifically on structured conversational flows for engineering design.
- Break condition: If the LLM loses context across stages or fails to maintain coherence between architectural and block-level specifications.

### Mechanism 2
- Claim: The two-user emulation approaches (Direct Context and Open Context) enable automated testing of the application's design capabilities.
- Mechanism: Direct Context provides all requirements upfront, while Open Context uses a second GPT model to emulate user interaction by answering questions based on a predefined list of requirements.
- Core assumption: A second GPT model can effectively emulate user behavior by selecting appropriate answers from a predefined list based on the questions asked.
- Evidence anchors:
  - [section C. Automated Testing]: Describes both emulation approaches and their implementation details.
  - [section III. Results]: Compares results between direct and open contexts, noting that direct context provides more consistent solutions.
  - [corpus]: Weak evidence. No related papers specifically address automated testing of LLM-based design tools using user emulation.
- Break condition: If the user-emulating GPT model fails to ask relevant questions or provides incorrect answers, leading to incomplete or incorrect design specifications.

### Mechanism 3
- Claim: The application can translate high-level project requirements into specific component values and design parameters for data acquisition systems.
- Mechanism: The detailing stage of the conversational flow prompts the LLM to calculate specific values for each block based on the system requirements and the chosen architecture.
- Core assumption: The LLM can perform accurate calculations and provide specific component values when given clear requirements and constraints.
- Evidence anchors:
  - [section II. Methodology B. Chat Flow 3. Detailing Stage]: Explains how the detailing stage works and how it prompts the model for specific calculations.
  - [section III. Results A. Best Solutions per Testbench]: Shows examples of calculated values in the best solutions for different testbenches.
  - [corpus]: Weak evidence. Related papers focus on GPT applications in different domains, not specifically on engineering calculations.
- Break condition: If the LLM makes calculation errors or fails to satisfy multiple requirements simultaneously, as observed in the accelerometry testbench results.

## Foundational Learning

- Concept: Top-Down Design Methodology
  - Why needed here: The application uses a top-down approach to systematically break down high-level requirements into specific block-level designs, which is essential for creating coherent data acquisition systems.
  - Quick check question: What are the four main stages of the conversational flow used in the application?

- Concept: Data Acquisition System Components
  - Why needed here: Understanding the different types of components (sensors, amplifiers, filters, ADCs) and their functions is crucial for designing appropriate architectures and block-level specifications.
  - Quick check question: What are the five categories used to classify blocks in the categorisation stage?

- Concept: Anti-Aliasing and Signal Conditioning
  - Why needed here: Proper signal conditioning and anti-aliasing are critical for ensuring accurate measurements and preventing aliasing in data acquisition systems.
  - Quick check question: Why is an anti-aliasing filter placed directly before the ADC in a data acquisition system?

## Architecture Onboarding

- Component map: CLI interface with Go backend using OpenAI API -> GPT-4-Turbo model for main design tasks -> Secondary GPT model for user emulation in automated testing -> Four-stage conversational flow (Architectural, Categorisation, Detailing, Revision) -> DOT format for diagram generation -> 160 test iterations across four testbenches

- Critical path: 1. User provides project description 2. LLM asks clarifying questions (or uses predefined requirements) 3. Architecture diagram generated 4. Blocks categorized 5. Each block detailed with specific parameters 6. Final solution compiled and presented

- Design tradeoffs:
  - Conversation history management vs. context window limitations
  - Direct context (faster, more consistent) vs. open context (more realistic testing)
  - Component specificity vs. generalization across different projects
  - Calculation accuracy vs. processing speed

- Failure signatures:
  - Inconsistent gain values across different blocks
  - Incorrect component values (wrong scale or wrong component type)
  - Missing critical components (e.g., Wheatstone bridge for strain gauges)
  - Architectural errors (e.g., anti-aliasing filter after ADC)
  - Theoretical mistakes in calculations

- First 3 experiments:
  1. Run a simple angular position project with minimal requirements to test basic architecture generation
  2. Test the open context approach with a predefined user emulator to validate the question-answering mechanism
  3. Compare results between direct and open contexts for a basic thermometry project to evaluate consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can conversation history be effectively managed to maintain consistency across block details while avoiding prohibitive context size growth?
- Basis in paper: [explicit] The paper discusses how the lack of conversation history sharing across detailing stages caused consistency issues, with examples like gain being set twice (in instrumentation amplifier and output stage).
- Why unresolved: The paper identifies this as a limitation but doesn't propose solutions for maintaining context without losing information or increasing costs.
- What evidence would resolve it: Testing different context management strategies (like summarization, hierarchical context, or selective memory) and measuring their impact on solution consistency and quality.

### Open Question 2
- Question: What improvements can be made to the user emulation approach to better extract project requirements from users?
- Basis in paper: [explicit] The paper notes that the open context approach (with user emulation) was less consistent than direct context, suggesting the model struggled to ask appropriate questions to extract requirements.
- Why unresolved: The paper suggests this needs improvement but doesn't explore specific strategies for enhancing the model's questioning capabilities.
- What evidence would resolve it: Comparative testing of different prompting strategies, question templates, or multi-turn dialogue approaches to see which yields more complete requirement extraction.

### Open Question 3
- Question: How can the tool be enhanced to better handle interdependent project requirements, particularly in calculation-heavy testbenches?
- Basis in paper: [explicit] The accelerometry testbench showed poor performance because requirements were interdependent and the tool couldn't propagate necessary values across stages.
- Why unresolved: The paper identifies this as a key limitation but doesn't propose methods for better requirement propagation or dependency management.
- What evidence would resolve it: Testing approaches like requirement dependency mapping, staged calculation frameworks, or constraint propagation algorithms to improve handling of interconnected specifications.

## Limitations
- The application struggles with simultaneously satisfying all requirements, particularly in calculation-heavy scenarios
- Theoretical mistakes and incorrect component values occur frequently in the generated solutions
- The user-emulating GPT model in open context approach fails to ask necessary questions for complete requirement extraction
- Manual analysis revealed significant inconsistency between blocks due to lack of shared conversation history

## Confidence
- High confidence: The conversational top-down methodology can generate coherent system architectures when provided with clear requirements
- Medium confidence: The application can produce block-level specifications with reasonable accuracy, though with occasional theoretical errors
- Medium confidence: The direct context approach provides more consistent results than open context, but both have significant limitations in requirement satisfaction
- Low confidence: The user-emulating GPT model can effectively replicate real user behavior in complex engineering design scenarios

## Next Checks
1. Expand requirement testing: Implement a more comprehensive set of requirements that test edge cases and conflicting constraints to evaluate how well the model handles complex trade-offs between different system specifications.

2. Multi-turn interaction analysis: Conduct detailed analysis of conversation histories in the open context to identify specific patterns where the user-emulating model fails to ask critical questions or misunderstands requirements.

3. Error classification refinement: Develop a more granular error classification system to distinguish between calculation errors, architectural mistakes, and requirement satisfaction failures, enabling targeted improvements to the conversational flow and prompting strategy.