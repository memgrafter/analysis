---
ver: rpa2
title: On Practical Diversified Recommendation with Controllable Category Diversity
  Framework
arxiv_id: '2402.03801'
source_url: https://arxiv.org/abs/2402.03801
tags:
- user
- category
- diversity
- categories
- items
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the echo chamber/filter bubble problem in
  recommender systems by introducing a two-stage framework called CCDF (Controllable
  Category Diversity Framework). The framework explicitly controls category diversity
  by dividing the process into User-Category Matching and Constrained Item Matching
  stages.
---

# On Practical Diversified Recommendation with Controllable Category Diversity Framework

## Quick Facts
- arXiv ID: 2402.03801
- Source URL: https://arxiv.org/abs/2402.03801
- Reference count: 34
- Primary result: Two-stage CCDF framework achieves up to 6.66% conversion rate increase and 19.43% more novel category exposure while maintaining recommendation accuracy.

## Executive Summary
This paper addresses the echo chamber problem in recommender systems by introducing a two-stage framework called CCDF (Controllable Category Diversity Framework). The method explicitly controls category diversity by separating user-category matching from constrained item retrieval. Offline experiments show DeepU2C outperforms state-of-the-art methods, especially on N-diversity tasks. Online A/B testing demonstrates significant improvements in conversion rates and diversity metrics, with controllable trade-offs between accuracy and diversity through parameter tuning.

## Method Summary
The CCDF framework divides the recommendation process into two stages: User-Category Matching and Constrained Item Matching. Stage I uses a DeepU2C model with a combined cross-entropy and triplet loss function to predict user preferences for categories, handling both interacted (U-diversity) and non-interacted (N-diversity) categories. Stage II retrieves items based on selected categories using posterior weighted scores (CTR×1 + CVR×10 + CPR×100). The method explicitly controls diversity through parameter K, which determines how many top categories to select for item retrieval.

## Key Results
- DeepU2C achieves HR@30 of 21.22% on U-diversity and 15.17% on N-diversity tasks, outperforming baselines by 5.56% and 8.25% respectively
- Online A/B testing shows up to 6.66% increase in conversion rate and 19.43% increase in exposed N-category number with K=30
- The framework maintains strong accuracy while significantly improving both U-diversity and N-diversity metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-stage architecture decouples diversity control from item retrieval accuracy, allowing explicit parameter tuning.
- Mechanism: By separating category selection (stage I) from item retrieval (stage II), the model can independently optimize diversity (via top-K categories) without sacrificing item relevance within those categories.
- Core assumption: Category-level diversity is a good proxy for user exposure to novel content and that item accuracy within constrained categories remains high.
- Evidence anchors:
  - [abstract] "divides the responsibilities of category diversity and item accuracy into two different stages"
  - [section 3.2] "The advantage of our CCDF is that, it is able to explicitly control the diversity level of the recommended list by controlling parameter K"
  - [corpus] Weak corpus evidence; no direct mention of two-stage architectures in neighbors.
- Break condition: If top-K categories are too broad, constrained item retrieval fails to maintain relevance; if too narrow, N-diversity gains are minimal.

### Mechanism 2
- Claim: DeepU2C's combined loss function (cross entropy + triplet) improves both U-diversity and N-diversity predictions.
- Mechanism: Cross entropy loss handles memorization of known category interactions; triplet loss enforces relative ranking between similar and dissimilar categories, enhancing generalization to unseen categories.
- Core assumption: The combination of memorization and generalization losses improves performance across both diversity types without overfitting.
- Evidence anchors:
  - [section 3.3.3] "To improve the model performance, we employ a combined loss function consisting of cross entropy loss and triplet loss functions"
  - [section 4.2] ablation results show "Wide Layer greatly improves the performance of DeepU2C on U-diversity task" and "deep networks...play a crucial role" for N-diversity.
  - [corpus] No direct evidence; neighbors focus on diversity frameworks but not loss design.
- Break condition: If triplet margin is poorly tuned, ranking collapse occurs, hurting N-diversity; if cross entropy dominates, memorization limits novelty.

### Mechanism 3
- Claim: Explicit N-diversity definition (categories not in user history) drives discovery of novel user interests, alleviating echo chambers.
- Mechanism: By predicting next categories both within and outside user's historical set, the model can intentionally surface unseen categories that align with latent preferences.
- Core assumption: N-diversity categories are meaningfully related to user interests even if never clicked, enabling effective discovery.
- Evidence anchors:
  - [section 3.1.1] "N-diversity, also known as novelty, captures the degree to which the categories in recommended items differ from user historical behaviors"
  - [section 4.4.1] "the exposed and clicked N-category number...indicate how many categories that have not occurred in user historical behaviors are exposed and clicked"
  - [corpus] Neighbor papers discuss diversity but lack explicit N-diversity definition; no corpus support.
- Break condition: If N-diversity categories are too unrelated, users perceive irrelevance and disengage; if too similar, novelty gain is minimal.

## Foundational Learning

- Concept: Category-based diversity vs. item-based diversity
  - Why needed here: This work uses category as the diversity unit rather than item similarity or latent features, simplifying control and evaluation.
  - Quick check question: If two items are from different categories but similar in content, how does the model treat them for diversity purposes?

- Concept: Two-stage candidate generation in recommender systems
  - Why needed here: Understanding match vs. rank modules clarifies why category selection is separated from item scoring.
  - Quick check question: In a funnel architecture, what risks arise if diversity is only applied at the ranking stage?

- Concept: Cross-entropy vs. triplet loss in recommendation
  - Why needed here: The combined loss balances accuracy (cross-entropy) and ranking quality (triplet) for both diversity tasks.
  - Quick check question: What happens to model performance if triplet loss is removed but cross-entropy remains?

## Architecture Onboarding

- Component map: User Request -> BE for Category (DeepU2C) -> top-K categories -> BE for Item (posterior weighted) -> RTP -> Exposure

- Critical path: User request → BE for Category (DeepU2C) → top-K categories → BE for Item (posterior weighted) → RTP → exposure

- Design tradeoffs:
  - Parameter K controls diversity but may reduce item accuracy if too large
  - Embedding sizes balance expressiveness vs. latency (online: 64/32/8/8 dims)
  - Combined loss adds training complexity but improves N-diversity

- Failure signatures:
  - Low N-category exposure despite high K → category selection too conservative
  - Conversion drop with high K → item relevance within categories suffers
  - Slow online response → embedding computation not precomputed

- First 3 experiments:
  1. Vary K from 5 to 50, measure N-diversity vs. conversion rate trade-off
  2. Remove triplet loss, compare N-diversity performance drop
  3. Swap Wide Layer for pure deep network, assess U-diversity impact

## Open Questions the Paper Calls Out

- Can the accuracy of the DeepU2C model be improved, particularly for the N-diversity task in stage I?
- Can user preferences for items under the constraint of a specific category be modeled through deep networks to improve the accuracy of stage II?
- What are the long-term effects of implementing the CCDF on user satisfaction and platform revenue?

## Limitations
- Dataset bias: Offline experiments rely heavily on Taobao and Alibaba.com e-commerce data, limiting generalization to other domains
- Scalability concerns: Maintaining separate BE services for Category and Item raises questions about real-time performance under high traffic
- Category system dependency: Explicit category-based diversity may struggle with fine-grained or rapidly evolving category systems

## Confidence
- **High confidence**: The two-stage architecture effectively separates diversity control from item retrieval (Mechanism 1)
- **Medium confidence**: The combined loss function significantly improves N-diversity predictions (Mechanism 2)
- **Low confidence**: N-diversity categories meaningfully align with latent user preferences (Mechanism 3)

## Next Checks
1. **Cross-domain validation**: Apply CCDF to non-e-commerce domains (e.g., news, streaming) and measure diversity metric transfer while controlling for category system differences.

2. **Scalability stress test**: Simulate peak load scenarios to quantify the latency impact of maintaining separate BE services and determine the threshold where diversity gains are offset by performance degradation.

3. **Latent preference alignment**: Conduct user studies to verify whether N-diversity categories that users never interacted with actually match their latent interests, or if they represent random exploration noise.