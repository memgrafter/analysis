---
ver: rpa2
title: Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via
  Weight Disentanglement
arxiv_id: '2408.03092'
source_url: https://arxiv.org/abs/2408.03092
tags:
- llms
- merging
- widen
- qwen1
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of merging pre-trained (PT)
  and fine-tuned (FT) large language models (LLMs) with diverse parameter changes.
  The authors propose a novel method called WIDEN (Weight Disentanglement) that disentangles
  model weights into magnitude and direction components, then adaptively fuses them
  based on their respective contributions.
---

# Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement

## Quick Facts
- arXiv ID: 2408.03092
- Source URL: https://arxiv.org/abs/2408.03092
- Reference count: 28
- Merging pre-trained and fine-tuned LLMs through weight disentanglement improves multilingual capabilities while preserving instruction-following skills

## Executive Summary
This paper addresses the challenge of merging pre-trained (PT) and fine-tuned (FT) large language models with diverse parameter changes. The authors propose WIDEN (Weight Disentanglement), a novel method that disentangles model weights into magnitude and direction components, then adaptively fuses them based on their respective contributions. The method successfully merges Qwen1.5-Chat (FT) with Sailor (PT), achieving significant improvements in multilingual capabilities while preserving instruction-following skills, outperforming existing methods on both multilingual benchmarks and conventional FT model merging.

## Method Summary
WIDEN disentangles model weights into magnitude and direction components, then performs adaptive fusion by considering their respective contributions. The method computes divergence relative to a backbone for both components separately using absolute magnitude changes and cosine similarity. It ranks weights within each model based on their divergence, then applies a calibrated softmax function to combine multiple models. The calibration preserves the importance of critical weights that would otherwise be downweighted by the normalization constraint.

## Key Results
- Achieves average rank of 1.15 on 7B and 1.77 on 14B model scales on the South-East Asian language benchmark
- Successfully merges Qwen1.5-Chat (FT) with Sailor (PT), improving multilingual capabilities while preserving instruction-following skills
- Outperforms existing methods on both multilingual benchmarks and conventional FT model merging tasks

## Why This Works (Mechanism)

### Mechanism 1
Disentangling weights into magnitude and direction components enables adaptive importance scoring that mitigates the impact of diverse parameter change ranges between FT and PT models. The method decomposes each weight into a magnitude vector and direction matrix, then computes divergence relative to the backbone for both components separately using absolute magnitude changes and cosine similarity.

### Mechanism 2
Ranking weights within each model based on their divergence relative to the backbone normalizes importance scores across models with different parameter change ranges. After computing divergence for each weight, WIDEN sorts weights by divergence and assigns normalized ranking scores between 0 and 1.

### Mechanism 3
Score calibration in the softmax function preserves the importance of critical weights that would otherwise be downweighted by the normalization constraint. WIDEN identifies weights whose importance exceeds the average by a factor t, then assigns them a calibrated score s instead of the softmax value.

## Foundational Learning

- **Weight disentanglement into magnitude and direction components**: Enables separate analysis of how much parameters changed (magnitude) versus in what direction (direction), which is crucial when merging models with vastly different adaptation scales. Quick check: If a weight vector changes from [1, 2] to [2, 4], what are its magnitude and direction components relative to the original?

- **Cosine similarity for direction comparison**: Provides a scale-invariant measure of how much the direction of weight changes has shifted between models, complementing the magnitude-based analysis. Quick check: What is the cosine similarity between vectors [1, 0] and [0.5, 0.866], and what does this value represent?

- **Softmax with score calibration**: Balances the need for normalized importance scores across multiple models while preserving the significance of universally important parameters. Quick check: How does score calibration modify the softmax output for weights that exceed the average importance by a factor of 2?

## Architecture Onboarding

- **Component map**: Weight disentanglement module -> Divergence estimation module -> Ranking module -> Merging module -> Calibration parameters (t, s)
- **Critical path**: 1) Disentangle weights of all models into magnitude and direction, 2) Compute divergence of each component relative to backbone, 3) Rank weights within each model by divergence, 4) Apply calibrated softmax to compute final importance scores, 5) Merge weights using weighted average based on importance
- **Design tradeoffs**: Computational overhead of disentanglement vs. potential performance gains, choice of calibration threshold t, memory requirements for storing intermediate representations
- **Failure signatures**: Performance degradation when merging models with similar parameter change ranges, numerical instability when computing cosine similarity for near-zero magnitude weights, suboptimal results when critical weights differ significantly between models
- **First 3 experiments**: 1) Merge two FT models with similar parameter changes using WIDEN and compare against average merging, 2) Merge an FT and PT model with large parameter change differences and evaluate multilingual vs. instruction-following capabilities, 3) Vary the calibration threshold t systematically to find optimal settings for different model pairs

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the limitations and unaddressed aspects, several questions arise regarding the method's generalizability to different model architectures, sizes, and training objectives.

## Limitations
- The choice of calibration threshold t and score s lacks theoretical justification and appears to be determined through grid search
- Limited analysis of failure cases or conditions where WIDEN might underperform relative to simpler approaches
- The method's sensitivity to the choice of backbone model is not explored

## Confidence
- Claims about WIDEN's effectiveness in merging PT and FT LLMs: **Medium confidence**
- Performance gains on South-East Asian language benchmark: **Medium confidence** (absolute metric values not reported)
- Method's generalization to other model architectures and tasks: **Low confidence** (limited experimental scope)

## Next Checks
1. Conduct systematic ablation studies removing each component (magnitude analysis, direction analysis, score calibration) to quantify their individual contributions to performance gains
2. Test WIDEN on merging models with similar parameter change ranges to verify it doesn't degrade performance when simpler methods suffice
3. Evaluate the method's robustness across different model architectures beyond the Qwen1.5 family to assess generalizability