---
ver: rpa2
title: 'COLD: Causal reasOning in cLosed Daily activities'
arxiv_id: '2411.19500'
source_url: https://arxiv.org/abs/2411.19500
tags:
- causal
- events
- page
- reasoning
- activity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COLD (Causal Reasoning in Closed Daily Activities),
  a framework for evaluating large language models' (LLMs) causal reasoning abilities
  using real-world daily activities. The key idea is to use human-generated script
  knowledge about daily activities to create causal graphs and generate a large number
  of causal query triplets, bringing evaluation closer to the "mini-Turing test" for
  causal reasoning.
---

# COLD: Causal reasOning in cLosed Daily activities

## Quick Facts
- arXiv ID: 2411.19500
- Source URL: https://arxiv.org/abs/2411.19500
- Reference count: 40
- Introduces COLD framework for evaluating LLMs' causal reasoning using daily activities

## Executive Summary
This paper presents COLD, a framework for evaluating large language models' (LLMs) causal reasoning capabilities using real-world daily activities. The framework leverages human-generated script knowledge about daily activities to create causal graphs and generate millions of causal query triplets. COLD aims to bring causal reasoning evaluation closer to a "mini-Turing test" by testing models on their understanding of causal relationships between events in everyday contexts. The evaluation reveals that even simple daily activities pose significant challenges for LLMs, with accuracy ranging from 42-86% across different activities.

## Method Summary
The COLD framework uses script knowledge bases like ATOMIC to generate causal graphs for daily activities. For each activity, the framework creates multiple instances by permuting the ordering of events while maintaining the same causal structure. Causal queries are then generated from these graphs, resulting in approximately 9 million queries per activity. The framework evaluates open-weight LLMs on their ability to answer these causal queries, testing their understanding of event relationships. Additionally, the paper proposes using backdoor adjustments and Average Treatment Effect (ATE) to estimate causal strengths between events, with temporal ordering serving as a proxy for causal relationships.

## Key Results
- COLD generates approximately 9 million causal queries per daily activity
- LLM performance ranges from 42-86% accuracy across different activities
- Temporal ordering can serve as a proxy for causal relationships
- Causal reasoning remains challenging even for simple daily activities

## Why This Works (Mechanism)
The framework's effectiveness stems from its systematic approach to generating causal queries based on human-generated script knowledge. By creating multiple instances of the same causal structure with different event orderings, COLD tests the models' ability to understand underlying causal relationships rather than relying on surface-level patterns. The use of backdoor adjustments and ATE provides a quantitative measure of causal strength, while the large-scale query generation enables rigorous evaluation of LLMs' causal reasoning capabilities.

## Foundational Learning
- **Script knowledge**: Why needed - Provides structured understanding of daily activities; Quick check - Verify knowledge base coverage of target activities
- **Causal graphs**: Why needed - Visual representation of event relationships; Quick check - Ensure graph accuracy for each activity
- **Backdoor adjustment**: Why needed - Controls for confounding variables in causal inference; Quick check - Validate adjustment method's effectiveness
- **Average Treatment Effect (ATE)**: Why needed - Quantifies causal strength between events; Quick check - Test ATE calculations across diverse scenarios
- **Temporal ordering**: Why needed - Serves as proxy for causal relationships; Quick check - Assess correlation between ordering and causation
- **Causal query generation**: Why needed - Creates systematic evaluation tasks; Quick check - Verify query diversity and coverage

## Architecture Onboarding

### Component Map
Script Knowledge -> Causal Graph Generation -> Query Generation -> LLM Evaluation -> ATE Calculation

### Critical Path
The critical path begins with script knowledge extraction, followed by causal graph construction, query generation, LLM evaluation, and finally ATE calculation for causal strength estimation.

### Design Tradeoffs
The framework balances between comprehensive coverage of daily activities and computational feasibility. While generating millions of queries ensures thorough evaluation, it also raises concerns about potential redundancy. The reliance on ATOMIC's event-action structures limits the framework's applicability to activities not well-represented in existing knowledge bases.

### Failure Signatures
- Poor performance on activities with complex temporal relationships
- Inconsistent results across different LLM models
- Limited effectiveness for activities requiring physical reasoning
- Potential cultural and contextual biases in human-generated scripts

### First Experiments
1. Test framework on a simple daily activity with well-defined event sequences
2. Compare performance of different open-weight LLMs on the same activity
3. Validate ATE calculations using synthetic causal graphs with known relationships

## Open Questions the Paper Calls Out
The paper raises questions about the framework's applicability to activities requiring physical reasoning or spatial awareness, the impact of cultural and contextual biases in human-generated scripts, and the generalizability of findings to proprietary LLMs and activities beyond those covered by ATOMIC's knowledge base.

## Limitations
- Reliance on ATOMIC's event-action structures may limit coverage of complex daily activities
- Assumption that temporal ordering indicates causal relationships may not hold for all activities
- Reported accuracy variation across activities isn't fully explained by prompt and temperature analysis
- Focus on open-weight LLMs limits conclusions about proprietary models

## Confidence
- **High confidence**: Framework's systematic approach to generating causal queries and demonstrating LLMs' limitations in causal reasoning
- **Medium confidence**: Proposed backdoor adjustment method and its effectiveness across diverse daily activities
- **Low confidence**: Generalizability of findings to proprietary LLMs and activities beyond ATOMIC's knowledge base

## Next Checks
1. Evaluate the framework's performance on activities requiring physical reasoning or spatial awareness
2. Test the backdoor adjustment method's effectiveness across a broader range of activities, including those with complex temporal relationships
3. Assess the impact of cultural and contextual biases in human-generated scripts on LLM performance across different demographic groups