---
ver: rpa2
title: 'MOSAIC: Multiple Observers Spotting AI Content'
arxiv_id: '2409.07615'
source_url: https://arxiv.org/abs/2409.07615
tags:
- text
- detection
- texts
- language
- machine-generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new method for detecting machine-generated
  text using an ensemble of Large Language Models (LLMs) called the Robust Scoring
  Algorithm (RSA). The key idea is to use a mixture of LLMs to assign codelengths
  to text sequences, leveraging information-theoretic principles from universal compression.
---

# MOSAIC: Multiple Observers Spotting AI Content

## Quick Facts
- arXiv ID: 2409.07615
- Source URL: https://arxiv.org/abs/2409.07615
- Authors: Matthieu Dubois; François Yvon; Pablo Piantanida
- Reference count: 20
- Key outcome: A new method for detecting machine-generated text using an ensemble of Large Language Models (LLMs) called the Robust Scoring Algorithm (RSA), which achieves strong detection performance across various datasets and is robust to different generators and languages.

## Executive Summary
This paper proposes a new method for detecting machine-generated text using an ensemble of Large Language Models (LLMs) called the Robust Scoring Algorithm (RSA). The key idea is to use a mixture of LLMs to assign codelengths to text sequences, leveraging information-theoretic principles from universal compression. RSA optimally combines the strengths of multiple LLMs by solving a min-max problem to find the best distribution over the ensemble that minimizes the worst-case expected overhead. Experiments on various datasets show that RSA achieves strong detection performance, outperforming several baselines, and is robust to different generators and languages. The method is also flexible and can be easily extended by adding new models to the ensemble.

## Method Summary
The Robust Scoring Algorithm (RSA) is a method for detecting machine-generated text by leveraging an ensemble of Large Language Models (LLMs). The core idea is to compute a detection score for each text by comparing the codelength of the observed sequence under the optimal mixture model to the average codelength under all models in the ensemble. RSA uses the Blahut-Arimoto algorithm to compute optimal weights for each LLM in the ensemble, derived by maximizing the mutual information between the model selection and the observed token sequence. This ensures the mixture captures the most regularity from the input, effectively distinguishing between human and machine-generated text.

## Key Results
- RSA achieves strong detection performance, outperforming several baselines, and is robust to different generators and languages.
- The method is flexible and can be easily extended by adding new models to the ensemble, improving its generalization to unseen generators.
- RSA's performance varies across different text domains, suggesting potential improvements with domain-adapted models in the ensemble.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RSA leverages a mixture of LLMs to produce a robust scoring algorithm by finding the model mixture that minimizes the worst-case expected overhead.
- Mechanism: The algorithm uses the Blahut-Arimoto algorithm to compute optimal weights for each LLM in the ensemble. These weights are derived by maximizing the mutual information between the model selection and the observed token sequence, ensuring the mixture captures the most regularity from the input.
- Core assumption: Different LLMs have complementary strengths in detecting various types of machine-generated text, and combining them optimally yields better robustness than any single model.
- Evidence anchors:
  - [abstract] "RSA optimally combines the strengths of multiple LLMs by solving a min-max problem to find the best distribution over the ensemble that minimizes the worst-case expected overhead."
  - [section 2.2] "Our goal will be to derive a robust scoring algorithm that best extracts regularity in the data, which is equivalent to identifying the model that achieves the best compression of the input tokens."
  - [corpus] Weak - no direct evidence in related papers; the method is novel in its use of Blahut-Arimoto for this task.
- Break condition: If the ensemble contains models that are too similar in their strengths, the mixture may not provide additional robustness, or if the mutual information maximization does not align with detection accuracy.

### Mechanism 2
- Claim: The RSA score effectively distinguishes between human and machine-generated text by comparing the codelength of the observed sequence under the optimal mixture model to the average codelength under all models in the ensemble.
- Mechanism: For a given text, RSA computes two terms: (1) the codelength of the observed sequence under the optimal mixture model q*, and (2) the average codelength of sequences generated by the ensemble. The difference between these terms forms the RSA score. Human-generated text is expected to have a larger score because it is less predictable by the ensemble.
- Core assumption: Machine-generated text is more regular and thus has lower codelengths under the ensemble of LLMs compared to human-generated text.
- Evidence anchors:
  - [section 2.2] "If the input sentence is generated by one of the LLMs in the family or another closely related one, the score is expected to be small... However, if the input sentence is human-generated, the score is expected to be large as the first term will dominate."
  - [abstract] "The better the best-fitting LLM in PM(Y) fits the artificially generated data, the shorter the codelengh L⋆(yt|w<t) ≜ − log q⋆(yt|w<t)."
  - [corpus] Weak - related works use perplexity-based methods but not the specific codelength comparison mechanism of RSA.
- Break condition: If the sampling method used to generate text significantly differs from the models' training distribution, the codelength assumption may break down, as observed with Llama-7b regeneration.

### Mechanism 3
- Claim: The RSA method is flexible and can be easily extended by adding new models to the ensemble, improving its generalization to unseen generators.
- Mechanism: Since RSA computes the optimal mixture weights dynamically for each input, adding a new LLM to the ensemble simply means it will be considered in the mutual information maximization. The Blahut-Arimoto algorithm will automatically adjust the weights to incorporate the new model's strengths.
- Core assumption: New models added to the ensemble will provide complementary information that improves the overall detection performance.
- Evidence anchors:
  - [abstract] "The method is also flexible and can be easily extended by adding new models to the ensemble."
  - [section 4.1.3] "RSA makes the augmentation of the ensemble quite easy... To showcase the effect of this feature, we add Phi-3 in our ensemble."
  - [corpus] Weak - the method is novel in its ensemble extension approach; related works focus on fixed pairs of models.
- Break condition: If the new model is poorly trained or generates text very differently from the existing ensemble, it may not improve performance and could even degrade it.

## Foundational Learning

- Concept: Information Theory and Universal Compression
  - Why needed here: RSA is grounded in information-theoretic principles, using codelengths and mutual information to measure the regularity of text sequences. Understanding these concepts is crucial for grasping how RSA works.
  - Quick check question: What is the relationship between codelength and probability in information theory, and how does this relate to detecting machine-generated text?

- Concept: Language Model Probability Distributions
  - Why needed here: RSA relies on multiple LLMs, each defining a probability distribution over token sequences. Understanding how these models generate probabilities is essential for implementing the method.
  - Quick check question: How do autoregressive language models compute the probability of a token given the previous context, and why is this important for RSA?

- Concept: Ensemble Methods and Model Combination
  - Why needed here: RSA combines multiple LLMs using optimal weights derived from mutual information maximization. Understanding ensemble methods and how to combine model predictions is key to implementing and extending RSA.
  - Quick check question: What are the advantages of using an ensemble of models over a single model, and how does RSA's approach differ from simple averaging?

## Architecture Onboarding

- Component map: Input text sequence -> LLM Ensemble (multiple pre-trained models) -> Blahut-Arimoto Algorithm (optimal mixture weights) -> RSA Score (codelength comparison) -> Output classification (human or machine-generated)

- Critical path:
  1. Tokenize the input text using the shared tokenizer of the LLM ensemble
  2. For each token in the sequence, compute the forward pass for all LLMs in the ensemble
  3. Run the Blahut-Arimoto algorithm to compute the optimal mixture weights q*
  4. Calculate the RSA score by comparing the codelength under q* to the average codelength
  5. Apply a threshold to the RSA score to classify the text

- Design tradeoffs:
  - Using a larger ensemble of LLMs may improve robustness but increases computational cost
  - The Blahut-Arimoto algorithm adds complexity but is necessary for optimal model combination
  - RSA's flexibility in adding new models is advantageous but requires careful consideration of each model's strengths

- Failure signatures:
  - If the RSA score fails to distinguish between human and machine-generated text, it may indicate that the ensemble lacks diversity or that the text domain is not well-represented
  - Poor performance on a specific dataset may suggest the need for domain-adapted models in the ensemble
  - If adding a new model degrades performance, it may be due to the model's incompatibility with the existing ensemble

- First 3 experiments:
  1. Implement RSA with a small ensemble (e.g., 2-3 LLMs) on a simple dataset (e.g., Ghostbuster) to verify basic functionality
  2. Compare RSA's performance to a single LLM baseline to demonstrate the benefit of ensemble methods
  3. Add a new LLM to the ensemble and measure the impact on detection performance to validate the flexibility of RSA

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the RSA method's performance change when the detector ensemble includes models trained on different domains or genres beyond those used in the experiments?
- Basis in paper: [inferred] The paper mentions RSA's performance varied across different text domains, suggesting potential improvements with domain-adapted models.
- Why unresolved: The paper only tested RSA on a limited set of datasets and genres. It did not explore the impact of including models trained on different domains or genres.
- What evidence would resolve it: Testing RSA on a wider range of datasets, including those from different domains and genres, would show how well it adapts to various types of text.

### Open Question 2
- Question: Can the RSA method be extended to handle tokenizers from different models, and how would this affect its performance?
- Basis in paper: [explicit] The paper mentions a limitation where RSA requires all models in the ensemble to share the same tokenizer.
- Why unresolved: The paper does not provide a solution for combining models with different tokenizers, nor does it explore the impact on performance.
- What evidence would resolve it: Developing and testing a method to combine models with different tokenizers, and comparing its performance to the current RSA method, would address this limitation.

### Open Question 3
- Question: How does the RSA method's performance compare to other zero-shot detection methods when applied to real-world scenarios with noisy or adversarial text?
- Basis in paper: [inferred] The paper mentions the need for robustness against adversarial attacks and variations in text domains.
- Why unresolved: The paper only tested RSA on controlled datasets and did not evaluate its performance on real-world text with noise or adversarial modifications.
- What evidence would resolve it: Testing RSA on real-world text datasets, including those with noise or adversarial modifications, and comparing its performance to other zero-shot methods, would demonstrate its robustness.

## Limitations

- The RSA method's effectiveness may depend heavily on how the machine-generated text was originally produced, as evidenced by some degradation when text is regenerated with the same model.
- The computational overhead of running multiple LLMs through the Blahut-Arimoto algorithm could be prohibitive for real-time applications, though this is not explicitly quantified in the paper.
- RSA requires all models in the ensemble to share the same tokenizer, which limits its flexibility in combining models with different tokenization schemes.

## Confidence

- High Confidence: The core information-theoretic framework (using codelengths and mutual information for detection) is well-grounded and consistently supported by theoretical justification and experimental results.
- Medium Confidence: The claim that RSA outperforms baseline methods is supported by experiments, but the margins of improvement vary significantly across datasets, and some comparisons lack direct statistical significance testing.
- Medium Confidence: The flexibility of adding new models to the ensemble is demonstrated through experiments with Phi-3, but the long-term impact of model additions on detection performance across diverse domains remains unclear.

## Next Checks

1. **Domain Transfer Validation**: Test RSA on a new domain (e.g., legal or medical texts) to verify whether the ensemble maintains detection performance when faced with specialized vocabulary and writing styles not represented in the training data.

2. **Generation Method Sensitivity Analysis**: Systematically vary sampling parameters (temperature, top_p, repetition penalty) for a single generator model and measure how RSA's detection performance changes across this spectrum to quantify sensitivity to generation strategies.

3. **Ensemble Composition Impact Study**: Conduct controlled experiments by adding increasingly similar models to the ensemble and measure the point at which additional models no longer improve (or begin to degrade) detection performance, establishing guidelines for optimal ensemble size and diversity.