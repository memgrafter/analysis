---
ver: rpa2
title: Link Prediction with Untrained Message Passing Layers
arxiv_id: '2406.16687'
source_url: https://arxiv.org/abs/2406.16687
tags:
- uni00000013
- layers
- link
- uni00000011
- untrained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of untrained message passing layers
  in graph neural networks for link prediction tasks. The authors remove trainable
  parameters from standard message passing architectures like GCN, SAGE, and GIN,
  creating simplified versions that are more efficient and theoretically interpretable.
---

# Link Prediction with Untrained Message Passing Layers

## Quick Facts
- arXiv ID: 2406.16687
- Source URL: https://arxiv.org/abs/2406.16687
- Reference count: 40
- Primary result: Untrained message passing layers often match or exceed trained counterparts in link prediction, especially with high-dimensional features

## Executive Summary
This paper investigates the use of untrained message passing layers in graph neural networks for link prediction tasks. By removing trainable parameters from standard architectures like GCN, SAGE, and GIN, the authors create simplified variants that are more computationally efficient while maintaining strong performance. The theoretical analysis establishes connections between features produced by untrained layers and classical path-based node similarity measures, providing insights into why these simplified architectures work well for link prediction.

## Method Summary
The authors implement untrained variants of standard GNN architectures (GCN, SAGE, GIN, GraphConv) by removing trainable parameters while maintaining self-loops. They create simplified versions that add a final linear classifier to the untrained layers, and fully untrained versions that use only inner products of propagated features. The approach is evaluated on various graph datasets using 3-fold cross-validation with Adam optimizer and binary cross-entropy loss, comparing against baseline trained models.

## Key Results
- Untrained message passing layers achieve competitive performance compared to fully trained MPNNs on link prediction tasks
- Performance gains are particularly pronounced with high-dimensional features
- Untrained architectures are computationally more efficient while maintaining accuracy
- Theoretical analysis connects untrained message passing to path-based topological similarity measures

## Why This Works (Mechanism)

### Mechanism 1
Untrained message passing layers implicitly encode path-based topological similarity measures, explaining their strong link prediction performance without training. When initial node features are orthonormal, the inner product of node features after l layers equals the sum of normalized paths of length 2l between nodes, creating a path-based measure similar to Katz index or rooted PageRank.

### Mechanism 2
Untrained message passing layers avoid over-squashing and over-smoothing problems that plague trained models. By removing nonlinearities and learnable parameters, untrained message passing preserves feature variance and prevents the collapse of node representations that occurs in deep trained networks.

### Mechanism 3
The simplified architecture (untrained MP layers + trained linear classifier) achieves good performance by learning to weight path-based features appropriately. The final linear layer acts as a learned inner product that can emphasize or de-emphasize different path lengths and structural patterns captured by the untrained propagation.

## Foundational Learning

- **Concept**: Graph Neural Networks and Message Passing
  - Why needed here: Understanding how information flows through graphs is essential for grasping why untrained message passing can work
  - Quick check question: What is the difference between aggregation and update functions in message passing?

- **Concept**: Path-based Link Prediction Measures
  - Why needed here: The theoretical analysis connects untrained message passing to classical link prediction heuristics like Katz index and Adamic-Adar
  - Quick check question: How does the number of paths between two nodes relate to their similarity in link prediction?

- **Concept**: Orthogonality and High-Dimensional Spaces
  - Why needed here: The theoretical results rely on the assumption that high-dimensional random features are approximately orthogonal
  - Quick check question: Why do collections of high-dimensional random vectors tend to be mutually orthogonal?

## Architecture Onboarding

- **Component map**: Input features -> Untrained MP layer (S^l H(0)) -> Inner product computation -> (Optional) Linear transformation -> Link score

- **Critical path**: Feature propagation → Inner product computation → (Optional) Linear transformation → Link score

- **Design tradeoffs**:
  - Accuracy vs. efficiency: Fully untrained models are faster but slightly less accurate on attributed graphs
  - Number of layers: More layers capture longer paths but may introduce noise if features aren't perfectly orthogonal
  - Normalization: Degree-based normalization (GCN, SAGE) performs better than no normalization (GIN)

- **Failure signatures**:
  - Poor performance on graphs with correlated node features (violates orthogonality assumption)
  - Degraded accuracy when using low-dimensional features
  - Over-smoothing in untrained GIN due to lack of degree normalization

- **First 3 experiments**:
  1. Compare UTGCN vs. GCN on a small attributed graph with one-hot features
  2. Test the effect of increasing layers on a non-attributed graph with one-hot encodings
  3. Evaluate fully untrained vs. simplified architecture on a high-dimensional feature dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions do untrained message passing layers outperform their trained counterparts in link prediction tasks?
- Basis in paper: The paper states that untrained message passing layers can lead to competitive and even superior performance compared to fully trained MPNNs, especially in the presence of high-dimensional features.
- Why unresolved: The paper provides experimental evidence showing improved performance but does not systematically analyze the conditions that determine when untrained layers will outperform trained ones.
- What evidence would resolve it: A comprehensive study examining performance across diverse datasets with varying feature dimensions, graph sizes, and topological properties, identifying specific characteristics that correlate with untrained layer superiority.

### Open Question 2
- Question: How do untrained message passing layers generalize to out-of-distribution link prediction scenarios?
- Basis in paper: The paper focuses on standard link prediction settings but mentions that the theoretical analysis provides insights into initialization schemes. However, it doesn't address generalization to graphs with different characteristics than training data.
- Why unresolved: The paper demonstrates strong performance on standard benchmarks but doesn't evaluate how untrained layers perform when applied to graphs with different properties than those seen during training.
- What evidence would resolve it: Experiments testing untrained layer performance on graphs with systematically varied properties compared to training data, measuring performance degradation and identifying which graph characteristics affect generalization most.

### Open Question 3
- Question: Can untrained message passing layers be effectively combined with other link prediction methods that use structural features?
- Basis in paper: The paper mentions that current state-of-the-art methods combine GNNs and structural features, and their theoretical results establish connections between MPNNs and path-based measures. However, it doesn't explore hybrid approaches.
- Why unresolved: While the paper demonstrates the effectiveness of standalone untrained layers, it doesn't investigate whether combining them with other structural features or heuristic methods could yield additional performance gains.
- What evidence would resolve it: Experiments integrating untrained message passing features with other link prediction components (e.g., common neighbor measures, Katz index, subgraph-based features) to evaluate whether hybrid approaches can further improve performance.

### Open Question 4
- Question: What is the theoretical limit of performance for untrained message passing layers in link prediction?
- Basis in paper: The paper establishes theoretical connections between untrained layer features and path-based similarity measures, showing that these features implicitly encode neighborhood information.
- Why unresolved: The paper demonstrates practical performance but doesn't characterize the theoretical upper bound of what untrained layers can achieve compared to optimal link prediction methods.
- What evidence would resolve it: Analysis deriving bounds on the predictive power of features produced by untrained layers, comparing these bounds to theoretical limits of link prediction accuracy based on graph structure alone.

## Limitations

- The theoretical analysis critically depends on the assumption that initial node features are approximately orthonormal, which may not hold in real-world datasets with correlated features
- The claim that untrained layers inherently avoid over-squashing and over-smoothing problems is weakly supported and may depend heavily on specific normalization choices
- Performance degradation may occur with untrained models when node features are not sufficiently orthogonal

## Confidence

- **High confidence**: The empirical observation that untrained message passing layers achieve competitive performance on link prediction tasks is well-supported by experimental results across multiple datasets and architectures
- **Medium confidence**: The theoretical connection between untrained message passing and path-based similarity measures is sound under the orthonormal feature assumption, but the practical relevance requires further validation
- **Low confidence**: The claim that untrained layers inherently avoid over-squashing and over-smoothing problems is weakly supported and may depend heavily on specific normalization choices

## Next Checks

1. Empirically verify the orthogonality assumption by measuring inner products between random node features in various datasets to confirm they concentrate near zero
2. Test the robustness of untrained models to correlated initial features by adding structured noise to one-hot encodings and measuring performance degradation
3. Compare the feature distributions of untrained vs. trained models across multiple layers to quantify differences in variance preservation and potential over-smoothing effects