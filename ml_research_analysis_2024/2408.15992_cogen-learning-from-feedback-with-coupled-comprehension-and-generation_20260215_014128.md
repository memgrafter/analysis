---
ver: rpa2
title: 'CoGen: Learning from Feedback with Coupled Comprehension and Generation'
arxiv_id: '2408.15992'
source_url: https://arxiv.org/abs/2408.15992
tags:
- comprehension
- generation
- round
- learning
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the coupling of language comprehension and generation
  in a continual learning setting, where a model learns from interactions with human
  users. The authors propose techniques to tightly integrate these two capabilities,
  both at inference-time via joint inference and at training-time by generating examples
  and rewards for each role from feedback on performance in that role as well as the
  opposing role.
---

# CoGen: Learning from Feedback with Coupled Comprehension and Generation

## Quick Facts
- arXiv ID: 2408.15992
- Source URL: https://arxiv.org/abs/2408.15992
- Reference count: 33
- Primary result: Coupling language comprehension and generation improves performance by up to 26% absolute improvement in reference game accuracy

## Executive Summary
This paper introduces CoGen, a system that tightly couples language comprehension and generation capabilities to enable continual learning from human interactions. The approach uses a reference game scenario where a speaker describes images and a listener guesses the target, with both roles handled by the same model. By implementing joint inference and data sharing between the two capabilities, the system creates feedback loops where improvement in one area drives improvement in the other. The results demonstrate substantial performance gains over non-coupled systems, with up to 26% absolute improvement in accuracy.

## Method Summary
The method employs the IDEFICS2-8B model with LoRA adapters, trained using REINFORCE policy gradient algorithm for both comprehension and generation tasks. The coupling occurs through two mechanisms: joint inference that combines comprehension and generation probability distributions during decision-making, and data sharing where successful interactions from one role provide training examples for the other. The system is evaluated in a reference game with tangram shapes, collecting human-model interactions over multiple rounds and retraining the model with accumulated data.

## Key Results
- Coupling comprehension and generation leads to up to 26% absolute improvement in performance
- The coupled system achieves up to 17% higher accuracy compared to non-coupled baselines
- Coupling makes the system's language significantly more human-like, reducing vocabulary collapse and improving semantic similarity to human language

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coupling creates a virtuous cycle where improvement in one capability drives improvement in the other
- Mechanism: Joint inference and data sharing create feedback loops where comprehension gains improve generation via joint reasoning, and generation improvements provide better learning signals for comprehension
- Core assumption: Comprehension and generation are sufficiently complementary that improvement in one directly benefits the other
- Evidence anchors:
  - [abstract] "coupling comprehension and generation leads to performance improvements up to 26% in absolute terms"
  - [section] "As one capability improves (e.g., comprehension), the model's performance on the opposing capability (e.g., generation) also improves via the joint inference procedure"
  - [corpus] Weak - no direct corpus evidence found for this specific virtuous cycle mechanism

### Mechanism 2
- Claim: Data sharing from positive interactions exposes generation to human language patterns
- Mechanism: When the model performs well as a listener, human utterances from that interaction are added to generation training data, exposing the generation model to diverse human language
- Core assumption: Exposure to human language is beneficial for improving the naturalness and effectiveness of generated language
- Evidence anchors:
  - [section] "An important result of this process is introducing human language into the training data of the speaker model"
  - [section] "This can enable the system to expand its generation abilities and make the language more similar to humans"
  - [corpus] Weak - corpus evidence focuses on UI components rather than language learning dynamics

### Mechanism 3
- Claim: Joint inference approximates pragmatic reasoning by combining listener and speaker perspectives
- Mechanism: The joint probability distribution weights comprehension and generation distributions, allowing the model to reason about both what to say and what will be understood
- Core assumption: Pragmatic reasoning in reference games benefits from considering both speaker's intent and listener's interpretation simultaneously
- Evidence anchors:
  - [section] "We couple the two distributions Pl and Ps during inference by sampling from one distribution and then re-rank with a weighted geometric mean"
  - [section] "This joint formulation is similar to a rational speech act model (RSA) with a single level of recursion"
  - [corpus] Weak - corpus evidence relates to diffusion models for long-horizon tasks, not pragmatic reasoning

## Foundational Learning

- Concept: Contextual bandit learning with REINFORCE algorithm
  - Why needed here: The system needs to learn from binary success/failure signals in human interactions rather than supervised labels
  - Quick check question: How does the inverse propensity score coefficient prevent negative examples from destabilizing learning?

- Concept: Continual learning with data accumulation
  - Why needed here: The model must improve over multiple rounds of human interaction while retaining and building upon previous learning
  - Quick check question: What is the difference between retraining from scratch each round versus fine-tuning on accumulated data?

- Concept: Joint probability distributions for multi-task inference
  - Why needed here: The coupling mechanism requires combining comprehension and generation probabilities during inference
  - Quick check question: How does the geometric mean weighting between Pl and Ps affect the final joint distribution?

## Architecture Onboarding

- Component map: IDEFICS2-8B model with LoRA adapters -> prompt-based task switching -> joint inference module -> data sharing pipeline -> REINFORCE training loop
- Critical path: Human interaction → feedback collection → data conversion → joint training → model update → redeployment
- Design tradeoffs: Simplicity of REINFORCE vs. potential benefits of more sophisticated RL algorithms; computational cost of joint inference vs. performance gains
- Failure signatures: Performance plateaus despite more data; generated language becomes repetitive or unnatural; joint inference produces degenerate outputs
- First 3 experiments:
  1. Implement data sharing without joint inference to isolate its effect
  2. Test different λ values for joint inference weighting
  3. Compare REINFORCE vs. PPO for the training algorithm

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of data sharing change when using different vision-language models beyond IDEFICS2?
- Basis in paper: [inferred] The paper uses IDEFICS2-8B and shows data sharing improves performance, but doesn't explore other models
- Why unresolved: The study focuses on a single model architecture and doesn't compare effectiveness across different vision-language models
- What evidence would resolve it: Comparing performance and language trends when using data sharing with models like GPT-4V, Flamingo, or other state-of-the-art VLMs

### Open Question 2
- Question: What is the long-term impact of coupling comprehension and generation on language drift and vocabulary diversity in real-world deployment scenarios?
- Basis in paper: [explicit] The paper shows coupling reduces vocabulary collapse but still observes some decrease, and discusses limitations of fixed worker pools
- Why unresolved: The study has a fixed set of workers and limited rounds, making it unclear how coupling would affect language in dynamic, large-scale deployments
- What evidence would resolve it: Long-term deployment studies with changing user populations, measuring vocabulary growth, semantic drift, and alignment with human language over thousands of interactions

### Open Question 3
- Question: How does the coupling strategy affect performance on spatial reasoning tasks over time, and can the model overcome its initial weakness in this area?
- Basis in paper: [explicit] The paper identifies consistent underperformance on spatial reasoning tasks and shows coupling helps but doesn't eliminate the gap
- Why unresolved: The analysis shows persistent difficulty with spatial language despite overall improvement, without explaining why this specific aspect remains challenging
- What evidence would resolve it: Analysis of how spatial reasoning performance evolves with additional training, comparison of attention patterns on spatial vs. non-spatial descriptions, and evaluation of whether coupling strategies specifically designed for spatial reasoning improve outcomes

## Limitations
- The coupling mechanisms, while intuitively sound, lack extensive ablation studies to isolate the contribution of each component
- The human interaction data collection process is not fully specified, making it difficult to assess potential biases or limitations in the evaluation
- The corpus evidence for related work was notably weak, suggesting either a novel contribution or limited prior work in this exact area

## Confidence
- **High confidence**: The basic premise that coupling comprehension and generation can improve performance in reference games; the experimental methodology and evaluation metrics are sound
- **Medium confidence**: The specific mechanisms by which coupling creates performance improvements; the qualitative claims about language becoming more human-like
- **Low confidence**: The generalizability of results beyond the specific tangram reference game setting; the scalability of the approach to more complex language tasks

## Next Checks
1. Conduct ablation studies to isolate the contribution of joint inference versus data sharing in the coupling mechanism
2. Test the approach on a different reference game dataset or a more complex language task to assess generalizability
3. Implement and compare alternative coupling strategies (e.g., attention-based fusion, shared encoder architectures) to validate the chosen approach