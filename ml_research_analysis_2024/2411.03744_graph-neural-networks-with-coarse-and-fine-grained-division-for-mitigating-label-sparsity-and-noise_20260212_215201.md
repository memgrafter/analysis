---
ver: rpa2
title: Graph Neural Networks with Coarse- and Fine-Grained Division for Mitigating
  Label Sparsity and Noise
arxiv_id: '2411.03744'
source_url: https://arxiv.org/abs/2411.03744
tags:
- nodes
- noise
- label
- labels
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semi-supervised node classification
  on graphs with sparse and noisy labels. Existing GNNs struggle with noisy labels
  because they often connect unlabeled nodes to potentially noisy labeled ones, propagating
  misinformation during message passing.
---

# Graph Neural Networks with Coarse- and Fine-Grained Division for Mitigating Label Sparsity and Noise

## Quick Facts
- arXiv ID: 2411.03744
- Source URL: https://arxiv.org/abs/2411.03744
- Reference count: 40
- This paper proposes GNN-CFGD, which uses GMM-based coarse division, clean-label linking, and fine-grained confidence-based supervision to improve GNN performance under label sparsity and noise.

## Executive Summary
This paper addresses the challenge of semi-supervised node classification on graphs with sparse and noisy labels. Existing GNNs struggle with noisy labels because they often connect unlabeled nodes to potentially noisy labeled ones, propagating misinformation during message passing. To tackle this, the authors propose GNN-CFGD, which combines three key ideas: (1) a Gaussian Mixture Model (GMM) to coarsely separate clean and noisy labels using per-node loss distributions from peer GCNs, (2) a clean-labels-oriented link strategy that connects unlabeled nodes only to identified clean labels via an edge predictor, and (3) a fine-grained division of both noisy and unlabeled nodes into confidence sets and remaining sets based on predicted confidence. Experiments on Cora-ML, CiteSeer, PubMed, and Coauthor CS datasets with uniform and pair noise show GNN-CFGD consistently outperforms state-of-the-art baselines, particularly under higher noise rates.

## Method Summary
GNN-CFGD addresses label noise in GNNs through a three-component framework. First, two peer GCNs are trained simultaneously, and their per-node cross-entropy losses are modeled by a GMM to coarsely separate clean and noisy labels. Second, an edge predictor (GCN encoder + cosine-similarity decoder) learns node similarities and adds edges from unlabeled nodes to clean-labeled nodes based on high similarity scores. Third, the peer GCNs predict pseudo-labels for noisy-labeled and unlabeled nodes, which are then divided into confidence sets (nodes meeting agreement and confidence thresholds) and remaining sets (others). The model is trained using a composite loss combining cross-entropy on clean/confidence sets, down-weighted loss on remaining sets, graph reconstruction loss, and consistency regularization between peer predictions.

## Key Results
- On PubMed with 40% uniform noise, GNN-CFGD achieves 78.70% accuracy compared to GCN's 70.97%
- Consistent performance improvement across Cora-ML, CiteSeer, PubMed, and Coauthor CS datasets under both uniform and pair noise
- Ablation studies confirm the effectiveness of each component, especially the coarse-grained GMM-based division and clean-label linking strategy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coarse-grained GMM division separates clean labels from noisy labels based on per-node loss distributions
- Mechanism: Two peer GCNs are trained simultaneously; their per-node cross-entropy losses are modeled by a GMM with two components (small-loss = clean, large-loss = noisy). Nodes are considered clean if both peers agree (intersection of high-probability nodes).
- Core assumption: Deep models initially memorize clean samples before noisy ones, so loss magnitude correlates with label cleanliness.
- Evidence anchors:
  - [abstract] "we introduce a Gaussian Mixture Model (GMM) based on the memory effect to perform a coarse-grained division of the given labels into clean and noisy labels."
  - [section 4.2] "Recent research has demonstrated that deep models (including GNN) have the appealing phenomenon that they initially memorize clean samples and then gradually memorize noisy samples as the training epoch increases."

### Mechanism 2
- Claim: Clean labels oriented link connects unlabeled nodes only to cleanly identified labeled nodes, reducing noisy label propagation.
- Mechanism: An edge predictor (GCN encoder + cosine-similarity decoder) learns node similarities. Edges are added from unlabeled nodes to clean-labeled nodes based on high similarity scores, excluding noisy-labeled nodes.
- Core assumption: Graph augmentation via links to clean-labeled nodes provides stronger, less corrupted supervision than links to potentially noisy labeled nodes.
- Evidence anchors:
  - [abstract] "we propose a clean labels oriented link that connects unlabeled nodes to cleanly labeled nodes, aimed at mitigating label sparsity and promoting supervision propagation."
  - [section 4.3] "connecting unlabeled to clean labeled nodes is more effective for improving the classification performance of GCN."

### Mechanism 3
- Claim: Fine-grained division refines supervision by splitting noisy-labeled nodes into confident vs. remaining sets, and generating pseudo-labels for unlabeled nodes.
- Mechanism: After coarse division, the two peer GCNs predict pseudo-labels for noisy-labeled and unlabeled nodes. Nodes meeting agreement and confidence thresholds are kept for supervision; others are down-weighted or discarded.
- Core assumption: Peer agreement plus confidence thresholding can identify reliably corrected labels, enabling the model to use noisy data without overfitting.
- Evidence anchors:
  - [abstract] "to provide refined supervision for noisy labeled nodes and additional supervision for unlabeled nodes, we fine-grain the noisy labeled and unlabeled nodes into two candidate sets based on confidence, respectively."
  - [section 4.4] "The nodes that satisfy Eq. (14) form a confidence setVcf. Nodes in Vcf are used for supervision..."

## Foundational Learning

- Concept: Gaussian Mixture Models (GMM) for clustering loss distributions
  - Why needed here: GMM models the bimodal loss distribution expected from clean vs. noisy labels, enabling probabilistic identification of clean nodes.
  - Quick check question: If a node has low loss in both peer GCNs, what does the GMM assign it in terms of label cleanliness probability?

- Concept: Graph convolutional neural networks (GCN) message passing
  - Why needed here: GCN aggregates neighbor features to update node representations; understanding how message passing propagates label information is key to grasping why linking to clean-labeled nodes matters.
  - Quick check question: In a standard GCN, what happens to an unlabeled node's representation if its neighbors include many noisy-labeled nodes?

- Concept: Consistency regularization (KL divergence between peer predictions)
  - Why needed here: Penalizing divergence between peer GCN outputs stabilizes training and prevents overfitting to noise, especially when refining noisy labels.
  - Quick check question: If two peer GCNs disagree strongly on a node's label, what does the consistency loss encourage?

## Architecture Onboarding

- Component map:
  - Input: Graph (A, X), noisy label set YN
  - GMM + peer GCNs: Coarse division → clean label set Vcl
  - Edge predictor (GCN encoder + cosine decoder): Link unlabeled nodes to Vcl → augmented adjacency Â
  - Peer GCNs on augmented graph: Predict pseudo-labels for VN and VU
  - Fine-grained division: Confidence sets Vcf, Vpl; remaining sets Vre, Vun
  - Loss: Cross-entropy on clean/confidence sets, down-weighted on remaining, graph reconstruction loss, consistency regularization
  - Output: Predicted labels for unlabeled nodes

- Critical path: A → peer GCNs → GMM → Vcl → edge predictor → Â → peer GCNs → pseudo-labels → fine-grained sets → loss → updated GCNs

- Design tradeoffs:
  - GMM threshold pth and confidence thresholds thpse1/2: Too high → too few clean/noisy nodes used; too low → noise leaks in.
  - Number of negative samples Nneg in edge predictor: Higher → better negative sampling but more computation.
  - Balance parameters α (reconstruction) and λ (consistency): Over-weighting reconstruction may hurt classification; over-weighting consistency may slow learning.

- Failure signatures:
  - Model accuracy drops sharply when noise rate > 40% → GMM fails to cleanly separate nodes.
  - High variance across runs → peer GCNs disagree too much or confidence thresholds too strict.
  - No improvement over baseline → clean label set too small or edge predictor too weak.

- First 3 experiments:
  1. Run with uniform noise at 20% on Cora-ML, vary pth in {0.4,0.5,0.6}, observe clean label set size and accuracy.
  2. Compare linkCL vs linkL by replacing GMM output with random clean label guess, measure propagation of noisy labels.
  3. Remove consistency regularization (set λ=0), check if overfitting occurs on noisy-labeled nodes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed GMM-based coarse-grained division perform on real-world datasets with naturally occurring label noise versus synthetically injected noise?
- Basis in paper: [inferred] The paper evaluates the GMM approach on datasets with synthetic noise but does not discuss its performance on real-world noisy datasets.
- Why unresolved: Real-world label noise often exhibits complex, non-uniform patterns that may not be captured by synthetic noise models.
- What evidence would resolve it: Experiments comparing GMM performance on datasets with known real-world label noise against synthetic noise scenarios.

### Open Question 2
- Question: What is the impact of varying the number of peer GCNs on the robustness and accuracy of the GNN-CFGD model?
- Basis in paper: [explicit] The paper mentions using two peer GCNs but does not explore the effect of using more or fewer networks.
- Why unresolved: The optimal number of peer GCNs for balancing computational cost and performance improvement is unclear.
- What evidence would resolve it: Systematic experiments varying the number of peer GCNs and analyzing performance trade-offs.

### Open Question 3
- Question: How does the edge predictor in the clean labels oriented link component scale with very large graphs in terms of computational efficiency?
- Basis in paper: [inferred] The paper does not address scalability concerns or computational complexity for large-scale graphs.
- Why unresolved: Large graphs may introduce significant computational overhead, affecting the practicality of the edge predictor.
- What evidence would resolve it: Scalability analysis and performance benchmarks on large graphs with varying sizes.

### Open Question 4
- Question: What are the long-term effects of pseudo-label generation on model performance as more unlabeled nodes are processed?
- Basis in paper: [explicit] The paper discusses generating pseudo-labels but does not explore the cumulative impact over time.
- Why unresolved: Accumulation of incorrect pseudo-labels could degrade performance, but the threshold and dynamics are unclear.
- What evidence would resolve it: Longitudinal studies tracking model performance as more pseudo-labels are generated and utilized.

## Limitations
- The GMM-based coarse division relies heavily on the assumption that clean and noisy labels exhibit distinct loss distributions, which may not hold for all graph structures or noise patterns
- The method's effectiveness appears to depend on having sufficient clean labels to bootstrap the process - extreme noise rates (>40%) may break the initial GMM separation
- Computational overhead from maintaining two peer GCNs and the edge predictor is not thoroughly analyzed

## Confidence
- Mechanism 1 (GMM coarse division): Medium-High
- Mechanism 2 (clean label linking): High
- Mechanism 3 (fine-grained division): Medium

## Next Checks
1. Test GNN-CFGD on graphs with heterophily (where neighbor labels may differ) to assess generalization beyond homophilic graphs
2. Analyze the sensitivity of results to different confidence threshold values (thpse1, thpse2) across datasets
3. Evaluate the method's performance when clean labels are extremely sparse (<5% of total labels) to test robustness limits