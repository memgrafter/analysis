---
ver: rpa2
title: Negative Label Guided OOD Detection with Pretrained Vision-Language Models
arxiv_id: '2403.20078'
source_url: https://arxiv.org/abs/2403.20078
tags:
- labels
- negative
- detection
- auroc
- fpr95
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents NegLabel, a novel method for out-of-distribution
  (OOD) detection in vision-language models (VLMs). The core idea is to leverage a
  large set of negative labels, semantically distant from the in-distribution (ID)
  classes, to enhance the model's ability to distinguish OOD samples.
---

# Negative Label Guided OOD Detection with Pretrained Vision-Language Models

## Quick Facts
- arXiv ID: 2403.20078
- Source URL: https://arxiv.org/abs/2403.20078
- Authors: Xue Jiang; Feng Liu; Zhen Fang; Hong Chen; Tongliang Liu; Feng Zheng; Bo Han
- Reference count: 40
- One-line primary result: NegLabel achieves state-of-the-art OOD detection performance by leveraging negative labels semantically distant from ID classes.

## Executive Summary
This paper introduces NegLabel, a novel method for out-of-distribution (OOD) detection in vision-language models (VLMs) that leverages negative labels semantically distant from in-distribution (ID) classes. The approach uses a NegMining algorithm to select high-quality negative labels from extensive corpora based on their distance from ID labels, and proposes a novel OOD score combining affinities between images and both ID and negative labels. Extensive experiments demonstrate that NegLabel achieves state-of-the-art performance on various OOD detection benchmarks, particularly when combined with CLIP models.

## Method Summary
NegLabel addresses OOD detection by mining negative labels that are semantically distant from ID classes and incorporating them into a novel scoring mechanism. The method consists of three main components: (1) NegMining algorithm that selects negative labels from lexical databases like WordNet based on their semantic distance from ID labels, (2) a NegLabel score that combines similarities between image embeddings and both ID and negative label embeddings using a sum-softmax formulation, and (3) a grouping strategy that divides negative labels into groups to reduce variance in the OOD score. The approach is designed to work in a zero-shot setting without requiring fine-tuning on the ID classes.

## Key Results
- Achieves 94.21% AUROC and 25.40% FPR95 on ImageNet-1k OOD detection benchmark when combined with CLIP
- Outperforms numerous existing methods in both zero-shot and fully-supervised settings
- Demonstrates remarkable robustness against domain shifts across various OOD detection benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Negative labels improve OOD detection by increasing the semantic gap between ID and OOD samples.
- Mechanism: The NegMining algorithm selects negative labels that are semantically distant from ID labels. This creates a larger separation in the embedding space between ID samples (which have low affinity to negative labels) and OOD samples (which have higher affinity to negative labels).
- Core assumption: The semantic distance between negative labels and ID labels is positively correlated with their distance from OOD samples in the embedding space.
- Evidence anchors:
  - [abstract]: "We design a novel scheme for the OOD score collaborated with negative labels."
  - [section]: "The algorithm utilizes the distance between a negative label and ID labels as a metric to assess their adequacy in terms of semantic divergence."
  - [corpus]: "Weak evidence. Corpus only provides related papers but no direct semantic analysis."
- Break condition: If the selected negative labels are not sufficiently distant from OOD samples, or if the embedding space does not preserve semantic relationships, the mechanism fails.

### Mechanism 2
- Claim: The sum-softmax formulation of the NegLabel score provides robustness against inter-class confusion.
- Mechanism: Instead of using the maximum similarity to any ID label, the score sums over all ID label similarities. This smooths out errors from misclassifying between similar classes.
- Core assumption: ID samples will have higher total similarity to the set of ID labels than OOD samples, even if individual class similarities are confused.
- Evidence anchors:
  - [abstract]: "The score combines the knowledge from the ID and negative label space, thus better leveraging the VLMs' capabilities of comprehending text."
  - [section]: "The numerator of Eq. (6) uses the sum of the sample's similarity to all ID labels, making the OOD score more robust to super-class confusion."
  - [corpus]: "No direct evidence about softmax robustness in corpus."
- Break condition: If the sum of similarities across ID labels is not a reliable indicator of ID-ness, or if OOD samples coincidentally have high total similarity to ID labels.

### Mechanism 3
- Claim: The grouping strategy reduces variance in the OOD score by limiting false positives within subgroups.
- Mechanism: Negative labels are divided into groups, and the OOD score is computed separately for each group. This prevents any single negative label from having disproportionate influence on the score.
- Core assumption: False positives between ID images and negative labels are independent across groups, so averaging reduces variance.
- Evidence anchors:
  - [abstract]: "To balance the trade-off between the additional knowledge gained from negative labels and the risk of false positives, we propose a grouping strategy."
  - [section]: "This strategy limits the risk of false positives within each group, and further smooths this noise through averaging across groups."
  - [corpus]: "No direct evidence about grouping strategy in corpus."
- Break condition: If false positives are correlated across groups, or if the number of groups is too small to effectively reduce variance.

## Foundational Learning

- Concept: Vision-Language Models (VLMs) like CLIP
  - Why needed here: The paper relies on CLIP-like models for extracting image and text embeddings, which are the foundation of the OOD detection approach.
  - Quick check question: What are the two encoders in a CLIP-like model, and what do they extract?

- Concept: Zero-shot classification
  - Why needed here: The OOD detection method operates in a zero-shot setting, where the model has not been fine-tuned on the specific ID classes.
  - Quick check question: How does zero-shot classification differ from traditional supervised classification in terms of training data requirements?

- Concept: Semantic similarity in embedding space
  - Why needed here: The method relies on measuring the similarity between image embeddings and text embeddings of labels to determine OOD-ness.
  - Quick check question: What metric is typically used to measure similarity between embeddings in VLMs like CLIP?

## Architecture Onboarding

- Component map:
  Text encoder -> Image encoder -> NegMining algorithm -> NegLabel score computation

- Critical path:
  1. Preprocess: Calculate text embeddings for ID labels and negative labels.
  2. Inference: Encode input image to get image embedding.
  3. Compute cosine similarities between image embedding and all text embeddings.
  4. Calculate NegLabel score using the sum-softmax formulation.
  5. Compare score to threshold to classify as ID or OOD.

- Design tradeoffs:
  - Number of negative labels (M): More labels provide better coverage but increase computation and risk of false positives.
  - Temperature coefficient (τ): Higher values amplify differences but can lead to overconfidence.
  - Number of groups (ng): More groups reduce variance but increase computation.

- Failure signatures:
  - Poor performance on iNaturalist: May indicate that negative labels are not sufficiently distant from OOD samples in that domain.
  - Performance drops with domain shift: Suggests the method is sensitive to changes in the distribution of ID data.
  - High variance in OOD scores: Could indicate that the grouping strategy is not effectively reducing false positives.

- First 3 experiments:
  1. Reproduce the ImageNet-1k benchmark results to verify the basic functionality.
  2. Test the impact of varying the number of negative labels (M) on OOD detection performance.
  3. Evaluate the robustness of the method to different domain shifts by using ImageNet-Sketch as ID data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of negative label corpus (e.g., WordNet vs. Wikipedia) impact the performance of NegLabel?
- Basis in paper: [explicit] The paper discusses using WordNet as the corpus and mentions potential exploration of other sources like Wikipedia.
- Why unresolved: The paper does not provide experimental results comparing different corpus sources.
- What evidence would resolve it: Experiments comparing NegLabel performance using different corpora (e.g., WordNet, Wikipedia, Part-of-Speech Tags) would reveal the impact of corpus choice.

### Open Question 2
- Question: What is the optimal number of negative labels for different OOD detection tasks and datasets?
- Basis in paper: [explicit] The paper mentions that the performance of NegLabel improves with increasing negative labels but then declines, suggesting an optimal number exists.
- Why unresolved: The paper does not provide a systematic analysis of the relationship between the number of negative labels and OOD detection performance across various tasks and datasets.
- What evidence would resolve it: Conducting experiments with varying numbers of negative labels for different OOD detection tasks and datasets would identify the optimal number for each scenario.

### Open Question 3
- Question: How does the NegMining algorithm's percentile distance threshold (η) affect the selection of negative labels and subsequent OOD detection performance?
- Basis in paper: [explicit] The paper mentions using the 5th percentile distance as the default setting and provides a brief discussion on its rationale.
- Why unresolved: The paper does not explore the impact of different percentile distance thresholds on the quality of negative labels and OOD detection performance.
- What evidence would resolve it: Experiments comparing NegLabel performance with different percentile distance thresholds would reveal the optimal threshold for selecting negative labels.

## Limitations

- The method's performance is highly dependent on the quality and comprehensiveness of the negative label corpus (WordNet), which may limit its applicability in domains with limited lexical resources.
- The effectiveness of the approach is tied to the specific architecture and capabilities of the underlying vision-language model (CLIP), potentially limiting generalization to other VLMs.
- The grouping strategy, while reducing variance, may introduce bias if the groups are not well-balanced or if false positives are correlated across groups.

## Confidence

- **High Confidence**: The basic mechanism of using negative labels to increase the semantic gap between ID and OOD samples is well-supported by the experimental results. The state-of-the-art performance on ImageNet-1k and other benchmarks provides strong evidence for this core claim.
- **Medium Confidence**: The effectiveness of the sum-softmax formulation and the grouping strategy in improving OOD detection performance is supported by ablation studies, but the specific hyperparameters (temperature coefficient τ, number of groups ng) may require tuning for different datasets and VLMs.
- **Low Confidence**: The claim that the method exhibits remarkable robustness against domain shifts is based on a limited number of experiments. More extensive testing across diverse domain shifts and VLMs is needed to validate this claim.

## Next Checks

1. **Negative Label Quality Analysis**: Conduct a detailed analysis of the quality of negative labels selected by the NegMining algorithm. Measure the semantic distance between ID labels and negative labels, and assess whether this distance correlates with OOD detection performance.

2. **Cross-VLM Generalization**: Evaluate the method's performance using different vision-language models beyond CLIP, such as OpenCLIP or BLIP. Compare the results to determine if the proposed approach is specific to CLIP or generalizes to other VLMs.

3. **Domain Shift Robustness**: Design experiments to systematically test the method's robustness against various types of domain shifts, including changes in background, lighting, and object pose. Quantify the performance degradation and identify the factors that contribute to it.