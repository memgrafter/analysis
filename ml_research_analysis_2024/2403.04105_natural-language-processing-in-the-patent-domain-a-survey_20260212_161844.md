---
ver: rpa2
title: 'Natural Language Processing in the Patent Domain: A Survey'
arxiv_id: '2403.04105'
source_url: https://arxiv.org/abs/2403.04105
tags:
- patent
- patents
- language
- information
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey reviews NLP applications in the patent domain, highlighting
  the potential of large language models (LLMs) for tasks such as classification,
  retrieval, analysis, and generation. Patents present unique challenges due to their
  long context, technical language, and precision requirements.
---

# Natural Language Processing in the Patent Domain: A Survey

## Quick Facts
- **arXiv ID**: 2403.04105
- **Source URL**: https://arxiv.org/abs/2403.04105
- **Reference count**: 40
- **Primary result**: Reviews NLP applications in patents, highlighting LLMs' potential for classification, retrieval, analysis, and generation tasks while identifying key challenges and research gaps.

## Executive Summary
This survey comprehensively reviews Natural Language Processing applications in the patent domain, emphasizing the transformative potential of large language models (LLMs) for various patent-related tasks. Patents present unique challenges due to their long context length, highly technical and artificial language, and strict precision requirements. While traditional NLP methods have been successfully applied to patent analysis, the survey reveals that LLM applications remain largely underdeveloped, presenting significant opportunities for future research. The paper systematically categorizes nine analysis tasks and four generation tasks, evaluating current methodologies and identifying critical research directions including the need for better datasets, benchmarks, and domain-specific LLMs to improve patent processing efficiency and effectiveness.

## Method Summary
The survey provides a comprehensive review of existing literature on NLP applications in the patent domain, systematically categorizing tasks and methodologies while identifying gaps in current research. It introduces patent fundamentals including structural characteristics and data sources, then evaluates both traditional and emerging LLM approaches across classification, retrieval, extraction, novelty prediction, granting prediction, litigation prediction, valuation, technology forecasting, innovation recommendation, and generation tasks. The analysis draws on 40 references spanning patent law, NLP methodologies, and application-specific studies to provide a holistic view of the field's current state and future directions.

## Key Results
- Patent texts present unique challenges including long context length, technical language, and high precision requirements that distinguish them from general NLP tasks
- Traditional NLP methods have been successfully applied to patent tasks, but LLM applications remain largely unexplored despite their potential advantages
- The survey identifies nine analysis tasks and four generation tasks, systematically reviewing methodologies and performance while highlighting critical research gaps in datasets, benchmarks, and domain-specific model development

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Patent classification can be improved by incorporating image data alongside text data.
- **Mechanism**: Patent documents contain both textual descriptions and visual drawings (figures). While textual data is the primary carrier of legally binding information, images can provide additional context and details about the invention. Convolutional Neural Networks (CNNs) can automatically extract image features from patent drawings, which can then be combined with text embeddings for a more comprehensive patent representation.
- **Core assumption**: Patent images contain meaningful information that is complementary to the textual descriptions and can enhance the classification accuracy.
- **Evidence anchors**:
  - [abstract]: "A patent is not merely a text document but can include drawings, i.e., visual components. Thus, multimodal methods such as CLIP (Radford et al., 2021) and Vision Transformers (Dosovitskiy, 2020) may unlock this potential."
  - [section]: "Images can serve for automated patent classification (Jiang et al., 2021). There is usually no specific feature extraction process. Deep-learning networks, typically convolutional neural networks, can automatically extract image features from the pixel values."
  - [corpus]: Weak evidence. The corpus contains papers related to patent generation and analysis but lacks direct evidence for image-based patent classification.
- **Break condition**: If the patent images are too generic or lack sufficient detail, the image features may not provide meaningful information for classification.

### Mechanism 2
- **Claim**: Fine-tuning transformer-based language models on patent-specific data can significantly improve performance on patent-related tasks compared to using general-purpose models.
- **Mechanism**: Patent texts have unique characteristics, including long context length, technical language, and high precision requirements. General-purpose language models, which are pre-trained on diverse text corpora, may not capture these patent-specific nuances effectively. Fine-tuning these models on patent-specific datasets allows them to adapt to the unique language patterns, terminology, and structure of patent documents.
- **Core assumption**: Patent-specific fine-tuning can improve the model's understanding of patent language and enhance its performance on patent-related tasks.
- **Evidence anchors**:
  - [abstract]: "The patent language is highly technical and artificial, including specialized terminology, legal phrases, and sometimes newly coined terms to describe new concepts that may not yet have been widely recognized."
  - [section]: "Lee et al. fine-tuned the BERT model for the patent classification task and achieved 81.75% precision (Lee and Hsiang, 2020b), which was more than 7% higher than traditional machine learning under the same setting, using word embedding and classifiers (Li et al., 2018)."
  - [corpus]: Weak evidence. The corpus contains papers related to patent analysis and generation but lacks direct evidence for patent-specific fine-tuning.
- **Break condition**: If the patent-specific dataset is too small or lacks diversity, the fine-tuned model may overfit to the training data and not generalize well to unseen patent documents.

### Mechanism 3
- **Claim**: Leveraging the hierarchical structure of patent classification codes can improve the accuracy of patent classification tasks.
- **Mechanism**: Patent classification codes follow a hierarchical structure, with sections, classes, sub-classes, main groups, and sub-groups. This hierarchy reflects the relationships between different technology areas. By considering this hierarchical structure during classification, models can leverage the semantic relationships between different levels of the hierarchy to make more informed predictions.
- **Core assumption**: The hierarchical structure of patent classification codes captures meaningful relationships between different technology areas.
- **Evidence anchors**:
  - [abstract]: "Two of the most popular classification schemes are the International Patent Classification (IPC) and Cooperative Patent Classification (CPC) systems. These IPC/CPC codes are hierarchical and divided into sections, classes, sub-classes, main groups, and sub-groups."
  - [section]: "The all-categories method checks whether the top-1 prediction is included in the set of the main class and all incidental classes."
  - [corpus]: Weak evidence. The corpus contains papers related to patent analysis and generation but lacks direct evidence for hierarchical patent classification.
- **Break condition**: If the hierarchical relationships between classification codes are not well-defined or do not capture the true semantic relationships between technology areas, leveraging the hierarchy may not improve classification accuracy.

## Foundational Learning

- **Concept**: Patent document structure and terminology
  - Why needed here: Understanding the unique structure and terminology of patent documents is crucial for effectively applying NLP techniques to patent-related tasks. Patents have specific sections (title, abstract, claims, description, drawings) and use precise legal and technical language.
  - Quick check question: What are the key sections of a patent document, and how do they differ from typical text documents?

- **Concept**: Patent classification schemes (IPC/CPC)
  - Why needed here: Patent classification schemes provide a standardized way to categorize patents based on their technology area. Understanding these schemes is essential for tasks like patent classification and retrieval.
  - Quick check question: What are the main differences between the IPC and CPC classification schemes, and how do they organize patent documents hierarchically?

- **Concept**: NLP techniques for text processing (embeddings, transformers)
  - Why needed here: NLP techniques, such as word embeddings and transformer models, are the foundation for analyzing and processing patent texts. Understanding these techniques is crucial for effectively applying them to patent-related tasks.
  - Quick check question: How do word embeddings capture semantic relationships between words, and how do transformer models use self-attention to capture long-range dependencies in text?

## Architecture Onboarding

- **Component map**: Data preprocessing -> Feature extraction (text, image, metadata embeddings) -> Model architecture (transformers, hybrid models) -> Task-specific layers (classification heads, retrieval modules, generation modules) -> Evaluation

- **Critical path**: 
  1. Data preprocessing: Prepare patent documents for analysis by handling patent-specific elements and extracting relevant features
  2. Feature extraction: Generate text, image, and metadata embeddings to represent patent documents in a numerical format
  3. Model training: Train transformer-based models or hybrid models on patent-specific datasets for the desired task (classification, retrieval, generation)
  4. Evaluation: Assess model performance using appropriate metrics and compare against baselines

- **Design tradeoffs**:
  - Text vs. image vs. metadata: Decide the optimal combination of data sources for the task
  - Model complexity vs. computational cost: Balance model performance with computational resources
  - Patent-specific vs. general-purpose models: Choose between fine-tuning general models or using patent-specific models

- **Failure signatures**:
  - Poor performance on long patent descriptions: Indicates issues with handling long sequences or capturing long-range dependencies
  - Inability to handle patent-specific terminology: Suggests the need for patent-specific fine-tuning or domain adaptation
  - Overfitting to training data: Indicates the need for more diverse training data or regularization techniques

- **First 3 experiments**:
  1. Fine-tune a pre-trained BERT model on a patent classification dataset and compare its performance against a traditional machine learning model (e.g., SVM with TF-IDF features)
  2. Implement a hybrid model that combines text embeddings with image features from patent drawings and evaluate its performance on a patent classification task
  3. Develop a patent-specific language model by pre-training a transformer model on a large corpus of patent documents and fine-tuning it on a downstream patent task (e.g., claim generation)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective are large language models (LLMs) compared to traditional methods for patent classification, particularly when using detailed patent descriptions instead of just titles and abstracts?
- Basis in paper: [explicit] The paper notes that "most research has focused on short text parts of patents, such as titles and abstracts" but these are "usually generic and vain," and recommends focusing on "detailed patent descriptions that contain detailed and specific information about an invention."
- Why unresolved: Current research has not extensively tested LLMs on detailed patent descriptions, and the effectiveness of LLMs in this context remains unexplored.
- What evidence would resolve it: Comparative studies using LLMs on detailed patent descriptions versus traditional methods using titles and abstracts would provide insights into their relative effectiveness.

### Open Question 2
- Question: What are the challenges and potential solutions for using LLMs to accurately assess patent novelty, given the need to compare features rather than just textual similarity?
- Basis in paper: [explicit] The paper highlights that "novelty prediction is a well-specified task by law" but current methods "may correlate with the formal patent novelty but are not equivalent and therefore not necessarily useful for an automated examination process."
- Why unresolved: LLMs need to be adapted to understand and compare patent features accurately, which is a complex task due to the variability of terminology and the need for legal precision.
- What evidence would resolve it: Development and testing of LLMs specifically trained to extract and compare patent features, along with validation against legal standards, would address this challenge.

### Open Question 3
- Question: How can multimodal methods be effectively integrated into patent processing tasks, such as classification and retrieval, given the variability in quality and usefulness of patent drawings?
- Basis in paper: [explicit] The paper mentions that "many drawings in patents are generic without the corresponding description, and some drawings suffer from poor resolution, pixelation, or low quality," yet multimodal methods could "combine multiple data types to improve the performance of patent analysis."
- Why unresolved: The variability in patent drawings poses a challenge for multimodal models, and there is limited research on how to effectively leverage both text and images in patent tasks.
- What evidence would resolve it: Studies comparing the performance of multimodal models versus text-only models on patent tasks, using datasets with varying drawing quality, would provide insights into the effectiveness of multimodal approaches.

## Limitations

- Most empirical evidence for LLM applications in patents remains emerging, with limited comprehensive performance benchmarks comparing traditional methods against modern LLMs
- Quality and availability of patent-specific datasets vary significantly across different tasks, potentially biasing conclusions about method effectiveness
- The survey identifies promising directions but lacks extensive validation studies across diverse patent domains and task types

## Confidence

- **High confidence**: The unique challenges of patent processing (long context, technical language, precision requirements) are well-established and supported by multiple sources in the patent literature
- **Medium confidence**: The potential benefits of patent-specific fine-tuning and multimodal approaches (text + images) are supported by preliminary evidence but require more extensive validation across diverse patent domains
- **Medium confidence**: The identified future research directions (better datasets, benchmarks, domain-specific LLMs) are logical extensions of current limitations but their relative importance may vary by specific patent task

## Next Checks

1. Conduct controlled experiments comparing general-purpose LLMs against patent-fine-tuned models across at least five different patent tasks (e.g., classification, novelty prediction, claim generation) using standardized evaluation metrics
2. Create a benchmark dataset that includes both textual and visual patent elements to systematically evaluate multimodal approaches for patent classification and retrieval tasks
3. Perform ablation studies to quantify the contribution of patent-specific pretraining versus task-specific fine-tuning in improving performance on downstream patent analysis tasks