---
ver: rpa2
title: On the Local Complexity of Linear Regions in Deep ReLU Networks
arxiv_id: '2412.18283'
source_url: https://arxiv.org/abs/2412.18283
tags:
- local
- complexity
- linear
- networks
- regions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for understanding the complexity
  of deep ReLU networks based on the distribution of linear regions in the input space.
  The authors define a measure called local complexity, which captures the average
  density of linear regions over a data distribution.
---

# On the Local Complexity of Linear Regions in Deep ReLU Networks

## Quick Facts
- **arXiv ID**: 2412.18283
- **Source URL**: https://arxiv.org/abs/2412.18283
- **Reference count**: 40
- **Primary result**: Local complexity measures the average density of linear regions in ReLU networks and correlates with feature learning, adversarial robustness, and optimization dynamics

## Executive Summary
This paper introduces a framework for understanding the complexity of deep ReLU networks based on the distribution of linear regions in the input space. The authors define a measure called local complexity, which captures the average density of linear regions over a data distribution and is robust to small perturbations in network parameters. They establish theoretical connections between local complexity and key network properties including feature learning, adversarial robustness, and implicit regularization during optimization. The framework provides both theoretical analysis and empirical validation across MNIST classification and synthetic data experiments.

## Method Summary
The authors define local complexity as the expected volume of the nonlinear locus over the data distribution, where the nonlinear locus represents boundaries between linear regions. They compute this measure by adding Gaussian noise to biases and estimating the fraction of neurons that are "good" (nonlinear) at each input point. The framework connects local complexity to local rank (average dimension of feature manifolds), total variation (adversarial robustness), and representation cost (optimization dynamics). Experiments train fully connected MLPs with ReLU activations using Adam optimizer with learning rate 1e-4, tracking these metrics throughout training on MNIST and synthetic datasets.

## Key Results
- Networks that learn low-dimensional feature representations have lower local complexity
- Local complexity serves as an upper bound on total variation, connecting it to adversarial robustness
- Optimization implicitly minimizes local complexity through representation cost minimization
- Empirical validation shows tight relationship between local complexity and local rank in synthetic data, with more complex dynamics observed on MNIST

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local complexity measures the average density of linear regions in the input space, which directly reflects the model's representational simplicity.
- Mechanism: By defining local complexity as the expected volume of the nonlinear locus over the data distribution, the authors create a measure that is robust to small parameter perturbations. This allows them to capture the typical behavior of the network rather than just the complexity at a single parameter value.
- Core assumption: The nonlinear locus (where gradients are discontinuous) corresponds to boundaries between linear regions, and its density over the data distribution reflects model complexity.
- Evidence anchors:
  - [abstract] "We define the local complexity of a neural network with continuous piecewise linear activations as a measure of the density of linear regions over an input data distribution."
  - [section 3] "For fixed parameter θ, the nonlinear locus of the network Nθ over the input space is given by BNθ = {x ∈ Rn0 : ∇xNθ(·) is discontinuous at x}."
  - [corpus] Weak - corpus doesn't mention linear regions or complexity measures directly.
- Break condition: If the data distribution has regions with zero density, the local complexity measure may not capture the true complexity of the network in those regions.

### Mechanism 2
- Claim: Networks that learn low-dimensional feature representations have lower local complexity.
- Mechanism: The authors show that the local rank (average dimension of the feature manifold at intermediate layers) is bounded above by the local complexity. Since lower-dimensional feature manifolds imply fewer linear regions, networks with low-dimensional representations will have lower local complexity.
- Core assumption: The dimension of the feature manifold at each layer directly correlates with the number of linear regions in that layer's output.
- Evidence anchors:
  - [abstract] "We show theoretically that ReLU networks that learn low-dimensional feature representations have a lower local complexity."
  - [section 4] "Theorem 5. For any ϵ > 0, the local ranks across layers can be bounded in terms of the local complexity as follows: 1/n0 Cbias LC ≤ PL l=1 q C2 grad LRϵ l +ϵ2nl."
  - [corpus] Weak - corpus doesn't provide evidence for this specific relationship between feature dimensionality and linear regions.
- Break condition: If the network learns representations that are low-dimensional but highly nonlinear within that subspace, the bound may not hold.

### Mechanism 3
- Claim: Local complexity is bounded by total variation, providing a connection to adversarial robustness.
- Mechanism: The authors prove that the local complexity serves as an upper bound on the total variation of the network over the input space. Since total variation measures how much the network's output changes with respect to small input changes, a lower local complexity implies greater robustness to adversarial examples.
- Core assumption: The total variation of a network over the data distribution is a meaningful measure of its adversarial robustness.
- Evidence anchors:
  - [abstract] "we show that the local complexity serves as an upper bound on the total variation of the function over the input data distribution and thus that feature learning can be related to adversarial robustness."
  - [section 5] "Theorem 7. Let gl denote the rest of the network after the lth layer, so that Nθ = gl ◦ ϕ(zl − bl). Let Cl denote the Lipschitz constant of gl. Then with the same setting and notations as Theorem 2: TV · Lcη bias max1≤l≤L Cl − ¯ξη − B · Cgrad · Cbias ≤ LC."
  - [corpus] Weak - corpus doesn't discuss total variation or adversarial robustness in the context of linear regions.
- Break condition: If the network has high Lipschitz constants in later layers, the bound may not effectively constrain total variation.

## Foundational Learning

- Concept: Linear regions in piecewise linear neural networks
  - Why needed here: The entire paper builds on understanding how the input space is partitioned into linear regions by ReLU networks, and how this partitioning relates to model complexity.
  - Quick check question: What determines the number and shape of linear regions in a ReLU network?

- Concept: Feature manifolds and their dimensionality
  - Why needed here: The paper connects the local complexity of linear regions to the dimensionality of learned feature representations, showing that networks with lower-dimensional feature manifolds have simpler linear region structures.
  - Quick check question: How does the rank of the Jacobian of intermediate layer representations relate to the dimensionality of the feature manifold?

- Concept: Total variation and its relationship to robustness
  - Why needed here: The paper establishes a bound between local complexity and total variation, suggesting that networks with simpler linear region structures are more robust to adversarial examples.
  - Quick check question: Why does lower total variation of a network over the data distribution imply greater adversarial robustness?

## Architecture Onboarding

- Component map:
  - Local complexity: Defined as the expected density of nonlinear locus over the data distribution
  - Local rank: Average dimension of feature manifolds at intermediate layers
  - Total variation: Expected gradient magnitude over the data distribution
  - Representation cost: Minimum parameter norm needed to represent a function
  - Weight decay: Regularization term that implicitly minimizes local complexity

- Critical path:
  1. Define local complexity using the expected volume of nonlinear locus
  2. Connect local complexity to local rank through Jacobian analysis
  3. Establish bound between local complexity and total variation
  4. Show how optimization implicitly minimizes local complexity through representation cost

- Design tradeoffs:
  - Local complexity vs. expressive power: Simpler linear region structures may limit the network's ability to fit complex functions
  - Robustness vs. accuracy: Networks with lower local complexity may be more robust but potentially less accurate
  - Dimensionality vs. complexity: Lower-dimensional feature representations lead to simpler linear region structures but may lose information

- Failure signatures:
  - If the data distribution has regions with zero density, local complexity may not capture true network complexity
  - If the network learns highly nonlinear representations within low-dimensional manifolds, bounds may not hold
  - If Lipschitz constants in later layers are large, total variation bound may be loose

- First 3 experiments:
  1. Compute local complexity for a simple 2-layer network with varying widths to verify the theoretical bounds
  2. Train a network on a synthetic dataset with known feature dimensionality and measure the correlation between local rank and local complexity
  3. Compare adversarial robustness of networks with different local complexities on a standard benchmark like MNIST or CIFAR-10

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the dynamics of local complexity and local rank interact during training across different architectures and datasets?
- Basis in paper: [explicit] The paper shows that local complexity and local rank are tightly related in synthetic Gaussian data experiments, but notes that "the dynamics of the local rank can become much more complex and it is not yet fully understood" for other datasets like MNIST.
- Why unresolved: The empirical results in Figure 12 demonstrate complex interactions between local complexity and local rank that differ from synthetic data, but the paper doesn't provide theoretical analysis explaining these differences.
- What evidence would resolve it: Detailed analysis of how the relationship between local complexity and local rank varies with architecture depth, width, dataset complexity, and training dynamics across multiple benchmark datasets.

### Open Question 2
- Question: Can the theoretical bounds between local complexity and total variation be tightened to better explain the empirical observations during training?
- Basis in paper: [explicit] The paper acknowledges that "the theoretical result may not fully explain the relationship between the total variation and the local complexity during training" and that "the dynamics can be more complex in general."
- Why unresolved: The bound in Theorem 7 depends on Lipschitz constants that may not capture the full relationship, and empirical results show that total variation can increase while local complexity decreases in some training phases.
- What evidence would resolve it: Derivation of tighter bounds that account for the specific training dynamics observed, or identification of additional factors that influence the relationship between local complexity and total variation during different training phases.

### Open Question 3
- Question: How does the local complexity framework extend to other piecewise linear activation functions beyond ReLU?
- Basis in paper: [inferred] The paper focuses exclusively on ReLU networks but notes in the limitations that "our proof techniques could be adapted to obtain results for more general piecewise linear activation functions."
- Why unresolved: The current theoretical framework and empirical results are specific to ReLU networks, and extending them to other activation functions would require significant modifications to the proofs and potentially different experimental validation.
- What evidence would resolve it: Successful extension of the local complexity definition and theoretical bounds to at least two other piecewise linear activation functions (e.g., LeakyReLU, Maxout), with corresponding empirical validation showing similar relationships to representation learning and robustness.

## Limitations
- The theoretical bounds between local complexity and total variation may be loose and not fully explain empirical training dynamics
- The framework focuses on fully connected MLPs with ReLU activations and may not generalize to other architectures or activation functions
- Computational cost of accurately estimating local complexity for large networks could limit practical applicability

## Confidence
- **High Confidence**: The mathematical definitions and theorems relating local complexity to feature learning and total variation are rigorously proven within the paper's framework.
- **Medium Confidence**: The empirical validation across MNIST and synthetic datasets supports the theoretical claims, though the results may not generalize to more complex architectures or real-world distributions.
- **Low Confidence**: The connection between local complexity and grokking behavior, while intriguing, is primarily based on indirect observations and requires further investigation.

## Next Checks
1. **Bound Tightness Analysis**: Systematically measure the gap between theoretical bounds and empirical values of local complexity, total variation, and adversarial robustness across different network architectures and datasets.

2. **Generalization Study**: Test whether the observed relationships between local complexity and feature learning hold for convolutional networks, transformers, and other architectures beyond fully connected MLPs.

3. **Robustness Benchmarking**: Conduct controlled experiments comparing networks with artificially constrained local complexities to measure the direct impact on adversarial robustness across multiple attack types and threat models.