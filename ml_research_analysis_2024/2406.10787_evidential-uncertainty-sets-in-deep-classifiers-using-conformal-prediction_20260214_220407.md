---
ver: rpa2
title: Evidential Uncertainty Sets in Deep Classifiers Using Conformal Prediction
arxiv_id: '2406.10787'
source_url: https://arxiv.org/abs/2406.10787
tags:
- prediction
- coverage
- sets
- data
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Evidential Conformal Prediction (ECP), a method
  for generating prediction sets in image classification tasks that outperforms state-of-the-art
  conformal prediction methods in terms of set size and adaptivity while maintaining
  coverage guarantees. ECP uses evidential deep learning to compute non-conformity
  scores based on uncertainty surprisal and expected utility, leading to smaller and
  more adaptive prediction sets.
---

# Evidential Uncertainty Sets in Deep Classifiers Using Conformal Prediction

## Quick Facts
- arXiv ID: 2406.10787
- Source URL: https://arxiv.org/abs/2406.10787
- Authors: Hamed Karimi; Reza Samavi
- Reference count: 9
- Primary result: Generates prediction sets with median size of 1.64-4.06 labels (vs 2.63-20.62 for baselines) while maintaining coverage

## Executive Summary
This paper introduces Evidential Conformal Prediction (ECP), a novel approach for constructing prediction sets in deep image classifiers that achieves smaller set sizes while maintaining coverage guarantees. The method leverages evidential deep learning to quantify uncertainty through belief functions, replacing traditional softmax probabilities with evidential distributions. ECP computes non-conformity scores based on uncertainty surprisal and expected utility, enabling more adaptive and efficient prediction sets. Experiments on ImageNet datasets demonstrate that ECP outperforms state-of-the-art conformal prediction methods in both set size and adaptivity metrics.

## Method Summary
ECP integrates evidential deep learning with conformal prediction by replacing softmax outputs with evidential distributions that capture both aleatoric and epistemic uncertainty. The method computes non-conformity scores using a combination of uncertainty surprisal (measuring surprise at prediction) and expected utility (measuring confidence in correct prediction). During inference, ECP constructs prediction sets by including all labels whose non-conformity scores fall below a calibrated threshold. The approach maintains valid coverage guarantees while producing significantly smaller and more adaptive prediction sets compared to traditional conformal methods. The framework is compatible with existing deep learning architectures and requires only modification of the output layer and non-conformity scoring function.

## Key Results
- ECP achieves median prediction set sizes of 1.64-4.06 labels across ImageNet datasets, compared to 2.63-20.62 for baseline methods
- Maintains target coverage level of 1-Î´ across all tested configurations
- Demonstrates superior adaptivity in coverage, with more stable performance across different data subsets
- Shows favorable size-adaptivity trade-off compared to competing approaches

## Why This Works (Mechanism)
ECP works by explicitly modeling uncertainty through evidential distributions rather than point estimates or softmax probabilities. The evidential framework captures both the randomness in data (aleatoric uncertainty) and the model's ignorance about correct predictions (epistemic uncertainty). By using uncertainty surprisal as the non-conformity score, ECP penalizes predictions that are both unlikely and uncertain, while expected utility rewards confident correct predictions. This dual consideration allows ECP to make more nuanced decisions about which predictions to include in the set, resulting in smaller sets that still maintain coverage guarantees. The evidential approach also provides natural calibration of uncertainty estimates, which is crucial for reliable conformal prediction.

## Foundational Learning

**Conformal Prediction**: A framework for constructing prediction sets with guaranteed coverage. Needed because it provides statistical guarantees for uncertainty quantification. Quick check: Can you explain the difference between marginal and conditional coverage?

**Evidential Deep Learning**: Uses belief functions instead of probabilities to model uncertainty. Needed because it captures both aleatoric and epistemic uncertainty naturally. Quick check: Can you describe the difference between a Dirichlet distribution and a softmax output?

**Non-conformity Measures**: Functions that quantify how different a prediction is from the expected behavior. Needed because they determine which predictions are included in the set. Quick check: Can you explain why the choice of non-conformity measure affects set size?

## Architecture Onboarding

**Component Map**: Input Images -> Evidential Network -> Belief Parameters -> Non-conformity Scores -> Prediction Set Construction -> Output

**Critical Path**: The evidential network must accurately estimate belief parameters, which are then used to compute non-conformity scores. The prediction set construction step uses these scores along with calibration data to produce final predictions. Performance is bottlenecked by the evidential network's ability to capture true uncertainty.

**Design Tradeoffs**: Evidential approaches provide better uncertainty quantification but increase model complexity and inference time compared to standard softmax networks. The choice of non-conformity measure involves balancing set size against coverage adaptivity.

**Failure Signatures**: Overconfident evidential predictions lead to coverage failures. Poor calibration of the evidential network results in suboptimal non-conformity scores. Computational overhead may make the method impractical for real-time applications.

**3 First Experiments**:
1. Compare ECP prediction set sizes against standard softmax-based conformal prediction on CIFAR-10
2. Test coverage guarantees under covariate shift by evaluating on ImageNet variants
3. Analyze the impact of evidential network architecture depth on uncertainty quantification quality

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to image classification on ImageNet datasets only
- Computational overhead from evidential uncertainty quantification not fully characterized
- Claims of "outperforming state-of-the-art" based on limited comparison set
- No validation on non-image data modalities or real-world deployment scenarios

## Confidence

**High confidence**: Theoretical framework is sound and core experimental results showing reduced set sizes while maintaining coverage are well-supported.

**Medium confidence**: Adaptivity claims supported by experiments but require broader testing across diverse distributions and out-of-distribution scenarios.

**Low confidence**: "Outperforms state-of-the-art" claim should be tempered as comparison set is relatively limited and doesn't include all contemporary approaches.

## Next Checks

1. Test ECP on non-image datasets (text, tabular, time series) to assess cross-domain robustness
2. Evaluate computational overhead and inference latency compared to standard conformal prediction methods
3. Validate coverage guarantees under covariate shift and domain adaptation scenarios to test real-world applicability