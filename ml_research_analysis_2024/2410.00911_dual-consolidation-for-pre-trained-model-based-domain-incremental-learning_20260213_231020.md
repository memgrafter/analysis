---
ver: rpa2
title: Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning
arxiv_id: '2410.00911'
source_url: https://arxiv.org/abs/2410.00911
tags:
- learning
- uni00000013
- classifier
- uni00000044
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DUAL CONSOLIDATION (DUCT) addresses catastrophic forgetting in
  domain-incremental learning by consolidating knowledge at both representation and
  classifier levels. The method merges backbones across different stages to create
  a unified embedding space suitable for multiple domains, while using class-wise
  semantic information to estimate and consolidate classifier weights.
---

# Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning

## Quick Facts
- arXiv ID: 2410.00911
- Source URL: https://arxiv.org/abs/2410.00911
- Authors: Da-Wei Zhou; Zi-Wen Cai; Han-Jia Ye; Lijun Zhang; De-Chuan Zhan
- Reference count: 40
- Primary result: DUCT achieves state-of-the-art performance, outperforming existing methods by 1-7% in final accuracy

## Executive Summary
DUCT addresses catastrophic forgetting in domain-incremental learning by consolidating knowledge at both representation and classifier levels. The method merges backbones across different stages to create a unified embedding space suitable for multiple domains, while using class-wise semantic information to estimate and consolidate classifier weights. Extensive experiments on four benchmark datasets (Office-Home, DomainNet, CORe50, and CDDB) demonstrate that DUCT achieves state-of-the-art performance, outperforming existing methods by 1-7% in final accuracy.

## Method Summary
DUCT employs dual consolidation to address catastrophic forgetting in domain-incremental learning with pre-trained models. The approach consolidates representation by merging backbones across stages to create a unified embedding space, then consolidates classifiers by estimating old domain weights using class-wise semantic information and merging them with historical classifiers. This coordinated consolidation process aligns both components with the consolidated embedding space, enabling incremental classification while resisting forgetting.

## Key Results
- Achieves state-of-the-art performance, outperforming existing methods by 1-7% in final accuracy
- Shows strong robustness across different task orders and pre-trained model backbones
- Particularly effective resistance to forgetting as measured by standard forgetting metrics

## Why This Works (Mechanism)

### Mechanism 1
DUCT consolidates knowledge at both representation and classifier levels to resist catastrophic forgetting in domain-incremental learning. The method merges backbones across different stages to create a unified embedding space suitable for multiple domains, while using class-wise semantic information to estimate and consolidate classifier weights.

### Mechanism 2
DUCT addresses the mismatch between consolidated embeddings and classifiers by introducing an extra classifier consolidation process. Leveraging class-wise semantic information, DUCT estimates the classifier weights of old domains within the latest embedding space, then merges historical and estimated classifiers to align them with the consolidated embedding space.

### Mechanism 3
DUCT achieves strong robustness across different task orders and pre-trained model backbones. The method's dual consolidation approach, which combines representation and classifier consolidation, provides a balanced and adaptable solution that can handle varying task orders and pre-trained model backbones.

## Foundational Learning

- Concept: Domain-Incremental Learning (DIL)
  - Why needed here: DUCT is specifically designed to address catastrophic forgetting in DIL, where models need to adapt to new domains while preserving knowledge from previous domains.
  - Quick check question: What is the main challenge that DUCT aims to solve in DIL?

- Concept: Representation and Classifier Consolidation
  - Why needed here: DUCT's dual consolidation approach involves consolidating knowledge at both the representation and classifier levels to resist catastrophic forgetting.
  - Quick check question: How does DUCT consolidate knowledge at the representation and classifier levels?

- Concept: Class-Wise Semantic Information
  - Why needed here: DUCT leverages class-wise semantic information to estimate and consolidate classifier weights, addressing the mismatch between consolidated embeddings and classifiers.
  - Quick check question: How does DUCT utilize class-wise semantic information in the classifier consolidation process?

## Architecture Onboarding

- Component map:
  Representation Consolidation -> Classifier Consolidation -> DUCT Framework

- Critical path:
  1. Merge backbones across different stages to create a unified embedding space
  2. Use class-wise semantic information to estimate classifier weights of old domains
  3. Consolidate classifier weights by merging historical and estimated classifiers
  4. Align consolidated classifiers with the unified embedding space

- Design tradeoffs:
  - Balancing representation and classifier consolidation to achieve optimal performance
  - Choosing appropriate pre-trained model backbones and task orders for robustness

- Failure signatures:
  - Inability to capture task-specific features from all seen domains
  - Failure to align classifiers with the consolidated embedding space
  - Poor performance across different task orders and pre-trained model backbones

- First 3 experiments:
  1. Test DUCT's performance on a benchmark dataset with varying task orders
  2. Evaluate DUCT's robustness to changes in pre-trained model backbones
  3. Assess DUCT's ability to resist catastrophic forgetting in DIL scenarios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DUCT's performance scale when applied to very large-scale datasets with hundreds or thousands of domains?
- Basis in paper: The paper demonstrates DUCT's effectiveness on four benchmark datasets but doesn't explore scaling to extremely large domain spaces.
- Why unresolved: The experiments only cover datasets with 4-11 domains, leaving uncertainty about performance in scenarios with much larger domain spaces.
- What evidence would resolve it: Experiments on datasets with 50+ domains or synthetic benchmarks with controllable domain numbers would clarify DUCT's scalability.

### Open Question 2
- Question: What is the impact of different pre-trained model architectures (beyond ViT variants) on DUCT's consolidation effectiveness?
- Basis in paper: The paper evaluates DUCT with ViT-B/16 using IN1K and IN21K weights, and briefly mentions ResNet101 compatibility, but doesn't systematically compare different architectural families.
- Why unresolved: The consolidation mechanism may interact differently with various architectural designs (CNNs, MLPs, hybrid models), but this relationship remains unexplored.
- What evidence would resolve it: Comprehensive benchmarking across diverse architectures like ConvNeXt, Swin Transformers, and MLP-Mixers would reveal architectural dependencies.

### Open Question 3
- Question: How does DUCT perform when the class distribution across domains is highly imbalanced or contains novel classes in later domains?
- Basis in paper: The experiments assume fixed label space across domains, but real-world scenarios often involve evolving class sets or severe class imbalance.
- Why unresolved: The classifier consolidation mechanism assumes consistent class sets, and its behavior under distribution shifts or class evolution is unknown.
- What evidence would resolve it: Experiments with synthetic class imbalance, domain-specific classes, or staged class introductions would test DUCT's robustness to label space variations.

### Open Question 4
- Question: What is the computational overhead of DUCT's dual consolidation process compared to single-stage methods during inference?
- Basis in paper: The paper states that DUCT maintains only two models during training and uses consolidated weights during inference, but doesn't provide detailed computational complexity analysis.
- Why unresolved: While memory requirements are addressed, the inference time complexity and potential bottlenecks in the consolidation steps remain unclear.
- What evidence would resolve it: Profiling studies measuring FLOPs, latency, and energy consumption during inference would quantify the practical trade-offs of DUCT's approach.

## Limitations
- Reliance on optimal transport and similarity weighting schemes whose sensitivity to hyperparameters remains unclear
- Assumes class-wise semantic information is consistently available and meaningful across domain shifts
- Requires storing historical classifier information, potentially limiting scalability for very large models or many incremental stages

## Confidence
**High Confidence** - The core claims about DUCT's effectiveness in reducing catastrophic forgetting and achieving state-of-the-art performance are well-supported by extensive experiments across four benchmark datasets.

**Medium Confidence** - Claims about robustness across different task orders and pre-trained backbones are supported but could benefit from more systematic ablation studies on the sensitivity to these variations.

**Low Confidence** - The paper's claims about scalability and computational efficiency are not thoroughly evaluated, particularly regarding memory requirements for storing historical classifiers during the consolidation process.

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary the consolidation parameters (α_ϕ, α_w) and optimal transport regularization to assess stability of DUCT's performance across different settings.

2. **Scalability Benchmark**: Evaluate DUCT's performance and memory consumption as the number of incremental stages increases, particularly for larger backbone architectures beyond ViT-B/16.

3. **Cross-Domain Transferability**: Test DUCT's effectiveness when task orders are deliberately designed to maximize domain similarity conflicts, validating claims about robustness to challenging domain shift scenarios.