---
ver: rpa2
title: Randomized Confidence Bounds for Stochastic Partial Monitoring
arxiv_id: '2402.05002'
source_url: https://arxiv.org/abs/2402.05002
tags:
- action
- confidence
- regret
- games
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new class of strategies for stochastic
  partial monitoring (PM) based on randomizing confidence bounds. The proposed RandCBP
  and RandCBPside strategies improve empirical performance while maintaining theoretical
  regret guarantees, addressing a gap where deterministic PM strategies underperform
  compared to stochastic baselines.
---

# Randomized Confidence Bounds for Stochastic Partial Monitoring

## Quick Facts
- arXiv ID: 2402.05002
- Source URL: https://arxiv.org/abs/2402.05002
- Reference count: 40
- Primary result: RandCBP reduces regret by up to 73% in cost-efficient verification of deployed classifiers

## Executive Summary
This paper introduces a novel approach to stochastic partial monitoring (PM) by randomizing confidence bounds in successive elimination strategies. The authors propose RandCBP and RandCBPside* strategies that improve empirical performance while maintaining theoretical regret guarantees. The work addresses a critical gap where deterministic PM strategies underperform compared to stochastic baselines, particularly in hard contextual games. The paper demonstrates significant performance improvements across canonical PM games and a real-world application of monitoring deployed classifier error rates.

## Method Summary
The method extends the CBP (Confidence Bound based algorithm for Partial monitoring) framework by introducing randomization into the confidence bounds. RandCBP and RandCBPside* replace deterministic elimination thresholds with stochastic ones, where confidence bounds are randomly perturbed. The randomization is controlled by parameters K (number of random bounds), σ (standard deviation), and ε (mixing parameter). For contextual settings, RandCBPside* uses side information to construct pseudo-counts based on the inverse Gram matrix, allowing for context-aware exploration. The strategies maintain the theoretical regret guarantees of their deterministic counterparts while achieving better empirical performance.

## Key Results
- RandCBP reduces regret by up to 73% compared to baselines in the τ-detection game for monitoring deployed classifiers
- Empirical performance improvements of 20-30% in canonical PM games (Apple Tasting, Label Efficient)
- First regret bounds for hard contextual PM games using RandCBPside*
- Theoretical validation showing randomized bounds have smaller expected width than deterministic counterparts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Randomizing confidence bounds in non-OFU-based strategies like CBP improves empirical performance while preserving regret guarantees.
- Mechanism: Deterministic confidence bounds create overly conservative exploration thresholds. Randomization introduces stochasticity that tightens the exploration-exploitation trade-off, allowing faster elimination of suboptimal actions.
- Core assumption: The randomized confidence bounds maintain the statistical validity of the elimination criterion while reducing the expected width of the bounds.
- Evidence anchors:
  - [abstract] "We introduce a new class of PM strategies based on the randomization of deterministic confidence bounds."
  - [section 3.2] "The width of the randomized confidence bounds of RandCBP and RandCBPside⋆ is in expectation smaller than the width of deterministic confidence bounds counterparts CBP and CBPside⋆."
  - [corpus] No direct evidence for this specific claim in related papers.
- Break condition: If the randomization introduces too much variance, causing premature elimination of potentially optimal actions.

### Mechanism 2
- Claim: The contextual setting requires adaptation of exploration mechanisms from non-contextual settings.
- Mechanism: In contextual settings, exploration should be based on pseudo-counts that reflect how often an action has been played in similar contexts, rather than absolute action counts.
- Core assumption: Contexts can be meaningfully compared using the weighted 2-norm in the inverse Gram matrix.
- Evidence anchors:
  - [section 4.1] "The quantity 1/∥x∥2 G−1 a,t is a pseudo-count of the number of selections of action a at a given context x."
  - [section 4.1] "In the specific case of orthogonal contexts sampled from the finite set of d-dimensional one-hot vectors, 1/∥x∥2 G−1 a,t corresponds to the exact number of selections of action a in context x."
  - [corpus] No direct evidence for this specific claim in related papers.
- Break condition: If contexts are too dissimilar, the pseudo-counts become meaningless.

### Mechanism 3
- Claim: The τ-detection game formulation allows monitoring of deployed classifiers in a cost-efficient manner.
- Mechanism: By framing classifier error rate monitoring as a partial monitoring game, the agent can adaptively decide when to verify predictions based on the observed error rates and a tolerance threshold.
- Core assumption: The error rates of different classes are independent and can be estimated separately.
- Evidence anchors:
  - [section 6] "We design a PM game, that we name the τ-detection game, to estimate the outcome distribution over multiple rounds for a predicted class c."
  - [section 6] "The loss matrix is designed such that the optimal action is to pass when pc < τ and to verify when pc ≥ τ."
  - [corpus] No direct evidence for this specific claim in related papers.
- Break condition: If error rates are correlated across classes, the independent estimation assumption breaks.

## Foundational Learning

- Concept: Partial monitoring framework and its classification into easy, hard, and intractable games.
  - Why needed here: Understanding the game classification is crucial for choosing appropriate strategies and understanding their regret guarantees.
  - Quick check question: What distinguishes an easy game from a hard game in partial monitoring?

- Concept: Successive elimination strategies and their confidence bound mechanisms.
  - Why needed here: CBP-based strategies rely on successive elimination, and understanding this mechanism is key to understanding how randomization improves performance.
  - Quick check question: How does the successive elimination criterion work in CBP?

- Concept: Contextual partial monitoring and the role of side information.
  - Why needed here: The paper extends CBP to contextual settings, requiring understanding of how side information affects the problem structure.
  - Quick check question: How does the optimal action depend on the context in contextual partial monitoring?

## Architecture Onboarding

- Component map: Game environments (Apple Tasting, Label Efficient, τ-detection) -> Strategies (CBP, RandCBP, CBPside⋆, RandCBPside⋆) -> Evaluation metrics (regret, win-count, f1-score)
- Critical path: Strategy selection → Action execution → Feedback observation → Confidence bound update → Action selection
- Design tradeoffs: Deterministic vs. randomized confidence bounds (exploration-exploitation trade-off), contextual vs. non-contextual settings (complexity vs. applicability)
- Failure signatures: Premature elimination of optimal actions (overly aggressive randomization), failure to identify optimal actions (insufficient exploration), computational inefficiency (poor implementation of inverse Gram matrix updates)
- First 3 experiments:
  1. Implement and test RandCBP on the Apple Tasting game with varying randomization parameters (K, σ, ε)
  2. Implement and test RandCBPside⋆ on the Label Efficient game with linear contexts
  3. Implement the τ-detection game and evaluate C-RandCBP on simulated classifier error rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do randomized confidence bounds perform in partial monitoring games with continuous action and feedback spaces?
- Basis in paper: [inferred] The paper mentions that randomization offers interesting perspectives for online learning strategies relying on statistical deviation bounds that are overly conservative in practice, particularly for bounds in logistic and neural settings.
- Why unresolved: The authors only tested randomization in finite action and feedback spaces, leaving the continuous case unexplored.
- What evidence would resolve it: Empirical comparisons of RandCBP/RandCBPside* with continuous-action PM strategies like Kirschner et al. (2020) on benchmark problems.

### Open Question 2
- Question: What are the lower bounds for contextual partial monitoring games with stochastic outcomes?
- Basis in paper: [inferred] The authors state that obtaining lower bounds in the contextual setting is a possible future research direction.
- Why unresolved: The paper only provides upper bounds for RandCBPside* in both easy and hard contextual games.
- What evidence would resolve it: A formal proof establishing the minimax regret lower bounds for contextual PM games, possibly building on techniques from adversarial PM settings.

### Open Question 3
- Question: How sensitive are the empirical performance gains of RandCBP and RandCBPside* to the choice of randomization hyper-parameters (ε, σ, K)?
- Basis in paper: [explicit] The authors acknowledge that hyper-parameter tuning is not easily achievable in online learning and provide some sensitivity analysis in Appendix E.3.
- Why unresolved: The sensitivity analysis in the paper is limited to a few values and specific games, not providing a comprehensive understanding of the hyper-parameter space.
- What evidence would resolve it: A systematic study varying all three hyper-parameters across multiple PM games, identifying optimal ranges and potential trade-offs.

## Limitations

- Limited evaluation scope: The RandCBPside⋆ extension is only evaluated on the Label Efficient game, leaving its performance in other contextual settings unexplored.
- Hyper-parameter sensitivity: The paper acknowledges that the randomization parameters (K, σ, ε) require tuning, which is challenging in online learning settings without a validation set.
- Scalability concerns: The computational overhead of maintaining inverse Gram matrices for high-dimensional contexts is not fully characterized.

## Confidence

High confidence: The core claim that randomization improves confidence-bound strategies has High confidence given the theoretical derivation showing reduced expected bound width and the empirical results demonstrating consistent performance gains across multiple games.

Medium confidence: The extension to contextual settings with RandCBPside⋆ has Medium confidence due to the limited evaluation scope and the reliance on the pseudo-count interpretation of context similarity.

## Next Checks

1. **Scalability Analysis**: Evaluate RandCBPside⋆ on synthetic contextual PM games with increasing numbers of actions and contexts to quantify computational overhead and identify breaking points in the inverse Gram matrix updates.

2. **Robustness Testing**: Systematically vary the randomization parameters (K, σ, ε) in RandCBP across different game types to determine optimal parameter regimes and identify conditions where randomization provides minimal benefit.

3. **Theoretical Gap Analysis**: Rigorously verify that the randomization mechanism preserves the concentration inequalities required for the regret bounds, particularly focusing on the impact of variance introduced by the random perturbations.