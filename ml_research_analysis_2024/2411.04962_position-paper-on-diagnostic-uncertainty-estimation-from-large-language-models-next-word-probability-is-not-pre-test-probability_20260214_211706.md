---
ver: rpa2
title: 'Position Paper On Diagnostic Uncertainty Estimation from Large Language Models:
  Next-Word Probability Is Not Pre-test Probability'
arxiv_id: '2411.04962'
source_url: https://arxiv.org/abs/2411.04962
tags:
- llms
- probability
- diagnostic
- methods
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates the ability of large language models (LLMs)
  to estimate pre-test diagnostic probabilities, a critical component of clinical
  decision-making. Three methods for extracting uncertainty estimates from LLMs were
  evaluated: token logits, verbalized confidence, and feature-based calibrators.'
---

# Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability

## Quick Facts
- arXiv ID: 2411.04962
- Source URL: https://arxiv.org/abs/2411.04962
- Authors: Yanjun Gao; Skatje Myers; Shan Chen; Dmitriy Dligach; Timothy A Miller; Danielle Bitterman; Guanhua Chen; Anoop Mayampurath; Matthew Churpek; Majid Afshar
- Reference count: 4
- Key outcome: Feature-based calibrators can achieve performance comparable to traditional ML models for structured EHR tasks

## Executive Summary
This study evaluates three methods for extracting diagnostic uncertainty estimates from large language models (LLMs): token logits, verbalized confidence, and feature-based calibrators. The research focuses on structured electronic health record data for sepsis, arrhythmia, and congestive heart failure diagnosis using Mistral-7B and Llama3-70B models. Results demonstrate that feature-based calibrators perform comparably to state-of-the-art XGB classifiers, while token logits and verbalized confidence methods show poor performance and unreliable calibration, particularly for low-prevalence conditions.

## Method Summary
The study employs a controlled experimental design using structured EHR data from approximately 4,000 patients per diagnosis task. Three uncertainty estimation methods were systematically evaluated: token logits extraction, verbalized confidence scoring, and feature-based calibrators using clinical variables. The LLMs (Mistral-7B and Llama3-70B) were prompted with patient information and asked to predict diagnosis while providing uncertainty estimates. Performance was measured using AUROC, calibration metrics (Brier score, ECE), and comparison against XGB classifiers. The experimental setup includes systematic comparison across different pre-test probability ranges and diagnosis tasks with varying prevalence rates.

## Key Results
- Feature-based calibrators achieved AUROC comparable to XGB classifiers (0.80-0.91 range) for all three diagnoses
- Token logits and verbalized confidence methods demonstrated poor calibration, particularly for low-prevalence conditions
- Verbalized confidence showed inconsistent reliability across different pre-test probability ranges
- Calibration errors were most pronounced in arrhythmia prediction (prevalence ~5%)

## Why This Works (Mechanism)
The study demonstrates that LLMs can integrate clinical features effectively when using appropriate calibration frameworks, but struggle with direct uncertainty quantification through next-word probabilities or verbalized responses. The mechanism behind feature-based calibrators' success lies in their ability to leverage LLMs' contextual understanding while maintaining statistical rigor through external calibration models.

## Foundational Learning
1. Pre-test probability concepts - Why needed: Fundamental to clinical decision-making; Quick check: Understanding Bayes' theorem application
2. Calibration metrics (Brier score, ECE) - Why needed: Essential for evaluating uncertainty estimation quality; Quick check: Can compute and interpret these metrics
3. LLM uncertainty quantification methods - Why needed: Critical for safe clinical deployment; Quick check: Understanding differences between token-level and aggregate uncertainty
4. EHR data structure and clinical features - Why needed: Context for model inputs; Quick check: Familiarity with MIMIC-III data schema
5. Statistical comparison methods - Why needed: To evaluate model performance rigorously; Quick check: Understanding of confidence intervals and hypothesis testing

## Architecture Onboarding

**Component Map:**
Mistral-7B/Llama3-70B -> Prompt Processor -> Uncertainty Estimator -> Calibration Model -> Performance Metrics

**Critical Path:**
Patient features → LLM inference → Uncertainty extraction method → Calibration → AUROC/Brier score calculation

**Design Tradeoffs:**
- Structured vs. unstructured input data
- Direct uncertainty extraction vs. post-hoc calibration
- Model size vs. computational efficiency
- Binary vs. multi-class classification

**Failure Signatures:**
- Poor calibration in low-prevalence conditions
- Inconsistent verbalized confidence responses
- Overconfidence in high-stakes predictions
- Distribution shift across different patient populations

**3 First Experiments:**
1. Replicate AUROC comparison between feature-based calibrators and XGB classifiers
2. Test calibration performance across different pre-test probability ranges
3. Evaluate verbalized confidence reliability using standardized scoring

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to three specific diagnoses in structured EHR format
- Small sample size (N=4,000 per task) may not capture clinical complexity
- Binary classification framing oversimplifies diagnostic uncertainty
- Ad hoc verbalized confidence scoring lacks standardization

## Confidence

**High Confidence:**
- Feature-based calibrators can achieve performance comparable to traditional ML models for structured EHR tasks

**Medium Confidence:**
- Next-word probability is not a reliable estimator of pre-test probability for clinical diagnosis
- LLMs show inconsistent calibration across different pre-test probability ranges

**Low Confidence:**
- Generalizability of findings to open-ended clinical scenarios and other medical domains

## Next Checks
1. Evaluate uncertainty estimation methods on multi-class diagnostic tasks and longitudinal patient trajectories to assess temporal reasoning capabilities
2. Test verbalized confidence scoring using standardized clinical communication frameworks and physician-annotated confidence levels
3. Validate findings on external datasets with different prevalence rates and demographic distributions to assess bias and robustness