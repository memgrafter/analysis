---
ver: rpa2
title: Ensemble Watermarks for Large Language Models
arxiv_id: '2411.19563'
source_url: https://arxiv.org/abs/2411.19563
tags:
- features
- watermark
- detection
- text
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an ensemble watermark approach for large
  language models (LLMs) that combines multiple distinct watermark features to improve
  resilience against attacks like paraphrasing. The method integrates acrostics, sensorimotor
  norms, and the established red-green watermark by manipulating token logits during
  generation, controlled via a secret key derived from the text.
---

# Ensemble Watermarks for Large Language Models

## Quick Facts
- arXiv ID: 2411.19563
- Source URL: https://arxiv.org/abs/2411.19563
- Authors: Georg Niess; Roman Kern
- Reference count: 14
- Key outcome: Ensemble watermark approach combining acrostics, sensorimotor norms, and red-green watermark achieves 98% detection rate under normal conditions and 95% after paraphrasing attack, outperforming single-feature methods

## Executive Summary
This paper introduces an ensemble watermark approach for large language models (LLMs) that combines multiple distinct watermark features to improve resilience against attacks like paraphrasing. The method integrates acrostics, sensorimotor norms, and the established red-green watermark by manipulating token logits during generation, controlled via a secret key derived from the text. Detection uses statistical tests to identify the embedded features.

Experiments on three LLMs (Llama 3.1 8B, Llama 3.2 3B, Mistral 7B) show the ensemble achieves a 98% detection rate under normal conditions and maintains 95% after a paraphrasing attack. In contrast, the red-green feature alone drops to 49% detection post-attack. The approach offers flexibility in feature combinations, uses the same detection function across configurations, and balances watermark strength with minimal impact on text perplexity.

## Method Summary
The ensemble watermark approach manipulates LLM logits during text generation to embed multiple watermark features: acrostics (first letters spelling words), sensorimotor norms (word associations from human sensorimotor experiences), and the red-green watermark (pre-defined token lists). A secret key derived from the text controls which features are embedded and detected. During generation, token logits are boosted for words matching the target watermark features. Detection uses statistical hypothesis testing with Z-scores and p-values to identify embedded patterns. The method is implemented as a logits processor that can be applied to any LLM without modifying model weights.

## Key Results
- Ensemble watermark achieves 98% detection rate under normal conditions versus 49% for red-green feature alone
- After paraphrasing attack, ensemble maintains 95% detection rate while red-green drops to 49%
- Minimal impact on text perplexity (less than 5% increase) across all tested configurations
- All three feature combinations (acrostic+sensorimotor+red-green, various pairs) outperform single-feature baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Logits manipulation enables fine-grained control over token selection to embed watermark features without changing model weights.
- Mechanism: During generation, token logits are boosted for words that match the target watermark feature (acrostic, sensorimotor, or green list). The LLM samples from the adjusted logits, producing text that statistically reflects the embedded pattern.
- Core assumption: Logits adjustments are small enough not to cause large changes in overall text perplexity, preserving fluency.
- Evidence anchors:
  - [abstract] Mentions combining acrostics, sensorimotor norms, and red-green watermark by manipulating token logits during generation.
  - [section] Details how logits[t] += δacro · 1{starts_with_acrostic_letter} and similar boosts for sensorimotor and red-green features.
  - [corpus] Weak evidence: No direct mention of logits manipulation in neighbors, but watermarking approaches in general often rely on logit modification.
- Break condition: If δ values are too large, perplexity spikes and text becomes unnatural; if too small, watermark detection fails.

### Mechanism 2
- Claim: Dynamic secret keys derived from text allow each feature to be controlled consistently across generation and detection.
- Mechanism: A secret key (e.g., sensorimotor class, acrostic letter) is generated by hashing previous tokens/sentences. This key drives which logits to boost during generation and which tokens to check during detection, ensuring feature consistency.
- Core assumption: Hashing yields stable, repeatable keys for both generation and detection phases.
- Evidence anchors:
  - [abstract] Notes a secret key derived from the text controls watermark features.
  - [section] Shows hash functions applied to words and sentences to update keys during generation.
  - [corpus] Weak evidence: Not explicitly covered in neighbors, but key-based control is standard in watermarking literature.
- Break condition: If tokenization differs between generation and detection, the hash sequence will diverge and detection will fail.

### Mechanism 3
- Claim: Combining multiple independent watermark features increases resilience against paraphrasing attacks.
- Mechanism: Each feature has its own detection probability. By multiplying them, the final score is more robust because an attacker must simultaneously evade all feature detectors.
- Core assumption: Features are statistically independent and their detection probabilities multiply.
- Evidence anchors:
  - [abstract] Reports 98% detection rate under normal conditions, 95% after paraphrasing attack, versus 49% for red-green alone.
  - [section] Describes final_score = Pacrostic × Psensorimotor × Predgreen, assuming independence.
  - [corpus] Weak evidence: Neighbors discuss robustness but not multi-feature ensembles.
- Break condition: If features are highly correlated, independence assumption fails and detection probability gain is overstated.

## Foundational Learning

- Concept: Large language model logits and softmax
  - Why needed here: Watermarking relies on logit manipulation; understanding logits is essential to implement and debug the method.
  - Quick check question: What happens to the output distribution if you add a constant to all logits versus adding to a single token's logit?

- Concept: Statistical hypothesis testing and p-values
  - Why needed here: Detection uses Z-scores and p-value thresholds (α = 0.05) to decide if watermark is present.
  - Quick check question: If Z = 2.0, what is the one-tailed p-value for detecting the watermark?

- Concept: Hash functions and key generation
  - Why needed here: Secret keys must be reproducible for both generation and detection phases.
  - Quick check question: If you hash the same sentence twice, will you get the same key? What about if tokenization differs?

## Architecture Onboarding

- Component map: Logits processor → Feature boosters (acrostic, sensorimotor, red-green) → Token sampler → Text output; Detection pipeline mirrors this with token checks → Probability aggregation → Final score
- Critical path: During generation: logits ← adjust for features ← sample token; During detection: check tokens ← compute probabilities ← aggregate score
- Design tradeoffs: Larger δ boosts detection but increases perplexity; more features increase robustness but add computational overhead; independent features ease detection logic but may not be truly independent
- Failure signatures: Detection fails if tokenization mismatches; perplexity spikes if δ too high; low detection if features are weakly embedded
- First 3 experiments:
  1. Test single feature detection (red-green only) with varying δ to find sweet spot between detection rate and perplexity
  2. Verify key generation consistency by running generation and detection on same text with identical tokenization
  3. Compare detection rates with and without paraphrasing attack to confirm resilience improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the ensemble watermark's performance scale with text length beyond the single-sentence case?
- Basis in paper: [explicit] The paper mentions an ablation study on text length, but focuses on incremental sentence partitioning starting from single sentences.
- Why unresolved: The study only goes up to full texts, not exploring performance for very long documents (e.g., paragraphs or pages).
- What evidence would resolve it: Additional experiments testing watermark detection rates and perplexity impact on texts with hundreds of sentences or multiple pages.

### Open Question 2
- Question: What is the impact of combining the ensemble watermark with other watermarking strategies, such as sampling schemes or model fine-tuning?
- Basis in paper: [inferred] The paper mentions ongoing research by Zhu et al. [2024] combining red-green watermarking with sampling schemes, but does not explore this for the ensemble approach.
- Why unresolved: The ensemble approach's flexibility suggests potential for integration with other techniques, but this is not investigated.
- What evidence would resolve it: Experiments combining the ensemble watermark with different sampling strategies or fine-tuning approaches, comparing detection rates and robustness to attacks.

### Open Question 3
- Question: How resilient is the ensemble watermark to more sophisticated paraphrasing attacks that preserve the original meaning while significantly altering the text structure?
- Basis in paper: [explicit] The paper tests resilience to paraphrasing attacks that change at least 10% of the text, but does not explore more advanced attacks.
- Why unresolved: The current attack method is relatively simple, and more sophisticated techniques might be able to evade detection more effectively.
- What evidence would resolve it: Experiments using advanced paraphrasing tools or techniques that focus on semantic preservation while altering sentence structure and word choice.

## Limitations
- Experimental evaluation limited to three small open-weight models and single paraphrasing attack strategy
- Independence assumption for feature aggregation not empirically validated
- Computational overhead of manipulating logits for three features simultaneously not quantified
- Impact on inference latency remains unclear

## Confidence
- High confidence: The core mechanism of logit manipulation for embedding watermark features is well-established in the watermarking literature and directly supported by the experimental results showing improved detection rates over single-feature baselines
- Medium confidence: The resilience claim (95% detection after paraphrasing) is supported by experiments but limited to one attack type; generalization to other attacks remains uncertain
- Medium confidence: The independence assumption for feature aggregation is stated but not validated; detection performance may be overstated if features are correlated
- Low confidence: The scalability of the approach to larger models and its robustness against a broader range of attacks is not demonstrated

## Next Checks
1. Validate independence assumption: Generate a large corpus of watermarked text and compute pairwise correlations between feature detection scores to empirically test the independence assumption underlying the multiplicative aggregation

2. Test against broader attack suite: Apply the ensemble watermark to text and subject it to multiple attack types (synonym replacement, grammatical restructuring, adversarial paraphrasing) to assess robustness beyond the single T5-based paraphrasing attack

3. Scale to larger models and measure overhead: Implement the watermarking method on a larger model (e.g., Llama 3.1 70B) and quantify the impact on inference latency and computational cost, comparing against the 8B/3B/7B models used in the paper