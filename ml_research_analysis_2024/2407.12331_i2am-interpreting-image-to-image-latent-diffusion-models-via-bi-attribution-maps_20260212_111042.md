---
ver: rpa2
title: 'I2AM: Interpreting Image-to-Image Latent Diffusion Models via Bi-Attribution
  Maps'
arxiv_id: '2407.12331'
source_url: https://arxiv.org/abs/2407.12331
tags:
- image
- attention
- reference
- attribution
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces I2AM, a method for interpreting image-to-image
  diffusion models via bi-attribution maps. I2AM visualizes bidirectional attribution
  maps showing how reference images influence generated outputs and vice versa, aggregating
  cross-attention scores across time steps, attention heads, and layers.
---

# I2AM: Interpreting Image-to-Image Latent Diffusion Models via Bi-Attribution Maps

## Quick Facts
- **arXiv ID**: 2407.12331
- **Source URL**: https://arxiv.org/abs/2407.12331
- **Reference count**: 36
- **Key outcome**: Introduces I2AM method for interpreting I2I diffusion models via bidirectional attribution maps, achieving mIoU 0.2416 on unseen PBE-generated images for object detection

## Executive Summary
This paper introduces I2AM, a novel method for interpreting image-to-image diffusion models through bidirectional attribution maps. The approach visualizes how reference images influence generated outputs and vice versa by aggregating cross-attention scores across time steps, attention heads, and layers. I2AM provides insights into information transfer mechanisms in tasks like object detection, inpainting, and super-resolution. The authors also introduce IMACS, a novel evaluation metric that measures alignment between attribution maps and inpainting masks, correlating with downstream performance. Experiments demonstrate I2AM's effectiveness in identifying key regions responsible for generation, even in complex scenes, and its utility for model debugging and refinement.

## Method Summary
I2AM interprets I2I diffusion models by computing cross-attention scores between reference and generated image patches across all layers and time steps. These scores are aggregated to create unified attribution maps showing how reference regions influence generation (R2G) and how generated regions relate to reference (G2R). The method includes four aggregation levels (ULAM, TLAM, HLAM, LLAM) and introduces Specific-Reference Attribution Maps (SRAM) for detailed patch-level analysis. A novel Inpainting Mask Attention Consistency Score (IMACS) evaluates attribution map quality by measuring alignment with ground truth masks. The approach enables visualization of information flow and identification of critical regions affecting generation quality.

## Key Results
- I2AM achieves mIoU 0.2416 on unseen PBE-generated images for object detection task
- Attribution maps successfully identify key regions responsible for generation in complex scenes
- IMACS metric correlates strongly with existing performance metrics for inpainting tasks
- Visualization reveals both forward transfer (reference to generated) and reverse mapping (generated to reference) patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-attention scores aggregated across time steps, heads, and layers can reveal which regions of the reference image influence the generated image and vice versa.
- Mechanism: The diffusion model uses cross-attention at each layer to connect reference and generated patches. By summing attention scores across t, n, and l, I2AM creates a unified attribution map showing the overall influence of each reference patch on the generated image. This works because cross-attention captures semantic relationships between image regions, and aggregation reveals persistent patterns.
- Core assumption: Cross-attention scores meaningfully represent feature transfer between reference and generated images across all layers and time steps.
- Evidence anchors:
  - [abstract]: "I2AM aggregates cross-attention scores across time steps, attention heads, and layers, offering insights into how critical features are transferred between images."
  - [section]: "Cross-attention maps using I2AM. The top map shows how the generated image is influenced by the reference image (Q1), while the bottom map illustrates how the reference image contributes to the generated image (Q2)."
  - [corpus]: Weak. Corpus papers focus on general I2I translation but don't specifically address cross-attention interpretability.

### Mechanism 2
- Claim: The bidirectional attribution maps (R2G and G2R) provide complementary perspectives that together offer a complete picture of information flow.
- Mechanism: R2G maps show how the reference image influences the generated image (query=key=reference), while G2R maps show how the generated image relates back to the reference (query=key=generated). This bidirectional analysis captures both the forward transfer of information and the reverse mapping, revealing potential asymmetries in the model's understanding.
- Core assumption: The model's cross-attention mechanism is symmetric enough that both directions provide meaningful, complementary information about the generation process.
- Evidence anchors:
  - [abstract]: "visualizing bidirectional attribution maps, from the reference image to the generated image and vice versa"
  - [section]: "This dual approach enhances our ability to interpret the intricate behavior of I2I diffusion models in various tasks, highlighting the key contributions from each perspective."
  - [corpus]: Missing. Corpus doesn't contain papers specifically discussing bidirectional attribution in diffusion models.

### Mechanism 3
- Claim: The Inpainting Mask Attention Consistency Score (IMACS) correlates with downstream task performance because it measures alignment between attention maps and ground truth masks.
- Mechanism: IMACS calculates how well the attention map overlaps with the inpainting mask, penalizing attention that falls outside mask regions. Higher IMACS indicates better alignment between where the model focuses and where the ground truth indicates important regions, which correlates with better generation quality.
- Core assumption: Attention map alignment with ground truth masks is a valid proxy for generation quality and task performance.
- Evidence anchors:
  - [abstract]: "we introduce the Inpainting Mask Attention Consistency Score (IMACS) as a novel evaluation metric to assess the alignment between attribution maps and inpainting masks, which correlates strongly with existing performance metrics."
  - [section]: "IMACS g/r indicate better alignment between the attention maps and the corresponding masks, and thus, superior performance as an XAI metric."
  - [corpus]: Weak. Corpus papers focus on I2I translation but don't discuss IMACS or mask-attention alignment metrics.

## Foundational Learning

- Concept: Cross-attention in transformers
  - Why needed here: I2AM directly manipulates and aggregates cross-attention scores to create attribution maps. Understanding how queries, keys, and values interact in cross-attention is essential for interpreting the results.
  - Quick check question: What is the difference between self-attention and cross-attention, and how does the query-key relationship differ between them?

- Concept: Diffusion model sampling process
  - Why needed here: I2AM operates across time steps in the diffusion process. Understanding how noise is progressively removed and how conditioning affects this process is crucial for interpreting temporal patterns in attribution maps.
  - Quick check question: How does classifier-free guidance modify the denoising process, and what effect might this have on attention patterns?

- Concept: Image patch embedding and attention maps
  - Why needed here: The attribution maps are computed at the patch level. Understanding how images are divided into patches, embedded, and how attention maps are structured (HW x HW) is necessary for interpreting the spatial relationships.
  - Quick check question: How does the size of image patches affect the resolution and interpretability of attention maps?

## Architecture Onboarding

- Component map: Image Encoder -> U-Net -> Cross-attention module -> Aggregation functions -> Thresholding -> IMACS computation

- Critical path: Image → Patch Embeddings → Cross-Attention (across layers/time) → Attribution Maps → Aggregation → Visualization/IMACS

- Design tradeoffs:
  - Aggregation vs. granularity: Aggregating across all axes gives a unified view but loses temporal/head-specific patterns
  - Threshold selection: Higher thresholds reduce noise but may miss subtle influences
  - Patch size: Larger patches reduce resolution but may capture broader semantic relationships
  - Computational cost: Computing attention for all patches is expensive but provides detailed attribution

- Failure signatures:
  - Uniform attention maps: May indicate the model isn't using the reference image meaningfully
  - Attention concentrated outside masks: Suggests the model focuses on irrelevant regions
  - Temporal inconsistency: Attention patterns that don't make sense across time steps
  - Mismatch between R2G and G2R: May indicate asymmetric or incomplete understanding

- First 3 experiments:
  1. Run I2AM on a simple inpainting task with a single object and clear mask to verify basic functionality
  2. Compare IMACS scores with qualitative inpainting quality to validate the metric
  3. Visualize TLAM, HLAM, and LLAM separately to understand the contribution of each axis before aggregation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does I2AM's bi-attribution mapping approach generalize to other image-to-image tasks beyond the three studied (object detection, inpainting, and super-resolution)?
- Basis in paper: [explicit] The authors note that I2AM was "primarily tested in paired settings with reference-based tasks" and suggest future work aims to extend it to "broader applications, such as colorization and style transfer"
- Why unresolved: The paper only demonstrates I2AM on three specific tasks. The method's effectiveness for tasks with different characteristics (e.g., style transfer where content preservation is less critical) remains unexplored.
- What evidence would resolve it: Experiments applying I2AM to additional image-to-image tasks like colorization, style transfer, and depth estimation, comparing attribution map quality and downstream task performance across these domains.

### Open Question 2
- Question: What is the optimal aggregation strategy across time steps, attention heads, and layers for different image-to-image tasks?
- Basis in paper: [inferred] The authors mention that "it is also possible to calculate the map by considering two axes simultaneously, rather than just one" and show some layer-resolution combined visualizations, but don't systematically explore this
- Why unresolved: The paper uses simple summation across all axes for ULAM but acknowledges other aggregation possibilities. The impact of different aggregation strategies on attribution map quality and task performance is unexplored.
- What evidence would resolve it: Systematic comparison of different aggregation strategies (weighted sums, learned combinations, attention-based pooling) across multiple tasks, measuring attribution map quality and downstream performance.

### Open Question 3
- Question: How does the choice of image encoder architecture (multi-scale vs single embedding) affect I2AM's interpretability and effectiveness?
- Basis in paper: [explicit] The authors note that models like StableVITON use "all patch embeddings from the reference image, allowing for bidirectional visualization" while others like PBE use "only the CLS token"
- Why unresolved: The paper demonstrates I2AM works with both architectures but doesn't analyze how the encoder choice impacts attribution quality, computational efficiency, or downstream task performance.
- What evidence would resolve it: Comparative study of I2AM performance using different image encoder architectures across multiple tasks, measuring attribution map quality, computational overhead, and task-specific metrics.

## Limitations
- The IMACS metric was primarily validated on inpainting tasks and may not generalize well to other I2I applications
- Computational cost of computing cross-attention scores for all patch pairs may limit scalability to high-resolution images
- Method relies on pre-trained diffusion models and cannot address potential biases or limitations in underlying architectures

## Confidence
- Medium confidence: Bidirectional attribution mechanism
- Low confidence: IMACS metric generalizability
- Medium confidence: Visual interpretability claims

## Next Checks
1. Cross-task IMACS validation: Test IMACS correlation with performance metrics across object detection and super-resolution tasks, not just inpainting, to assess metric generalizability.

2. Ablation of aggregation dimensions: Systematically disable aggregation across time steps, attention heads, or layers to quantify each dimension's contribution to attribution map quality and downstream task performance.

3. Baseline comparison on synthetic data: Create controlled synthetic I2I scenarios with known ground truth attention patterns to quantitatively compare I2AM against alternative attribution methods.