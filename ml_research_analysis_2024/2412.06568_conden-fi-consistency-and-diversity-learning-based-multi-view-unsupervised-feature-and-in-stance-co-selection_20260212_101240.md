---
ver: rpa2
title: 'CONDEN-FI: Consistency and Diversity Learning-based Multi-View Unsupervised
  Feature and In-stance Co-Selection'
arxiv_id: '2412.06568'
source_url: https://arxiv.org/abs/2412.06568
tags:
- selection
- feature
- data
- instance
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CONDEN-FI, a method for multi-view unsupervised
  feature and instance co-selection. It addresses the problem of simultaneously selecting
  informative features and representative instances from multi-view unlabeled data.
---

# CONDEN-FI: Consistency and Diversity Learning-based Multi-View Unsupervised Feature and In-stance Co-Selection

## Quick Facts
- arXiv ID: 2412.06568
- Source URL: https://arxiv.org/abs/2412.06568
- Reference count: 40
- Primary result: Achieves over 10% improvement in classification accuracy and F1 score on YaleB dataset compared to second-best method

## Executive Summary
CONDEN-FI addresses the challenge of simultaneous feature and instance selection in multi-view unlabeled data by learning inter-view consistent and view-specific representations. The method reconstructs original data while adaptively learning a view-consensus similarity graph to select diverse instances. Evaluated on eight real-world datasets, CONDEN-FI demonstrates state-of-the-art performance, significantly outperforming existing methods in both classification accuracy and F1 score metrics.

## Method Summary
The proposed method learns inter-view consistent and view-specific representations to reconstruct original multi-view data. It incorporates a view-consensus similarity graph that adaptively learns relationships between instances across different views. This graph enables the simultaneous selection of informative features and representative instances while maintaining diversity. The approach is designed for unsupervised settings where no labeled data is available, making it particularly useful for exploratory data analysis and preprocessing for downstream tasks.

## Key Results
- Achieves over 10% improvement in classification accuracy on YaleB dataset compared to second-best method
- Shows significant improvements in F1 score across all eight real-world datasets
- Demonstrates superior performance compared to state-of-the-art multi-view unsupervised feature and instance selection methods

## Why This Works (Mechanism)
The method's effectiveness stems from simultaneously learning consistent representations across views while preserving view-specific characteristics. By reconstructing the original data through these representations, the approach captures both shared and unique information across views. The adaptive view-consensus similarity graph enables selection of diverse instances by identifying representatives that span the data distribution effectively.

## Foundational Learning
1. **Multi-view data representation learning** - Why needed: To capture both shared and unique information across different views of the same data; Quick check: Verify that learned representations can reconstruct original data with minimal error
2. **Unsupervised feature selection** - Why needed: To identify informative features without labeled data; Quick check: Confirm selected features maintain or improve downstream task performance
3. **Instance selection in unsupervised settings** - Why needed: To identify representative samples when no labels are available; Quick check: Validate that selected instances span the data distribution effectively
4. **Consistency learning across views** - Why needed: To ensure complementary information is captured across different data representations; Quick check: Measure similarity of representations across views
5. **Diversity preservation** - Why needed: To avoid selecting redundant or similar instances; Quick check: Verify selected instances are well-distributed across feature space
6. **Graph-based similarity learning** - Why needed: To model relationships between instances across views; Quick check: Validate that learned graph captures meaningful instance relationships

## Architecture Onboarding

Component map: Data inputs -> Multi-view representation learning -> Consistency and diversity learning -> View-consensus similarity graph -> Feature and instance selection

Critical path: The method learns representations through consistency and diversity learning, which are then used to construct the view-consensus similarity graph. This graph directly enables both feature and instance selection, making the representation learning and graph construction the critical components.

Design tradeoffs: The approach balances between learning consistent representations across views (which captures shared information) and maintaining view-specific characteristics (which preserves unique information). This tradeoff is crucial for effective reconstruction and selection.

Failure signatures: Poor reconstruction quality indicates issues with representation learning; lack of diversity in selected instances suggests problems with the similarity graph; degradation in downstream task performance points to suboptimal feature selection.

First experiments:
1. Verify reconstruction quality on held-out data to ensure learned representations capture essential information
2. Test feature selection quality by evaluating downstream task performance with selected features
3. Assess instance selection diversity by measuring coverage of data distribution and redundancy among selected instances

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity analysis is incomplete, particularly for the multiple learning components involved
- Lack of ablation studies to quantify individual component contributions to overall performance
- Limited testing on complex, high-dimensional real-world data beyond face and digit datasets

## Confidence

| Claim | Confidence |
|-------|------------|
| Performance claims on benchmark datasets | High |
| Theoretical framework validity | Medium |
| Scalability and computational efficiency | Low |
| Generalization to complex real-world scenarios | Medium |

## Next Checks

1. Conduct computational complexity analysis and runtime comparison with baseline methods on large-scale datasets
2. Perform ablation studies to quantify the contribution of each component (consistency learning, diversity learning, consensus graph) to overall performance
3. Test the method on high-dimensional, noisy real-world datasets from domains beyond faces and digits (e.g., medical imaging or text data) to evaluate robustness and generalization capability