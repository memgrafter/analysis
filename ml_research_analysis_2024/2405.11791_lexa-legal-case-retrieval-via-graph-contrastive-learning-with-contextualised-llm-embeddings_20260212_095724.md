---
ver: rpa2
title: 'LEXA: Legal Case Retrieval via Graph Contrastive Learning with Contextualised
  LLM Embeddings'
arxiv_id: '2405.11791'
source_url: https://arxiv.org/abs/2405.11791
tags:
- legal
- graph
- case
- retrieval
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of legal case retrieval by proposing
  LEXA, an enhanced framework that extends CaseGNN to fully utilize structural information
  in text-attributed case graphs. LEXA introduces three key improvements: (1) an edge-updated
  graph attention layer (EUGAT) for jointly refining node and edge features, (2) an
  enhanced graph contrastive learning objective for stronger supervision, and (3)
  LLM-based contextualised embeddings to enrich graph representations.'
---

# LEXA: Legal Case Retrieval via Graph Contrastive Learning with Contextualised LLM Embeddings

## Quick Facts
- arXiv ID: 2405.11791
- Source URL: https://arxiv.org/abs/2405.11791
- Reference count: 40
- Improves legal case retrieval performance by 5.3-8.8% NDCG@5 over CaseGNN baseline

## Executive Summary
LEXA is a novel legal case retrieval framework that addresses limitations in existing graph-based methods by fully utilizing structural information in text-attributed case graphs. The framework extends CaseGNN with three key innovations: an edge-updated graph attention layer for joint feature refinement, enhanced graph contrastive learning for stronger supervision, and LLM-based contextualised embeddings for richer graph representations. Extensive experiments on COLIEE 2022 and 2023 datasets demonstrate consistent state-of-the-art performance across multiple evaluation metrics.

## Method Summary
LEXA addresses the problem of legal case retrieval by enhancing the CaseGNN framework to better utilize structural information in text-attributed case graphs. The method introduces three key improvements: an edge-updated graph attention layer (EUGAT) that jointly refines node and edge features, an enhanced graph contrastive learning objective that provides stronger supervision, and LLM-based contextualised embeddings that enrich graph representations. The framework processes legal case documents as nodes in a citation graph, where edges represent citations between cases, and combines structural information with semantic representations derived from large language models to improve retrieval accuracy.

## Key Results
- LEXA improves over CaseGNN by 5.3-8.8% in NDCG@5 on COLIEE datasets
- Outperforms all baseline methods across multiple evaluation metrics
- Demonstrates consistent state-of-the-art performance on both COLIEE 2022 and 2023 datasets

## Why This Works (Mechanism)
LEXA's effectiveness stems from its holistic approach to legal case retrieval that combines structural legal knowledge with contextual LLM representations. By jointly refining node and edge features through the EUGAT layer, the framework captures both the semantic content of legal cases and their citation relationships. The enhanced contrastive learning objective creates stronger supervisory signals that help the model distinguish relevant from irrelevant cases more effectively. The integration of LLM embeddings provides rich contextual information that complements the structural features, resulting in more accurate and robust retrieval performance.

## Foundational Learning

1. **Graph Neural Networks for Legal Information Retrieval** - Why needed: Legal cases are inherently interconnected through citations, requiring models that can process relational data. Quick check: Does the model effectively leverage citation networks between legal documents?

2. **Contrastive Learning in Legal Text Processing** - Why needed: Legal case retrieval requires distinguishing between semantically similar but legally distinct cases. Quick check: Can the model generate meaningful positive and negative pairs from legal documents?

3. **Large Language Model Embeddings for Legal Documents** - Why needed: Legal texts contain complex terminology and context that require sophisticated language understanding. Quick check: Do LLM embeddings capture legal-specific semantics better than traditional embeddings?

## Architecture Onboarding

**Component Map:** Legal documents → Graph Construction → EUGAT Layer → Contrastive Learning → LLM Embeddings → Final Representation → Retrieval Ranking

**Critical Path:** Graph Construction → EUGAT Layer → Contrastive Learning → Final Representation

**Design Tradeoffs:** The framework trades computational complexity for improved retrieval accuracy by incorporating LLM embeddings and graph contrastive learning, which may impact real-time deployment scenarios.

**Failure Signatures:** Performance degradation may occur when legal citation networks are sparse or when LLM embeddings fail to capture jurisdiction-specific legal terminology.

**First Experiments:**
1. Test retrieval performance with and without EUGAT layer to isolate its contribution
2. Evaluate contrastive learning effectiveness by comparing with non-contrastive variants
3. Assess LLM embedding impact by comparing with traditional word embeddings

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on COLIEE datasets from specific years (2022-2023), limiting generalizability to diverse legal contexts
- LLM-based contextual embeddings introduce computational overhead that may constrain practical deployment
- Graph construction assumes availability of structured legal citations, which may not be universal across all jurisdictions

## Confidence
- LEXA's performance superiority over CaseGNN and baselines: High confidence
- Edge-updated graph attention layer effectiveness: Medium confidence
- Graph contrastive learning contribution: Medium confidence
- LLM embeddings as effective graph node features: High confidence

## Next Checks
1. Evaluate LEXA on additional legal case retrieval datasets from different jurisdictions and time periods to assess robustness beyond COLIEE benchmarks.

2. Conduct a more granular ablation study isolating the contributions of EUGAT, contrastive learning, and LLM embeddings to quantify their individual and combined impacts.

3. Benchmark LEXA's runtime and memory requirements compared to baseline methods, particularly focusing on the overhead introduced by LLM-based contextual embeddings and graph contrastive learning.