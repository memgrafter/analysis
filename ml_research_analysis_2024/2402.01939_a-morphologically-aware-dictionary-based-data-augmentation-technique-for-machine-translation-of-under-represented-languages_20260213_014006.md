---
ver: rpa2
title: A Morphologically-Aware Dictionary-based Data Augmentation Technique for Machine
  Translation of Under-Represented Languages
arxiv_id: '2402.01939'
source_url: https://arxiv.org/abs/2402.01939
tags:
- data
- synthetic
- languages
- sentences
- seed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a morphologically-aware dictionary-based data
  augmentation technique for machine translation of under-represented languages. The
  method synthesizes parallel data using morpho-syntactic information and bilingual
  lexicons, combined with a small amount of seed parallel data.
---

# A Morphologically-Aware Dictionary-based Data Augmentation Technique for Machine Translation of Under-Represented Languages

## Quick Facts
- arXiv ID: 2402.01939
- Source URL: https://arxiv.org/abs/2402.01939
- Reference count: 20
- Key outcome: Data augmentation technique using morphologically-aware dictionary-based replacement improves MT for low-resource languages, with gains up to 4.24 BLEU points using as few as five seed sentences

## Executive Summary
This paper presents a morphologically-aware dictionary-based data augmentation technique for machine translation of under-represented languages. The method synthesizes parallel data using morpho-syntactic information and bilingual lexicons, combined with a small amount of seed parallel data. It consists of four components: alignment, analysis, replacement, and generation. The approach creates new grammatically-correct sentences by replacing words in the source sentence with morphologically equivalent words from a bilingual dictionary, and then generating corresponding target sentences. The synthetic data is filtered using language models to improve quality. Experiments on 14 languages show consistent improvements in translation performance, with gains of up to 4.24 BLEU points compared to baseline models. The method is effective even with very limited seed data, demonstrating improvements with as few as five seed sentences.

## Method Summary
The method consists of four components: alignment, analysis, replacement, and generation. First, word alignments are obtained from the seed parallel data using fast_align. Then, morphological features of aligned word pairs are analyzed using Stanza. For replacement, words in the source sentence are randomly selected and replaced with other words from the bilingual dictionary that share identical morphological features. Inflection generation is performed using pyinflect to ensure grammatical correctness. The corresponding target sentence is generated by replacing the aligned word with the translation from the bilingual dictionary. Finally, the augmented sentences are filtered using a language model trained on monolingual data, and the top-k sentences are selected based on perplexity scores.

## Key Results
- The method consistently improves translation performance across 14 languages
- Improvements are achieved even with extremely limited seed data (as few as 5 sentences)
- Gains of up to 4.24 BLEU points compared to baseline models
- Language model filtering of synthetic data proves crucial for quality improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Morphologically-aware replacement preserves grammaticality in synthetic sentences
- Mechanism: By replacing words with candidates that share identical morphological features (e.g., part-of-speech tag, case, number, gender), the generated sentences maintain syntactic validity in the target language
- Core assumption: Morphological features are sufficient to preserve grammatical correctness in synthetic sentences
- Evidence anchors:
  - [abstract] "Our methodology adheres to a realistic scenario backed by the small parallel seed data. It is linguistically informed, as it aims to create augmented data that is more likely to be grammatically correct."
  - [section 2.2] "We first replace 'guitar' with another random word, e.g. 'flower', having identical morphological features... We do this to guarantee that the new word follows the correct morphological features."
  - [corpus] Weak evidence - corpus shows related work on dictionary-based MT but lacks direct morphological validation studies
- Break condition: When morphological features alone are insufficient to ensure grammaticality (e.g., idiomatic expressions, complex syntactic dependencies)

### Mechanism 2
- Claim: Language model perplexity filtering improves synthetic data quality
- Mechanism: By ranking synthetic sentences based on language model perplexity scores and selecting those with lower perplexity, the approach retains sentences that are more natural and contextually appropriate
- Core assumption: Perplexity from a language model trained on monolingual data correlates with sentence quality in the target language
- Evidence anchors:
  - [section 2.3] "We filter the augmented sentences using the LM and rank them based on the perplexity scores to pick the sentences with the correct context."
  - [table 4] Shows filtering with LM leads to consistent improvements while random sampling produces unstable results
  - [corpus] Weak evidence - corpus contains related data augmentation work but limited LM-based filtering studies
- Break condition: When language model perplexity doesn't correlate with translation quality (e.g., domain-specific terminology, rare word combinations)

### Mechanism 3
- Claim: Small seed data with morphological analysis can generate sufficient synthetic data for effective training
- Mechanism: By analyzing morphological features of aligned word pairs and using bilingual dictionaries to find morphologically equivalent replacements, the system creates diverse synthetic parallel data even from limited seed examples
- Core assumption: Morphological analysis and dictionary-based replacement can create diverse, useful synthetic data without requiring large parallel corpora
- Evidence anchors:
  - [abstract] "Our method leads to improvements even when using only five seed sentences and a bilingual lexicon."
  - [section 5] "Even if we have few high-quality parallel sentences and a good-quality lexicon, our method is bound to boost MT system quality."
  - [corpus] Moderate evidence - corpus includes related work on low-resource MT but limited studies on extreme data scarcity scenarios
- Break condition: When seed data quality is too poor to provide reliable morphological analysis or when bilingual dictionaries lack sufficient coverage

## Foundational Learning

- Concept: Morphological feature tagging
  - Why needed here: To identify and preserve grammatical properties (case, number, gender, tense) when replacing words in sentences
  - Quick check question: What morphological features would you need to preserve when replacing a noun in accusative case singular form?

- Concept: Word alignment in parallel corpora
  - Why needed here: To establish correspondence between words in source and target sentences for consistent replacement
  - Quick check question: How would you handle cases where a single source word aligns to multiple target words or vice versa?

- Concept: Perplexity calculation for language models
  - Why needed here: To measure how "natural" synthetic sentences are and filter out poor quality examples
  - Quick check question: Given a sentence probability P and length n, how do you calculate perplexity?

## Architecture Onboarding

- Component map: Tokenization → Word alignment → Morphological tagging → Word replacement → Inflection generation → Language model filtering → Training
- Critical path: Seed data → Morphological analysis → Dictionary lookup → Inflection → LM filtering → Training
- Design tradeoffs:
  - Morphological precision vs. coverage: More precise morphological analysis improves quality but may reduce available replacements
  - Filtering threshold vs. data quantity: Stricter perplexity thresholds improve quality but reduce available training data
  - Seed data size vs. synthetic diversity: More seed data enables more diverse synthetic sentences but requires more computational resources
- Failure signatures:
  - Poor BLEU scores despite synthetic data addition: Indicates issues with morphological analysis or dictionary quality
  - Very low perplexity scores on synthetic data: Suggests filtering is too lenient and allowing poor quality sentences
  - Rapid overfitting with small amounts of synthetic data: Indicates synthetic data lacks diversity or quality
- First 3 experiments:
  1. Baseline comparison: Train with only real seed data (0K) and measure BLEU score
  2. Small-scale augmentation: Generate 1K synthetic sentences using morphologically-aware approach and measure improvement
  3. Filtering effectiveness: Compare LM-filtered vs. random synthetic data selection on the same amount of data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform on languages with highly agglutinative morphology compared to languages with fusional or isolating morphology?
- Basis in paper: [inferred] The paper focuses on 14 languages with varying morphological characteristics but does not explicitly compare performance across different morphological types.
- Why unresolved: The paper does not analyze the performance differences between languages with different morphological types.
- What evidence would resolve it: Comparative analysis of the method's performance on languages with different morphological types (e.g., agglutinative vs. fusional) using the same experimental setup.

### Open Question 2
- Question: What is the optimal amount of synthetic data to add for different resource levels of target languages?
- Basis in paper: [explicit] The paper mentions that adding more synthetic data does not always lead to improvements and that different amounts of synthetic data were tested.
- Why unresolved: The paper does not provide a clear guideline on how to determine the optimal amount of synthetic data for different resource levels.
- What evidence would resolve it: Detailed analysis of the relationship between resource levels of target languages and the optimal amount of synthetic data to add, possibly through additional experiments or theoretical analysis.

### Open Question 3
- Question: How does the quality of the bilingual dictionary affect the performance of the proposed method?
- Basis in paper: [inferred] The paper uses dictionaries from the PanLex database but does not analyze the impact of dictionary quality on performance.
- Why unresolved: The paper does not investigate the relationship between dictionary quality and the effectiveness of the proposed method.
- What evidence would resolve it: Comparative analysis of the method's performance using dictionaries of varying quality, or an analysis of the impact of specific dictionary features (e.g., coverage, accuracy) on performance.

### Open Question 4
- Question: How does the proposed method compare to other data augmentation techniques for low-resource machine translation?
- Basis in paper: [explicit] The paper mentions that the method is "orthogonal to" other augmentation techniques like back-translation but does not provide a direct comparison.
- Why unresolved: The paper does not include experiments comparing the proposed method to other data augmentation techniques.
- What evidence would resolve it: Direct comparison of the proposed method with other data augmentation techniques (e.g., back-translation, unsupervised methods) using the same experimental setup and evaluation metrics.

## Limitations
- Method effectiveness heavily depends on quality of morphological analysis tools and bilingual dictionaries
- Limited validation on specialized domains beyond general domain translation
- Performance on languages with very limited linguistic resources not thoroughly explored

## Confidence
- **High confidence**: The core methodology of morphologically-aware replacement combined with language model filtering is sound and theoretically justified
- **Medium confidence**: The claim that improvements persist with as few as five seed sentences is supported by results, but lower bounds of seed data quality vs quantity trade-offs not fully explored
- **Low confidence**: Claims about effectiveness for "under-represented languages" not thoroughly validated, as tested languages still have reasonable resources available

## Next Checks
1. **Morphological feature robustness test**: Systematically evaluate the method's performance when morphological analysis tools produce errors or incomplete feature sets, particularly for languages with rich morphology or limited linguistic resources

2. **Lexicon coverage analysis**: Quantify the relationship between bilingual lexicon coverage and synthetic data quality, including experiments that deliberately use lexicons with varying coverage percentages to determine the minimum viable coverage for effective augmentation

3. **Domain adaptation validation**: Test the method on specialized domain corpora (e.g., medical or legal texts) to assess whether morphologically-aware augmentation maintains effectiveness outside of general domain translation scenarios