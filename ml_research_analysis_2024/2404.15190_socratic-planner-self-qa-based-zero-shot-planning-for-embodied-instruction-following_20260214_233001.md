---
ver: rpa2
title: 'Socratic Planner: Self-QA-Based Zero-Shot Planning for Embodied Instruction
  Following'
arxiv_id: '2404.15190'
source_url: https://arxiv.org/abs/2404.15190
tags:
- socratic
- planner
- task
- language
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Socratic Planner introduces a zero-shot planning method for
  Embodied Instruction Following (EIF) that uses self-questioning and answering to
  decompose instructions into substructural information, then generates a sequence
  of subgoals without any labeled training data. It also incorporates a visually-grounded
  re-planning mechanism that adjusts plans based on dense visual feedback when unexpected
  situations arise during execution.
---

# Socratic Planner: Self-QA-Based Zero-Shot Planning for Embodied Instruction Following

## Quick Facts
- arXiv ID: 2404.15190
- Source URL: https://arxiv.org/abs/2404.15190
- Authors: Suyeon Shin; Sujin jeon; Junghyun Kim; Gi-Cheon Kang; Byoung-Tak Zhang
- Reference count: 40
- Primary result: State-of-the-art zero-shot performance on ALFRED benchmark using self-questioning LLM for task decomposition

## Executive Summary
The Socratic Planner introduces a novel zero-shot approach for Embodied Instruction Following (EIF) that eliminates the need for labeled training data by leveraging self-questioning and answering within a Large Language Model (LLM). The method decomposes complex instructions into substructural information through an internal Socratic dialogue, generating a sequence of subgoals for task execution. It also incorporates a vision-based re-planning mechanism that uses dense visual feedback from a Vision-Language Model (VLM) to adjust plans when execution failures occur. Experiments on the ALFRED benchmark demonstrate state-of-the-art performance among zero-shot methods, particularly excelling at long-horizon tasks requiring complex inference, and closely matching or exceeding the performance of few-shot methods.

## Method Summary
The Socratic Planner employs a zero-shot planning approach that first uses the Socratic Task Decomposer (STD) to facilitate self-questioning and answering within an LLM, decomposing complex task instructions into substructural information. This decomposed information is then used by the Task Planner to generate a sequence of subgoals for execution. When execution failures occur, a Vision-Language Model (VLM) provides dense visual feedback to identify the cause of failure and enable re-planning. The method is evaluated on the ALFRED benchmark using both strict and relaxed high-level planning metrics, demonstrating state-of-the-art zero-shot performance.

## Key Results
- Achieves state-of-the-art performance among zero-shot methods on ALFRED benchmark
- Outperforms all zero-shot baselines and closely matches few-shot method performance
- Excels particularly at long-horizon tasks requiring complex inference and planning
- Introduces RelaxedHLP metric that considers semantically equivalent plans for more comprehensive evaluation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-questioning and answering enables the LLM to decompose complex instructions into substructural information without labeled training data.
- Mechanism: The Socratic Task Decomposer (STD) uses an inquiry-based approach where the LLM autonomously generates questions and answers about sub-tasks, their order, target objects, and execution methods, effectively creating an internal dialogue to understand task structure.
- Core assumption: The LLM can generate meaningful questions and answers that capture the necessary substructural information for task planning without any in-context examples.
- Evidence anchors:
  - [abstract] "The Socratic Planner first facilitates self-questioning and answering by the Large Language Model (LLM), which in turn helps generate a sequence of subgoals"
  - [section] "Inspired by Socrates's Socratic method [24], a method used to stimulate critical thinking through a series of questions and answers – we empower LLMs to decompose complex task instructions into substructural information by engaging in self-questioning and answering"

### Mechanism 2
- Claim: Vision-Language Model (VLM) provides dense visual feedback that enables effective re-planning when execution fails.
- Mechanism: When execution failures occur, the VLM analyzes the current visual state to determine if the target object exists, if the action is valid, and what caused the failure. This visual information is then used to adjust the plan through the LLM.
- Core assumption: The VLM can accurately infer the cause of failures and provide actionable feedback based on visual information alone, without requiring simulator error messages or human intervention.
- Evidence anchors:
  - [abstract] "The Socratic Planner then adjusts plans based on dense visual feedback through a visually grounded re-planning mechanism"
  - [section] "Leveraging this dense visual feedback, the Task Planner finally reasons about revising the plan and adjusts it to be better suited to the environment"

### Mechanism 3
- Claim: The RelaxedHLP metric provides a more comprehensive evaluation of high-level planning by considering semantically equivalent plans.
- Mechanism: RelaxedHLP extends the strict evaluation by accepting multiple valid subgoal sequences that produce the same execution result, rather than requiring exact matches to ground truth plans.
- Core assumption: There are multiple semantically equivalent high-level plans that can achieve the same task completion, and human evaluators would consider these equivalent.
- Evidence anchors:
  - [abstract] "we introduce a relaxed evaluation metric for high-level planning, RelaxedHLP, that extends the existing strict high-level planning metric, StrictHLP, by considering multiple possible correct plans"
  - [section] "we introduce a relaxed evaluation metric for high-level planning, RelaxedHLP, that extends the existing strict high-level planning metric, StrictHLP, by considering multiple possible correct plans"

## Foundational Learning

- Concept: Socratic method of inquiry-based learning
  - Why needed here: The Socratic method provides the theoretical foundation for the self-questioning and answering mechanism that enables zero-shot planning
  - Quick check question: How does the Socratic method differ from traditional instruction-following approaches in AI planning?

- Concept: Embodied Instruction Following (EIF) task structure
  - Why needed here: Understanding the two-stage process (high-level planning + low-level control) is crucial for implementing the Socratic Planner correctly
  - Quick check question: What are the key differences between high-level planning and low-level control in the EIF task?

- Concept: Vision-Language Model (VLM) capabilities
  - Why needed here: The VLM's ability to analyze visual scenes and provide dense feedback is essential for the re-planning mechanism
  - Quick check question: What types of visual information does the VLM need to analyze for effective re-planning?

## Architecture Onboarding

- Component map: Instruction → STD → Task Planner → Low-level Controller → Execution → VLM feedback → Re-planning (if needed)
- Critical path: Instruction → STD → Task Planner → Low-level Controller → Execution → VLM feedback → Re-planning (if needed)
- Design tradeoffs:
  - Zero-shot vs. few-shot learning: Zero-shot eliminates data requirements but may sacrifice some accuracy
  - STD complexity: More detailed questioning improves planning but increases computational cost
  - VLM feedback granularity: More detailed visual analysis improves re-planning but may slow down the system
- Failure signatures:
  - STD failure: Poor quality subgoals or missing task substructures
  - Task Planner failure: Incorrect subgoal sequences
  - VLM failure: Inability to identify failure causes or provide useful feedback
  - Low-level Controller failure: Execution errors unrelated to planning
- First 3 experiments:
  1. Test STD with simple instructions to verify self-questioning generates meaningful substructural information
  2. Validate Task Planner produces correct subgoal sequences using STD output
  3. Test VLM feedback mechanism with simulated execution failures to ensure proper re-planning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Socratic Planner vary with different LLMs, particularly when using models with different reasoning capabilities or knowledge bases?
- Basis in paper: [inferred] The paper mentions using GPT-Turbo-3.5 but does not explore the impact of using other LLMs.
- Why unresolved: The paper focuses on demonstrating the effectiveness of the Socratic Planner approach rather than comparing different LLMs.
- What evidence would resolve it: Experiments comparing the performance of Socratic Planner using different LLMs (e.g., GPT-4, Claude, LLaMA) on the ALFRED benchmark.

### Open Question 2
- Question: Can the Socratic Planner generalize to more complex tasks beyond household activities, such as industrial assembly or scientific experimentation?
- Basis in paper: [explicit] The paper demonstrates the effectiveness of Socratic Planner on the ALFRED benchmark, which focuses on household tasks.
- Why unresolved: The ALFRED benchmark is limited to household tasks, and the paper does not explore the scalability of the approach to more complex domains.
- What evidence would resolve it: Applying the Socratic Planner to other task-oriented datasets or real-world scenarios involving more complex tasks and evaluating its performance.

### Open Question 3
- Question: How does the Socratic Planner handle tasks with ambiguous or incomplete instructions, and what are the limitations of its reasoning capabilities in such scenarios?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of Socratic Planner on the ALFRED benchmark, which assumes clear and complete instructions.
- Why unresolved: The paper does not explore the robustness of the approach to ambiguous or incomplete instructions, which are common in real-world scenarios.
- What evidence would resolve it: Experiments evaluating the performance of Socratic Planner on tasks with ambiguous or incomplete instructions, and analyzing its failure modes and limitations.

## Limitations
- Zero-shot approach relies heavily on underlying LLM's reasoning capabilities, which may not generalize across different instruction domains or language styles
- Paper lacks ablation studies to isolate contribution of vision-based re-planning versus other components
- RelaxedHLP metric has not been validated against human judgments of semantic equivalence

## Confidence

- **High Confidence**: The core mechanism of using self-questioning for task decomposition is well-supported by the experimental results, showing consistent improvements over baseline zero-shot methods.
- **Medium Confidence**: The vision-based re-planning mechanism's effectiveness is demonstrated, but the paper lacks ablation studies showing how much of the performance gain comes specifically from the visual feedback versus other components.
- **Low Confidence**: The RelaxedHLP metric, while conceptually valuable, has not been validated against human judgments of semantic equivalence, raising questions about its discriminative power.

## Next Checks

1. Conduct ablation studies to isolate the contribution of the Socratic Task Decomposer versus the vision-based re-planning mechanism on overall performance.
2. Test the system on out-of-distribution instructions (different styles, domains, or languages) to assess generalization beyond ALFRED's specific instruction format.
3. Perform human evaluation studies to validate that RelaxedHLP's notion of semantic equivalence aligns with human judgments of plan correctness.