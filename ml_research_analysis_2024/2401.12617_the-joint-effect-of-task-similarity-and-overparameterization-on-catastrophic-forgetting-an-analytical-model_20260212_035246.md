---
ver: rpa2
title: The Joint Effect of Task Similarity and Overparameterization on Catastrophic
  Forgetting -- An Analytical Model
arxiv_id: '2401.12617'
source_url: https://arxiv.org/abs/2401.12617
tags:
- qmva
- conference
- page
- published
- iclr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the joint effect of task similarity and overparameterization
  on catastrophic forgetting in continual learning. The authors propose a two-task
  linear regression model where the second task is a random orthogonal transformation
  of the first task, and the Dimensionality of Transformed Subspace (DOTS) controls
  task similarity.
---

# The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model

## Quick Facts
- arXiv ID: 2401.12617
- Source URL: https://arxiv.org/abs/2401.12617
- Reference count: 40
- This paper analyzes how task similarity and overparameterization jointly affect catastrophic forgetting in continual learning

## Executive Summary
This paper presents an analytical model examining how task similarity and overparameterization interact to influence catastrophic forgetting in continual learning. The authors develop a two-task linear regression framework where the second task is a random orthogonal transformation of the first, with a Dimensionality of Transformed Subspace (DOTS) parameter controlling task similarity. Through rigorous mathematical analysis, they derive an exact expression for expected worst-case forgetting, revealing a nuanced relationship: highly overparameterized models exhibit maximum forgetting at intermediate task similarity levels, while near the interpolation threshold, forgetting decreases monotonically with task similarity. The work challenges the common assumption that overparameterization alone can prevent forgetting, demonstrating instead that its effectiveness depends critically on task similarity.

## Method Summary
The authors propose a two-task continual linear regression model where task 2 is a random orthogonal transformation of task 1, with task similarity controlled by the Dimensionality of Transformed Subspace (DOTS) parameter. They derive an exact analytical expression for expected worst-case forgetting under this model when trained using sequential gradient descent without explicit forgetting prevention mechanisms. The analysis leverages the relationship between task similarity and the principal angles between data matrices. Empirical validation is conducted using synthetic linear regression data and neural networks on permuted MNIST benchmarks, varying both task similarity (through permutation sizes) and overparameterization levels (through model widths).

## Key Results
- In highly overparameterized models, intermediate task similarity causes the most forgetting
- Near the interpolation threshold, forgetting decreases monotonically with task similarity
- Overparameterization alone cannot always prevent forgetting; its effectiveness depends on task similarity as captured by the DOTS measure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task similarity and overparameterization interact in a non-monotonic way: intermediate task similarity causes the most forgetting in highly overparameterized models, while in near-interpolation threshold models, forgetting decreases monotonically with task similarity.
- Mechanism: The paper introduces a two-task linear regression model where the second task is a random orthogonal transformation of the first task, and the Dimensionality of Transformed Subspace (DOTS) controls task similarity. The authors derive an exact analytical expression for expected worst-case forgetting under this model, revealing the nuanced pattern described above.
- Core assumption: The model assumes that tasks are realizable by linear models and that data matrices have full rank for the analysis to be valid.
- Evidence anchors:
  - [abstract] "The key finding is a nuanced pattern: in highly overparameterized models, intermediate task similarity causes the most forgetting. However, near the interpolation threshold, forgetting decreases monotonically with expected task similarity."
  - [section] "In highly overparameterized models, intermediate task similarity causes the most forgetting. However, near the interpolation threshold, forgetting decreases monotonically with the expected task similarity."
- Break condition: The model assumptions break down when tasks are not realizable by linear models or when data matrices do not have full rank.

### Mechanism 2
- Claim: Overparameterization alone cannot always prevent forgetting; its effect depends on task similarity.
- Mechanism: The paper shows that even with extremely high overparameterization levels, forgetting does not vanish entirely but instead depends on task similarity as captured by the DOTS measure. This challenges the common belief that overparameterization alone can prevent forgetting.
- Core assumption: The paper assumes that the relationship between overparameterization and forgetting is not solely determined by the level of overparameterization but also by the similarity between tasks.
- Evidence anchors:
  - [abstract] "The results show that overparameterization alone cannot always prevent forgetting, and its effect depends on task similarity."
  - [section] "Importantly, we observe once more that even with extremely high overparameterization levels ( β = 1 − d p → 1), forgetting does not vanish entirely. Instead, this outcome is contingent on task similarity, as captured by our DOTS measure."
- Break condition: The assumption breaks down if overparameterization levels are so high that they completely eliminate the need for task similarity considerations.

### Mechanism 3
- Claim: The joint effect of task similarity and overparameterization on catastrophic forgetting can be analyzed using a random orthogonal transformation model.
- Mechanism: The paper proposes a model where the second task is a random orthogonal transformation of the first task, with the Dimensionality of Transformed Subspace (DOTS) controlling task similarity. This model allows for an exact analytical expression of expected worst-case forgetting.
- Core assumption: The model assumes that the random orthogonal transformation is a valid abstraction of popular permutation benchmarks and that the resulting tasks are equally difficult for a fully connected model.
- Evidence anchors:
  - [section] "This similarity notion provides a natural knob that controls how similar tasks are after a random transformation. This notion also closely characterizes popular permutation benchmarks, for which it was first suggested by the seminal work of Kirkpatrick et al. (2017)."
  - [corpus] "Disentangling and Mitigating the Impact of Task Similarity for Continual Learning" - This paper addresses the impact of task similarity on continual learning, providing context for the importance of the DOTS measure.
- Break condition: The assumption breaks down if the random orthogonal transformation does not accurately represent the task similarity in real-world benchmarks.

## Foundational Learning

- Concept: Linear Regression
  - Why needed here: The paper's analysis is based on a two-task linear regression model, which is fundamental to understanding the proposed mechanisms.
  - Quick check question: Can you explain how the loss function in linear regression is formulated and minimized?

- Concept: Orthogonal Transformations
  - Why needed here: The paper uses random orthogonal transformations to model task similarity, making this concept crucial for understanding the proposed model.
  - Quick check question: What properties of orthogonal transformations make them suitable for modeling task similarity in this context?

- Concept: Catastrophic Forgetting
  - Why needed here: The paper's primary focus is on understanding and mitigating catastrophic forgetting in continual learning, making this concept essential for grasping the paper's contributions.
  - Quick check question: Can you explain what catastrophic forgetting is and why it poses a challenge in continual learning?

## Architecture Onboarding

- Component map: Two-task linear regression model with random orthogonal transformations -> Dimensionality of Transformed Subspace (DOTS) measure -> Analytical expression for expected worst-case forgetting -> Empirical validation with synthetic data and neural networks

- Critical path: 1. Define the data model and similarity measure 2. Derive the analytical expression for expected worst-case forgetting 3. Validate the findings using synthetic data and neural networks

- Design tradeoffs: Simplicity vs. realism in the data model; Analytical tractability vs. generality of the model; Computational efficiency vs. accuracy in validation experiments

- Failure signatures: Inability to derive analytical expressions for more complex models; Failure to validate findings in real-world benchmarks; Overreliance on assumptions that do not hold in practice

- First 3 experiments: 1. Implement the two-task linear regression model with random orthogonal transformations and analyze the forgetting behavior under different levels of task similarity and overparameterization. 2. Validate the analytical findings using linear regression on synthetic data with varying DOTS and overparameterization levels. 3. Extend the validation to neural networks on permuted MNIST benchmarks and analyze the relationship between task similarity, overparameterization, and forgetting.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the joint effects of task similarity and overparameterization on catastrophic forgetting extend beyond two tasks to multi-task continual learning scenarios?
- Basis in paper: The paper explicitly acknowledges this limitation in Section 4.1, noting that their analysis focused on T=2 tasks and that extending to T≥3 tasks poses immediate challenges.
- Why unresolved: The authors note that their current analysis already required intricate techniques and proofs, suggesting that tackling the extension to T≥3 tasks may be considerably difficult. They reference previous work showing that convergence analysis for T≥3 tasks cyclically is notably more challenging than for T=2 tasks.
- What evidence would resolve it: Theoretical derivations extending the current analytical framework to multi-task scenarios, or empirical studies demonstrating similar joint effects of task similarity and overparameterization in multi-task continual learning settings.

### Open Question 2
- Question: How do the findings on task similarity and overparameterization translate to more complex nonlinear models like MLPs, CNNs, and transformers?
- Basis in paper: The paper explicitly identifies this as an immediate next step in Section 4.1, stating "An immediate next step is to explore the extension of our analysis and empirical findings to more intricate non-linear models (e.g., MLPs, CNNs, and transformers)".
- Why unresolved: The authors focused on linear models and data permutation tasks as a starting point for theoretical analysis. While they mention connections between overparameterized neural networks and linear models via the neural tangent kernel (NTK) regime, they acknowledge that the proxy for overparameterization (β = 1 - d/p) directly controlling task subspace overlap in linear models is different from the width of deep networks.
- What evidence would resolve it: Empirical studies on complex neural network architectures demonstrating similar joint effects of task similarity and overparameterization on catastrophic forgetting, or theoretical connections between the linear model analysis and nonlinear models in the NTK regime.

### Open Question 3
- Question: How does the choice of task similarity measure impact the observed relationship between task similarity, overparameterization, and catastrophic forgetting?
- Basis in paper: The paper uses a specific notion of task similarity (Dimensionality of Transformed Subspace, DOTS) that is motivated by permutation benchmarks and relates to the principal angles between data matrices. However, they acknowledge in Section 4.1 that exploring other notions of task similarity could be valuable.
- Why unresolved: The authors chose this particular measure for its clear mathematical relationship and generation of equally difficult tasks for fully connected models. They note that while there is criticism that permutation tasks are relatively easy to solve in practice, they believe this setting is most amenable for initial theoretical results. However, they don't explore how other measures of task similarity might affect the observed relationships.
- What evidence would resolve it: Empirical studies comparing catastrophic forgetting across different task similarity measures in the same experimental setup, or theoretical work connecting different task similarity measures to the observed joint effects of task similarity and overparameterization.

## Limitations
- The two-task linear regression model with random orthogonal transformations may not fully capture the complexity of real-world continual learning scenarios
- The assumption of linear realizability and full-rank data matrices constrains applicability to more complex, nonlinear tasks
- The DOTS measure, while elegant, may not fully capture semantic or functional task similarities that emerge in real applications

## Confidence
- Analytical results under specified model assumptions: High
- Empirical validation in synthetic and permuted MNIST settings: Medium

## Next Checks
1. Test the analytical predictions using two-layer neural networks with nonlinear activations to assess whether the forgetting patterns hold beyond linear models.
2. Implement experiments with gradually varying task similarity (not just orthogonal transformations) to validate whether the DOTS measure accurately predicts forgetting across different similarity regimes.
3. Apply the framework to more complex continual learning benchmarks (e.g., class-incremental CIFAR, CORe50) to evaluate whether the overparameterization-task similarity interaction persists in practical scenarios with heterogeneous task relationships.