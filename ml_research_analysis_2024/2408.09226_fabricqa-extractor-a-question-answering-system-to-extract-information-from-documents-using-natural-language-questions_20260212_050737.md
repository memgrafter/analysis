---
ver: rpa2
title: 'FabricQA-Extractor: A Question Answering System to Extract Information from
  Documents using Natural Language Questions'
arxiv_id: '2408.09226'
source_url: https://arxiv.org/abs/2408.09226
tags:
- question
- answer
- relation
- passage
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FabricQA-Extractor, a system that uses natural
  language questions to extract structured information from large collections of documents.
  The key contribution is the Relation Coherence model, which leverages knowledge
  of the target relational schema to improve extraction quality.
---

# FabricQA-Extractor: A Question Answering System to Extract Information from Documents using Natural Language Questions

## Quick Facts
- arXiv ID: 2408.09226
- Source URL: https://arxiv.org/abs/2408.09226
- Authors: Qiming Wang; Raul Castro Fernandez
- Reference count: 40
- Key outcome: A system using natural language questions to extract structured information from large document collections, achieving subsecond latencies and up to 7-point F1 score improvements through a Relation Coherence model that leverages bidirectional relationship consistency.

## Executive Summary
This paper presents FabricQA-Extractor, a question answering system designed to extract structured information from large collections of documents. The key innovation is the Relation Coherence model, which improves extraction quality by leveraging knowledge of the target relational schema. The system processes millions of documents with subsecond latencies through a funnel-based architecture that progressively filters and refines candidate answers. Experiments on Wikipedia and biomedical datasets demonstrate significant improvements in extraction quality compared to baseline approaches, with the system maintaining good performance even on new domains without retraining.

## Method Summary
FabricQA-Extractor uses a pipeline approach where documents are first chunked into passages and indexed using an IR system. When answering questions, the system retrieves relevant passages, ranks them using a passage ranker (RC model), and then uses an answer ranker (BERT-based) to identify candidate answers. The Relation Coherence model then verifies bidirectional relationship consistency by checking if both forward and reverse relationships exist in the same passage. Finally, an ensemble method combines scores from multiple models to produce the final answer. The system is trained on the QA-ZRE benchmark and evaluated on partially filled relations from Wikipedia and biomedical domains.

## Key Results
- The Relation Coherence model improves F1 scores by up to 7 points compared to baseline approaches
- The system achieves subsecond latencies when processing millions of documents
- Good performance is maintained on new domains without retraining, as demonstrated on biomedical data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Relation Coherence model improves extraction quality by leveraging bidirectional consistency between forward and reverse relationships.
- Mechanism: When the system identifies a relationship S→O, it verifies the reverse relationship O→S exists in the same passage, creating a coherence score that boosts passage ranking accuracy.
- Core assumption: If a relationship exists between two entities in one direction, the reverse relationship should also hold true within the same textual context.
- Evidence anchors:
  - [abstract] "Relation Coherence model, which leverages knowledge of the target relational schema to improve extraction quality"
  - [section III-A] "the insight we introduce in this paper is that given R, O, and a reverse question ← −Q, a correct passage should contain S as well"
  - [corpus] Weak - neighboring papers focus on RAG and extraction but don't explicitly validate bidirectional relationship checking
- Break condition: If the text contains directional or asymmetric relationships (e.g., "parent of" vs "child of") where reverse relationships don't logically hold.

### Mechanism 2
- Claim: The funnel architecture achieves subsecond latencies by progressively filtering millions of passages through increasingly sophisticated but computationally expensive components.
- Mechanism: Large-scale IR indexing (fast, syntactic) → Passage Ranker (moderate, semantic) → Answer Ranker (slow, neural) → Relation Coherence (slowest, relational) creates a computational efficiency hierarchy.
- Core assumption: Early filtering stages can reduce the input to downstream components by orders of magnitude without losing relevant content.
- Evidence anchors:
  - [abstract] "end-to-end pipeline that uses passage ranking, answer ranking, and ensemble techniques to achieve subsecond latencies"
  - [section IV-A] "FabricQA-Extractor implements a funnel-based architecture. The more downstream a component, the more sophisticated and the more computationally expensive it is."
  - [section V-C] "FabricQA-Extractor answers questions in subsecond latencies" with throughput measurements showing performance degradation as pipeline complexity increases
- Break condition: If early filtering is too aggressive and removes relevant passages, or if downstream components cannot process the filtered volume in acceptable time.

### Mechanism 3
- Claim: The system generalizes to new domains without retraining by using question answering as a universal interface that doesn't require relationship-specific training data.
- Mechanism: Instead of training separate classifiers per relationship, the system uses natural language questions and pre-trained language models that can adapt to different domains through semantic understanding.
- Core assumption: Pre-trained language models capture sufficient semantic knowledge to understand questions and passages across different domains without domain-specific fine-tuning.
- Evidence anchors:
  - [abstract] "the system maintains good performance even on new domains without retraining"
  - [section II-C] "Recent advances in machine reading comprehension... provide the answer to a natural language question when a short passage of text is provided"
  - [section V-B] Results showing 7-point improvement on biomedical data without retraining the Relation Coherence model
- Break condition: If domain-specific terminology or context is too different from training data for the pre-trained models to understand questions and passages correctly.

## Foundational Learning

- Concept: Reading Comprehension Models (BERT, Albert, BiDAF)
  - Why needed here: These models form the core of both forward searching (finding answers) and backward searching (finding subjects), and understanding their architecture is crucial for implementing the Answer Ranker and Relation Coherence components
  - Quick check question: What is the maximum sequence length that BERT-based models typically accept, and why does this constraint affect passage chunking strategy?

- Concept: Information Retrieval Systems and Ranking (BM25, ElasticSearch)
  - Why needed here: The initial retrieval stage uses IR systems to narrow millions of passages to hundreds, and understanding ranking algorithms helps optimize passage selection before expensive neural processing
  - Quick check question: How does BM25 scoring differ from semantic similarity scoring, and why is exact match important for passage re-ranking?

- Concept: Ensemble Methods and Normalization (Z-score, model averaging)
  - Why needed here: The final answer selection combines scores from multiple models (OpenQA, Relation Coherence) that have different scales and distributions
  - Quick check question: Why is across-row-normalization using Z-scores more effective than simple averaging when combining model predictions?

## Architecture Onboarding

- Component map:
  Offline: Chunker → Indexer (builds passage index)
  Online: IR System → Passage Ranker (RC model) → Answer Ranker (BERT-based) → Relation Coherence (bidirectional verification) → Ensemble (Z-score normalization)
  Data flow: Questions → IR → 30 passages → RC ranking → top 5 → Answer Ranker → top K3 → Relation Coherence → final answer

- Critical path: IR retrieval → Passage Ranker → Answer Ranker → Relation Coherence → Final answer selection
  - Latency bottleneck: Answer Ranker and Relation Coherence (GPU-intensive)
  - Throughput bottleneck: Passage Ranker (must process 30 passages per question)

- Design tradeoffs:
  - Passage size vs. model limits: 100-word passages balance context completeness with BERT's 512-token limit
  - Retrieval depth vs. computation: 30 passages retrieved but only 5 processed by expensive models
  - Model complexity vs. generalization: Complex Relation Coherence improves accuracy but requires training data

- Failure signatures:
  - Low recall: Too aggressive passage filtering in Passage Ranker
  - Low precision: Relation Coherence overfitting to training data
  - High latency: GPU queue saturation from multiple model inferences
  - Domain adaptation failure: Poor performance on new vocabulary without retraining

- First 3 experiments:
  1. Test IR retrieval accuracy with different passage sizes (10-200 tokens) to find optimal chunking strategy
  2. Benchmark Passage Ranker performance with different numbers of retrieved passages (10, 30, 50) to find recall-precision tradeoff
  3. Validate Relation Coherence generalization by testing on out-of-domain data without retraining the coherence model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Relation Coherence model perform on other domains beyond Wikipedia and biomedical text, such as legal or financial documents?
- Basis in paper: [inferred] The paper demonstrates effectiveness on Wikipedia and biomedical domains but does not explore other domains like legal or financial documents.
- Why unresolved: The evaluation is limited to two specific domains, leaving open the question of generalizability to other specialized domains.
- What evidence would resolve it: Testing the Relation Coherence model on diverse document collections from legal, financial, or other specialized domains and measuring performance improvements.

### Open Question 2
- Question: What is the optimal training dataset size and diversity for the Relation Coherence model to achieve maximum performance?
- Basis in paper: [explicit] The paper shows diminishing returns with larger training datasets and suggests that a small, representative dataset is sufficient.
- Why unresolved: The exact relationship between training dataset size, diversity, and model performance is not fully characterized.
- What evidence would resolve it: Systematic experiments varying both the size and diversity of training datasets to identify optimal configurations for different relationship types.

### Open Question 3
- Question: How does the Relation Coherence model handle complex relationships involving multiple entities or nested relationships?
- Basis in paper: [inferred] The paper focuses on simple subject-relationship-object triples but does not address more complex relationship structures.
- Why unresolved: The model's architecture and evaluation are based on straightforward relational structures without testing more complex scenarios.
- What evidence would resolve it: Testing the model on datasets containing complex relationships, multiple entities, and nested structures to evaluate performance degradation or required adaptations.

## Limitations

- The Relation Coherence model's effectiveness depends on the assumption that bidirectional relationships exist in the same textual context, which may not hold for directional or asymmetric relationships.
- The evaluation focuses primarily on biomedical and general domain datasets, with limited validation across diverse domains that might have different relationship patterns.
- The computational efficiency claims don't fully account for GPU availability constraints in real-world deployments.

## Confidence

**High Confidence**: The funnel architecture design and its computational efficiency benefits are well-supported by the experimental results showing subsecond latencies. The claim about achieving good performance on new domains without retraining is validated through the BioNLP experiments.

**Medium Confidence**: The Relation Coherence mechanism shows theoretical soundness and positive experimental results, but the assumption about bidirectional relationship consistency may not generalize to all relationship types. The 7-point F1 improvement is significant but may vary with different datasets.

**Low Confidence**: The claim about maintaining "good performance" on new domains is based on limited out-of-domain testing. The paper doesn't explore edge cases where the Relation Coherence model might fail or how it performs with highly specialized domain terminology.

## Next Checks

1. **Bidirectional Relationship Validation**: Test the Relation Coherence model on datasets containing directional relationships (e.g., "parent," "employer," "located in") to verify it doesn't incorrectly enforce bidirectional consistency where it doesn't logically apply.

2. **Domain Diversity Assessment**: Evaluate the system across at least three additional domains (e.g., legal, financial, social media) to assess generalization claims and identify domain-specific failure patterns that weren't captured in the biomedical and general domain tests.

3. **Computational Resource Analysis**: Measure actual GPU memory usage and processing times across different hardware configurations to validate the subsecond latency claims under realistic deployment constraints, including scenarios with concurrent requests and varying batch sizes.