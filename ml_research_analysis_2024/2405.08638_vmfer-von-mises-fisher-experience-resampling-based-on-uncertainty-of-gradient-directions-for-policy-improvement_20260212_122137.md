---
ver: rpa2
title: 'vMFER: Von Mises-Fisher Experience Resampling Based on Uncertainty of Gradient
  Directions for Policy Improvement'
arxiv_id: '2405.08638'
source_url: https://arxiv.org/abs/2405.08638
tags:
- uncertainty
- policy
- vmfer
- gradient
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the inefficiency in policy improvement caused
  by gradient disagreements from ensemble critics in reinforcement learning. It introduces
  uncertainty of gradient directions as a metric to quantify disagreement and proposes
  von Mises-Fisher Experience Resampling (vMFER) to resample transitions based on
  this uncertainty.
---

# vMFER: Von Mises-Fisher Experience Resampling Based on Uncertainty of Gradient Directions for Policy Improvement

## Quick Facts
- **arXiv ID**: 2405.08638
- **Source URL**: https://arxiv.org/abs/2405.08638
- **Reference count**: 40
- **Primary result**: vMFER achieves over 10% average performance improvement over baselines (TD3, SAC) across Mujoco tasks by resampling transitions based on gradient direction uncertainty from ensemble critics.

## Executive Summary
This paper addresses the inefficiency in policy improvement caused by gradient disagreements from ensemble critics in reinforcement learning. It introduces uncertainty of gradient directions as a metric to quantify disagreement and proposes von Mises-Fisher Experience Resampling (vMFER) to resample transitions based on this uncertainty. vMFER assigns higher sampling probability to transitions with lower uncertainty, improving policy improvement reliability. Experiments show vMFER significantly outperforms baselines like TD3 and SAC across Mujoco tasks, with over 10% average performance improvement. The method is compatible with ensemble-based algorithms and demonstrates robustness even when combined with Prioritized Experience Replay. Ablation studies confirm the importance of gradient direction reliability in policy optimization.

## Method Summary
vMFER introduces a novel approach to policy improvement by addressing gradient disagreements from ensemble critics. The method computes gradients for each transition from multiple critics, models these gradient directions using the von Mises-Fisher distribution, and quantifies uncertainty based on the concentration parameter. Transitions with lower uncertainty (more consistent gradient directions) are assigned higher sampling probabilities. This uncertainty-based resampling is integrated as a plugin to existing ensemble-based algorithms like TD3 and SAC, requiring only minor modifications to the training loop. The approach leverages the observation that transitions with consistent gradient directions across critics are more reliable for policy updates.

## Key Results
- vMFER achieves over 10% average performance improvement compared to TD3 and SAC across Mujoco tasks
- vMFER demonstrates robust performance gains across different ensemble sizes (2-4 critics)
- When combined with Prioritized Experience Replay, vMFER shows enhanced performance, indicating complementary benefits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient direction disagreement in ensemble critics causes unreliable policy updates.
- Mechanism: When multiple critics are used, each can produce a different Q-value for the same state-action pair, leading to different gradients for the actor update. These gradients may point in conflicting directions, making the update less reliable.
- Core assumption: The disagreement among gradient directions is a meaningful indicator of transition reliability.
- Evidence anchors:
  - [abstract]: "when using multiple critics, the actor in the policy improvement process can obtain different gradients."
  - [section 3.1]: "Despite this, existing Actor-Critic frameworks ... often merge these multiple gradients into a single gradient for policy improvement, disregarding the information that can be derived from the discrepancies among these gradients."
  - [corpus]: Missing direct evidence; weak corpus relevance to this specific claim.
- Break condition: If ensemble critics consistently agree on gradient directions, the uncertainty measure becomes uninformative.

### Mechanism 2
- Claim: Uncertainty of gradient directions can be modeled as a von Mises-Fisher distribution.
- Mechanism: The directions of gradients from different critics for the same transition are treated as samples from a von Mises-Fisher distribution. The concentration parameter of this distribution quantifies the uncertainty.
- Core assumption: Gradient directions for the same transition under ensemble critics follow a von Mises-Fisher distribution.
- Evidence anchors:
  - [section 3.3]: "we assume that the directions of the gradients are sampled from the von Mises-Fisher distribution."
  - [section 3.3]: "we use the von Mises-Fisher distribution [Fisher, 1953] to quantify such uncertainty associated with each transition."
  - [corpus]: Weak corpus relevance; the method is specialized.
- Break condition: If gradient directions do not follow a von Mises-Fisher distribution, the uncertainty quantification becomes inaccurate.

### Mechanism 3
- Claim: Resampling transitions based on gradient direction uncertainty improves policy improvement reliability.
- Mechanism: Transitions with lower uncertainty (more concentrated gradient directions) are assigned higher sampling probability during policy improvement. This ensures more reliable gradients are used for updates.
- Core assumption: Lower uncertainty in gradient directions implies higher reliability for policy improvement.
- Evidence anchors:
  - [abstract]: "vMFER assigns higher sampling probability to transitions with lower uncertainty, improving policy improvement reliability."
  - [section 3.4]: "Our objective is to independently fit von Mises-Fisher distributions to the gradients from each transition and evaluate their uncertainty levels to ascertain the probability of each transitionâ€™s utilization."
  - [corpus]: Weak corpus relevance; the method is specialized.
- Break condition: If resampling does not lead to improved policy performance, the assumption about uncertainty-reliability link is invalid.

## Foundational Learning

- Concept: Directional statistics and the von Mises-Fisher distribution
  - Why needed here: To model and quantify the uncertainty in gradient directions for transitions.
  - Quick check question: What is the von Mises-Fisher distribution, and why is it suitable for modeling gradient directions?

- Concept: Ensemble methods in reinforcement learning
  - Why needed here: Understanding how ensemble critics work and why they introduce gradient disagreements is crucial for grasping the problem vMFER addresses.
  - Quick check question: How do ensemble critics in RL algorithms like TD3 and SAC differ from single critics, and what problem does this introduce?

- Concept: Policy improvement vs. policy evaluation in actor-critic frameworks
  - Why needed here: vMFER specifically targets the policy improvement step, so understanding the distinction and the role of gradients in this step is essential.
  - Quick check question: In the actor-critic framework, what is the difference between policy evaluation and policy improvement, and where do gradients come into play?

## Architecture Onboarding

- Component map: Ensemble critics -> Actor network -> Replay buffer (with sampling factors) -> vMFER module

- Critical path:
  1. Collect transitions and store in replay buffer.
  2. Sample a mini-batch of transitions.
  3. For each transition, compute gradients from each critic.
  4. Calculate the uncertainty of gradient directions using von Mises-Fisher distribution.
  5. Update the sampling factor for each transition based on its uncertainty.
  6. Resample transitions based on updated sampling factors.
  7. Update the actor network using resampled transitions.

- Design tradeoffs:
  - Computational cost vs. performance gain: Calculating gradient direction uncertainties adds overhead, but can improve learning efficiency.
  - Ensemble size vs. uncertainty estimation: Larger ensembles provide more gradient samples for uncertainty estimation but increase computation.

- Failure signatures:
  - High variance in policy performance across runs.
  - Slow convergence or failure to improve beyond a certain point.
  - Overfitting to specific transitions due to incorrect uncertainty estimates.

- First 3 experiments:
  1. Implement vMFER with a simple ensemble (e.g., 2 critics) on a basic continuous control task (e.g., Pendulum) and compare to baseline.
  2. Vary the ensemble size and observe the impact on vMFER's performance and uncertainty estimation.
  3. Combine vMFER with Prioritized Experience Replay and evaluate the combined effect on a more complex task (e.g., Hopper).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the vMFER method perform in tasks with continuous action spaces of higher dimensionality (e.g., 20+ dimensions)?
- Basis in paper: [inferred] The paper mentions the scalability of vMF modeling gradient directions and discusses computational complexity, but does not provide experimental results for high-dimensional action spaces.
- Why unresolved: The experiments are limited to Mujoco tasks with relatively low-dimensional action spaces, leaving uncertainty about performance in higher-dimensional settings.
- What evidence would resolve it: Experiments comparing vMFER performance across a range of action space dimensionalities, particularly in tasks with 20+ dimensional continuous actions.

### Open Question 2
- Question: What is the impact of vMFER on sample efficiency in environments with extremely sparse rewards (e.g., reward only given after 1000+ steps)?
- Basis in paper: [inferred] The paper mentions potential applications to sparse reward scenarios and combines vMFER with Hindsight Experience Replay, but does not provide results for extremely sparse reward environments.
- Why unresolved: The experiments focus on dense reward environments and moderately sparse rewards (HER experiments), not extremely sparse scenarios that would stress-test sample efficiency.
- What evidence would resolve it: Comparative experiments measuring sample efficiency (steps to threshold performance) between vMFER and baselines in environments with exponentially increasing reward sparsity.

### Open Question 3
- Question: How sensitive is vMFER's performance to the choice of ensemble size when the resampling probability is determined by uncertainty?
- Basis in paper: [explicit] The ablation study shows that varying ensemble size has minimal effect on vMFER when resampling probability is determined by uncertainty, but doesn't explore sensitivity.
- Why unresolved: The paper only tests a few ensemble sizes and doesn't systematically analyze the sensitivity of performance to ensemble size variations under the uncertainty-based resampling method.
- What evidence would resolve it: A comprehensive sensitivity analysis showing performance curves across a wide range of ensemble sizes (e.g., 2-50) when using uncertainty-based resampling.

## Limitations
- The method assumes gradient direction disagreements reliably indicate transition uncertainty, which may not hold in all scenarios
- Computational overhead from uncertainty estimation and resampling could limit scalability to larger problems
- The von Mises-Fisher distribution assumption for gradient directions requires further empirical validation

## Confidence
- Mechanism 1 (gradient disagreement as uncertainty indicator): Medium - supported by theoretical reasoning but limited empirical validation
- Mechanism 2 (vMFD modeling of gradient directions): Low - theoretical justification present but no empirical validation of distributional fit
- Mechanism 3 (resampling improves reliability): High - demonstrated through ablation studies and performance comparisons

## Next Checks
1. Test vMFER's performance degradation when ensemble critics are trained to agree (remove gradient disagreement) to validate the core assumption
2. Conduct ablation studies varying ensemble size and measuring the impact on uncertainty estimation quality and policy performance
3. Analyze computational overhead scaling by implementing vMFER on larger state-action spaces (e.g., Humanoid task) to verify practical applicability limits