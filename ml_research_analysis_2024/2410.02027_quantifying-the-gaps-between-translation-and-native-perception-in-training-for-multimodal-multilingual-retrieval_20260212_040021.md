---
ver: rpa2
title: Quantifying the Gaps Between Translation and Native Perception in Training
  for Multimodal, Multilingual Retrieval
arxiv_id: '2410.02027'
source_url: https://arxiv.org/abs/2410.02027
tags:
- captions
- german
- english
- translation
- differences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper quantifies the gaps between translation and native perception
  in multilingual multimodal retrieval. The authors compare German image-text retrieval
  performance when training on native German captions versus German captions translated
  from English (both human and machine translation).
---

# Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval

## Quick Facts
- **arXiv ID:** 2410.02027
- **Source URL:** https://arxiv.org/abs/2410.02027
- **Reference count:** 17
- **Primary result:** Significant performance gaps exist between native and translated captions in multilingual multimodal retrieval, with proposed augmentation strategies improving over naive translation but not fully closing the gap.

## Executive Summary
This paper quantifies the performance gaps between native and translated captions in multilingual multimodal retrieval systems. The authors systematically compare German image-text retrieval performance when training on native German captions versus German captions translated from English, using both human and machine translation. They find substantial performance gaps favoring native captions. To address this, they propose three caption augmentation strategies using paraphrasing techniques before translation: hypernymization, random paraphrasing with an LLM, and targeted paraphrasing using reference captions. These strategies improve performance over naive translation, with a combined approach yielding a mean recall improvement of 1.3. However, a gap remains between translated and native captions, indicating this as an open challenge for the community.

## Method Summary
The authors conduct experiments on German image-text retrieval by training models on three caption sources: native German captions, German captions translated from English (both human and machine translation), and augmented translated captions. They evaluate multiple multimodal retrieval models across different augmentation strategies, including hypernymization (replacing specific terms with broader categories), random paraphrasing using LLMs, and targeted paraphrasing guided by reference captions. The performance is measured using recall metrics at different cutoffs, comparing against a baseline of models trained on native German captions.

## Key Results
- Native German captions outperform both human and machine-translated German captions in image-text retrieval tasks
- Three augmentation strategies (hypernymization, random paraphrasing, and targeted paraphrasing) improve performance over naive translation
- Combined augmentation approach achieves a mean recall improvement of 1.3 over baseline translation
- A persistent performance gap remains between augmented translated captions and native German captions

## Why This Works (Mechanism)
The performance gaps arise because translation processes lose or distort nuanced information that native speakers naturally encode in captions. Translation from English to German (or vice versa) often misses cultural context, specific visual details, or subtle linguistic cues that are critical for accurate image-text matching. The augmentation strategies work by enriching the translated captions with additional semantic information before translation, helping to preserve important details that would otherwise be lost.

## Foundational Learning

**Multimodal Retrieval Systems**
- *Why needed:* Understanding how models match images and text across languages
- *Quick check:* Can identify key components (image encoder, text encoder, similarity metric) and their interactions

**Cross-lingual Transfer Learning**
- *Why needed:* Grasping how knowledge transfers between languages in multimodal contexts
- *Quick check:* Can explain zero-shot cross-lingual transfer and its limitations

**Paraphrasing Techniques**
- *Why needed:* Understanding how semantic content can be preserved while changing surface form
- *Quick check:* Can distinguish between different paraphrasing approaches and their effects

**Machine Translation Evaluation**
- *Why needed:* Knowing how to measure translation quality beyond BLEU scores
- *Quick check:* Can identify task-specific translation evaluation metrics

## Architecture Onboarding

**Component Map**
Image Encoder -> Text Encoder -> Similarity Function -> Retrieval Output

**Critical Path**
The most critical path is from caption generation (translation/augmentation) through the text encoder to the similarity function, as caption quality directly impacts retrieval performance.

**Design Tradeoffs**
Translation quality vs. computational cost: Machine translation is faster but less accurate than human translation. Augmentation strategies add preprocessing overhead but improve downstream performance.

**Failure Signatures**
- Significant performance drop when switching from native to translated captions
- Inconsistent retrieval results across different image categories
- Poor performance on culturally-specific or visually subtle content

**First Experiments**
1. Compare retrieval performance using native vs. translated captions on a small validation set
2. Test each augmentation strategy individually to identify the most effective approach
3. Evaluate the impact of different translation tools (Google Translate vs. human translation)

## Open Questions the Paper Calls Out
The paper identifies the remaining gap between augmented translated captions and native German captions as an open challenge for the community, suggesting that current augmentation strategies are insufficient to fully bridge this divide.

## Limitations
- Limited to German as a single target language, limiting generalizability to other languages with different linguistic structures
- Results may vary with different translation tools or paraphrasing models not tested in the study
- Evaluation conducted on a specific image-text retrieval dataset, which may not generalize to other domains

## Confidence
- **High:** The existence of performance gaps between native and translated captions
- **High:** The effectiveness of the proposed augmentation strategies in improving performance
- **Medium:** The completeness of the proposed solution in closing the gap between native and translated captions

## Next Checks
1. Replicate the experiments with additional target languages, particularly those with significantly different linguistic structures from German, to assess generalizability.
2. Test the augmentation strategies using alternative translation tools and paraphrasing models to evaluate robustness to methodological variations.
3. Conduct experiments on different multimodal datasets (e.g., different image domains or retrieval tasks) to determine if the findings hold across diverse data distributions.