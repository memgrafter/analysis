---
ver: rpa2
title: 'Integrating Social Determinants of Health into Knowledge Graphs: Evaluating
  Prediction Bias and Fairness in Healthcare'
arxiv_id: '2412.00245'
source_url: https://arxiv.org/abs/2412.00245
tags:
- graph
- sdoh
- knowledge
- bias
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the integration of Social Determinants of
  Health (SDoH) into biomedical knowledge graphs and the resulting fairness concerns
  in healthcare predictions. The researchers constructed an SDoH-enriched knowledge
  graph using the MIMIC-III dataset and PrimeKG, incorporating disease, drug, and
  SDoH information.
---

# Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare

## Quick Facts
- **arXiv ID**: 2412.00245
- **Source URL**: https://arxiv.org/abs/2412.00245
- **Reference count**: 34
- **Primary result**: Proposed method significantly reduced bias across five SDoH categories while maintaining MRR around 0.36

## Executive Summary
This study addresses the integration of Social Determinants of Health (SDoH) into biomedical knowledge graphs and the resulting fairness concerns in healthcare predictions. The researchers constructed an SDoH-enriched knowledge graph using the MIMIC-III dataset and PrimeKG, incorporating disease, drug, and SDoH information. They introduced a novel fairness formulation for graph embeddings focusing on invariance with respect to sensitive SDoH information, specifically targeting bias in drug-disease link predictions. To mitigate detected biases, the authors proposed a post-processing method that strategically reweights edges connected to SDoH factors, balancing their influence on graph representations.

## Method Summary
The researchers built an SDoH knowledge graph by integrating MIMIC-III patient data, MIMIC-SBDH SDoH annotations, and PrimeKG phenotype information. They trained a heterogeneous-GCN model for drug-disease link prediction and developed a novel fairness formulation based on statistical independence from sensitive SDoH factors. The bias detection method used Ti-free drug nodes (drugs with no direct SDoH connections) to isolate SDoH effects. The proposed post-processing de-biasing approach strategically reweighted edges between SDoH and drug nodes to reduce bias while monitoring predictive performance through MRR.

## Key Results
- Significant bias reduction across five SDoH categories (Education, Economics, Environment, Community Present/Absent)
- Maintained predictive accuracy with MRR values around 0.36 after bias mitigation
- Demonstrated effectiveness of edge reweighting strategy for balancing SDoH influence on graph representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Re-weighting edges between SDoH nodes and drug nodes reduces bias in link predictions by diminishing the disproportionate influence of sensitive social factors.
- Mechanism: By adding learnable scalar weights to the edges in the adjacency matrix, the GCN can modulate the contribution of each edge during message passing. This allows the model to down-weight edges connected to SDoH nodes that may introduce bias, thereby making predictions more invariant to these sensitive factors.
- Core assumption: The influence of SDoH on link prediction can be modeled as a function of edge weights, and that adjusting these weights can reduce bias without harming overall predictive performance.
- Evidence anchors:
  - [abstract] "To mitigate these biases, we propose a post-processing method that strategically reweights edges connected to SDoHs, balancing their influence on graph representations."
  - [section] "To address this inherent bias in traditional GCNs, we proposed a re-weighting strategy on the edges between SDoHs and drugs."
  - [corpus] Weak: No direct corpus evidence for re-weighting SDoH edges specifically, though related work exists on edge weighting for fairness in graphs.
- Break condition: If SDoH influence is not primarily mediated through edge weights (e.g., if node features dominate), re-weighting may not reduce bias effectively.

### Mechanism 2
- Claim: Defining fairness as invariance with respect to sensitive SDoH factors enables detection of bias in drug-disease link predictions.
- Mechanism: The proposed fairness notion requires that the probability of a drug-disease link be statistically independent of the presence of sensitive SDoH connections. Bias is measured as the difference in predicted scores when SDoH information is toggled, allowing targeted detection.
- Core assumption: A simple demographic parity-style independence criterion is sufficient to capture meaningful fairness violations in link prediction tasks.
- Evidence anchors:
  - [abstract] "We introduce a novel fairness formulation for graph embeddings, focusing on invariance with respect to sensitive SDoH information."
  - [section] "Formally, given a drug u and a disease v, for the edge between u and v, the score (probability) should be independent with sensitive SDoH information T âˆ—."
  - [corpus] Weak: Most related work focuses on node-attribute fairness; few directly adapt demographic parity to link prediction with SDoH.
- Break condition: If SDoH influences outcomes through complex interactions not captured by simple edge toggling, the bias metric may under- or over-estimate true disparities.

### Mechanism 3
- Claim: Using Ti-free drug nodes isolates the effect of sensitive SDoH factors for bias measurement.
- Mechanism: By selecting drugs that have no connections to a given SDoH category, and then artificially connecting them to either presence or absence states, the method measures how much the predictions change purely due to that SDoH factor.
- Core assumption: Ti-free drugs truly have no embedded SDoH influence, so differences in predictions arise solely from the manipulated connections.
- Evidence anchors:
  - [section] "We then define Ti-free drug nodes as the drug nodes which are not connected with any nodes in Ti."
  - [section] "To detect the bias with respect to sensitive SDoH Ti = {w0, w1}, we first collect Ti-free drug nodes..."
  - [corpus] Weak: No direct corpus evidence for the Ti-free drug node isolation strategy; this appears to be a novel methodological choice.
- Break condition: If SDoH effects propagate through multi-hop paths not severed by removing direct edges, the Ti-free assumption may be violated.

## Foundational Learning

- Graph Neural Networks (GCNs)
  - Why needed here: The study relies on GCNs to embed nodes in the knowledge graph and perform link prediction between drugs and diseases.
  - Quick check question: How does a GCN update a node's representation using its neighbors' features and the graph structure?

- Social Determinants of Health (SDoH)
  - Why needed here: SDoH factors are the sensitive attributes whose influence on predictions the study seeks to detect and mitigate.
  - Quick check question: What are examples of SDoH categories used in the study, and how are they encoded as nodes in the knowledge graph?

- Fairness Notions in Machine Learning
  - Why needed here: The study defines a new fairness metric tailored to graph link prediction, based on independence from sensitive SDoH information.
  - Quick check question: How does the proposed fairness criterion differ from traditional demographic parity, and why is it adapted for graph settings?

## Architecture Onboarding

- Component map:
  MIMIC-III dataset -> MIMIC-SBDH SDoH annotations -> PrimeKG phenotypes -> SDoH knowledge graph -> Heterogeneous-GCN model -> Bias detection pipeline -> Bias mitigation module

- Critical path:
  1. Build SDoH knowledge graph from MIMIC-III, MIMIC-SBDH, and PrimeKG.
  2. Train heterogeneous GCN on drug-disease links.
  3. Detect bias for each SDoH category using Ti-free drug nodes and score comparison.
  4. Apply re-weighting strategy to reduce bias while monitoring MRR.

- Design tradeoffs:
  - Fairness vs. accuracy: Re-weighting can reduce bias but risks degrading link prediction performance if over-applied.
  - Granularity of SDoH: More detailed SDoH categories increase fairness granularity but also model complexity and data sparsity.
  - Computational cost: Iterative bias detection and re-weighting increases training time versus a single-pass model.

- Failure signatures:
  - MRR drops significantly after re-weighting: over-suppression of SDoH edges.
  - Bias reduction is minimal: re-weighting insufficient or Ti-free assumption violated.
  - Model overfitting to training graph: lack of regularization or small dataset size.

- First 3 experiments:
  1. Train baseline GCN on the SDoH knowledge graph; measure MRR and bias for each SDoH category.
  2. Apply bias detection to identify the most biased SDoH category; visualize edge weight distributions.
  3. Apply re-weighting only for the most biased category; compare post-reweighting MRR and bias to baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the bias detection and mitigation methods be extended to handle more than two sensitive SDoH categories simultaneously?
- Basis in paper: [explicit] The authors mention that their current method considers only two nodes in the sensitive SDoH factor T*, and note that "This can be extended for more than two nodes."
- Why unresolved: The paper demonstrates the method with binary SDoH values (e.g., True/False) but acknowledges the need for extension to handle multiple values within a single SDoH category or multiple categories simultaneously.
- What evidence would resolve it: Experimental results showing the effectiveness of the method when extended to multi-category SDoH factors, with quantitative comparisons of bias reduction across different configurations.

### Open Question 2
- Question: How would the proposed fairness framework perform on knowledge graphs constructed from more diverse healthcare datasets beyond MIMIC-III?
- Basis in paper: [explicit] The authors acknowledge that "The primary limitation lies in the dataset used, which, while comprehensive, may not fully represent the diversity of global populations and healthcare systems."
- Why unresolved: The current study only validates the approach on the MIMIC-III dataset, limiting generalizability to other healthcare contexts and populations.
- What evidence would resolve it: Comparative studies applying the same methodology to knowledge graphs built from different healthcare datasets (e.g., from different countries, healthcare systems, or demographic groups) with performance and fairness metrics.

### Open Question 3
- Question: What is the optimal balance between bias reduction and predictive accuracy when applying different reweighting strategies across multiple SDoH categories?
- Basis in paper: [explicit] The authors report that their method achieved significant bias reduction while maintaining MRR values around 0.36, but do not explore the trade-off space or compare different reweighting strategies.
- Why unresolved: The paper presents a single reweighting approach and shows it maintains accuracy, but doesn't investigate whether alternative strategies might achieve better trade-offs or how the balance varies across different SDoH categories.
- What evidence would resolve it: Systematic experiments comparing multiple reweighting strategies, their impact on different fairness metrics, and their effects on various predictive performance measures across different SDoH categories.

## Limitations
- The study relies on a single dataset (MIMIC-III) and its associated SDoH annotations, limiting generalizability to other healthcare settings or populations.
- The fairness definition based on statistical independence may not fully capture the complex causal pathways through which SDoH influence health outcomes.
- The edge re-weighting approach is post-hoc and heuristic; its long-term stability and generalization across datasets remain unproven.

## Confidence
- **High confidence**: The methodology for constructing the SDoH-enriched knowledge graph is sound, and the experimental results showing bias reduction while maintaining MRR are clearly presented.
- **Medium confidence**: The fairness formulation and bias detection pipeline are novel but lack direct validation against ground truth bias levels in the dataset.
- **Medium confidence**: The post-processing re-weighting strategy is effective in this context but its optimality and robustness to different SDoH distributions is uncertain.

## Next Checks
1. Test the bias detection and mitigation pipeline on an independent healthcare dataset with SDoH annotations to assess generalizability.
2. Perform ablation studies to isolate the contribution of edge re-weighting versus other potential interventions (e.g., adversarial debiasing, data augmentation).
3. Evaluate whether the fairness gains persist under domain shift, such as when applying the model to populations with different SDoH distributions or healthcare systems.