---
ver: rpa2
title: Do causal predictors generalize better to new domains?
arxiv_id: '2402.09891'
source_url: https://arxiv.org/abs/2402.09891
tags:
- causal
- mean
- time
- measured
- mask
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study empirically tests whether models trained on causal features
  generalize better across domains than models using all available features. Using
  16 prediction tasks from diverse domains, the authors find that models trained on
  all features consistently outperform causal predictors in both in-domain and out-of-domain
  accuracy.
---

# Do causal predictors generalize better to new domains?

## Quick Facts
- arXiv ID: 2402.09891
- Source URL: https://arxiv.org/abs/2402.09891
- Reference count: 40
- Primary result: Models using all features outperform causal feature models in both in-domain and out-of-domain accuracy across 16 diverse tasks

## Executive Summary
This study empirically tests whether models trained on causal features generalize better across domains than models using all available features. Using 16 prediction tasks from diverse domains, the authors find that models trained on all features consistently outperform causal predictors in both in-domain and out-of-domain accuracy. Adding anti-causal features to causal sets often improves out-of-domain performance. Causal machine learning methods and causal discovery algorithms do not perform better than standard models on causal features. Extensive robustness checks confirm these findings. The authors conclude that in typical tabular datasets, using all available features is preferable for domain generalization, challenging the assumed superiority of causal modeling.

## Method Summary
The study evaluates 16 prediction tasks from diverse domains using multiple datasets. For each task, feature sets are defined based on domain knowledge: all features, causal features, arguably causal features, and anti-causal features. Data is split into in-domain and out-of-domain sets. Multiple machine learning models (XGBoost, LightGBM, FT Transformer, SAINT) are trained on each feature set using hyperparameter optimization. Performance is evaluated using in-domain and out-of-domain accuracy, with shift gaps computed to measure performance differences across domains. The study also examines Pareto frontiers and conducts extensive robustness checks by removing features one at a time and sampling random subsets.

## Key Results
- Models using all available features consistently outperform models using only causal features in both in-domain and out-of-domain accuracy
- Adding anti-causal features to causal feature sets improves out-of-domain performance in 5/5 tested tasks
- Causal machine learning methods and causal discovery algorithms do not outperform standard models trained on causal features
- Results hold across 16 diverse tasks from health, employment, education, social benefits, and politics domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Models trained on all available features outperform models trained only on causal features in both in-domain and out-of-domain accuracy.
- Mechanism: The theoretical invariance assumption underlying causal feature selection may not hold in typical tabular datasets. Standard models can leverage spurious correlations or proxy features that are predictive in multiple domains, compensating for distributional shifts that affect causal relationships.
- Core assumption: All domains are positive reweightings of one another, making the Bayes optimal predictor with respect to classification error in one domain also optimal in any other domain.
- Evidence anchors:
  - [abstract]: "Without exception, we find that predictors using all available features, regardless of causality, have better in-domain and out-of-domain accuracy than predictors using causal features."
  - [section]: "Unlike causal machine learning researchers, social scientists generally see no reason to believe in the universality of causal relationships."
  - [corpus]: Weak corpus evidence for this specific mechanism. Related papers discuss causality and generalization but do not directly support the specific claim about all-features outperforming causal features.

### Mechanism 2
- Claim: Adding anti-causal features to causal features improves out-of-domain performance.
- Mechanism: Anti-causal features, while influenced by the target, may contain information about the target's future state or external factors that affect the target across domains. Including them provides additional predictive signal that compensates for domain shifts.
- Core assumption: Anti-causal features contain domain-invariant information about the target's future state or external factors.
- Evidence anchors:
  - [abstract]: "Adding anti-causal features—i.e., features caused by the target variable—to the set of causal features improves out-of-domain performance."
  - [section]: "It is therefore astounding that the out-of-domain performance of the (arguably) causal features is improved by adding anti-causal features (5/5 tasks)."
  - [corpus]: Weak corpus evidence. Related papers discuss causality and generalization but do not directly support the specific claim about anti-causal features improving performance.

### Mechanism 3
- Claim: Causal machine learning methods and causal discovery algorithms do not perform better than standard models on causal features.
- Mechanism: The assumptions underlying causal machine learning methods (e.g., invariance of causal mechanisms, correct causal structure) are unlikely to be met in typical tabular datasets. Standard models trained on all features can capture complex relationships that causal methods miss.
- Core assumption: The assumptions of existing theoretical work on causal machine learning are unlikely to be met in the tabular data settings studied.
- Evidence anchors:
  - [abstract]: "In addition, we show that recent causal machine learning methods for domain generalization do not perform better in our evaluation than standard predictors trained on the set of causal features."
  - [section]: "Likewise, causal discovery algorithms either fail to run or select causal variables that perform no better than our selection."
  - [corpus]: Weak corpus evidence. Related papers discuss causality and generalization but do not directly support the specific claim about causal machine learning methods not outperforming standard models.

## Foundational Learning

- Concept: Causal inference and the invariance assumption
  - Why needed here: Understanding the theoretical basis for causal feature selection and why it may fail in practice.
  - Quick check question: What is the invariance assumption, and why is it important for causal feature selection?

- Concept: Domain generalization and distribution shift
  - Why needed here: Understanding how models generalize to new domains and the challenges posed by distribution shift.
  - Quick check question: What is domain generalization, and what are the main challenges in achieving it?

- Concept: Feature selection and its impact on model performance
  - Why needed here: Understanding how different feature selections (all features, causal features, anti-causal features) affect model performance in different domains.
  - Quick check question: How does feature selection impact model performance in in-domain and out-of-domain settings?

## Architecture Onboarding

- Component map: Data preprocessing -> Feature selection -> Model training -> Evaluation -> Analysis
- Critical path: Data preprocessing → Feature set definition → In-domain/out-of-domain split → Model training with hyperparameter optimization → Performance evaluation across domains → Pareto frontier analysis
- Design tradeoffs: Using all features maximizes predictive performance but sacrifices interpretability; using only causal features maintains causal interpretability but may lose predictive power; adding anti-causal features is a middle ground that sometimes improves generalization
- Failure signatures: If causal features or anti-causal features significantly outperform all features, it may indicate that the assumptions of causal machine learning methods are met in the dataset. Conversely, if all features consistently underperform, it may suggest issues with data quality or feature engineering.
- First 3 experiments:
  1. Train a baseline model on all features and evaluate its in-domain and out-of-domain performance.
  2. Train a model