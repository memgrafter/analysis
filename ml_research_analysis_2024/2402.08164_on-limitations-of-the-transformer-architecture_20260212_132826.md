---
ver: rpa2
title: On Limitations of the Transformer Architecture
arxiv_id: '2402.08164'
source_url: https://arxiv.org/abs/2402.08164
tags:
- function
- composition
- xavier
- problem
- complexity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes fundamental limitations of the Transformer
  architecture for compositional reasoning tasks. Using Communication Complexity,
  the authors prove that a single Transformer layer cannot reliably compute function
  composition when domain sizes exceed embedding dimensions and precision constraints.
---

# On Limitations of the Transformer Architecture

## Quick Facts
- arXiv ID: 2402.08164
- Source URL: https://arxiv.org/abs/2402.08164
- Authors: Binghui Peng; Srini Narayanan; Christos Papadimitriou
- Reference count: 10
- Key outcome: This paper establishes fundamental limitations of the Transformer architecture for compositional reasoning tasks using Communication Complexity theory.

## Executive Summary
This paper proves that Transformers have fundamental limitations in compositional reasoning tasks. Using Communication Complexity theory, the authors show that a single Transformer layer cannot reliably compute function composition when domain sizes exceed embedding dimensions and precision constraints. They also demonstrate that Chain-of-Thought prompting requires exponentially many steps for iterated composition, and that multi-layer Transformers cannot perform several fundamental computational tasks under widely accepted complexity assumptions.

## Method Summary
The authors employ theoretical analysis using Communication Complexity to establish information-theoretic lower bounds on Transformer capabilities. They prove that a single Transformer layer cannot solve function composition problems when the information requirements exceed the layer's computational capacity (H(d+1)p < n log n). For multi-layer Transformers, they use complexity theory arguments to show that Transformer computation belongs to log-space complexity class L, while fundamental compositional tasks require more computational power.

## Key Results
- Single Transformer layer fails to compute function composition correctly with probability at least R/(3n log n) when n log n > H(d+1)p
- Chain-of-Thought prompting requires Ω(√n/(Hdp)) steps to solve iterated composition problems
- Multi-layer Transformers cannot solve circuit evaluation, 2-SAT, and Horn SAT problems under widely accepted complexity assumptions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Single Transformer layer cannot reliably compute function composition when domain sizes exceed embedding dimensions and precision constraints.
- Mechanism: Communication Complexity lower bounds show that Faye cannot communicate sufficient information about function f to Xavier with fewer than n log n bits, while Transformer attention computation requires fewer bits (H(d+1)p < n log n).
- Core assumption: The proof relies on comparing information-theoretic communication requirements with the computational capacity of Transformer attention mechanisms.
- Evidence anchors:
  - [abstract]: "Transformers fail to solve function composition correctly with probability at least R/(3n log n) when n log n > H(d+1)p"
  - [section]: "Theorem 1. Consider a function composition problem with input domain size |A| = |B| = |C| = n, and an H-headed transformer layer L with embedding dimension d and computation precision p, and assume that H(d+1)p < n log n. Then L cannot solve correctly the function composition problem."
  - [corpus]: Weak - related papers focus on Transformer expressivity and limitations but don't provide direct evidence for this specific communication complexity argument.

### Mechanism 2
- Claim: Chain-of-Thought prompting requires Ω(√n/(Hdp)) steps to solve iterated composition problems.
- Mechanism: Reduction from pointer chasing problem shows that CoT steps must simulate communication rounds, and each round can only transmit limited information (H(d+1)p bits per step).
- Core assumption: The number of CoT steps needed scales with the communication complexity of the underlying pointer chasing problem.
- Evidence anchors:
  - [abstract]: "The authors also prove that Chain-of-Thought prompting requires Ω(√n/(Hdp)) steps to solve iterated composition"
  - [section]: "Theorem 2. Let H be the number of attention heads, d the embedding dimension, p the computation precision, and n be the domain size of the iterated composition problem. A Transformer layer requires Ω(√n/(Hdp)) CoT steps for answering correctly iterated function composition prompts."
  - [corpus]: Weak - related papers discuss Transformer limitations but don't provide evidence for this specific CoT complexity result.

### Mechanism 3
- Claim: Multi-layer Transformers cannot perform several fundamental computational tasks (circuit evaluation, 2-SAT, Horn SAT) under widely accepted complexity assumptions.
- Mechanism: Multi-layer Transformer computation belongs to logarithmic space complexity class L, while these problems are NL-complete or P-complete, requiring more computational power unless L = NL or L = P.
- Core assumption: Computational complexity theory separations (L ≠ NL, L ≠ P) hold, and Transformer computation is indeed log-space bounded.
- Evidence anchors:
  - [abstract]: "multi-layer Transformers cannot perform several fundamental computational tasks underlying compositionality (circuit evaluation, 2-SAT, Horn SAT) under widely accepted complexity assumptions"
  - [section]: "Theorem 3. The four problems of Derivability, 2-SAT, Horn SAT, and Circuit evaluation cannot be solved by multi-layer Transformers unless L = NL."
  - [corpus]: Weak - related papers discuss Transformer expressivity but don't provide evidence for these specific complexity class separations.

## Foundational Learning

- Concept: Communication Complexity theory
  - Why needed here: Provides the theoretical foundation for proving information-theoretic lower bounds on Transformer capabilities
  - Quick check question: If two agents need to compute f(g(x)) and can only communicate B bits, what's the minimum B needed to guarantee correct computation for all possible functions?

- Concept: Computational Complexity classes (L, NL, P)
  - Why needed here: Establishes the theoretical framework for comparing Transformer computational capabilities with known hard problems
  - Quick check question: What's the relationship between log-space computation and non-deterministic log-space computation, and why does this matter for Transformer limitations?

- Concept: Function composition and iterated composition
  - Why needed here: These are the specific tasks being analyzed for Transformer limitations
  - Quick check question: Given functions f: A→B and g: B→C, what's the formal definition of the composition f∘g?

## Architecture Onboarding

- Component map: Input tokens → Self-attention computation (yi) → Combining function Φ → Next layer input → Final output
- Critical path: Input tokens → Self-attention computation (yi) → Combining function Φ → Next layer input → Final output
- Design tradeoffs: Embedding dimension d vs. number of attention heads H vs. computation precision p
- Failure signatures: Incorrect function composition answers, need for excessive CoT steps, inability to solve compositionality tasks
- First 3 experiments:
  1. Test function composition with small domains where H(d+1)p ≥ n log n to verify when limitation breaks
  2. Measure CoT steps required for iterated composition as domain size increases
  3. Test 2-SAT and Horn SAT problems of increasing size to observe when Transformer performance degrades

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific attention mechanisms or architectural modifications could enable Transformers to reliably perform function composition?
- Basis in paper: [explicit] The paper proves that a single Transformer layer cannot reliably compute function composition when domain sizes exceed embedding dimensions and precision constraints.
- Why unresolved: The proof identifies fundamental limitations in the softmax computation and information bottleneck, but doesn't explore potential architectural modifications that could overcome these limitations while maintaining Transformer efficiency.
- What evidence would resolve it: Experimental results showing modified Transformer architectures that can reliably solve function composition tasks beyond the theoretical limits, with analysis of which modifications specifically address the identified bottlenecks.

### Open Question 2
- Question: What is the practical threshold size at which Transformers begin to fail on function composition tasks, and how does this scale with embedding dimension and precision?
- Basis in paper: [inferred] The paper's theoretical results show failure when n log n > H(d+1)p, but this is asymptotic and doesn't indicate practical failure points.
- Why unresolved: The theoretical bounds are asymptotic and don't translate directly to practical scenarios where domain sizes are finite and embedding dimensions are in the hundreds.
- What evidence would resolve it: Systematic empirical studies mapping the exact domain sizes and parameter configurations where Transformers fail on composition tasks, parameterized by embedding dimension and precision.

### Open Question 3
- Question: Can alternative prompting strategies beyond Chain-of-Thought effectively mitigate Transformer limitations on compositional reasoning?
- Basis in paper: [explicit] The paper shows that CoT requires Ω(√n/(Hdp)) steps for iterated composition, suggesting it's not a complete solution.
- Why unresolved: The paper only analyzes CoT's effectiveness and doesn't explore other prompting strategies that might better address the underlying architectural limitations.
- What evidence would resolve it: Comparative empirical studies of various prompting strategies (including novel approaches) on composition tasks, measuring both success rates and prompt complexity requirements.

## Limitations

- The theoretical limitations may only manifest under extreme conditions that don't occur in practical applications
- Complexity class separations (L ≠ NL, L ≠ P) are widely believed but unproven assumptions
- The paper focuses on inherent architectural constraints without exploring potential architectural modifications or alternative training strategies

## Confidence

**High Confidence:** The single-layer Transformer limitations for function composition have strong theoretical grounding through communication complexity arguments.

**Medium Confidence:** The Chain-of-Thought limitations are logically derived but depend heavily on how CoT implementation maps to the theoretical model.

**Low Confidence:** The multi-layer Transformer complexity class separations rely on unproven complexity theory assumptions.

## Next Checks

1. **Empirical Boundary Testing:** Systematically vary domain size n, embedding dimension d, precision p, and attention heads H to empirically identify when function composition accuracy degrades.

2. **CoT Step Analysis:** Measure actual CoT steps required for iterated composition tasks across different domain sizes and precision levels, comparing empirical results with the predicted Ω(√n/(Hdp)) scaling relationship.

3. **Complexity Class Simulation:** Design specific circuit evaluation, 2-SAT, and Horn SAT problems that push Transformers to their theoretical limits, testing whether performance degrades in ways consistent with log-space bounded computation constraints.