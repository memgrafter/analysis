---
ver: rpa2
title: 'Long-Term Fairness Inquiries and Pursuits in Machine Learning: A Survey of
  Notions, Methods, and Challenges'
arxiv_id: '2406.06736'
source_url: https://arxiv.org/abs/2406.06736
tags:
- fairness
- long-term
- learning
- conference
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a comprehensive overview of long-term fairness
  in machine learning, addressing the limitations of static fairness approaches. It
  proposes a taxonomy categorizing long-term fairness into four problem settings:
  dynamic modeling, distribution shift, delayed impact, and performative prediction.'
---

# Long-Term Fairness Inquiries and Pursuits in Machine Learning: A Survey of Notions, Methods, and Challenges

## Quick Facts
- arXiv ID: 2406.06736
- Source URL: https://arxiv.org/abs/2406.06736
- Reference count: 24
- Primary result: Comprehensive survey proposing taxonomy of long-term fairness in ML with four problem settings

## Executive Summary
This survey provides a comprehensive overview of long-term fairness in machine learning, addressing the limitations of static fairness approaches. It proposes a taxonomy categorizing long-term fairness into four problem settings: dynamic modeling, distribution shift, delayed impact, and performative prediction. The paper reviews various fairness notions, including effort-based, cumulative group, meritocratic, and causality-motivated fairness. Mitigation techniques leveraging reinforcement learning, bandits, and causal modeling are discussed, along with evaluation methods in applications like credit lending and recommender systems. Key challenges include capturing real-world dynamics, addressing intersectional identities, and developing efficient evaluation methods. The survey highlights the need for approaches that balance short-term and long-term fairness while considering complex system interactions and stakeholder interests.

## Method Summary
The survey methodology involves conducting a comprehensive search for relevant papers using established approaches, including curating seed papers, developing keywords, searching proceedings of relevant conferences and journals, and following citation trails. The survey presents a high-level taxonomy for long-term fairness, examines long-term fair learning methods in multiple standard problem settings and evaluations, and discusses open challenges and future directions. The paper analyzes and categorizes identified papers based on problem settings (dynamic modeling, distribution shift, delayed impact, performative prediction), fairness notions (effort-based, cumulative group, meritocratic, causality-motivated), mitigation techniques (reinforcement learning, bandits, causal modeling), and evaluation methods.

## Key Results
- Proposes taxonomy of long-term fairness into four problem settings: dynamic modeling, distribution shift, delayed impact, and performative prediction
- Reviews fairness notions including effort-based, cumulative group, meritocratic, and causality-motivated fairness
- Discusses mitigation techniques leveraging reinforcement learning, bandits, and causal modeling
- Identifies key challenges including capturing real-world dynamics, addressing intersectional identities, and developing efficient evaluation methods

## Why This Works (Mechanism)
The survey works by providing a comprehensive framework that bridges the gap between short-term static fairness approaches and the complex dynamics of real-world decision-making systems. By categorizing long-term fairness into distinct problem settings, it allows researchers and practitioners to identify which aspects of fairness dynamics are most relevant to their specific applications. The mechanism of connecting fairness notions to mitigation techniques through the lens of problem settings enables a systematic approach to addressing fairness over time.

## Foundational Learning
1. **Static vs Dynamic Fairness** - Understanding the difference between one-time fairness interventions and fairness that evolves over time. This is needed to recognize why traditional fairness approaches may fail in dynamic systems. Quick check: Can the fairness measure capture changes in system dynamics over multiple time steps?

2. **Performative Prediction** - The concept that ML models can influence the very distribution they aim to predict. This is crucial for understanding how fairness interventions can have unintended consequences. Quick check: Does the model account for how its predictions might change future data distributions?

3. **Causal Fairness Notions** - Understanding how causal relationships between variables affect fairness assessments. This is needed to distinguish between fair and unfair disparities that arise from different causal pathways. Quick check: Are the causal assumptions and structure clearly specified in the fairness model?

## Architecture Onboarding

Component Map: Problem Setting → Fairness Notion → Mitigation Technique → Evaluation Method

Critical Path: The critical path begins with identifying the appropriate problem setting (dynamic modeling, distribution shift, delayed impact, or performative prediction), then selecting relevant fairness notions, choosing suitable mitigation techniques, and finally implementing appropriate evaluation methods.

Design Tradeoffs: The main tradeoffs involve balancing short-term versus long-term fairness, computational efficiency versus model complexity, and theoretical guarantees versus practical applicability. Researchers must also consider the tradeoff between model interpretability and predictive power when choosing mitigation techniques.

Failure Signatures: Common failure modes include incomplete literature coverage due to search limitations, misinterpretation of complex fairness notions, and oversimplification of dynamic system interactions. Failure to account for intersectional identities or real-world complexities can lead to ineffective or harmful fairness interventions.

First Experiments:
1. Apply the taxonomy to categorize a set of recent papers on fairness in dynamic systems to validate the framework's coverage and utility.
2. Implement a simple simulation of a credit lending system with feedback loops to test the effectiveness of different mitigation techniques across the identified problem settings.
3. Conduct a case study applying the causality-motivated fairness notions to a real-world dataset with known causal structure to evaluate practical applicability.

## Open Questions the Paper Calls Out
None

## Limitations
- The survey methodology is not fully specified, limiting reproducibility and creating uncertainty about literature coverage completeness
- High-level discussion may not capture all nuances and implementation details of specific techniques
- Field is still evolving, making the taxonomy potentially subject to future refinement or disagreement among researchers

## Confidence
- Overall taxonomy and classification framework: Medium confidence
- Coverage of well-established concepts and techniques: High confidence
- Coverage of emerging areas and future directions: Medium confidence

## Next Checks
1. Compare the survey's taxonomy and classification of long-term fairness notions with other recent surveys or reviews in the field to assess consistency and identify potential gaps or disagreements.

2. Conduct a spot-check of the literature coverage by selecting a random sample of papers cited in the survey and verifying their relevance to the discussed topics and their proper representation in the survey's framework.

3. Reach out to experts in the field of long-term fairness to gather feedback on the survey's coverage, classification, and identification of key challenges and future directions.