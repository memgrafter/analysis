---
ver: rpa2
title: Open-Vocabulary Calibration for Fine-tuned CLIP
arxiv_id: '2402.04655'
source_url: https://arxiv.org/abs/2402.04655
tags:
- calibration
- classes
- methods
- tuning
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses miscalibration in vision-language models after
  fine-tuning, particularly under open-vocabulary conditions. The authors observe
  that while existing calibration methods work well on base classes, they fail to
  transfer to unseen classes.
---

# Open-Vocabulary Calibration for Fine-tuned CLIP

## Quick Facts
- arXiv ID: 2402.04655
- Source URL: https://arxiv.org/abs/2402.04655
- Authors: Shuoyuan Wang; Jindong Wang; Guoqing Wang; Bob Zhang; Kaiyang Zhou; Hongxin Wei
- Reference count: 40
- Primary result: DAC improves open-vocabulary calibration by up to 16% ECE reduction across 7 prompt tuning methods and 11 datasets

## Executive Summary
This work addresses miscalibration in vision-language models after fine-tuning, particularly under open-vocabulary conditions. The authors observe that while existing calibration methods work well on base classes, they fail to transfer to unseen classes. They propose Distance-Aware Calibration (DAC), which scales the temperature based on the textual distance between predicted and base classes, using normalized text embeddings. Evaluated across 7 prompt tuning methods and 11 datasets, DAC consistently improves open-vocabulary calibration—achieving up to 16% reduction in Expected Calibration Error (ECE), with an average of 6.84% improvement—without sacrificing accuracy or inference speed.

## Method Summary
The paper proposes Distance-Aware Calibration (DAC), a post-hoc calibration method for fine-tuned CLIP models. DAC scales the temperature during inference based on the textual deviation (TD) score between the predicted class and base classes. The TD score is computed as the average Euclidean distance between the normalized text embedding of the predicted class and its K nearest neighbors among base class embeddings. The method uses K=5 neighbors throughout and applies temperature scaling only to novel classes while preserving base class calibration. DAC is compatible with 7 prompt tuning methods (CoOp, CoCoOp, ProDA, KgCoOp, MaPLe, ProGrad, PromptSRC) and is designed to be computationally efficient without requiring hyperparameter tuning.

## Key Results
- DAC reduces ECE on novel classes by up to 16% (average 6.84%) across 11 datasets
- The method maintains calibration performance on base classes while improving novel class calibration
- DAC works consistently across 7 different prompt tuning methods without affecting accuracy
- No additional hyperparameter tuning is required beyond the fixed K=5 neighbor setting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distance-aware calibration corrects miscalibration by scaling temperature according to textual distance between predicted and base classes.
- Mechanism: When a predicted class is far from the base classes in the normalized text embedding space, the method applies a higher temperature scaling factor, which reduces the logit scale and thereby decreases overconfidence. For classes close to base classes, the scaling factor is 1, preserving the calibration quality of base classes.
- Core assumption: The degree of textual deviation between a predicted class and base classes correlates with the degree of miscalibration in that prediction.

### Mechanism 2
- Claim: Normalization of textual features is critical for accurate proximity estimation and effective calibration.
- Mechanism: By normalizing the text embeddings, the method ensures that the proximity calculation using Euclidean distance is meaningful and not dominated by magnitude differences, allowing the Textual Deviation (TD) score to accurately reflect class similarity.
- Core assumption: Unnormalized features can lead to incorrect K-nearest-neighbor-based proximity scores, especially when Euclidean distance is used.

### Mechanism 3
- Claim: DAC improves calibration without sacrificing accuracy because it only adjusts the confidence level, not the predicted class.
- Mechanism: DAC modifies the logit scale (temperature) based on the predicted class's textual deviation, which affects the confidence (softmax probabilities) but not the argmax decision that determines the predicted class label.
- Core assumption: Adjusting temperature based on textual deviation does not change the ranking of class probabilities, only their relative magnitudes.

## Foundational Learning

- Concept: Expected Calibration Error (ECE)
  - Why needed here: ECE is the primary metric used to quantify miscalibration in the paper, measuring the difference between predicted confidence and actual accuracy.
  - Quick check question: What does an ECE of 0% indicate about a model's calibration?

- Concept: Temperature Scaling
  - Why needed here: Temperature scaling is the baseline calibration method that DAC builds upon by modifying it to be distance-aware.
  - Quick check question: How does temperature scaling modify the softmax output without changing the predicted class?

- Concept: L2 Normalization of Embeddings
  - Why needed here: L2 normalization is applied to text embeddings before proximity calculation, which is critical for the textual deviation measure to be meaningful.
  - Quick check question: Why is L2 normalization typically applied to embeddings in contrastive learning frameworks like CLIP?

## Architecture Onboarding

- Component map: Input image -> image encoder -> image embedding -> logit computation -> DAC temperature scaling -> softmax -> calibrated probabilities; Input text label -> text encoder -> normalized text embedding -> K-NN proximity calculation -> TD score computation

- Critical path: 1. Input image → image encoder → image embedding 2. Input text label → text encoder → normalized text embedding 3. Calculate textual proximity between predicted class and base classes 4. Compute TD score 5. Apply TD-based temperature scaling to logit 6. Softmax to get calibrated probabilities

- Design tradeoffs:
  - Choosing K (number of neighbors) for proximity calculation: larger K may be more stable but less sensitive to local structure
  - Computational cost of nearest neighbor search: can be precomputed for base classes but adds overhead for new classes
  - Sensitivity to embedding quality: if text embeddings don't capture semantic similarity well, TD scores will be unreliable

- Failure signatures:
  - Calibration degrades when new classes are semantically similar to base classes but far in embedding space
  - Performance becomes unstable with small K values
  - Normalization step is skipped or incorrectly implemented
  - Temperature scaling factor becomes too extreme (very high or low values)

- First 3 experiments:
  1. Run DAC on a single dataset (e.g., Flowers102) with CoOp to verify ECE reduction on new classes while maintaining base class calibration
  2. Vary K from 1 to 10 to observe sensitivity of calibration performance to the number of neighbors
  3. Compare DAC against baseline temperature scaling on high-confidence predictions to verify reduction in overconfidence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Distance-Aware Calibration (DAC) perform when applied to other vision-language models beyond CLIP, such as BLIP or ALIGN?
- Basis in paper: [explicit] The paper evaluates DAC specifically on CLIP-based models and tuning methods, but does not explore its generalization to other vision-language architectures.
- Why unresolved: The study focuses exclusively on CLIP and its variants, leaving the broader applicability of DAC to other architectures untested.
- What evidence would resolve it: Empirical evaluation of DAC on a range of vision-language models (e.g., BLIP, ALIGN, Florence) across multiple datasets, comparing calibration performance to CLIP-based results.

### Open Question 2
- Question: Can DAC be extended to multi-label classification tasks, where each image may have multiple relevant text labels?
- Basis in paper: [inferred] The paper focuses on single-label classification tasks, but vision-language models are increasingly used in multi-label scenarios, which could present unique calibration challenges.
- Why unresolved: The current formulation of DAC assumes a single predicted class per input, making its extension to multi-label settings non-trivial.
- What evidence would resolve it: Implementation and evaluation of DAC in multi-label classification benchmarks, measuring improvements in calibration metrics like ECE across diverse multi-label datasets.

### Open Question 3
- Question: What is the impact of DAC on model calibration in the presence of significant domain shifts, such as from natural images to medical or satellite imagery?
- Basis in paper: [explicit] The paper evaluates DAC on 11 diverse datasets, but does not specifically address extreme domain shifts or cross-domain generalization.
- Why unresolved: While the datasets used are varied, they do not fully represent the extreme distribution shifts encountered in real-world deployment scenarios.
- What evidence would resolve it: Controlled experiments comparing DAC's calibration performance on models trained in one domain (e.g., natural images) and tested on significantly different domains (e.g., medical scans, satellite imagery), with baseline and DAC-calibrated models.

## Limitations

- The method's effectiveness relies on the assumption that textual embedding distance correlates with visual similarity and calibration needs, which may not hold universally across all semantic domains
- The choice of K=5 neighbors appears somewhat arbitrary without systematic sensitivity analysis, and performance could vary significantly with different K values
- The evaluation focuses primarily on classification tasks with natural image datasets, leaving uncertainty about DAC's performance in specialized domains like medical imaging

## Confidence

**High Confidence**: The claim that DAC improves open-vocabulary calibration (ECE reduction up to 16%) is well-supported by experimental results across 11 datasets and 7 prompt tuning methods.

**Medium Confidence**: The assertion that DAC works without affecting accuracy or requiring hyperparameter tuning is supported but could benefit from more extensive testing across diverse model architectures.

**Low Confidence**: The paper's claim about DAC's computational efficiency and lack of hyperparameter tuning needs more rigorous benchmarking, particularly regarding the overhead of K-nearest neighbor searches during inference.

## Next Checks

1. **Cross-Domain Validation**: Test DAC on non-natural image datasets (e.g., medical imaging, satellite imagery, or industrial inspection) to verify the generalization of the textual-visual correlation assumption across different semantic domains.

2. **K-Value Sensitivity Analysis**: Systematically evaluate DAC's performance across a range of K values (1-20) on a representative subset of datasets to quantify the sensitivity of calibration performance to this hyperparameter and identify optimal ranges for different task types.

3. **Real-Time Inference Benchmark**: Measure the actual computational overhead of DAC during inference, including the cost of K-nearest neighbor searches, and compare it against the claimed efficiency benefits to verify the practical deployment viability of the method.