---
ver: rpa2
title: Data Similarity-Based One-Shot Clustering for Multi-Task Hierarchical Federated
  Learning
arxiv_id: '2410.02733'
source_url: https://arxiv.org/abs/2410.02733
tags: []
core_contribution: The paper proposes a one-shot clustering algorithm for hierarchical
  federated learning to address task heterogeneity by grouping users with similar
  data distributions. The method leverages data similarity estimation via eigen decomposition
  of Gram matrices, enabling privacy-preserving clustering without model-specific
  knowledge.
---

# Data Similarity-Based One-Shot Clustering for Multi-Task Hierarchical Federated Learning

## Quick Facts
- arXiv ID: 2410.02733
- Source URL: https://arxiv.org/abs/2410.02733
- Authors: Abdulmoneam Ali; Ahmed Arafa
- Reference count: 16
- Primary result: Achieves superior clustering accuracy and variance reduction compared to random clustering in hierarchical federated learning

## Executive Summary
This paper proposes a one-shot clustering algorithm for hierarchical federated learning to address task heterogeneity by grouping users with similar data distributions. The method leverages data similarity estimation via eigen decomposition of Gram matrices, enabling privacy-preserving clustering without model-specific knowledge. Users exchange eigenvector matrices, compute relevance scores, and apply hierarchical agglomerative clustering to assign groups. Experiments on CIFAR-10 and Fashion MNIST demonstrate superior accuracy and variance reduction compared to random clustering, with robustness to unbalanced label distributions and cross-dataset similarity.

## Method Summary
The proposed method uses eigen decomposition of weighted Gram matrices to estimate data similarity between users without exposing raw data. Each user computes eigenvalues and eigenvectors of their Gram matrix, shares the eigenvectors with others, and calculates relevance scores based on how their data vary in the direction of other users' eigenvectors. These relevance scores form a symmetric similarity matrix that hierarchical agglomerative clustering uses to group users. The approach enables privacy-preserving clustering without requiring model-specific knowledge, as it relies solely on data distribution similarity.

## Key Results
- Superior clustering accuracy compared to random clustering baseline on CIFAR-10 and Fashion MNIST
- Significant variance reduction in test accuracy across users
- Robustness to unbalanced label distributions and cross-dataset similarity
- Effective clustering using only top few eigenvectors, reducing communication overhead

## Why This Works (Mechanism)

### Mechanism 1
Eigenvalue decomposition of Gram matrices captures task-specific data similarity without exposing raw data. Each user computes eigenvalues/vectors of a weighted Gram matrix derived from their data. By projecting other users' eigenvectors onto their own data, they estimate relevance scores. Users then share only the eigenvectors (not raw data), preserving privacy. The core assumption is that data distributions of users within the same task are similar enough that eigenvalue structures align, enabling meaningful similarity comparisons.

### Mechanism 2
Relevance scores are symmetric and robust enough to identify clusters via HAC. Each user computes both forward and reverse relevance (r(i,j) and r(j,i)). The GPS averages these to form a symmetric similarity matrix R, which HAC uses to iteratively merge closest users. The core assumption is that relevance is a reliable similarity metric that HAC can exploit; averaging forward and reverse scores improves stability.

### Mechanism 3
Low-dimensional eigenvector exchange suffices for accurate clustering. Experiments show that using only the top few eigenvectors (e.g., 5 out of 784) retains enough discriminative power, drastically reducing communication. The core assumption is that most discriminative information for clustering is captured in the top eigenvalues/vectors; smaller eigenvalues add noise rather than signal.

## Foundational Learning

- **Gram matrix and eigen decomposition**
  - Why needed here: Used to quantify similarity between users' data distributions in a privacy-preserving way
  - Quick check question: What does each eigenvalue represent in the context of data similarity?

- **Hierarchical Agglomerative Clustering (HAC)**
  - Why needed here: Merges users iteratively based on pairwise similarity until the desired number of clusters is reached
  - Quick check question: How does the choice of distance metric affect HAC outcomes?

- **Relevance score computation**
  - Why needed here: Normalizes and compares eigenvalue magnitudes to measure how similarly two users' data vary
  - Quick check question: Why do we take the minimum and maximum of λ(i) and ˆλ(j) before normalizing?

## Architecture Onboarding

- **Component map**: Users -> GPS (aggregates relevance scores, runs HAC) -> LPSs (run FedAvg, share common layers)
- **Critical path**: 
  1. Users compute and exchange eigenvectors
  2. Users compute relevance scores and send to GPS
  3. GPS builds R, runs HAC, assigns users to LPSs
  4. LPSs run FedAvg; share common layers with GPS
  5. GPS aggregates, broadcasts updated common layers
- **Design tradeoffs**: 
  - Privacy vs. accuracy: Eigenvector exchange is minimal but still leaks some structural info
  - Communication vs. accuracy: Fewer eigenvectors reduce overhead but risk losing discriminative power
  - Number of clusters (T) must be known a priori
- **Failure signatures**:
  - Poor clustering accuracy → check relevance score distribution or HAC linkage method
  - Communication bottleneck → reduce eigenvector count or batch relevance exchanges
  - Model divergence → verify LPS user assignments match true tasks
- **First 3 experiments**:
  1. Synthetic 2-task dataset: Test clustering accuracy vs. random baseline
  2. Vary eigenvector count: Measure accuracy drop when reducing from 50 to 5
  3. Cross-dataset similarity: Mix CIFAR-10 and CIFAR-100 users; verify correct grouping

## Open Questions the Paper Calls Out

- **Robustness to noisy eigenvector matrices**: How robust is the clustering algorithm to noisy or corrupted eigenvector matrices during transmission? The paper mentions studying robustness to noisy eigenvectors as a future direction, indicating this has not been investigated yet.

- **Optimal number of common layers**: What is the optimal number of common layers to share between local parameter servers and the global parameter server for different task heterogeneity levels? The paper shares only the first common layers in experiments but does not systematically investigate how different numbers of shared layers affect performance across varying task similarities.

- **Performance under class-level imbalance**: How does the algorithm perform when users have significantly different numbers of samples per class within their assigned tasks? The paper mentions unbalanced label distributions in the Fashion MNIST experiment but only considers unbalanced task distributions, not class-level imbalance within tasks.

## Limitations
- Clustering mechanism assumes eigenvalue structures sufficiently distinguish tasks, which may not hold for highly overlapping or noisy distributions
- Requires number of tasks T to be known a priori, limiting applicability when task count is uncertain
- Privacy is preserved through eigenvector exchange but still reveals structural information about data distributions

## Confidence

**High confidence**: Privacy-preserving data similarity estimation via eigen decomposition, communication efficiency gains from low-dimensional eigenvector exchange

**Medium confidence**: Clustering accuracy improvements over random baselines, robustness to unbalanced label distributions

**Low confidence**: Cross-dataset similarity handling and generalization to real-world heterogeneous federated learning scenarios

## Next Checks

1. **Scalability Test**: Evaluate clustering performance and communication overhead on datasets with 100+ users and varying degrees of task heterogeneity to assess real-world applicability.

2. **Robustness Analysis**: Systematically test the method's performance under different noise levels, data imbalance ratios, and overlapping task distributions to identify failure boundaries.

3. **Privacy Audit**: Conduct a formal privacy analysis to quantify the information leakage through eigenvector exchange and compare against established privacy metrics like differential privacy guarantees.