---
ver: rpa2
title: Adaptive Routing of Text-to-Image Generation Requests Between Large Cloud Model
  and Light-Weight Edge Model
arxiv_id: '2411.13787'
source_url: https://arxiv.org/abs/2411.13787
tags:
- quality
- routing
- cloud
- edge
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of routing text-to-image generation
  requests between cloud-based large models and edge-based lightweight models to balance
  cost and quality. The proposed RouteT2I framework dynamically selects the appropriate
  model for each user prompt by predicting multi-metric image quality differences
  using a dual-gate token selection mixture-of-experts (MoE) architecture.
---

# Adaptive Routing of Text-to-Image Generation Requests Between Large Cloud Model and Light-Weight Edge Model

## Quick Facts
- arXiv ID: 2411.13787
- Source URL: https://arxiv.org/abs/2411.13787
- Authors: Zewei Xin; Qinya Li; Chaoyue Niu; Fan Wu; Guihai Chen
- Reference count: 40
- Key outcome: RouteT2I achieves 83.97% of cloud quality improvement while reducing cloud requests by 70.24% compared to random routing

## Executive Summary
This paper addresses the challenge of routing text-to-image generation requests between cloud-based large models and edge-based lightweight models to balance cost and quality. The proposed RouteT2I framework dynamically selects the appropriate model for each user prompt by predicting multi-metric image quality differences using a dual-gate token selection mixture-of-experts (MoE) architecture. The method evaluates image quality through contrastive metrics comparing generated images against positive and negative text descriptions, and uses Pareto relative superiority to quantify quality differences. Evaluation across 18 model pairs shows that RouteT2I achieves 83.97% of the quality improvement of using cloud models exclusively while reducing cloud requests by 70.24% compared to random routing at a 50% quality improvement target.

## Method Summary
RouteT2I implements a dynamic routing framework that uses a dual-gate token selection MoE architecture to predict image quality differences between edge and cloud models. The system processes user prompts through token selection gates that identify key tokens influencing specific quality metrics, with positive and negative gates evaluating opposing token influences. Quality is assessed across 10 dimensions using contrastive text pairs, and Pareto relative superiority quantifies the multi-metric quality differences. The routing strategy then allocates prompts based on these predictions and predefined cost constraints, routing only prompts showing significant quality gaps to the cloud while maintaining cost-effective edge processing for others.

## Key Results
- RouteT2I achieves 83.97% of the quality improvement of using cloud models exclusively
- Cloud request reduction of 70.24% compared to random routing at a 50% quality improvement target
- System maintains quality while achieving significant cost savings through intelligent routing decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The routing model uses dual-gate token selection MoE to identify and evaluate key tokens influencing image quality metrics.
- Mechanism: The model treats user prompts as token sequences, uses a token selection gate to choose top-K tokens per expert (aligned with quality metrics), and employs positive/negative gates to evaluate opposing token influences.
- Core assumption: Certain tokens in prompts have disproportionate influence on specific image quality metrics, and these can be identified and ranked before image generation.
- Evidence anchors:
  - [abstract] "RouteT2I then predicts the expected quality of the generated images by identifying key tokens in the prompt and comparing their impact on the quality."
  - [section 5.1.1] "We design a token selection gate, where experts align with quality metrics and actively choose the most relevant tokens to simulate metric attention to different image attributes."
  - [corpus] Weak - No direct corpus evidence for token selection MoE in routing, but related to "mixture-of-experts" approaches in routing literature.
- Break condition: If token influence patterns vary significantly across prompts or quality metrics, the top-K selection becomes ineffective at capturing relevant tokens.

### Mechanism 2
- Claim: Multi-dimensional quality metrics combined with Pareto relative superiority enable robust routing decisions despite subjective image quality.
- Mechanism: The system evaluates generated images across 10 quality dimensions using contrastive text pairs, normalizes quality distances, and computes Pareto relative superiority to quantify quality differences between edge and cloud outputs.
- Core assumption: Multi-metric evaluation provides a more comprehensive and noise-resistant basis for routing than single-objective metrics, and Pareto superiority captures the trade-off between different quality dimensions.
- Evidence anchors:
  - [abstract] "Since generated image quality is challenging to measure and compare directly, RouteT2I establishes multi-dimensional quality metrics..."
  - [section 4] "We introduce a multi-dimensional metric to comprehensively evaluate generated image quality, providing noise resistance and stability for quality-prediction-based routing."
  - [corpus] Weak - No direct corpus evidence for Pareto relative superiority in routing, but related to multi-objective optimization in routing literature.
- Break condition: If quality metrics are highly correlated or if the relative importance of different metrics changes significantly across prompts, the Pareto comparison becomes less discriminative.

### Mechanism 3
- Claim: The routing strategy uses predicted Pareto relative superiority to route prompts based on quality-cost trade-offs, achieving 70% cloud request reduction.
- Mechanism: Prompts with Pareto relative superiority below threshold Î± are routed to cloud (indicating edge quality is significantly worse), while others stay on edge, maintaining quality while reducing cloud costs.
- Core assumption: The routing model can accurately predict which prompts will benefit most from cloud processing, and that cost savings from reduced cloud usage outweigh any quality degradation from routing decisions.
- Evidence anchors:
  - [abstract] "RouteT2I further introduces the Pareto relative superiority to compare the multi-metric quality of the generated images. Based on this comparison and predefined cost constraints, RouteT2I allocates prompts to either the edge or the cloud."
  - [section 5.2] "Only prompts that show a notable quality gap when generated in the cloud are routed there, while the rest remain on the cost-effective edge."
  - [section 6.2] "To achieve 50% of the quality improvement attained by fully using the cloud model, the number of requests routed to the cloud model is reduced by 70.24% compared to a random routing policy."
- Break condition: If the routing model's predictions become inaccurate for certain prompt types, or if cost constraints change significantly, the routing strategy may fail to maintain the quality-cost balance.

## Foundational Learning

- Concept: Mixture-of-Experts (MoE) architectures
  - Why needed here: The routing model uses dual-gate token selection MoE to focus on key tokens influencing image quality metrics
  - Quick check question: How does a token selection gate in MoE differ from traditional expert routing mechanisms?

- Concept: Pareto optimality and multi-objective optimization
  - Why needed here: The routing problem involves balancing multiple image quality metrics simultaneously
  - Quick check question: What distinguishes Pareto relative superiority from traditional Pareto optimality?

- Concept: Contrastive learning for quality evaluation
  - Why needed here: Quality metrics are evaluated by comparing images against positive and negative text descriptions
  - Quick check question: How does contrastive quality evaluation differ from absolute quality scoring?

## Architecture Onboarding

- Component map: Router (dual-gate MoE with token selection) -> Quality Prediction -> Routing Strategy -> Edge/Cloud Model Selection
- Critical path: User prompt -> Token processing -> Gate selection -> Expert evaluation -> Pareto prediction -> Routing decision
- Design tradeoffs: Token selection vs. computational cost; multi-metric evaluation vs. prediction accuracy; routing rate vs. quality preservation
- Failure signatures: Poor quality predictions -> inappropriate routing; high false positive rate -> unnecessary cloud usage; high false negative rate -> quality degradation
- First 3 experiments:
  1. Test routing accuracy on simple prompts with known edge/cloud quality differences
  2. Evaluate token selection gate performance by measuring correlation between selected tokens and quality impact
  3. Measure Pareto prediction accuracy against ground truth quality comparisons

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RouteT2I change when using real-time human feedback to adjust routing decisions instead of relying solely on predicted quality metrics?
- Basis in paper: [inferred] The paper discusses multi-metric quality measures and routing strategy but doesn't explore adaptive learning from actual user preferences or real-time quality assessments during deployment.
- Why unresolved: The evaluation focuses on pre-trained quality metrics and offline testing rather than incorporating dynamic user feedback during the routing process.
- What evidence would resolve it: Comparative experiments showing routing performance with and without real-time human feedback integration, measuring improvements in user satisfaction and quality metrics.

### Open Question 2
- Question: What is the impact of incorporating contextual information beyond the text prompt itself (such as user history or device capabilities) on routing effectiveness?
- Basis in paper: [inferred] The paper treats prompts as isolated text sequences without considering additional contextual factors that might influence generation quality or routing decisions.
- Why unresolved: The routing model architecture focuses solely on token-level analysis of individual prompts without leveraging broader contextual information.
- What evidence would resolve it: Performance comparisons between context-aware and context-agnostic routing approaches across diverse user scenarios and device configurations.

### Open Question 3
- Question: How does RouteT2I's routing performance scale when applied to heterogeneous model pairs with vastly different architectures or generation paradigms (e.g., diffusion vs autoregressive models)?
- Basis in paper: [explicit] The paper mentions testing different model pairs but doesn't deeply analyze routing performance across fundamentally different architectural approaches.
- Why unresolved: While various model pairs are tested, the paper doesn't specifically examine extreme architectural differences or their impact on routing accuracy.
- What evidence would resolve it: Systematic experiments comparing routing performance across different architectural combinations, particularly focusing on cases where models use fundamentally different generation approaches.

## Limitations

- The dual-gate token selection MoE architecture lacks detailed implementation specifications that make exact reproduction challenging
- Quality assessment relies on contrastive evaluation with positive/negative text pairs, introducing potential subjectivity despite multi-metric evaluation
- Pareto relative superiority calculation depends on specific normalization parameters and weighting schemes not fully detailed in the paper

## Confidence

**High Confidence** - Claims about the routing framework architecture, the use of dual-gate token selection MoE, and the multi-metric quality evaluation approach are well-supported by the methodology section and experimental setup.

**Medium Confidence** - Claims regarding the 83.97% quality improvement and 70.24% cloud request reduction are based on experimental results, but exact reproducibility depends on implementation details not fully specified.

**Low Confidence** - Claims about robustness to diverse prompt distributions and generalization to unseen prompt types are not extensively validated in the paper.

## Next Checks

1. **Token Selection Gate Effectiveness**: Validate that the token selection gate correctly identifies tokens with significant impact on quality metrics by measuring correlation between selected tokens and observed quality improvements across diverse prompt types.

2. **Pareto Prediction Accuracy**: Compare predicted Pareto relative superiority values against ground truth quality comparisons to quantify prediction accuracy and identify systematic biases in quality predictions.

3. **Routing Strategy Robustness**: Test routing strategy performance across different prompt distributions and edge-cloud latency scenarios to evaluate robustness and identify conditions where quality-cost trade-off may break down.