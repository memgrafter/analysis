---
ver: rpa2
title: 'InceptionCapsule: Inception-Resnet and CapsuleNet with self-attention for
  medical image Classification'
arxiv_id: '2402.02274'
source_url: https://arxiv.org/abs/2402.02274
tags:
- learning
- classification
- breast
- proposed
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the problem of achieving accurate medical
  image classification in the presence of random initial weight selection and insufficient
  vector richness, which can lead to overfitting and poor generalization. The proposed
  InceptionCapsule approach combines transfer learning with the Inception-ResNet model
  (using ImageNet pre-trained weights) for robust initial feature extraction, followed
  by a CapsuleNet architecture enriched with a self-attention mechanism to learn discriminative
  vector representations.
---

# InceptionCapsule: Inception-Resnet and CapsuleNet with self-attention for medical image Classification

## Quick Facts
- arXiv ID: 2402.02274
- Source URL: https://arxiv.org/abs/2402.02274
- Reference count: 40
- Primary result: Achieves 97.62% accuracy on 5-class Kvasir, 94.30% on 8-class Kvasir, and 98.88% accuracy with 95.34% precision and 93.74% F1-score on BUSI breast cancer dataset

## Executive Summary
This paper proposes InceptionCapsule, a novel approach for medical image classification that addresses two key challenges: avoiding random weight initialization and ensuring rich vector representations. The method combines transfer learning with pre-trained Inception-ResNet for stable feature extraction, followed by a CapsuleNet architecture enhanced with self-attention to learn discriminative vector representations. The model was evaluated on gastrointestinal image classification (Kvasir dataset) and breast cancer detection (BUSI dataset), demonstrating superior performance compared to existing methods.

## Method Summary
InceptionCapsule employs a two-stage architecture: first, Inception-ResNet with ImageNet pre-trained weights extracts robust features from medical images; second, these features are processed by a CapsuleNet with self-attention mechanism that learns spatial hierarchies and emphasizes discriminative regions. The model uses dynamic routing to refine how lower-level features contribute to higher-level class predictions. Training was conducted on standard computer hardware with Python 3.9, TensorFlow 2.0, and Keras 2.0, using 70-80% of data for training and the remainder for validation and testing.

## Key Results
- Achieved 97.62% accuracy on 5-class Kvasir dataset classification
- Reached 94.30% accuracy on 8-class Kvasir dataset classification
- Obtained 98.88% accuracy, 95.34% precision, and 93.74% F1-score on BUSI breast cancer dataset

## Why This Works (Mechanism)

### Mechanism 1
Transfer learning from ImageNet provides stable initial weights that reduce overfitting and underfitting. Pretrained Inception-ResNet layers serve as feature extractors, avoiding random initialization and leveraging rich features learned from large-scale data. Core assumption: Features learned from natural images are transferable to medical images, especially in domains with limited labeled data.

### Mechanism 2
Self-attention mechanism selects and emphasizes discriminative features learned by the CapsuleNet. Attention module assigns higher weights to relevant features while suppressing noise, improving classification accuracy on small medical datasets. Core assumption: Not all features learned by CapsuleNet are equally useful; attention can identify and prioritize the most discriminative ones.

### Mechanism 3
CapsuleNet's dynamic routing and vector-based representation capture spatial hierarchies and part-whole relationships better than CNNs. Capsules encode pose and instantiation parameters in vectors, and routing-by-agreement refines how lower-level features contribute to higher-level classes. Core assumption: Vector-based representations can encode spatial relationships more effectively than scalar activations, especially for medical image structures.

## Foundational Learning

- **Concept: Transfer learning**
  - Why needed here: Medical datasets are often small; ImageNet pretraining provides robust feature extraction without overfitting
  - Quick check question: What are the risks of negative transfer when applying natural image models to medical domains?

- **Concept: Self-attention**
  - Why needed here: Focus on discriminative regions in high-dimensional medical images to improve signal-to-noise ratio
  - Quick check question: How does self-attention differ from spatial attention in convolutional architectures?

- **Concept: Capsule networks and dynamic routing**
  - Why needed here: Preserve spatial hierarchies and part-whole relationships, crucial for detecting subtle pathological patterns
  - Quick check question: What advantage do vector outputs have over scalar activations in capturing object pose?

## Architecture Onboarding

- **Component map**: Inception-ResNet (feature extraction) → CapsuleNet (vector encoding) → Self-attention (feature selection) → Classification layer (softmax)
- **Critical path**: Input → Inception feature extraction → Capsule dynamic routing → Self-attention weighting → FC + Softmax → Output
- **Design tradeoffs**: Inception-ResNet gives rich features but increases compute; self-attention adds interpretability but complexity; capsules handle spatial relationships but require careful routing tuning
- **Failure signatures**: Low validation accuracy despite high training accuracy (overfitting); high training loss with stable validation loss (routing or attention instability); class imbalance affecting attention weights
- **First 3 experiments**:
  1. Train InceptionCapsule without self-attention on Kvasir-5; compare to baseline CNN accuracy
  2. Add self-attention; measure impact on precision/recall and attention weight distributions
  3. Evaluate on BUSI dataset; analyze sensitivity/specificity trade-offs and F1-score improvement

## Open Questions the Paper Calls Out
No open questions were explicitly identified in the paper.

## Limitations
- Exact architectural details of the self-attention mechanism integrated with CapsuleNet remain unspecified
- Hyperparameter settings (learning rate, batch size, optimizer choice) are not provided
- Claim of outperforming state-of-the-art methods lacks direct comparative experiments with recent architectures

## Confidence

- **High Confidence**: Transfer learning with Inception-ResNet providing stable initial weights and avoiding random initialization
- **Medium Confidence**: Self-attention mechanism effectively selecting discriminative features
- **Medium Confidence**: CapsuleNet dynamic routing capturing spatial hierarchies better than CNNs

## Next Checks
1. Implement ablation study comparing InceptionCapsule with and without self-attention on Kvasir-5 dataset to quantify attention module contribution to accuracy gains
2. Test model generalization by evaluating on external medical datasets not used in training to assess true domain transferability
3. Compare routing convergence behavior and attention weight distributions across different medical image types to identify potential failure modes in capsule network training