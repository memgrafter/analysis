---
ver: rpa2
title: Exploring Large Language Models for Climate Forecasting
arxiv_id: '2411.13724'
source_url: https://arxiv.org/abs/2411.13724
tags:
- climate
- rainfall
- predictions
- data
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the potential of large language models
  (LLMs) like GPT-4 to generate reliable future climate predictions, focusing on rainfall
  forecasting at short-term (15-day) and long-term (12-month) scales. While LLMs have
  been explored for descriptive climate content, their predictive capabilities remain
  underexamined.
---

# Exploring Large Language Models for Climate Forecasting

## Quick Facts
- arXiv ID: 2411.13724
- Source URL: https://arxiv.org/abs/2411.13724
- Authors: Yang Wang; Hassan A. Karimi
- Reference count: 0
- Key outcome: LLMs like GPT-4 generate conservative climate forecasts that align with historical averages, struggling to incorporate expert model outputs and capture emerging trends

## Executive Summary
This study investigates the potential of large language models (LLMs) like GPT-4 for climate forecasting, specifically rainfall prediction at short-term (15-day) and long-term (12-month) scales. While LLMs have been explored for descriptive climate content, their predictive capabilities remain underexamined. The research compares GPT-4's performance with and without expert model (EM) inputs, revealing that GPT-4 tends to generate conservative forecasts closely aligned with historical averages, regardless of expert data integration. This tendency is particularly pronounced in long-term predictions, where GPT-4's outputs show high correlation with 30-year averages but limited sensitivity to emerging trends. The findings highlight both the promise and limitations of LLMs in climate forecasting, suggesting a hybrid approach leveraging expert models for uncertainty-aware predictions could enhance reliability.

## Method Summary
The study employs a multi-step approach to evaluate LLM performance in climate forecasting. First, historical climate data for 15 US cities (1900-2022) is collected and preprocessed. An LSTM-based expert model is trained to generate baseline rainfall predictions. GPT-4 is then used to generate forecasts under four experimental conditions: GPT-only, GPT with EM rainfall input, GPT with EM temperature input, and GPT with teleconnection indices. Predictions are evaluated against historical averages using RMSE, Pearson correlation coefficient, and Nash-Sutcliffe efficiency metrics. The experiments reveal GPT-4's tendency to default to historical averages and its limited ability to integrate expert model outputs as physical constraints.

## Key Results
- GPT-4 consistently generates conservative forecasts closely aligned with 30-year historical averages
- Expert model integration provides minimal improvement to LLM predictions, suggesting superficial data interpretation
- Long-term forecasts show higher correlation with historical averages but reduced sensitivity to emerging trends
- GPT-4 struggles to incorporate teleconnection indices and domain-specific climate knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs default to historical averages when trend signals are weak
- Mechanism: In the absence of strong trend signals or clear causal relationships, the model's generation process reverts to patterns most strongly represented in its training data—namely, historical climate averages
- Core assumption: The LLM's training corpus contains sufficient historical climate data that it can recognize and reproduce average patterns when uncertain
- Evidence anchors:
  - [abstract] "GPT, when operating independently, tends to generate conservative forecasts, often reverting to historical averages in the absence of clear trend signals"
  - [section] "GPT-generated predictions closely align with the 30-year average in both short-term and long-term forecasts"
  - [corpus] Weak evidence - no direct studies on LLM behavior when trend signals are weak
- Break condition: When clear trend signals or strong causal relationships are present in the input data

### Mechanism 2
- Claim: LLMs struggle to integrate expert model outputs as actionable physical knowledge
- Mechanism: The LLM treats expert model predictions as textual information rather than physical constraints, limiting its ability to incorporate domain-specific insights into its predictions
- Core assumption: LLMs process all inputs through their language modeling framework rather than understanding the physical meaning of numerical predictions
- Evidence anchors:
  - [section] "GPT may not accurately interpret the data or effectively adjust its prediction strategy based on it. In other words, GPT is likely to treat this input as textual information"
  - [section] "whether adding regional factors or global teleconnection factors, GPT's results declined compared to when this knowledge was not added"
  - [corpus] No direct evidence found about LLMs' ability to integrate expert model outputs
- Break condition: When LLMs are specifically trained or fine-tuned on climate model outputs with explicit physical interpretation

### Mechanism 3
- Claim: LLMs smooth out extreme predictions from expert models
- Mechanism: When presented with extreme values from expert models, LLMs adjust predictions toward historical averages to maintain conservative, stable outputs
- Core assumption: LLMs have a built-in bias toward generating stable, non-extreme predictions when faced with anomalous data
- Evidence anchors:
  - [section] "Exp2 noticeably dampened the magnitude of these peaks" and "GPT is inclined to revert toward the average, leading to a smoothing effect in its predictions"
  - [section] "GPT's tendency to generate results close to the multi-year average was more pronounced in cities with higher rainfall"
  - [corpus] No direct evidence found about LLMs' smoothing behavior with extreme values
- Break condition: When extreme values are sufficiently frequent in the training data or when explicit constraints are applied

## Foundational Learning

- Concept: Time series forecasting fundamentals
  - Why needed here: Understanding the differences between autoregressive, sequence-to-sequence, and hybrid approaches is crucial for interpreting why LLMs struggle with climate prediction
  - Quick check question: What are the key differences between statistical forecasting methods and physical climate models, and how might each approach handle uncertainty differently?

- Concept: Climate teleconnections and physical climate processes
  - Why needed here: Understanding how global climate patterns (like ENSO, PDO, NAO) influence regional weather is essential for interpreting why LLMs struggle to incorporate teleconnection data
  - Quick check question: How do teleconnection patterns like El Niño/Southern Oscillation affect precipitation patterns in different regions, and why might this be difficult for an LLM to capture?

- Concept: Language model limitations for numerical prediction
  - Why needed here: Understanding the fundamental differences between language modeling and numerical prediction helps explain why LLMs struggle with climate forecasting tasks
  - Quick check question: What are the key architectural and training differences between LLMs and traditional time series forecasting models, and how might these differences impact their ability to handle numerical data?

## Architecture Onboarding

- Component map:
  - Expert Model (EM) -> LSTM-based climate prediction model providing baseline forecasts
  - LLM Interface -> GPT-4o with specific prompt engineering for climate prediction
  - Data Pipeline -> Historical climate data preprocessing and feature extraction
  - Evaluation Framework -> RMSE, correlation coefficients, and Nash-Sutcliffe efficiency metrics
  - Uncertainty Quantification -> Standard deviation-based uncertainty measures

- Critical path:
  1. Historical data collection and preprocessing
  2. EM model training and prediction generation
  3. LLM prediction generation under different experimental conditions
  4. Comparative evaluation against ground truth and baseline
  5. Analysis of trend-capturing ability and uncertainty handling

- Design tradeoffs:
  - Precision vs. interpretability: LLMs offer natural language interfaces but sacrifice prediction precision
  - Flexibility vs. reliability: LLMs can handle diverse queries but struggle with specialized numerical prediction
  - Data requirements: LLMs require extensive training data while expert models can work with focused datasets

- Failure signatures:
  - Predictions consistently revert to historical averages regardless of input
  - Poor performance on extreme weather events or anomalous conditions
  - Inability to properly integrate expert model outputs as physical constraints
  - Inconsistent results across different experimental conditions

- First 3 experiments:
  1. Compare LLM predictions against historical averages for a simple test case
  2. Test LLM's ability to reproduce basic statistical properties of input data
  3. Evaluate LLM's response to contradictory or anomalous input signals

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating uncertainty measures (e.g., standard deviation of historical rainfall) with LLM-generated predictions improve accuracy and reduce over-reliance on historical averages?
- Basis in paper: [explicit] The study tested adding standard deviation as an uncertainty measure to prompt GPT-4o, resulting in improved alignment with the Expert Model's (EM) predictions.
- Why unresolved: While the inclusion of uncertainty information improved results, it did not fully achieve the desired outcome of adjusting predictions based on varying levels of uncertainty.
- What evidence would resolve it: Systematic testing of different uncertainty metrics (e.g., confidence intervals, prediction intervals) and their integration into LLM prompts, followed by comparative analysis with baseline and EM predictions.

### Open Question 2
- Question: How can LLMs like GPT-4o be optimized to better integrate and interpret domain-specific climate knowledge (e.g., teleconnection indices, expert model outputs)?
- Basis in paper: [explicit] The study found that directly providing expert model predictions to GPT-4o did not significantly improve its forecasts, suggesting limitations in interpreting and integrating such data.
- Why unresolved: The study relied on basic prompt engineering, and more advanced techniques (e.g., knowledge distillation, fine-tuning) were not explored.
- What evidence would resolve it: Comparative experiments using advanced techniques like fine-tuning GPT-4o on climate-specific datasets or employing multi-task learning frameworks to evaluate improvements in prediction accuracy.

### Open Question 3
- Question: What is the extent to which LLMs can capture and predict extreme climate events compared to traditional physical models?
- Basis in paper: [inferred] The study observed that GPT-4o tends to generate conservative forecasts aligned with historical averages, potentially smoothing out extreme events and reducing sensitivity to anomalies.
- Why unresolved: The study did not explicitly test GPT-4o's ability to predict extreme climate events or compare its performance to physical models in such scenarios.
- What evidence would resolve it: Experiments designed to test LLM predictions during known extreme climate events, comparing their accuracy and sensitivity to physical models and historical data.

## Limitations
- LLMs consistently revert to historical averages regardless of input data quality or expert model integration
- Limited ability to capture and predict extreme weather events and emerging climate trends
- Study scope restricted to rainfall prediction for 15 US cities, limiting generalizability

## Confidence
- Medium confidence: LLMs revert to historical averages (supported by experimental results but lacks direct validation)
- Low confidence: LLMs struggle to integrate expert model outputs as physical knowledge (based on negative results rather than positive evidence)
- Medium confidence: LLMs smooth out extreme predictions (supported by evidence but generalizability uncertain)

## Next Checks
1. Test with synthetic trend data: Design experiments using artificially generated climate data with clear, known trends to determine whether GPT-4 can capture directional changes when trend signals are unambiguous.
2. Evaluate extreme event prediction: Assess GPT-4's performance specifically on historical extreme weather events to quantify its ability to predict anomalies and determine whether the smoothing effect extends to catastrophic events.
3. Compare with specialized climate transformers: Benchmark GPT-4 against transformer models specifically designed for climate prediction to determine whether the observed limitations are inherent to LLMs or could be addressed through climate-specific architectural modifications.