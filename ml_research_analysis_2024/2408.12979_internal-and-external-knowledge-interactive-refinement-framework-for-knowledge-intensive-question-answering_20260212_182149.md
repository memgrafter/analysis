---
ver: rpa2
title: Internal and External Knowledge Interactive Refinement Framework for Knowledge-Intensive
  Question Answering
arxiv_id: '2408.12979'
source_url: https://arxiv.org/abs/2408.12979
tags:
- knowledge
- external
- arxiv
- internal
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces IEKR, a novel internal and external knowledge
  interactive refinement framework for knowledge-intensive question answering. The
  method leverages internal knowledge within LLMs to improve the retrieval of relevant
  external knowledge from knowledge bases, addressing the challenge of knowledge gaps
  between input text and needed knowledge.
---

# Internal and External Knowledge Interactive Refinement Framework for Knowledge-Intensive Question Answering

## Quick Facts
- arXiv ID: 2408.12979
- Source URL: https://arxiv.org/abs/2408.12979
- Reference count: 15
- Key outcome: IEKR achieves new state-of-the-art performance on three benchmarks, with 93.7% accuracy on CommonsenseQA compared to previous best of 84.3%

## Executive Summary
This paper introduces IEKR, a novel framework that leverages both internal knowledge within large language models and external knowledge from knowledge bases to improve knowledge-intensive question answering. The method addresses knowledge gaps by first prompting the LLM to generate internal knowledge about query entities, then using this knowledge to retrieve complementary external facts, and finally combining both sources to generate answers. Experiments on CommonsenseQA, OpenbookQA, and MedQA-USMLE demonstrate significant improvements over existing methods, achieving new state-of-the-art performance.

## Method Summary
IEKR operates through three main components: internal knowledge reflection, external knowledge retrieval, and answer generation. The framework first extracts entities from the query using named entity recognition, then prompts the LLM to generate internal knowledge about these entities. This internal knowledge is combined with the original query to retrieve relevant external knowledge from knowledge bases using a cross-encoder retriever. Finally, both internal and external knowledge sources are fed into the LLM to generate the final answer. The method uses a single retrieval step rather than iterative approaches, and employs a verifier module to refine internal knowledge based on external facts.

## Key Results
- Achieves 93.7% accuracy on CommonsenseQA, outperforming previous best of 84.3%
- Achieves 93.3% accuracy on OpenbookQA, surpassing previous best of 90.2%
- Achieves 90.3% accuracy on MedQA-USMLE, exceeding previous best of 87.1%
- Ablation study shows 4.5% drop on CommonsenseQA when removing internal knowledge reflection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM internal knowledge fills retrieval gaps between query terms and needed knowledge
- Mechanism: Prompting LLM to generate explicit knowledge about query entities provides bridge terms that enable retriever to find relevant external facts
- Core assumption: LLM has encoded relevant knowledge for query entities that can be surfaced through simple prompts
- Evidence anchors:
  - [abstract]: "LLMs have already encoded rich knowledge in their pretrained parameters and utilizing these internal knowledge improves the retrieval of external knowledge"
  - [section 1]: "we empirically observe that LLMs have already encoded rich knowledge in their pretrained parameters and utilizing these internal knowledge improves the retrieval of external knowledge when applying them to knowledge-intensive tasks"
  - [corpus]: Weak - corpus contains related RAG papers but none specifically about using LLM internal knowledge for retrieval enhancement
- Break condition: If LLM lacks relevant knowledge about query entities, prompting will produce irrelevant or no knowledge, failing to bridge retrieval gap

### Mechanism 2
- Claim: External knowledge complements and corrects internal knowledge
- Mechanism: Retrieved external facts are used to verify and augment LLM-generated internal knowledge before final answer generation
- Core assumption: External knowledge can identify and correct hallucinations in internal knowledge
- Evidence anchors:
  - [abstract]: "as well as exploit the external knowledge to refine the hallucination of generated internal knowledge"
  - [section 4.3]: "The external knowledge is utilized to complement the internal knowledge into input of LLM for answers"
  - [corpus]: Weak - corpus shows general RAG approaches but not specific mechanisms for knowledge complementarity
- Break condition: If retrieved external knowledge is irrelevant or contradicts without correction, it may confuse rather than improve answer generation

### Mechanism 3
- Claim: Single retrieval step with enriched query is sufficient
- Mechanism: Combining internal and query knowledge creates rich input for one-time external knowledge retrieval
- Core assumption: Enriched query context captures all necessary information for relevant knowledge retrieval
- Evidence anchors:
  - [abstract]: "By simply adding a prompt like 'Tell me something about' to the LLMs"
  - [section 6.2]: "Our method does not need multi-time retrieval and only retrieves once based on the concrete internal knowledge within LLM but derives significant improvement"
  - [corpus]: Weak - most RAG methods in corpus use multiple retrieval steps, this is a distinguishing feature
- Break condition: If one retrieval step misses critical knowledge, iterative retrieval may be necessary for optimal performance

## Foundational Learning

- Concept: Knowledge graph structure and representation
  - Why needed here: Understanding how external knowledge is stored and retrieved from KB
  - Quick check question: How are knowledge triples (entity, relation, entity) used in retrieval?

- Concept: Cross-encoder architecture for retrieval
  - Why needed here: Retriever module uses cross-encoder to score knowledge relevance
  - Quick check question: What is the difference between bi-encoder and cross-encoder in retrieval?

- Concept: Named entity recognition (NER)
  - Why needed here: Used to extract entities from query for internal knowledge generation
  - Quick check question: How does NER identify which query terms should be expanded for knowledge generation?

## Architecture Onboarding

- Component map:
  Query → NER → Entity extraction → LLM internal knowledge generation → Internal knowledge + query → Retriever (cross-encoder) → Top-k external knowledge sentences → Internal knowledge + external knowledge + query → LLM answer generation

- Critical path: Query → Internal knowledge → External retrieval → Answer generation

- Design tradeoffs:
  - Single vs. multi-step retrieval: IEKR chooses single step for efficiency
  - Number of external knowledge sentences: Tradeoff between context richness and computational cost
  - LLM size: Larger LLMs may have more internal knowledge but increase cost

- Failure signatures:
  - Low accuracy despite retrieval: May indicate poor internal knowledge generation or irrelevant external retrieval
  - High computational cost: May indicate too many external knowledge sentences being retrieved
  - Inconsistent results: May indicate prompt instability or retriever sensitivity

- First 3 experiments:
  1. Ablation: Remove internal knowledge reflection, measure drop in accuracy
  2. Parameter sweep: Vary number of external knowledge sentences (10, 50, 100)
  3. Comparison: Run same framework with different LLM sizes (3B vs 7B) on same dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of IEKR scale with increasing LLM parameter size beyond 7B?
- Basis in paper: [inferred] The paper notes that future research will conduct experiments with LLMs larger than 7B, suggesting the current experiments are limited to 3B-7B models.
- Why unresolved: The paper does not provide performance data for LLMs larger than 7B, leaving the scalability question unanswered.
- What evidence would resolve it: Performance results of IEKR on benchmarks using LLMs with parameter sizes larger than 7B, such as 13B, 30B, or 175B.

### Open Question 2
- Question: What is the impact of different types of external knowledge sources (e.g., knowledge graphs vs. text documents) on IEKR's performance?
- Basis in paper: [inferred] The paper uses knowledge graphs (ConceptNet and a self-constructed graph) as external knowledge sources but does not compare with other types like text documents or Wikipedia.
- Why unresolved: The paper does not explore the effect of varying the format or type of external knowledge on IEKR's performance.
- What evidence would resolve it: Comparative experiments showing IEKR's performance using different external knowledge formats, such as text documents, Wikipedia, or other knowledge bases, on the same benchmarks.

### Open Question 3
- Question: How does the number of retrieved external knowledge sentences (m) affect IEKR's performance on different types of questions (e.g., simple vs. complex reasoning)?
- Basis in paper: [explicit] The paper varies m from 10 to 100 and observes a performance drop at m=100 due to irrelevant information, but does not analyze its impact on different question types.
- Why unresolved: The paper does not investigate how the optimal number of retrieved sentences varies based on question complexity or type.
- What evidence would resolve it: Detailed analysis of IEKR's performance with different values of m on subsets of questions categorized by complexity, reasoning type, or other relevant features.

## Limitations
- Dependence on LLM's internal knowledge quality, which may be insufficient for specialized domains
- Single-step retrieval may miss critical knowledge for complex queries requiring deeper exploration
- Framework relies on specific knowledge bases, raising questions about generalizability to other domains

## Confidence
- High Confidence: Achieving state-of-the-art performance on three benchmark datasets with clear metrics
- Medium Confidence: Internal knowledge reflection improving external knowledge retrieval, though mechanism needs more validation
- Low Confidence: External knowledge effectively refining internal knowledge hallucinations, with limited evidence of verifier module's effectiveness

## Next Checks
1. Ablation study with synthetic queries: Create controlled test cases where LLM's internal knowledge is known to be correct, partially correct, or incorrect, then measure how well IEKR identifies and corrects these knowledge states using external knowledge.

2. Iterative retrieval comparison: Implement a multi-step retrieval version of IEKR and compare performance against single-step approach on queries known to require deeper knowledge exploration, measuring both accuracy gains and computational overhead.

3. Cross-domain robustness test: Apply IEKR to a new domain (e.g., legal or financial knowledge) with an appropriate knowledge base, evaluating whether internal knowledge reflection mechanism generalizes beyond commonsense and medical domains.