---
ver: rpa2
title: Sampling Latent Material-Property Information From LLM-Derived Embedding Representations
arxiv_id: '2409.11971'
source_url: https://arxiv.org/abs/2409.11971
tags:
- ranking
- embeddings
- query
- materials
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study explores the use of large language model (LLM) embeddings
  to predict material properties without additional training. It proposes a method
  to construct material embeddings by aggregating element-level representations, optionally
  with contextual keywords.
---

# Sampling Latent Material-Property Information From LLM-Derived Embedding Representations

## Quick Facts
- arXiv ID: 2409.11971
- Source URL: https://arxiv.org/abs/2409.11971
- Authors: Luke P. J. Gilligan; Matteo Cobelli; Hasan M. Sayeed; Taylor D. Sparks; Stefano Sanvito
- Reference count: 0
- Primary result: LLM embeddings can capture material property relationships with careful query term selection, achieving ρ > 0.5 for Curie temperature using terms like 'magnet' or 'iron'.

## Executive Summary
This study investigates whether large language model (LLM) embeddings can predict material properties without additional training. The researchers construct material embeddings by aggregating element-level representations, optionally with contextual keywords, and evaluate their ability to rank materials by properties like Curie temperature, thermoelectric power factor, and band gap. The approach shows promise but reveals that direct chemical formula embeddings perform poorly, while composition-weighted elemental embeddings with appropriate contextualization yield moderate to strong Spearman rank correlations for certain properties.

## Method Summary
The methodology involves constructing material embeddings through composition-weighted aggregation of element-level embeddings from Llama 2 (13B parameters). Elements are optionally contextualized with domain-specific terms (e.g., "ferromagnet iron"), then averaged using atomic fractions. Compound rankings are determined by cosine similarity to property-related query keys, and performance is evaluated using Spearman rank correlation against ground truth property rankings.

## Key Results
- Direct chemical formula embeddings perform poorly for property prediction
- Composition-weighted elemental embeddings with contextualization yield ρ > 0.5 for Curie temperature using terms like 'magnet' or 'iron'
- Performance varies significantly with query term selection, indicating sensitivity to contextualization strategy
- LLM can capture some material-property relationships but requires careful term selection for reliability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large language models can capture latent material property information through contextualized element-level embeddings.
- Mechanism: The LLM encodes statistical relationships between elements and their properties across its training corpus. By injecting domain-specific context terms (e.g., "ferromagnet iron"), the embedding is biased toward the relevant property space, allowing cosine similarity comparisons to reflect relative material performance.
- Core assumption: The LLM's training corpus contains sufficient domain-specific co-occurrence patterns to encode meaningful material-property relationships.
- Evidence anchors:
  - [abstract] "Vector embeddings derived from large language models (LLMs) show promise in capturing latent information from the literature."
  - [section] "Interestingly, the situation with 'iron' is exactly the opposite, namely the word 'iron' provides modest contextualization... but the same term appears to be the most performing in producing a cosine-similarity ranking of compounds."
  - [corpus] Weak - no direct evidence in related papers about LLM embedding performance on materials science tasks.
- Break condition: If the LLM training data lacks sufficient material science literature or the target property has no strong compositional correlation with element co-occurrence patterns.

### Mechanism 2
- Claim: Composition-weighted elemental embeddings can approximate compound-level properties when individual element embeddings capture relevant contextual information.
- Mechanism: Each element in a compound is embedded with domain-specific context, then aggregated using atomic fractions to create a compound representation. This compositional approach leverages the LLM's ability to encode element-property relationships at the atomic level.
- Core assumption: Material properties can be approximated as linear combinations of constituent element properties weighted by atomic fraction.
- Evidence anchors:
  - [section] "the full name of the element is used in place of the symbol of the chemical element... Most importantly, we attempt to enforce the contextualization of the embedding by performing a 'quasi-contextualisation' step."
  - [section] "vC = Σ X∈C wX vX" (formula showing composition-weighted aggregation)
  - [corpus] Missing - no direct evidence in related papers about compositional embedding strategies for materials.
- Break condition: When material properties depend nonlinearly on composition or when crystal structure and atomic arrangement dominate over elemental composition.

### Mechanism 3
- Claim: Query term selection critically influences the quality of property-based rankings from LLM embeddings.
- Mechanism: The cosine similarity between compound embeddings and query term embeddings determines the ranking. Different query terms capture different aspects of the property space, and optimal performance requires matching the query term to the semantic context present in the LLM's embeddings.
- Core assumption: The LLM's embedding space contains distinct regions corresponding to different semantic contexts of the same property.
- Evidence anchors:
  - [section] "The only exception is when querying with 'cobalt', which gives us rather uncorrelated rankings for all the embeddings tested"
  - [section] "the ranking computed according to the similarity with an empty key (first column) seems to be also rather good, a fact that we may consider accidental"
  - [corpus] Weak - related papers mention embedding methods but not query term optimization strategies.
- Break condition: When no query term in the LLM's vocabulary adequately captures the semantic context of the target property.

## Foundational Learning

- Concept: Cosine similarity in high-dimensional embedding spaces
  - Why needed here: The ranking methodology relies on comparing compound embeddings to query term embeddings using cosine similarity to establish relative property performance.
  - Quick check question: What is the range of possible cosine similarity values, and what do the extremes represent?

- Concept: Spearman rank correlation coefficient
  - Why needed here: The evaluation metric compares the LLM-derived rankings to ground truth rankings, measuring how well the embedding-based approach preserves relative ordering.
  - Quick check question: What Spearman correlation value indicates perfect agreement between two rankings?

- Concept: Contextualization in transformer-based language models
  - Why needed here: The methodology depends on modifying element embeddings by adding domain-specific prefixes to capture property-relevant information from the LLM's training.
  - Quick check question: How does the autoregressive nature of LLMs limit their ability to capture future context in a sentence?

## Architecture Onboarding

- Component map: LLM embedding extractor → Context term injector → Element embedding aggregator → Cosine similarity calculator → Spearman correlation evaluator
- Critical path: Context term injection → Element embedding extraction → Composition-weighted aggregation → Similarity ranking → Correlation evaluation
- Design tradeoffs: Simple chemical formula embeddings vs. composition-weighted elemental embeddings (complexity vs. performance), domain-specific vs. general query terms (coverage vs. precision)
- Failure signatures: Low Spearman correlation across all query terms indicates poor LLM material science encoding; high correlation only with specific elements suggests compositional bias rather than true property understanding
- First 3 experiments:
  1. Test GDP-country ranking to verify LLM embedding quality on general domain before materials science application
  2. Compare Curie temperature rankings using different context terms ("ferromagnet" vs. "magnet" vs. "iron") to identify optimal contextualization strategy
  3. Test thermoelectric power factor rankings with different query terms ("Seebeck coefficient" vs. "thermal conductivity") to understand query term sensitivity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific aspects of LLM training data contribute to better material property prediction performance?
- Basis in paper: [explicit] The paper notes that different LLMs perform differently on material property prediction tasks, suggesting that the training data content may influence performance. It states "different LLMs seem to perform quantitatively and sometimes qualitatively differently from each other, possibly reflecting the content of the datasets the models have been trained on."
- Why unresolved: The paper doesn't investigate which specific types of text, domains, or training data characteristics lead to better performance in materials science tasks.
- What evidence would resolve it: Systematic comparison of LLMs trained on different corpora (materials science-focused vs general text) on the same property prediction tasks, with analysis of which training data features correlate with performance.

### Open Question 2
- Question: Can a systematic methodology be developed for selecting optimal contextualization terms and query keys for material property prediction?
- Basis in paper: [inferred] The paper finds that performance depends heavily on the choice of contextualization terms and query keys, but currently relies on intuitive or material-specific choices rather than a systematic approach. It states "a more robust term-engineering strategy is required to increase the reliability of property-based ranking using LLM embeddings."
- Why unresolved: The paper shows that while contextualization helps, there's no clear methodology for choosing terms, and performance varies widely between choices.
- What evidence would resolve it: Development and validation of a methodology (e.g., based on statistical analysis of co-occurrence patterns or automated term discovery) that consistently identifies effective contextualization terms across different material properties.

### Open Question 3
- Question: How can the limitations of autoregressive LLMs (inability to access future context) be overcome for material property prediction?
- Basis in paper: [explicit] The paper identifies this as a fundamental limitation, noting that "due to the causal attention masking, a LLM can only integrate information from the context that has appeared before the word of interest in the sequence" which is problematic for tasks like predicting Curie temperatures from chemical formulas.
- Why unresolved: The paper doesn't propose or test solutions to this architectural limitation of LLMs for materials science applications.
- What evidence would resolve it: Demonstration of improved performance using either bidirectional models fine-tuned for materials science, modified autoregressive architectures that can access relevant future context, or preprocessing strategies that rearrange text to place relevant information before the target token.

## Limitations
- Performance highly sensitive to query term selection, requiring extensive optimization
- Only tested one LLM (Llama 2 13B) and one compositional strategy
- Evaluation focused on ranking accuracy without absolute prediction accuracy
- LLM material science knowledge bounded by training corpus coverage

## Confidence

**High Confidence**: The observation that composition-weighted elemental embeddings outperform direct chemical formula embeddings is well-supported by consistent results across multiple properties and query terms.

**Medium Confidence**: The claim that contextualization terms improve performance is supported but requires careful term selection, with performance varying widely between choices.

**Low Confidence**: The assertion that this approach can reliably predict material properties without additional training is not supported by the inconsistent performance and need for extensive query optimization.

## Next Checks
1. Test the methodology across multiple LLMs (different architectures, sizes, and training datasets) to determine whether performance is model-dependent or generalizable.
2. Systematically evaluate a comprehensive set of query terms for each property to map the sensitivity landscape and identify optimal contextualization strategies.
3. Extend evaluation beyond ranking to measure absolute prediction accuracy (e.g., mean absolute error) to assess practical utility for property prediction tasks.