---
ver: rpa2
title: Two-Phase Dynamics of Interactions Explains the Starting Point of a DNN Learning
  Over-Fitted Features
arxiv_id: '2405.10262'
source_url: https://arxiv.org/abs/2405.10262
tags:
- interactions
- input
- samples
- training
- order
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the dynamics of DNN learning interactions,
  revealing that DNNs learn interactions in two phases. The first phase mainly penalizes
  medium and high-order interactions, while the second phase learns interactions of
  gradually increasing orders.
---

# Two-Phase Dynamics of Interactions Explains the Starting Point of a DNN Learning Over-Fitted Features

## Quick Facts
- **arXiv ID**: 2405.10262
- **Source URL**: https://arxiv.org/abs/2405.10262
- **Reference count**: 40
- **Primary result**: DNNs learn interactions in two phases; the first penalizes medium/high-order interactions, the second learns gradually increasing orders, with this transition marking the start of over-fitting

## Executive Summary
This paper investigates the dynamics of how deep neural networks (DNNs) learn interactions between input features during training. The authors propose that DNNs exhibit a two-phase learning pattern: an initial phase where high-order interactions are penalized, followed by a second phase where interactions of gradually increasing orders are learned. Critically, this transition temporally aligns with when the gap between training and testing losses begins to widen, marking the onset of over-fitting. The findings are validated across multiple architectures (CNNs, Transformers, GNNs) and tasks (image classification, NLP, 3D point cloud classification).

## Method Summary
The authors analyze DNN training dynamics by extracting AND-OR interactions from model outputs on masked samples using a sampling-based approximation method. They train various DNN architectures (LeNet, VGG, AlexNet, BERT, DGCNN) on multiple datasets (MNIST, CIFAR-10, CUB200-2011, Tiny-ImageNet, SST-2, ShapeNet) using SGD optimizer for 512 epochs. The interaction distribution across different orders is computed at various training epochs, and the gap between training and testing losses is monitored. The analysis focuses on how the strength of low, medium, and high-order interactions evolves during training and how this relates to generalization performance.

## Key Results
- DNNs exhibit a two-phase interaction learning pattern: first penalizing high-order interactions, then learning increasingly complex interactions
- The transition between phases temporally aligns with the widening gap between training and testing losses
- High-order interactions demonstrate weaker generalization power than low-order interactions, as measured by Jaccard similarity
- The two-phase phenomenon is observed consistently across different architectures (CNNs, Transformers, GNNs) and tasks (image, text, 3D data)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DNNs learn interactions in two distinct phases during training, with the first phase eliminating high-order interactions and the second phase gradually learning higher-order interactions.
- Mechanism: During the first phase, the network penalizes and eliminates interactions of medium and high orders, focusing on learning only low-order interactions. In the second phase, the network begins to learn interactions of gradually increasing orders, which corresponds to the beginning of learning over-fitted features.
- Core assumption: The sparsity property of interactions holds, meaning a well-trained DNN only encodes a small number of salient interactions for inference.
- Evidence anchors:
  - [abstract] "The first phase mainly penalizes interactions of medium and high orders, and the second phase mainly learns interactions of gradually increasing orders."
  - [section] "In the first phase of the training process, as Figure 2 shows, the strength of the high-order and medium-order interactions encoded by the DNN gradually decreases, while the strength of the low-order interactions gradually increases."
  - [corpus] Found 25 related papers; average neighbor FMR=0.412, but none directly cite this two-phase dynamics mechanism. Weak corpus support for this specific claim.
- Break condition: If the sparsity property does not hold, or if the DNN does not exhibit the characteristic fusiform distribution of interactions before training.

### Mechanism 2
- Claim: The two-phase dynamics is temporally aligned with the gap between testing and training losses, marking the starting point of learning over-fitted features.
- Mechanism: The gap between training and testing losses remains relatively small during the first phase, indicating the DNN has not learned over-fitted features. Shortly after entering the second phase, the gap widens rapidly, signaling the beginning of learning over-fitted features.
- Core assumption: The gap between training and testing losses is a reliable metric for the over-fitting level of a model.
- Evidence anchors:
  - [abstract] "We can consider the two-phase phenomenon as the starting point of a DNN learning over-fitted features."
  - [section] "We have found that the two-phase phenomenon and the gap between the testing and training losses are aligned temporally during the training process."
  - [corpus] No direct corpus evidence supporting this specific alignment claim.
- Break condition: If the gap between training and testing losses does not accurately reflect the over-fitting level, or if other factors influence the gap.

### Mechanism 3
- Claim: High-order interactions have weaker generalization power than low-order interactions, which explains the dynamics of the generalization power of the DNN during training.
- Mechanism: As the DNN learns interactions of gradually increasing orders in the second phase, the generalization power decreases because high-order interactions are less generalizable than low-order interactions.
- Core assumption: The generalization power of interactions is inversely related to their order.
- Evidence anchors:
  - [abstract] "In particular, we have also verified the claim that high-order interactions have weaker generalization power than low-order interactions."
  - [section] "Zhou et al. [32] have found that high-order interactions have weaker generalization power than low-order interactions."
  - [corpus] Found 25 related papers; average neighbor FMR=0.412, but none directly test this generalization power claim for interactions of different orders.
- Break condition: If high-order interactions do not consistently show weaker generalization power, or if other factors influence the generalization power more significantly.

## Foundational Learning

- **Concept**: Interaction theory and AND-OR interaction decomposition
  - **Why needed here**: The entire analysis is built on the foundation of interaction theory, which allows the DNN's inference to be decomposed into a set of AND and OR interactions between input variables.
  - **Quick check question**: Can you explain the difference between an AND interaction and an OR interaction in the context of DNN inference?

- **Concept**: Sparsity property of interactions
  - **Why needed here**: The sparsity property ensures that a well-trained DNN only encodes a small number of salient interactions for inference, which is crucial for the two-phase dynamics analysis.
  - **Quick check question**: What does the sparsity property imply about the number of salient interactions a DNN typically encodes for a given input sample?

- **Concept**: Universal matching property of interactions
  - **Why needed here**: The universal matching property guarantees that the DNN's outputs on all masked samples can be accurately matched by the numerical effects of a small number of salient interactions, validating the use of interactions as primitive inference patterns.
  - **Quick check question**: How does the universal matching property support the claim that interactions can faithfully explain the DNN's inference logic?

## Architecture Onboarding

- **Component map**: DNN model -> Interaction extraction module -> Analysis components
- **Critical path**: 1) Train DNN on dataset. 2) Extract interactions at different training epochs. 3) Analyze the distribution of interactions over different orders. 4) Identify the two-phase dynamics and its alignment with the gap between training and testing losses.
- **Design tradeoffs**: The choice of interaction extraction method (e.g., sampling-based approximation) affects computational cost and accuracy. The threshold for salient interactions influences the sparsity of the interaction set. The order of interactions considered impacts the granularity of the analysis.
- **Failure signatures**: If the two-phase dynamics is not observed, it could indicate issues with the interaction extraction method, the DNN architecture, or the dataset. If the alignment with the gap between training and testing losses is not found, it might suggest that the gap is not a reliable metric for over-fitting in this context.
- **First 3 experiments**:
  1. Train a simple DNN (e.g., LeNet) on MNIST and extract interactions at different epochs to verify the two-phase dynamics.
  2. Compare the distribution of interactions over different orders for a DNN trained with and without noise labels to validate the claim that high-order interactions have weaker generalization power.
  3. Train multiple DNNs with different architectures on various datasets to demonstrate the universality of the two-phase dynamics phenomenon.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How do different DNN architectures affect the order distribution of interactions during the two-phase dynamics?
- **Basis in paper**: [explicit] The paper tests LeNet, VGG-11/13/16, AlexNet, Bert-Medium/Tiny, and DGCNN on various datasets.
- **Why unresolved**: While the paper shows that all tested architectures exhibit the two-phase phenomenon, it doesn't deeply analyze how architectural differences (e.g., depth, width, attention mechanisms) influence the order distribution of interactions during each phase.
- **What evidence would resolve it**: Detailed experiments comparing interaction order distributions across different architectures (e.g., CNNs vs. Transformers vs. GNNs) at various training epochs, including ablation studies on architectural components.

### Open Question 2
- **Question**: What is the precise relationship between the order of interactions and their generalization power across different tasks and datasets?
- **Basis in paper**: [explicit] The paper shows that high-order interactions have weaker generalization power than low-order interactions using Jaccard similarity on SST-2, MNIST, CIFAR-10, CUB200-2011, and Tiny-ImageNet datasets.
- **Why unresolved**: The paper provides evidence for this relationship but doesn't establish a precise mathematical relationship or explore how this relationship might vary across different types of tasks (e.g., image classification vs. NLP vs. point cloud classification) or dataset characteristics.
- **What evidence would resolve it**: Quantitative analysis of the generalization power-order relationship across diverse tasks and datasets, potentially including a theoretical framework explaining why higher-order interactions are less generalizable.

### Open Question 3
- **Question**: Can the two-phase dynamics of interaction learning be leveraged to develop more effective early stopping criteria for DNN training?
- **Basis in paper**: [inferred] The paper identifies that the two-phase dynamics is temporally aligned with the gap between testing and training losses, and that the second phase marks the beginning of learning over-fitted features.
- **Why unresolved**: While the paper identifies the starting point of learning over-fitted features, it doesn't explore how this knowledge could be practically applied to improve training strategies, such as developing adaptive early stopping methods based on interaction order distributions.
- **What evidence would resolve it**: Experiments demonstrating that monitoring interaction order distributions during training can predict overfitting more accurately than traditional metrics, and showing improved model performance when using such criteria for early stopping.

## Limitations

- The core finding of two-phase interaction dynamics is well-supported empirically but lacks strong theoretical grounding.
- The sparsity and universal matching properties are assumed rather than proven for general DNN architectures.
- The sampling-based approximation for interaction calculation introduces potential computational noise that isn't quantified.
- The claim about high-order interactions having weaker generalization power relies on a single cited study rather than direct experimental validation in this work.

## Confidence

- **High Confidence**: The empirical observation of two distinct phases in interaction learning across multiple architectures and datasets. The temporal alignment between phase transitions and loss gap changes is robust.
- **Medium Confidence**: The interpretation that the second phase marks the beginning of over-fitting. While the timing aligns, causal relationships aren't definitively established.
- **Low Confidence**: The theoretical explanation of why high-order interactions have weaker generalization power. The evidence is indirect and based on previous work rather than direct experimentation.

## Next Checks

1. **Controlled Experiment on Generalization Power**: Design an experiment that directly compares the generalization performance of high-order versus low-order interactions by systematically manipulating interaction orders in trained models and measuring their test performance.

2. **Theoretical Analysis of Phase Transitions**: Develop mathematical analysis explaining why the first phase penalizes high-order interactions and why this coincides with minimal over-fitting. This could involve analyzing the loss landscape and interaction sparsity during different training phases.

3. **Alternative Over-fitting Metrics**: Validate the claim that the two-phase dynamics marks the onset of over-fitting by comparing with alternative over-fitting indicators such as sharpness of minima, PAC-Bayes bounds, or information bottleneck measures.