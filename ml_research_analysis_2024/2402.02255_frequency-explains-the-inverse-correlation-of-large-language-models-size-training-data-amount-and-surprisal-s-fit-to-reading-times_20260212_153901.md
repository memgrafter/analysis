---
ver: rpa2
title: Frequency Explains the Inverse Correlation of Large Language Models' Size,
  Training Data Amount, and Surprisal's Fit to Reading Times
arxiv_id: '2402.02255'
source_url: https://arxiv.org/abs/2402.02255
tags:
- surprisal
- variants
- reading
- training
- times
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates why larger Transformer-based language models
  with more training data yield surprisal estimates that poorly predict human reading
  times, focusing on the role of word frequency. Experiments across four language
  model families and four reading time corpora reveal that the inverse correlation
  between model size and surprisal fit is strongest for rare words, driven by larger
  models' disproportionately accurate predictions of them.
---

# Frequency Explains the Inverse Correlation of Large Language Models' Size, Training Data Amount, and Surprisal's Fit to Reading Times

## Quick Facts
- arXiv ID: 2402.02255
- Source URL: https://arxiv.org/abs/2402.02255
- Authors: Byung-Doh Oh; Shisen Yue; William Schuler
- Reference count: 15
- Key outcome: Larger Transformer-based language models with more training data yield surprisal estimates that poorly predict human reading times, driven by their disproportionately accurate predictions of rare words.

## Executive Summary
This study investigates why larger language models with more training data produce surprisal estimates that diverge from human reading times. Through experiments across four language model families and four reading time corpora, the authors demonstrate that word frequency is the key explanatory factor. Larger models learn to predict rare words more accurately than smaller models, and this superhumanly complex association for rare words causes their surprisal estimates to poorly predict human reading times.

## Method Summary
The study uses linear mixed-effects regression models to predict reading times from surprisal estimates calculated by four language model families (GPT-2, GPT-Neo, OPT, Pythia) on four corpora (Natural Stories, Dundee, GECO, Provo). Models are evaluated across different training checkpoints and sizes. Feature attribution analysis is conducted by limiting context window sizes. Word frequency effects are analyzed by partitioning data into quintiles based on unigram log-probabilities from the Pile dataset.

## Key Results
- The inverse correlation between model size and surprisal fit to reading times is strongest for rare words
- Larger models show disproportionately accurate predictions for rare words compared to smaller models
- Training dynamics reveal all model variants learn to predict rare words over time, with larger variants doing so more accurately
- Feature attribution analysis shows larger models rely on both longer effective context windows and stronger local associations for rare word prediction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Larger models learn more accurate predictions for rare words, causing surprisal to diverge from human reading times.
- Mechanism: Larger models have more parameters and training data, allowing them to learn complex associations for rare words that humans don't use.
- Core assumption: Human reading times are more predictable by simpler models that don't overfit rare words.
- Evidence anchors:
  - [abstract]: "The current work presents a series of analyses showing that word frequency is a key explanatory factor underlying these two trends."
  - [section]: "residual errors from four LM families on four corpora show that the inverse correlation between model size and fit to reading times is the strongest on the subset of least frequent words"
  - [corpus]: Strong evidence from four language model families (GPT-2, GPT-Neo, OPT, Pythia) and four reading time corpora (Natural Stories, Dundee, GECO, Provo)

### Mechanism 2
- Claim: Training dynamics show all model variants learn to predict rare words during later training steps, but larger variants do so more accurately.
- Mechanism: As models see more training data, they shift from predicting frequent words to rare words, with larger models learning faster and more accurately.
- Core assumption: The learning trajectory of language models follows a pattern where rare word prediction improves with more data and larger models.
- Evidence anchors:
  - [abstract]: "training dynamics reveal that during later training steps, all model variants learn to predict rare words and that larger model variants do so more accurately"
  - [section]: "model variants of all sizes learn to accurately predict frequent tokens and also show little difference in surprisal values during early training steps"
  - [corpus]: Training dynamics analysis of Pythia models shows clear progression in rare word prediction accuracy

### Mechanism 3
- Claim: Larger models use both longer effective context windows and stronger local associations to predict rare words.
- Mechanism: Feature attribution analysis shows that when context is limited, larger models show greater surprisal increases, indicating reliance on early context and strong local associations.
- Core assumption: The ability to utilize longer contexts and stronger associations directly enables more accurate rare word prediction.
- Evidence anchors:
  - [abstract]: "a feature attribution analysis demonstrates that larger model variants are able to accurately predict rare words based on both an effectively longer context window size as well as stronger local associations"
  - [section]: "larger model variants demonstrate larger degrees of increase as a result of limiting the context window"
  - [corpus]: Feature attribution analysis across four corpora provides direct evidence of context window effects

## Foundational Learning

- Concept: Linear mixed-effects modeling
  - Why needed here: To account for both fixed effects (surprisal, word length, etc.) and random effects (subject, sentence) in reading time data
  - Quick check question: What's the difference between a fixed effect and a random effect in the context of reading time regression models?

- Concept: Byte-pair encoding (BPE) tokenization
  - Why needed here: All language models use different BPE tokenizers, affecting how words are represented and how surprisal is calculated
  - Quick check question: How does BPE tokenization affect surprisal calculations for rare words that get split into multiple tokens?

- Concept: Feature attribution methods
  - Why needed here: To understand which parts of the context contribute to predictions, particularly for rare words
  - Quick check question: What's the difference between occlusion-based feature attribution and gradient-based methods?

## Architecture Onboarding

- Component map: Data preprocessing -> Tokenization -> LM surprisal calculation -> Regression modeling -> Residual analysis -> Feature attribution
- Critical path: Reading time data -> LM surprisal estimates -> Regression model fit -> Residual error analysis -> Frequency-based partitioning
- Design tradeoffs: Using linear mixed-effects models provides better handling of nested data structure but increases computational complexity compared to simple linear regression
- Failure signatures: Poor fit to reading times could indicate data leakage, tokenization issues, or incorrect handling of spillover effects
- First 3 experiments:
  1. Replicate the frequency-based partitioning of residual errors to confirm inverse correlation strength
  2. Run training dynamics analysis on a subset of Pythia checkpoints to verify learning trajectory patterns
  3. Implement context limitation feature attribution on a smaller scale to verify context window effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the inverse correlation between model size and surprisal fit to reading times generalize to other languages and language families?
- Basis in paper: [explicit] The authors acknowledge this as an "interesting direction for future work" and suggest that the frequency-based explanation should generalize to other languages if they are of sufficient size and trained on large amounts of data.
- Why unresolved: The study only examined English-language models and data from native English speakers.
- What evidence would resolve it: Conducting similar analyses on models trained on other languages (e.g., morphologically rich languages, languages with different word order) and comparing the frequency effects across languages.

### Open Question 2
- Question: What is the precise mechanism by which larger models learn more complex associations for rare words that lead to poorer surprisal fit?
- Basis in paper: [inferred] The authors suggest that larger models have an effectively longer context window and stronger local associations for predicting rare words, but the exact learning dynamics and representations are not fully elucidated.
- Why unresolved: The study used feature attribution to gain insights but did not fully characterize the learned representations or the training dynamics that lead to the complex associations.
- What evidence would resolve it: Detailed analyses of the learned representations, attention patterns, and training dynamics of larger vs. smaller models, potentially using techniques like probing classifiers or analyzing the gradients during training.

### Open Question 3
- Question: How do frequency effects interact with other factors like syntactic complexity, semantic plausibility, and contextual predictability in driving reading times?
- Basis in paper: [inferred] The study focuses on frequency as a key explanatory factor but acknowledges that other factors likely contribute to reading times and surprisal fit.
- Why unresolved: The analyses controlled for some baseline predictors but did not fully disentangle the effects of frequency from other linguistic factors.
- What evidence would resolve it: Experiments that systematically manipulate frequency, syntactic complexity, semantic plausibility, and contextual predictability, and measure their individual and interactive effects on reading times and surprisal fit.

## Limitations

- The analysis relies heavily on specific corpora and model variants, which may limit generalizability
- The feature attribution analysis using context window limitation provides correlational evidence but cannot definitively prove causal mechanisms
- The study focuses on Transformer-based models, so findings may not extend to other architectures

## Confidence

- High Confidence: The inverse correlation between model size and surprisal fit to reading times is well-established across multiple corpora and model families
- Medium Confidence: The mechanisms explaining why larger models learn more accurate predictions for rare words (longer context windows and stronger local associations) are supported by feature attribution analysis
- Low Confidence: The claim that superhumanly complex associations learned by large models cause divergence from human-like expectations is more speculative and relies on indirect evidence

## Next Checks

1. **Ablation study on context window effects:** Systematically vary context window sizes across different model families and measure the impact on rare word prediction accuracy and surprisal fit to reading times

2. **Cross-linguistic validation:** Replicate the analysis on non-English reading time corpora to test whether frequency effects generalize across languages with different morphological and syntactic structures

3. **Alternative feature attribution methods:** Compare the context window limitation approach with gradient-based feature attribution methods to verify that the observed effects are robust across different attribution techniques