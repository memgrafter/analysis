---
ver: rpa2
title: Declarative Design of Neural Predicates in Neuro-Symbolic Systems
arxiv_id: '2405.09521'
source_url: https://arxiv.org/abs/2405.09521
tags:
- image
- digit
- prototype
- neural
- predicates
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the lack of declarativeness in neuro-symbolic
  systems caused by the functional nature of neural predicates. The authors propose
  a framework for designing fully declarative neural predicates by structuring them
  around prototypes that learn domains from data.
---

# Declarative Design of Neural Predicates in Neuro-Symbolic Systems

## Quick Facts
- arXiv ID: 2405.09521
- Source URL: https://arxiv.org/abs/2405.09521
- Reference count: 40
- Key outcome: Framework for fully declarative neural predicates using prototypes achieves comparable performance to DeepProblog (98.4% vs 98.7% accuracy) while enabling arbitrary query answering

## Executive Summary
This paper addresses the fundamental limitation of current neuro-symbolic systems where neural predicates are functional rather than declarative, preventing arbitrary query answering without retraining. The authors propose a framework that structures neural predicates around prototypes learned from data, using an encoding-decoding scheme to relate instances to prototypes in latent space. Implemented within DeepProblog, the approach enables answering both classification and generative queries with the same model. Experiments on MNIST tasks show that declarative neural predicates achieve performance comparable to traditional approaches while providing new capabilities for unseen queries.

## Method Summary
The method involves structuring neural predicates around prototypes that learn domains from data through a variational autoencoder framework. Prototypes are learned as multivariate Gaussian distributions in latent space, with instances encoded to this space and compared for similarity to prototypes. The system uses a prototype membership relation modeled as annotated disjunction to ensure exclusive membership while maintaining probabilistic reasoning. Training combines classification loss with reconstruction loss, enabling the system to learn both discriminative and generative capabilities simultaneously.

## Key Results
- Declarative neural predicates achieve 98.4% accuracy on MNIST digit classification, comparable to DeepProblog's 98.7%
- Generative accuracy of 88.1% on simple queries (digit(?,3)) and 62.2% on complex multi-digit addition queries
- Same model successfully answers arbitrary queries involving neural predicates without retraining
- Learning from direct supervision preserves reasoning capabilities while enabling new query types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Declarative neural predicates can learn prototypes that capture domains of non-symbolic arguments, enabling arbitrary query answering without retraining.
- Mechanism: By structuring neural predicates around prototypes and using an encoding-decoding relation (prototype_match), the system learns latent representations of concepts (e.g., digits) and can sample from these prototypes to answer any query involving the predicate.
- Core assumption: Prototypes are mutually exclusive and can be learned from data using standard neural architectures (e.g., VAEs).
- Evidence anchors:
  - [abstract] "The main idea is to relate instances to prototypes through a relational interpretation of the encoding-decoding scheme."
  - [section 4.1] "We overcome this problem by structuring predicates around prototypes, which learn the domains of non-symbolic arguments from data."
  - [corpus] Weak - neighboring papers focus on general neuro-symbolic frameworks but don't specifically address declarative neural predicates with prototypes.
- Break condition: If prototypes cannot be learned effectively (e.g., poor generative models), the system cannot sample valid instances for unification, breaking arbitrary query answering.

### Mechanism 2
- Claim: Declarative neural predicates preserve learning and reasoning capabilities while enabling new query types.
- Mechanism: The prototype-based approach reuses DeepProblog's inference procedures but changes the semantics of neural predicates, allowing the system to answer both classification and generative queries with the same model.
- Core assumption: The modified neural predicate semantics are compatible with existing inference engines without requiring new special machinery.
- Evidence anchors:
  - [abstract] "We first show that the declarative extension preserves the learning and reasoning capabilities while being able to answer arbitrary queries while only being trained on a single query type."
  - [section 4] "Our framework is designed to avoid changes to the internal mechanisms in (Deep)Problog. The proposed framework changes the semantics of DeepProblog programs but preserves the inference procedure."
  - [corpus] Weak - neighboring papers discuss neuro-symbolic capabilities but don't specifically address preserving reasoning while adding declarativeness.
- Break condition: If the inference procedure cannot handle the modified semantics (e.g., prototype membership probabilities), the system fails to answer queries correctly.

### Mechanism 3
- Claim: Learning from direct supervision achieves comparable performance to traditional neural predicates.
- Mechanism: The prototype-based neural predicates learn to classify digits accurately (98.4% vs 98.7%) while simultaneously learning generative capabilities.
- Core assumption: The more complex task of learning domains through prototypes does not significantly impact classification performance.
- Evidence anchors:
  - [section 5.2] "When learned from direct supervision, prototype-based neural predicates are as effective as their functional counterpart (table 1)."
  - [table 1] "DeepProblog 98.7% vs DeclDeepProblog 98.4%"
  - [corpus] Weak - neighboring papers focus on neuro-symbolic systems generally but don't provide specific performance comparisons for declarative vs functional neural predicates.
- Break condition: If the learning task becomes too complex (e.g., distant supervision), performance degrades significantly, limiting practical applicability.

## Foundational Learning

- Concept: Encoding-decoding scheme for neural predicates
  - Why needed here: Enables relating instances to prototypes in latent space, allowing flexible query answering
  - Quick check question: How does the encode(Image, Prot, P) relation differ when Image is given vs when it's a variable?

- Concept: Prototype membership as annotated disjunction
  - Why needed here: Ensures exclusive membership to prototypes while maintaining probabilistic reasoning
  - Quick check question: Why is exclusive prototype membership important for unification over infinite domains?

- Concept: Variational autoencoder training objective
  - Why needed here: Provides a principled way to learn prototype distributions and reconstruction capabilities
  - Quick check question: What are the three components of the lower bound used to train declarative neural predicates?

## Architecture Onboarding

- Component map:
  Encoder network -> Prototype network -> Decoder network -> Inference engine

- Critical path:
  1. Encode input image to latent space
  2. Compute similarity to prototypes
  3. Sample from closest prototype (for generative queries)
  4. Decode sample to image space
  5. Return result through DeepProblog inference

- Design tradeoffs:
  - Fixed vs learned number of prototypes: Fixed is simpler but less flexible
  - Gaussian vs other distributions: Gaussian enables tractable likelihood computation
  - VAE vs other generative models: VAE provides principled training but may limit expressiveness

- Failure signatures:
  - Poor reconstruction quality: Indicates inadequate decoder or training
  - Prototypes not mutually exclusive: Suggests issues with membership probability computation
  - Performance degradation on distant supervision: Indicates difficulty learning from indirect signals

- First 3 experiments:
  1. Train on direct supervision (digit/2 task) and verify classification accuracy matches DeepProblog
  2. Test arbitrary query answering (e.g., ?-digit(?,3)) and verify generative accuracy
  3. Train on distant supervision (add/3 task) and compare performance to functional neural predicates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the number of prototypes be automatically determined instead of requiring user specification?
- Basis in paper: [explicit] "While we assume a fixed number of prototypes, the prototypes themselves are learned from data with prototype networks... We assume that the user gives the number of prototypes and leave the problem of automatically finding them for future work."
- Why unresolved: The paper acknowledges this as a limitation and explicitly states it as future work without providing a concrete method for automatic determination.
- What evidence would resolve it: An algorithm that can determine the optimal number of prototypes based on training data characteristics, with empirical validation showing improved performance or usability compared to manual specification.

### Open Question 2
- Question: What are the scalability limitations of the proposed framework when dealing with larger, more complex domains beyond MNIST?
- Basis in paper: [explicit] "One of the biggest challenges is the scalability... We have noticed that incorporating exclusive membership to prototypes ensures fast convergence; however, each training iteration takes twice as much time."
- Why unresolved: The paper only provides initial experimental results on MNIST tasks and mentions scalability as a concern without detailed analysis of performance bottlenecks or solutions.
- What evidence would resolve it: Comprehensive benchmarking studies showing computational complexity, memory requirements, and performance degradation on progressively larger datasets, along with proposed optimizations or architectural modifications to address identified bottlenecks.

### Open Question 3
- Question: How can the quality of generated images be improved to better match the true distribution of digits?
- Basis in paper: [explicit] "The generated images, sampled from the selected prototype, look more similar to those generated from another prototype... This issue might be overcome by using a more powerful generative model or training longer."
- Why unresolved: The paper acknowledges that generated images do not fully capture digit characteristics and suggests potential improvements without implementing or validating them.
- What evidence would resolve it: Experimental results comparing different generative architectures (e.g., diffusion models, GANs) or training strategies, with quantitative metrics showing improved image quality and qualitative assessments demonstrating better preservation of digit features.

## Limitations
- Scalability concerns for larger domains due to increased computational complexity
- Fixed number of prototypes requires manual specification rather than automatic determination
- Generated images may not fully capture true digit characteristics, limiting practical utility

## Confidence

**High confidence**: The declarative extension preserves learning and reasoning capabilities (mechanism 2), based on the explicit claim that inference procedures remain unchanged.

**Medium confidence**: Comparable performance on direct supervision (mechanism 3), supported by the reported 98.4% vs 98.7% accuracy but lacking details on experimental setup.

**Medium confidence**: Arbitrary query answering capability (mechanism 1), theoretically plausible given the prototype-based approach but untested for all query types.

## Next Checks

1. **Prototype exclusivity verification**: Visualize prototype distributions in latent space and measure pairwise overlap to confirm mutual exclusivity assumption.

2. **Inference compatibility test**: Implement a minimal DeepProblog program with declarative neural predicates and verify that existing inference engines can handle prototype membership probabilities correctly.

3. **Robustness to supervision type**: Systematically vary the ratio of direct to distant supervision during training and measure the impact on both classification and generative accuracy to identify breaking points.