---
ver: rpa2
title: 'CHORDONOMICON: A Dataset of 666,000 Songs and their Chord Progressions'
arxiv_id: '2410.22046'
source_url: https://arxiv.org/abs/2410.22046
tags:
- chord
- music
- dataset
- chords
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Chordonomicon is a large-scale dataset containing over 666,000
  user-generated songs with chord progressions, structural annotations, genre labels,
  and release dates. The data was collected through web scraping from Ultimate Guitar,
  followed by manual curation and conversion to standardized chord formats.
---

# CHORDONOMICON: A Dataset of 666,000 Songs and their Chord Progressions

## Quick Facts
- arXiv ID: 2410.22046
- Source URL: https://arxiv.org/abs/2410.22046
- Reference count: 26
- Dataset contains over 666,000 user-generated songs with chord progressions

## Executive Summary
Chordonomicon is a large-scale dataset containing over 666,000 user-generated songs with chord progressions, structural annotations, genre labels, and release dates. The data was collected through web scraping from Ultimate Guitar, followed by manual curation and conversion to standardized chord formats. The dataset includes 403,923 tracks with structural part labels, 364,273 with genre information, and 438,809 with release dates. Chord progressions are represented as weighted directed graphs and are also provided in text format using the Harte syntax, enabling integration with music theory ontologies. The dataset supports multiple MIR tasks including chord prediction, genre classification, and decade classification. Baseline experiments demonstrate the dataset's utility, with a transformer-based model achieving 60.13% accuracy on chord prediction and graph kernel methods achieving 40.3% and 26.6% accuracy on decade and genre classification respectively.

## Method Summary
The dataset was created through web scraping of Ultimate Guitar, followed by extensive cleaning and normalization. Songs were processed to convert chords into the Harte syntax format, then transformed into weighted directed graphs representing chord progressions. The dataset was split into training, validation, and test sets, with metadata preserved including genre, release date, and structural annotations. Baseline experiments used a GPT-2 transformer for chord prediction and graph kernel methods (WL, Shortest Path, Sampling) for genre and decade classification tasks.

## Key Results
- Transformer-based model achieves 60.13% accuracy on chord prediction task
- Graph kernel methods achieve 40.3% accuracy on decade classification and 26.6% on genre classification
- Dataset includes 667,858 tracks with 736 unique chords, enabling large-scale MIR research
- Provides both text-based (Harte syntax) and graph-based representations of chord progressions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large-scale chord progression data enables transformer-based models to learn long-range harmonic dependencies better than n-gram or RNN approaches.
- Mechanism: Transformers with causal attention can model chord progressions as sequential language, capturing context beyond fixed n-gram windows. The dataset's 667,858 tracks with average 76 chords each provide sufficient statistical diversity for this learning.
- Core assumption: Chord progressions exhibit statistical regularities that can be modeled as language, and the dataset's scale is sufficient to learn these patterns.
- Evidence anchors:
  - [abstract] "baseline experiments demonstrate the dataset's utility, with a transformer-based model achieving 60.13% accuracy on chord prediction"
  - [section] "In our experiments, we wanted to explore the efficacy of transformers (Vaswani et al. 2017) for chord prediction"
  - [corpus] Weak - no direct corpus evidence for transformer performance comparison
- Break condition: If chord progressions are too idiosyncratic or the vocabulary size (736 unique chords) overwhelms the model's capacity to generalize.

### Mechanism 2
- Claim: Graph representation of chord progressions enables effective genre and decade classification through structural pattern recognition.
- Mechanism: Converting chord progressions to weighted directed graphs captures harmonic relationships and progression frequencies. Graph kernels (WL, Shortest Path, Sampling) can then extract structural features for classification tasks.
- Core assumption: The harmonic structure of music contains discriminative information about genre and era that can be captured through graph topology and edge weights.
- Evidence anchors:
  - [section] "Music tracks often feature intricate harmonies, leading to a multitude of chord connections. Graphs are well-known for their ability to model complex structures and relationships"
  - [section] "We employed a baseline approach based on kernel matrices derived from graph kernels"
  - [corpus] Weak - no direct corpus evidence showing graph representation improves classification over sequence-based methods
- Break condition: If graph structural features don't correlate with genre/era distinctions or if the graph representation loses important sequential information.

### Mechanism 3
- Claim: Integration with music theory ontologies through standardized Harte syntax enables hybrid AI systems that combine symbolic knowledge with learned representations.
- Mechanism: The Harte syntax provides a formal representation that links to existing music theory ontologies (Chord Ontology, Functional Harmony Ontology), allowing systems to leverage both learned patterns and symbolic music theory knowledge.
- Core assumption: Music theory knowledge can complement learned representations and improve performance on tasks where pure data-driven approaches struggle.
- Evidence anchors:
  - [abstract] "Chord progressions are unique in their ability to be represented in multiple formats (e.g. text, graph) and the wealth of information chords convey in given contexts"
  - [section] "By utilizing both the Harte syntax and the syntax suggested by the FHO, our dataset can be integrated with the FHO and Chord Ontology"
  - [corpus] Weak - no direct corpus evidence demonstrating performance improvements from ontology integration
- Break condition: If the symbolic knowledge doesn't align well with the learned representations or if the integration overhead outweighs performance benefits.

## Foundational Learning

- Concept: Music Information Retrieval (MIR) fundamentals
  - Why needed here: Understanding the domain-specific challenges of working with music data, including copyright constraints, representation formats, and evaluation metrics
  - Quick check question: What are the key differences between symbolic (chord progressions) and audio-based MIR tasks, and why does this matter for dataset design?

- Concept: Graph representation learning
  - Why needed here: The dataset includes graph representations of chord progressions, requiring understanding of graph kernels, graph neural networks, and their application to music data
  - Quick check question: How do different graph kernels (WL, Shortest Path, Sampling) capture different aspects of graph structure, and which might be most appropriate for harmonic progression analysis?

- Concept: Transformer architectures and language modeling
  - Why needed here: The baseline experiments use transformer models for chord prediction, requiring understanding of causal attention, tokenization strategies, and sequence modeling
  - Quick check question: How does causal attention in transformers differ from bidirectional attention, and why is this important for sequence prediction tasks like chord prediction?

## Architecture Onboarding

- Component map: Web scraping → Cleaning and normalization → Harte syntax conversion → Graph representation generation → Model training (transformers/graph kernels) → Evaluation and analysis
- Critical path: Data collection and cleaning → Graph representation generation → Model selection and training → Performance evaluation on chord prediction and classification tasks
- Design tradeoffs: Large vocabulary size (736 chords) vs. model capacity; graph representation complexity vs. information preservation; symbolic ontology integration vs. computational overhead
- Failure signatures: Poor performance on chord prediction may indicate tokenization issues or insufficient training data; classification failures may suggest structural features aren't discriminative enough
- First 3 experiments:
  1. Train a simple n-gram baseline on chord progressions and compare with transformer performance to establish baseline improvements
  2. Evaluate different graph kernel methods on genre classification to determine which structural features are most informative
  3. Test chord prediction accuracy as a function of sequence length to understand model limitations and optimal input contexts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the Chordonomicon dataset's chord prediction model compare to state-of-the-art models trained on smaller, more curated datasets when evaluated on a common benchmark?
- Basis in paper: [explicit] The paper mentions that chord prediction accuracy is 60.13%, but does not provide a direct comparison to other models or datasets.
- Why unresolved: The paper focuses on introducing the dataset and demonstrating its utility, rather than conducting a comprehensive comparison with existing models. The authors acknowledge the need for further experiments with different tokenization schemes, neural architectures, and hyperparameters.
- What evidence would resolve it: A systematic comparison of the Chordonomicon-based model's performance against models trained on established datasets like Isophonics or Billboard, using a standardized evaluation protocol and metrics.

### Open Question 2
- Question: Can the integration of music theory ontologies, such as the Functional Harmony Ontology (FHO), significantly improve the performance of genre and decade classification tasks on the Chordonomicon dataset?
- Basis in paper: [explicit] The authors propose enriching the dataset with music theory ontologies and suggest that this could improve classification performance, but they do not provide experimental results to support this claim.
- Why unresolved: The paper presents a baseline classification approach using graph kernels but does not explore the potential benefits of semantic enrichment. The authors acknowledge this as a direction for future work.
- What evidence would resolve it: Experiments comparing the classification performance of models trained on the raw dataset versus models trained on the semantically enriched dataset, using the same evaluation metrics and cross-validation procedures.

### Open Question 3
- Question: How does the Chordonomicon dataset's graph representation facilitate the application of graph neural networks (GNNs) for music-related tasks, and what is the potential performance gain compared to traditional sequence-based approaches?
- Basis in paper: [inferred] The paper introduces a graph representation of the dataset and mentions the potential for applying graph machine learning techniques, but does not provide experimental results or a detailed analysis of the graph structure's properties.
- Why unresolved: The paper focuses on introducing the dataset and its graph representation but does not explore the potential of GNNs for various music-related tasks. The authors acknowledge the need for further experiments in this area.
- What evidence would resolve it: A comprehensive study comparing the performance of GNN-based models and sequence-based models (e.g., transformers) on various tasks (e.g., chord prediction, genre classification) using the Chordonomicon dataset, with a detailed analysis of the graph structure's impact on model performance.

## Limitations
- Dataset bias toward rock, pop, and metal genres due to Ultimate Guitar's user demographics
- Chord transcription accuracy is user-dependent and unverified
- Graph kernel methods show relatively low performance (40.3% and 26.6%) suggesting potential limitations in capturing musical features
- Claims about ontology integration benefits remain speculative without empirical validation

## Confidence
**High confidence**: The dataset creation methodology is well-documented and reproducible, with clear procedures for web scraping, cleaning, and conversion to standardized formats. The transformer-based chord prediction results are reliable within the experimental setup described.

**Medium confidence**: The baseline performance metrics are valid for the specific experimental conditions but may not generalize to all chord prediction or classification scenarios. The integration potential with music theory ontologies is conceptually sound but untested in practice.

**Low confidence**: The claims about graph representations being superior to other methods for genre and decade classification lack comparative experiments with alternative approaches. The utility of ontology integration for improving model performance remains speculative without empirical validation.

## Next Checks
1. **Bias analysis**: Conduct a systematic analysis of genre and era representation in the dataset to quantify potential biases and assess their impact on model generalization across different musical styles.

2. **Baseline comparison**: Implement and evaluate traditional n-gram and RNN models on the chord prediction task to establish whether transformers provide significant advantages over simpler sequence models for this specific problem.

3. **Ontology integration experiment**: Design and execute an experiment testing whether incorporating music theory knowledge from the Chord Ontology or Functional Harmony Ontology improves chord prediction or classification performance compared to pure data-driven approaches.