---
ver: rpa2
title: Plastic Learning with Deep Fourier Features
arxiv_id: '2410.20634'
source_url: https://arxiv.org/abs/2410.20634
tags:
- deep
- linear
- networks
- network
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses loss of plasticity in continual learning,
  where neural networks become less trainable on new tasks over time. The authors
  identify that linear function approximation and deep linear networks do not suffer
  from this problem, providing theoretical analysis for both cases.
---

# Plastic Learning with Deep Fourier Features

## Quick Facts
- **arXiv ID:** 2410.20634
- **Source URL:** https://arxiv.org/abs/2410.20634
- **Reference count:** 25
- **Primary result:** Deep Fourier features significantly improve continual learning performance across CIFAR10, CIFAR100, and tiny-ImageNet by maintaining network trainability through adaptive linearity.

## Executive Summary
This paper addresses the problem of loss of plasticity in continual learning, where neural networks become less trainable on new tasks over time. The authors identify that linear function approximation and deep linear networks avoid this problem due to their optimization properties, and propose deep Fourier features as a solution that combines linearity's trainability benefits with nonlinear networks' expressive power. By concatenating sine and cosine activations in every layer, the method creates an adaptively-linear network where each pre-activation connects to one unit well-approximated by a linear function, significantly improving performance on multiple continual learning scenarios.

## Method Summary
Deep Fourier features replace standard ReLU activations with concatenated sin/cos activations in every hidden layer of standard architectures like ResNet-18. This creates an adaptively-linear network where for any pre-activation value, one of the two sinusoidal functions is approximately linear, maintaining an embedded deep linear network structure while preserving nonlinear expressiveness. The method works as a drop-in replacement with approximately half the parameters due to the dual activation structure, and is evaluated on CIFAR10, CIFAR100, and tiny-ImageNet under various continual learning scenarios including label noise, class-incremental learning, and random label memorization.

## Key Results
- Deep Fourier features significantly outperform standard ReLU networks and other plasticity mitigation techniques across multiple datasets and continual learning scenarios
- The method achieves high trainability, allowing for higher regularization strengths and better generalization in continual learning settings
- Performance improvements are consistent across different task configurations, with notable gains in scenarios involving label noise and class-incremental learning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Linear function approximation and deep linear networks avoid loss of plasticity because their gradient dynamics remain effective for continual learning tasks.
- **Mechanism:** The convexity of linear function approximation ensures a unique global optimum per task, preventing interference from previous task solutions. Deep linear networks maintain effective learning due to preconditioning that accelerates optimization similar to linear dynamics.
- **Core assumption:** Strong convexity of the objective function and bounded parameters at global optima across tasks.
- **Evidence anchors:** [abstract] "linear function approximation, as well as a special case of deep linear networks, do not suffer from loss of plasticity"; [section] "Theorem 1...assuming the objective function is µ-strongly convex"
- **Break condition:** If the objective function is not strongly convex or parameters at global optima become unbounded.

### Mechanism 2
- **Claim:** Deep Fourier features create an adaptively-linear network where each pre-activation connects to one unit well-approximated by a linear function, maintaining trainability while preserving nonlinear expressiveness.
- **Mechanism:** By concatenating sine and cosine activations, one of the two sinusoidal functions is always approximately linear for any given pre-activation value, creating a network that embeds a deep linear network while retaining nonlinearity.
- **Core assumption:** For any z, either sin(x) or cos(x) can be approximated by a linear function with bounded error on a local interval around z.
- **Evidence anchors:** [abstract] "deep Fourier features - concatenating sine and cosine activations in every layer"; [section] "Proposition 1. For any z, there exists a linear function, Lz(x) = a(z)x + b(z), such that either: |sin(x) − Lz(x)| ≤ c, or |cos(x) − Lz(x)| ≤ c"
- **Break condition:** If the approximation error exceeds acceptable bounds or if the concatenation strategy fails to maintain the embedded linear structure.

### Mechanism 3
- **Claim:** High unit sign entropy prevents unit saturation and linearization, maintaining plasticity in neural networks.
- **Mechanism:** Networks with high unit sign entropy have hidden units that are positive on approximately half the inputs, avoiding the problems of unit saturation (low entropy, mostly negative) and unit linearization (low entropy, mostly positive).
- **Core assumption:** Unit sign entropy correlates with the network's ability to maintain effective gradient flow during continual learning.
- **Evidence anchors:** [section] "Definition 1 (Unit Sign Entropy). The entropy, H, of the unit's sign, sgn(h(x)), on a distribution of inputs to the network, p(x), is given by H(sgn(h(x))) = Ep(x)[sgn(h(x))]"; [section] "We show that linear networks have high unit sign entropy, meaning that the sign of a hidden unit on different inputs is positive on approximately half the inputs"
- **Break condition:** If unit sign entropy cannot be maintained across tasks or if other factors dominate plasticity loss.

## Foundational Learning

- **Concept:** Convex optimization and strong convexity
  - Why needed here: The theoretical proof that linear function approximation avoids loss of plasticity relies on strong convexity assumptions to guarantee unique global optima and bounded suboptimality gaps.
  - Quick check question: What property of the objective function ensures that gradient descent converges to a unique global optimum regardless of initialization?

- **Concept:** Gradient dynamics and preconditioning in deep linear networks
  - Why needed here: Understanding how deep linear networks differ from standard deep networks in their optimization dynamics is crucial for explaining their sustained plasticity.
  - Quick check question: How does the preconditioner P_θ in deep linear networks affect the effective gradient dynamics compared to standard deep networks?

- **Concept:** Taylor series approximation and error bounds
  - Why needed here: The proof that deep Fourier features maintain approximate linearity relies on Taylor series remainder analysis to bound the approximation error.
  - Quick check question: What mathematical tool is used to show that one of the sinusoidal functions (sin or cos) can be approximated by a linear function with bounded error?

## Architecture Onboarding

- **Component map:** Input -> Linear transformation -> Deep Fourier features (sin+cos concatenation) -> Linear transformation -> Deep Fourier features -> ... -> Output layer
- **Critical path:** Data flows through linear transformations followed by deep Fourier feature concatenations in each hidden layer. The key insight is that for any pre-activation value, one of the two sinusoidal outputs will be approximately linear, maintaining an embedded deep linear network structure.
- **Design tradeoffs:** Deep Fourier features reduce the effective width of each layer by half (due to concatenation) but provide better plasticity. This tradeoff between parameter efficiency and trainability must be balanced based on task complexity and dataset size.
- **Failure signatures:** If trainability degrades over tasks (loss of plasticity), check if the sinusoidal approximation error is too large. If generalization suffers, consider regularization. If training becomes unstable, verify the initialization and learning rate settings.
- **First 3 experiments:**
  1. Replace ReLU activations in a simple MLP with deep Fourier features on MNIST random label memorization to verify maintained trainability.
  2. Test different depths of deep Fourier networks on CIFAR10 with random label non-stationarity to find optimal depth for plasticity.
  3. Compare deep Fourier features with standard ReLU networks on CIFAR100 class-incremental learning to validate generalization benefits.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the theoretical relationship between unit sign entropy and the trainability of neural networks in continual learning?
- **Basis in paper:** [explicit] The paper identifies unit sign entropy as a key metric for understanding saturation and linearization issues in activation functions, and empirically shows that higher unit sign entropy correlates with better trainability.
- **Why unresolved:** While the paper provides empirical evidence linking unit sign entropy to trainability, a rigorous theoretical framework explaining this relationship is lacking.
- **What evidence would resolve it:** A mathematical proof or formal analysis demonstrating how unit sign entropy directly impacts gradient dynamics and convergence rates in continual learning settings.

### Open Question 2
- **Question:** How do deep Fourier features perform on more complex, high-dimensional tasks beyond image classification?
- **Basis in paper:** [inferred] The paper demonstrates deep Fourier features' effectiveness on standard image datasets (CIFAR, tiny-ImageNet) but doesn't explore their performance on other data types like text, audio, or graph-structured data.
- **Why unresolved:** The adaptive linearity property may not translate equally well to all data modalities, and the sinusoidal activations might have different effects on different types of data.
- **What evidence would resolve it:** Empirical evaluation of deep Fourier features on diverse datasets including natural language processing, speech recognition, and molecular property prediction tasks.

### Open Question 3
- **Question:** What is the optimal depth and width configuration for deep Fourier networks to balance expressivity and trainability?
- **Basis in paper:** [explicit] The paper shows that scaling width improves performance for deep Fourier networks, but the relationship between depth, width, and trainability is not fully characterized.
- **Why unresolved:** The paper only explores limited scaling configurations and doesn't provide theoretical bounds on the optimal architecture size.
- **What evidence would resolve it:** Systematic ablation studies across multiple datasets measuring the trade-off between network capacity, trainability, and generalization performance.

### Open Question 4
- **Question:** How does the concatenation structure in deep Fourier features affect information flow and gradient propagation compared to other architectural modifications?
- **Basis in paper:** [explicit] The paper notes that deep Fourier features halve the effective width of the network and provides theoretical analysis showing how they embed a deep linear network.
- **Why unresolved:** The specific mechanisms by which the sine-cosine concatenation influences learning dynamics are not fully explained, and how this compares to other architectural approaches like attention or gating mechanisms.
- **What evidence would resolve it:** Comparative analysis of gradient norms, information bottleneck metrics, and learning dynamics across different architectural modifications in continual learning scenarios.

## Limitations
- The theoretical guarantees rely on strong convexity assumptions that may not hold in practice for complex deep learning tasks
- The unit sign entropy concept, while theoretically sound, lacks empirical validation through ablation studies
- Performance improvements come at the cost of reduced effective network width due to the concatenation strategy

## Confidence

- **High:** The core claim that linear function approximation avoids plasticity loss is well-supported by theoretical analysis and corroborated by related work
- **Medium:** The effectiveness of deep Fourier features as a practical solution is demonstrated empirically but could benefit from more extensive ablation studies
- **Medium:** The relationship between unit sign entropy and plasticity maintenance is theoretically justified but lacks direct empirical validation

## Next Checks
1. Conduct ablation studies removing either sin or cos components from deep Fourier features to quantify the contribution of each component to plasticity maintenance
2. Test deep Fourier features on more diverse continual learning scenarios including reinforcement learning tasks and generative modeling to assess generalizability
3. Perform sensitivity analysis on the approximation error bounds (c in Proposition 1) to determine how robust the method is to variations in this parameter