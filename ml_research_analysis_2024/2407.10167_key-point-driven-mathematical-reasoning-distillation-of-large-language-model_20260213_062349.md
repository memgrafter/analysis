---
ver: rpa2
title: Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model
arxiv_id: '2407.10167'
source_url: https://arxiv.org/abs/2407.10167
tags:
- reasoning
- slms
- mathematical
- question
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes Key-Point-Driven Mathematical Reasoning Distillation
  (KPDD), a method to improve the reasoning capabilities of Small Language Models
  (SLMs) by breaking down problem-solving into key point extraction and step-by-step
  solution. KPDD generates reasoning datasets using LLMs, then fine-tunes two SLMs:
  one for extracting core questions and problem-solving information, and another for
  generating Chain-of-Thought (KPDD-CoT) or Program-of-Thought (KPDD-PoT) rationales.'
---

# Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model

## Quick Facts
- arXiv ID: 2407.10167
- Source URL: https://arxiv.org/abs/2407.10167
- Authors: Xunyu Zhu; Jian Li; Can Ma; Weiping Wang
- Reference count: 9
- Key outcome: KPDD improves SLM mathematical reasoning by extracting key points before generating Chain-of-Thought or Program-of-Thought rationales, achieving state-of-the-art results on multiple mathematical reasoning datasets.

## Executive Summary
This paper proposes Key-Point-Driven Mathematical Reasoning Distillation (KPDD), a method to improve the reasoning capabilities of Small Language Models (SLMs) by breaking down problem-solving into key point extraction and step-by-step solution. KPDD generates reasoning datasets using LLMs, then fine-tunes two SLMs: one for extracting core questions and problem-solving information, and another for generating Chain-of-Thought (KPDD-CoT) or Program-of-Thought (KPDD-PoT) rationales. Experimental results show that KPDD-CoT significantly improves SLM reasoning performance, while KPDD-PoT achieves state-of-the-art results on mathematical reasoning tasks, reducing semantic misunderstanding errors and enhancing the deployment of efficient SLMs.

## Method Summary
KPDD distills reasoning capabilities from LLMs to SLMs through a two-stage fine-tuning process. First, LLMs generate reasoning datasets using few-shot prompting and filtering. Then, two FlanT5 models are fine-tuned: one extracts key points (core question and problem-solving information) and another generates reasoning steps. KPDD-CoT produces Chain-of-Thought rationales, while KPDD-PoT generates executable Python code to eliminate calculation errors. The method uses GSM8K training data augmented 4x, with learning rate 5e-4, batch size 32, and 10 epochs for fine-tuning.

## Key Results
- KPDD-CoT significantly improves SLM reasoning performance across multiple datasets including GSM8K, ASDiv, SVAMP, and MultiArith
- KPDD-PoT achieves state-of-the-art performance by reducing semantic misunderstanding errors and eliminating calculation errors through code execution
- Mathematical reasoning datasets with diverse reasoning paths effectively enhance SLM performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Breaking the problem-solving process into key point extraction and step-by-step solution reduces semantic misunderstanding errors in small language models.
- Mechanism: By explicitly extracting the core question and problem-solving information before generating reasoning steps, the model can focus on understanding the problem before attempting to solve it.
- Core assumption: Semantic misunderstanding errors occur because models attempt to solve problems without fully understanding the problem structure.
- Evidence anchors:
  - [abstract]: "KPDD enhances the reasoning performance of SLMs by breaking down the problem-solving process into Key Points Extraction and Step-by-Step Solution."
  - [section]: "Our experimental results show that KPDD not only achieves good reasoning performance on the GSM8K test dataset but also performs well on the ASDiv, SV AMP, and MultiArith datasets."
- Break condition: If key point extraction itself introduces errors or if the extracted key points are insufficient for problem solving.

### Mechanism 2
- Claim: Program-of-Thought (PoT) format eliminates calculation errors by offloading arithmetic to Python interpreter.
- Mechanism: Converting reasoning steps into executable Python code separates the logical reasoning from numerical computation, preventing calculation mistakes.
- Core assumption: Calculation errors in CoT reasoning stem from the model's arithmetic capabilities rather than understanding.
- Evidence anchors:
  - [abstract]: "KPDD-PoT achieves state-of-the-art performance in mathematical reasoning tasks, reducing semantic misunderstanding errors and enhancing the deployment of efficient SLMs."
  - [section]: "This approach not only reduces misunderstanding errors but also avoids calculation errors, further enhancing the SLM's mathematical reasoning performance."
- Break condition: If Python interpreter execution fails or if the generated code has logical errors.

### Mechanism 3
- Claim: Multiple reasoning paths in the distillation dataset improve SLM performance through diverse perspectives.
- Mechanism: Training on varied reasoning approaches helps the SLM develop more robust problem-solving strategies and reduces overfitting to a single reasoning pattern.
- Core assumption: Exposure to multiple reasoning strategies helps the model generalize better across different problem types.
- Evidence anchors:
  - [section]: "As the number of reasoning paths in the distillation dataset increases, the SLM tends to achieve better performance."
  - [section]: "This indicates that a mathematical reasoning dataset with diverse reasoning paths can effectively enhance the mathematical reasoning performance of SLMs."
- Break condition: If additional reasoning paths introduce conflicting strategies that confuse the model.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) reasoning
  - Why needed here: Understanding CoT is essential as KPDD builds upon this foundation by enhancing the extraction and organization of reasoning steps
  - Quick check question: What is the main advantage of Chain-of-Thought prompting compared to direct answer generation?

- Concept: Program-of-Thought (PoT) reasoning
  - Why needed here: PoT is a core component of KPDD-PoT that eliminates calculation errors through code execution
  - Quick check question: How does PoT differ from CoT in handling numerical computations?

- Concept: Knowledge distillation
  - Why needed here: The entire KPDD framework relies on transferring reasoning capabilities from larger LLMs to smaller SLMs
  - Quick check question: What are the key challenges in distilling reasoning capabilities compared to factual knowledge?

## Architecture Onboarding

- Component map: LLM generation -> filtering -> KPDD-Key fine-tuning -> KPDD-Solve fine-tuning -> Python interpreter (PoT only) -> final answer
- Critical path: generate reasoning dataset → filter correct answers → fine-tune KPDD-CoT-Key → fine-tune KPDD-CoT-Solve → inference
- Design tradeoffs: The system trades computational efficiency for accuracy by using two SLMs instead of one, but this enables better error handling. The PoT approach trades interpretability for correctness by using code execution instead of model calculations.
- Failure signatures: Understanding errors manifest as incorrect key point extraction, calculation errors appear as wrong answers in CoT but correct logic in PoT, and filtering failures result in incorrect answers being included in the training data.
- First 3 experiments:
  1. Run KPDD-CoT on GSM8K test set to verify improvement over baseline CoTD
  2. Run KPDD-PoT on the same test set to confirm elimination of calculation errors
  3. Test both approaches on out-of-domain datasets (ASDiv, SVAMP, MultiArith) to verify transfer learning capabilities

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the limitations section, potential open questions include: How does KPDD perform when applied to non-mathematical reasoning tasks? What is the impact of varying the number of demonstrations in the few-shot prompting for data generation? How does the performance of KPDD compare when using different LLMs as the teacher model for generating reasoning datasets?

## Limitations
- The filtering mechanism for KPDD datasets is not fully specified, making it difficult to assess how many reasoning paths were actually retained versus discarded
- The exact demonstration set used for few-shot prompting is not provided, which could affect reproducibility
- The computational overhead of running two separate SLMs versus a single model approach is not discussed, limiting understanding of practical deployment implications

## Confidence
- High Confidence: KPDD-CoT improves SLM mathematical reasoning performance compared to baseline CoTD
- Medium Confidence: KPDD-PoT eliminates calculation errors through Python interpreter execution
- Low Confidence: Multiple reasoning paths in the distillation dataset significantly improve SLM performance through diverse perspectives

## Next Checks
1. **Ablation Study on Reasoning Path Diversity**: Conduct controlled experiments varying only the number of reasoning paths (e.g., 1, 3, 5, 10) while keeping dataset size constant to isolate the impact of reasoning diversity on SLM performance.

2. **Error Analysis Across KPDD Components**: Perform detailed error analysis on the GSM8K test set to categorize failures by type (key point extraction errors, reasoning errors, calculation errors, execution errors).

3. **Cross-Dataset Generalization Test**: Evaluate KPDD-CoT and KPDD-PoT on additional out-of-domain mathematical reasoning datasets beyond the four tested to assess whether the claimed transfer learning capabilities hold across a broader range of problem types and difficulty levels.