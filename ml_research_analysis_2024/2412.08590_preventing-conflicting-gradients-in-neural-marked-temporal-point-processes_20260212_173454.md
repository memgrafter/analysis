---
ver: rpa2
title: Preventing Conflicting Gradients in Neural Marked Temporal Point Processes
arxiv_id: '2412.08590'
source_url: https://arxiv.org/abs/2412.08590
tags:
- base
- training
- sahp
- learning
- gradients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that learning neural Marked Temporal Point
  Process (MTPP) models can be interpreted as a two-task learning problem, where tasks
  for predicting event arrival times and event types (marks) share parameters and
  are optimized jointly. This parameter sharing often leads to conflicting gradients
  during training, where gradients for the two tasks point in opposite directions,
  degrading model performance.
---

# Preventing Conflicting Gradients in Neural Marked Temporal Point Processes

## Quick Facts
- arXiv ID: 2412.08590
- Source URL: https://arxiv.org/abs/2412.08590
- Reference count: 40
- Demonstrates that conflicting gradients during joint optimization of time and mark prediction in neural MTPP models can be prevented through novel disjoint parametrizations, significantly improving predictive accuracy.

## Executive Summary
This paper addresses a fundamental issue in learning neural Marked Temporal Point Process (MTPP) models: conflicting gradients that arise when jointly optimizing time and mark prediction tasks. The authors demonstrate that standard MTPP formulations can be interpreted as two-task learning problems with shared parameters, leading to gradient conflicts that degrade performance. They introduce novel parametrizations that enable separate modeling and training of each task, effectively avoiding these conflicts. Experiments on five real-world datasets show significant improvements in predictive accuracy, particularly for mark prediction, attributed to both the prevention of conflicts and more accurate modeling of the dependency between arrival times and marks.

## Method Summary
The method introduces novel parametrizations for neural MTPP models that enable separate modeling and training of time and mark prediction tasks. This is achieved through either duplicated models with disjoint parameters or novel direct parametrizations. The framework also employs distinct history embeddings for time and mark prediction tasks using separate history encoders. Models are trained using Adam optimizer with learning rate 1e-3, with early stopping based on validation loss. The approach is evaluated on five real-world datasets with categorical marks, comparing base models (shared parameters) against base+ (disjoint decoders) and base++ (disjoint history encoders and decoders) configurations.

## Key Results
- Disjoint parametrizations (base+ and base++) significantly reduce conflicting gradients (cos ϕTM values approach 0) compared to base models
- Base++ framework consistently improves mark prediction performance across all datasets, with average LM improvements of 15-30%
- Separate history encoders (base++) provide additional gains over disjoint decoders alone (base+), particularly for the mark prediction task
- Conflicting gradients are most prevalent early in training and diminish as models converge

## Why This Works (Mechanism)

### Mechanism 1
Learning neural MTPP models can be interpreted as a two-task learning problem, where both tasks share parameters and are optimized jointly, often leading to conflicting gradients. The factorization of the joint density into time and mark prediction tasks creates two separate objectives (LT and LM) that share parameters. When gradients from these tasks point in opposite directions (cos ϕTM < 0), following the average gradient can be detrimental to learning each individual task.

### Mechanism 2
Novel parametrizations for neural MTPP models allow separate modeling and training of each task, effectively avoiding the problem of conflicting gradients. By introducing disjoint parametrizations where time and mark prediction tasks use separate sets of parameters (θT and θM), the framework eliminates the source of conflicting gradients. This is achieved through either duplicated models with disjoint parameters or novel direct parametrizations.

### Mechanism 3
Using distinct history embeddings for time and mark prediction tasks further enhances the separation of tasks and improves performance. By employing separate history encoders (ENCT and ENCM) that produce different embeddings (hT and hM) for each task, the framework allows the model to capture information relevant to each task independently, leading to better overall performance.

## Foundational Learning

- **Concept**: Temporal Point Processes and Marked Temporal Point Processes (MTPP)
  - Why needed here: Understanding the mathematical framework of MTPP is crucial as the paper builds on this foundation to introduce the two-task learning problem and the issue of conflicting gradients.
  - Quick check question: Can you explain the difference between a simple temporal point process and a marked temporal point process?

- **Concept**: Multi-task Learning and Conflicting Gradients
  - Why needed here: The paper interprets learning MTPP as a multi-task learning problem and identifies conflicting gradients as a key issue. Understanding these concepts is essential to grasp the problem and the proposed solution.
  - Quick check question: What are conflicting gradients in the context of multi-task learning, and why are they problematic?

- **Concept**: Neural Network Parametrizations and Factorization
  - Why needed here: The paper introduces novel parametrizations for MTPP models, involving the factorization of the joint density. Understanding neural network parametrizations and factorization techniques is important for implementing the proposed framework.
  - Quick check question: How does the factorization of the joint density into time and mark prediction tasks enable separate modeling and training?

## Architecture Onboarding

- **Component map**: Event Encoder -> History Encoder -> Decoder -> NLL Computation -> Gradient Descent
- **Critical path**: 
  1. Encode each event in the history
  2. Use history encoder(s) to create history representation(s)
  3. Use decoder(s) to define the MTPP model(s)
  4. Compute the negative log-likelihood (NLL)
  5. Optimize the NLL using gradient descent
- **Design tradeoffs**: Shared vs. separate parameters for time and mark prediction tasks; single vs. separate history encoders for time and mark prediction tasks; complexity of parametrizations vs. modeling power
- **Failure signatures**: Conflicting gradients during training (cos ϕTM < 0); degraded performance on either time or mark prediction task; high gradient magnitude similarity (GMS) with conflicting gradients
- **First 3 experiments**:
  1. Implement a baseline MTPP model and verify the occurrence of conflicting gradients during training.
  2. Implement the proposed framework with separate decoders and compare performance to the baseline.
  3. Implement the advanced framework with separate history encoders and compare performance to the previous implementation.

## Open Questions the Paper Calls Out

### Open Question 1
How do conflicting gradients in neural MTPP models scale with increasing model capacity and dataset size? The paper only tested a limited range of model capacities (25K-100K parameters) and didn't explore very large-scale datasets or extremely high-capacity models. Systematic experiments scaling both model size (10x-1000x current size) and dataset size across multiple orders of magnitude, measuring CG, GMS, TPI, and task performance metrics at each scale would resolve this.

### Open Question 2
How does the proposed framework perform when extended to more complex event types beyond categorical marks, such as temporal graphs or spatio-temporal point processes? The authors acknowledge this limitation in the conclusion, stating they focused solely on categorical marks and that investigating conflicting gradients in more complex scenarios is a promising future direction. Implementation and evaluation of the framework on datasets with temporal graphs, continuous marks, or spatio-temporal point processes, measuring whether conflicts still emerge and if the disjoint parametrizations remain beneficial would resolve this.

### Open Question 3
How does the choice of proper scoring rule beyond negative log-likelihood affect the emergence and impact of conflicting gradients in neural MTPP models? The authors discuss extending their framework to other proper scoring rules like CRPS for time prediction and Brier score for mark prediction, noting this as future work. All experiments used negative log-likelihood, so it's unknown whether different scoring rules would lead to different conflict patterns or require different parametrizations to prevent conflicts. Training neural MTPP models with alternative proper scoring rules, measuring CG, GMS, TPI during training, and comparing performance to NLL-trained models to see if conflict patterns change with different objectives would resolve this.

## Limitations

- The effectiveness of disjoint parametrizations depends on the assumption that time and mark prediction tasks can be meaningfully separated without losing modeling power.
- The computational overhead of maintaining separate parameter sets and history encoders may be prohibitive for very large-scale applications.
- The paper focuses solely on categorical marks, leaving the extension to more complex event types as future work.

## Confidence

- **High confidence**: The mathematical derivation of conflicting gradients and their impact on joint optimization (Section 3) - supported by clear factorization of the NLL and empirical gradient analysis.
- **Medium confidence**: The effectiveness of separate history encoders (base++ framework) - improvements are demonstrated but the added complexity may not justify gains in all scenarios.
- **Medium confidence**: The generalization across all five datasets - while consistent improvements are shown, the specific characteristics of each dataset may influence the magnitude of gains differently.

## Next Checks

1. Systematically measure cos ϕTM across all base models during training to verify that conflicting gradients are indeed the primary source of performance degradation, not other optimization issues.

2. Design experiments where time and mark prediction tasks are artificially made more interdependent (e.g., by introducing strong conditional dependencies) to test whether the disjoint framework maintains performance advantages.

3. Conduct ablation studies measuring the parameter count and FLOPs of each framework (base, base+, base++) against performance gains to establish when the added complexity becomes worthwhile.