---
ver: rpa2
title: 'Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion'
arxiv_id: '2410.13674'
source_url: https://arxiv.org/abs/2410.13674
tags:
- data
- guidance
- synthetic
- images
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DisCL uses image-guided diffusion to generate a spectrum of synthetic-to-real
  data for hard samples. It then applies curriculum learning, selecting guidance levels
  adaptively to maximize learning progress.
---

# Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion

## Quick Facts
- arXiv ID: 2410.13674
- Source URL: https://arxiv.org/abs/2410.13674
- Authors: Yijun Liang; Shweta Bhardwaj; Tianyi Zhou
- Reference count: 40
- Key outcome: DisCL improves minority-class accuracy by 17.06% on ImageNet-LT and boosts iWildCam OOD/ID F1 scores by 2.7%/2.1% through adaptive synthetic-to-real data curriculum learning.

## Executive Summary
DisCL introduces a novel approach for training models with low-quality or scarce data by generating synthetic-to-real data using image-guided diffusion. The method creates a spectrum of synthetic images with controllable proximity to real data through classifier-free guidance, then applies curriculum learning to adaptively select the optimal guidance level during training. This approach effectively bridges the synthetic-to-real distribution gap while enhancing data quality and diversity, demonstrating strong improvements on long-tail classification and low-quality image tasks.

## Method Summary
DisCL employs a two-phase approach: first generating synthetic-to-real data using Stable Diffusion XL with controllable image guidance levels, then applying curriculum learning to select optimal guidance levels during training. The synthetic data generation uses CLIPScore filtering to remove low-fidelity images, creating a pool of high-quality synthetic samples at various guidance levels. For long-tail classification, a non-adaptive curriculum progressively increases guidance levels, while for low-quality data, an adaptive curriculum selects guidance levels based on learning progress measured through ground-truth class confidence improvement on validation subsets.

## Key Results
- Improves minority-class accuracy by 17.06% on ImageNet-LT
- Boosts iWildCam OOD and ID macro F1 scores by 2.7% and 2.1% respectively
- Outperforms fixed-guidance and text-only baselines across multiple datasets and model sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DisCL's dynamic guidance selection improves minority-class accuracy by 17.06% on ImageNet-LT
- Mechanism: Adaptive curriculum selects the guidance level that maximizes learning progress per epoch, focusing on synthetic data that best bridges the gap between prototypical features and task-specific distribution
- Core assumption: Learning progress can be measured via ground-truth class confidence improvement on validation subsets
- Evidence anchors:
  - [abstract]: "DisCL improves minority-class accuracy by 17.06% on ImageNet-LT"
  - [section]: "adaptive curriculum detailed in Algorithm 2, which selects the image guidance level λ at each epoch based on progress – defined by improvement in ground-truth class confidence"
  - [corpus]: No direct corpus evidence for this specific mechanism; this is an inference from the described methodology
- Break condition: If validation progress measurement becomes noisy or uninformative, the adaptive selection may choose suboptimal guidance levels

### Mechanism 2
- Claim: Lower image guidance (λ→0) generates prototypical features that serve as effective warm-up for learning harder, more specific data
- Mechanism: Text-only guidance produces synthetic images focusing on class-typical features, which are easier to learn initially before transitioning to higher-guidance, more realistic samples
- Core assumption: Prototypical features provide better learning foundations than task-specific but potentially noisy real data
- Evidence anchors:
  - [abstract]: "With weaker image guidance, the synthetic images will be easier to learn but suffer from a larger distribution gap to the original data"
  - [section]: "images generated with lower image guidance usually contain prototypical features easier to learn"
  - [corpus]: No direct corpus evidence; this is inferred from the described curriculum design
- Break condition: If the distribution gap becomes too large, early exposure to low-guidance data may introduce harmful biases that are difficult to correct later

### Mechanism 3
- Claim: CLIPScore filtering removes low-fidelity synthetic images that would otherwise degrade model performance
- Mechanism: CLIPScore measures alignment between synthetic images and text prompts; images below threshold are discarded before training
- Core assumption: CLIPScore effectively correlates with downstream classification performance
- Evidence anchors:
  - [abstract]: "Filter out Synthetic Data with Low-Fidelity... which measures CLIP cosine similarity between synthetic images and text prompt"
  - [section]: "CLIPScore [18] to filter out poor-quality images in the synthetic data"
  - [corpus]: No direct corpus evidence for CLIPScore's effectiveness in this specific context
- Break condition: If CLIPScore threshold is set too high, it may remove useful but challenging samples; if too low, it may retain poor-quality data that hurts learning

## Foundational Learning

- Concept: Curriculum Learning
  - Why needed here: Enables progressive learning from easier to harder samples, crucial for bridging the synthetic-to-real data gap
  - Quick check question: What distinguishes adaptive curriculum learning from non-adaptive in the DisCL framework?

- Concept: Diffusion Models and Classifier-Free Guidance
  - Why needed here: Provides the mechanism for generating synthetic-to-real interpolations with controllable proximity to real images
  - Quick check question: How does modifying the initial step t in the denoising process control image guidance level?

- Concept: Domain Adaptation and Distribution Gap
  - Why needed here: Understanding how synthetic data distribution differs from real data is essential for designing effective bridging strategies
  - Quick check question: What metrics are used to quantify the synthetic-to-real distribution gap in DisCL?

## Architecture Onboarding

- Component map: Data Generation Pipeline (Stable Diffusion XL + CLIPScore filtering + text prompt generation) -> Curriculum Engine (adaptive selection algorithm + validation set evaluation + guidance level scheduling) -> Training Loop (Model finetuning + progress measurement + curriculum adjustment)
- Critical path: Image identification -> Synthetic generation (multiple λ) -> CLIPScore filtering -> Curriculum selection -> Model training
- Design tradeoffs:
  - Synthetic diversity vs. real-data proximity: Lower λ increases diversity but widens distribution gap
  - Computational cost vs. curriculum sophistication: Adaptive selection requires more computation than fixed schedules
  - CLIPScore threshold selection: Balancing data quality vs. quantity
- Failure signatures:
  - Overfitting to synthetic data: Model performs well on generated samples but poorly on real test data
  - Ineffective guidance selection: Adaptive curriculum fails to improve performance over random selection
  - Poor CLIPScore filtering: Low-quality synthetic images pass through and degrade learning
- First 3 experiments:
  1. Baseline comparison: Test DisCL vs. text-only guidance (λ=0) on a small subset of ImageNet-LT
  2. CLIPScore sensitivity: Vary CLIPScore threshold and measure impact on downstream performance
  3. Guidance level sweep: Test fixed guidance levels (λ=0, 0.3, 0.5, 0.7, 0.9) to identify optimal ranges for each task

## Open Questions the Paper Calls Out
None

## Limitations
- The method relies heavily on CLIPScore as a quality metric without validation of its correlation with downstream performance
- Optimal guidance levels and CLIPScore thresholds appear dataset-specific and require extensive hyperparameter tuning
- The adaptive curriculum selection depends on ground-truth class confidence as a progress metric, which may not generalize well to all tasks

## Confidence

### Major Uncertainties and Limitations
The method relies heavily on the assumption that CLIPScore effectively measures synthetic image quality and relevance for downstream classification tasks. This correlation has not been validated in the paper, creating a potential weak point in the pipeline. The adaptive curriculum selection mechanism depends on ground-truth class confidence improvement as a proxy for learning progress, but this assumes that validation performance accurately reflects generalization capabilities. Additionally, the optimal guidance levels and CLIPScore thresholds appear to be dataset-specific and were likely determined through extensive hyperparameter tuning that is not fully disclosed.

### Confidence Assessment
- **High confidence**: The overall improvement claims (17.06% on ImageNet-LT, 2.7%/2.1% on iWildCam) are directly supported by experimental results in the paper.
- **Medium confidence**: The mechanism of using lower guidance for prototypical features and higher guidance for realistic samples is logically sound but lacks empirical validation of the underlying assumptions about distribution gaps and learning dynamics.
- **Low confidence**: The effectiveness of CLIPScore filtering for this specific application has not been validated, and the adaptive curriculum selection strategy's sensitivity to different progress metrics remains untested.

## Next Checks
1. **CLIPScore correlation validation**: Conduct experiments to verify that CLIPScore threshold selection correlates with downstream classification performance, not just image-text alignment.
2. **Curriculum selection robustness**: Test the adaptive curriculum against random guidance selection and alternative progress metrics to ensure the selection strategy adds value beyond random choice.
3. **Distribution gap quantification**: Measure and report the Wasserstein or other distributional distance metrics between synthetic and real data at different guidance levels to validate the claimed trade-off between diversity and proximity.