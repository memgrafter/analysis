---
ver: rpa2
title: Multi-dimensional Evaluation of Empathetic Dialog Responses
arxiv_id: '2402.11409'
source_url: https://arxiv.org/abs/2402.11409
tags:
- empathy
- dialogue
- customer
- question
- perceived
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a multi-dimensional empathy evaluation framework
  for conversational systems, distinguishing between expressed communicative intents
  (speaker perspective) and perceived empathy (listener perspective). The framework
  measures expressed empathy through 16 specific communicative intents and perceived
  empathy across four dimensions: engagement, understanding, sympathy, and helpfulness.'
---

# Multi-dimensional Evaluation of Empathetic Dialog Responses

## Quick Facts
- arXiv ID: 2402.11409
- Source URL: https://arxiv.org/abs/2402.11409
- Reference count: 23
- Primary result: Instruction-finetuned Flan-T5 models outperform prompting and supervised classifiers on empathy classification tasks

## Executive Summary
This paper introduces a multi-dimensional empathy evaluation framework for conversational systems that distinguishes between expressed communicative intents (speaker perspective) and perceived empathy (listener perspective). The framework measures expressed empathy through 16 specific communicative intents and perceived empathy across four dimensions: engagement, understanding, sympathy, and helpfulness. Applied to an internal customer service dataset of 2,000 dialogues, the study found that expressed intents and perceived empathy dimensions are interconnected yet distinct, with perceived empathy strongly correlating with overall dialogue satisfaction. To address the high cost of human annotation, the paper evaluates automated measurement methods, finding that instruction-finetuned language models (Flan-T5 family) significantly outperform prompting methods (including GPT-4 and Flan-XXL) and traditional supervised classifiers on both public and internal datasets.

## Method Summary
The method involves creating a multi-dimensional evaluation framework that measures both expressed communicative intents (16 specific categories) and perceived empathy dimensions (engagement, understanding, sympathy, helpfulness) from annotated dialogue datasets. The approach uses instruction-finetuned language models, specifically the Flan-T5 family, trained on three datasets: Empathy Mental Health (EMH), Emotion Support Conversation (ESConv), and an internal Empeval dataset of 2,000 customer service dialogues. The instruction-finetuning process incorporates natural language instructions with specific components including intent description, definition, domain context, and classification options. Models process dialogues using a sliding window approach with 3 preceding and 3 proceeding utterances to capture context, and are evaluated using macro precision, recall, F1, and accuracy metrics.

## Key Results
- Instruction-finetuned Flan-T5 models outperform prompting methods and traditional supervised classifiers on empathy classification tasks
- Including proceeding context utterances significantly improves classification performance compared to using only preceding context
- The multi-dimensional framework captures distinct aspects of conversational empathy, with perceived empathy dimensions strongly correlating with overall dialogue satisfaction
- Different loss functions (Focal loss, LDAM) help address class imbalance in the long-tail distributed empathy datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instruction-finetuning with natural language instructions significantly improves conversational empathy classification performance compared to prompting or supervised finetuning alone.
- Mechanism: Instruction-finetuning allows the model to understand the task context and intent better by providing explicit natural language descriptions of what needs to be classified, rather than relying solely on learned patterns from labeled data or generic prompts.
- Core assumption: The model's pretraining corpus contains sufficient knowledge about empathy and conversational context to benefit from explicit instruction-based guidance.
- Evidence anchors: "instruction-finetuned classifiers based on Flan-T5 family models outperform prompting methods and other competitive baselines"

### Mechanism 2
- Claim: Including proceeding context utterances significantly improves classification performance compared to using only preceding context.
- Mechanism: Proceeding context provides additional information about the conversational flow and potential responses, allowing the model to better understand the complete conversational context and the speaker's intent.
- Core assumption: Conversational empathy is inherently context-dependent and requires understanding both what has been said and what might be said next.
- Evidence anchors: "Removing proceeding contexts hurts performance...matches our motivation that empathy is a collaborative practice and context-dependent"

### Mechanism 3
- Claim: The multi-dimensional framework (measuring both expressed intents and perceived empathy) captures more nuanced aspects of conversational empathy than uni-dimensional approaches.
- Mechanism: By measuring both how empathy is expressed and how it is perceived, the framework accounts for the collaborative nature of empathy in conversation, recognizing that expressed empathy doesn't always translate to perceived empathy.
- Core assumption: Empathy in conversation is a relational phenomenon that involves both the speaker's expression and the listener's perception, rather than just an individual trait.
- Evidence anchors: "our analytical framework to measure both expressed intents from the speaker's perspective and perceived empathy from the listener's perspective"

## Foundational Learning

- Concept: Multi-label classification with class imbalance
  - Why needed here: The empathy datasets contain long-tail distributions where some empathy intents/strategies are much more frequent than others
  - Quick check question: What loss function modification can help address class imbalance in multi-label classification?

- Concept: Sliding window context processing for long sequences
  - Why needed here: Dialogues can be very long, exceeding language model context limits, requiring a sliding window approach to process them
  - Quick check question: How many preceding and proceeding utterances are used in the sliding window approach?

- Concept: Instruction-finetuning methodology
  - Why needed here: The paper compares instruction-finetuning against prompting and supervised finetuning, showing it achieves the best performance
  - Quick check question: What are the four key components of the natural language instruction schema used in the experiments?

## Architecture Onboarding

- Component map: Data pipeline (Dialogue loading → Utterance splitting → Context window creation) → Model layer (Flan-T5 encoder-decoder) → Classification head (Linear layer) → Loss functions (Cross-entropy, Focal loss, LDAM) → Evaluation (Macro metrics)

- Critical path: Data preprocessing → Model training (with appropriate loss function) → Evaluation on held-out test sets → Ablation studies on context window size and instruction components

- Design tradeoffs:
  - Context window size: Larger windows provide more context but increase computational cost and may include irrelevant information
  - Model size: Larger models (Flan-T5-XL) achieve better performance but require more computational resources
  - Loss function choice: Standard cross-entropy vs. specialized losses (Focal, LDAM) for handling class imbalance

- Failure signatures:
  - Poor performance on infrequent classes suggests class imbalance issues
  - Degradation when removing proceeding context indicates model relies heavily on forward-looking information
  - Similar performance across different model families may indicate task difficulty exceeds current model capabilities

- First 3 experiments:
  1. Compare instruction-finetuned Flan-T5-Large vs. standard supervised finetuning on a small subset of the Empeval dataset
  2. Test the impact of removing proceeding context (using only 3 preceding utterances) on model performance
  3. Evaluate different loss functions (cross-entropy vs. Focal loss) on the long-tail distributed Empeval dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different instruction tuning template formats (e.g., different ordering of definition, domain, options) affect performance on empathy classification tasks?
- Basis in paper: The paper mentions using "natural language instructions" with parts (1) intent, (2) definition, (3) domain, (4) options, but only provides one example and mentions "complete instruction tuning templates are given in Appendix E"
- Why unresolved: The paper doesn't systematically compare different template formats or provide details on what variations were tested.
- What evidence would resolve it: Systematic comparison of different template formats on a held-out development set, showing how different arrangements of instruction components affect performance.

### Open Question 2
- Question: Does the effectiveness of instruction-finetuned models vary across different empathy dimensions (engagement, understanding, sympathy, helpfulness)?
- Basis in paper: The paper reports that "each perceived empathy aspect is connected with a distinct set of expressed intents" and shows varying correlations with conversation satisfaction, suggesting the dimensions may differ in difficulty.
- Why unresolved: The paper reports overall performance metrics but doesn't analyze model performance separately for each empathy dimension.
- What evidence would resolve it: Detailed breakdown of model performance metrics (precision, recall, F1) for each of the four perceived empathy dimensions.

### Open Question 3
- Question: How would the inclusion of customer satisfaction ratings as an additional training signal affect model performance on perceived empathy tasks?
- Basis in paper: The paper shows strong correlation between perceived empathy and conversation satisfaction ratings, suggesting this information could be valuable for training.
- Why unresolved: The paper only uses binary labels derived from dual-annotator agreement and doesn't explore incorporating satisfaction ratings.
- What evidence would resolve it: Comparison of model performance when training with satisfaction ratings as additional features or labels versus using only binary annotations.

## Limitations
- The internal Empeval dataset represents only customer service dialogues and may not generalize to other conversational domains
- The study evaluates only English-language dialogues, limiting applicability to multilingual contexts
- The instruction-finetuning approach requires careful crafting of natural language instructions, but exact templates are not provided
- The computational cost of including proceeding context utterances may be prohibitive for real-time applications

## Confidence
**High Confidence** - The finding that instruction-finetuned Flan-T5 models outperform prompting methods and supervised classifiers is well-supported by experimental results across multiple datasets.

**Medium Confidence** - The claim that proceeding context significantly improves performance is supported by ablation studies, but practical necessity depends on application constraints.

**Low Confidence** - The generalizability of the multi-dimensional framework beyond customer service and mental health support contexts is uncertain.

## Next Checks
1. Test the instruction-finetuned models on conversational datasets from different domains (healthcare, education, personal relationships) to assess generalizability of the empathy classification framework.

2. Systematically vary the components of the natural language instructions (intent description, examples, output format) to determine which elements contribute most to performance gains.

3. Implement a live system using the best-performing model configuration to measure actual user satisfaction and engagement in deployed customer service scenarios, comparing against baseline systems.