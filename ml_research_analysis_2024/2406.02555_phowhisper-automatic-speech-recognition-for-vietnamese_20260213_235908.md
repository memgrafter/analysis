---
ver: rpa2
title: 'PhoWhisper: Automatic Speech Recognition for Vietnamese'
arxiv_id: '2406.02555'
source_url: https://arxiv.org/abs/2406.02555
tags:
- phowhisper
- vietnamese
- speech
- vlsp
- recognition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces PhoWhisper, a family of five Whisper-based
  models fine-tuned for Vietnamese automatic speech recognition. These models were
  trained on a large-scale dataset of 844 hours of Vietnamese audio, including diverse
  regional accents, and augmented with environmental noise to enhance robustness.
---

# PhoWhisper: Automatic Speech Recognition for Vietnamese

## Quick Facts
- arXiv ID: 2406.02555
- Source URL: https://arxiv.org/abs/2406.02555
- Reference count: 2
- Introduces five Whisper-based ASR models achieving state-of-the-art Vietnamese WER scores

## Executive Summary
PhoWhisper introduces a family of five Whisper-based models fine-tuned for Vietnamese automatic speech recognition. The models were trained on a large-scale dataset of 844 hours of Vietnamese audio with diverse regional accents and environmental noise augmentation. PhoWhisper achieves state-of-the-art performance across four benchmark Vietnamese ASR datasets, with PhoWhisperlarge setting new benchmarks on all tasks. The work demonstrates the effectiveness of fine-tuning large multilingual models for Vietnamese ASR and provides open-sourced models for future research.

## Method Summary
The method involves fine-tuning five Whisper model variants (tiny, base, small, medium, large) on an 844-hour Vietnamese speech dataset that includes CMV-Vi, VIVOS, VLSP 2020 Task-1, and private data. Environmental noise from Piczak (2015) was added to half of the training set using audiomentations. Models were trained with specific learning rates (3.75e-5 to 5e-6), batch size of 64, and 48,000 update steps on 8 A100 GPUs.

## Key Results
- PhoWhisperlarge achieves WER scores of 8.14%, 4.67%, 13.75%, and 26.68% on Common Voice, VIVOS, VLSP Task-1, and VLSP Task-2 respectively
- PhoWhisperlarge outperforms all previous wav2vec2-based baselines by significant margins
- All five PhoWhisper variants outperform existing Vietnamese ASR models on at least one benchmark

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning Whisper on diverse Vietnamese accents improves WER across all benchmark datasets. The large multilingual model adapts its learned speech representations to Vietnamese phonological characteristics through exposure to varied accents. The core assumption is that Whisper's pretraining generalizes enough to capture Vietnamese acoustic-phonetic structure. Break condition: Rare or highly non-standard accents not represented in training data may cause WER degradation.

### Mechanism 2
Noise augmentation during training improves robustness to environmental sounds. Adding noise to half of the training set simulates real-world acoustic conditions, forcing the model to learn invariant features. The core assumption is that Piczak noise types represent real-world conditions. Break condition: Test conditions containing noise types not present in augmentation may reduce performance.

### Mechanism 3
Scaling model size from tiny to large improves ASR performance on Vietnamese benchmarks. Larger models have more parameters to learn complex mappings between acoustic features and Vietnamese phonemes. The core assumption is sufficient training data to prevent overfitting. Break condition: Insufficient training data relative to model size may cause overfitting and worse performance.

## Foundational Learning

- **Fine-tuning vs. training from scratch**: Why needed here - understanding why Whisper's multilingual pretraining was leveraged instead of building from scratch. Quick check: What are the advantages of fine-tuning a large pretrained model over training a smaller model from scratch on the same dataset?

- **Noise augmentation in speech**: Why needed here - explains how adding noise during training improves robustness to real-world conditions. Quick check: How does noise augmentation help a model generalize to unseen acoustic environments?

- **Model scaling and WER**: Why needed here - relates model capacity to performance improvements on ASR benchmarks. Quick check: Why might increasing model size improve ASR performance, assuming sufficient training data?

## Architecture Onboarding

- **Component map**: Data collection -> noise augmentation -> model initialization -> fine-tuning with specific LR and batch size -> evaluation on benchmarks
- **Critical path**: Data collection → noise augmentation → model initialization → fine-tuning with specific LR and batch size → evaluation on benchmarks
- **Design tradeoffs**: Larger models achieve better WER but require more compute and memory; noise augmentation adds robustness but may reduce clean-condition performance; diverse accent data improves generalization but increases training complexity
- **Failure signatures**: High WER on any benchmark dataset indicates either insufficient accent coverage, inadequate noise augmentation, or model underfitting/overfitting
- **First 3 experiments**:
  1. Fine-tune PhoWhisperbase on 844h data without noise augmentation, evaluate on all benchmarks
  2. Add noise augmentation to training, re-evaluate to measure robustness gains
  3. Scale up to PhoWhispermedium, compare WER improvements against base model

## Open Questions the Paper Calls Out

### Open Question 1
How does PhoWhisper perform on Vietnamese speech with significant background noise compared to clean speech? The paper mentions environmental noise incorporation but does not evaluate performance on noisy speech specifically. Evidence needed: WER scores on Vietnamese ASR benchmark datasets with varying levels of background noise compared to clean speech performance.

### Open Question 2
How does PhoWhisper's performance scale with the size of the fine-tuning dataset? The paper uses 844 hours but does not explore dataset size impact on performance. Evidence needed: WER scores on benchmark datasets when fine-tuning PhoWhisper on progressively larger subsets of the training data.

### Open Question 3
How does PhoWhisper generalize to unseen Vietnamese accents and dialects not present in the training data? The paper mentions diverse accents from 26K speakers but does not evaluate generalization to unseen accents. Evidence needed: WER scores on benchmark datasets containing speech from Vietnamese accents and dialects not represented in the training data.

## Limitations
- Environmental noise augmentation parameters (SNR levels, specific noise types, mixing ratios) are unspecified
- Private training dataset details remain undisclosed, raising questions about potential data leakage
- Lacks ablation studies showing individual contributions of accent diversity, noise augmentation, and model scaling

## Confidence

- **High Confidence**: PhoWhisperlarge achieves state-of-the-art WER scores on all four Vietnamese benchmark datasets
- **Medium Confidence**: Noise augmentation improves robustness to environmental sounds
- **Low Confidence**: Accent diversity from 26K speakers across 63 provinces is sufficient to cover all test conditions

## Next Checks

1. **Ablation Study on Noise Augmentation**: Fine-tune PhoWhisperbase with and without noise augmentation on the same training data, then compare WER scores across all benchmarks to quantify the exact contribution of noise robustness.

2. **Accent Coverage Analysis**: Perform detailed analysis of accent representation in the training data versus test sets, including speaker location mapping and rare accent detection, to verify the claim that diverse accents improve generalization.

3. **Model Scaling Efficiency Test**: Conduct controlled experiments varying model size while keeping training data constant to establish whether performance improvements scale linearly with parameter count or follow diminishing returns.