---
ver: rpa2
title: 'Geneverse: A collection of Open-source Multimodal Large Language Models for
  Genomic and Proteomic Research'
arxiv_id: '2406.15534'
source_url: https://arxiv.org/abs/2406.15534
tags:
- llms
- gene
- process
- data
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Geneverse is a collection of open-source LLMs and MLLMs finetuned
  for genomic and proteomic research. The models are adapted using parameter-efficient
  fine-tuning on domain-specific datasets, including gene function descriptions, protein
  structure information, and spatial transcriptomic data.
---

# Geneverse: A collection of Open-source Multimodal Large Language Models for Genomic and Proteomic Research

## Quick Facts
- arXiv ID: 2406.15534
- Source URL: https://arxiv.org/abs/2406.15534
- Authors: Tianyu Liu; Yijia Xiao; Xiao Luo; Hua Xu; W. Jim Zheng; Hongyu Zhao
- Reference count: 40
- Geneverse finetuned Mistral-7B achieves 0.975 average accuracy for gene function description, surpassing GPT-4 and other baselines

## Executive Summary
Geneverse is a collection of open-source LLMs and MLLMs finetuned for genomic and proteomic research. The models are adapted using parameter-efficient fine-tuning on domain-specific datasets, including gene function descriptions, protein structure information, and spatial transcriptomic data. Geneverse outperforms closed-source models on tasks like gene function summarization, protein function inference from structure, and marker gene identification. The models and training strategies are freely accessible.

## Method Summary
The Geneverse framework involves finetuning open-source LLMs (Mistral-7B, Gemma-7B, LLaMAPro-8B) and MLLMs (LLaVA-7B) using LoRA parameter-efficient fine-tuning on domain-specific datasets. Training data includes gene function descriptions from NCBI and synthetic descriptions generated by GPT-3.5 for protein-encoding genes, protein structure images from AlphaFold database, and spatial transcriptomic data from human breast tissue. Post-processing corrects numerical gene information and removes redundant descriptions. Models are evaluated on factual accuracy, structural correctness, and BLEU/ROUGE1 scores.

## Key Results
- Finetuned Mistral-7B achieves 0.975 average accuracy for gene function description, surpassing GPT-4 and other baselines
- MLLMs show improved factual and structural accuracy for protein classification and spatial transcriptomics tasks
- Data augmentation with synthetic descriptions improves model coverage of less common genes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Finetuning open-source LLMs with domain-specific data can outperform closed-source models on specialized tasks.
- Mechanism: The model adapts its internal representations through parameter-efficient fine-tuning, allowing it to learn task-specific patterns from curated datasets without catastrophic forgetting.
- Core assumption: The base model's pre-training provides sufficient general knowledge that can be specialized effectively with limited domain data.
- Evidence anchors:
  - [abstract]: "adapted LLMs and MLLMs perform well for these tasks and may outperform closed-source large-scale models"
  - [section]: "Mistral-7B (LoRA) 0.950 1.000 0.975 0.349 0.592 Y" - shows Mistral-7B finetuned outperformed GPT-4
  - [corpus]: Weak evidence; related work focuses on similar tasks but not direct comparison of finetuned open vs closed models
- Break condition: If the base model lacks sufficient general knowledge or the domain data is too sparse for effective adaptation.

### Mechanism 2
- Claim: Multimodal input enhances protein function inference by incorporating structural information.
- Mechanism: By combining text descriptions with structural images, the model can learn mappings between 3D protein configurations and functional annotations that text alone cannot capture.
- Core assumption: Protein structure contains information about function that can be extracted through visual patterns.
- Evidence anchors:
  - [abstract]: "MLLMs are also finetuned for protein classification and spatial transcriptomics, showing improved factual and structural accuracy"
  - [section]: "For the protein task, we downloaded the protein structure images from the Deepmind Alphafold2 website"
  - [corpus]: Weak evidence; related work mentions multimodal approaches but doesn't specifically validate structural-image integration for function inference
- Break condition: If protein structure doesn't reliably encode functional information or the image encoding fails to capture relevant features.

### Mechanism 3
- Claim: Data augmentation with synthetic descriptions improves model coverage of less common genes.
- Mechanism: GPT-3.5 generates descriptions for protein-encoding genes not well-represented in NCBI, expanding the training distribution and reducing knowledge gaps.
- Core assumption: Synthetic descriptions maintain factual accuracy while filling coverage gaps in the real dataset.
- Evidence anchors:
  - [section]: "To ensure the correctness of training datasets, we only focused on protein-encoding genes for the outputs of GPT 3.5"
  - [section]: "Extended Data Figure 3 shows the results of data ablation, which suggests that integrating both NCBI and GPT 3.5 leads to the best performance"
  - [corpus]: No direct evidence; corpus focuses on related methods but not this specific augmentation approach
- Break condition: If synthetic descriptions introduce factual errors or create distribution mismatch that harms generalization.

## Foundational Learning

- Concept: Parameter-efficient fine-tuning (PEFT)
  - Why needed here: Enables adaptation of large models with limited compute resources while preserving general knowledge
  - Quick check question: What is the primary benefit of LoRA compared to full fine-tuning for a 7B parameter model?

- Concept: Multimodal learning
  - Why needed here: Protein function depends on both sequence/textual information and 3D structure
  - Quick check question: How does combining image and text modalities improve protein classification accuracy compared to text-only models?

- Concept: Gene Ontology enrichment analysis (GOEA)
  - Why needed here: Validates that generated descriptions capture biologically meaningful functional relationships
  - Quick check question: What does a significant GOEA result tell us about the quality of gene embeddings from model outputs?

## Architecture Onboarding

- Component map: Base LLM/MLLM -> PEFT adapter (LoRA) -> Domain-specific dataset (NCBI + synthetic) -> Post-processing (database lookup for IDs) -> Evaluation (truthfulness + structural correctness)
- Critical path: Data preparation -> Model selection and fine-tuning -> Post-processing -> Evaluation
- Design tradeoffs: PEFT vs full fine-tuning (speed/compute vs potential performance), synthetic data augmentation vs purity of training data
- Failure signatures: Poor truthfulness scores (factual errors), low structural scores (format violations), inconsistent embeddings (poor representation quality)
- First 3 experiments:
  1. Benchmark different base models (Mistral, LLaMA2, Gemma) with identical fine-tuning setup
  2. Compare LoRA vs full fine-tuning on a subset of data to measure performance trade-offs
  3. Ablation study: NCBI-only vs NCBI+GPT-3.5 to quantify augmentation benefits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can retrieval-augmented generation (RAG) models be improved for biomedical applications to avoid generating unstructured outputs and maintain high factual accuracy?
- Basis in paper: [explicit] The paper notes that RAG-based LLMs did not satisfy structural requirements and sometimes generated multiple paragraphs, with low structural scores observed for models like Mistral-7B (RAG).
- Why unresolved: While the paper identifies RAG's limitations in biomedical contexts, it does not explore specific modifications or alternative architectures that could address these issues, such as improved retrieval mechanisms or hybrid models.
- What evidence would resolve it: Comparative studies evaluating RAG-based models with enhanced retrieval techniques, structured output constraints, or hybrid approaches (e.g., RAG + fine-tuning) on domain-specific tasks, demonstrating improved factual and structural performance.

### Open Question 2
- Question: What is the impact of model scale (e.g., 7B vs. 13B+ parameters) on the performance of LLMs and MLLMs for genomic and proteomic tasks, and are larger models always superior in these domains?
- Basis in paper: [inferred] The paper benchmarks models like LLaMA2-7B, LLaMA2-13B, and LLaMA3-8B but does not systematically explore how model scale affects performance, particularly for MLLMs or tasks involving multimodal data.
- Why unresolved: The paper focuses on 7B and 13B-level models due to computational constraints, leaving the scalability question unaddressed. Larger models may offer better performance but could also introduce challenges like overfitting or resource inefficiency.
- What evidence would resolve it: Empirical studies comparing LLMs and MLLMs of varying scales (e.g., 7B, 13B, 70B+) on genomic and proteomic tasks, analyzing trade-offs between performance, computational cost, and generalizability.

### Open Question 3
- Question: How can the integration of synthetic data from advanced LLMs (e.g., GPT-3.5) with real biological data be optimized to enhance the performance of domain-specific models without introducing bias or errors?
- Basis in paper: [explicit] The paper uses synthetic data from GPT-3.5 to augment real data from NCBI, showing improved performance, but does not explore methods to balance or validate the synthetic data's quality.
- Why unresolved: While the paper demonstrates the benefits of data augmentation, it does not address potential biases in synthetic data or strategies to ensure its alignment with biological knowledge.
- What evidence would resolve it: Studies evaluating the impact of synthetic data quality, diversity, and bias on model performance, using techniques like data filtering, human validation, or domain-specific synthetic data generation.

## Limitations
- Data Quality and Representativeness: Reliance on synthetic data from GPT-3.5 without direct validation against ground truth introduces uncertainty about factual accuracy and potential bias.
- Evaluation Scope: Strong performance on specific benchmarks doesn't guarantee generalizability to broader biological applications or complex real-world datasets.
- Resource Accessibility: Actual availability of finetuned models, training code, and datasets is not explicitly confirmed, potentially limiting reproducibility.

## Confidence
- **High Confidence**: Finetuning open-source LLMs with domain-specific data can outperform closed-source models on specialized tasks.
- **Medium Confidence**: Multimodal input enhances protein function inference by incorporating structural information.
- **Low Confidence**: Data augmentation with synthetic descriptions improves model coverage of less common genes.

## Next Checks
1. **Synthetic Data Validation**: Conduct thorough validation of synthetic gene function descriptions generated by GPT-3.5 against ground truth data to assess factual accuracy and potential impact on model performance.
2. **Broader Evaluation**: Expand evaluation of Geneverse models to include a wider range of biological tasks and real-world datasets to assess generalizability and practical utility.
3. **Accessibility Verification**: Confirm availability of finetuned models, training code, and datasets to ensure the Geneverse framework is truly accessible for further research and development.