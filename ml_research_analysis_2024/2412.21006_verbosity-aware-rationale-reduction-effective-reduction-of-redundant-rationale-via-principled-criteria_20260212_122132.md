---
ver: rpa2
title: 'Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale
  via Principled Criteria'
arxiv_id: '2412.21006'
source_url: https://arxiv.org/abs/2412.21006
tags:
- reasoning
- sentences
- training
- while
- rationale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Verbosity-Aware Rationale Reduction (VARR),
  a method that improves large language model reasoning efficiency by identifying
  and removing redundant reasoning sentences during training. The approach uses a
  likelihood-based criterion called "verbosity" to determine which sentences can be
  eliminated without harming performance.
---

# Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria

## Quick Facts
- arXiv ID: 2412.21006
- Source URL: https://arxiv.org/abs/2412.21006
- Reference count: 39
- Key outcome: VARR improves average accuracy by 7.71% while reducing token generation by 19.87% across various reasoning tasks

## Executive Summary
This paper introduces Verbosity-Aware Rationale Reduction (VARR), a method that improves large language model reasoning efficiency by identifying and removing redundant reasoning sentences during training. The approach uses a likelihood-based criterion called "verbosity" to determine which sentences can be eliminated without harming performance. Unlike previous token-level reduction methods, VARR operates at the sentence level, preserving essential reasoning while removing unnecessary steps. Experiments show VARR outperforms existing reduction methods that trade accuracy for efficiency, demonstrating robustness across different model sizes and task types.

## Method Summary
VARR identifies redundant reasoning sentences using a likelihood-based "verbosity" criterion and removes them during training. The method operates in two stages: a warm-up phase with complete rationales (0.1 of total steps) followed by sentence-level reduction using likelihood differences. VARR+ extends this by contrasting with wrong answers to improve robustness. The framework is trained with AdamW optimizer, weight decay 0.005, and learning rate 5×10^-6, with optimizer reinitialization after each epoch.

## Key Results
- VARR achieves 7.71% average accuracy improvement while reducing token generation by 19.87%
- Sentence-level reduction outperforms token-level methods by preserving essential reasoning structure
- VARR+ demonstrates improved robustness across most datasets when contrasting with wrong answers
- The method shows consistent performance gains across Mistral 7B and Llama3.2 (1B-3B) model sizes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Sentence-level reduction preserves essential reasoning while removing redundancy
- **Mechanism**: The method identifies sentences with low "verbosity" scores (likelihood difference) and removes them, maintaining reasoning quality while reducing token generation
- **Core assumption**: Early sentences in reasoning paths contain more redundancy than later ones
- **Evidence anchors**:
  - [abstract] "VARR operates at the sentence level, preserving essential reasoning while removing unnecessary steps"
  - [section] "Empirical analysis shows that sentences in early rationale steps can introduce redundancy"
  - [corpus] Weak evidence - no direct corpus support found for sentence-level effectiveness over token-level
- **Break condition**: If later sentences prove more redundant than early ones, or if token-level reduction shows equal or better performance

### Mechanism 2
- **Claim**: Verbosity-based criteria enable principled sentence selection
- **Mechanism**: Uses likelihood ratio between complete and reduced rationales to quantify informational contribution of each sentence
- **Core assumption**: Log-likelihood differences accurately measure informational value of sentences
- **Evidence anchors**:
  - [abstract] "uses a likelihood-based criterion called 'verbosity' to determine which sentences can be eliminated"
  - [section] "We introduce the concept of 'verbosity', a likelihood-based criteria, to identify redundant reasoning sentences"
  - [corpus] Weak evidence - no corpus support for likelihood ratio as optimal metric
- **Break condition**: If alternative metrics (entropy, mutual information) prove more effective at identifying redundancy

### Mechanism 3
- **Claim**: Contrasting with wrong answers improves robustness
- **Mechanism**: Compares verbosity scores between correct and incorrect answers to ensure reduced rationales maintain discrimination ability
- **Core assumption**: Models show miscalibrated likelihoods for correct vs incorrect answers that can be exploited
- **Evidence anchors**:
  - [abstract] "VARR+ resulted in performance improvements across most datasets"
  - [section] "we examine whether reduced rationales R′ lead to inaccurate answer generation by incorporating a wrong answer yw"
  - [corpus] Weak evidence - no corpus support for incorrect answer sampling improving robustness
- **Break condition**: If contrasting with wrong answers degrades performance or adds unnecessary complexity

## Foundational Learning

- **Likelihood-based criteria**: Why needed here: The method relies on measuring likelihood differences to identify redundant sentences
  - Quick check question: What does a high verbosity score indicate about a sentence's importance?

- **Chain-of-thought reasoning**: Why needed here: Understanding how intermediate reasoning steps contribute to final answers is essential
  - Quick check question: Why might early reasoning steps contain more redundancy than later ones?

- **Information theory basics**: Why needed here: The method uses KL-divergence and entropy concepts
  - Quick check question: How does KL-divergence measure the difference between two probability distributions?

## Architecture Onboarding

- **Component map**: Warm-up stage -> Verbosity evaluator -> Reduction scheduler -> Training loop

- **Critical path**: 
  1. Compute complete rationale likelihood
  2. Compute reduced rationale likelihood (with candidate sentence removed)
  3. Calculate verbosity score
  4. Apply removal criteria
  5. Update model parameters

- **Design tradeoffs**:
  - Sentence vs token level: Sentences provide natural boundaries but may be too coarse
  - Single vs dual criteria: VARR+ adds complexity but improves robustness
  - Linear vs adaptive scheduling: Linear schedule is simpler but may not optimize reduction

- **Failure signatures**:
  - Performance drops indicate over-aggressive reduction
  - No efficiency gains suggest failure to identify redundancy
  - Instability during training may indicate poor warm-up duration

- **First 3 experiments**:
  1. Test on single dataset with varying warm-up durations to find optimal balance
  2. Compare sentence-level vs token-level reduction on same dataset
  3. Evaluate VARR vs VARR+ to measure impact of wrong answer contrast

## Open Questions the Paper Calls Out
The paper explicitly mentions it will explore VARR's application to iterative reasoning path generation and refinement/reflexion-based evaluation in future work, indicating this as an open direction for extending the method beyond single-step reasoning tasks.

## Limitations
- Sentence-level reduction may not be optimal compared to token-level approaches
- Likelihood-based verbosity criterion lacks comparison with alternative redundancy metrics
- Computational overhead of sentence-level processing is not fully characterized

## Confidence
**High Confidence**: The experimental results showing VARR's performance improvements over baselines on standard reasoning datasets are robust and well-documented.

**Medium Confidence**: The mechanism by which sentence-level reduction outperforms token-level approaches is plausible but not definitively proven.

**Low Confidence**: The claim that likelihood-based verbosity is the optimal criterion for identifying redundancy is weakly supported.

## Next Checks
1. **Direct token-level comparison**: Implement and evaluate a token-level reduction variant of VARR on the same datasets to quantify the actual benefit of sentence-level granularity.

2. **Alternative redundancy metrics**: Replace the likelihood-based verbosity criterion with entropy-based and mutual information-based measures to determine if simpler metrics suffice.

3. **Cross-task generalization**: Test VARR on non-reasoning tasks such as summarization or classification to evaluate whether the sentence reduction approach generalizes beyond chain-of-thought reasoning.