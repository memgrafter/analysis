---
ver: rpa2
title: 'SpanSeq: Similarity-based sequence data splitting method for improved development
  and assessment of deep learning projects'
arxiv_id: '2402.14482'
source_url: https://arxiv.org/abs/2402.14482
tags:
- data
- sequences
- spanseq
- similarity
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SpanSeq is a method for similarity-aware data partitioning designed
  to prevent data leakage in deep learning projects involving biological sequences.
  It uses k-mer distances to estimate sequence similarity, clusters similar sequences
  using DBSCAN, and distributes clusters across partitions to minimize similarity
  between sets.
---

# SpanSeq: Similarity-based sequence data splitting method for improved development and assessment of deep learning projects

## Quick Facts
- arXiv ID: 2402.14482
- Source URL: https://arxiv.org/abs/2402.14482
- Reference count: 40
- Key outcome: Similarity-aware data partitioning prevents data leakage in deep learning on biological sequences

## Executive Summary
SpanSeq is a method for similarity-aware data partitioning designed to prevent data leakage in deep learning projects involving biological sequences. It uses k-mer distances to estimate sequence similarity, clusters similar sequences using DBSCAN, and distributes clusters across partitions to minimize similarity between sets. SpanSeq outperforms random splitting in model assessment and development, as demonstrated on two state-of-the-art models: DeepLoc (protein subcellular localization) and DL-RNA (RNA secondary structure prediction). Results show that random splits overestimate model performance due to data leakage, while SpanSeq provides more reliable assessments and reduces training time by improving early stopping.

## Method Summary
SpanSeq partitions sequence data into training, validation, and test sets while minimizing similarity between partitions to prevent data leakage. The method first calculates k-mer distances between all sequence pairs using tools like Mash or KMA. It then clusters sequences with DBSCAN (using minPoint=1 for single-linkage behavior), ensuring highly similar sequences remain together. Finally, it distributes clusters across k partitions using makespan optimization to balance partition sizes while minimizing similarity between them. The method is designed to work with large datasets of proteins, genes, and genomes, and is applicable to both nucleotide and amino acid sequences.

## Key Results
- Random splits overestimate model performance due to data leakage between training and test sets
- SpanSeq provides more reliable model assessments with MCC scores closer to true generalization performance
- Similarity-aware splitting reduces training time by improving early stopping effectiveness

## Why This Works (Mechanism)

### Mechanism 1
Using k-mer distance instead of pairwise alignment enables scalable similarity calculation on large sequence datasets without prohibitive O(n²l) complexity. k-mer comparison reduces sequences to sets of short subsequences, allowing Jaccard or Mash distances to approximate sequence similarity in sub-linear time relative to sequence length. Core assumption: The chosen k-mer distance correlates well with true sequence identity for the types of sequences being clustered. Evidence anchors: [abstract] "As an alternative to pairwise alignment, SpanSeq takes advantage of k-mer comparisons, where sets of k-mers are compared and used as an unbiased estimate of the pairwise alignment" and [section] "Using k-mer comparison instead of alignment related measures allows for this. The results of the correlation (Figure 1, and Supplementary Material, Supplementary Figure S3), indicate that most k-mer distances gather information similar to that retrieved by identity."

### Mechanism 2
Clustering similar sequences with DBSCAN before partitioning ensures no high-similarity pairs appear in different partitions, preventing data leakage. DBSCAN groups all sequences within a similarity threshold (ϵ) into the same cluster; makespan optimization then distributes clusters across partitions while minimizing size imbalance. Core assumption: Single-linkage DBSCAN behavior (minPoint=1) is sufficient to capture all sequences that should be grouped to avoid leakage. Evidence anchors: [abstract] "Clustering of similar sequences into clusters (DBSCAN)" and "Partitions creation by distributing the clusters into k partitions" and [section] "To avoid similar sequences between partitions, SpanSeq clusters similar sequences together using DBSCAN (implemented in the software CCPhylo)."

### Mechanism 3
Similarity-aware partitioning improves model generalization by preventing memorization of training samples that appear in the test set. By ensuring test sequences are dissimilar to training sequences, the model cannot rely on memorizing specific examples, forcing it to learn true underlying patterns. Core assumption: There exists a similarity threshold τ below which sequences have different phenotypes or labels, making them safe to include in different partitions. Evidence anchors: [abstract] "Results show that random splits overestimate model performance due to data leakage, while SpanSeq provides more reliable assessments" and [section] "If above certain similarity threshold (τ) sequences have the same phenotype, it is impossible to know if our model is predicting based on memorization or on generalization."

## Foundational Learning

- Concept: Understanding of k-mer distance metrics (Jaccard, Mash, Cosine) and their relationship to sequence similarity
  - Why needed here: Different k-mer distances have different correlation profiles with sequence identity; choosing the right one affects clustering quality
  - Quick check question: Which k-mer distance shows the highest correlation with sequence identity for protein sequences in SpanSeq's experiments?

- Concept: DBSCAN clustering algorithm and single-linkage behavior
  - Why needed here: DBSCAN is used to group similar sequences; understanding its parameters (ϵ, minPoint) is crucial for proper cluster formation
  - Quick check question: What value of minPoint does SpanSeq use to make DBSCAN behave as single-linkage clustering?

- Concept: Makespan optimization and tabu search for partition balancing
  - Why needed here: After clustering, the makespan problem ensures partitions are balanced in size while minimizing similarity between them
  - Quick check question: What is the worst-case runtime complexity of the makespan optimization step in SpanSeq?

## Architecture Onboarding

- Component map: Sequence dataset -> k-mer distance calculation -> DBSCAN clustering -> Makespan-based partition distribution -> k balanced partitions
- Critical path: Distance calculation → DBSCAN clustering → Makespan optimization
- Design tradeoffs:
  - k-mer size vs. computational efficiency: Larger k-mers provide better specificity but require more memory
  - ϵ threshold in DBSCAN: Higher values create fewer, larger clusters (less diversity in training) but reduce leakage risk
  - Partition balancing vs. similarity minimization: Stricter similarity constraints may lead to imbalanced partitions
- Failure signatures:
  - High correlation between training and test performance indicates data leakage
  - Large performance gaps between random and similarity-aware splits
  - Clusters containing sequences with different labels (indicating τ is too high)
- First 3 experiments:
  1. Run SpanSeq on a small, well-characterized dataset (like DeepLoc 2.0 subset) with different k-mer distances to observe correlation with identity
  2. Compare cluster formation with different ϵ values to find the optimal threshold for a given dataset
  3. Validate partition quality by measuring similarity between sequences in different partitions and comparing model performance with random splits

## Open Questions the Paper Calls Out

- How does the performance of SpanSeq compare to alignment-based methods like MMseqs or GraphPart for similarity-aware data partitioning?
  - Basis in paper: [inferred] The paper compares SpanSeq to random splitting but does not benchmark it against other similarity-aware partitioning methods
  - Why unresolved: The paper focuses on demonstrating the importance of similarity-aware partitioning in general rather than comparing different methods for achieving it
  - What evidence would resolve it: A head-to-head comparison of SpanSeq with MMseqs, GraphPart, and other methods on datasets of varying sizes and sequence types

- How should the k-mer size and minimizer size parameters in SpanSeq be optimally chosen for different sequence types and lengths?
  - Basis in paper: [explicit] The paper notes relationships between optimal k-mer/minimizer sizes and sequence lengths but does not provide specific guidance
  - Why unresolved: The paper acknowledges the relationship but states that a detailed study of parameter selection strategies is outside its scope
  - What evidence would resolve it: Empirical studies determining optimal parameter ranges for different sequence types (proteins, genes, genomes) and length distributions

- Can SpanSeq be effectively extended to handle datasets where sequences are conglomerates of multiple elements (e.g., protein-ligand complexes, sequence profiles)?
  - Basis in paper: [explicit] The paper explicitly states that the use of SpanSeq for such complex inputs has not been explored
  - Why unresolved: The paper focuses on single-sequence predictors and does not investigate more complex input structures
  - What evidence would resolve it: Testing SpanSeq on datasets with multi-element sequences and evaluating whether it can appropriately partition based on similarity of the combined structures

## Limitations

- The method's performance on multi-label classification tasks or regression problems is not demonstrated
- While k-mer distances show good correlation with sequence identity in the tested cases, this relationship may break down for highly divergent sequences or those with low complexity regions
- The choice of similarity threshold τ is dataset-specific and requires careful calibration

## Confidence

- High: The core mechanism of preventing data leakage through similarity-aware partitioning is well-validated by experimental results
- Medium: The scalability claims for large datasets are supported by results but not extensively tested across diverse use cases
- Low: The optimal similarity threshold τ for different biological sequence types remains an open question requiring dataset-specific tuning

## Next Checks

1. Test SpanSeq on a dataset with known evolutionary relationships (like PFAM families) to verify that sequences from the same family are not split across partitions
2. Measure the impact of different k-mer sizes on clustering quality and model performance for both protein and RNA sequences
3. Evaluate SpanSeq's performance on a multi-label classification task to assess its applicability beyond binary and multiclass problems