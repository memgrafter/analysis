---
ver: rpa2
title: Cultural evolution in populations of Large Language Models
arxiv_id: '2403.08882'
source_url: https://arxiv.org/abs/2403.08882
tags:
- evolution
- cultural
- agents
- similarity
- stories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for simulating cultural evolution
  in populations of large language models (LLMs), allowing researchers to manipulate
  variables like network structure, personality traits, and transformation prompts.
  The model organizes LLM agents in networks where they exchange and transform stories
  across generations.
---

# Cultural evolution in populations of Large Language Models

## Quick Facts
- arXiv ID: 2403.08882
- Source URL: https://arxiv.org/abs/2403.08882
- Authors: Jérémy Perez; Corentin Léger; Marcela Ovando-Tellez; Chris Foulon; Joan Dussauld; Pierre-Yves Oudeyer; Clément Moulin-Frier
- Reference count: 40
- One-line primary result: A framework simulating cultural evolution in LLM populations, showing network structure and personality prompts affect cultural dynamics

## Executive Summary
This paper introduces a framework for simulating cultural evolution in populations of large language models (LLMs), allowing researchers to manipulate variables like network structure, personality traits, and transformation prompts. The model organizes LLM agents in networks where they exchange and transform stories across generations. The authors provide metrics for analyzing the similarity of generated content and visualizations to track cultural dynamics. Preliminary results show that the model replicates findings from human cultural evolution studies and that different network structures and transformation prompts lead to distinct evolutionary patterns.

## Method Summary
The framework simulates cultural evolution by organizing LLM agents in networks where they exchange and transform stories across generations. Each agent generates stories based on personality and transformation prompts, then shares them with network neighbors. The process repeats over multiple generations while tracking similarity metrics and cultural dynamics. The system uses Mistral-7B-based LLM instances, various network topologies (fully-connected, circle, caveman), and different prompt types to study how these factors influence cultural evolution patterns.

## Key Results
- The framework replicates theoretical predictions from cultural evolution studies regarding network structure effects on homogenization
- Different personality prompts (Creative vs. NotCreative) produce distinct patterns of cultural variation and stability
- Fully-connected networks show faster cultural homogenization compared to circle and caveman networks
- The model successfully demonstrates that LLM-based simulations can generate testable hypotheses about cultural evolution mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs can simulate the transformation of cultural information in ways analogous to human cognitive mechanisms during cultural transmission.
- **Mechanism:** The model uses LLMs as agents arranged in networks, where each agent receives stories from neighbors, applies transformation prompts (e.g., "Combine two stories") and personality prompts, then generates new stories. This mimics the non-random transformation of cultural information during human transmission events.
- **Core assumption:** LLMs' text transformations under structured prompts approximate the evolved cognitive mechanisms that influence cultural evolution in humans.
- **Evidence anchors:**
  - [abstract] "We here propose that leveraging the capacity of Large Language Models (LLMs) to mimic human behavior may be fruitful to address this gap."
  - [section] "Using Large Language Models (LLMs) to simulate the evolution of linguistic culture appears fruitful, as we can expect those models to transform cultural information in realistic ways."
  - [corpus] Weak - no direct corpus evidence linking LLM transformations to human cognitive mechanisms during cultural transmission.
- **Break condition:** If LLM transformations under prompts systematically differ from documented human transmission biases (e.g., simplification, embellishment, contamination), the simulation would misrepresent cultural dynamics.

### Mechanism 2
- **Claim:** Network structure influences the speed and pattern of cultural homogenization in LLM agent populations.
- **Mechanism:** Different network topologies (fully-connected, circle, caveman) change the average path length and connectivity between agents, affecting how quickly stories converge and homogenize across generations.
- **Core assumption:** Cultural information spreads faster and homogenizes more quickly in networks with shorter average path lengths and higher connectivity.
- **Evidence anchors:**
  - [section] "More efficient networks (that is, networks with smaller average path length) lead to quicker diffusion of information and thus lower diversity [11] [12] [37] [26]."
  - [section] Results show fully-connected networks exhibit faster homogenization than circle or caveman networks.
  - [corpus] Weak - no corpus evidence directly linking LLM network dynamics to empirical cultural diffusion studies.
- **Break condition:** If the relationship between network structure and cultural homogenization in LLMs does not mirror empirical patterns observed in human cultural systems, the model's predictions would be invalid.

### Mechanism 3
- **Claim:** Personality prompts assigned to LLM agents influence the diversity and nature of cultural content generated.
- **Mechanism:** Agents with "Creative" personalities generate more varied content, while "NotCreative" personalities produce more stable, similar content. Mixed populations show dynamics influenced by the dominant personality type.
- **Core assumption:** LLM responses to personality prompts meaningfully alter their content generation patterns in ways analogous to human personality differences affecting cultural transmission.
- **Evidence anchors:**
  - [section] "Agents in the Creative condition generate more variation than agents in the NotCreative condition: indeed, the NotCreative appears to exhibit higher similarity with the first generation, between successive generations, and within generations compared to the Creative condition."
  - [section] "It also indicates that the dynamics of machine-generated culture will likely be influenced by the specific way in which generative agents are instructed to use pre-existing social information, and which personality traits to emulate."
  - [corpus] Weak - no corpus evidence showing LLM personality prompt effects match documented human personality influences on cultural transmission.
- **Break condition:** If LLM responses to personality prompts do not produce consistent, predictable patterns of content variation, or if these patterns diverge significantly from human personality effects on cultural evolution, the simulation would misrepresent personality's role.

## Foundational Learning

- **Concept: Cultural Evolution Theory**
  - Why needed here: The model is explicitly designed to simulate cultural evolution processes, requiring understanding of how culture changes over time through transmission and transformation.
  - Quick check question: What are the two main theoretical schools in cultural evolution, and how do they differ in explaining cultural change?
- **Concept: Agent-Based Modeling**
  - Why needed here: The framework uses multi-agent simulations where LLM instances act as independent agents, requiring knowledge of how agent interactions produce emergent system-level behaviors.
  - Quick check question: In agent-based models, how do local interaction rules between agents lead to global patterns in the system?
- **Concept: Network Science**
  - Why needed here: The model manipulates network structures to study their effects on cultural dynamics, requiring understanding of how network topology affects information flow and diffusion.
  - Quick check question: How does average path length in a network relate to the speed of information diffusion?

## Architecture Onboarding

- **Component map:** LLM Agents -> Network Structure -> Prompt System -> Analysis Module -> User Interface
- **Critical path:**
  1. Set up network structure and agent personalities
  2. Generate initial stories using initialization prompts
  3. For each generation: agents receive neighbor stories, apply transformation prompts, generate new stories
  4. Compute similarity metrics and generate visualizations
  5. Repeat for specified number of generations
- **Design tradeoffs:**
  - LLM choice vs. computational cost: Mistral-7B offers good performance but requires significant resources
  - Network complexity vs. interpretability: More complex networks may produce richer dynamics but harder to analyze
  - Prompt specificity vs. generalizability: Highly specific prompts may produce clearer effects but reduce model applicability
- **Failure signatures:**
  - No evolution in stories across generations (possibly prompt issues)
  - Complete homogenization too quickly (network structure too efficient)
  - No similarity patterns (LLM not responding to prompts appropriately)
  - Memory errors (too many agents or generations for available resources)
- **First 3 experiments:**
  1. Single agent chain (10 generations) with default prompts to verify basic functionality
  2. Two-agent network with different personalities to test personality effects
  3. Fully-connected network (5 agents, 5 generations) to observe baseline homogenization patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different personality traits in LLM agents affect the rate and direction of cultural evolution in the simulations?
- Basis in paper: [explicit] The paper manipulates agent personalities (Creative, NotCreative, Mixed) and observes differential impacts on cultural dynamics.
- Why unresolved: The paper only provides preliminary results with limited simulations for each personality condition, making it difficult to draw definitive conclusions about the specific effects of personality traits on cultural evolution.
- What evidence would resolve it: Conducting more extensive simulations with a larger number of agents and generations for each personality condition, while systematically varying personality traits, would provide more robust evidence for the impact of personality on cultural evolution.

### Open Question 2
- Question: How does the grounding of cultural content in a physical environment influence the evolution of culture in LLM agent populations?
- Basis in paper: [inferred] The paper acknowledges that human cultural evolution is grounded in a physical environment, but the current model assumes fixed personalities and does not include environmental interactions.
- Why unresolved: The current model does not incorporate environmental factors, making it impossible to study their influence on cultural evolution.
- What evidence would resolve it: Extending the model to include a simulated physical environment and studying how environmental factors, such as resource availability or social structures, affect the evolution of cultural content would provide insights into the role of environmental grounding in cultural evolution.

### Open Question 3
- Question: How do different network structures influence the diversity and stability of cultural content in LLM agent populations?
- Basis in paper: [explicit] The paper manipulates network structures (fully-connected, circle, caveman) and observes distinct patterns in the similarity matrices, suggesting different rates of cultural homogenization.
- Why unresolved: The paper only provides a limited comparison of three network structures and does not explore the full range of possible network configurations or their long-term effects on cultural diversity and stability.
- What evidence would resolve it: Conducting more comprehensive simulations with a wider variety of network structures, including more complex and realistic configurations, and analyzing the long-term effects on cultural diversity and stability would provide a deeper understanding of the role of network structure in cultural evolution.

## Limitations

- Lack of empirical validation against real human cultural evolution data
- Heavy reliance on prompt engineering with unclear sensitivity to prompt wording
- High computational cost limiting scalability and rapid iteration

## Confidence

- **High confidence:** The framework's architecture and methodology are sound and represent a novel contribution to both cultural evolution and AI research. The claim that network structure affects cultural homogenization is well-supported within the model's parameters.
- **Medium confidence:** The demonstration that personality prompts influence content generation patterns. While consistent within the simulation, there is limited external validation against human personality effects on cultural transmission.
- **Low confidence:** The claim that LLM transformations under prompts approximate evolved human cognitive mechanisms for cultural transmission. This remains a theoretical assertion without empirical validation.

## Next Checks

1. Compare LLM-generated story transformations against documented human transmission biases in controlled experiments with human participants.
2. Test the model's sensitivity to prompt variations by systematically modifying key prompt parameters and measuring changes in cultural dynamics.
3. Validate network structure effects by replicating the simulation with multiple LLM models (different sizes/architectures) to assess generalizability.