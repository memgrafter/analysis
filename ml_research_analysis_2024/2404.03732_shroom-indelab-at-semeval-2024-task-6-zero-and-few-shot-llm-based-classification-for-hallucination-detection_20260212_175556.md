---
ver: rpa2
title: 'SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification
  for Hallucination Detection'
arxiv_id: '2404.03732'
source_url: https://arxiv.org/abs/2404.03732
tags:
- text
- task
- hallucination
- data
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper describes a system for detecting hallucinations in outputs
  from large language models (LLMs). The system uses prompt engineering and in-context
  learning to classify outputs as either hallucinatory or not.
---

# SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification for Hallucination Detection

## Quick Facts
- arXiv ID: 2404.03732
- Source URL: https://arxiv.org/abs/2404.03732
- Reference count: 5
- Fourth-best and sixth-best performance in model-agnostic and model-aware tracks respectively

## Executive Summary
This paper describes SHROOM-INDElab's approach to detecting hallucinations in large language model (LLM) outputs using prompt engineering and in-context learning. The system classifies outputs as hallucinatory or not through a two-stage process: first applying zero-shot classification, then augmenting with few-shot examples selected via negative entropy and diversity metrics. The approach achieved competitive performance in the SemEval-2024 Task 6 competition, ranking fourth in the model-agnostic track and sixth in the model-aware track. Key findings include the effectiveness of zero-shot prompting over few-shot with automatically generated examples, and the importance of including explicit concept definitions in prompts for improved accuracy and correlation with human judgments.

## Method Summary
The system uses prompt engineering and in-context learning with LLMs to build classifiers for hallucination detection. It defines tasks, roles, and concepts for each data point, then generates zero-shot classifications without providing examples. Temperature sampling and majority voting are used to produce classifications. For few-shot classification, examples are selected based on a trade-off between diversity of prompts and consistency of majority voting results, then used to augment the zero-shot query prompt. The system's performance is evaluated using accuracy and Spearman's correlation coefficient with human labellers' judgments.

## Key Results
- Achieved fourth-best performance in model-agnostic track and sixth-best in model-aware track
- Zero-shot approach provided better accuracy than few-shot with automatically generated examples
- Including concept definitions in prompts improved both accuracy and Spearman's ρ
- Temperature sampling between 0.5-1.0 optimized accuracy, while 0.5-1.5 optimized Spearman's ρ

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Including concept definitions in prompts improves accuracy and Spearman's ρ
- Mechanism: Explicit definition of hallucination concept provides structured context for LLM to evaluate outputs
- Core assumption: LLMs benefit from explicit definitions rather than implicit understanding
- Evidence anchors:
  - "We interpret the results of the ablation study as indicating that the exclusion of an explicit definition of hallucination leads to poorer accuracy and Spearman's ρ suggests the utility of including intentional definitions of concepts in prompts for LLM-based classifiers"
  - "For the notion of hallucination that is held constant across all of the tasks"

### Mechanism 2
- Claim: Temperature sampling and majority voting improves probability estimation
- Mechanism: Multiple stochastic generations followed by aggregation reduces variance in classification decisions
- Core assumption: Stochastic sampling captures model uncertainty that single deterministic runs miss
- Evidence anchors:
  - "The estimated probability is calculated by performing temperature sampling, querying the LLM multiple times to generate a sample of classifications, and then dividing the number of positive classifications by the total number of classifications in the sample"
  - "Temperature sampling is performed in producing both Stage 1 zero-shot and Stage 2 few-shot classifications"

### Mechanism 3
- Claim: Zero-shot approach provides better accuracy than few-shot with automatically generated examples
- Mechanism: Zero-shot queries with clear task/role definitions are sufficient for classification without need for example selection overhead
- Core assumption: Prompt quality and task specification matter more than in-context examples for this classification task
- Evidence anchors:
  - "We further found that a zero-shot approach provided better accuracy than a few-shot approach using automatically generated examples"
  - "The result in the ablation study that the exclusion of selected examples led to better accuracy"

## Foundational Learning

- Concept: In-context learning with large language models
  - Why needed here: The system relies on LLMs making classification decisions based on prompt instructions rather than fine-tuning
  - Quick check question: What is the difference between zero-shot and few-shot prompting in LLM-based classification?

- Concept: Temperature sampling for probability estimation
  - Why needed here: The system needs to provide probability estimates for classification decisions
  - Quick check question: How does temperature sampling help estimate uncertainty in LLM outputs?

- Concept: Negative entropy as selection criterion
  - Why needed here: Used to select the most informative examples for few-shot prompting
  - Quick check question: What does maximizing negative entropy achieve when selecting examples?

## Architecture Onboarding

- Component map: Stage 1 (Zero-shot classification) -> Example selection module (Negative entropy + diversity) -> Stage 2 (Few-shot classification) -> Temperature sampling and majority voting -> Output probability estimation

- Critical path:
  1. Receive data point with task, input, target, generated text
  2. Generate zero-shot classifications for unlabeled data
  3. Select examples using negative entropy and diversity metrics
  4. Create few-shot prompt with examples
  5. Perform temperature sampling and majority voting
  6. Output classification and probability estimate

- Design tradeoffs:
  - Zero-shot vs few-shot: Better accuracy vs need for example selection
  - Number of samples: Higher accuracy vs increased computational cost
  - Temperature setting: Balance between exploration and exploitation

- Failure signatures:
  - Low accuracy with high temperature: Over-exploration leading to noisy classifications
  - Low Spearman's ρ: Poor probability calibration
  - Degradation with examples: Example selection algorithm not working as intended

- First 3 experiments:
  1. Compare zero-shot vs few-shot performance on validation set
  2. Sweep temperature parameter from 0.1 to 2.0 with fixed other parameters
  3. Test different numbers of samples per query (5, 10, 20) on accuracy and ρ

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why did the zero-shot approach outperform the few-shot approach in this hallucination detection task?
- Basis in paper: "We further found that a zero-shot approach provided better accuracy than a few-shot approach using automatically generated examples."
- Why unresolved: The paper doesn't provide a clear explanation for this unexpected result, which goes against the common assumption that few-shot learning typically performs better than zero-shot learning.
- What evidence would resolve it: Further experiments comparing zero-shot and few-shot performance on different datasets and tasks, or an analysis of the quality of the automatically generated examples used in the few-shot approach.

### Open Question 2
- Question: How does the temperature setting affect the performance of the hallucination detection classifier?
- Basis in paper: The paper discusses the impact of temperature on classifier performance, showing that accuracy is best between 0.5 and 1.0, while Spearman's ρ is best between 0.5 and 1.5.
- Why unresolved: While the paper identifies the optimal temperature range, it doesn't explain the underlying reasons for this relationship or how it might vary with different datasets or tasks.
- What evidence would resolve it: A more detailed analysis of how temperature affects the model's decision-making process, or experiments varying temperature across different types of tasks and datasets.

### Open Question 3
- Question: What is the impact of the number of examples per label on the few-shot classifier's performance?
- Basis in paper: The paper shows that increasing the number of examples beyond one per label leads to increased accuracy but decreased Spearman's ρ.
- Why unresolved: The paper doesn't explain why this trade-off occurs or what the optimal number of examples might be for different scenarios.
- What evidence would resolve it: Further experiments varying the number of examples across different tasks and datasets, or an analysis of how the examples influence the model's decision-making process.

## Limitations
- Limited ablation studies that isolate individual components' contributions to overall performance
- Comparison based on automatically generated examples rather than manually curated ones
- Lack of investigation into why explicit concept definitions improve performance mechanistically

## Confidence

**High Confidence Claims:**
- The system architecture using zero-shot followed by few-shot classification is technically sound and implementable
- The evaluation metrics (accuracy and Spearman's ρ) are appropriate for this task
- The overall fourth-place and sixth-place rankings are verifiable through competition results

**Medium Confidence Claims:**
- Zero-shot approach outperforms few-shot with automatically generated examples
- Including concept definitions improves performance
- Temperature sampling with majority voting improves probability estimation

**Low Confidence Claims:**
- The specific contribution of each component to overall performance (due to lack of ablation studies isolating individual factors)
- Generalizability of findings to other hallucination detection tasks or datasets
- Optimal hyperparameter settings (temperature, number of samples) across different scenarios

## Next Checks

1. **Ablation study isolation**: Conduct experiments that isolate each component (concept definitions, example selection, temperature sampling) to determine their individual contributions to performance, rather than testing them in combination.

2. **Alternative uncertainty estimation**: Compare the temperature sampling and majority voting approach against alternative uncertainty estimation methods (such as entropy-based scoring or model ensembles) to verify that the chosen method is optimal for this task.

3. **Manual vs automatic example curation**: Test whether manually curated few-shot examples outperform automatically generated ones, which would challenge the paper's finding that zero-shot is superior to few-shot with automatic examples.