---
ver: rpa2
title: Recursive Joint Simulation in Games
arxiv_id: '2402.08128'
source_url: https://arxiv.org/abs/2402.08128
tags:
- simulation
- agents
- game
- games
- players
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper studies how AI agents can use joint simulation to achieve
  more cooperative outcomes in strategic games. It introduces a framework where agents
  first observe a recursive simulation of their interaction before choosing their
  actions.
---

# Recursive Joint Simulation in Games

## Quick Facts
- arXiv ID: 2402.08128
- Source URL: https://arxiv.org/abs/2402.08128
- Authors: Vojtech Kovarik; Caspar Oesterheld; Vincent Conitzer
- Reference count: 8
- One-line primary result: Recursive joint simulation between AI agents creates strategic equivalence to infinitely repeated games, enabling cooperative outcomes through established game theory results.

## Executive Summary
This paper introduces a framework where AI agents use recursive joint simulation to achieve more cooperative outcomes in strategic games. Before choosing actions, agents observe a recursive simulation of their interaction, which includes nested sub-simulations with a small chance of failure to prevent infinite recursion. The key insight is that this recursive joint simulation is strategically equivalent to infinitely repeated games with exponential discounting, allowing direct transfer of folk theorem results. This equivalence shows that agents can achieve cooperative equilibria in games like Prisoner's Dilemma through strategies like grim trigger, where they cooperate as long as their opponent cooperates in all sub-simulations.

## Method Summary
The paper defines Recursive Joint Simulation (RJS) as a game where players first decide whether to simulate their interaction, then play the game based on simulation outcomes. The framework is modeled as an extensive-form game with chance nodes for simulation continuation, where agents recursively simulate with probability p. The authors prove strategic equivalence between RJS and infinitely repeated games, then explore variations including voluntary simulation, variable simulation probability over time, and limited simulation budgets. These variations correspond to different types of repeated games, maintaining the strategic equivalence under appropriate conditions.

## Key Results
- Recursive joint simulation is strategically equivalent to infinitely repeated games with exponential discounting (Theorem 1)
- Cooperative equilibria are achievable in RJS games through grim trigger strategies and other repeated game mechanisms (Corollary 4)
- The framework is robust to variations including voluntary simulation, variable continuation probabilities, and limited budgets, each corresponding to different repeated game structures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recursive joint simulation creates a strategic equivalence to infinitely repeated games with exponential discounting
- Mechanism: By nesting simulations with probability p of continuing deeper, the game structure mirrors a repeated game where continuation probability is p and payoffs are discounted by (1-p) per round
- Core assumption: Agents cannot distinguish between being in a simulation and reality, and only real actions have consequences
- Evidence anchors:
  - [abstract]: "This equivalence allows direct transfer of results from repeated game theory, such as folk theorems"
  - [section]: "Theorem 1 (Strategic equivalence to infinitely-repeated games). For any G and p, RJS(G, p) is strategically equivalent to RepT=?(G, p) and Repω(G, p)"
  - [corpus]: Weak - neighbors discuss multi-agent simulations but not recursive joint simulation equivalence specifically
- Break condition: If agents can detect simulation boundaries or if only real actions matter becomes ambiguous

### Mechanism 2
- Claim: Voluntary simulation with grim trigger strategies maintains strategic equivalence to the base RJS game
- Mechanism: Players agree to simulate, but defect if any player refuses simulation; this creates incentives for continued simulation without changing equilibrium outcomes
- Core assumption: Public knowledge of simulation preferences and ability to punish non-cooperation
- Evidence anchors:
  - [section]: "any strategy from the original game RJS(G, p) can be extended as follows: (i) The players always agree to be simulated. (ii) If the opponent declines to be simulated...the player responds by 'grim trigger'"
  - [abstract]: "The framework is robust to several variations: making simulation voluntary"
  - [corpus]: Weak - neighbors don't discuss voluntary simulation variants
- Break condition: If simulation preferences become private information or punishment mechanisms fail

### Mechanism 3
- Claim: Variable simulation probability creates equivalence to repeated games with non-exponential discounting
- Mechanism: When simulation probability varies by depth pt, the resulting game structure matches a repeated game where each round has continuation probability pt
- Core assumption: Infinite sum of simulation probabilities converges (∑pt < ∞)
- Evidence anchors:
  - [section]: "Proposition 5. Suppose that P∞ t=0 pt < ∞. Then RJS(G, (pt)∞ t=0) is realisation-equivalent to Replast T=?(G, (pt)∞ t=0)"
  - [abstract]: "The framework is robust to several variations: varying the simulation probability over time"
  - [corpus]: Weak - neighbors discuss variable agent behaviors but not variable continuation probabilities
- Break condition: If ∑pt diverges or agents can manipulate continuation probabilities

## Foundational Learning

- Concept: Extensive-form games representation
  - Why needed here: The paper models recursive simulations as extensive-form games with chance nodes for simulation continuation
  - Quick check question: What game-theoretic structure represents sequential decision-making with chance events?

- Concept: Folk theorems in repeated games
  - Why needed here: The strategic equivalence enables transfer of folk theorem results showing cooperative equilibria are possible
  - Quick check question: What game-theoretic result allows cooperative outcomes in repeated games when continuation probability is sufficiently high?

- Concept: Self-locating beliefs and perfect recall
  - Why needed here: Agents must form beliefs about their position in the simulation hierarchy, which affects strategic reasoning
  - Quick check question: How does perfect recall affect belief formation in games with indistinguishable states?

## Architecture Onboarding

- Component map: Game engine -> Simulation manager -> Agent interface -> Equivalence verifier
- Critical path: Base game setup → Simulation nesting (with p probability) → Agent action selection → Payoff calculation from top-level actions
- Design tradeoffs:
  - Simulation depth vs. computational cost: Deeper simulations enable richer strategic possibilities but increase computational burden
  - p value selection: Higher p enables better equivalence to infinitely repeated games but increases average simulation depth
  - Belief formation method: Regular methods simplify analysis but may not capture all strategic nuances
- Failure signatures:
  - Agents detect simulation boundaries (violates indistinguishability assumption)
  - Simulation probability p becomes too low (breaks equivalence to repeated games)
  - Self-locating beliefs become inconsistent (breaks strategic reasoning)
- First 3 experiments:
  1. Verify strategic equivalence by implementing Prisoner's Dilemma with p=0.9 and comparing equilibria to repeated game with discount factor 0.9
  2. Test voluntary simulation variant by implementing grim trigger punishment and checking if cooperation is maintained
  3. Explore variable p by implementing RJS with pt = 0.9^t and verifying equivalence to finitely repeated game with T rounds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions can recursive joint simulation be practically implemented in real-world AI systems?
- Basis in paper: [explicit] The paper discusses the need for indistinguishability between simulation and reality, noting this is challenging in practice, especially with rich interactions with the real world.
- Why unresolved: The paper identifies this as a promising future direction but doesn't provide concrete conditions or solutions for practical implementation.
- What evidence would resolve it: Specific technical solutions or protocols that ensure simulation indistinguishability in practical scenarios, along with demonstrations of successful implementation in AI systems.

### Open Question 2
- Question: How do self-locating beliefs form in recursive joint simulation games when using non-regular methods like generalized single halfing?
- Basis in paper: [explicit] The paper discusses regular methods of self-locating beliefs but notes that generalized single halfing (GSH) is not regular and may assign higher probabilities to being in possible worlds where one takes fewer actions.
- Why unresolved: The paper only proves propositions for regular methods and suggests that GSH might lead to different, potentially unnatural beliefs.
- What evidence would resolve it: A formal analysis of self-locating beliefs in recursive joint simulation games using non-regular methods, comparing outcomes with regular methods.

### Open Question 3
- Question: What are the implications of limited simulation budgets on the strategic equivalence between recursive joint simulation games and finitely repeated games?
- Basis in paper: [explicit] The paper discusses how limited simulation budgets can be modeled as a special case of RJS(G, (pt)∞t=0) and shows it's equivalent to finitely repeated games, but doesn't explore the strategic implications in detail.
- Why unresolved: While the equivalence is established, the paper doesn't explore how this affects the strategic outcomes or equilibria in practical scenarios with limited budgets.
- What evidence would resolve it: Detailed analysis of strategic outcomes and equilibria in recursive joint simulation games with various limited simulation budgets, compared to corresponding finitely repeated games.

## Limitations
- The framework assumes agents cannot distinguish between simulation and reality, which may be difficult to achieve in practice with rich real-world interactions
- Computational complexity grows with simulation depth, potentially limiting practical application to complex games
- The paper doesn't fully address how agents form and maintain self-locating beliefs about their position in the simulation hierarchy

## Confidence
- High confidence: Strategic equivalence between RJS and repeated games (Theorem 1)
- Medium confidence: Folk theorem applications and cooperative equilibria in RJS games
- Low confidence: Scalability and practical implementation details

## Next Checks
1. **Equivalence verification experiment**: Implement a simple game (e.g., Prisoner's Dilemma) with RJS and explicitly verify payoff equivalence to the corresponding repeated game across multiple strategy profiles. Check if the strategic equivalence holds in practice, not just in theory.

2. **Belief formation robustness test**: Implement agents with different belief formation strategies about their simulation depth. Test whether strategic reasoning breaks down when beliefs become inconsistent or when agents can detect simulation boundaries.

3. **Computational complexity analysis**: Measure simulation depth and computational requirements for RJS with varying p values and game complexities. Determine practical limits on game size and simulation depth before the approach becomes computationally infeasible.