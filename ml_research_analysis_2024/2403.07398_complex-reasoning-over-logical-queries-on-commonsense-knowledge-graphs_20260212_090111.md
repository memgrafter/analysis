---
ver: rpa2
title: Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs
arxiv_id: '2403.07398'
source_url: https://arxiv.org/abs/2403.07398
tags:
- queries
- commonsense
- reasoning
- complex
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COM 2, a novel dataset for complex commonsense
  reasoning constructed by sampling multi-hop logical queries from a commonsense knowledge
  graph and verbalizing them into natural language questions. The dataset includes
  over 780K training examples and 1.3K human-verified evaluation examples covering
  various query types such as conjunctions, projections, and their combinations.
---

# Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs

## Quick Facts
- arXiv ID: 2403.07398
- Source URL: https://arxiv.org/abs/2403.07398
- Authors: Tianqing Fang; Zeming Chen; Yangqiu Song; Antoine Bosselut
- Reference count: 40
- Key outcome: Introduces COM 2 dataset with 780K+ training examples and 1.3K human-verified evaluation examples for complex commonsense reasoning

## Executive Summary
This paper introduces COM 2, a novel dataset for complex commonsense reasoning constructed by sampling multi-hop logical queries from a commonsense knowledge graph and verbalizing them into natural language questions. The dataset includes over 780K training examples and 1.3K human-verified evaluation examples covering various query types such as conjunctions, projections, and their combinations. Experiments show that fine-tuning models on COM 2 significantly improves their performance on eight downstream commonsense reasoning tasks, with gains up to 9% over strong baselines. The dataset also serves as a challenging benchmark, revealing that even powerful language models like GPT-4 struggle with complex multi-hop reasoning, achieving only 45-54% accuracy.

## Method Summary
The COM 2 dataset is constructed by sampling multi-hop logical queries from the ATOMIC20 20 commonsense knowledge graph, then verbalizing these queries into natural language questions using a combination of rule-based templates and LLM-based approaches. The method involves preprocessing the KG by normalizing nodes and filtering low-quality triples, sampling complex query structures (2i, 2p, 3i, ip, pi) using pre-order traversal, verbalizing contexts and questions, and converting answers to multiple-choice format. Models are fine-tuned on the synthetic training data for 1 epoch and evaluated on manually-verified examples.

## Key Results
- Fine-tuning models on COM 2 improves downstream commonsense reasoning performance by up to 9% over strong baselines
- CAR + COM 2 outperforms 11B version of UnifiedQA-v2 and Flan-T5 by 9% and 3% respectively
- Even GPT-4 struggles with COM 2, achieving only 45-54% accuracy on the challenging multi-hop reasoning benchmark

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distant supervision from COM 2 improves multi-hop reasoning without human annotations.
- Mechanism: Logical queries are sampled from a commonsense knowledge graph and verbalized into natural language questions, providing scalable training data for models to learn complex reasoning patterns.
- Core assumption: Multi-hop logical queries sampled from CSKGs capture sufficient diversity and complexity to improve downstream reasoning.
- Evidence anchors:
  - [abstract]: "Experiments show that fine-tuning models on COM 2 significantly improves their performance on eight downstream commonsense reasoning tasks, with gains up to 9% over strong baselines."
  - [section 4.2]: "CAR + COM 2 also outperforms the 11B version of UnifiedQA-v2 and Flan-T5, which are both fine-tuned on numerous (commonsense) question answering datasets, by 9% and 3%, respectively."
  - [corpus]: Weak evidence - only related titles available, no specific citations to COM 2 performance.
- Break condition: If the sampled queries do not capture sufficient diversity or if the verbalization step introduces noise that confuses models rather than improving reasoning.

### Mechanism 2
- Claim: Training on COM 2 improves zero-shot performance on out-of-domain tasks.
- Mechanism: The diverse query structures in COM 2 (conjunction, projection, and combinations) provide rich supervision that generalizes to unseen reasoning scenarios in downstream tasks.
- Core assumption: The reasoning patterns learned from COM 2's query structures transfer effectively to out-of-domain tasks.
- Evidence anchors:
  - [abstract]: "Our results demonstrate the challenges faced by even powerful LLMs and supervised question answering models on the COM 2 dataset, underscoring the difficulty of performing complex multi-hop reasoning."
  - [section 5.1]: "Notably, the combination of CAR and COM 2 achieves the highest performance among all models, surpassing even ChatGPT and GPT-4, despite having a parameter size at least two orders of magnitude smaller."
  - [corpus]: Weak evidence - only related titles available, no specific citations to zero-shot transfer performance.
- Break condition: If the reasoning patterns in COM 2 are too specific to its query types and do not transfer to the structures found in downstream tasks.

### Mechanism 3
- Claim: Chain-of-Thought prompting improves reasoning performance on COM 2.
- Mechanism: CoT allows models to first induce causes or effects of individual events in intersection-based queries (2i and 3i), or induce hidden variables in projection-based queries (2p).
- Core assumption: Decomposing complex queries into simpler reasoning steps through CoT improves model performance.
- Evidence anchors:
  - [section 4.2]: "We observe that Chain-of-Thought (CoT) improves reasoning