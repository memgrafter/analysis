---
ver: rpa2
title: Mitigating Copy Bias in In-Context Learning through Neuron Pruning
arxiv_id: '2410.01288'
source_url: https://arxiv.org/abs/2410.01288
tags:
- shot
- neurons
- copying
- tasks
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the issue of "copying bias" in few-shot in-context
  learning (ICL) with large language models (LLMs), where models tend to copy answers
  from provided examples rather than learning underlying patterns. The authors propose
  a method to mitigate this bias by identifying and pruning "copying neurons" - specific
  neurons that prioritize copying over generalization.
---

# Mitigating Copy Bias in In-Context Learning through Neuron Pruning

## Quick Facts
- arXiv ID: 2410.01288
- Source URL: https://arxiv.org/abs/2410.01288
- Authors: Ameen Ali; Lior Wolf; Ivan Titov
- Reference count: 26
- Primary result: Neuron pruning effectively reduces copying bias in ICL across diverse tasks and model architectures

## Executive Summary
This paper addresses the problem of "copying bias" in few-shot in-context learning (ICL) where large language models tend to replicate answers from provided examples rather than learning underlying patterns. The authors propose a novel method to identify and prune specific "copying neurons" that trigger this behavior. By leveraging Integrated Gradients on a synthetic vowel-counting task, they identify neurons responsible for copying, then prune them to improve ICL performance. The method is shown to be effective across multiple model architectures (Transformers and State-Space Models) and consistently improves performance on diverse ICL tasks while also enhancing the quality of task representations.

## Method Summary
The method identifies "copying neurons" using Integrated Gradients (IG) attribution on a synthetic vowel-counting task. IG traces prediction shifts when neurons' weights change, identifying those contributing most to copying behavior (where predictions shift from correct answers to those in the prompt). The top-scoring neurons are then pruned from specific layers in various model architectures. The optimal pruning rate and layer are determined using a validation proxy dataset. This targeted neuron pruning improves ICL accuracy across 18 diverse tasks while reducing copying errors and enhancing task vector quality.

## Key Results
- Significant reductions in copying errors across multiple models and tasks
- Consistent ICL accuracy improvements across 18 diverse tasks
- Enhanced quality of task vectors, indicating improved task representation
- Method effectiveness demonstrated across Transformers and State-Space Models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pruning neurons that prioritize copying over generalization improves ICL performance.
- Mechanism: The method identifies "copying neurons" that trigger models to replicate answers from the prompt examples instead of learning underlying patterns. By pruning these neurons, the model is forced to focus on recognizing task patterns rather than relying on copying shortcuts.
- Core assumption: Copying neurons are task-agnostic and responsible for copying behavior across a range of ICL tasks.
- Evidence anchors:
  - [abstract] "We propose a novel and simple method to mitigate such copying bias... pruning these neurons consistently improves performance across a diverse set of ICL tasks."
  - [section 3.3] "We hypothesize that there exists a small number of neurons, which we call copying neurons, that trigger the model to copy responses from the prompt examples"
  - [corpus] Weak - the corpus papers discuss copying in language models but don't specifically address targeted neuron pruning as a solution
- Break condition: If copying neurons are task-specific rather than task-agnostic, the pruning method would need to be applied differently for each task.

### Mechanism 2
- Claim: Integrated Gradients (IG) can effectively identify copying neurons by attributing prediction shifts to individual neurons.
- Mechanism: IG traces the change in model output (prediction shift) when a neuron's weight changes from baseline to original value. Neurons contributing most to copying (where prediction shifts from correct answer to one in the prompt) are identified as copying neurons.
- Core assumption: The prediction shift (difference between probability of ground truth answer and probability of prompt answers) is a valid proxy for copying behavior.
- Evidence anchors:
  - [section 3.3] "By leveraging IG, we can attribute ΔL to individual components. This approach enables us to identify specific neurons responsible for copying within the LLM."
  - [section 3.1] Definition of copying bias and how prediction yn+1 is called a copying prediction if it's wrong AND yn+1 ∈ S (in the prompt examples)
  - [corpus] Missing - no direct evidence in corpus about using IG specifically for identifying copying neurons
- Break condition: If the prediction shift doesn't accurately capture copying behavior, IG would identify wrong neurons.

### Mechanism 3
- Claim: Pruning copying neurons enhances task recognition quality as measured by task vectors.
- Mechanism: The pruning method improves the quality of task vectors (Hendel et al., 2023), which represent the model's ability to recognize and adapt to tasks during ICL. Better task vectors indicate improved task representation and reasoning.
- Core assumption: Task vectors are a valid proxy for measuring a model's task recognition ability in ICL.
- Evidence anchors:
  - [abstract] "pruning enhances the quality of these vectors, suggesting that the pruned neurons previously hindered effective task recognition"
  - [section 4.3] Results showing improved Task-Vectors-Pruned accuracy compared to standard ICL and Task-Vectors without pruning
  - [corpus] Weak - the corpus papers discuss task vectors and ICL but don't specifically connect neuron pruning to improved task vector quality
- Break condition: If task vectors don't accurately reflect the model's ability to recognize and adapt to tasks, improvements in task vectors wouldn't translate to better ICL performance.

## Foundational Learning

- Concept: Integrated Gradients (IG) attribution method
  - Why needed here: IG is used to identify which neurons contribute most to copying behavior by attributing the prediction shift to individual neurons
  - Quick check question: How does IG differ from simple gradient-based attribution methods?

- Concept: In-Context Learning (ICL) framework
  - Why needed here: Understanding ICL is crucial because the method specifically targets copying bias in few-shot learning scenarios where models learn from provided examples
  - Quick check question: What distinguishes copying bias from other types of errors in ICL?

- Concept: Neuron-level analysis and pruning
  - Why needed here: The method operates at the neuron level, identifying and pruning specific neurons rather than applying general model modifications
  - Quick check question: Why might pruning specific neurons be preferable to other model modification techniques like fine-tuning?

## Architecture Onboarding

- Component map: The method operates on linear layers within model blocks. For different architectures, it targets specific layer types: fc1 linear (OPT), mlp.c fc cnn (GPT2), mlp.dense h to 4h linear (Bloom), mlp.gate proj linear (Llama), mixer.in proj linear (Mamba).

- Critical path: 1) Generate synthetic vowel-counting dataset, 2) Identify copying neurons using IG on synthetic data, 3) Determine optimal pruning rate and layer using validation dataset, 4) Apply pruning to target layer, 5) Evaluate on ICL tasks.

- Design tradeoffs: The method trades model capacity (by removing neurons) for improved generalization. It requires no task-specific data but does need a synthetic dataset for neuron identification.

- Failure signatures: If pruning is applied to wrong layer, performance may degrade. If too many neurons are pruned, the model may lose capacity for legitimate pattern recognition. If too few are pruned, copying bias may persist.

- First 3 experiments:
  1. Verify that the unpruned model exhibits copying errors on the synthetic vowel-counting task
  2. Apply IG to the synthetic dataset and examine attribution scores to confirm copying neurons can be identified
  3. Test pruning on a small percentage of top-scoring neurons and verify reduction in copying errors on the validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific characteristics distinguish "copying neurons" from other types of neurons identified in previous studies (e.g., safety neurons, language-specific neurons)?
- Basis in paper: [explicit] The paper identifies "copying neurons" as a specific subset that prioritizes copying over generalization, distinct from other neuron types discussed in related work.
- Why unresolved: The paper doesn't provide a detailed comparison of copying neurons with other neuron types or their distinguishing features.
- What evidence would resolve it: A systematic comparison of activation patterns, attribution scores, and functional roles of copying neurons versus other neuron types across multiple tasks and models.

### Open Question 2
- Question: How does the effectiveness of neuron pruning for mitigating copying bias vary with model size and architecture (e.g., Transformers vs. State-Space Models)?
- Basis in paper: [inferred] The paper tests the method across various model architectures and sizes but doesn't provide a detailed analysis of how effectiveness scales with model complexity.
- Why unresolved: While results are shown for different models, there's no systematic analysis of how pruning effectiveness changes with model scale or architecture type.
- What evidence would resolve it: A comprehensive study comparing pruning effectiveness across a wider range of model sizes and architectures, including analysis of the optimal pruning rate for each configuration.

### Open Question 3
- Question: What is the relationship between the identified copying neurons and the model's ability to learn novel tasks beyond the specific ICL tasks tested?
- Basis in paper: [explicit] The paper shows that pruning copying neurons improves performance across diverse ICL tasks, suggesting a general mechanism.
- Why unresolved: The paper doesn't explore whether the benefits of pruning extend to entirely new types of tasks or whether there are any negative impacts on learning capabilities.
- What evidence would resolve it: Testing the pruned models on a broader range of tasks, including those not previously seen during neuron identification, and comparing their learning curves to unpruned models.

## Limitations

- The synthetic vowel-counting task may not fully capture the complexity of real-world copying bias across diverse ICL scenarios
- The claim that copying neurons are "task-agnostic" lacks theoretical justification for why these neurons would generalize across fundamentally different tasks
- The optimal pruning rate and layer identification relies on a proxy validation dataset, which may not perfectly align with downstream ICL performance

## Confidence

- **High Confidence**: The empirical demonstration that neuron pruning reduces copying errors on the synthetic vowel-counting task and improves ICL accuracy across multiple real datasets
- **Medium Confidence**: The mechanism by which Integrated Gradients identifies copying neurons is sound, but the interpretation that these neurons are specifically responsible for copying rather than general pattern matching could be questioned
- **Medium Confidence**: The claim about improved task vector quality as evidence of better task recognition, as the relationship between task vectors and actual ICL performance could be more complex than presented

## Next Checks

1. Test the method on a broader range of copying scenarios beyond vowel-counting, including tasks with structural similarities to prompt examples but requiring generalization
2. Conduct ablation studies removing IG attribution and using random neuron pruning to quantify how much performance gain comes specifically from targeting copying neurons
3. Evaluate the pruned models on out-of-distribution ICL tasks to assess whether improved copying bias mitigation generalizes to unseen task types