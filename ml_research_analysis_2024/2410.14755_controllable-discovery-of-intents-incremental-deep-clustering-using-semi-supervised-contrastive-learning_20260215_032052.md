---
ver: rpa2
title: 'Controllable Discovery of Intents: Incremental Deep Clustering Using Semi-Supervised
  Contrastive Learning'
arxiv_id: '2410.14755'
source_url: https://arxiv.org/abs/2410.14755
tags:
- learning
- dataset
- intents
- clustering
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Controllable Discovery of Intents (CDI), a
  semi-supervised deep clustering framework for discovering new intents in conversational
  AI systems. The key innovation is combining unsupervised contrastive learning, supervised
  fine-tuning, and iterative clustering with pseudo-labeling, while using learning-without-forgetting
  to prevent catastrophic forgetting.
---

# Controllable Discovery of Intents: Incremental Deep Clustering Using Semi-Supervised Contrastive Learning

## Quick Facts
- arXiv ID: 2410.14755
- Source URL: https://arxiv.org/abs/2410.14755
- Authors: Mrinal Rawat, Hithesh Sankararaman, Victor Barres
- Reference count: 8
- Primary result: Outperforms state-of-the-art by 10.26% and 11.72% in clustering accuracy on CLINC and BANKING datasets

## Executive Summary
This paper introduces Controllable Discovery of Intents (CDI), a semi-supervised deep clustering framework for discovering new intents in conversational AI systems. CDI combines unsupervised contrastive learning, supervised fine-tuning with learning-without-forgetting, and iterative clustering with pseudo-labeling. The framework allows human-in-the-loop control by incrementally refining clusters based on expert feedback. Experiments on three datasets demonstrate superior performance compared to state-of-the-art methods while successfully discovering new intents incrementally.

## Method Summary
CDI employs a three-stage approach: domain adaptation using unsupervised contrastive learning, supervised fine-tuning with learning-without-forgetting (LwF) to preserve knowledge of known intents, and iterative clustering with pseudo-labeling. The method uses MPNet as the backbone, generates positive pairs through dropout-based SimCSE, and employs K-means clustering with Hungarian algorithm for label alignment. Human experts can interactively refine clusters through an interface that allows sample selection and cluster merging.

## Key Results
- Achieves 10.26% and 11.72% improvement in clustering accuracy over state-of-the-art methods on CLINC and BANKING datasets
- Successfully discovers new intents incrementally with simulated human feedback
- Prevents catastrophic forgetting through LwF mechanism while learning new intents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning without forgetting (LwF) prevents catastrophic forgetting during stage transitions.
- Mechanism: LwF adds a KL-divergence penalty that keeps the new model's output close to the old model's output for known intents.
- Core assumption: The old model's knowledge for known intents remains useful when learning new pseudo-labels.
- Evidence anchors:
  - [abstract] "we draw from continual learning literature and use learning-without-forgetting to prevent catastrophic forgetting across those training stages"
  - [section] "To address this problem, Learning without Forgetting (LwF) (Li and Hoiem, 2018) was proposed which aims to preserve the previously learned knowledge while learning new tasks"
- Break condition: If the KL-divergence penalty is too small, forgetting occurs; if too large, learning new intents is blocked.

### Mechanism 2
- Claim: Unsupervised contrastive learning (UCL) improves domain adaptation by creating positive pairs from the same sentence.
- Mechanism: SimCSE generates positive pairs by applying different dropout masks to the same sentence, then optimizes cosine similarity.
- Core assumption: Same sentences share semantic meaning regardless of dropout variations, so they should have similar embeddings.
- Evidence anchors:
  - [section] "For every input sentence xi, we generate a positive pair x+i by feeding the same input twice to the encoder with different dropout masks"
  - [section] "The learning objective is described below: Lucl = −∑i∈N log esim(hzi i ,hz′i i )/τ"
- Break condition: If dropout masks produce too different embeddings, the positive pairs may no longer represent the same semantic content.

### Mechanism 3
- Claim: Incremental human-in-the-loop clustering discovers new intents by iteratively refining clusters with expert feedback.
- Mechanism: At each iteration, high-confidence samples are selected based on distance to cluster centroids, then presented to human for labeling and merging.
- Core assumption: Human experts can reliably identify meaningful intents from cluster visualizations and select representative samples.
- Evidence anchors:
  - [section] "Our tool allows them to interactively select or deselect samples within each cluster. The user can also merge similar clusters"
  - [section] "At each iteration t, we use the trained model Mt−1 to extract representations of the unlabeled dataset DU and perform K-means clustering"
- Break condition: If cluster quality is poor due to insufficient training, human feedback may not be reliable enough to guide meaningful intent discovery.

## Foundational Learning

- Concept: Contrastive learning fundamentals
  - Why needed here: Understanding how positive and negative pairs create meaningful embedding spaces for clustering
  - Quick check question: What happens to embedding similarity when contrastive loss is minimized?

- Concept: Catastrophic forgetting in transfer learning
  - Why needed here: Recognizing why models lose knowledge when fine-tuning on new tasks without preservation mechanisms
  - Quick check question: How does KL-divergence help maintain old knowledge during new learning?

- Concept: K-means clustering assumptions
  - Why needed here: Understanding limitations of centroid-based clustering in high-dimensional spaces
  - Quick check question: What happens when cluster boundaries are not spherical in embedding space?

## Architecture Onboarding

- Component map:
  MPNet backbone → UCL domain adaptation → Stage 1 supervised fine-tuning (LwF) → Stage 2 iterative clustering (Hungarian algorithm) → Human-in-the-loop interface
  Key modules: Dropout-based positive pair generation, KL-divergence preservation layer, K-means clustering engine, Hungarian algorithm matching

- Critical path:
  1. Domain adaptation with UCL on unlabeled data
  2. Fine-tuning on labeled data with LwF objective
  3. K-means clustering on fine-tuned embeddings
  4. Pseudo-label generation and Hungarian alignment
  5. Iterative refinement with human feedback

- Design tradeoffs:
  - Freezing first 11 MPNet layers balances adaptation speed vs. computational cost
  - Confidence threshold (0.7-0.95) trades recall vs. precision in sample selection
  - K initialization strategy affects early iteration efficiency

- Failure signatures:
  - Low clustering accuracy with high known intent ratios suggests insufficient fine-tuning
  - Stagnant K values across iterations indicate poor embedding quality or bad confidence thresholds
  - Sudden accuracy drops between stages suggest LwF parameter λ is too small

- First 3 experiments:
  1. Baseline: Run CDI without LwF to measure forgetting impact
  2. Ablation: Test different confidence thresholds (0.5, 0.7, 0.9) on sample selection
  3. Scaling: Vary known intent ratios (25%, 50%, 75%) to observe adaptation robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CDI perform on languages other than English, and what architectural modifications would be needed for effective multilingual intent discovery?
- Basis in paper: [explicit] The authors mention "In future work, we plan to extend our approach to other languages" as a future direction
- Why unresolved: The current work only evaluates on English datasets (CLINC, BANKING, TELECOM), leaving the multilingual performance unknown
- What evidence would resolve it: Experimental results on multilingual datasets or cross-lingual transfer learning experiments showing performance on non-English intent discovery tasks

### Open Question 2
- Question: What is the optimal strategy for determining the initial number of clusters K and confidence thresholds γ in real-world applications where ground truth labels are unavailable?
- Basis in paper: [inferred] The authors acknowledge they "did not investigate in detail to calculate the optimal value of K" and use heuristic thresholds (γ = 0.7 for first iteration, γ = 0.95 for subsequent iterations)
- Why unresolved: The paper relies on simulated human feedback with ground truth labels for evaluation, which doesn't reflect practical deployment scenarios where true labels are unknown
- What evidence would resolve it: Comparative analysis of different K estimation methods (elbow method, silhouette analysis, gap statistic) and adaptive threshold determination strategies evaluated on unlabeled datasets

### Open Question 3
- Question: How does incorporating contextual information from the full conversation transcript impact CDI's intent discovery performance compared to using turn-level embeddings alone?
- Basis in paper: [explicit] The authors state "Turn embeddings do not account for the larger context of the transcript in which the turn appears" and note this as a limitation
- Why unresolved: The current experiments only use turn-level embeddings without leveraging conversational context, leaving the potential performance gain from context incorporation unexplored
- What evidence would resolve it: Experimental comparison between turn-level vs. context-aware embeddings (e.g., hierarchical models, transformer-based context aggregation) on the same intent discovery tasks showing performance differences

## Limitations
- Evaluation relies on simulated human feedback with ground truth labels, not reflecting real-world scenarios where true labels are unknown
- Computational cost of iterative refinement with contrastive learning and LwF mechanisms may limit practical deployment
- Scalability to very large intent spaces (1000+ intents) is not demonstrated

## Confidence
- **High Confidence**: The theoretical foundation of contrastive learning and LwF mechanisms is well-established in the literature. The clustering methodology using K-means and Hungarian algorithm alignment is standard practice.
- **Medium Confidence**: The claimed performance improvements are plausible given the methodology, but depend heavily on implementation details and hyperparameter tuning. The incremental discovery process with human feedback is promising but introduces variability.
- **Low Confidence**: The scalability of the approach to very large intent spaces (1000+ intents) is not demonstrated. The impact of different confidence thresholds on discovery quality needs more systematic exploration.

## Next Checks
1. **Ablation Study**: Conduct controlled experiments removing LwF and UCL components to quantify their individual contributions to performance gains, particularly focusing on catastrophic forgetting and domain adaptation effects.

2. **Confidence Threshold Sensitivity**: Systematically evaluate how different confidence thresholds (0.5, 0.7, 0.9) affect the trade-off between discovery recall and precision across multiple dataset splits and random seeds.

3. **Generalization Test**: Apply CDI to a completely different domain (e.g., healthcare or customer support) with minimal hyperparameter tuning to assess the method's domain adaptation capabilities beyond the reported datasets.