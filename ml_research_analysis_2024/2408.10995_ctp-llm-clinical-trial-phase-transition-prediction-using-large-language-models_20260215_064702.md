---
ver: rpa2
title: 'CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models'
arxiv_id: '2408.10995'
source_url: https://arxiv.org/abs/2408.10995
tags:
- trial
- phase
- clinical
- trials
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of predicting clinical trial
  phase transitions using trial protocol documents. The authors introduce CTP-LLM,
  a fine-tuned GPT-3.5-based model, and the PhaseTransition (PT) Dataset, which labels
  trials based on their progression through regulatory phases.
---

# CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models

## Quick Facts
- arXiv ID: 2408.10995
- Source URL: https://arxiv.org/abs/2408.10995
- Reference count: 40
- Primary result: 67% overall accuracy in predicting clinical trial phase transitions, with 75% accuracy for Phase III to approval transitions

## Executive Summary
This paper addresses the challenge of predicting clinical trial phase transitions using trial protocol documents. The authors introduce CTP-LLM, a fine-tuned GPT-3.5-based model, and the PhaseTransition (PT) Dataset, which labels trials based on their progression through regulatory phases. CTP-LLM analyzes original protocol texts without requiring human-selected features and achieves 67% accuracy in predicting phase transitions across all phases and 75% accuracy for the transition from Phase III to final approval. The study demonstrates the potential of large language models in forecasting clinical trial outcomes and assessing trial design.

## Method Summary
The authors created the PhaseTransition dataset by collecting trial protocols from ClinicalTrials.gov and phase transition labels from BioMedtracker. They developed two models: a BERT+RF hybrid using clinical BERT embeddings with a Random Forest classifier, and CTP-LLM, a fine-tuned GPT-3.5 Turbo model. The models take trial protocol descriptions (concatenating 11 protocol attributes) as input and predict whether trials successfully transition to the next phase. Training was performed across all three phases simultaneously to capture dependencies between phases.

## Key Results
- CTP-LLM achieved 67% accuracy in predicting trial phase transitions across all phases
- For Phase III to approval transitions specifically, accuracy reached 75%
- Multi-phase training improved prediction accuracy compared to single-phase models
- The model performs well even with limited Phase III training data by leveraging information from earlier phases

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Using trial protocol documents as input allows the model to automatically identify relevant features for predicting phase transitions.
- **Mechanism**: The model analyzes the full trial protocol text, including study objectives, design, participant criteria, and treatment plans, without requiring human-selected features. This enables the model to discover complex relationships between protocol characteristics and trial outcomes.
- **Core assumption**: The textual information in trial protocols contains sufficient signal about trial success/failure to enable accurate predictions.
- **Evidence anchors**: "CTP-LLM achieves a 67% accuracy rate in predicting trial phase transitions across all phases and a 75% accuracy rate specifically in predicting the transition from Phase III to final approval."

### Mechanism 2
- **Claim**: Labeling trials based on phase transitions rather than recruitment status provides more accurate training data for outcome prediction.
- **Mechanism**: The model uses a novel labeling method that tracks whether a drug advances to subsequent phases based on Biomedtracker data, rather than just whether a trial was completed. This captures the true outcome of interest (phase transition success) rather than just completion status.
- **Core assumption**: Phase transition labels are more meaningful indicators of trial success than recruitment status alone.
- **Evidence anchors**: "A trial can have been completed as planned while having proven that the test treatment has no efficacy... Similarly, a trial could have been terminated because the tested treatment showed promising effects earlier than expected."

### Mechanism 3
- **Claim**: Training a model across multiple phases simultaneously captures the interconnected nature of the clinical trial process and improves prediction accuracy.
- **Mechanism**: The model is trained on trials from all three phases together, allowing it to learn relationships between earlier phase characteristics and later phase outcomes. This reflects the real-world regulatory process where information from earlier phases influences later phases.
- **Core assumption**: Information from earlier phases is predictive of success in later phases, and training across phases captures these dependencies.
- **Evidence anchors**: "We conclude that the remaining Phase I and Phase II trial data in CTP-LLM's training set holds valuable information on predicting the transition from Phase III to Approval."

## Foundational Learning

- **Clinical trial phases and regulatory process**: Why needed here: Understanding the structure of clinical trials (Phases I, II, III, and FDA approval) is essential to grasp what the model is predicting and why phase transitions matter.
  - Quick check question: What are the typical goals of each clinical trial phase, and why is Phase III considered the most costly?

- **Natural Language Processing (NLP) fundamentals**: Why needed here: The models use text processing techniques to analyze trial protocols, so understanding tokenization, embeddings, and transformer architectures is crucial.
  - Quick check question: What is the difference between token-level and document-level representations in NLP?

- **Machine learning evaluation metrics**: Why needed here: The paper reports accuracy and F1 scores, so understanding these metrics and their limitations is important for interpreting results.
  - Quick check question: Why might F1 score be more informative than accuracy for this imbalanced classification problem?

- **Clinical trial data sources**: Why needed here: The models use ClinicalTrials.gov and Biomedtracker data, so understanding these sources and their limitations is important for contextualizing the results.
  - Quick check question: What are the main differences between ClinicalTrials.gov and Biomedtracker, and why does the paper use both?

## Architecture Onboarding

- **Component map**: Data collection (ClinicalTrials.gov + Biomedtracker) -> Dataset creation (Labeling based on phase transitions) -> Model training (BERT+RF and CTP-LLM) -> Evaluation (Test on held-out data, ablation studies)

- **Critical path**: The most critical sequence is: data collection → accurate labeling → model training → evaluation. Each step depends on the previous one, and errors compound through the pipeline.

- **Design tradeoffs**: 
  - BERT+RF offers lower computational cost and faster training but may miss complex patterns that LLMs can capture.
  - CTP-LLM provides higher accuracy but requires API access and is more expensive to train.
  - Multi-phase training captures dependencies but may introduce look-ahead bias if not handled carefully.

- **Failure signatures**:
  - Low accuracy on test set could indicate data leakage, poor labeling, or insufficient signal in the input features.
  - High variance between runs might suggest unstable training or insufficient data.
  - Performance degradation on specific phases could indicate class imbalance or domain shift.

- **First 3 experiments**:
  1. Train BERT+RF on a single phase (Phase III only) to establish a baseline for comparison with multi-phase training.
  2. Fine-tune CTP-LLM on the full dataset with the standard prompt to establish the main result (67% accuracy).
  3. Conduct an ablation study by removing key features (e.g., participant criteria) to identify the most important input elements.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CTP-LLM model handle clinical trial protocols with missing or incomplete information, and what impact does this have on its prediction accuracy?
- Basis in paper: [inferred] The paper mentions that ClinicalTrials.gov entries are of varying quality and that some trials lack accurate and complete information.
- Why unresolved: The paper does not provide specific details on how the model deals with missing or incomplete information in the trial protocols.
- What evidence would resolve it: A detailed analysis of the model's performance on trials with varying levels of information completeness, including metrics on accuracy and F1 scores for trials with missing data.

### Open Question 2
- Question: What are the specific reasons behind the high attrition rates observed in trials classified as "Unknown" drug types, and how does this compare to other drug classes?
- Basis in paper: [explicit] The paper notes that trials with an unreported drug type fail in approximately 90% of cases, but does not delve into the reasons for this high failure rate.
- Why unresolved: The paper identifies the high failure rate but does not explore the underlying causes or compare them to other drug classes.
- What evidence would resolve it: A comparative study of the reasons for trial failures across different drug classes, focusing on the "Unknown" category to identify specific factors contributing to their high attrition rates.

### Open Question 3
- Question: How does the performance of CTP-LLM in predicting phase transitions vary across different medical fields or indications, and what factors contribute to these variations?
- Basis in paper: [inferred] The paper discusses the use of a comprehensive dataset that includes trials from various medical fields but does not analyze performance variations across these fields.
- Why unresolved: The paper does not provide a breakdown of the model's performance by medical field or indication.
- What evidence would resolve it: A detailed analysis of the model's accuracy and F1 scores for trials across different medical fields, identifying factors such as indication complexity or field-specific trial design elements that influence prediction performance.

## Limitations
- The relatively modest accuracy rates (67% overall, 75% for Phase III to approval) suggest the models still struggle with this complex prediction task.
- The novel labeling approach based on phase transitions rather than recruitment status depends entirely on the accuracy and completeness of BioMedtracker data.
- The comparison between CTP-LLM and BERT+RF models is complicated by fundamental architectural differences and computational costs.

## Confidence
- **High confidence**: The mechanism of using trial protocol text as input for prediction is well-established and the data collection methodology from ClinicalTrials.gov is standard practice.
- **Medium confidence**: The claim that phase transition labels are superior to recruitment status labels is logically sound but relies heavily on the quality of external BioMedtracker data.
- **Low confidence**: The claim that multi-phase training provides significant benefits over single-phase training is based on limited ablation studies and lacks strong comparative evidence from the literature.

## Next Checks
1. Conduct an independent verification of BioMedtracker phase transition labels against FDA approval databases to assess labeling accuracy and potential biases.
2. Perform a cost-benefit analysis comparing CTP-LLM's performance gains against BERT+RF's lower computational requirements across different trial phases.
3. Test the model's generalization ability on trials from different therapeutic areas or time periods to evaluate whether performance holds beyond the original dataset.