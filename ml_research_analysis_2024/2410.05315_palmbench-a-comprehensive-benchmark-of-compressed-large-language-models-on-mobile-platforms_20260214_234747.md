---
ver: rpa2
title: 'PalmBench: A Comprehensive Benchmark of Compressed Large Language Models on
  Mobile Platforms'
arxiv_id: '2410.05315'
source_url: https://arxiv.org/abs/2410.05315
tags:
- quantization
- mobile
- devices
- memory
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PalmBench, a comprehensive benchmarking framework
  for evaluating large language models (LLMs) on mobile devices. The framework automates
  performance testing across multiple mobile platforms and quantization configurations,
  measuring resource utilization, accuracy, and harmful outputs.
---

# PalmBench: A Comprehensive Benchmark of Compressed Large Language Models on Mobile Platforms

## Quick Facts
- arXiv ID: 2410.05315
- Source URL: https://arxiv.org/abs/2410.05315
- Reference count: 16
- Key outcome: iPhones outperform other platforms in energy efficiency, latency, and throughput for LLM inference; 4-bit quantization preserves performance while reducing model size to one-quarter

## Executive Summary
This paper introduces PalmBench, a comprehensive benchmarking framework for evaluating large language models (LLMs) on mobile devices. The framework automates performance testing across multiple mobile platforms and quantization configurations, measuring resource utilization, accuracy, and harmful outputs. Key findings include that iPhones demonstrate superior performance characteristics compared to Android and Linux platforms, and that 4-bit quantization methods can effectively compress models while maintaining acceptable accuracy levels. The study also reveals that lower-bit quantization increases hallucinations and toxic content generation, with 3-bit quantization performing particularly poorly in these metrics.

## Method Summary
The PalmBench framework automates benchmarking of compressed LLMs on mobile platforms using Android GPU Inspector, Xcode profiler, and Nvidia Visual profilers to collect performance metrics. The study evaluates various popular LLMs (Llama-2, Llama-3, RedPajama, Vicuna, TinyLlama, Qwen2, Mistral-7B, Gemma) with different quantization configurations (2-bit, 3-bit, 4-bit, 5-bit, 6-bit, 8-bit) across multiple mobile platforms including Google Pixel devices, iPhone 12 Pro and 15 Pro, Samsung S22 Ultra, Orange Pi 5, and Nvidia Jetson Orin Nano. Performance metrics include resource utilization, latency, throughput, energy consumption, memory footprint, output matching accuracy, toxicity, and hallucination detection using SQuAD and Natural Questions datasets.

## Key Results
- iPhones outperform other platforms in energy efficiency, latency, and throughput for LLM inference
- 4-bit quantization methods like GPTQ, AWQ, and group-wise quantization preserve model performance while reducing size to one-quarter of original models
- 3-bit quantization shows more performance degradation and increased hallucinations compared to 2-bit and 4-bit methods
- Quantized models generate toxic and hallucinated content, with lower bit quantization levels performing worse

## Why This Works (Mechanism)

### Mechanism 1
- Claim: 4-bit quantization preserves LLM performance while reducing model size to one-quarter
- Mechanism: Quantization methods like GPTQ, AWQ, and group-wise quantization reduce weight precision from 16/32 bits to 4 bits, compressing the model size by 75% while maintaining comparable accuracy through careful preservation of salient weights and activation-aware quantization.
- Core assumption: The quantized weights and activations maintain sufficient information fidelity to preserve model behavior within acceptable error bounds.
- Evidence anchors:
  - [abstract] "4-bit quantization methods like GPTQ, AWQ, and group-wise quantization can preserve model performance while reducing size to one-quarter of original models"
  - [section 4.2] "4-bit and 6-bit quantization mostly maintains performance compared to the original non-quantized model"
  - [corpus] Weak - neighbor papers discuss quantization but don't directly confirm this specific claim
- Break condition: When quantization noise exceeds the model's tolerance threshold, causing significant accuracy degradation or hallucinations

### Mechanism 2
- Claim: iPhones outperform other platforms in energy efficiency, latency, and throughput for LLM inference
- Mechanism: Apple's Metal driver and hardware optimization provide superior GPU utilization and thermal management, enabling more efficient model execution compared to Android's OpenCL and Linux's CUDA implementations.
- Core assumption: Hardware-software co-design and driver maturity directly translate to measurable performance advantages in real-world inference tasks.
- Evidence anchors:
  - [abstract] "iPhones outperform other platforms in energy efficiency, latency, and throughput for LLM inference"
  - [section 4.3] "the iPhones exhibited lower resource utilization than other test platforms" and "iPhone 12 Pro outperforms newer Android devices"
  - [corpus] Weak - neighbor papers discuss mobile deployment but don't provide comparative iOS vs Android performance data
- Break condition: When model complexity exceeds hardware optimization benefits or when thermal throttling occurs

### Mechanism 3
- Claim: Lower-bit quantization increases hallucinations and toxic content generation
- Mechanism: Quantization reduces model precision, which can amplify noise in the probability distributions used for token generation, leading to more frequent generation of erroneous or harmful content.
- Core assumption: Model precision directly correlates with output quality, and quantization noise manifests as hallucinations and toxicity.
- Evidence anchors:
  - [abstract] "3-bit quantization shows more performance degradation and increased hallucinations" and "Quantized models generate toxic and hallucinated content, with 3-bit quantization performing worse"
  - [section 4.7] "Lower bit quantization typically leads to increased hallucinations and toxicity. However, 3-bit quantization performs worse than both 2-bit group-wise quantization and all 4-bit methods"
  - [corpus] Weak - neighbor papers don't discuss hallucination/toxicity effects of quantization
- Break condition: When quantization methods are sufficiently advanced to preserve output quality across bit levels

## Foundational Learning

- Concept: Post-training quantization (PTQ) and its impact on model accuracy
  - Why needed here: The paper's core findings depend on understanding how quantization affects both model size and performance, particularly the trade-off between compression and accuracy.
  - Quick check question: What is the relationship between quantization bit-depth and model accuracy, and at what point does accuracy degradation become unacceptable?

- Concept: GPU acceleration and driver optimization differences across platforms
  - Why needed here: The performance comparisons between iOS, Android, and Linux platforms rely on understanding how different GPU drivers (Metal, OpenCL, CUDA) affect inference efficiency.
  - Quick check question: How do Metal, OpenCL, and CUDA drivers differ in their optimization approaches for mobile/edge GPU inference?

- Concept: Hallucination detection and toxicity measurement in LLM outputs
  - Why needed here: The paper's evaluation of quantized models includes analysis of hallucinations and toxicity, requiring understanding of benchmark datasets and evaluation methodologies.
  - Quick check question: What are the key metrics and datasets used to quantify hallucinations and toxicity in LLM outputs, and how reliable are LLM-as-a-judge approaches?

## Architecture Onboarding

- Component map: Mobile devices (iOS, Android, Ubuntu) -> Profiling tools (Android GPU Inspector, Xcode profiler, Nvidia Visual profiler) -> Inference engines (MLC-LLM, llama.cpp) -> Quantization frameworks (GPTQ, AWQ, group-wise) -> Evaluation metrics (resource utilization, accuracy, toxicity, hallucination)
- Critical path: Model execution → Resource monitoring → Data collection → Analysis → Performance evaluation, with quantization configuration as a key variable
- Design tradeoffs: Memory usage vs. quantization level (higher quantization reduces memory but may increase latency), accuracy vs. compression (lower bits save space but degrade quality), platform compatibility vs. performance optimization (broad support vs. platform-specific efficiency)
- Failure signatures: Memory allocation errors when models exceed device capacity, thermal throttling causing performance degradation, driver incompatibility preventing model execution, inaccurate measurements due to profiling tool limitations
- First 3 experiments:
  1. Run the same model (e.g., Llama-2-7B) across all platforms with identical quantization to establish baseline performance differences
  2. Test multiple quantization levels (2-bit, 3-bit, 4-bit) on a single platform to understand precision trade-offs
  3. Measure resource utilization (CPU/GPU/memory) during inference to identify bottlenecks and optimization opportunities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different quantization methods (e.g., GPTQ, AWQ, group-wise) impact the trade-off between memory usage, latency, and model accuracy on mobile devices?
- Basis in paper: Explicit - The paper discusses various quantization methods (GPTQ, AWQ, group-wise) and their effects on memory usage, latency, and accuracy.
- Why unresolved: While the paper provides some insights into these trade-offs, it doesn't offer a comprehensive comparison of all quantization methods across different models and platforms.
- What evidence would resolve it: A detailed analysis comparing the performance of different quantization methods across multiple models and platforms, measuring memory usage, latency, and accuracy.

### Open Question 2
- Question: What is the optimal quantization bit-width for balancing model performance and resource constraints on mobile devices?
- Basis in paper: Explicit - The paper explores various quantization levels (2-bit, 3-bit, 4-bit, 5-bit, 6-bit) and their impact on model performance and resource usage.
- Why unresolved: The paper doesn't provide a clear recommendation for the optimal quantization level, as the best choice may depend on specific model and platform characteristics.
- What evidence would resolve it: A systematic evaluation of different quantization bit-widths across multiple models and platforms, identifying the optimal balance between performance and resource constraints.

### Open Question 3
- Question: How do quantization methods affect the generation of toxic and hallucinated content in LLMs on mobile devices?
- Basis in paper: Explicit - The paper mentions that quantization can lead to increased hallucinations and toxicity in model outputs.
- Why unresolved: The paper doesn't provide a detailed analysis of how different quantization methods impact the generation of harmful content.
- What evidence would resolve it: A comprehensive study evaluating the frequency and severity of toxic and hallucinated outputs across different quantization methods and models.

## Limitations

- The benchmarking framework's automation relies heavily on platform-specific profiling tools, which may introduce measurement inconsistencies across different operating systems
- The evaluation of hallucinations and toxicity using LLM-as-a-judge approaches may not fully capture the nuanced quality degradation from quantization
- The study focuses primarily on specific model architectures (Llama-family and similar) and quantization methods, potentially limiting generalizability to other LLM families or novel compression techniques

## Confidence

**High Confidence:** The comparative performance analysis between iOS and Android platforms, supported by multiple quantitative metrics (latency, energy efficiency, throughput). The claim that iPhones outperform other platforms is well-supported by systematic measurements across multiple devices.

**Medium Confidence:** The relationship between quantization bit-depth and model accuracy/hallucinations. While the paper shows clear trends, the evaluation methodology for detecting hallucinations and toxicity may have inherent biases, particularly when using LLM-based evaluation.

**Low Confidence:** The generalizability of findings to all mobile platforms and LLM architectures. The study focuses on specific hardware configurations and model families, and the performance characteristics may differ significantly for other platforms or model types.

## Next Checks

1. **Cross-Platform Consistency Validation:** Replicate the benchmarking framework on additional mobile platforms (e.g., Windows on ARM devices, additional Android manufacturers) to verify whether the iPhone performance advantage holds across a broader hardware spectrum. This would involve running identical models and quantization configurations across at least 5-7 different mobile platforms.

2. **Hallucination Detection Validation:** Implement a multi-method hallucination detection approach combining LLM-as-a-judge with human evaluation and fact-checking against knowledge bases. Compare the detection rates and false positive/negative rates across different quantization levels to validate the paper's findings about hallucination increases.

3. **Long-Term Performance Stability Test:** Conduct extended inference sessions (minimum 1 hour) on each platform to measure thermal throttling effects and long-term performance degradation. This would validate whether the reported performance advantages hold under sustained usage conditions rather than short benchmark runs.