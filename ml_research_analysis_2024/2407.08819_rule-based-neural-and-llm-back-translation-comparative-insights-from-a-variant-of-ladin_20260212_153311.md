---
ver: rpa2
title: 'Rule-Based, Neural and LLM Back-Translation: Comparative Insights from a Variant
  of Ladin'
arxiv_id: '2407.08819'
source_url: https://arxiv.org/abs/2407.08819
tags:
- data
- translation
- ladin
- monolingual
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates machine translation for the low-resource
  Ladin language by comparing three back-translation approaches: a fine-tuned neural
  MT model, a rule-based system, and a large language model. Using only 18k parallel
  Ladin-Italian sentence pairs, the authors fine-tune a multilingual NMT model and
  augment it with synthetic data generated by each approach.'
---

# Rule-Based, Neural and LLM Back-Translation: Comparative Insights from a Variant of Ladin

## Quick Facts
- arXiv ID: 2407.08819
- Source URL: https://arxiv.org/abs/2407.08819
- Reference count: 17
- One-line primary result: Back-translation model choice has minimal impact on translation quality in low-resource Ladin, with combined approaches performing best.

## Executive Summary
This paper investigates machine translation for the low-resource Ladin language by comparing three back-translation approaches: a fine-tuned neural MT model, a rule-based system, and a large language model. Using only 18k parallel Ladin-Italian sentence pairs, the authors fine-tune a multilingual NMT model and augment it with synthetic data generated by each approach. Experiments on three distinct test sets show that all methods achieve comparable translation quality, with the best results obtained by combining back-translations from all three approaches. Notably, the LLM-based translations perform best for the Italian-to-Ladin direction, while the rule-based system shows more stable round-trip translations. The findings suggest that in low-resource scenarios, the choice of back-translation model has minimal impact on final translation quality, though each approach exhibits different characteristics in terms of fluency and robustness.

## Method Summary
The authors fine-tune a multilingual NMT model (opus-mt-ine-ine) on 18k Ladin-Italian parallel sentences and generate synthetic training data using three back-translation approaches: a fine-tuned NMT model, a rule-based system, and an LLM. The synthetic data is combined with authentic parallel data to train enhanced models. Evaluation is conducted using BLEU and chrF++ scores on three distinct test sets, along with round-trip translation analysis to assess model robustness.

## Key Results
- All three back-translation approaches (NMT, RBMT, LLM) achieve comparable translation quality in the low-resource Ladin setting.
- Combining back-translations from all three approaches yields the best overall performance.
- LLM-based translations perform best for the Italian-to-Ladin direction, while the rule-based system shows more stable round-trip translations.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Back-translation model choice has minimal impact on final translation quality in low-resource settings.
- Mechanism: All three approaches (fine-tuned NMT, rule-based, LLM) generate synthetic training data that is sufficiently fluent and accurate to improve a fine-tuned base model, despite differences in fluency and robustness.
- Core assumption: Synthetic data quality differences are small enough that the fine-tuned model can adapt equally well to any source.
- Evidence anchors:
  - [abstract] "all approaches achieve comparable translation quality in this low-resource scenario"
  - [section] "all approaches achieve comparable translation quality in this low-resource scenario, yet round-trip translations highlight differences in model performance"
  - [corpus] Weak evidence; related work focuses on high-resource or different tasks.
- Break condition: If synthetic data quality variance exceeds model adaptation capacity, performance differences would emerge.

### Mechanism 2
- Claim: Iterative back-translation with multiple paradigms broadens synthetic data diversity, improving robustness.
- Mechanism: Combining back-translations from NMT, RBMT, and LLM introduces varied linguistic patterns and structures, enriching the training corpus beyond what any single paradigm could provide.
- Core assumption: Model improvements come from diversity of synthetic examples, not just quantity.
- Evidence anchors:
  - [section] "all approaches achieve comparable translation quality in this low-resource scenario"
  - [section] "combining the different back-translations, as modelA2 results indicate"
  - [corpus] Weak evidence; related work does not directly address multi-paradigm back-translation.
- Break condition: If diversity gains plateau, further combinations yield diminishing returns.

### Mechanism 3
- Claim: LLM-generated translations improve fluency without sacrificing accuracy in low-resource settings.
- Mechanism: LLM's strong fluency generation compensates for limited data, providing high-quality synthetic sentences that improve target-side fluency in fine-tuned models.
- Core assumption: LLM fluency transfer outweighs potential hallucination risks in low-resource scenarios.
- Evidence anchors:
  - [abstract] "LLM-based translations perform best for the Italian-to-Ladin direction"
  - [section] "LLM-based translations perform best for the Italian-to-Ladin direction, while the rule-based system shows more stable round-trip translations"
  - [corpus] Weak evidence; related work does not directly compare LLM fluency in back-translation.
- Break condition: If hallucination errors become significant, accuracy may degrade despite fluency gains.

## Foundational Learning

- Concept: Back-translation as data augmentation
  - Why needed here: Understanding how synthetic data improves low-resource NMT performance.
  - Quick check question: Why is back-translation particularly useful when parallel data is scarce?
- Concept: Multilingual model fine-tuning
  - Why needed here: Base model (opus-mt-ine-ine) is multilingual; fine-tuning adapts it to specific language pair.
  - Quick check question: How does fine-tuning a multilingual model differ from training from scratch on a low-resource pair?
- Concept: Round-trip translation evaluation
  - Why needed here: Provides insight into model robustness beyond standard BLEU/chrF++ metrics.
  - Quick check question: What does a large gap between forward and backward round-trip scores indicate?

## Architecture Onboarding

- Component map: Monolingual Ladin → back-translation (NMT/RBMT/LLM) → synthetic Italian → fine-tuned NMT model
- Critical path: Monolingual data collection → back-translation generation → model fine-tuning → evaluation
- Design tradeoffs:
  - Back-translation model choice vs. synthetic data quality
  - Iterative back-translation vs. training time/compute cost
  - LLM prompt engineering vs. automation efficiency
- Failure signatures:
  - Low BLEU scores across all models → data quality or model capacity issue
  - High perplexity but high BLEU → fluency vs. adequacy mismatch
  - Round-trip scores much lower than forward scores → robustness problems
- First 3 experiments:
  1. Compare N1 (fine-tuned on authentic only) vs. BM (base model) to verify data quality.
  2. Generate N2, R2, L2 and compare performance to assess back-translation model impact.
  3. Train A1 (combined back-translations) and compare to individual back-translation models to test diversity benefit.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the performance of the Ladin translation models change if the LLM-generated translations were filtered to remove hallucinated or incorrect outputs before training?
- Basis in paper: [inferred] The paper mentions that the LLM tends to generate more fluent but potentially less accurate translations, especially for Testset 3, and suggests that filtering synthetic data could improve results.
- Why unresolved: The authors did not implement any filtering of the LLM-generated translations, so the impact of this filtering on model performance remains unknown.
- What evidence would resolve it: Training models with filtered vs. unfiltered LLM-generated data and comparing their performance on the three test sets would provide empirical evidence of the impact of data filtering.

### Open Question 2
- Question: What is the specific impact of providing example translations in the prompt on the quality of LLM-generated Ladin-to-Italian translations?
- Basis in paper: [explicit] The authors note that providing 8 example translations in JSON format reduced the failure rate but are unsure to what extent these examples helped with the translation itself.
- Why unresolved: The authors did not conduct experiments to isolate the effect of the example translations from other factors in the prompting process.
- What evidence would resolve it: Comparing the quality of LLM translations generated with and without example translations in the prompt, while keeping other prompt elements constant, would quantify the impact of examples.

### Open Question 3
- Question: How would incorporating morphological disambiguation modules into the rule-based system affect the quality of back-translations and the resulting NMT models?
- Basis in paper: [inferred] The paper mentions that the rule-based system currently selects the first suggestion in cases of morphological and lexical ambiguity, which can sometimes result in incorrect choices.
- Why unresolved: The authors did not implement disambiguation modules in their rule-based system, so the potential improvement from such modules remains unexplored.
- What evidence would resolve it: Implementing morphological disambiguation in the rule-based system and comparing the quality of back-translations and resulting NMT models with the current system would demonstrate the impact of disambiguation.

### Open Question 4
- Question: What is the optimal balance between the three back-translation approaches (NMT, RBMT, and LLM) when combining them to create synthetic training data?
- Basis in paper: [explicit] The authors found that combining back-translations from all three approaches yielded the best results, but they did not explore the optimal weighting or ratio of each method.
- Why unresolved: The authors combined equal amounts of data from each approach without investigating whether different proportions might yield better results.
- What evidence would resolve it: Systematically varying the proportion of each back-translation method in the training data and measuring the resulting model performance would identify the optimal balance.

### Open Question 5
- Question: How would the performance of the Ladin translation models differ if forward translations (Italian to Ladin) were filtered to remove noisy or inaccurate outputs before training?
- Basis in paper: [inferred] The authors note that including forward translations did not consistently improve models, suggesting these synthesized texts introduce too much noise, and suggest filtering this data could slightly improve the model.
- Why unresolved: The authors did not implement any filtering of the forward translations, so the impact of this filtering on model performance remains unknown.
- What evidence would resolve it: Training models with filtered vs. unfiltered forward translations and comparing their performance on the three test sets would provide empirical evidence of the impact of data filtering.

## Limitations
- The study focuses on a single low-resource language pair (Ladin-Italian) with only 18k parallel sentences, limiting generalizability.
- LLM prompting details are not fully specified, making replication challenging.
- Evaluation relies primarily on automatic metrics without extensive human assessment of translation quality or hallucination detection.

## Confidence

**High confidence**: The finding that combining back-translations from all three approaches yields the best results, supported by multiple experimental conditions and clear performance improvements.

**Medium confidence**: The claim that LLM-generated translations perform best for Italian-to-Ladin direction, as this is based on a single experimental condition and may be influenced by specific test set characteristics.

**Low confidence**: The generalizability of minimal impact from back-translation model choice across different low-resource scenarios, given the limited data size and single language pair focus.

## Next Checks

1. **Replication across language pairs**: Test the same three back-translation approaches on another low-resource language pair (e.g., Nepali-English or Occitan-French) to assess generalizability of the minimal impact finding.

2. **Human evaluation protocol**: Conduct detailed human assessment of translation fluency, adequacy, and hallucination rates across NMT, RBMT, and LLM-generated synthetic data to complement automatic metrics.

3. **Data size sensitivity analysis**: Systematically vary the amount of monolingual data used for back-translation (e.g., 10k, 50k, 100k sentences) to identify when back-translation model differences become significant.