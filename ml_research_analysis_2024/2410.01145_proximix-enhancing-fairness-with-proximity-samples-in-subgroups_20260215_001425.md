---
ver: rpa2
title: 'ProxiMix: Enhancing Fairness with Proximity Samples in Subgroups'
arxiv_id: '2410.01145'
source_url: https://arxiv.org/abs/2410.01145
tags:
- fairness
- dataset
- samples
- mixup
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses bias retention in mixup-based data augmentation
  for fairness in machine learning. The authors propose ProxiMix, a method that generates
  fairer synthetic samples by considering proximity-aware label relationships alongside
  pairwise mixup.
---

# ProxiMix: Enhancing Fairness with Proximity Samples in Subgroups

## Quick Facts
- arXiv ID: 2410.01145
- Source URL: https://arxiv.org/abs/2410.01145
- Reference count: 40
- ProxiMix significantly improves fairness metrics while maintaining prediction performance

## Executive Summary
ProxiMix addresses bias retention in mixup-based data augmentation by incorporating proximity-aware label relationships alongside traditional pairwise mixup. The method generates fairer synthetic samples by considering labels from nearby samples in feature space, reducing reliance on potentially biased pairwise labels. Experiments across three datasets (Adult, Law School, Credit Default) and three models (Logistic Regression, Decision Tree, MLP) demonstrate significant improvements in fairness metrics like Demographic Parity and Equalized Odds compared to standard mixup, while maintaining competitive prediction performance.

## Method Summary
ProxiMix extends the mixup data augmentation technique by incorporating proximity-aware labeling. The method generates synthetic samples by combining traditional mixup labels with labels from nearby samples in feature space, weighted by a balancing parameter d. This approach reduces bias retention by considering the labels of proximity samples as latent label relationships rather than relying solely on pairwise labels. The algorithm samples from different subgroup combinations (Ci ⊙ Cj) and generates synthetic samples with labels that interpolate between mixup-based and proximity-based labeling. The balancing parameter d allows fine-tuned control over the tradeoff between fairness improvements and prediction performance.

## Key Results
- ProxiMix improves fairness metrics (DP and Eodds) by up to 20% compared to standard mixup
- Optimal balancing degree d varies by dataset: d=0.7 for Credit dataset, d=0.2 for Adult dataset
- ProxiMix maintains competitive prediction performance while improving fairness across all tested models

## Why This Works (Mechanism)

### Mechanism 1
Proximity-aware label generation reduces bias retention in synthetic samples. ProxiMix incorporates labels from proximity samples when generating synthetic data, reducing reliance on potentially biased pairwise labels. The core assumption is that labels of nearby samples are more representative of true relationships than the original biased dataset labels.

### Mechanism 2
Balancing parameter d controls tradeoff between mixup and proximity-based labeling. The d parameter allows interpolation between traditional mixup (d=1) and purely proximity-based labeling (d=0), enabling fine-tuned control over fairness-performance tradeoff. Different values of d are optimal for different sampling strategies and datasets.

### Mechanism 3
Sampling strategy selection impacts fairness improvements. Different combinations of subgroup sampling (Ci ⊙ Cj) yield varying levels of fairness improvement depending on which subgroups are underrepresented. Focusing on underrepresented labels in unprivileged groups when generating samples improves fairness.

## Foundational Learning

- Concept: Mixup data augmentation technique
  - Why needed here: ProxiMix builds directly on mixup by extending it with proximity-aware labeling
  - Quick check question: What is the mathematical formulation of the mixup technique for generating synthetic samples?

- Concept: Fairness metrics (Demographic Parity, Equalized Odds)
  - Why needed here: These metrics are used to evaluate ProxiMix's effectiveness in reducing bias across subgroups
  - Quick check question: How do Demographic Parity and Equalized Odds differ in what aspects of model fairness they measure?

- Concept: Counterfactual explanations and recourse fairness
  - Why needed here: The paper validates ProxiMix's effectiveness from an XAI perspective by examining counterfactual cost across subgroups
  - Quick check question: What does it mean for a model to have "fair recourse" across different demographic groups?

## Architecture Onboarding

- Component map: Proximity sample identification -> Label counting mechanism -> Balancing parameter d interpolation -> Integration with mixup framework -> Model training pipeline

- Critical path: 1) Sample selection from subgroups (Ci ⊙ Cj) 2) Proximity sample identification for S0 3) Label counting in proximity set 4) Lambda-based label generation (Yλ) 5) Proximity-based label generation (Ysim) 6) Final label interpolation using d 7) Synthetic sample creation 8) Model training with augmented data

- Design tradeoffs: Higher proximity sample counts improve label representativeness but increase computation time; larger d values maintain better prediction performance but reduce fairness gains; different Ci ⊙ Cj strategies work better for different datasets and models

- Failure signatures: Fairness metrics not improving despite proximity-based sampling; model performance degrading significantly with proximity-based labels; inconsistent results across different runs with same parameters

- First 3 experiments: 1) Baseline comparison: Run ProxiMix with d=1 (pure mixup) to establish baseline performance 2) Single strategy test: Implement one Ci ⊙ Cj strategy with varying d values (0, 0.2, 0.5, 0.8, 1) to observe fairness-performance tradeoff 3) Cross-dataset validation: Test the optimal d value from experiment 2 on a different dataset to check generalizability

## Open Questions the Paper Calls Out

- What is the optimal balancing degree d for different dataset and subgroup combinations in ProxiMix? The paper found that different sampling strategies require different optimal d values (e.g., d=0.7 for Credit dataset's C1⊙C1' strategy, d=0.2 for C3⊙C3', and d=0.2 for Adult dataset's C4⊙C3' strategy).

- How does ProxiMix perform with multi-class classification tasks and intersectional fairness considerations? The authors state "In future work, we plan to extent ProxiMix to multi-class tasks and consider intersectional fairness" in the conclusion.

- What is the computational efficiency trade-off of ProxiMix compared to standard mixup methods? The paper mentions "To enhance computational efficiency, we find ProxiSet first in practice" and describes a 'furthest-first' rule for selecting proximity samples, suggesting ProxiMix is more computationally intensive than standard mixup.

## Limitations

- The optimal balancing parameter d appears dataset-specific, suggesting limited generalizability without extensive parameter tuning
- Reliance on Euclidean distance for proximity calculations may not capture complex feature relationships in high-dimensional spaces
- The paper lacks theoretical guarantees about convergence or bounds on fairness improvements

## Confidence

**High Confidence Claims:**
- ProxiMix improves fairness metrics (DP and Eodds) compared to standard mixup
- Different Ci ⊙ Cj sampling strategies yield varying fairness improvements
- The balancing parameter d effectively controls the fairness-performance tradeoff

**Medium Confidence Claims:**
- The specific optimal d values (0.7 for Credit, 0.2 for Adult) generalize across models
- Proximity-aware labeling consistently reduces bias retention
- Counterfactual explanation fairness improvements are statistically significant

**Low Confidence Claims:**
- The 10-sample proximity threshold is optimal for all datasets
- Euclidean distance is the best proximity metric for all feature spaces
- The observed fairness improvements will persist with larger, more diverse datasets

## Next Checks

1. Test ProxiMix with alternative proximity metrics (cosine similarity, Mahalanobis distance) to verify that Euclidean distance is not a limiting factor for the observed improvements.

2. Conduct experiments varying the proximity sample threshold from 5 to 50 samples to determine if the reported improvements are robust to this parameter choice.

3. Apply the optimal d values from Adult and Credit datasets to a third, distinct dataset (e.g., COMPAS) to evaluate whether the dataset-specific parameter tuning is a fundamental limitation or can be mitigated through transfer learning approaches.