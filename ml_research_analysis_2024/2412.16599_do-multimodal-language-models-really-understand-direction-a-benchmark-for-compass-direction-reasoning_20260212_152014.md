---
ver: rpa2
title: Do Multimodal Language Models Really Understand Direction? A Benchmark for
  Compass Direction Reasoning
arxiv_id: '2412.16599'
source_url: https://arxiv.org/abs/2412.16599
tags:
- reasoning
- direction
- compass
- spatial
- relative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a benchmark dataset (CDR) to evaluate compass
  direction reasoning in multimodal language models (MLMs), addressing the underexplored
  gap between spatial and compass direction understanding. The dataset includes three
  types of images (icons, letters, numbers) with 100K+ samples covering both spatial
  (up, down, left, right) and compass (north, south, east, west) directions.
---

# Do Multimodal Language Models Really Understand Direction? A Benchmark for Compass Direction Reasoning

## Quick Facts
- arXiv ID: 2412.16599
- Source URL: https://arxiv.org/abs/2412.16599
- Authors: Hang Yin; Zhifeng Lin; Xin Liu; Bin Sun; Kan Li
- Reference count: 28
- Primary result: Most MLMs perform near random guessing (12.5%) on compass reasoning tasks

## Executive Summary
This paper addresses a critical gap in multimodal language model evaluation by introducing the Compass Direction Reasoning (CDR) benchmark. While MLMs excel at spatial reasoning tasks (identifying up, down, left, right), they struggle significantly with compass directions (north, south, east, west). The authors created a dataset with 100K+ samples using icons, letters, and numbers to evaluate both spatial and compass reasoning capabilities. The benchmark reveals that most models perform at random guessing levels on compass tasks, highlighting a fundamental limitation in their understanding of real-world directional relationships.

## Method Summary
The authors developed a benchmark dataset (CDR) containing 100K+ image-question pairs across three image types: icons, letters, and numbers. They evaluated multiple MLMs including LLaVA-7B, GPT-4o-mini, and others on both spatial (up/down/left/right) and compass (north/south/east/west) direction reasoning tasks. The study compared absolute direction reasoning (identifying fixed directions) versus relative direction reasoning (determining relationships between objects). To improve performance, they explored fine-tuning approaches including mixed data training with out-of-domain datasets and Chain-of-Thought (CoT) methods that provide step-by-step reasoning instructions.

## Key Results
- MLMs achieve only 12.5% accuracy on compass direction reasoning tasks, equivalent to random guessing
- Performance on relative compass reasoning (11.79%) is significantly worse than spatial tasks (45.23%)
- Fine-tuning LLaVA-7B with mixed data and CoT approaches improves relative compass reasoning to 53.43%
- Most models show egocentric bias, interpreting directions from their own perspective rather than the image's orientation

## Why This Works (Mechanism)

### Mechanism 1
MLMs fail at compass direction reasoning because they cannot map spatial relationships to real-world orientation rules. The models struggle with the abstract nature of compass directions, which require understanding geographical orientation principles beyond simple spatial relationships. This limitation stems from the fundamental challenge of connecting image-based spatial reasoning to real-world directional concepts.

### Mechanism 2
Chain-of-Thought fine-tuning improves performance by explicitly teaching the relationship between spatial and compass reasoning through step-by-step instructions. The CoT approach helps models understand that compass directions are fixed relative to the world, while spatial directions are relative to the image. This explicit reasoning framework enables better generalization from spatial to compass reasoning tasks.

### Mechanism 3
Mixed data fine-tuning enhances generalization by introducing complexity and variation through out-of-domain datasets. The addition of diverse training data prompts models to refine their direction inference capabilities and better understand the nuances between different types of directional reasoning. An optimal mix ratio of approximately 2:1 (in-domain to out-of-domain) was found to maximize performance.

## Foundational Learning

- **Spatial reasoning as foundation for compass reasoning**: Understanding how basic spatial relationships serve as the building blocks for more complex compass direction understanding is crucial for evaluating MLMs' directional capabilities. Quick check: Can you explain how spatial reasoning relates to compass reasoning in the context of MLMs?

- **Real-world physical rules and orientation principles**: MLMs need to understand geographical orientation principles and how compass directions relate to the real world to accurately reason about directional relationships. Quick check: What are some real-world physical rules and orientation principles that MLMs should understand for compass reasoning?

- **Step-by-step reasoning and Chain-of-Thought methods**: CoT methods help MLMs understand complex reasoning tasks by providing explicit reasoning steps, which is essential for bridging the gap between spatial and compass direction reasoning. Quick check: How does step-by-step reasoning help MLMs improve their compass direction reasoning abilities?

## Architecture Onboarding

- **Component map**: Image + Question -> MML -> Direction Reasoning Answer; Object Classification -> Spatial Direction Reasoning -> Compass Direction Reasoning -> Relative Direction Reasoning

- **Critical path**: 1) Image preprocessing and object detection, 2) Question understanding and parsing, 3) Direction reasoning based on spatial and compass rules, 4) Answer generation

- **Design tradeoffs**: Simplicity vs. complexity (simple images for fair evaluation vs. complex real-world images for comprehensive testing); Generalization vs. specificity (balanced directional distributions vs. task-specific data)

- **Failure signatures**: Random guessing levels (12.5%) on compass reasoning tasks; Significant performance drop on relative compass reasoning compared to spatial tasks; Limited improvement with direct fine-tuning on CDR data

- **First 3 experiments**: 1) Evaluate MLMs on object classification and absolute direction reasoning tasks, 2) Fine-tune LLaVA-7B on CDR data and evaluate performance on relative compass reasoning, 3) Explore impact of mixdata and CoT fine-tuning methods on MLM performance

## Open Questions the Paper Calls Out

### Open Question 1
How do MLMs generalize compass direction reasoning to real-world scenarios beyond the controlled CDR benchmark? The paper uses simplified, low-ambiguity images which may not capture the complexity of real-world scenarios. Testing MLMs on naturalistic images like maps and street views would provide evidence for generalization capabilities.

### Open Question 2
What is the impact of varying the mix ratio of mixed data on the model's performance in compass direction reasoning? While the paper found an optimal ratio of approximately 2:1, further exploration with different ratios could reveal more about the relationship between data diversity and model performance.

### Open Question 3
How does the performance of MLMs on compass direction reasoning compare to humans in terms of accuracy and reasoning steps? While the paper highlights the accuracy gap (100% for humans vs. 12.5% for models), a detailed comparison of reasoning approaches would help understand the fundamental differences in how humans and MLMs solve these tasks.

## Limitations
- Performance ceiling of 53.43% accuracy even after advanced fine-tuning suggests fundamental limitations in current MLM architectures
- CDR benchmark uses simplified synthetic images that may not capture the complexity of real-world directional reasoning scenarios
- The study focuses on specific image types (icons, letters, numbers) which may not represent the full range of real-world objects and contexts

## Confidence

| Claim | Confidence |
|-------|------------|
| MLMs perform near random guessing on compass tasks | High |
| CoT fine-tuning improves performance substantially | Medium |
| Generalizability to real-world scenarios | Low |

## Next Checks

1. Test trained models on real-world images with natural objects and backgrounds to assess whether performance improvements transfer beyond synthetic data

2. Evaluate the impact of incorporating explicit geographical orientation rules and training data on compass reasoning performance

3. Investigate whether larger model architectures or different fine-tuning strategies can achieve better than 53.43% accuracy on relative compass reasoning tasks