---
ver: rpa2
title: Incremental Learning of Affordances using Markov Logic Networks
arxiv_id: '2410.17624'
source_url: https://arxiv.org/abs/2410.17624
tags:
- knowledge
- evidence
- learning
- formula
- formulas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MLN-CLA enables robots to incrementally learn new object affordances
  by retaining existing knowledge and only updating changed knowledge. The method
  clusters formulas by domain co-occurrence and employs knowledge updating strategies
  to prevent catastrophic forgetting.
---

# Incremental Learning of Affordances using Markov Logic Networks

## Quick Facts
- arXiv ID: 2410.17624
- Source URL: https://arxiv.org/abs/2410.17624
- Reference count: 3
- Primary result: MLN-CLA achieves 0.92 AUC on zero-shot affordance inference, outperforming batch-trained MLN baselines

## Executive Summary
This paper introduces MLN-CLA, a method for incremental learning of object affordances using Markov Logic Networks (MLNs) that addresses catastrophic forgetting. The approach clusters formulas by domain co-occurrence and employs three knowledge updating strategies (CL-Naive, CL-Conservative, CL-Balanced) to selectively update changed knowledge while retaining existing knowledge. In experiments, MLN-CLA demonstrates superior performance on zero-shot affordance inference tasks, with CL-Balanced showing best overall performance in constant learning scenarios and CL-Conservative excelling in formula learning.

## Method Summary
MLN-CLA enables robots to incrementally learn new object affordances by retaining existing knowledge and only updating changed knowledge. The method clusters formulas by domain co-occurrence and employs knowledge updating strategies to prevent catastrophic forgetting. New evidence arrives incrementally, and only affected Knowledge Categories are converted to MLNs for weight updates, then merged back using conflict resolution policies. The framework supports learning both new constants (objects) and new formulas, with three strategies available for handling weight conflicts during knowledge merging.

## Key Results
- MLN-CLA achieved 0.92 AUC on zero-shot affordance inference tasks
- Outperformed batch-trained MLN baselines across all experimental conditions
- CL-Balanced strategy showed best overall performance in constant learning scenarios
- CL-Conservative excelled in formula learning while CL-Naive provided fastest adaptation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CL-Balanced strategy acts as a regularizer preventing overfitting to recent evidence
- Mechanism: Computes weighted average of old and new formula weights based on evidence counts, smoothing weight updates over time
- Core assumption: Formula weights from different evidence sets represent complementary knowledge that should be merged
- Evidence anchors: [abstract] CL-Balanced showed best performance; [section] hypothesises regularizing effect
- Break condition: Unbalanced evidence counts diminish regularization effect

### Mechanism 2
- Claim: Domain-based clustering enables efficient incremental updates
- Mechanism: Groups formulas sharing domain sets, updating only affected categories to reduce computational overhead
- Core assumption: Related knowledge sharing domain sets can be updated together without affecting unrelated clusters
- Evidence anchors: [section] Domain set equality enables category merging; [corpus] Moderate evidence for clustering effectiveness
- Break condition: Significant domain relationship changes require category restructuring

### Mechanism 3
- Claim: Knowledge updating strategies resolve formula weight conflicts using evidence-based policies
- Mechanism: CL-Naive overwrites, CL-Conservative updates only with higher evidence count, CL-Balanced computes weighted averages
- Core assumption: Conflicting weights represent different evidence sets that can be combined meaningfully
- Evidence anchors: [section] Conflict resolution assumes different evidence sets; [corpus] Weak evidence for strategy validation
- Break condition: Varying evidence quality makes count-based policies suboptimal

## Foundational Learning

- Concept: First-Order Logic (FOL) and Markov Logic Networks
  - Why needed here: MLNs extend FOL by adding probabilistic weights to formulas, enabling soft constraints for uncertain reasoning about object affordances
  - Quick check question: How does a Markov Logic Network differ from pure First-Order Logic in handling contradictory information?

- Concept: Catastrophic Forgetting in Incremental Learning
  - Why needed here: The paper addresses the challenge that new evidence can overwrite essential existing knowledge, degrading performance on previously learned tasks
  - Quick check question: What mechanism does MLN-CLA use to prevent overwriting important old knowledge when incorporating new evidence?

- Concept: Knowledge Base Management and Clustering
  - Why needed here: MLN-CLA introduces Knowledge Lists and Categories to organize and efficiently update related formulas, essential for selective retraining
  - Quick check question: How are Knowledge Categories determined, and why is this clustering approach beneficial for incremental learning?

## Architecture Onboarding

- Component map:
  Knowledge List -> Knowledge Categories -> MLN Models -> Evidence Databases -> Knowledge Updating Strategies

- Critical path:
  1. New evidence arrives (MLN, database, or both)
  2. Compare against existing Knowledge List to identify unknown elements
  3. Assign formulas to appropriate Knowledge Categories
  4. Convert affected categories to MLNs for weight updates
  5. Merge updated MLNs back into Knowledge List
  6. Apply knowledge updating strategy to resolve conflicts
  7. Update Knowledge List with merged knowledge

- Design tradeoffs:
  - Category granularity vs. update efficiency: Finer categories enable more targeted updates but increase management overhead
  - Strategy aggressiveness vs. stability: Aggressive strategies adapt quickly but risk forgetting, while conservative ones preserve knowledge but adapt slowly
  - Domain-based vs. predicate-based clustering: Domain clustering enables category merging but may group unrelated formulas with shared domains

- Failure signatures:
  - Performance degradation over time: May indicate inadequate conflict resolution or category restructuring needs
  - Category explosion: Too many small categories reduce update efficiency
  - Weight oscillation: Formulas repeatedly flipping between values suggest unstable learning dynamics

- First 3 experiments:
  1. Test constant learning: Feed new objects incrementally while keeping formulas fixed, measure AUC improvement over batch baselines
  2. Test formula learning: Introduce new formulas one at a time, evaluate zero-shot inference performance on unseen predicates
  3. Strategy comparison: Run identical learning scenarios with each updating strategy, analyze trade-offs between adaptation speed and knowledge preservation

## Open Questions the Paper Calls Out

- Open Question 1: How does varying batch sizes of new evidence per time step affect the performance and system stability of MLN-CLA?
  - Basis: Authors mention current implementation doesn't vary batch sizes and suggest further investigation
  - Why unresolved: No experimental results or analysis on batch size impact provided
  - What evidence would resolve it: Experiments comparing performance and stability across different batch sizes

- Open Question 2: How would replacing Alchemy's default learning algorithms with Online Structure Learning (OSL) affect MLN-CLA's performance?
  - Basis: Authors suggest replacing Alchemy's algorithms with OSL to improve learning performance
  - Why unresolved: Uses default algorithms and only hypothesizes about OSL improvements
  - What evidence would resolve it: Comparative experiments between default algorithms versus OSL for weight and structure learning

- Open Question 3: What other knowledge updating strategies beyond CL-Naive, CL-Conservative, and CL-Balanced could be effective for MLN-CLA?
  - Basis: Authors state other strategies are possible and invite further research
  - Why unresolved: Only explores three specific strategies without investigating the full space
  - What evidence would resolve it: Development and testing of new strategies comparing performance across scenarios

## Limitations

- Implementation details for Alchemy software and MLN configuration parameters are not fully specified, affecting reproducibility
- Effectiveness of domain-based clustering for MLNs has only moderate corpus support, lacking comprehensive validation
- Conflict resolution strategies lack detailed studies on performance beyond tested scenarios

## Confidence

- High confidence: Core incremental learning framework and basic architecture design
- Medium confidence: Effectiveness of knowledge updating strategies (CL-Balanced performance supported by experimental results)
- Low confidence: Generalization of domain clustering benefits and conflict resolution mechanisms beyond tested scenarios

## Next Checks

1. Implement ablation studies removing the domain clustering mechanism to quantify its contribution to performance gains
2. Test knowledge updating strategies with synthetic evidence of varying quality (not just quantity) to evaluate robustness
3. Evaluate the framework on a different robotics affordance dataset to assess generalizability beyond the presented experimental setup