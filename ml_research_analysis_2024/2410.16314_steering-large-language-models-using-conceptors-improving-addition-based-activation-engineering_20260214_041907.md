---
ver: rpa2
title: 'Steering Large Language Models using Conceptors: Improving Addition-Based
  Activation Engineering'
arxiv_id: '2410.16314'
source_url: https://arxiv.org/abs/2410.16314
tags:
- steering
- layer
- activation
- conceptor
- beta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces conceptors as a novel method for steering
  large language models (LLMs) by projecting activation vectors using ellipsoidal
  regions instead of simple vector addition. Unlike traditional additive steering
  that translates activations with a fixed steering vector, conceptors capture complex
  activation patterns through soft projection matrices computed from sets of activation
  vectors.
---

# Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering

## Quick Facts
- arXiv ID: 2410.16314
- Source URL: https://arxiv.org/abs/2410.16314
- Authors: Joris Postmus; Steven Abreu
- Reference count: 40
- Primary result: Conceptors outperform additive steering by capturing complex activation patterns through ellipsoidal projections rather than simple vector translation

## Executive Summary
This paper introduces conceptors as a novel method for steering large language models by projecting activation vectors using ellipsoidal regions instead of simple vector addition. Unlike traditional additive steering that translates activations with a fixed steering vector, conceptors capture complex activation patterns through soft projection matrices computed from sets of activation vectors. Experiments on GPT-J and GPT-NeoX models show that conceptor-based steering outperforms traditional additive methods across multiple function tasks, achieving higher accuracy. Furthermore, combining conceptors using Boolean operations for composite functions outperforms additively combining steering vectors.

## Method Summary
The paper proposes conceptor-based steering for large language models, where conceptors are computed as closed-form matrices from activation vectors of in-context learning examples. The conceptor matrix is calculated using the formula C = R(R + α^(-2)I)^(-1), where R is the correlation matrix of activations and α is an aperture parameter. Steering is applied through matrix-vector multiplication (h' = βc*C*h) rather than simple addition. The method is compared against traditional additive steering (h' = βadd*hf + h) on function tasks like antonyms, capitalize, and country-capital, with experiments conducted on GPT-J 6B and GPT-NeoX 20B models. Boolean operations (AND, OR) are also explored for combining multiple steering goals.

## Key Results
- Conceptor-based steering outperforms additive steering across multiple function tasks on both GPT-J and GPT-NeoX models
- Boolean operations on conceptors (AND operation) for composite functions empirically outperform additively combining steering vectors
- Mean-centering technique improves steering effectiveness by reducing activation space bias
- Optimal steering performance occurs at different layers for different models (layers 9-16 for GPT-J, layers 10-30 for GPT-NeoX)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conceptors outperform additive steering by capturing complex activation patterns through ellipsoidal projections rather than simple vector translation.
- Mechanism: Conceptors compute a soft projection matrix from sets of activation vectors, encoding correlations between activations. This matrix projects new activations toward the pattern represented by the principal directions of the original activation cloud, scaling components according to their importance in the pattern.
- Core assumption: The activation space of complex functions can be better represented as a region (ellipsoid) rather than a single point (steering vector).
- Evidence anchors:
  - [abstract] "Conceptors act as soft projection matrices and offer more precise control over complex activation patterns."
  - [section] "Conceptors can better capture the activation space of complex patterns compared to simple point representations, which discard information about correlations."
  - [corpus] Weak evidence - no directly comparable conceptor steering studies found.
- Break condition: If the activation patterns are simple linear transformations that can be adequately captured by a single vector, the additional complexity of conceptors provides no advantage.

### Mechanism 2
- Claim: Boolean operations on conceptors enable more effective composite function steering than arithmetic mean of steering vectors.
- Mechanism: The OR operation merges covariance matrices from different conceptors, creating a new conceptor that represents the union of activation patterns. The AND operation (via De Morgan's law) finds the intersection of activation patterns, allowing steering toward multiple functions simultaneously.
- Core assumption: Combining steering goals through Boolean operations on conceptors preserves the structural relationships between activation patterns better than simple vector addition.
- Evidence anchors:
  - [section] "We can combine multiple steering matrices using the conceptor Boolean operations... C1 ∧ C2 is computed using the correlation matrix (R−1 1 + R−1 2 )−1."
  - [abstract] "We further use Boolean operations on conceptors for combined steering goals that empirically outperform additively combining steering vectors on a set of tasks."
  - [corpus] Weak evidence - no comparable Boolean operation studies found in corpus.
- Break condition: If the target functions have conflicting activation patterns that cannot be meaningfully combined, Boolean operations may produce degraded performance.

### Mechanism 3
- Claim: Mean-centering improves steering effectiveness by removing activation space bias that dilutes task-specific signals.
- Mechanism: Subtracting the mean activation vector (computed over a broad dataset) from steering vectors/conceptors reduces the inherent anisotropy in LLM activation spaces, making the steering signal more focused on task-specific behavior.
- Core assumption: LLM activation vectors are systematically offset from the origin in a consistent direction that doesn't encode task-specific information.
- Evidence anchors:
  - [section] "Mean-centering attempts to mitigate this by subtracting the mean activation of a broader dataset that represents the general activation space of the model."
  - [section] "Mean-centering improves the performance of additive steering by as much as 2x (on the country-capital task)."
  - [corpus] Weak evidence - no directly comparable mean-centering studies found.
- Break condition: If the mean activation vector is itself influenced by task-specific patterns, mean-centering could remove useful signal.

## Foundational Learning

- Concept: Matrix-vector multiplication as soft projection
  - Why needed here: Conceptor steering fundamentally operates through matrix-vector multiplication, which projects activations onto ellipsoidal regions rather than translating them.
  - Quick check question: Given a conceptor matrix C and activation vector x, what operation produces the steered activation?

- Concept: Eigenvalues and regularization in matrix inversion
  - Why needed here: The conceptor matrix computation involves eigenvalue decomposition and regularization through the aperture parameter α, which controls the trade-off between pattern representation and generalization.
  - Quick check question: How does the aperture parameter α affect the eigenvalues of the conceptor matrix?

- Concept: Boolean algebra on matrices
  - Why needed here: Combining conceptors for composite functions requires understanding Boolean operations (AND, OR, NOT) as defined on positive semi-definite matrices.
  - Quick check question: What matrix operation corresponds to the conceptor AND operation?

## Architecture Onboarding

- Component map: GPT-J/GPT-NeoX residual stream -> conceptor computation (offline) -> matrix-vector multiplication during inference -> output generation
- Critical path: Activation caching -> conceptor matrix computation -> parameter tuning -> inference-time steering
- Design tradeoffs: Conceptors provide better pattern capture but require O(n³) computation for n-dimensional activations; mean-centering adds preprocessing but improves accuracy
- Failure signatures: Steering degrades if aperture parameter is poorly chosen, if training data for mean-centering is unrepresentative, or if conceptor operations produce ill-conditioned matrices
- First 3 experiments:
  1. Implement basic conceptor steering on a single function (antonyms) without mean-centering to verify matrix computation and steering effectiveness
  2. Add mean-centering to the conceptor steering and compare performance gains
  3. Implement AND operation on two conceptors for a composite function and validate against baseline additive steering

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does conceptor steering scale to larger language models beyond 20 billion parameters, and does it maintain its performance advantage over additive steering?
- Basis in paper: [explicit] The paper concludes that "further research should be conducted to assess... the scalability to larger models."
- Why unresolved: The experiments only tested GPT-J (6B) and GPT-NeoX (20B) models, leaving the performance on larger models like GPT-3 (175B) or LLaMA-2 (70B) unknown.
- What evidence would resolve it: Conducting the same experiments on larger language models and comparing conceptor vs. additive steering performance across multiple model sizes.

### Open Question 2
- Question: What is the computational overhead of applying conceptor steering during inference, particularly when switching between multiple steering mechanisms?
- Basis in paper: [explicit] The paper mentions that "there may be an overhead cost for switching the conceptor steering on and off" but does not quantify this cost.
- Why unresolved: The paper acknowledges this as a potential limitation but does not provide empirical measurements of the switching overhead during auto-regressive generation.
- What evidence would resolve it: Measuring inference time and memory usage when applying conceptor steering with and without switching between different steering matrices.

### Open Question 3
- Question: How does the performance of conceptor-based steering on complex behaviors compare to its performance on simple function tasks?
- Basis in paper: [explicit] The paper states that "further research should be conducted to assess... the performance on more complex behaviors/tasks."
- Why unresolved: All experiments focused on simple function tasks (antonyms, capitalize, etc.), but the paper acknowledges that complex behaviors might behave differently.
- What evidence would resolve it: Testing conceptor steering on more complex tasks like summarization, translation, or multi-step reasoning problems and comparing results to additive methods.

## Limitations
- Limited exploration of Boolean operations - only AND operation tested on one composite function
- No ablation studies on hyperparameter sensitivity (aperture parameter, layer selection)
- Computational overhead of conceptor computation not measured
- Performance results may not generalize to more complex linguistic patterns or real-world applications

## Confidence
- **High confidence**: Conceptors outperform additive steering on individual function tasks - supported by multiple experimental runs across different models and functions with consistent accuracy improvements
- **Medium confidence**: Boolean operations on conceptors improve composite function steering - based on limited experimental evidence with one function combination
- **Medium confidence**: Mean-centering improves steering effectiveness - results are mixed across different tasks and models

## Next Checks
1. Replicate the Boolean operation experiments with multiple composite function pairs (including OR operations) to verify the generality of the improved performance
2. Conduct ablation studies varying the aperture parameter α and layer selection to identify optimal steering configurations and understand sensitivity to hyperparameters
3. Measure inference-time computational overhead of conceptor-based steering versus additive methods to assess practical deployment considerations