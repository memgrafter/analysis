---
ver: rpa2
title: 'Compliance Cards: Automated EU AI Act Compliance Analyses amidst a Complex
  AI Supply Chain'
arxiv_id: '2406.14758'
source_url: https://arxiv.org/abs/2406.14758
tags:
- compliance
- cards
- https
- project
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Compliance Cards introduce a systematic approach to automating\
  \ EU AI Act compliance analyses in complex AI supply chains. The system uses three\
  \ interlocking transparency artifacts\u2014Project, Data, and Model Cards\u2014\
  to capture AIA-specific metadata from different stakeholders."
---

# Compliance Cards: Automated EU AI Act Compliance Analyses amidst a Complex AI Supply Chain

## Quick Facts
- arXiv ID: 2406.14758
- Source URL: https://arxiv.org/abs/2406.14758
- Reference count: 40
- Automated EU AI Act compliance analysis using three interlocking transparency artifacts

## Executive Summary
Compliance Cards introduce a systematic approach to automating EU AI Act compliance analyses in complex AI supply chains. The system uses three interlocking transparency artifacts—Project, Data, and Model Cards—to capture AIA-specific metadata from different stakeholders. A companion algorithm processes these artifacts to render real-time compliance predictions. This approach addresses the challenge of analyzing compliance across multiple component sources by pre-harmonizing information and enabling automated analysis.

## Method Summary
The system employs three YAML-based transparency artifacts (Project, Data, and Model Cards) that capture AIA-specific metadata from different supply chain participants. A rules-based Python algorithm processes these artifacts to generate compliance predictions. The approach enables asynchronous population of metadata by domain experts who possess the most relevant knowledge about their respective components, reducing the burden on AI providers who integrate multiple components.

## Key Results
- Enables real-time compliance analysis by harmonizing component-level metadata before aggregation
- Reduces compliance assessment burden by allowing domain experts to populate relevant CCs
- Provides computational format for algorithmic manipulation of metadata to render compliance predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Compliance Cards enable automated, real-time compliance analysis by harmonizing component-level metadata before aggregation
- Mechanism: Separate artifacts (Project, Data, Model CCs) capture AIA-specific metadata asynchronously from different stakeholders, eliminating the need for post-hoc harmonization
- Core assumption: Component suppliers can provide accurate, relevant metadata before integration occurs
- Break condition: If component metadata is incomplete or inaccurate, the automated analysis will produce incorrect compliance predictions

### Mechanism 2
- Claim: Computational format enables algorithmic manipulation for rapid compliance assessments
- Mechanism: Attribute-value pairs in YAML/JSON format allow rules-based algorithms to process metadata and render compliance predictions
- Core assumption: AIA requirements can be encoded as deterministic rules over the captured metadata
- Break condition: If AIA requirements are too nuanced or context-dependent to encode as rules, the algorithm will fail to capture required complexity

### Mechanism 3
- Claim: Pre-population by domain experts reduces burden on AI providers during compliance assessment
- Mechanism: Dataset and model suppliers populate their respective CCs with expertise about their components, while providers focus on project-level information
- Core assumption: Information asymmetry exists along the AI supply chain where component makers have better knowledge of their products
- Break condition: If component suppliers refuse to share metadata or provide low-quality information, the system fails to reduce provider burden

## Foundational Learning

- Concept: EU AI Act regulatory framework and operator roles
  - Why needed here: Understanding which requirements apply to which operator roles (provider vs. deployer) is essential for correctly populating CC attributes
  - Quick check question: Which AI operator bears the highest responsibility for satisfying AIA requirements and why?

- Concept: AI supply chain complexity and information asymmetry
  - Why needed here: Recognizing why separate artifacts are needed rather than a single unified form requires understanding how knowledge is distributed across supply chain participants
  - Quick check question: Why might a provider integrating a pre-trained model have limited insight into that model's training data characteristics?

- Concept: Machine-readable transparency artifacts and metadata standards
  - Why needed here: Understanding existing formats (Model Cards, Data Cards) and their limitations helps contextualize why Compliance Cards extend them
  - Quick check question: What key metadata is missing from standard Model Cards that would be necessary for AIA compliance analysis?

## Architecture Onboarding

- Component map: Compliance Cards (Project, Data, Model) -> Compliance Cards Algorithm -> GitHub repository (templates and implementation)

- Critical path: 1. Component suppliers populate Data CCs and Model CCs 2. Provider populates Project CC 3. All CCs are assembled 4. Algorithm processes CCs to render compliance prediction

- Design tradeoffs:
  - Rule-based vs. LLM-based algorithm (simplicity vs. adaptability)
  - Mandatory vs. optional attributes (completeness vs. adoption friction)
  - Local vs. hosted algorithm (privacy vs. accessibility)

- Failure signatures:
  - Missing or incomplete CCs leading to "out of scope" determinations
  - Inconsistent attribute values across related CCs
  - Algorithm runtime errors due to unexpected metadata formats

- First 3 experiments:
  1. Populate sample CCs for a simple AI system with one dataset and one model, run algorithm
  2. Test algorithm with missing Data CC to verify "out of scope" handling
  3. Create conflicting attribute values between Project CC and Model CC to test validation logic

## Open Questions the Paper Calls Out

1. How will the Compliance Cards system handle situations where component datasets or models are not publicly available or accessible to the AI provider?
   - Basis: Paper mentions closed components and federated learning scenarios but doesn't provide concrete solutions
   - Why unresolved: Only briefly mentions zero-knowledge proofs as a possibility without implementation details
   - What evidence would resolve it: Technical specification showing verification without component access

2. What is the expected performance overhead of integrating Compliance Cards population into real-time AI development workflows?
   - Basis: Paper discusses real-time needs but provides no performance benchmarks
   - Why unresolved: Emphasizes importance without quantifying computational cost
   - What evidence would resolve it: Benchmark studies comparing time/resources to traditional methods

3. How will the Compliance Cards system adapt to evolving EU AI Act standards and other emerging AI regulations?
   - Basis: Paper acknowledges dynamic nature of AI regulation but lacks update strategy
   - Why unresolved: Recognizes need for updates but doesn't specify maintenance process
   - What evidence would resolve it: Documented process for regular updates to CC attributes and algorithm

## Limitations

- Relies heavily on accurate metadata provision from all supply chain participants
- Current incompleteness of AIA requires future updates to CC attributes and algorithm
- Rule-based algorithm may struggle with nuanced or context-dependent compliance requirements

## Confidence

- **High confidence**: The core architectural design of using separate CC artifacts for different supply chain participants is well-founded
- **Medium confidence**: The automated compliance prediction capability is theoretically sound but depends heavily on metadata quality
- **Low confidence**: The claim that this approach will "democratize access to compliance analysis" assumes widespread adoption and technical literacy

## Next Checks

1. Test the system with incomplete or inconsistent CC metadata to verify how gracefully the algorithm handles missing information
2. Validate the rule-based algorithm against actual AIA requirements by running it on real-world AI systems with known compliance characteristics
3. Evaluate the burden reduction claim by comparing time and expertise required to complete CCs versus traditional compliance assessment methods across different supply chain roles