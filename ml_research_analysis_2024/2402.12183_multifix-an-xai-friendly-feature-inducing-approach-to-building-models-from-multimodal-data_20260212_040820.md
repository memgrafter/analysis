---
ver: rpa2
title: 'MultiFIX: An XAI-friendly feature inducing approach to building models from
  multimodal data'
arxiv_id: '2402.12183'
source_url: https://arxiv.org/abs/2402.12183
tags:
- features
- data
- feature
- image
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MultiFIX is an interpretable multimodal learning pipeline that
  explicitly induces separate features from different data types, enabling clear identification
  of each modality's contribution to the final prediction. It combines deep learning
  for feature extraction with GP-GOMEA for creating inherently interpretable symbolic
  expressions.
---

# MultiFIX: An XAI-friendly feature inducing approach to building models from multimodal data

## Quick Facts
- arXiv ID: 2402.12183
- Source URL: https://arxiv.org/abs/2402.12183
- Reference count: 27
- Primary result: Interpretable multimodal learning pipeline that combines deep learning feature extraction with symbolic regression for explainable predictions

## Executive Summary
MultiFIX is an interpretable multimodal learning pipeline designed to explicitly induce separate features from different data types while enabling clear identification of each modality's contribution to final predictions. The approach combines deep learning for feature extraction with GP-GOMEA (Genetic Programming - Gene-pool Optimal Mixing Evolutionary Algorithm) to create inherently interpretable symbolic expressions. MultiFIX employs Grad-CAM for explaining image features and GP-GOMEA for both tabular feature and fusion block explanations, demonstrating effectiveness on synthetic datasets while providing transparency in model decisions.

## Method Summary
MultiFIX operates as a pipeline that extracts features from different modalities using specialized techniques, then fuses these features through GP-GOMEA to generate interpretable symbolic expressions. The system uses Grad-CAM for image feature visualization, allowing users to understand which parts of images contribute to predictions. For tabular and fusion components, GP-GOMEA creates symbolic expressions that are inherently interpretable, showing exactly how different features combine to produce outcomes. This architecture enables clear attribution of predictive power to specific modalities while maintaining model accuracy.

## Key Results
- MultiFIX achieves high accuracy on synthetic multimodal datasets while providing clear interpretability of modality contributions
- The approach outperforms single-modality models when complementary information exists between modalities
- Performance degrades with XOR-correlated modalities, requiring autoencoder pre-training to enable proper feature learning

## Why This Works (Mechanism)
MultiFIX works by explicitly separating feature extraction for different modalities before combining them in an interpretable manner. The use of symbolic regression through GP-GOMEA ensures that the final model takes the form of mathematical expressions that humans can understand, rather than opaque neural network weights. Grad-CAM provides visual explanations for image features by highlighting regions that contribute most to predictions. The fusion process using GP-GOMEA allows the model to show exactly how different modality features combine, making the contribution of each data type transparent.

## Foundational Learning
- Symbolic Regression: Why needed - Creates interpretable mathematical expressions instead of black-box models; Quick check - Verify expressions are mathematically valid and computationally efficient
- Genetic Programming: Why needed - Evolves population of candidate solutions to find optimal feature combinations; Quick check - Monitor convergence and diversity in GP population
- Grad-CAM: Why needed - Provides visual explanations for CNN-based image feature extraction; Quick check - Validate heatmap alignment with human perception
- Gene-pool Optimal Mixing: Why needed - Efficiently explores solution space by mixing building blocks; Quick check - Track improvement rates during optimization
- Multimodal Fusion: Why needed - Combines complementary information from different data sources; Quick check - Measure redundancy and complementarity metrics
- Autoencoder Pre-training: Why needed - Handles complex modality correlations like XOR relationships; Quick check - Verify reconstruction quality and feature separability

## Architecture Onboarding

Component Map:
Image features -> Grad-CAM visualization -> GP-GOMEA fusion
Tabular features -> GP-GOMEA analysis -> GP-GOMEA fusion
GP-GOMEA fusion -> Symbolic expression output

Critical Path:
Feature extraction (Grad-CAM for images, GP-GOMEA for tabular) → Fusion via GP-GOMEA → Symbolic expression generation

Design Tradeoffs:
- Interpretability vs. raw performance: Symbolic expressions sacrifice some accuracy for explainability
- Computational cost: GP-GOMEA optimization can be expensive but provides better interpretability
- Modality dependency: Performance heavily relies on quality of individual modality feature extraction

Failure Signatures:
- Poor performance on XOR-correlated modalities without pre-training
- Overfitting in GP-GOMEA when population diversity is insufficient
- Grad-CAM visualizations that don't align with human intuition about important image regions

First Experiments:
1. Test feature extraction quality on simple image classification with known important regions
2. Validate GP-GOMEA symbolic expressions on synthetic tabular data with ground truth relationships
3. Evaluate fusion performance on synthetic multimodal dataset with clearly complementary information

## Open Questions the Paper Calls Out
None

## Limitations
- Performance degrades significantly with XOR-correlated modalities, requiring autoencoder pre-training
- Reliance on specific interpretability techniques (Grad-CAM, GP-GOMEA) may limit generalization
- Most validation comes from synthetic datasets rather than real-world applications

## Confidence
- High confidence in interpretability claims due to clear methodology for feature attribution
- Medium confidence in performance claims as validation relies primarily on synthetic datasets
- Medium confidence in superiority claims over single-modality models, requiring broader domain testing

## Next Checks
1. Test MultiFIX on real-world multimodal datasets beyond synthetic examples to verify practical applicability
2. Evaluate the autoencoder pre-training approach's effectiveness across different types of modality correlations beyond XOR
3. Benchmark MultiFIX against other interpretable multimodal methods using standardized metrics for both accuracy and interpretability