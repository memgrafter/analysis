---
ver: rpa2
title: 'S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised
  Pre-Training for Autonomous Driving'
arxiv_id: '2410.23085'
source_url: https://arxiv.org/abs/2410.23085
tags:
- clustering
- object
- cribo
- learning
- s3pt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'S3PT is a scene semantics and structure guided clustering approach
  for self-supervised pre-training on autonomous driving data. It improves upon prior
  clustering-based methods by addressing imbalanced object class and size distributions
  through three key contributions: semantic distribution consistent clustering using
  von Mises-Fisher normalization for better rare class representation, object diversity
  consistent spatial clustering with relaxed uniformity assumptions to handle varied
  object sizes, and depth-guided spatial clustering incorporating LiDAR depth information
  to account for 3D scene structure.'
---

# S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving

## Quick Facts
- arXiv ID: 2410.23085
- Source URL: https://arxiv.org/abs/2410.23085
- Authors: Maciej K. Wozniak; Hariprasath Govindarajan; Marvin Klingner; Camille Maurice; B Ravi Kiran; Senthil Yogamani
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on nuScenes semantic segmentation (mIoU 51.51) and 3D object detection (NDS 26.49) using scene semantics and structure guided clustering

## Executive Summary
S3PT introduces a novel scene semantics and structure guided clustering approach for self-supervised pre-training on autonomous driving data. The method addresses limitations in prior clustering-based approaches by incorporating semantic distribution consistency using von Mises-Fisher normalization, object diversity consistent spatial clustering with relaxed uniformity assumptions, and depth-guided spatial clustering using LiDAR information. These modifications enable better representation of rare classes and improved handling of diverse object sizes while leveraging 3D scene structure for enhanced clustering quality.

## Method Summary
S3PT builds upon clustering-based self-supervised learning frameworks like DINO and CrIBo by introducing three key modifications for autonomous driving datasets. First, it replaces standard L2 normalization with von Mises-Fisher normalization to enable flexible cluster spread for better representation of long-tailed class distributions. Second, it modifies spatial clustering to handle diverse object sizes by reducing Sinkhorn-Knopp iterations and increasing cluster count, relaxing the uniformity assumption. Third, it incorporates depth information from LiDAR data into the clustering cost matrix to account for 3D scene structure. The method is evaluated on nuScenes, nuImages, and Cityscapes datasets using ViT-Small/16 and ViT-Base/16 models pre-trained for 500 and 100 epochs respectively.

## Key Results
- Achieves nuImages mIoU of 51.51 with Mask Transformer and 42.94 with linear probing
- Improves nuScenes NDS score to 26.49 for 3D object detection
- Demonstrates superior generalization across autonomous driving datasets
- Shows enhanced robustness to distant and occluded objects compared to prior methods

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Semantic distribution consistent clustering using von Mises-Fisher (vMF) normalization improves representation of rare classes.
- **Mechanism**: vMF normalization allows the model to learn from long-tailed class distributions by enabling flexible cluster spread rather than enforcing uniform class prior as in standard DINO. This means rare classes like motorcycles or pedestrians can form tighter, more distinct clusters.
- **Core assumption**: The class frequency in the dataset is representative of the underlying distribution, and a vMF-based formulation better captures this without collapsing rare classes into dominant ones.
- **Evidence anchors**:
  - [abstract] "incorporate semantic distribution consistent clustering to encourage better representation of rare classes such as motorcycles or animals"
  - [section] "Using vMF normalized formulation of DINO enables more flexible cluster spread... This formulation is obtained by using unnormalized prototypes... enabling flexible cluster spread [25] and is shown to perform well when learning from such long-tailed datasets [26]."

### Mechanism 2
- **Claim**: Object diversity consistent spatial clustering with relaxed uniformity assumptions handles imbalanced and diverse object sizes.
- **Mechanism**: Instead of enforcing a uniform spatial cluster size distribution (which assumes all objects are similarly sized), the method increases the number of clusters and reduces Sinkhorn-Knopp iterations. This allows the clustering to identify small objects (e.g., pedestrians, traffic signs) without forcing them to merge into larger clusters.
- **Core assumption**: Real-world scenes contain objects of highly variable sizes and counts; uniform spatial cluster assumptions are unrealistic.
- **Evidence anchors**:
  - [abstract] "introduce object diversity consistent spatial clustering, to handle imbalanced and diverse object sizes, ranging from large background areas to small objects such as pedestrians and traffic signs"
  - [section] "Running the algorithm for multiple iterations strongly encourages a uniform distribution of areas over the spatial clusters. This makes the implicit assumption that all the objects should be approximately equally sized... we propose to modify the spatial clustering to remain consistent to the object diversity observed in AD scenes."

### Mechanism 3
- **Claim**: Depth-guided spatial clustering incorporates LiDAR depth to improve region separation and 3D structure awareness.
- **Mechanism**: The transportation cost matrix for clustering is augmented with depth differences between tokens and cluster centroids. This ensures that objects at different depths but similar appearance (e.g., two cars in front/behind) are assigned to separate clusters.
- **Core assumption**: Depth information is available and accurate at token locations; depth differences meaningfully separate semantically distinct objects.
- **Evidence anchors**:
  - [abstract] "propose a depth-guided spatial clustering to regularize learning based on geometric information of the scene"
  - [section] "We modify this transportation cost to also account for the depth information, available through the LiDAR data as: T = T (CrIBo) + βT (depth)... This enables the spatial clustering to account for the scene structure made apparent through depth guidance."

## Foundational Learning

- **Concept**: Self-supervised learning with clustering-based pretext tasks
  - Why needed here: The method builds on DINO and CrIBo, which use clustering to assign pseudo-labels for pre-training without labeled data.
  - Quick check question: What is the role of the teacher-student architecture in these clustering methods?

- **Concept**: Von Mises-Fisher (vMF) distribution and its use in clustering
  - Why needed here: vMF normalization replaces L2 normalization to allow non-uniform cluster spread, crucial for handling long-tailed class distributions.
  - Quick check question: How does vMF normalization differ from L2 normalization in terms of cluster assignment probability?

- **Concept**: Optimal transport and Sinkhorn-Knopp algorithm for clustering
  - Why needed here: Spatial clustering is formulated as an optimal transport problem; relaxing uniformity by reducing SK iterations enables diverse object size handling.
  - Quick check question: What is the effect of increasing SK iterations on cluster uniformity?

## Architecture Onboarding

- **Component map**: View augmentation -> Dense feature extraction -> Depth completion -> Spatial clustering module (cost matrix + Sinkhorn-Knopp) -> vMF-normalized semantic clustering -> Teacher/student consistency loss

- **Critical path**: View augmentation → Dense feature extraction → Depth completion → Depth-guided cost computation → Joint spatial clustering → vMF-normalized semantic clustering → Teacher/student consistency loss

- **Design tradeoffs**:
  - More spatial clusters → better small object capture but higher compute
  - Fewer SK iterations → relaxed uniformity but risk of noisy clusters
  - Depth weight β → balances geometric vs. appearance cues

- **Failure signatures**:
  - Uniform cluster sizes dominate → small objects lost
  - Depth term too high → clusters split on depth alone, ignoring semantics
  - vMF over-relaxed → rare classes not distinct enough

- **First 3 experiments**:
  1. Replace L2 normalization with vMF normalization and measure rare class performance on nuImages.
  2. Increase spatial clusters to 128 and reduce SK iterations to 1; compare segmentation of small objects.
  3. Add depth term with β=0.5; evaluate 3D object detection improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform on datasets with significantly different object size distributions compared to nuScenes and Cityscapes, such as aerial imagery or microscopy data?
- Basis in paper: [inferred] The paper demonstrates improved performance on nuScenes and Cityscapes datasets, which have specific object size distributions (ranging from large background areas to small objects like pedestrians and traffic signs). However, the method's generalization to datasets with substantially different object size distributions is not evaluated.
- Why unresolved: The paper focuses on autonomous driving datasets with similar characteristics. Evaluating the method on datasets with different object size distributions would require additional experiments and potentially modifications to the depth-guided clustering component.
- What evidence would resolve it: Empirical results showing the method's performance on datasets with different object size distributions, along with any necessary modifications to the algorithm to handle these distributions effectively.

### Open Question 2
- Question: What is the impact of using different depth completion methods on the overall performance of the depth-guided spatial clustering?
- Basis in paper: [explicit] The paper mentions using IP-Basic depth interpolation for obtaining depth information at every token location from sparse LiDAR point clouds. However, it does not explore the impact of using alternative depth completion methods.
- Why unresolved: The choice of depth completion method could significantly affect the quality of depth information used in the clustering process. Different methods may have varying levels of accuracy and computational efficiency.
- What evidence would resolve it: Comparative experiments using multiple depth completion methods (e.g., deep learning-based approaches) and analysis of their impact on the overall performance of the depth-guided spatial clustering and downstream tasks.

### Open Question 3
- Question: How does the proposed method scale with increasing dataset size and diversity, particularly in terms of computational resources and performance gains?
- Basis in paper: [explicit] The paper mentions that larger and more diverse datasets yield higher performance gains, but it does not provide a detailed analysis of the scaling behavior or computational requirements.
- Why unresolved: Understanding the scaling behavior is crucial for practical deployment and determining the optimal trade-off between dataset size, computational resources, and performance gains.
- What evidence would resolve it: Empirical results showing the performance gains and computational requirements as the dataset size and diversity increase, along with analysis of the scaling behavior and identification of any diminishing returns or computational bottlenecks.

## Limitations
- Relies heavily on LiDAR depth data quality, which may limit effectiveness in poor sensing conditions
- Requires careful hyperparameter tuning for multiple components (cluster count, SK iterations, depth weight, temperature)
- Performance gains depend on dataset characteristics and may vary with different object size distributions

## Confidence

- **Semantic distribution consistent clustering with vMF normalization**: Medium confidence
- **Object diversity consistent spatial clustering**: High confidence
- **Depth-guided spatial clustering**: Medium confidence
- **Overall performance improvements**: High confidence

## Next Checks
1. **Cross-dataset robustness test**: Evaluate S3PT pre-training on nuScenes and transfer to a dataset without LiDAR (e.g., KITTI or BDD100K) to assess whether the depth-guided clustering component provides benefits that persist even when depth information is unavailable during downstream tasks.

2. **Ablation study on depth weight**: Systematically vary the depth weight parameter β (e.g., 0.0, 0.5, 1.0, 2.0) and evaluate the trade-off between geometric and appearance-based clustering performance, particularly focusing on cases where depth information might conflict with semantic similarity.

3. **Rare class frequency sensitivity**: Create controlled experiments by artificially adjusting the frequency of rare classes in the training data (e.g., reducing motorcycle instances to 10%, 1%, 0.1%) to test the limits of vMF normalization's ability to maintain distinct representations for extremely rare categories.