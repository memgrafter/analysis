---
ver: rpa2
title: 'DRS: Deep Question Reformulation With Structured Output'
arxiv_id: '2411.17993'
source_url: https://arxiv.org/abs/2411.17993
tags:
- question
- questions
- entities
- uni00000013
- uni00000018
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DRS (Deep Question Reformulation with Structured
  Output), a method that improves large language models' ability to reformulate unanswerable
  questions. The approach combines DFS-based search with structured outputs to explore
  entity combinations while maintaining answerability and intent preservation.
---

# DRS: Deep Question Reformulation With Structured Output

## Quick Facts
- **arXiv ID**: 2411.17993
- **Source URL**: https://arxiv.org/abs/2411.17993
- **Reference count**: 20
- **Primary result**: DRS improves LLM reformulation accuracy from 23.03% to 70.42% for GPT-3.5 and from 26.35% to 56.75% for GEMMA2-9B

## Executive Summary
This paper introduces DRS (Deep Question Reformulation with Structured Output), a method that significantly improves large language models' ability to reformulate unanswerable questions into answerable ones while preserving user intent. The approach combines depth-first search (DFS) with structured outputs to systematically explore entity combinations and generate grounded questions. Experimental results demonstrate substantial performance improvements across multiple models, with GPT-3.5 accuracy increasing from 23.03% to 70.42% and GEMMA2-9B improving from 26.35% to 56.75%. The method also introduces a more reliable evaluation framework using GPT-4O-MINI.

## Method Summary
DRS reformulates unanswerable questions by first extracting and classifying entities from the original question, then using DFS to explore combinations of these entities. For each combination, DRS generates a structured statement containing the selected entities based on document context, then generates a question from that statement. The method employs a two-stage evaluation process using GPT-4O-MINI to verify answerability and measure entity overlap with the original question. This structured approach ensures reformulated questions are both answerable and maintain user intent by preserving original entities.

## Key Results
- GPT-3.5 accuracy improves from 23.03% to 70.42% using DRS
- GEMMA2-9B accuracy increases from 26.35% to 56.75%
- DRS outperforms existing methods across all tested LLMs
- GPT-4O-MINI provides more reliable evaluation than previous LLAMA2-7B evaluator

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DRS improves reformulation by constraining LLM outputs with structured entity combinations rather than allowing free-form generation.
- Mechanism: The DFS-based search systematically explores combinations of extracted entities from the original question. For each combination, DRS first generates a structured statement containing all selected entities based on the document context, then generates a question from that statement. This two-step structured generation ensures the reformulated question is both answerable (because it's grounded in the document) and preserves intent (because it includes specific entities from the original question).
- Core assumption: LLMs can reliably generate structured outputs when explicitly constrained with entity requirements, and that grounding question generation in document-derived statements reduces hallucination.

### Mechanism 2
- Claim: The two-stage evaluation process (answerability + entity overlap) ensures reformulated questions balance practical utility with intent preservation.
- Mechanism: After generating candidate questions, DRS first filters for answerability using GPT-4O-MINI to verify questions can be answered from the document. Then it selects among answerable candidates based on entity overlap score, prioritizing questions that preserve more original entities. This creates a tradeoff between making questions answerable and maintaining user intent.
- Core assumption: Answerability and entity preservation are both necessary for useful reformulation, and that GPT-4O-MINI can reliably evaluate both criteria.

### Mechanism 3
- Claim: Entity classification into semantic roles (subject, object, attribute, predicate, others) improves extraction quality by filtering out non-essential entities.
- Mechanism: After initial entity extraction, DRS uses a second LLM prompt to classify entities into five categories. Only entities classified as subject, object, or attribute are retained for reformulation. This filters out verb phrases and other non-essential elements that might otherwise lead to poor reformulation quality.
- Core assumption: Classifying entities by semantic role and filtering out non-essential categories improves the quality of entity sets used for reformulation.

## Foundational Learning

- **Concept**: Depth-First Search (DFS) algorithm
  - Why needed here: DFS systematically explores all possible entity combinations up to a certain depth, ensuring comprehensive coverage of potential reformulation paths while controlling computational cost through pruning
  - Quick check question: If you have 5 entities and want to explore all combinations of 2 entities, how many combinations would DFS generate?

- **Concept**: Structured output generation
  - Why needed here: Direct question generation from entities often fails because LLMs can hallucinate content; generating a statement first and then a question from that statement ensures grounding in the document
  - Quick check question: Why might generating a statement first be more reliable than generating a question directly when trying to ensure answerability?

- **Concept**: Entity overlap metrics for evaluation
  - Why needed here: Simple answerability checks aren't enough; we need to ensure reformulated questions preserve user intent by measuring how many original entities are retained
  - Quick check question: If an original question has 4 entities and a reformulated question has 2 of those entities, what is the entity overlap score?

## Architecture Onboarding

- **Component map**: Entity Extraction -> Entity Classification -> DFS Search -> Structured Generation -> Candidate Storage -> Answerability Evaluation -> Entity Overlap Evaluation -> Final Selection

- **Critical path**: Entity Extraction → Entity Classification → DFS Search → Structured Generation → Answerability Evaluation → Entity Overlap Evaluation → Final Selection

- **Design tradeoffs**:
  - Number of candidates vs. runtime: More candidates increase accuracy but also increase computation time
  - DFS depth vs. coverage: Deeper searches find more combinations but exponentially increase candidates
  - Temperature settings: Higher temperature increases diversity but may reduce instruction-following reliability
  - Entity filtering strictness: More aggressive filtering reduces noise but may remove important entities

- **Failure signatures**:
  - Low accuracy despite high candidate count: Entity extraction or classification may be failing
  - Runtime too long: DFS depth or candidate count may be too high for the problem size
  - Questions not preserving intent: Entity overlap metric may need adjustment or entity classification may be poor
  - Answerability failures: Structured generation may not be properly grounding questions in document content

- **First 3 experiments**:
  1. Baseline test: Run DRS with minimal parameters (depth=1, candidates=1) to verify the core pipeline works
  2. Parameter sweep: Vary candidate count from 1-5 and measure accuracy/runtime tradeoff
  3. Temperature sensitivity: Test different temperature settings to find optimal balance between diversity and reliability for each LLM model

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation framework relies entirely on GPT-4O-MINI, introducing potential evaluator bias
- Performance across diverse domains beyond tested datasets remains uncertain
- Entity classification errors can propagate through the entire pipeline

## Confidence
- **High confidence**: Core methodology combining DFS-based search with structured outputs is well-specified and theoretically sound
- **Medium confidence**: Evaluation framework using GPT-4O-MINI is more reliable than previous approaches
- **Low confidence**: Claims about method's generalizability to unseen domains and languages

## Next Checks
1. **Evaluator reliability test**: Run the same reformulation tasks through multiple different LLM evaluators (GPT-4O-MINI, Claude, Gemini) and compare their assessments of answerability and entity overlap to quantify evaluator consistency and potential bias.

2. **Cross-domain robustness**: Apply DRS to datasets from substantially different domains (e.g., medical, legal, or scientific literature) and measure whether the performance gains observed in the original datasets persist when entity extraction becomes more complex.

3. **Error analysis on failure cases**: Systematically analyze 50-100 unanswerable questions where DRS failed to produce acceptable reformulations, categorizing failures by type (entity extraction errors, poor entity classification, generation failures, evaluator misjudgments) to identify the primary failure modes and their relative frequencies.