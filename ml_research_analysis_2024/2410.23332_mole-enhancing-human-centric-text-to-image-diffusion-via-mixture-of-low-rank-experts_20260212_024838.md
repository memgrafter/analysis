---
ver: rpa2
title: 'MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank
  Experts'
arxiv_id: '2410.23332'
source_url: https://arxiv.org/abs/2410.23332
tags:
- images
- mole
- dataset
- hand
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating natural-looking
  human-centric images, particularly focusing on faces and hands, which often lack
  realism due to insufficient training data. The authors propose Mixture of Low-rank
  Experts (MoLE), a method that leverages a large-scale human-centric dataset and
  employs low-rank modules as experts for refining face and hand generation.
---

# MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts

## Quick Facts
- arXiv ID: 2410.23332
- Source URL: https://arxiv.org/abs/2410.23332
- Authors: Jie Zhu; Yixiong Chen; Mingyu Ding; Ping Luo; Leye Wang; Jingdong Wang
- Reference count: 40
- Primary result: MoLE significantly improves human-centric image generation quality using Mixture of Low-rank Experts

## Executive Summary
MoLE addresses the persistent challenge of generating realistic human-centric images, particularly focusing on faces and hands that often lack authenticity in diffusion models. The method leverages a large-scale human-centric dataset and employs low-rank modules as specialized experts for refining these challenging areas. By integrating these experts through a soft assignment mechanism, MoLE enables adaptive and flexible activation within the diffusion model. The approach demonstrates substantial improvements over state-of-the-art methods, validated through enhanced human preference scores and image rewards across multiple benchmarks.

## Method Summary
MoLE proposes a novel approach to human-centric image generation by utilizing low-rank experts specifically designed for face and hand refinement. The method incorporates these experts into diffusion models through a soft assignment mechanism that allows for adaptive activation based on the input content. This mixture-of-experts architecture enables the model to dynamically allocate computational resources where they are most needed, improving the quality of human features while maintaining efficiency. The approach is validated across different diffusion model architectures including SD v1.5, SD v2.1, and PixArt-α, demonstrating both effectiveness and versatility in enhancing human-centric image generation.

## Key Results
- Significant improvement in human preference scores compared to state-of-the-art methods
- Enhanced image rewards on two custom benchmarks for human-centric generation
- Successful generalization across multiple diffusion model architectures (SD v1.5, SD v2.1, PixArt-α)

## Why This Works (Mechanism)
The method works by addressing the fundamental limitation of insufficient training data for human features in standard diffusion models. By employing low-rank experts specifically trained on large-scale human-centric datasets, MoLE can focus computational resources on the most challenging aspects of human image generation - faces and hands. The soft assignment mechanism allows for dynamic routing of information to the appropriate expert based on content, enabling adaptive refinement where it's most needed. This targeted approach overcomes the generalization limitations of standard diffusion models while maintaining efficiency through the low-rank structure of the expert modules.

## Foundational Learning
- Diffusion models: Need to understand the iterative denoising process and how noise is progressively removed to generate images
- Low-rank matrix factorization: Required to grasp how low-rank experts reduce computational complexity while maintaining representational power
- Mixture of experts: Essential for understanding how multiple specialized models can be combined through routing mechanisms
- Soft assignment mechanisms: Important for comprehending how experts are dynamically selected based on input content
- Human-centric datasets: Critical for appreciating the data requirements and quality considerations for training specialized models

## Architecture Onboarding

**Component map:**
Input image/text prompt -> Diffusion model backbone -> Soft assignment module -> Face expert / Hand expert -> Output refined image

**Critical path:**
Text prompt → Text encoder → U-Net backbone → Soft assignment routing → Expert modules (face/hand) → Denoising steps → Final image

**Design tradeoffs:**
The soft assignment mechanism provides flexibility but introduces routing complexity; low-rank experts reduce computational cost but may limit representational capacity compared to full-rank alternatives; the method requires large-scale human-centric datasets which may not be universally accessible.

**Failure signatures:**
Over-activation of experts leading to inconsistent results; routing decisions that don't match content needs; artifacts at the boundaries between expert-refined and non-refined regions; degradation in non-human-centric image quality.

**First experiments to run:**
1. Test expert activation patterns on diverse human-centric prompts to verify appropriate routing
2. Compare low-rank vs full-rank expert performance to quantify efficiency gains
3. Evaluate generalization by testing on out-of-distribution human poses and compositions

## Open Questions the Paper Calls Out
None

## Limitations
- Dependency on large-scale human-centric datasets that may not be accessible to all researchers
- Soft assignment mechanism complexity could affect consistency across different scenarios
- Evaluation metrics relying on human preference scores may have subjective components

## Confidence
- Claims about technical implementation and methodology: High
- Claims about performance improvements: Medium
- Claims about generalization across architectures: Medium
- Claims about human preference metrics: Medium

## Next Checks
1. Test MoLE's performance on smaller, more constrained human-centric datasets to evaluate effectiveness when large-scale data is unavailable
2. Conduct ablation studies specifically focusing on the soft assignment mechanism to quantify impact on both performance and computational efficiency
3. Implement cross-validation testing across additional diffusion model architectures beyond the three tested to verify claimed generalization capabilities