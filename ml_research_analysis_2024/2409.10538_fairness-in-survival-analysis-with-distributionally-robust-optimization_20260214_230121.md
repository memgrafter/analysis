---
ver: rpa2
title: Fairness in Survival Analysis with Distributionally Robust Optimization
arxiv_id: '2409.10538'
source_url: https://arxiv.org/abs/2409.10538
tags: []
core_contribution: The authors propose a method to convert existing survival analysis
  models into ones that encourage fairness using distributionally robust optimization
  (DRO). The key challenge is that existing DRO theory requires loss functions that
  decompose across data points, but commonly used survival loss functions (like Cox
  models) involve pairwise comparisons.
---

# Fairness in Survival Analysis with Distributionally Robust Optimization

## Quick Facts
- arXiv ID: 2409.10538
- Source URL: https://arxiv.org/abs/2409.10538
- Reference count: 40
- The authors propose a method to convert existing survival analysis models into ones that encourage fairness using distributionally robust optimization (DRO).

## Executive Summary
This paper addresses the challenge of incorporating fairness into survival analysis models using distributionally robust optimization (DRO). The key technical hurdle is that standard DRO theory requires loss functions decomposable across data points, but survival analysis losses (like Cox models) involve pairwise comparisons. The authors propose two main approaches: a sample splitting strategy that creates independent single-point losses, and an exact method for Cox models that reparameterizes the loss to be decomposable. They demonstrate their approach on Cox models, DeepHit, and SODEN, showing that DRO variants often outperform existing fairness regularization techniques while maintaining accuracy.

## Method Summary
The authors convert existing survival analysis models into fair versions by applying DRO using a sample splitting approach. The training data is split into two sets, and a DRO loss is computed over one set while treating the other as fixed, creating independent single-point losses. For Cox models specifically, they derive an exact DRO approach without sample splitting by reparameterizing the full likelihood using piecewise constant baseline hazards. The approach is demonstrated on Cox models (both classical and deep variants), DeepHit, and SODEN. Hyperparameter tuning uses fairness metrics (CI or FCG) with tolerance for small accuracy degradation.

## Key Results
- DRO variants often outperform existing fairness regularization techniques in terms of recently established fairness metrics
- The sample splitting approach successfully adapts DRO to survival models with pairwise comparison losses
- The exact Cox DRO approach provides theoretical guarantees without data efficiency loss
- Fairness improvements are achieved without significant accuracy loss (Ctd and IBS remain comparable to baselines)

## Why This Works (Mechanism)

### Mechanism 1
DRO can be adapted to survival analysis models with pairwise or multi-point coupling losses by using sample splitting. The training data is split into two disjoint subsets D1 and D2. For each point in D1, the loss is computed using only that point and points in D2 as fixed references. This creates independent, single-point losses that comply with DRO theory. Core assumption: The adjacency sets A_i for individual losses can be approximated by A_i ∩ D2 without significant loss of model fidelity.

### Mechanism 2
The heuristic approach of applying DRO directly to coupled losses works in practice despite theoretical violations. DRO optimization is applied to the full loss function (with multi-point coupling) as if it were decomposable, ignoring the coupling issue. Core assumption: The optimization dynamics of gradient descent with respect to the DRO objective still implicitly favor fairness even without theoretical guarantees.

### Mechanism 3
For Cox models specifically, exact DRO can be implemented without sample splitting by reparameterizing the loss. The Cox full likelihood is expressed in terms of a piecewise constant baseline hazard with parameters ψ. This introduces additional parameters that decouple the loss across data points, making it compatible with standard DRO. Core assumption: The Breslow approximation (piecewise constant baseline hazard) is a valid and accurate representation of the true baseline hazard for the purposes of DRO.

## Foundational Learning

- Concept: Distributionally Robust Optimization (DRO)
  - Why needed here: DRO is the core framework used to encourage fairness by minimizing worst-case error across subpopulations.
  - Quick check question: What is the role of the parameter α in DRO, and how does it affect the subpopulations considered?

- Concept: Survival analysis loss functions with pairwise comparisons
  - Why needed here: Many survival models (e.g., Cox, DeepHit) have losses that involve comparisons between pairs of data points, which violates DRO's decomposability assumption.
  - Quick check question: Why does the Cox partial likelihood involve a sum over all training points with Y_j ≥ Y_i?

- Concept: Sample splitting and cross-fitting
  - Why needed here: These techniques are used to create independent, single-point losses that comply with DRO theory when the original loss has multi-point coupling.
  - Quick check question: How does the cross-fitting approach in Algorithm 2 use both D1 and D2 to improve data efficiency?

## Architecture Onboarding

- Component map: Survival model (Cox/DeepHit/SODEN) -> DRO wrapper (heuristic/sample splitting/exact Cox) -> Evaluation metrics (Ctd, IBS, CI, FCI, FCG)
- Critical path: Train -> Validate (tune α) -> Test (evaluate accuracy and fairness)
- Design tradeoffs: Heuristic DRO is simpler but lacks theoretical guarantees; sample splitting is theoretically sound but uses data less efficiently; exact Cox DRO is optimal for Cox but not generalizable
- Failure signatures: If fairness metrics do not improve, check if α is too large (ignoring minority groups) or if the adjacency approximation in sample splitting is too coarse
- First 3 experiments:
  1. Apply heuristic DRO to a simple Cox model on a small dataset and compare fairness metrics to the baseline
  2. Implement sample splitting DRO on DeepHit and verify that the accuracy-fairness tradeoff curve shifts toward better fairness
  3. Test the exact Cox DRO on a medium-sized dataset and compare its performance to the sample splitting version

## Open Questions the Paper Calls Out

### Open Question 1
Does the sample splitting DRO approach maintain its fairness benefits when applied to survival models with continuous time rather than discrete time? The paper assumes discrete time in its theoretical analysis and uses discrete time grids for DeepHit, but does not explore continuous time survival models like neural ODEs. This remains unresolved because the authors note their approach "does not easily generalize to other survival models with nonempty adjacency sets" beyond what they demonstrate.

### Open Question 2
Can the hyperparameter α be tuned effectively without using validation set fairness metrics that require specifying sensitive attributes? The authors acknowledge this limitation, noting that "we are effectively using some information about which features to treat as sensitive as it shows up in computing the validation set fairness metric" and call for "other fairness evaluation metrics that can be used for the validation set."

### Open Question 3
What is the optimal number of folds for cross-fitting in the sample splitting DRO approach? The authors use 2-fold cross-fitting for simplicity but note in Appendix B that "for K-fold cross-validation, one could use more than 2 folds" and defer "identifying an 'optimal' split to future work."

## Limitations
- The sample splitting approach introduces potential efficiency loss and relies on adjacency set approximations that may not hold in all scenarios
- The heuristic approach lacks theoretical guarantees and may not generalize well to all survival model architectures
- The exact Cox DRO approach is specific to Cox models and does not extend to more complex survival models

## Confidence

**High**: The sample splitting mechanism is well-theoretically grounded and the empirical results show consistent improvements in fairness metrics
**Medium**: The heuristic approach shows good empirical performance but lacks theoretical justification
**Medium**: The exact Cox DRO approach is theoretically sound but limited in scope

## Next Checks

1. Test the sample splitting approach on survival models with non-linear hazard functions to assess adjacency set approximation quality
2. Compare the heuristic DRO's performance across different survival model architectures to identify its limitations
3. Evaluate the sensitivity of fairness improvements to the choice of α parameter and its tuning procedure