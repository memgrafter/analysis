---
ver: rpa2
title: Learning to Build by Building Your Own Instructions
arxiv_id: '2410.01111'
source_url: https://arxiv.org/abs/2410.01111
tags:
- assembly
- stack
- expert
- instruction
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces InstructioNet, a new method for the Break-and-Make
  problem in LTRON where an agent must learn to build a previously unseen LEGO assembly
  using a single interactive session. The key idea is to create an explicit instruction
  stack memory by disassembling the assembly and periodically saving images.
---

# Learning to Build by Building Your Own Instructions

## Quick Facts
- arXiv ID: 2410.01111
- Source URL: https://arxiv.org/abs/2410.01111
- Authors: Aaron Walsman; Muru Zhang; Adam Fishman; Ali Farhadi; Dieter Fox
- Reference count: 40
- One-line primary result: Achieves F1 scores up to 0.98 on 2-brick models and 0.59 on challenging RC-Vehicles dataset containing assemblies averaging 31 bricks each

## Executive Summary
This paper introduces InstructioNet, a method for learning to build previously unseen LEGO assemblies through a single interactive disassembly and reassembly session. The key innovation is using an explicit instruction stack created during disassembly to provide short-term visual targets during reassembly, avoiding the need for long-term implicit memory. The method employs online imitation learning with a vision transformer model and achieves substantially better performance than previous baselines on both simple random assemblies and complex RC-Vehicles.

## Method Summary
InstructioNet addresses the Break-and-Make problem by first disassembling an assembly while saving images to an explicit instruction stack. During reassembly, the model uses this stack as step-by-step visual instructions, only needing to match the current scene with the top stack image. The model uses a conditional vision transformer with online imitation learning, where an expert mixture (α=0.75) alternates between expert-generated and model-generated trajectories to teach recovery from mistakes. The approach includes several improvements to LTRON including a simplified interface and a new RC-Vehicles dataset with more complex assemblies.

## Key Results
- Achieves F1 scores up to 0.98 on 2-brick models
- Achieves F1 score of 0.59 on RC-Vehicles dataset with assemblies averaging 31 bricks each
- Substantially outperforms previous baselines on both random construction assemblies and RC-Vehicles dataset
- Demonstrates successful learning of assembly from a single interactive disassembly session

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using an explicit instruction stack allows the model to reduce long-term memory demands by breaking the assembly task into short-term visual matching steps.
- Mechanism: The model saves intermediate disassembly images to a stack, then during assembly only needs to match the current scene with the top stack image, effectively using the stack as a step-by-step visual instruction manual.
- Core assumption: The assembly process is approximately reversible—matching the reverse disassembly sequence will guide correct reconstruction.
- Evidence anchors:
  - [abstract] "These instructions form an explicit memory that allows the model to reason about the assembly process one step at a time, avoiding the need for long-term implicit memory."
  - [section] "When rebuilding the model the agent only has to reason about its current observation and the page of the instruction stack that it is currently working on."
  - [corpus] Weak evidence—no direct matches in neighbor papers about explicit instruction stacks for LEGO assembly.
- Break condition: If the disassembly sequence is not approximately reversible (e.g., non-hierarchical or ambiguous assembly steps), the instruction stack would not provide useful guidance.

### Mechanism 2
- Claim: Online imitation learning with an expert mixture (α=0.75) allows the model to learn recovery from its own mistakes while still receiving high-quality supervision.
- Mechanism: The model alternates between expert-generated and model-generated trajectories, training on expert labels for both. This exposes the model to states it might reach due to mistakes and teaches recovery behavior.
- Core assumption: The expert can always provide correct guidance even when the model deviates, and the replay buffer prevents catastrophic forgetting.
- Evidence anchors:
  - [section] "Incorporating trajectories generated by the agent in this way allows the model to learn to recover from its mistakes: when the model takes an inappropriate action it will reach part of the state space that would not have been encountered if acting according to the expert, yet seeing the expert's advice in these states shows the model how to correctly recover from this behavior."
  - [corpus] No direct matches—neighbor papers focus on different assembly paradigms (AR, multi-robot) without online expert mixtures.
- Break condition: If the expert cannot handle states far from the optimal path, training may fail; if the replay buffer is too small, catastrophic forgetting could occur.

### Mechanism 3
- Claim: Conditioning cursor actions on high-level action and parameters via attention improves performance compared to unconditioned models.
- Mechanism: The DPT decoder outputs are attended over using the sampled high-level action and parameters as a query, creating a conditional distribution over click locations specific to the current action context.
- Core assumption: The relationship between high-level action and appropriate cursor location is consistent enough to benefit from conditioning.
- Evidence anchors:
  - [section] "We found it beneficial to condition these click locations on the high level action and parameters sampled from the initial decoder heads."
  - [corpus] Weak evidence—neighbor papers discuss vision-language modeling and AR assembly but not conditional cursor action generation in detail.
- Break condition: If the action-parameter space is too large or sparse, the conditioning may not provide meaningful signal, leading to instability or degraded performance.

## Foundational Learning

- Concept: Vision transformers for image tokenization and sequence modeling
  - Why needed here: The model must process both current and instruction stack images as sequences of patches and attend over them to make decisions.
  - Quick check question: What is the patch size used to tokenize the 128x128 images, and how many tokens does this produce per image?
- Concept: Imitation learning and DAgger-style online training
  - Why needed here: The agent requires expert supervision to learn the complex assembly task, and online data generation allows learning recovery behaviors.
  - Quick check question: What value of the expert mixture constant α was found to work well, and what does it represent?
- Concept: Loss functions for dense prediction (click location estimation)
  - Why needed here: The model must predict 2D cursor click locations, requiring a loss that encourages probability mass on acceptable pixels without being overly strict.
  - Quick check question: Which loss function (summed cross-entropy, binary cross-entropy, or MSE) was found to outperform the others for cursor location prediction?

## Architecture Onboarding

- Component map: Transformer encoder (12 blocks, 512 channels, 8 heads) → Action head (discrete actions and parameters) → DPT decoders (dense features) → Attention-based click/release heads (conditional on action/parameters) → Instruction stack (current image + top stack image + phase token)
- Critical path: Image tokenization → Transformer encoding → Action prediction → Parameter sampling → Conditional cursor prediction → Environment execution
- Design tradeoffs: Explicit instruction stack simplifies memory but assumes reversible assembly; online training with expert mixture balances exploration and supervision but requires a capable expert; conditional cursor actions improve accuracy but add model complexity
- Failure signatures: Model gets stuck in early assembly steps (insufficient expert guidance); model fails to complete Break phase (cannot discover all bricks); model loses ability to connect bricks after certain training steps (conditional action head instability)
- First 3 experiments:
  1. Train with summed cross-entropy loss vs binary cross-entropy vs MSE on cursor locations to verify the best loss function.
  2. Train with and without conditional action head connections to confirm the importance of conditioning.
  3. Train with expert mixture α=1.0 (pure behavior cloning) vs α=0.75 to demonstrate the benefit of online learning with self-generated data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of InstructioNet change with increasing assembly complexity beyond the RC-Vehicles dataset?
- Basis in paper: [explicit] The paper demonstrates success on RC-Vehicles with 31-brick assemblies but notes that the model's failure modes suggest room for improvement on larger models.
- Why unresolved: The paper does not test on assemblies larger than those in the RC-Vehicles dataset, and the model's limitations on larger models are only inferred from failure cases.
- What evidence would resolve it: Testing InstructioNet on assemblies with significantly more bricks (e.g., 50-100) and comparing performance metrics (F1 scores, AED) to smaller models would provide concrete evidence of scalability limits.

### Open Question 2
- Question: Can the instruction stack approach be generalized to other assembly or construction tasks beyond LEGO?
- Basis in paper: [inferred] The paper's instruction stack is specifically designed for LEGO assembly, and while it shows success, the method relies on assumptions about reversibility and discrete connection points.
- Why unresolved: The paper does not explore applications to other domains like furniture assembly, robotic manipulation, or CAD modeling, where the assumptions might not hold.
- What evidence would resolve it: Applying the InstructioNet framework to other assembly tasks and measuring performance relative to task-specific baselines would determine generalizability.

### Open Question 3
- Question: How does the choice of expert mixture ratio (α) affect the trade-off between learning speed and final performance?
- Basis in paper: [explicit] The paper uses α = 0.75 as a default but also tests α = 1.0 (behavior cloning) and notes differences in performance.
- Why unresolved: The paper does not systematically explore the full range of α values or analyze the impact on training stability, convergence speed, or performance on different dataset sizes.
- What evidence would resolve it: Training models with varying α values (e.g., 0.25, 0.5, 0.75, 1.0) and measuring both training curves and final performance on all datasets would clarify the optimal trade-off.

## Limitations

- The explicit instruction stack approach fundamentally relies on the reversibility of assembly processes, which may not hold for assemblies with hierarchical or conditional assembly steps.
- The online training methodology depends heavily on having an expert policy that can provide guidance in states far from optimal trajectories, but the implementation details of this expert remain unspecified.
- While the model shows substantial improvements over baselines, performance on the RC-Vehicles dataset still has room for improvement with an F1 score of only 0.59 for complete assemblies averaging 31 bricks.

## Confidence

- **High confidence**: The mechanism of using explicit instruction stacks to reduce long-term memory demands (Mechanism 1) is well-supported by the described experimental results showing substantial performance improvements over baselines.
- **Medium confidence**: The effectiveness of online imitation learning with expert mixtures (Mechanism 2) is supported by the paper's claims, but the lack of detailed expert policy specifications creates uncertainty about reproducibility.
- **Medium confidence**: The benefit of conditioning cursor actions on high-level parameters (Mechanism 3) is claimed but only briefly supported, with no ablation studies shown in the paper.

## Next Checks

1. **Generalization test**: Evaluate InstructioNet on assemblies with non-linear assembly sequences (e.g., conditional sub-assemblies) to verify whether the instruction stack approach fails when reversibility assumptions break down.
2. **Expert policy verification**: Implement and test multiple expert policies (rule-based vs learned) to determine how critical the expert quality is to the online training success and whether simpler experts suffice.
3. **Instruction stack size study**: Systematically vary the instruction stack capacity and measure the performance trade-off between memory requirements and assembly accuracy to find the optimal stack size for different assembly complexities.