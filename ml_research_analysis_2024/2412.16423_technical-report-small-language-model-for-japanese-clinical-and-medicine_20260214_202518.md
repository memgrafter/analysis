---
ver: rpa2
title: 'Technical Report: Small Language Model for Japanese Clinical and Medicine'
arxiv_id: '2412.16423'
source_url: https://arxiv.org/abs/2412.16423
tags:
- arxiv
- language
- tokens
- ncvc-slm-1
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This report presents NCVC-slm-1, a 1-billion-parameter Japanese
  language model specialized for clinical and medical domains. The model was trained
  using high-quality Japanese text, including a small augmented dataset of clinical
  and medical content covering diseases, drugs, and examinations.
---

# Technical Report: Small Language Model for Japanese Clinical and Medicine

## Quick Facts
- arXiv ID: 2412.16423
- Source URL: https://arxiv.org/abs/2412.16423
- Reference count: 40
- Primary result: NCVC-slm-1 achieves highest scores on 6/8 JMED-LLM benchmark tasks but scores below 20% on Japanese medical licensing examination (IgakuQA) benchmark

## Executive Summary
This report presents NCVC-slm-1, a 1-billion-parameter Japanese language model specifically designed for clinical and medical applications. The model incorporates specialized pre-processing, morphological analysis, and tokenization techniques to effectively handle Japanese text. Trained on high-quality Japanese text with augmented clinical and medical content covering diseases, drugs, and examinations, NCVC-slm-1 demonstrates strong performance in specialized clinical tasks while showing limitations in general medical knowledge assessment.

## Method Summary
NCVC-slm-1 was developed through training on Japanese text with specialized focus on clinical and medical domains. The model employs custom pre-processing, morphological analysis, and tokenization techniques tailored for Japanese language processing. The training corpus includes both general Japanese text and augmented datasets containing clinical and medical content covering diseases, drugs, and medical examinations. The model architecture and training methodology were designed to optimize performance on domain-specific tasks while maintaining computational efficiency.

## Key Results
- Achieved highest scores on 6 out of 8 tasks in the JMED-LLM benchmark
- Demonstrated strong performance on specialized clinical and medical downstream tasks
- Scored below 20% on the Japanese medical licensing examination (IgakuQA) benchmark

## Why This Works (Mechanism)
The model's specialized performance on clinical tasks is attributed to its domain-specific training approach, incorporating augmented medical datasets and Japanese-specific language processing techniques. The morphological analysis and tokenization are optimized for Japanese medical terminology, while the training corpus balance ensures coverage of both general language patterns and medical domain knowledge.

## Foundational Learning
- Japanese morphological analysis: Essential for proper word segmentation in Japanese text
- Domain-specific tokenization: Critical for handling medical terminology and abbreviations
- Clinical knowledge representation: Needed for accurate medical information retrieval and generation
- Quick check: Verify tokenization accuracy on medical terminology

## Architecture Onboarding
Component Map: Input Text -> Japanese Morphological Analysis -> Tokenization -> Model Processing -> Output Generation
Critical Path: Text input flows through morphological analysis and tokenization before reaching the core model
Design Tradeoffs: Balance between model size (1B parameters) and performance on clinical tasks
Failure Signatures: Poor performance on general medical knowledge tasks, particularly in licensing exam scenarios
First Experiments:
1. Evaluate model on Japanese medical terminology recognition
2. Test performance on clinical decision support tasks
3. Assess general language understanding capabilities

## Open Questions the Paper Calls Out
None

## Limitations
- Limited capability in general medical knowledge assessment (below 20% on medical licensing exam)
- Unclear training data composition affecting performance interpretation
- Potential gaps in handling rare diseases and complex clinical scenarios

## Confidence
- High confidence: JMED-LLM benchmark performance (6/8 tasks with highest scores)
- Medium confidence: IgakuQA benchmark results due to limited performance breakdown
- Medium confidence: Domain specialization claims based on available benchmarking data

## Next Checks
1. Conduct detailed error analysis on IgakuQA benchmark failures to identify specific knowledge gaps
2. Evaluate model performance on rare disease diagnosis and complex clinical case scenarios
3. Analyze training data composition correlation with benchmark performance across medical subdomains