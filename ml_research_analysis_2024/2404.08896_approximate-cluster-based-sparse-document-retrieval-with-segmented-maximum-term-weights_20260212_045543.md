---
ver: rpa2
title: Approximate Cluster-Based Sparse Document Retrieval with Segmented Maximum
  Term Weights
arxiv_id: '2404.08896'
source_url: https://arxiv.org/abs/2404.08896
tags:
- retrieval
- cluster
- anytime
- document
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ASC (approximate cluster-based retrieval with
  segmented maximum term weights), a method for speeding up sparse document retrieval.
  The approach partitions the inverted index into clusters and uses segmented maximum
  term weights within each cluster to improve rank score bound estimation and enable
  more aggressive pruning of low-scoring documents.
---

# Approximate Cluster-Based Sparse Document Retrieval with Segmented Maximum Term Weights

## Quick Facts
- arXiv ID: 2404.08896
- Source URL: https://arxiv.org/abs/2404.08896
- Reference count: 40
- Primary result: ASC achieves 1.5-3x speedup over MaxScore while maintaining similar relevance scores

## Executive Summary
This paper presents ASC (approximate cluster-based retrieval with segmented maximum term weights), a method for accelerating sparse document retrieval. The approach partitions the inverted index into clusters and uses segmented maximum term weights within each cluster to improve rank score bound estimation and enable more aggressive pruning of low-scoring documents. ASC introduces two parameters (μ, η) to control the rank-safeness competitiveness of pruning, with η=1 providing probabilistic safety guarantees. The method is evaluated on MS MARCO and BEIR datasets with three learned sparse retrieval models (SPLADE, uniCOIL, LexMAE).

## Method Summary
ASC partitions the inverted index into clusters and uses segmented maximum term weights within each cluster to improve rank score bound estimation and enable more aggressive pruning of low-scoring documents. The method introduces two parameters (μ, η) to control the rank-safeness competitiveness of pruning, with η=1 providing probabilistic safety guarantees. By estimating upper bounds on document scores more accurately through segmented maximum term weights, ASC can prune more documents while maintaining retrieval effectiveness.

## Key Results
- ASC achieves 1.5-3x speedup compared to the original MaxScore algorithm
- Maintains similar relevance scores while improving retrieval speed
- Outperforms baseline approaches in both speed and effectiveness
- Compatible with other efficiency optimization techniques like early termination and static index pruning

## Why This Works (Mechanism)
ASC works by improving the estimation of upper bounds on document scores through segmented maximum term weights. Traditional maximum term weight approaches can overestimate document scores, leading to insufficient pruning. By segmenting the maximum term weights within each cluster, ASC creates tighter upper bounds that enable more aggressive pruning without sacrificing retrieval quality. The two parameters (μ, η) provide control over the trade-off between speed and retrieval accuracy.

## Foundational Learning
- **Inverted Index Structure**: Why needed - fundamental to understanding how documents are stored and retrieved. Quick check - can identify document-term relationships and posting lists.
- **Maximum Term Weight**: Why needed - core concept for score upper bound estimation. Quick check - understands how maximum weights affect pruning decisions.
- **Cluster-based Partitioning**: Why needed - enables more efficient pruning through localized score bounds. Quick check - can explain benefits of dividing index into clusters.
- **Rank-safeness**: Why needed - ensures retrieval quality isn't compromised by aggressive pruning. Quick check - understands trade-off between speed and accuracy.

## Architecture Onboarding

Component Map:
Index -> Clusters -> Segmented Maximum Weights -> Score Bound Estimation -> Document Pruning

Critical Path:
Query processing begins with cluster identification, followed by segmented maximum weight calculation, score bound estimation, and finally document pruning based on estimated bounds.

Design Tradeoffs:
- Speed vs. accuracy through μ and η parameters
- Cluster size vs. pruning effectiveness
- Memory overhead of maintaining segmented weights vs. computational savings

Failure Signatures:
- Too aggressive pruning (low μ, η) leading to loss of relevant documents
- Insufficient pruning (high μ, η) resulting in minimal speed gains
- Incorrect cluster partitioning causing poor score bound estimation

First Experiments:
1. Baseline comparison with MaxScore on MS MARCO dataset
2. Parameter sensitivity analysis for μ and η
3. Evaluation with different learned sparse models (SPLADE, uniCOIL, LexMAE)

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Modest speedup (1.5-3x) compared to more recent index pruning methods
- Limited testing across different learned sparse models
- Uncertainty about real-world applicability and scalability

## Confidence
- **High**: The correctness of the rank-safeness theoretical framework and the μ=η=1 configuration providing probabilistic safety guarantees.
- **Medium**: The empirical speedup claims of 1.5-3x over MaxScore and the effectiveness of the segmented maximum term weights scheme.
- **Low**: The generalizability of results across different learned sparse models and the comparative advantage over more recent index pruning methods.

## Next Checks
1. Evaluate ASC with a broader range of learned sparse models beyond SPLADEv2, including newer models like SPLADEv3 and ColBERTv2.
2. Conduct head-to-head comparisons with recent index pruning methods (DeeperImpact, Cluster Pruning) on the same hardware and evaluation setup.
3. Test the scalability of ASC on larger datasets (beyond MS MARCO) and with different query distributions to assess real-world applicability.