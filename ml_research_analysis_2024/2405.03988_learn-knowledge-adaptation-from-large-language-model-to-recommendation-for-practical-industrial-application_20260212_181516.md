---
ver: rpa2
title: 'LEARN: Knowledge Adaptation from Large Language Model to Recommendation for
  Practical Industrial Application'
arxiv_id: '2405.03988'
source_url: https://arxiv.org/abs/2405.03988
tags:
- user
- recommendation
- item
- learn
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes LEARN, a framework that adapts large language
  models (LLMs) to recommendation systems by extracting item text embeddings with
  a frozen LLM and aligning them to collaborative embeddings via twin-tower architecture
  and contrastive learning. This approach overcomes the limitations of ID-based embeddings
  and addresses the domain gap between open-world LLM knowledge and recommendation
  tasks.
---

# LEARN: Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application

## Quick Facts
- arXiv ID: 2405.03988
- Source URL: https://arxiv.org/abs/2405.03988
- Reference count: 9
- LEARN adapts LLMs to recommendation systems via twin-tower architecture and contrastive learning, achieving 13.95% average improvement in Recall@10 and 0.84pp AUC gain in online A/B tests.

## Executive Summary
LEARN is a framework that adapts large language models (LLMs) to recommendation systems by extracting item text embeddings with a frozen LLM and aligning them to collaborative embeddings via twin-tower architecture and contrastive learning. This approach overcomes the limitations of ID-based embeddings and addresses the domain gap between open-world LLM knowledge and recommendation tasks. The method demonstrates state-of-the-art performance on both public benchmarks and large-scale industrial datasets, with significant online A/B test results showing improved user engagement and revenue.

## Method Summary
LEARN uses a frozen LLM as a content extractor to generate item embeddings, then employs twin-tower architecture where both user and item towers have CEX and PAL modules. The PAL modules project content embeddings into collaborative embeddings using contrastive learning with the recommendation task as supervision. The framework implements sample weighting to prioritize recent items and includes two variants for the item tower: one using causal attention and one using self-attention. Training uses contrastive loss with sample weighting, while inference feeds user and item embeddings to an online ranking model.

## Key Results
- Average 13.95% improvement in Recall@10 on Amazon Review datasets compared to state-of-the-art baselines
- 0.84pp AUC gain in online A/B tests on short-video platform with 10% revenue uplift
- LEARN shows superior performance for cold-start and long-tail users/items compared to traditional ID-based methods

## Why This Works (Mechanism)

### Mechanism 1
LEARN overcomes the domain gap between LLM open-world knowledge and collaborative recommendation knowledge by projecting content embeddings into collaborative embeddings via twin-tower architecture and contrastive learning. The framework uses a frozen LLM to extract item content embeddings, then applies twin-tower architecture where both user and item towers have CEX and PAL modules. The PAL modules project content embeddings into collaborative embeddings using contrastive learning with the recommendation task as supervision.

### Mechanism 2
Freezing LLM parameters prevents catastrophic forgetting of open-world knowledge while still enabling effective adaptation to recommendation tasks. LEARN keeps the pretrained LLM parameters frozen during training, using it only as a content extractor rather than fine-tuning it on recommendation data. This preserves the LLM's general knowledge while adapting to the recommendation domain.

### Mechanism 3
LEARN's sample weighting strategy prioritizes recent items to capture current user interests, improving recommendation performance for cold-start and long-tail users/items. The framework implements a two-stage sampling strategy where recent items receive higher weights using the formula: wi = log(α + i · β − α) / (N − 1), with α=10 and β=10000.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: LEARN uses contrastive learning to align content embeddings from the LLM domain with collaborative embeddings in the recommendation domain by maximizing similarity between positive pairs while minimizing similarity with negative pairs
  - Quick check question: What is the key difference between contrastive learning and traditional supervised learning in the context of LEARN's alignment approach?

- Concept: Catastrophic forgetting
  - Why needed here: Understanding catastrophic forgetting explains why LEARN freezes LLM parameters rather than fine-tuning them, preserving the LLM's open-world knowledge while still adapting to recommendation tasks
  - Quick check question: Why might fine-tuning a pretrained LLM on recommendation data lead to worse performance than freezing it?

- Concept: Twin-tower architecture
  - Why needed here: LEARN employs twin-tower architecture to separately process user history and target items, then align their embeddings through contrastive learning for effective recommendation
  - Quick check question: How does twin-tower architecture differ from single-tower approaches in handling user-item interactions?

## Architecture Onboarding

- Component map: User history text → CEX module (frozen LLM + pooling) → PAL module (content adaptor + transformer + projection layers) → user embeddings; Target item text → CEX module (frozen LLM + pooling) → PAL module (content adaptor + transformer + projection layers) → item embeddings

- Critical path: Item text description → CEX module (frozen LLM) → content embeddings → PAL module → item embeddings → contrastive loss → optimization

- Design tradeoffs:
  - Freezing LLM vs fine-tuning: Preserves open-world knowledge but may limit task-specific adaptation
  - Twin-tower vs single-tower: Better separation of user and item processing but requires alignment mechanism
  - Sample weighting vs random sampling: Captures recent interests but may overemphasize recency

- Failure signatures:
  - Poor performance despite high-quality LLM embeddings: Domain gap alignment failure
  - Degradation in general knowledge tasks: Catastrophic forgetting from inappropriate fine-tuning
  - Overemphasis on recent items: Sample weighting too aggressive

- First 3 experiments:
  1. Baseline comparison: Run LEARN vs frozen LLM embeddings without alignment to verify domain gap exists
  2. Fine-tuning ablation: Compare LEARN with fine-tuned LLM variant to confirm catastrophic forgetting
  3. Sampling strategy test: Compare LEARN with random sampling vs sample weighting to validate recency importance

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions but implies several through its limitations discussion. Key unanswered questions include how LEARN's performance scales with longer user sequences, the impact on cold-start performance for entirely new items, and computational efficiency comparisons to traditional ID-based models during inference.

## Limitations
- Domain gap bridging mechanism lacks detailed ablation studies showing exact contribution of alignment versus other factors
- Catastrophic forgetting argument is theoretical without empirical evidence comparing frozen vs fine-tuned approaches
- Sample weighting strategy's effectiveness may be dataset-specific and not generalize across all recommendation domains

## Confidence
- **High confidence**: The twin-tower architecture design and the general approach of using frozen LLM embeddings are well-supported by experimental results
- **Medium confidence**: The domain gap bridging mechanism is plausible but lacks detailed ablation studies isolating alignment contribution
- **Low confidence**: The catastrophic forgetting argument is largely theoretical without direct empirical validation

## Next Checks
1. Ablation study on alignment contribution: Compare LEARN with and without PAL module alignment to quantify exact performance improvement from domain gap bridging
2. Catastrophic forgetting empirical test: Train LEARN with fine-tuned LLM parameters and compare performance on both recommendation tasks and general language understanding tasks
3. Cross-domain sample weighting validation: Test sample weighting strategy on datasets with different recency patterns to determine generalizability beyond tested short-video platform