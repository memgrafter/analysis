---
ver: rpa2
title: 'Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4
  to test BERT'
arxiv_id: '2405.02024'
source_url: https://arxiv.org/abs/2405.02024
tags:
- language
- transformer
- different
- bert
- blocks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the mechanisms of language processing in
  large language models (LLMs) by analyzing the activation patterns of BERT's hidden
  units when processing narratives with varying writing styles. We used ChatGPT to
  generate seven stylistic variations of ten Aesop's fables, which were then fed into
  BERT.
---

# Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT

## Quick Facts
- arXiv ID: 2405.02024
- Source URL: https://arxiv.org/abs/2405.02024
- Reference count: 40
- Primary result: BERT's earlier layers specialize in processing writing style while later layers specialize in processing narrative content

## Executive Summary
This study investigates how BERT processes narrative content and writing styles by analyzing activation patterns across its transformer layers. Using ChatGPT-generated stylistic variations of Aesop's fables, researchers found that BERT's earlier layers (particularly layer 1) cluster according to writing style, while later layers (4-5) cluster according to narrative content. This layer-wise specialization suggests that different parts of the transformer architecture are specialized for processing distinct linguistic properties. The findings provide insights into the internal mechanisms of LLMs and suggest potential models for understanding human language processing.

## Method Summary
The researchers used ChatGPT to generate seven stylistic variations of ten Aesop's fables, creating 70 narratives total. These narratives were processed by BERT base model without fine-tuning, and CLS token activations were extracted from all 12 transformer blocks. Multi-dimensional scaling (MDS) was applied to project high-dimensional activation vectors into 2D space for visualization. The study calculated two metrics - Entropy of Distance Distribution (EDD) and Generalized Discrimination Value (GDV) - to quantify clustering patterns. EDD measured label-free clustering isotropy, while GDV quantified how well representations clustered according to predefined labels (style or content).

## Key Results
- BERT's earlier layers (layer 1) show clustering according to writing style variations
- Later layers (4-5) show clustering according to narrative content rather than style
- The GDV metric effectively quantifies class separation in high-dimensional representations
- Different layers of BERT demonstrate specialization for processing specific language properties

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BERT's earlier layers specialize in processing writing style while later layers specialize in processing narrative content.
- Mechanism: The activation vectors of BERT's hidden units cluster differently across layers, with stylistic variations clustering in earlier layers (layer 1) and narrative content clustering in later layers (layers 4-5).
- Core assumption: Different layers of BERT perform distinct processing tasks despite having identical building blocks.
- Evidence anchors:
  - [abstract] "We found that the activation vectors of the hidden units cluster according to stylistic variations in earlier layers of BERT (1) than narrative content (4-5)."
  - [section] "We found that writing style is processed in earlier transformer blocks (block: 1) than the semantic content (block: 4-5), which means that the transformer blocks of BERT are specialized to perform certain tasks of language processing."
  - [corpus] Weak evidence - the corpus contains related studies but none specifically confirm the layer-wise specialization for style vs content.
- Break condition: If subsequent experiments show no clear distinction in clustering patterns between layers for different linguistic properties.

### Mechanism 2
- Claim: The GDV (Generalized Discrimination Value) effectively quantifies how well CLS token vectors cluster according to predefined labels (style or content).
- Mechanism: GDV measures class separation in high-dimensional representations, with lower values indicating better clustering according to labels.
- Core assumption: GDV is a reliable metric for quantifying class separation in neural network representations.
- Evidence anchors:
  - [abstract] "the generalized discrimination value (GDV , [40], [43]–[47]) were calculated from the distance matrices derived from the high dimensional data in order to quantify the degree of clustering."
  - [section] "The GDV , however, quantifies how well high-dimensional representations cluster according to given labels."
  - [corpus] Moderate evidence - related studies use similar probing techniques but may not directly validate GDV for this specific application.
- Break condition: If GDV values do not correlate with visual inspection of clustering patterns or fail to distinguish between different types of linguistic properties.

### Mechanism 3
- Claim: Using GPT-4 to generate stylistically varied narratives provides controlled input for analyzing BERT's processing mechanisms.
- Mechanism: ChatGPT generates multiple stylistic variations of the same narratives, allowing researchers to isolate the effect of writing style on BERT's internal representations.
- Core assumption: GPT-4 can reliably produce distinct stylistic variations while maintaining consistent semantic content.
- Evidence anchors:
  - [abstract] "we have used ChatGPT to generate seven different stylistic variations of ten different narratives (Aesop's fables)."
  - [section] "The rephrased fable is double-checked to be sure that the fable does fulfill all needed requirements (length, content etc.)."
  - [corpus] Weak evidence - the corpus contains studies using LLMs for narrative analysis but doesn't specifically address the reliability of style variation generation.
- Break condition: If stylistic variations are not distinct enough to produce measurable differences in BERT's layer-wise processing.

## Foundational Learning

- Concept: Multi-dimensional scaling (MDS)
  - Why needed here: MDS projects high-dimensional CLS token vectors into 2D space for visualization and analysis of clustering patterns.
  - Quick check question: What is the primary purpose of using MDS in this study?

- Concept: Entropy of Distance Distribution (EDD)
  - Why needed here: EDD quantifies whether points are distributed isotropically or form clusters independently of labels, providing a label-free measure of clustering.
  - Quick check question: How does EDD differ from GDV in terms of clustering quantification?

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Understanding how BERT's 12 identical transformer blocks process input is crucial for interpreting layer-wise specialization results.
  - Quick check question: What is the role of attention heads within each transformer block?

## Architecture Onboarding

- Component map: Input narratives → GPT-4 (style variation generation) → BERT (processing) → CLS token extraction → MDS projection → GDV/EDD calculation → Visualization and analysis
- Critical path: The sequence from generating stylistically varied narratives to extracting and analyzing CLS tokens is critical for the study's results.
- Design tradeoffs: Using pre-trained BERT vs. fine-tuning for this specific task; choosing MDS over other dimensionality reduction techniques.
- Failure signatures: Inconsistent clustering patterns across layers; GDV values not correlating with visual inspection; failure to distinguish between style and content processing.
- First 3 experiments:
  1. Generate a small set of narratives with clear stylistic differences and verify distinct clustering in early layers.
  2. Test whether semantic content becomes more prominent in later layers by analyzing narratives with similar styles but different content.
  3. Validate the reliability of GDV as a clustering metric by comparing its results with alternative methods on the same dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the representations of writing style and semantic content interact and combine in the later transformer blocks of BERT?
- Basis in paper: [explicit] The paper states that "in the last attention blocks of BERT, the CLS tokens cluster according to content as well as style, so that in both cases the GDV decreases again in the last transformer blocks."
- Why unresolved: The paper does not provide a detailed analysis of how these representations interact and combine in the later blocks, only that they both influence the final representation.
- What evidence would resolve it: Further analysis of the activation patterns in the later transformer blocks, potentially using techniques like probing classifiers or visualizing the attention patterns, could reveal how the representations of style and content are integrated.

### Open Question 2
- Question: Can the findings on the specialization of transformer blocks for style and content processing be generalized to other language models or tasks?
- Basis in paper: [inferred] The paper suggests that "different layers of the transformer process language differently and are specialized on certain properties of language," but this is based on a specific model (BERT) and task (narrative processing).
- Why unresolved: The study only examines one model and one type of task. It is unclear whether similar patterns of specialization would be observed in other language models or when processing different types of linguistic information.
- What evidence would resolve it: Replicating the study with different language models (e.g., GPT-3, RoBERTa) and tasks (e.g., sentiment analysis, machine translation) would help determine the generalizability of the findings.

### Open Question 3
- Question: How do the findings on the processing of style and content in BERT relate to the neural mechanisms of language processing in the human brain?
- Basis in paper: [explicit] The paper aims to "use LLMs as a model to understand fundamental mechanisms of language processing in neural networks, in order to make predictions and generate hypotheses on how the human brain does language processing."
- Why unresolved: While the paper suggests that the specialization of transformer blocks in BERT might be a "useful model of the human brain," it does not provide direct evidence for this claim or explain the specific mechanisms by which the two systems might be similar.
- What evidence would resolve it: Comparing the activation patterns in BERT with neuroimaging data from humans processing language, particularly focusing on the processing of style and content, could provide insights into the similarities and differences between the two systems.

## Limitations

- The study relies on narratives generated by ChatGPT, which introduces potential variability in style consistency that isn't directly validated
- The analysis focuses solely on BERT without examining whether similar patterns emerge in other transformer architectures
- While the GDV metric shows promise, its reliability as a clustering quantification tool hasn't been thoroughly validated against alternative methods

## Confidence

- Layer-wise specialization claims: Medium
- GDV metric reliability: Medium
- Style vs content separation: Medium
- Cross-model generalizability: Low

## Next Checks

1. Validate the distinctness of ChatGPT-generated stylistic variations through human annotation or alternative style detection methods
2. Test whether similar layer-wise clustering patterns emerge when using different dimensionality reduction techniques (t-SNE, UMAP) on the same dataset
3. Apply the same analysis pipeline to a different transformer model (e.g., RoBERTa) to assess generalizability of findings