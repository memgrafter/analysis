---
ver: rpa2
title: 'Homomorphism Counts for Graph Neural Networks: All About That Basis'
arxiv_id: '2402.08595'
source_url: https://arxiv.org/abs/2402.08595
tags:
- graph
- counts
- graphs
- homomorphism
- spasm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the expressive power of graph neural networks
  by analyzing how well they can count certain graph patterns. It shows that adding
  homomorphism basis counts as features is more expressive than adding subgraph or
  homomorphism counts of the target pattern.
---

# Homomorphism Counts for Graph Neural Networks: All About That Basis

## Quick Facts
- arXiv ID: 2402.08595
- Source URL: https://arxiv.org/abs/2402.08595
- Authors: Emily Jin; Michael Bronstein; İsmail İlkan Ceylan; Matthias Lanzinger
- Reference count: 40
- Key outcome: Adding homomorphism basis counts as features is more expressive than adding subgraph or homomorphism counts of target patterns, with theoretical proofs and empirical improvements in molecular property prediction and link prediction tasks.

## Executive Summary
This paper addresses the expressive limitations of graph neural networks by introducing homomorphism basis counts as features. The authors prove that counting homomorphisms from a carefully selected basis of smaller graph patterns can capture complex graph motifs more efficiently than directly counting the target patterns themselves. This approach provides a theoretically grounded method for enhancing GNN expressiveness while maintaining computational efficiency, offering significant improvements over existing methods in molecular property prediction and link prediction tasks.

## Method Summary
The method introduces homomorphism basis counts as features for graph neural networks, where a basis of smaller graph patterns is selected such that any target graph motif can be expressed as a linear combination of homomorphisms from these basis patterns. The approach leverages homomorphism algebra to systematically construct these bases and compute the linear transformation coefficients. This framework is implemented as a feature augmentation layer that can be integrated into existing GNN architectures, providing a principled way to enhance expressiveness without requiring architectural modifications.

## Key Results
- Homomorphism basis counts are strictly more expressive than direct subgraph or homomorphism counting of target patterns
- The method achieves significant improvements in molecular property prediction on ZINC and ChEMBL datasets
- Computational efficiency is maintained through the linear transformation framework, enabling tractable computation even for larger patterns

## Why This Works (Mechanism)
The mechanism works because graph motifs can be decomposed into linear combinations of homomorphisms from smaller basis patterns. This algebraic structure allows the network to capture complex structural relationships through a compact set of features, avoiding the redundancy and computational overhead of directly counting large patterns. The basis selection ensures that all necessary information for distinguishing non-isomorphic graphs is preserved while eliminating redundant features.

## Foundational Learning

**Homomorphisms vs Subgraphs**: Homomorphisms allow edge reuse and are more flexible than subgraph counts. Needed to understand why homomorphism counting is more expressive. Quick check: Can a cycle of length 4 be counted using only homomorphism counts from triangles and edges?

**Graph Isomorphism Testing**: Understanding when two graphs cannot be distinguished by certain features. Needed to establish the expressiveness guarantees. Quick check: If two graphs have identical homomorphism basis counts, are they necessarily isomorphic?

**Linear Algebra over Graph Features**: How graph properties can be expressed as linear combinations of basis elements. Needed to understand the transformation from basis counts to target pattern counts. Quick check: Verify that the cycle count formula in terms of homomorphism counts is correct for small graphs.

## Architecture Onboarding

**Component Map**: Input Graph -> Homomorphism Basis Computation -> Linear Transformation Layer -> GNN Architecture -> Output

**Critical Path**: The homomorphism basis computation and linear transformation layer are critical for feature generation, followed by standard GNN processing for task-specific learning.

**Design Tradeoffs**: The method trades some computational overhead for homomorphism basis computation against significant gains in expressiveness and reduced redundancy compared to direct pattern counting.

**Failure Signatures**: Poor performance may occur when the selected basis is insufficient to distinguish the graph structures relevant to the task, or when the linear transformation coefficients are not well-suited to the target domain.

**First Experiments**: 
1. Verify homomorphism basis counts distinguish non-isomorphic graphs on small synthetic datasets
2. Compare runtime of homomorphism basis computation versus direct pattern counting on graphs of varying sizes
3. Test expressiveness on graph classification tasks with known structural differences

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

- Theoretical framework assumes fixed-size graphs and may need adaptation for very large or variable-sized graphs
- Experimental validation is limited in scale, particularly for expressiveness benchmarks which only test a small set of target motifs
- No negative results or failure cases where the approach underperforms traditional methods are presented

## Confidence

**High confidence** in theoretical expressiveness claims, supported by formal proofs and consistency with homomorphism theory
**High confidence** in computational efficiency claims, validated through both theoretical analysis and empirical benchmarks
**Medium confidence** in empirical performance improvements due to limited dataset diversity and scale of experiments

## Next Checks

1. Evaluate scalability on graphs with 10,000+ nodes to empirically verify computational efficiency claims and identify performance bottlenecks
2. Test the approach on additional molecular datasets beyond ZINC and ChEMBL to validate generalizability across different molecular size distributions and property types
3. Systematically test the method's ability to distinguish non-isomorphic graphs across a broader range of graph families to more thoroughly validate theoretical expressiveness claims