---
ver: rpa2
title: 'Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy'
arxiv_id: '2411.03513'
source_url: https://arxiv.org/abs/2411.03513
tags:
- slicing
- layers
- layer
- slicegpt
- dynamic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a dynamic layer-specific pruning approach for
  large language models (LLMs) that improves upon the constant slicing method of SliceGPT.
  The key innovation is the Layer Redundancy (LR) score, which measures how much each
  layer changes its input using cosine similarity between inputs and outputs.
---

# Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy

## Quick Facts
- arXiv ID: 2411.03513
- Source URL: https://arxiv.org/abs/2411.03513
- Reference count: 32
- Primary result: Dynamic layer-specific pruning outperforms constant slicing, achieving up to 5% better accuracy and 7% lower perplexity across multiple benchmarks

## Executive Summary
This paper introduces a dynamic layer-specific pruning approach for large language models (LLMs) that improves upon the constant slicing method of SliceGPT. The key innovation is the Layer Redundancy (LR) score, which measures how much each layer changes its input using cosine similarity between inputs and outputs. This score guides variable pruning of individual layers while maintaining a fixed average pruning percentage across all layers. Experiments on Llama3-8B and Mistral-7B demonstrate that dynamic slicing outperforms constant slicing, achieving up to 5% better accuracy and 7% lower perplexity across multiple benchmarks.

## Method Summary
The method computes Layer Redundancy (LR) scores by measuring cosine similarity between layer inputs and outputs using validation data. These scores are then scaled to achieve a target average pruning percentage (SP) while preserving a base percentage (SB) for all layers, creating per-layer slicing percentages. The variable slicing percentages are applied to each layer using SliceGPT's PCA-based compression method. The approach maintains fixed average pruning while allowing more aggressive pruning of redundant layers and less pruning of important layers, ultimately improving model performance compared to uniform pruning approaches.

## Key Results
- Dynamic slicing achieves up to 5% better accuracy across five evaluated datasets compared to constant slicing
- Perplexity decreases by as much as 1.4 points when using dynamic layer-specific pruning
- The method shows consistent improvements across both Llama3-8B and Mistral-7B models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layer redundancy scores enable dynamic layer pruning that adapts to individual layer contributions rather than applying uniform pruning across all layers.
- Mechanism: The Layer Redundancy (LR) score measures cosine similarity between layer inputs and outputs, identifying which layers change their input less (more redundant). Higher redundancy layers can be pruned more aggressively while preserving critical layers, maintaining performance with less overall pruning.
- Core assumption: Layers with higher cosine similarity between input and output are more redundant and can be pruned more without significant performance loss.
- Evidence anchors:
  - [abstract] "The key innovation is the Layer Redundancy (LR) score, which measures how much each layer changes its input using cosine similarity between inputs and outputs."
  - [section 3.1] "We define this as the Layer Redundancy (LR) score: LR(Li) = LI_i Â· LO_i / (||LI_i|| ||LO_i||)"
  - [corpus] Weak evidence - only one related paper mentions "redundant nature" of layers but doesn't discuss layer redundancy scoring

### Mechanism 2
- Claim: Dynamic slicing maintains fixed average pruning percentage while allowing variable layer-specific pruning percentages.
- Mechanism: The method scales LR scores to achieve a target average pruning percentage (SP) while preserving a base percentage (SB) for all layers. This creates per-layer slicing percentages that sum to the desired total while allowing more aggressive pruning of redundant layers.
- Core assumption: It's possible to maintain performance while varying pruning percentages across layers as long as the average remains fixed.
- Evidence anchors:
  - [section 3.2] "Our goal is to have a function that slices variable sized parts of each layers based on their LR score while keeping the overall average of sliced out parts across all layers to be a fixed percentage"
  - [abstract] "This score guides variable pruning of individual layers while maintaining a fixed average pruning percentage across all layers"
  - [corpus] No direct evidence - corpus papers don't discuss fixed average pruning with variable per-layer percentages

### Mechanism 3
- Claim: Layer redundancy pruning outperforms constant slicing methods by preserving functionality in critical layers.
- Mechanism: By pruning more from redundant layers and less from important layers based on LR scores, the method maintains better model accuracy and lower perplexity compared to uniform pruning approaches like SliceGPT.
- Core assumption: Dynamic allocation of pruning based on layer importance preserves more model functionality than uniform pruning.
- Evidence anchors:
  - [abstract] "Experiments on Llama3-8B and Mistral-7B demonstrate that dynamic slicing outperforms constant slicing, achieving up to 5% better accuracy and 7% lower perplexity"
  - [section 5] "Figure 2 shows the behaviors of Llama3-8b and Mistral-7b... the accuracy is improved across all of the 5 evaluated datasets, and the perplexity decreases by as much as 1.4"
  - [corpus] Weak evidence - corpus papers mention "redundant nature" but don't compare dynamic vs constant slicing performance

## Foundational Learning

- Concept: Cosine similarity and its interpretation in neural network layers
  - Why needed here: The LR score fundamentally relies on measuring cosine similarity between layer inputs and outputs to quantify redundancy
  - Quick check question: If layer input vector is [1, 2, 3] and output vector is [2, 4, 6], what is their cosine similarity and what does this imply about layer redundancy?

- Concept: Principal Component Analysis (PCA) for dimensionality reduction
  - Why needed here: The slicing method uses a specialized version of PCA to compress layer representations by selectively omitting components
  - Quick check question: In PCA-based compression, if we have 100 principal components and keep only the top 10, what percentage of the original dimensionality are we preserving?

- Concept: Model pruning and its impact on model performance
  - Why needed here: Understanding how removing parameters affects accuracy and perplexity is crucial for interpreting the experimental results
  - Quick check question: If a model has 7 billion parameters and we prune 30%, how many parameters remain, and what typical performance degradation might we expect based on literature?

## Architecture Onboarding

- Component map:
  - LR score calculator: Computes cosine similarity between layer inputs/outputs using validation data
  - LR scaler: Transforms raw LR scores to achieve target average pruning percentage
  - Layer slicer: Applies variable PCA-based compression to each layer based on computed slicing percentages
  - Evaluation pipeline: Measures accuracy and perplexity across multiple benchmarks
  - Configuration manager: Handles different model architectures (Llama3-8B, Mistral-7B) and pruning ratios

- Critical path:
  1. Compute LR scores for all layers using validation data
  2. Scale LR scores to achieve target average pruning percentage
  3. Apply variable layer-specific slicing using PCA-based compression
  4. Evaluate pruned model on benchmarks
  5. Compare against baseline constant slicing

- Design tradeoffs:
  - Fixed average pruning vs. optimal layer-specific pruning: Maintaining fixed average enables fair comparison but may limit optimal performance
  - Validation data choice: Using pg-19 validation set for LR computation vs. task-specific data
  - Computational cost: Computing LR scores requires full validation pass but only needs to be done once per model

- Failure signatures:
  - Performance worse than constant slicing: Indicates LR scores don't correlate with actual layer importance
  - Extremely uneven pruning distribution: Suggests LR score scaling needs adjustment
  - High perplexity despite good accuracy: Indicates text generation quality degradation

- First 3 experiments:
  1. Run constant slicing (SB=SP) as baseline to verify implementation matches SliceGPT results
  2. Implement LR score computation and verify cosine similarity values make intuitive sense (high for redundant layers, low for important layers)
  3. Test dynamic slicing with SP=30%, SB=10% on Llama3-8B and compare accuracy/perplexity against baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Layer Redundancy (LR) score correlate with other layer importance metrics such as spectral analysis or gradient-based methods?
- Basis in paper: [explicit] The paper mentions that SliceGPT's initial attempts to implement dynamic pruning through spectral analysis did not yield a reliable method, and that the LR score is a new metric introduced in this work.
- Why unresolved: The paper does not compare the LR score with other established layer importance metrics, leaving open the question of whether LR is more effective or if it captures different aspects of layer importance.
- What evidence would resolve it: Empirical studies comparing LR scores with spectral analysis, gradient-based methods, or other importance metrics on the same models and datasets, showing which metric better predicts layer redundancy and pruning performance.

### Open Question 2
- Question: Can the dynamic slicing method be effectively extended to hybrid approaches that combine layer removal with partial layer pruning, such as removing the least important layers completely and applying dynamic slicing to moderately important layers?
- Basis in paper: [explicit] The paper suggests that variable slicing scaled from layer importance can be easily extended and merged with techniques like ShortGPT by removing the least important layers completely and slicing moderately important layers using the proposed approach.
- Why unresolved: The paper does not provide experimental results or analysis of such hybrid methods, leaving open the question of whether combining layer removal with partial pruning would enhance model efficiency and performance.
- What evidence would resolve it: Experimental results comparing hybrid methods (combining layer removal and partial pruning) with the current dynamic slicing approach, showing improvements in accuracy, perplexity, and computational efficiency.

### Open Question 3
- Question: What is the optimal method for selecting the Slice Base (SB) value, beyond using the minimum perplexity on a calibration dataset like Wikitextv2?
- Basis in paper: [explicit] The paper notes that they only experiment with one method to choose the SB value (that gives lowest perplexity) and there can be other methods for estimating SB which they leave for future work.
- Why unresolved: The paper does not explore alternative methods for selecting SB, such as using task-specific validation sets or cross-validation, leaving open the question of whether there are better ways to determine SB that could further improve model performance.
- What evidence would resolve it: Comparative studies using different SB selection methods (e.g., task-specific validation, cross-validation, or learning-based approaches) to determine which method consistently yields the best performance across various models and tasks.

## Limitations
- The approach assumes cosine similarity between layer inputs and outputs is a reliable proxy for layer redundancy, which may not capture all aspects of functional importance
- The method constrains variable per-layer pruning by maintaining a fixed average pruning percentage, potentially limiting optimal dynamic allocation
- LR scores are computed using a generic validation dataset (PG-19) rather than task-specific data, which may not accurately reflect layer importance for specific downstream tasks

## Confidence
- **High Confidence**: The experimental results showing dynamic slicing outperforms constant slicing (5% accuracy improvement, 7% perplexity reduction) are well-supported by the data presented in Figures 2 and 3
- **Medium Confidence**: The core mechanism of using cosine similarity to measure layer redundancy is intuitively sound but lacks strong theoretical justification for why this metric correlates with functional importance
- **Medium Confidence**: The LR score scaling approach to maintain fixed average pruning percentages while enabling variable per-layer pruning is mathematically sound but may not be optimal for all scenarios

## Next Checks
1. **Ablation Study**: Test dynamic slicing with SP=SP (no base percentage) to determine if the performance gains are primarily due to the variable allocation rather than the fixed average constraint

2. **Task-Specific LR Scores**: Compute LR scores using task-specific validation data for each benchmark rather than the generic PG-19 set to evaluate if this improves performance alignment with task requirements

3. **Layer Importance Correlation**: Conduct a controlled experiment comparing LR scores against other layer importance metrics (e.g., gradient-based importance, ablation studies) to validate that cosine similarity is indeed a good proxy for functional importance