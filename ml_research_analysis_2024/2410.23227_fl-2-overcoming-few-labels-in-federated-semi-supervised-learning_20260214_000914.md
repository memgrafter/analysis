---
ver: rpa2
title: '(FL)$^2$: Overcoming Few Labels in Federated Semi-Supervised Learning'
arxiv_id: '2410.23227'
source_url: https://arxiv.org/abs/2410.23227
tags:
- learning
- data
- clients
- federated
- labeled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the problem of Federated Semi-Supervised Learning\
  \ (FSSL) when labeled data is scarce, specifically addressing the significant performance\
  \ gap between FSSL and centralized SSL due to confirmation bias. The authors propose\
  \ (FL)\xB2, a method that employs three key strategies to mitigate this issue: (1)\
  \ client-specific adaptive thresholding adjusts pseudo-labeling thresholds based\
  \ on each client's learning progress, (2) sharpness-aware consistency regularization\
  \ applies consistency loss between original and adversarially perturbed model outputs\
  \ using high-confidence pseudo-labels, and (3) learning status-aware aggregation\
  \ assigns higher weights to clients with lower learning status during model aggregation."
---

# (FL)$^2$: Overcoming Few Labels in Federated Semi-Supervised Learning

## Quick Facts
- arXiv ID: 2410.23227
- Source URL: https://arxiv.org/abs/2410.23227
- Authors: Seungjoo Lee; Thanh-Long V. Le; Jaemin Shin; Sung-Ju Lee
- Reference count: 40
- One-line primary result: (FL)² achieves up to 23.0% higher accuracy than baselines in SVHN with 250 labels, and 22.2% higher accuracy in CIFAR10 with only 10 labels

## Executive Summary
This paper addresses the critical challenge of Federated Semi-Supervised Learning (FSSL) when labeled data is extremely scarce. The authors identify confirmation bias as the primary bottleneck preventing FSSL from achieving performance comparable to centralized SSL, particularly in resource-constrained settings. They propose (FL)², a three-pronged approach that adaptively adjusts pseudo-labeling thresholds, applies consistency regularization to high-confidence samples only, and uses learning status-aware model aggregation to mitigate confirmation bias and improve overall performance.

## Method Summary
(FL)² employs three key strategies to overcome confirmation bias in FSSL: (1) client-specific adaptive thresholding adjusts pseudo-labeling thresholds based on each client's learning progress, starting with low thresholds early in training and increasing them as confidence improves; (2) sharpness-aware consistency regularization applies consistency loss between original and adversarially perturbed model outputs using only high-confidence pseudo-labels to prevent error propagation; (3) learning status-aware aggregation assigns higher weights to clients with lower learning status during model aggregation, ensuring their updates are better reflected in the global model. The method is evaluated on CIFAR10, CIFAR100, and SVHN with 10-400 labeled samples using WideResNet architectures and shows consistent improvements over existing FSSL methods.

## Key Results
- Achieves up to 23.0% higher accuracy than baselines in SVHN with 250 labels
- Improves CIFAR10 accuracy by 22.2% with only 10 labels compared to existing methods
- Demonstrates consistent performance gains across both IID and non-IID (Dirichlet α=0.1, 0.3) client data distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Client-specific adaptive thresholding reduces confirmation bias by including more data early in training and focusing on high-confidence samples later
- Mechanism: The threshold τ k t starts low, allowing more unlabeled samples to be used for pseudo-labeling in early rounds. As training progresses, the threshold increases based on the client's learning status, improving pseudo-label quality
- Core assumption: Clients' learning progress can be profiled through their confidence in pseudo-labels, and this profile correlates with the quality of data they can contribute
- Evidence anchors:
  - [abstract] "We adaptively change the threshold according to the clients' learning status"
  - [section 4.1] "This approach sets a low initial threshold value, as the model exhibits lower confidence in the data at the beginning of training"
  - [corpus] Weak - no direct corpus support for this specific adaptive thresholding mechanism
- Break condition: If clients' learning statuses diverge significantly from their pseudo-label confidence, the threshold adjustment could become misaligned

### Mechanism 2
- Claim: Sharpness-aware consistency regularization improves generalization by regularizing only carefully selected high-confidence samples
- Mechanism: Instead of applying SAM to all pseudo-labeled data (which could propagate errors), the method perturbs weights using only high-confidence samples (τf threshold) and then enforces consistency between original and perturbed model outputs
- Core assumption: Incorrect pseudo-labels will not benefit from SAM's generalization and could harm the model if included
- Evidence anchors:
  - [abstract] "we apply consistency regularization to carefully selected data samples that are highly likely correct"
  - [section 4.2] "Generalization of incorrect data samples leads to the propagation of errors, thereby degrading the model's performance"
  - [corpus] Weak - related work mentions SAM-Fed but doesn't detail this specific consistency regularization approach
- Break condition: If the high-confidence threshold (τf) is too restrictive, too few samples may be used for regularization

### Mechanism 3
- Claim: Learning status-aware aggregation gives more weight to clients with lower learning status, ensuring their updates are better reflected in the global model
- Mechanism: Clients with lower thresholds (indicating lower learning status) receive higher aggregation weights βk t = 1−τ k t PK k=1(1−τ k t), allowing their more informative updates to have greater influence
- Core assumption: Clients with lower learning status have more room for improvement and their updates contain more valuable information for the global model
- Evidence anchors:
  - [abstract] "Clients with lower learning status receive higher aggregation weights, ensuring their updates are well reflected in the global model"
  - [section 4.3] "clients with lower thresholds, which indicate more valuable learning updates, are given a greater influence on the global model"
  - [corpus] Weak - no direct corpus support for this specific learning status-aware aggregation
- Break condition: If some clients consistently have very low learning status due to poor data quality, over-weighting them could degrade global model performance

## Foundational Learning

- Concept: Federated Learning (FL) - A distributed machine learning framework where clients train local models on their data and a server aggregates these models while preserving data privacy
  - Why needed here: The paper builds on FL framework to address semi-supervised learning with limited labeled data
  - Quick check question: What is the key privacy-preserving aspect of FL that distinguishes it from centralized learning?

- Concept: Semi-Supervised Learning (SSL) - A learning paradigm that leverages both labeled and unlabeled data to improve model performance
  - Why needed here: The paper extends SSL to the federated setting where labeled data is scarce
  - Quick check question: How does pseudo-labeling work in SSL, and what problem does it introduce?

- Concept: Confirmation Bias in SSL - The tendency of models to overfit to easy-to-learn samples or incorrectly pseudo-labeled data, especially pronounced in federated settings
  - Why needed here: This is the core problem the paper addresses through its three mechanisms
  - Quick check question: Why is confirmation bias more severe in FSSL compared to centralized SSL?

## Architecture Onboarding

- Component map: Server with labeled data -> Clients with unlabeled data -> Client-specific adaptive thresholding module -> Sharpness-aware consistency regularization module -> Learning status-aware aggregation module -> Updated global model
- Critical path: Server distributes global model → Clients generate pseudo-labels and train locally → Server aggregates models with adaptive weights → Repeat for multiple rounds
- Design tradeoffs: The adaptive thresholding introduces client-side computation overhead but improves data utilization. The consistency regularization adds complexity but prevents error propagation. The status-aware aggregation requires tracking client learning progress
- Failure signatures: If confirmation bias persists, test accuracy will plateau early. If thresholds are misconfigured, some clients may contribute poor updates. If aggregation weights are wrong, the global model may converge to suboptimal solutions
- First 3 experiments:
  1. Implement client-specific adaptive thresholding alone and compare pseudo-label accuracy and test accuracy against fixed threshold baseline
  2. Add sharpness-aware consistency regularization and measure its impact on test accuracy when applied to all vs. high-confidence samples only
  3. Implement learning status-aware aggregation and evaluate its effect on convergence speed and final accuracy compared to uniform aggregation

## Open Questions the Paper Calls Out

- Open Question 1: How does the proposed learning status-aware aggregation method perform in extreme non-IID scenarios where clients have completely disjoint label distributions?
- Open Question 2: What is the theoretical relationship between the sharpness-aware consistency regularization and the model's generalization ability in the federated setting?
- Open Question 3: How sensitive is (FL)²'s performance to the choice of perturbation strength ρ in sharpness-aware consistency regularization across different datasets and model architectures?
- Open Question 4: What is the impact of (FL)²'s computational overhead on resource-constrained clients compared to existing FSSL methods?
- Open Question 5: How does the proposed method scale with increasing number of clients and communication rounds in large-scale federated learning deployments?

## Limitations

- Heavy dependence on hyperparameter tuning (thresholds, perturbation magnitude, aggregation weights) which may not generalize well to different datasets
- Computational overhead from client-specific adaptive thresholding and sharpness-aware consistency regularization could be prohibitive for resource-constrained devices
- Evaluation primarily on image classification tasks without demonstrating effectiveness on other domains like NLP or tabular data

## Confidence

- Core mechanism effectiveness: High
- Generalization to non-image datasets: Low
- Computational efficiency claims: Medium
- Hyperparameter sensitivity: Medium

## Next Checks

1. Perform ablation study to measure individual contribution of each of the three mechanisms (adaptive thresholding, consistency regularization, status-aware aggregation) by removing them one at a time
2. Test the method on non-image datasets (e.g., text classification or tabular data) to evaluate cross-domain applicability
3. Conduct sensitivity analysis on key hyperparameters (τk thresholds, ρ perturbation magnitude, β aggregation weights) to identify robustness boundaries