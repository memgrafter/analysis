---
ver: rpa2
title: 'IMUDiffusion: A Diffusion Model for Multivariate Time Series Synthetisation
  for Inertial Motion Capturing Systems'
arxiv_id: '2411.02954'
source_url: https://arxiv.org/abs/2411.02954
tags:
- sequences
- synthetic
- class
- time
- classifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IMUDiffusion is a denoising diffusion probabilistic model specifically
  designed for generating synthetic multivariate time series data from inertial measurement
  units (IMUs) in human activity recognition. The model uses a UNet-based architecture
  with individual schedulers for accelerometer and gyroscope data, and processes sequences
  in the frequency domain via STFT to generate realistic human motion patterns.
---

# IMUDiffusion: A Diffusion Model for Multivariate Time Series Synthetisation for Inertial Motion Capturing Systems

## Quick Facts
- arXiv ID: 2411.02954
- Source URL: https://arxiv.org/abs/2411.02954
- Reference count: 26
- Primary result: 30% macro F1-score improvement in human activity recognition using synthetic IMU data

## Executive Summary
IMUDiffusion introduces a denoising diffusion probabilistic model specifically designed for generating synthetic multivariate time series data from inertial measurement units (IMUs) in human activity recognition. The model employs a UNet-based architecture with individual schedulers for accelerometer and gyroscope data, processing sequences in the frequency domain via STFT to generate realistic human motion patterns. When synthetic data from IMUDiffusion was combined with real IMU data, macro F1-scores in human activity classification improved by up to 30% in most cases, with performance exceeding or matching a baseline model trained on full real datasets in 11 out of 12 participants.

## Method Summary
IMUDiffusion is a denoising diffusion probabilistic model that generates synthetic IMU time series data for human activity recognition. The model uses a UNet-based architecture with 32 base channels and processes 160-timestep sequences from right-thigh IMUs at 50Hz. The approach transforms time series to the frequency domain using STFT (hanning window, length 22, overlap 20) before applying diffusion, with separate linear schedulers for accelerometer (β=9e-4) and gyroscope (β=6e-4) data. The model is trained for 4500 epochs on the Banos et al. dataset using smooth L1 loss, generating synthetic sequences that are evaluated through leave-one-subject-out cross-validation (LOSOCV) and measured by macro F1-score improvements in activity classification.

## Key Results
- Synthetic data addition improved macro F1-scores by up to 30% in most cases
- IMUDiffusion outperformed or matched baseline models trained on full real datasets in 11 out of 12 participants
- The model successfully addressed class imbalance and improved differentiation between similar activities like walking and running
- UMAP and k-means clustering with DTW validated the quality of generated sequences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IMUDiffusion can improve HAR performance by up to 30% macro F1-score when synthetic data is added to the training set.
- Mechanism: Synthetic sequences generated by IMUDiffusion provide additional variability and balance the dataset, especially for underrepresented classes like Jump Up and similar classes like Walking vs. Running.
- Core assumption: The synthetic sequences maintain realistic characteristics of the target activities while introducing diversity not present in the limited real dataset.
- Evidence anchors:
  - [abstract]: "by joining our dataset with synthetic data, we achieve a significant improvement in the performance of our baseline human activity classifier. In some cases, we are able to improve the macro F1-score by almost 30%."
  - [section]: "The synthetic sequences significantly improved the results for almost all participants, compared to the 2 Sample baseline classifier."
  - [corpus]: Limited direct evidence of 30% improvement in corpus papers; closest is general claims about diffusion models improving HAR performance.
- Break condition: If the synthetic sequences fail to capture the true dynamics of the activities or introduce artifacts that confuse the classifier.

### Mechanism 2
- Claim: Individual schedulers for accelerometer and gyroscope data improve the quality of synthetic multivariate time series.
- Mechanism: Different sensors have different noise characteristics and dynamics; using separate diffusion rates (βAcc = 9e−4, βGyro = 6e−4) allows the model to learn appropriate denoising processes for each sensor type.
- Core assumption: The accelerometer and gyroscope data have sufficiently different statistical properties that require different noise injection schedules.
- Evidence anchors:
  - [section]: "Another challenge was the identification of the optimal β value, as each sensor reacts differently on the scheduler. Therefore, we separated the linear schedulers diffusion rate β to match them individually."
  - [corpus]: Weak evidence in corpus; most diffusion papers use single schedulers without sensor-specific adaptation.
- Break condition: If the difference between sensor types is not significant enough to warrant separate schedulers, or if the model overfits to sensor-specific noise patterns.

### Mechanism 3
- Claim: Transforming time series to the frequency domain via STFT before diffusion improves the model's ability to capture periodic motion patterns.
- Mechanism: Human activities like walking and running have periodic components that are more easily modeled in the frequency domain; STFT provides a time-frequency representation that preserves temporal structure while revealing frequency content.
- Core assumption: The periodic nature of human activities is better represented in the frequency domain, making it easier for the diffusion model to learn and generate realistic sequences.
- Evidence anchors:
  - [section]: "Therefore, we transformed the initial signal to the frequency domain by computing the short time fourier transform (STFT)."
  - [corpus]: Limited evidence; most time series diffusion models work in the time domain. This appears to be a novel contribution.
- Break condition: If the STFT transformation loses critical temporal information or if the diffusion model struggles to work with complex-valued frequency representations.

## Foundational Learning

- Concept: Denoising Diffusion Probabilistic Models (DDPMs)
  - Why needed here: IMUDiffusion is based on DDPM architecture, which learns to reverse a gradual noising process to generate data from Gaussian noise.
  - Quick check question: What is the key difference between DDPMs and GANs in terms of training stability and mode coverage?

- Concept: Short-Time Fourier Transform (STFT)
  - Why needed here: The model uses STFT to transform IMU time series into the frequency domain before processing with the diffusion model.
  - Quick check question: Why is STFT preferred over a simple Fourier transform for non-stationary signals like human motion?

- Concept: Dynamic Time Warping (DTW)
  - Why needed here: DTW is used as a distance metric for k-means clustering of time series to compare real and synthetic sequences.
  - Quick check question: How does DTW handle temporal misalignments between similar motion patterns?

## Architecture Onboarding

- Component map: STFT preprocessing -> Noise injection via schedulers -> UNet denoising -> Inverse STFT -> Classification
- Critical path: STFT preprocessing → Noise injection via schedulers → UNet denoising → Inverse STFT → Classification
- Design tradeoffs:
  - Separate schedulers improve sensor-specific denoising but increase hyperparameter complexity
  - Frequency domain transformation captures periodicity but may lose some temporal resolution
  - 3000 timesteps provide smooth denoising but increase training time significantly
- Failure signatures:
  - Synthetic sequences that look realistic but fail to improve classifier performance
  - Mode collapse where generated sequences only cover a subset of real motion patterns
  - Overfitting to training participants when evaluated with LOSOCV
- First 3 experiments:
  1. Generate synthetic sequences for a single activity (e.g., Walking) and visualize both time and frequency domain representations to verify realistic patterns
  2. Train classifier with 0%, 1%, and 10% synthetic data additions to measure performance improvement curve
  3. Compare UMAP visualizations of real vs. synthetic sequences to assess distribution overlap and clustering patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the IMUDiffusion model perform when applied to different types of IMU sensors with varying sampling rates or sensor configurations?
- Basis in paper: [inferred] The paper mentions the model was tested with a specific six-axis IMU at 50 Hz, but does not explore performance across different sensor types or configurations.
- Why unresolved: The study focused on a single IMU setup, and no comparative analysis was provided for other sensor types or sampling rates.
- What evidence would resolve it: Testing the model with IMUs of different sampling rates, sensor axes, or configurations and comparing the generated sequence quality and classification performance.

### Open Question 2
- Question: What is the optimal number of synthetic sequences needed to achieve consistent improvements in classification performance without overfitting?
- Basis in paper: [explicit] The paper discusses the gradual addition of synthetic sequences but notes fluctuations in test score values, especially with small amounts of synthetic data.
- Why unresolved: While the paper adds synthetic sequences incrementally, it does not identify a clear threshold for optimal performance or address overfitting risks.
- What evidence would resolve it: Conducting experiments with varying amounts of synthetic data and analyzing the point at which classification performance plateaus or begins to degrade.

### Open Question 3
- Question: How does the IMUDiffusion model handle real-world noise and sensor drift in IMU data, and what preprocessing steps are most effective?
- Basis in paper: [inferred] The paper mentions the noisy nature of IMU data and the impact of sequencing, but does not explore strategies for handling noise or drift in real-world scenarios.
- Why unresolved: The study focuses on synthetic data generation and classification but does not address noise reduction or sensor drift correction in the preprocessing pipeline.
- What evidence would resolve it: Testing the model with noisy or drifted IMU data and evaluating the impact of different preprocessing techniques on synthetic data quality and classification accuracy.

## Limitations

- The 30% improvement claim is based on a single dataset (Banos et al.) with 12 participants, limiting generalizability
- The effectiveness of frequency domain transformation compared to time-domain approaches is not rigorously validated through ablation studies
- Individual schedulers show improved results, but the specific β values (9e-4 and 6e-4) appear empirically chosen without systematic optimization

## Confidence

- High confidence: Technical implementation details of UNet architecture, training procedure, and data preprocessing are well-specified and reproducible
- Medium confidence: The mechanism by which frequency domain transformation improves periodic motion capture is plausible but not conclusively proven
- Low confidence: The generalizability of the 30% improvement claim across different HAR datasets and activity types

## Next Checks

1. **Ablation study**: Compare IMUDiffusion performance with and without frequency domain transformation and with shared vs. individual schedulers to isolate the contribution of each design choice
2. **Cross-dataset evaluation**: Test the model on a different IMU dataset (e.g., UCI HAR or PAMAP2) to assess generalization beyond the Banos et al. dataset
3. **Temporal vs. frequency domain analysis**: Generate synthetic sequences in both domains and use UMAP + DTW clustering to verify that frequency domain representations indeed better capture periodic motion patterns while preserving temporal structure