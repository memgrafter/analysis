---
ver: rpa2
title: Customizing Text-to-Image Models with a Single Image Pair
arxiv_id: '2405.01536'
source_url: https://arxiv.org/abs/2405.01536
tags:
- style
- image
- content
- lora
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Pair Customization, a method to customize
  text-to-image diffusion models using a single image pair. The key idea is to learn
  separate LoRA weights for style and content from the image pair, encouraging orthogonality
  between them to improve disentanglement.
---

# Customizing Text-to-Image Models with a Single Image Pair

## Quick Facts
- **arXiv ID**: 2405.01536
- **Source URL**: https://arxiv.org/abs/2405.01536
- **Reference count**: 40
- **Primary result**: Introduces Pair Customization, a method to customize text-to-image diffusion models using a single image pair by learning separate LoRA weights for style and content with orthogonality constraints.

## Executive Summary
This paper introduces Pair Customization, a method to customize text-to-image diffusion models using a single image pair. The key idea is to learn separate LoRA weights for style and content from the image pair, encouraging orthogonality between them to improve disentanglement. During inference, a novel style guidance is proposed to better preserve content structure while applying the learned style. Experiments show that Pair Customization outperforms existing methods in preserving image structure and faithfully applying style, as measured by perceptual distance to ground-truth style images and human preference studies. The method is also effective for real image editing and blending multiple learned styles.

## Method Summary
The method employs joint optimization with two distinct LoRA weight spaces: one for style and one for content. The content LoRA reconstructs the content image while the style LoRA learns stylistic differences between the style and content images. To encourage disentanglement, row-space orthogonality is enforced between the style and content LoRA parameters. During inference, a novel style guidance mechanism modifies the diffusion process to better preserve content structure while applying the learned style. The method is trained on a single image pair and can be applied to both artistic style transfer and real image editing tasks.

## Key Results
- Pair Customization achieves superior structure preservation and style transfer compared to existing methods
- Human preference studies show 78.4% preference for Pair Customization over vanilla SDXL and 56.8% over P&D
- The method successfully blends multiple learned styles and works effectively on real images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning separate LoRA weights for style and content from an image pair improves disentanglement and prevents overfitting to specific image content.
- Mechanism: The paper uses joint optimization with two distinct LoRA weight spaces: one for style and one for content. By explicitly modeling the content through a separate LoRA, the style LoRA can focus on extracting stylistic differences without memorizing the content of the training image.
- Core assumption: The style image shares the same layout and structure as the content image, allowing the model to learn style-content separation from the pair.
- Evidence anchors:
  - [abstract] "We employ a joint optimization method that explicitly separates the style and content into distinct LoRA weight spaces."
  - [section 3.2] "Our key idea is to learn a separate content LoRA θcontent = θ0 + ∆θcontent to reconstruct the content image. By explicitly modeling the content, we can train the style LoRA to 'extract' the stylistic differences between the style and content image."
  - [corpus] Weak - corpus doesn't directly address the mechanism of learning from image pairs.
- Break condition: If the image pair does not share the same layout and structure, the assumption of shared structure fails and disentanglement may not work.

### Mechanism 2
- Claim: Row-space orthogonality between style and content LoRA parameters improves style and content disentanglement.
- Mechanism: The paper enforces orthogonality upon the LoRA weights by initializing the B matrices with zero and the A matrices from an orthonormal basis, then only updating the B matrices during training. This forces the style and content LoRA updates to respond to orthogonal inputs.
- Core assumption: Orthogonal weight spaces lead to orthogonal representations in the model's latent space, improving disentanglement.
- Evidence anchors:
  - [section 3.2] "To further encourage style and content LoRAs to represent separate concepts, we enforce orthogonality upon the LoRA weights... This forces the style and content LoRA updates to respond to orthogonal inputs, and empirically reduces visual artifacts."
  - [section 3.2] "This technique is inspired by Po et al. [67]."
  - [corpus] Weak - corpus doesn't directly address orthogonality in LoRA weights.
- Break condition: If the orthogonality constraint is too restrictive, it may prevent the model from learning complex relationships between style and content.

### Mechanism 3
- Claim: Style guidance modifies the diffusion process to better preserve content structure while applying the learned style.
- Mechanism: The paper extends classifier-free guidance by adding a third guidance term that integrates style LoRA predictions into the original denoising path. This helps preserve the original image structure when applying the learned style.
- Core assumption: The difference between style LoRA and pre-trained model predictions captures the stylistic change without affecting content.
- Evidence anchors:
  - [section 3.3] "Style guidance integrates style LoRA predictions into the original denoising path, which aids in better content preservation and facilitates smoother control over the stylization strength."
  - [section 3.3] "This method is more effective than the previous technique, where a customized model's strength is controlled by the magnitude of LoRA weights [78]."
  - [section 3.3] "We obtain additional guidance from a customized model and apply it to the original model."
- Break condition: If the style LoRA has not learned a good representation of the style, the guidance term may introduce artifacts or incorrect stylization.

## Foundational Learning

- Concept: Diffusion models and denoising process
  - Why needed here: The paper builds upon diffusion models as the underlying generative framework, so understanding how they work is essential to grasp the method.
  - Quick check question: How does a diffusion model gradually transform random noise into an image through iterative denoising steps?

- Concept: Low-Rank Adaptation (LoRA) and parameter-efficient fine-tuning
  - Why needed here: The paper uses LoRA to learn style and content weights efficiently without full fine-tuning of the large text-to-image model.
  - Quick check question: How does LoRA decompose weight updates into low-rank matrices, and why is this more parameter-efficient than full fine-tuning?

- Concept: Classifier-free guidance and conditional generation
  - Why needed here: The paper extends classifier-free guidance to create the new style guidance mechanism for better content preservation.
  - Quick check question: How does classifier-free guidance work in diffusion models, and what role does the guidance scale play in controlling the strength of conditioning?

## Architecture Onboarding

- Component map:
  Pre-trained text-to-image diffusion model (Stable Diffusion XL) -> Style LoRA adapter (learns stylistic differences) -> Content LoRA adapter (learns to reconstruct content image) -> Style guidance mechanism (modifies denoising process) -> Training pipeline (joint optimization with separate losses)

- Critical path:
  1. Train content LoRA to reconstruct content image
  2. Train style LoRA jointly with content LoRA to reconstruct style image while encouraging orthogonality
  3. At inference, apply style guidance to preserve content while applying style

- Design tradeoffs:
  - Separate LoRA weights vs. single LoRA: Separate weights improve disentanglement but require more parameters
  - Orthogonality constraint: Improves disentanglement but may restrict learning capacity
  - Style guidance vs. LoRA scaling: Guidance better preserves content but adds complexity to inference

- Failure signatures:
  - Overfitting to content: Generated images copy content from training image rather than applying style
  - Poor style transfer: Generated images don't match the desired style
  - Structure loss: Generated images lose the structure of the original content

- First 3 experiments:
  1. Train with only style LoRA (no content LoRA) - expect overfitting to content
  2. Train without orthogonality constraint - expect reduced disentanglement
  3. Use standard LoRA scaling instead of style guidance - expect worse content preservation

## Open Questions the Paper Calls Out
None

## Limitations
- The method assumes the content and style images share the same underlying structure and layout, which may not always hold
- Evaluation focuses primarily on artistic style transfer rather than real-world applications where content preservation is more critical
- Human preference study uses 150 pairs which may not be sufficient for robust conclusions

## Confidence

**High Confidence**: The core mechanism of using separate LoRA weights for style and content is well-established in the literature and the implementation appears sound. The orthogonality constraint and style guidance modifications are novel but grounded in existing techniques.

**Medium Confidence**: The claim that Pair Customization outperforms existing methods is supported by quantitative metrics and human studies, but the evaluation setup has limitations. The human preference study uses 150 pairs which may not be sufficient for robust conclusions, and the perceptual distance metric (DreamSim) is relatively new and may not fully capture human perception of style similarity.

**Low Confidence**: The generalization capability of the method beyond artistic style transfer to real image editing scenarios is demonstrated but not thoroughly evaluated. The paper shows promising results on real images but lacks systematic evaluation of when and why the method might fail in practical applications.

## Next Checks

1. **Structure Consistency Test**: Evaluate the method on image pairs where the content and style images have different structures (e.g., different object arrangements) to quantify how the assumption of shared structure affects performance.

2. **Robustness to Content Variation**: Test the method with multiple content images using the same style image to measure consistency in style transfer quality and identify potential overfitting to specific content.

3. **Real-World Application Stress Test**: Apply the method to a diverse set of real-world images (not just artistic styles) and evaluate both quantitative metrics and user studies to assess practical utility beyond the controlled experimental conditions.