---
ver: rpa2
title: 'Question Rephrasing for Quantifying Uncertainty in Large Language Models:
  Applications in Molecular Chemistry Tasks'
arxiv_id: '2408.03732'
source_url: https://arxiv.org/abs/2408.03732
tags:
- uncertainty
- smiles
- llms
- chemistry
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Question Rephrasing, a technique for quantifying
  uncertainty in large language models (LLMs) by evaluating their sensitivity to equivalent
  variations of input. The method combines input uncertainty assessment through systematic
  rephrasing of molecular representations (e.g., SMILES variants) with output uncertainty
  measurement using entropy-based metrics from repeated sampling.
---

# Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks

## Quick Facts
- arXiv ID: 2408.03732
- Source URL: https://arxiv.org/abs/2408.03732
- Reference count: 16
- Primary result: Question Rephrasing technique reveals GPT-4's sensitivity to input variations in molecular chemistry, with entropy-based uncertainty metrics showing predictive power for response correctness (AUC 0.546-0.993).

## Executive Summary
This paper introduces Question Rephrasing, a technique for quantifying uncertainty in large language models by evaluating their sensitivity to equivalent variations of input. The method combines input uncertainty assessment through systematic rephrasing of molecular representations (e.g., SMILES variants) with output uncertainty measurement using entropy-based metrics from repeated sampling. Applied to property prediction and reaction prediction in molecular chemistry tasks, the approach reveals that GPT-4 exhibits sensitivity to input variations, with significant performance declines observed when reformulated SMILES representations are used.

## Method Summary
The Question Rephrasing technique involves generating multiple SMILES variants for molecules using RDKit, then ranking these variants by GPT-4's confidence in interpreting them. For each molecule-task pair, both original and reformulated SMILES prompts are constructed using structured prompt design with role-playing, few-shot ICL samples, and target questions. The LLM generates multiple responses for each prompt, and uncertainty is quantified using entropy-based metrics (Class Entropy for classification, hierarchical clustering-based similarity for generation). The method then compares input uncertainty between variants and predicts correctness using uncertainty metrics.

## Key Results
- GPT-4 shows significant performance declines (7-15 percentage points) when reformulated SMILES representations are used
- Output uncertainty metrics demonstrate moderate to high predictive power for response correctness with AUC scores ranging from 0.546 to 0.993
- The approach reveals that LLMs exhibit sensitivity to input variations, highlighting limitations in fundamental chemistry understanding
- Class Entropy and hierarchical clustering-based similarity effectively quantify output uncertainty for different task types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method quantifies input uncertainty by measuring how LLM outputs change when the same molecular information is presented in different but semantically equivalent SMILES representations.
- Mechanism: By generating multiple SMILES variants for the same molecule and selecting the variant GPT-4 is most confident interpreting, the approach creates controlled input perturbations while preserving meaning. Comparing output uncertainty between original and reformulated prompts reveals the model's sensitivity to input variations.
- Core assumption: SMILES variants generated from the same molecular structure are semantically equivalent and should produce identical LLM responses if the model truly understands molecular chemistry.

### Mechanism 2
- Claim: Output uncertainty measured through entropy metrics correlates with response correctness, enabling prediction of when LLM outputs can be trusted.
- Mechanism: Repeated sampling with identical inputs creates a distribution of responses. Entropy-based metrics (Class Entropy for classification, hierarchical clustering-based similarity for generation) quantify the consistency of this distribution. Lower entropy indicates higher confidence and potentially higher accuracy.
- Core assumption: The entropy of LLM output distributions meaningfully captures the model's uncertainty about its responses, and this uncertainty correlates with actual correctness.

### Mechanism 3
- Claim: Question Rephrasing technique reveals whether LLMs truly understand molecular chemistry or are performing superficial string matching.
- Mechanism: By systematically reformulating molecular representations while preserving meaning, the approach tests whether LLM responses depend on specific input formats or demonstrate robust understanding of underlying chemical concepts.
- Core assumption: A model that truly understands molecular chemistry should produce consistent responses across semantically equivalent input variations, while a model relying on pattern matching would show sensitivity to input rephrasing.

## Foundational Learning

- Concept: SMILES notation and molecular representation
  - Why needed here: The entire method relies on understanding how molecular structures can be represented in multiple equivalent ways through SMILES notation
  - Quick check question: Can you explain why aspirin can have multiple valid SMILES representations while representing the same molecule?

- Concept: Entropy and information theory
  - Why needed here: Output uncertainty metrics are based on entropy calculations that quantify the distribution of LLM responses
  - Quick check question: How does Shannon entropy measure uncertainty in a probability distribution of class predictions?

- Concept: Hierarchical clustering and molecular fingerprints
  - Why needed here: For generation tasks, similarity between generated SMILES is measured using Tanimoto similarity on molecular fingerprints, then clustered to calculate uncertainty
  - Quick check question: What is the relationship between molecular fingerprints, Tanimoto similarity, and hierarchical clustering in measuring SMILES generation consistency?

## Architecture Onboarding

- Component map: SMILES variant generation -> GPT-4 confidence ranking -> Prompt construction -> LLM response generation -> Uncertainty calculation -> Correctness prediction
- Critical path: For each molecule-task pair, generate SMILES variants → rank by GPT-4 confidence → construct original and reformulated prompts → generate repeated responses → calculate output uncertainty → compare input uncertainty between variants → predict correctness using uncertainty metrics
- Design tradeoffs: The method trades computational cost (multiple LLM calls per molecule) for comprehensive uncertainty quantification. Using GPT-4 for SMILES ranking adds confidence but introduces dependency on another LLM. The choice of 5 samples for property prediction vs 3-20 for reaction prediction balances statistical significance with computational efficiency.
- Failure signatures: Large performance drops when using reformulated SMILES suggest input sensitivity; low AUC scores for uncertainty metrics indicate poor correlation between uncertainty and correctness; inconsistent SMILES variant ranking suggests GPT-4 confidence doesn't reflect actual interpretability.
- First 3 experiments:
  1. Run the full pipeline on a single molecule from the BBBP dataset with original SMILES, verify all components execute correctly and check output uncertainty calculation
  2. Test SMILES variant generation and ranking by comparing RDKit-generated variants with GPT-4-ranked confidence scores for consistency
  3. Evaluate the correlation between Class Entropy and prediction correctness on a small sample (10 molecules) from any property prediction dataset to validate the uncertainty-correctness relationship

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GPT-4's sensitivity to SMILES variations compare to specialized chemical models trained on molecular data?
- Basis in paper: The paper notes that "we observed a substantial decline in model performance on reaction prediction tasks when presented with the variations in molecular representation, demonstrating the LLMs' weakness in understanding basic chemistry knowledge."
- Why unresolved: While the paper demonstrates that GPT-4 is sensitive to input variations, it does not provide a direct comparison to specialized chemical models, leaving the relative performance unclear.
- What evidence would resolve it: Comparative studies measuring GPT-4's sensitivity to SMILES variations against specialized chemical models on identical tasks and datasets.

### Open Question 2
- Question: Can the entropy-based uncertainty metrics be generalized to other scientific domains beyond molecular chemistry?
- Basis in paper: The paper applies the entropy-based uncertainty metrics specifically to chemistry tasks, but the methodology could potentially be adapted for other scientific domains.
- Why unresolved: The paper focuses solely on molecular chemistry tasks, without exploring the applicability of the uncertainty metrics to other scientific domains.
- What evidence would resolve it: Application and validation of the entropy-based uncertainty metrics on tasks from other scientific domains, such as physics or biology, with corresponding evaluation of their predictive power for correctness.

### Open Question 3
- Question: What is the impact of different SMILES generation algorithms on the input uncertainty of LLMs?
- Basis in paper: The paper uses RDKit to generate alternative SMILES representations and prompts GPT-4 to rank them by confidence.
- Why unresolved: The paper does not explore how different SMILES generation algorithms might affect the input uncertainty and the subsequent performance of LLMs.
- What evidence would resolve it: Comparative analysis using multiple SMILES generation algorithms to create input variations and measuring the resulting input uncertainty and LLM performance.

### Open Question 4
- Question: How do different prompt engineering strategies affect the output uncertainty of LLMs in chemistry tasks?
- Basis in paper: The paper employs a structured prompt design but does not investigate how variations in prompt engineering might influence output uncertainty.
- Why unresolved: The study uses a fixed prompt structure, leaving the potential impact of different prompt engineering strategies on output uncertainty unexplored.
- What evidence would resolve it: Systematic experimentation with various prompt engineering strategies and their effects on the output uncertainty metrics and model performance.

## Limitations
- The method depends heavily on GPT-4's performance in ranking SMILES variants, creating potential circular dependencies
- Computational cost of repeated sampling (5-20 calls per molecule) may limit scalability for large datasets
- The study focuses exclusively on GPT-4 without comparison to other LLM architectures or smaller models

## Confidence
**High Confidence Claims:**
- Question Rephrasing successfully reveals GPT-4's sensitivity to input variations (AUC 0.546-0.993)
- Entropy-based uncertainty metrics provide meaningful measures of output consistency
- GPT-4 demonstrates significant performance declines with reformulated SMILES

**Medium Confidence Claims:**
- Correlation between entropy metrics and correctness generalizes across molecular chemistry tasks
- Sampling strategy (5-20 responses) adequately captures output distribution
- Specific entropy formulas and similarity metrics are optimal for this domain

**Low Confidence Claims:**
- Method's effectiveness would transfer to other LLM architectures beyond GPT-4
- Computational overhead is justified by accuracy improvements in practical applications
- Findings about LLM chemistry understanding generalize to other scientific domains

## Next Checks
1. **Cross-LLM Validation**: Test Question Rephrasing with at least two additional LLM architectures (e.g., Claude, Llama) to determine whether input sensitivity patterns are specific to GPT-4 or represent a broader LLM limitation.

2. **Sample Size Sensitivity Analysis**: Systematically vary the number of repeated samples (1, 3, 5, 10, 20) to determine the minimum sample size that maintains acceptable uncertainty-correctness correlation while reducing computational cost.

3. **Domain Transfer Test**: Apply Question Rephrasing to a non-chemistry domain with clear semantic equivalences (e.g., mathematical expressions, logical statements) to test whether input sensitivity is domain-specific or a general LLM limitation.