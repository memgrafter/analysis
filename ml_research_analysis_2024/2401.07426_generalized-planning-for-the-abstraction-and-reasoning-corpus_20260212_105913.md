---
ver: rpa2
title: Generalized Planning for the Abstraction and Reasoning Corpus
arxiv_id: '2401.07426'
source_url: https://arxiv.org/abs/2401.07426
tags:
- node
- color
- nodes
- planning
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GPAR, a generalized planning-based approach
  to solve ARC tasks, which are abstract reasoning challenges that require object
  recognition, abstract reasoning, and procedural analogies. GPAR encodes each ARC
  task into a planning domain definition language (PDDL) problem with object-centric
  abstractions, and uses a generalized planning solver to synthesize planning programs
  that represent compact solutions with conditional statements, looping, and branching
  structures.
---

# Generalized Planning for the Abstraction and Reasoning Corpus

## Quick Facts
- arXiv ID: 2401.07426
- Source URL: https://arxiv.org/abs/2401.07426
- Reference count: 13
- Primary result: GPAR achieves 50.63% accuracy on test instances vs 40% for best baseline

## Executive Summary
This paper introduces GPAR, a generalized planning-based approach to solve ARC tasks, which are abstract reasoning challenges that require object recognition, abstract reasoning, and procedural analogies. GPAR encodes each ARC task into a planning domain definition language (PDDL) problem with object-centric abstractions, and uses a generalized planning solver to synthesize planning programs that represent compact solutions with conditional statements, looping, and branching structures. The paper shows how to scale up the solver by incorporating domain knowledge specific to ARC in the form of restrictions over the actions model, predicates, arguments and valid structure of planning programs.

## Method Summary
GPAR models ARC tasks as generalized planning problems by encoding them into PDDL domain and instance files. The approach uses object-centric abstractions (4-connected, 8-connected, same-color, etc.) to convert pixel grids into graphs of nodes with attributes. A generalized planning solver (PGP(v)) searches for planning programs that solve all training instances by manipulating pointers over objects and applying transformations. Domain knowledge is incorporated through action pruning based on training instance analysis and structural constraints on program synthesis.

## Key Results
- GPAR achieves 50.63% accuracy on test instances and 53.75% accuracy on training instances
- Outperforms state-of-the-art solvers on object-centric ARC tasks (40% and 49.38% for best baseline)
- Successfully handles tasks involving node coloring, positioning, and shape transformation through object-centric abstractions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generalized planning (GP) compactly represents ARC solutions as planning programs with pointers, enabling scalable search over object-centric abstractions.
- Mechanism: Each ARC task is encoded as a PDDL problem; a GP solver searches for a single program that solves all training instances by manipulating pointers to iterate over nodes and apply transformations.
- Core assumption: The ARC task's underlying rules can be captured by a finite set of object attributes and relations, and these can be expressed in PDDL with external functions for complex effects.
- Evidence anchors:
  - [abstract] "It casts an ARC problem as a generalized planning (GP) problem, where a solution is formalized as a planning program with pointers."
  - [section] "Solutions, known as generalized plans, can be formalized as planning programs with pointers (Segovia-Aguas, Jim´enez, and Jonsson 2019) where conditional statements, and looping and branching structures allow the compact representation of solutions."
  - [corpus] Weak evidence: only the paper itself cites this specific GP-to-ARC encoding approach; no independent replication found.

### Mechanism 2
- Claim: Domain knowledge pruning reduces the search space by eliminating irrelevant actions based on training instance analysis.
- Mechanism: Constraints are inferred from training images (e.g., if positions never change, remove movement actions; if colors never change, remove color updates) and are applied before search to shrink the DSL.
- Core assumption: ARC tasks exhibit consistent properties across training instances that can be detected statically and used to prune the action space without losing valid solutions.
- Evidence anchors:
  - [abstract] "We show how to scale up GP solvers via domain knowledge specific to ARC in the form of restrictions over the actions model, predicates, arguments and valid structure of planning programs."
  - [section] "Different node definitions can compensate for the limitations of a certain abstraction... We consider mainly three constraints based on whether all nodes’ positions, colors, or sizes remain unchanged across training input and output images."
  - [corpus] Weak evidence: no external validation of pruning effectiveness beyond this paper's ablation.

### Mechanism 3
- Claim: Program synthesis with structural restrictions (application vs. looping sections) and predicate/argument constraints increases solution generalizability and prevents overfitting.
- Mechanism: The solver separates the program into an application section (where conditions and actions are programmed) and a looping section (pre-generated pointer iteration), with constraints ensuring test predicates only reference attributes present in all instances.
- Core assumption: ARC tasks have consistent object attributes across training and test instances, so predicates conditioned on those attributes will generalize.
- Evidence anchors:
  - [abstract] "We show how to scale up GP solvers via domain knowledge specific to ARC in the form of restrictions over the actions model, predicates, arguments and valid structure of planning programs."
  - [section] "Argument constraints make sure that if a node color or size predicate is used in a test action, then the arguments chosen describe attributes that exist in all training and test input images."
  - [corpus] Weak evidence: no external study comparing this structure to unrestricted search.

## Foundational Learning

- Concept: PDDL (Planning Domain Definition Language)
  - Why needed here: GPAR models each ARC task as a PDDL domain and instance file, allowing the use of automated planning solvers.
  - Quick check question: Can you write a simple PDDL domain with a predicate and an action schema that changes a node's color?

- Concept: Generalized Planning (GP) and planning programs with pointers
  - Why needed here: GP allows a single compact program to solve multiple instances of an ARC task by manipulating pointers over object types.
  - Quick check question: Given a program with two pointers over nodes, how would you iterate over all node pairs to apply a transformation?

- Concept: Graph abstractions for object recognition in images
  - Why needed here: GPAR uses 4-connected, 8-connected, same-color, etc., abstractions to convert pixel grids into graphs of nodes with attributes, enabling object-centric reasoning.
  - Quick check question: For a 3x3 grid with a diagonal of one color, how many 4-connected components are there?

## Architecture Onboarding

- Component map:
  - DSL Generation -> PGP(v) Solver -> Verification
  - External Functions provide complex preconditions/effects

- Critical path:
  1. Input ARC task → DSL Generation → PDDL files.
  2. PGP(v) receives PDDL, pointers, constraints, novelty threshold.
  3. Search for program → solution found or timeout.
  4. Execute on test instances → evaluate accuracy.

- Design tradeoffs:
  - Expressiveness vs. tractability: richer DSLs increase solution space; pruning keeps it tractable.
  - Abstraction selection: simpler abstractions reduce search space but may miss needed transformations.
  - Partial instantiation: allows fixing attributes for looping but may overfit if not generalized.

- Failure signatures:
  - No solution found: likely abstraction too simple or pruning too aggressive.
  - Solution works on training but not test: overfitting due to overly specific predicates or missing test predicates.
  - Slow search: large DSL or low novelty threshold; consider adding more constraints.

- First 3 experiments:
  1. Run GPAR on a simple recoloring task with 4-connected abstraction, v=1, n=3; verify solution found quickly.
  2. Disable action pruning and observe if search time increases; confirm pruning effectiveness.
  3. Add a new node attribute (e.g., "on border") and test if it helps solve a movement task that previously failed.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GPAR handle tasks requiring complex spatial reasoning or understanding of object attributes like center, corner, and area?
- Basis in paper: [inferred] The paper mentions that GPAR struggles with tasks involving dynamic attributes between nodes and movement actions defined with large numeric parameters.
- Why unresolved: The paper does not provide a detailed explanation of how GPAR addresses these challenges or if there are any ongoing efforts to improve its performance in this area.
- What evidence would resolve it: A detailed analysis of GPAR's performance on tasks requiring complex spatial reasoning, including specific examples of tasks it struggles with and potential solutions to improve its performance.

### Open Question 2
- Question: How can GPAR be extended to handle tasks involving shape transformations like rescaling, completion, and analogical replication?
- Basis in paper: [explicit] The paper states that the augmentation class of tasks, which involves shape transformations, is difficult to implement in imperative programs based on DSLs, and GPAR struggles with this category.
- Why unresolved: The paper does not provide a clear explanation of how GPAR can be extended to handle these tasks or if there are any ongoing efforts to improve its performance in this area.
- What evidence would resolve it: A detailed analysis of GPAR's performance on tasks involving shape transformations, including specific examples of tasks it struggles with and potential solutions to improve its performance.

### Open Question 3
- Question: How can GPAR's performance be improved by identifying the most useful abstractions for a given ARC task?
- Basis in paper: [explicit] The paper mentions that identifying the most useful abstractions is still an open problem and that new heuristics can be defined to guide the search of programs through relaxations from the DSL representation.
- Why unresolved: The paper does not provide a clear explanation of how to identify the most useful abstractions or if there are any ongoing efforts to improve GPAR's performance in this area.
- What evidence would resolve it: A detailed analysis of the effectiveness of different abstractions for various ARC tasks, including specific examples of tasks where certain abstractions perform better than others and potential strategies to automatically select the most useful abstractions for a given task.

## Limitations

- Reliance on domain-specific constraints that may not generalize to all ARC tasks
- Lack of ablation studies comparing different abstraction choices
- Results not independently replicated

## Confidence

- Generalized planning approach to ARC: High
- Domain knowledge pruning effectiveness: Medium
- Program synthesis with structural restrictions: Medium

## Next Checks

1. Perform ablation studies systematically removing different domain knowledge constraints to quantify their individual contributions to performance
2. Test the approach on a subset of non-object-centric ARC tasks to evaluate generalization beyond the stated scope
3. Implement a simpler baseline using the same PDDL encoding but without domain knowledge pruning to isolate the impact of constraint-based search space reduction