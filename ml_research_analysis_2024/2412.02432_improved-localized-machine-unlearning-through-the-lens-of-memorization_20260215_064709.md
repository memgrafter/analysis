---
ver: rpa2
title: Improved Localized Machine Unlearning Through the Lens of Memorization
arxiv_id: '2412.02432'
source_url: https://arxiv.org/abs/2412.02432
tags:
- unlearning
- forget
- parameters
- localization
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Localized unlearning is an emerging research area that aims to
  remove the influence of a specified subset of training data from a machine learning
  model after training, while minimizing computational cost and preserving model utility.
  The key challenge lies in identifying which subset of parameters to modify for effective
  unlearning without damaging the model's performance on retained data.
---

# Improved Localized Machine Unlearning Through the Lens of Memorization

## Quick Facts
- arXiv ID: 2412.02432
- Source URL: https://arxiv.org/abs/2412.02432
- Authors: Reihaneh Torkzadehmahani; Reza Nasirigerdeh; Georgios Kaissis; Daniel Rueckert; Gintare Karolina Dziugaite; Eleni Triantafillou
- Reference count: 26
- Key outcome: DEL achieves state-of-the-art unlearning performance with 10-30% parameter budgets while maintaining or improving test accuracy

## Executive Summary
This paper introduces Deletion by Example Localization (DEL), a novel localized unlearning algorithm that leverages insights from memorization research to improve unlearning effectiveness. DEL identifies critical parameters using weighted gradients computed over the forget set, then resets and fine-tunes only these parameters while preserving model utility. The method demonstrates superior performance across three datasets (CIFAR-10, SVHN, ImageNet-100) with different architectures (ResNet-18, ViT, ResNet-50), achieving better unlearning metrics while maintaining or improving test accuracy compared to both localized and full-parameter unlearning methods.

## Method Summary
DEL combines a novel localization strategy with a Reset + Finetune unlearning algorithm. The localization strategy identifies critical parameters by computing weighted gradients over the forget set, then groups parameters by output channels to determine channel-level criticality scores. Parameters are selected based on their criticality scores within a specified budget constraint. The unlearning algorithm resets the selected critical parameters and fine-tunes them using only the retained data. The method is evaluated using forget accuracy, membership inference attack (MIA) scores, and test accuracy metrics across various parameter budgets and non-IID forget set scenarios.

## Key Results
- DEL achieves superior unlearning performance with 10-30% parameter budgets compared to state-of-the-art methods
- The method maintains or improves test accuracy while effectively removing forget-set influence
- DEL shows particular robustness for non-IID forget sets where data-specific localization proves crucial
- Channel-level granularity outperforms both parameter-level and layer-level approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DEL achieves better unlearning performance by targeting parameters most critical for forget-set-specific predictions while preserving utility.
- Mechanism: Uses criticality score based on weighted gradients (|θo_j · g_j(θo, S)|) to identify parameters most important for the forget set, then resets and fine-tunes only those parameters.
- Core assumption: Parameters with high weighted gradient magnitudes on the forget set are most responsible for memorizing those examples.
- Evidence anchors: [abstract] "DEL identifies critical parameters through a novel approach that combines channel-level granularity with weighted gradients based on forget-set-specific information"
- Break condition: If forget-set examples are not actually memorized by the identified critical parameters, or if utility preservation fails due to over-targeting.

### Mechanism 2
- Claim: Channel-level granularity improves unlearning effectiveness compared to parameter-level or layer-level approaches.
- Mechanism: Groups parameters by output channels/neurons and selects channels based on average top-h criticality scores rather than individual parameters.
- Core assumption: Memorization occurs at channel level rather than individual parameter level, making channel-wise decisions more robust to heuristic errors.
- Evidence anchors: [abstract] "combines channel-level granularity with weighted gradients"
- Break condition: If memorization is actually distributed more finely than channel level, or if channel grouping misses critical individual parameters.

### Mechanism 3
- Claim: Data-dependent localization outperforms data-agnostic approaches for non-IID forget sets.
- Mechanism: Tailors parameter selection to the specific forget set distribution rather than using generic layer selection strategies.
- Core assumption: The distribution of the forget set matters for determining which parameters need modification for effective unlearning.
- Evidence anchors: [section] "we observe that i) our method pairs well with different unlearning algorithms, ii) in terms of forget accuracy and MIA score, our method yields the best results"
- Break condition: If forget set distribution has minimal impact on parameter criticality, or if data-agnostic methods perform equally well.

## Foundational Learning

- Concept: Parameter criticality scoring based on weighted gradients
  - Why needed here: DEL's effectiveness depends on correctly identifying which parameters are most responsible for forget-set memorization
  - Quick check question: How would you modify the criticality score if you wanted to use unweighted gradients instead?

- Concept: Channel-level parameter grouping
  - Why needed here: DEL uses channels as the basic unit for parameter selection, requiring understanding of neural network architecture
  - Quick check question: In a convolutional layer, what parameters belong to the same output channel?

- Concept: Membership Inference Attacks (MIA)
  - Why needed here: MIA score is one of the primary metrics for evaluating unlearning effectiveness
  - Quick check question: What information does an MIA attacker use to determine if an example was in the training set?

## Architecture Onboarding

- Component map: Localization strategy -> Parameter selection -> Reset + Finetune -> Evaluation
- Critical path: 1) Compute forget-set gradients for all parameters 2) Calculate weighted criticality scores 3) Group parameters by channels and compute channel criticality 4) Select top channels within budget constraint 5) Reset selected parameters 6) Fine-tune on retain set 7) Evaluate against oracle and baselines
- Design tradeoffs: Granularity vs. efficiency (channel-level vs. parameter-level selection), Data-specific vs. generic (forget-set-specific vs. training-set-wide gradients), Reset vs. finetune (complete parameter reset vs. gradual modification)
- Failure signatures: Poor forget accuracy despite high parameter budget (indicates incorrect criticality scoring), Low test accuracy (suggests over-aggressive parameter targeting), MIA score similar to baseline (means unlearning didn't effectively remove forget-set influence)
- First 3 experiments: 1) Compare DEL with random parameter selection at 30% budget on CIFAR-10 non-IID forget set 2) Test different channel selection strategies (top-1 vs. top-3 vs. top-5) at fixed budget 3) Evaluate DEL with different unlearning algorithms (Random Label vs. NegGrad+ vs. RFT) at 20% budget

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of localized unlearning vary across different types of non-IID forget sets (e.g., class-specific vs. distribution-specific)?
- Basis in paper: The paper notes that "for non-IID forget sets, tailoring the parameter selection to the specific forget set (rather than the training set more broadly) is more important than it is for IID forget sets," but doesn't deeply explore what characteristics of non-IID forget sets matter most.
- Why unresolved: The paper only examines two classes (2 and 5) for non-IID forget sets and doesn't systematically vary other characteristics like sample distribution or class relationships.
- What evidence would resolve it: Experiments varying non-IID forget set characteristics (e.g., different class pairs, samples from overlapping distributions, forget sets with varying degrees of distribution shift) while measuring unlearning performance across multiple metrics.

### Open Question 2
- Question: Does the superiority of channel-level granularity over parameter-level granularity hold across all neural network architectures and tasks?
- Basis in paper: The authors found that "channel-wise granularity and weighted gradients" performed best in their experiments, but this was tested primarily on vision tasks with ResNet and ViT architectures.
- Why unresolved: The experiments are limited to image classification tasks with specific architectures, and the generalizability to other domains (NLP, reinforcement learning) or architectures (RNNs, transformers with different designs) is unknown.
- What evidence would resolve it: Systematic testing of the localization strategy across diverse architectures (CNNs, RNNs, transformers), tasks (classification, regression, generation), and domains (vision, language, tabular data) with controlled comparisons of granularity levels.

### Open Question 3
- Question: What is the relationship between memorization localization and unlearning effectiveness across different model training regimes and dataset complexities?
- Basis in paper: The authors reference conflicting findings in the literature about whether memorization localization informs unlearning, noting that "insights from [Maini et al., 2023] led us to improve upon state-of-the-art," but the connection remains unclear.
- Why unresolved: The paper doesn't systematically explore how memorization patterns change with different training regimes (e.g., data augmentation, regularization, curriculum learning) or dataset complexities (e.g., long-tail distributions, noisy labels).
- What evidence would resolve it: Experiments measuring memorization patterns under varied training conditions and analyzing how these patterns correlate with unlearning effectiveness, potentially through controlled ablation studies or memorization-unlearning correlation analyses.

## Limitations
- The exact implementation details for channel criticality scoring remain underspecified
- The method's effectiveness across diverse architectures and domains is untested
- The relationship between memorization patterns and unlearning effectiveness is not fully explored

## Confidence
- Weighted gradient-based localization: Medium-High
- Channel-level granularity benefits: Medium
- Data-dependent localization advantages: Medium
- Cross-architecture generalization: Low

## Next Checks
1. Implement and compare alternative channel criticality aggregation methods (sum vs. max vs. top-k average of constituent parameters) to verify the claimed benefits of the specific approach used

2. Test DEL's performance on a novel architecture (e.g., ConvNeXt or Swin Transformer) with varying parameter budgets to assess generalization beyond the three architectures studied

3. Conduct ablation studies removing the data-dependent component by using training-set-wide gradients instead of forget-set-specific gradients to quantify the contribution of data-dependent localization