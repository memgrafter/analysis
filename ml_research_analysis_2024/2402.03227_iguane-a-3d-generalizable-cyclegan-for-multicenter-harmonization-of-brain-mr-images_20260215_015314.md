---
ver: rpa2
title: 'IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain
  MR images'
arxiv_id: '2402.03227'
source_url: https://arxiv.org/abs/2402.03227
tags:
- images
- harmonization
- iguane
- brain
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IGUANe is a 3D generative adversarial network for harmonizing structural
  brain MRI across multiple acquisition sites without needing traveling subjects.
  It extends CycleGAN with a many-to-one training strategy, enabling application to
  any image from an unseen site.
---

# IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain MR images

## Quick Facts
- arXiv ID: 2402.03227
- Source URL: https://arxiv.org/abs/2402.03227
- Reference count: 26
- IGUANe is a 3D generative adversarial network for harmonizing structural brain MRI across multiple acquisition sites without needing traveling subjects.

## Executive Summary
IGUANe is a 3D CycleGAN extension that addresses the challenge of harmonizing structural brain MRI images from multiple acquisition sites without requiring traveling subjects. The model employs a many-to-one training strategy, learning to map from multiple source sites to a reference site while maintaining cycle-consistency, enabling application to unseen sites. Trained on T1-weighted images from 11 scanners, IGUANe demonstrates superior performance in preserving individual anatomical information, maintaining biological patterns, and improving prediction tasks compared to existing harmonization methods.

## Method Summary
IGUANe extends CycleGAN with a many-to-one training strategy, using 11 generators and 20 discriminators to learn mappings from multiple source sites to a reference site. The model employs residual learning where generators output residual images added to inputs, with background set to neutral values during training. Age-balanced sampling prevents suppression of biological information. The model is trained on 4347 T1-weighted images from 11 studies using SALD as reference, with validation every 5 epochs using age/sex prediction metrics.

## Key Results
- IGUANe better preserves individual information and maintains biological patterns compared to HM, WS, STGAN, and CALAMITI
- The model outperforms other methods in brain age prediction (MAE 4.22 vs 5.33-6.22) and CN/AD classification (accuracy 79.2% vs 76.1-78.6%)
- Age-GM volume correlations are reinforced after harmonization (r=0.6485 vs 0.5881 for ADNI, r=0.6392 vs 0.5819 for MIRIAD)

## Why This Works (Mechanism)

### Mechanism 1
Many-to-one domain translation enables universal harmonization across unseen sites without retraining. IGUANe trains a single forward generator to map from multiple source sites to a reference site while maintaining cycle-consistency, allowing it to generalize to images from sites not seen during training.

### Mechanism 2
Residual learning and background neutral value setting preserve anatomical information during harmonization. The generator learns to output only the residual image, which is added to the input, while background is set to a neutral value during training to focus on brain intensities.

### Mechanism 3
Age-balanced sampling prevents suppression of biological information during training. For each source site, a probability distribution based on participant ages is used to sample MR images, achieving balanced age distribution with the reference site.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: IGUANe is built on CycleGAN, a GAN architecture for image-to-image translation
  - Quick check question: What are the roles of the generator and discriminator in a GAN?

- Concept: Domain adaptation and harmonization
  - Why needed here: The paper addresses the challenge of harmonizing MRI images from multiple acquisition sites
  - Quick check question: What are the main differences between harmonization and normalization techniques?

- Concept: Residual learning
  - Why needed here: IGUANe uses residual learning to preserve anatomical information during harmonization
  - Quick check question: How does residual learning differ from direct image generation?

## Architecture Onboarding

- Component map: 11 generators (1 forward, 10 backward), 20 discriminators (10 forward, 10 backward), training/validation loop
- Critical path: Training data preprocessing → Many-to-one CycleGAN training → Model validation → Inference
- Design tradeoffs: 3D convolutions for whole brain processing vs. 2D for computational efficiency; residual learning for anatomical preservation vs. direct generation for flexibility
- Failure signatures: Poor generalization to new sites, loss of anatomical details, over-homogenization of inter-subject differences
- First 3 experiments:
  1. Train on a small dataset with 2-3 sites and evaluate on a held-out site
  2. Compare SSIM and inter-subject distance preservation with and without residual learning
  3. Test the effect of different age sampling strategies on biological pattern preservation

## Open Questions the Paper Calls Out

### Open Question 1
How well does IGUANe generalize to MRI modalities other than T1-weighted images? The study focuses exclusively on T1-weighted images, and the authors acknowledge the need for further research to assess the model's performance on other MRI modalities.

### Open Question 2
How does IGUANe perform in preserving and enhancing specific biological patterns in MR images of individuals with brain lesions? The study does not include participants with brain lesions, and the authors acknowledge the need for further research to assess the model's performance in this context.

### Open Question 3
How does IGUANe compare to other harmonization methods in terms of computational efficiency and resource requirements? The study does not provide a comprehensive comparison of IGUANe's computational efficiency and resource requirements with other harmonization methods.

## Limitations

- Generalizability claims rely heavily on the diversity of 11 training sites, with limited detail on scanner models and protocols
- Evaluation on 5 unseen sites represents a limited test of true generalization capability
- Clinical dataset analysis shows improvement in effect sizes but does not demonstrate direct clinical impact on diagnostic accuracy

## Confidence

- **High confidence**: SSIM preservation for traveling subjects, preservation of inter-subject distances, and brain age prediction MAE improvements
- **Medium confidence**: Reinforcement of age-GM volume correlations and hippocampal volume effect sizes, dependent on FreeSurfer segmentation quality
- **Low confidence**: Universal harmonization across any unseen site without retraining requires broader validation

## Next Checks

1. Test IGUANe on a dataset with scanner types and protocols completely absent from the training set (e.g., 7T MRI, specialized research sequences) to evaluate true generalization limits.
2. Conduct ablation studies systematically varying the number of training sites (3, 5, 8, 11) to quantify the relationship between training diversity and generalization performance.
3. Evaluate harmonization impact on downstream clinical tasks by testing whether harmonized images improve diagnostic accuracy in multicenter clinical trials or reduce false positive/negative rates in disease detection.