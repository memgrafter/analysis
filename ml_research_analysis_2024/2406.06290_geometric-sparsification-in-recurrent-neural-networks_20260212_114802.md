---
ver: rpa2
title: Geometric sparsification in recurrent neural networks
arxiv_id: '2406.06290'
source_url: https://arxiv.org/abs/2406.06290
tags:
- moduli
- sparse
- neural
- regularization
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces moduli regularization, a novel technique for
  sparsifying recurrent neural networks (RNNs) by leveraging their underlying geometric
  structure. The method embeds hidden-state neurons into a metric space and differentially
  penalizes weights based on the distance between neurons in this space.
---

# Geometric sparsification in recurrent neural networks

## Quick Facts
- arXiv ID: 2406.06290
- Source URL: https://arxiv.org/abs/2406.06290
- Reference count: 40
- Primary result: Moduli regularization achieves up to 90% sparsity in RNNs while maintaining model performance through geometric sparsification

## Executive Summary
This paper introduces moduli regularization, a novel technique for sparsifying recurrent neural networks by leveraging their underlying geometric structure. The method embeds hidden-state neurons into a metric space and differentially penalizes weights based on the distance between neurons in this space. By exploiting the hypothesis that RNN hidden states lie on low-dimensional attractors, the approach provides an explicit geometric description of desired sparse architectures and enables end-to-end learning of RNN geometry.

The authors validate their method on three benchmark tasks: navigation, natural language processing (NLP), and the adding problem. They demonstrate that moduli regularization can achieve high sparsity (up to 90%) while maintaining model performance, especially when the moduli space is well-suited to the task. The method also produces more stable sparse architectures compared to traditional sparsification techniques, as evidenced by superior performance in lottery ticket experiments.

## Method Summary
Moduli regularization introduces a novel regularizer for RNNs that embeds hidden-state neurons into a metric space M and differentially penalizes weights based on their distance in this space. The regularizer computes Rf(Whh) using an inhibitor function f that maps distances to penalty values, with the total loss being the standard RNN loss plus λ·Rf(Whh). This approach can use either fixed embeddings in appropriate moduli spaces (like tori for navigation) or learn embeddings during training. Combined with magnitude pruning, the method achieves sparse architectures that respect the underlying geometric structure while maintaining performance.

## Key Results
- Achieves up to 90% sparsity on navigation task with minimal error using toroidal moduli space
- Demonstrates more stable sparse architectures than traditional methods in lottery ticket experiments
- Shows improved performance on adding problem and NLP tasks compared to L1 regularization and shuffled moduli regularization baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Moduli regularization creates geometrically structured sparse architectures by penalizing weights based on distance in a chosen metric space.
- Mechanism: The regularizer assigns larger penalties to connections between neurons that are far apart in the embedding space M, while connections between nearby neurons are penalized less. This differential penalty structure drives the network to develop sparse architectures that respect the underlying geometry.
- Core assumption: The hidden states of RNNs lie on or near a low-dimensional manifold that can be captured by an appropriate metric space embedding.
- Evidence anchors:
  - [abstract]: "Moduli regularization leverages the dynamical system induced by the recurrent structure to induce a geometric relationship between neurons in the hidden state of the RNN."
  - [section 2.2]: "Moduli regularization...is computed by embedding hidden-state neurons into a metric space M, and differentially penalizing weights according to their distance on M."
  - [corpus]: Weak - no direct comparison to geometric vs non-geometric regularization methods found in corpus.
- Break condition: The geometric assumption fails if the hidden states do not lie on a manifold, or if the chosen metric space M poorly approximates the true underlying geometry.

### Mechanism 2
- Claim: Trained embeddings can learn the appropriate geometric structure for tasks lacking known moduli spaces.
- Mechanism: When M is a high-dimensional Euclidean space, the embedding i can be optimized during training to place neurons in positions that minimize the regularized loss. This allows the network to discover task-relevant geometric relationships even without prior knowledge of the appropriate moduli space.
- Core assumption: The optimization process can effectively learn a useful embedding when given sufficient capacity in M.
- Evidence anchors:
  - [section 2.3]: "When M has a smooth structure and the inhibitor function f is differentiable, i can be taken as a parameter of the RNN and optimized by gradient descent during the course of training."
  - [section 4.2]: "Training embeddings as we did in this context can be actively harmful to the final model quality" - showing that this mechanism doesn't always work.
  - [corpus]: Weak - no evidence of successful learned embeddings in similar work found in corpus.
- Break condition: The learned embedding degenerates (e.g., all neurons mapped to a single point) or the optimization gets stuck in poor local minima.

### Mechanism 3
- Claim: Sparse architectures learned via moduli regularization are more stable than those from traditional sparsification methods.
- Mechanism: The geometric structure imposed by moduli regularization creates sparse architectures with more consistent weight distributions across different initializations. This stability is demonstrated by lottery ticket experiments where models retrained on the sparse architecture with randomized weights maintain high performance.
- Core assumption: The geometric structure provides a more robust basis for sparse connectivity than magnitude-based pruning alone.
- Evidence anchors:
  - [abstract]: "we show that moduli regularization induces more stable recurrent neural nets, and achieves high fidelity models above 90% sparsity."
  - [section 4]: "models retrained on moduli-generated sparse architectures outperform models retrained on traditional sparse architectures."
  - [corpus]: Moderate - the lottery ticket hypothesis is well-established in literature, supporting the general concept of stable sparse architectures.
- Break condition: The sparse architecture becomes too constrained, preventing effective learning even with good initializations, or the regularization strength is poorly tuned.

## Foundational Learning

- Concept: Metric spaces and manifold geometry
  - Why needed here: The entire method relies on embedding neurons into a metric space and using distance-based penalties, requiring understanding of basic geometric concepts.
  - Quick check question: Can you explain the difference between Euclidean distance and geodesic distance on a manifold?

- Concept: RNN dynamics and continuous attractors
  - Why needed here: The method is based on the hypothesis that RNN hidden states lie on low-dimensional attractors, requiring understanding of RNN behavior.
  - Quick check question: What is a continuous attractor in the context of RNNs, and how does it relate to the hidden state dynamics?

- Concept: Regularization techniques and sparsification methods
  - Why needed here: The work combines L1 regularization with a novel geometric regularizer, requiring understanding of how different regularization approaches affect network sparsity.
  - Quick check question: How does L1 regularization differ from the moduli regularization approach in terms of how they encourage sparsity?

## Architecture Onboarding

- Component map:
  - Hidden state neurons embedded in metric space M
  - Inhibitor function f controlling distance-based penalties
  - Embedding function i mapping neurons to M
  - Hidden update matrix Whh subject to regularization
  - Regularization coefficient λ controlling penalty strength

- Critical path:
  1. Choose appropriate moduli space M based on task (torus for navigation, learned for others)
  2. Initialize embeddings i (random or trained)
  3. Compute regularization term Rf(Whh) using distances in M
  4. Add regularization to loss function
  5. Apply magnitude pruning during training to achieve target sparsity

- Design tradeoffs:
  - Fixed vs. trained embeddings: Fixed embeddings require domain knowledge but are computationally cheaper; trained embeddings can adapt but add parameters and training time
  - Choice of inhibitor function: Different functions (DoG, sinusoid, etc.) create different sparsity patterns
  - Sparsity target: Higher sparsity saves computation but may degrade performance

- Failure signatures:
  - Poor performance despite high sparsity: Likely wrong choice of moduli space or inhibitor function
  - Instability in lottery ticket experiments: Architecture may be too constrained or regularization too strong
  - Slow convergence: Embedding optimization may be stuck in poor local minima

- First 3 experiments:
  1. Navigation task with toroidal moduli space and fixed embedding to validate basic approach
  2. Adding problem with learned embedding in R3 to test adaptive geometry discovery
  3. NLP task with various moduli spaces to test performance on non-geometric tasks

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the content, several significant questions arise regarding the method's generalization and theoretical foundations.

## Limitations
- The geometric assumptions about RNN hidden states may not hold across all task domains, particularly for complex NLP tasks
- Trained embeddings can sometimes be actively harmful to model quality, suggesting brittleness in the approach
- Limited validation on non-recurrent architectures and complex real-world tasks

## Confidence

- **High confidence**: The mathematical framework for moduli regularization is well-defined and internally consistent
- **Medium confidence**: Empirical results showing improved stability in lottery ticket experiments and high sparsity retention
- **Low confidence**: Claims about the learned embeddings discovering task-relevant geometry, given contradictory evidence in the paper

## Next Checks

1. **Cross-domain generalization test**: Apply moduli regularization to a diverse set of tasks (e.g., time series forecasting, reinforcement learning control) to evaluate whether the geometric approach consistently outperforms non-geometric sparsification methods across different data distributions.

2. **Ablation on embedding initialization**: Systematically vary the initialization strategy for learned embeddings (random, pretrained, structured) and measure impact on both convergence speed and final model quality to determine if the optimization challenges identified in the paper can be mitigated.

3. **Geometric structure analysis**: Perform dimensionality reduction (t-SNE, UMAP) on trained RNN hidden states across different tasks to empirically verify whether the states actually lie on low-dimensional manifolds as assumed by the method, and whether these manifolds correspond to the chosen moduli spaces.