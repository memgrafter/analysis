---
ver: rpa2
title: Federated Learning with MMD-based Early Stopping for Adaptive GNSS Interference
  Classification
arxiv_id: '2410.15681'
source_url: https://arxiv.org/abs/2410.15681
tags:
- learning
- classes
- class
- local
- gnss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a federated learning method for GNSS interference
  classification that addresses the challenge of adapting to novel interference classes
  across distributed sensor stations. The key innovation is a dynamic early stopping
  mechanism based on maximum mean discrepancy (MMD) of feature embeddings between
  local and global models, which balances underrepresented classes and improves model
  generalization.
---

# Federated Learning with MMD-based Early Stopping for Adaptive GNSS Interference Classification

## Quick Facts
- arXiv ID: 2410.15681
- Source URL: https://arxiv.org/abs/2410.15681
- Reference count: 40
- Primary result: Achieves >98% accuracy on GNSS interference classification across multiple real-world and controlled datasets using federated learning with MMD-based dynamic early stopping

## Executive Summary
This paper addresses the challenge of adapting GNSS interference classification models across distributed sensor stations with novel interference classes and environmental scenarios. The authors propose a federated learning framework that leverages Maximum Mean Discrepancy (MMD) of feature embeddings for dynamic early stopping during local model training. By measuring the discrepancy between local and global model representations, the method automatically adjusts training epochs to balance underrepresented classes while maintaining high overall accuracy. The approach outperforms state-of-the-art federated learning methods on three real-world and controlled GNSS datasets, achieving classification accuracies exceeding 98% and up to 99.989% on adaptation tasks.

## Method Summary
The method employs federated averaging with momentum (FedAvgM) as the baseline aggregation mechanism, enhanced with a dynamic early stopping strategy based on MMD loss between local and global model feature embeddings. Each local model is trained on its respective dataset and computes the MMD loss after each round, which determines the number of training epochs for subsequent rounds. The epoch calculation formula dynamically adjusts training intensity based on representation alignment, with lower MMD indicating better alignment and thus fewer required epochs. The framework uses ResNet18 as the feature extractor, pre-trained on ImageNet, and incorporates few-shot learning with prototypical networks to adapt to novel interference classes with limited labeled data.

## Key Results
- Achieves classification accuracies exceeding 98% across all tested datasets
- Outperforms MSE-based early stopping approaches on adaptation tasks
- Demonstrates superior performance in balancing underrepresented classes while maintaining overall accuracy
- Successfully adapts to novel interference classes with classification accuracies up to 99.989%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic epoch adjustment via MMD reduces overfitting on dominant classes while improving adaptation to underrepresented classes.
- Mechanism: The method computes the MMD loss between local and global model feature embeddings after each round. If the discrepancy is low, the local model reduces its training epochs (Ei,r), focusing on fine-tuning harder-to-learn classes. If high, it trains up to Emax epochs to better align distributions.
- Core assumption: Lower MMD indicates better alignment of feature representations between local and global models, enabling fewer epochs without sacrificing performance.
- Evidence anchors:
  - [abstract]: "We introduce a dynamic early stopping method to balance out-of-distribution classes based on representation learning, specifically utilizing the maximum mean discrepancy of feature embeddings between local and global models."
  - [section III]: "The number of epochs are calculated by Ei,r = [Emax,i,r · d||f(hg(ω0)) − f(hi(ωr))|| / max(||f(hg(ω0)) − f(hi(ωr))||)]."
  - [corpus]: Weak/no direct support; corpus neighbors mention early stopping but not MMD-based balancing.
- Break condition: If MMD fails to reflect true representation alignment, early stopping could prematurely halt learning on critical classes.

### Mechanism 2
- Claim: MMD is more robust than MSE for measuring embedding discrepancies, especially with scale and outlier sensitivity.
- Mechanism: MMD computes the squared difference between mean feature embeddings of global and local models. It is less sensitive to feature magnitude and more robust to outliers compared to MSE.
- Core assumption: MMD captures domain shift more effectively, leading to better training decisions.
- Evidence anchors:
  - [section III]: "MSE is highly sensitive to the scale and magnitude of the feature embeddings and is non-robust to outliers... the maximum mean discrepancy (MMD) loss has emerged as a standard metric for domain adaptation."
  - [abstract]: "Our proposed MMD-based early stopping method is primarily designed for GNSS interference monitoring applications but can be generalized to a wide range of other use cases."
  - [corpus]: No direct MMD vs MSE comparison in neighbors; indirect relevance only.
- Break condition: If the feature space is not smooth or if classes are not well-separated, MMD may misrepresent true distributional differences.

### Mechanism 3
- Claim: Few-shot learning with prototypical networks enables efficient adaptation to novel interference classes with limited labeled data.
- Mechanism: Local models fine-tune on novel classes using support and query sets. The class is assigned by nearest-prototype distance in the embedding space, enabling adaptation without large labeled datasets.
- Core assumption: Prototypes in the embedding space can represent class centers effectively for novel classes.
- Evidence anchors:
  - [abstract]: "Each device trains the model on its local data and shares only the model updates... a significant challenge in FL is managing the feature distribution of novel, unbalanced data across devices."
  - [section III]: "The primary objective is to learn a representation that minimizes intra-class distances while maximizing inter-class distances... the class assigned to the query image is determined by the smallest distance to the average of the support images."
  - [corpus]: No explicit mention of prototypical networks in neighbors; weak relevance.
- Break condition: If novel classes are too dissimilar or overlap heavily, prototypes may not generalize effectively.

## Foundational Learning

- Concept: Federated Averaging with Momentum (FedAvgM)
  - Why needed here: Provides the baseline aggregation mechanism that balances communication efficiency with convergence stability across heterogeneous clients.
  - Quick check question: What is the main difference between FedAvg and FedAvgM in terms of handling non-iid data?

- Concept: Maximum Mean Discrepancy (MMD)
  - Why needed here: Serves as a robust metric for measuring domain shift between local and global models, enabling dynamic training decisions.
  - Quick check question: Why is MMD preferred over MSE for measuring embedding distribution differences?

- Concept: Few-shot Learning with Prototypical Networks
  - Why needed here: Allows local models to adapt to new interference classes with minimal labeled data, crucial for real-world deployment with novel jammers.
  - Quick check question: How does the prototypical network assign a class label to a query image?

## Architecture Onboarding

- Component map:
  - Global model: Pre-trained ResNet18 → Fine-tuned on base classes → Aggregates weights from locals
  - Local models: Copy global weights → Fine-tune on novel classes → Compute MMD loss → Report weights + epochs
  - MMD module: Computes feature embedding discrepancy → Determines epoch adjustment
  - Data pipeline: Spectrogram generation from IQ snapshots → Class-balanced sampling

- Critical path:
  1. Global model initialization and base training
  2. Weight distribution to local models
  3. Local fine-tuning with MMD-based early stopping
  4. Weight aggregation and global model update
  5. Weight redistribution for next round

- Design tradeoffs:
  - Epoch reduction vs. underfitting: Aggressive epoch cutting may hurt learning on complex classes
  - MMD vs. MSE: MMD is more robust but computationally heavier
  - Communication vs. privacy: Selective weight sharing vs. full gradients

- Failure signatures:
  - Accuracy plateaus early → Possible over-aggressive epoch reduction
  - Confusion between similar classes → Need better embedding separation or data augmentation
  - High variance across rounds → Possible instability in MMD estimation

- First 3 experiments:
  1. Baseline FedAvgM without early stopping on highway dataset → Confirm performance drop without dynamic epochs
  2. MSE-based early stopping on controlled small-scale dataset → Compare robustness vs. MMD
  3. MMD early stopping with varied Emax ranges → Tune sensitivity to distribution shift

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed MMD-based early stopping method compare to other domain adaptation techniques in federated learning for GNSS interference classification?
- Basis in paper: [explicit] The paper states that MMD loss has emerged as a standard metric for domain adaptation and cross-modal retrieval applications, and their method achieves higher accuracy than MSE-based approaches.
- Why unresolved: The paper only compares their MMD-based method to MSE-based early stopping and baseline FL methods, not to other domain adaptation techniques like adversarial domain adaptation or maximum classifier discrepancy.
- What evidence would resolve it: Comparative experiments between MMD-based early stopping and other domain adaptation techniques in the same federated learning framework for GNSS interference classification.

### Open Question 2
- Question: What is the optimal number of local models (M) for federated learning in GNSS interference classification across different highway environments?
- Basis in paper: [inferred] The paper uses 4 local models in their experiments but does not explore how varying the number of local models affects classification performance or communication efficiency.
- What evidence would resolve it: Systematic experiments varying the number of local models while keeping other parameters constant to identify the point of diminishing returns in classification accuracy.

### Open Question 3
- Question: How does the proposed method perform when adapting to completely novel interference classes not seen in any of the training datasets?
- Basis in paper: [inferred] The paper focuses on adapting to new classes between datasets and new scenarios within datasets, but does not test zero-shot or few-shot learning capabilities for entirely novel interference types.
- What evidence would resolve it: Evaluation of the federated learning system on datasets containing interference classes that are completely absent from the training data, measuring its ability to classify these novel classes.

## Limitations

- The epoch reduction formula depends on empirically chosen parameters (Emin, Emax) that may not generalize across different dataset characteristics
- The method assumes sufficient base training data for the initial global model, which may not hold in highly dynamic interference scenarios where novel classes emerge rapidly
- Reliance on MMD as a proxy for feature alignment may not fully capture complex domain shifts in heterogeneous interference environments

## Confidence

- High confidence: Classification accuracy results (>98%) and comparison against FedAvgM baseline
- Medium confidence: MMD-based early stopping mechanism effectiveness, due to limited ablation studies
- Medium confidence: Few-shot learning adaptation claims, as the prototypical network implementation details are not fully specified

## Next Checks

1. Ablation study comparing MMD-based early stopping against MSE-based and fixed-epoch baselines across all four datasets to quantify the specific contribution of MMD
2. Sensitivity analysis of epoch parameters (Emin, Emax) to determine robustness to hyperparameter choices and their impact on underrepresented class performance
3. Cross-dataset generalization test where the global model trained on one environment is evaluated on another to assess true adaptation capability beyond in-domain improvements