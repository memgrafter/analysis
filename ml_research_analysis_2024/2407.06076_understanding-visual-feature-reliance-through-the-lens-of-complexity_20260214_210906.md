---
ver: rpa2
title: Understanding Visual Feature Reliance through the Lens of Complexity
arxiv_id: '2407.06076'
source_url: https://arxiv.org/abs/2407.06076
tags:
- features
- feature
- complexity
- learning
- complex
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a metric to quantify feature complexity in
  deep vision models, based on V-information that accounts for computational constraints.
  The authors extract 10,000 features from an ImageNet-trained ResNet50 and measure
  their complexity at each training epoch.
---

# Understanding Visual Feature Reliance through the Lens of Complexity

## Quick Facts
- arXiv ID: 2407.06076
- Source URL: https://arxiv.org/abs/2407.06076
- Reference count: 40
- Primary result: Novel V-information metric reveals how deep vision models prioritize simpler features and build complex ones incrementally during training

## Executive Summary
This paper introduces a metric to quantify feature complexity in deep vision models, based on V-information that accounts for computational constraints. The authors extract 10,000 features from an ImageNet-trained ResNet50 and measure their complexity at each training epoch. They find that complex features require more computation to extract and tend to be learned later in training. Simpler features dominate early in training and are propagated through residual connections. Complex features are incrementally built through the main branch. The study reveals a "simplicity bias" where models prefer simpler features for decision-making, and surprisingly, important features become simpler over time as they are shifted to earlier layers. This suggests a "sedimentation process" where foundational elements are established near the network's input. The work provides insights into feature learning dynamics and the interplay between complexity and importance in neural networks.

## Method Summary
The authors developed a V-information-based metric to quantify feature complexity in deep neural networks. They extracted 10,000 features from an ImageNet-trained ResNet50 and measured their complexity at each training epoch. The analysis tracked when features were learned, their computational requirements, and their importance to model decisions. The study examined how features propagated through residual connections versus the main branch, and how feature importance and complexity evolved throughout training.

## Key Results
- Complex features require more computation to extract and are learned later in training
- Simpler features dominate early in training and are propagated through residual connections
- Important features become simpler over time as they are shifted to earlier layers

## Why This Works (Mechanism)
The paper's findings reveal that deep vision models exhibit a "simplicity bias" where they prioritize simpler features for decision-making. This bias emerges from the computational constraints captured by the V-information metric. The mechanism works because simpler features can be computed with less computational resources, making them more efficient for the model to rely upon. The incremental building of complex features through the main branch allows the model to gradually construct sophisticated representations while maintaining computational efficiency.

## Foundational Learning
1. **V-information metric**: A measure that quantifies the computational resources required to extract features, providing a principled way to assess feature complexity.
   - Why needed: Traditional information theory metrics don't account for computational constraints that are critical in neural network optimization.
   - Quick check: Compare V-information scores with alternative complexity metrics like parameter count or FLOPs.

2. **Feature importance dynamics**: How the importance of features changes throughout training, with important features becoming simpler over time.
   - Why needed: Understanding how models prioritize and refine features is crucial for interpretability and efficiency.
   - Quick check: Track feature importance using ablation studies or integrated gradients.

3. **Residual connection propagation**: How simpler features are propagated through skip connections while complex features are built in the main branch.
   - Why needed: This architectural choice significantly impacts how features are learned and utilized.
   - Quick check: Compare feature propagation patterns in architectures with and without residual connections.

## Architecture Onboarding

**Component map:** Input -> ResNet50 layers -> Feature extraction (10,000 features) -> V-information complexity measurement -> Training epoch tracking -> Importance assessment

**Critical path:** Feature extraction from trained model → Complexity quantification via V-information → Temporal tracking of feature learning → Importance determination → Analysis of simplicity bias and sedimentation

**Design tradeoffs:** The study focuses on ResNet50 architecture, which may limit generalizability to other architectures. The V-information metric, while theoretically grounded, represents a novel approach that requires validation across different contexts.

**Failure signatures:** If the V-information metric doesn't capture meaningful complexity differences, or if the simplicity bias doesn't manifest across different architectures or datasets, the core findings would be challenged.

**First experiments:**
1. Replicate the analysis on Vision Transformers and ConvNext architectures
2. Test the V-information metric on synthetic datasets with known complexity gradients
3. Conduct intervention studies where complex features are artificially introduced earlier in training

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis based on a single ResNet50 model trained on ImageNet, raising generalizability concerns
- V-information metric is novel and its behavior in different contexts remains to be fully validated
- Focus on feature complexity without considering semantic meaning or task relevance

## Confidence
- Claim: Complex features are "incrementally built" through the main branch (Medium confidence)
- Claim: "Sedimentation process" hypothesis (Medium confidence)
- Claim: Generalizability across architectures and datasets (Low confidence)

## Next Checks
1. Replicate the analysis across multiple architectures (e.g., Vision Transformers, ConvNext) and datasets to test generalizability
2. Conduct ablation studies where specific complex features are artificially introduced earlier in training to test causality
3. Implement feature tracking across layers throughout training to directly observe the proposed "sedimentation" mechanism rather than inferring it from final states