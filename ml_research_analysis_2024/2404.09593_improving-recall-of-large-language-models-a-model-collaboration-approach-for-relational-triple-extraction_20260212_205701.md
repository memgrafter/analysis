---
ver: rpa2
title: 'Improving Recall of Large Language Models: A Model Collaboration Approach
  for Relational Triple Extraction'
arxiv_id: '2404.09593'
source_url: https://arxiv.org/abs/2404.09593
tags:
- extraction
- triples
- llms
- pairs
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of low recall in extracting multiple
  relational triples from complex sentences using large language models (LLMs). While
  LLMs can accurately extract triples from simple sentences through few-shot learning
  or fine-tuning, they often miss triples in complex sentences with multiple entities
  and relations.
---

# Improving Recall of Large Language Models: A Model Collaboration Approach for Relational Triple Extraction

## Quick Facts
- arXiv ID: 2404.09593
- Source URL: https://arxiv.org/abs/2404.09593
- Reference count: 0
- Primary result: Proposes an evaluation-filtering framework integrating small models with LLMs to significantly improve recall in extracting multiple relational triples from complex sentences.

## Executive Summary
This paper addresses the problem of low recall in extracting multiple relational triples from complex sentences using large language models (LLMs). While LLMs can accurately extract triples from simple sentences through few-shot learning or fine-tuning, they often miss triples in complex sentences with multiple entities and relations. The authors propose an evaluation-filtering framework that integrates small models with LLMs for relational triple extraction. The framework includes an evaluation model that can extract related entity pairs with high precision using a simple labeling principle and a deep neural network. The evaluation model outputs token pair evaluation matrices, which are embedded as prompts into the extraction process of the LLMs. The authors conduct extensive experiments on several public datasets, demonstrating that their method can significantly improve the recall of LLMs in relational triple extraction, especially from complex sentences containing multiple triples.

## Method Summary
The authors propose an evaluation-filtering framework that integrates small models with LLMs for relational triple extraction. The framework includes an evaluation model that extracts related entity pairs with high precision using a simple labeling principle and a deep neural network. The evaluation model outputs token pair evaluation matrices, which are embedded as prompts into the extraction process of the LLMs. The method uses a BERT-based encoder and a 2-dim decoder to generate token pair evaluation matrices. These matrices are used to filter candidate entity pairs, which are then embedded as prompts to guide LLMs in extracting relational triples. The authors also employ LoRA for efficient fine-tuning of LLMs on the extraction task.

## Key Results
- The evaluation-filtering framework significantly improves the recall of LLMs in extracting multiple relational triples from complex sentences.
- The method achieves higher precision on complex sentences when the evaluation model is embedded into traditional extraction models.
- Experiments on public datasets (NYT series, Wiki-KBP, SKE21, HacRED) demonstrate consistent improvements across different sentence complexities.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The evaluation model provides high-precision candidate entity pairs to LLMs, improving recall without sacrificing precision.
- Mechanism: The evaluation model scores token pairs using a 2D attention matrix derived from BERT/RoBERTa embeddings. High-scoring pairs are passed as prompts to LLMs, which use their superior language understanding to assign relations.
- Core assumption: Token-level scoring can accurately capture entity pair relevance without explicit span detection.
- Evidence anchors:
  - [abstract]: "The framework includes an evaluation model that can extract related entity pairs with high precision."
  - [section 3.4.2]: "We compute the 2-dim attention matrix as the output of the decoder" and "Aij = qT i kj/ √ d2"
  - [corpus]: Weak - only 8 related papers found, average FMR 0.526 suggests moderate relevance.

### Mechanism 2
- Claim: Fine-tuning LLMs with LoRA improves extraction accuracy compared to zero/few-shot prompting.
- Mechanism: LoRA adds low-rank decomposition matrices to frozen LLM weights, allowing efficient adaptation to extraction tasks without full fine-tuning.
- Core assumption: The downstream extraction task requires minimal parameter updates compared to original pretraining.
- Evidence anchors:
  - [section 3.7]: "LoRA is a parameter-efficient fine-tuning (PEFT) method. It freezes the large-scale parameters... through low-rank decomposition"
  - [section 4.3]: "the triple extraction results of various LLMs... have been significantly enhanced" with evaluation-filtering
  - [corpus]: No direct evidence found in neighbors.

### Mechanism 3
- Claim: Two-stage extraction (LLM + evaluation filtering) outperforms single-stage extraction on complex sentences.
- Mechanism: First stage extracts triples directly; second stage uses evaluation model to filter candidates and prompts LLM to refine results.
- Core assumption: LLMs can improve upon filtered candidates by leveraging contextual understanding.
- Evidence anchors:
  - [section 3.1]: "Our LLM-based relational triple extraction framework comprises two stages"
  - [section 4.3]: "The results indicate that when a sentence contains a substantial number of triples, the direct application of LLMs... often yields poor results"
  - [corpus]: No direct evidence found in neighbors.

## Foundational Learning

- Concept: Token-level evaluation vs entity-level evaluation
  - Why needed here: Complex sentences have overlapping entities and relations; token-level scoring handles unseen entities and noisy spans better.
  - Quick check question: Why does the evaluation model operate on token pairs rather than entity spans?

- Concept: Low-rank adaptation (LoRA) in fine-tuning
  - Why needed here: Full fine-tuning is computationally expensive; LoRA enables efficient task adaptation while preserving LLM capabilities.
  - Quick check question: How does LoRA differ from standard fine-tuning in terms of parameter updates?

- Concept: Self-attention mechanism for pairwise scoring
  - Why needed here: Enables efficient O(N²) scoring of all token pairs in a sentence using transformer architecture.
  - Quick check question: What is the computational complexity of scoring all token pairs in a sentence of length N?

## Architecture Onboarding

- Component map: Input sentence → BERT/RoBERTa encoder → 2D attention decoder → Token pair evaluation matrix → Candidate filtering → LLM (LoRA-tuned) with prompt → Final triples

- Critical path:
  1. Encode sentence to token embeddings
  2. Compute token pair attention scores
  3. Filter candidates by threshold
  4. Construct prompt with filtered pairs
  5. LLM extracts/refines triples
  6. Output final results

- Design tradeoffs:
  - Token-level vs entity-level evaluation: More flexible but noisier
  - 2D attention vs separate relation classification: Simpler but less explicit
  - LoRA vs full fine-tuning: Faster but potentially less accurate

- Failure signatures:
  - Low precision: Evaluation model over-generates candidates
  - Low recall: Evaluation model misses positive pairs or LLM ignores filtered candidates
  - Slow inference: Large evaluation matrices or complex prompt construction

- First 3 experiments:
  1. Baseline: LLM extraction without evaluation filtering
  2. Ablation: Remove second stage (LLM refinement) to test necessity
  3. Ablation: Remove candidate filtering to measure evaluation model impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the evaluation-filtering framework scale with increasing sentence complexity (number of triples and entities)?
- Basis in paper: [explicit] The paper demonstrates improved recall for complex sentences containing multiple triples, but does not extensively analyze performance scaling with increasing complexity.
- Why unresolved: The paper provides results for sentences with varying numbers of triples, but does not systematically investigate the relationship between sentence complexity and framework performance.
- What evidence would resolve it: Experiments analyzing framework performance on sentences with a wider range of triple counts and entity densities, including extremely complex sentences.

### Open Question 2
- Question: What is the impact of different instruction templates and prompt engineering strategies on the performance of the LLM-based extraction?
- Basis in paper: [explicit] The paper presents an instruction template but does not explore alternative templates or prompt engineering techniques.
- Why unresolved: The effectiveness of the proposed instruction template is demonstrated, but the impact of variations in prompt design on extraction performance remains unexplored.
- What evidence would resolve it: Comparative experiments evaluating the performance of the framework using different instruction templates and prompt engineering strategies.

### Open Question 3
- Question: How does the evaluation-filtering framework compare to other state-of-the-art methods for complex relational triple extraction, such as multi-step or joint extraction approaches?
- Basis in paper: [explicit] The paper compares the framework to base LLMs and traditional small models, but does not directly compare it to other complex extraction methods.
- Why unresolved: The framework's performance is evaluated against simpler baselines, but its relative effectiveness compared to more advanced extraction techniques is not established.
- What evidence would resolve it: Comparative experiments directly evaluating the framework against state-of-the-art complex extraction methods on the same datasets and metrics.

## Limitations

- The evaluation model's reliance on token-level scoring may struggle with multi-token entities, nested entities, or entities with overlapping spans.
- The 2D attention mechanism assumes linear token relationships that may not capture complex syntactic dependencies in sentences with long-range relations.
- LoRA fine-tuning, while computationally efficient, may not fully capture the nuanced language understanding required for complex triple extraction tasks.

## Confidence

**High Confidence**: The claim that LLMs struggle with multiple relational triples in complex sentences is well-supported by existing literature and the paper's empirical results. The observation that evaluation-filtering improves recall is also strongly evidenced by the experimental results showing consistent improvements across multiple datasets.

**Medium Confidence**: The claim that the evaluation model provides high-precision candidate entity pairs is supported by the methodology but lacks extensive ablation studies to quantify precision improvements. The assertion that LoRA fine-tuning is sufficient for the extraction task is plausible given the literature but not rigorously validated against full fine-tuning in the paper.

**Low Confidence**: The claim that the two-stage extraction process significantly outperforms single-stage approaches is based on limited comparisons and lacks analysis of failure cases. The paper does not adequately address scenarios where the evaluation model might introduce noise or when LLM refinement might degrade rather than improve results.

## Next Checks

1. **Ablation Study on Token-Level Scoring**: Conduct experiments comparing the evaluation model's token-level approach against entity-level approaches (using NER systems) to quantify precision and recall differences, particularly for multi-token entities and nested entity structures.

2. **Robustness Testing on Noisy Data**: Test the framework's performance on intentionally corrupted input sentences with typos, missing punctuation, or non-standard formatting to evaluate its resilience to real-world data quality issues that could affect both the evaluation model and LLM performance.

3. **Parameter Sensitivity Analysis**: Systematically vary the evaluation model's threshold for candidate filtering and the LoRA rank parameter to identify optimal settings and understand the trade-offs between precision, recall, and computational efficiency across different dataset characteristics.