---
ver: rpa2
title: Automatic Extraction of Relationships among Motivations, Emotions and Actions
  from Natural Language Texts
arxiv_id: '2408.00966'
source_url: https://arxiv.org/abs/2408.00966
tags:
- action
- events
- event
- food
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a graph-based framework to explicitly reveal
  relationships among motivations, emotions, and actions from natural language texts.
  The proposed method builds a directed acyclic graph (MEA-DAG) that integrates a
  manually designed Nature Design graph representing human innate nature and Nurture
  Belief learned from developmental experiences.
---

# Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts

## Quick Facts
- arXiv ID: 2408.00966
- Source URL: https://arxiv.org/abs/2408.00966
- Reference count: 22
- Primary result: 63% of generated MEA-DAGs make logical sense

## Executive Summary
This paper introduces a graph-based framework that automatically extracts relationships among motivations, emotions, and actions from natural language texts without requiring manual annotation. The method builds a directed acyclic graph (MEA-DAG) that integrates a manually designed Nature Design graph representing human innate nature with Nurture Belief tuples learned from developmental experiences. By leveraging large language models and ASER event extraction patterns, the framework processes Amazon Fine Foods Reviews to generate 92,990 valid MEA-DAGs, with 63% judged to make logical sense through human evaluation.

## Method Summary
The framework extracts relationships among motivations, emotions, and actions by first building a manually designed Nature Design graph that represents human innate nature. It then uses large language models (GLM-4) to automatically generate Nurture Belief tuples mapping words to graph nodes without annotation. Events are extracted from text using ASER patterns combined with POS tagging and dependency parsing, focusing on food-related mental states. These events are linked to nodes via pattern matching and belief tuples, then forward transmission through the graph generates coherent motivation-emotion-action relationships. The method was evaluated on Amazon Fine Foods Reviews, generating 92,990 MEA-DAGs.

## Key Results
- Generated 92,990 valid MEA-DAGs from Amazon Fine Foods Reviews
- 63% of MEA-DAGs were judged to make logical sense by human evaluation
- Error analysis identified seven types of errors, with Event Linking Loss and ASER Extraction Loss being most frequent
- Long reviews showed higher error rates (43.4%) compared to short reviews (29.8%)

## Why This Works (Mechanism)

### Mechanism 1
- Large language models can replace manual annotation for building Nurture Belief tuples by generating semantic mappings from words to nodes
- LLM prompts are engineered to classify words (adjectives, verbs) into positive/negative emotion or experience feeling categories without requiring labeled datasets
- Core assumption: LLMs have sufficient semantic understanding to accurately categorize words into the correct node types

### Mechanism 2
- ASER event extraction patterns combined with POS tagging and dependency parsing can reliably identify food-related mental states from review texts
- Events matching specific keyword combinations (food + feeling, food + emotion, "I/We" + emotion, emotional action) are linked to corresponding nodes in Nature Design
- Core assumption: The defined keyword patterns are comprehensive enough to capture all relevant food-related mental state events

### Mechanism 3
- Forward transmission through the Nature Design graph can accurately propagate signals from activated nodes to generate coherent motivation-emotion-action relationships
- Activated nodes send signals along directed links to tail nodes, which then activate their own tail nodes, creating a chain of relationships
- Core assumption: The manually designed Nature Design graph structure correctly represents the causal relationships between motivations, emotions, and actions

## Foundational Learning

- **Directed Acyclic Graphs (DAGs)**: The framework relies on a manually designed DAG (Nature Design) to represent human motivations, emotions, and actions
  - Why needed here: To represent causal relationships without cycles that could create logical inconsistencies
  - Quick check question: Can you explain why a DAG is used instead of a cyclic graph for this application?

- **Event extraction using dependency parsing and POS tagging**: ASER extraction patterns depend on identifying specific syntactic structures in text to find relevant events
  - Why needed here: To accurately identify food-related mental state events from review texts
  - Quick check question: What POS tags and dependency relations would you look for to identify "I feel happy" as an emotion event?

- **Semantic understanding and word sense disambiguation**: The framework must correctly interpret word meanings in context to link events to appropriate nodes
  - Why needed here: To accurately classify words into emotion/feeling categories and link events to correct nodes
  - Quick check question: How would you determine whether "light" in "light coffee" refers to weight or flavor when linking to emotion/feeling nodes?

## Architecture Onboarding

- **Component map**: Nature Design Graph -> ASER Event Extractor -> LLM Filters -> Event Linking -> Forward Transmission Engine -> Action Classifier -> MEA-DAG Output
- **Critical path**: Text → ASER Extraction → Event Linking → Forward Transmission → Action Classification → MEA-DAG Output
- **Design tradeoffs**:
  - Manual vs. learned Nature Design: Manual design provides interpretability but may miss nuances
  - Pattern-based vs. semantic event extraction: Patterns are efficient but brittle; semantic understanding is more robust but computationally expensive
  - LLM reliance vs. rule-based filtering: LLMs provide flexibility but introduce uncertainty; rules are deterministic but inflexible
- **Failure signatures**:
  - Low percentage of logically sensible MEA-DAGs (current: 63%)
  - High frequency of specific error types (Event Linking Loss, ASER Extraction Loss)
  - Long review processing performs worse than short reviews
  - Inconsistent LLM outputs across similar inputs
- **First 3 experiments**:
  1. Test Nature Design completeness by manually analyzing MEA-DAGs to identify missing nodes or relationships
  2. Evaluate ASER pattern coverage by running extracted events through a human annotator to identify missed patterns
  3. Measure LLM classification accuracy by creating a test set of words with ground truth node labels and comparing LLM predictions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the Nature Design graph be automatically extended with new nodes and links based on perceived events and their outcomes?
- Basis in paper: The paper mentions that one interesting direction of improvement is to equip the algorithm with learning ability, being able to automatically build new nodes and links when it perceives new events and their outcomes
- Why unresolved: The current Nature Design graph is manually built and limited in scope, which leads to Event Linking Loss errors when critical information is not incorporated in the MEA-DAG
- What evidence would resolve it: An automated method that can analyze new events, infer their relationships to existing nodes, and dynamically add new nodes and links to the Nature Design graph would resolve this question

### Open Question 2
- Question: How can the framework be improved to handle lengthy reviews more effectively?
- Basis in paper: The paper shows that the error rate for long reviews (43.4%) is higher than for short reviews (29.8%), indicating that the current methods are not well-suited for processing lengthy reviews
- Why unresolved: The main bottlenecks of processing long reviews lie in lack of rich nodes and links in Nature Design, as well as lack of comprehensive and in-depth understanding of a sentence
- What evidence would resolve it: An improved framework that can effectively handle lengthy reviews would have lower error rates for long reviews compared to the current methods, and would address the specific error types (Event Linking Loss, ASER Extraction Loss, and Wrong Subsequent Action) that are more prevalent in long reviews

### Open Question 3
- Question: How can the framework incorporate a mechanism for automatic error-correction of Nurture Belief?
- Basis in paper: The paper mentions that through subsequent experiences, humans consistently reinforce correct beliefs and fix wrong beliefs, and this mechanism should work perfectly for the Wrong Belief error type
- Why unresolved: The current methods have no ability to automatically correct errors in Nurture Belief, which leads to events being linked to incorrect nodes
- What evidence would resolve it: An automatic error-correction mechanism that can identify and correct errors in Nurture Belief based on subsequent experiences and feedback would resolve this question

## Limitations

- The manually designed Nature Design graph structure is not fully validated against real-world human behavior data
- LLM-generated Nurture Belief tuples rely on model generalization without formal accuracy measurements
- ASER extraction patterns may miss context-dependent emotional expressions not captured by predefined keyword combinations

## Confidence

- **High Confidence**: The overall framework architecture and the concept of using LLMs for automatic extraction without annotation
- **Medium Confidence**: The ASER event extraction methodology and forward transmission mechanism
- **Low Confidence**: The completeness and accuracy of the manually designed Nature Design graph

## Next Checks

1. **Graph Structure Validation**: Conduct a systematic comparison between generated MEA-DAGs and human-annotated mental state graphs from a subset of reviews to identify missing nodes and incorrect relationships in the Nature Design graph.

2. **Event Extraction Coverage Analysis**: Use human annotators to manually tag all food-related emotional expressions in 100 randomly selected reviews, then measure the recall of ASER patterns against this gold standard.

3. **LLM Classification Accuracy Test**: Create a benchmark dataset of 500 words with ground truth classifications (positive/negative emotion/experience feeling) and evaluate the GLM-4 model's accuracy, precision, and recall on this dataset.