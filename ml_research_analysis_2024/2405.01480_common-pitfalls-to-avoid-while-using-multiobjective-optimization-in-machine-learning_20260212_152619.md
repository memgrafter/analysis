---
ver: rpa2
title: Common pitfalls to avoid while using multiobjective optimization in machine
  learning
arxiv_id: '2405.01480'
source_url: https://arxiv.org/abs/2405.01480
tags:
- pareto
- https
- optimization
- neural
- front
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses common pitfalls when applying multiobjective
  optimization (MOO) in machine learning, particularly for physics-informed neural
  networks (PINNs). The authors focus on three optimization methods - weighted sum
  (WS), multiobjective gradient descent algorithm (MGDA), and NSGA-II - to identify
  challenges and provide guidelines for proper application.
---

# Common pitfalls to avoid while using multiobjective optimization in machine learning

## Quick Facts
- arXiv ID: 2405.01480
- Source URL: https://arxiv.org/abs/2405.01480
- Reference count: 40
- Multiobjective optimization (MOO) pitfalls in physics-informed neural networks (PINNs) identified through experiments with weighted sum, MGDA, and NSGA-II methods

## Executive Summary
This paper systematically identifies common pitfalls when applying multiobjective optimization in machine learning, focusing on physics-informed neural networks. Through experiments on three equations of increasing complexity, the authors demonstrate that MOO effectiveness depends critically on factors like objective conflict, Pareto front geometry, and proper optimization method selection. The study provides practical guidelines for avoiding these pitfalls and emphasizes the importance of careful problem characterization before applying MOO techniques.

## Method Summary
The study implements three multiobjective optimization methods - weighted sum (WS), multiobjective gradient descent algorithm (MGDA), and NSGA-II - to identify challenges in MOO applications. Experiments use PINNs trained on three equations (logistic, heat, and Rayleigh-Bénard convection) with exact solutions and controlled noise injection. The WS method combines data and physics losses with varying weights, MGDA computes common descent directions from both gradient sets, and NSGA-II uses evolutionary optimization. Pareto fronts are analyzed and visualized across different network sizes and noise levels.

## Key Results
- MOO is only beneficial when objectives are truly conflicting; non-conflicting objectives yield single-point Pareto fronts
- Weighted sum method cannot find non-convex regions of Pareto fronts due to geometric limitations
- Gradient normalization is essential for MGDA convergence and prevents numerical instability
- NSGA-II scales poorly with network size, while gradient-based methods perform better for deep networks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pareto optimality requires conflict between objectives for meaningful trade-offs
- **Mechanism:** If objectives share a common minimizer, all weighting combinations yield the same solution, eliminating the need for MOO
- **Core assumption:** Conflicting objectives create distinct Pareto optimal solutions across the weight space
- **Evidence anchors:**
  - [abstract] "A key aspect of MOO is the existence of a Pareto set, rather than a single optimal solution, which represents the optimal trade-offs between different objectives"
  - [section] "We call the objective functions conflicting if they do not have a joint minimizer. If the objective functions are not conflicting, the Pareto front consists only of a single point"
  - [corpus] Weak evidence - corpus papers focus on method development rather than conflict verification
- **Break condition:** Objectives become aligned due to problem structure or model expressivity

### Mechanism 2
- **Claim:** Weighted sum method can only find convex regions of the Pareto front
- **Mechanism:** WS optimization pushes the weighted hyperplane orthogonal to α until it contacts the attainable set; non-convex regions are never contacted
- **Core assumption:** The geometry of the attainable set determines which regions are reachable via WS
- **Evidence anchors:**
  - [section] "While the WS method is easy to implement, it is not capable of locating the non-convex parts of the Pareto front"
  - [section] "It can be shown that any (locally) optimal solution θ∗ to (WS) is a (locally) weakly Pareto optimal solution for (MOP)"
  - [corpus] Moderate evidence - related papers discuss decomposition methods but not WS limitations explicitly
- **Break condition:** The Pareto front becomes entirely convex

### Mechanism 3
- **Claim:** Gradient normalization is essential for MGDA convergence
- **Mechanism:** Without normalization, magnitude differences between gradients can cause numerical instability and poor direction selection
- **Core assumption:** MGDA's direction computation assumes comparable gradient scales across objectives
- **Evidence anchors:**
  - [section] "To mitigate the effect of differences in magnitudes of gradients, it is important to normalize the gradients in each iteration before calculating the descent direction"
  - [section] "We observe that in Figure 11b where gradients are normalized, the points on the front are more evenly distributed compared to Figure 11a where the gradients have not been normalized"
  - [corpus] Weak evidence - corpus focuses on evolutionary algorithms rather than gradient-based methods
- **Break condition:** Objectives have naturally comparable scales or use adaptive gradient methods

## Foundational Learning

- **Concept:** Pareto optimality definition
  - Why needed here: Understanding when solutions are truly optimal trade-offs versus dominated solutions
  - Quick check question: Can you identify if a solution is Pareto optimal given two objective values?

- **Concept:** Convex vs non-convex Pareto fronts
  - Why needed here: Determines which optimization methods will successfully find the full Pareto front
  - Quick check question: Given two objective functions, how would you determine if their Pareto front is convex?

- **Concept:** Multiobjective gradient descent algorithm mechanics
  - Why needed here: MGDA requires solving a quadratic subproblem to find common descent directions
  - Quick check question: What is the mathematical form of the MGDA direction computation?

## Architecture Onboarding

- **Component map:** Data → Model → Optimization → Pareto analysis → Visualization
- **Critical path:** Collocation points and noise injection → Feed-forward networks with varying sizes → WS, MGDA, NSGA-II implementations → Pareto front analysis and non-dominance filtering → Visualization
- **Design tradeoffs:**
  - Network size vs. expressivity (affects objective conflict)
  - Learning rate vs. convergence stability (affects plateau behavior)
  - Sampling density vs. computational cost (affects Pareto front resolution)
- **Failure signatures:**
  - Single point Pareto front (no objective conflict)
  - Spiky loss curves during training (poor convergence)
  - Clustered points without proper non-dominance filtering
- **First 3 experiments:**
  1. Logistic equation with zero noise to verify no conflict case
  2. Heat equation with moderate noise to observe convex Pareto front formation
  3. WS vs MGDA comparison on logistic equation to demonstrate method differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we systematically detect and measure objective conflicts in multi-task deep learning problems before applying multiobjective optimization?
- Basis in paper: [explicit] The paper discusses that MOO is only beneficial if objectives are conflicting and critiques previous studies where MOO was used despite non-conflicting objectives
- Why unresolved: While the paper mentions computing gradients to check alignment and running NSGA-II briefly as potential solutions, there is no established quantitative metric or systematic approach for determining objective conflict in DL settings
- What evidence would resolve it: A validated metric or diagnostic tool that quantifies objective conflict levels in DL problems, along with empirical studies showing its effectiveness across different ML tasks

### Open Question 2
- Question: What stopping criteria can effectively balance convergence and overfitting prevention for evolutionary algorithms in multiobjective deep learning?
- Basis in paper: [explicit] The paper notes that evolutionary algorithms like NSGA-II struggle with convergence detection and overfitting, unlike gradient-based methods which can use validation losses
- Why unresolved: The paper identifies this as a challenge but doesn't propose specific solutions beyond noting the difficulty of applying gradient-based stopping criteria to population-based methods
- What evidence would resolve it: A novel stopping criterion specifically designed for evolutionary algorithms in DL that reliably prevents overfitting while ensuring adequate convergence

### Open Question 3
- Question: How does network architecture expressiveness influence the structure and existence of Pareto fronts in multiobjective deep learning problems?
- Basis in paper: [explicit] The paper demonstrates that using a smaller, less expressive network for the Rayleigh-Bénard convection problem created artificial conflicts between objectives, producing distinct Pareto fronts compared to larger networks
- Why unresolved: While the paper shows this effect exists, it doesn't explore the relationship systematically or provide guidelines for selecting appropriate architectures based on problem characteristics
- What evidence would resolve it: A systematic study mapping network capacity to Pareto front characteristics across multiple problem types, establishing clear guidelines for architecture selection in MOO applications

## Limitations
- Experiments limited to physics-informed neural networks, which may not generalize to other ML domains
- Reliance on synthetic data with controlled noise levels rather than real-world complexities
- Focus on only three optimization methods without exploring the full space of MOO approaches
- Limited exploration of network architecture impacts beyond size variations

## Confidence
- **High Confidence**: Claims about Pareto front geometry requirements (convexity, conflict necessity) - well-established theoretical foundations
- **Medium Confidence**: Method-specific performance comparisons (WS vs MGDA vs NSGA-II) - based on limited experiments across three problems
- **Medium Confidence**: Scaling observations for NSGA-II with network size - demonstrated but not systematically varied

## Next Checks
1. Test Pareto front identification on non-convex problems with varying network expressivity to validate claims about WS method limitations
2. Implement alternative MOO methods (e.g., epsilon-constraint, multiobjective genetic algorithms) to benchmark against the three methods studied
3. Apply the same experimental framework to standard supervised learning problems to assess domain transferability of identified pitfalls