---
ver: rpa2
title: Addressing Graph Heterogeneity and Heterophily from A Spectral Perspective
arxiv_id: '2410.13373'
source_url: https://arxiv.org/abs/2410.13373
tags:
- graph
- filtering
- meta-paths
- heterogeneous
- meta-path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes H2SGNN, a spectral graph neural network for
  heterogeneous graphs with heterophily. The method combines local independent filtering,
  which applies different polynomial filters to meta-paths with varying homophily
  levels, and global hybrid filtering, which uses learnable coefficients to combine
  meta-paths and explore higher-order neighbors.
---

# Addressing Graph Heterogeneity and Heterophily from A Spectral Perspective

## Quick Facts
- arXiv ID: 2410.13373
- Source URL: https://arxiv.org/abs/2410.13373
- Reference count: 40
- Outperforms state-of-the-art methods with average improvements of 1.2% and 0.9% on IMDB and AMiner datasets

## Executive Summary
This paper addresses the challenge of heterogeneous graphs with heterophily by proposing H2SGNN, a spectral graph neural network that combines local independent filtering and global hybrid filtering. The method applies different polynomial filters to meta-paths with varying homophily levels while exploring higher-order neighbors through learnable coefficients. Experiments on four datasets demonstrate superior performance compared to existing methods while using fewer parameters and less memory. The learned filters also provide interpretability by implicitly reflecting graph homophily.

## Method Summary
H2SGNN is a two-module architecture that addresses graph heterogeneity and heterophily from a spectral perspective. The first module, local independent filtering, segments the heterogeneous graph into subgraphs based on different meta-paths and applies separate polynomial filters to each subgraph, with learnable coefficients per meta-path and per polynomial basis order. The second module, global hybrid filtering, constructs a weighted sum of meta-path adjacency matrices and applies polynomial filtering to this aggregated matrix, which theoretically corresponds to terms in a multivariate non-commutative polynomial. The method uses cross-entropy loss on training nodes and evaluates performance using Micro-F1 and Macro-F1 scores.

## Key Results
- Achieves average improvements of 1.2% and 0.9% on IMDB and AMiner datasets respectively
- Uses fewer parameters and less memory compared to existing methods (PSHGCN has several times more parameters)
- Demonstrates interpretability through learned filters that reflect graph homophily levels
- Shows robustness to heterophily with 2.0% and 2.5% average improvements on heterophilic graphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The local independent filtering module learns node representations that adapt to different homophily levels across meta-paths.
- Mechanism: The method segments the heterogeneous graph into subgraphs based on different meta-paths and applies separate polynomial filters to each subgraph, with learnable coefficients per meta-path and per polynomial basis order.
- Core assumption: Different meta-paths in a heterogeneous graph exhibit varying degrees of homophily, and applying a uniform filter across all meta-paths is suboptimal.
- Evidence anchors:
  - [abstract] "Local independent filtering adaptively learns node representations under different homophily, while global hybrid filtering exploits high-order neighbors to learn more possible meta-paths."
  - [section 3.1] "we employ meta-paths of induced homogeneous subgraphs to assess homophily... For the normalized adjacency matrix Ë†Að‘– of the ð‘–-th meta-path subgraph, the local individual filtering operation can be expressed as follows: Zð‘– = Î£ð‘˜ ð›¼ð‘–,ð‘˜â„Žð‘–,ð‘˜( Ë†Að‘–)XW"
  - [corpus] Evidence weak: No direct corpus paper discusses meta-path-specific homophily-aware filtering in spectral GNNs.
- Break condition: If meta-paths cannot be reliably defined or if all meta-paths exhibit similar homophily levels, the adaptive benefit diminishes.

### Mechanism 2
- Claim: The global hybrid filtering module is theoretically equivalent to a multivariate polynomial under certain conditions, enabling efficient exploration of higher-order neighbors.
- Mechanism: The method constructs a global adjacency matrix as a weighted sum of meta-path adjacency matrices (A = Î£áµ¢ ð›½áµ¢ Ë†Aáµ¢), then applies polynomial filtering to this aggregated matrix, which theoretically corresponds to terms in a multivariate non-commutative polynomial.
- Core assumption: Higher-order products of the global adjacency matrix capture interactions between different meta-paths, effectively learning additional meta-paths without explicitly defining them.
- Evidence anchors:
  - [abstract] "global hybrid filtering exploits high-order neighbors to learn more possible meta-paths... Global hybrid filtering is theoretically equivalent to a multivariate polynomial under certain conditions."
  - [section 3.2] "Global hybrid filtering can learn more possible meta-paths... the second-order product of the meta-paths ð‘ƒð´ð‘ƒ and ð‘ƒð¶ð‘ƒ will contain the four meta-paths ð‘ƒð´ð‘ƒð´ð‘ƒ, ð‘ƒð´ð‘ƒð¶ð‘ƒ, ð‘ƒð¶ð‘ƒð´ð‘ƒ, and ð‘ƒð¶ð‘ƒð¶ð‘ƒ"
  - [section 3.4] "Proposition 1. The ð‘›-order terms in the global hybrid filter correspond to terms in the multivariate non-commutative polynomial with ð‘› matrix products."
- Break condition: If the meta-paths used to construct the global adjacency matrix do not capture the relevant graph structure, the equivalence breaks down and performance degrades.

### Mechanism 3
- Claim: The combination of local independent filtering and global hybrid filtering achieves better performance with fewer parameters and less memory compared to existing methods.
- Mechanism: Local filtering uses R(K+1) parameters for R meta-paths and polynomial order K, while global filtering adds R+K+1 parameters. This linear scaling contrasts with exponential growth in multivariate polynomial methods.
- Core assumption: The linear parameter growth does not sacrifice expressive power because the global hybrid filtering captures higher-order interactions that would otherwise require exponentially more terms.
- Evidence anchors:
  - [section 3.4] "compared to PSHGCN, we add local individual filters to filter each meta-path separately... Table 2: Comparison of the number of parameters and terms... H2SGNN-ð‘™ð‘œð‘ð‘Žð‘™: R(K+1) parameters, H2SGNN-ð‘”ð‘™ð‘œð‘ð‘Žð‘™: R+K+1 parameters"
  - [section 4.5] "Figure 6 compares the parameter usage... PSHGCN has several times more parameters than the proposed H2SGNN on each dataset"
  - [corpus] Evidence weak: No direct corpus paper demonstrates spectral GNNs with both linear parameter growth and equivalent expressive power to multivariate polynomials.
- Break condition: If the order K must be extremely high to capture necessary graph structure, the linear parameter advantage may be offset by performance requirements.

## Foundational Learning

- Concept: Spectral graph neural networks and graph Fourier transform
  - Why needed here: The entire method is built on spectral filtering of graphs using polynomial approximations of spectral kernels
  - Quick check question: What is the relationship between the polynomial order K and the neighborhood range that can be aggregated in spectral GNNs?

- Concept: Meta-paths and induced homogeneous subgraphs in heterogeneous graphs
  - Why needed here: The method relies on defining meta-paths to segment the graph and assess homophily levels
  - Quick check question: How is the adjacency matrix of a meta-path defined in terms of the base relation matrices?

- Concept: Polynomial bases (monomial, Jacobi, Legendre) and their properties
  - Why needed here: The method allows choosing different polynomial bases for local and global filtering operations
  - Quick check question: What is the key difference between monomial, Jacobi, and Legendre polynomial bases in terms of their weight functions?

## Architecture Onboarding

- Component map: Feature matrix X -> Local Independent Filtering (R polynomial filters) -> Global Hybrid Filtering (weighted meta-path aggregation) -> Feature transformation -> Classification

- Critical path: Graph preprocessing â†’ Meta-path adjacency matrix construction â†’ Local filtering (R paths) â†’ Global filtering â†’ Feature transformation â†’ Classification

- Design tradeoffs:
  - Meta-path selection: Pre-defining meta-paths vs. automatically learning them
  - Polynomial basis choice: GPRGNN, Jacobi, or Legendre basis for different filtering modules
  - Order K: Higher order captures more structure but increases computation

- Failure signatures:
  - Poor performance: Meta-paths may not capture relevant graph structure or homophily levels
  - Memory issues: If K is too high or too many meta-paths are used
  - Training instability: Learnable coefficients may not converge properly

- First 3 experiments:
  1. Ablation study: Remove local filtering (only global) and remove global filtering (only local) to verify both components are necessary
  2. Parameter sensitivity: Vary polynomial order K to find optimal value and demonstrate linear parameter scaling
  3. Filter visualization: Plot learned filters for different meta-paths to verify they adapt to different homophily levels

## Open Questions the Paper Calls Out
- How can spectral GNNs be effectively applied to heterogeneous graphs without pre-defining any meta-paths?
- What is the theoretical limit of expressiveness for the proposed H2SGNN compared to full multivariate polynomial approaches?
- How does the proposed local independent filtering affect long-range dependencies in heterogeneous graphs?

## Limitations
- Requires pre-defining meta-paths in advance, which may not capture all relevant graph structure
- Theoretical equivalence to multivariate polynomials relies on specific conditions that may not hold in practice
- Meta-path selection is critical to performance and not addressed systematically

## Confidence
**High Confidence**: The experimental results showing improved performance over baselines (1.2% and 0.9% average improvements on IMDB and AMiner) appear well-supported by the data presented. The architectural design combining local and global filtering modules follows established spectral GNN principles.

**Medium Confidence**: The theoretical equivalence between global hybrid filtering and multivariate polynomials is mathematically sound but may not translate directly to practical performance gains. The interpretability claims about learned filters reflecting homophily levels need further validation beyond the visualizations provided.

**Low Confidence**: The generalizability of results across different datasets and the robustness of the method when meta-paths are not well-defined or when heterophily levels vary significantly within meta-paths.

## Next Checks
1. **Meta-path Sensitivity Analysis**: Systematically vary the number and types of meta-paths used and measure performance degradation to establish how critical meta-path selection is to the method's success.

2. **Real-time Filter Visualization**: Implement dynamic visualization of learned filters during training to verify that they indeed adapt to different homophily levels across meta-paths as claimed.

3. **Computational Complexity Benchmarking**: Measure actual inference time and memory usage during prediction (not just parameter count) to validate the claimed efficiency improvements compared to baselines.