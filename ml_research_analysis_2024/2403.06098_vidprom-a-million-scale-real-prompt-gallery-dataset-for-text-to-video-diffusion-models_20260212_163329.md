---
ver: rpa2
title: 'VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion
  Models'
arxiv_id: '2403.06098'
source_url: https://arxiv.org/abs/2403.06098
tags:
- prompts
- dataset
- videos
- vidprom
- text-to-video
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VidProM, the first large-scale dataset featuring
  1.67 million unique text-to-video prompts from real users and 6.69 million videos
  generated by four state-of-the-art diffusion models. The authors highlight the necessity
  of this dataset by comparing it to DiffusionDB, a text-to-image prompt-gallery dataset,
  and demonstrate how VidProM differs in terms of semantics, modality, and techniques.
---

# VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models

## Quick Facts
- **arXiv ID:** 2403.06098
- **Source URL:** https://arxiv.org/abs/2403.06098
- **Reference count:** 40
- **Primary result:** Introduces VidProM, the first large-scale dataset of 1.67M unique text-to-video prompts and 6.69M videos generated by four state-of-the-art diffusion models

## Executive Summary
VidProM is the first million-scale dataset specifically designed for text-to-video diffusion models, featuring 1.67 million unique prompts from real users and 6.69 million videos generated across four different models. The dataset addresses a critical gap in the field by providing real user prompts rather than synthetic captions, capturing authentic creative expression and model-specific generation characteristics. By including granular NSFW filtering, semantic deduplication, and comprehensive metadata, VidProM enables new research directions in prompt engineering, efficient video generation, and video copy detection for diffusion models.

## Method Summary
The dataset was constructed by scraping text-to-video prompts from Discord channels, generating videos using four state-of-the-art diffusion models (Pika, Text2Video-Zero, VideoCraft2, and ModelScope), and processing the results through a multi-stage pipeline. NSFW filtering was applied using Detoxify to assign six probability scores for different content categories. Semantic deduplication was performed using text-embedding-3-large embeddings with a cosine similarity threshold of 0.8. The resulting dataset includes prompts, generated videos, NSFW probabilities, embeddings, UUIDs, and timestamps, all distributed under CC BY-NC 4.0 license.

## Key Results
- 1.67 million unique text-to-video prompts collected from real users across Discord channels
- 6.69 million videos generated by four different state-of-the-art diffusion models
- Comprehensive NSFW filtering with six-category probability assignments for content safety
- Semantic deduplication ensuring diverse topic coverage with cosine similarity threshold of 0.8
- Dataset inspires new research directions in prompt engineering, efficient generation, and copy detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VidProM's diversity stems from combining real user prompts with multiple diffusion model generations, producing a richer distribution than caption-video datasets.
- Mechanism: By scraping prompts from Discord channels and generating videos across four different diffusion models, the dataset captures both human creativity in prompt formulation and model-specific biases in video generation.
- Core assumption: Real user prompts differ significantly in semantics and length from standard video captions, and this difference matters for model training and evaluation.
- Evidence anchors: [abstract] "1.67 Million unique text-to-Video Prompts from real users... 6.69 million videos generated by four state-of-the-art diffusion models"
- Break condition: If real user prompts were similar to captions or if all models produced nearly identical videos, the claimed diversity advantage would disappear.

### Mechanism 2
- Claim: The NSFW filtering system using six separate probabilities enables researchers to customize safety thresholds for their specific applications.
- Mechanism: By providing individual toxicity, obscenity, identity attack, insult, threat, and sexual explicitness scores for each prompt, researchers can apply different thresholds depending on their use case and risk tolerance.
- Core assumption: Different research contexts require different levels of content filtering, and providing granular probabilities is more useful than a single binary flag.
- Evidence anchors: [section 3] "we employ a state-of-the-art NSFW model, Detoxify, to assign probabilities in six aspects of NSFW content"
- Break condition: If researchers find the granularity unnecessary or if a single threshold proves sufficient for all use cases, the complexity would not provide value.

### Mechanism 3
- Claim: The semantic de-duplication process ensures broader topic coverage by maintaining prompts with low cosine similarity, enabling better representation of diverse video generation scenarios.
- Mechanism: By filtering prompts so that any two have cosine similarity below 0.8, the dataset avoids redundant topics while maintaining a wide range of content areas.
- Core assumption: Semantic diversity in prompts leads to better generalization in text-to-video models and more comprehensive evaluation.
- Evidence anchors: [section 3] "semantically unique prompts... if, for any two arbitrary prompts, their cosine similarity calculated using text-embedding-3-large embeddings is less than 0.8"
- Break condition: If semantic similarity below 0.8 proves too restrictive or if topic diversity doesn't correlate with model performance improvements, the approach would need revision.

## Foundational Learning

- Concept: Cosine similarity and text embeddings
  - Why needed here: Understanding how semantic de-duplication works requires knowledge of vector similarity metrics and how text embeddings represent semantic content
  - Quick check question: What would be the cosine similarity between two identical prompts after embedding?

- Concept: NSFW detection and content filtering
  - Why needed here: Researchers need to understand how the six-probability NSFW system works to appropriately filter data for their specific applications
  - Quick check question: Why might a researcher want to use different thresholds for different NSFW categories?

- Concept: Diffusion model training and evaluation
  - Why needed here: Understanding the significance of prompt-gallery datasets requires knowledge of how text-to-video diffusion models are trained and evaluated
  - Quick check question: How might training on real user prompts differ from training on standard video captions?

## Architecture Onboarding

- Component map: Discord scraping → prompt extraction → UUID assignment → video generation (4 models) → NSFW filtering (6 categories) → embedding (text-embedding-3-large) → semantic deduplication (cosine < 0.8) → dataset packaging

- Critical path: Prompt extraction → video generation → NSFW filtering → embedding → semantic deduplication → dataset packaging

- Design tradeoffs:
  - Multiple models vs. single model: Provides diversity but increases complexity and storage
  - Real user prompts vs. synthetic prompts: More authentic but potentially noisier
  - Granular NSFW probabilities vs. binary flags: More flexible but more complex
  - Semantic deduplication vs. raw data: Better diversity but potential loss of redundancy

- Failure signatures:
  - Low semantic diversity despite deduplication: May indicate embedding model issues
  - High NSFW probabilities across most prompts: May indicate filter sensitivity issues
  - Poor distribution of generated videos: May indicate generation model biases
  - Storage/performance issues: May indicate scaling problems with large video files

- First 3 experiments:
  1. Validate semantic deduplication by sampling random prompts and verifying their pairwise cosine similarity is below 0.8
  2. Test NSFW filtering by applying different threshold combinations and measuring precision/recall on known safe/unsafe samples
  3. Compare prompt distributions between VidProM and caption-video datasets to quantify the claimed semantic differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the semantic uniqueness threshold of 0.8 affect the quality and diversity of the VidProS subset?
- Basis in paper: [explicit] The authors define semantically unique prompts as those with a cosine similarity less than 0.8.
- Why unresolved: The choice of 0.8 as the threshold is not justified with empirical evidence or comparative analysis.
- What evidence would resolve it: A study comparing the diversity and utility of VidProS with different thresholds (e.g., 0.7, 0.9) would clarify the impact of this parameter.

### Open Question 2
- Question: How effective are existing fake image detection methods when applied to video frames from different diffusion models?
- Basis in paper: [explicit] The authors benchmark eight fake image detection models on video frames from Pika, VideoCraft2, Text2Video-Zero, and ModelScope.
- Why unresolved: The results show poor generalization, but the underlying reasons (e.g., specific artifacts, model architecture) are not explored.
- What evidence would resolve it: Detailed analysis of model failures and identification of key features distinguishing fake video frames would provide insights.

### Open Question 3
- Question: What are the legal implications of using replicated content in videos generated by diffusion models?
- Basis in paper: [inferred] The authors mention that replicated content may infringe on copyrights, using an example of a video replicating "The Persistence of Memory."
- Why unresolved: The paper does not discuss legal frameworks or precedents for such cases.
- What evidence would resolve it: Legal analysis or case studies on copyright infringement involving AI-generated content would clarify the risks.

## Limitations
- The dataset's true impact on model performance remains uncertain without validation experiments showing improved results
- The effectiveness of the semantic deduplication approach at threshold 0.8 is not empirically validated
- Claims about semantic differences between real user prompts and captions lack rigorous quantitative validation

## Confidence
- **High confidence:** The dataset collection methodology and basic statistics (1.67M prompts, 6.69M videos, NSFW filtering approach)
- **Medium confidence:** The claims about semantic differences between real user prompts and captions, as these are supported by qualitative observations but lack rigorous quantitative validation
- **Low confidence:** The assertion that VidProM will significantly advance text-to-video research, as this is speculative without demonstration experiments

## Next Checks
1. Conduct a quantitative comparison of prompt distributions between VidProM and standard caption-video datasets using embedding similarity metrics to validate the claimed semantic differences
2. Perform ablation studies on the semantic deduplication threshold to determine if 0.8 is optimal for balancing diversity and coverage
3. Train baseline text-to-video models using VidProM versus traditional datasets to empirically demonstrate any performance improvements or unique capabilities enabled by the real user prompt distribution