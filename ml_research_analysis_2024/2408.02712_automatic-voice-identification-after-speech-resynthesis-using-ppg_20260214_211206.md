---
ver: rpa2
title: Automatic Voice Identification after Speech Resynthesis using PPG
arxiv_id: '2408.02712'
source_url: https://arxiv.org/abs/2408.02712
tags:
- speech
- speaker
- audio
- speakers
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether Phonetic PosteriorGrams (PPGs) can
  be used as an interpretable intermediate representation for speech resynthesis while
  preventing source speaker identity leakage. PPGs are frame-level probabilistic phoneme
  representations that disentangle phonetic and rhythmic information from speaker
  identity.
---

# Automatic Voice Identification after Speech Resynthesis using PPG
## Quick Facts
- **arXiv ID**: 2408.02712
- **Source URL**: https://arxiv.org/abs/2408.02712
- **Reference count**: 0
- **Primary result**: PPG-based resynthesis prevents speaker identity leakage with EER >48% while maintaining comparable speech quality to TTS systems

## Executive Summary
This study investigates whether Phonetic PosteriorGrams (PPGs) can serve as an interpretable intermediate representation for speech resynthesis while preventing source speaker identity leakage. PPGs are frame-level probabilistic phoneme representations that disentangle phonetic and rhythmic information from speaker identity. The authors trained a PPG-to-Mel spectrogram model using Tacotron2 architecture and evaluated both the quality of synthesized speech and its vulnerability to automatic speaker verification attacks. The results demonstrate that PPG-based resynthesis successfully prevents speaker identification while maintaining comparable speech quality to conventional TTS systems.

## Method Summary
The researchers constructed a PPG-to-Mel spectrogram model (PPG2Mel) based on Tacotron2 architecture, training it on the LibriSpeech corpus using pre-trained WavLM representations to extract PPG features. They evaluated the quality of PPG-synthesized speech through mean opinion score (MOS) tests against both text-based TTS and natural speech baselines. For speaker verification, they conducted experiments using both naive ASV models (trained on natural speech) and informed models (trained on synthetic speech), measuring equal error rates (EER) to quantify speaker identification performance. The evaluation also included a PPG-based phoneme recognition model to verify that phonetic information was preserved during the resynthesis process.

## Key Results
- PPG2Mel achieved MOS score of 3.24 ± 0.07, comparable to TTS baseline (3.11 ± 0.07), with most degradation attributed to the vocoder
- Both naive and informed ASV models failed to identify source speakers in PPG-synthesized speech, with EERs exceeding 48% compared to 1.98% for natural speech
- PPG-based phoneme recognition achieved 25.16% CER, confirming successful preservation of phonetic information during resynthesis

## Why This Works (Mechanism)
PPGs function as speaker-independent phonetic representations by encoding frame-level phoneme probabilities that capture the linguistic content while removing speaker-specific characteristics. The resynthesis process through PPG2Mel learns to reconstruct speech from these phonetic features without access to the original speaker identity information. Since the model is trained to predict Mel spectrograms directly from PPGs rather than from speaker-conditioned inputs, the resulting speech lacks the speaker identity cues that would enable automatic speaker verification systems to perform successful identification.

## Foundational Learning
- **Phonetic PosteriorGrams (PPGs)**: Frame-level probabilistic representations of phoneme presence that separate linguistic content from speaker identity. Needed to provide speaker-independent intermediate representation for resynthesis.
- **Tacotron2 architecture**: Sequence-to-sequence model for speech synthesis that maps linguistic features to Mel spectrograms. Needed as the backbone for PPG-to-Mel conversion.
- **WavLM representations**: Pre-trained models for extracting robust PPG features from raw audio. Needed to obtain high-quality phonetic embeddings.
- **HiFi-GAN vocoder**: Neural vocoder for converting Mel spectrograms to raw waveforms. Needed to produce natural-sounding speech from synthetic spectrograms.
- **Equal Error Rate (EER)**: Metric measuring the error rate where false acceptance rate equals false rejection rate in speaker verification. Needed to quantify speaker identification performance.
- **Mean Opinion Score (MOS)**: Subjective quality assessment metric where raters evaluate speech naturalness. Needed to compare perceptual quality across synthesis methods.

## Architecture Onboarding
**Component map**: WavLM -> PPG extraction -> Tacotron2 PPG2Mel -> Mel spectrogram -> HiFi-GAN -> Waveform

**Critical path**: The PPG2Mel model represents the critical path, as it must successfully reconstruct Mel spectrograms from PPG features while preserving phonetic content and removing speaker identity information.

**Design tradeoffs**: The choice of WavLM for PPG extraction provides robust phonetic representations but may introduce computational overhead. Using Tacotron2 architecture offers proven synthesis capabilities but may limit exploration of more advanced architectures. The reliance on a single vocoder (HiFi-GAN) constrains the evaluation of synthesis quality variations.

**Failure signatures**: High EERs (>48%) in ASV experiments indicate successful speaker identity removal. MOS scores significantly below 3.0 would indicate quality degradation beyond acceptable thresholds. High phoneme recognition error rates would suggest loss of phonetic information during resynthesis.

**3 first experiments**:
1. Test ASV performance on PPG-synthesized speech using diverse model architectures beyond the baseline
2. Compare synthesis quality using alternative vocoders to isolate the impact of vocoding from PPG-based synthesis
3. Evaluate phoneme recognition performance on PPG-synthesized speech to verify linguistic content preservation

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions in the provided content.

## Limitations
- Results are limited to English speech corpora, restricting generalizability to other languages
- Focus on speaker verification rather than broader speaker identification scenarios leaves real-world applicability uncertain
- Reference-based MOS evaluation introduces potential subjectivity in quality assessments
- Use of single model architectures and vocoder may constrain findings' applicability to other synthesis frameworks

## Confidence
- **High**: Core claim that PPG effectively removes speaker identity information during resynthesis, supported by consistently high EERs (>48%) across both naive and informed ASV models
- **Medium**: Quality comparison between PPG2Mel and TTS systems, given the small MOS difference and potential biases in reference-based evaluation
- **Medium**: Interpretability claims, as the study demonstrates successful phoneme recognition but does not extensively validate explicit phoneme-saliency relationships

## Next Checks
1. Evaluate PPG-based resynthesis across multiple languages and non-English speech corpora to assess cross-linguistic generalization
2. Test ASV performance on PPG-synthesized speech using diverse model architectures and vocoders to verify robustness
3. Conduct controlled experiments comparing PPG with alternative speaker-discriminative representations in both synthesis quality and identity preservation metrics