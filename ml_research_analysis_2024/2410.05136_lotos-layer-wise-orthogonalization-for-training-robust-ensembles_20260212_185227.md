---
ver: rpa2
title: 'LOTOS: Layer-wise Orthogonalization for Training Robust Ensembles'
arxiv_id: '2410.05136'
source_url: https://arxiv.org/abs/2410.05136
tags:
- ensemble
- lotos
- layers
- ensembles
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how Lipschitz continuity affects adversarial
  transferability in ensemble models. While lower Lipschitz constants improve individual
  model robustness, they also increase transferability among ensemble members, reducing
  overall ensemble robustness.
---

# LOTOS: Layer-wise Orthogonalization for Training Robust Ensembles

## Quick Facts
- arXiv ID: 2410.05136
- Source URL: https://arxiv.org/abs/2410.05136
- Authors: Ali Ebrahimpour-Boroojeny; Hari Sundaram; Varun Chandrasekaran
- Reference count: 21
- Primary result: LOTOS increases robust accuracy by 6 percentage points against black-box attacks on CIFAR-10

## Executive Summary
This paper addresses a critical limitation in ensemble adversarial training: while lowering Lipschitz constants improves individual model robustness, it paradoxically increases adversarial transferability among ensemble members, reducing overall ensemble effectiveness. The authors propose LOTOS (Layer-wise Orthogonalization for Training Robust Ensembles), which promotes orthogonality among the top-k singular vector subspaces of corresponding affine layers across ensemble models. This approach effectively reduces transferability rates while maintaining individual model robustness. Experiments demonstrate that LOTOS increases robust accuracy by 6 percentage points against black-box attacks on CIFAR-10 and can enhance state-of-the-art ensemble robustness methods by 10.7 percentage points.

## Method Summary
LOTOS is a regularization method that adds an orthogonalization loss to the standard training objective for ensemble models. The method operates by computing the top-k singular vector subspaces of corresponding affine layers across ensemble models and penalizing their alignment. This is combined with spectral norm clipping to control individual model Lipschitz constants. The orthogonalization is particularly efficient for convolutional layers, where k=1 can be effective due to correlated singular values. The method works by forcing ensemble members to respond differently to the same input perturbations, thereby reducing the transferability of adversarial examples between models while maintaining their individual robustness.

## Key Results
- LOTOS increases robust accuracy by 6 percentage points against black-box attacks on CIFAR-10
- Can enhance state-of-the-art ensemble robustness methods by 10.7 percentage points
- Effective with heterogeneous ensembles and computationally efficient for convolutional layers
- Reduces transferability rates while maintaining individual model robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lower Lipschitz constants increase adversarial transferability among ensemble models
- Mechanism: When individual models become smoother (lower Lipschitz), their decision boundaries align more closely, creating shared vulnerable subspaces for adversarial examples
- Core assumption: Adversarial perturbations exploit directions of high sensitivity in the model's transformation space
- Evidence anchors:
  - [abstract] "although a lower Lipschitz constant increases the robustness of a single model, it is not as beneficial in training robust ensembles as it increases the transferability rate of adversarial examples across models"
  - [section 3.2] "decreasing L (Lipschitz constant), might be an indicator of higher similarity in the risk of the two models on the adversarial examples, which might imply a higher Trate"
  - [corpus] Weak - related papers focus on transferability but don't directly address the Lipschitz-transferability relationship

### Mechanism 2
- Claim: Orthogonalizing top-k singular vector subspaces increases ensemble diversity
- Mechanism: By penalizing the alignment of corresponding layers' transformations, LOTOS forces models to respond differently to the same input perturbations
- Core assumption: Adversarial examples primarily exploit the principal directions of transformation in each layer
- Evidence anchors:
  - [abstract] "LOTOS... counteracts this adverse effect. It does so by promoting orthogonality among the top-k sub-spaces of the transformations of the corresponding affine layers"
  - [section 4] "LOTOS promotes the orthogonality among these sub-spaces which leads to different behaviors when perturbing the clean samples along a specific direction"
  - [corpus] Weak - no direct evidence in related papers about orthogonalizing singular vector subspaces for ensemble diversity

### Mechanism 3
- Claim: Efficient orthogonalization is possible with k=1 for convolutional layers
- Mechanism: The structure of convolutional layers creates correlations between singular values that allow effective orthogonalization with minimal subspace dimensions
- Core assumption: Singular values of convolutional layers are correlated in a way that bounds the impact of remaining singular vectors
- Evidence anchors:
  - [section 4.1] "We theoretically show that our method is highly efficient for convolutional layers"
  - [section 4.1] Theorem 4.1 proves "even k = 1 can be effective in orthogonalization with respect to the remaining singular vectors for convolutional layers"
  - [corpus] Weak - related papers discuss convolutional layer properties but not this specific orthogonalization efficiency claim

## Foundational Learning

- Concept: Lipschitz continuity and spectral norms
  - Why needed here: LOTOS builds on the idea that controlling Lipschitz constants affects robustness, but needs to understand when this becomes counterproductive
  - Quick check question: What is the relationship between spectral norm of a matrix and the Lipschitz constant of its associated linear transformation?

- Concept: Singular value decomposition and its role in neural network transformations
  - Why needed here: LOTOS operates on the top-k singular vector subspaces of affine layers, requiring understanding of how SVD captures the most important transformation directions
  - Quick check question: How does the singular value decomposition of a matrix relate to the directions of maximum change in the output space?

- Concept: Transferability rate definition and measurement
  - Why needed here: The paper's core argument depends on quantifying how adversarial examples transfer between models, requiring clear understanding of the formal definition
  - Quick check question: Given two models F and G, how would you compute the transferability rate of adversarial examples from F to G?

## Architecture Onboarding

- Component map: Spectral norm clipping -> Layer transformations -> SVD computation -> Orthogonalization loss -> Combined training objective
- Critical path: For each training batch, compute forward passes for all ensemble models, calculate the orthogonalization loss using their corresponding layer transformations, add this to the standard cross-entropy loss, and perform backpropagation with both terms
- Design tradeoffs: Orthogonalization increases computational overhead but LOTOS is efficient for convolutional layers. More aggressive orthogonalization (lower mal) reduces transferability but may slightly decrease individual model robustness. The k parameter controls subspace dimension - larger k increases effectiveness but also computational cost.
- Failure signatures: If orthogonalization is too aggressive, individual model robustness may decrease significantly. If k is too small, orthogonalization may be ineffective. If mal is too large, transferability reduction may be minimal. Batch normalization layers reduce the effectiveness of spectral norm clipping.
- First 3 experiments:
  1. Train an ensemble with and without LOTOS (k=1, mal=0.8) and measure transferability rate using white-box attacks
  2. Vary the mal parameter (0.1, 0.5, 0.8, 1.0) and observe the tradeoff between transferability reduction and individual model robustness
  3. Test LOTOS with heterogeneous architectures by applying orthogonalization only to the first layer of each model

## Open Questions the Paper Calls Out

- Open Question 1: What is the optimal value of the orthogonalization weight parameter λ in Equation (4) for different model architectures and datasets?
  - Basis in paper: [inferred] The paper mentions λ controls the effect of the orthogonalization loss but does not specify an optimal value or provide guidance on tuning it for different scenarios.
  - Why unresolved: The paper uses default parameters when combining LOTOS with prior methods but doesn't explore the sensitivity of results to different λ values or provide a principled approach for setting it.
  - What evidence would resolve it: Systematic experiments varying λ across different architectures (ResNet, DLA) and datasets (CIFAR-10, CIFAR-100) showing how robust accuracy changes with different λ values, ideally with recommendations for specific ranges.

- Open Question 2: How does LOTOS perform on larger-scale datasets and more complex architectures beyond CIFAR-10/100 and ResNet/DLA?
  - Basis in paper: [explicit] The paper states "We used both CIFAR-10 and CIFAR-100 datasets" and "The models we use in these experiments consist of ResNet-18, ResNet-34, and DLA."
  - Why unresolved: The experiments are limited to relatively small datasets and specific architectures, leaving uncertainty about scalability to larger vision datasets (ImageNet, COCO) or more complex architectures (Vision Transformers, larger ResNets).
  - What evidence would resolve it: Experiments on larger datasets like ImageNet and more complex architectures showing whether the computational efficiency benefits and robustness improvements observed on CIFAR datasets generalize to these more challenging settings.

- Open Question 3: What is the theoretical relationship between the degree of Lipschitz continuity (C value) and the optimal mal parameter in LOTOS?
  - Basis in paper: [inferred] The paper shows that decreasing C increases transferability, and LOTOS uses mal to control orthogonalization, but doesn't explore how these two parameters should be jointly tuned.
  - Why unresolved: The paper treats C and mal as independent parameters, but there may be an optimal relationship between them - for example, more stringent Lipschitz constraints (lower C) might require different mal values to maintain ensemble robustness.
  - What evidence would resolve it: Experiments systematically varying both C and mal together to find optimal combinations, or theoretical analysis showing how the trade-off between individual model robustness (controlled by C) and ensemble diversity (controlled by mal) should be balanced.

## Limitations
- Limited testing on larger-scale datasets beyond CIFAR-10/100
- Focuses primarily on white-box and black-box transferability scenarios
- Computational overhead may be prohibitive for extremely large models or ensembles
- Orthogonalization approach may not generalize well to very deep or highly heterogeneous ensembles

## Confidence

- Mechanism 1 (Lipschitz-transferability relationship): Medium confidence - The theoretical analysis is sound but the direct evidence is limited in related work
- Mechanism 2 (Orthogonalization for diversity): Medium confidence - The approach is novel and the results are promising, but the assumption about adversarial perturbations exploiting principal directions needs more validation
- Mechanism 3 (Efficiency with k=1): Low confidence - Relies on a specific theoretical result without extensive empirical validation across diverse architectures

## Next Checks

1. Test LOTOS with k=1,2,3 for various convolutional architectures to empirically verify the efficiency claim and determine optimal k values across different layer types
2. Evaluate LOTOS against adaptive attackers who specifically target the orthogonalized subspaces or use ensemble-aware attack strategies
3. Apply LOTOS to ensemble methods beyond adversarial training, such as knowledge distillation ensembles or self-ensemble training, to assess broader applicability