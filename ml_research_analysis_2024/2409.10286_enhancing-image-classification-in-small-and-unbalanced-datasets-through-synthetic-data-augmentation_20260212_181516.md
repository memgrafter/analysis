---
ver: rpa2
title: Enhancing Image Classification in Small and Unbalanced Datasets through Synthetic
  Data Augmentation
arxiv_id: '2409.10286'
source_url: https://arxiv.org/abs/2409.10286
tags:
- data
- synthetic
- images
- class
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a synthetic data augmentation approach using
  class-specific Variational Autoencoders (VAEs) to address the challenges of small
  and unbalanced datasets in medical image classification, specifically for esophagogastroduodenoscopy
  (EGD) images. By generating realistic synthetic images through latent space interpolation,
  the method fills feature space gaps and improves model performance.
---

# Enhancing Image Classification in Small and Unbalanced Datasets through Synthetic Data Augmentation

## Quick Facts
- arXiv ID: 2409.10286
- Source URL: https://arxiv.org/abs/2409.10286
- Authors: Neil De La Fuente; Mireia Majó; Irina Luzko; Henry Córdova; Gloria Fernández-Esparrach; Jorge Bernal
- Reference count: 22
- One-line primary result: Synthetic data augmentation using class-specific VAEs improves classification accuracy for underrepresented classes in small, imbalanced EGD image datasets

## Executive Summary
This study addresses the challenge of small and unbalanced datasets in medical image classification by introducing a synthetic data augmentation approach using class-specific Variational Autoencoders (VAEs). Applied to esophagogastroduodenoscopy (EGD) images categorized by the Barcelona scale, the method generates realistic synthetic images through latent space interpolation, effectively filling feature space gaps for underrepresented classes. Tested on a dataset of 321 images, the approach achieved over 18% accuracy improvement for the most underrepresented class and 6% overall accuracy improvement, while also enhancing precision and recall metrics.

## Method Summary
The method employs class-specific VAEs trained on each class of the EGD dataset to learn the latent distribution of that class. Latent space interpolation is used to generate synthetic images that fill feature space gaps for underrepresented classes. These synthetic images are combined with real data and traditional augmentation techniques (rotations, mirroring) to train classification models (EfficientNet-V2 and ResNet-50). The approach was evaluated on a dataset of 321 EGD images categorized into three classes using the Barcelona scale, with an 80-20 training/validation and testing split.

## Key Results
- Accuracy for the most underrepresented class (class 1) increased by over 18%
- Overall accuracy improved by 6%
- Enhanced precision and recall metrics, demonstrating improved model robustness
- Effective in addressing class imbalance challenges in medical image classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Class-specific VAEs generate synthetic images that fill gaps in feature space for underrepresented classes.
- Mechanism: Each class is modeled with its own VAE, which learns the latent distribution of that class. Latent space interpolation creates intermediate points that represent plausible variations within the class, thus expanding the training data diversity.
- Core assumption: The latent space captures meaningful semantic variations and that interpolated points are realistic and relevant for classification.
- Evidence anchors:
  - [abstract] "generating realistic synthetic images through latent space interpolation, the method fills feature space gaps"
  - [section] "By training class-specific autoencoders, the unique characteristics and nuances of each class are captured in the latent space"
  - [corpus] Weak corpus support: No direct match, but related works (e.g., 166925, 45873) also use class-specific augmentation to improve minority class performance.
- Break condition: If latent space interpolations generate unrealistic images or samples outside the manifold of real data, the synthetic images may mislead the classifier.

### Mechanism 2
- Claim: Combining synthetic data with traditional augmentation leads to synergistic performance gains.
- Mechanism: Traditional augmentations (rotations, flips) provide geometric diversity, while synthetic VAE images add distributional diversity by filling underpopulated feature regions. The combination improves the model's robustness to both geometric and semantic variations.
- Core assumption: The two augmentation strategies complement each other rather than overlap or conflict.
- Evidence anchors:
  - [abstract] "By combining real and synthetic data, an increase of over 18% in the accuracy of the most challenging underrepresented class was observed"
  - [section] "These enhancements suggest that synthetic data not only supplements the training set but also instills a better understanding of the feature space"
  - [corpus] Limited direct evidence; most corpus works focus on one augmentation type, not their combination.
- Break condition: If synthetic and traditional augmentations generate highly redundant samples, the benefit may plateau or even degrade performance due to overfitting to synthetic patterns.

### Mechanism 3
- Claim: Latent space interpolation preserves class identity while increasing intra-class variability.
- Mechanism: Interpolating between two latent vectors of the same class generates intermediate representations that remain within the same class manifold, preserving class semantics while introducing novel, plausible variations.
- Core assumption: The VAE's latent space is semantically smooth and interpolations remain within valid class boundaries.
- Evidence anchors:
  - [section] "This interpolation is achieved by computing a weighted sum of their latent vectors z1 and z2, yielding a new latent representation, denoted as zinterp"
  - [abstract] "generating realistic, varied synthetic data that fills feature space gaps"
  - [corpus] Weak support; only indirect evidence from related generative augmentation works.
- Break condition: If interpolation crosses class boundaries in latent space, synthetic samples may become ambiguous or misclassified, hurting performance.

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) and latent space interpolation
  - Why needed here: VAEs learn probabilistic latent representations that can be sampled and interpolated to generate realistic synthetic data for underrepresented classes.
  - Quick check question: What is the role of the KL divergence term in the VAE loss function?

- Concept: Class imbalance and feature space analysis
  - Why needed here: Understanding how imbalance creates sparse regions in feature space guides the design of synthetic data that targets those gaps.
  - Quick check question: How does class imbalance typically affect model precision and recall for minority classes?

- Concept: Data augmentation strategies and their effects on model generalization
  - Why needed here: Knowing when and how to combine traditional and synthetic augmentations ensures maximal benefit without overfitting.
  - Quick check question: What are the risks of using only traditional augmentations on highly imbalanced datasets?

## Architecture Onboarding

- Component map:
  Dataset loader -> Train/validation/test split -> Class-specific VAE trainer (per class) -> Latent space interpolation engine -> Synthetic data generator -> Classification model (EfficientNet-V2/ResNet-50) -> Evaluation pipeline (accuracy, precision, recall, F1)

- Critical path:
  Train VAEs -> Generate synthetic images via interpolation -> Merge with real data -> Train classifier -> Evaluate

- Design tradeoffs:
  - More synthetic images per class -> Better coverage but higher risk of overfitting to synthetic patterns
  - Larger latent space dimension -> More expressive but slower training and more memory
  - Interpolation weight granularity -> Finer control over diversity but more hyperparameters

- Failure signatures:
  - Classifier accuracy plateaus or drops when synthetic data is added
  - Synthetic images look unrealistic or do not resemble class samples
  - Training loss diverges due to poor VAE reconstruction quality

- First 3 experiments:
  1. Train class-specific VAEs on each class, generate 100 synthetic images per class, evaluate interpolation quality visually.
  2. Add synthetic images to training set, retrain classifier, compare class-1 accuracy to baseline.
  3. Vary interpolation weight α granularity, measure impact on synthetic sample diversity and classification performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the synthetic images generated by VAEs compare in quality to real images, and does this impact model performance?
- Basis in paper: [explicit] The paper acknowledges that synthetic images generated by VAEs may not capture all nuances of real medical images, potentially leading to biases in the training process.
- Why unresolved: The study does not provide a detailed comparison between the quality of synthetic and real images, nor does it explore how these differences might affect model performance.
- What evidence would resolve it: A detailed visual and quantitative comparison of synthetic versus real images, including their impact on model performance metrics.

### Open Question 2
- Question: Can the proposed synthetic data augmentation approach be effectively scaled to larger and more diverse medical image datasets?
- Basis in paper: [inferred] The study was conducted on a relatively small dataset of 321 images, which may limit the generalizability of the findings.
- Why unresolved: The effectiveness of the approach on larger datasets remains untested, and scaling up could introduce new challenges or limitations.
- What evidence would resolve it: Testing the approach on larger, more diverse datasets and analyzing any changes in performance and scalability.

### Open Question 3
- Question: How does the proposed synthetic data augmentation method influence model interpretability and reliability in real-world clinical environments?
- Basis in paper: [explicit] The paper suggests future efforts could focus on understanding how synthetic data influences model interpretability and reliability in real-world clinical environments.
- Why unresolved: The study does not explore the interpretability and reliability of models trained with synthetic data in practical settings.
- What evidence would resolve it: Conducting clinical trials or real-world tests to evaluate model performance and reliability when using synthetic data augmentation.

## Limitations
- Dataset size remains small (321 total images), limiting generalizability of results
- No ablation study isolating the impact of synthetic vs. traditional augmentation
- Visual quality of synthetic images not evaluated, though performance improved
- Method tuned for 3-class EGD classification; scalability to more classes unclear

## Confidence
- **High confidence** in observed accuracy improvements (>18% for class 1, 6% overall)
- **Medium confidence** in mechanism explanations, as latent space behavior not directly visualized
- **Low confidence** in generalization claims beyond EGD domain without broader testing

## Next Checks
1. Conduct ablation study: compare performance with synthetic augmentation only vs. traditional augmentation only vs. combined
2. Perform visual Turing test: have medical experts distinguish real vs. synthetic EGD images
3. Test scalability: apply method to dataset with 5+ classes and measure performance degradation