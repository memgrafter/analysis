---
ver: rpa2
title: 'Causality from Bottom to Top: A Survey'
arxiv_id: '2403.11219'
source_url: https://arxiv.org/abs/2403.11219
tags:
- causal
- causality
- data
- inference
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive survey of causality research
  over the past five decades, covering its development, characteristics, types, inference
  methods, applications, and interactions with other approaches like AI, ML, and GAI.
  The authors highlight the key distinctions between causality and correlation, emphasizing
  causality's unique properties such as directionality, necessity, and counterfactual
  reasoning.
---

# Causality from Bottom to Top: A Survey

## Quick Facts
- arXiv ID: 2403.11219
- Source URL: https://arxiv.org/abs/2403.11219
- Reference count: 40
- Key outcome: Comprehensive survey of causality research over five decades, covering development, characteristics, inference methods, applications, and interactions with AI/ML/RL approaches

## Executive Summary
This survey provides a comprehensive overview of causality research spanning five decades, examining how causality has evolved from a philosophical concept to a fundamental approach for understanding relationships between events. The authors trace the development of causality across different fields and highlight its unique properties that distinguish it from correlation and other analytical approaches. The paper emphasizes the growing importance of causality in artificial intelligence and machine learning, particularly for addressing challenges related to fairness, bias, and explainability. Through systematic analysis of literature, the survey identifies key methodological advances and emerging research directions in causal inference.

## Method Summary
This survey paper employs a literature review methodology to examine causality research across five decades, analyzing approximately 40 key references to trace the development and application of causal inference methods. The authors synthesize findings across multiple domains including medicine, economics, education, and AI/ML, while identifying key characteristics that distinguish causality from other analytical approaches. The paper systematically organizes the surveyed literature into thematic categories covering theoretical foundations, methodological approaches, practical applications, and future research directions. The survey aims to provide a comprehensive framework for understanding how causality has evolved and its current role in advancing AI and related fields.

## Key Results
- Causality has evolved from philosophical concept to fundamental framework for explaining event relationships across diverse domains
- Causal inference methods including graphical models, potential outcomes, and instrumental variables provide systematic approaches for identifying cause-effect relationships
- Integration of causality with ML techniques shows promise for improving fairness, bias detection, and explainability in AI systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causality provides a framework for understanding why one event leads to another, enabling prediction and control.
- Mechanism: Causality identifies directional cause-effect relationships, allowing manipulation of causes to observe changes in effects.
- Core assumption: Causal relationships exist and can be identified from data or experimental design.
- Evidence anchors:
  - [abstract] "Causality has become a fundamental approach for explaining the relationships between events, phenomena, and outcomes"
  - [section] "Causality can be defined as a relationship between an event (called the cause) and a second event (called the effect), where the cause brings about the effect or directly influences its occurrence"
  - [corpus] Weak - corpus papers focus on OOD generalization and Granger causality rather than basic cause-effect framework
- Break condition: If no clear temporal precedence or mechanism exists between variables, causal inference becomes unreliable

### Mechanism 2
- Claim: Graph databases efficiently represent and query causal relationships compared to relational databases.
- Mechanism: Directed Acyclic Graphs (DAGs) in graph databases explicitly model causal dependencies, enabling faster causal inference.
- Core assumption: Causal relationships can be represented as directed edges between nodes in a graph structure.
- Evidence anchors:
  - [section] "The database architecture also influences the causal inference process. Graph databases, due to their ability to represent Directed Acyclic Graphs (DAGs), provide a suitable platform for causal analysis"
  - [abstract] No direct evidence for graph database efficiency
  - [corpus] Weak - corpus papers don't discuss database architectures for causality
- Break condition: If causal relationships involve cycles or require complex conditional dependencies not easily represented in graph structure

### Mechanism 3
- Claim: Causality addresses fairness and bias in AI systems by focusing on causal effects rather than associative effects.
- Mechanism: Causal models identify root causes of bias and discrimination, enabling targeted interventions to mitigate unfair outcomes.
- Core assumption: Bias and discrimination have identifiable causal mechanisms that can be modeled and modified.
- Evidence anchors:
  - [abstract] "Additionally, the paper examines the role of causality in addressing fairness, bias, and discrimination in AI systems"
  - [section] "Causal reasoning plays a significant role in identifying unfair biases and understanding their root causes"
  - [corpus] Weak - corpus papers don't address fairness or bias in causality
- Break condition: If causal models cannot capture the complexity of social and systemic factors contributing to bias

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs)
  - Why needed here: DAGs provide the mathematical foundation for representing causal relationships without feedback loops
  - Quick check question: Can a DAG contain cycles between nodes?

- Concept: Counterfactual reasoning
  - Why needed here: Counterfactuals enable reasoning about hypothetical interventions and what-if scenarios
  - Quick check question: What distinguishes counterfactual reasoning from simple correlation analysis?

- Concept: Confounding variables
  - Why needed here: Confounders can create spurious correlations that masquerade as causal relationships
  - Quick check question: How does failing to control for confounders affect causal inference validity?

## Architecture Onboarding

- Component map: Data ingestion → Preprocessing (feature selection, temporal ordering) → Causal structure learning → Causal effect estimation → Validation → Deployment
- Critical path: Causal discovery algorithms must complete before effect estimation can begin; validation must occur before deployment
- Design tradeoffs: Computational efficiency vs. causal model complexity; data requirements vs. inference accuracy; interpretability vs. predictive power
- Failure signatures: Spurious causal relationships identified; poor generalization to new datasets; inability to handle missing data or confounders
- First 3 experiments:
  1. Implement basic causal discovery on synthetic data with known causal structure to validate algorithm correctness
  2. Test graph database representation efficiency by comparing causal query performance against relational database approach
  3. Evaluate causal model fairness assessment on benchmark datasets with documented bias patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we close the gap between human and AI causality understanding, particularly in terms of intuitive reasoning and common sense knowledge?
- Basis in paper: [explicit] The paper states "We estimate one of the future challenges is to close this gap by endowing AI with capacities that mimic human causal reasoning abilities more closely."
- Why unresolved: Current AI/ML approaches primarily rely on statistical correlations, while humans understand causation through intuitive theories and common sense knowledge about how the world works.
- What evidence would resolve it: Development and evaluation of AI systems that can demonstrate robust causal reasoning abilities comparable to humans across diverse domains and contexts.

### Open Question 2
- Question: How can we develop scalable causal discovery algorithms that can handle large-scale datasets with hundreds or thousands of variables while maintaining properties like robustness, modularity, and interpretability?
- Basis in paper: [explicit] The paper mentions "causal discovery at scale is a critical area of research" and "The goal is to develop scalable algorithms capable of handling large-scale datasets with hundreds or thousands of variables."
- Why unresolved: Current causal discovery methods face challenges in scaling up to handle complex real-world datasets while preserving desirable properties like interpretability and robustness to violations of assumptions.
- What evidence would resolve it: New algorithms and frameworks that can effectively discover causal structures in high-dimensional data while maintaining interpretability and robustness, validated on both synthetic and real-world benchmarks.

### Open Question 3
- Question: How can we effectively integrate causality with reinforcement learning to improve offline evaluation, generalization, and safe exploration in complex and dynamic environments?
- Basis in paper: [explicit] The paper discusses "causal reinforcement learning is another promising area, involving the integration of causal reasoning into reinforcement learning" and mentions benefits like improved decision-making and better handling of confounding variables.
- Why unresolved: Developing scalable causal models to handle complex and dynamic environments in reinforcement learning remains a challenge, and there are open questions about how to effectively incorporate causal reasoning into the RL framework.
- What evidence would resolve it: Novel approaches and empirical results demonstrating improved performance and safety in RL tasks through the integration of causal reasoning, validated on challenging benchmark problems and real-world applications.

## Limitations

- The survey provides broad overview but lacks detailed methodological specifications for implementing causal inference methods
- Claims about causality's superiority over correlation approaches and applications in fairness/bias mitigation lack empirical validation
- Paper does not address computational scalability challenges or provide quantitative comparisons between different causal inference approaches

## Confidence

- **High Confidence**: The fundamental distinction between causality and correlation, and the basic properties of causal relationships (directionality, necessity, counterfactual reasoning)
- **Medium Confidence**: The effectiveness of graph databases for causal representation and the role of causality in addressing AI fairness
- **Low Confidence**: The specific claims about causality's integration with ML techniques and its comparative advantages over traditional approaches without empirical support

## Next Checks

1. Implement and benchmark multiple causal discovery algorithms on synthetic datasets with known ground truth to compare their accuracy and computational efficiency
2. Design a controlled experiment comparing causal inference performance on graph databases versus relational databases for a specific causal query task
3. Apply causal fairness assessment methods to benchmark datasets with documented bias patterns and validate whether identified interventions actually reduce discrimination in downstream models