---
ver: rpa2
title: 'MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and
  Knowledge Aggregation'
arxiv_id: '2406.17484'
source_url: https://arxiv.org/abs/2406.17484
tags:
- medical
- knowledge
- tasks
- arxiv
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MEDCARE, a medical large language model (LLM)
  designed to address the limitations of existing models in handling diverse medical
  tasks. The authors categorize medical tasks into knowledge-intensive tasks, requiring
  deep medical knowledge, and alignment-required tasks, demanding strict adherence
  to specific output formats.
---

# MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation

## Quick Facts
- arXiv ID: 2406.17484
- Source URL: https://arxiv.org/abs/2406.17484
- Authors: Yusheng Liao; Shuyang Jiang; Zhe Chen; Yanfeng Wang; Yu Wang
- Reference count: 36
- Primary result: State-of-the-art performance on over 20 medical tasks using a two-stage fine-tuning pipeline

## Executive Summary
This paper introduces MEDCARE, a medical large language model designed to excel at both knowledge-intensive tasks and alignment-required tasks in the medical domain. The authors address the challenge of catastrophic forgetting by decoupling knowledge learning from alignment training through a two-stage fine-tuning pipeline. The model demonstrates superior performance across three sizes (1.8B, 7B, 14B) compared to existing models with similar parameter counts.

## Method Summary
MEDCARE employs a two-stage fine-tuning pipeline starting from Qwen1.5-Chat base models. The first stage uses Knowledge Aggregator and Noise Aggregator modules to encode diverse medical knowledge while filtering detrimental information. The second stage introduces an alignment module with orthogonal regularization to prevent knowledge forgetting and adapt to specific task requirements. The model is available in three sizes (1.8B, 7B, 14B) and demonstrates state-of-the-art performance across multiple medical benchmarks.

## Key Results
- Outperforms existing models on medical knowledge exams (MedQA, MMedBench, CMB, CMExam)
- Achieves strong performance on alignment-required tasks (CBLUE, CCTE)
- Shows consistent improvement across all three model sizes (1.8B, 7B, 14B)
- Demonstrates effective knowledge retention through orthogonal regularization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling alignment and knowledge learning prevents catastrophic forgetting of general medical knowledge.
- Mechanism: Two-stage pipeline first encodes broad medical knowledge without interference from alignment tasks, then applies task-specific alignment with orthogonal regularization to ensure alignment space doesn't overlap with knowledge space.
- Core assumption: First stage must capture general knowledge before alignment fine-tuning; otherwise, alignment fine-tuning would overwrite general knowledge.
- Evidence anchors:
  - [abstract] "we drop the NOISE AGGREGATOR to avoid the interference of suboptimal representation and leverage an additional alignment module optimized towards an orthogonal direction to the knowledge space to mitigate knowledge forgetting."
  - [section 3.3] "we introduce an additional alignment LoRA module Align(·) in the FFN module to acquire specific alignment knowledge from the alignment dataset... we introduce an orthogonal loss to ensure that the new alignment task is learned in a direction orthogonal to the original knowledge task."
- Break condition: If alignment tasks require substantial knowledge updates during the second stage, orthogonal regularization may not fully prevent forgetting.

### Mechanism 2
- Claim: Mixing LoRA experts with shared knowledge experts allows efficient multi-task learning without parameter explosion.
- Mechanism: Knowledge Aggregator uses shared experts to encode common knowledge across tasks, while Noise Aggregator uses task-specific experts to handle alignment-specific formatting, enabling knowledge sharing while isolating task-specific learning.
- Core assumption: Knowledge from different medical tasks is sufficiently similar to benefit from shared expert representations.
- Evidence anchors:
  - [section 3.2] "we adopt the MoLoRA structure as the NOISE AGGREGATOR and introduce shared experts as the KNOWLEDGE AGGREGATOR to further circumvent low generalization due to the high specialization of each expert."
  - [section 5] "The KA stage improves the knowledge capacity of the models and the DA stage adapts the models to learn the target formats."
- Break condition: If medical tasks require highly specialized knowledge with little overlap, shared experts may underperform task-specific experts.

### Mechanism 3
- Claim: Removing the Noise Aggregator after the first stage prevents routing mismatch from degrading knowledge encoding.
- Mechanism: Noise Aggregator introduces routing decisions that can mismatch experts to tasks, causing suboptimal performance. Removing it after the first stage ensures only Knowledge Aggregator remains to encode medical knowledge.
- Core assumption: Routing mismatch in MoLoRA is a significant source of performance degradation for knowledge tasks.
- Evidence anchors:
  - [section 5] "We investigate the effect of different combinations of MoLoRA experts in NOISE AGGREGATOR on the final performance to demonstrate the routing mismatch... the mismatch between the experts' activation times and their corresponding performance."
  - [section 5] "By discarding the NOISE AGGREGATOR after the first stage of fine-tuning reduces the alignment performance of the model, the target format can be learned faster by retraining the model with the second-stage medical adaptation."
- Break condition: If routing in MoLoRA is improved or if Noise Aggregator is necessary for certain alignment tasks, removing it may hurt performance.

## Foundational Learning

- **Concept: Low-Rank Adaptation (LoRA)**
  - Why needed here: LoRA allows efficient fine-tuning of large models by decomposing weight updates into low-rank matrices, reducing parameter count while maintaining performance.
  - Quick check question: What is the primary advantage of using LoRA over full fine-tuning in large language models?

- **Concept: Mixture of Experts (MoE)**
  - Why needed here: MoE enables conditional computation where different experts handle different types of inputs, allowing efficient multi-task learning without parameter explosion.
  - Quick check question: How does MoE differ from standard dense model architectures in terms of parameter efficiency?

- **Concept: Orthogonal Regularization**
  - Why needed here: Orthogonal regularization ensures that different learning objectives (knowledge vs alignment) occur in separate subspaces, preventing interference between them.
  - Quick check question: Why is orthogonal regularization important when fine-tuning a model for multiple objectives?

## Architecture Onboarding

- **Component map**: Qwen1.5 base model → LoRA adapters (knowledge aggregation stage) → MoLoRA mixture (noise aggregator + shared experts) → LoRA adapters (alignment stage) → Orthogonal regularization loss
- **Critical path**: Knowledge aggregation stage → Noise aggregator removal → Alignment stage with orthogonal regularization → Merge adapters back to base model
- **Design tradeoffs**: Using shared experts in KA reduces parameters but may limit task-specific specialization; removing NA after MKA stage simplifies inference but requires DA stage for alignment capability
- **Failure signatures**: If alignment performance drops after KA stage, check whether NA was properly removed; if knowledge performance degrades, check orthogonal regularization strength
- **First 3 experiments**:
  1. Run KA stage only and evaluate knowledge task performance vs baseline
  2. Run KA+DA stages and evaluate alignment task performance
  3. Run KA+DA with orthogonal regularization disabled and compare knowledge retention

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model's performance change when the scale of fine-tuning corpus becomes smaller, and what is the minimum dataset size required for effective knowledge learning?
- Basis in paper: [explicit] The paper states, "To show the effective knowledge learning ability of MEDCARE, we compare the performance of models with varying scales of the first-stage fine-tuning corpus."
- Why unresolved: The paper does not provide specific performance metrics or minimum dataset size requirements for effective knowledge learning when the fine-tuning corpus is scaled down.
- What evidence would resolve it: Detailed performance metrics of MEDCARE on knowledge-intensive tasks across different sizes of fine-tuning datasets, including the minimum dataset size needed to maintain performance above a certain threshold.

### Open Question 2
- Question: What are the specific roles of the Knowledge Aggregator (KA) and Noise Aggregator (NA) in the model's learning process, and how do they interact with each other?
- Basis in paper: [explicit] The paper mentions, "We investigate the effect of different combinations of MoLoRA experts in NOISE AGGREGATOR on the final performance to demonstrate the routing mismatch."
- Why unresolved: While the paper discusses the roles of KA and NA, it does not provide a detailed analysis of their specific functions and interactions in the learning process.
- What evidence would resolve it: A comprehensive analysis of the individual contributions of KA and NA to the model's performance, including ablation studies and visualizations of their interactions.

### Open Question 3
- Question: How does the orthogonal regularization term in the downstream alignment stage affect the model's ability to learn alignment tasks without forgetting knowledge acquired in the first stage?
- Basis in paper: [explicit] The paper states, "We introduce an orthogonal regularization term to ensure non-overlapping between the optimization space of alignment and knowledge space in the first stage."
- Why unresolved: The paper does not provide empirical evidence on the effectiveness of the orthogonal regularization term in preserving knowledge while learning alignment tasks.
- What evidence would resolve it: Comparative performance metrics of MEDCARE with and without orthogonal regularization on both knowledge-intensive and alignment-required tasks, demonstrating the impact on knowledge retention and alignment learning.

## Limitations

- The core mechanisms rely on theoretical assumptions about orthogonal regularization and expert routing that lack direct empirical validation through ablation studies.
- Evaluation focuses on benchmark performance without investigating model robustness to adversarial inputs, generalization to unseen medical conditions, or clinical utility in real-world scenarios.
- The paper doesn't address potential biases in medical knowledge representation or safety considerations for clinical deployment.

## Confidence

- **High confidence**: The two-stage fine-tuning pipeline structure and the general approach of separating knowledge encoding from alignment learning. The performance improvements on established medical benchmarks are measurable and reproducible.
- **Medium confidence**: The effectiveness of orthogonal regularization in preventing knowledge forgetting, as the paper shows improved performance but doesn't provide direct evidence of reduced interference between knowledge and alignment subspaces.
- **Low confidence**: The specific claim that removing the Noise Aggregator is necessary for optimal knowledge encoding, as the routing mismatch analysis lacks quantitative metrics and the paper doesn't explore alternative routing strategies or compare with other expert mixture approaches.

## Next Checks

1. **Ablation study on orthogonal regularization**: Train MEDCARE variants with varying strengths of orthogonal regularization (including disabled) and measure knowledge retention on medical knowledge tasks during the alignment stage to directly quantify the forgetting mitigation effect.

2. **Expert routing analysis**: Implement quantitative metrics for expert routing quality including activation entropy, expert utilization distribution, and correlation between routing decisions and task performance to validate the routing mismatch claims.

3. **Clinical utility validation**: Design a small-scale evaluation with medical practitioners to assess whether MEDCARE's format adherence and knowledge accuracy translate to practical clinical decision support, measuring both task completion quality and clinical relevance of responses.