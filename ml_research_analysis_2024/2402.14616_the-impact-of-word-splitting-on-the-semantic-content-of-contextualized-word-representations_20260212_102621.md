---
ver: rpa2
title: The Impact of Word Splitting on the Semantic Content of Contextualized Word
  Representations
arxiv_id: '2402.14616'
source_url: https://arxiv.org/abs/2402.14616
tags:
- split
- word
- words
- pairs
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the effect of word splitting on the quality
  of contextualized word representations derived from language models. The authors
  evaluate representations on semantic similarity tasks involving out-of-vocabulary
  words that are segmented into subwords.
---

# The Impact of Word Splitting on the Semantic Content of Contextualized Word Representations

## Quick Facts
- arXiv ID: 2402.14616
- Source URL: https://arxiv.org/abs/2402.14616
- Authors: Aina Garí Soler; Matthieu Labeau; Chloé Clavel
- Reference count: 40
- This study investigates the effect of word splitting on the quality of contextualized word representations derived from language models.

## Executive Summary
This paper examines how word splitting affects the semantic content of contextualized word representations from language models. The authors evaluate representations on semantic similarity tasks involving out-of-vocabulary words that are segmented into subwords. They find that representations of split-words are often, but not always, worse than those of in-vocabulary words. The study reveals important patterns about how splitting impacts semantic similarity judgments and highlights the need for careful interpretation when comparing across different split-types.

## Method Summary
The study evaluates contextualized word representations on semantic similarity tasks, focusing on out-of-vocabulary words that require subword segmentation. The authors use the SimLex-999 benchmark to measure semantic similarity, analyzing how different split-types (no-split, 1-SPLIT, 2-SPLIT) affect representation quality. They examine frequency differences as a potential explanation for performance variations and compare similarity values across split configurations.

## Key Results
- The quality of representations for split-words is often, but not always, worse than in-vocabulary words
- Performance on 1-SPLIT pairs is generally lower than on 2-SPLIT pairs, likely due to frequency differences
- Similarity values between two split-words are generally higher than between two full-words, cautioning against direct comparison across split-types

## Why This Works (Mechanism)
Word splitting in language models affects how semantic information is captured in contextualized representations. When words are split into subwords, the model must reconstruct semantic relationships from potentially less coherent or lower-frequency components. This reconstruction process can introduce noise or lose important semantic nuances, particularly when only one word in a pair is split (1-SPLIT), as opposed to both words being split (2-SPLIT).

## Foundational Learning
- Contextualized word representations - Why needed: Form the basis of modern NLP understanding; Quick check: Verify representations capture word meaning in context
- Subword tokenization - Why needed: Enables handling of out-of-vocabulary words; Quick check: Confirm splitting strategy matches model's vocabulary
- Semantic similarity benchmarks - Why needed: Provide standardized evaluation of semantic understanding; Quick check: Ensure benchmark covers diverse semantic relationships
- Frequency effects in NLP - Why needed: Critical confounding factor in representation quality; Quick check: Analyze frequency distributions across split-types
- Cross-split comparison - Why needed: Reveals systematic differences in representation quality; Quick check: Verify statistical significance of observed differences

## Architecture Onboarding

Component map:
Vocabulary -> Tokenizer -> Language Model -> Contextualized Representations -> Semantic Similarity Task

Critical path:
The tokenizer segments input words, the language model generates contextualized representations, and these representations are compared in semantic similarity tasks. The quality of the final similarity scores depends critically on how the tokenizer handles out-of-vocabulary words and how the model reconstructs meaning from subword components.

Design tradeoffs:
The primary tradeoff involves balancing vocabulary size (computational efficiency) against the quality of representations for rare/complex words. Smaller vocabularies require more frequent splitting, potentially degrading semantic quality, while larger vocabularies improve representation quality but increase computational costs.

Failure signatures:
Poor performance on semantic similarity tasks for split-word pairs, particularly 1-SPLIT pairs, indicates that the model struggles to adequately reconstruct semantic relationships from subword components. This is especially pronounced for low-frequency words that undergo splitting.

3 first experiments:
1. Compare semantic similarity scores across different split-types (no-split, 1-SPLIT, 2-SPLIT) on the same benchmark
2. Analyze frequency distributions of words in each split-type to identify potential confounds
3. Examine similarity scores for matched-frequency pairs across split-types to isolate splitting effects

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation relies on a specific semantic similarity task (SimLex-999) which may not capture all aspects of semantic meaning
- The analysis focuses primarily on frequency differences without thoroughly investigating other factors like morphological complexity
- The study does not explore how different tokenization strategies or language model architectures might affect splitting impacts

## Confidence
- 1-SPLIT pairs perform worse than 2-SPLIT pairs: High
- Frequency as primary explanation: Medium
- Caution against cross-split comparisons: Medium

## Next Checks
1. Replicate findings across additional semantic similarity benchmarks beyond SimLex-999 to assess generalizability
2. Control for frequency differences explicitly by creating matched frequency samples to isolate splitting effects
3. Analyze whether morphological complexity or semantic transparency of split components correlates with performance differences