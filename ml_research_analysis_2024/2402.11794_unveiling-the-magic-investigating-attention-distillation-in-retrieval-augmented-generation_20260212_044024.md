---
ver: rpa2
title: 'Unveiling the Magic: Investigating Attention Distillation in Retrieval-augmented
  Generation'
arxiv_id: '2402.11794'
source_url: https://arxiv.org/abs/2402.11794
tags:
- training
- attention
- distillation
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the effectiveness of attention distillation
  in retrieval-augmented generation, focusing on decoder-only language models. It
  finds that attention scores from high-quality reader models are crucial for effective
  retriever training, while low-quality readers lead to poor performance.
---

# Unveiling the Magic: Investigating Attention Distillation in Retrieval-augmented Generation

## Quick Facts
- arXiv ID: 2402.11794
- Source URL: https://arxiv.org/abs/2402.11794
- Authors: Zizhong Li; Haopeng Zhang; Jiawei Zhang
- Reference count: 7
- The paper finds that attention scores from high-quality reader models are crucial for effective retriever training, while low-quality readers lead to poor performance.

## Executive Summary
This paper investigates attention distillation in retrieval-augmented generation, focusing on how attention scores from reader models can serve as effective supervisory signals for training retrievers. The authors discover that high-quality reader models produce attention scores that highlight answer tokens and question-related tokens, which are crucial for effective retriever training. Based on these findings, they propose two indicators to evaluate attention distillation quality: one based on attention to answer tokens and another based on attention to question-related tokens. The indicators are validated on different experimental settings and show promise in distinguishing between high and low-quality attention distillation.

## Method Summary
The paper investigates attention distillation in retrieval-augmented generation using decoder-only language models. The method involves training a Contriever retriever model using attention scores from a Falcon-1b reader model as supervisory signals. Two training settings are explored: off-the-shelf distillation (using the initial untrained Falcon-1b) and fine-tuned distillation (fine-tuning Falcon-1b first, then updating Contriever). The retriever is trained to minimize KL divergence between its document probability distribution and the attention-based distribution from the reader. The proposed indicators measure attention to answer-related tokens (PAT_TN) and question-related tokens (MQ correlation) to evaluate distillation quality.

## Key Results
- Attention scores from high-quality reader models are crucial for effective retriever training, while low-quality readers lead to poor performance
- High-quality readers allocate higher attention to answer tokens and question-related tokens
- The proposed indicators (PAT_TN and MQ correlation) effectively distinguish between high and low-quality attention distillation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention scores from high-quality reader models provide effective supervisory signals for retriever training.
- Mechanism: High-quality readers allocate higher attention to answer tokens and question-related tokens, which the retriever can learn to prioritize during training.
- Core assumption: Attention scores correlate with token relevance for answering questions.
- Evidence anchors:
  - [abstract] "attention scores from high-quality reader models are crucial for effective retriever training"
  - [section 3.2] "tokens closer to answer tokens...receive increasingly higher attention scores" in fine-tuned models
  - [corpus] Weak - no direct evidence found in neighboring papers
- Break condition: If reader quality is low, attention scores fail to highlight relevant tokens, leading to poor retriever performance.

### Mechanism 2
- Claim: Attention distillation works because it captures implicit relevance patterns that manual annotation would provide.
- Mechanism: The reader's self-attention scores implicitly encode which document tokens are most useful for generating correct answers, which can be distilled to train the retriever.
- Core assumption: Self-attention scores in decoder-only models reflect cross-attention patterns that indicate relevance.
- Evidence anchors:
  - [section 2] "we utilize the self-attention scores related to the output tokens as an indicator for indicating document relevance"
  - [section 3.2] "high-quality readers focus more on relevant answer tokens, thereby enhancing both the retriever's performance"
  - [corpus] Weak - no direct evidence found in neighboring papers
- Break condition: If self-attention scores don't correlate with relevance (e.g., in perplexity distillation), the mechanism fails.

### Mechanism 3
- Claim: The proposed indicators can distinguish between high and low-quality attention distillation by measuring attention to answer and question-related tokens.
- Mechanism: Higher average attention scores and Spearman correlation between attention and semantic similarity indicate better distillation quality.
- Core assumption: Attention scores that correlate with semantic similarity to answers/questions indicate effective supervision.
- Evidence anchors:
  - [section 3.2] "Higher average PAT T N(mai) values indicate better attention distillation quality"
  - [section 3.2] "if the average Spearman correlation between the attention scores of MQ and their similarity to Q is above the threshold...attention distillation quality is considered good"
  - [corpus] Weak - no direct evidence found in neighboring papers
- Break condition: If correlation doesn't hold (e.g., encoder-decoder models show polarized distributions), indicators become unreliable.

## Foundational Learning

- Concept: KL divergence as a training objective
  - Why needed here: The retriever is trained to minimize KL divergence between its document probability distribution and the attention-based distribution from the reader.
  - Quick check question: What does minimizing KL divergence between pAT T N and pRET R accomplish in the training process?

- Concept: Token embedding cosine similarity
  - Why needed here: Used to measure semantic proximity between tokens and answer/question tokens to identify which tokens receive attention.
  - Quick check question: How does cosine similarity between token embeddings help identify answer-related and question-related tokens?

- Concept: Spearman correlation as a statistical measure
  - Why needed here: Used to assess whether attention scores monotonically increase with semantic similarity to answers/questions.
  - Quick check question: What does a high Spearman correlation between attention scores and semantic similarity indicate about the reader model?

## Architecture Onboarding

- Component map: Question -> Retriever selects documents -> Reader generates answer with attention -> Attention scores distilled to retriever -> Retriever learns to prioritize relevant documents
- Critical path: Question → Retriever selects documents → Reader generates answer with attention → Attention scores distilled to retriever → Retriever learns to prioritize relevant documents
- Design tradeoffs:
  - Fixed document set size (k=5) balances retrieval quality vs computational cost
  - Decoder-only vs encoder-decoder architecture affects attention interpretation
  - Self-attention vs cross-attention impacts how relevance is measured
- Failure signatures:
  - Off-the-shelf distillation performs worse than initial retriever
  - Perplexity distillation shows no alignment with answer/question-related tokens
  - Encoder-decoder models show polarized Spearman correlation distributions
- First 3 experiments:
  1. Run off-the-shelf distillation with initial Falcon-1b reader and compare HR@5 to baseline Contriever
  2. Fine-tune reader on NQ dataset, then perform distillation and measure indicator values
  3. Test perplexity distillation method and validate against the proposed indicators

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do attention scores from high-quality reader models differ from those of low-quality models at the token level, and what specific patterns in these scores contribute to effective retriever training?
- Basis in paper: [explicit] The paper discusses the importance of high-quality reader models for effective attention distillation and identifies commonalities in attention scores that align with high-quality supervisory signals.
- Why unresolved: While the paper identifies that high-quality reader models focus more on relevant answer and question-related tokens, it does not provide a detailed quantitative analysis of the specific patterns in attention scores that differentiate high-quality from low-quality models.
- What evidence would resolve it: A comprehensive quantitative analysis comparing attention scores from high-quality and low-quality reader models, identifying specific patterns and features that contribute to effective retriever training.

### Open Question 2
- Question: Can the proposed indicators for evaluating attention distillation quality be generalized to other retrieval-augmented generation tasks beyond question answering?
- Basis in paper: [explicit] The paper proposes two indicators based on attention to answer and question-related tokens, validated on QA tasks, but does not explore their applicability to other tasks.
- Why unresolved: The paper focuses on QA tasks and does not provide evidence or discussion on whether the indicators are applicable to other retrieval-augmented generation tasks.
- What evidence would resolve it: Experimental validation of the indicators on a variety of retrieval-augmented generation tasks, such as summarization or dialogue generation, to assess their generalizability.

### Open Question 3
- Question: How does the size and complexity of language models affect the effectiveness of attention distillation in retrieval-augmented generation?
- Basis in paper: [inferred] The paper uses lightweight language models due to their flexibility but does not explore the impact of model size and complexity on attention distillation effectiveness.
- Why unresolved: The paper does not investigate whether larger or more complex models would yield different results in terms of attention distillation effectiveness.
- What evidence would resolve it: Comparative studies using language models of varying sizes and complexities to determine how these factors influence the effectiveness of attention distillation in retrieval-augmented generation.

## Limitations

- The theoretical foundation connecting attention patterns to retrieval effectiveness remains somewhat under-explained
- The generalizability of proposed indicators across different model architectures and datasets is not fully established
- The distinction between decoder-only and encoder-decoder models in attention interpretation is mentioned but not thoroughly explored

## Confidence

**High Confidence:** The core finding that high-quality reader models produce attention scores crucial for effective retriever training is well-supported by the experimental results showing significant performance differences between off-the-shelf and fine-tuned distillation settings.

**Medium Confidence:** The two proposed indicators (PAT_TN and MQ correlation) appear effective in the tested settings, but their robustness across different model sizes, architectures, and datasets remains to be validated.

**Low Confidence:** The mechanism explanation for why attention distillation works is largely theoretical. While the empirical results are convincing, the paper doesn't provide sufficient ablation studies to isolate whether attention scores specifically are responsible for the observed improvements.

## Next Checks

1. **Cross-Architecture Validation:** Test the proposed indicators on encoder-decoder models and other retriever architectures to verify their generalizability and understand the "polarized distributions" phenomenon mentioned for encoder-decoder models.

2. **Ablation Study:** Design experiments to isolate the contribution of attention-based supervision versus other potential signals by systematically removing or modifying components of the distillation process.

3. **Scaling Analysis:** Evaluate the indicators and overall approach across different model scales to determine whether the relationship between reader quality, attention patterns, and retriever performance holds across the spectrum of model sizes.