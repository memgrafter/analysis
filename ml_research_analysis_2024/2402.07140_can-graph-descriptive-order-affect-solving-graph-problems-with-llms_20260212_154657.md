---
ver: rpa2
title: Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?
arxiv_id: '2402.07140'
source_url: https://arxiv.org/abs/2402.07140
tags:
- graph
- node
- path
- arxiv
- order
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study reveals that the order of graph descriptions significantly
  impacts large language models' (LLMs) performance on graph reasoning tasks. The
  researchers found that ordered graph descriptions consistently outperform random
  descriptions across six graph tasks, with improvements ranging from 5% to 86%.
---

# Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?

## Quick Facts
- arXiv ID: 2402.07140
- Source URL: https://arxiv.org/abs/2402.07140
- Reference count: 38
- This study reveals that the order of graph descriptions significantly impacts large language models' (LLMs) performance on graph reasoning tasks, with ordered descriptions outperforming random descriptions by 5-86% across six graph tasks.

## Executive Summary
This study systematically investigates how the order of graph descriptions affects LLM performance on graph reasoning tasks. The researchers found that ordered graph descriptions consistently outperform random descriptions across six graph tasks, with improvements ranging from 5% to 86%. Specifically, BFS order showed strong performance in connectivity and shortest path tasks, while DFS excelled in Hamilton path and topological sort tasks. The study introduces the GraphDO dataset and demonstrates that attention bias—stemming from positional encoding limitations—drives these performance differences. These findings highlight the importance of strategic graph description ordering for optimizing LLM performance in graph-related problems.

## Method Summary
The researchers created the GraphDO dataset with 8,500 graph reasoning cases using Erdős-Rényi graph generation with 5-15 nodes and 0.3 connection probability. They implemented four graph description orders (BFS, DFS, PageRank, Personalized PageRank) and converted graphs to natural language using adjacency format. The study evaluated six mainstream LLMs using different prompt styles (zero-shot, zero-shot CoT, few-shot CoT, CoT, CoT-BAG) across six graph tasks: connectivity detection, cycle detection, Hamilton path, shortest path, topological sort, and node classification. Performance was measured using accuracy metrics.

## Key Results
- Ordered graph descriptions consistently outperform random descriptions across all six graph tasks, with improvements ranging from 5% to 86%
- BFS order excels at connectivity and shortest path tasks, while DFS performs better on Hamilton path and topological sort tasks
- PageRank-based ordering shows consistent superiority for node classification tasks across all tested datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ordered graph descriptions improve LLM performance by reducing attention bias from positional encoding limitations.
- Mechanism: Positional encodings in transformers provide sequence information, but unordered graph descriptions lack inherent sequence structure. When graph descriptions are ordered (e.g., BFS, DFS), the positional encodings can better capture structural patterns, reducing attention bias toward certain parts of the graph based on their order in the sequence.
- Core assumption: Positional encodings in LLMs are insufficient for capturing graph structure complexity when descriptions are unordered.
- Evidence anchors:
  - [abstract]: "attention bias—stemming from positional encoding limitations—drives these performance differences"
  - [section 4.2]: "We hypothesize that LLMs' improved performance with ordered descriptions stems from limitations in positional encoding and attention mechanisms—what we call attention bias"
  - [corpus]: Weak evidence - the corpus doesn't contain specific studies on positional encoding limitations in graph reasoning tasks.

### Mechanism 2
- Claim: Different graph description orders favor different types of graph reasoning tasks based on their structural characteristics.
- Mechanism: BFS order benefits tasks requiring local connectivity exploration (cycle detection, connectivity detection) because it processes nodes level-by-level, revealing adjacent connections early. DFS order excels at tasks requiring deep exploration of global structures (Hamilton path, topological sort) by thoroughly exploring paths before backtracking.
- Core assumption: The traversal order of graph descriptions aligns with the reasoning patterns needed for different graph tasks.
- Evidence anchors:
  - [abstract]: "BFS order showed strong performance in connectivity and shortest path tasks, while DFS excelled in Hamilton path and topological sort tasks"
  - [section 4.2]: "BFS generally outperforms DFS in tasks like cycle detection, connectivity detection, and shortest path. For tasks requiring deeper exploration, such as topological sort and Hamilton path, DFS performs better"
  - [corpus]: Moderate evidence - the corpus contains related work on graph reasoning with LLMs but doesn't specifically address task-specific ordering advantages.

### Mechanism 3
- Claim: Probability distribution-based orders (PageRank, Personalized PageRank) outperform traversal-based orders for node classification tasks.
- Mechanism: Node classification relies on understanding global graph structure and node importance. PageRank and PPR capture global probability distributions of node importance, which aligns better with the reasoning needed for node classification than local traversal orders.
- Core assumption: Node classification benefits more from global importance ranking than from local structural exploration.
- Evidence anchors:
  - [abstract]: "the PR order consistently outperforms the PPR across all datasets, while PPR generally performs better than traversal-based orders"
  - [section 4.2]: "For node classification task, as demonstrated in Table 2, the PR order consistently outperforms the PPR across all datasets, while PPR generally performs better than traversal-based orders"
  - [corpus]: Moderate evidence - related work exists on graph embeddings and node importance but not specifically on ordering for node classification with LLMs.

## Foundational Learning

- Concept: Graph representation and encoding methods
  - Why needed here: Understanding how graphs can be converted to text descriptions is fundamental to grasping why ordering matters
  - Quick check question: What are the differences between adjacency list format and other graph encoding methods for LLM input?

- Concept: Graph traversal algorithms (BFS, DFS)
  - Why needed here: The study relies on these traversal methods to create ordered graph descriptions, and understanding their differences explains the task-specific performance variations
  - Quick check question: How do BFS and DFS differ in their approach to exploring graph structures, and why would these differences matter for LLM reasoning?

- Concept: PageRank algorithm and probability distributions on graphs
  - Why needed here: PageRank-based ordering is one of the key methods used, and understanding how it ranks nodes helps explain its effectiveness for certain tasks
  - Quick check question: How does the PageRank algorithm determine node importance, and why might this be useful for node classification tasks?

## Architecture Onboarding

- Component map: Graph generation -> Graph encoding -> Description ordering -> Prompt generation -> LLM inference -> Response parsing -> Accuracy calculation
- Critical path: Graph generation → Graph encoding → Description ordering → Prompt generation → LLM inference → Response parsing → Accuracy calculation
- Design tradeoffs: Using simpler graph tasks (connectivity, cycle detection) allows for clearer demonstration of ordering effects but may not generalize to more complex real-world graph problems. The choice of Erdős-Rényi graphs with moderate density ensures solvability but may not represent all graph types.
- Failure signatures: If accuracy improvements from ordering are minimal across all tasks, it may indicate that the LLM has learned to overcome positional encoding limitations or that the graph description format itself is not optimal for graph reasoning.
- First 3 experiments:
  1. Run the same graph reasoning task with both random and BFS ordering to establish baseline performance difference
  2. Test BFS vs DFS ordering on a task known to benefit from local connectivity (like cycle detection) to validate task-specific ordering advantages
  3. Compare PageRank vs traversal-based orders on node classification task to verify probability distribution-based ordering effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the performance impact of graph description order persist across different graph sizes and densities beyond the current experimental range?
- Basis in paper: [inferred] The paper states "we chose n between 5 and 15" and uses ER graphs with fixed probability p=0.3, but doesn't explore how order effects scale with graph complexity.
- Why unresolved: The study focused on relatively small, sparse graphs (n=5-15, p=0.3) to maintain consistency with previous work. This leaves open whether the observed order effects generalize to larger, denser graphs or real-world networks with varying structures.
- What evidence would resolve it: Systematic experiments varying graph size (n>15), density (p≠0.3), and structural properties (scale-free, small-world) while measuring performance differences across orders.

### Open Question 2
- Question: Can LLMs be fine-tuned or prompted to reduce attention bias from graph description order, making them more robust to input ordering?
- Basis in paper: [explicit] The paper identifies "attention bias" from positional encoding limitations as the mechanism behind order effects, but doesn't explore mitigation strategies.
- Why unresolved: While the paper documents the phenomenon and its causes, it doesn't investigate whether architectural modifications, specialized positional encodings, or targeted fine-tuning could reduce the sensitivity to description order.
- What evidence would resolve it: Comparative experiments testing models with graph-specific positional encodings, models fine-tuned on diverse description orders, or models using different attention mechanisms (sparse attention, global attention) on the same graph tasks.

### Open Question 3
- Question: How do graph description orders interact with different graph representation formats (adjacency matrix, edge list, node list) in affecting LLM performance?
- Basis in paper: [inferred] The study uses adjacency list format exclusively but doesn't compare performance across different graph encoding methods despite acknowledging "graphs can be described in text through multiple encoding methods."
- Why unresolved: The paper demonstrates order effects for one encoding format but leaves open whether these effects generalize across representation types or whether certain orders are particularly beneficial for specific formats.
- What evidence would resolve it: Parallel experiments encoding the same graphs using multiple formats (adjacency matrix, edge list, node list with attributes) and testing the same description orders across all formats to identify format-order interactions.

## Limitations
- The study focuses primarily on relatively small synthetic graphs (5-15 nodes), which may not generalize to larger, real-world graph structures
- The analysis is limited to adjacency list format for graph descriptions without exploring alternative representations
- While the attention bias hypothesis is compelling, the study doesn't directly measure attention patterns to confirm the mechanism

## Confidence

- **High confidence**: The study's primary claims about ordered graph descriptions improving LLM performance carry high confidence due to robust experimental results across six different graph tasks and multiple LLMs.
- **Medium confidence**: The proposed mechanism of attention bias from positional encoding limitations remains medium confidence as the study provides indirect evidence through empirical results rather than direct analysis of attention patterns.
- **High confidence**: The task-specific ordering advantages (BFS for connectivity/shortest path, DFS for Hamilton path/topological sort) show high confidence based on repeated observations across multiple datasets.

## Next Checks

1. **Cross-scale validation**: Test the same ordering effects on larger graphs (100+ nodes) to verify whether the performance improvements scale or diminish with graph complexity.

2. **Attention pattern analysis**: Use attention visualization tools to directly examine whether ordered descriptions actually reduce attention bias toward specific graph regions as hypothesized.

3. **Alternative representation comparison**: Compare the adjacency list format with alternative graph encodings (edge lists, matrix representations) to determine if ordering effects are format-dependent or generalizable.