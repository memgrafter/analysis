---
ver: rpa2
title: Goal Recognition via Linear Programming
arxiv_id: '2404.07934'
source_url: https://arxiv.org/abs/2404.07934
tags:
- goal
- recognition
- constraints
- observations
- plan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel linear programming approach to goal
  recognition by adapting the operator-counting framework. The authors propose new
  constraints based on observations and landmarks to efficiently compute heuristic
  estimates of the cost-to-goal for planning tasks.
---

# Goal Recognition via Linear Programming

## Quick Facts
- arXiv ID: 2404.07934
- Source URL: https://arxiv.org/abs/2404.07934
- Authors: Felipe Meneguzzi; Luísa R. de A. Santos; Ramon Fraga Pereira; André G. Pereira
- Reference count: 9
- Key outcome: This paper introduces a novel linear programming approach to goal recognition by adapting the operator-counting framework. The authors propose new constraints based on observations and landmarks to efficiently compute heuristic estimates of the cost-to-goal for planning tasks. They prove that their constraints provide lower bounds on the cost of plans that comply with observations, and show that the new constraints improve the quality of the solution, especially in deciding which goals are unlikely to be part of the solution. The approach is evaluated on a large benchmark of planning domains, and the results show that it outperforms previous state-of-the-art goal recognition methods in terms of accuracy and efficiency.

## Executive Summary
This paper presents a novel approach to goal recognition using linear programming (LP) that adapts the operator-counting framework. The key innovation is the introduction of new LP constraints based on observations and landmarks to efficiently compute heuristic estimates of the cost-to-goal for planning tasks. The authors prove that their constraints provide lower bounds on the cost of plans that comply with observations, and demonstrate that the new constraints improve the quality of the solution, especially in deciding which goals are unlikely to be part of the solution. The approach is evaluated on a large benchmark of planning domains, and the results show that it outperforms previous state-of-the-art goal recognition methods in terms of accuracy and efficiency.

## Method Summary
The paper introduces a novel linear programming approach to goal recognition by adapting the operator-counting framework. The authors propose new constraints based on observations and landmarks to efficiently compute heuristic estimates of the cost-to-goal for planning tasks. They prove that their constraints provide lower bounds on the cost of plans that comply with observations, and show that the new constraints improve the quality of the solution, especially in deciding which goals are unlikely to be part of the solution. The approach is evaluated on a large benchmark of planning domains, and the results show that it outperforms previous state-of-the-art goal recognition methods in terms of accuracy and efficiency.

## Key Results
- The LP constraints provide lower bounds on the cost of plans that comply with observations.
- The landmark constraints improve recognition accuracy by tightening the LP solution space.
- The LP framework naturally handles noisy observations through the unreliability parameter ε.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The operator-counting framework efficiently computes lower bounds on the cost of plans that comply with observations.
- Mechanism: By adding observation-counting constraints to the operator-counting LP, the solver enforces that only plans consistent with the observed sequence of actions are considered. These constraints bound the count of each observed operator in the LP solution, ensuring compliance while minimizing total cost.
- Core assumption: The optimal solution to the LP is always a lower bound on the actual optimal plan cost for the goal hypothesis.
- Evidence anchors:
  - [abstract] "they prove that the new constraints provide lower bounds on the cost of plans that comply with observations"
  - [section] Theorem 1 proves that hIP_s*,Ω(s) is a lower bound on the cost of an optimal complying plan.
  - [corpus] Weak. No direct corpus evidence on lower bounds; only mentions "inverse kinematic planning" which is tangentially related.
- Break condition: If the observation sequence contains many noisy observations beyond the allowed unreliability ε, the LP may become infeasible or the lower bound may become too loose.

### Mechanism 2
- Claim: Landmark constraints derived from observations improve recognition accuracy by tightening the LP solution space.
- Mechanism: The approach extracts disjunctive action landmarks from the preconditions of observed operators. These landmarks require at least one operator in each landmark set to be executed if the corresponding observation is part of the plan. By encoding this dependency in the LP, the solver eliminates infeasible operator combinations, leading to more informed cost estimates.
- Core assumption: Every observation in a plan must be preceded by its preconditions, so operators achieving those preconditions form necessary landmarks.
- Evidence anchors:
  - [abstract] "they introduce novel LP/IP landmark constraints hLMC for goal recognition tasks that extract information on-the-fly, from the observation sequence"
  - [section] Definition 13 encodes landmark constraints for goal recognition tasks.
  - [corpus] Weak. No direct corpus evidence on landmark constraints; only general "hierarchical" planning.
- Break condition: If the landmark extraction algorithm is incomplete or incorrect, the LP may exclude valid plans or fail to prune infeasible ones.

### Mechanism 3
- Claim: The LP framework naturally handles noisy observations through the unreliability parameter ε.
- Mechanism: By relaxing the requirement that all observations must be satisfied, and instead requiring at least |Ω| - ⌊|Ω| * ε⌋ observations to be satisfied, the LP can ignore a controlled number of spurious observations. This prevents noise from inflating the cost estimates for correct goal hypotheses.
- Core assumption: Noisy observations are uniformly distributed and independent of the true plan, so ignoring a fraction ε of them will not systematically bias the recognition.
- Evidence anchors:
  - [abstract] "we show how the new IP/LP constraints can improve the recognition of goals under both partial and noisy observability"
  - [section] Theorem 2 proves the lower bound property still holds with noisy observations under ε.
  - [corpus] Weak. No direct corpus evidence on noisy observations; only general "continuous control models".
- Break condition: If the noise rate ε is underestimated, the LP may wrongly ignore true observations, hurting recognition accuracy.

## Foundational Learning

- Concept: Linear Programming and Integer Programming relaxation
  - Why needed here: The operator-counting framework solves a relaxation of an IP to efficiently estimate plan costs. Understanding LP duality and relaxation is essential to grasp why the solutions are lower bounds.
  - Quick check question: Why does solving the LP relaxation of the operator-counting IP yield a lower bound on the true optimal plan cost?

- Concept: Planning landmarks and disjunctive action landmarks
  - Why needed here: Landmark constraints are the primary source of additional LP constraints. Knowing what landmarks are and how they are extracted is necessary to understand the hLMC heuristic.
  - Quick check question: What is the difference between a conjunctive landmark and a disjunctive action landmark in planning?

- Concept: Goal Recognition as Planning formulation
  - Why needed here: The problem setting maps goal recognition to a planning task with observations as constraints. Understanding this mapping is critical to follow the constraint definitions.
  - Quick check question: In the Goal Recognition as Planning framework, how are observations represented as constraints on the planning task?

## Architecture Onboarding

- Component map: Input layer (Domain model, goal hypotheses, observation sequence, noise level) -> Preprocessor (Landmark extraction, constraint generation) -> LP solver (Fast Downward with CPLEX backend) -> Postprocessor (Heuristic value extraction, solution set computation) -> Evaluation (Comparison with baseline RG/POM approaches)
- Critical path: Observation -> Landmark extraction -> Constraint generation -> LP solve -> Heuristic comparison -> Recognition output
- Design tradeoffs:
  - Tightness of LP relaxation vs. solve time: Adding more landmark constraints tightens the bound but increases LP size.
  - Noise tolerance vs. accuracy: Higher ε allows more noise but may reduce recognition precision.
  - Completeness of landmark extraction vs. computational overhead: More complete landmarks improve accuracy but increase preprocessing cost.
- Failure signatures:
  - LP infeasible: Likely due to overly restrictive landmark constraints or inconsistent observations.
  - Very loose lower bounds: May indicate missing landmark constraints or high noise level.
  - Slow solves: Could be caused by large number of landmark constraints or complex domain.
- First 3 experiments:
  1. Verify lower bound property: Run LP on a simple domain with known optimal plan and check that LP cost ≤ optimal plan cost.
  2. Landmark impact: Compare recognition accuracy with and without landmark constraints on a domain with clear landmark structure (e.g., blocks world).
  3. Noise handling: Generate synthetic noisy observations with known noise level and test recognition accuracy across different ε values.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the novel landmark constraints (hLMCΩΩ,s∗) perform compared to other types of operator-counting constraints (hSEQ, hPhO, hFLOW) in goal recognition tasks?
- Basis in paper: [explicit] The paper mentions that the authors' previous work used various sources of operator-counting constraints, but this article focuses on landmark constraints. It also states that landmark constraints contribute more towards goal recognition tasks than other sources of constraints (Santos et al., 2021).
- Why unresolved: The paper does not provide a direct comparison of the performance of different types of operator-counting constraints in goal recognition tasks.
- What evidence would resolve it: Empirical results comparing the accuracy and efficiency of different types of operator-counting constraints (hLMCΩΩ,s∗, hSEQ, hPhO, hFLOW) on a variety of goal recognition benchmarks.

### Open Question 2
- Question: How does the performance of the LP-based goal recognition approach vary with different levels of noise in the observations?
- Basis in paper: [explicit] The paper discusses the impact of noisy observations on the goal recognition task and proposes a method to handle noisy observations using an unreliability rating parameter (ε).
- Why unresolved: The paper does not provide a comprehensive analysis of the performance of the LP-based approach under different levels of noise in the observations.
- What evidence would resolve it: Experimental results showing the agreement ratio and computational time of the LP-based approach under different levels of noise in the observations.

### Open Question 3
- Question: How does the computational cost of the LP-based goal recognition approach scale with the size of the planning task and the number of goal hypotheses?
- Basis in paper: [explicit] The paper mentions that the LP-based approach is more computationally efficient than the classical planning approach (RG) and the landmark-based approach (POM).
- Why unresolved: The paper does not provide a detailed analysis of the computational cost of the LP-based approach as a function of the size of the planning task and the number of goal hypotheses.
- What evidence would resolve it: Experimental results showing the computational time of the LP-based approach on planning tasks of varying sizes and with different numbers of goal hypotheses.

## Limitations

- The landmark extraction technique is only briefly described, and its completeness and correctness are not thoroughly validated.
- The assumption that noisy observations are uniformly distributed may not hold in real-world scenarios, potentially limiting the approach's applicability.
- The computational cost of the LP-based approach may increase significantly with the size of the planning task and the number of goal hypotheses.

## Confidence

- **High Confidence:** The theoretical proof that the LP constraints provide lower bounds on plan costs (Mechanism 1).
- **Medium Confidence:** The claim that landmark constraints improve recognition accuracy (Mechanism 2), as the evidence is primarily based on experimental results rather than theoretical analysis.
- **Low Confidence:** The assumption about uniform distribution of noisy observations (Mechanism 3), as this is not empirically validated.

## Next Checks

1. **Landmark Extraction Validation:** Implement a simple landmark extraction technique and compare its completeness and correctness against the one used in the paper. Test on domains with known landmark structures to assess its impact on recognition accuracy.
2. **Noise Distribution Analysis:** Generate synthetic observation sequences with different noise distributions (e.g., clustered noise, systematic noise) and evaluate the approach's performance. Compare against the uniform noise assumption to identify potential biases.
3. **Scalability Assessment:** Test the approach on larger planning domains and longer observation sequences to assess its scalability and identify potential bottlenecks in landmark constraint generation or LP solving.