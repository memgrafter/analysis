---
ver: rpa2
title: How to Craft Backdoors with Unlabeled Data Alone?
arxiv_id: '2404.06694'
source_url: https://arxiv.org/abs/2404.06694
tags:
- backdoor
- data
- poison
- contrastive
- backdoors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work explores the feasibility of crafting backdoor attacks
  on self-supervised learning (SSL) models using only unlabeled data. The authors
  propose two strategies for poison set selection: clustering-based selection using
  pseudolabels obtained from K-means clustering of SSL features, and contrastive selection
  derived from maximizing mutual information between the input and backdoor selection.'
---

# How to Craft Backdoors with Unlabeled Data Alone?

## Quick Facts
- arXiv ID: 2404.06694
- Source URL: https://arxiv.org/abs/2404.06694
- Reference count: 36
- This work demonstrates that effective backdoor attacks can be crafted on self-supervised learning models using only unlabeled data.

## Executive Summary
This paper investigates the feasibility of creating backdoor attacks on self-supervised learning (SSL) models without requiring labeled data. The authors propose two strategies for selecting poison samples: clustering-based selection using K-means on SSL features, and contrastive selection based on maximizing mutual information between inputs and backdoor selection. Experiments on CIFAR-10 and ImageNet-100 show that both methods significantly outperform random poisoning, with the contrastive selection achieving higher attack success rates across various SSL methods.

## Method Summary
The paper proposes two no-label backdoor (NLB) methods that exploit unlabeled data for crafting backdoor attacks on SSL models. Clustering-based NLB uses K-means clustering on SSL features to create pseudo-labels and selects poison samples from the most consistent cluster. Contrastive NLB employs a mutual information principle via Total Contrastive Similarity (TCS) criterion, selecting samples that maximize intra-cluster similarity while minimizing inter-cluster similarity. Both methods inject backdoor triggers into selected poison samples and evaluate attack effectiveness through clean accuracy, poison accuracy, and attack success rate metrics.

## Key Results
- No-label backdoors are effective on multiple SSL methods (SimCLR, MoCo v2, BYOL, Barlow Twins) on CIFAR-10 and ImageNet-100
- Contrastive selection outperforms clustering-based selection in most cases
- No-label backdoors remain partially effective even after finetuning-based backdoor defenses
- Clustering-based selection achieves high cluster consistency rates (CCR) allowing effective poison selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: No-label backdoors can be crafted by selecting poison sets based on mutual information maximization between input and selection variable.
- Mechanism: The poison selection process maximizes the mutual information I(X; S) between the input data X and the backdoor selection variable S, which creates a feature split with minimal input uncertainty within each group.
- Core assumption: The pretrained SSL model approximately maximizes I(X; Z), so I(X; Z; S) ≈ H(X) - H(X|S) = I(X; S).
- Evidence anchors:
  - [abstract] "Experiments on CIFAR-10 and ImageNet-100 show that both no-label backdoors are effective on many SSL methods and outperform random poisoning by a large margin."
  - [section] "Eq. (5) is also known as the Information Gain criterion used in decision trees when choosing the most important input feature for splitting the data at each node"
  - [corpus] Weak - the related papers focus on semi-supervised learning and backdoor mitigation, not on the mutual information principle for poison selection
- Break condition: If the pretrained SSL model does not adequately maximize mutual information, or if the feature space is not discriminative enough to create meaningful splits.

### Mechanism 2
- Claim: Contrastive selection creates effective no-label backdoors by maximizing similarity within poison set while minimizing similarity to non-poisoned samples.
- Mechanism: The poison set is selected using an InfoNCE-style criterion that maximizes the total contrastive similarity between poisoned samples while pushing them away from clean samples in the feature space.
- Core assumption: The SSL feature space captures meaningful semantic similarity that can be exploited for backdoor selection.
- Evidence anchors:
  - [abstract] "The contrastive selection method, based on the mutual information principle, outperforms clustering-based selection in most cases."
  - [section] "Inspired by the fact that log P x′ /∈P exp(f (x)⊤f (x′)) ≥ maxx′ /∈P f (x)⊤f (x′), we approximate this term with M negative samples with the largest feature similarities to x"
  - [corpus] Missing - related papers don't discuss contrastive selection for backdoor attacks
- Break condition: If the feature space is not well-suited for contrastive learning, or if the negative sampling strategy fails to capture meaningful hard negatives.

### Mechanism 3
- Claim: Clustering-based no-label backdoors work by leveraging pseudolabels from K-means clustering of SSL features to select same-class poison samples.
- Mechanism: K-means clustering on SSL features creates pseudolabels that group samples from the same class together, allowing poison selection from consistent clusters.
- Core assumption: SSL features are discriminative enough for K-means to create clusters with high class consistency rates (CCR).
- Evidence anchors:
  - [abstract] "Experiments on CIFAR-10 and ImageNet-100 show that both no-label backdoors are effective on many SSL methods and outperform random poisoning by a large margin."
  - [section] "We treat each cluster as a pseudo-class, and correspondingly, we annotate the unlabeled dataset with K pseudo-labels"
  - [corpus] Weak - related papers discuss semi-supervised learning but not clustering-based backdoor selection
- Break condition: If K-means initialization produces poor clustering, or if SSL features are not discriminative enough for meaningful clustering.

## Foundational Learning

- Concept: Self-supervised learning (SSL) and contrastive learning
  - Why needed here: The entire backdoor attack mechanism relies on SSL pretraining to extract meaningful features for poison selection
  - Quick check question: What is the key difference between SimCLR and MoCo v2 in terms of how they handle negative samples?

- Concept: Mutual information and its estimation via InfoNCE
  - Why needed here: The contrastive selection method is directly derived from maximizing mutual information between input and backdoor selection
  - Quick check question: How does InfoNCE provide a variational lower bound on mutual information?

- Concept: K-means clustering and cluster consistency metrics
  - Why needed here: The clustering-based method depends on K-means to create pseudolabels with high class consistency rates
  - Quick check question: What metric can be used to automatically estimate the number of clusters K when it's unknown?

## Architecture Onboarding

- Component map: SSL pretraining (SimCLR/MoCo v2/BYOL/Barlow Twins) -> Feature extraction -> Poison selection (clustering/contrastive) -> Backdoor injection -> Downstream evaluation
- Critical path: Pretraining (500 epochs CIFAR-10, 300 epochs ImageNet-100) -> Feature extraction -> Poison selection (O(M^2) complexity) -> Trigger injection -> Linear probing (100 epochs CIFAR-10, 50 epochs ImageNet-100)
- Design tradeoffs:
  - Clustering vs contrastive selection: Clustering is simpler but less stable; contrastive is more principled but computationally heavier
  - Poison rate selection: Higher rates increase attack success but may be more detectable; trade-off between effectiveness and stealth
  - Trigger type: BadNet vs Blend - BadNet is simpler but Blend may be more stealthy
- Failure signatures:
  - Low CCR (< 50%) indicates poor clustering performance or feature space inadequacy
  - ASR close to random baseline (~10% CIFAR-10, ~1% ImageNet-100) suggests selection method failure
  - High clean accuracy but low poison accuracy with low ASR may indicate ineffective trigger injection
- First 3 experiments:
  1. Verify baseline performance: Run random poison selection on CIFAR-10 with SimCLR pretraining and measure clean accuracy, poison accuracy, and ASR
  2. Compare clustering selection: Run clustering-based poison selection with K=10 and compare CCR, clean accuracy, poison accuracy, and ASR against baseline
  3. Test contrastive selection: Run contrastive poison selection using TCS criterion and evaluate all metrics, comparing against both previous methods

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed no-label backdoor (NLB) perform when applied to modern SSL methods like DINO and MoCo-v3, and what are the differences in effectiveness between these methods?
- Basis in paper: [explicit] The paper mentions evaluating NLB on DINO and MoCo-v3 on ImageNet-100, showing that the methods perform well for poisoning these models, with contrastive selection achieving higher attack success rates (ASRs) than clustering-based selection.
- Why unresolved: While the paper provides initial results, a comprehensive analysis of the performance differences across various modern SSL methods and the reasons behind these differences are not fully explored.
- What evidence would resolve it: Detailed comparative studies across a wider range of SSL methods, including varying architectures and training strategies, would provide insights into the generalizability and effectiveness of NLB.

### Open Question 2
- Question: Can the proposed no-label backdoor attacks be mitigated by defenses other than fine-tuning, such as PatchSearch, and how do these defenses compare in effectiveness?
- Basis in paper: [explicit] The paper evaluates the performance of NLB against fine-tuning-based defense and PatchSearch, showing that both defenses can reduce the ASR but not entirely remove the backdoor.
- Why unresolved: The paper does not extensively explore the effectiveness of other potential defenses or provide a comprehensive comparison of their efficacy against NLB.
- What evidence would resolve it: Systematic evaluation of NLB against a variety of defenses, including those specifically designed for SSL, and comparative analysis of their effectiveness would provide a clearer understanding of the robustness of NLB.

### Open Question 3
- Question: How does the mutual information principle used in contrastive selection influence the choice of poison set, and can alternative MI-based criteria be more effective?
- Basis in paper: [explicit] The paper introduces the mutual information principle for poison selection and compares it with InfoNCE, showing that TCS (Total Contrastive Similarity) has similar performance but better computation complexity.
- Why unresolved: The paper does not explore other potential MI-based criteria or provide a thorough analysis of why the proposed TCS is optimal.
- What evidence would resolve it: Comparative studies of various MI-based selection criteria, including theoretical analysis and empirical evaluation, would elucidate the strengths and weaknesses of the proposed approach and identify potential improvements.

## Limitations

- The theoretical foundation relies on assumptions about SSL pretraining maximizing mutual information that are difficult to verify empirically
- Effectiveness may not generalize beyond the specific SSL models tested (SimCLR, MoCo v2, BYOL, Barlow Twins)
- The stealthiness of attacks is uncertain as poison selection may create detectable artifacts in feature space

## Confidence

- Effectiveness of contrastive selection: High (strong empirical results)
- Theoretical foundation via mutual information: Medium (plausible but not fully verified)
- Generalization to other SSL methods: Low (only tested on 4 specific methods)

## Next Checks

1. Verify the relationship between TCS scores and ASR by systematically varying the number of negatives M and measuring correlation with attack success
2. Test the robustness of no-label backdoors against state-of-the-art backdoor defenses beyond simple finetuning
3. Evaluate whether the poison selection creates detectable artifacts in the feature space using unsupervised anomaly detection