---
ver: rpa2
title: 'PALP: Prompt Aligned Personalization of Text-to-Image Models'
arxiv_id: '2401.06105'
source_url: https://arxiv.org/abs/2401.06105
tags:
- prompt
- personalization
- image
- subject
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of aligning personalized text-to-image
  models with complex prompts while maintaining subject fidelity. The core method
  idea is to use a score distillation sampling (SDS) term that steers the model's
  predictions toward the target prompt during fine-tuning, preventing overfitting
  and preserving prompt alignment.
---

# PALP: Prompt Aligned Personalization of Text-to-Image Models

## Quick Facts
- arXiv ID: 2401.06105
- Source URL: https://arxiv.org/abs/2401.06105
- Authors: Moab Arar; Andrey Voynov; Amir Hertz; Omri Avrahami; Shlomi Fruchter; Yael Pritch; Daniel Cohen-Or; Ariel Shamir
- Reference count: 40
- One-line primary result: Achieves 91.2% user preference for prompt alignment and 72.1% similarity rating for subject fidelity compared to state-of-the-art baselines

## Executive Summary
PALP addresses the challenge of personalizing text-to-image models while maintaining both subject fidelity and prompt alignment. The method introduces a score distillation sampling (SDS) term during fine-tuning that steers the model toward the target prompt without overfitting to training images. This approach enables users to generate images of personalized subjects with complex, style-rich prompts while preserving the subject's identity and appearance.

The key innovation is the Delta Denoising Score (DDS) variant, which uses the residual direction between personalized and pre-trained predictions rather than guiding toward the class center. This prevents mode collapse and over-saturation while maintaining subject-specific features. The method achieves state-of-the-art performance on prompt alignment (91.2% user preference) and subject preservation (72.1% similarity rating) while requiring only a single reference image for personalization.

## Method Summary
PALP fine-tunes text-to-image models using LoRA on personal images while adding a prompt-alignment loss through score distillation sampling (SDS). The method uses the Delta Denoising Score (DDS) variant that guides the model using the residual direction between personalized and pre-trained predictions, preventing mode collapse. During training, the model optimizes two objectives: personalization (reconstruction loss on noisy samples) and prompt-alignment (SDS/DDS guidance toward target prompt). The method uses different guidance scales for each objective and trains for 500 steps with a learning rate of 5e-5.

## Key Results
- Achieves 91.2% user preference for prompt alignment compared to baselines
- Maintains 72.1% similarity rating for subject fidelity in user studies
- Outperforms state-of-the-art methods including Textual Inversion and DreamBooth
- Enables multi-subject personalization with a single reference image
- Successfully transfers artistic styles while preserving subject identity

## Why This Works (Mechanism)

### Mechanism 1
The score distillation sampling (SDS) term prevents overfitting to training images while maintaining alignment with the target prompt. By using the pre-trained model's knowledge of prompt elements (excluding the new subject), the method steers the personalized model's predictions toward the desired prompt distribution without memorizing specific training image details. This works because the pre-trained model already understands all prompt elements except the new subject, so its guidance can maintain prompt alignment during personalization.

### Mechanism 2
The Delta Denoising Score (DDS) variant improves diversity and prevents mode collapse compared to standard SDS. Instead of guiding toward the center of the class distribution, DDS uses the residual direction between personalized and pre-trained predictions, maintaining subject-specific features while aligning with the prompt. This works because standard SDS guidance toward the class center causes over-saturation and mode collapse, while DDS preserves subject identity better.

### Mechanism 3
Using the same noise sample for both personalization and prompt-alignment branches improves text alignment. Sharing the noise sample creates coupling between the two objectives, ensuring that prompt alignment influences the denoising path that reconstructs the subject. This works because independent noise sampling for each branch reduces the coupling between prompt alignment and subject reconstruction, leading to suboptimal results.

## Foundational Learning

- Concept: Diffusion models and denoising score matching
  - Why needed here: The method builds on diffusion models' ability to generate images through iterative denoising, and understanding score matching is crucial for implementing the SDS guidance.
  - Quick check question: What is the role of the noise prediction network in the denoising process, and how does it relate to score matching?

- Concept: Low-Rank Adaptation (LoRA) for efficient fine-tuning
  - Why needed here: The method uses LoRA to update only a subset of weights for personalization, making it computationally efficient while preserving most of the pre-trained model's knowledge.
  - Quick check question: How does LoRA differ from full fine-tuning, and why is it particularly suitable for personalization with limited training data?

- Concept: Classifier-free guidance in diffusion models
  - Why needed here: The method uses classifier-free guidance to extrapolate between conditional and unconditional predictions for the SDS guidance term.
  - Quick check question: How does classifier-free guidance work, and what is the effect of the guidance scale parameter on the generated images?

## Architecture Onboarding

- Component map: Pre-trained text-to-image model -> LoRA adapter -> New word embedding -> Personalization loss + Prompt-alignment loss -> Guidance scale parameters

- Critical path: Initialize LoRA weights and new embedding -> Sample noise and apply forward diffusion to create xt -> Compute personalization loss using LoRA-adapted model -> Compute prompt-alignment loss using pre-trained model -> Combine losses and update LoRA weights and embedding -> Generate images using the personalized model with target prompt

- Design tradeoffs: Balancing personalization and prompt-alignment objectives, choosing guidance scales (α and β) for optimal results, deciding between same noise vs. independent noise for branches, selecting the number of fine-tuning steps to prevent overfitting

- Failure signatures: Overfitting (generated images closely resemble training images but ignore prompt elements), underfitting (poor subject representation and weak prompt alignment), mode collapse (limited diversity in generated images, repetitive patterns), unstable training (NaN losses or exploding gradients during fine-tuning)

- First 3 experiments: Ablation study comparing same noise vs. independent noise for branches using a simple prompt, guidance scale sweep testing different α and β values to find optimal balance, early stopping analysis measuring performance vs. number of fine-tuning steps to determine optimal training duration

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed method perform when scaling to larger text-to-image models with improved text-encoders and bigger capacity? The paper mentions validation with larger models but provides limited details on performance comparisons.

### Open Question 2
What is the impact of using different noise sampling strategies (same noise vs. different noise) on the performance of the proposed method? While the paper notes that same noise helps with prompt alignment, it doesn't provide a detailed analysis of why this occurs.

### Open Question 3
How does the proposed method handle more complex and intricate prompts that involve multiple subjects, styles, and elements? The paper demonstrates the method on some complex prompts but doesn't explore the limits of handling highly intricate instructions.

## Limitations

- Performance on highly complex prompts with many elements remains unclear, as user studies only evaluated relatively simple prompts
- Computational efficiency claims lack absolute training time metrics, making real-world deployment costs difficult to assess
- User study methodology may be subjective and could vary across different user groups or cultural contexts

## Confidence

**High Confidence**: The claim that PALP outperforms baselines in user preference studies is well-supported by quantitative metrics (91.2% preference for prompt alignment, 72.1% similarity ratings) and controlled experiments with 12 subjects.

**Medium Confidence**: The mechanism by which DDS prevents mode collapse and improves diversity is theoretically sound but lacks direct empirical evidence comparing diversity metrics across different guidance strategies.

**Medium Confidence**: The claim that PALP enables multi-subject personalization with a single reference image is demonstrated but relies heavily on the specific implementation details of the subject-identity preservation technique.

## Next Checks

1. **Diversity Analysis**: Measure the diversity of generated samples across multiple seeds for both PALP and baseline methods using established metrics like LPIPS or perceptual path length to validate the claim that DDS prevents mode collapse.

2. **Prompt Complexity Scaling**: Test PALP on prompts with increasing complexity (5+ elements) to determine if the performance advantage holds for more complex instructions, representing a critical real-world use case.

3. **Cross-Dataset Generalization**: Evaluate PALP's performance on different subject categories (animals, objects, abstract concepts) beyond human subjects to assess whether the method's advantages generalize across diverse personalization scenarios.