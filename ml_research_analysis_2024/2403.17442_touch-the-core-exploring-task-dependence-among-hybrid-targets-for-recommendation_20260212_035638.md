---
ver: rpa2
title: 'Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation'
arxiv_id: '2403.17442'
source_url: https://arxiv.org/abs/2403.17442
tags:
- task
- htlnet
- tasks
- targets
- core
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of multi-task learning with hybrid
  targets in recommendation systems, where discrete auxiliary tasks and a core continuous
  task need to be jointly optimized. The authors propose the Hybrid Targets Learning
  Network (HTLNet), which introduces label embedding units to explicitly transfer
  label information between tasks and information fusion units to adaptively aggregate
  task representations.
---

# Touch the Core: Exploring Task Dependence Among Hybrid Targets for Recommendation

## Quick Facts
- arXiv ID: 2403.17442
- Source URL: https://arxiv.org/abs/2403.17442
- Reference count: 40
- Primary result: HTLNet achieves state-of-the-art performance on multi-task learning with hybrid targets in recommendation systems, outperforming baselines on two public datasets and one industrial dataset

## Executive Summary
This paper addresses the challenge of multi-task learning with hybrid targets in recommendation systems, where discrete auxiliary tasks must be jointly optimized with a core continuous task. The authors propose HTLNet, which introduces label embedding units to explicitly transfer label information between tasks and information fusion units to adaptively aggregate task representations. To address optimization challenges caused by gradient conflicts between regression and classification tasks, they design a gradient adjustment strategy that aligns gradient directions and balances magnitudes. Experiments demonstrate that HTLNet consistently outperforms state-of-the-art multi-task learning baselines across all tasks, with significant improvements validated through online A/B tests.

## Method Summary
HTLNet introduces label embedding units (LEU) for each classification task to explicitly transfer label information to the core continuous task, using Gumbel-softmax for differentiable sampling. Information fusion units (IFU) employ attention mechanisms to adaptively aggregate information from preceding tasks. The gradient adjustment strategy resolves conflicts between regression and classification tasks through direction alignment (projection onto normal plane) and magnitude balancing (adaptive scaling). The model is evaluated on KuaiRand, Kaggle-Revenue, and an industrial fund recommendation dataset using metrics including AUC, LogLoss, NRMSE, NMAE, Spearman, and Gini.

## Key Results
- HTLNet outperforms state-of-the-art multi-task learning baselines across all tasks on KuaiRand, Kaggle-Revenue, and industrial datasets
- Online A/B tests validate HTLNet's effectiveness with significant improvements in click-through rate, conversion rate, and purchase amount
- Gradient adjustment strategy successfully resolves optimization challenges between regression and classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Label embedding units enable explicit transfer of discrete task information to the core continuous task, overcoming limitations of implicit task relationships in standard MTL
- Mechanism: Two-row embedding tables map discrete labels (0/1) to learnable dense vectors, with Gumbel-softmax enabling differentiable sampling for soft weighting
- Core assumption: Label embedding table can effectively capture and transfer label information from discrete tasks to benefit core continuous task
- Evidence anchors: Abstract states label embedding "explicitly transfer the label information among these tasks"; Section 4.1.1 describes Gumbel-softmax implementation
- Break condition: If label embedding fails to capture meaningful information or Gumbel-softmax becomes too deterministic, transfer becomes ineffective or noisy

### Mechanism 2
- Claim: Information fusion units adaptively aggregate information from preceding tasks using attention mechanisms, ensuring relevant information transfer while avoiding negative transfer
- Mechanism: IFU uses attention to assign adaptive weights to information from all preceding tasks, allowing selective fusion based on task relevance
- Core assumption: Attention-based fusion can effectively distinguish useful from irrelevant information across tasks
- Evidence anchors: Abstract mentions IFU design; Section 4.1.2 describes attention mechanism for adaptive weighting
- Break condition: If attention fails to learn meaningful weights due to vanishing gradients or poor initialization, it cannot effectively filter relevant information

### Mechanism 3
- Claim: Gradient adjustment strategy resolves conflicts between regression and classification tasks by aligning gradient directions and balancing magnitudes
- Mechanism: Two operations applied: (1) gradient direction conflict resolution using projection onto normal plane of core task gradient, (2) gradient magnitude balancing using adaptive scaling based on gradient norm ratios
- Core assumption: Gradient magnitudes and directions from regression and classification tasks can be meaningfully aligned to stabilize training
- Evidence anchors: Abstract states gradient adjustment "aligns gradient directions and balances magnitudes"; Section 4.2 describes both conflict resolution and magnitude balancing
- Break condition: If gradient adjustment hyperparameters are poorly tuned, optimization may become unstable or converge to suboptimal solutions

## Foundational Learning

- Concept: Multi-task learning (MTL) with hybrid targets
  - Why needed here: Jointly optimizing regression and classification tasks in recommendation systems, not well-handled by standard MTL approaches
  - Quick check question: Can you explain the difference between implicit and explicit task dependence in MTL?

- Concept: Gradient conflict resolution in multi-task learning
  - Why needed here: Identifies gradient conflicts between regression and classification tasks as major optimization challenge requiring specialized strategy
  - Quick check question: How does gradient projection operation resolve direction conflicts between tasks?

- Concept: Gumbel-softmax reparameterization trick
  - Why needed here: Enables differentiable sampling of labels for label embedding, avoiding non-differentiability of hard sampling operations
  - Quick check question: What is role of temperature parameter τ in Gumbel-softmax, and how does it affect sampling process?

## Architecture Onboarding

- Component map: Input features -> Shared Embedding Layer -> Task Towers (with LEU and IFU) -> Predictions -> Losses -> Gradient Adjustment -> Parameter Updates

- Critical path: Features processed through shared embeddings, routed to task-specific towers with label embedding and information fusion, generating predictions and losses, with gradient adjustment applied before parameter updates

- Design tradeoffs:
  - LEU vs. direct label usage: LEU avoids training-test discrepancy but introduces additional parameters
  - Attention vs. concatenation in IFU: Attention allows adaptive fusion but is more computationally expensive
  - Gradient adjustment vs. no adjustment: Adjustment stabilizes training but requires careful hyperparameter tuning

- Failure signatures:
  - Poor performance on core target: Likely due to ineffective label embedding or information fusion
  - Unstable training: May indicate gradient conflicts not properly resolved
  - Negative transfer: Could suggest attention mechanism not learning meaningful weights

- First 3 experiments:
  1. Compare HTLNet with and without LEU to assess impact of label embedding on performance
  2. Replace attention in IFU with concatenation to evaluate importance of adaptive information fusion
  3. Disable gradient adjustment strategy to observe effect on training stability and convergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does HTLNet perform when the core target is discrete rather than continuous?
- Basis in paper: [inferred] Paper states HTLNet "posits the hypothesis that the objective of the final core target is to be continuous while those of all the preceding tasks are to be discrete" and mentions interest in generalizing to other cases
- Why unresolved: Paper only evaluates HTLNet on datasets where core target is continuous
- What evidence would resolve it: Experiments comparing HTLNet to baselines on datasets with discrete core target, measuring same metrics

### Open Question 2
- Question: What is optimal architecture for transferring information between tasks when there are more than three sequential tasks?
- Basis in paper: [explicit] Paper assumes "user T conversion steps to complete core targets" and uses T=3 in experiments, but doesn't explore performance with different task numbers
- Why unresolved: Paper only evaluates HTLNet with three sequential tasks, leaving scalability unexplored
- What evidence would resolve it: Experiments testing HTLNet with varying task numbers (2, 4, 5) on datasets with different task hierarchies, comparing performance metrics

### Open Question 3
- Question: How does HTLNet's performance compare to specialized single-task models on core continuous target when computational resources not constrained?
- Basis in paper: [inferred] Paper focuses on multi-task learning benefits and shows HTLNet outperforms other MTL models, but doesn't compare to state-of-the-art single-task models
- Why unresolved: Paper's ablation studies only compare HTLNet variants and other MTL approaches
- What evidence would resolve it: Head-to-head comparisons between HTLNet and single-task models on core continuous target only, measuring NRMSE/NMAE metrics

## Limitations

- Evaluation scope limited to three datasets (two public, one industrial) in recommendation domains, unclear whether approach generalizes beyond this context
- Gradient adjustment strategy introduces multiple hyperparameters requiring careful tuning, with no guidance on selection or sensitivity analysis
- Effectiveness of label embedding relies primarily on comparative performance rather than ablation studies demonstrating specific contribution

## Confidence

**High Confidence**: 
- Core architecture design is technically sound and follows established deep learning principles
- Identification of gradient conflicts as real optimization challenge is well-founded

**Medium Confidence**:
- Effectiveness of specific gradient adjustment strategy in resolving conflicts and improving convergence
- Claim that explicit label embedding is superior to implicit information sharing in standard MTL frameworks
- Assertion that proposed approach significantly outperforms state-of-the-art baselines

**Low Confidence**:
- Generalizability of results across diverse recommendation domains and data distributions
- Robustness of approach to hyperparameter variations and different initialization schemes

## Next Checks

1. **Ablation Study on Label Embedding**: Implement HTLNet without label embedding units (using direct label values) and compare performance across all three datasets to quantify specific contribution of label embeddings

2. **Gradient Adjustment Sensitivity Analysis**: Systematically vary hyperparameters α and γ across wide range of values, plotting training curves and final performance metrics to identify optimal ranges and assess robustness

3. **Cross-Domain Generalization Test**: Apply HTLNet to non-recommendation domain (e.g., healthcare prediction with mixed regression and classification targets) to evaluate effectiveness beyond recommendation contexts tested in paper