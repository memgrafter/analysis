---
ver: rpa2
title: Towards Enabling FAIR Dataspaces Using Large Language Models
arxiv_id: '2403.15451'
source_url: https://arxiv.org/abs/2403.15451
tags:
- dataspaces
- data
- llms
- odrl
- gndo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores the use of Large Language Models (LLMs) to support
  the adoption of FAIR dataspaces by assisting with tasks like creating and understanding
  semantic metadata schemas and generating FAIR data instances. Using GPT-4 as a proof-of-concept,
  the authors demonstrate how LLMs can aid in extending SHACL shapes for cultural
  data, creating dataset instances, and generating ODRL usage policies.
---

# Towards Enabling FAIR Dataspaces Using Large Language Models

## Quick Facts
- arXiv ID: 2403.15451
- Source URL: https://arxiv.org/abs/2403.15451
- Reference count: 17
- Primary result: LLMs can assist with FAIR dataspace tasks like extending SHACL shapes and generating RDF instances, though accuracy and provenance issues remain.

## Executive Summary
This paper explores using Large Language Models (LLMs) to support the adoption of FAIR (Findable, Accessible, Interoperable, Reusable) dataspaces by assisting with tasks like creating and understanding semantic metadata schemas and generating FAIR data instances. Using GPT-4 as a proof-of-concept, the authors demonstrate how LLMs can aid in extending SHACL shapes for cultural data, creating dataset instances, and generating ODRL usage policies. The results show that LLMs can successfully perform these tasks, though some issues with precision and provenance remain. The paper proposes a research agenda to investigate open models, integration with Knowledge Graphs, safety considerations, and user acceptance to make LLMs more reliable and practical for FAIR dataspace adoption.

## Method Summary
The authors use GPT-4 to demonstrate three key tasks: extending SHACL shapes with domain-specific properties (using GND ontology for cultural heritage data), generating RDF dataset instances based on these shapes, and creating ODRL usage policies. The approach leverages function calling to retrieve external information (like GND IDs) and prompt engineering to guide the LLM. The evaluation focuses on a single painting dataset ("Der Wanderer Ã¼ber dem Nebelmeer" by Caspar David Friedrich) as a proof-of-concept, demonstrating the feasibility of using LLMs for FAIR dataspace tasks without providing comprehensive quantitative evaluation.

## Key Results
- GPT-4 successfully extended SHACL shapes with GND properties for cultural heritage data
- LLM generated valid RDF instances including retrieving artist GND IDs via function calling
- ODRL usage policies were created that conform to specified constraints and associations
- Some precision and provenance issues were identified, requiring further investigation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can assist in creating and extending semantic metadata schemas for FAIR dataspaces by leveraging domain knowledge provided in prompts.
- Mechanism: The LLM processes the domain-specific metadata standards and ontology properties provided in the prompt to generate valid SHACL shapes that extend existing schemas without breaking consistency.
- Core assumption: The LLM has sufficient knowledge of the relevant ontologies (e.g., GND) and can correctly interpret domain-specific metadata requirements.
- Evidence anchors:
  - [abstract] "The authors demonstrate how LLMs can aid in extending SHACL shapes for cultural data"
  - [section] "The painter with their identifier and the date of production have been correctly added"
- Break condition: The LLM lacks knowledge of the relevant ontologies or cannot correctly interpret domain-specific metadata requirements, leading to incorrect or incomplete schema extensions.

### Mechanism 2
- Claim: LLMs can generate FAIR data instances based on SHACL shapes and retrieve necessary information from external knowledge sources.
- Mechanism: Using function calling, the LLM can invoke external functions to retrieve information (e.g., GND IDs) and then generate valid RDF instances that conform to the provided schema.
- Core assumption: The LLM can correctly parse the schema, identify missing information, invoke the appropriate functions, and generate valid instances.
- Evidence anchors:
  - [abstract] "creating dataset instances"
  - [section] "the instance in listing 4 is generated, alongside a description of how GPT-4 resolved prompt ambiguities"
- Break condition: The LLM fails to correctly parse the schema, cannot identify the appropriate functions to invoke, or generates invalid instances that do not conform to the schema.

### Mechanism 3
- Claim: LLMs can generate ODRL usage policies that conform to specified constraints and are associated with the generated data instances.
- Mechanism: The LLM uses the provided instance and policy requirements to generate an ODRL policy with the correct permissions, constraints, and associations.
- Core assumption: The LLM understands the ODRL ontology and can correctly generate policies that conform to the specified constraints and associations.
- Evidence anchors:
  - [abstract] "generating ODRL usage policies"
  - [section] "We generate the usage policy based on the Open Digital Rights Language (ODRL)"
- Break condition: The LLM does not understand the ODRL ontology or cannot correctly generate policies that conform to the specified constraints and associations.

## Foundational Learning

- Concept: Semantic Web technologies (RDF, SHACL, ontologies)
  - Why needed here: The paper focuses on using LLMs to assist with tasks related to FAIR dataspaces, which heavily rely on Semantic Web technologies.
  - Quick check question: What is the purpose of SHACL in the context of FAIR dataspaces?

- Concept: Large Language Models (LLMs) and their capabilities
  - Why needed here: The paper explores the use of LLMs to support the adoption of FAIR dataspaces by assisting with various tasks.
  - Quick check question: What are the key capabilities of LLMs that make them suitable for assisting with FAIR dataspace tasks?

- Concept: FAIR Data Principles
  - Why needed here: The paper aims to support the adoption of FAIR dataspaces, which are based on the FAIR Data Principles.
  - Quick check question: What are the four main principles of FAIR data?

## Architecture Onboarding

- Component map: LLM (e.g., GPT-4) -> SHACL shapes (metadata schema) -> RDF instances (data) -> ODRL policies (usage rights) -> External knowledge sources (e.g., GND) -> Function calling mechanism

- Critical path:
  1. Extend SHACL shapes based on domain knowledge
  2. Generate RDF instances based on extended shapes
  3. Retrieve necessary information from external sources
  4. Generate ODRL policies based on instance and constraints
  5. Associate policies with instances

- Design tradeoffs:
  - Using proprietary vs. open LLMs (cost, data sovereignty, performance)
  - Interactive vs. automated LLM-based systems
  - Prompt engineering vs. fine-tuning for model adaptation
  - Integrating LLMs with KGs for knowledge and correctness vs. standalone LLM usage

- Failure signatures:
  - Incorrect or incomplete schema extensions
  - Invalid RDF instances that do not conform to the schema
  - ODRL policies that do not conform to specified constraints or associations
  - Hallucinations or errors in LLM-generated content

- First 3 experiments:
  1. Test LLM's ability to extend SHACL shapes based on domain knowledge
  2. Test LLM's ability to generate valid RDF instances based on extended shapes
  3. Test LLM's ability to generate ODRL policies based on instance and constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can synergies between dataspace participants be used to fine-tune LLMs effectively?
- Basis in paper: [explicit] The authors propose investigating how synergies between dataspace participants can be used to fine-tune models.
- Why unresolved: The paper does not provide a concrete methodology for leveraging these synergies.
- What evidence would resolve it: A study demonstrating collaborative fine-tuning approaches among dataspace participants, showing improved model performance and cost-effectiveness.

### Open Question 2
- Question: What is a reasonable tradeoff between model size, fine-tuning effort, model performance, and safety for specific dataspace applications?
- Basis in paper: [explicit] The authors propose investigating the tradeoff between model size, fine-tuning effort, model performance, and safety.
- Why unresolved: The paper does not provide specific guidelines or metrics for evaluating these tradeoffs.
- What evidence would resolve it: A comprehensive analysis of various LLM configurations, their performance, costs, and safety implications in dataspace applications.

### Open Question 3
- Question: How can dataspace participants be empowered to perform LLM inference on the edge with equal or less cost compared to hosted APIs?
- Basis in paper: [explicit] The authors propose investigating how dataspace participants can be empowered to perform inference on the edge with equal or less cost compared to hosted OpenAI APIs.
- Why unresolved: The paper does not provide a concrete solution for edge inference or cost comparison.
- What evidence would resolve it: A study comparing edge inference costs and performance with hosted APIs, along with practical implementations of edge LLM deployment for dataspace applications.

## Limitations

- Limited scope of evaluation with only a single painting dataset used as proof-of-concept
- Reliance on proprietary GPT-4 model raises cost and data sovereignty concerns
- Lack of quantitative evaluation metrics for accuracy and consistency of generated outputs
- No concrete mechanisms for addressing provenance and explainability of LLM-generated content

## Confidence

**High confidence**: LLMs can assist with extending SHACL shapes and generating RDF instances based on provided schemas and domain knowledge. The mechanism is well-demonstrated and technically sound.

**Medium confidence**: LLMs can generate ODRL usage policies that conform to specified constraints. While the approach is valid, the correctness of generated policies requires more rigorous validation.

**Low confidence**: LLMs can reliably support FAIR dataspace adoption at scale. The current work is a proof-of-concept that doesn't address scalability, user acceptance, or integration challenges.

## Next Checks

1. **Cross-domain validation**: Test the LLM approach on at least three diverse datasets (e.g., cultural heritage, scientific data, healthcare) to assess generalizability and identify domain-specific challenges.

2. **Open model comparison**: Replicate the key tasks using open LLMs (e.g., LLaMA, Mistral) with and without fine-tuning to evaluate performance differences and identify when proprietary models are truly necessary.

3. **Quantitative accuracy assessment**: Develop a systematic evaluation framework that measures precision, recall, and consistency of LLM-generated SHACL shapes, RDF instances, and ODRL policies against ground truth schemas and ontologies.