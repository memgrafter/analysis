---
ver: rpa2
title: 'Explainable Artificial Intelligence and Multicollinearity : A Mini Review
  of Current Approaches'
arxiv_id: '2406.11524'
source_url: https://arxiv.org/abs/2406.11524
tags:
- features
- feature
- multicollinearity
- shap
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reviews current approaches to handling multicollinearity
  in explainable artificial intelligence (XAI) methods. It searched three repositories
  (Web of Science, Scopus, IEEE Xplore) and identified seven relevant papers that
  address the multicollinearity issue in XAI.
---

# Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches

## Quick Facts
- arXiv ID: 2406.11524
- Source URL: https://arxiv.org/abs/2406.11524
- Reference count: 24
- This paper reviews current approaches to handling multicollinearity in explainable artificial intelligence (XAI) methods.

## Executive Summary
This paper reviews current approaches to handling multicollinearity in explainable artificial intelligence (XAI) methods. It searched three repositories (Web of Science, Scopus, IEEE Xplore) and identified seven relevant papers that address the multicollinearity issue in XAI. The paper discusses common XAI methods (SHAP, LIME, PDP, ALE, Anchor) and their limitations in dealing with multicollinearity. It then reviews seven proposed methods to handle this issue, including Modified Index Position, Extended Kernel SHAP, Normalized Movement Rate, SHAP Cohort Refinement, Multi-Collinearity Corrected, Conditional Subgroups, and Conditional Inference Trees. These methods aim to either modify existing XAI approaches or provide post-hoc corrections to account for feature dependencies. The review highlights the need for more research on sampling methods with XAI in the presence of multicollinearity and suggests developing new visualization techniques that better reflect feature interactions.

## Method Summary
The paper conducted a literature review by searching three repositories (Web of Science, Scopus, IEEE Xplore) for papers addressing multicollinearity in XAI methods. After applying inclusion and exclusion criteria, seven papers were identified that propose various approaches to handle this issue. The methods were categorized and analyzed based on their approaches to dealing with feature dependencies in XAI explanations. The review synthesized findings and identified gaps in current research, particularly around sampling methods and visualization techniques.

## Key Results
- Identified seven papers that address multicollinearity in XAI methods
- Reviewed approaches include Modified Index Position, Extended Kernel SHAP, Normalized Movement Rate, and several SHAP-based modifications
- Highlighted the need for more research on sampling methods and visualization techniques that account for feature interactions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SHAP's original formulation assumes feature independence, which causes unreliable importance scores when features are collinear.
- Mechanism: SHAP calculates Shapley values using marginal distributions instead of conditional distributions, leading to incorrect attribution when features are dependent.
- Core assumption: Features in the model are independent of each other.
- Evidence anchors:
  - [abstract] "Multicollinearity is one of the big issue that should be considered when XAI generates the explanation in terms of the most informative features in an AI system."
  - [section] "In the original version of SHAP, it assumes that the features are independent when it calculates a score of each feature."
  - [corpus] Weak evidence - corpus doesn't directly address SHAP's independence assumption, but mentions related work on explainable AI methods.
- Break condition: When features are highly correlated and SHAP assigns importance to only one feature from a collinear group, missing the combined effect.

### Mechanism 2
- Claim: Extended Kernel SHAP replaces marginal distributions with conditional distributions to handle multicollinearity.
- Mechanism: Uses alternative distributions (Gaussian copula, Gaussian, empirical) to estimate conditional probabilities instead of assuming independence.
- Core assumption: The conditional distribution can be accurately estimated using the proposed approaches.
- Evidence anchors:
  - [section] "Extended Kernel SHAP proposed four approaches to estimate the conditional distribution instead of replacing it with the marginal distribution."
  - [corpus] Weak evidence - corpus doesn't directly address Extended Kernel SHAP, but mentions work on explainable AI for dependent features.
- Break condition: When high-dimensional data makes accurate conditional distribution estimation computationally infeasible or inaccurate.

### Mechanism 3
- Claim: Modified Index Position (MIP) iteratively removes top features to identify truly significant features in presence of collinearity.
- Mechanism: Retrains model and re-applies XAI after removing top feature; tracks which features consistently rise to top position.
- Core assumption: If two features are collinear and correlated with outcome, removing one will cause the other to become top-ranked.
- Evidence anchors:
  - [section] "MIP modifies the outcomes of XAI to consider the multicollinearity. It removes iteratively the top feature from the list, retrain the model, apply XAI and generates the list of significant features again."
  - [corpus] Weak evidence - corpus doesn't directly address MIP method, but mentions related work on explainable AI methods.
- Break condition: When feature interactions are too complex for simple iterative removal to capture, or when computational cost becomes prohibitive.

## Foundational Learning

- Concept: Multicollinearity
  - Why needed here: Understanding how correlated features affect XAI interpretation is central to this review.
  - Quick check question: What happens to coefficient interpretation in linear regression when two predictors are highly correlated?

- Concept: Shapley values
  - Why needed here: SHAP method is a primary focus of this review and understanding its mechanics is crucial.
  - Quick check question: How does the assumption of feature independence affect Shapley value calculations?

- Concept: Model-agnostic vs. model-specific XAI methods
  - Why needed here: The review distinguishes between methods that work with any model versus those tied to specific algorithms.
  - Quick check question: What are the tradeoffs between using model-agnostic versus model-specific explanation methods?

## Architecture Onboarding

- Component map:
  - Literature search and filtering pipeline
  - XAI method categorization system
  - Multicollinearity handling method classification
  - Implementation availability tracker
  - Evaluation criteria framework

- Critical path:
  1. Define search criteria and repositories
  2. Execute search and collect papers
  3. Filter papers based on relevance criteria
  4. Categorize remaining papers by method type
  5. Analyze methods' approaches to multicollinearity
  6. Document findings and suggest future directions

- Design tradeoffs:
  - Breadth vs. depth of literature coverage
  - Focus on specific XAI methods vs. general approaches
  - Inclusion of theoretical vs. practical implementations
  - Balance between local and global explanation methods

- Failure signatures:
  - Incomplete literature coverage leading to missing key methods
  - Misclassification of methods due to unclear documentation
  - Overlooking important implementation details
  - Failing to identify connections between seemingly different approaches

- First 3 experiments:
  1. Implement MIP method on a simple dataset with known collinear features to verify its iterative feature removal logic.
  2. Compare SHAP and Extended Kernel SHAP outputs on a dataset with clear feature dependencies to demonstrate the impact of using conditional vs. marginal distributions.
  3. Apply NMR stability metric across multiple models on the same dataset to evaluate its effectiveness in identifying stable explanations under multicollinearity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective sampling methods for XAI in the presence of multicollinearity, particularly for high-dimensional datasets?
- Basis in paper: [explicit] The paper explicitly states "more research is required on sampling methods with XAI and presence of multicollinearity" and mentions that "methods based on the conditional distribution depends highly on the efficiency of the conditional sampler which is challenging in high dimension."
- Why unresolved: Current XAI methods either make unrealistic independence assumptions or rely on conditional distributions that are difficult to estimate efficiently in high-dimensional spaces.
- What evidence would resolve it: Comparative studies of different sampling methods (e.g., conditional probability, Bayesian models) applied to high-dimensional datasets with known multicollinearity, demonstrating their effectiveness in producing reliable feature importance scores.

### Open Question 2
- Question: How can visualization techniques be developed to better reflect feature interactions and multicollinearity in XAI explanations?
- Basis in paper: [explicit] The paper states "current plots of XAI to explain the models either locally or globally are misleading because they do not reflect the complexity interaction between the features" and suggests "new plots are required to embed and reflect the interaction between the features and their effect on the outcome."
- Why unresolved: Existing visualization methods like PDP and ALE assume feature independence, which is rarely the case in real-world applications, especially in domains like healthcare and biology.
- What evidence would resolve it: Development and validation of new visualization techniques that accurately represent feature interactions and dependencies, with user studies demonstrating improved interpretability compared to current methods.

### Open Question 3
- Question: How can SHAP scores be modified to account for multicollinearity when dealing with mixed feature types (continuous, discrete, ordinal, and categorical)?
- Basis in paper: [explicit] The paper discusses methods like Extended Kernel SHAP and Conditional Inference Trees that attempt to address multicollinearity in SHAP, but notes limitations in handling mixed feature types.
- Why unresolved: Current methods either focus on specific feature types or are computationally expensive, making them impractical for real-world applications with diverse feature types.
- What evidence would resolve it: A comprehensive study comparing the performance of different SHAP modification techniques across datasets with mixed feature types, evaluating their ability to accurately capture feature importance while accounting for multicollinearity.

## Limitations

- Limited number of identified papers (n=7) suggests either the problem is under-researched or search methodology missed relevant work
- Focus on post-hoc correction methods rather than fundamentally redesigning XAI algorithms to handle feature dependencies
- Limited empirical validation of proposed solutions, with most methods remaining theoretical or having limited implementation details

## Confidence

- Confidence is Medium for the claim that multicollinearity significantly impacts XAI interpretation, as this is well-established in statistics but specific impacts on modern XAI methods need more empirical validation
- Confidence is Low-Medium for the proposed solutions, as most are theoretical or have limited implementation details available

## Next Checks

1. Implement and test at least two of the reviewed methods (e.g., MIP and Extended Kernel SHAP) on benchmark datasets with known multicollinearity to empirically evaluate their effectiveness.

2. Conduct a broader literature search using alternative keywords and databases to verify completeness of the current review and identify any missed approaches.

3. Develop a standardized evaluation framework to compare different multicollinearity-handling methods across multiple metrics (computational cost, interpretability preservation, accuracy of feature importance).