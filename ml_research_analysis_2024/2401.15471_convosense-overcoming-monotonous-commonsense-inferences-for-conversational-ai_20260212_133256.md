---
ver: rpa2
title: 'ConvoSense: Overcoming Monotonous Commonsense Inferences for Conversational
  AI'
arxiv_id: '2401.15471'
source_url: https://arxiv.org/abs/2401.15471
tags:
- inferences
- dialogue
- commonsense
- inference
- speaker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses limitations in existing dialogue commonsense
  inference datasets by constructing a new synthetic dataset called ConvoSense using
  GPT. The key innovation is generating inferences that are more detailed, novel,
  and diverse compared to existing datasets.
---

# ConvoSense: Overcoming Monotonous Commonsense Inferences for Conversational AI

## Quick Facts
- arXiv ID: 2401.15471
- Source URL: https://arxiv.org/abs/2401.15471
- Authors: Sarah E. Finch; Jinho D. Choi
- Reference count: 17
- Primary result: ConvoSense enables models to generate higher quality, more novel, and more detailed commonsense inferences for dialogue contexts compared to existing datasets

## Executive Summary
This paper addresses the limitations of existing dialogue commonsense inference datasets by constructing ConvoSense, a large-scale synthetic dataset generated using GPT. The dataset contains over 500,000 inferences across 12,000 dialogues covering 10 popular inference types. The authors demonstrate that models trained on ConvoSense produce significantly more plausible, detailed, and novel inferences compared to models trained on existing datasets. The work also explores different training and decoding strategies, finding that diverse beam search on single-output models performs best for generating diverse commonsense inferences.

## Method Summary
The authors construct ConvoSense by using GPT to generate commonsense inferences for dialogue contexts selected from the SODA dataset. They employ BERTopic clustering to ensure topical diversity and carefully engineered prompts to elicit novel and detailed inferences. T5-3B models are then trained on the generated data using monomorphic, monomorphic diverse, and polymorphic strategies. The evaluation includes automatic metrics (BLEU, BERTScore, sentence similarity) combined with human assessment of reasonability and novelty, using a novel PolyAgg aggregation method for multi-inference examples.

## Key Results
- ConvoSense contains over 500,000 inferences across 12,000 dialogues with 10 inference types
- Models trained on ConvoSense achieve 93% reasonability and 98% novelty on human evaluation
- Diverse beam search decoding with Hamming distance reward outperforms other decoding strategies for generating diverse inferences
- ConvoSense models generate inferences with greater detail and novelty compared to models trained on existing datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT can generate high-quality, novel, and detailed commonsense inferences for dialogue contexts that surpass human-generated inferences in novelty and detail
- Mechanism: GPT's zero-shot generation framework with carefully engineered prompts that explicitly instruct the model to provide novel information not present in the conversation context, combined with its large-scale pretraining on diverse web data
- Core assumption: GPT has learned sufficient world knowledge and reasoning capabilities during pretraining to generate plausible commonsense inferences without task-specific fine-tuning
- Evidence anchors: [abstract]: "GPT...boasts greater contextual novelty, offers a higher volume of inferences per example, and substantially enriches the detail conveyed by the inferences"; [section]: "GPT outputs achieve higher detail than that observed from human-generated inferences...GPT surpasses the novelty of the human-generated inferences for the majority of the existing datasets"
- Break condition: If GPT's training data lacks sufficient coverage of certain commonsense domains, or if the zero-shot approach fails to capture nuanced dialogue contexts, the generated inferences may become implausible or repetitive

### Mechanism 2
- Claim: Training generative commonsense models on ConvoSense enables superior performance in producing plausible inferences with greater detail and novelty compared to models trained on existing datasets
- Mechanism: ConvoSense provides a large-scale dataset with diverse, novel inferences across multiple dialogue contexts and inference types, allowing models to learn rich representations of dialogue commonsense
- Core assumption: The diversity and quality of inferences in ConvoSense are sufficient to train models that can generalize to produce high-quality inferences on unseen dialogue contexts
- Evidence anchors: [abstract]: "Our dataset contains over 500,000 inferences across 12,000 dialogues with 10 popular inference types, which empowers the training of generative commonsense models for dialogue that are superior in producing plausible inferences with high novelty"; [section]: "models trained on ConvoSense excel in generating plausible inferences with greater detail and novelty, compared to ones trained on existing datasets"
- Break condition: If ConvoSense's coverage is too narrow or if the training process overfits to specific dialogue patterns, the trained models may fail to generalize to diverse real-world dialogue scenarios

### Mechanism 3
- Claim: Using diverse beam search decoding on single-output models outperforms direct generation of multiple inferences for producing diverse commonsense inferences
- Mechanism: Diverse beam search with Hamming distance reward explicitly encourages the model to generate outputs that are semantically distinct from each other, leading to more diverse inferences
- Core assumption: The model's ability to generate diverse inferences is primarily constrained by the decoding strategy rather than the model architecture itself
- Evidence anchors