---
ver: rpa2
title: Learning to Compress Prompt in Natural Language Formats
arxiv_id: '2402.18700'
source_url: https://arxiv.org/abs/2402.18700
tags:
- prompt
- prompts
- capsule
- nano-capsulator
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work aims to compress lengthy prompts in natural language
  formats while maintaining utility and transferability across different large language
  models (LLMs). To address this, we propose the Nano-Capsulator framework, which
  encapsulates long prompts into shorter, natural language-formatted Capsule Prompts.
---

# Learning to Compress Prompt in Natural Language Formats

## Quick Facts
- arXiv ID: 2402.18700
- Source URL: https://arxiv.org/abs/2402.18700
- Reference count: 6
- Primary result: Reduces prompt length by 81.4% while maintaining transferability across LLMs

## Executive Summary
This work introduces Nano-Capsulator, a framework for compressing lengthy prompts in natural language formats while preserving utility and ensuring transferability across different large language models. The framework employs a semantics-preserving summarization approach combined with a reward function that optimizes compression rate while maintaining prompt effectiveness. Experimental results demonstrate significant compression rates (81.4% reduction) and performance improvements (4.5x latency reduction, 80.1% budget savings) across multiple LLMs and datasets.

## Method Summary
Nano-Capsulator compresses long prompts into shorter NL-formatted Capsule Prompts using a two-component approach: NL-formatted prompt compression and prompt utility preservation. The framework optimizes a reward function featuring length constraints while maintaining semantic similarity through a semantics-preserving loss. Training uses a frozen LLM for reward calculation without task-specific supervision, enabling generalizability. The model is trained on few-shot CoT datasets and reading comprehension datasets using Adam optimizer with specific hyperparameters, then evaluated across multiple LLMs for transferability.

## Key Results
- Reduces original prompt length by 81.4%
- Decreases inference latency up to 4.5x
- Saves 80.1% of budget overheads
- Maintains transferability across diverse LLMs and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantics-preserving summarization maintains prompt utility during compression
- Mechanism: Uses a reward function with semantics-preserving loss measuring similarity between hidden state embeddings
- Core assumption: Semantic similarity in hidden states accurately reflects utility preservation
- Evidence anchors: [abstract], [section] - mentions semantics preserving loss and hidden state similarity
- Break condition: If semantic similarity doesn't correlate with actual prompt utility

### Mechanism 2
- Claim: Length constraint rewards enable effective compression while maintaining transferability
- Mechanism: Optimizes reward function featuring length constraints penalizing prompts exceeding threshold
- Core assumption: Length constraints guide compression without sacrificing transferability
- Evidence anchors: [abstract], [section] - describes reward function with length constraints
- Break condition: If constraints are too strict, forcing excessive information loss

### Mechanism 3
- Claim: Unsupervised training enables transferability across different LLMs and datasets
- Mechanism: Trains without supervision using frozen LLM for reward calculation
- Core assumption: Reward function captures transferable semantic information
- Evidence anchors: [abstract], [section] - demonstrates transferability across LLMs
- Break condition: If frozen LLM embeddings are too model-specific

## Foundational Learning

- Concept: Reward-based optimization
  - Why needed here: Optimizes both semantic preservation and length constraints simultaneously
  - Quick check question: How does combining multiple reward functions affect optimization compared to single-objective training?

- Concept: Hidden state embeddings as semantic representation
  - Why needed here: Measures semantic similarity using hidden state embeddings from LLM
  - Quick check question: Why might hidden state embeddings be a good proxy for semantic similarity in prompt compression?

- Concept: Transfer learning and model generalizability
  - Why needed here: Aims to compress prompts that work across different LLMs and datasets
  - Quick check question: What challenges arise when creating model-agnostic compressed prompts?

## Architecture Onboarding

- Component map:
  Input -> Nano-Capsulator F(· | θC) with TRep and TSumm instructions -> Reward calculator Rcap(G∗(·), Q, C, K) with Φ(·) truncation -> NL-formatted Capsule Prompt

- Critical path:
  1. Generate Capsule Prompt from original prompt using TSumm instruction
  2. Calculate reward score comparing downstream task performance with original vs. compressed prompt
  3. Update Nano-Capsulator parameters to maximize reward while minimizing semantic loss

- Design tradeoffs:
  - Length constraint vs. utility preservation: Stricter limits may reduce prompt utility
  - Reward function choice: Different metrics may affect compression quality
  - Model size: Larger models may capture more semantics but increase computational cost

- Failure signatures:
  - Capsule Prompts too short and losing essential information
  - Prompts meeting length constraints but failing to preserve semantic meaning
  - Poor transferability across different LLMs despite good training performance

- First 3 experiments:
  1. Compress simple few-shot CoT prompt and verify Capsule Prompt maintains task accuracy
  2. Test transferability by evaluating compressed prompts across different LLMs (Vicuna-13B, PaLM, Claude2)
  3. Vary length constraints to find optimal balance between compression rate and utility preservation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance vary when using different distance metrics (cosine similarity, KL divergence) instead of MSE in semantic loss?
- Basis in paper: [explicit] Paper mentions Ddist can be any suitable distance measurement
- Why unresolved: Only experiments with mean squared error
- What evidence would resolve it: Experiments with alternative distance metrics comparing performance

### Open Question 2
- Question: Can Nano-Capsulator be extended to handle multimodal prompts while preserving utility and transferability?
- Basis in paper: [inferred] Framework focuses on text-based prompts only
- Why unresolved: Current design may not be directly applicable to multimodal inputs
- What evidence would resolve it: Extending framework to incorporate image processing capabilities

### Open Question 3
- Question: What is the impact of varying length constraints during training on transferability and utility?
- Basis in paper: [explicit] Mentions optimizing with length constraints and experiments with different settings
- Why unresolved: No comprehensive analysis of how different constraints affect performance
- What evidence would resolve it: Systematic study with varying length constraints during training

## Limitations
- Semantics preservation relies on hidden state embedding similarity, which may not fully capture prompt utility preservation
- Limited evaluation across diverse LLM architectures beyond three models
- Primary validation on few-shot CoT and reading comprehension tasks, with uncertain generalizability to other prompt types

## Confidence
- High confidence: Core compression mechanism and basic experimental results showing quantitative improvements
- Medium confidence: Transferability claims across different LLMs and effectiveness of unsupervised training approach
- Low confidence: Robustness across diverse prompt types and general applicability to all LLM architectures

## Next Checks
1. Conduct ablation studies varying length constraints systematically to determine sensitivity of utility preservation to compression ratios
2. Test transferability on wider range of LLM architectures including different model families to validate cross-architecture generalization
3. Evaluate performance on diverse prompt types beyond few-shot CoT and reading comprehension, including code generation and mathematical reasoning