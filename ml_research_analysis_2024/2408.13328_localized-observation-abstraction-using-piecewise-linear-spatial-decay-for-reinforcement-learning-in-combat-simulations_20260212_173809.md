---
ver: rpa2
title: Localized Observation Abstraction Using Piecewise Linear Spatial Decay for
  Reinforcement Learning in Combat Simulations
arxiv_id: '2408.13328'
source_url: https://arxiv.org/abs/2408.13328
tags:
- abstraction
- observation
- learning
- complexity
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training deep reinforcement
  learning agents in complex combat simulations, where increased scenario complexity
  leads to exponential growth in training time. The authors propose a novel localized
  observation abstraction method using piecewise linear spatial decay to reduce state
  space complexity while preserving critical spatial information.
---

# Localized Observation Abstraction Using Piecewise Linear Spatial Decay for Reinforcement Learning in Combat Simulations

## Quick Facts
- arXiv ID: 2408.13328
- Source URL: https://arxiv.org/abs/2408.13328
- Authors: Scotty Black; Christian Darken
- Reference count: 0
- Primary result: Localized observation with piecewise linear spatial decay outperformed global observation across 10 complexity levels, achieving 475.975% better performance in 3x3 games

## Executive Summary
This paper addresses the challenge of training deep reinforcement learning agents in complex combat simulations, where increased scenario complexity leads to exponential growth in training time. The authors propose a novel localized observation abstraction method using piecewise linear spatial decay to reduce state space complexity while preserving critical spatial information. Their method compresses the global observation space into a localized 7x7 grid, applying weighted decay to peripheral information. Across 10 levels of scenario complexity (3x3 to 12x12 gameboards), the localized observation approach consistently outperformed the global observation method, achieving mean scores of 181.4 versus 31.5 in the simplest scenarios and maintaining significantly better performance as complexity increased.

## Method Summary
The authors developed a localized observation abstraction method that compresses the global observation space into a 7x7 grid centered on the agent on-move. The method uses piecewise linear spatial decay weights to preserve high-fidelity information in the central 5x5 region while progressively compressing peripheral information into radial sectors. The decay function uses three linear segments: w=1 for d≤3, linearly decreasing for 3<d<7, and w=0.01 for 7≤d<100. This approach was tested using DQN with a residual convolutional neural network processing hexagonal convolutions, trained for 10 million steps against a Pass-Agg baseline across 10 complexity levels ranging from 3x3 to 12x12 gameboards.

## Key Results
- Localized observation achieved mean scores of 181.4 versus 31.5 in 3x3 scenarios
- 475.975% performance improvement over global observation in simplest scenarios
- Consistent outperformance across all complexity levels despite both methods converging toward random performance at 12x12
- Mean scores decreased from 181.4 (3x3) to 6.2 (12x12) for localized, and 31.5 to 5.5 for global observation

## Why This Works (Mechanism)

### Mechanism 1
The 7x7 localized observation with piecewise linear spatial decay reduces effective state space complexity while preserving critical spatial relationships near the agent. By compressing peripheral information into radial sectors with linearly decaying weights, the method retains high-fidelity information within a 5x5 central region and gradually reduces resolution for distant information. This allows the convolutional network to focus computational resources on the most relevant spatial relationships while maintaining awareness of the broader context. The core assumption is that the most critical information for decision-making is within the immediate vicinity of the agent.

### Mechanism 2
The consistent centering of the observation on the agent on-move facilitates faster generalization and learning. Unlike global observations where the agent's position varies across the board, the localized observation always presents the agent in the center position. This consistency allows the neural network to learn position-invariant features more efficiently, as the same spatial relationships map to consistent network inputs regardless of absolute position on the gameboard. The core assumption is that the agent's decision-making depends more on relative spatial relationships than absolute positions on the board.

### Mechanism 3
The piecewise linear spatial decay function provides an optimal balance between information preservation and computational efficiency. The decay function uses three distinct linear segments that preserve high-resolution information for nearby hexagons while progressively compressing distant information. This prevents information overload while ensuring the agent maintains awareness of distant threats and objectives. The core assumption is that information value decreases with distance in a piecewise linear manner, and a maximum value cap of 1.0 prevents convolutional distortion from high-perimeter values.

## Foundational Learning

- **State Abstraction in Reinforcement Learning**: Understanding how state abstraction functions (φ: S→S$) is critical to grasping why the localized observation approach works, as it formally maps the complex global state to a simplified representation while preserving essential information for decision-making. *Quick check: What are the three desiderata for useful state abstraction according to Abel (2020), and how does the localized observation method satisfy each one?*

- **Convolutional Neural Networks for Hexagonal Grids**: The neural network architecture uses HexagDLy hexagonal convolutions to process the 18×n×n observation space. Understanding hexagonal convolutions is essential for comprehending how the network processes spatial relationships in this unique grid structure. *Quick check: How do hexagonal convolutions differ from standard square convolutions, and why are they particularly suited for this Atlatl combat simulation environment?*

- **Reinforcement Learning Sample Inefficiency**: The paper addresses RL's well-documented sample inefficiency problem, which is exacerbated in high-dimensional state spaces. Understanding this challenge is crucial for appreciating why state space reduction through abstraction is necessary. *Quick check: What is the relationship between state space complexity and training time in reinforcement learning, and how does the exponential growth pattern specifically impact combat simulations?*

## Architecture Onboarding

- **Component map**: Atlatl Simulation Environment -> Gymnasium Interface -> Neural Network -> RL Algorithm -> Training Pipeline -> Evaluation Framework
- **Critical path**: Observation preprocessing → Neural network processing → Q-value prediction → Action selection → Environment step → Reward calculation → Experience replay → Network update
- **Design tradeoffs**: The localized observation sacrifices some spatial fidelity for computational efficiency and faster learning. The piecewise linear decay function represents a balance between preserving nearby information and compressing distant information. The 7x7 grid size was likely chosen as a compromise between context awareness and state space reduction.
- **Failure signatures**: If the agent consistently makes poor decisions involving distant units or cities, the spatial decay may be too aggressive. If training is unstable or slow, the observation compression may be discarding too much information. If performance degrades rapidly with complexity, the abstraction may not scale well.
- **First 3 experiments**:
  1. Compare training curves for global vs. localized observations on a 3x3 gameboard to verify the claimed 475.975% performance improvement
  2. Test different decay function parameters (transition points, maximum weights) to find optimal settings for various scenario complexities
  3. Evaluate the impact of observation size (e.g., 5x5 vs 7x7 vs 9x9) on both performance and training efficiency across multiple complexity levels

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What is the optimal decay rate function for different types of spatial relationships in combat scenarios?
- **Basis in paper**: The authors use a specific piecewise linear decay function but acknowledge that fidelity of information is lost in the process
- **Why unresolved**: The paper uses a fixed decay function without exploring variations or optimizing for different scenario types
- **What evidence would resolve it**: Systematic testing of different decay functions across various combat scenarios with quantitative performance comparisons

### Open Question 2
- **Question**: How does the localized observation approach perform with different neural network architectures beyond the residual CNN used in this study?
- **Basis in paper**: Only one neural network architecture was tested, limiting understanding of architecture-independence
- **Why unresolved**: The paper uses a specific neural network architecture but doesn't explore alternatives
- **What evidence would resolve it**: Comparative studies using transformers, LSTMs, and other architectures with the localized observation method

### Open Question 3
- **Question**: What is the relationship between training budget and the crossover point where localized observation outperforms rule-based approaches?
- **Basis in paper**: The authors note that "experiments that involved training in simpler environments, we expect this crossover point to move further to the right as we increase our training budget"
- **Why unresolved**: The paper only tests one training budget size and makes predictions about larger budgets without empirical validation
- **What evidence would resolve it**: Empirical testing of multiple training budget sizes with corresponding crossover point measurements

## Limitations

- The performance of both global and localized observation methods converges toward random performance at high complexity levels (12x12 gameboard), raising questions about practical utility at extreme complexity
- The approach was tested exclusively within the Atlatl combat simulation framework, with no empirical validation of performance in different types of environments or with varying spatial relationships
- Claims about computational efficiency improvements lack supporting empirical data on training time, memory usage, or wall-clock performance differences

## Confidence

**High Confidence (8-10/10):**
- The localized observation method with piecewise linear spatial decay is correctly implemented and produces consistent results within the Atlatl simulation environment
- The performance comparison methodology (100,000-game evaluations) provides statistically meaningful results
- The core observation that localized observation outperforms global observation in smaller scenarios is well-supported

**Medium Confidence (5-7/10):**
- The specific performance improvements (e.g., 475.975% better in 3x3 games) are accurately measured but may not generalize to other domains
- The convergence of both methods to random performance at high complexity represents a real phenomenon but the interpretation of its implications requires further investigation
- The choice of 7x7 grid size and specific decay parameters represents a reasonable optimization but may not be globally optimal

**Low Confidence (0-4/10):**
- Claims about computational efficiency improvements lack supporting empirical data
- The scalability of the approach to dramatically different spatial domains or non-combat applications
- The long-term stability and robustness of the trained agents beyond the evaluation conditions

## Next Checks

**Next Check 1**: Measure and compare GPU memory usage, training wall-clock time, and inference latency between global and localized observation approaches across all complexity levels to confirm theoretical computational benefits translate to practical advantages.

**Next Check 2**: Implement the localized observation method in at least two different spatial domains (e.g., navigation tasks, resource management games) to assess whether the 7x7 grid size and decay parameters remain optimal or require adaptation for different spatial relationships and information distributions.

**Next Check 3**: Experiment with different spatial decay functions beyond the piecewise linear approach (e.g., exponential decay, Gaussian weighting, adaptive decay based on information density) to determine if performance gains can be improved or if the linear decay represents a local optimum in the parameter space.