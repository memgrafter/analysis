---
ver: rpa2
title: 'A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning
  in Transformer Decoder'
arxiv_id: '2407.20485'
source_url: https://arxiv.org/abs/2407.20485
tags:
- attention
- tokens
- token
- score
- a2sf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the memory bottleneck in large language models
  (LLMs) caused by the growing size of KV cache, especially during long sequence handling.
  The core method, A2SF (Accumulative Attention Score with Forgetting Factor), introduces
  a forgetting factor that penalizes past attention scores exponentially over time,
  ensuring fairer comparison among tokens of different ages in the transformer decoder
  structure.
---

# A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder

## Quick Facts
- arXiv ID: 2407.20485
- Source URL: https://arxiv.org/abs/2407.20485
- Authors: Hyun-rae Jo; Dongkun Shin
- Reference count: 28
- Primary result: A2SF improves accuracy in LLaMA 2 by up to 7.8% in 1-shot and 5.1% in 0-shot tasks compared to H2O baseline

## Executive Summary
This paper addresses the memory bottleneck in large language models caused by the growing size of KV cache, especially during long sequence handling. The core method, A2SF (Accumulative Attention Score with Forgetting Factor), introduces a forgetting factor that penalizes past attention scores exponentially over time, ensuring fairer comparison among tokens of different ages in the transformer decoder structure. This resolves the imbalance in token importance scoring caused by causal masking. The primary results show that A2SF improves accuracy in LLaMA 2 by up to 7.8% in 1-shot and 5.1% in 0-shot tasks compared to the H2O baseline, with enhanced token selection performance closely resembling the ideal pruning mask.

## Method Summary
A2SF modifies the Accumulative Attention Score (A2S) by introducing a Forgetting Factor α that exponentially decays past attention scores over time. The method multiplies past attention scores by α raised to the power of steps since generation, ensuring older tokens receive larger penalties and providing fairness among different ages of tokens. This addresses the imbalance caused by causal masking where early tokens accumulate more attention scores simply due to their position. The Forgetting Factor allows tuning of how much past context is considered, enabling adaptation to different datasets and tasks.

## Key Results
- A2SF improves LLaMA 2 accuracy by up to 7.8% in 1-shot and 5.1% in 0-shot tasks compared to H2O baseline
- Token selection quality closely resembles the ideal pruning mask when evaluated with cosine similarity
- Different datasets show varying optimal Forgetting Factor values, with MathQA benefiting from higher values

## Why This Works (Mechanism)

### Mechanism 1
A2SF introduces a forgetting factor that applies an exponentially decreasing penalty to past attention scores to correct the imbalance in token importance caused by causal masking. The method multiplies past attention scores by a forgetting factor raised to the power of the number of steps since the score was generated. Older scores are thus penalized more heavily, reducing their disproportionate influence on the accumulative attention score. Core assumption: Past attention scores should be weighted less over time to reflect the relevance of recent context in token importance. Evidence anchors: [abstract] "A2SF applies a penalty to the past Attention Score generated from old tokens by repeatedly multiplying the Forgetting Factor to the Attention Score over time." Break condition: If the forgetting factor is too small, all past information is quickly lost and the model cannot leverage useful context; if too large, the original imbalance remains.

### Mechanism 2
A2SF ensures fairer comparison among tokens of different ages by reducing the impact of the accumulated attention scores from earlier tokens. By exponentially decaying past attention scores, the method prevents early tokens from always having higher accumulative scores simply due to their position in the sequence. Core assumption: The number of times attention scores accumulate varies by token position due to masking, creating unfair comparisons. Evidence anchors: [abstract] "older tokens receive a larger penalty, providing fairness among different ages of tokens." Break condition: If the forgetting factor is poorly tuned, the model may under- or over-penalize certain tokens, leading to suboptimal pruning decisions.

### Mechanism 3
The forgetting factor allows tuning of how much past context is considered, enabling adaptation to different datasets and tasks. By adjusting the forgetting factor value, the model can control the rate at which past attention scores decay, balancing the influence of recent versus historical context. Core assumption: Different datasets may require different balances between recent and historical context for optimal performance. Evidence anchors: [abstract] "A2SF has the potential for tuning considered for the dataset by setting the value of α." Break condition: If the forgetting factor is not tuned for the specific task, performance may degrade compared to a well-tuned baseline.

## Foundational Learning

- Concept: Transformer Decoder Structure and Causal Masking
  - Why needed here: Understanding how causal masking creates an imbalance in accumulative attention scores is crucial to grasping why A2SF is necessary.
  - Quick check question: Why does causal masking cause early tokens to have higher accumulative attention scores than later tokens?

- Concept: Accumulative Attention Score (A2S) in Transformer Models
  - Why needed here: A2SF builds upon the A2S mechanism; knowing how it works is essential to understanding the modification.
  - Quick check question: How is the accumulative attention score calculated in a transformer decoder model?

- Concept: Exponential Decay and Forgetting Curves
  - Why needed here: The forgetting factor applies exponential decay to past scores; understanding this concept is key to the mechanism.
  - Quick check question: How does exponential decay model the concept of forgetting over time?

## Architecture Onboarding

- Component map: Transformer Decoder Model -> Masked Self-Attention Layer -> Key-Value (KV) Cache -> Accumulative Attention Score (A2S) Calculator -> A2SF Modifier (introduces forgetting factor) -> Token Pruning Module

- Critical path:
  1. Generate token
  2. Calculate attention scores
  3. Apply A2SF modifier to past scores
  4. Accumulate modified scores
  5. Select tokens for pruning based on modified scores
  6. Update KV cache

- Design tradeoffs:
  - Forgetting factor value: Balancing between retaining useful context and preventing early token bias
  - Computational overhead: A2SF adds a small computation cost but can improve accuracy
  - Tuning requirements: Need to tune forgetting factor for different datasets and tasks

- Failure signatures:
  - If forgetting factor is too small: Loss of important historical context, potential accuracy drop
  - If forgetting factor is too large: Early token bias persists, leading to suboptimal pruning
  - If forgetting factor is poorly tuned: Inconsistent performance across different datasets

- First 3 experiments:
  1. Implement A2SF with a fixed forgetting factor and compare accuracy to baseline on a standard dataset (e.g., LLaMA 2)
  2. Tune the forgetting factor for a specific dataset and measure the impact on accuracy and token selection
  3. Compare the cosine similarity of attention scores generated by A2SF to the ideal pruning mask and analyze the token selection quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal Forgetting Factor value across different types of datasets and tasks, and how does it vary based on linguistic characteristics?
- Basis in paper: [explicit] The paper discusses the impact of the Forgetting Factor on accuracy and mentions that different datasets like MathQA benefit from higher Forgetting Factor values compared to others.
- Why unresolved: The paper shows that the optimal Forgetting Factor varies between datasets but does not provide a comprehensive method to determine it for new, unseen datasets or tasks.
- What evidence would resolve it: A systematic study that analyzes the Forgetting Factor's impact across a diverse range of datasets with varying linguistic characteristics (e.g., datasets rich in numbers, abstract concepts, or technical jargon) and develops a predictive model for optimal Forgetting Factor selection.

### Open Question 2
- Question: How does the Forgetting Factor affect the interpretability of the token selection process, and can it be tuned to improve model transparency?
- Basis in paper: [inferred] The paper suggests that the Forgetting Factor influences how much historical context is considered, which could affect which tokens are deemed important and thus impact interpretability.
- Why unresolved: While the paper discusses the Forgetting Factor's role in balancing past and present token importance, it does not explore how this affects the transparency or interpretability of the model's decision-making process.
- What evidence would resolve it: An analysis comparing token selection patterns with different Forgetting Factor values and correlating them with human-interpretable linguistic features, possibly leading to guidelines for tuning the Forgetting Factor to enhance interpretability.

### Open Question 3
- Question: Can the Forgetting Factor be dynamically adjusted during inference based on the evolving context of the sequence, and what would be the benefits or drawbacks?
- Basis in paper: [explicit] The paper mentions that the Forgetting Factor could be tuned for different datasets but does not explore dynamic adjustment during inference.
- Why unresolved: The paper treats the Forgetting Factor as a static parameter but does not investigate whether adapting it in real-time could improve performance, especially in sequences with varying context complexity.
- What evidence would resolve it: Experiments comparing static versus dynamic Forgetting Factor strategies across sequences of different lengths and contexts, measuring improvements in accuracy and efficiency.

### Open Question 4
- Question: How does the Forgetting Factor interact with other KV cache compression techniques, and can they be combined to achieve better overall performance?
- Basis in paper: [explicit] The paper notes that A2SF is a token selection technique and could enhance other KV cache processing algorithms when integrated.
- Why unresolved: The paper does not explore combinations of A2SF with other compression techniques like quantization or low-rank decomposition mentioned in related works.
- What evidence would resolve it: Empirical studies testing A2SF in conjunction with other compression methods, analyzing the cumulative effects on accuracy, memory usage, and computational efficiency.

## Limitations

- The exact forgetting factor (α) value used in reported experiments is not specified, though Figure 5 shows accuracy across [0.0, 0.9]
- Implementation details of how A2SF modifies the H2O token pruning mask calculation are not fully detailed in the paper
- Results are based on a single implementation without extensive ablation studies on forgetting factor values

## Confidence

The core claim that A2SF improves accuracy in LLaMA 2 by up to 7.8% in 1-shot and 5.1% in 0-shot tasks compared to H2O baseline is supported by the paper's own experimental results. However, this confidence is Medium because the results are based on a single implementation and the specific forgetting factor value is not disclosed.

The claim that A2SF ensures fairer comparison among tokens of different ages is supported by the theoretical analysis in the paper, but lacks direct empirical validation through ablation studies or comparison to other fairness metrics. This confidence is Low.

The assertion that the forgetting factor allows tuning for different datasets and tasks is discussed in the paper but lacks corpus evidence or extensive experimental validation across diverse datasets. This confidence is Low.

## Next Checks

1. Conduct an ablation study by implementing A2SF with different forgetting factor values (e.g., [0.1, 0.5, 0.9]) and measure the impact on accuracy and token selection quality across the specified datasets.

2. Compare the cosine similarity of attention scores generated by A2SF to the ideal pruning mask and analyze the token selection quality, providing quantitative evidence for the fairness claim.

3. Reproduce the main results using the provided code repository on a different hardware setup (e.g., RTX 4090) to verify the reported accuracy improvements and assess the impact of computational differences on the forgetting factor's effectiveness.