---
ver: rpa2
title: Semantic Residual Prompts for Continual Learning
arxiv_id: '2403.06870'
source_url: https://arxiv.org/abs/2403.06870
tags:
- prompts
- learning
- tasks
- each
- clip
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the stability issue in continual learning prompting
  methods, where learned prompt selection keys can catastrophically forget and interfere
  with previously learned prompts. The authors propose a two-level prompting strategy
  that leverages a foundation model (CLIP) for stable prompt selection.
---

# Semantic Residual Prompts for Continual Learning

## Quick Facts
- arXiv ID: 2403.06870
- Source URL: https://arxiv.org/abs/2403.06870
- Reference count: 40
- One-line primary result: +5.96 average accuracy improvement over state-of-the-art continual learning methods

## Executive Summary
The paper addresses catastrophic forgetting in continual learning prompting methods by introducing a two-level prompting strategy that leverages CLIP's stable embedding space for reliable prompt selection. The method employs learned prompts in CLIP's textual encoder to produce stable class prototypes, which serve as keys for retrieving second-level prompts that adapt a frozen ViT using an additive residual mechanism. Multi-modal generative replay further enhances performance across nine challenging image classification datasets, demonstrating significant improvements over existing continual learning approaches.

## Method Summary
STAR-Prompt addresses catastrophic forgetting in continual learning by implementing a two-level prompting framework that separates prompt selection from adaptation. First-level prompts are learned to condition CLIP's textual encoder, producing stable class prototypes that serve as selection keys. These keys retrieve second-level prompts that inject semantic information into a frozen ViT through an additive residual mechanism after MSA layers, rather than concatenation. The method also incorporates multi-modal generative replay using Mixture of Gaussians to model class distributions and generate synthetic samples, improving generalization across task boundaries while maintaining stability through frozen backbone parameters.

## Key Results
- Achieves +5.96 average accuracy improvement over state-of-the-art continual learning methods across nine image classification datasets
- Demonstrates resilience to domain shifts with performance close to stationary joint training upper bound
- Shows superior stability in prompt selection, avoiding catastrophic forgetting in the selection mechanism itself

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-level prompting reduces catastrophic forgetting in prompt selection.
- Mechanism: First-level prompts are learned in CLIP's stable embedding space, producing class prototypes that serve as keys for second-level prompts. This separation ensures the selection mechanism does not drift across tasks.
- Core assumption: CLIP's embedding space provides stable representations that resist forgetting when used as keys.
- Evidence anchors:
  - [abstract] "As keys are learned while tasks progress, the prompting selection strategy is itself subject to catastrophic forgetting... To make the selection strategy more stable, we leverage a foundation model (CLIP)..."
  - [section 3.4] "we argue that learning keys as such is susceptible to interference between tasks... Since keys are continuously adjusted to align with the queries of the current task, they may drift..."
- Break condition: If CLIP's embedding space becomes unstable due to domain shifts or fine-tuning, the key stability advantage disappears.

### Mechanism 2
- Claim: Additive semantic residuals inject class-specific information more reliably than prompt concatenation.
- Mechanism: Second-level prompts are added after MSA layers rather than concatenated before them, ensuring consistent contribution to ViT embeddings regardless of attention weights.
- Core assumption: MSA layers may ignore concatenated prompts if attention weights deem them unimportant.
- Evidence anchors:
  - [section 3.4] "While most methods [41,48] concatenate the learned prompts to the arguments of the Multi-head Self-Attention (MSA) layer... our second-level prompts are used as semantic residuals which are added before the MLP layer input."
  - [section 3.4] "While there is no guarantee that a pre-trained and frozen MSA layer will take into account all the prompt tokens, our additive mechanism forces the ViT embeddings to include CLIP-derived semantics."
- Break condition: If ViT's MSA layers develop new attention patterns that bypass residuals, or if MLP layers become invariant to residual inputs.

### Mechanism 3
- Claim: Multi-modal generative replay improves generalization across tasks.
- Mechanism: Each class is modeled as a Mixture of Gaussians in both CLIP visual space and ViT feature space, generating synthetic samples that preserve multimodal class distributions.
- Core assumption: Class distributions are multimodal rather than unimodal, and synthetic samples from MoG better represent true data.
- Evidence anchors:
  - [section 3.5] "To capture multiple peaks in the distribution of each class, we extend this idea by introducing, in both stages of our training, a Mixture of Gaussians (MoGs) representation of the feature distribution."
  - [section 3.5] "Using this generative replay technique, we obtain: LP_GR = − 1/nN_t N_t Σ c=1 n Σ i=1 log p(y_i = c|~z~z~z_i)"
- Break condition: If the number of Gaussian components is insufficient to capture true class structure, or if synthetic samples diverge from real data distribution.

## Foundational Learning

- Concept: Continual Learning and Catastrophic Forgetting
  - Why needed here: The entire method addresses the stability-plasticity dilemma inherent in CL scenarios where models must learn new tasks without forgetting old ones.
  - Quick check question: Why does fine-tuning the entire model on new tasks typically cause catastrophic forgetting of previously learned knowledge?

- Concept: Foundation Models and Multi-modal Embeddings
  - Why needed here: CLIP provides the stable embedding space that enables reliable prompt selection, and understanding its properties is crucial for the two-level approach.
  - Quick check question: How does CLIP's training objective (contrastive learning between images and text) contribute to the stability of its embedding space?

- Concept: Vision Transformers and Attention Mechanisms
  - Why needed here: The second-level prompting modifies ViT's MSA and MLP layers, requiring understanding of how attention mechanisms process input tokens.
  - Quick check question: What is the difference between how MSA layers process concatenated inputs versus added residuals?

## Architecture Onboarding

- Component map:
  - CLIP (frozen): Image encoder E_vis(·), Text encoder E_txt(·)
  - First-level prompts: Learnable tokens for each class, fed to E_txt(·)
  - Second-level prompts: Learnable residuals for each ViT layer
  - ViT backbone (frozen): Modified to accept additive residuals
  - Classification head: Task-specific linear layer
  - Generative replay module: MoG fitting and sampling for both stages

- Critical path:
  1. Image → E_vis(·) → Visual embedding (query)
  2. Query + First-level prompts → E_txt(·) → Class prototypes (keys)
  3. Similarity matching → Retrieve second-level prompt (residual)
  4. Residual injection into ViT layers → Classification

- Design tradeoffs:
  - Two backbones vs single backbone: Increased memory but improved stability
  - Additive residuals vs prefix tuning: More consistent semantic injection vs parameter efficiency
  - MoG vs single Gaussian: Better distribution modeling vs computational cost

- Failure signatures:
  - Prompt selection confusion: If second-level prompts retrieve wrong class information
  - Residual saturation: If added values become too large relative to MSA outputs
  - Generation collapse: If MoG sampling produces unrealistic synthetic samples

- First 3 experiments:
  1. Test prompt selection stability: Compare prompt retrieval accuracy across tasks using confusion matrices
  2. Validate residual mechanism: Compare classification performance with and without additive residuals
  3. Assess generative replay: Evaluate performance with MoG vs single Gaussian and with/without replay

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the learned keys in the first-level prompting stage of STAR-Prompt maintain stability over time without being subject to catastrophic forgetting?
- Basis in paper: [explicit] The authors claim that the first-level prompting stage, which leverages CLIP's textual encoder, leads to stable class prototypes. They argue that this stability arises from the fine-tuning regime of CLIP models, which favors stability over plasticity.
- Why unresolved: The paper does not provide a detailed explanation of the underlying mechanisms that ensure the stability of the learned keys. It would be beneficial to understand the specific factors contributing to this stability and how they prevent catastrophic forgetting.
- What evidence would resolve it: Experimental results demonstrating the stability of the learned keys over time, even when presented with new tasks or domain shifts. Additionally, an analysis of the learned keys' properties, such as their semantic meaning and relationship to the input data, would provide insights into the stability mechanisms.

### Open Question 2
- Question: What is the optimal number of Gaussian components (M) in the Mixture of Gaussians (MoGs) used for generative replay in STAR-Prompt?
- Basis in paper: [explicit] The authors mention using a MoG to model the multimodal distribution of each class in both the first and second stages of training. However, they do not provide a thorough analysis of the impact of varying the number of Gaussians (M) on the model's performance.
- Why unresolved: The optimal value of M likely depends on the complexity and characteristics of the dataset. Without a comprehensive evaluation of different M values, it is unclear how to choose the most suitable number of Gaussians for each task or dataset.
- What evidence would resolve it: An ablation study exploring the impact of different M values on the model's performance across various datasets. This would help identify the optimal number of Gaussians for each dataset and provide insights into the relationship between M and the complexity of the data distribution.

### Open Question 3
- Question: How does the semantic residual mechanism in STAR-Prompt compare to other prompt-based adaptation methods, such as prefix tuning, in terms of effectiveness and efficiency?
- Basis in paper: [explicit] The authors claim that their semantic residual mechanism, which adds learned prompts after the MSA layer in the ViT, is more effective than prefix tuning, which prepends prompts to the input sequence. They provide some experimental evidence supporting this claim.
- Why unresolved: While the paper demonstrates the superiority of the semantic residual mechanism over prefix tuning, it does not provide a comprehensive comparison of the two methods in terms of their effectiveness and efficiency. It would be valuable to understand the specific advantages and disadvantages of each approach and their impact on the model's performance and computational requirements.
- What evidence would resolve it: A detailed comparison of the semantic residual mechanism and prefix tuning across various datasets and tasks. This comparison should include not only the final performance metrics but also an analysis of the computational cost, memory usage, and convergence speed of each method.

## Limitations

- The paper assumes CLIP's embedding space remains stable across all nine diverse datasets (medical, aerial, natural images), but this assumption is not independently validated
- No direct empirical comparison between additive residuals and standard prefix tuning to quantify the claimed superiority
- The assumption that class distributions are inherently multimodal is never validated on the actual datasets, and synthetic sample quality is not quantitatively assessed

## Confidence

- **High confidence** in the two-level prompting architecture and its basic implementation feasibility, as the components (CLIP, ViT, prompt learning) are well-established.
- **Medium confidence** in the additive residual mechanism's superiority over concatenation, since the theoretical argument is sound but lacks direct empirical comparison.
- **Low confidence** in the claimed stability benefits without understanding how CLIP's embedding space behaves across domain shifts - the method could fail if CLIP representations drift significantly.

## Next Checks

1. **Prompt Selection Stability Test**: Implement a controlled experiment tracking prompt retrieval accuracy across task boundaries on a subset of datasets (e.g., CIFAR-100) to verify that first-level prompts maintain stable class representations.

2. **Residual vs Concatenation Ablation**: Replace the additive residual mechanism with standard prefix concatenation while keeping all other components identical, then compare performance on Split ImageNet-R to quantify the benefit.

3. **CLIP Stability Analysis**: Measure the consistency of CLIP embeddings for the same classes across different tasks/datasets using intra-class distance metrics to validate the foundation of the two-level approach.