---
ver: rpa2
title: Fine-grained and Explainable Factuality Evaluation for Multimodal Summarization
arxiv_id: '2402.11414'
source_url: https://arxiv.org/abs/2402.11414
tags:
- summary
- evaluation
- factuality
- summarization
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FALLACIOUS, a framework for evaluating the
  factuality of multimodal summarization models. The authors address the challenge
  of assessing whether generated summaries accurately reflect the information in the
  input text and image.
---

# Fine-grained and Explainable Factuality Evaluation for Multimodal Summarization

## Quick Facts
- arXiv ID: 2402.11414
- Source URL: https://arxiv.org/abs/2402.11414
- Reference count: 27
- Introduces FALLACIOUS framework for multimodal summarization factuality evaluation with up to 0.88 Pearson correlation with human judgment

## Executive Summary
This paper introduces FALLACIOUS, a framework for evaluating the factuality of multimodal summarization models. The authors address the challenge of assessing whether generated summaries accurately reflect information from both text and image inputs. FALLACIOUS employs two complementary approaches: a reference-based method that compares generated summaries against ground truth using fine-grained QA pairs, and a reference-free approach that evaluates consistency between summaries and multimodal inputs without requiring reference summaries. Experimental results demonstrate that FALLACIOUS outperforms existing metrics like CLIPBERTScore, BERTScore, and CLIPScore in correlation with human judgment of factuality, achieving up to 0.88 Pearson correlation on certain datasets.

## Method Summary
FALLACIOUS addresses multimodal summarization factuality evaluation through two complementary frameworks. The reference-based approach generates fine-grained yes/no questions from ground truth summaries and uses text-based and vision-based QA models to verify answers against both the source content and generated summaries. The reference-free approach directly evaluates consistency between generated summaries and multimodal inputs by generating QA pairs from the multimodal content itself and checking whether the summary adequately answers these questions. Both approaches leverage LLMs for question generation and employ specialized QA models for verification. The framework provides fine-grained factuality scores at the question level, offering more interpretable evaluation compared to holistic metrics.

## Key Results
- FALLACIOUS achieves up to 0.88 Pearson correlation with human judgment on factuality evaluation
- Outperforms existing metrics including CLIPBERTScore, BERTScore, and CLIPScore in correlation with human judgment
- Reference-free approach successfully eliminates dependency on ground truth summaries while maintaining strong performance

## Why This Works (Mechanism)
FALLACIOUS works by decomposing the complex task of factuality evaluation into manageable QA-based verification steps. The framework generates targeted yes/no questions that probe specific facts from the multimodal input, then uses specialized QA models to verify whether these facts are correctly preserved in the generated summary. By operating at a fine-grained level (question-by-question), the framework can pinpoint specific factual errors rather than providing only holistic scores. The dual reference-based and reference-free approaches provide flexibility for different evaluation scenarios, with the reference-based method offering detailed comparison against ground truth and the reference-free method enabling evaluation when reference summaries are unavailable.

## Foundational Learning

**QA-based factuality verification** - Why needed: Traditional metrics like BERTScore measure semantic similarity but cannot detect factual errors or hallucinations. Quick check: Verify that generated QA pairs accurately capture key facts from source content.

**Multimodal QA integration** - Why needed: Multimodal summarization requires evaluating consistency across both text and image modalities, not just text alone. Quick check: Ensure vision-based QA models correctly interpret visual information and align with text-based understanding.

**LLM-powered question generation** - Why needed: Manual creation of comprehensive QA pairs is impractical; automated generation enables scalable evaluation. Quick check: Validate that automatically generated questions cover diverse aspects of the source content without bias.

## Architecture Onboarding

**Component map**: Multimodal Input → LLM Question Generator → Text QA Model + Vision QA Model → Factuality Score Calculator → Final Evaluation Score

**Critical path**: The most critical path involves generating accurate QA pairs from source content, correctly answering these questions using specialized QA models, and comparing these answers against the summary's treatment of the same facts. Any error in this chain propagates to the final score.

**Design tradeoffs**: Reference-based approach offers detailed comparison with ground truth but requires reference summaries; reference-free approach enables broader applicability but may miss nuanced factual discrepancies. The framework trades computational efficiency for fine-grained interpretability.

**Failure signatures**: Poor QA generation leads to irrelevant or misleading questions; inaccurate QA model responses create false positives/negatives; modality mismatch between text and vision QA outputs; failure to handle multimodal reasoning requiring integration of both modalities.

**3 first experiments**:
1. Test QA generation quality by manually evaluating sample questions for relevance and coverage
2. Evaluate individual QA model performance on isolated text and vision tasks
3. Conduct ablation study removing either text or vision components to assess modality-specific contributions

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Framework performance depends heavily on quality of automatically generated QA pairs and accuracy of text/vision QA models
- Reference-free approach may miss nuanced factual discrepancies that human evaluators catch when comparing against reference summaries
- Evaluation primarily conducted on datasets with generated summaries rather than real-world applications, limiting generalizability
- Framework effectiveness across diverse domains and multimodal content types remains untested

## Confidence
- **High confidence**: Experimental results showing superior correlation with human judgment compared to baseline metrics
- **Medium confidence**: Claim of providing more interpretable and fine-grained evaluation
- **Medium confidence**: Framework's ability to generalize across different multimodal summarization tasks and domains

## Next Checks
1. Conduct user studies with human evaluators to assess whether fine-grained scores provided by FALLACIOUS are practically useful and interpretable for improving multimodal summarization models
2. Test the framework on additional datasets representing diverse domains (e.g., medical, technical, news) and multimodal content types to evaluate generalizability
3. Perform ablation studies to quantify impact of each component (QA generation, text QA, vision QA) on overall performance and identify potential bottlenecks or error sources