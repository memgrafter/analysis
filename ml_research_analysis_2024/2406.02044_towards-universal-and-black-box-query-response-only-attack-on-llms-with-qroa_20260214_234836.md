---
ver: rpa2
title: Towards Universal and Black-Box Query-Response Only Attack on LLMs with QROA
arxiv_id: '2406.02044'
source_url: https://arxiv.org/abs/2406.02044
tags:
- attack
- function
- triggers
- optimization
- qroa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces QROA, a black-box, query-only method to generate
  jailbreak attacks on large language models (LLMs) by appending optimized triggers
  to malicious instructions. Unlike prior approaches, QROA does not require access
  to model logits or human-crafted templates and operates solely through the standard
  query-response interface.
---

# Towards Universal and Black-Box Query-Response Only Attack on LLMs with QROA

## Quick Facts
- arXiv ID: 2406.02044
- Source URL: https://arxiv.org/abs/2406.02044
- Authors: Hussein Jawad; Yassine Chenik; Nicolas J. -B. Brunel
- Reference count: 36
- Key outcome: Achieves >80% ASR on Vicuna, Falcon, and Mistral with 25K queries

## Executive Summary
This paper introduces QROA, a black-box, query-only method to generate jailbreak attacks on large language models (LLMs) by appending optimized triggers to malicious instructions. Unlike prior approaches, QROA does not require access to model logits or human-crafted templates and operates solely through the standard query-response interface. It formulates the attack as an optimization bandit problem, using a surrogate model and token-level optimization to explore suffix variations. The method is evaluated on Vicuna, Falcon, and Mistral, achieving an Attack Success Rate (ASR) greater than 80% with a budget of 25K queries. QROA also includes QROA-UNV, an extension that enables one-query jailbreaks across a wide range of instructions by identifying universal adversarial suffixes.

## Method Summary
QROA is a black-box jailbreak attack method that operates solely through query-response interactions with LLMs. It formulates jailbreaking as an optimization bandit problem where the objective is to find trigger suffixes that maximize harmful output generation without access to model logits. The method uses a surrogate model (a multi-layer perceptron with pre-trained GPT2 embeddings) to approximate the scoring function, trained via experience replay on prompt-score pairs. Upper Confidence Bound (UCB) selection balances exploration and exploitation during the iterative optimization process. QROA-UNV extends this to find universal suffixes effective across diverse malicious instructions through statistical validation.

## Key Results
- Achieves >80% ASR on Vicuna-7B, Falcon-7B, and Mistral-7B with 25K queries
- QROA-UNV successfully identifies universal adversarial suffixes for one-query jailbreaks
- Outperforms baseline methods GCG and PAL in both ASR and query efficiency
- Effective against Llama2-chat, demonstrating transferability to models with safety fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: QROA works by iteratively optimizing suffixes without direct access to the model's internal parameters.
- Mechanism: The algorithm formulates jailbreak as an optimization bandit problem, using a surrogate model to approximate the scoring function. This surrogate model is trained via experience replay, which stores prompt-score pairs and updates the model using gradient descent on a mean squared error loss. At each iteration, token-level variants are generated, scored by the surrogate model, and the top-K variants are selected for evaluation against the real LLM. The Upper Confidence Bound (UCB) method balances exploration and exploitation.
- Core assumption: The surrogate model can effectively approximate the true scoring function even without access to logits.
- Evidence anchors:
  - [abstract] "By framing the attack as an optimization bandit problem, QROA employs a surrogate model and token level optimization to efficiently explore suffix variations."
  - [section 4] "This model is designed to approximate the scoring function S(x, I ), facilitating the definition of the optimization objective as arg max x S(x) ≈ arg max x m(x)."
  - [corpus] Weak corpus evidence; no direct citations to this surrogate modeling approach.
- Break condition: If the surrogate model fails to approximate the true scoring function accurately, the optimization process will not converge to effective triggers.

### Mechanism 2
- Claim: The use of reinforcement learning principles, particularly experience replay and UCB-based selection, enables efficient exploration of the large search space of possible suffixes.
- Mechanism: Experience replay stores past experiences (prompts and their scores) in a buffer. During each iteration, a batch of experiences is sampled to update the surrogate model parameters. The UCB method selects the most promising trigger by balancing the average score and the uncertainty (exploration factor), calculated as UCB = average_score + c * sqrt(log(total_queries) / (n + 1)), where n is the number of times the trigger has been selected.
- Core assumption: The UCB method effectively balances exploration and exploitation in this discrete, high-dimensional search space.
- Evidence anchors:
  - [section 4] "Experience replay is a fundamental technique in reinforcement learning that allows learning algorithms to reuse past experiences to break the temporal correlations in successive training samples."
  - [section 4.1] "Utilize the Upper Confidence Bound (UCB) method for trigger selection, calculated as UCB = average_score + c * sqrt(log(total_queries) / (n + 1))."
  - [corpus] Weak corpus evidence; no direct citations to this specific UCB application in LLM jailbreaking.
- Break condition: If the UCB exploration factor is not well-tuned, the algorithm may either get stuck in local optima (too little exploration) or waste queries on unpromising triggers (too much exploration).

### Mechanism 3
- Claim: QROA-UNV extends QROA to find universal adversarial suffixes that work across a wide range of instructions with a single query.
- Mechanism: QROA-UNV identifies triggers that, when appended to any malicious instruction, consistently produce harmful outputs. This is achieved by optimizing the surrogate model to maximize the alignment score across a diverse set of instructions, then validating the triggers using statistical testing (z-test) to ensure they exceed a predefined threshold with high confidence.
- Core assumption: There exist universal adversarial suffixes that are effective across different types of malicious instructions.
- Evidence anchors:
  - [abstract] "We propose QROA-UNV, an extension that identifies universal adversarial suffixes for individual models, enabling one-query jailbreaks across a wide range of instructions."
  - [section 5.2.4] "We also tested the model against Llama2-chat, the fine-tuned version of Llama2 designed to resist Jailbreak attacks, achieving good ASR with a suboptimal initial trigger seed."
  - [corpus] Weak corpus evidence; no direct citations to universal suffix approaches in this context.
- Break condition: If the model's safety alignment is too strong or the instructions are too diverse, no universal suffix may exist that works consistently across all cases.

## Foundational Learning

- Concept: Reinforcement Learning (RL) and Q-learning
  - Why needed here: QROA uses RL principles like experience replay and surrogate models to optimize triggers without gradient access.
  - Quick check question: How does the UCB method balance exploration and exploitation in QROA?

- Concept: Optimization Bandit Problems
  - Why needed here: The attack is formulated as an optimization problem where the objective is to maximize the alignment function without direct gradient access.
  - Quick check question: What is the role of the surrogate model in approximating the true scoring function?

- Concept: Statistical Hypothesis Testing (z-test)
  - Why needed here: QROA-UNV uses statistical testing to validate that identified triggers consistently produce harmful outputs above a threshold.
  - Quick check question: How does the z-test ensure that a trigger is statistically significant for inducing malicious behavior?

## Architecture Onboarding

- Component map: Surrogate Model (MLP) -> Experience Replay Buffer -> UCB Selector -> Token Variant Generator -> Alignment Function Evaluator -> LLM
- Critical path:
  1. Initialize with a random or known effective trigger
  2. Use UCB to select the best trigger so far
  3. Generate token variants by replacing one token
  4. Score variants using the surrogate model
  5. Select top-K variants for evaluation against the real LLM
  6. Store results in the replay buffer
  7. Update the surrogate model using gradient descent on sampled experiences
  8. Repeat until query budget is exhausted
- Design tradeoffs:
  - Query Budget vs. ASR: Higher budgets allow more exploration and refinement, improving ASR
  - Surrogate Model Complexity vs. Training Time: More complex models may better approximate the scoring function but require more computation
  - UCB Exploration Factor vs. Convergence Speed: Higher exploration may find better triggers but slow down convergence
- Failure signatures:
  - Surrogate model consistently underestimates or overestimates scores
  - UCB selection gets stuck in local optima
  - No triggers pass the statistical validation threshold
  - LLM consistently refuses to respond to all triggers
- First 3 experiments:
  1. Run QROA with a small query budget (e.g., 5K) on Vicuna-7B and Vicuna-13B to compare ASR and observe differences in model behavior
  2. Test QROA with different alignment functions (e.g., harmful detection vs. entailment) to evaluate their impact on ASR
  3. Implement QROA-UNV and validate universal suffixes across a diverse set of instructions to measure transferability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How transferable is the surrogate model mθ across different malicious instructions, and what architectural modifications would maximize cross-instruction generalization?
- Basis in paper: [inferred] The paper mentions that future research could focus on enhancing the transferability of the surrogate model between different malicious instructions, and the authors plan to exploit the potential of the surrogate model as a safety filter to predict and mitigate unintended harmful outputs from LLMs.
- Why unresolved: The paper does not provide experimental results or detailed analysis on the transferability of the surrogate model across different instructions. The authors only propose it as a future research direction without concrete evidence or methodology.
- What evidence would resolve it: Experimental results comparing the performance of the surrogate model when trained on one set of instructions versus another, or when fine-tuned across different instruction sets, would provide evidence on its transferability.

### Open Question 2
- Question: What is the impact of the initial trigger string on the convergence speed and effectiveness of the QROA algorithm, and can this be optimized through adaptive initialization strategies?
- Basis in paper: [explicit] The paper mentions that the starting point is to generate an initial trigger string either randomly or from a predefined list of known effective triggers, and that the algorithm starts an iterative process across several epochs. The paper also discusses the challenges of flat response landscapes and the necessity of an initialization step for some LLMs.
- Why unresolved: The paper does not provide a detailed analysis of how different initial trigger strings affect the convergence speed and effectiveness of the QROA algorithm. The impact of adaptive initialization strategies is also not explored.
- What evidence would resolve it: Experimental results comparing the convergence speed and effectiveness of the QROA algorithm using different initial trigger strings, including adaptive initialization strategies, would provide evidence on the impact of the initial trigger string.

### Open Question 3
- Question: How does the choice of alignment function f influence the attack success rate and the robustness of the QROA algorithm against defensive measures, and what are the trade-offs between different alignment functions?
- Basis in paper: [explicit] The paper discusses the choice of alignment function and presents two proposed alignment models: the Harmful Evaluation Model and the Entailment Evaluation Model. It also mentions that the choice of alignment function is a crucial hyperparameter influencing the effectiveness of the model.
- Why unresolved: The paper does not provide a comprehensive comparison of different alignment functions in terms of their impact on attack success rate and robustness against defensive measures. The trade-offs between different alignment functions are not explored in detail.
- What evidence would resolve it: Experimental results comparing the performance of the QROA algorithm using different alignment functions, including their impact on attack success rate and robustness against defensive measures, would provide evidence on the influence of the alignment function choice.

## Limitations
- The surrogate model's effectiveness in approximating the true scoring function is not thoroughly validated
- Statistical validation assumes normal distribution of scores without robustness analysis
- Evaluation focuses on ASR percentages without deep analysis of output harmfulness or false positives
- Generalizability to other model architectures and languages is not explored

## Confidence
- High Confidence: The core methodology of using optimization bandits with surrogate models for black-box attacks is sound and well-grounded in reinforcement learning literature
- Medium Confidence: The reported ASR results on the tested models are likely reproducible, though exact values may vary due to stochastic elements in the algorithm
- Low Confidence: Claims about universal suffix effectiveness across diverse instruction sets and robustness against different alignment strategies require more extensive validation

## Next Checks
1. Conduct ablation studies to quantify how surrogate model accuracy impacts final ASR and test with intentionally degraded surrogate models
2. Evaluate QROA against a broader range of models including decoder-only architectures and models with different safety training approaches
3. Test QROA against simple defensive strategies like input filtering, output sanitization, and adaptive safety training to understand attack resilience