---
ver: rpa2
title: Neural Networks Learn Statistics of Increasing Complexity
arxiv_id: '2402.04362'
source_url: https://arxiv.org/abs/2402.04362
tags:
- order
- statistics
- neural
- loss
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The distributional simplicity bias (DSB) posits that neural networks
  first learn low-order statistics of the data distribution, such as mean and covariance,
  before higher-order correlations. This paper provides compelling evidence for the
  DSB by showing that early in training, networks perform well on maximum-entropy
  distributions matching training set low-order statistics, but lose this ability
  later.
---

# Neural Networks Learn Statistics of Increasing Complexity

## Quick Facts
- arXiv ID: 2402.04362
- Source URL: https://arxiv.org/abs/2402.04362
- Authors: Nora Belrose; Quintin Pope; Lucia Quirke; Alex Mallen; Xiaoli Fern
- Reference count: 40
- Primary result: Neural networks first learn low-order statistics of data distributions before higher-order correlations, exhibiting a distributional simplicity bias

## Executive Summary
This paper provides compelling evidence for the distributional simplicity bias (DSB) - the phenomenon where neural networks learn low-order statistics of data distributions before higher-order correlations. The authors demonstrate that early in training, networks perform well on maximum-entropy distributions matching training set low-order statistics but lose this ability later. They extend this analysis to discrete domains by proving an equivalence between token n-gram frequencies and moments of embedding vectors, and observe a "double descent" phenomenon in language models where in-context learning enables even lower loss later in training.

## Method Summary
The paper employs optimal transport methods to edit low-order statistics between classes and uses maximum entropy sampling to generate synthetic data matching specified low-order statistics. The authors train various architectures (ConvNeXt, Swin Transformer, RegNet-Y, and language models) on image and text datasets, then evaluate performance on synthetic datasets with controlled low-order statistics throughout training. They analyze accuracy/loss curves to identify U-shaped patterns indicating the transition from low-order to high-order statistic sensitivity.

## Key Results
- Neural networks show U-shaped loss curves when evaluated on maximum entropy distributions matching training set low-order statistics
- Optimal transport maps can surgically edit low-order statistics between classes while minimally perturbing higher-order statistics
- Language models exhibit a "double descent" phenomenon where in-context learning enables lower loss after initial U-shaped scaling
- The distributional simplicity bias is observed across multiple architectures and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural networks first learn to fit low-order statistics of the data distribution before higher-order correlations.
- Mechanism: During training, the expected loss can be expressed as a Taylor expansion around the mean input, where early terms depend primarily on low-order moments (mean, covariance) and later terms on higher-order moments. The magnitude of moments decays exponentially with order for typical data distributions, causing the network to prioritize matching low-order statistics first.
- Core assumption: The Taylor expansion of the loss function converges and the network's behavior can be approximated by the first few terms early in training.
- Evidence anchors:
  - [abstract] "networks automatically learn to perform well on maximum-entropy distributions whose low-order statistics match those of the training set early in training, then lose this ability later"
  - [section 2.1] "we can Taylor expand the loss for any given x around the mean input µ" and "the moment magnitude to decay exponentially with order when the coordinates are independent"
  - [corpus] Weak - related work focuses on frequency principles and Fourier analysis rather than distributional moments
- Break condition: If the data distribution has unusually large higher-order moments relative to lower-order moments, or if the network architecture or initialization causes higher-order terms to dominate early in training.

### Mechanism 2
- Claim: Optimal transport maps can be used to edit low-order statistics of one class to match another while minimally perturbing higher-order statistics.
- Mechanism: Optimal transport theory provides analytic formulas (e.g., Gaussian OT) for transforming samples from one distribution to another while minimizing expected squared Euclidean distance. By computing optimal transport maps between class-conditional distributions, we can "graft" low-order statistics from one class onto another.
- Core assumption: The optimal transport map preserves the essential structure needed for the network to classify based on low-order statistics.
- Evidence anchors:
  - [section 2.3] "the map T (x) = A(x − mP ) + mQ is the optimal transport map from P to Q under the L2 cost function" and "we use three OT methods in our experiments"
  - [section 2.3] "we compute their means and covariance matrices, and plug these statistics into Eq. 3 to get the k(k−1) optimal transport maps from each class to every other class"
  - [corpus] Moderate - related work on "Slowing Learning by Erasing Simple Features" suggests similar approaches to modifying feature learning
- Break condition: If the optimal transport map significantly distorts higher-order statistics beyond what's acceptable for the network to maintain its low-order bias.

### Mechanism 3
- Claim: Maximum entropy sampling can generate synthetic data that match specified low-order statistics while maximizing uncertainty about higher-order statistics.
- Mechanism: By constructing maximum entropy distributions constrained to match certain low-order statistics (e.g., mean and covariance for Gaussian), we create synthetic data that isolates the effect of those statistics. This allows testing whether networks are sensitive to statistics up to a given order.
- Core assumption: The principle of maximum entropy provides a principled way to operationalize "deletion" of higher-order statistics.
- Evidence anchors:
  - [abstract] "generate synthetic data that match the class-conditional means and covariances, but are otherwise maximum entropy"
  - [section 2.4] "the maximum entropy distribution supported on Rd with known mean µ and covariance matrix Σ is the Gaussian distribution N (µ, Σ)"
  - [corpus] Weak - related work focuses on generative models rather than maximum entropy sampling for controlled experiments
- Break condition: If the maximum entropy distribution under the given constraints doesn't adequately represent "deletion" of higher-order information, or if the network learns to exploit structure in the sampling process itself.

## Foundational Learning

- Concept: Taylor series expansion of analytic functions
  - Why needed here: The paper's theoretical framework relies on expressing the expected loss as a Taylor series around the mean input to analyze the contribution of different order moments
  - Quick check question: What is the general form of a Taylor series expansion for a function f(x) around a point a?

- Concept: Central moments and cumulants of probability distributions
  - Why needed here: The paper analyzes how neural networks learn to match different order moments (mean, covariance, skewness, etc.) of the data distribution
  - Quick check question: What is the difference between raw moments and central moments of a distribution?

- Concept: Optimal transport theory and Wasserstein distance
  - Why needed here: The paper uses optimal transport maps to surgically edit low-order statistics between classes while minimizing perturbation
  - Quick check question: What is the Monge-Kantorovich optimal transport problem trying to minimize?

## Architecture Onboarding

- Component map:
  Data pipeline: Dataset loading (CIFAR-10, CIFARNet, Fashion MNIST, MNIST, SVHN, language models) -> Preprocessing (normalization, augmentation) -> Batch loading
  Model training: Model instantiation (ConvNeXt, Swin Transformer, RegNet-Y, language models) -> Training loop with specified optimizer, learning rate schedule, and augmentation -> Checkpoint saving
  OT and sampling: Optimal transport computation (Gaussian OT, CQN, bounded shift) -> Maximum entropy sampling (Gaussian, hypercube-constrained, Conrad distribution, ICS) -> Data generation for experiments
  Evaluation: Model accuracy/loss computation on synthetic datasets -> Statistical analysis of results -> Visualization generation

- Critical path:
  1. Load dataset and compute class-conditional statistics (mean, covariance)
  2. Generate optimal transport maps between classes
  3. Apply OT to create edited datasets for criterion 1 testing
  4. Generate maximum entropy synthetic datasets for criterion 2 testing
  5. Train models on original data while periodically evaluating on synthetic datasets
  6. Analyze accuracy/loss curves to identify U-shaped patterns

- Design tradeoffs:
  - Computational cost vs. image resolution: Higher resolution images require more memory for covariance matrices (O(d²) space, O(d³) time)
  - Sampling accuracy vs. speed: Exact maximum entropy sampling may be intractable; approximate methods trade precision for tractability
  - Model capacity vs. bias detection: Smaller models may show stronger DSB effects but may not generalize well; larger models may obscure effects

- Failure signatures:
  - No U-shaped loss curve: Could indicate the DSB doesn't apply to this architecture/dataset combination, or that the synthetic data generation is flawed
  - High variance in results: May suggest insufficient sample size or instability in the OT/sampling procedures
  - Accuracy doesn't drop below random baseline: Could indicate the network isn't learning higher-order statistics as expected

- First 3 experiments:
  1. Reproduce the CIFAR-10 U-shaped accuracy curve on 1st and 2nd order synthetic data using ConvNeXt with default hyperparameters
  2. Implement coordinate-wise quantile normalization (CQN) and test its effect on a simple binary classification problem
  3. Generate maximum entropy Gaussian samples for MNIST and verify they match the target mean and covariance statistics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do learning dynamics change when the input distribution has more complex higher-order statistics that cannot be easily captured by low-order moments?
- Basis in paper: [inferred] The paper shows that networks become sensitive to higher-order statistics as training progresses, but does not explore what happens when the true data distribution has inherently complex higher-order structure.
- Why unresolved: The experiments primarily use image datasets and n-gram models where low-order statistics provide reasonable approximations, leaving open the question of how networks behave with inherently complex distributions.
- What evidence would resolve it: Training networks on datasets with known complex higher-order structure (e.g., textures with specific spatial correlations) and measuring whether the DSB pattern still holds or if networks adapt differently.

### Open Question 2
- Question: Does the distributional simplicity bias extend to other network architectures beyond the ones tested, such as convolutional networks with different receptive field sizes or attention-based architectures?
- Basis in paper: [explicit] The authors state "model scale has a remarkably small effect on the learning curves" but do not test diverse architectural families.
- Why unresolved: The experiments focus on ConvNeXt, Swin Transformer, and RegNet-Y architectures, leaving uncertainty about whether the DSB is a general property of neural networks or specific to certain architectural designs.
- What evidence would resolve it: Systematic experiments across diverse architectures (CNNs, transformers, MLPs) on the same datasets to determine if the DSB pattern is consistent across architectural families.

### Open Question 3
- Question: What is the relationship between the distributional simplicity bias and other known phenomena like grokking or double descent in terms of underlying mechanisms?
- Basis in paper: [inferred] The paper observes a "double descent" phenomenon in language models but does not explore connections to other generalization phenomena.
- Why unresolved: The DSB provides a framework for understanding early learning dynamics, but its relationship to other temporal phenomena in training (like grokking's delayed generalization) remains unclear.
- What evidence would resolve it: Comparative analysis of training trajectories showing how DSB, grokking, and double descent manifest across different datasets and architectures, potentially revealing shared or distinct mechanisms.

## Limitations

- The Gaussian optimal transport approach assumes class-conditional distributions are approximately Gaussian, which may not hold for real datasets
- Memory constraints limit exact OT map computation for high-dimensional data, requiring approximations
- The theoretical foundation relies on Taylor expansion assumptions that may not hold for all network architectures or data distributions

## Confidence

- Core DSB claims: High
- Extension to language models and double descent: Medium
- Theoretical foundations and assumptions: Medium
- Optimal transport methods: Medium

## Next Checks

1. Apply rigorous statistical tests (e.g., paired t-tests with multiple comparison corrections) to verify that U-shaped curves and accuracy differences across synthetic datasets are statistically significant and not due to random variation.

2. Systematically vary network depth, width, and architectural components (attention vs convolution) to identify which factors most strongly influence the strength of the DSB effect and whether the phenomenon generalizes across diverse model families.

3. Quantify how closely the class-conditional distributions in each dataset match Gaussian assumptions by computing higher-order moments and testing for normality, validating the use of Gaussian OT and identifying when alternative methods might be needed.