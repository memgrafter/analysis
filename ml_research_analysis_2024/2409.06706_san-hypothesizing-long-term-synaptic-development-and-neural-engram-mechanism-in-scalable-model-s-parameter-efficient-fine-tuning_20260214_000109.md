---
ver: rpa2
title: 'SAN: Hypothesizing Long-Term Synaptic Development and Neural Engram Mechanism
  in Scalable Model''s Parameter-Efficient Fine-Tuning'
arxiv_id: '2409.06706'
source_url: https://arxiv.org/abs/2409.06706
tags:
- lora
- arxiv
- tasks
- scaling
- vision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SAN (Synapse and Neuron), a method inspired
  by biological neural network mechanisms to enhance parameter-efficient fine-tuning
  (PEFT). SAN draws insights from Neural Engrams and Long-Term Potentiation/Depression
  in biological neural networks, establishing a connection between low-rank properties
  observed in PEFT parameter space shifting and neurobiological mechanisms.
---

# SAN: Hypothesizing Long-Term Synaptic Development and Neural Engram Mechanism in Scalable Model's Parameter-Efficient Fine-Tuning

## Quick Facts
- arXiv ID: 2409.06706
- Source URL: https://arxiv.org/abs/2409.06706
- Reference count: 34
- Outperforms LoRA by 3.2% on vision tasks, 4.7% on language tasks, and 1.9% on visual-language tasks

## Executive Summary
SAN (Synapse and Neuron) is a parameter-efficient fine-tuning method that draws inspiration from biological neural network mechanisms to improve performance without introducing additional trainable parameters. The method decomposes and propagates scaling components from anterior feature adjusting vectors towards posterior weight matrices, establishing a connection between low-rank properties observed in PEFT parameter space shifting and neurobiological mechanisms. Extensive experiments demonstrate SAN's effectiveness across vision, language, and visual-language tasks, achieving significant improvements over existing methods like LoRA and Full Fine-Tuning.

## Method Summary
SAN improves parameter-efficient fine-tuning by extracting scaling vectors from anterior layers (via element-wise ratio of adjusted vs. original features) and applying them to posterior layer weights. This approach enables more fine-grained parameter adjustment than traditional methods by eliminating the assumption that each row of the current layer's weight matrix uses the same scaling factor. The method introduces implicit regularization through the quadratic nature of scaling vector influence when propagated through layers, preventing overfitting while maintaining expressiveness. SAN can be integrated with existing PEFT methods like LoRA, DoRA, and SSF as a plug-and-play enhancement.

## Key Results
- Vision tasks: Outperforms Full Fine-Tuning by up to 8.7% and LoRA by 3.2% across 25 datasets using ViT, SwinT, and ConvNeXt backbones
- Language tasks: Surpasses ChatGPT by up to 8.5% and LoRA by 4.7% on Commonsense Reasoning with 8 datasets using LLaMA models
- Visual-language tasks: Exceeds FFT by up to 2.4% and LoRA by 1.9% on Mixed Visual Instruction with 7 datasets using LLaVA models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAN improves PEFT by decomposing feature adjustment vectors and explicitly propagating scaling components to subsequent layers
- Mechanism: The method extracts scaling vectors from anterior layers (via element-wise ratio of adjusted vs. original features) and applies them to posterior layer weights, effectively pre-scaling pre-trained parameters without adding trainable parameters
- Core assumption: The scaling effect on current features implicitly adjusts subsequent layer weights, and making this propagation explicit preserves these relationships even with non-linear activations
- Evidence anchors: [abstract] "decomposes and propagates scaling components from anterior feature adjusting vectors towards posterior weight matrices"; [section 3.2] "We first compute the output following standard LoRA: y′l = yl + [Wup(WdownxT )]T...Then, we obtain the scaling vector by computing the element-wise ratio between y′l and yl"
- Break condition: If non-linear activations significantly disrupt the scaling relationship between layers, or if the Pool operation loses critical information about scaling variations

### Mechanism 2
- Claim: SAN achieves more fine-grained parameter adjustment than traditional methods like SSF by eliminating the assumption that each row of the current layer's weight matrix uses the same scaling factor
- Mechanism: Instead of applying a single scaling vector to all parameters in a row, SAN allows unique adjustment values for every parameter through explicit propagation, achieving dimension-wise scaling without extra trainable parameters
- Core assumption: The propagation of scaling vectors can effectively replace the need for additional trainable parameters while maintaining expressiveness
- Evidence anchors: [section 3.2] "By propagating the scaling vectors γl from the current layer to the posterior layer's weight, we can overcome the strong assumption of SSF and achieve a more fine-grained adjustment"; [section 3.2] "W′l+1 = γl+1 ⊙ (γl ⊙ Wl+1)"
- Break condition: If the element-wise multiplication operations create numerical instability or if the scaling vectors become too extreme and dominate the pre-trained weights

### Mechanism 3
- Claim: SAN introduces implicit regularization that prevents overfitting through the quadratic nature of scaling vector influence when propagated through layers
- Mechanism: When scaling vectors are propagated through multiple layers, their effect becomes squared (γ²), which acts as a soft constraint discouraging extreme values and promoting stability
- Core assumption: The quadratic influence of scaling vectors creates a natural regularization effect that penalizes large deviations from the initial value of 1
- Evidence anchors: [section 3.2] "The presence of (γl)2 this formulation reveals a crucial property: the effect of the scaling vectors is essentially squared when propagated through layers"; [section 3.2] "R(γ) = λ Σl ||γl − 1||²"
- Break condition: If the regularization effect is too strong and prevents the model from making necessary large adjustments, or if the assumption about quadratic influence doesn't hold in deeper networks

## Foundational Learning

- Concept: Low-rank properties in parameter space shifting during PEFT
  - Why needed here: Understanding that PEFT methods like LoRA exploit low-rank properties is crucial for grasping why SAN's approach of propagating scaling components is effective
  - Quick check question: What is the fundamental assumption behind low-rank adaptation methods like LoRA, and how does this relate to the parameter space being adjusted?

- Concept: Neural Engrams and Long-Term Potentiation/Depression in biological neural networks
  - Why needed here: SAN draws inspiration from these biological mechanisms, where strengthening/weakening of existing connections enables rapid learning without creating new synapses
  - Quick check question: How do LTP/D phenomena in BNNs relate to the concept of propagating scaling components in SAN, and what biological efficiency principle does this mirror?

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: SAN is applied to transformer-based models (ViT, SwinT, LLaVA, etc.), so understanding how attention layers work and how they can be decomposed is essential
  - Quick check question: In a transformer block, what are the main components that SAN would need to modify, and how does the propagation of scaling vectors interact with these components?

## Architecture Onboarding

- Component map:
  Input features from layer l → LoRA update computation → Scaling vector extraction (element-wise ratio) → Weight matrix scaling for layer l+1 → Output through activation/normalization

- Critical path:
  1. Compute LoRA output: y′l = yl + [Wup(WdownxT)]T
  2. Extract scaling vector: γl = Pool(y′l ⊘ yl)
  3. Apply scaling to next layer: W′l+1 = γl ⊙ Wl+1
  4. Forward pass with scaled weights

- Design tradeoffs:
  - Parameter efficiency vs. expressiveness: SAN maintains the same parameter count as baseline methods while improving performance
  - Locational vs. functional proximity: Choice between propagating to next layer or corresponding layer in next block
  - Pool operation design: Different pooling strategies may affect how scaling information is aggregated

- Failure signatures:
  - Numerical instability from extreme scaling values
  - Loss of expressiveness if Pool operation over-aggregates information
  - Degraded performance if scaling vectors don't properly capture adjustment patterns
  - Training instability from improper learning rate scaling

- First 3 experiments:
  1. Implement SAN on top of LoRA with ViT-B on CIFAR-100, comparing with baseline LoRA performance
  2. Test different Pool operations (mean, max, learned) to see impact on scaling vector quality
  3. Evaluate locational vs. functional proximity propagation strategies on a small vision task to determine which is more effective

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SAN's performance scale with different model sizes, particularly for very large language models beyond LLaMA-7B and LLaMA-13B?
- Basis in paper: [explicit] The paper states "Our approach, SAN, further explores this trend. SAN demonstrates plug-and-play capability not only for LoRA but also for prompt tuning methods like SSF. It can even be integrated with DoRA itself. When combined with LoRA, our method outperforms DoRA, achieving accuracy gains ranging from 2.4% (LLaMA2-7B) to 4.6% (LLaMA3-8B)."
- Why unresolved: The experiments only tested up to LLaMA3-8B, leaving uncertainty about performance on significantly larger models.
- What evidence would resolve it: Comprehensive benchmarking of SAN on models larger than LLaMA3-8B (e.g., LLaMA-70B or GPT-3 size models) across multiple tasks to establish scaling behavior.

### Open Question 2
- Question: What is the theoretical limit of SAN's expressiveness when propagating scaling vectors through many layers, and how does this affect performance on extremely deep networks?
- Basis in paper: [inferred] The paper mentions "This propagation allows for more efficient parameter adaptation and provides better optimization stability" and discusses self-regulation through implicit regularization, but doesn't explore theoretical limits.
- Why unresolved: While SAN shows improved performance, the paper doesn't establish bounds on how far scaling vectors can be effectively propagated through deep architectures.
- What evidence would resolve it: Mathematical analysis of scaling vector propagation through deep networks, combined with empirical tests on architectures with varying depths to identify performance plateaus or degradation points.

### Open Question 3
- Question: How does SAN's mechanism relate to other biological learning principles beyond LTP/D and Neural Engrams, such as spike-timing-dependent plasticity or homeostatic plasticity?
- Basis in paper: [explicit] The paper draws connections between SAN and "Long-Term Potentiation/Depression (LTP/D) phenomena, which govern synapse development through neurotransmitter release modulation" and "Neural Engram (NE) (Tonegawa et al., 2015) phenomenon observed in Biological Neural Networks (BNNs)."
- Why unresolved: The paper focuses specifically on LTP/D and Neural Engrams but acknowledges that "future research should focus on discovering more NE mechanisms in scalable ANNs."
- What evidence would resolve it: Investigation of SAN's behavior under conditions that would test other biological learning mechanisms, and theoretical work connecting SAN's mathematical formulation to these additional neurobiological principles.

## Limitations
- The biological inspiration claims (Neural Engrams, LTP/D) lack direct empirical validation connecting them to the scaling vector propagation mechanism
- Key implementation details like the Pool() function design are not fully specified, creating potential reproducibility gaps
- The connection between low-rank PEFT properties and neurobiological mechanisms remains largely conceptual without mechanistic verification

## Confidence
- **High Confidence**: The mathematical formulation of SAN is sound, and the performance improvements over baseline methods are well-documented across multiple benchmarks and domains
- **Medium Confidence**: The biological motivation provides an interesting framework but lacks direct evidence linking the proposed mechanism to actual neural engram/LTP phenomena
- **Medium Confidence**: The mechanism of propagating scaling vectors appears to work empirically, though the theoretical grounding connecting this to biological efficiency principles needs further validation

## Next Checks
1. Conduct ablation studies comparing SAN with random scaling vector propagation to verify that the learned scaling vectors contain meaningful information beyond random patterns
2. Implement SAN with different Pool operations (mean, max, learned) to determine the sensitivity of performance to this design choice and identify optimal pooling strategies
3. Test SAN's effectiveness on smaller models (below 1B parameters) to determine if the method maintains its advantages when applied to less parameter-efficient architectures, validating the scalability claims