---
ver: rpa2
title: 'Chain of Evidences and Evidence to Generate: Prompting for Context Grounded
  and Retrieval Augmented Reasoning'
arxiv_id: '2401.05787'
source_url: https://arxiv.org/abs/2401.05787
tags:
- context
- reasoning
- step
- arxiv
- evidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Chain of Evidences (CoE) and Evidence to
  Generate (E2G), a novel prompting framework designed to improve context grounding
  and retrieval-augmented reasoning in large language models (LLMs). The approach
  addresses limitations in existing chain-of-thought (CoT) methods, such as hallucination
  and lack of context verification, by focusing on evidence extraction from context
  before generating answers.
---

# Chain of Evidences and Evidence to Generate: Prompting for Context Grounded and Retrieval Augmented Reasoning

## Quick Facts
- arXiv ID: 2401.05787
- Source URL: https://arxiv.org/abs/2401.05787
- Reference count: 19
- Primary result: CoE achieved 53.8% accuracy on LogiQA (18% above CoT baseline), E2G achieved 83.3 F1 on DROP (outperforming Gemini Ultra by 0.9 points)

## Executive Summary
This paper introduces Chain of Evidences (CoE) and Evidence to Generate (E2G), a novel prompting framework designed to improve context grounding and retrieval-augmented reasoning in large language models. The approach addresses limitations in existing chain-of-thought methods by focusing on evidence extraction from context before generating answers, reducing hallucination and improving factual correctness. The framework was evaluated across eight knowledge-intensive reasoning and generation tasks using GPT-4, PaLM-2, and ChatGPT, showing consistent performance gains over baseline methods.

## Method Summary
The framework uses a two-step prompting approach. First, CoE generates reasoning steps explicitly grounded in the provided context by extracting evidence and generating answers with explanations. Second, E2G uses these evidence sequences in a second step to produce the final answer, reducing noise and cognitive load. The method can be applied as a single-step (CoE-Short or CoE-Long) or dual-step (E2G) process, with the dual-step approach using only concise evidence as context for faster processing.

## Key Results
- CoE achieved 53.8% accuracy on LogiQA, outperforming chain-of-thought by 18 percentage points
- E2G achieved 83.3 F1 on DROP, outperforming Gemini Ultra by 0.9 points
- E2G showed consistent improvements across multiple tasks including HotpotQA (+1.8 EM) and NQ (+3.2 EM)

## Why This Works (Mechanism)

### Mechanism 1
E2G improves reasoning accuracy by separating evidence extraction from answer generation, allowing focused context processing. First pass uses CoE to generate both an answer and evidence from the full context. Second pass uses only the concise evidence as context, reducing noise and cognitive load.

### Mechanism 2
CoE reduces hallucination by explicitly grounding reasoning steps in the provided context rather than allowing model-generated hypotheses. The prompt instruction "Generate the answer with evidence and explanation" forces the model to extract and cite reasoning from the context.

### Mechanism 3
Using evidence as context in G-step improves efficiency by reducing token processing requirements. The G-step context (evidence only) is significantly shorter than original context, leading to faster processing and lower computational cost.

## Foundational Learning

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: Understanding baseline CoT is essential to grasp why CoE and E2G improve upon it
  - Quick check question: What is the primary limitation of standard CoT prompting identified in this paper?

- Concept: Context grounding in language models
  - Why needed here: The framework's core innovation is improving context grounding to reduce hallucination
  - Quick check question: How does CoE ensure reasoning steps are grounded in the provided context?

- Concept: Retrieval-augmented generation (RAG)
  - Why needed here: The framework specifically targets RAG scenarios where long, imperfect contexts create challenges
  - Quick check question: What problem does E2G solve in retrieval-augmented reasoning tasks?

## Architecture Onboarding

- Component map: System/Objective Instruction -> CoE-Short/CoE-Long -> E2G Pipeline -> Context Selection
- Critical path: Context → System Instruction → CoE (E-step) → Evidence → CoE (G-step) → Final Answer
- Design tradeoffs:
  - CoE-Short vs CoE-Long: Speed vs reasoning depth
  - Single-step vs two-step: Efficiency vs accuracy in long contexts
  - Evidence-only vs Evidence+Context in G-step: Speed vs completeness for multi-query questions
- Failure signatures:
  - Over-reliance on evidence leading to "unknown" responses when common sense is needed
  - Incomplete evidence preventing full answer reconstruction
  - Context-free reasoning tasks performing worse than standard CoT
- First 3 experiments:
  1. Compare CoE-Short vs CoE-Long on LogiQA to validate reasoning depth vs efficiency tradeoff
  2. Test E2G vs single-step CoE on HotpotQA to verify multi-hop reasoning improvements
  3. Evaluate G-step context variations (Evidence vs Evidence+Context) on NQ to determine optimal context selection

## Open Questions the Paper Calls Out

### Open Question 1
How can the overemphasis on context grounding in Chain of Evidences be mitigated to allow better use of common sense and world knowledge in LLM reasoning? The paper identifies this as a challenge but does not provide solutions for balancing context grounding with common sense reasoning.

### Open Question 2
Can the Chain of Evidences framework be effectively adapted for low-resource languages or specialized domains like biomedicine where retrieval accuracy may be lower? The paper explicitly mentions these as areas where the framework may not exhibit the same trends as in English benchmarks.

### Open Question 3
What is the optimal balance between using Evidence-only versus Evidence + Original Context in the G-step for multi-answer queries, and can this be automated? While the paper introduces an adaptive approach, it only uses simple heuristics and does not explore more sophisticated methods.

## Limitations

- Framework's effectiveness diminishes on tasks requiring common sense reasoning or open-ended generation, as evidenced by lower performance on ELI5 and FEVER
- Two-step E2G approach introduces computational overhead despite faster G-step processing
- Method's reliance on complete, explicit context evidence limits its applicability to scenarios where such evidence is sparse or ambiguous

## Confidence

- **High Confidence**: Performance improvements on LogiQA, DROP, HotpotQA, and NQ where context grounding is essential
- **Medium Confidence**: Runtime efficiency claims and generalization across the eight task types
- **Low Confidence**: Claims about the framework's applicability to open-ended generation tasks and common sense reasoning

## Next Checks

1. Test CoE/E2G on tasks requiring significant common sense inference to quantify the performance degradation observed on FEVER and ELI5
2. Conduct ablation studies comparing different evidence selection strategies to understand the tradeoff between conciseness and completeness
3. Measure the actual computational overhead of the two-step E2G approach across varying context lengths to validate the claimed efficiency gains versus single-step CoT methods