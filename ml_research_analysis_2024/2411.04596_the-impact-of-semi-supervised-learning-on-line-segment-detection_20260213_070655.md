---
ver: rpa2
title: The Impact of Semi-Supervised Learning on Line Segment Detection
arxiv_id: '2411.04596'
source_url: https://arxiv.org/abs/2411.04596
tags:
- line
- dataset
- data
- supervised
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first semi-supervised framework for line
  segment detection, combining consistency regularization with a compact line segment
  model. The approach uses both labeled and unlabeled data, with two strongly augmented
  views of unlabeled images guided by a common weakly perturbed view.
---

# The Impact of Semi-Supervised Learning on Line Segment Detection

## Quick Facts
- arXiv ID: 2411.04596
- Source URL: https://arxiv.org/abs/2411.04596
- Authors: Johanna Engman; Karl Åström; Magnus Oskarsson
- Reference count: 40
- Primary result: First semi-supervised framework for line segment detection, achieving >200% improvement with 1/16 labeled data on forestry datasets

## Executive Summary
This paper introduces the first semi-supervised framework for line segment detection, combining consistency regularization with a compact line segment model. The approach uses both labeled and unlabeled data, with two strongly augmented views of unlabeled images guided by a common weakly perturbed view. Tested on standard benchmarks and forestry datasets, the method shows significant improvements over fully supervised models, especially when only a small fraction of data is labeled.

## Method Summary
The method uses a MobileNetV2 backbone with M-LSD head to predict line segments using Tri-point (TP), segment-of-line (SoL), and geometric losses on labeled data. For unlabeled data, consistency regularization is applied between two strongly augmented views and one weakly augmented view using cross-entropy loss. A modified CutMix variant is proposed to preserve line continuity better than standard CutMix. The model is trained with a combination of labeled and unlabeled losses, showing strong performance even with minimal labeled data.

## Key Results
- On Finnwoodlands dataset with 1/16 labeled data, semi-supervised model achieved 31.1 sAP10 vs 7.8 for supervised (200% improvement)
- Semi-supervised model with 1/2 labeled data exceeded fully supervised model performance
- Method generalizes well to new domains and performs favorably against pretrained state-of-the-art models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Consistency regularization with multiple strong augmentations guides the model to learn robust line representations from unlabeled data.
- Mechanism: The framework presents three versions of each unlabeled image—one weakly perturbed and two strongly perturbed—to the shared model. The cross-entropy loss between weakly and strongly perturbed outputs enforces consistency, encouraging the model to produce similar line detections despite large appearance changes.
- Core assumption: The strongly augmented views preserve the underlying line structure while altering superficial appearance.
- Evidence anchors:
  - [abstract] "consistency loss based on differently augmented and perturbed unlabeled images"
  - [section 3.3] "consistency loss is calculated between each of the two strongly perturbed versions of the image and the weakly perturbed version"
- Break condition: If strong augmentations distort the line geometry beyond recognition, the consistency loss becomes meaningless and the model learns noise instead of structure.

### Mechanism 2
- Claim: Using only half the dataset with ground truth labels but leveraging the rest as unlabeled data yields performance comparable to or better than fully supervised training.
- Mechanism: The semi-supervised framework splits the training data into labeled and unlabeled subsets. The labeled subset provides direct task-specific supervision via the line segment loss (TP, SoL, geometric losses), while the unlabeled subset provides additional regularization via the consistency loss.
- Core assumption: The unlabeled data distribution is similar enough to the labeled data for consistency regularization to be effective.
- Evidence anchors:
  - [abstract] "Leveraging the use of a consistency loss based on differently augmented and perturbed unlabeled images with a small amount of labeled data, we show comparable results to fully supervised methods."
  - [section 4.3] "For the 1/2 split the performance exceeds the performance of the fully supervised model"
- Break condition: If the unlabeled data comes from a very different domain, the consistency loss may reinforce incorrect predictions, degrading performance.

### Mechanism 3
- Claim: The proposed modified CutMix (splitting images along one dimension) is better suited for line detection than the original CutMix.
- Mechanism: Standard CutMix cuts random squares and patches them, which can break long lines into short, misaligned segments. The modified version splits only along one axis (x or y), preserving line continuity and reducing bias toward short lines while still providing augmentation diversity.
- Core assumption: Line continuity is important for detection accuracy and that single-axis splits preserve it better than random squares.
- Evidence anchors:
  - [section 3.4] "Using CutMix counteracts the system from finding long consistent lines, and we propose a variant more suited to line detection."
  - [section 4.5] "interestingly, for line segment detection we find that using the regular CutMix is unfavourable, and leads to a bias to very short line segments."
- Break condition: If the scene contains many horizontal or vertical lines, splitting along one axis may still break many lines; adaptive splitting strategies might be needed.

## Foundational Learning

- Concept: Tri-point (TP) line representation
  - Why needed here: M-LSD uses TP to encode line segments as center point plus two displacement vectors, enabling direct prediction from feature maps without post-processing.
  - Quick check question: How many feature maps does the model output for the TP representation and what does each encode?

- Concept: Semi-supervised consistency regularization
  - Why needed here: Allows the model to learn from unlabeled data by enforcing that different augmentations of the same image produce similar predictions, reducing annotation burden.
  - Quick check question: In the unlabeled loss, what threshold condition must be met before applying the consistency loss?

- Concept: Structural Average Precision (sAP)
  - Why needed here: Standard AP metrics can be sensitive to overlapping detections; sAP provides a more robust evaluation for line segment detection by considering structural similarity.
  - Quick check question: What threshold is used for sAP in this paper and why might it be chosen?

## Architecture Onboarding

- Component map: Input (512x512x3 image) -> Shared MobileNetV2 backbone -> 16-layer feature map output (TP, SoL, classification layers) -> Labeled loss (TP + SoL + Geo) + Unlabeled loss (consistency via cross-entropy) -> Backpropagation
- Critical path: Image augmentation -> Shared model forward pass -> Compute labeled and unlabeled losses -> Gradient update -> Model checkpointing based on validation sAP10
- Design tradeoffs: Small MobileNetV2 backbone for speed vs. larger backbones for accuracy; two strong augmentations for consistency vs. computational cost; custom CutMix for line preservation vs. more general augmentation strategies
- Failure signatures: Degraded sAP10 with more unlabeled data (consistency loss overfitting); low FH score indicating missed lines; high variance across runs suggesting instability in augmentation or loss balancing
- First 3 experiments:
  1. Train supervised baseline on full Finnwoodlands dataset, measure sAP10 and FH
  2. Train semi-supervised model on 1/16 labeled + rest unlabeled, compare performance
  3. Swap the modified CutMix with original CutMix, measure impact on short vs. long line detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of semi-supervised line segment detection scale with larger and more diverse datasets, and what are the computational trade-offs involved?
- Basis in paper: [inferred] The paper tests semi-supervised methods on relatively small datasets (Finnwoodlands, Wireframe) and focuses on compact models. It does not explore performance on larger or more diverse datasets.
- Why unresolved: The study is limited to small-scale benchmarks and forestry-specific datasets, leaving open questions about scalability and computational efficiency for larger datasets.
- What evidence would resolve it: Experiments testing the semi-supervised framework on larger, more diverse datasets (e.g., COCO, Cityscapes) with detailed analysis of computational costs and model scalability.

### Open Question 2
- Question: Can the proposed semi-supervised framework be extended to detect other geometric features (e.g., circles, polygons) or higher-level semantic structures in images?
- Basis in paper: [explicit] The paper mentions that future work includes adapting the model to handle other low-parametric features than lines, but does not explore this direction.
- Why unresolved: The current framework is tailored for line segment detection and does not investigate its applicability to other geometric or semantic features.
- What evidence would resolve it: Development and evaluation of the semi-supervised framework for detecting circles, polygons, or other geometric features, along with performance comparisons to existing methods.

### Open Question 3
- Question: How does the proposed CutMix variant compare to other data augmentation strategies for line segment detection, and what are its limitations?
- Basis in paper: [explicit] The paper introduces a modified CutMix variant for line segment detection and compares it to the original CutMix and no CutMix. However, it does not explore other augmentation strategies.
- Why unresolved: The study focuses on a single augmentation variant and does not evaluate its performance against other potential strategies for line segment detection.
- What evidence would resolve it: Comparative experiments testing the proposed CutMix variant against other augmentation strategies (e.g., MixUp, Mosaic) for line segment detection, with detailed analysis of their strengths and weaknesses.

### Open Question 4
- Question: What is the impact of semi-supervised learning on the robustness of line segment detection models to noise, occlusions, and domain shifts?
- Basis in paper: [inferred] The paper demonstrates that semi-supervised methods improve generalization to new domains (e.g., forestry scenes), but does not explicitly test robustness to noise or occlusions.
- Why unresolved: The study focuses on domain adaptation and performance on clean datasets, leaving open questions about the model's robustness to real-world challenges.
- What evidence would resolve it: Experiments testing the semi-supervised model's performance on noisy, occluded, or domain-shifted images, with comparisons to fully supervised models.

## Limitations
- Reliance on small MobileNetV2 backbone may restrict performance on complex line detection tasks
- Modified CutMix may not generalize well to datasets with predominantly horizontal or vertical lines
- Consistency regularization assumes strong augmentations preserve line structure without quantitative analysis

## Confidence
- High confidence in consistency regularization effectiveness (sAP10 improvements: 31.1 vs 7.8 on Finnwoodlands 1/16 split)
- Medium confidence in modified CutMix design (supported by ablation but lacks comparison to alternatives)
- Medium confidence in domain generalization claims (performance shown but cross-domain robustness not extensively tested)

## Next Checks
1. Augmentation Sensitivity Analysis: Systematically vary augmentation strength and measure impact on consistency loss effectiveness and final sAP10 scores
2. Backbone Scaling Study: Replace MobileNetV2 with larger backbones (ResNet-50, EfficientNet-B3) to quantify performance trade-offs
3. Cross-Domain Transfer Test: Train on one dataset (Wireframe) and evaluate on completely different line detection tasks (architectural drawings, road networks)