---
ver: rpa2
title: Causal prompting model-based offline reinforcement learning
arxiv_id: '2406.01065'
source_url: https://arxiv.org/abs/2406.01065
tags:
- learning
- causal
- offline
- policy
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of applying offline reinforcement
  learning to medical decision-making systems, where datasets are highly suboptimal
  (noisy, incomplete) and diverse due to varying patient populations. The authors
  propose the Causal Prompting Reinforcement Learning (CPRL) framework, which integrates
  invariant causal prompts with a hierarchical policy that learns reusable skills.
---

# Causal prompting model-based offline reinforcement learning

## Quick Facts
- arXiv ID: 2406.01065
- Source URL: https://arxiv.org/abs/2406.01065
- Authors: Xuehui Yu; Yi Guan; Rujia Shen; Xin Li; Chen Tang; Jingchi Jiang
- Reference count: 10
- Primary result: CPRL outperforms state-of-the-art RL baselines on noisy, diverse medical datasets using invariant causal prompts and skill reuse

## Executive Summary
This paper addresses the challenge of applying offline reinforcement learning to medical decision-making systems, where datasets are highly suboptimal (noisy, incomplete) and diverse due to varying patient populations. The authors propose the Causal Prompting Reinforcement Learning (CPRL) framework, which integrates invariant causal prompts with a hierarchical policy that learns reusable skills. Central to the method is the Hidden-Parameter Block Causal Prompting Dynamic (Hip-BCPD) model, which uses causal knowledge to adapt across different patient environments without introducing additional parameters. Experiments on both simulation and a newly released real-world medical dataset from the Dnurse app show that CPRL outperforms state-of-the-art RL baselines, demonstrating robust performance in noisy and out-of-distribution settings.

## Method Summary
The CPRL framework combines invariant causal prompts with a hierarchical policy to address offline RL challenges in medical domains. The core component is the Hip-BCPD model, which reconstructs states from observations using pre-trained causal prompts and hidden parameters that encode patient-specific traits. A hierarchical CCM policy decomposes tasks into subsystems, learning reusable skills that can be transferred across similar environments. The method employs model ensemble regularization, where multiple Hip-BCPDs are trained independently and policy updates are accepted only if performance improves on a sufficient fraction (70%) of ensemble models. The framework is evaluated on both simulated data with varying noise levels and a real-world medical dataset from the Dnurse app.

## Key Results
- CPRL achieves higher normalized single-step average reward compared to state-of-the-art RL baselines on both simulated and real-world medical datasets
- The method demonstrates robust performance in out-of-distribution and noisy environments, with consistent improvements across 6 random seeds
- Ablation studies confirm the effectiveness of Hip-BCPDs and the skill-reuse strategy in improving generalization and robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hip-BCPDs mitigate overfitting to noisy data by aligning hidden parameters with task-specific causal structures while keeping causal prompts invariant.
- Mechanism: Causal prompts derived from a pre-trained glucose-insulin model act as templates to reconstruct states from observations. Hidden parameters θ encode patient-specific traits, allowing the dynamic model to generalize across diverse environments without introducing extra learnable parameters.
- Core assumption: The underlying causal structure (graph edges) is invariant across tasks, but hidden parameters vary by environment.
- Evidence anchors:
  - [abstract]: "Hidden-Parameter Block Causal Prompting Dynamic (Hip-BCPD) to model environmental dynamics. This approach utilises invariant causal prompts and aligns hidden parameters to generalise to new and diverse online users."
  - [section]: "The Hip-BCPD assumes a shared causal graph amongst state variables across all environments and varying hidden parameters (θ in Figure 2(a)) among different environments."
  - [corpus]: Weak. Nearest neighbor papers discuss offline RL generalization but not specifically causal prompting or invariant graph structures.
- Break condition: If the causal structure changes between environments, the invariant prompt assumption fails, leading to poor reconstruction and generalization.

### Mechanism 2
- Claim: The hierarchical CCM policy with skill-reuse accelerates learning and improves generalization by decomposing the task into subsystems and reusing learned skills across tasks.
- Mechanism: The high-level policy partitions the Hip-BCPD into subsystems, each controlled by a low-level policy. Learned skills from one subsystem can be reused in others via forward-coupled reasoning, reducing the need to train from scratch for each new environment.
- Core assumption: Subsystems are internally independent and their solutions are reusable across similar tasks.
- Evidence anchors:
  - [abstract]: "a single policy is trained to address multiple tasks through the amalgamation of reusable skills, circumventing the need for training from scratch."
  - [section]: "The high-level policy divides a CGD into K sub-CGDs and generates a strategy to reuse optimal skills automatically, and the low-level policy learns the skill of controlling a sub-CGD stably."
  - [corpus]: Weak. Closest neighbors discuss offline RL and generalization but not hierarchical skill-reuse strategies tied to causal graph decomposition.
- Break condition: If subsystem independence assumption is violated (e.g., high coupling), skill reuse may fail and generalization will degrade.

### Mechanism 3
- Claim: Model ensemble prevents overfitting and stabilizes policy learning by evaluating performance across multiple independently trained Hip-BCPDs.
- Mechanism: Multiple Hip-BCPDs are trained on the same dataset with different initializations. Policy updates are accepted only if performance improves on a sufficient fraction (70%) of ensemble models, reducing exploitation of dataset-specific biases.
- Core assumption: Diverse models capture different aspects of data uncertainty; ensemble agreement signals robust generalization.
- Evidence anchors:
  - [abstract]: "Experiments conducted across datasets with varying levels of noise...demonstrate that our proposed method can make robust decisions in out-of-distribution and noisy environments, outperforming contemporary algorithms."
  - [section]: "First, we construct a set of Hip-BCPDs {Tψ1 , ..., TψM } (referred to as a model ensemble)...Should the ratio fall below 70% across five gradient updates...the current iteration will be concluded."
  - [corpus]: Weak. Nearest neighbor papers discuss offline RL generalization but not ensemble-based uncertainty regularization.
- Break condition: If ensemble members converge to similar biases (e.g., due to limited diversity), the regularization effect is lost.

## Foundational Learning

- Concept: Hidden-Parameter Block MDPs (Hip-BMDPs)
  - Why needed here: Hip-BMDPs provide the formal framework for modeling environments with latent task parameters, which is essential for generalizing across diverse patient populations in medical RL.
  - Quick check question: What is the difference between the state space and observation space in a Hip-BMDP, and how do hidden parameters affect them?

- Concept: Causal graph dynamics and invariance
  - Why needed here: Causal invariance allows the model to generalize across environments where the causal relationships remain stable, even if parameters change.
  - Quick check question: How does a causal graph structure enable the model to predict outcomes under interventions?

- Concept: Prompt learning with pre-trained models
  - Why needed here: Prompt learning allows rapid adaptation of the dynamic model using causal templates from a pre-trained glucose-insulin system, avoiding costly retraining from scratch.
  - Quick check question: How does the masked language modeling approach in prompt learning simplify dynamic model training?

## Architecture Onboarding

- Component map: Hip-BCPD -> Masked model PΘ -> CCM hierarchical policy -> Model ensemble
- Critical path:
  1. Pre-train causal prompts from glucose-insulin system
  2. Train Hip-BCPD on offline dataset to learn hidden parameters
  3. Train CCM policy on top of Hip-BCPD
  4. Use model ensemble to regularize training and prevent overfitting
  5. Evaluate policy on out-of-distribution and noisy test environments
- Design tradeoffs:
  - Causal prompts vs. end-to-end learning: Prompts reduce training complexity but require careful design
  - Skill reuse vs. task-specific training: Reusing skills speeds learning but may limit fine-tuning
  - Ensemble size vs. computational cost: Larger ensembles improve robustness but increase training time
- Failure signatures:
  - Poor generalization: Hidden parameters not properly aligned to environments
  - Slow learning: Subsystem independence assumption violated, hindering skill reuse
  - Overfitting: Model ensemble fails to capture data uncertainty, or Hip-BCPD fits noise
- First 3 experiments:
  1. Test Hip-BCPD reconstruction accuracy on synthetic noisy data with known ground truth
  2. Validate CCM skill reuse by training on a simple hierarchical task and transferring to a similar task
  3. Evaluate ensemble regularization by training with and without ensemble on a noisy offline dataset

## Open Questions the Paper Calls Out

- Question: How can the causal prompt template be generalized across diverse medical domains beyond glucose-insulin systems?
  - Basis in paper: [explicit] The paper derives the causal prompt from a publicly accessible glucose-insulin system and notes this approach "might not be attainable in resource-limited situations" for other domains
  - Why unresolved: The paper demonstrates the approach on one medical domain but does not explore whether the causal prompt methodology can be systematically applied to other physiological systems or medical decision-making tasks
  - What evidence would resolve it: Empirical validation showing successful application of the causal prompting approach across multiple distinct medical domains (e.g., cardiovascular, respiratory, neurological systems) with comparable performance improvements

## Limitations
- Limited empirical validation of causal invariance across diverse patient populations
- No characterization of Hip-BCPD ensemble diversity or failure modes when ensemble members converge to similar biases
- Potential violation of subsystem independence assumption in more complex medical systems

## Confidence
- Confidence in main claims: Medium
- Supporting evidence is primarily empirical rather than analytical
- The paper establishes correlation between proposed methods and improved robustness but lacks rigorous proof of why mechanisms work in medical domain

## Next Checks
1. Conduct systematic ablation studies to isolate the contribution of causal prompts vs. hidden parameters vs. ensemble regularization on out-of-distribution performance
2. Validate the subsystem independence assumption by measuring coupling strength between learned skills and testing skill transfer across different subsystem configurations
3. Test the causal invariance assumption by evaluating performance degradation when the underlying causal structure is deliberately perturbed in synthetic patient populations