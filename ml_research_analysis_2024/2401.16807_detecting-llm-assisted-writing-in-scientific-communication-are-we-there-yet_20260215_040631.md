---
ver: rpa2
title: 'Detecting LLM-assisted writing in scientific communication: Are we there yet?'
arxiv_id: '2401.16807'
source_url: https://arxiv.org/abs/2401.16807
tags:
- writing
- llm-assisted
- detectors
- text
- style
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study evaluated four state-of-the-art detectors for identifying
  LLM-assisted writing in scientific papers against a simple detector based on abrupt
  changes in writing style around the time of LLM proliferation. The four detectors
  performed poorly, achieving 54.6%-63.7% accuracy and 0.29-0.60 F1 score on a small
  test set of 22 papers.
---

# Detecting LLM-assisted writing in scientific communication: Are we there yet?

## Quick Facts
- arXiv ID: 2401.16807
- Source URL: https://arxiv.org/abs/2401.16807
- Authors: Teddy Lazebnik; Ariel Rosenfeld
- Reference count: 16
- The study evaluated four state-of-the-art detectors for identifying LLM-assisted writing in scientific papers against a simple detector based on abrupt changes in writing style around the time of LLM proliferation. The four detectors performed poorly, achieving 54.6%-63.7% accuracy and 0.29-0.60 F1 score on a small test set of 22 papers. In contrast, the simple writing style change detector achieved 72.7% accuracy and 0.70 F1 score, with a much lower false positive rate of 3.1%. The results indicate that existing LLM-generated text detectors are suboptimal for detecting LLM-assisted writing, highlighting the need for specialized detectors focused on this task.

## Executive Summary
This study evaluates the performance of four cutting-edge detectors for identifying LLM-assisted writing in scientific communication, comparing them against a simple ad-hoc detector designed to identify abrupt writing style changes around the time of LLM proliferation. The four state-of-the-art detectors (DetectLLM, Zippy, LLMDet, and ConDA) were originally designed for detecting pure LLM-generated text and were found to perform poorly on the task of detecting LLM-assisted writing, achieving only 54.6%-63.7% accuracy and 0.29-0.60 F1 score on a small test set of 22 papers. In contrast, the simple writing style change detector, which identifies authors whose writing style changes abruptly around the time of LLM proliferation, achieved 72.7% accuracy and 0.70 F1 score with a much lower false positive rate of 3.1%. These results indicate that existing LLM-generated text detectors are suboptimal for detecting LLM-assisted writing and highlight the need for specialized detectors exclusively dedicated to this task.

## Method Summary
The study evaluated four existing LLM-generated text detectors (DetectLLM, Zippy, LLMDet, and ConDA) by applying them to a small test set of 22 scientific papers (11 with acknowledged LLM use and 11 matched controls from 2021-2022). The detectors were tuned using grid search to find optimal decision thresholds. Additionally, a custom detector called LAW (Writing Style Change Detector) was implemented based on the premise that sudden changes in an author's writing style around the time of LLM proliferation could indicate LLM-assisted writing. The LAW detector modeled an author's writing style dynamics using pre-2022 publications, detected anomalies in 2023 publications, and compared the writing style delta vector with LLM-generated text style using cosine similarity. The performance of all detectors was evaluated using accuracy and F1 score on the assessment set, as well as false positive rate on a set of 1,094 publications from 2022 or earlier.

## Key Results
- Four state-of-the-art detectors (DetectLLM, Zippy, LLMDet, ConDA) achieved 54.6%-63.7% accuracy and 0.29-0.60 F1 score on the test set of 22 papers
- The simple writing style change detector achieved 72.7% accuracy and 0.70 F1 score with a much lower false positive rate of 3.1%
- Existing detectors were originally designed for pure LLM-generated text detection, not LLM-assisted writing detection
- The LAW detector's performance suggests the need for specialized detectors exclusively dedicated to LLM-assisted writing detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simple writing style change detection outperforms complex LLM-generated text detectors for identifying LLM-assisted writing.
- Mechanism: The detector identifies authors whose writing style changes abruptly around the time of LLM proliferation, and attributes these changes to LLM assistance based on similarity between the delta vector and LLM-generated text style.
- Core assumption: A sudden change in writing style that aligns with LLM writing characteristics is indicative of LLM-assisted writing.
- Evidence anchors:
  - [abstract]: "Our evaluation of four cutting-edge LLM-generated text detectors reveals their suboptimal performance compared to a simple ad-hoc detector designed to identify abrupt writing style changes around the time of LLM proliferation."
  - [section]: "The approach is based on the premise that a sudden change in one's writing style around the time of LLM proliferation could potentially indicate LLM-assisted writing, especially if the change aligns with LLM writing style."
  - [corpus]: Weak evidence - corpus neighbors focus on detecting LLM-generated text or keystroke dynamics, not writing style change patterns.
- Break condition: If authors frequently change writing styles for legitimate reasons (e.g., different paper types, co-authorship changes) that aren't related to LLM use.

### Mechanism 2
- Claim: Existing detectors perform poorly because they were designed for pure LLM-generated text detection, not LLM-assisted writing detection.
- Mechanism: Detectors trained to distinguish between human and LLM-generated text fail when applied to texts that are predominantly human-written but contain LLM assistance.
- Core assumption: The task of detecting LLM-assisted writing is fundamentally different from detecting pure LLM-generated text.
- Evidence anchors:
  - [abstract]: "These detectors need not necessarily be proficient in detecting LLM-assisted writing, as they were not originally designed for this purpose."
  - [section]: "Our findings reveal subpar performance, raising substantial concerns regarding the practical value of using these models to detect potentially undisclosed LLM-assisted writing."
  - [corpus]: Weak evidence - corpus focuses on various detection methods but doesn't directly address the distinction between pure LLM-generated and LLM-assisted text detection.
- Break condition: If existing detectors can be retrained or adapted to handle the mixed nature of LLM-assisted writing.

### Mechanism 3
- Claim: The writing style change detector achieves better results due to its specific focus on the temporal aspect of LLM proliferation.
- Mechanism: By training on pre-2022 publications (assumed to be LLM-free) and testing on 2023 publications, the detector captures the transition period when LLM use became prevalent.
- Core assumption: The period around 2022-2023 marks a clear boundary for LLM influence on academic writing.
- Evidence anchors:
  - [section]: "we use the most recent publications made in or before 2022 (i.e., free of LLM influences) for modeling the author's writing style dynamics."
  - [section]: "at the inference phase, for a given publication made in 2023 by a, we use a na√Øve anomaly detection approach"
  - [corpus]: Weak evidence - corpus neighbors don't address temporal aspects of LLM detection.
- Break condition: If LLM use became prevalent gradually rather than abruptly around 2022-2023, or if authors adopted LLMs at different times.

## Foundational Learning

- Concept: Anomaly detection in time-series data
  - Why needed here: The detector uses anomaly detection to identify unusual changes in writing style patterns over time.
  - Quick check question: What statistical method does the detector use to determine if a publication's writing style is anomalous compared to an author's previous work?

- Concept: Cosine similarity for text vector comparison
  - Why needed here: The detector uses cosine similarity to compare the writing style delta vector with the style vector of LLM-generated text.
  - Quick check question: How does the detector determine whether the similarity between the delta vector and LLM text style is significant enough to classify as LLM-assisted?

- Concept: Writing style feature extraction
  - Why needed here: The detector relies on extracting writing style features to model and compare author styles over time.
  - Quick check question: What specific writing style features might be extracted to capture an author's unique writing patterns?

## Architecture Onboarding

- Component map:
  - Data collection module (pre-2022 publications for training, 2023 publications for inference)
  - Writing style modeling component (calculates average change and standard deviation in style features)
  - Anomaly detection system (identifies publications with significant style deviations)
  - LLM generation module (generates text for style comparison)
  - Similarity calculation engine (computes cosine similarity between delta vectors and LLM text style)

- Critical path:
  1. Collect author's pre-2022 publications
  2. Model writing style dynamics (Avg(a) and STD(a))
  3. Analyze 2023 publication for anomalies
  4. Generate LLM text for comparison
  5. Calculate similarity and make classification decision

- Design tradeoffs:
  - Specificity vs. sensitivity: Higher thresholds reduce false positives but may miss subtle LLM assistance
  - Temporal window: Wider windows capture more style changes but may include non-LLM influences
  - Feature selection: More features may improve accuracy but increase computational complexity

- Failure signatures:
  - High false positive rate: May indicate overly sensitive anomaly detection or inappropriate threshold
  - Low detection rate: Could suggest insufficient training data or need for different writing style features
  - Inconsistent results across authors: May indicate need for author-specific calibration

- First 3 experiments:
  1. Test the detector on a known set of publications with varying degrees of LLM assistance to establish baseline performance
  2. Compare detection rates using different writing style feature sets to identify optimal feature combination
  3. Evaluate the impact of different temporal windows (e.g., using 2021-2022 vs. just 2022 publications for training)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop specialized detectors that outperform the simple writing style change detector for LLM-assisted writing detection?
- Basis in paper: [explicit] The paper concludes that existing LLM-generated text detectors are suboptimal and calls for the development of specialized detectors exclusively dedicated to LLM-assisted writing detection.
- Why unresolved: The study only evaluated existing state-of-the-art detectors and a simple writing style change detector, which outperformed the former. There is no evidence that specialized detectors have been developed or tested.
- What evidence would resolve it: Development and evaluation of specialized detectors that achieve higher accuracy and lower false positive rates compared to the simple writing style change detector and existing LLM-generated text detectors.

### Open Question 2
- Question: What are the limitations and challenges in detecting LLM-assisted writing using writing style changes, and how can they be addressed?
- Basis in paper: [explicit] The paper acknowledges limitations of the writing style change detector, such as not being able to consider authors with limited publications prior to LLM proliferation and potential undetected LLM-assisted writing over time.
- Why unresolved: The study only presented a simple writing style change detector and did not explore ways to overcome its limitations or address the challenges in detecting LLM-assisted writing using this approach.
- What evidence would resolve it: Development of more advanced writing style change detectors that can handle authors with limited pre-LLM proliferation publications and detect gradual changes in writing style over time, along with evaluation of their performance.

### Open Question 3
- Question: How can we obtain a larger and more diverse dataset of LLM-assisted writing instances for evaluation purposes?
- Basis in paper: [explicit] The paper mentions that gathering more unsolicited instances of LLM-assisted writing is highly challenging due to authors' reluctance to explicitly report it.
- Why unresolved: The study relied on a small assessment set of 22 papers and a false-positive set of 1,094 publications. The limited size and potential bias in the dataset may affect the generalizability of the results.
- What evidence would resolve it: Creation of a large-scale dataset of LLM-assisted writing instances across various domains and disciplines, obtained through methods that encourage authors to disclose their LLM use or by analyzing patterns in writing style changes around the time of LLM proliferation.

## Limitations

- The study's findings are limited by the extremely small assessment set of only 22 papers, which constrains the statistical power and generalizability of the results.
- The detector's reliance on a specific temporal boundary (2022-2023) assumes a binary shift in LLM adoption that may not reflect gradual real-world adoption patterns.
- The writing style change detector's performance depends heavily on the quality of writing style feature extraction and the assumption that style changes around 2022 are primarily attributable to LLM use rather than other factors like evolving writing conventions or changing co-authorship patterns.

## Confidence

**High Confidence**: The finding that existing detectors perform poorly on LLM-assisted writing detection is well-supported by the comparative evaluation results, showing substantial differences in accuracy (54.6%-63.7% vs. 72.7%) and F1 scores (0.29-0.60 vs. 0.70).

**Medium Confidence**: The superiority of the simple writing style change detector is supported by the results but requires validation on larger datasets to confirm generalizability beyond the small test set used.

**Low Confidence**: The mechanism explanation for why existing detectors fail (their design for pure LLM detection vs. LLM-assisted writing) is theoretically sound but not empirically tested through direct comparison or adaptation of existing models to the new task.

## Next Checks

1. **Scale validation**: Test the writing style change detector on a significantly larger dataset (minimum 100+ papers with verified LLM use) to confirm whether the performance advantage persists with increased statistical power.

2. **Temporal validation**: Evaluate the detector's performance across different time windows (e.g., using 2021-2023 vs. just 2022-2023 publications) to assess whether the 2022 boundary assumption is critical to performance or whether the method generalizes across gradual adoption patterns.

3. **Feature ablation study**: Systematically remove or modify individual writing style features in the detector to identify which features contribute most to detection performance and whether simpler feature sets maintain comparable accuracy.