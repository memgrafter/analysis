---
ver: rpa2
title: Knowledge Authoring with Factual English, Rules, and Actions
arxiv_id: '2411.06253'
source_url: https://arxiv.org/abs/2411.06253
tags:
- role
- kalm
- sentence
- word
- patient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This dissertation introduces novel approaches to knowledge authoring
  that significantly enhance the expressiveness and usability of knowledge representation
  systems. The primary contributions include extending KALM to factual English (KALM
  FL), which reduces grammatical restrictions while maintaining high accuracy in knowledge
  authoring.
---

# Knowledge Authoring with Factual English, Rules, and Actions

## Quick Facts
- **arXiv ID**: 2411.06253
- **Source URL**: https://arxiv.org/abs/2411.06253
- **Reference count**: 0
- **Primary result**: Novel approaches to knowledge authoring that extend KALM to factual English (KALM FL), enable rule and action authoring (KALM RA), and optimize disambiguation with up to 68% runtime reduction while maintaining 95-100% accuracy

## Executive Summary
This dissertation introduces significant advancements in knowledge authoring systems by extending KALM to factual English (KALM FL), which reduces grammatical restrictions while maintaining high accuracy. The work enables users to author knowledge using natural language sentences, rules, and actions without requiring expertise in logical formalisms. Building upon KALM FL, KALM RA supports authoring of rules and actions using factual sentences, enabling multi-step reasoning and temporal knowledge representation. The dissertation also addresses runtime inefficiencies in KALM-based systems through two optimized disambiguation approaches (RelBERT-based and SBERT-based), achieving substantial performance improvements while maintaining or improving accuracy. These contributions represent significant progress in making knowledge authoring more accessible, efficient, and expressive.

## Method Summary
The approach extends KALM to factual English (KALM FL) by using mStanza, a neural parser that generates multi-best dependency parses, combined with factual sentence validation and paraparsing to handle grammatical flexibility while maintaining semantic accuracy. KALM RA builds upon KALM FL to support rule and action authoring through integration with F-logic and Simplified Event Calculus, enabling temporal reasoning and multi-step inference. To address runtime inefficiencies, the dissertation proposes RelBERT-based and SBERT-based disambiguation approaches that replace BabelNet-based semantic path search with neural embedding similarity calculations. The method uses a pipeline where factual sentences are parsed by mStanza, validated against factual properties, normalized through paraparsing, converted to logical representations, and stored in a DLV database for reasoning. Evaluation uses controlled datasets including UTI guidelines and bAbI tasks to measure accuracy and runtime performance.

## Key Results
- KALM FL achieves 95% accuracy on fact and query authoring while significantly reducing grammatical restrictions compared to ACE
- KALM RA achieves 100% accuracy on rule authoring and 99.3% accuracy on authoring and reasoning with actions
- Optimized disambiguation approaches (RelBERT-based and SBERT-based) achieve up to 68% runtime reduction while maintaining or improving accuracy
- The optimized approaches approximately triple the speed of the disambiguation process compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: KALM FL significantly reduces grammatical restrictions by extending factual English beyond ACE's controlled natural language constraints.
- **Mechanism**: Replaces the ACE-based syntactic parser (APE) with mStanza, which uses multi-best dependency parses to enable more flexible grammatical structures while maintaining semantic accuracy.
- **Core assumption**: Multi-best dependency parsing with factual sentence constraints can achieve high semantic accuracy without ACE's grammatical restrictions.
- **Evidence anchors**:
  - [abstract] "KALM FL uses a neural parser for natural language, m Stanza, to parse what we call factual English sentences, which require little grammar training to use."
  - [section 3.3] "KALM FL uses mStanza instead of APE as the syntactic parser and includes two additional key steps (Error Detection and Correction, and Paraparsing) to tackle a slew of problems caused by the use of m Stanza."
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.428, average citations=0.0. Top related titles: KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning.

### Mechanism 2
- **Claim**: RelBERT-based and SBERT-based disambiguation approaches significantly improve runtime efficiency while maintaining or improving accuracy.
- **Mechanism**: Replaces BabelNet-based semantic path search with neural embedding similarity calculations for role-filler disambiguation, eliminating expensive graph traversal operations.
- **Core assumption**: Neural embeddings can capture semantic relationships between roles and fillers with sufficient accuracy to replace BabelNet's synset-based disambiguation.
- **Evidence anchors**:
  - [abstract] "two optimized disambiguation approaches—RelBERT-based and SBERT-based—were proposed, achieving up to 68% runtime reduction while maintaining or improving accuracy."
  - [section 5.3.2] "The revised approaches demonstrated significantly faster performance. Specifically, RBD reduces the runtime by approximately 55% compared to the baseline approach, while SBD approximately triples the speed of the process."
  - [corpus] Weak - corpus doesn't directly address disambiguation speed improvements.

### Mechanism 3
- **Claim**: KALM RA extends KALM FL to handle rules and actions through integration with Event Calculus and disjunctive logic programming.
- **Mechanism**: Maps factual English sentences describing rules and actions to SEC axioms and DLV disjunctive logic programming rules, enabling temporal reasoning and multi-step inference.
- **Core assumption**: SEC axioms can be effectively expressed as factual English sentences that KALM RA can parse and translate into executable logical rules.
- **Evidence anchors**:
  - [abstract] "Building upon KALMFL, we propose KALM for Rules and Actions (KALMRA), to represent and reason with rules and actions."
  - [section 4.1.2] "KALMRA supports two types of negation in rules: explicit negation and negation as failure (with the stable model semantics)."
  - [corpus] Weak - corpus doesn't directly address SEC integration or rule authoring capabilities.

## Foundational Learning

- **Concept**: Factual sentences as a subset of English for knowledge authoring
  - **Why needed here**: Provides the grammatical foundation that allows KALM FL to move beyond ACE's restrictions while maintaining semantic accuracy
  - **Quick check question**: What distinguishes a factual sentence from other English sentences in the context of knowledge authoring?

- **Concept**: Dependency parsing and universal dependencies
  - **Why needed here**: Essential for mStanza to generate and analyze syntactic structures that KALM FL uses for semantic interpretation
  - **Quick check question**: How do universal dependency labels help KALM FL identify the grammatical roles in factual sentences?

- **Concept**: Semantic frames and role-filler relationships
  - **Why needed here**: Core to KALM's frame-based parsing approach that maps English sentences to logical representations
  - **Quick check question**: What is the relationship between a semantic frame, its roles, and role-fillers in KALM's knowledge representation?

## Architecture Onboarding

- **Component map**: Factual sentence → mStanza parsing → factual validation → paraparsing → frame-based parsing → role-filler disambiguation → unique logical representation → DLV storage → query reasoning

- **Critical path**: Factual sentence → mStanza parsing → factual validation → paraparsing → frame-based parsing → role-filler disambiguation → unique logical representation → DLV storage → query reasoning

- **Design tradeoffs**: Flexibility vs. accuracy (more flexible grammar increases parsing ambiguity), speed vs. precision (neural embeddings vs. BabelNet), expressiveness vs. complexity (factual English vs. full English)

- **Failure signatures**: Parse failures (factual sentence validation fails), disambiguation failures (multiple candidate parses with similar scores), semantic mismatch (equivalent meanings parsed differently), runtime bottlenecks (disambiguation step)

- **First 3 experiments**:
  1. Test mStanza on CNLD dataset to verify factual sentence parsing accuracy
  2. Implement RelBERT disambiguation on CNLDM dataset to measure runtime improvement
  3. Run KALM RA on bAbI Task 2 to verify action reasoning capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What is the maximum grammatical complexity of factual sentences that KALM FL can handle without losing accuracy?
- **Basis in paper**: [explicit] Section 3.4.1 mentions that NLD sentences "go beyond factual sentences" but KALM FL still achieves 0.99 accuracy, suggesting a boundary exists.
- **Why unresolved**: The paper doesn't define clear boundaries or test cases at the edge of factual sentence complexity.
- **What evidence would resolve it**: Systematic testing of increasingly complex sentence structures (nested clauses, coordination, passive voice) to identify the point where accuracy drops below 95%.

### Open Question 2
- **Question**: How does the performance of RBD and SBD compare to BabelNet-based disambiguation when extended to handle word-sense level disambiguation?
- **Basis in paper**: [inferred] Section 5.1.2 and 5.2 acknowledge that RBD and SBD don't use BabelNet synsets but suggest a synset-like system could be developed for fair comparison.
- **Why unresolved**: The paper only compares frame-level and role-level accuracy, not word-sense level accuracy where BabelNet excels.
- **What evidence would resolve it**: Development of a synset-like clustering system for RBD/SBD definitions and direct comparison of word-sense disambiguation accuracy against BabelNet-based approach.

### Open Question 3
- **Question**: What is the impact of using different coreference resolution tools on KALM RA's accuracy for compound coreference tasks?
- **Basis in paper**: [explicit] Section 4.3.2 states that Task 13 (Compound Coreference) accuracy depends entirely on the output of neuralcoref, the coreference resolver used.
- **Why unresolved**: The paper only tested one coreference resolution tool and doesn't explore alternatives or improvements.
- **What evidence would resolve it**: Testing KALM RA with multiple coreference resolution tools (e.g., different neural models, rule-based systems) to determine if accuracy on Task 13 can be improved beyond 93.1%.

## Limitations
- Factual English constraint still requires users to learn specific grammatical patterns despite being more flexible than ACE
- Dependency on external APIs (BabelNet, GPT-4) creates potential scalability and cost concerns
- Performance of optimization techniques may degrade on knowledge domains with highly ambiguous role-filler relationships

## Confidence
- **KALM FL accuracy claims**: High (95% accuracy on controlled datasets with systematic evaluation)
- **KALM RA rule/action authoring**: High (100% accuracy on rule authoring, 99.3% on action reasoning)
- **Runtime optimization results**: Medium (68% improvement shown but may not generalize across all domains)
- **Real-world applicability**: Medium (evaluation primarily on synthetic/narrow-domain datasets)

## Next Checks
1. Test KALM FL on diverse real-world knowledge authoring tasks beyond controlled datasets to evaluate practical usability and error rates.
2. Compare RelBERT and SBERT disambiguation approaches against alternative neural embedding methods on datasets with high semantic ambiguity.
3. Evaluate the scalability of KALM RA with large knowledge bases containing thousands of rules and actions to identify potential performance bottlenecks.