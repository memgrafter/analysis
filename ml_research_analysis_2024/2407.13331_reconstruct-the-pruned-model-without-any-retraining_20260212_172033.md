---
ver: rpa2
title: Reconstruct the Pruned Model without Any Retraining
arxiv_id: '2407.13331'
source_url: https://arxiv.org/abs/2407.13331
tags:
- pruning
- arxiv
- liar
- reconstruction
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LIAR, a linear interpolation-based adaptive
  reconstruction framework for structured pruning of large language models without
  retraining. LIAR reformulates the reconstruction problem as estimating pruned outputs
  using preserved modules, minimizing reconstruction error via linear interpolation
  of weight matrices.
---

# Reconstruct the Pruned Model without Any Retraining

## Quick Facts
- arXiv ID: 2407.13331
- Source URL: https://arxiv.org/abs/2407.13331
- Reference count: 40
- Primary result: LIAR achieves 98% accuracy on BERT with 50% parameters pruned without retraining

## Executive Summary
This paper introduces LIAR, a linear interpolation-based adaptive reconstruction framework for structured pruning of large language models without retraining. LIAR reformulates the reconstruction problem as estimating pruned outputs using preserved modules, minimizing reconstruction error via linear interpolation of weight matrices. The method is both efficient (no back-propagation, few minutes on single GPU) and generalizable across different pruning criteria and model architectures.

Evaluated on BERT and LLaMA models across GLUE, SQuAD, WikiText, and common sense reasoning tasks, LIAR achieves 98% accuracy on BERT with 50% parameters pruned and improves LLaMA-7B performance by 2.56x under 50% pruning. The framework consistently outperforms state-of-the-art retraining-free methods, demonstrating robust generalization to various pruning modules and criteria while requiring minimal calibration data.

## Method Summary
LIAR is a retraining-free structured pruning framework that reconstructs pruned model outputs using linear interpolation of preserved weight matrices. The method estimates transformation matrices Q and P via least squares on calibration data, then applies these matrices to update preserved weights and biases to approximate the behavior of pruned components. This approach avoids backpropagation and retraining while maintaining high accuracy across various pruning criteria and model architectures.

## Key Results
- Achieves 98% accuracy on BERT with 50% parameters pruned
- Improves LLaMA-7B performance by 2.56x under 50% pruning ratio
- Maintains high accuracy (98%) even after removing 50% of BERT parameters
- Outperforms state-of-the-art retraining-free methods across multiple benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LIAR minimizes reconstruction error by estimating masked outputs using preserved modules via linear interpolation of weight matrices.
- Mechanism: Reformulates the reconstruction problem as estimating pruned outputs, then uses least squares to compute transformation matrices Q and P. These matrices capture correlations between preserved and pruned components, and linear interpolation updates preserved weights and biases to reconstruct masked outputs.
- Core assumption: The masked output can be approximated by a linear combination of preserved components.
- Evidence anchors:
  - [abstract] "By applying linear interpolation to the preserved weights, LIAR minimizes reconstruction error and effectively reconstructs the pruned output."
  - [section] "To address the issue of instability in certain channels, we propose to approximate the varying patterns that cannot be compensated by the averaged value. Specifically, we reconstruct the varying patterns of pruned channel k with a linear combination of the others..."
  - [corpus] Weak - neighbors focus on oracle pruning and MoE, not on linear interpolation reconstruction.

### Mechanism 2
- Claim: LIAR generalizes across different pruning criteria and model architectures without retraining.
- Mechanism: Uses least squares estimation to derive transformation matrices from preserved components to masked components. This estimation is independent of the pruning criterion used, enabling compatibility with various pruning methods.
- Core assumption: The transformation matrices Q and P can be reliably estimated from calibration data regardless of which pruning criterion was used.
- Evidence anchors:
  - [abstract] "LIAR does not require back-propagation or retraining and is compatible with various pruning criteria and modules."
  - [section] "Figure 4 shows that LIAR significantly improves performance under all pruning ratios compared to simple pruning without any reconstruction. Furthermore, LIAR reduces the gap between different pruning metrics..."
  - [corpus] Weak - corpus neighbors discuss different pruning approaches but don't address generalization across criteria via linear interpolation.

### Mechanism 3
- Claim: LIAR achieves computational efficiency by requiring only forward passes and linear algebra operations, avoiding backpropagation and retraining.
- Mechanism: Uses calibration dataset to estimate transformation matrices via least squares (forward pass only), then applies matrix operations to update weights and biases. No gradient computation or iterative optimization required.
- Core assumption: Matrix operations and least squares estimation are computationally cheaper than backpropagation and retraining.
- Evidence anchors:
  - [abstract] "LIAR does not require back-propagation or retraining and is compatible with various pruning criteria and modules."
  - [section] "Table 5 shows that the time required increases with both model size and the number of samples. Notably, LIAR consistently demonstrates low time costs on larger models, particularly completing tasks with the LLaMA-7B model in just under one minute."
  - [corpus] Weak - corpus neighbors discuss pruning efficiency but not specifically the computational advantage of linear interpolation over retraining.

## Foundational Learning

- Concept: Linear algebra and least squares estimation
  - Why needed here: LIAR relies on solving least squares problems to estimate transformation matrices Q and P that capture relationships between preserved and pruned components
  - Quick check question: Can you explain how the least squares solution Q = (X^T X)^-1 X^T Y finds the best linear approximation of Y using X?

- Concept: Structured pruning and mask operations
  - Why needed here: Understanding how structured pruning removes entire groups of weights (heads, neurons, etc.) and how masks define which components are preserved vs. pruned is essential for implementing LIAR
  - Quick check question: What's the difference between structured pruning and unstructured pruning, and why does LIAR focus on structured pruning?

- Concept: Model architecture of transformers (BERT, LLaMA)
  - Why needed here: LIAR operates on specific transformer components (attention heads, FFN neurons) and understanding the layer structure is crucial for proper implementation
  - Quick check question: How do the attention mechanism and feed-forward network in a transformer layer differ in terms of their role and parameter structure?

## Architecture Onboarding

- Component map:
  - Input layer: Calibration dataset D for estimating transformation matrices
  - Processing: For each layer ℓ, split weights Wℓ into preserved (Wℓ_u) and pruned (Wℓ_m) components based on mask Mℓ
  - Core algorithm: Compute transformation matrices Qℓ (input) and Pℓ (weight) via least squares
  - Output layer: Updated weight matrix (I + QℓPℓ)Wℓ_u and bias Xℓ_m Wℓ_m + Bℓ
  - Final model: Pruned model S with reconstructed outputs

- Critical path:
  1. Load pre-trained model M and calibration dataset D
  2. For each layer ℓ in M:
     a. Split Xℓ and Wℓ into preserved and pruned components
     b. Estimate Qℓ and Pℓ using least squares
     c. Update weight and bias using linear interpolation
     d. Collect hidden input Xℓ+1 for next layer
  3. Return pruned and reconstructed model S

- Design tradeoffs:
  - Accuracy vs. computation: More calibration samples improve matrix estimation accuracy but increase computation time
  - Generalization vs. specificity: Linear interpolation provides good generalization across pruning criteria but may not capture nonlinear relationships
  - Memory vs. speed: Loading model in 16-bit format saves memory but may slightly reduce numerical precision

- Failure signatures:
  - High reconstruction error in specific layers indicates poor matrix estimation
  - Performance degradation after pruning suggests calibration dataset is unrepresentative
  - Instability across different pruning ratios indicates sensitivity to pruning criteria

- First 3 experiments:
  1. Test LIAR on a single BERT layer with synthetic data where the ground truth transformation is known
  2. Apply LIAR to prune 10% of FFN neurons in BERT on GLUE tasks and compare with naive pruning
  3. Evaluate LIAR's sensitivity to calibration dataset size by varying from 128 to 1024 samples on LLaMA-7B

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does LIAR's performance scale with even higher pruning ratios (e.g., 70-90%) on both BERT and LLaMA models?
- Basis in paper: [explicit] The paper demonstrates LIAR's effectiveness up to 50% pruning but does not explore higher ratios, stating it "maintains 98% accuracy even after removing 50% of its parameters" and achieves "2.56× performance enhancement for LLaMA-7B under the 50% pruning ratio."
- Why unresolved: The paper's experimental results are limited to 50% pruning, leaving uncertainty about LIAR's robustness at extreme compression levels where model degradation becomes more severe.
- What evidence would resolve it: Empirical results showing accuracy/retention metrics for BERT and LLaMA models at 70%, 80%, and 90% pruning ratios across multiple tasks would clarify LIAR's practical limits.

### Open Question 2
- Question: Can LIAR be effectively combined with quantization techniques for further model compression?
- Basis in paper: [explicit] The paper mentions LIAR is "orthogonal and compatible with quantization for further compression" but does not provide experimental validation of this combination.
- Why unresolved: While theoretical compatibility is claimed, no empirical evidence demonstrates whether LIAR+quantization yields better results than either technique alone or introduces new challenges.
- What evidence would resolve it: Experiments comparing model performance, memory usage, and inference speed when applying LIAR followed by quantization versus quantization alone or other compression combinations.

### Open Question 3
- Question: How sensitive is LIAR to the choice and size of the calibration dataset across different domains and tasks?
- Basis in paper: [explicit] The paper shows LIAR requires minimal calibration data ("only requires a small calibration dataset") and tests robustness with varying sample sizes, but doesn't explore domain/task-specific variations in calibration data requirements.
- Why unresolved: The experiments use general benchmarks, but real-world deployment may involve specialized domains where calibration data characteristics differ significantly from the training distribution.
- What evidence would resolve it: Comparative studies applying LIAR to models fine-tuned on specialized domains (medical, legal, technical) with calibration data from both in-domain and out-of-domain sources, measuring performance degradation and calibration data requirements.

## Limitations
- LIAR's effectiveness depends on the assumption that pruned outputs can be approximated by linear combinations of preserved components, which may fail for highly nonlinear relationships.
- The framework focuses specifically on structured pruning of attention heads and feed-forward neurons, with unexplored performance on other pruning granularities.
- While computational efficiency is demonstrated for LLaMA-7B, scaling behavior for extremely large models beyond this scale hasn't been validated.

## Confidence
- **High confidence**: Computational efficiency claim (no backpropagation, minimal calibration time) - well-supported by timing results across different model sizes.
- **Medium confidence**: Generalization across pruning criteria claim - supported by experiments showing LIAR improves performance regardless of pruning metric, but mechanism could be more thoroughly explained.
- **Medium confidence**: Performance improvement claims (98% BERT accuracy at 50% pruning, 2.56x improvement on LLaMA-7B) - based on extensive experiments but depend heavily on calibration dataset quality.

## Next Checks
1. **Sensitivity Analysis**: Systematically vary calibration dataset size from 64 to 4096 samples across different model scales (BERT-base, BERT-large, LLaMA-7B, LLaMA-13B) to identify minimum effective sample size and quantify trade-off between calibration cost and reconstruction quality.

2. **Nonlinearity Stress Test**: Design synthetic test cases where pruned components have known nonlinear relationships with preserved components that cannot be captured by linear interpolation. Measure reconstruction error on these cases to establish boundaries of LIAR's effectiveness.

3. **Cross-Criteria Transferability**: Apply LIAR trained on one pruning criterion (e.g., L1-norm) to models pruned with a different criterion (e.g., movement pruning) to test whether transformation matrices can generalize across pruning methods without recalibration.