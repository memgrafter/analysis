---
ver: rpa2
title: Distributed Thompson sampling under constrained communication
arxiv_id: '2410.15543'
source_url: https://arxiv.org/abs/2410.15543
tags:
- regret
- bayesian
- sampling
- agents
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a distributed Thompson sampling algorithm for
  multi-agent Bayesian optimization under constrained communication. The algorithm
  allows each agent to use its own Gaussian process model to sample points and share
  information only with neighbors in a communication graph.
---

# Distributed Thompson sampling under constrained communication

## Quick Facts
- arXiv ID: 2410.15543
- Source URL: https://arxiv.org/abs/2410.15543
- Reference count: 40
- This paper proposes a distributed Thompson sampling algorithm for multi-agent Bayesian optimization under constrained communication.

## Executive Summary
This paper introduces a distributed Thompson sampling algorithm for multi-agent Bayesian optimization where agents share information only with neighbors in a communication graph. Each agent maintains its own Gaussian process model and samples points from the posterior distribution, sharing these samples with connected neighbors. The algorithm provides theoretical regret bounds that depend on graph structure, specifically the clique cover number and clique number, showing faster convergence than sequential single-agent methods when the communication graph is connected.

## Method Summary
The method implements distributed Thompson sampling where each agent maintains its own Gaussian process (GP) model of the objective function and samples from the posterior distribution to select query points. Agents share their sampled points with neighbors according to a communication graph, allowing parallel exploration while maintaining theoretical guarantees. The regret bounds depend on graph-theoretic properties - specifically, the clique cover number affects average regret while the clique number affects simple regret. The algorithm decomposes the communication graph into disjoint complete subgraphs to analyze performance.

## Key Results
- Distributed Thompson sampling achieves faster convergence than sequential single-agent methods when the communication graph is connected
- Regret bounds scale with the clique cover number and clique number of the communication graph
- Numerical simulations on Rosenbrock and Ackley functions show regret decreases with higher graph connectivity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The distributed Thompson sampling algorithm achieves faster convergence than sequential single-agent Thompson sampling when the communication graph is connected, because agents can coordinate sampling through shared information without requiring full graph connectivity.
- **Mechanism**: Each agent maintains its own Gaussian process model and updates it with local data plus data received from neighbors. The Bayesian average regret bound depends on the clique cover number of the communication graph, meaning that better connectivity (smaller clique cover number) leads to faster convergence. The algorithm allows parallel sampling while still providing theoretical guarantees through information-theoretic bounds on regret.
- **Core assumption**: The communication graph is connected, and each agent can sample from its Gaussian process posterior and share points with neighbors within each time step.
- **Evidence anchors**:
  - [abstract]: "When compared to sequential single-agent Thompson sampling, our bound guarantees faster convergence with respect to time as long as the communication graph is connected."
  - [section]: "Our regret bound involves the Maximum Information Gain (MIG), which is a constant that captures the complexity of the objective function... We can construct a collection of n disjoint complete subgraphs {Gk}k∈{1,...,n}, where each Gk = (Vk, Ek) is a subgraph of G, with ∪k∈{1,...,n}Vk = V."
  - [corpus]: "The regret bounds show faster convergence compared to sequential single-agent Thompson sampling when the communication graph is connected."
- **Break condition**: If the communication graph becomes disconnected or if agents cannot reliably share sampled points with neighbors, the convergence guarantees break down because the theoretical bounds depend on graph connectivity.

### Mechanism 2
- **Claim**: The regret bounds scale favorably with graph structure, specifically with the clique cover number and clique number, allowing distributed agents to achieve better performance than centralized approaches when communication is constrained.
- **Mechanism**: The algorithm decomposes the communication graph into disjoint complete subgraphs (cliques), and the regret bound for each clique depends on its size. By selecting the clique cover number (minimum number of cliques needed to cover all agents), the overall regret bound improves as the graph becomes more connected. The largest clique size directly affects the simple regret bound.
- **Core assumption**: The communication graph can be decomposed into complete subgraphs, and the algorithm can leverage this structure to bound regret.
- **Evidence anchors**:
  - [section]: "Let {Gk}k∈{1,...,n} be a collection of n disjoint complete subgraphs of communication graph G = (V, E), where Gk = (Vk, Ek), and ∪k∈{1,...,n}Vk = V. Then the Bayesian average regret after t timesteps satisfies RAB(t) ≤ 1/M · Pn k=1 |Vk|(C1/t|Vk| + q(C2ξ|Vk|βtΨt|Vk|/t|Vk|))."
  - [section]: "We also characterize Bayesian simple regret, demonstrating a bound of ˜O(1/t|Vmax|), where |Vmax| is the size of the largest complete subgraph of the communication network G."
  - [corpus]: "Theoretical results provide bounds on Bayesian average regret and simple regret that depend on the structure of the communication graph, specifically the clique cover number and clique number."
- **Break condition**: If the graph structure changes dynamically or if the clique decomposition becomes inefficient (many small cliques), the theoretical advantages diminish.

### Mechanism 3
- **Claim**: The distributed approach maintains the exploration-exploitation balance of Thompson sampling while enabling parallel evaluation, leading to better sample efficiency than sequential methods.
- **Mechanism**: Each agent samples from its posterior Gaussian process (exploration) and selects the maximizer (exploitation). By sharing sampled points with neighbors, agents collectively explore the search space more efficiently than a single agent could. The parallel nature of the algorithm allows t total evaluations to be distributed across M agents, improving the effective sample rate.
- **Core assumption**: Thompson sampling's inherent exploration-exploitation balance translates effectively to the distributed setting when agents share information appropriately.
- **Evidence anchors**:
  - [abstract]: "In our distributed Thompson sampling implementation, each agent receives sampled points from neighbors, where the communication network is encoded in a graph; each agent utilizes their own Gaussian process to model the objective function."
  - [section]: "At each time step t, all agents update their GPs with the data history available to them. The agent then queries the objective function at xt,i, which is the maximizer of the acquisition function sampled from the posterior GP, ˆft,i ∼ GP t,i."
  - [corpus]: "The algorithm allows each agent to use its own Gaussian process model to sample points and share information only with neighbors in a communication graph."
- **Break condition**: If the Gaussian process models become too dissimilar across agents due to poor communication or if the parallel sampling disrupts the careful balance of exploration and exploitation, performance degrades.

## Foundational Learning

- **Concept**: Gaussian Processes and kernel functions
  - Why needed here: The algorithm relies on Gaussian processes to model the unknown objective function and make predictions about where to sample next. Understanding kernels is crucial because they define the function space and affect the information gain bounds.
  - Quick check question: What is the relationship between the kernel function choice and the Maximum Information Gain (MIG) term in the regret bounds?

- **Concept**: Thompson sampling and posterior sampling
  - Why needed here: The algorithm uses Thompson sampling to select query points by sampling from the posterior distribution of the Gaussian process. Understanding this sampling mechanism is essential for implementing the algorithm correctly.
  - Quick check question: How does Thompson sampling balance exploration and exploitation in the context of Bayesian optimization?

- **Concept**: Graph theory and connectivity
  - Why needed here: The theoretical guarantees depend on properties of the communication graph, specifically the clique cover number and clique number. Understanding these concepts is necessary to interpret the regret bounds and design effective communication topologies.
  - Quick check question: Why does a smaller clique cover number lead to better regret bounds in this distributed setting?

## Architecture Onboarding

- **Component map**: 
  - Gaussian Process Manager -> Thompson Sampler -> Communication Layer -> Regret Tracker
  - Graph Analyzer -> Regret Tracker

- **Critical path**: 
  1. Update GP models with local data and received neighbor data
  2. Sample from posterior distributions for each agent
  3. Find maximizers of sampled functions
  4. Query objective function at selected points
  5. Share sampled points with neighbors
  6. Update regret metrics

- **Design tradeoffs**:
  - Communication frequency vs. regret performance: More frequent sharing improves performance but increases communication cost
  - Model synchronization vs. autonomy: Tighter synchronization improves coordination but reduces agent independence
  - Exploration intensity vs. convergence speed: More aggressive exploration may find better optima but converge slower

- **Failure signatures**:
  - Degrading regret performance over time despite consistent communication
  - Large discrepancies between agent GP models indicating poor information sharing
  - Communication bottlenecks when many agents attempt to share simultaneously
  - Numerical instability in GP updates with too much or too little data

- **First 3 experiments**:
  1. Implement sequential single-agent Thompson sampling as baseline, verify regret bounds match theoretical predictions
  2. Add communication layer with synthetic data sharing, measure impact on regret convergence
  3. Test with different graph topologies (Erdős-Rényi with varying connectivity), compare regret performance to theoretical predictions

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes perfect communication without accounting for delays, packet loss, or asynchronous updates
- Regret bounds may become large for sparse or irregular communication graphs due to clique cover number scaling
- Computational complexity of Thompson sampling acquisition function maximization may be prohibitive for high-dimensional problems

## Confidence
- Theoretical claims: High
- Practical applicability: Medium
- Numerical simulations: Medium

## Next Checks
1. **Graph Structure Robustness**: Test the algorithm with dynamic communication graphs where connectivity changes over time, measuring how regret bounds degrade compared to the static case.

2. **High-Dimensional Scaling**: Implement the algorithm for higher-dimensional optimization problems (d > 10) and measure computational complexity of the Thompson sampling acquisition function maximization.

3. **Communication Overhead Analysis**: Quantify the communication cost (bandwidth and latency) required to achieve the theoretical regret improvements, comparing this to the actual performance gains.