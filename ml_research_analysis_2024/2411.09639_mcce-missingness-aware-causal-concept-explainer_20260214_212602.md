---
ver: rpa2
title: 'MCCE: Missingness-aware Causal Concept Explainer'
arxiv_id: '2411.09639'
source_url: https://arxiv.org/abs/2411.09639
tags:
- concepts
- concept
- causal
- mcce
- unobserved
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of estimating causal concept effects
  when some concepts are unobserved in the data. The authors demonstrate that unobserved
  concepts can bias causal effect estimation and introduce the Missingness-aware Causal
  Concept Explainer (MCCE) framework.
---

# MCCE: Missingness-aware Causal Concept Explainer

## Quick Facts
- arXiv ID: 2411.09639
- Source URL: https://arxiv.org/abs/2411.09639
- Reference count: 8
- Key outcome: MCCE achieves superior or comparable performance to baselines across multiple distance metrics when 1-2 concepts are unobserved in sentiment analysis tasks

## Executive Summary
This paper addresses the problem of estimating causal concept effects when some concepts are unobserved in the data. The authors demonstrate that unobserved concepts can bias causal effect estimation and introduce the Missingness-aware Causal Concept Explainer (MCCE) framework. MCCE constructs pseudo-concepts orthogonal to observed concepts to capture missing information, then uses a linear predictor to model relationships between concepts and model outputs. Tested on the CEBaB dataset for sentiment analysis, MCCE achieves superior or comparable performance to baselines including S-Learner and CPM across multiple distance metrics when 1-2 concepts are unobserved.

## Method Summary
MCCE addresses unobserved concept bias by constructing orthogonal pseudo-concepts that capture information orthogonal to observed concepts. The framework uses a linear predictor trained on both observed and pseudo-concepts to approximate black-box model outputs while providing unbiased causal effect estimates. The method involves extracting vector representations from input, computing projection matrices, creating pseudo-concepts via orthogonal projection, training a linear predictor, and using the trained model for causal effect estimation.

## Key Results
- MCCE achieves superior or comparable performance to baselines (S-Learner, CPM) across multiple distance metrics
- The method shows robust performance especially when evaluated using Cosine distance
- MCCE provides both local and global explanations and can function as an interpretable prediction model
- Performance remains stable with 1-2 unobserved concepts but degrades with more unobserved concepts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unobserved concepts introduce residual bias in causal effect estimation by leaving uncaptured components in the model output.
- Mechanism: When some concepts are unobserved, the linear model trained on only observed concepts cannot fully capture the output because it misses the contribution from unobserved concepts (CunÎ²un). This residual term biases the estimated coefficients for observed concepts.
- Core assumption: The relationship between concepts and model output is approximately linear, and the unobserved concepts have non-zero contribution to the output.
- Evidence anchors: [abstract] "We theoretically demonstrate that unobserved concepts can bias the estimation of the causal effects of observed concepts."

### Mechanism 2
- Claim: Orthogonal pseudo-concepts can capture information from unobserved concepts by projecting raw input onto the orthogonal complement of observed concepts.
- Mechanism: By constructing pseudo-concepts as (I - P)H where P is the projection matrix onto observed concepts, MCCE ensures these pseudo-concepts contain only information orthogonal to observed concepts. This orthogonal constraint prevents collinearity while capturing missing information.
- Core assumption: The raw input vector H contains all necessary information about all concepts, including unobserved ones, and the linear transformation can extract relevant information.
- Evidence anchors: [section] "These pseudo-concepts are then combined with the observed concepts to train a linear model that approximates the output of a black-box model."

### Mechanism 3
- Claim: The linear predictor trained on both observed and pseudo-concepts can approximate the black-box model output while providing unbiased causal effect estimates.
- Mechanism: By minimizing MSE between the black-box output and the linear combination of observed concepts and pseudo-concepts, MCCE learns coefficients that can explain the model behavior while accounting for unobserved concepts through pseudo-concepts.
- Core assumption: The linear combination of observed concepts and pseudo-concepts can approximate the black-box model output, and the pseudo-concepts effectively capture information from unobserved concepts.
- Evidence anchors: [section] "Empirical results show that our proposed MCCE achieves promising performance in estimating the Individual Concept Causal Effect Errors"

## Foundational Learning

- Concept: Causal inference and confounding
  - Why needed here: Understanding how unobserved confounders can bias causal effect estimates is fundamental to recognizing why MCCE's approach is necessary
  - Quick check question: If we have a treatment T and outcome Y, but an unobserved confounder C affects both, what happens to our causal effect estimate of T on Y if we don't control for C?

- Concept: Linear algebra and orthogonal projections
  - Why needed here: The construction of pseudo-concepts relies on orthogonal projections to ensure they capture only information not present in observed concepts
  - Quick check question: Given matrix A and vector v, what does (I - AA^+)v represent, and why is this useful for creating orthogonal complements?

- Concept: Concept-based model explanations
  - Why needed here: Understanding how high-level concepts can be used to explain black-box model behavior is essential for grasping MCCE's overall approach
  - Quick check question: How does using human-interpretable concepts for model explanations differ from traditional feature attribution methods, and what are the advantages?

## Architecture Onboarding

- Component map: Raw input -> Extractor (language model) -> Orthogonal projector -> Linear predictor -> Inference engine
- Critical path:
  1. Extract H from input using pre-trained language model
  2. Compute projection matrix P from observed concepts
  3. Create pseudo-concepts: Cpseud = (I - P)H
  4. Train linear predictor on [Cob, Cpseud] to match black-box output
  5. Use trained model for causal effect estimation
- Design tradeoffs:
  - Number of pseudo-concepts: Too few may not capture enough information; too many may overfit
  - Choice of extractor: Different language models may capture different levels of concept information
  - Linear assumption: May not hold for all black-box models, limiting applicability
- Failure signatures:
  - Poor ICaCE-Error performance: Suggests pseudo-concepts aren't capturing relevant information
  - High correlation between observed and pseudo-concepts: Indicates construction failure
  - Model performance drops significantly with more unobserved concepts: Suggests linear approximation breaking down
- First 3 experiments:
  1. Test orthogonal property: Verify that C_T^ob * Cpseud = 0 for random inputs
  2. Ablation study: Compare performance with and without pseudo-concepts on CEBaB dataset
  3. Sensitivity analysis: Test performance across different numbers of pseudo-concepts (1x, 2x, 3x observed concepts count)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MCCE scale with the number of unobserved concepts beyond the tested range of 1-2 concepts?
- Basis in paper: [explicit] The paper states "MCCE remains robust, showing only a marginal decrease, when two concepts are unobserved compared to just one" but does not test scenarios with 3 or more unobserved concepts
- Why unresolved: The experimental validation was limited to the CEBaB dataset with only 4 concepts total, preventing testing with more than 2 unobserved concepts
- What evidence would resolve it: Empirical results showing MCCE performance with 3+ unobserved concepts on datasets with more concept annotations

### Open Question 2
- Question: What is the theoretical justification for choosing the number of pseudo-concepts in MCCE?
- Basis in paper: [explicit] "The number of pseudo-concepts in MCCE is a hyperparameter that needs to be pre-selected. Empirically, we observe that a number of pseudo-concepts comparable to or slightly greater than the number of observed concepts tends to yield the best results"
- Why unresolved: The paper acknowledges this as an empirical observation without theoretical grounding, stating "The theoretical rationale for the choice of the number of pseudo-concepts remains a subject for further investigation"
- What evidence would resolve it: A formal mathematical proof or theoretical framework explaining the optimal relationship between observed concepts, pseudo-concepts, and model performance

### Open Question 3
- Question: How does MCCE perform on non-text modalities such as images or tabular data?
- Basis in paper: [explicit] "MCCE is designed to be modal-agnostic but needs further validation on modalities beyond text" and "further empirical validation is necessary to fully establish its effectiveness across varied datasets"
- Why unresolved: All experiments were conducted on the CEBaB text dataset, and the paper explicitly states that validation on other modalities is needed
- What evidence would resolve it: Empirical results demonstrating MCCE's performance on image datasets (e.g., ImageNet with concept annotations) or tabular healthcare data with multiple concepts

## Limitations
- The linear approximation assumption may not hold for all black-box models
- Validation is limited to a single dataset with specific characteristics
- The method's performance with more than 2 unobserved concepts is not thoroughly explored

## Confidence
- High confidence: The theoretical demonstration that unobserved concepts bias causal effect estimation
- Medium confidence: The effectiveness of orthogonal pseudo-concepts in capturing missing information
- Medium confidence: The overall performance improvements over baselines, particularly for Cosine distance
- Low confidence: Generalizability to other domains beyond sentiment analysis and restaurant reviews

## Next Checks
1. Test MCCE's performance on non-text domains (e.g., image classification) to verify generalizability beyond sentiment analysis
2. Conduct ablation studies varying the number of pseudo-concepts (1x, 2x, 3x observed concepts) to identify optimal configuration
3. Evaluate MCCE on black-box models with known non-linear relationships to test the limits of the linear approximation assumption