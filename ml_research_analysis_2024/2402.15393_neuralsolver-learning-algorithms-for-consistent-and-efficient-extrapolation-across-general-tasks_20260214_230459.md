---
ver: rpa2
title: 'NeuralSolver: Learning Algorithms For Consistent and Efficient Extrapolation
  Across General Tasks'
arxiv_id: '2402.15393'
source_url: https://arxiv.org/abs/2402.15393
tags:
- neuralthink
- tasks
- task
- size
- recurrent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NeuralThink is a recurrent solver that enables learning algorithms
  from small problems and executing them on large ones, even when input and output
  sizes differ. It uses a recurrent convolutional block to iteratively process input
  information at multiple scales, a processing block to aggregate that information,
  and a curriculum-based training scheme for better extrapolation.
---

# NeuralSolver: Learning Algorithms For Consistent and Efficient Extrapolation Across General Tasks

## Quick Facts
- arXiv ID: 2402.15393
- Source URL: https://arxiv.org/abs/2402.15393
- Authors: Bernardo Esteves; Miguel Vasco; Francisco S. Melo
- Reference count: 40
- Primary result: NeuralThink outperforms prior recurrent solvers in consistent extrapolation to larger problems for both symmetrical and asymmetrical tasks with fewer parameters.

## Executive Summary
NeuralThink is a recurrent solver designed to learn algorithms from small problems and execute them on larger ones, even when input and output sizes differ. It uses a recurrent convolutional block to iteratively process input information at multiple scales, a processing block to aggregate that information, and a curriculum-based training scheme for better extrapolation. The method demonstrates consistent performance improvements over prior state-of-the-art recurrent solvers in extrapolation tasks.

## Method Summary
NeuralThink employs a recurrent convolutional module with LayerNorm ConvLSTM that iteratively processes input observations at different scales. The original input is re-fed at each iteration to prevent forgetting. After recurrent processing, a processing block with three convolutional layers aggregates the features, optionally using global max-pooling for asymmetrical tasks where input and output sizes differ. The model is trained using curriculum learning, starting with small images and gradually increasing input dimensionality, with 20% of batches sampled from previously seen sizes to prevent catastrophic forgetting.

## Key Results
- NeuralThink consistently outperforms DeepThink, FeedForward, and Random baselines in extrapolation to larger problems
- Demonstrates superior performance on both symmetrical tasks (same input/output size) and asymmetrical tasks (different input/output size)
- Achieves better results with fewer parameters than competing methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recurrent convolutional block propagates information across arbitrary input sizes via iterative spatial processing
- Mechanism: Convolutional LSTM iterates over the observation, each iteration capturing information from a larger receptive field; original input is re-fed at every step to prevent forgetting
- Core assumption: Spatial invariances in the input can be exploited by fixed convolutional kernels applied iteratively
- Evidence anchors:
  - [abstract] "recurrent convolutional block to iteratively process input information at different scales"
  - [section] "The propagation of information also influences the output prediction... as the number of iterations increases, a larger number of sections in the maze become white"
  - [corpus] Weak evidence; neighboring papers focus on matrix models or graph algorithms, not iterative spatial reasoning
- Break condition: If the task requires global, non-local reasoning beyond what multiple iterations of convolution can capture

### Mechanism 2
- Claim: Processing block with optional aggregation converts variable-sized feature maps into fixed-sized outputs
- Mechanism: After recurrent processing, a stack of conv layers reduces channel dimensions; optional global max-pooling collapses spatial dimensions for asymmetrical tasks
- Core assumption: Features extracted at multiple scales can be compressed without losing task-relevant information
- Evidence anchors:
  - [abstract] "processing module, responsible for aggregating the previously processed information"
  - [section] "processing block (with an aggregation function)... is responsible for merging the perceived information in the model"
  - [corpus] Weak evidence; no neighbor papers directly address this design pattern
- Break condition: If aggregation discards critical spatial structure needed for the output

### Mechanism 3
- Claim: Curriculum-based training improves extrapolation by gradually increasing input dimensionality
- Mechanism: Model starts on small images, curriculum increases size every N epochs; 20% of batches sampled from previously seen sizes to prevent catastrophic forgetting
- Core assumption: Learning on progressively larger inputs builds hierarchical representations that generalize
- Evidence anchors:
  - [abstract] "curriculum-based training scheme, that improves the extrapolation performance of the method"
  - [section] "we employ a curriculum learning approach... we initially train the models on lower-dimensionality observations, and then gradually increase the dimensionality"
  - [corpus] Weak evidence; no neighbor papers discuss curriculum learning in this context
- Break condition: If curriculum schedule is too aggressive, causing model to lose early-learned patterns

## Foundational Learning

- Concept: Convolutional Neural Networks
  - Why needed here: Recurrent convolutional block relies on conv layers to extract spatial features iteratively
  - Quick check question: How does a 3×3 convolution with stride 1 and padding 1 preserve spatial dimensions?

- Concept: Recurrent Neural Networks / LSTM
  - Why needed here: Convolutional LSTM maintains hidden state across iterations to propagate information spatially
  - Quick check question: What gating mechanisms in LSTM help prevent vanishing gradients over many iterations?

- Concept: Curriculum Learning
  - Why needed here: Gradual increase in input size helps model build scalable representations without forgetting
  - Quick check question: Why might sampling 20% of batches from previous sizes help avoid catastrophic forgetting?

## Architecture Onboarding

- Component map: Input → Recurrent Convolutional Block (LayerNorm ConvLSTM + re-fed input) → Processing Block (3 conv layers + optional global max-pooling) → Output
- Critical path: Recurrent iterations → Feature aggregation → Output prediction
- Design tradeoffs: More iterations vs. deeper conv layers; aggregation type (max vs. avg) affects information retention
- Failure signatures: Overthinking (performance drops with too many iterations), underfitting (too few iterations), poor aggregation (loss of spatial detail)
- First 3 experiments:
  1. Run with 1 iteration only to confirm model can learn without recurrence (should fail on large inputs)
  2. Run with curriculum disabled to see if extrapolation collapses
  3. Swap max-pooling for average-pooling in processing block to test impact on asymmetrical tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural modifications would allow NeuralThink to handle tasks with more complex sequential dependencies or multi-step reasoning?
- Basis in paper: [inferred] The paper discusses NeuralThink's success in single-step and simple multi-step tasks like Doorkey, but does not explore its limitations with more complex sequences or reasoning tasks.
- Why unresolved: The current experiments focus on relatively straightforward tasks. More complex scenarios might require additional architectural elements or training strategies not yet explored.
- What evidence would resolve it: Testing NeuralThink on tasks with longer action sequences, conditional branching, or nested dependencies, and analyzing performance degradation or required modifications.

### Open Question 2
- Question: How does the choice of aggregation function (e.g., max pooling vs. average pooling) affect NeuralThink's performance in tasks with varying output dimensionalities?
- Basis in paper: [explicit] The ablation study shows that max pooling outperforms average pooling in some tasks, but the paper does not provide a comprehensive analysis of why this occurs or under what conditions other aggregation functions might be beneficial.
- Why unresolved: The paper only tests two pooling methods and does not explore other aggregation strategies or their impact on different types of tasks.
- What evidence would resolve it: Systematic comparison of different aggregation functions (e.g., attention mechanisms, learned pooling) across a variety of asymmetrical tasks with different output dimensionalities.

### Open Question 3
- Question: What are the theoretical limits of NeuralThink's extrapolation capabilities in terms of input size and task complexity?
- Basis in paper: [inferred] While the paper demonstrates successful extrapolation to large input sizes (512x512), it does not establish theoretical bounds or analyze at what point performance begins to degrade significantly.
- Why unresolved: The experiments show practical success but do not provide theoretical analysis of the model's limitations or the factors that determine its extrapolation ceiling.
- What evidence would resolve it: Mathematical analysis of the model's receptive field growth, computational complexity, and information propagation limits, combined with empirical testing at increasingly extreme scales.

## Limitations
- Partial specification of hyperparameters and training details could impact reproducibility
- Claim of "consistent extrapolation" is supported by experimental results on several tasks but generality across arbitrary algorithmic problems is not fully established
- Mechanism for why curriculum learning improves extrapolation is theoretically sound but not extensively validated across diverse domains

## Confidence

- High confidence: The architectural design of NeuralThink (recurrent convolutional block + processing block) is well-specified and experimentally validated
- Medium confidence: The effectiveness of curriculum-based training for extrapolation is demonstrated but may not generalize to all problem types
- Low confidence: The claim of outperforming all prior state-of-the-art recurrent solvers is based on a limited set of tasks and may not hold for broader algorithmic challenges

## Next Checks
1. Test NeuralThink on a wider range of algorithmic problems beyond those presented to assess scalability and generalization
2. Conduct ablation studies on the curriculum learning schedule to determine optimal progression and batch sampling strategies
3. Compare NeuralThink's performance with additional baseline methods, including transformer-based approaches, to contextualize its relative effectiveness