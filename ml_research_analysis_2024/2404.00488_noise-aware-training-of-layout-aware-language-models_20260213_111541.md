---
ver: rpa2
title: Noise-Aware Training of Layout-Aware Language Models
arxiv_id: '2404.00488'
source_url: https://arxiv.org/abs/2404.00488
tags:
- training
- document
- documents
- extractor
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of training custom information
  extraction models for thousands of different visually rich document types in a scalable
  way, where traditional pre-training approaches exceed maximum allowable training
  time. The authors propose a Noise-Aware Training (NAT) framework that uses weak
  supervision from multiple models and synthetic data augmentation to train extractors
  with limited human-labeled samples.
---

# Noise-Aware Training of Layout-Aware Language Models

## Quick Facts
- **arXiv ID**: 2404.00488
- **Source URL**: https://arxiv.org/abs/2404.00488
- **Reference count**: 9
- **Primary result**: Reduces human labeling effort by up to 73% while improving macro-F1 scores by up to 6% compared to transfer learning baselines

## Executive Summary
This paper introduces a Noise-Aware Training (NAT) framework for training information extraction models on visually rich documents when labeled data is scarce. The framework uses weak supervision from multiple models and synthetic data augmentation to reduce reliance on human-labeled samples. By incorporating sample re-weighting, weight thresholding, and noise-aware loss functions, NAT handles noisy training data effectively. Experiments across four datasets demonstrate significant improvements in label efficiency and model performance compared to standard transfer learning approaches.

## Method Summary
NAT employs a three-phase workflow: (1) Pre-train layout-aware models (LayoutLMV2/FormNet) on large document corpora using L1-transfer, (2) Fine-tune on weakly augmented corpora using two model-based weak supervision sources with noise-aware training that includes sample re-weighting, weight thresholding, and noise-aware loss, and (3) Fine-tune on synthetically augmented corpora generated through rule-based transformations of human-labeled documents. The framework estimates confidence scores for weakly labeled samples and uses these as weights in the loss function to down-weight low-confidence samples.

## Key Results
- Reduces human labeling effort by up to 73% while maintaining or improving extraction performance
- Improves macro-F1 scores by up to 6% compared to transfer learning baselines
- Demonstrates effectiveness across four diverse document datasets (CORD, FUNSD, Utility, French Invoice)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Noise-aware training improves model robustness by down-weighting low-confidence weakly labeled samples
- Mechanism: Confidence scores from weak supervision sources are used as sample weights in the loss function, with higher weights for more confident samples
- Core assumption: Confidence scores correlate with true label accuracy
- Evidence anchors: Abstract mentions confidence estimation and uncertainty measurement; section describes re-weighting during loss computation
- Break condition: Weak supervision sources produce systematically biased confidence scores uncorrelated with accuracy

### Mechanism 2
- Claim: Sequential fine-tuning on multiple weak supervision sources improves generalization
- Mechanism: Model fine-tuned sequentially on weakly augmented corpora from different weak supervision sources to learn diverse labeling patterns
- Core assumption: Different weak supervision sources capture complementary aspects of the labeling task
- Evidence anchors: Abstract mentions multiple models as independent weak supervision sources; section describes focus on training iterations of each model
- Break condition: Weak supervision sources are highly correlated with similar biases

### Mechanism 3
- Claim: Synthetic data augmentation expands training distribution and improves robustness to layout variations
- Mechanism: Rule-based synthetic document generation using synonym substitution, format substitution, coordinate transformation, and bounding-box expansion
- Core assumption: Synthetic transformations preserve semantic meaning while creating meaningful variations
- Evidence anchors: Abstract mentions synthetic document generation and fine-tuning on synthetically augmented corpus; section describes rule-based augmentation strategy
- Break condition: Synthetic transformations create unrealistic or semantically incorrect examples

## Foundational Learning

- **Transfer learning fundamentals**
  - Why needed here: Framework relies on pre-training on large datasets followed by fine-tuning on target tasks
  - Quick check question: What are the key differences between fine-tuning and continued pre-training, and when would you choose one over the other?

- **Weak supervision and confidence estimation**
  - Why needed here: Framework's effectiveness depends on generating and utilizing weakly labeled data with appropriate confidence scores
  - Quick check question: How do you calculate sample weights from confidence scores, and what are the implications of using different weighting schemes?

- **Data augmentation strategies**
  - Why needed here: Framework uses rule-based synthetic data generation to improve model generalization
  - Quick check question: What are the key considerations when designing data augmentation rules for document understanding tasks?

## Architecture Onboarding

- **Component map**: Pre-training phase (LayoutLMV2/FormNet backbone) → Weak supervision phase (two model-based extractors) → Noise-aware training (sample re-weighting, weight thresholding, noise-aware loss) → Synthetic augmentation phase (rule-based document generation) → Fine-tuning pipeline (sequential fine-tuning)

- **Critical path**: Pre-training → Weak label generation → Noise-aware fine-tuning → Synthetic augmentation → Final fine-tuning

- **Design tradeoffs**: Model complexity vs training time; number of weak supervision sources vs computational cost; synthetic data quality vs quantity

- **Failure signatures**: Poor test performance despite good training metrics (overfitting to weak labels or synthetic data); high variance across runs (instability in weak supervision or noise-aware training); slow convergence (issues with learning rate or data quality)

- **First 3 experiments**:
  1. Validate weak supervision quality: Compare weak labels against human-labeled documents to assess accuracy and confidence calibration
  2. Test noise-aware training: Implement basic sample re-weighting and measure impact on model performance with noisy labels
  3. Evaluate synthetic augmentation: Generate synthetic documents and test if they improve model robustness to layout variations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance scale with increasing numbers of weak supervision sources?
- Basis in paper: Paper mentions using two weak supervision sources but doesn't explore impact of adding more sources
- Why unresolved: No experimental results or analysis for varying numbers of weak supervision sources beyond two used in experiments
- What evidence would resolve it: Experiments comparing model performance with different numbers of weak supervision sources (1, 2, 3, 4) using same datasets and evaluation metrics

### Open Question 2
- Question: What is the impact of different noise-aware loss formulations on model performance?
- Basis in paper: Paper introduces specific noise-aware loss function but doesn't explore alternative formulations
- Why unresolved: Only presents results using proposed noise-aware loss without benchmarking against other formulations
- What evidence would resolve it: Comparative experiments using different noise-aware loss formulations on same datasets

### Open Question 3
- Question: How does NAT perform on document types with significantly different visual layouts or domain characteristics?
- Basis in paper: Paper evaluates on four datasets but doesn't explore performance across highly diverse document types
- Why unresolved: Experiments focus on specific document types without testing more diverse or challenging categories
- What evidence would resolve it: Experiments applying NAT to broader range of document types with varying layouts, domains, and complexity levels

## Limitations
- Weak supervision source implementations are not fully specified, particularly the multimodal bi-LSTM network
- Confidence calibration between weak supervision sources and true label accuracy remains unverified
- Performance improvements depend heavily on specific hyperparameter choices not fully disclosed

## Confidence

- **High Confidence**: Overall three-phase workflow architecture and general concept of using weak supervision with noise-aware training
- **Medium Confidence**: Specific noise-aware training implementation is theoretically sound but lacks empirical validation of confidence score correlation with accuracy
- **Low Confidence**: Exact performance improvements claimed depend heavily on specific weak supervision source implementations and hyperparameter choices

## Next Checks
1. Implement weak supervision sources and validate their label accuracy against held-out human-labeled documents, measuring confidence score calibration
2. Create controlled experiments with synthetic noisy labels of known quality to test whether sample re-weighting and weight thresholding improve performance
3. Systematically vary synthetic augmentation parameters and measure impact on model robustness while monitoring for overfitting to synthetic patterns