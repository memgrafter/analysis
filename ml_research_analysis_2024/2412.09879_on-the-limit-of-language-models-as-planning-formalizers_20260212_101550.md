---
ver: rpa2
title: On the Limit of Language Models as Planning Formalizers
arxiv_id: '2412.09879'
source_url: https://arxiv.org/abs/2412.09879
tags:
- block
- pddl
- clear
- natural
- plan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates large language models (LLMs) as formalizers
  that translate natural language descriptions of planning environments into complete
  Planning Domain Definition Language (PDDL) files. The authors generate four planning
  datasets with descriptions ranging from heavily templated to natural-sounding language,
  and compare LLM-as-formalizer against LLM-as-planner baselines across multiple models.
---

# On the Limit of Language Models as Planning Formalizers

## Quick Facts
- arXiv ID: 2412.09879
- Source URL: https://arxiv.org/abs/2412.09879
- Authors: Cassie Huang; Li Zhang
- Reference count: 34
- Primary result: LLM-as-formalizer approach outperforms LLM-as-planner on BlocksWorld tasks, with performance degrading as descriptions become more natural

## Executive Summary
This paper evaluates large language models as formalizers that translate natural language descriptions of planning environments into complete Planning Domain Definition Language (PDDL) files. The authors generate four planning datasets with descriptions ranging from heavily templated to natural-sounding language, comparing LLM-as-formalizer against LLM-as-planner baselines across multiple models. Key results show that strong models like GPT-4o and o3-mini can effectively generate complete PDDL, outperforming direct planning approaches, while open-source models like Llama-3.1 and Gemma struggle with syntax errors. Performance degrades as descriptions become more natural, suggesting models rely on pattern matching. The LLM-as-formalizer approach proves more robust to lexical perturbations than direct planning.

## Method Summary
The study generates four planning datasets (BlocksWorld, MysteryBlocksWorld, Logistics, Barman) with varying levels of naturalness in their descriptions, from heavily templated PDDL-like text to natural language. Using the KANI framework with zero-shot prompting, the authors evaluate multiple models including GPT-4o, o3-mini, Llama-3.1, Gemma-2, and DeepSeek-R1. The LLM-as-formalizer approach converts natural language descriptions into PDDL files that are then solved by deterministic planners, while LLM-as-planner directly generates plans from descriptions. Performance is measured using Solvability (percentage of solvable predicted PDDL) and Correctness (percentage of correct plans validated against ground truth) metrics.

## Key Results
- GPT-4o and o3-mini successfully generate complete PDDL outperforming direct planning approaches on BlocksWorld tasks
- Performance degrades as descriptions become more natural, with models relying on pattern matching rather than semantic understanding
- LLM-as-formalizer shows greater robustness to lexical perturbations compared to LLM-as-planner
- Open-source models like Llama-3.1 and Gemma primarily make syntax errors, while all models face semantic challenges in action definitions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-as-formalizer outperforms LLM-as-planner because it reduces the reasoning burden by delegating formal structure generation to deterministic solvers
- Mechanism: The LLM acts as an information extraction tool to convert natural language into PDDL, while the planner handles the complex search problem
- Core assumption: LLMs are better at extracting and organizing information than performing formal reasoning
- Evidence anchors:
  - [abstract] "LLM-as-formalizer often outperforms LLM-as-planner for many model-data combinations, though not always"
  - [section 5.2] "On BlocksWorld-100, gpt-4o is able to generate solvable PDDL 64 times, out of 100, and of those 64 plans, 60 of them are correct. This far surpasses the LLM-as-planner baseline, which only found correct plans 33/100 times"
- Break condition: When the LLM cannot generate syntactically correct PDDL, or when the task requires real-time planning where solver latency is prohibitive

### Mechanism 2
- Claim: More natural descriptions increase task difficulty because they require implicit knowledge inference rather than pattern matching
- Mechanism: Natural language descriptions omit explicit predicate information that must be inferred, while templated descriptions explicitly state all preconditions and effects
- Core assumption: Models rely on explicit pattern matching for PDDL generation and struggle with implicit knowledge extraction
- Evidence anchors:
  - [abstract] "As the descriptions become more natural-sounding, we observe a decrease in performance"
  - [section 5.3] "We can see that on BlocksWorld-100 as the problem sounds more similar to PDDL and less natural, the performance of all the models improves"
- Break condition: When descriptions contain explicit PDDL-like patterns that can be matched directly

### Mechanism 3
- Claim: Models that can generate complete PDDL are more robust to lexical perturbations than those that cannot
- Mechanism: Models with sufficient capacity and PDDL knowledge can handle domain name changes and maintain semantic understanding, while others fail completely
- Core assumption: Lexical perturbation tests reveal whether models are memorizing specific patterns versus understanding semantic relationships
- Evidence anchors:
  - [abstract] "LLM-as-formalizer is much more robust to long-tail lexical distribution than LLM-as-planner"
  - [section 5.4] "On MysteryBlocksWorld-100, we can see that LLM-as-planner was not able to find a single correct plan... However, gpt-4o-as-formalizer surpassed this baseline with a Correctness score of 70/100"
- Break condition: When perturbations are so extreme that semantic relationships become unrecognizable

## Foundational Learning

- Concept: Planning Domain Definition Language (PDDL) syntax and semantics
  - Why needed here: The entire evaluation depends on generating valid PDDL files that can be parsed and solved
  - Quick check question: What are the required components of a valid PDDL domain file and problem file?

- Concept: Information extraction vs. formal reasoning capabilities of LLMs
  - Why needed here: The paper's key insight is that LLMs excel at information extraction but struggle with formal reasoning
  - Quick check question: Why might an LLM be better at converting natural language to structured data than at solving planning problems directly?

- Concept: Natural language processing and implicit knowledge inference
  - Why needed here: Understanding how models handle natural descriptions requires knowledge of NLP and common-sense reasoning
  - Quick check question: How does the omission of explicit predicates in natural descriptions affect model performance compared to templated descriptions?

## Architecture Onboarding

- Component map: Natural language description -> LLM -> PDDL output -> Solver -> Plan -> Validator -> Performance metrics
- Critical path: Natural language description -> LLM PDDL generation -> Solver plan generation -> Validation
- Design tradeoffs: LLM-as-formalizer trades solver latency for higher plan correctness vs. LLM-as-planner trades speed for lower correctness
- Failure signatures: Syntax errors in PDDL generation, semantic errors in action definitions, solver timeouts, validation failures
- First 3 experiments:
  1. Test LLM-as-formalizer on Heavily Templated BlocksWorld-100 to establish baseline performance
  2. Compare performance degradation between Heavily Templated and Natural BlocksWorld-100
  3. Test same models on MysteryBlocksWorld-100 to evaluate lexical perturbation robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of LLM-as-formalizer compare to LLM-as-planner across more complex domains like Sokoban or Wumpus World?
- Basis in paper: [explicit] The paper evaluates four domains (BlocksWorld, Logistics, Barman, and Mystery BlocksWorld) but focuses primarily on BlocksWorld and Logistics for detailed analysis.
- Why unresolved: The study only scratches the surface of more complex domains, leaving the scalability of LLM-as-formalizer unexplored.
- What evidence would resolve it: Benchmarking LLM-as-formalizer on domains with larger state spaces, more intricate action spaces, and partial observability.

### Open Question 2
- Question: What is the impact of using advanced prompting techniques like self-refine or voting on the performance of LLM-as-formalizer?
- Basis in paper: [explicit] The paper acknowledges that advanced prompting techniques could improve performance but does not explore them.
- Why unresolved: The study uses only zero-shot prompting and minimal few-shot/chain-of-thought experiments, limiting insights into potential performance gains.
- What evidence would resolve it: Systematic experiments comparing zero-shot, few-shot, chain-of-thought, and advanced prompting techniques across multiple models and domains.

### Open Question 3
- Question: How do LLM-as-formalizer approaches perform in partially observable environments or domains requiring commonsense knowledge?
- Basis in paper: [explicit] The paper focuses on fully observable environments and suggests LLM-as-planner might excel in tasks requiring commonsense knowledge.
- Why unresolved: The study does not explore partially observable domains or tasks requiring significant commonsense reasoning.
- What evidence would resolve it: Evaluating LLM-as-formalizer on partially observable domains like "Find the keys" or "Escape the room" scenarios.

## Limitations

- Evaluation scope limited to four domains with varying complexity, raising questions about generalizability
- Heavy reliance on zero-shot prompting without exploring few-shot or fine-tuned approaches that might improve performance
- Error analysis focuses primarily on syntax vs. semantic errors without detailed investigation of specific failure modes

## Confidence

**High Confidence**: The observation that GPT-4o and o3-mini can effectively generate complete PDDL outperforming direct planning approaches is well-supported by the quantitative results across multiple datasets. The performance degradation as descriptions become more natural is consistently demonstrated.

**Medium Confidence**: The claim that LLM-as-formalizer is more robust to lexical perturbations than LLM-as-planner, while supported by the MysteryBlocksWorld results, is based on a single perturbation experiment. The broader generalizability to other types of perturbations remains uncertain.

**Low Confidence**: The assertion that open-source models primarily make syntax errors while all models face semantic challenges requires more detailed error analysis across diverse domains. The error categorization appears to be based on limited observations.

## Next Checks

1. **Error Analysis Expansion**: Conduct detailed error categorization across all model-dataset combinations, distinguishing between syntax errors, semantic errors, and planning failures to validate the proposed error taxonomy.

2. **Cross-Domain Generalization**: Test the LLM-as-formalizer approach on more complex planning domains (e.g., hierarchical planning tasks) to evaluate whether performance patterns observed in BlocksWorld and Logistics generalize.

3. **Prompt Engineering Impact**: Systematically vary prompt templates and few-shot examples to determine whether performance on natural descriptions can be improved through better prompting strategies, addressing the fundamental limitation of implicit knowledge extraction.