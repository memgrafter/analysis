---
ver: rpa2
title: Latent Variable Sequence Identification for Cognitive Models with Neural Network
  Estimators
arxiv_id: '2406.14742'
source_url: https://arxiv.org/abs/2406.14742
tags:
- latent
- lasenet
- neural
- variables
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose LaseNet, a method that uses neural Bayes estimation
  with RNNs to extract time-varying latent variables from computational cognitive
  models, particularly those with intractable likelihoods. LaseNet learns a direct
  mapping between experimental data and latent variable space using simulated datasets,
  enabling researchers to access a wider class of models for model-based neural analyses.
---

# Latent Variable Sequence Identification for Cognitive Models with Neural Network Estimators

## Quick Facts
- arXiv ID: 2406.14742
- Source URL: https://arxiv.org/abs/2406.14742
- Authors: Ti-Fen Pan; Jing-Jing Li; Bill Thompson; Anne Collins
- Reference count: 40
- Primary result: LaseNet achieves competitive performance in inferring latent variable sequences in both tractable and intractable models, outperforming likelihood-dependent methods like MLE and EM in some cases.

## Executive Summary
This paper introduces LaseNet, a neural Bayes estimation method for extracting time-varying latent variables from computational cognitive models with intractable likelihoods. LaseNet learns a direct mapping between experimental data and latent variable space using simulated datasets and recurrent neural networks, enabling researchers to access a wider class of models for model-based neural analyses. The approach demonstrates strong performance across multiple cognitive models, including reinforcement learning and hierarchical reinforcement learning frameworks, with competitive accuracy in both continuous and discrete latent variable recovery.

## Method Summary
LaseNet employs a neural Bayes estimation framework that learns a direct mapping from observable sequences to latent variables using simulated data. The method uses a bidirectional RNN with GRU cells to process temporal sequences, followed by MLP layers that map the RNN embeddings to the latent space. The network is trained on simulated (Z, Y) pairs from cognitive models and can handle both continuous and discrete latent variables through separate output heads. During inference, the trained network takes real experimental data as input and outputs the corresponding latent variable sequence without requiring likelihood computation.

## Key Results
- LaseNet achieves 93% accuracy in latent discrete cue identification and RMSE of 0.119 for Q-value identification in RL models
- The method outperforms likelihood-dependent approaches (MLE, EM) when model parameters are highly uncertain or likelihoods are intractable
- LaseNet generalizes across different computational models and adapts to both continuous and discrete latent spaces

## Why This Works (Mechanism)

### Mechanism 1
LaseNet avoids likelihood computation by learning a direct mapping from observable sequences to latent variables using simulated data. The RNN+MLP architecture learns a parametric approximation to the Bayes estimator that minimizes expected risk over the latent space, bypassing the need to compute the likelihood at inference time. Core assumption: Simulated datasets can approximate the true joint distribution of observables and latents sufficiently for the neural mapping to generalize. Evidence anchors: [abstract], [section], [corpus]. Break condition: Large simulation-to-real distribution shift or highly multimodal latent space.

### Mechanism 2
Bidirectional RNNs capture both past and future context needed for accurate latent variable inference. The bi-RNN processes the observable sequence in both forward and backward directions, producing a summary embedding that conditions on all available information before and after each time step. Core assumption: The latent variable at time t depends on the full observable history and possibly future information. Evidence anchors: [abstract], [section], [corpus]. Break condition: Strictly causal tasks where future information is unavailable at inference.

### Mechanism 3
Neural Bayes estimators generalize better than likelihood-dependent methods when model parameters are highly uncertain or the likelihood is intractable. By training on simulated data with known latents, LaseNet learns a function that implicitly marginalizes over parameter uncertainty, avoiding explicit parameter estimation steps. Core assumption: The simulation-based training distribution covers the range of plausible parameter settings encountered in real data. Evidence anchors: [abstract], [section], [corpus]. Break condition: Misspecified parameter space or insufficient training data coverage.

## Foundational Learning

- Concept: Bayes estimators and decision theory
  - Why needed here: LaseNet is formalized as minimizing expected risk under a loss function, analogous to classical Bayes estimators.
  - Quick check question: What loss function would you use for continuous vs discrete latent spaces, and why?

- Concept: Simulation-based inference (SBI)
  - Why needed here: The method relies on generating synthetic datasets from the computational model to train the neural network.
  - Quick check question: How does SBI bypass the need for analytic likelihood computation, and what are its limitations?

- Concept: Recurrent neural networks and bidirectional processing
  - Why needed here: The model uses bi-RNNs to capture temporal dependencies in the observable sequence for accurate latent variable inference.
  - Quick check question: What is the difference between forward-only and bidirectional RNNs in terms of the information they use at each time step?

## Architecture Onboarding

- Component map: Input observables -> Bi-RNN (GRU) -> MLP layers -> Output heads (continuous + discrete)
- Critical path: 1. Simulate (Z, Y) pairs from cognitive model 2. Train bi-RNN+MLP to minimize L(z, Å·) 3. Feed real Y into trained network to obtain latent sequence Z
- Design tradeoffs: Bi-RNN vs forward-only (better accuracy vs online inference capability); Separate vs shared output heads (flexibility vs simplicity); Number of MLP layers (capacity vs overfitting risk)
- Failure signatures: High training loss but low validation loss (overfitting); High loss on both (insufficient capacity or poor simulation coverage); Systematic bias in recovered latents (simulation mismatch)
- First 3 experiments: 1. Train on 4-P RL model and compare RMSE to MLE on synthetic data 2. Add discrete latent head and test joint recovery in Meta RL 3. Swap bi-RNN for forward-only RNN and measure performance degradation

## Open Questions the Paper Calls Out

### Open Question 1
How does LaseNet perform on cognitive models with more complex hierarchical structures or higher-dimensional latent spaces? The paper demonstrates LaseNet on models with up to 21 free parameters but doesn't explore very deep hierarchies or extremely high-dimensional latent spaces. Testing on more complex models like deep hierarchical RL agents would resolve this.

### Open Question 2
How does LaseNet handle uncertainty estimation in real-world experimental settings where model misspecification is likely? The paper acknowledges the lack of uncertainty estimation and mentions potential solutions like bootstrapping or evidential learning, but doesn't provide comprehensive solutions or empirical validation. Implementing and validating uncertainty estimation methods would resolve this.

### Open Question 3
Can LaseNet be extended to handle continuous-time cognitive models or models with non-stationary latent dynamics? The paper focuses on discrete-time models and doesn't address continuous-time modeling or non-stationary latent dynamics. Extending LaseNet to handle continuous-time models and testing on non-stationary dynamics would resolve this.

## Limitations
- Performance depends critically on simulation coverage matching real data distributions
- Real-world validation is limited to only two model types
- Bidirectional RNN design precludes online inference in streaming scenarios

## Confidence
- High confidence in the core neural Bayes estimation framework and mathematical formulation
- Medium confidence in relative performance improvements over likelihood-dependent methods
- Medium confidence in generalizability claim across cognitive models

## Next Checks
1. Test LaseNet on additional cognitive models (e.g., hierarchical Bayesian models, deep RL agents) to assess cross-model generalization
2. Conduct ablation studies removing bidirectional processing to quantify information gain from future context
3. Evaluate performance degradation when training simulations use mismatched parameter priors compared to true data-generating process