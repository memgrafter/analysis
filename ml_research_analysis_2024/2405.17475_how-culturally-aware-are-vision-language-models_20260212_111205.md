---
ver: rpa2
title: How Culturally Aware are Vision-Language Models?
arxiv_id: '2405.17475'
source_url: https://arxiv.org/abs/2405.17475
tags:
- image
- cultural
- arxiv
- images
- awareness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Cultural Awareness Score (CAS) to measure
  the ability of vision-language models to generate culturally sensitive image captions.
  The authors curated a dataset, MOSAIC-1.5k, with 1,500 images of cultural elements,
  including traditional dances, symbols, and mythological concepts, annotated with
  ground truth captions.
---

# How Culturally Aware are Vision-Language Models?

## Quick Facts
- arXiv ID: 2405.17475
- Source URL: https://arxiv.org/abs/2405.17475
- Authors: Olena Burda-Lassen; Aman Chadha; Shashank Goswami; Vinija Jain
- Reference count: 30
- Key outcome: Introduced CAS metric; Gemini Pro Vision achieved 36% CAS, OpenFlamingo 8%

## Executive Summary
This paper addresses the critical gap in evaluating vision-language models' ability to generate culturally sensitive image captions. The authors introduce the Cultural Awareness Score (CAS), a binary metric that measures whether captions include accurate cultural context alongside basic image description. They curate MOSAIC-1.5k, a dataset of 1,500 culturally diverse images, and evaluate four leading VLMs. Results show significant room for improvement, with Gemini Pro Vision achieving the highest CAS of 36% while OpenFlamingo scored only 8%. The study reveals that real-life dance photos yield the best cultural awareness, while cultural signs and symbols suffer from high hallucination rates.

## Method Summary
The researchers developed MOSAIC-1.5k, a dataset containing 1,500 images from cultural domains including traditional dances, costumes, mythology, and symbols sourced from Wikimedia, Wikipedia, Pixabay, Kaggle, and Symbolikon. They created ground truth captions with cultural context and evaluated four vision-language models (GPT-4V, Gemini Pro Vision, LLaVA, OpenFlamingo) using a custom prompt. The Cultural Awareness Score (CAS) was calculated as a binary metric assessing three criteria: correct image description, culturally-specific information, and adherence to Responsible AI principles. The evaluation compared model performance across different image types and measured hallucination rates.

## Key Results
- Gemini Pro Vision achieved the highest CAS score of 36%, while OpenFlamingo scored only 8%
- Real-life dance photographs achieved highest CAS scores and lowest hallucination rates (6% for Gemini)
- Cultural signs and symbols had the most hallucinations (28% for Gemini) and lowest CAS scores
- GPT-4V failed to generate culturally aware captions for 55% of symbol images
- All models showed significant room for improvement in culturally aware image captioning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The CAS evaluation effectively quantifies cultural awareness by treating cultural relevance as a binary presence/absence signal, making scoring more consistent than partial credit systems.
- Mechanism: The binary CAS formula (1) assigns 1 if all three criteria are met (correct description, cultural context, responsible AI) and 0 otherwise. This eliminates ambiguity in partial credit assignment and ensures that only fully culturally aware captions receive credit.
- Core assumption: Cultural awareness can be meaningfully reduced to a binary decision without losing critical nuance in evaluation.
- Evidence anchors:
  - [abstract] "We propose a new evaluation metric, the Cultural Awareness Score (CAS), which measures the degree of cultural awareness in image captions."
  - [section IV] "We propose the following definition of the CAS: binary score to assess the presence or the absence of the relevant culturally-specific information within the generated image caption."
  - [corpus] Weak evidence - no corpus papers directly validate the binary approach, though related work mentions similar cultural evaluation frameworks.
- Break condition: If cultural nuances require partial credit (e.g., partially correct cultural references), the binary approach may systematically underestimate model performance.

### Mechanism 2
- Claim: Real-life photographs achieve higher CAS scores because they provide richer visual context that helps models identify cultural elements more accurately.
- Mechanism: The paper shows real-life dance photos achieved highest CAS and lowest hallucinations (6% for Gemini), while cultural signs/symbols had most hallucinations (28%) and lowest CAS. This suggests visual complexity and context richness improve cultural recognition.
- Core assumption: Visual complexity and contextual richness in real photographs provide more cues for accurate cultural identification than simplified representations.
- Evidence anchors:
  - [section V] "real-life photographs, particularly those depicting dancers, not only achieved the highest CAS scores but also showed the lowest instances of erroneous image captioning."
  - [section V] "vector images and icons denoting cultural signs and symbols were marked by the most significant levels of hallucinations, accompanied by the lowest Cultural Awareness Scores"
  - [corpus] Weak evidence - corpus papers discuss cultural awareness but don't specifically address image type effects on CAS.
- Break condition: If models become sophisticated enough to extract cultural context from minimal visual cues, this mechanism would weaken.

### Mechanism 3
- Claim: The MOSAIC-1.5k dataset's multi-image-per-concept approach reduces bias and increases evaluation fairness compared to single-example datasets.
- Mechanism: By selecting 1-10 images per cultural concept, the dataset captures variance in how cultural elements can be represented, preventing overfitting to specific visual presentations and improving generalizability of CAS scores.
- Core assumption: Cultural concepts have visual variance that must be captured to properly evaluate model generalization.
- Evidence anchors:
  - [section III-A] "We tried to select 1-10 images per cultural concept to ensure variance and fairness in image recognition evaluation."
  - [section V] "Our research aims to evaluate the performance of four vision-language models using the newly introduced Cultural Awareness Score, CAS. In addition to proposing and defining the CAS, we offer a labeled dataset MOSAIC-1.5k."
  - [corpus] Weak evidence - corpus papers mention cultural evaluation but don't discuss multi-image dataset design strategies.
- Break condition: If cultural concepts have very consistent visual representations, the multi-image approach may add unnecessary complexity without improving evaluation quality.

## Foundational Learning

- Concept: Binary classification evaluation
  - Why needed here: CAS uses binary scoring (1/0) rather than continuous metrics, requiring understanding of binary classification principles and their limitations
  - Quick check question: Why might binary scoring be more appropriate than continuous scoring for cultural awareness evaluation?

- Concept: Multimodal model evaluation metrics
  - Why needed here: Understanding ROUGE-L, hallucination metrics, and their limitations in multimodal contexts is essential for interpreting CAS results
  - Quick check question: What are the key differences between text-only and multimodal evaluation metrics?

- Concept: Cultural sensitivity in AI
  - Why needed here: The research requires understanding how cultural concepts differ from general knowledge and why standard evaluation metrics may miss cultural nuances
  - Quick check question: How does cultural awareness differ from general knowledge accuracy in AI evaluation?

## Architecture Onboarding

- Component map: MOSAIC-1.5k curation → Model inference → CAS calculation → Analysis → Dataset release; Evaluation framework: ROUGE-L baseline → CAS binary scoring → Hallucination detection
- Critical path: Dataset curation and labeling → Model evaluation with CAS → Analysis of results by image type → Publication of dataset and findings
- Design tradeoffs: Binary vs. continuous CAS scoring (simplicity vs. nuance), single vs. multi-image per concept (efficiency vs. robustness), ground truth length (detail vs. consistency)
- Failure signatures: High hallucination rates in specific image types, GPT-4V failures on 55% of symbol images, low CAS scores across all models indicating systemic issues
- First 3 experiments:
  1. Re-run CAS evaluation with continuous scoring (0-1 scale) to compare with binary results
  2. Test additional vision-language models (e.g., Claude 3, LLaVA-Next) to establish baseline comparison
  3. Conduct ablation study removing Responsible AI criteria to measure its impact on CAS scores

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different prompting techniques impact the Cultural Awareness Scores of vision-language models?
- Basis in paper: [explicit] The paper mentions that prompt engineering techniques impact VLMs outputs, but evaluation remains a challenge.
- Why unresolved: The study used a specific prompt but did not systematically test how variations in prompting affect CAS scores across different models.
- What evidence would resolve it: Systematic experimentation with multiple prompt variations (e.g., different phrasings, instructions, or examples) applied to the same models and dataset, measuring resulting CAS changes.

### Open Question 2
- Question: What specific characteristics of vector images and icons lead to higher hallucination rates in vision-language models?
- Basis in paper: [explicit] The paper notes that vector images and icons representing cultural signs and symbols had the highest hallucination levels and lowest CAS scores.
- Why unresolved: While the correlation is observed, the underlying reasons for this pattern (e.g., lack of texture, simplified features, or training data bias) are not explored.
- What evidence would resolve it: Comparative analysis of hallucination rates across image types with controlled feature variations, or investigation into the training data distribution for different image categories.

### Open Question 3
- Question: Can the Cultural Awareness Score metric be generalized to other domains beyond cultural concepts, such as scientific or historical imagery?
- Basis in paper: [inferred] The CAS is introduced as a binary score for culturally-specific information, but its applicability to other specialized domains is not discussed.
- Why unresolved: The metric's formulation and evaluation are specific to cultural contexts, and its effectiveness in other knowledge domains remains untested.
- What evidence would resolve it: Application of CAS to diverse datasets from other domains (e.g., medical imaging, historical artifacts) with domain-specific ground truth, measuring its sensitivity and reliability.

## Limitations
- Binary CAS metric may oversimplify complex cultural nuances and underestimate partial performance
- Limited evaluation to only four vision-language models restricts generalizability
- Dataset selection bias toward visually distinctive cultural elements rather than representative samples

## Confidence
- **High confidence**: Real-life photographs achieve higher CAS scores due to richer visual context is well-supported by clear performance differences
- **Medium confidence**: Binary scoring effectiveness for cultural awareness is reasonable but lacks extensive validation against continuous alternatives
- **Low confidence**: Multi-image-per-concept design significantly improves evaluation fairness lacks direct validation and comparative studies

## Next Checks
1. Conduct inter-annotator agreement studies on CAS scoring to quantify reliability and identify ambiguous cases where binary scoring may be insufficient
2. Perform cross-cultural validation by having annotators from different cultural backgrounds score the same captions to test cultural bias in the evaluation framework
3. Test additional vision-language models beyond the four evaluated to establish whether performance patterns are model-specific or represent broader trends