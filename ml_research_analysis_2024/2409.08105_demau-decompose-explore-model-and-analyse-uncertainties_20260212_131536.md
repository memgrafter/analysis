---
ver: rpa2
title: 'DEMAU: Decompose, Explore, Model and Analyse Uncertainties'
arxiv_id: '2409.08105'
source_url: https://arxiv.org/abs/2409.08105
tags:
- uncertainty
- learning
- machine
- demau
- uncertainties
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DEMAU is an open-source educational and exploratory tool for visualizing
  and analyzing uncertainty in machine learning classification models. It enables
  decomposition of total uncertainty into epistemic (reducible) and aleatoric (irreducible)
  components, supporting multiple uncertainty quantification frameworks including
  probabilities, credal sets, possibilities, and belief functions.
---

# DEMAU: Decompose, Explore, Model and Analyse Uncertainties

## Quick Facts
- arXiv ID: 2409.08105
- Source URL: https://arxiv.org/abs/2409.08105
- Authors: Arthur Hoarau; Vincent Lemaire
- Reference count: 0
- Primary result: DEMAU is an open-source educational and exploratory tool for visualizing and analyzing uncertainty in machine learning classification models.

## Executive Summary
DEMAU is an open-source educational and exploratory tool designed to visualize and analyze uncertainty in machine learning classification models. The tool decomposes total uncertainty into epistemic (reducible) and aleatoric (irreducible) components while supporting multiple uncertainty quantification frameworks including probabilities, credal sets, possibilities, and belief functions. Built with modular architecture, DEMAU enables integration of custom datasets, models, and uncertainty methods, making it particularly useful for active learning and adaptive learning applications through uncertainty sampling.

## Method Summary
DEMAU implements uncertainty quantification and decomposition for classification models through a modular software architecture. The tool supports multiple mathematical formalisms for uncertainty including Shannon entropy, Gini index, least confident measures, and Dempster-Shafer belief functions. Users can load datasets (built-in or custom CSV files), select from pre-built models (K-NN, SVM, Naive Bayes, Random Forest), and choose uncertainty quantification methods. The tool then visualizes uncertainty as 2D maps with color gradients, enabling decomposition of uncertainty into epistemic and aleatoric components for model diagnostics and active learning applications.

## Key Results
- Successfully decomposes total uncertainty into epistemic and aleatoric components for model diagnostics
- Supports multiple uncertainty quantification frameworks (probabilistic, credal, possibilistic, belief functions)
- Offers modular integration of custom datasets, models, and uncertainty methods
- Facilitates active learning through uncertainty sampling capabilities
- Provides 2D uncertainty visualization with color gradient representation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DEMAU decomposes total uncertainty into epistemic and aleatoric components for clearer model diagnostics.
- Mechanism: The tool applies established decomposition frameworks to separate reducible epistemic uncertainty from irreducible aleatoric uncertainty, enabling targeted interventions in active learning or adaptive learning pipelines.
- Core assumption: Uncertainty decomposition methods produce consistent and meaningful partitions across different models and datasets.
- Evidence anchors:
  - [abstract] "quantification and decomposition of model uncertainty"
  - [section 2.4] "decomposition into reducible and irreducible uncertainties"
  - [corpus] weak - no direct mention of epistemic/aleatoric decomposition in neighbors
- Break condition: If the decomposition algorithm fails to converge or produces overlapping uncertainty values, the visualization will mislead users about model reliability.

### Mechanism 2
- Claim: Multiple uncertainty quantification frameworks broaden applicability.
- Mechanism: DEMAU integrates different mathematical formalisms for uncertainty (Shannon entropy, Gini index, least confident, Dempster-Shafer belief functions) so users can compare results across frameworks and select the most appropriate for their domain.
- Core assumption: Different uncertainty frameworks yield complementary insights without contradicting each other.
- Evidence anchors:
  - [abstract] "probabilities, credal sets, possibilities, and belief functions"
  - [section 2.3] "different computations of the model uncertainty, with Gini criteria, Shannon's entropy and a Least-Confident measure"
  - [corpus] weak - no corpus mention of these specific frameworks
- Break condition: If the frameworks produce inconsistent uncertainty maps, users may misinterpret the reliability of model predictions.

### Mechanism 3
- Claim: Modular architecture allows seamless integration of custom components.
- Mechanism: Users can drop CSV files into a datasets folder, add Python classes in models/ and uncertainties/ directories, and refresh the interface without restarting, enabling rapid experimentation and extension.
- Core assumption: The underlying file structure and naming conventions are robust to arbitrary user additions without breaking dependencies.
- Evidence anchors:
  - [section 2.5] "New dataset can be added by simply deposing a CSV file into the datasets folder... Machine learning models can be added in the models file and uncertainty quantification methods in the uncertainties file"
  - [abstract] "modular integration of custom datasets, models, and uncertainty methods"
  - [corpus] weak - no corpus mention of modularity
- Break condition: If a user-provided module violates expected interfaces, the tool will fail to load or crash.

## Foundational Learning

- Concept: Uncertainty quantification in classification models
  - Why needed here: DEMAU's purpose is to visualize and analyze model uncertainty; without understanding what uncertainty measures mean, users cannot interpret results.
  - Quick check question: What is the difference between aleatoric and epistemic uncertainty?

- Concept: Active learning and uncertainty sampling
  - Why needed here: DEMAU is explicitly designed for use in active learning scenarios where uncertainty guides data selection; knowing how uncertainty sampling works is essential for applying the tool effectively.
  - Quick check question: How does uncertainty sampling differ from random sampling in active learning?

- Concept: Data visualization for high-dimensional model outputs
  - Why needed here: DEMAU reduces multi-class, multi-feature outputs to 2D uncertainty maps; understanding dimensionality reduction and color gradients is necessary to correctly read the interface.
  - Quick check question: What does a red-to-blue gradient typically signify in uncertainty visualizations?

## Architecture Onboarding

- Component map: Frontend (GUI panels, dropdowns, canvas) -> Backend (data loader, model manager, uncertainty calculator) -> Plugin system (datasets/, models/, uncertainties/ folders)
- Critical path: Load dataset -> Train/select model -> Compute uncertainty -> Render 2D map with uncertainty gradient
- Design tradeoffs: Flexible plugin system vs. risk of user errors; built-in models vs. limited customizability; interactive exploration vs. performance on large datasets
- Failure signatures: Dataset not loading (CSV format error); model not appearing (class not registered); uncertainty calculation hangs (grid size too large); color gradient not rendering (matplotlib backend issue)
- First 3 experiments:
  1. Load built-in Iris dataset, select K-NN model, view total uncertainty map
  2. Load built-in Iris dataset, select Naive Bayes, compute and compare Gini vs. entropy uncertainty maps
  3. Add a simple CSV dataset, implement a dummy model, verify it appears in the model dropdown

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DEMAU's uncertainty visualization impact the effectiveness of active learning compared to traditional uncertainty sampling methods?
- Basis in paper: [inferred] The paper mentions DEMAU is useful for "active learning or adaptive learning, and especially in uncertainty sampling" but doesn't provide empirical comparisons.
- Why unresolved: The paper presents DEMAU as a tool without evaluating its practical impact on active learning performance.
- What evidence would resolve it: Empirical studies comparing active learning outcomes using DEMAU's uncertainty visualizations versus traditional uncertainty sampling methods on benchmark datasets.

### Open Question 2
- Question: How does the decomposition of uncertainty into epistemic and aleatoric components in DEMAU correlate with actual model improvement potential?
- Basis in paper: [explicit] The paper mentions "decomposition into reducible (epistemic) and irreducible (aleatoric) components" but doesn't validate if this decomposition guides effective model improvement.
- Why unresolved: The paper presents the decomposition capability but doesn't demonstrate its practical utility in identifying areas where model improvement is most beneficial.
- What evidence would resolve it: Studies showing how accurately the decomposed uncertainty regions in DEMAU predict where additional training data would most improve model performance.

### Open Question 3
- Question: How does DEMAU handle uncertainty visualization for high-dimensional datasets beyond the 2D reduction techniques mentioned?
- Basis in paper: [inferred] The paper mentions "reduction techniques" for 2D representation but doesn't elaborate on their effectiveness for high-dimensional data.
- Why unresolved: The paper focuses on 2D visualization capabilities without addressing challenges in visualizing uncertainty for high-dimensional datasets.
- What evidence would resolve it: Evaluation of DEMAU's uncertainty visualization quality and interpretability when applied to datasets with varying numbers of dimensions, and comparison with alternative high-dimensional visualization methods.

## Limitations

- The tool's effectiveness depends heavily on the quality and diversity of user-provided datasets and models, with no built-in dataset curation or model validation
- Performance on large datasets may be limited due to computational overhead in uncertainty calculation across dense 2D grids
- The decomposition into epistemic and aleatoric uncertainty relies on theoretical frameworks that may not generalize well to all model types or data distributions

## Confidence

- **High Confidence**: DEMAU successfully implements uncertainty visualization and supports multiple uncertainty quantification frameworks as described
- **Medium Confidence**: The modular architecture allows integration of custom components, though user experience may vary based on technical expertise
- **Low Confidence**: The accuracy and meaningfulness of uncertainty decomposition across diverse real-world scenarios remains unverified

## Next Checks

1. Test DEMAU with a benchmark dataset (e.g., MNIST) across all supported uncertainty frameworks and verify consistency of uncertainty maps
2. Implement a custom uncertainty quantification method and validate it integrates correctly with the plugin system
3. Evaluate tool performance and visualization quality on a large dataset (1000+ samples, 10+ features) to identify scalability limitations