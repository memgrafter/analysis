---
ver: rpa2
title: Computational Thought Experiments for a More Rigorous Philosophy and Science
  of the Mind
arxiv_id: '2405.08304'
source_url: https://arxiv.org/abs/2405.08304
tags:
- world
- they
- virtual
- about
- science
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper advocates for the use of Virtual World Cognitive Science
  (VW CogSci) to study mental and linguistic representation. By using virtual embodied
  agents in simulated environments, researchers can model complex cognitive processes
  and interactions between minds and worlds.
---

# Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind

## Quick Facts
- arXiv ID: 2405.08304
- Source URL: https://arxiv.org/abs/2405.08304
- Authors: Iris Oved; Nikhil Krishnaswamy; James Pustejovsky; Joshua Hartshorne
- Reference count: 17
- Key outcome: This paper advocates for the use of Virtual World Cognitive Science (VW CogSci) to study mental and linguistic representation through embodied agents in simulated environments, focusing on belief and concept tokens rather than types.

## Executive Summary
This paper proposes Virtual World Cognitive Science (VW CogSci) as a method to study mental and linguistic representation by using embodied agents in simulated environments. The approach allows researchers to take a god's-eye view of dynamical relationships between mental entities and environmental entities, eliminating problematic talk of belief and concept types while preserving tokens in individual cognizers' minds. By simulating complex interactions in virtual worlds, VW CogSci provides a more rigorous framework for studying cognitive development and the nature of mental representations.

## Method Summary
The method involves building virtual worlds using platforms like VOXWorlds and VOXML to create environments with objects and agents. Researchers implement embodied virtual agents with sensory and motor capabilities and configure learning algorithms to form mental representations from perceptual experiences. Simulations are run to observe how agents interact with their environment and form concepts, with the goal of tracking dynamical relationships between mental entities and environmental entities. The approach focuses on belief and concept tokens rather than types, allowing for a more rigorous study of cognitive development and representation.

## Key Results
- VW CogSci eliminates belief and concept type puzzles by providing a god's-eye view of token-level representations
- The method supports rigorous testing of cognitive development theories through controlled counterfactual simulations
- VW CogSci enables exploration of non-human and non-actual minds in non-actual worlds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VW CogSci eliminates belief and concept type puzzles by providing a god's-eye view of token-level representations.
- Mechanism: By modeling individual concept and belief tokens in virtual agents, researchers bypass the need to resolve type-level identity questions.
- Core assumption: Type-level identity puzzles arise from incomplete scenario descriptions; a full simulation eliminates ambiguity.
- Evidence anchors: [abstract] discusses eliminating problematic talk of belief and concept types while preserving tokens; [section] describes children learning and carving joints in their world through simulation.
- Break condition: If the simulation environment cannot represent all relevant sensory and motor details, the god's-eye view remains incomplete.

### Mechanism 2
- Claim: VW CogSci supports rigorous testing of cognitive development theories through controlled counterfactual simulations.
- Mechanism: Researchers can build virtual worlds with different physics, object properties, and learning algorithms to test how agents develop representations under varied conditions.
- Core assumption: Cognitive development can be meaningfully studied by varying environmental and agent parameters in simulation.
- Evidence anchors: [abstract] mentions rigorous framework for studying cognitive development; [section] describes building worlds with different gravity or properties.
- Break condition: If the simulation platform lacks sufficient fidelity to model the relevant cognitive processes, results may not generalize.

### Mechanism 3
- Claim: VW CogSci enables exploration of non-human and non-actual minds in non-actual worlds.
- Mechanism: By decoupling cognition from human embodiment and our actual world, researchers can test theories about possible minds in possible environments.
- Core assumption: Understanding cognition requires studying minds beyond those like ours in our world.
- Evidence anchors: [abstract] discusses simulation of complex dynamical relationships; [section] mentions exploring how agents interact with various possible worlds.
- Break condition: If the theory of mind being tested requires human-specific constraints, non-actual simulations may not apply.

## Foundational Learning

- Concept: Embodied and embedded cognition
  - Why needed here: VW CogSci is grounded in the idea that cognition depends on sensory-motor interactions with an environment, not just internal processing.
  - Quick check question: What is the difference between embodied and embedded cognition?

- Concept: Propositional attitudes (beliefs and desires)
  - Why needed here: The paper argues for focusing on belief and concept tokens rather than types, which are tied to propositional attitudes.
  - Quick check question: Why might some cognitive scientists argue for eliminating talk of beliefs and desires from scientific explanations?

- Concept: Thought experiments in philosophy
  - Why needed here: The paper uses philosophical puzzles (e.g., Kripke's Pierre, Putnam's Twin Earth) to motivate the need for VW CogSci as a more rigorous method.
  - Quick check question: What is a key limitation of traditional philosophical thought experiments that VW CogSci addresses?

## Architecture Onboarding

- Component map: VOXWorlds platform (Unity-based environment builder) -> VOXML (object and behavior modeling language) -> Virtual agents (embodied, with sensors and actuators) -> Learning algorithms (symbolic, neural, hybrid) -> Simulation engine (physics, dynamics, rendering)

- Critical path: 1. Define research question (e.g., concept learning in novel environments) 2. Build or select VOXWorld scenario 3. Design or select virtual agent(s) 4. Configure learning algorithm(s) 5. Run simulation 6. Analyze agent representations and behaviors

- Design tradeoffs:
  - Fidelity vs. computational cost: Higher-fidelity simulations take longer but may yield more realistic results.
  - Symbolic vs. neural representations: Symbolic models are more interpretable; neural models may learn more flexibly.
  - Open vs. closed worlds: Open worlds allow more agent autonomy but are harder to control.

- Failure signatures:
  - Agent fails to form coherent representations: Check sensor/actuator configuration and learning algorithm.
  - Simulation runs but yields no meaningful data: Verify that world and agent are sufficiently complex and interactive.
  - Results don't generalize: Ensure that the simulation includes sufficient variation and controls.

- First 3 experiments:
  1. Replicate Kripke's Pierre scenario in a simple VOXWorld to observe token-level concept formation and misalignment.
  2. Test concept learning under varying object properties (e.g., jadeite vs. nephrite) to see how agents carve up categories.
  3. Compare symbolic vs. neural agent representations in a shared environment to evaluate interpretability and flexibility.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can virtual agents in simulated environments develop and use mental representations that are functionally equivalent to human concepts and beliefs?
- Basis in paper: [explicit] The paper discusses how virtual agents can form representations and how these might develop through experience in the virtual world.
- Why unresolved: While the paper demonstrates the potential for virtual agents to form representations, it does not conclusively prove that these are functionally equivalent to human concepts and beliefs.
- What evidence would resolve it: Comparative studies showing that virtual agents can perform tasks requiring complex reasoning and concept use at a level comparable to humans.

### Open Question 2
- Question: How do different sensory and motor configurations in virtual agents affect their ability to learn and use concepts?
- Basis in paper: [explicit] The paper mentions experimenting with different "innate" sensory and motor abilities in virtual agents.
- Why unresolved: The paper does not provide empirical data on how varying sensory and motor configurations impact concept learning and use in virtual agents.
- What evidence would resolve it: Systematic experiments comparing concept learning and use across virtual agents with different sensory and motor configurations.

### Open Question 3
- Question: Can the method of Virtual World Cognitive Science (VW CogSci) provide new insights into the nature of mental and linguistic representation that are not accessible through traditional philosophical methods?
- Basis in paper: [explicit] The paper argues that VW CogSci can dissolve philosophical puzzles about representation by providing a god's-eye view.
- Why unresolved: While the paper presents a theoretical argument for the potential of VW CogSci, it does not provide concrete examples of new insights gained through this method.
- What evidence would resolve it: Case studies where VW CogSci has led to novel theoretical insights or empirical findings about mental and linguistic representation.

## Limitations
- The central claim that VW CogSci eliminates belief and concept type puzzles receives Medium confidence due to lack of empirical validation through implemented simulations.
- The claim about supporting rigorous testing of cognitive development theories receives Medium confidence as the paper lacks concrete examples of successful simulations.
- The assertion that VW CogSci enables exploration of non-human and non-actual minds receives Low confidence for generalization claims due to lack of demonstrated translation to understanding actual human cognition.

## Confidence
- VW CogSci eliminates belief and concept type puzzles: Medium confidence
- VW CogSci supports rigorous testing of cognitive development theories: Medium confidence
- VW CogSci enables exploration of non-human and non-actual minds: Low confidence

## Next Checks
1. Implement and run a simulation of Kripke's Pierre scenario to observe whether token-level representations actually resolve the type-level identity puzzle in practice.
2. Compare concept learning outcomes between symbolic and neural agent architectures in identical VW CogSci environments to evaluate the trade-offs claimed between interpretability and flexibility.
3. Test concept formation under varying environmental complexity levels to determine the minimum simulation fidelity required for meaningful cognitive insights.