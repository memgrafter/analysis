---
ver: rpa2
title: 'Event Extraction in Basque: Typologically motivated Cross-Lingual Transfer-Learning
  Analysis'
arxiv_id: '2404.06392'
source_url: https://arxiv.org/abs/2404.06392
tags:
- language
- event
- languages
- extraction
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how typological similarity between source
  and target languages impacts cross-lingual transfer learning for Event Extraction.
  The authors introduce EusIE, the first Event Extraction dataset for Basque, and
  conduct experiments across three tasks (entity detection, event detection, and argument
  extraction) using 72 language pairs.
---

# Event Extraction in Basque: Typologically motivated Cross-Lingual Transfer-Learning Analysis

## Quick Facts
- **arXiv ID**: 2404.06392
- **Source URL**: https://arxiv.org/abs/2404.06392
- **Reference count**: 0
- **Key outcome**: Typological similarity between source and target languages significantly impacts cross-lingual transfer learning for Event Extraction, with different linguistic features (script, morphology, word order) being more relevant for different tasks.

## Executive Summary
This paper investigates how linguistic similarity between source and target languages affects cross-lingual transfer learning for Event Extraction. The authors introduce EusIE, the first Event Extraction dataset for Basque, and conduct experiments across three tasks (entity detection, event detection, and argument extraction) using 72 language pairs. The key finding is that shared linguistic characteristics significantly affect transfer quality, with different features being more relevant for different tasks: common writing script and morphological features benefit token classification tasks, while common word order is most important for structural prediction tasks like argument extraction.

## Method Summary
The study uses XLM-RoBERTa (base version) as the backbone multilingual language model and trains three separate models for entity detection, event detection, and argument extraction. The approach uses token classification for entity and event detection tasks, while argument extraction employs a conditional generation approach using event trigger markers. Experiments involve training models on source language data from the MEE dataset and evaluating on the newly created EusIE Basque dataset, with analysis of linguistic features (script, morphology, word order) across all 72 language pairs to understand their impact on transfer quality.

## Key Results
- Basque achieves consistently lower F1 scores across all three Event Extraction tasks compared to other target languages
- For token classification tasks (entity and event detection), shared writing script and morphological similarity are the most important factors for transfer quality
- For structural prediction tasks (argument extraction), word order similarity is the most critical feature for successful cross-lingual transfer
- Different source languages perform variably across tasks, with English being particularly effective for entity and event detection but less so for argument extraction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shared writing script between source and target languages improves cross-lingual transfer quality for all three tasks (entity, event, argument extraction).
- Mechanism: Languages with the same script share more tokens in the model's vocabulary, leading to better representation and understanding during transfer.
- Core assumption: The multilingual language model's tokenizer treats tokens from the same script similarly, enabling better cross-lingual transfer.
- Evidence anchors:
  - [abstract] "Further analysis reveals that for tasks involving token classification (i.e. entity and trigger identification) sharing writing script shows higher cross-lingual transfer benefit."
  - [section] "Script turns out to be the most relevant feature across tasks."
  - [corpus] Weak evidence: No explicit discussion of script in corpus data, only inferred from model behavior.
- Break condition: If the tokenizer is significantly biased towards certain scripts or if languages with the same script have vastly different vocabularies.

### Mechanism 2
- Claim: Word order similarity between source and target languages is most important for event argument extraction.
- Mechanism: Similar word order allows the model to better understand the structural relationships between events and their arguments, improving transfer for argument extraction.
- Core assumption: The model relies on word order patterns to identify argument roles in event extraction.
- Evidence anchors:
  - [abstract] "In contrast, for tasks involving structural prediction like argument extraction, common word order is the most relevant feature."
  - [section] "Word Order, as we hypothesized, affects significantly the argument extraction task."
  - [corpus] Weak evidence: No explicit analysis of word order impact on model performance in corpus data.
- Break condition: If the model relies more on other syntactic features or if word order is not as critical for argument extraction in the specific dataset.

### Mechanism 3
- Claim: Languages with similar morphology perform better for entity and event detection tasks.
- Mechanism: Shared morphological features lead to more consistent tokenization and representation of entities and events across languages.
- Core assumption: Morphological similarity results in better cross-lingual token representation for entity and event detection.
- Evidence anchors:
  - [abstract] "Further analysis reveals that for tasks involving token classification (i.e. entity and trigger identification) sharing writing script shows higher cross-lingual transfer benefit. In contrast, when structural understanding is involved (e.g. argument extraction) word order matters the most."
  - [section] "Morphology is an important feature in entity and event detection, where lexical information could play a significant role, as we hypothesized."
  - [corpus] Weak evidence: No explicit discussion of morphology impact on model performance in corpus data.
- Break condition: If the model does not rely heavily on morphological features for entity and event detection or if other linguistic features are more important.

## Foundational Learning

- Concept: Cross-lingual transfer learning
  - Why needed here: Understanding how models trained on one language can be applied to another is crucial for leveraging resources in low-resource languages like Basque.
  - Quick check question: What are the main challenges in cross-lingual transfer learning, and how do they differ from monolingual approaches?

- Concept: Event extraction pipeline
  - Why needed here: The paper focuses on three tasks in event extraction (entity detection, event detection, argument extraction), and understanding the pipeline is essential for interpreting the results.
  - Quick check question: How do the three tasks in event extraction differ in terms of complexity and the skills required for each?

- Concept: Language typology
  - Why needed here: The paper analyzes how different linguistic features (script, morphology, word order) impact cross-lingual transfer, requiring an understanding of language typology.
  - Quick check question: What are the main dimensions of language typology, and how do they influence the way languages are processed by NLP models?

## Architecture Onboarding

- Component map:
  - XLM-RoBERTa (base version) -> Three separate models (entity detection, event detection, argument extraction) -> Basque evaluation (EusIE dataset)

- Critical path:
  1. Preprocess text using IXA-pipes for Basque tokenization
  2. Train three models (entity, event, argument) on source language data
  3. Evaluate models on Basque (EusIE dataset)
  4. Analyze results based on linguistic features of source and target languages

- Design tradeoffs:
  - Using a sequence labeling approach vs. more complex architectures like question answering or textual entailment
  - Focusing on Basque as a target language vs. a more diverse set of target languages
  - Using expert annotators vs. crowd-working services for dataset creation

- Failure signatures:
  - Poor performance on Basque compared to other target languages
  - Inconsistent results across the three tasks
  - Lack of correlation between linguistic features and transfer quality

- First 3 experiments:
  1. Replicate in-language experiments on MEE dataset to establish baseline performance
  2. Train models on each source language and evaluate on Basque (EusIE dataset)
  3. Analyze the impact of linguistic features on cross-lingual transfer by running all-vs-all experiments and performing regression analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different cross-lingual transfer approaches (e.g., parallel corpora projection, model fine-tuning, knowledge distillation) compare to the multilingual sequence labeling approach used in this paper for Basque Event Extraction?
- Basis in paper: [explicit] The authors mention parallel corpora projection as a previous approach and note they chose multilingual sequence labeling for efficiency, but do not compare these approaches.
- Why unresolved: The paper only evaluates one cross-lingual transfer method, making it impossible to determine if the observed typological effects are specific to this approach or generalizable across methods.
- What evidence would resolve it: Comparative experiments using multiple cross-lingual transfer approaches (parallel corpora projection, model fine-tuning, knowledge distillation) with the same Basque dataset and typological analysis would reveal whether the observed language transfer patterns are method-specific or universal.

### Open Question 2
- Question: How do the typological transfer patterns observed for Basque generalize to other low-resource languages with different typological profiles (e.g., morphologically rich languages like Finnish, or languages with different scripts like Arabic or Chinese)?
- Basis in paper: [explicit] The authors analyze 72 language pairs but only test Basque as the target language, hypothesizing that their findings might apply more broadly but not empirically verifying this.
- Why unresolved: The paper's analysis is limited to Basque as the target language, and while it covers many source languages, the results may be specific to Basque's unique typological features.
- What evidence would resolve it: Extending the experiments to additional low-resource target languages with diverse typological profiles (e.g., Finnish, Arabic, Chinese) would reveal whether the script, morphology, and word order effects observed for Basque are universal or language-specific.

### Open Question 3
- Question: What is the impact of training data size on cross-lingual transfer quality when the source and target languages share different combinations of typological features?
- Basis in paper: [explicit] The authors observe that languages scale differently with training data and that mixing all languages helps at smaller sizes but introduces noise at larger sizes, but do not systematically analyze this interaction with typological similarity.
- Why unresolved: The paper examines training data scaling but does not analyze how the relationship between training size and transfer quality varies depending on the degree of typological similarity between source and target languages.
- What evidence would resolve it: Controlled experiments varying training data sizes for language pairs with different levels of typological similarity (high script/morphology similarity vs. low similarity) would reveal whether typological distance affects the optimal training size for cross-lingual transfer.

## Limitations
- The study relies on only one multilingual model (XLM-RoBERTa), limiting generalizability to other architectures
- High variance in argument extraction results suggests potential instability in findings
- No inter-annotator agreement statistics provided for the expert-annotated Basque dataset

## Confidence
**High Confidence:** The general finding that typological similarity affects cross-lingual transfer quality is well-supported by the experimental results across all three tasks.

**Medium Confidence:** The specific rankings of linguistic features by importance (script > morphology > word order for entity/event detection; word order > others for argument extraction) are supported by the data but would benefit from additional validation.

**Low Confidence:** The precise quantitative impact of each linguistic feature on transfer quality requires more rigorous statistical analysis, and the claim about lexical information significance remains speculative.

## Next Checks
1. **Statistical Robustness Analysis**: Conduct bootstrap resampling of the 72 language pairs to establish confidence intervals for the reported feature importance rankings, particularly for the argument extraction task which shows high variance.

2. **Controlled Feature Ablation**: Design experiments that isolate individual linguistic features by selecting language pairs that differ on only one dimension (e.g., same script but different word order, or same word order but different script) to test causal relationships.

3. **Cross-Model Validation**: Replicate the key experiments using alternative multilingual architectures (e.g., mT5, multilingual BERT) to assess whether the linguistic feature effects generalize beyond XLM-RoBERTa.