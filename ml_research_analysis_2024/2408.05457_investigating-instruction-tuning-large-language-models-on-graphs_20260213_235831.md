---
ver: rpa2
title: Investigating Instruction Tuning Large Language Models on Graphs
arxiv_id: '2408.05457'
source_url: https://arxiv.org/abs/2408.05457
tags:
- graph
- tasks
- llms
- language
- unseen
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores instruction-tuning large language models (LLMs)
  on graph-structured data. The authors construct a comprehensive benchmark dataset
  with 79 fine-grained graph tasks from academic and e-commerce domains, totaling
  44,240 training instances and 18,960 test samples.
---

# Investigating Instruction Tuning Large Language Models on Graphs

## Quick Facts
- arXiv ID: 2408.05457
- Source URL: https://arxiv.org/abs/2408.05457
- Reference count: 8
- Primary result: JSON graph representation consistently outperforms natural language and DOT formats across different LLMs and graph types

## Executive Summary
This paper explores instruction tuning large language models (LLMs) on graph-structured data by constructing a comprehensive benchmark dataset with 79 fine-grained graph tasks from academic and e-commerce domains. The study investigates three graph representation formats - natural language, JSON, and DOT - finding that JSON consistently yields the best performance across different LLMs and graph types. The research also examines LLM generalization abilities across three levels: unseen subtasks, unseen domains, and unseen answer types, revealing both promising capabilities and limitations in handling inductive reasoning tasks.

## Method Summary
The researchers constructed a dataset with 79 graph-related tasks from Amazon Metadata and MAPLE datasets, containing 44,240 training instances and 18,960 test samples. They fine-tuned LLMs (Llama-2, Mistral, Gemma) using LoRA parameter-efficient fine-tuning on question-graph pairs with different graph representations. The evaluation used Exact Match (EM) and F1 score metrics, testing generalization across unseen subtasks, domains, and answer types. The study systematically compared performance across different graph representation formats and LLM architectures.

## Key Results
- JSON format for graph representation consistently outperforms natural language and DOT formats across various LLMs and graph types
- LLMs can effectively generalize to new subtasks and domains but struggle with inductive reasoning tasks like link prediction
- Models may overfit on simple counting tasks while showing promise in deriving new algorithms based on learned graph understanding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: JSON representation improves LLM performance on graph tasks because it provides a structured, machine-readable format that aligns with the systematic processing capabilities of LLMs.
- Mechanism: JSON format offers a clear, hierarchical structure that maps well to graph data, allowing LLMs to efficiently parse and understand graph relationships, leading to better performance on tasks like finding neighbors, counting nodes, and pathfinding.
- Core assumption: LLMs are trained on diverse text data that includes JSON-like structures, making them familiar with this format.
- Evidence anchors:
  - [abstract]: "Our findings indicate that JSON format for graph representation consistently outperforms natural language and code formats across various LLMs and graph types."
  - [section 4.2.1]: "The findings indicate that JSON format for graph representation consistently outperforms natural language and code formats across various LLMs and graph types."
  - [corpus]: Weak evidence. Related papers discuss graph representations but don't specifically address JSON's effectiveness.
- Break condition: If LLMs are not pre-trained on JSON-like structures, or if the graph complexity exceeds the JSON format's ability to represent it clearly.

### Mechanism 2
- Claim: Instruction tuning on graph-related tasks enables LLMs to develop a general understanding of graph structures and algorithms.
- Mechanism: By training on diverse graph tasks, LLMs learn to recognize and apply graph algorithms like finding neighbors, counting nodes, and pathfinding. This knowledge generalizes to unseen tasks and domains.
- Core assumption: LLMs can learn and apply abstract graph concepts from specific examples during training.
- Evidence anchors:
  - [abstract]: "Our findings also reveal LLM is capable of handling tasks requiring graph algorithms not seen during training, which indicates that graph instruction tuning enables LLM to derive new algorithms itself based on its understanding of the graph and the algorithms learned during training."
  - [section 4.2.2]: "However, the LLM may easily get overfitted on simple counting tasks and doesnâ€™t generalize well on inductive reasoning tasks like link prediction."
  - [corpus]: Weak evidence. Related papers discuss instruction tuning but don't specifically address its effectiveness on graph tasks.
- Break condition: If the training tasks are too limited or not diverse enough to cover the range of graph algorithms needed for generalization.

### Mechanism 3
- Claim: Decomposing complex graph tasks into fine-grained sub-tasks improves LLM generalization.
- Mechanism: By breaking down tasks into sub-tasks, LLMs can focus on specific aspects of graph algorithms. This allows for more targeted learning and better generalization to unseen sub-tasks.
- Core assumption: LLMs can effectively learn and apply specific sub-tasks to solve more complex, unseen tasks.
- Evidence anchors:
  - [section 3.3]: "Furthermore, we subdivided each task into 2 to 4 sub-tasks, which share the same graph algorithm but focus on different node or edge types."
  - [section 4.2.2]: "As mentioned in Section 3.3, we show the performance of models over the in-domain seen and unseen sub-tasks under each answer type."
  - [corpus]: Weak evidence. Related papers don't specifically address the impact of task decomposition on LLM performance.
- Break condition: If the sub-tasks are too similar or not representative of the full range of graph algorithms needed for generalization.

## Foundational Learning

- Concept: Graph representation formats (Natural Language, JSON, DOT)
  - Why needed here: Understanding different graph representation formats is crucial for effectively using LLMs on graph-related tasks. The choice of representation significantly impacts LLM performance.
  - Quick check question: What are the key differences between natural language, JSON, and DOT formats for representing graph data, and how might these differences affect an LLM's ability to process the information?

- Concept: Graph algorithms (Finding neighbors, Counting nodes, Pathfinding)
  - Why needed here: LLMs need to understand and apply various graph algorithms to solve graph-related tasks. Knowledge of these algorithms is essential for designing effective instruction tuning and evaluating LLM performance.
  - Quick check question: Can you describe the basic steps of finding neighbors, counting nodes, and pathfinding algorithms in a graph? How might an LLM approach these tasks differently from traditional graph processing methods?

- Concept: Generalization in machine learning
  - Why needed here: Understanding generalization is crucial for evaluating the effectiveness of instruction tuning on LLMs. It helps in assessing how well the models can apply learned knowledge to new, unseen tasks and domains.
  - Quick check question: What is generalization in machine learning, and why is it particularly challenging for LLMs when dealing with graph-structured data? How do the three levels of generalization (unseen sub-tasks, unseen domains, unseen answer types) contribute to a comprehensive evaluation of LLM performance?

## Architecture Onboarding

- Component map:
  - Graph data sources (Amazon Metadata, MAPLE) -> Graph sampling and preprocessing pipeline -> Instruction tuning framework (LoRA, parameter-efficient fine-tuning) -> Evaluation framework (metrics: EM, F1 score) -> Different LLM models (Llama-2, Mistral, Gemma)

- Critical path:
  1. Graph data collection and preprocessing
  2. Instruction tuning with different graph representations
  3. Evaluation on seen and unseen tasks
  4. Analysis of results and identification of strengths/weaknesses

- Design tradeoffs:
  - Graph representation format: JSON vs. natural language vs. DOT
  - Model scale: 7B vs. 13B parameters
  - Training domain: Amazon vs. MAPLE
  - Task granularity: Fine-grained sub-tasks vs. broader task categories

- Failure signatures:
  - Overfitting on simple counting tasks
  - Difficulty with inductive reasoning tasks like link prediction
  - Struggles with unseen answer types
  - Performance degradation on larger, more complex graphs

- First 3 experiments:
  1. Compare LLM performance on graph tasks using different graph representation formats (JSON, natural language, DOT) on a small, simple graph.
  2. Evaluate LLM generalization by testing on unseen sub-tasks within the same domain and graph representation format.
  3. Assess domain generalization by training on one dataset (e.g., Amazon) and testing on another (e.g., MAPLE) with the same graph representation format.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific graph representation format beyond JSON, natural language, and DOT would yield optimal performance for instruction-tuning LLMs on graphs?
- Basis in paper: [explicit] The paper compares three graph representations (natural language, JSON, and DOT) and finds JSON consistently performs best, but does not explore other formats like XML or YAML.
- Why unresolved: The study focuses on three common representations and does not investigate whether other formats might offer superior performance.
- What evidence would resolve it: Conducting instruction-tuning experiments with alternative graph representation formats and comparing their performance metrics against the existing formats would provide a definitive answer.

### Open Question 2
- Question: How does the performance of instruction-tuned LLMs on graph tasks scale with the size of the training graph?
- Basis in paper: [inferred] The paper mentions that subgraphs from the Amazon Metadata network are generally larger than those from the MAPLE network and observes differences in cross-domain generalization, suggesting a potential relationship between graph size and model performance.
- Why unresolved: While the paper notes a correlation between graph size and performance, it does not explicitly test how performance scales with varying graph sizes.
- What evidence would resolve it: Training LLMs on graphs of systematically varied sizes and measuring performance on corresponding test sets would clarify the relationship between graph size and model effectiveness.

### Open Question 3
- Question: Can instruction-tuned LLMs effectively generalize to graph tasks involving node or edge types that were not present in the training data?
- Basis in paper: [explicit] The paper investigates generalization to unseen sub-tasks, domains, and answer types but does not specifically address the challenge of completely new node or edge types.
- Why unresolved: The experiments focus on tasks that are structurally similar to those seen during training, leaving open the question of how models handle entirely novel graph elements.
- What evidence would resolve it: Designing experiments where LLMs are trained on graphs with a limited set of node and edge types and then tested on graphs containing entirely new types would determine their ability to generalize to unseen graph elements.

## Limitations

- Dataset construction bias: The study relies on two specific datasets (Amazon Metadata and MAPLE) which may not fully represent the diversity of real-world graph structures
- Representation format constraints: The study doesn't explore hybrid representations or alternative structured formats that might better capture complex graph relationships
- Model size and architecture constraints: Experiments are limited to 7B and 13B parameter models, leaving uncertainty about how findings scale to larger models

## Confidence

- High confidence: JSON format consistently outperforms natural language and DOT representations across different LLMs and graph types
- Medium confidence: Generalization capabilities across unseen subtasks and domains are demonstrated but may be influenced by specific task decomposition and dataset selection
- Low confidence: Claim about LLMs' ability to "derive new algorithms itself based on its understanding of the graph" is based on limited evidence

## Next Checks

1. Cross-dataset validation: Test the instruction-tuned models on entirely new graph datasets (e.g., social networks, biological networks) not seen during training or used in the original evaluation to verify generalization claims.

2. Ablation study on graph representation complexity: Systematically vary the complexity of JSON representations (nested structures, multiple relationship types) to identify breaking points where performance degrades significantly.

3. Inductive reasoning benchmark: Create a dedicated benchmark with more challenging link prediction tasks involving unseen edge types and complex reasoning patterns to better assess the claimed limitations in inductive reasoning capabilities.