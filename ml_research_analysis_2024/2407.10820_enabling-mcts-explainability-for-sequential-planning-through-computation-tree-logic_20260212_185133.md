---
ver: rpa2
title: Enabling MCTS Explainability for Sequential Planning Through Computation Tree
  Logic
arxiv_id: '2407.10820'
source_url: https://arxiv.org/abs/2407.10820
tags:
- mcts
- planning
- queries
- query
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining Monte Carlo Tree
  Search (MCTS) decisions in sequential planning for public transit systems. The authors
  introduce a novel explanation framework using Computation Tree Logic (CTL) to make
  MCTS decisions interpretable for non-technical users.
---

# Enabling MCTS Explainability for Sequential Planning Through Computation Tree Logic
## Quick Facts
- arXiv ID: 2407.10820
- Source URL: https://arxiv.org/abs/2407.10820
- Reference count: 40
- Primary result: CTL-based explainer significantly outperforms baselines in user study for MCTS decision explanation

## Executive Summary
This paper addresses the challenge of explaining Monte Carlo Tree Search (MCTS) decisions in sequential planning for public transit systems. The authors introduce a novel explanation framework using Computation Tree Logic (CTL) to make MCTS decisions interpretable for non-technical users. Their approach translates user queries into formal logic specifications, verifies these against the MCTS search tree using CTL semantics, and converts the results into natural language explanations using predefined templates.

The framework successfully handles three types of queries (factual, contrastive, and tree expansion) and adapts to different user technical backgrounds. A user study with 82 participants demonstrated that this CTL-based explainer significantly outperforms baseline methods in terms of understandability, satisfaction, completeness, and reliability when explaining route planning decisions.

## Method Summary
The paper presents a framework that enables MCTS explainability through CTL by first translating user-defined requirements into rigorous logic specifications using language templates. These CTL formulas are then verified against the MCTS search tree using formal CTL semantics. The framework records quantitative details of any violations and generates natural language explanations using predefined templates. The approach handles three query types: factual queries about algorithm decisions, contrastive queries comparing alternatives, and tree expansion queries exploring additional options. A user study with 82 participants evaluated the framework's effectiveness across five different scenarios.

## Key Results
- CTL-based explainer significantly outperforms baseline methods in user study
- Framework successfully handles three query types (factual, contrastive, tree expansion)
- Explanations demonstrate high understandability and satisfaction across different user technical backgrounds
- Quantitative violation tracking provides actionable feedback beyond binary satisfaction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CTL formulas provide a formal bridge between user queries and MCTS search tree verification
- Mechanism: User queries are translated into CTL formulas using language templates and state variables, then checked against the MCTS search tree using CTL semantics. The binary satisfaction results are combined with quantitative violation data to generate natural language explanations.
- Core assumption: User queries can be adequately captured by predefined language templates and mapped to appropriate state variables and CTL specifications.
- Evidence anchors:
  - [abstract] "Our framework begins by taking user-defined requirements and translating them into rigorous logic specifications through the use of language templates."
  - [section 3.3] "We employ the following structured language template: 'Based on the current vehicle assignment, is it expected that [ passenger number] will be [ action] [time]?'"
  - [corpus] Weak - no direct corpus evidence found for this specific CTL-to-query mapping approach.

### Mechanism 2
- Claim: Quantitative violation tracking provides actionable feedback beyond binary CTL satisfaction
- Mechanism: When CTL formulas evaluate to false, the explainer records specific violation details (e.g., delay in minutes, capacity overflow) at each violating state, then aggregates this data to calculate violation percentages and temporal ranges.
- Core assumption: Users benefit more from understanding the extent and pattern of violations rather than just knowing they exist.
- Evidence anchors:
  - [section 3.2] "To provide a quantitative assessment of each state where the CTL formula evaluates to false, we record the specific details of the violation, such as the extent of delay in minutes, at that particular state."
  - [section 3.4] "Specifically, at line 13 of Algorithm 2, we derive two key quantitative insights from the aggregated list of violations across all expanded nodes within the MCTS tree."
  - [corpus] Weak - limited corpus evidence for this specific quantitative tracking approach in MCTS explainability.

### Mechanism 3
- Claim: Three-query categorization aligns with user information needs across technical backgrounds
- Mechanism: Factual queries address "why was this action taken?", contrastive queries address "why not this alternative?", and tree expansion queries address "what if we explored further?". This structure adapts explanations to user expertise levels.
- Core assumption: Users have distinct information needs that map cleanly to these three categories, and these categories sufficiently cover the space of explainable MCTS decisions.
- Evidence anchors:
  - [abstract] "Our explainer categorizes user queries into three varieties: factual queries that provide insights into the algorithm's decisions derived from states and actions in the search tree, contrastive queries that compare user-suggested decisions with the algorithm's recommendations by identifying CTL violations or inferior rewards, and alternative plan explanations that involve extending the search to additional options."
  - [section 4.2] "We assess the effectiveness of each query type using the following questions..."
  - [corpus] Moderate - some corpus evidence for query categorization in explainable AI, but not specifically for MCTS.

## Foundational Learning

- Concept: Computation Tree Logic (CTL) syntax and semantics
  - Why needed here: CTL provides the formal logic framework for verifying MCTS search tree properties against user queries
  - Quick check question: What is the difference between the "A" (for all) and "E" (exists) quantifiers in CTL, and when would you use each?

- Concept: Monte Carlo Tree Search (MCTS) algorithm structure
  - Why needed here: Understanding MCTS tree structure is essential for knowing how to verify queries against the search tree
  - Quick check question: In MCTS, what do the N(s,a) and Q(s,a) values represent at each tree node?

- Concept: Markov Decision Process (MDP) formulation for sequential planning
  - Why needed here: The MDP provides the state, action, and reward structure that MCTS explores, which determines what can be explained
  - Quick check question: In the transit planning MDP described, what are the state variables and how do they define the search space?

## Architecture Onboarding

- Component map: Query Processor -> CTL Verifier -> Violation Tracker -> Explanation Generator -> MCTS Engine
- Critical path: Query → CTL Translation → Tree Verification → Violation Aggregation → Natural Language Generation
- Design tradeoffs:
  - Template-based query mapping vs. free-form query processing: Templates ensure consistency but limit expressiveness
  - Binary satisfaction vs. quantitative violation tracking: Binary is simpler but less informative; quantitative is richer but more complex
  - Search tree vs. tree expansion: Using existing tree is faster but may miss explanations; expansion is more complete but computationally expensive
- Failure signatures:
  - Query translation errors: Users receive explanations that don't match their intent
  - CTL verification timeouts: Complex formulas take too long to verify against large trees
  - Violation aggregation inconsistencies: Different runs produce different quantitative results
  - Natural language generation failures: Explanations are grammatically incorrect or nonsensical
- First 3 experiments:
  1. Verify the query-to-CTL mapping works for all three query types using simple test cases
  2. Test CTL verification on a small, hand-crafted MCTS tree with known properties
  3. Validate the end-to-end pipeline with a complete transit planning scenario and verify explanations match expected outcomes

## Open Questions the Paper Calls Out
- How does the explainer handle queries involving multiple constraints simultaneously (e.g., capacity AND timing constraints)?
- What is the computational overhead of performing tree expansion for under-explored branches compared to standard MCTS?
- How does the explainer's performance scale with increasing numbers of vehicles and requests in the transit planning scenario?

## Limitations
- Paper lacks specific technical details for implementation, including exact weight values for the reward function and complete language templates
- User study evaluation relies on self-reported metrics without objective validation of explanation accuracy
- No quantitative comparison against alternative explainability approaches beyond stated baseline methods

## Confidence
- **High confidence** in the CTL framework's theoretical validity for verifying search tree properties against formal specifications
- **Medium confidence** in the practical effectiveness of the three-query categorization system, as the user study provides evidence but doesn't establish generalizability beyond the tested scenarios
- **Low confidence** in the scalability of the approach to larger, more complex planning problems, as the evaluation focuses on a specific transit planning case

## Next Checks
1. Implement a small-scale MCTS planning problem with hand-crafted search trees to verify that CTL formula generation and verification produce correct results for all three query types
2. Conduct a controlled experiment comparing the CTL-based explainer against alternative methods (rule-based, feature importance) using objective metrics like explanation coverage and computational overhead
3. Test the query-to-CTL translation system with diverse user queries beyond the provided examples to assess the robustness of the template-based approach