---
ver: rpa2
title: 'COSCO: A Sharpness-Aware Training Framework for Few-shot Multivariate Time
  Series Classification'
arxiv_id: '2409.09645'
source_url: https://arxiv.org/abs/2409.09645
tags:
- time
- series
- classification
- data
- cosco
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of few-shot multivariate time
  series classification, where deep neural networks struggle with limited training
  data per class. The authors propose COSCO, a new learning framework that combines
  sharpness-aware minimization (SAM) optimization with a prototypical loss function.
---

# COSCO: A Sharpness-Aware Training Framework for Few-shot Multivariate Time Series Classification

## Quick Facts
- arXiv ID: 2409.09645
- Source URL: https://arxiv.org/abs/2409.09645
- Reference count: 40
- Primary result: Achieves 70.5% average accuracy and rank 2.429 in 10-shot multivariate time series classification

## Executive Summary
This paper addresses the challenge of few-shot multivariate time series classification, where deep neural networks struggle with limited training data per class. The authors propose COSCO, a new learning framework that combines sharpness-aware minimization (SAM) optimization with a prototypical loss function. SAM improves generalization by minimizing worst-case loss in parameter neighborhoods, while the prototypical loss enhances robustness to outliers by using class centroids. Experiments on 21 multivariate time series datasets from the UEA archive show that COSCO achieves the highest average accuracy (70.5%) and rank (2.429) in 10-shot settings, outperforming ResNet and other baselines.

## Method Summary
COSCO is a learning framework for few-shot multivariate time series classification that combines SAM optimization with a prototypical loss function. The framework uses a ResNet backbone to generate embeddings from time series data, then applies SAM to find flatter minima in the loss landscape while using prototypical loss to measure distances to class centroids rather than individual samples. This combination addresses both optimization challenges (sharp minima) and data scarcity issues (outlier sensitivity) in few-shot settings. The method is evaluated on 21 UEA multivariate time series datasets under 1-shot and 10-shot scenarios.

## Key Results
- COSCO achieves highest average accuracy (70.5%) among all tested methods on 21 UEA datasets
- COSCO obtains best average rank (2.429) in 10-shot settings, outperforming ResNet and other baselines
- Ablation studies confirm both SAM and prototypical loss components contribute to performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sharpness-aware minimization (SAM) improves generalization by flattening the loss landscape in few-shot settings.
- Mechanism: SAM performs a perturb-then-update operation where it first finds the worst-case perturbation within a neighborhood of the current parameters, then updates parameters to minimize this worst-case loss. This forces the model to find parameters where the entire neighborhood has low loss, not just a single sharp point.
- Core assumption: Sharp local minima correlate with poor generalization in few-shot learning scenarios.
- Evidence anchors:
  - [abstract] "Specifically, we propose a new learning framework named COSCO consisting of a sharpness-aware minimization (SAM) optimization and a Prototypical loss function to improve the generalization ability of DNN for multivariate time series classification problems under few-shot setting."
  - [section] "In particular, without sufficient labeled data or prior knowledge regularization, the large scale of trainable parameters often fall into sharp local minima during model training [1, 10], where the loss value increases rapidly with any small perturbation to the model weights."
  - [corpus] Weak evidence - no direct citations about SAM's effectiveness in time series classification specifically.
- Break condition: If the perturbation radius ρ is too large, SAM may optimize for irrelevant parameter regions that don't correspond to meaningful model variations.

### Mechanism 2
- Claim: Prototypical loss improves robustness to outliers by using class centroids instead of individual samples.
- Mechanism: Instead of using cross-entropy with individual samples, prototypical loss computes class centroids as the mean embedding of all samples in each class, then measures distance from each sample to its class centroid. This reduces the influence of outlier samples that would otherwise skew the decision boundary.
- Core assumption: In few-shot settings, individual outlier samples have disproportionate influence on the learned decision boundary.
- Evidence anchors:
  - [abstract] "In addition, COSCO utilizes a prototypical loss to replace the conventional cross-entropy loss to further improve the robustness against outlier samples in data scarcity situations."
  - [section] "Under few-shot learning setting, any outlier samples could severely affect the decision boundary learnt by the model and significantly hurt the model generalization [9, 24]."
  - [corpus] Weak evidence - no direct citations about prototypical loss's effectiveness in time series classification.
- Break condition: If class centroids are poorly estimated due to extreme data imbalance or if the embedding space doesn't meaningfully separate classes.

### Mechanism 3
- Claim: The combination of SAM and prototypical loss addresses both optimization landscape issues and data scarcity simultaneously.
- Mechanism: SAM handles the optimization problem by finding flatter minima, while prototypical loss handles the data problem by being inherently more robust to outliers. Together they create a framework that works well when both labeled data and good optimization are challenging.
- Core assumption: Few-shot learning problems suffer from both optimization difficulties (sharp minima) and data difficulties (outliers), and addressing both is more effective than addressing either alone.
- Evidence anchors:
  - [abstract] "Specifically, we propose a new learning framework named COSCO consisting of a sharpness-aware minimization (SAM) optimization and a Prototypical loss function to improve the generalization ability of DNN for multivariate time series classification problems under few-shot setting."
  - [section] "In summary, our main contributions is as follows: 1) propose a new learning framework designed for few-shot multivariate time series classification; 2) conduct comprehensive experimental results to demonstrate that COSCO outperforms baselines; 3) conduct ablation test to show the effectiveness of the modules."
  - [corpus] Weak evidence - no direct citations about the combined effectiveness of SAM and prototypical loss in time series.
- Break condition: If the two components interfere with each other's optimization processes or if one component dominates the other's effects.

## Foundational Learning

- Concept: Time series embedding and representation learning
  - Why needed here: The prototypical loss operates on embeddings computed by the neural network, so understanding how time series are transformed into meaningful vector representations is crucial.
  - Quick check question: What properties should a good time series embedding have for classification tasks?

- Concept: Sharpness in loss landscapes and generalization theory
  - Why needed here: SAM is based on the principle that flatter minima generalize better, so understanding the relationship between loss landscape geometry and model performance is essential.
  - Quick check question: How does the curvature of the loss landscape at a minimum relate to the model's expected performance on unseen data?

- Concept: Prototype-based learning and metric learning
  - Why needed here: Prototypical loss is fundamentally a metric learning approach that uses distances to class prototypes, so understanding distance metrics and prototype-based classification is important.
  - Quick check question: What are the advantages and disadvantages of using L2 distance versus other distance metrics in prototype-based classification?

## Architecture Onboarding

- Component map: Input time series -> ResNet backbone -> Embedding space -> Class centroid computation -> Distance calculation -> Loss computation -> SAM optimization -> Parameter update
- Critical path: Input time series → Backbone network → Embedding space → Class centroid computation → Distance calculation → Loss computation → SAM optimization → Parameter update
- Design tradeoffs: Using prototypical loss saves parameters by avoiding the final classification layer, but requires computing class centroids which adds computational overhead. SAM improves generalization but doubles the gradient computation cost per iteration.
- Failure signatures: Poor performance on certain datasets may indicate that either SAM's perturbation radius is inappropriate for that dataset's scale, or that the embedding space doesn't separate classes well enough for prototypical loss to work effectively.
- First 3 experiments:
  1. Run COSCO with default settings on a small dataset to verify the basic pipeline works
  2. Compare COSCO with and without SAM on the same dataset to isolate SAM's contribution
  3. Compare COSCO with and without prototypical loss on the same dataset to isolate the loss function's contribution

## Open Questions the Paper Calls Out
None

## Limitations
- Weak evidence for SAM's effectiveness specifically in time series classification domain
- Limited mechanistic understanding of why SAM and prototypical loss work well together for time series
- No comparison with transformer-based approaches for few-shot learning

## Confidence

**High confidence**: COSCO achieves state-of-the-art performance on the tested UEA datasets (70.5% average accuracy, rank 2.429 in 10-shot). The experimental methodology is sound and the results are reproducible with the provided specifications.

**Medium confidence**: The individual contributions of SAM and prototypical loss are effective in few-shot settings. While the ablation studies support this, the mechanistic explanations for why these components specifically help with time series classification remain somewhat generic.

**Low confidence**: The claims about why COSCO works particularly well for time series data are not well-supported. The paper doesn't demonstrate that time series present unique challenges that COSCO specifically addresses better than other data types.

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically vary the SAM perturbation radius ρ and prototypical loss temperature parameter across different datasets to identify optimal ranges and understand robustness to these settings.

2. **Cross-domain comparison**: Test COSCO on non-time-series few-shot classification tasks (e.g., image classification) to determine if the framework's effectiveness is specific to time series or generalizes across domains.

3. **Ablation of backbone architecture**: Replace the ResNet backbone with alternative architectures (e.g., Transformer, LSTM) to isolate whether the performance gains come from the SAM/prototypical components or the specific ResNet architecture used.