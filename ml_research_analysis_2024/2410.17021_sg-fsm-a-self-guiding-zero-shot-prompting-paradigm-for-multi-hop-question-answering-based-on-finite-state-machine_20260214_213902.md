---
ver: rpa2
title: 'SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question
  Answering Based on Finite State Machine'
arxiv_id: '2410.17021'
source_url: https://arxiv.org/abs/2410.17021
tags:
- answer
- question
- reasoning
- manchu
- paragraph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SG-FSM, a self-guiding zero-shot prompting
  method for multi-hop question answering that addresses challenges of hallucination,
  error propagation, and format inconsistency in existing approaches. The method uses
  a finite state machine paradigm to iteratively decompose complex questions into
  sub-questions, search for answers in provided paragraphs, and self-correct outputs
  through a controlled reasoning process.
---

# SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question Answering Based on Finite State Machine

## Quick Facts
- arXiv ID: 2410.17021
- Source URL: https://arxiv.org/abs/2410.17021
- Authors: Xiaochen Wang; Junqing He; Liang Chen; Reza Haf Zhe Yang; Yiru Wang; Xiangdi Meng; Kunhao Pan; Zhifang Sui
- Reference count: 4
- Primary result: SG-FSM nearly doubles F1 score on Musique dataset while significantly reducing format errors

## Executive Summary
This paper introduces SG-FSM, a self-guiding zero-shot prompting method for multi-hop question answering that addresses challenges of hallucination, error propagation, and format inconsistency in existing approaches. The method uses a finite state machine paradigm to iteratively decompose complex questions into sub-questions, search for answers in provided paragraphs, and self-correct outputs through a controlled reasoning process. SG-FSM outperforms strong baselines on challenging datasets like Musique, nearly doubling the F1 score while significantly reducing format errors and improving the correctness of intermediate reasoning and supporting evidence.

## Method Summary
SG-FSM implements a structured, self-guiding approach for multi-hop question answering using a finite state machine paradigm. The method iteratively breaks down complex questions into manageable sub-questions, searches for answers in provided paragraphs, and employs self-correction mechanisms to improve accuracy. The FSM consists of four main states: decomposing questions, revising decomposed outputs, searching paragraphs, and judging if further decomposition is needed, followed by a final summary revision stage. The approach is evaluated on HotpotQA, 2WikiMultiHopQA, and Musique datasets using GPT-3.5-turbo-1106 and Qwen-72B models, achieving superior performance in terms of exact match, F1 score, and format compliance compared to chain-of-thought and other baseline methods.

## Key Results
- Nearly doubles F1 score on Musique dataset compared to baseline methods
- Significantly reduces format errors in generated outputs
- Improves correctness of intermediate reasoning and supporting evidence
- Demonstrates robustness in handling long-context reasoning paths

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative decomposition reduces cognitive load and prevents answer drift
- Mechanism: By breaking complex multi-hop questions into sequential sub-questions, the model maintains focus on smaller, manageable reasoning steps rather than losing track of the original question in long contexts
- Core assumption: LLMs perform better on simpler sub-tasks than complex multi-step reasoning
- Evidence anchors:
  - [abstract] "Unlike traditional chain-of-thought methods, SG-FSM tackles MHQA by iteratively breaking down complex questions into sub-questions, correcting itself to improve accuracy."
  - [section] "The SG-FSM is formally described as a five-tuple (Q, Σ, δ, q0, q5), where: Q = {q0, q1, q2, q3, q4, q5} is the set of states, where: q0: Decomposing the question q1: Revising the output of decomposing q2: Searching in the given paragraph q3: Revising the output of searching q4: Judging if question can be decomposed further q5: The end of SG-FSM1, final answer is found"
  - [corpus] "FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering" - weak evidence, only mentions FSM approach

### Mechanism 2
- Claim: State transitions enforce structured reasoning and format compliance
- Mechanism: The finite state machine paradigm constrains the reasoning process through predefined state transitions, ensuring outputs follow expected formats and reducing hallucinations
- Core assumption: Structured state transitions can guide LLMs to produce more consistent and evaluable outputs
- Evidence anchors:
  - [abstract] "SG-FSM reduces hallucination, enabling recovery of the correct final answer despite intermediate errors. It also improves adherence to specified output formats, simplifying evaluation significantly."
  - [section] "The specific finite state automaton diagram is located in the upper part of Figure 1. It shows clear process of the FSM and how the states are transitioned."
  - [corpus] "Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering" - weak evidence, mentions consistency but not FSM approach

### Mechanism 3
- Claim: Self-correction through iterative revision improves answer accuracy
- Mechanism: The revision states (q1, q3) allow the model to detect and correct format errors immediately, preventing error propagation through the reasoning chain
- Core assumption: LLMs can recognize their own output errors and self-correct when explicitly prompted
- Evidence anchors:
  - [abstract] "SG-FSM reduces hallucination, enabling recovery of the correct final answer despite intermediate errors."
  - [section] "After each step, the LLMs output content should be immediately parsed for analysis, and any errors should be corrected immediately. Only outputs with format errors enter this revisor step to self-correction."
  - [corpus] "ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision" - weak evidence, mentions iterative approaches but not self-correction

## Foundational Learning

- Concept: Finite State Machines (FSM)
  - Why needed here: FSM provides a structured framework for controlling the reasoning process through defined states and transitions
  - Quick check question: Can you describe how an FSM would model a simple vending machine that accepts coins and dispenses items?

- Concept: Chain-of-Thought (CoT) reasoning
  - Why needed here: Understanding CoT limitations is crucial to appreciate why SG-FSM's structured approach outperforms it
  - Quick check question: What are the main failure modes of standard CoT prompting in multi-hop question answering?

- Concept: Multi-hop question answering
  - Why needed here: The task requires understanding how information needs to be retrieved and integrated across multiple documents
  - Quick check question: What distinguishes a 2-hop question from a 3-hop question in terms of reasoning complexity?

## Architecture Onboarding

- Component map: Decomposer -> Searcher -> Terminator -> (repeat if continue) -> Summarizer
- Critical path: Decomposer → Searcher → Terminator → (repeat if continue) → Summarizer
- Design tradeoffs:
  - Structured control vs. flexibility: FSM approach is more rigid but more reliable
  - Self-correction vs. efficiency: Multiple revision attempts ensure quality but add latency
  - Single-task focus vs. context retention: Processing one sub-question at a time reduces errors but may lose broader context
- Failure signatures:
  - Format errors that persist through multiple revision attempts
  - Terminator incorrectly determining whether to continue
  - Sub-question decomposition that doesn't lead to answerable questions
  - Search results that don't contain relevant information
- First 3 experiments:
  1. Test the FSM transitions with a simple 2-hop question to verify state transitions work correctly
  2. Evaluate format compliance by measuring the percentage of correctly formatted outputs across 50 questions
  3. Compare error propagation by tracking how often initial sub-question errors affect the final answer versus CoT baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of FSM states for different types of multi-hop reasoning tasks?
- Basis in paper: [inferred] The paper describes a specific FSM with 8 states but does not systematically explore variations in the number of states or their impact on performance across different question types.
- Why unresolved: The current implementation uses a fixed FSM structure without exploring whether different question types or reasoning depths might benefit from different state configurations.
- What evidence would resolve it: Systematic ablation studies varying the number of states, their definitions, and transition rules across multiple datasets with different reasoning complexities.

### Open Question 2
- Question: How does SG-FSM's performance degrade as the number of reasoning hops increases beyond 4?
- Basis in paper: [explicit] The paper mentions that "Currently, most MHQA questions require 2-4 hops of reasoning" and designs the FSM accordingly, but does not test scenarios with more hops.
- Why unresolved: The terminator component makes decisions based on whether questions can be further decomposed, but the paper doesn't evaluate how well this scales to questions requiring 5+ hops of reasoning.
- What evidence would resolve it: Testing SG-FSM on datasets with longer reasoning chains (5+ hops) and analyzing failure modes when reasoning paths exceed the current FSM design.

### Open Question 3
- Question: What is the relationship between the quality of sub-question decomposition and final answer accuracy?
- Basis in paper: [explicit] The paper states that "we enhance the accuracy of each step towards the sub-questions" but does not provide quantitative analysis of how decomposition quality correlates with final performance.
- Why unresolved: While the paper demonstrates that SG-FSM improves overall performance, it doesn't measure whether errors in individual decomposition steps propagate or if the revision mechanism effectively corrects them.
- What evidence would resolve it: Detailed error analysis tracking the accuracy of each sub-question and its impact on the final answer, including metrics on how often the revision mechanism successfully corrects errors.

## Limitations
- Limited experimental scope with only three datasets and two model types tested
- Reliance on specific prompt templates and JSON formatting requirements may limit generalizability
- FSM paradigm may not capture all possible reasoning patterns needed for complex multi-hop questions

## Confidence
- High confidence: The FSM mechanism for structured reasoning and the self-correction capability through revision states are well-supported by the experimental results and clear theoretical framework
- Medium confidence: Claims about reduced hallucination and improved interpretability are supported by the data but would benefit from additional qualitative analysis of reasoning paths
- Low confidence: The assertion that this approach significantly outperforms all existing methods may be overstated given the limited comparison to newer state-of-the-art techniques

## Next Checks
1. Test SG-FSM on additional multi-hop QA datasets with varying complexity levels to assess generalizability across different question types and domains
2. Conduct ablation studies removing the self-correction mechanism to quantify its specific contribution to performance improvements
3. Implement human evaluation of reasoning paths to verify that the improved format compliance actually translates to better interpretability and trustworthiness of the generated explanations