---
ver: rpa2
title: Efficient Parking Search using Shared Fleet Data
arxiv_id: '2404.10646'
source_url: https://arxiv.org/abs/2404.10646
tags:
- parking
- resource
- time
- available
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of finding available on-street
  parking spots in a competitive multi-agent environment. The core method idea involves
  using shared fleet data to reduce uncertainty about future resource states by incorporating
  the parking intentions of other fleet vehicles.
---

# Efficient Parking Search using Shared Fleet Data

## Quick Facts
- arXiv ID: 2404.10646
- Source URL: https://arxiv.org/abs/2404.10646
- Authors: Niklas StrauÃŸ; Lukas Rottkamp; Sebatian Schmoll; Matthias Schubert
- Reference count: 37
- One-line primary result: Proposed multi-agent approaches using shared fleet data reduce parking search time by up to 84% compared to single-agent methods

## Executive Summary
This paper addresses the problem of finding available on-street parking spots in competitive multi-agent environments by leveraging shared fleet data. The authors propose two main approaches: "reservations" where agents share their targeted parking bay, and "multi-agent dynamic probability adaption" using a biased random walk to approximate agent behavior when parking spots become occupied. Through agent-based simulations using real-world and synthetic data from Melbourne, Australia, the results show significant reductions in parking time compared to single-agent approaches.

## Method Summary
The method formulates parking search as a Markov Decision Process where states represent agent positions and resource availability. Two main approaches are implemented: the "reservations" approach where agents share their currently targeted parking bay and expected arrival time, and the "multi-agent dynamic probability adaption" approach that uses a biased random walk to approximate agent behavior when their intended spot becomes occupied. These approaches are evaluated using both replanning and hindsight planning algorithms, with CTMC models predicting resource availability. The system was tested through agent-based simulations using real-world parking data from Melbourne and synthetic occupation data.

## Key Results
- Parking time reduced by up to 84% compared to single-agent approaches
- Reservations approach shows effectiveness in reducing competition for same resources
- Probability adaptation approach provides more comprehensive multi-agent consideration than reservations alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sharing intended parking spot (reservation) within a fleet reduces uncertainty about future resource states.
- Mechanism: Agents share their current target parking spot and expected arrival time. Other fleet agents treat that spot as occupied if they expect to arrive later, effectively reducing competition over the same resource.
- Core assumption: Agents act selfishly and only care about minimizing their own search time; reservations reflect the earliest arrival time among fleet vehicles.

### Mechanism 2
- Claim: Biased random walk approximates agent behavior when their intended spot is unavailable, enabling dynamic probability adaptation.
- Mechanism: When an agent's intended resource is unavailable, a biased random walk simulates likely alternative paths within an isochrone. This updates availability probabilities of nearby resources to reflect the likelihood other agents will choose them.
- Core assumption: The biased random walk's jump probabilities reasonably approximate the agent's actual decision-making policy.

### Mechanism 3
- Claim: Hindsight planning with reservations/dynamically adapted probabilities reduces expected search time by sampling more realistic futures.
- Mechanism: Instead of treating all resources as independent, reservations lock certain resources across all sampled futures, and probability adaptations shift likelihood mass toward more probable alternative spots.
- Core assumption: Sampling 100 determinizations with reservations/adaptations provides a good approximation of the true expected costs.

## Foundational Learning

- Concept: Markov Decision Process (MDP) formulation of resource routing
  - Why needed here: The parking search problem is modeled as an MDP where states represent agent position and resource availability, and actions are movement or parking decisions
  - Quick check question: In an MDP for parking, what determines the transition probabilities between states?

- Concept: Continuous-Time Markov Chain (CTMC) for modeling resource availability
  - Why needed here: CTMCs model the time-dependent probability that a parking spot is available, incorporating both real-time sensor data and long-term usage patterns
  - Quick check question: What two parameters define the sojourn times in the CTMC model used here?

- Concept: Deterministic planning with replanning vs. stochastic planning with hindsight
  - Why needed here: Replanning determinizes the most likely future and recomputes when surprises occur; hindsight planning samples multiple futures and averages optimal solutions
  - Quick check question: Why might replanning fail in "probabilistically interesting" tasks?

## Architecture Onboarding

- Component map: Road network graph -> Resource list -> Agent manager -> CTMC predictor -> Reservation system -> Probability adaptor -> Planner -> Simulator
- Critical path: 1. Agent selects next action using planner. 2. Agent moves along edge, triggering CTMC updates. 3. If agent reaches target spot, checks reservation/adaptations. 4. If conflict, agent re-plans using updated probabilities.
- Design tradeoffs:
  - Replanning is computationally cheaper but less robust to high uncertainty
  - Hindsight planning is more accurate but requires more computation per decision
  - Reservations are simple but only capture single-target intentions
  - Probability adaptations are more comprehensive but rely on accurate random walk modeling
- Failure signatures:
  - High number of unsuccessful resource claims indicates poor probability modeling
  - Consistently high computation times suggest replanning with reservations is hitting NP-hard pathfinding
  - No improvement over single-agent baselines indicates multi-agent sharing is ineffective
- First 3 experiments:
  1. Run baseline replanning on synthetic data, measure parking time
  2. Add reservations, compare reduction in parking time and unsuccessful claims
  3. Replace reservations with probability adaptations, measure change in parking time and computation time

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed multi-agent approaches perform in partially observable settings where not all parking bay states are known?
- Basis in paper: The authors mention that partially observable settings are interesting but beyond the scope of the current paper
- Why unresolved: The paper focuses on fully observable scenarios and does not provide data or analysis for partially observable settings
- What evidence would resolve it: Experimental results comparing the performance of the proposed approaches in partially observable settings against fully observable settings, along with an analysis of the impact of uncertainty on their effectiveness

### Open Question 2
- Question: What is the impact of varying the number of agents and resources on the computational efficiency and effectiveness of the proposed multi-agent approaches?
- Basis in paper: The paper mentions that the methods are efficient and can be deployed in real-world scenarios, but does not provide a detailed analysis of how scalability affects performance
- Why unresolved: The paper does not explore the relationship between the number of agents/resources and the computational overhead or effectiveness of the approaches
- What evidence would resolve it: A comprehensive study varying the number of agents and resources, measuring both computational time and parking time, to identify any scalability limitations or performance bottlenecks

### Open Question 3
- Question: How do the proposed approaches compare to other state-of-the-art methods for dynamic resource routing in multi-agent settings, such as those based on game theory or reinforcement learning?
- Basis in paper: The paper focuses on its own proposed methods and does not provide a direct comparison to other advanced techniques like game-theoretic or reinforcement learning approaches
- Why unresolved: The paper does not include a comparison with other advanced methods that could potentially offer different advantages or insights
- What evidence would resolve it: A comparative study evaluating the proposed approaches against other state-of-the-art methods, using the same metrics and scenarios, to determine their relative strengths and weaknesses

## Limitations

- The effectiveness relies heavily on accurate CTMC-based resource availability predictions
- The biased random walk approximation may not accurately model actual human driver decision-making
- Computational complexity may become prohibitive for very large-scale scenarios with hindsight planning

## Confidence

- High Confidence: Sharing intended parking spots (reservations) reduces uncertainty about future resource states
- Medium Confidence: Biased random walk approximates agent behavior when their intended spot is unavailable
- Low Confidence: Sampling 100 determinizations with reservations/adaptations provides good approximation of true expected costs

## Next Checks

1. Compare predicted availability probabilities from CTMC model with actual sensor data to assess accuracy of resource availability predictions
2. Profile computation time for hindsight planning approach with reservations and probability adaptations in large-scale scenarios
3. Conduct user studies to gather data on actual decision-making behavior of human drivers when intended parking spot is unavailable, and compare with biased random walk approximation