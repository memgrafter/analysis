---
ver: rpa2
title: 'FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive
  Model Fusion'
arxiv_id: '2410.20380'
source_url: https://arxiv.org/abs/2410.20380
tags:
- learning
- local
- data
- fusefl
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a causal analysis of the performance gap between
  multi-round federated learning and one-shot federated learning, identifying that
  the gap arises from the "isolation problem," where locally trained models may easily
  fit to spurious correlations due to data heterogeneity. To address this, the authors
  propose FuseFL, a novel approach that decomposes neural networks into blocks and
  progressively trains and fuses each block in a bottom-up manner for feature augmentation.
---

# FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion

## Quick Facts
- arXiv ID: 2410.20380
- Source URL: https://arxiv.org/abs/2410.20380
- Authors: Zhenheng Tang; Yonggang Zhang; Peijie Dong; Yiu-ming Cheung; Amelie Chi Zhou; Bo Han; Xiaowen Chu
- Reference count: 40
- Primary result: Achieves one-shot federated learning performance close to multi-round methods with minimal communication costs

## Executive Summary
This paper addresses the fundamental performance gap between multi-round and one-shot federated learning by introducing FuseFL, a novel approach that decomposes neural networks into blocks and progressively fuses them in a bottom-up manner. The authors identify the "isolation problem" as the root cause of one-shot FL underperformance - when models are trained in isolation on non-IID data, they tend to fit to spurious correlations rather than invariant features. FuseFL's progressive model fusion with feature augmentation from other clients' models significantly improves one-shot FL performance while maintaining low communication and storage costs.

## Method Summary
FuseFL decomposes neural networks into K blocks and trains them progressively in a bottom-up manner. In each round, clients first train their local blocks, then exchange these blocks with other clients. The exchanged blocks are used to augment intermediate features through concatenation or averaging operations, helping filter out spurious features while retaining invariant ones. This process repeats for each block, with earlier blocks being frozen after fusion. The final classifier is calibrated using the fully fused model. The approach introduces minimal communication overhead - only K block exchanges compared to full model exchanges in traditional FL, with memory requirements scaling as sqrt(M) where M is the number of clients.

## Key Results
- Achieves 85.92% accuracy on CIFAR-10 with non-IID degree a=0.5, outperforming existing one-shot methods by significant margins
- Maintains performance close to multi-round federated learning while using only 1/4 of the model size in communication
- Scales effectively to 50+ clients with minimal performance degradation
- Works across diverse datasets (MNIST, CIFAR-10, SVHN, CIFAR-100, Tiny-Imagenet) and model architectures (ResNet-18, VGG-16)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Local models in one-shot federated learning fit to spurious correlations due to data heterogeneity, causing performance drop.
- **Mechanism:** When models are trained in isolation on non-IID data, they learn to rely on features that correlate with labels in their local dataset but are not truly invariant across clients. This leads to overfitting on spurious features.
- **Core assumption:** Spurious features exist in local datasets and differ between clients, while invariant features remain constant.
- **Evidence anchors:**
  - [abstract] "this performance drop of OFL methods comes from the isolation problem, which means that locally isolatedly trained models in OFL may easily fit to spurious correlations due to data heterogeneity"
  - [section 3.2] "the spurious features Rspu m are other factors that occasionally exist in data and do not have a relationship to Y, which means that the heterogeneous features of data (non-iid) with the same class come from the spurious featuresRspu m"
  - [corpus] Weak - no direct corpus evidence supporting spurious feature fitting in OFL
- **Break condition:** If all clients have IID data or if the model architecture inherently prevents fitting to spurious features.

### Mechanism 2
- **Claim:** Augmenting intermediate features from other clients helps filter out spurious features and retain invariant features.
- **Mechanism:** By fusing features from other clients' models at each block level, the model can learn to focus on features that are consistent across clients (invariant) while discarding client-specific spurious features.
- **Core assumption:** Features that pass through other clients' models are more likely to be invariant since other clients cannot see their spurious features.
- **Evidence anchors:**
  - [abstract] "From the causal perspective, we observe that the spurious fitting can be alleviated by augmenting intermediate features from other clients"
  - [section 3.3] "Using other local models Hi̸=m(Xm) help to filter out spurious features Rspu m, but retain Rinv m"
  - [corpus] Weak - no direct corpus evidence supporting feature augmentation in OFL
- **Break condition:** If the feature adaptation method fails to properly align features from different clients.

### Mechanism 3
- **Claim:** Progressive model fusion with block-wise communication achieves one-shot FL performance with minimal communication costs.
- **Mechanism:** By splitting the model into blocks and progressively fusing each block, FuseFL can achieve performance close to ensemble learning while only communicating a fraction of the model size.
- **Core assumption:** The model can be effectively decomposed into blocks that can be trained and fused independently without losing performance.
- **Evidence anchors:**
  - [abstract] "FuseFL decomposes neural networks into several blocks and progressively trains and fuses each block following a bottom-up manner for feature augmentation, introducing no additional communication costs"
  - [section 4.3] "To obtain rm = 1, we obtain the scaling ratio γ = √M, which means that FuseFL can keep similar memory requirements with the original model size S"
  - [corpus] Weak - no direct corpus evidence supporting progressive fusion in OFL
- **Break condition:** If the block decomposition is not effective or if the progressive fusion introduces too much error.

## Foundational Learning

- **Concept:** Causal inference and structure equation models
  - Why needed here: To understand how data generation processes affect model learning and identify the root cause of performance gaps
  - Quick check question: Can you explain how a causal graph helps identify spurious correlations in federated learning?

- **Concept:** Information bottleneck principle
  - Why needed here: To understand how neural networks learn intermediate representations and how to optimize for invariant features
  - Quick check question: How does minimizing mutual information between representations and input data help improve generalization?

- **Concept:** Federated learning with non-IID data
  - Why needed here: To understand the specific challenges of training models on heterogeneous client data
  - Quick check question: What are the main differences between IID and non-IID data distributions in federated learning?

## Architecture Onboarding

- **Component map:** Model decomposer -> Communication layer -> Feature fusion module -> Adaptation layer -> Training coordinator

- **Critical path:**
  1. Split model into K blocks
  2. Train first block locally on each client
  3. Exchange first blocks and fuse features
  4. Train second block using fused features
  5. Repeat steps 3-4 for remaining blocks
  6. Calibrate final classifier

- **Design tradeoffs:**
  - Block size vs. communication efficiency: Smaller blocks reduce communication but may hurt performance
  - Feature fusion method: Concatenation preserves more information but increases memory; averaging reduces memory but may lose information
  - Progressive freezing: Helps stabilize training but may limit flexibility

- **Failure signatures:**
  - Performance plateaus early: May indicate insufficient feature adaptation
  - Memory overflow: Likely due to feature concatenation explosion
  - Slow convergence: Could be caused by poor block decomposition or inadequate local training

- **First 3 experiments:**
  1. Test with K=2 blocks on a simple dataset (MNIST) to verify basic functionality
  2. Compare different feature fusion methods (concatenation vs. averaging) on CIFAR-10
  3. Test scalability by increasing number of clients from 5 to 50 on SVHN

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FuseFL perform when applied to extremely large-scale models like GPT-3 or other transformer-based architectures?
- Basis in paper: [explicit] The paper mentions that FuseFL could potentially be extended to transformer-based frameworks and large language models, but does not provide experimental results.
- Why unresolved: The authors only tested FuseFL on ResNet architectures for image classification tasks. Applying it to very large models with billions of parameters would require significant computational resources and infrastructure that may not be readily available.
- What evidence would resolve it: Experiments demonstrating FuseFL's effectiveness on transformer-based models, particularly large language models, would show its scalability and potential for real-world deployment in communication-constrained scenarios.

### Open Question 2
- Question: What is the optimal number of communication rounds (K) for FuseFL to achieve the best trade-off between performance and communication efficiency?
- Basis in paper: [explicit] The paper mentions that K is a hyperparameter that can be tuned, and they provide results for different values of K (2, 4, 8) in their experiments. However, they do not provide a systematic study on how to choose the optimal K.
- Why unresolved: The optimal K likely depends on factors such as the model architecture, dataset characteristics, and the degree of data heterogeneity. A systematic study to determine the optimal K for different scenarios would be valuable.
- What evidence would resolve it: Experiments showing the performance of FuseFL with different values of K for various model architectures, datasets, and levels of data heterogeneity would help identify the optimal K for different scenarios.

### Open Question 3
- Question: How does FuseFL handle the presence of malicious clients that upload adversarial or backdoored modules?
- Basis in paper: [inferred] The paper mentions that FuseFL is vulnerable to adversarial attacks, similar to other FL methods. However, it does not provide a detailed analysis of how to detect and mitigate such attacks.
- Why unresolved: Detecting and mitigating adversarial attacks in FL is a challenging problem, especially when clients can upload arbitrary modules. Developing effective defense mechanisms for FuseFL would be crucial for its real-world deployment.
- What evidence would resolve it: Experiments demonstrating the effectiveness of different defense mechanisms against adversarial attacks in FuseFL, such as anomaly detection or robust aggregation techniques, would show its resilience to malicious clients.

## Limitations

- The causal analysis of spurious feature fitting lacks direct empirical validation linking it to the performance gap in one-shot FL
- The block decomposition strategy's optimality is unclear - the paper doesn't explore alternative decompositions or justify specific block boundaries
- The progressive freezing mechanism could potentially harm model flexibility, though this isn't thoroughly investigated

## Confidence

- **High**: The core contribution of FuseFL as a novel approach for one-shot federated learning is well-established through extensive experiments
- **Medium**: The causal analysis explaining why one-shot methods underperform is plausible but lacks direct empirical support
- **Low**: The claim that FuseFL "significantly improves" one-shot federated learning performance needs more rigorous statistical analysis

## Next Checks

1. **Ablation study on block size**: Systematically vary the number of blocks (K=2, 4, 8) and measure impact on both performance and communication efficiency to validate the progressive fusion mechanism

2. **Spurious feature analysis**: Use feature attribution methods (like Integrated Gradients) to compare feature importance distributions between FuseFL and baseline one-shot methods, directly testing if FuseFL reduces spurious feature reliance

3. **Communication cost validation**: Implement and measure actual communication costs across different network conditions and client scales to verify the claimed efficiency gains, particularly examining the sqrt(M) scaling relationship