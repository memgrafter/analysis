---
ver: rpa2
title: 'TEARS: Textual Representations for Scrutable Recommendations'
arxiv_id: '2410.19302'
source_url: https://arxiv.org/abs/2410.19302
tags:
- user
- tears
- summaries
- summary
- they
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TEARS, a recommender system that uses natural
  language user summaries instead of traditional high-dimensional embeddings. TEARS
  generates user summaries using an LLM, then aligns these text representations with
  learned black-box embeddings via optimal transport, allowing users to edit summaries
  for controllable recommendations.
---

# TEARS: Textual Representations for Scrutable Recommendations

## Quick Facts
- arXiv ID: 2410.19302
- Source URL: https://arxiv.org/abs/2410.19302
- Reference count: 40
- TEARS outperforms three popular VAE models on MovieLens-1M, Netflix, and Goodbooks datasets while maintaining user controllability through text summary editing.

## Executive Summary
TEARS introduces a novel recommender system that uses natural language user summaries instead of traditional high-dimensional embeddings. The system generates user summaries using an LLM, then aligns these text representations with learned black-box embeddings via optimal transport, allowing users to edit summaries for controllable recommendations. Tested on MovieLens-1M, Netflix, and Goodbooks datasets, TEARS demonstrates superior performance to three popular VAE models while maintaining scrutability. User controllability is evaluated through three simulated tasks—large-scope interest flips, fine-grained rank adjustments, and guided contextual recommendations—showing TEARS can effectively adapt recommendations through text edits.

## Method Summary
TEARS generates user summaries with GPT-4-turbo or LLaMA 3.1-405b using a structured prompt, then encodes these summaries with T5-base. A frozen backbone VAE encoder processes user-item interactions into Gaussian embeddings. Optimal transport aligns the summary and interaction embeddings, which are then combined via convex interpolation (controlled by α). The shared decoder generates recommendations, allowing users to edit summaries for controllable recommendations. The model is trained with a loss combining reconstruction, optimal transport alignment, and KL divergence terms.

## Key Results
- TEARS outperforms Multi-VAE, RecVAE, and MacridVAE on MovieLens-1M, Netflix, and Goodbooks datasets across NDCG and recall metrics
- User controllability measured through three simulated tasks shows TEARS can effectively flip interests, adjust rankings, and provide contextual recommendations
- The system achieves competitive performance even with α=1 (text-only recommendations), demonstrating the quality of LLM-generated summaries
- Controllability peaks at α=0.5, balancing text-driven personalization with rich interaction history

## Why This Works (Mechanism)

### Mechanism 1
Optimal transport alignment enables TEARS to map text and black-box embeddings into a shared latent space, preserving both recommendation performance and controllability. By parameterizing both encoders as Gaussian VAEs, OT aligns their latent distributions via the Wasserstein distance, ensuring that edits in text summaries translate into meaningful shifts in recommendations without disrupting the underlying CF structure. Core assumption: Gaussian latent representations and OT are sufficient to capture the full alignment needed for high-quality recommendations. Evidence anchors: [abstract] "we use an optimal transport procedure to align the summaries' representation with the learned representation of a standard VAE for collaborative filtering." Break condition: If latent distributions are non-Gaussian or OT cannot adequately capture the geometry of the alignment, performance and controllability degrade.

### Mechanism 2
The LLM-generated text summaries uniquely encode user preferences, enabling high-quality recommendations even without black-box embeddings. Summaries capture inferred preferences, high-level attributes (genres), and fine-grained details (plots/themes) that, when decoded through a T5 encoder and shared decoder, yield recommendations competitive with or better than AE baselines. Core assumption: Pre-trained LLMs (GPT-4-turbo or LLaMA 3.1-405b) can consistently generate unique, detailed summaries that preserve all necessary preference information. Evidence anchors: [abstract] "TEARS uses a modern LLM to generate user summaries based on user preferences. We find the summaries capture user preferences uniquely." Break condition: If LLM outputs become generic or omit key preference signals, recommendation quality collapses; summaries longer than ~200 words also reduce controllability.

### Mechanism 3
Interpolating between summary-only (α=1) and black-box-only (α=0) embeddings lets users balance interpretability and performance, and guides recommendations with contextual prompts. The convex combination z_c = αz_s + (1-α)z_r allows the model to generate recommendations that blend text-driven personalization with rich interaction history; setting α=0.5 and providing a short prompt shifts the black-box representation toward the desired context. Core assumption: The shared decoder can interpret a convex combination of two aligned embeddings without loss of semantic coherence. Evidence anchors: [abstract] "Changing the mixing coefficient allows the system designer or its users to guide their recommendations further...users can choose recommendations based entirely on their user summaries...or select a blend of both." Break condition: If the shared decoder cannot handle the blended representation, or if OT alignment is poor, controllability and recommendation quality suffer.

## Foundational Learning

- Concept: Variational Autoencoder (VAE) basics
  - Why needed here: TEARS extends VAEs for collaborative filtering; understanding latent encoding/decoding and KL-regularization is critical for aligning text and black-box embeddings.
  - Quick check question: What role does the KL divergence term play in the VAE loss, and why is it important for the OT alignment step?

- Concept: Optimal transport (Wasserstein distance) for distribution alignment
  - Why needed here: OT is used to align Gaussian latents of text and black-box encoders; knowing its closed-form for Gaussians explains the alignment term in the loss.
  - Quick check question: Given two Gaussians N(μ1,Σ1) and N(μ2,Σ2), write the Wasserstein distance formula used in the paper.

- Concept: LLM prompt engineering and summary evaluation
  - Why needed here: Summaries are the bottleneck representation; knowing how to craft effective prompts and evaluate uniqueness (BLEU, edit distance) is essential for reproducible results.
  - Quick check question: If two summaries have an edit distance of 160 words and an average length of 170 words, what does that say about their uniqueness?

## Architecture Onboarding

- Component map: LLM → User summary generator → T5-base encoder → Gaussian latent → OT alignment → Convex combination (α) → Shared decoder → Recommendations
- Critical path: LLM → T5 encoder → OT alignment → shared decoder → recommendations
- Design tradeoffs:
  - Fixed α during training (α=0.5) vs. tunable at inference (improves alignment stability but adds hyperparameter tuning)
  - Gaussian latents vs. more flexible distributions (closed-form OT is simple but may be restrictive)
  - Prompt length (~200 words) vs. summary richness vs. cognitive load (longer → better info but harder to edit)
- Failure signatures:
  - Low controllability → OT alignment missing or α too low
  - Degraded performance vs. AE baselines → LLM summaries not unique or lack key signals
  - Instability during training → both encoders updated or OT weight λ1 too high
- First 3 experiments:
  1. Train TEARS Base (only text encoder + shared decoder) and evaluate NDCG@50 to confirm summary alone is insufficient.
  2. Add OT alignment with λ1 tuned; evaluate controllability (|Δup/down|) vs. recommendation quality at α=1.
  3. Compare OT alignment vs. JSD/contrastive baselines to confirm OT yields best performance and controllability.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of TEARS change when using different LLM architectures (e.g., smaller or specialized LLMs) for generating user summaries? The paper compares GPT-4-turbo and LLaMA 3.1-405b for summary generation, showing comparable performance, but does not explore smaller or specialized LLM architectures. Comparative experiments evaluating TEARS performance with smaller LLMs (e.g., LLaMA 3B) or specialized models (e.g., domain-specific summarization models) across the same datasets would resolve this.

### Open Question 2
Can TEARS maintain effective controllability and performance in cold-start scenarios where users have minimal interaction history? The paper evaluates TEARS on users with sufficient ratings (≥20 for ML-1M, ≥100 for Netflix/Goodbooks) but does not address cold-start users. Experiments on cold-start users with limited ratings, measuring TEARS' recommendation quality and controllability compared to traditional methods would resolve this.

### Open Question 3
How does the optimal transport alignment scale with larger, more diverse datasets, and what are its computational trade-offs? The paper uses optimal transport for aligning summary and black-box embeddings, noting its importance, but does not discuss scalability or computational costs. Runtime comparisons and performance metrics of TEARS with and without OT alignment on datasets with millions of users/items, analyzing computational efficiency would resolve this.

### Open Question 4
Can TEARS be extended to incorporate multimodal user data (e.g., text, images, audio) for richer user representations? The paper focuses on text-based user summaries but mentions the potential for future work in multimodal interactions. Implementation and evaluation of a multimodal TEARS variant using additional data types, measuring improvements in recommendation quality and controllability would resolve this.

## Limitations
- Reliance on LLM-generated summaries may not generalize well across different user populations or cultural contexts
- Evaluation focuses primarily on simulated controllability tasks rather than real user studies, limiting understanding of practical usability
- The prompt engineering process is not fully specified, making replication challenging

## Confidence
- High: The core mechanism of OT alignment between text and black-box embeddings, and the overall framework architecture
- Medium: The performance claims relative to VAE baselines, given the standard evaluation protocols used
- Low: The scalability claims and real-world applicability without extensive user testing

## Next Checks
1. Conduct ablation studies varying the OT weight λ₁ across a wider range to identify optimal alignment strength
2. Test the system with alternative LLMs (e.g., Claude, LLaMA) to verify robustness to different summary generators
3. Evaluate summary uniqueness metrics (BLEU, edit distance) across all users to confirm the claimed uniqueness property