---
ver: rpa2
title: Fair Active Ranking from Pairwise Preferences
arxiv_id: '2402.03252'
source_url: https://arxiv.org/abs/2402.03252
tags:
- items
- ranking
- group
- error
- group-aware
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a fair active ranking problem under pairwise
  comparison feedback. The authors propose a fairness-aware objective function based
  on cascaded norms, generalizing prior work.
---

# Fair Active Ranking from Pairwise Preferences

## Quick Facts
- arXiv ID: 2402.03252
- Source URL: https://arxiv.org/abs/2402.03252
- Authors: Sruthi Gorantla; Sara Ahmadian
- Reference count: 40
- This paper introduces a fair active ranking problem under pairwise comparison feedback, proposing fairness-aware objective functions and algorithms with proven sample complexity bounds.

## Executive Summary
This paper addresses the problem of fair active ranking from pairwise preferences, where the goal is to output a ranking that minimizes a fairness-aware error metric based on cascaded norms. The authors propose both group-blind and group-aware algorithms, analyze their sample complexity, and prove matching lower bounds for the group-blind case. The group-aware algorithm achieves lower sample complexity and better group-wise error balance in experiments on real and synthetic datasets.

## Method Summary
The paper introduces a fair active ranking problem under pairwise comparison feedback, proposing a fairness-aware objective function based on cascaded norms that generalizes multiple fairness notions. Two algorithms are presented: a group-blind algorithm that treats all items equally, and a group-aware algorithm that separates ranking into group-wise ranking and merging steps. The group-aware approach achieves lower sample complexity and better error balance by efficiently allocating queries between inter-group and intra-group comparisons.

## Key Results
- Group-aware algorithms achieve lower sample complexity than group-blind approaches by separating ranking into group-wise ranking and merging steps
- Matching lower bounds (up to log factors) are proven for group-blind algorithms, establishing near-optimality
- The cascaded norm objective generalizes multiple fairness notions, allowing control over group-wise versus item-wise fairness through parameters p and q
- Experiments on real and synthetic datasets demonstrate the group-aware algorithm's superior performance in balancing group-wise errors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The cascaded norm objective allows the algorithm to generalize across multiple fairness notions by tuning parameters p and q.
- Mechanism: By structuring the error metric as an ℓq norm over group-level ℓp norms, the algorithm can control how much weight is given to group-wise versus item-wise fairness. For example, setting q = 1 and p = 1 with weights w(h) = 1/|Gh| yields proportional errors, while setting w(h) = nh gives equal total errors across groups.
- Core assumption: The Plackett-Luce model's pairwise independence property holds, allowing error aggregation across groups without bias.
- Evidence anchors:
  - [abstract]: "Our proposed objective function asks to minimize the ℓq norm of the error of the groups, where the error of a group is the ℓp norm of the error of all the items within that group, for p, q ≥ 1."
  - [section]: "This yields a metric that generalizes several well-known notions of fairness."
  - [corpus]: Weak. Corpus shows related ranking preference works but lacks cascaded norm examples.
- Break condition: If the pairwise comparison model deviates from Plackett-Luce (e.g., violates independence), error aggregation across groups may be biased.

### Mechanism 2
- Claim: Group-aware algorithms achieve lower sample complexity by separating ranking into group-wise ranking and merging steps.
- Mechanism: In Step 1, the algorithm uses BEAT-THE-PIVOT within each group with group-specific error tolerances. In Step 2, it merges group-wise rankings pairwise, using a smaller error parameter than would be needed for global ranking. This targeted approach reduces unnecessary cross-group comparisons.
- Core assumption: The merge step can be done efficiently with pairwise comparisons between groups, and group-wise rankings are stable under the chosen error parameters.
- Evidence anchors:
  - [abstract]: "The group-aware algorithm uses separate ranking and merging steps, achieving lower sample complexity and better group-wise error balance in experiments."
  - [section]: "The key idea in our algorithm design is ensuring that we efficiently balance our queries between inter-group and intra-group pairwise comparisons and in the right order."
  - [corpus]: Weak. No explicit corpus support for two-step merge strategies in ranking.
- Break condition: If groups are very imbalanced in size, the merge step may dominate complexity, eroding the advantage over group-blind methods.

### Mechanism 3
- Claim: Lower bounds for group-blind algorithms match the upper bounds of BEAT-THE-PIVOT up to log factors, proving near-optimality.
- Mechanism: The lower bound construction uses a change-of-measure argument: define hard instances where group-wise error accumulation forces any group-blind algorithm to make Ω(n^{1+max{2/q,2/p}}/ϵ²) queries. This matches the BEAT-THE-PIVOT upper bound when run with adjusted parameters.
- Core assumption: The symmetric property of algorithms (insensitive to item labeling) is preserved and can be exploited in the lower bound proof.
- Evidence anchors:
  - [abstract]: "We provide matching lower bounds up to certain logarithmic factors for group-blind algorithms."
  - [section]: "Proving the lower bound on the sample complexity involves defining a true instance... and defining a class of alternative instances..."
  - [corpus]: Weak. No direct corpus mention of matching lower bounds for active ranking.
- Break condition: If algorithms break symmetry or use group information, the lower bound construction no longer applies.

## Foundational Learning

- Concept: Plackett-Luce (PL) preference model
  - Why needed here: The paper assumes PL model for pairwise comparison feedback, which underpins both algorithm design and theoretical analysis.
  - Quick check question: In the PL model, what is the probability that item i wins over item i′?
    - Answer: θi / (θi + θi′)

- Concept: Cascaded norms and error aggregation
  - Why needed here: The fairness metric is defined as an ℓq norm over group-level ℓp norms, so understanding how norms compose is essential to grasp the objective.
  - Quick check question: If p = q = 1 and all items in a group have error 0.1, what is the group error?
    - Answer: 0.1 (since ℓ1 norm of equal values is just the common value).

- Concept: Active learning and PAC learning
  - Why needed here: The algorithms are active learners that must output a ranking with error < ϵ with probability > 1−δ, so understanding PAC sample complexity is core.
  - Quick check question: What does it mean for a ranking algorithm to be (ϵ, δ)-PACF-Ranker?
    - Answer: It outputs a ranking that is an ϵ-Best-FAIR-Ranking with probability at least 1−δ after a finite number of oracle calls.

## Architecture Onboarding

- Component map:
  - Input: Set of n items, group labels (for group-aware), parameters (p, q, w), error tolerance ϵ, confidence δ
  - Core: BEAT-THE-PIVOT subroutine (group-blind baseline and group-aware Step 1)
  - Group-aware: Group-wise ranking + pairwise merging loop
  - Output: Ranking σ that satisfies fairness constraints

- Critical path:
  1. For group-aware: Group-wise ranking via BEAT-THE-PIVOT (O(log n) queries per item)
  2. Merge sorted groups pairwise (O(n/ϵ² log n/δ) queries)
  3. Return final ranking

- Design tradeoffs:
  - Group-blind: Simpler, no group info needed, but higher sample complexity due to treating all items equally
  - Group-aware: Lower sample complexity and better error balance, but requires group labels and more complex merge logic
  - Parameter choice (p, q): Controls fairness granularity; smaller values give more weight to individual errors

- Failure signatures:
  - If group labels are noisy or incorrect, group-aware may misallocate error budget
  - If p or q are set too large, the algorithm may behave like a group-blind one, losing fairness benefits
  - If groups are highly imbalanced, merging may become a bottleneck

- First 3 experiments:
  1. Run both group-blind and group-aware on a synthetic dataset with two equal-sized groups; compare sample complexity and group-wise errors
  2. Vary p and q on the same dataset; observe how the gap between group-blind and group-aware changes
  3. Test group-aware on a real-world dataset with three groups; verify that minority groups receive lower errors than group-blind

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the gap between the upper and lower bounds for group-aware algorithms be closed for the merging step complexity?
- Basis in paper: [explicit] The authors state: "The gap in our lower and upper bound for the group-aware case is mainly in terms of the sample complexity to merge the ranked lists of groups."
- Why unresolved: The techniques used for exact comparisons do not readily extend to the stochastic feedback case under the Plackett-Luce model.
- What evidence would resolve it: A new proof technique that can handle stochastic pairwise comparisons for merging sorted lists, potentially adapting the lower bound techniques from exact comparison sorting.

### Open Question 2
- Question: How do the sample complexity bounds change under alternative choice models like multinomial probit, Mallows, or nested logit models?
- Basis in paper: [explicit] The authors conclude: "It would also be interesting to study the problem under alternative choice models, such as the multinomial probit, Mallows, nested logit, generalized extreme-value models, etc."
- Why unresolved: The current analysis is specifically tailored to the Plackett-Luce model's independence of irrelevant alternatives property.
- What evidence would resolve it: Sample complexity analysis and matching lower bounds for PAC fair ranking under these alternative choice models.

### Open Question 3
- Question: Can we derive lower bounds for the full class of group-aware and symmetric (ϵ, δ)-PACF-Rankers (not just in-group algorithms)?
- Basis in paper: [explicit] The authors state: "For the algorithms that are allowed to make pairwise comparisons of items from different groups, it becomes challenging to bound the KL divergence between true and alternative instances for some of the pairwise comparisons."
- Why unresolved: The change-of-measure argument by Kaufmann et al. (2014) cannot be directly applied when comparisons across groups are allowed.
- What evidence would resolve it: A novel lower bound proof technique that can handle the KL divergence calculations for algorithms making cross-group comparisons.

## Limitations
- The gap between upper and lower bounds for group-aware algorithms remains open, representing a significant theoretical limitation
- Limited corpus support for key mechanisms (cascaded norm objective, group-aware merge strategy, matching lower bounds)
- The analysis is specific to the Plackett-Luce model and may not extend to alternative choice models without significant modifications

## Confidence
- **High**: Basic Plackett-Luce model assumptions and error metric definitions
- **Medium**: Cascaded norm mechanism, group-aware algorithm sample complexity improvements, matching lower bounds for group-blind case
- **Low**: Absence of lower bounds for group-aware algorithms, corpus support for specific ranking preference works

## Next Checks
1. Implement and test the BEAT-THE-PIVOT algorithm from Saha and Gopalan (2019) as a baseline, verifying that it achieves the claimed O(n^{1+max{2/q,2/p}}/ϵ² log n/δ) sample complexity when run with adjusted parameters.

2. Run controlled experiments on synthetic datasets with two equal-sized groups, varying p and q parameters to observe how the gap between group-blind and group-aware algorithms changes in practice.

3. Validate group-aware error distribution on real-world datasets (COMPAS, German Credit) by measuring whether minority groups receive lower errors compared to group-blind approaches, confirming the claimed error balance benefits.