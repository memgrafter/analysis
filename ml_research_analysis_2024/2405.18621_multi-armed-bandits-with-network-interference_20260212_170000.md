---
ver: rpa2
title: Multi-Armed Bandits with Network Interference
arxiv_id: '2405.18621'
source_url: https://arxiv.org/abs/2405.18621
tags:
- interference
- regret
- algorithm
- log2
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of minimizing regret in multi-armed
  bandits when the reward of each unit depends on treatments assigned to other units
  (network interference). The key challenge is that with N units and A actions, the
  action space grows exponentially as A^N, making naive approaches computationally
  intractable.
---

# Multi-Armed Bandits with Network Interference
## Quick Facts
- arXiv ID: 2405.18621
- Source URL: https://arxiv.org/abs/2405.18621
- Reference count: 40
- Key outcome: Algorithms for MAB with network interference achieving O((AsT)^(2/3)) or O(√(NAsT)) regret by exploiting sparse Fourier representation

## Executive Summary
This paper addresses the challenge of multi-armed bandits with network interference, where each unit's reward depends on treatments assigned to neighboring units. The key insight is that under sparse network interference, rewards can be expressed as sparse linear functions in the Fourier basis, reducing the effective dimensionality from exponential in N to linear in the number of neighbors s. The authors develop regression-based algorithms (explore-then-commit and sequential elimination) that leverage this sparse Fourier representation to achieve sublinear regret without the exponential dependence on the number of units that plagues naive approaches.

## Method Summary
The authors propose a Fourier-based approach to handle network interference in multi-armed bandits. For known interference graphs, they use explore-then-commit with OLS regression or sequential elimination algorithms. For unknown interference, they employ Lasso regression on the full Fourier basis while exploiting sparsity. The core technique transforms the exponentially large action space into a linear model in Fourier coordinates, enabling simple regression-based approaches that scale with the sparsity parameter s rather than the full dimensionality N.

## Key Results
- Achieves O((AsT)^(2/3)) regret for known interference using explore-then-commit with OLS regression
- Achieves O(√(NAsT)) regret for known interference using sequential elimination algorithm
- Achieves O(N^(1/3)(AsT)^(2/3)) regret for unknown interference using Lasso regression
- Numerical simulations show performance improvements over classical MAB baselines, particularly avoiding exponential scaling in N

## Why This Works (Mechanism)
### Mechanism 1
- Claim: Sparse network interference enables exponential reduction in the effective action space
- Mechanism: Under Assumption 2, each unit's reward function depends only on treatments of s neighboring units. This induces a sparse Fourier coefficient vector θn with only As non-zero entries, reducing the effective dimension from AN to As per unit.
- Core assumption: The interference graph is sparse (s ≪ N) and the reward function can be linearly represented in the Fourier basis.
- Evidence anchors:
  - [abstract]: "we study a sparse network interference model, where the reward of a unit is only affected by the treatments assigned to s neighboring units"
  - [section 3.3]: "Assumption 2 implies that the reward can be re-expressed as a sparse linear model" with Proposition 3.1 proving ∥θn∥0 ≤ As
  - [corpus]: Weak evidence - corpus papers focus on general MAB interference but don't address Fourier-based sparse representation specifically
- Break condition: If the interference graph becomes dense (s approaches N) or if rewards cannot be accurately represented as sparse Fourier functions, the dimensionality reduction fails and regret reverts to O(√ANT).

### Mechanism 2
- Claim: Known interference enables optimal O(√T) regret through sequential elimination
- Mechanism: When the interference graph G is known, Algorithm 3 uses sequential elimination to remove suboptimal actions. Each epoch eliminates actions whose estimated rewards fall below the current best by 2−ℓ, achieving O(√NAsT) regret with optimal T dependence.
- Core assumption: The learner has exact knowledge of the interference graph G and can perform local exploration on each unit's neighborhood.
- Evidence anchors:
  - [section 4.2]: "we utilize a 'sequential-elimination' algorithm that eliminates low-reward actions" achieving O(√NTAs) regret
  - [section D]: Theorem D.1 formalizes this result with precise epoch sizes and regret bound
  - [corpus]: No direct evidence - corpus papers don't discuss sequential elimination algorithms for known interference graphs
- Break condition: If the interference graph contains errors or if the algorithm cannot perform accurate local exploration due to insufficient samples, the elimination process may incorrectly remove optimal actions, leading to linear regret.

### Mechanism 3
- Claim: Unknown interference is handled through Lasso regression adapting to sparsity
- Mechanism: When G is unknown, Algorithm 2 uses Lasso regression on the full Fourier basis (dimension AN) but leverages sparsity of θn to achieve O(N1/3(AsT)2/3) regret. The incoherence of uniformly random Fourier designs enables Lasso to recover sparse coefficients.
- Core assumption: The Fourier design matrix from random actions is incoherent, and the true coefficient vectors θn are sufficiently sparse.
- Evidence anchors:
  - [section 5]: "we use the Lasso instead of OLS locally which adapts to sparsity of θn"
  - [section C]: Lemma C.2 proves incoherence of Fourier characteristics with high probability
  - [corpus]: Weak evidence - corpus papers mention high-dimensional bandits but not specifically Fourier-based Lasso approaches for network interference
- Break condition: If the true coefficient vectors are not sparse (s approaches N) or if the Fourier design becomes coherent due to poor action sampling, Lasso recovery fails and regret degrades significantly.

## Foundational Learning
- Concept: Discrete Fourier analysis on Boolean functions
  - Why needed here: Transforms the exponentially large action space into a linear model in Fourier basis, enabling regression-based approaches that scale with sparsity rather than full dimensionality
  - Quick check question: Can you explain why the Fourier coefficient θn,S is non-zero only when S ⊂ B(n) under sparse network interference?

- Concept: Sub-Gaussian concentration inequalities
  - Why needed here: Provides high-probability error bounds for empirical estimates in both OLS and Lasso regression, essential for establishing regret guarantees
  - Quick check question: How does the 1-sub-Gaussian assumption on noise translate to concentration bounds for the estimated Fourier coefficients?

- Concept: Incoherence and restricted eigenvalue conditions
  - Why needed here: Enables Lasso to recover sparse vectors from high-dimensional observations; specifically, the Fourier design from uniform random actions satisfies incoherence with high probability
  - Quick check question: What is the relationship between incoherence parameter and the required number of samples for Lasso to succeed?

## Architecture Onboarding
- Component map: N units → A actions → T rounds → Network interference graph G → Fourier coefficient estimation → Action selection → Reward observation → Regret calculation
- Critical path: Uniform exploration → Fourier coefficient estimation (OLS/Lasso) → Action selection → Reward observation → Regret accumulation
- Design tradeoffs:
  - Known vs unknown interference: Known interference enables sequential elimination with O(√T) regret but requires graph knowledge; unknown interference uses Lasso with worse T dependence but works without graph
  - Exploration length E: Longer exploration improves coefficient estimation but reduces exploitation time; can be chosen via cross-validation
  - Computational complexity: Lasso on AN dimensions vs OLS on As dimensions (known interference)
- Failure signatures:
  - Exponential regret growth: Indicates interference graph is denser than assumed or Fourier representation is inaccurate
  - High variance in coefficient estimates: Suggests insufficient exploration or violation of sub-Gaussian noise assumption
  - Lasso fails to converge: Points to incoherence issues or insufficient samples relative to AN
- First 3 experiments:
  1. Small-scale simulation with N=5, A=2, s=2 to verify Fourier coefficient recovery and basic regret scaling
  2. Known interference case with synthetic graph to compare explore-then-commit vs sequential elimination algorithms
  3. Unknown interference case with varying s values to observe transition from efficient to inefficient performance as sparsity breaks down

## Open Questions the Paper Calls Out
- Can we design algorithms that achieve optimal T dependence without the N^(1/3) penalty in the unknown interference case?
- Is there an algorithm that achieves the best of both worlds - optimal √T dependence without paying the √N cost?
- Can we establish lower bounds to understand the fundamental limits of network multi-armed bandits?

## Limitations
- The sparsity assumption (s ≪ N) is critical but may not hold in many real-world network interference scenarios
- The paper relies heavily on Fourier basis representations being accurate for the reward functions
- While the algorithms achieve sublinear regret theoretically, the constants hidden in O(·) notation could be prohibitively large for practical applications

## Confidence
- High confidence in the mathematical framework and Fourier analysis approach for known sparse interference
- Medium confidence in the sequential elimination algorithm's practical performance given limited experimental validation
- Low confidence in the Lasso-based approach for unknown interference, as the proof relies on idealized incoherence conditions that may not hold in practice

## Next Checks
1. Test algorithm performance on networks with varying sparsity levels (s/N ratios) to identify the transition point where regret scaling deteriorates from O(T^2/3) to O(√NT)
2. Implement the algorithms on real-world network data (e.g., social networks, e-commerce platforms) to verify that the theoretical assumptions about interference patterns hold empirically
3. Conduct ablation studies removing the Fourier representation assumption to quantify the contribution of this mathematical framework versus simpler approaches