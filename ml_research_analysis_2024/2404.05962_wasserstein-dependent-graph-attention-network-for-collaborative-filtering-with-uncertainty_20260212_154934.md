---
ver: rpa2
title: Wasserstein Dependent Graph Attention Network for Collaborative Filtering with
  Uncertainty
arxiv_id: '2404.05962'
source_url: https://arxiv.org/abs/2404.05962
tags:
- information
- user
- items
- users
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of modeling uncertainty in collaborative
  filtering for recommender systems. The authors propose a novel Wasserstein dependent
  Graph Attention Network (W-GAT) that represents users and items as Gaussian distributions
  to capture uncertainty.
---

# Wasserstein Dependent Graph Attention Network for Collaborative Filtering with Uncertainty

## Quick Facts
- arXiv ID: 2404.05962
- Source URL: https://arxiv.org/abs/2404.05962
- Authors: Haoxuan Li; Yuanxin Ouyang; Zhuang Liu; Wenge Rong; Zhang Xiong
- Reference count: 34
- Primary result: Achieves significant improvements in recall and NDCG metrics on three benchmark datasets using Wasserstein-dependent Graph Attention Network with Gaussian embeddings

## Executive Summary
This paper addresses the challenge of modeling uncertainty in collaborative filtering for recommender systems. The authors propose a novel Wasserstein dependent Graph Attention Network (W-GAT) that represents users and items as Gaussian distributions to capture uncertainty. W-GAT employs a graph attention mechanism with Wasserstein distance to propagate variance information and calculate attention scores, overcoming limitations of previous methods. The model also incorporates Wasserstein-dependent mutual information to maximize the similarity between positive user-item pairs. Experiments on three benchmark datasets demonstrate that W-GAT outperforms several competitive baselines.

## Method Summary
W-GAT represents users and items as Gaussian distributions with mean and variance embeddings. The model uses graph attention networks with Wasserstein distance to compute attention weights, which are symmetric and satisfy the triangle inequality. Variance information is propagated using squared attention matrices to preserve semantic continuity. The model is trained using BPR loss combined with Wasserstein-dependent mutual information loss to enhance similarity between positive pairs. The framework is evaluated on Movielens-1M, Digital Music, and MIND datasets with standard 5-core preprocessing.

## Key Results
- W-GAT outperforms competitive baselines including LightGCN, NGCF, and KGAT on all three benchmark datasets
- Significant improvements in recall@20 and NDCG@20 metrics across Movielens-1M, Digital Music, and MIND datasets
- The model effectively captures user uncertainty related to behavior information and interest diversity, as well as item uncertainty related to category information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Wasserstein distance in W-GAT provides more stable and semantically meaningful attention scores compared to KL divergence
- Mechanism: W-GAT uses Wasserstein distance as attention weights in the graph attention network, which is symmetric and satisfies the triangle inequality, avoiding the asymmetry and sensitivity to small differences inherent in KL divergence
- Core assumption: The semantic distinction between user and item variances requires a symmetric similarity measure that can propagate information appropriately
- Evidence anchors:
  - [abstract]: "We utilize graph attention network and Wasserstein distance to learn Gaussian embedding for each user and item"
  - [section]: "Wasserstein distance represents the differences between two distributions regarding the actual distance between sampled data... Wasserstein distance to measure similarity, which is not only symmetric but also satisfies the triangle inequality"
  - [corpus]: Weak - no direct evidence about Wasserstein vs KL divergence performance in GNNs
- Break condition: If the underlying distributions are too far apart or degenerate, Wasserstein distance may still suffer from gradient issues, though less severely than KL divergence

### Mechanism 2
- Claim: W-GAT's variance propagation strategy using squared attention matrix preserves semantic continuity between user and item representations
- Mechanism: W-GAT updates node variances using the squared attention weight matrix (Ã²) instead of direct attention weights, ensuring variance information propagates only between nodes with similar semantics
- Core assumption: User variances represent interest diversity while item variances represent category uncertainty, requiring different propagation patterns
- Evidence anchors:
  - [section]: "To preserve the semantic continuity of user and item variances, we propagate the variances by Ã², which ensures the information of variances comes from the nodes that have the same semantics"
  - [abstract]: "We utilize graph attention network and Wasserstein distance to learn Gaussian embedding for each user and item"
  - [corpus]: Weak - no direct evidence about variance propagation strategies in graph attention networks
- Break condition: If the attention mechanism becomes too selective, important cross-semantic information might be lost, potentially reducing recommendation diversity

### Mechanism 3
- Claim: Wasserstein-dependent mutual information provides more robust similarity estimation than KL-based methods
- Mechanism: W-GAT incorporates Wasserstein-dependent mutual information using Lipschitz-constrained functions, which requires fewer samples and avoids gradient vanishing issues compared to KL divergence-based estimation
- Core assumption: Mutual information estimation needs to be sample-efficient and stable for effective contrastive learning in collaborative filtering
- Evidence anchors:
  - [section]: "The widely used contrastive learning loss [9] maximizes the mutual information between positive pairs to enhance performances... Wasserstein distance addresses the limitations induced by KL divergence, which requires exponential-level sampling"
  - [abstract]: "Additionally, our method incorporates Wasserstein-dependent mutual information further to increase the similarity between positive pairs"
  - [corpus]: Weak - no direct evidence about Wasserstein-dependent mutual information in recommendation systems
- Break condition: If the Lipschitz constraint is too restrictive, the model might not capture fine-grained similarities between users and items

## Foundational Learning

- Concept: Gaussian distributions as embeddings
  - Why needed here: Allows modeling of uncertainty in user preferences and item categories, which point embeddings cannot capture
  - Quick check question: What are the two parameters that define a Gaussian distribution used for embeddings in this work?

- Concept: Wasserstein distance vs KL divergence
  - Why needed here: Determines how similarity between uncertain representations is calculated, affecting attention mechanisms and mutual information estimation
  - Quick check question: Which distance measure satisfies symmetry and triangle inequality, making it more suitable for graph-based collaborative filtering?

- Concept: Graph attention networks
  - Why needed here: Enables learning of importance weights between nodes based on their representations, crucial for propagating uncertainty information
  - Quick check question: How does the attention mechanism in GAT differ from standard graph convolution when dealing with probabilistic embeddings?

## Architecture Onboarding

- Component map: User-item interaction graph -> W-GAT layers with Wasserstein distance attention -> Similarity computation -> Loss calculation -> Parameter update
- Critical path: Graph construction → W-GAT encoding → Similarity computation → Loss calculation → Parameter update
- Design tradeoffs:
  - Using Gaussian embeddings increases model complexity but enables uncertainty modeling
  - Wasserstein distance is computationally more expensive than inner products but provides better semantic properties
  - The squared attention matrix for variance propagation reduces confusion but may limit information flow
- Failure signatures:
  - High variance in training loss indicates issues with mutual information estimation
  - Clustering of user/item embeddings suggests improper variance propagation
  - Suboptimal performance on sparse datasets may indicate insufficient uncertainty modeling
- First 3 experiments:
  1. Compare W-GAT with LightGCN on a small dataset to verify the impact of Gaussian embeddings
  2. Test different attention weight propagation strategies (A vs A²) to validate variance propagation design
  3. Evaluate performance with and without the Wasserstein-dependent mutual information loss to assess its contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can probabilistic embeddings be effectively extended to hypergraph-based recommendation systems?
- Basis in paper: [explicit] The paper mentions that probabilistic representations are worth exploring for enhancing recommendation diversity and could be applied to hypergraph recommendation systems in the future.
- Why unresolved: The paper focuses on bipartite graphs and does not address the complexities of hypergraphs, such as handling higher-order relationships and varying hyperedge sizes.
- What evidence would resolve it: Experimental results demonstrating improved performance on hypergraph datasets, along with analysis of how probabilistic embeddings capture uncertainty in higher-order interactions.

### Open Question 2
- Question: What are the optimal strategies for modeling variances in users and items to maximize recommendation accuracy and diversity?
- Basis in paper: [inferred] The paper discusses capturing uncertainty through variances but does not explore different strategies for modeling them or their impact on recommendation diversity.
- Why unresolved: The paper uses a simple diagonal covariance matrix and does not compare alternative methods for variance modeling or analyze the trade-off between accuracy and diversity.
- What evidence would resolve it: Comparative studies of different variance modeling techniques, including their effects on accuracy, diversity metrics, and computational efficiency.

### Open Question 3
- Question: How does the Lipschitz constraint in the Wasserstein dependent mutual information affect the model's ability to capture true user preferences?
- Basis in paper: [explicit] The paper introduces the Lipschitz constraint to prevent the model from exaggerating distances between negative samples, but does not analyze its impact on preference learning.
- Why unresolved: The paper does not provide empirical evidence or theoretical analysis of how the Lipschitz constraint influences the model's performance in distinguishing relevant from irrelevant items.
- What evidence would resolve it: Experiments comparing models with and without the Lipschitz constraint, along with analysis of how the constraint affects the model's ability to rank items and capture user preferences.

## Limitations

- The empirical validation relies on relatively small-scale datasets (M1M, DM, MIND) with limited diversity in recommendation domains
- The comparative analysis lacks extensive ablation studies isolating the contributions of individual components
- No discussion of computational complexity or scalability to larger real-world systems

## Confidence

- **High Confidence**: The theoretical framework using Wasserstein distance for attention mechanisms is well-established in the literature
- **Medium Confidence**: The experimental results showing performance improvements over baseline methods, though limited by dataset scale
- **Low Confidence**: Claims about semantic distinction between user and item variances without extensive qualitative analysis

## Next Checks

1. **Ablation study on component importance**: Remove the Wasserstein-dependent mutual information loss and compare performance to isolate its contribution
2. **Scalability evaluation**: Test the model on larger, more diverse datasets (e.g., Amazon product datasets) to assess real-world applicability
3. **Uncertainty visualization**: Generate t-SNE plots of learned Gaussian embeddings to qualitatively assess whether user variances capture interest diversity and item variances capture category uncertainty as claimed