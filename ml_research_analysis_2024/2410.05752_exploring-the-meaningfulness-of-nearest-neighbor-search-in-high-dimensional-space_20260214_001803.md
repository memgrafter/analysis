---
ver: rpa2
title: Exploring the Meaningfulness of Nearest Neighbor Search in High-Dimensional
  Space
arxiv_id: '2410.05752'
source_url: https://arxiv.org/abs/2410.05752
tags:
- dimensionality
- distance
- text
- meaningfulness
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the meaningfulness of nearest neighbor
  search (NNS) in high-dimensional vector spaces, a critical concern given the increasing
  dimensionality of vectors used in modern machine learning applications. The authors
  examine factors affecting NNS meaningfulness, focusing on the choice of distance
  functions and dimensionality.
---

# Exploring the Meaningfulness of Nearest Neighbor Search in High-Dimensional Space

## Quick Facts
- arXiv ID: 2410.05752
- Source URL: https://arxiv.org/abs/2410.05752
- Authors: Zhonghan Chen; Ruiyuan Zhang; Xi Zhao; Xiaojun Cheng; Xiaofang Zhou
- Reference count: 40
- Key outcome: High-dimensional text embeddings maintain NNS meaningfulness while random vectors quickly lose meaning as dimensionality increases

## Executive Summary
This paper investigates whether nearest neighbor search (NNS) remains meaningful in high-dimensional vector spaces, a critical concern for modern machine learning applications. The authors examine how dimensionality and distance functions affect NNS meaningfulness, using relative contrast (RC) as a quantitative measure. Their experiments span multiple datasets including random vectors, image features, and text embeddings of varying dimensions. The key finding is that text embeddings maintain high RC values even at very high dimensions, while random vectors rapidly lose meaningfulness as dimensions increase, demonstrating that high-dimensional text embeddings remain effective for NNS applications.

## Method Summary
The study employs relative contrast (RC) as the primary metric to evaluate NNS meaningfulness in high-dimensional spaces. Experiments systematically vary dimensionality from 16 to 12288 dimensions and test three distance functions (L1, L2, and angular) across multiple datasets. Text embeddings are customized using dense layers with frozen original model parameters, trained on NLI datasets. The methodology includes generating random vectors, image features (SIFT1M, GIST1M), image embeddings (ImageNet-Tiny, Places2), and text embeddings from various sources (AmazonQA, WikiSummary, GooAQ, AgNews, Yahoo, OrcaChat) using models like all-MiniLM-L6-V2 and bert-base-nli-mean-tokens.

## Key Results
- Text embeddings maintain high RC values (1.75-2.05) even at very high dimensions, while random vectors' RC values quickly converge to 1
- The choice of distance function (L1, L2, or angular) has minimal impact on NNS meaningfulness across all tested datasets
- Increasing dimensionality of text embeddings has minor effects on NNS meaningfulness compared to the dramatic degradation seen in random vectors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Text embeddings maintain meaningfulness in high-dimensional space due to their structured nature, while random vectors quickly lose meaning.
- Mechanism: The embedding models encode semantic relationships and patterns from real data, creating a structured distribution that resists the "curse of dimensionality." Random vectors follow a uniform distribution that collapses distances as dimensions increase.
- Core assumption: The structured distribution of text embeddings preserves relative contrast (RC) values even at high dimensions.
- Evidence anchors:
  - [abstract] "high-dimensional text embeddings exhibit increased resilience as dimensionality rises to higher levels when compared to random vectors"
  - [section] "RC values are consistently maintained at a high value (from 1.75 to 2.05), which indicates a meaningful NNS"
  - [corpus] Weak evidence - no direct corpus neighbors address this specific mechanism
- Break condition: If embedding models produce random-like distributions or if semantic structure is lost during training.

### Mechanism 2
- Claim: The choice of distance function (L1, L2, or angular) has minimal impact on NNS meaningfulness.
- Mechanism: Different distance functions compute relative distances consistently across datasets, preserving the ranking of point relationships. The core structure of the data distribution remains intact regardless of the distance metric used.
- Core assumption: Distance functions preserve the relative ordering of distances between points.
- Evidence anchors:
  - [abstract] "the choice of distance function (L1, L2, or angular) has minimal impact on the meaningfulness of NNS outcomes"
  - [section] "changing the distance function will not significantly impact the meaningfulness of the dataset in NNS"
  - [corpus] Weak evidence - no direct corpus neighbors address this specific mechanism
- Break condition: If datasets contain extreme outliers or have highly non-uniform distributions that interact differently with specific distance metrics.

### Mechanism 3
- Claim: Increasing dimensionality of text embeddings doesn't necessarily degrade NNS performance due to the effectiveness of embedding-based representation.
- Mechanism: Text embeddings capture meaningful semantic relationships that remain distinguishable even as dimensions increase, unlike random vectors which lose all structure.
- Core assumption: Embedding models create representations where semantic similarity corresponds to geometric proximity in high-dimensional space.
- Evidence anchors:
  - [abstract] "text embeddings maintain high RC values even at very high dimensions, indicating that they are less susceptible to the 'curse of dimensionality'"
  - [section] "the increment of dimensionality on text embeddings has minor effects over the meaningfulness of the NNS"
  - [corpus] Weak evidence - no direct corpus neighbors address this specific mechanism
- Break condition: If embedding models fail to capture meaningful semantic relationships or if dimensionality increases beyond the model's effective capacity.

## Foundational Learning

- Concept: Relative Contrast (RC)
  - Why needed here: RC is the primary metric for evaluating NNS meaningfulness in high-dimensional space.
  - Quick check question: How does RC change as dimensionality increases for random vectors vs text embeddings?

- Concept: Local Intrinsic Dimensionality (LID)
  - Why needed here: LID provides complementary information about dataset structure and helps understand the "curse of dimensionality."
  - Quick check question: What does a high LID value indicate about a dataset's susceptibility to the curse of dimensionality?

- Concept: Distance functions (L1, L2, Angular)
  - Why needed here: Different distance functions may affect NNS performance and are evaluated in the study.
  - Quick check question: How do L1 and L2 distances differ in their sensitivity to high-dimensional spaces?

## Architecture Onboarding

- Component map: Embedding model → Dimensionality transformation → Distance computation → RC calculation → Evaluation
- Critical path: Data → Embedding → Dimensionality adjustment → NNS computation → RC measurement
- Design tradeoffs: Higher dimensionality may capture more information but risks losing meaningfulness; simpler distance functions are faster but may be less discriminative.
- Failure signatures: Rapid convergence of RC to 1, loss of semantic relationships in retrieved neighbors, inconsistent results across distance functions.
- First 3 experiments:
  1. Generate random vectors and text embeddings at various dimensions (16-4096) and measure RC values.
  2. Apply different distance functions (L1, L2, Angular) to the same datasets and compare RC results.
  3. Vary dimensionality of a single embedding model and track RC changes to identify the inflection point where meaningfulness degrades.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the meaningfulness of NNS change for other types of high-dimensional embeddings (e.g., audio, video, or multimodal embeddings) compared to text and image embeddings?
- Basis in paper: [inferred] The paper focuses on text and image embeddings, noting that image embeddings were excluded from the dimensionality analysis due to their current secondary role in RAG systems. However, it does not address other modalities like audio or video.
- Why unresolved: The study does not include experiments or analysis on other embedding types, leaving their behavior in high-dimensional spaces unexplored.
- What evidence would resolve it: Conducting similar experiments with audio, video, or multimodal embeddings and comparing their relative contrast (RC) values across varying dimensions would clarify their meaningfulness in NNS.

### Open Question 2
- Question: Does the choice of distance function (e.g., L1, L2, or angular) have any impact on the computational efficiency or scalability of NNS in high-dimensional spaces?
- Basis in paper: [explicit] The paper concludes that the choice of distance function has minimal impact on the meaningfulness of NNS but does not discuss its effects on computational efficiency or scalability.
- Why unresolved: The study focuses solely on the meaningfulness of NNS and does not explore performance trade-offs related to distance function selection.
- What evidence would resolve it: Benchmarking the runtime and resource usage of NNS algorithms using different distance functions on large-scale high-dimensional datasets would provide insights into their efficiency.

### Open Question 3
- Question: How do different training objectives or embedding architectures (e.g., contrastive learning vs. masked language modeling) affect the resilience of embeddings to the curse of dimensionality?
- Basis in paper: [inferred] The paper uses specific embedding models (e.g., all-MiniLM-L6-V2 and bert-base-nli-mean-tokens) but does not explore how different training objectives or architectures influence their performance in high-dimensional spaces.
- Why unresolved: The study does not compare embeddings generated by different training methods or architectures, leaving their impact on dimensionality resilience unexplored.
- What evidence would resolve it: Comparing the RC values and NNS meaningfulness of embeddings generated by models with different training objectives or architectures (e.g., contrastive learning vs. masked language modeling) would clarify their relative performance.

## Limitations
- Findings are based on specific embedding models (MiniLM and BERT-base) and may not generalize to all architectures
- RC metric doesn't directly capture semantic relevance in all contexts
- Study focuses on specific datasets and distance functions, potentially missing edge cases

## Confidence
- High confidence: The observation that text embeddings maintain higher RC values than random vectors across increasing dimensions
- Medium confidence: The claim that distance function choice has minimal impact on NNS meaningfulness across all dataset types
- Low confidence: The generalization that increasing dimensionality never degrades NNS performance for any text embedding model

## Next Checks
1. Test additional embedding models beyond MiniLM and BERT-base to verify if the observed resilience to dimensionality is consistent across different architectures and training approaches.

2. Conduct ablation studies on the embedding training process to determine whether the structured distribution is primarily due to the model architecture or the training data characteristics.

3. Evaluate alternative distance metrics (such as Manhattan, Chebyshev, or learned metrics) and datasets with different dimensional characteristics to identify potential edge cases where distance function choice does impact meaningfulness.