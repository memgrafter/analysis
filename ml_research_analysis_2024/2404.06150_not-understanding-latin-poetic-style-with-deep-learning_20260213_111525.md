---
ver: rpa2
title: (Not) Understanding Latin Poetic Style with Deep Learning
arxiv_id: '2404.06150'
source_url: https://arxiv.org/abs/2404.06150
tags:
- keras
- layers
- latin
- style
- ovid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the use of neural networks to understand authorial
  style in classical Latin verse. The author attempts to analyze the attention of
  various neural network models (LSTMs and CNNs) trained on a corpus of Latin poetry
  encoded with sonic and metrical features.
---

# (Not) Understanding Latin Poetic Style with Deep Learning

## Quick Facts
- arXiv ID: 2404.06150
- Source URL: https://arxiv.org/abs/2404.06150
- Reference count: 26
- Primary result: Neural networks achieve 97-98% accuracy in authorship classification of Latin hexameter poetry

## Executive Summary
This paper investigates the use of neural networks (LSTMs and CNNs) to understand authorial style in classical Latin verse by encoding poems with syllabic and metrical features. While the models achieve high classification accuracy (97-98%), the author finds it difficult to interpret what specific poetic features the networks use for their decisions. The study suggests CNNs are better suited than LSTMs for this task due to faster training and potentially better interpretability, while also emphasizing the importance of dropout and batch normalization to prevent overfitting in small poetic datasets.

## Method Summary
The author trains LSTM and CNN models on a corpus of Latin hexameter poetry (12 authors, 72,922 lines) encoded with syllabic and metrical features. The models use pre-trained syllable embeddings and are trained on 64-line samples. The CNN architecture processes data as 2D spatial patterns (64x20x32), while LSTMs process sequences bidirectionally. Both models include batch normalization and dropout layers to reduce overfitting.

## Key Results
- CNNs achieve 97-98% classification accuracy on authorship attribution task
- LSTMs achieve 92-93% accuracy when trained only on metrical features
- Simple trainable embeddings outperform hand-designed domain-specific encodings
- CNNs train more quickly than LSTMs while maintaining equivalent accuracy

## Why This Works (Mechanism)

### Mechanism 1
The paper argues that CNNs are better suited than LSTMs for authorship classification of Latin poetry due to faster training, equivalent accuracy, and better interpretability. CNNs process spatial patterns more efficiently and are designed to detect local patterns that may correspond to poetic features like rhyme and alliteration. Their 2D structure aligns with the "sound picture" metaphor of poetry.

### Mechanism 2
Trainable embeddings outperform hand-designed domain-specific encodings for poetic style analysis. Simple, trainable embeddings can learn subtle stylistic patterns from the data, while hand-crafted encodings may miss important features or impose incorrect assumptions.

### Mechanism 3
Techniques like dropout and batch normalization are critical for preventing overfitting in small poetic datasets. Dropout randomly deactivates neurons during training, forcing the network to learn more robust features. Batch normalization normalizes the inputs to each layer, stabilizing the learning process.

## Foundational Learning

- **Neural network architecture (CNNs vs. LSTMs)**: Why needed here - The paper compares these two architectures for authorship classification and interpretability of Latin poetry. Quick check question: What are the key differences between CNNs and LSTMs, and why might CNNs be better suited for analyzing spatial patterns in poetry?

- **Embeddings and their role in neural networks**: Why needed here - The paper emphasizes the importance of trainable embeddings over hand-designed encodings for capturing poetic style. Quick check question: How do trainable embeddings learn to represent linguistic features, and why might they be more effective than fixed encodings for this task?

- **Overfitting and regularization techniques**: Why needed here - The paper highlights the importance of dropout and batch normalization for preventing overfitting in small datasets. Quick check question: What is overfitting, and how do dropout and batch normalization help prevent it in neural networks?

## Architecture Onboarding

- **Component map**: Embedding(32) -> Reshape(64x20x32) -> Conv2D(24,4x2) -> AvgPool(2x2) -> BN -> Conv2D(48,4x2) -> AvgPool(2x2) -> BN -> Flatten -> Dense(64) -> Dense(64) -> Dense(n_classes)

- **Critical path**: Data preprocessing → Embedding layer initialization → Convolutional feature extraction → Pooling and normalization → Final classification

- **Design tradeoffs**: Choice between CNNs and LSTMs involves tradeoffs between training speed, interpretability, and the ability to capture sequential vs. spatial patterns. Average pooling vs. max pooling affects the model's ability to detect features at different scales.

- **Failure signatures**: If the model overfits, it may achieve high accuracy on the training set but poor performance on unseen data. If embeddings don't capture meaningful features, the model may not learn effective representations of poetic style.

- **First 3 experiments**:
  1. Train a simple CNN with pre-trained embeddings on a small subset of data to verify basic architecture works
  2. Compare CNN performance with similar LSTM model to confirm CNNs are better suited for this task
  3. Experiment with different dropout rates and batch normalization configurations to find optimal regularization strategy

## Open Questions the Paper Calls Out

### Open Question 1
What specific poetic features or stylistic elements are the neural networks using to achieve such high accuracy in authorship classification? Despite high accuracy, the paper could not determine what specific features the networks focus on to make their decisions.

### Open Question 2
Are there more effective techniques for interpreting the attention of neural networks trained on poetic data? Current attention visualization methods seem insufficient for understanding how neural networks process and classify poetic style.

### Open Question 3
Do the pre-trained syllable embeddings contain meaningful poetic information that can be utilized for authorship attribution or stylistic analysis? The paper hints at potential usefulness but doesn't provide detailed analysis of what information these embeddings contain.

## Limitations
- Interpretability claims about CNNs are speculative without quantitative validation
- Results are based on a single poetic corpus and may not generalize to other languages or traditions
- Success heavily depends on the quality and complexity of the input encoding scheme

## Confidence
- **High confidence**: Classification accuracy results (97-98% for CNNs) and importance of dropout/batch normalization
- **Medium confidence**: CNNs train faster and achieve equivalent accuracy to LSTMs, superiority of trainable embeddings
- **Low confidence**: Broader claims about understanding poetic style and specific interpretability of CNNs for detecting poetic features

## Next Checks
1. **Feature ablation study**: Systematically remove individual encoded features to determine which contribute most to classification accuracy
2. **Cross-linguistic validation**: Apply methodology to different poetic traditions (e.g., Chinese regulated verse or English blank verse) to test generalizability
3. **Alternative encoding schemes**: Experiment with simpler encodings to test sensitivity of results to input representation