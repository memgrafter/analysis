---
ver: rpa2
title: Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization
arxiv_id: '2411.02920'
source_url: https://arxiv.org/abs/2411.02920
tags:
- domain
- classes
- samples
- learning
- generalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of open-set single-source domain
  generalization (OS-SDG), which aims to learn a model from a single source domain
  that can generalize to unknown target domains with both domain shifts and label
  shifts. The proposed approach, DEBUG, expands the scarce source domain by synthesizing
  new samples through background suppression and style augmentation.
---

# Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization

## Quick Facts
- arXiv ID: 2411.02920
- Source URL: https://arxiv.org/abs/2411.02920
- Authors: Pengkun Jiao; Na Zhao; Jingjing Chen; Yu-Gang Jiang
- Reference count: 40
- Key outcome: DEBUG achieves 9% increase in overall accuracy and 26% increase in h-score compared to DSU+OVA baseline on PACS dataset

## Executive Summary
This paper addresses the challenging open-set single-source domain generalization (OS-SDG) problem, where a model must learn from one source domain and generalize to unknown target domains with both domain shifts and label shifts. The proposed DEBUG framework tackles this through two complementary mechanisms: domain expansion via background suppression and style augmentation to create domain-invariant features, and boundary growth using edge maps as an additional modality to improve open-set recognition. Extensive experiments across multiple datasets demonstrate that DEBUG significantly outperforms existing methods, achieving state-of-the-art performance in recognizing both known and unknown classes in target domains.

## Method Summary
DEBUG addresses OS-SDG through a two-pronged approach: domain expansion and boundary growth. For domain expansion, it synthesizes new training samples by removing background regions using DenseCLIP segmentation and applying global probabilistic style augmentations. Knowledge distillation enforces consistency between features from original and augmented samples. For boundary growth, edge maps extracted via HED serve as an additional modality, training multi-binary classifiers with hard negatives to create more discriminative class boundaries. The model uses a ResNet backbone with both multi-class and one-vs-all binary classifiers, optimizing a combined loss of cross-entropy, one-vs-all loss with edge maps, and knowledge distillation loss.

## Key Results
- Achieves 9% increase in overall accuracy and 26% increase in h-score compared to DSU+OVA baseline on PACS
- State-of-the-art performance across PACS, Office31, OfficeHome, and DomainNet126 datasets
- Demonstrates effectiveness of both domain expansion and boundary growth mechanisms through ablation studies
- Shows robustness to different segmentation methods and edge detectors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain expansion through background suppression and style augmentation improves cross-domain generalization by reducing domain-specific biases
- Mechanism: The model learns domain-invariant features by distilling knowledge from augmented samples that remove background regions and apply global probabilistic style perturbations
- Core assumption: Domain-specific characteristics like background and style are primary sources of domain shift that can be mitigated through augmentation and consistency regularization
- Evidence anchors: [abstract] classification of domain characteristics, [section] adverse role of background, [corpus] weak evidence from neighbors
- Break condition: If background regions contain class-relevant information or if style augmentation fails to capture true domain distributions

### Mechanism 2
- Claim: Boundary growth through edge maps improves open-set recognition by creating more discriminative class boundaries
- Mechanism: Edge maps serve as an additional modality that represents out-of-distribution samples within each class, training multi-binary classifiers with hard negatives
- Core assumption: Edge maps provide sufficient semantic information while being sufficiently different from original images to act as effective hard negative samples
- Evidence anchors: [abstract] boundary growth using edge maps, [section] edge maps as new modality, [corpus] weak evidence from neighbors
- Break condition: If edge maps lose too much semantic information or fail to provide meaningful distribution shifts for boundary learning

### Mechanism 3
- Claim: Knowledge distillation between content-perturbed and style-perturbed samples enforces feature consistency that improves generalization
- Mechanism: The model distills knowledge from background-suppressed augmented samples by computing KL divergence between features from samples with and without background suppression
- Core assumption: Consistency between representations of semantically identical but differently augmented samples leads to more robust and generalizable features
- Evidence anchors: [section] consistency regularization, [section] domain-invariant representation learning, [corpus] moderate evidence from neighbors
- Break condition: If the distillation process causes feature collapse or if background-suppressed samples become too dissimilar from original samples

## Foundational Learning

- Concept: Background suppression through segmentation
  - Why needed here: To eliminate domain-specific background information that creates spurious correlations between background context and class labels
  - Quick check question: How would the model perform if background regions contained class-relevant information like "grass" for "cow" classes?

- Concept: Global probabilistic style augmentation
  - Why needed here: To model the global distribution of style statistics rather than relying on batch-specific statistics, providing smoother and more diverse augmentations
  - Quick check question: What happens if the global probabilistic model fails to capture the true distribution of style statistics across the dataset?

- Concept: Multi-binary classifier training with edge maps
  - Why needed here: To create more discriminative boundaries between known classes by incorporating out-of-distribution samples (edge maps) as hard negatives
  - Quick check question: How would the model's performance change if edge maps retained too much appearance information, reducing their effectiveness as OOD samples?

## Architecture Onboarding

- Component map: Feature encoder (ResNet-18/50/101) → Multi-class classifier (linear layer) → |Cs| binary classifiers (one-vs-all) → Knowledge distillation loss + OVA loss + Cross-entropy loss
- Critical path: Feature extraction → Multi-class prediction for known classes → Binary classifier predictions for OSR → Loss computation and backpropagation
- Design tradeoffs: 
  - Background suppression: Free but coarse masks vs. learned but expensive masks
  - Global probabilistic style: Smooth augmentations vs. batch-based local statistics
  - Edge maps: Effective OOD samples vs. potential loss of semantic information
- Failure signatures: 
  - Poor h-score indicates failure to recognize unknown classes
  - Low known class accuracy indicates overfitting to source domain
  - High variance across domains indicates poor generalization
- First 3 experiments:
  1. Ablation study: Remove background suppression and measure impact on h-score and acck
  2. Hyperparameter sweep: Test different α values (0.5-0.9) for global probabilistic style update
  3. Edge map comparison: Replace edge maps with weak/strong augmentations and measure boundary growth effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of background suppression vary with the choice of segmentation method?
- Basis in paper: [explicit] The paper states that DEBUG is relatively robust to the choice of segmentation methods, as demonstrated in Table X.
- Why unresolved: While the paper mentions robustness, it does not provide a detailed analysis of how different segmentation methods impact the performance of background suppression.
- What evidence would resolve it: A comprehensive comparison of different segmentation methods (e.g., class-aware vs. class-agnostic) and their impact on the performance of DEBUG would provide insights into the optimal choice of segmentation method.

### Open Question 2
- Question: How does the use of edge maps as a modality for boundary growth compare to other potential modalities?
- Basis in paper: [explicit] The paper proposes using edge maps as an additional modality for training multi-binary classifiers, but does not compare this approach to other potential modalities.
- Why unresolved: The paper does not explore alternative modalities that could potentially enhance boundary growth and improve the model's performance.
- What evidence would resolve it: A comparison of edge maps with other modalities (e.g., texture maps, depth maps) in terms of their effectiveness in promoting boundary growth and improving open-set recognition would provide valuable insights.

### Open Question 3
- Question: How does the global probabilistic-based style augmentation (GPSA) perform compared to other style augmentation techniques?
- Basis in paper: [explicit] The paper introduces GPSA as a novel approach to style augmentation, but does not provide a direct comparison with other existing techniques.
- Why unresolved: While the paper demonstrates the effectiveness of GPSA, it does not explore how it compares to other style augmentation methods in terms of performance and robustness.
- What evidence would resolve it: A comprehensive evaluation of GPSA against other style augmentation techniques (e.g., AdaIN, DSU) on various datasets and tasks would provide insights into its relative performance and potential advantages.

## Limitations
- The approach relies heavily on the quality of foreground segmentation masks and edge detector outputs, which may vary across datasets
- Assumes background regions are class-irrelevant, which may not hold for all datasets (e.g., environmental context containing class-relevant information)
- Performance depends on hyperparameter choices (α for style augmentation, λ1 and λ2 for loss weights) that require careful tuning

## Confidence

- High confidence: The overall framework combining domain expansion and boundary growth is sound and well-motivated for OS-SDG
- Medium confidence: The effectiveness of background suppression and edge maps as OOD samples, as these depend on dataset-specific characteristics
- Medium confidence: The knowledge distillation consistency regularization, as the optimal temperature τ and update frequency are not thoroughly explored

## Next Checks

1. Conduct ablation studies removing background suppression on datasets where background context is class-relevant (e.g., animal-in-environment datasets)
2. Test the model's robustness to different edge detector qualities by comparing HED with other edge detectors or noised edge maps
3. Evaluate the sensitivity of the global probabilistic style augmentation to different update frequencies and momentum values (α ranging from 0.5 to 0.99)