---
ver: rpa2
title: Comparison-based Active Preference Learning for Multi-dimensional Personalization
arxiv_id: '2411.00524'
source_url: https://arxiv.org/abs/2411.00524
tags:
- user
- feedback
- hand
- assistant
- preferences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of personalizing language models
  to individual user preferences across multiple dimensions, where preferences are
  often implicit and hard to articulate. The proposed Active Multi-dimensional Preference
  Learning (AMPLe) framework estimates user preferences through comparative feedback
  using Bayesian inference, with a modified posterior update procedure that incorporates
  a noise-handling parameter to mitigate estimation bias.
---

# Comparison-based Active Preference Learning for Multi-dimensional Personalization

## Quick Facts
- arXiv ID: 2411.00524
- Source URL: https://arxiv.org/abs/2411.00524
- Authors: Minhyeon Oh; Seungjoon Lee; Jungseul Ok
- Reference count: 40
- Primary result: Achieves superior feedback efficiency and more accurate personalization compared to baseline approaches through active multi-dimensional preference learning with noise-handling capabilities

## Executive Summary
This paper addresses the challenge of personalizing language models to individual user preferences across multiple dimensions using comparison-based active learning. The proposed Active Multi-dimensional Preference Learning (AMPLe) framework estimates user preferences through comparative feedback using Bayesian inference with a modified posterior update procedure that incorporates a noise-handling parameter. An active query selection strategy inspired by generalized binary search minimizes the number of required user interactions. Theoretical analysis and experiments on language generation tasks demonstrate that the method achieves superior feedback efficiency and more accurate personalization compared to baseline approaches.

## Method Summary
The framework estimates user preferences through comparative feedback using Bayesian inference with a modified posterior update procedure. It introduces a parameter γ to control noise-handling intensity, preventing convergence to incorrect user profiles when feedback contains noise. An active query selection strategy uses an acquisition function based on generalized binary search to maximize information gain per interaction. The method represents user preferences as a weight vector w across multiple dimensions, captured through linear scalarization of attribute rewards. The framework iteratively samples from the posterior, selects queries that maximize information gain, updates the posterior based on user feedback, and estimates the user profile using maximum a posteriori estimation.

## Key Results
- Achieves lower estimation errors compared to baseline approaches across multiple language generation tasks
- Requires fewer user interactions to achieve accurate personalization due to active query selection
- Demonstrates robustness to noisy feedback through the modified posterior update procedure with γ parameter

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modified posterior update with γ > 0 prevents convergence to incorrect user profiles when β < ∞
- Mechanism: The standard maximum likelihood estimation (γ = 0, β < ∞) can get stuck in regions of the profile space that are farther from the true profile but still consistent with some feedback. By introducing γ > 0 and using β = ∞, the update rule ensures that all densities that don't match the feedback are uniformly reduced, preventing the posterior from concentrating on incorrect regions.
- Core assumption: The true user profile w* lies in the interior of a polytope formed by the hyperplanes defined by the queries in Q
- Evidence anchors: [abstract]: "we introduce a parameter to control the intensity of the diminish and boost operations, addressing potential noise in user feedback"; [section 4.1]: Theorem 4.1 shows that with γ = 0 and β < ∞, the estimation error may not converge to 0

### Mechanism 2
- Claim: Active query selection using acquisition function αt maximizes information gain per interaction
- Mechanism: The acquisition function αt(x) = min_y E_w~Pt-1[1 - ℓβ,w(y|x)] ensures that each query splits the posterior distribution as evenly as possible, discarding roughly half of the remaining densities with each interaction. This is equivalent to generalized binary search in the profile space.
- Core assumption: The posterior distribution can be effectively approximated using Metropolis-Hastings sampling
- Evidence anchors: [section 4.2]: "we employ an acquisition function inspired by generalized binary search (Nowak, 2009; Sadigh et al., 2017)"; [section 5.2]: Figure 2 shows posterior samples being split roughly in half with each query

### Mechanism 3
- Claim: Linear scalarization allows multi-dimensional preferences to be captured through weighted sum of attribute rewards
- Mechanism: By representing user preferences as a weight vector w ∈ Ω where Σwi = 1 and wi ≥ 0, the framework can capture complex trade-offs between different attributes (e.g., helpfulness vs. harmlessness) through a single scalar utility function ⟨w, r(s,a)⟩
- Core assumption: The true utility function for the user can be well-approximated by a linear combination of the reward components
- Evidence anchors: [section 3]: "we apply linear scalarization...where a user's preference is encoded by a d-dimensional vector w"; [section 5.1]: Experiments on Assistant task with three attributes: "harmlessness," "helpfulness," and "humor"

## Foundational Learning

- Concept: Bayesian inference and posterior updating
  - Why needed here: The framework uses Bayesian inference to maintain a probability distribution over possible user profiles and update it based on comparative feedback
  - Quick check question: If we observe feedback y = 1 for a query x, which profiles w get boosted in the posterior update and which get diminished?

- Concept: Maximum a posteriori (MAP) estimation
  - Why needed here: After updating the posterior distribution, the framework estimates the true user profile by finding the mode of the posterior distribution
  - Quick check question: How does the MAP estimator differ from the maximum likelihood estimator in this context?

- Concept: Generalized binary search and information theory
  - Why needed here: The active query selection strategy is based on the principle of generalized binary search, which aims to maximize information gain by splitting the search space as evenly as possible
  - Quick check question: Why does minimizing E_w~Pt-1[1 - ℓβ,w(y|x)] correspond to selecting the most informative query?

## Architecture Onboarding

- Component map:
  Query pool generation -> Posterior sampling module -> Acquisition function module -> Posterior update module -> MAP estimator module -> Response generation module

- Critical path:
  1. Sample posterior from current distribution
  2. Compute acquisition function for all queries in pool
  3. Select query with maximum acquisition value
  4. Get user feedback on selected query
  5. Update posterior using modified update rule
  6. Estimate profile using MAP estimator
  7. Generate personalized response

- Design tradeoffs:
  - Sampling vs. exact computation: Using Metropolis-Hastings sampling for the acquisition function is computationally cheaper but introduces approximation error
  - Query pool size vs. diversity: Larger pools provide more options for active selection but may contain redundant queries
  - γ value vs. noise tolerance: Higher γ values provide better noise tolerance but may slow convergence in low-noise settings

- Failure signatures:
  - Estimation error plateaus: May indicate poor posterior sampling or suboptimal query selection
  - Posterior collapse: May indicate γ is too high relative to noise level
  - Oscillating estimates: May indicate β is too low, causing over-sensitivity to individual feedback

- First 3 experiments:
  1. Test with β* = ∞ and varying γ values on static context to verify noise tolerance
  2. Compare vol-mo vs vol-un on dynamic contexts to validate active selection advantage
  3. Test scalability by increasing number of attributes from 3 to 4 on Summary+ task

## Open Questions the Paper Calls Out

- Question: What is the theoretical convergence rate of the proposed AMPLe framework?
- Basis in paper: [inferred] The paper states "We hypothesize that our method may achieve exponential convergence, which we plan to explore in future work."
- Why unresolved: The authors mention they plan to explore this in future work, indicating it has not been analyzed yet.
- What evidence would resolve it: A rigorous mathematical proof or extensive empirical study demonstrating the convergence rate of the algorithm.

- Question: How does the AMPLe framework handle dynamic user preferences that change over time or across different contexts?
- Basis in paper: [inferred] The paper states "One limitation is that we assume a static user preference profile across all tasks and contexts."
- Why unresolved: The authors acknowledge this as a limitation and suggest future work could address context-dependent preferences.
- What evidence would resolve it: Experimental results or theoretical analysis showing the performance of AMPLe when user preferences change over time or across contexts.

- Question: How sensitive is the AMPLe framework to the choice of the reward function and the number of dimensions?
- Basis in paper: [explicit] The authors conduct ablation studies on the effect of dimensionality and hyperparameter choices, showing that increasing dimensions leads to larger estimation errors.
- Why unresolved: While the authors show some sensitivity to dimensionality, the impact of different reward function choices and their relationship to performance is not fully explored.
- What evidence would resolve it: Systematic experiments varying the reward function structure and comparing performance across different reward functions and dimensionalities.

## Limitations

- The framework assumes static user preferences across all tasks and contexts, not handling dynamic preferences that change over time
- Theoretical guarantees rely on the assumption that the true user profile lies in the interior of a polytope formed by query hyperplanes, which may not hold in practice
- The linear scalarization assumption may fail for users with non-linear preference structures, limiting the framework's ability to capture complex preference patterns

## Confidence

- **High**: The noise-handling mechanism with γ > 0 effectively prevents posterior collapse to incorrect regions (supported by Theorem 4.1 and experimental evidence)
- **Medium**: The active query selection strategy achieves information-theoretic optimality in practice (supported by theoretical motivation but limited empirical validation)
- **Medium**: The linear scalarization adequately captures multi-dimensional user preferences (supported by related work but not extensively validated for non-linear preferences)

## Next Checks

1. Test the algorithm with true user profiles near the boundary of the polytope to evaluate breakdown conditions and robustness
2. Conduct ablation studies varying γ across different noise levels to establish optimal parameter ranges
3. Validate performance on non-linear preference structures by introducing controlled deviations from linear scalarization assumptions