---
ver: rpa2
title: Riemannian Federated Learning via Averaging Gradient Streams
arxiv_id: '2409.07223'
source_url: https://arxiv.org/abs/2409.07223
tags:
- gradf
- which
- step
- riemannian
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops a Riemannian federated learning algorithm called
  RFedAGS that generalizes the Euclidean federated averaging (FedAvg) to Riemannian
  manifolds. The key innovation is a new server aggregation method called "averaging
  gradient streams," which efficiently combines local updates from multiple agents
  while preserving geometric structure.
---

# Riemannian Federated Learning via Averaging Gradient Streams

## Quick Facts
- arXiv ID: 2409.07223
- Source URL: https://arxiv.org/abs/2409.07223
- Reference count: 12
- Primary result: RFedAGS achieves sublinear convergence rates for non-convex problems with fixed step sizes, and supports multiple local updates across agents

## Executive Summary
This paper develops RFedAGS, a Riemannian federated learning algorithm that generalizes Euclidean federated averaging to Riemannian manifolds. The key innovation is "averaging gradient streams" - a server aggregation method that uses vector transport to combine mini-batch gradients across agents in their respective tangent spaces, avoiding the computational bottleneck of tangent mean computations. The algorithm provides comprehensive convergence analysis showing sublinear rates for non-convex problems and linear convergence for problems satisfying the Riemannian Polyak-Łojasiewicz condition.

## Method Summary
RFedAGS operates on Riemannian manifolds where data resides, using retraction and vector transport operations to maintain geometric structure. Each agent performs K local SGD steps, accumulating transported gradient streams in the tangent space at the global parameter. The server averages these transported gradients and performs retraction to update the global parameter. This approach supports multiple local updates (K>1) and achieves communication efficiency while maintaining convergence guarantees comparable to centralized Riemannian optimization methods.

## Key Results
- RFedAGS achieves sublinear convergence rates for non-convex problems with fixed step sizes, and global convergence with decaying step sizes
- For problems satisfying the Riemannian Polyak-Łojasiewicz condition, the algorithm converges linearly to a neighborhood of the optimum with fixed step sizes, or sublinearly to the optimum with decaying step sizes
- The algorithm supports multiple local updates (K>1) across agents, addressing a key limitation of prior Riemannian FL methods
- Extensive experiments demonstrate RFedAGS performs comparably to centralized methods while offering communication efficiency benefits

## Why This Works (Mechanism)

### Mechanism 1
Gradient stream averaging avoids tangent mean computations by transporting gradients to a common tangent space before averaging. Each agent uploads K-step gradient vectors in the tangent space at the global parameter, and the server averages these transported gradients before retracting back to the manifold. This works under the assumption that isometric vector transport preserves gradient relationships across tangent spaces.

### Mechanism 2
Multiple local updates (K>1) are enabled by averaging gradient streams instead of final parameters, sidestepping the non-linearity of composing multiple exponential maps. The sum of transported gradients approximates the effect of sequential local updates, assuming local update sequences don't diverge significantly from the global parameter.

### Mechanism 3
Convergence guarantees are maintained through bounded drift between local and global parameters. Lemma 4.4 provides explicit bounds on the distance between local updates and the global parameter, ensuring local updates don't drift too far. This relies on step sizes being bounded and gradients remaining controlled in a compact set.

## Foundational Learning

- **Concept: Riemannian manifolds and tangent spaces**
  - Why needed here: The algorithm operates on manifolds where parameters lie, requiring geometric operations like retraction and vector transport
  - Quick check question: What is the difference between the exponential map and a general retraction on a manifold?

- **Concept: Vector transport and isometric properties**
  - Why needed here: Gradient averaging requires transporting gradients from different tangent spaces to a common one without distorting their relationships
  - Quick check question: Why must the vector transport be isometric for the gradient averaging to work correctly?

- **Concept: Local SGD with multiple local steps**
  - Why needed here: Understanding how K local updates per agent interact with global parameter updates is crucial for analyzing convergence
  - Quick check question: How does the number of local steps K affect the communication-computation tradeoff in federated learning?

## Architecture Onboarding

- **Component map**: Server -> Agents -> Communication -> Server (broadcast, receive gradient streams, aggregate, retract)
- **Critical path**: 
  1. Server broadcasts global parameter to all agents
  2. Each agent performs K local SGD steps, accumulating transported gradients
  3. Agents upload gradient stream vectors to server
  4. Server averages gradient streams and performs retraction to get next global parameter
  5. Repeat for T outer iterations
- **Design tradeoffs**: 
  - Larger K reduces communication but may increase drift and slow convergence
  - Smaller batch sizes increase gradient variance but reduce per-iteration computation
  - Fixed step sizes enable linear convergence but may not find highly accurate solutions
  - Decaying step sizes improve final accuracy but slow initial convergence
- **Failure signatures**: 
  - Divergence: Check if step sizes exceed theoretical bounds
  - Slow convergence: Verify gradient variance is not too large relative to step size
  - Poor performance with K>1: Ensure gradient stream averaging adequately captures local update effects
- **First 3 experiments**:
  1. Compare RFedAGS with K=1 vs K=5 on sphere manifold principal eigenvector problem, measuring convergence speed and final accuracy
  2. Test RFedAGS with fixed vs decaying step sizes on SPD manifold Fréchet mean problem, measuring communication efficiency
  3. Evaluate RFedAGS vs RFedAvg on Grassmann manifold multitask feature learning, measuring NMSE and iteration count

## Open Questions the Paper Calls Out
- How does RFedAGS perform in the presence of partial agent participation and non-i.i.d. data distributions?
- What is the optimal number of local updates (K) for RFedAGS across different problem classes and data distributions?
- How does the choice of retraction and vector transport affect the convergence and computational efficiency of RFedAGS?

## Limitations
- The analysis assumes isometric vector transport, but practical implementations may use non-isometric transports for computational efficiency
- Convergence bounds rely on gradients being Lipschitz continuous over a compact set, which may not hold for problems with unbounded domains
- The theoretical analysis assumes full gradient computation for centralized methods, creating a comparison gap with practical mini-batch implementations

## Confidence

- **High confidence**: Sublinear convergence rate for non-convex problems with fixed step sizes (Theorem 4.5)
- **Medium confidence**: Linear convergence for RPL problems with fixed step sizes (Theorem 4.6)
- **Medium confidence**: K>1 local update support

## Next Checks
1. Reproduce RFedAGS algorithm on sphere manifold principal eigenvector problem with K=1 and K=5, comparing convergence curves against theoretical bounds
2. Implement both isometric and non-isometric vector transports on SPD manifolds, measuring impact on gradient averaging accuracy and convergence rates
3. For Stiefel manifold Brockett cost function, track distance between local and global parameters across iterations to validate drift bounds from Lemma 4.4