---
ver: rpa2
title: 'Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted
  Captions'
arxiv_id: '2411.09018'
source_url: https://arxiv.org/abs/2411.09018
tags:
- question
- captions
- image
- arxiv
- knowada
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of fine-tuning small-scale vision-language
  models on dense, detailed image captions, which often leads to hallucinations. The
  authors introduce Knowledge Adapted (KnowAda), a data-centric approach that adapts
  training captions by probing a model's existing visual knowledge and removing unknown
  information.
---

# Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted Captions

## Quick Facts
- **arXiv ID**: 2411.09018
- **Source URL**: https://arxiv.org/abs/2411.09018
- **Reference count**: 40
- **Primary result**: Introduces KnowAda, a data-centric approach that adapts training captions by probing a model's existing visual knowledge and removing unknown information, reducing hallucinations while preserving descriptiveness during fine-tuning of small-scale VLMs.

## Executive Summary
This paper addresses the challenge of fine-tuning small-scale vision-language models on dense, detailed image captions, which often leads to hallucinations. The authors introduce Knowledge Adapted (KnowAda), a data-centric approach that adapts training captions by probing a model's existing visual knowledge and removing unknown information. KnowAda balances hallucination reduction and descriptiveness, outperforming various baselines in both automatic metrics and human evaluations across multiple models (up to 7B parameters) and dense caption datasets. The proposed Decomposed NLI (DNLI) framework provides fine-grained evaluation of caption quality by breaking captions into individual propositions.

## Method Summary
The KnowAda pipeline generates visual questions from dense captions, probes the VLM's knowledge to identify unknown questions, and rewrites captions to remove information related to unknown details. This adapted data is then used to fine-tune VLMs, with the goal of reducing hallucinations while maintaining descriptiveness. The method is evaluated using the Decomposed NLI framework, which breaks captions into atomic propositions and assesses each for entailment, contradiction, or neutrality against ground truth, allowing separate tracking of descriptiveness and hallucination.

## Key Results
- KnowAda consistently reduces hallucinations while preserving descriptiveness across multiple VLMs (up to 7B parameters) and dense caption datasets
- Outperforms baselines including caption trimming and Gemini simplification in both automatic NLI metrics and human evaluations
- DNLI framework provides reliable, fine-grained evaluation showing strong alignment with human judgments

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: KnowAda improves caption quality by filtering out unknown information specific to each model's knowledge.
- **Mechanism**: The method probes a VLM's knowledge by generating questions from image captions, classifying them as known or unknown based on the model's ability to answer. Unknown information is removed, adapting the captions to match the model's visual understanding.
- **Core assumption**: Small-to-medium VLMs hallucinate more when fine-tuned on captions containing details beyond their pretraining knowledge.
- **Evidence anchors**:
  - [abstract]: "KnowAda minimizes hallucinations while preserving high descriptiveness."
  - [section 2.1]: Describes the knowledge probing step and rewriting process based on unknown questions.
- **Break condition**: If the VLM's pretraining knowledge is already broad enough to cover most dense caption details, removing unknown information may degrade descriptiveness unnecessarily.

### Mechanism 2
- **Claim**: The Decomposed NLI (DNLI) framework provides fine-grained evaluation of caption quality by breaking captions into propositions and assessing entailment.
- **Mechanism**: Captions are decomposed into atomic propositions. Each proposition is evaluated for entailment, contradiction, or neutrality against the ground truth. This allows separate tracking of descriptiveness (entailed propositions) and hallucination (contradicted propositions).
- **Core assumption**: Traditional metrics conflate factual accuracy with token overlap, making them inadequate for evaluating long captions.
- **Evidence anchors**:
  - [abstract]: "DNLI offers a more reliable measure of both descriptiveness and accuracy, demonstrating strong alignment with human judgments."
  - [section 3]: Details the DNLI evaluation process and metrics.
- **Break condition**: If the NLI model itself hallucinates or misclassifies propositions, DNLI results may be unreliable.

### Mechanism 3
- **Claim**: Fine-tuning primarily activates and refines pretrained knowledge rather than acquiring new information.
- **Mechanism**: Based on prior work, fine-tuning does not teach models new facts but helps them use existing knowledge more effectively. KnowAda aligns training data with this existing knowledge to avoid introducing contradictions.
- **Core assumption**: Attempting to fine-tune on content outside a model's pretrained knowledge increases hallucination rates.
- **Evidence anchors**:
  - [abstract]: References prior findings that "fine-tuning primarily adapts pre-existing factual knowledge" and that "fine-tuning on content not grounded in a model's pre-existing factual knowledge can lead to an increase in hallucinations."
  - [section 1]: Motivates KnowAda based on these prior findings.
- **Break condition**: If fine-tuning can actually acquire new knowledge beyond pretraining (contrary to the cited literature), KnowAda's knowledge-matching approach might be unnecessarily restrictive.

## Foundational Learning

- **Concept**: Visual knowledge probing via question generation and evaluation
  - Why needed here: To identify which parts of a dense caption are outside the VLM's knowledge and should be removed.
  - Quick check question: How does KnowAda determine if a visual detail in a caption is "unknown" to the model?

- **Concept**: Proposition decomposition for evaluation
  - Why needed here: To separately measure descriptiveness (how much correct detail is captured) and hallucination (how much incorrect information is generated).
  - Quick check question: What are the three possible judgments for each proposition in DNLI?

- **Concept**: Data-centric fine-tuning adaptation
  - Why needed here: Instead of modifying the model architecture or training procedure, KnowAda modifies the training data to match the model's capabilities.
  - Quick check question: What is the key difference between KnowAda and standard data curation approaches?

## Architecture Onboarding

- **Component map**: Dense Caption → Question Generation LLM → VLM Knowledge Probe → Question Classifier → Caption Rewriting LLM → Adapted Caption
- **Critical path**: Caption → Question Generation → Knowledge Probe → Unknown Classification → Caption Rewriting → Training Data
- **Design tradeoffs**: KnowAda trades caption completeness for reduced hallucination. Lower thresholds remove more information, reducing hallucinations but also reducing descriptiveness.
- **Failure signatures**: If KnowAda captions become too sparse, descriptiveness recall will drop. If the NLI evaluator misclassifies propositions, DNLI metrics will be unreliable.
- **First 3 experiments**:
  1. Run KnowAda pipeline on a small set of captions and verify the number of unknown questions detected varies by model
  2. Compare DNLI evaluation results between original and KnowAda-adapted captions
  3. Fine-tune a small VLM on both original and KnowAda captions, measure hallucination reduction

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the content, several open questions can be inferred:

- How does KnowAda's performance scale with larger vision-language models beyond 7B parameters, and does the effectiveness of knowledge adaptation change as model capacity increases?
- What is the long-term impact of KnowAda fine-tuning on model generalization to unseen data, and does it create any biases toward the adapted caption style?
- Can KnowAda's knowledge probing mechanism be extended to multi-modal knowledge gaps beyond visual understanding, such as reasoning or commonsense knowledge?

## Limitations
- Only evaluated on models up to 7B parameters, leaving scalability to larger models unknown
- Model-dependent approach requires separate adaptation for each model, limiting generalization
- Reliance on question generation and classification introduces potential sources of error

## Confidence
- **Core claim confidence**: Medium
- **DNLI framework reliability**: Medium
- **Knowledge probing accuracy**: Medium
- **Generalizability beyond tested models**: Low

## Next Checks
1. Conduct ablation studies varying the knowledge probing threshold to quantify its impact on the hallucination-descriptiveness trade-off across different VLM sizes.
2. Evaluate the DNLI framework's reliability by testing its consistency across multiple NLI models and comparing results with alternative proposition-level evaluation approaches.
3. Test KnowAda's generalization to other dense caption datasets and VLM architectures beyond those studied to assess its broader applicability.