---
ver: rpa2
title: Evaluating Vision-Language Models as Evaluators in Path Planning
arxiv_id: '2411.18711'
source_url: https://arxiv.org/abs/2411.18711
tags:
- path
- clearance
- turns
- vlms
- sharp
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces PathEval, a benchmark for evaluating vision-language
  models (VLMs) as path evaluators in complex planning scenarios. The benchmark tests
  VLMs on three levels: abstracting relevant path attributes from natural language
  descriptions, precisely perceiving low-level path details from images, and integrating
  visual and textual information to select the better path.'
---

# Evaluating Vision-Language Models as Evaluators in Path Planning

## Quick Facts
- **arXiv ID**: 2411.18711
- **Source URL**: https://arxiv.org/abs/2411.18711
- **Reference count**: 40
- **Primary result**: VLMs show significant vision bottlenecks in path evaluation, particularly for clearance metrics, despite reasonable performance in attribute abstraction

## Executive Summary
This work introduces PathEval, a benchmark for evaluating vision-language models (VLMs) as path evaluators in complex planning scenarios. The benchmark tests VLMs on three levels: abstracting relevant path attributes from natural language descriptions, precisely perceiving low-level path details from images, and integrating visual and textual information to select the better path. Analysis of nine state-of-the-art VLMs reveals significant challenges in low-level visual perception, particularly for clearance metrics. While VLMs perform reasonably well at attribute abstraction and exhibit mixed results in information integration, their vision components struggle to distinguish path differences in intricate environments. Providing explicit path descriptors substantially improves performance, confirming vision as the bottleneck.

## Method Summary
The study evaluates nine state-of-the-art VLMs using the PathEval benchmark, which consists of 14,550 path pairs rendered in 2D and 3D environments mapped to 15 decision-making scenarios. Each path has descriptors including minimum clearance, maximum clearance, average clearance, path length, smoothness, number of sharp turns, and maximum angle. VLMs are tested zero-shot on their ability to select the better path based on scenario requirements. The study also investigates the impact of providing explicit path descriptors and experiments with fine-tuning LLaVA-NeXT-7b for discriminative adaptation of vision encoders.

## Key Results
- VLMs exhibit significant vision bottlenecks, particularly struggling with clearance metrics despite reasonable attribute abstraction capability
- Providing explicit path descriptors improves VLM performance substantially (e.g., from 51.4% to 74.2% accuracy for Qwen2-VL-7b)
- Fine-tuning VLMs end-to-end does not resolve vision limitations; task-specific discriminative adaptation of vision encoders is needed
- GPT-4o shows mixed performance, leveraging commonsense knowledge effectively in some scenarios but failing in others requiring non-intuitive path preferences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VLMs can abstract relevant path attributes from natural language descriptions but fail at low-level visual perception
- Mechanism: VLMs successfully parse textual scenarios to identify relevant path metrics (attribute abstraction) but their vision encoders cannot extract those metrics from images
- Core assumption: The language component can correctly identify which path metrics matter, but the vision component cannot extract those metrics from images
- Evidence anchors:
  - [abstract] "VLMs can precisely abstract given scenarios to identify the desired traits and exhibit mixed performance in integrating the provided information. Yet, their vision component presents a critical bottleneck"
  - [section 4.1] "VLMs can precisely abstract given scenarios to identify the desired traits" and "their vision component presents a critical bottleneck"
  - [corpus] Weak evidence - only general VLM planning papers found, no specific evidence about attribute abstraction capability

### Mechanism 2
- Claim: Providing explicit path descriptors significantly improves VLM performance by bypassing the vision bottleneck
- Mechanism: When numerical descriptor values are provided as text, VLMs can directly compare these values without needing to extract them from images, revealing that the bottleneck is visual perception rather than reasoning
- Core assumption: VLMs have sufficient reasoning capability to compare numerical values once extracted, but cannot extract those values from images
- Evidence anchors:
  - [abstract] "Providing explicit path descriptors substantially improves performance, confirming vision as the bottleneck"
  - [section 4.1] "when providing these VLMs with verbalized path specifications, their performance significantly improves (e.g., 74.2% accuracy for Qwen2-VL-7b), which reveals a potential vision bottleneck"
  - [corpus] Weak evidence - general VLM evaluation papers found but no specific evidence about descriptor-based evaluation

### Mechanism 3
- Claim: Fine-tuning vision encoders for discriminative adaptation rather than end-to-end VLM fine-tuning improves path evaluation performance
- Mechanism: The vision encoders need task-specific discriminative training to learn to distinguish between path images, rather than general VLM fine-tuning which doesn't address the fundamental visual representation problem
- Core assumption: The vision encoders' representations are too similar for different paths, requiring specialized training to disentangle them
- Evidence anchors:
  - [abstract] "Our experimental results show that this issue cannot be trivially addressed via end-to-end fine-tuning; rather, task-specific discriminative adaptation of these vision encoders is needed"
  - [section 5.2] "Fine-tuning the encoders on a discrimination task can help disentangle the visual representations" and "this approach effectively disentangles the learned representations, resulting in significantly improved performance"
  - [corpus] Weak evidence - general vision encoder papers found but no specific evidence about discriminative adaptation for path evaluation

## Foundational Learning

- Concept: Spatial reasoning in complex environments
  - Why needed here: Path planning requires understanding spatial relationships between paths and obstacles, which is fundamental to evaluating which path better satisfies given constraints
  - Quick check question: Can you explain the difference between clearance metrics and path smoothness, and why both might be important for different planning scenarios?

- Concept: Vision-language model architecture
  - Why needed here: Understanding how VLMs combine visual and textual information is crucial for diagnosing where they fail (vision bottleneck vs. reasoning)
  - Quick check question: What are the key architectural components of a VLM and how do they typically process visual and textual information?

- Concept: Path planning algorithms and metrics
  - Why needed here: To understand what makes a path "good" in different scenarios and how VLMs should evaluate paths based on various metrics
  - Quick check question: What is the RRT algorithm and how does it generate path candidates that VLMs need to evaluate?

## Architecture Onboarding

- Component map: Image → Vision encoder → Visual features → Fusion with text → Reasoning → Path comparison → Output decision
- Critical path: Image → Vision encoder → Visual features → Fusion with text → Reasoning → Path comparison → Output decision
- Design tradeoffs:
  - Encoder size vs. computational efficiency
  - Fusion strategy (early vs. late fusion)
  - Task-specific vs. general-purpose vision encoders
  - Explanation generation vs. accuracy trade-off
- Failure signatures:
  - Random or near-random accuracy suggests vision bottleneck
  - Consistent bias toward certain path labels indicates reasoning issues
  - Improved performance with textual descriptors confirms vision limitations
  - Hallucinations in explanations when visual perception fails
- First 3 experiments:
  1. Test VLMs with only textual descriptors (no images) to confirm reasoning capability
  2. Test VLMs with only images (no descriptors) to measure pure visual perception
  3. Test VLMs with both images and descriptors to evaluate information integration capability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can vision encoders be effectively fine-tuned for task-specific discriminative adaptation in path evaluation?
- Basis in paper: [explicit] The paper demonstrates that simply fine-tuning VLMs end-to-end does not address the vision bottleneck issue, and suggests that task-specific discriminative adaptation of vision encoders is needed.
- Why unresolved: The paper only shows that fine-tuning vision encoders for discrimination improves path differentiation, but does not explore the optimal fine-tuning strategies or architectures for this specific task.
- What evidence would resolve it: Systematic comparison of different fine-tuning approaches (e.g., contrastive learning, supervised fine-tuning, adapter methods) on vision encoder performance in path evaluation tasks.

### Open Question 2
- Question: What are the fundamental limitations of current VLMs in low-level visual perception for complex environments?
- Basis in paper: [explicit] The paper identifies that VLMs struggle particularly with clearance metrics and that vision encoders cannot distinguish between paths in intricate scenarios.
- Why unresolved: While the paper identifies the problem, it doesn't deeply investigate whether this is due to architectural limitations, training data bias, or fundamental constraints in how VLMs process visual information.
- What evidence would resolve it: Controlled experiments comparing VLMs with specialized computer vision models on identical path perception tasks, and ablation studies on different visual encoding strategies.

### Open Question 3
- Question: How does path complexity and environmental structure affect VLM performance in path evaluation?
- Basis in paper: [explicit] The paper shows that GPT-4o's performance degrades as path segment complexity increases from points to straight lines to curves, and that environmental complexity adds challenges.
- Why unresolved: The paper only provides preliminary analysis on simplified environments, but doesn't systematically study how different environmental structures or path complexities impact VLM performance.
- What evidence would resolve it: Comprehensive benchmark testing VLMs across environments with varying obstacle arrangements, path densities, and visual complexity levels, with detailed performance breakdowns.

### Open Question 4
- Question: Can VLMs effectively integrate commonsense knowledge with visual perception for path evaluation in counterfactual scenarios?
- Basis in paper: [explicit] The paper observes that GPT-4o overuses common sense knowledge, failing on scenarios requiring non-intuitive path preferences (like maximizing path length).
- Why unresolved: The paper only identifies this limitation in a few scenarios but doesn't explore the extent of this bias or potential methods to mitigate it.
- What evidence would resolve it: Extensive testing of VLMs on diverse counterfactual path planning scenarios and evaluation of techniques to balance commonsense priors with task-specific requirements.

## Limitations

- The proposed solution of discriminative fine-tuning for vision encoders lacks extensive validation and only shows partial improvement
- The analysis of failure modes is limited to accuracy metrics without deeper investigation into specific visual features that VLMs struggle to perceive
- The study focuses on simplified 2D and 3D environments, limiting generalizability to real-world path planning scenarios

## Confidence

- **High confidence**: The vision bottleneck finding (VLMs perform significantly worse without textual descriptors)
- **Medium confidence**: The mixed performance in information integration capability
- **Low confidence**: The effectiveness of discriminative fine-tuning as a complete solution

## Next Checks

1. Conduct ablation studies to isolate which visual features (clearance vs. smoothness vs. turns) are most problematic for VLMs, using controlled path variations
2. Test whether larger vision encoders or specialized training data for path perception can overcome the identified bottleneck more effectively than discriminative fine-tuning
3. Evaluate cross-domain generalization by testing VLMs on path planning scenarios from different environments (urban vs. natural vs. indoor) to assess robustness of the vision bottleneck finding