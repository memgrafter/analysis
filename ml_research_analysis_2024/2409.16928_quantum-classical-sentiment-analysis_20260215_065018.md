---
ver: rpa2
title: Quantum-Classical Sentiment Analysis
arxiv_id: '2409.16928'
source_url: https://arxiv.org/abs/2409.16928
tags:
- time
- d-wave
- qubo
- quantum
- problems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores using hybrid classical-quantum classifiers
  for sentiment analysis, comparing them against classical CPLEX and Transformer models.
  The hybrid classifier achieved 76.1% F1 score versus 94.3% for Transformers and
  76.9% for CPLEX, while requiring significantly less training time (39.2s vs 101.9s
  for CPLEX).
---

# Quantum-Classical Sentiment Analysis

## Quick Facts
- arXiv ID: 2409.16928
- Source URL: https://arxiv.org/abs/2409.16928
- Reference count: 19
- Primary result: Hybrid classifier achieves 76.1% F1 score vs 94.3% for Transformers, but trains 2.6x faster (39.2s vs 101.9s)

## Executive Summary
This paper explores hybrid classical-quantum classifiers for sentiment analysis, demonstrating that quantum computing can accelerate optimization problems despite lower classification accuracy compared to classical Transformer models. The hybrid classifier achieved 76.1% F1 score versus 94.3% for Transformers and 76.9% for CPLEX, while requiring significantly less training time (39.2s vs 101.9s for CPLEX). A key limitation was identified in the hybrid solver's limited QPU usage, averaging only 0.08%. To address this, the authors developed QSplit, an algebraic decomposition algorithm that breaks QUBO problems into smaller chunks solvable on the QPU, though this approach sacrifices 35-50% solution quality for speed gains.

## Method Summary
The study converts sentiment analysis into QUBO formulation using SentenceBERT embeddings and SVM-derived matrices, then solves these problems using a hybrid classical-quantum approach. The method involves preprocessing with SentenceBERT to generate embeddings, converting classification problems to QUBO form, solving using D-Wave's hybrid solver and custom QSplit algorithm, and comparing results against CPLEX classical solvers and Transformer neural networks. The QSplit algorithm recursively decomposes large QUBO matrices into smaller subproblems that fit on the quantum processor, trading solution quality for reduced computation time.

## Key Results
- Hybrid classifier achieved 76.1% F1 score versus 94.3% for Transformers and 76.9% for CPLEX
- Quantum solver required 39.2 seconds vs 101.9 seconds for CPLEX (60% time reduction)
- QPU usage averaged only 0.08% in initial hybrid solver, addressed by QSplit algorithm
- QSplit reduced total computation time from 205.5s to 92.1s but solution quality deteriorated by 35-50%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: QSplit improves QPU utilization by decomposing large QUBO problems into smaller, solvable subproblems
- Mechanism: The QSplit algorithm recursively divides the QUBO matrix into four quadrants where each small QUBO matrix is solved directly on the QPU, and solutions are aggregated
- Core assumption: Smaller QUBO matrices can be efficiently solved on the QPU without significant loss of solution quality
- Evidence anchors:
  - "To overcome the limited use of the quantum process unit (QPU) by the D-Wave hybrid solver, we also started to investigate algebraic-based alternatives to the proprietary mechanisms that split QUBO problems between QPU and CPU."
  - "We investigate how to design a hybrid solver, called QSplit, to increase the use of the QPU, based on a quite simple algebraic technique that decomposes QUBO problems into smaller chunks."

### Mechanism 2
- Claim: The hybrid classifier achieves faster convergence times by leveraging quantum annealing for optimization
- Mechanism: The HCQC converts sentiment analysis problems into QUBO form where quantum annealing explores the solution space more efficiently than classical heuristics for certain problem structures
- Core assumption: Quantum annealing provides computational advantage for optimization problems derived from sentiment analysis
- Evidence anchors:
  - "Our findings indicate that while the HCQC underperforms relative to the Transformer in terms of classification accuracy, but it requires significantly less time to converge to a reasonably good approximate solution."
  - "The time required by D-Wave to find an optimal assignment is 60% less than that of the classical counterpart, with 39.2 seconds against 101.9."

### Mechanism 3
- Claim: Minor embedding search time increases exponentially with problem size, limiting direct QPU usage
- Mechanism: The minor embedding problem, which maps logical QUBO problem graph onto physical QPU hardware graph, is NP-complete and scales exponentially
- Core assumption: Computational complexity of finding minor embeddings scales exponentially with problem size
- Evidence anchors:
  - "The only operation with high computational cost among those described is the search for the minor embedding, which is NP-complete."
  - "For 128 variables, the calculation takes more than 7 minutes and occupies about 38% of the 5600 qubits available on the QPU."

## Foundational Learning

- Concept: Quadratic Unconstrained Binary Optimization (QUBO) formulation
  - Why needed here: The entire quantum-classical approach relies on converting sentiment analysis into QUBO form, which is the native input format for quantum annealers
  - Quick check question: What are the three main steps required to convert a general optimization problem into QUBO form as mentioned in the paper?

- Concept: Minor embedding in quantum annealing
  - Why needed here: Minor embedding maps logical problem graph onto physical hardware graph of the quantum processor and becomes computationally expensive
  - Quick check question: Why is the minor embedding problem described as NP-complete, and what implications does this have for solving large problems on quantum processors?

- Concept: Hybrid quantum-classical computing architecture
  - Why needed here: The paper presents a hybrid approach combining quantum and classical computing resources
  - Quick check question: In the context of this paper, what are the typical roles assigned to quantum versus classical components in the hybrid solver architecture?

## Architecture Onboarding

- Component map: SentenceBERT -> QUBO formulation -> QSplit decomposition -> Minor embedding -> QPU solving -> Solution aggregation -> Classification output

- Critical path: 1. Convert sentiment analysis to QUBO formulation 2. Apply QSplit decomposition algorithm 3. For each subproblem: perform minor embedding and solve on QPU 4. Aggregate solutions from QPU 5. Resolve conflicts and produce final classification

- Design tradeoffs:
  - QPU utilization vs. solution quality: Higher QPU usage leads to faster computation but worse solutions
  - Decomposition granularity: Smaller subproblems are easier to solve on QPU but increase CPU overhead
  - Hardware constraints: Physical topology of QPU limits size and structure of problems that can be solved directly

- Failure signatures:
  - Low QPU utilization (0.08% observed) indicates inefficient problem decomposition
  - Solution quality degradation of 35-50% suggests suboptimal decomposition strategy
  - Exponential increase in minor embedding time indicates approaching hardware scalability limits

- First 3 experiments:
  1. Reproduce baseline comparison between HCQC, CPLEX, and Transformer classifiers on TweetEval dataset
  2. Implement QSplit algorithm on small QUBO problems (4-8 variables) to verify correct decomposition
  3. Benchmark QSplit with increasing cut dimensions (2, 4, 8, 16, 32) on 128-variable problems

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we improve QSplit's solution quality while maintaining reduced computational time?
- Basis in paper: The paper states QSplit solutions deteriorate by 35-50% compared to direct QPU solving, suggesting "more refined problem partitioning strategies" or "work pipelines capable of using a set of methods for finding the optimal assignment"
- Why unresolved: The paper only suggests potential improvements without testing them
- What evidence would resolve it: Comparative experiments testing different partitioning strategies and hybrid solver combinations with their respective solution quality and computation time metrics

### Open Question 2
- Question: What is the optimal cut dimension for QSplit that balances solution quality and computational efficiency?
- Basis in paper: The paper shows solution quality deteriorates as cut dimension decreases, but doesn't identify an optimal point
- Why unresolved: The paper only tested a limited range of cut dimensions (2-32) without determining the optimal balance point
- What evidence would resolve it: Systematic testing across a broader range of cut dimensions with corresponding solution quality and computation time measurements

### Open Question 3
- Question: Can the QPU usage bottleneck in D-Wave's hybrid solver be overcome through alternative problem formulation approaches?
- Basis in paper: The paper identifies that the hybrid solver only uses 0.08% QPU time and suggests manual QUBO conversion and minor embedding could increase usage
- Why unresolved: The paper only tested manual approaches but didn't explore alternative problem formulations
- What evidence would resolve it: Testing different problem formulation techniques (e.g., variable encoding schemes, constraint relaxation methods) and measuring resulting QPU utilization rates

## Limitations
- QPU utilization remained extremely low at 0.08% in the initial hybrid solver
- Solution quality deteriorated by 35-50% when using QSplit decomposition
- Exponential scaling of minor embedding search time creates fundamental bottleneck for larger problems

## Confidence

- High confidence: Baseline performance comparisons (F1 scores and training times between HCQC, CPLEX, and Transformer models)
- Medium confidence: QSplit algorithm effectiveness and decomposition strategy
- Low confidence: Generalizability of findings to other sentiment analysis datasets and problem domains

## Next Checks

1. Implement QSplit decomposition on progressively larger QUBO problems (32, 64, 128 variables) to characterize the relationship between cut dimension, QPU utilization, and solution quality degradation

2. Compare solution quality of QSplit against alternative decomposition strategies (e.g., spectral partitioning, graph-based clustering) to validate the chosen approach

3. Benchmark the hybrid classifier on additional sentiment analysis datasets beyond TweetEval to assess robustness and generalizability of the findings