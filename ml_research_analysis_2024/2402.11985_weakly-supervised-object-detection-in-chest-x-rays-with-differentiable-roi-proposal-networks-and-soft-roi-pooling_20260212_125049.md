---
ver: rpa2
title: Weakly Supervised Object Detection in Chest X-Rays with Differentiable ROI
  Proposal Networks and Soft ROI Pooling
arxiv_id: '2402.11985'
source_url: https://arxiv.org/abs/2402.11985
tags:
- class
- patch
- detection
- supervised
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of weakly supervised object detection
  (WSup-OD) in medical images, specifically chest X-rays. The core method idea is
  to propose Weakly Supervised ROI Proposal Networks (WSRPN), a novel paradigm for
  WSup-OD that uses learned bounding box proposals on the fly through an attention
  mechanism.
---

# Weakly Supervised Object Detection in Chest X-Rays with Differentiable ROI Proposal Networks and Soft ROI Pooling

## Quick Facts
- arXiv ID: 2402.11985
- Source URL: https://arxiv.org/abs/2402.11985
- Authors: Philip Müller; Felix Meissen; Georgios Kaissis; Daniel Rueckert
- Reference count: 40
- One-line primary result: WSRPN achieves a new state-of-the-art performance on CXR8 with 96.5% relative improvement in RoDeO score compared to best baseline

## Executive Summary
This paper addresses weakly supervised object detection (WSup-OD) in chest X-rays by proposing Weakly Supervised ROI Proposal Networks (WSRPN), a novel paradigm that generates differentiable bounding box proposals on the fly using an attention mechanism. The method outperforms existing WSup-OD approaches by a significant margin, achieving a new state-of-the-art on the CXR8 dataset. WSRPN integrates seamlessly with classic backbone-head classification algorithms and is end-to-end trainable with only image-level labels, making it particularly suitable for medical imaging where bounding box annotations are scarce.

## Method Summary
WSRPN introduces a two-branch architecture with patch and ROI branches, using learned ROI tokens to generate differentiable bounding box proposals through an ROI-attention module. The method employs Gaussian ROI pooling to aggregate features within soft receptive fields centered around predicted box parameters (µ, σ), making the entire pipeline trainable end-to-end. A consistency regularization loss aligns spatial class distributions between branches, while supervised contrastive learning enhances feature discrimination. The approach uses MIL aggregation with LSE pooling for patches and noisyOR for ROIs, optimized using AdamW with specific hyperparameters.

## Key Results
- Achieves 96.5% relative improvement in RoDeO score compared to best baseline on CXR8 dataset
- WSRPN performs best on all evaluated diseases in both classification and localization metrics
- Outperforms baselines in AP, loc-acc, and RoDeO metrics across all IoU thresholds

## Why This Works (Mechanism)

### Mechanism 1
Gaussian ROI pooling with learned center coordinates and scale enables differentiable bounding box proposals that directly optimize localization accuracy without requiring external proposal algorithms. The model predicts box parameters (center µ, size σ) for each ROI token and constructs a soft receptive field using a 2D Gaussian distribution over patches. This soft attention map aggregates patch features into ROI features, making the entire box prediction pipeline differentiable and trainable end-to-end with only image-level labels. Core assumption: Relevant pathology features within an ROI follow a roughly normal distribution around the predicted box center.

### Mechanism 2
The two-branch architecture (patch branch + ROI branch) with consistency regularization stabilizes training by providing strong gradients from patch classification while learning high-quality box proposals in the ROI branch. The patch branch performs MIL classification on individual patches to provide stable gradients and discriminative feature learning. The ROI branch learns box proposals using ROI attention and Gaussian pooling. The consistency loss ensures alignment between spatial class distributions from both branches, preventing the ROI branch from drifting to poor proposals early in training. Core assumption: Patch-level classification provides stable gradients while ROI-level proposals can refine localization without destabilizing training.

### Mechanism 3
The noisyOR aggregation strategy outperforms LSE pooling for ROI branch MIL classification by better modeling the relationship between multiple ROIs and class presence. Instead of summing or max-pooling ROI probabilities, noisyOR computes 1 - ∏(1 - p_k) which models the probability that at least one ROI detects the class. This is more appropriate for multiple ROI proposals than LSE pooling used in patch branch. Core assumption: The presence of a class in an image is better modeled as "at least one ROI detects it" rather than a smoothed max operation.

## Foundational Learning

- **Concept: Multiple Instance Learning (MIL) framework for weakly supervised object detection**
  - Why needed here: The task requires detecting pathologies with only image-level labels, making MIL essential for learning from bags of regions (patches or ROIs) where at least one contains the pathology
  - Quick check question: In MIL, if an image is labeled positive for a disease, what must be true about its regions?

- **Concept: Class Activation Mapping (CAM) and its limitations for medical images**
  - Why needed here: Understanding why CAM-based approaches underperform in medical imaging (pathologies are subtle, lack clear edges) motivates the need for learned proposals rather than heuristic-based heatmaps
  - Quick check question: Why do Selective Search and Edge Boxes algorithms perform poorly on chest X-rays compared to natural images?

- **Concept: Attention mechanisms and cross-attention in transformer architectures**
  - Why needed here: The ROI attention component uses multi-head cross-attention between learned ROI tokens and patch features to gather relevant information for box prediction
  - Quick check question: In the ROI attention component, what serves as queries and what serves as keys/values?

## Architecture Onboarding

- **Component map**: DenseNet121 -> Patch encoder (CNN patches + positional encoding) -> Patch branch (MIL classification + LSE aggregation) -> ROI branch (ROI tokens -> ROI attention -> Box prediction + Gaussian ROI pooling -> ROI classification + noisyOR aggregation) -> Loss functions (patch BCE + supcon + ROI BCE + supcon + consistency loss)
- **Critical path**: Image -> Backbone -> ROI attention (cross-attention between ROI tokens and patch features) -> Box prediction (µ, σ) -> Gaussian ROI pooling (soft receptive field) -> ROI features -> Classification -> noisyOR aggregation -> Loss computation
- **Design tradeoffs**: Number of ROI tokens K vs. computational cost vs. localization granularity; Gaussian vs. generalized Gaussian distribution for receptive fields; patch size vs. feature resolution
- **Failure signatures**: High RoDeO loc but low shape scores indicates good localization but poor box aspect ratios; high classification accuracy but poor localization indicates the model is predicting classes without learning meaningful spatial correspondence
- **First 3 experiments**:
  1. Validate Gaussian ROI pooling by visualizing receptive fields Ak,m,n for different (µk, σk) values and checking they center on pathology regions
  2. Test the consistency loss by training with and without LP↔R and measuring ROI proposal quality (IoU with ground truth boxes)
  3. Experiment with different K values (5, 10, 15) to find the optimal number of ROI tokens that balances detection performance with computational efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does WSRPN perform on other medical imaging modalities (e.g., CT, MRI) beyond chest X-rays?
- **Basis in paper**: The paper mentions that future work could explore incorporating WSRPN into other medical imaging tasks, but does not provide experimental results on other modalities.
- **Why unresolved**: The paper focuses solely on chest X-ray images and does not investigate the generalizability of WSRPN to other medical imaging modalities.
- **What evidence would resolve it**: Conducting experiments on other medical imaging modalities and comparing the performance of WSRPN to existing methods on those datasets.

### Open Question 2
- **Question**: How does WSRPN handle overlapping pathologies or complex disease patterns in chest X-rays?
- **Basis in paper**: The paper mentions that WSRPN struggles with some pathologies, such as infiltration and pneumonia, and that further work is needed to improve its classification capabilities.
- **Why unresolved**: The paper does not provide a detailed analysis of how WSRPN handles overlapping pathologies or complex disease patterns.
- **What evidence would resolve it**: Conducting experiments on datasets with overlapping pathologies or complex disease patterns and analyzing the performance of WSRPN in those scenarios.

### Open Question 3
- **Question**: How can WSRPN be integrated with other forms of weak supervision, such as text or anatomical information?
- **Basis in paper**: The paper mentions that incorporating other forms of weak supervision, such as text or anatomical information, into WSRPN is a promising future research direction.
- **Why unresolved**: The paper does not provide any experimental results or insights on how WSRPN can be integrated with other forms of weak supervision.
- **What evidence would resolve it**: Conducting experiments on integrating WSRPN with other forms of weak supervision and evaluating its performance on disease localization tasks.

## Limitations

- Method's reliance on Gaussian assumptions for pathology feature distributions may not hold for all disease types, particularly those with irregular shapes or multimodal distributions
- Computational cost of ROI attention mechanism scales quadratically with input size, potentially limiting applicability to larger images or higher-resolution medical scans
- Evaluation on a single dataset (CXR8) with limited ground truth bounding boxes raises questions about generalizability to other medical imaging tasks

## Confidence

- **High Confidence**: The claim that WSRPN significantly outperforms existing WSup-OD methods on CXR8 is well-supported by the presented quantitative results (96.5% relative improvement in RoDeO score). The ablation studies and qualitative visualizations provide strong evidence for the effectiveness of the Gaussian ROI pooling and consistency regularization components.

- **Medium Confidence**: The assertion that the two-branch architecture with consistency regularization is essential for stable training is supported by ablation results, but the paper doesn't fully explore alternative stabilization techniques or provide comprehensive analysis of training dynamics across different disease types.

- **Low Confidence**: The claim that noisyOR aggregation is universally superior to LSE pooling for ROI branch classification is based on limited empirical comparison. The paper doesn't provide theoretical justification or extensive ablation studies across different aggregation strategies.

## Next Checks

1. **Generalization across datasets**: Evaluate WSRPN on additional medical imaging datasets (e.g., ChestX-ray14, VinBigData) and non-medical datasets (e.g., PASCAL VOC, MS COCO) to assess cross-domain performance and identify any dataset-specific biases or limitations.

2. **Robustness to pathological distributions**: Conduct controlled experiments using synthetic data with known pathological distributions (uniform, multimodal, irregular shapes) to systematically evaluate the impact of violating the Gaussian assumption on localization accuracy and to identify failure modes.

3. **Computational efficiency analysis**: Perform detailed profiling of the ROI attention mechanism to quantify the computational overhead of different K values and explore potential optimizations (sparse attention, hierarchical pooling) to improve scalability for clinical deployment on high-resolution scans.