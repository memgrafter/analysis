---
ver: rpa2
title: 'GradCraft: Elevating Multi-task Recommendations through Holistic Gradient
  Crafting'
arxiv_id: '2407.19682'
source_url: https://arxiv.org/abs/2407.19682
tags:
- gradient
- multi-task
- tasks
- gradcraft
- balance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GradCraft addresses the challenge of optimizing multiple recommendation
  objectives by simultaneously achieving appropriate magnitude balance and global
  direction balance among task gradients. The method dynamically adjusts gradient
  magnitudes to align with the maximum norm while applying projections to eliminate
  gradient conflicts in directions across all tasks.
---

# GradCraft: Elevating Multi-task Recommendations through Holistic Gradient Crafting

## Quick Facts
- arXiv ID: 2407.19682
- Source URL: https://arxiv.org/abs/2407.19682
- Reference count: 40
- Primary result: GradCraft achieves 0.278% relative improvement in AUC and 1.056% in GAUC compared to single-task baseline on WeChat and Kuaishou datasets

## Executive Summary
GradCraft addresses the challenge of optimizing multiple recommendation objectives by simultaneously achieving appropriate magnitude balance and global direction balance among task gradients. The method dynamically adjusts gradient magnitudes to align with the maximum norm while applying projections to eliminate gradient conflicts in directions across all tasks. Offline experiments on WeChat and Kuaishou datasets demonstrate that GradCraft achieves 0.278% relative improvement in AUC and 1.056% in GAUC compared to the single-task baseline, outperforming existing multi-task learning methods. Online A/B tests on a production platform show significant improvements: +0.505% in watch time, +0.950% in effective video views, and +1.746% in video sharing instances.

## Method Summary
GradCraft operates by first dynamically adjusting gradient magnitudes to prevent task dominance, scaling each task gradient by combining its original norm with the maximum norm among all tasks (controlled by hyper-parameter Ï„). It then performs global direction deconfliction by projecting each task's gradient onto the linear space of all conflicting gradients while maintaining positive similarity (controlled by Îµ). This sequential process ensures that neither magnitude imbalance nor direction conflicts interfere with the other, resulting in well-balanced gradient updates that improve multi-task optimization performance in recommendation systems.

## Key Results
- Achieves 0.278% relative improvement in AUC and 1.056% in GAUC compared to single-task baseline
- Outperforms existing multi-task learning methods on WeChat and Kuaishou datasets
- Online A/B tests show +0.505% increase in watch time, +0.950% in effective video views, and +1.746% in video sharing instances

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GradCraft ensures appropriate magnitude balance by dynamically aligning gradient norms with the maximum gradient norm across tasks.
- Mechanism: The method scales each task gradient by combining its original norm with the maximum norm among all tasks, controlled by hyper-parameter Ï„. This prevents any single task from dominating due to disproportionately large gradient norms.
- Core assumption: Gradient magnitude imbalance causes task dominance and sub-optimal performance in multi-task optimization.
- Evidence anchors:
  - [abstract]: "GradCraft dynamically adjusts gradient magnitudes to align with the maximum gradient norm"
  - [section 3.2]: "Rather than pursuing absolute uniformity of gradient norms... we aim to prevent excessive differences in norms"
- Break condition: If task-specific gradient norms naturally vary by orders of magnitude due to inherent task characteristics, this alignment may over-smooth important task distinctions.

### Mechanism 2
- Claim: GradCraft achieves global direction balance by projecting conflicting gradients simultaneously across all tasks.
- Mechanism: For each task, GradCraft projects its gradient onto the linear space of all conflicting gradients while maintaining positive similarity (controlled by Îµ), ensuring no negative cosine similarity exists between any pair of tasks.
- Core assumption: Pair-wise gradient conflict resolution is insufficient for global non-conflict in multi-task scenarios with many tasks.
- Evidence anchors:
  - [abstract]: "It then employs projections to eliminate gradient conflicts in directions while considering all conflicting tasks simultaneously"
  - [section 3.3]: "we apply projections to eliminate gradient conflicts while considering all conflicting tasks concurrently, ensuring a global balance in directions"
- Break condition: If the number of tasks becomes very large relative to model parameter dimension, the projection matrix may become computationally prohibitive or ill-conditioned.

### Mechanism 3
- Claim: Sequential application of magnitude adjustment followed by direction projection ensures neither step interferes with the other's effectiveness.
- Mechanism: By first normalizing gradient magnitudes to prevent dominance effects, the subsequent direction projection operates on a level playing field where magnitude differences cannot bias the conflict resolution.
- Core assumption: Gradient magnitude imbalance can interfere with direction-based conflict resolution, making sequential processing necessary.
- Evidence anchors:
  - [section 3.3]: "In this sequential process, achieving direction balance hinges on attaining magnitude balance, avoiding interference from the magnitude imbalance"
  - [section 4.3]: "This outcome can be attributed to disruption caused by magnitudes, underscoring the critical role of initially adjusting magnitudes"
- Break condition: If magnitude adjustment is disabled (GradCraft-ori), direction projection alone shows no advantage over simpler methods, confirming the necessity of the sequence.

## Foundational Learning

- Concept: Gradient descent optimization in multi-task learning
  - Why needed here: Understanding how gradients from multiple tasks are combined and updated is fundamental to grasping why GradCraft's gradient manipulation methods work
  - Quick check question: How does the standard multi-task gradient update differ from single-task updates, and what challenges arise when combining gradients from heterogeneous tasks?

- Concept: Gradient projection and orthogonalization
  - Why needed here: GradCraft's direction balancing mechanism relies on projecting gradients to eliminate conflicts, which requires understanding projection operations in high-dimensional spaces
  - Quick check question: What is the geometric interpretation of projecting one gradient onto another, and how does this affect the optimization trajectory?

- Concept: Loss weighting and uncertainty-based balancing
  - Why needed here: GradCraft is compared against methods like UC (uncertainty weighting) and EW (equal weighting), so understanding these baselines helps contextualize GradCraft's advantages
  - Quick check question: How do uncertainty-based and equal weighting approaches attempt to balance multi-task learning, and what are their limitations compared to gradient-level manipulation?

## Architecture Onboarding

- Component map:
  - Magnitude Adjustment Module -> Global Direction Deconfliction Module -> Gradient Combination Module
- Critical path: Forward pass â†’ Task-specific loss computation â†’ Backpropagation â†’ GradCraft processing (magnitude â†’ projection â†’ combination) â†’ Parameter update
- Design tradeoffs:
  - Computational overhead: Additional matrix operations for projection (manageable since projection matrix is small: nÃ—n where n=number of tasks)
  - Hyperparameter sensitivity: Ï„ controls magnitude balancing proximity, Îµ controls direction similarity; both require tuning
  - Model compatibility: Works with any multi-task architecture since it operates at gradient level
- Failure signatures:
  - Performance degrades when Ï„=1 (forcing all gradients to match max norm exactly)
  - Direction balance ineffective when magnitude adjustment is disabled
  - Both Ï„=0 (no adjustment) and Îµ=0 (zero similarity requirement) lead to suboptimal results
- First 3 experiments:
  1. Ablation test: Compare GradCraft vs GradCraft-ori vs GradCraft-local to verify sequential necessity
  2. Sensitivity analysis: Sweep Ï„ âˆˆ [0, 1] and Îµ âˆˆ [1e-12, 1e-7] to find optimal ranges
  3. Scalability test: Evaluate performance as task number increases from 2 to 6 to confirm growing advantage over baselines

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GradCraft's performance scale with an increasing number of tasks beyond the six tasks tested in the experiments?
- Basis in paper: [inferred] The paper mentions "We adjust the task number in the range of {2, 4, 6}" and shows performance improvements with increasing task numbers, but does not test beyond six tasks.
- Why unresolved: The experiments only tested up to six tasks, leaving uncertainty about performance at higher task counts which are common in real-world recommender systems.
- What evidence would resolve it: Additional experiments testing GradCraft with 8, 10, or more tasks would clarify whether the performance benefits continue to scale or plateau at higher task numbers.

### Open Question 2
- Question: What is the computational overhead of GradCraft compared to simpler methods like PCGrad+ when applied to very large-scale industrial recommender systems?
- Basis in paper: [explicit] The paper mentions "our method does not significantly introduce extra computation complexity" and notes that "ğºğ‘–ğº âŠ¤
ğ‘– âˆˆ Rğ‘›Ã—ğ‘›, where ğ‘› is the number of conflicting task gradients for ğ‘”ğ‘–," but does not provide concrete runtime comparisons.
- Why unresolved: While the theoretical complexity is discussed, the paper lacks empirical runtime measurements comparing GradCraft to simpler methods in large-scale settings.
- What evidence would resolve it: Systematic benchmarking of training times and inference latency for GradCraft versus baseline methods on industrial-scale datasets would quantify the practical computational overhead.

### Open Question 3
- Question: How sensitive is GradCraft's performance to the specific choice of backbone model architecture beyond the PLE model used in experiments?
- Basis in paper: [explicit] The paper states "Our work diverges from the aforementioned research as it concentrates on optimization perspective and remains model-agnostic," but all experiments use PLE as the backbone.
- Why unresolved: The paper claims model-agnosticism but only validates GradCraft with one specific architecture, leaving uncertainty about its effectiveness across different model types.
- What evidence would resolve it: Experiments applying GradCraft to multiple backbone architectures (e.g., MMoE, SharedBottom, or transformer-based models) would demonstrate its generalizability across different model structures.

## Limitations
- Performance depends heavily on specific characteristics of multi-task recommendation problem and correlation structure between tasks
- Projection-based approach may become computationally challenging with many tasks
- Method's sensitivity to hyperparameters (Ï„ and Îµ) requires careful tuning for each new application

## Confidence
- **High confidence**: The sequential application of magnitude adjustment followed by direction projection is necessary for optimal performance, as demonstrated by ablation studies
- **Medium confidence**: GradCraft's improvements are primarily driven by better gradient balance rather than other factors, though this could benefit from additional controlled experiments
- **Medium confidence**: The method scales well to larger numbers of tasks, based on theoretical arguments about the projection matrix size, but empirical validation across diverse task configurations would strengthen this claim

## Next Checks
1. **Task correlation sensitivity test**: Systematically vary the correlation structure between recommendation tasks to determine if GradCraft's advantages persist when tasks are weakly correlated versus highly correlated
2. **Projection matrix stability analysis**: Measure the condition number of projection matrices across different task configurations and gradient norm distributions to identify potential numerical stability issues
3. **Cross-domain generalization**: Apply GradCraft to multi-task problems outside short-video recommendations (e.g., multi-task classification or ranking) to verify the method's broader applicability beyond the demonstrated use case