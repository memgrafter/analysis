---
ver: rpa2
title: 'Dilated Convolution with Learnable Spacings makes visual models more aligned
  with humans: a Grad-CAM study'
arxiv_id: '2408.03164'
source_url: https://arxiv.org/abs/2408.03164
tags:
- dcls
- heatmaps
- grad-cam
- interpretability
- convolution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of interpreting deep neural
  network decisions by measuring alignment between model-generated heatmaps and human
  visual attention strategies. The authors introduce Threshold-Grad-CAM, a modified
  version of Grad-CAM that addresses issues with random heatmaps in certain architectures
  like ConvFormer and CAFormer.
---

# Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study

## Quick Facts
- **arXiv ID:** 2408.03164
- **Source URL:** https://arxiv.org/abs/2408.03164
- **Authors:** Rabih Chamas; Ismail Khalfaoui-Hassani; Timothee Masquelier
- **Reference count:** 15
- **Primary result:** Dilated Convolution with Learnable Spacings (DCLS) improves model interpretability alignment with human visual attention strategies across eight state-of-the-art models

## Executive Summary
This paper addresses the challenge of interpreting deep neural network decisions by measuring alignment between model-generated heatmaps and human visual attention strategies. The authors introduce Threshold-Grad-CAM, a modified version of Grad-CAM that addresses issues with random heatmaps in certain architectures like ConvFormer and CAFormer. They evaluate interpretability using Spearman correlation between model heatmaps and human-generated heatmaps from the ClickMe dataset across eight state-of-the-art models with and without Dilated Convolution with Learnable Spacings (DCLS). The results show that DCLS consistently improves interpretability scores in seven out of eight models, with top-1 accuracy gains in most cases except for FastViT and CAFormer.

## Method Summary
The authors propose a novel interpretability evaluation framework using Threshold-Grad-CAM, which modifies traditional Grad-CAM by applying a threshold to remove low-activation regions that produce random-looking heatmaps. They evaluate eight state-of-the-art vision models (ConvFormer, CAFormer, MobileNet, ShuffleNet, RepVGG, EfficientNet, FastViT, and ConvMixer) with and without DCLS on the ClickMe dataset containing human attention annotations. The key metric is Spearman correlation between model-generated heatmaps and human attention maps, measuring how well models align with human visual strategies. DCLS modifies standard dilated convolutions by learning the spacing parameter rather than using fixed values, potentially capturing more semantically relevant features at multiple scales.

## Key Results
- DCLS consistently improves interpretability scores in seven out of eight evaluated models
- Top-1 accuracy gains observed in most models except FastViT and CAFormer
- DCLS-equipped models show better alignment with human visual attention strategies than standard convolution-based models
- Threshold-Grad-CAM successfully addresses random heatmap issues in ConvFormer and CAFormer architectures

## Why This Works (Mechanism)
The improved interpretability with DCLS likely stems from its ability to capture multi-scale contextual information more effectively than fixed-dilation convolutions. By learning the spacing parameter, DCLS can adaptively sample features at varying receptive fields, allowing models to focus on semantically relevant regions that better match human attention patterns. This adaptive sampling potentially helps models distinguish between visually salient but conceptually irrelevant regions and truly important features for classification decisions.

## Foundational Learning
- **Grad-CAM:** A gradient-based visualization technique that generates heatmaps highlighting important regions for model decisions; needed for interpretability analysis and quick check is verifying that heatmaps correspond to object boundaries in validation images
- **Spearman correlation:** A non-parametric rank correlation measure used to assess alignment between model heatmaps and human attention; needed because it captures monotonic relationships without assuming linearity and can be checked by comparing correlation values across different threshold settings
- **Dilated convolutions:** Convolutional operations that expand the receptive field without increasing parameters by inserting spaces between kernel elements; needed for multi-scale feature extraction and quick check is measuring receptive field size across different dilation rates
- **Human attention datasets:** Collections of eye-tracking or click data showing where humans focus on images; needed as ground truth for interpretability evaluation and can be verified by visualizing attention maps against salient objects
- **Thresholding techniques:** Methods for binarizing continuous activation maps; needed to address random heatmap issues and can be validated by testing different threshold values and measuring consistency
- **Model alignment metrics:** Quantitative measures for comparing model behavior to human cognition; needed to establish interpretability benchmarks and can be checked by computing correlation distributions across multiple images

## Architecture Onboarding

**Component Map:** Input Images -> Backbone Model -> Grad-CAM Heatmap Generation -> Thresholding -> Spearman Correlation with Human Attention Maps

**Critical Path:** Image input flows through the backbone architecture, where Grad-CAM extracts class-specific activations, Threshold-Grad-CAM applies thresholding to remove noise, and the resulting heatmap is correlated with human attention data using Spearman correlation as the final evaluation metric.

**Design Tradeoffs:** The Threshold-Grad-CAM method trades computational overhead and hyperparameter sensitivity for more interpretable heatmaps, while DCLS trades increased parameter count and potential overfitting risk for improved multi-scale feature capture and better human alignment.

**Failure Signatures:** Random or scattered heatmaps indicate poor interpretability, low Spearman correlation scores suggest misalignment with human attention, and inconsistent results across different threshold values indicate threshold sensitivity issues.

**First Experiments:** 1) Visualize Grad-CAM heatmaps for correctly classified vs misclassified images to identify failure patterns, 2) Test different threshold values on a validation set to find optimal sensitivity, 3) Compare receptive field sizes between standard dilated convolutions and DCLS to quantify architectural differences

## Open Questions the Paper Calls Out
None

## Limitations
- Threshold-Grad-CAM introduces new hyperparameters (threshold value) that weren't extensively validated across different datasets or architectures
- Evaluation relies solely on Spearman correlation with human attention data from the ClickMe dataset, potentially missing other interpretability aspects
- Ablation studies are limited to only four specific models, making generalizability difficult to assess
- Trade-off between interpretability gains and computational overhead of DCLS wasn't thoroughly explored

## Confidence
- High confidence: DCLS improves Spearman correlation scores in most evaluated models
- Medium confidence: DCLS consistently improves interpretability across different architectures
- Medium confidence: Top-1 accuracy gains correlate with interpretability improvements
- Low confidence: Threshold-Grad-CAM method is robust across diverse model families

## Next Checks
1. Test DCLS with additional human attention datasets (SALICON, MIT300) to verify consistency across different human attention benchmarks
2. Conduct ablation studies on additional model architectures (including transformers with different self-attention mechanisms) to assess generalizability
3. Perform controlled experiments comparing computational efficiency versus interpretability gains to establish practical deployment thresholds