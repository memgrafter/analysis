---
ver: rpa2
title: 'From Local to Global: A Graph RAG Approach to Query-Focused Summarization'
arxiv_id: '2404.16130'
source_url: https://arxiv.org/abs/2404.16130
tags:
- answer
- community
- graph
- arxiv
- summaries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GraphRAG introduces a graph-based retrieval-augmented generation
  approach for answering global sensemaking questions over large text corpora. Unlike
  conventional vector RAG, which retrieves locally relevant text chunks, GraphRAG
  constructs a knowledge graph from the corpus, partitions it into communities of
  related entities, and pre-generates summaries for each community.
---

# From Local to Global: A Graph RAG Approach to Query-Focused Summarization

## Quick Facts
- arXiv ID: 2404.16130
- Source URL: https://arxiv.org/abs/2404.16130
- Reference count: 37
- GraphRAG outperforms vector RAG on comprehensiveness (72-83% win rate) and diversity (75-82% win rate) for global sensemaking questions

## Executive Summary
GraphRAG introduces a graph-based retrieval-augmented generation approach that addresses global sensemaking questions over large text corpora. Unlike conventional vector RAG which retrieves locally relevant text chunks, GraphRAG constructs a knowledge graph, partitions it into communities of related entities, and pre-generates summaries for each community. At query time, these summaries are mapped to partial answers and reduced to a final global answer. Evaluated on two ~1M token datasets, GraphRAG significantly outperformed vector RAG on comprehensiveness and diversity metrics while requiring 26-97% fewer tokens than source text summarization.

## Method Summary
The GraphRAG pipeline processes text corpora by first chunking documents and extracting entities, relationships, and claims using LLM prompts. These elements are used to construct a knowledge graph, which is then partitioned using community detection algorithms like Leiden into hierarchical communities. Community summaries are pre-generated for each community at different hierarchy levels. When answering queries, the system uses a map-reduce approach where community summaries are processed in parallel to generate partial answers, which are then merged into a final global answer. The approach was evaluated against conventional vector RAG and source text summarization using GPT-4 as judge on two datasets: podcast transcripts and news articles.

## Key Results
- GraphRAG achieved 72-83% win rates over vector RAG on comprehensiveness for global sensemaking questions
- GraphRAG achieved 75-82% win rates over vector RAG on diversity for global sensemaking questions
- Community summaries required 26-97% fewer tokens than source text summarization while providing small but consistent quality improvements

## Why This Works (Mechanism)

### Mechanism 1
GraphRAG outperforms vector RAG on global sensemaking questions because it uses hierarchical community summaries instead of local chunk retrieval. The system constructs a knowledge graph from the corpus, partitions it into communities of related entities, pre-generates summaries for each community, then at query time maps each community summary to partial answers before reducing them to a final global answer. This works when community detection algorithms like Leiden can meaningfully partition knowledge graphs into semantically coherent groups that, when summarized, retain sufficient context to answer global questions.

### Mechanism 2
Pre-generating community summaries reduces token consumption while improving answer quality compared to source text summarization. Instead of processing all source text chunks during query time, GraphRAG processes the knowledge graph once to create community summaries, then uses these compressed representations for answering questions, requiring 26-97% fewer tokens than processing source texts directly. This works when the knowledge graph extraction and community summarization process preserves the essential information needed to answer global questions while compressing redundant or irrelevant content.

### Mechanism 3
Map-reduce processing of community summaries enables parallel partial answer generation that improves comprehensiveness and diversity. Community summaries are randomly shuffled and divided into chunks, each processed independently to generate partial answers with helpfulness scores, then sorted and merged to create the final global answer. This works when parallel processing of independent community summaries captures diverse perspectives that, when combined, produce more comprehensive and diverse answers than sequential processing of related text chunks.

## Foundational Learning

- Knowledge Graph Construction
  - Why needed here: GraphRAG relies on converting unstructured text into structured entity-relationship graphs to enable community detection and hierarchical summarization
  - Quick check question: Can you explain the difference between nodes, edges, and claims in the GraphRAG knowledge graph representation?

- Community Detection Algorithms
  - Why needed here: The approach uses algorithms like Leiden to partition the knowledge graph into communities that can be summarized independently
  - Quick check question: What properties make a community detection algorithm suitable for GraphRAG's use case versus traditional network analysis?

- Query-Focused Summarization
  - Why needed here: Each community summary must be tailored to answer specific questions rather than providing generic overviews
  - Quick check question: How does query-focused summarization differ from extractive summarization in the context of GraphRAG?

## Architecture Onboarding

- Component map: Text Chunking → Entity/Relationship Extraction → Knowledge Graph Construction → Community Detection → Community Summary Generation → Query Processing (Map-Reduce)
- Critical path: 1) Knowledge graph construction (single pass over corpus) 2) Community detection and summary generation (pre-processing) 3) Query-time map-reduce processing (partial answer generation + reduction) 4) Final answer generation
- Design tradeoffs: Context window size (smaller windows preferred for comprehensiveness), community level selection (C0-C3 hierarchy levels), self-reflection iterations (improves recall but increases processing time)
- Failure signatures: Low comprehensiveness scores (may indicate incoherent community partitions), poor diversity scores (could suggest homogeneous communities), high token consumption (might indicate inefficient community structure)
- First 3 experiments: 1) Compare entity extraction quality with vs without self-reflection across different chunk sizes 2) Test different community detection algorithms (Louvain vs Leiden) on sample datasets 3) Evaluate the impact of context window size on answer quality for different question types

## Open Questions the Paper Calls Out

- How does GraphRAG performance scale with datasets significantly larger than 1 million tokens? The paper's experiments are limited to 1 million token datasets, and scaling behavior beyond this point remains unexplored.
- How does GraphRAG handle dynamic datasets where information is continuously added or updated? The current implementation builds a graph index once, but real-world applications often require handling evolving data.
- What is the optimal balance between community hierarchy depth and answer quality for different query types? The paper shows C1-C3 generally outperform C0 but doesn't establish clear criteria for choosing community levels based on query characteristics.

## Limitations

- Results rely entirely on GPT-4 as judge without human validation for the comprehensiveness and diversity metrics
- Evaluation is limited to only two datasets totaling approximately 1M tokens each, making generalizability uncertain
- The paper does not analyze whether specific types of information are systematically lost during the graph extraction and summarization process

## Confidence

- **High Confidence**: The architectural claims about how GraphRAG constructs knowledge graphs and uses community detection are well-specified and internally consistent
- **Medium Confidence**: The claim that GraphRAG significantly outperforms vector RAG on comprehensiveness and diversity is supported by the reported win rates (72-83% and 75-82% respectively), but relies on LLM-as-judge evaluation without human validation
- **Low Confidence**: The generalizability of results across different corpus types, sizes, and question domains remains uncertain given the limited evaluation scope

## Next Checks

1. Conduct human evaluation of the comprehensiveness and diversity metrics to verify alignment between GPT-4 judge scores and human assessments
2. Apply GraphRAG to datasets with different characteristics (technical documentation, medical literature, legal contracts) to assess generalizability beyond podcast and news domains
3. Perform ablation studies comparing answers generated directly from source texts versus those from community summaries to identify specific types of information that may be lost during the graph extraction and summarization pipeline