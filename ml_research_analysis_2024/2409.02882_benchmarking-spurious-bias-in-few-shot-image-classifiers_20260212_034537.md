---
ver: rpa2
title: Benchmarking Spurious Bias in Few-Shot Image Classifiers
arxiv_id: '2409.02882'
source_url: https://arxiv.org/abs/2409.02882
tags:
- spurious
- few-shot
- bias
- attributes
- fewstab
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FewSTAB, a benchmarking framework for evaluating
  the robustness of few-shot classifiers to spurious bias. FewSTAB constructs few-shot
  evaluation tasks with biased attributes using attribute-based sample selection strategies
  based on a pre-trained vision-language model, eliminating the need for manual dataset
  curation.
---

# Benchmarking Spurious Bias in Few-Shot Image Classifiers

## Quick Facts
- arXiv ID: 2409.02882
- Source URL: https://arxiv.org/abs/2409.02882
- Authors: Guangtao Zheng; Wenqian Ye; Aidong Zhang
- Reference count: 40
- Primary result: Proposes FewSTAB, a framework that automatically benchmarks spurious bias in few-shot classifiers using vision-language models, achieving accuracy gaps of 5-15% between random and FewSTAB tasks

## Executive Summary
This paper introduces FewSTAB, a benchmarking framework designed to evaluate the robustness of few-shot image classifiers to spurious bias. Unlike traditional approaches that require manual dataset curation, FewSTAB automatically constructs evaluation tasks with biased attributes using pre-trained vision-language models. The framework enables reusing existing few-shot benchmark datasets while providing a new dimension of evaluation on robustness to spurious bias. Experiments across ten few-shot learning methods and three datasets demonstrate that FewSTAB effectively reveals varied degrees of robustness to spurious bias.

## Method Summary
FewSTAB is a benchmarking framework that evaluates few-shot classifiers' robustness to spurious bias through automated task construction. The method uses pre-trained vision-language models to generate text descriptions of images, extracts attributes (nouns/adjectives), and identifies spurious correlations between classes and attributes. It then constructs support and query sets using attribute-based sample selection strategies - either intra-class (removing spurious attributes from query samples) or inter-class (including attributes from other classes). The framework evaluates classifiers on these constructed tasks and measures performance gaps between random tasks and FewSTAB tasks to quantify robustness to spurious bias.

## Key Results
- Accuracy gaps between random and FewSTAB tasks range from 5% to 15%, demonstrating effective bias detection
- Different few-shot learning methods show varied degrees of robustness to spurious bias across all tested datasets
- ViT-GPT2 and BLIP VLMs achieve attribute detection accuracies of 0.853-0.930 on miniImageNet and 0.826-0.919 on CUB-200
- The inter-class sample selection strategy is more effective than intra-class for revealing spurious bias

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FewSTAB reveals spurious bias by constructing few-shot tasks with explicitly controlled spurious correlations.
- Mechanism: The framework uses attribute-based sample selection strategies to create support and query sets where the support contains samples with spurious attributes and the query contains samples without them (intra-class) or with attributes from other classes (inter-class). This forces models relying on spurious correlations to fail on query samples.
- Core assumption: Spurious correlations that hold in support samples will lead to poor generalization on query samples if those correlations are broken.
- Evidence anchors:
  - [abstract] "FewSTAB creates few-shot evaluation tasks with biased attributes so that using them for predictions can demonstrate poor performance."
  - [section] "We propose attribute-based sample selection strategies that select support and query samples with biased attributes... if the support samples induce spurious bias in a few-shot classifier, then the query samples can effectively degrade the classifier's performance."
- Break condition: If the few-shot classifier learns features that are truly class-relevant rather than spurious, it will perform well regardless of the biased attributes.

### Mechanism 2
- Claim: Automated attribute detection via pre-trained vision-language models eliminates manual dataset curation.
- Mechanism: FewSTAB uses a pre-trained vision-language model to generate text descriptions of images, then extracts nouns and adjectives as attributes. This provides a scalable way to identify spurious attributes without human labeling.
- Core assumption: Pre-trained vision-language models can accurately identify attributes that humans would consider spurious.
- Evidence anchors:
  - [section] "we adopt a pre-trained VLM to automatically identify distinct attributes in images in text format... the VLM also detects the vase's color green, and another object table with its material wooden."
  - [section] "We used a pre-trained VLM named ViT-GPT2 to generate text descriptions for images... We also used another pre-trained VLM, BLIP, to test whether FewSTAB can produce consistent results."
- Break condition: If the VLM fails to identify relevant attributes or identifies irrelevant ones, the constructed tasks won't effectively test for spurious bias.

### Mechanism 3
- Claim: Inter-class attribute-based sample selection is more effective than intra-class for revealing spurious bias.
- Mechanism: Instead of just removing the spurious attribute from query samples (intra-class), inter-class selection also includes samples that have attributes from other classes in the support set, creating more challenging scenarios that expose model weaknesses.
- Core assumption: Including attributes from other classes in query samples creates more realistic scenarios where spurious bias manifests.
- Evidence anchors:
  - [section] "We propose the inter-class attribute-based sample selection below... generates a set of sample-label pairs which have class c, do not contain attribute a, but contain attribute a' from another class c'"
  - [section] "The inter-class attribute-based sample selection is built upon the intra-class attribute-based sample selection... we apply the above selection strategy to all the C - 1 spurious correlations in S other than ⟨c, a⟩"
- Break condition: If the model can learn to ignore attributes from other classes, this strategy becomes less effective.

## Foundational Learning

- Concept: Spurious correlation vs. true correlation
  - Why needed here: Understanding the difference is crucial for constructing effective evaluation tasks and interpreting results
  - Quick check question: What distinguishes a spurious correlation from a true correlation in few-shot classification?

- Concept: Vision-language models for attribute detection
  - Why needed here: FewSTAB relies on VLMs to automatically identify attributes, so understanding their capabilities and limitations is essential
  - Quick check question: How do vision-language models generate text descriptions from images, and what are their limitations?

- Concept: Meta-learning vs. transfer learning in few-shot classification
  - Why needed here: FewSTAB evaluates both types of methods, so understanding their differences helps in interpreting results
  - Quick check question: What are the key differences between meta-learning and transfer learning approaches in few-shot classification?

## Architecture Onboarding

- Component map:
  Vision-Language Model (VLM) → Attribute Detection → Sample Selection → Task Construction → Evaluation

- Critical path:
  1. Load test dataset
  2. Generate text descriptions using VLM
  3. Extract attributes (nouns/adjectives)
  4. Identify spurious correlations based on class-attribute relationships
  5. Construct support sets with mutually exclusive spurious attributes
  6. Construct query sets using inter-class selection strategy
  7. Evaluate few-shot classifiers on constructed tasks

- Design tradeoffs:
  - VLM choice: ViT-GPT2 vs. BLIP (different attribute detection capabilities)
  - Sample selection: Intra-class vs. inter-class strategies (effectiveness vs. sample availability)
  - Task complexity: Number of classes and shots (difficulty of revealing bias)

- Failure signatures:
  - Low accuracy gap between random and FewSTAB tasks indicates model robustness to spurious bias
  - High accuracy but low wAcc-A indicates model exploits spurious correlations
  - Inconsistent results across different VLMs suggest attribute detection issues

- First 3 experiments:
  1. Run FewSTAB with default settings (ViT-GPT2, inter-class selection) on miniImageNet to verify basic functionality
  2. Compare results using ViT-GPT2 vs. BLIP to assess VLM impact on evaluation
  3. Test both intra-class and inter-class selection strategies on a small dataset to verify effectiveness difference

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of vision-language model (VLM) affect the detection accuracy of spurious attributes and consequently the benchmark results?
- Basis in paper: [explicit] The paper discusses using different VLMs (ViT-GPT2 and BLIP) and shows their detection accuracies and Spearman's rank correlation coefficients.
- Why unresolved: The paper demonstrates that different VLMs have varying detection accuracies and that the choice of VLM can affect the effectiveness of FewSTAB in uncovering robustness to spurious bias. However, it does not provide a definitive answer on how to choose the optimal VLM for this task.
- What evidence would resolve it: A comprehensive study comparing the performance of FewSTAB with various state-of-the-art VLMs on different datasets and few-shot classification methods would help determine the best VLM choice for this benchmark.

### Open Question 2
- Question: Can FewSTAB be extended to evaluate robustness to spurious bias in few-shot classifiers trained on datasets with domain shifts or adversarial examples?
- Basis in paper: [inferred] The paper mentions that few-shot classifiers face risks like data distribution shifts and adversarial examples, but FewSTAB focuses specifically on spurious bias. It is not clear if FewSTAB can be adapted to evaluate robustness to these other types of risks.
- Why unresolved: The paper does not discuss the applicability of FewSTAB to datasets with domain shifts or adversarial examples. It is unclear if the attribute-based sample selection strategies and task construction methods used by FewSTAB can be effectively applied in these scenarios.
- What evidence would resolve it: Experiments applying FewSTAB to few-shot classifiers trained on datasets with known domain shifts or adversarial examples, and comparing the results with existing evaluation methods for these risks, would provide insights into the potential extension of FewSTAB.

### Open Question 3
- Question: How does the granularity of the attributes detected by the VLM impact the effectiveness of FewSTAB in revealing spurious bias?
- Basis in paper: [explicit] The paper mentions that the VLM may detect non-relevant attributes or miss some attributes due to its limited capacity, which can affect the task construction and the benchmark results.
- Why unresolved: The paper does not provide a detailed analysis of how the granularity of the detected attributes (e.g., fine-grained vs. coarse-grained) affects the ability of FewSTAB to construct tasks that effectively reveal spurious bias in few-shot classifiers.
- What evidence would resolve it: A study varying the granularity of the attributes detected by the VLM and evaluating the impact on FewSTAB's performance in terms of revealing spurious bias would help understand the importance of attribute granularity in this context.

## Limitations

- The paper doesn't validate whether detected spurious attributes align with human intuition about what constitutes a "spurious" feature
- Reliance on pre-trained VLMs for attribute detection introduces potential blind spots if VLMs systematically miss certain attributes or over-identify irrelevant ones
- The inter-class sample selection strategy may fail when attribute spaces don't overlap sufficiently between classes

## Confidence

- **High Confidence:** The mechanism for constructing biased tasks (intra-class sample selection) is well-established and clearly explained.
- **Medium Confidence:** The automated attribute detection via VLMs is novel but lacks thorough validation against ground-truth attribute labels.
- **Medium Confidence:** The effectiveness claims are supported by empirical results but don't explore edge cases where FewSTAB might fail or produce misleading evaluations.

## Next Checks

1. Conduct a human study where annotators identify spurious attributes in FewSTAB-constructed tasks to validate the VLM's attribute detection accuracy against human judgment.
2. Test FewSTAB on synthetic datasets where the true spurious correlations are known, to verify it correctly identifies and exposes these biases.
3. Evaluate FewSTAB's sensitivity to VLM choice by comparing results across multiple VLMs with different architectures and training data.