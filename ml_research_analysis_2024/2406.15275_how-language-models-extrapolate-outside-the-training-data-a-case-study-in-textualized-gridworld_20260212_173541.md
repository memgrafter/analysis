---
ver: rpa2
title: 'How language models extrapolate outside the training data: A case study in
  Textualized Gridworld'
arxiv_id: '2406.15275'
source_url: https://arxiv.org/abs/2406.15275
tags:
- planning
- cognitive
- language
- nright
- maps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates whether language models can extrapolate\
  \ learned behaviors to novel, more complex environments. The authors propose a path\
  \ planning task in a textualized Gridworld to probe language models\u2019 extrapolation\
  \ capabilities."
---

# How language models extrapolate outside the training data: A case study in Textualized Gridworld

## Quick Facts
- arXiv ID: 2406.15275
- Source URL: https://arxiv.org/abs/2406.15275
- Authors: Doyoung Kim; Jongwon Lee; Jinho Park; Minjoon Seo
- Reference count: 40
- Language models fail to extrapolate learned path planning behaviors to larger, unseen grid environments using conventional approaches

## Executive Summary
This paper investigates whether language models can extrapolate learned behaviors to novel, more complex environments through a path planning task in a textualized Gridworld. The authors demonstrate that conventional approaches including next token prediction and Chain of Thought (CoT) fine-tuning fail to generalize to larger, unseen environments. They propose cognitive maps for path planning, a novel CoT framework that simulates humanlike mental representations through tree-structured decision processes. Their approach enables systematic exploration and significantly improves extrapolation capabilities compared to baseline methods.

## Method Summary
The study uses a Textualized Gridworld task where language models must plan paths in grid environments with obstacles. The authors fine-tune Llama-3-8B on 50K training samples (up to 10×10 grids) for one epoch, then evaluate on test samples up to 20×20 grids. They implement four approach variants (NONE, COT, MARK, UNMARK) with forward and backward construction methods. Cognitive maps are constructed through sampling potential actions, propagating to predict resulting states, and backtracking to build complete decision trees. The unpromptable nature of cognitive maps is demonstrated through failed few-shot prompting attempts.

## Key Results
- Conventional approaches (next token prediction and Chain of Thought fine-tuning) fail to extrapolate to larger, unseen environments
- Cognitive maps for path planning significantly improve extrapolation performance compared to baselines
- Backward chaining construction consistently outperforms forward construction (76.5% vs 61.8% success rate)
- Cognitive maps require specialized training schemes and cannot be induced through simple prompting

## Why This Works (Mechanism)

### Mechanism 1
- Language models process structured textual representations of decision trees to reason about spatial relationships beyond training scope
- Core assumption: Models can effectively process and reason about structured textual representations capturing spatial relationships
- Evidence: Abstract states cognitive maps simulate humanlike mental representations; related work on learning cognitive maps from transformers (FMR=0.567)
- Break condition: Approach fails when environment complexity exceeds model capacity or context window limits

### Mechanism 2
- Backward chaining construction outperforms forward construction for path planning tasks
- Core assumption: Reverse order provides better structural cues for path planning than forward construction
- Evidence: Abstract shows UNMARK performed best with 76.5% for BWD vs 61.8% for FWD; related work on backward chaining (FMR=0.514)
- Break condition: Advantage may reverse for problems where forward reasoning is more natural

### Mechanism 3
- Cognitive maps are unpromptable and require specialized training rather than in-context learning
- Core assumption: Current models lack inherent ability to construct and utilize cognitive maps without specialized training
- Evidence: Abstract highlights unpromptable nature; experiments show no meaningful results through few-shot prompting; related work suggests specialized training needed (FMR=0.567)
- Break condition: Would break if future models develop inherent structured reasoning capabilities

## Foundational Learning

- **Dual-process theory of cognition (System 1 vs System 2 reasoning)**: Why needed - paper frames cognitive maps as System 2 reasoning mechanism enabling deliberative thinking. Quick check: Can you explain the difference between System 1 and System 2 reasoning and why cognitive maps are associated with System 2?

- **Chain of Thought (CoT) reasoning and its limitations**: Why needed - paper builds on CoT but identifies limitations in extrapolation, motivating cognitive maps. Quick check: What are the key limitations of conventional CoT approaches identified in the paper, and how do cognitive maps address them?

- **Complexity analysis and environment scaling**: Why needed - understanding how problem complexity scales with grid size is crucial for interpreting extrapolation results. Quick check: How does the paper define environment complexity, and why is this important for understanding extrapolation capabilities?

## Architecture Onboarding

- **Component map**: Llama-3-8B model trained on Gridworld path planning; key components are sampling (identifying possible actions), propagation (predicting resulting states), and backtracking (retracing paths); includes comparison baselines (NONE and COT) and evaluation metrics

- **Critical path**: Sampling potential actions from current state → propagating to predict resulting states → backtracking to construct complete decision tree; must be learned effectively for system to generalize

- **Design tradeoffs**: Verbosity vs effectiveness (more detailed maps improve performance but increase computational cost); forward vs backward construction (backward performs better but may be less intuitive); marking deadends vs not (marking improves efficiency but may reduce exploration flexibility)

- **Failure signatures**: Systems fail to extrapolate when cognitive map exceeds context window, training data lacks diversity, model overfits to specific configurations, or backward chaining encounters situations where forward reasoning would be better

- **First 3 experiments**: 1) Implement basic cognitive map construction on small grids to verify approach works before scaling, 2) Compare forward vs backward construction on medium-sized grids to confirm backward advantage, 3) Test unpromptable nature by attempting few-shot prompting with different model sizes

## Open Questions the Paper Calls Out

- **Can cognitive maps be extended beyond spatial reasoning to domains like mathematical problem-solving?** Basis: Paper discusses potential extensions to mathematical reasoning suggesting cognitive maps could guide mathematical problem-solving. Unresolved: No experimental evidence or concrete implementation details provided. Evidence needed: Developing and testing cognitive maps for mathematical problem-solving tasks demonstrating effectiveness.

- **What is the most effective training paradigm for developing general-purpose cognitive maps in language models?** Basis: Paper highlights unpromptable nature and suggests current pre-training insufficient, proposing alternative paradigms like reinforcement learning with CoT data augmentation. Unresolved: No empirical evidence comparing different training paradigms. Evidence needed: Comparative studies evaluating different training paradigms for developing cognitive maps.

- **How can hybrid approaches integrating cognitive maps and online exploration be designed to bridge the gap between offline and online reasoning?** Basis: Paper discusses complementary strengths of cognitive maps (offline) and exploration-based methods (online), suggesting hybrid approaches could approximate human cognitive planning. Unresolved: No concrete designs or experimental results provided. Evidence needed: Developing and testing hybrid approaches combining cognitive maps with online exploration methods.

## Limitations

- Results are limited to the Gridworld domain and may not generalize to other reasoning tasks
- Exact prompt formatting and construction details for different cognitive map variants are not fully specified
- Comparison is limited to a single model architecture (Llama-3-8B) and specific task type

## Confidence

- **High confidence**: Cognitive maps require specialized training (supported by multiple experiments showing few-shot prompting failure)
- **Medium confidence**: Backward chaining construction consistently outperforms forward construction (based on reported results but limited to this specific task)
- **Medium confidence**: Cognitive maps enable systematic exploration through structured mental representations (mechanism is plausible but requires more diverse task validation)

## Next Checks

1. **Cross-domain generalization test**: Apply cognitive map approach to different reasoning task (e.g., text-based puzzle solving or logical deduction) to validate benefits extend beyond Gridworld path planning

2. **Model architecture comparison**: Test whether larger models (Llama-3-70B or GPT-4) can achieve similar cognitive map capabilities through few-shot prompting rather than requiring full fine-tuning

3. **Scaling relationship validation**: Systematically vary training data diversity and grid complexity to establish precise relationship between training coverage and extrapolation capability beyond current binary training/test size split