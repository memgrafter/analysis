---
ver: rpa2
title: 'DriveGPT: Scaling Autoregressive Behavior Models for Driving'
arxiv_id: '2412.14415'
source_url: https://arxiv.org/abs/2412.14415
tags:
- scaling
- data
- dataset
- driving
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DriveGPT, a scalable autoregressive behavior
  model for autonomous driving. The authors model driving as a sequential decision-making
  task and learn a transformer model to predict future agent states in an autoregressive
  fashion.
---

# DriveGPT: Scaling Autoregressive Behavior Models for Driving

## Quick Facts
- arXiv ID: 2412.14415
- Source URL: https://arxiv.org/abs/2412.14415
- Reference count: 40
- Primary result: DriveGPT scales autoregressive behavior models for autonomous driving, achieving significant improvements in planning and motion prediction tasks through pretraining on large-scale datasets.

## Executive Summary
DriveGPT presents a scalable autoregressive behavior model for autonomous driving by modeling driving as a sequential decision-making task. The authors learn a transformer model to predict future agent states in an autoregressive fashion, scaling up both model parameters and training data by multiple orders of magnitude. The work explores scaling properties across dataset size, model parameters, and compute, demonstrating significant improvements over state-of-the-art baselines. The results validate the benefits of data scaling and show the potential of scaling up behavior models to improve the safety and robustness of autonomous driving systems.

## Method Summary
DriveGPT models autonomous driving as a sequential decision-making problem, using a transformer architecture to autoregressively predict future agent states. The approach scales both model size and training data by orders of magnitude, exploring the relationship between scale and performance. The model is trained on large-scale driving datasets and evaluated on planning and motion prediction tasks. The authors investigate scaling properties by varying dataset size, model parameters, and compute resources, demonstrating that performance improves with scale across these dimensions.

## Key Results
- DriveGPT achieves significant improvements in planning and motion prediction tasks compared to state-of-the-art baselines
- Performance improvements are validated through pretraining on large-scale datasets
- Scaling up model parameters and training data demonstrates clear benefits for autonomous driving behavior modeling

## Why This Works (Mechanism)
The success of DriveGPT stems from its autoregressive formulation of sequential decision-making, where the model learns to predict future states by conditioning on previous predictions. This approach captures the temporal dependencies inherent in driving scenarios. The transformer architecture enables effective modeling of long-range dependencies and complex interactions between agents. By scaling up both model capacity and training data, the system can learn richer representations of driving behavior, capturing nuanced patterns that smaller models might miss.

## Foundational Learning
- **Autoregressive modeling**: Why needed - to predict future states sequentially based on previous predictions; Quick check - verify that prediction error doesn't accumulate excessively over time
- **Transformer architecture**: Why needed - to capture long-range dependencies and complex agent interactions; Quick check - confirm attention mechanisms effectively focus on relevant parts of the input sequence
- **Scaling laws**: Why needed - to understand how performance improves with increased data and model size; Quick check - validate that performance gains follow predictable patterns as scale increases
- **Sequential decision-making**: Why needed - to model driving as a time-series prediction problem; Quick check - ensure the model can handle varying time horizons and prediction lengths

## Architecture Onboarding
- **Component map**: Input states -> Transformer encoder -> Autoregressive decoder -> Future state predictions
- **Critical path**: Raw sensor/input data flows through the transformer architecture to generate sequential predictions of future states
- **Design tradeoffs**: Larger models and datasets improve performance but increase computational requirements and energy consumption; autoregressive approach may accumulate prediction errors
- **Failure signatures**: Prediction errors may compound over time; model may struggle with rare or novel driving scenarios not well-represented in training data
- **First experiments**: 1) Test model performance on held-out test sets with varying degrees of similarity to training data; 2) Measure prediction error accumulation over different time horizons; 3) Compare performance gains against computational cost increases

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several remain regarding the generalizability of the approach to real-world scenarios, the computational feasibility of deployment, and the safety implications of scaling behavior models.

## Limitations
- The extent to which performance gains translate to safety-critical edge cases remains unclear
- Autoregressive formulation may introduce compounding prediction errors over long horizons
- Computational cost of scaling raises questions about practical deployment feasibility and energy efficiency

## Confidence
- High confidence in the core scaling benefits demonstrated through empirical improvements
- Medium confidence in claims about safety and robustness improvements, as these are inferred from benchmark performance
- Medium confidence in assertions about transformer architecture suitability, pending further ablation studies

## Next Checks
1. Evaluate DriveGPT on a held-out test set of challenging urban driving scenarios not seen during training to assess real-world generalization
2. Conduct a systematic study of prediction error accumulation over extended time horizons to quantify the reliability of long-term forecasts
3. Perform a cost-benefit analysis comparing performance gains from scaling against increased computational requirements and energy consumption to determine practical viability for commercial deployment