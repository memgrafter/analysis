---
ver: rpa2
title: Automatic Alignment of Discourse Relations of Different Discourse Annotation
  Frameworks
arxiv_id: '2403.20196'
source_url: https://arxiv.org/abs/2403.20196
tags:
- label
- relations
- discourse
- pdtb
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a fully automatic method for aligning discourse
  relations across different annotation frameworks, specifically RST and PDTB. The
  method learns label embeddings during a classification task using label-anchored
  contrastive learning, enabling mapping of relations without requiring argument matching.
---

# Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks

## Quick Facts
- arXiv ID: 2403.20196
- Source URL: https://arxiv.org/abs/2403.20196
- Authors: Yingxue Fu
- Reference count: 0
- Primary result: Automatic alignment method achieves 47.95 F1 score for mapping RST to PDTB discourse relations

## Executive Summary
This paper presents a fully automatic method for aligning discourse relations across different annotation frameworks, specifically RST and PDTB. The approach learns label embeddings during a classification task using label-anchored contrastive learning, enabling mapping of relations without requiring argument matching. Experiments on RST-DT and PDTB 3.0 show that the learned label embeddings correlate well with classification performance (Pearson correlation 0.88 between F1 and label embedding scores).

## Method Summary
The method learns label embeddings during a multi-class classification task using label-anchored contrastive learning. A BERT encoder processes argument pairs into contextualized representations, while a separate label encoder (BERT, RoBERTa, or random initialization) generates label embeddings. The training combines instance-centered and label-centered contrastive losses with cross-entropy losses on both labels and inputs. The approach maps discourse relations across frameworks by comparing learned label embeddings via cosine similarity, avoiding the need for argument matching. Data augmentation through back-translation is used to address data imbalance issues.

## Key Results
- Learned label embeddings show strong correlation with classification performance (Pearson 0.88 between F1 and label embedding scores)
- The approach achieves 47.95 F1 score in extrinsic evaluation when combining RST and PDTB data
- Label embedding quality (LEQ) serves as an effective intrinsic evaluation metric for alignment quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Label embeddings learned during classification can serve as anchors for mapping discourse relations across frameworks without requiring argument matching.
- Mechanism: The model learns to align input sequence representations with label embeddings through instance-centered and label-centered contrastive losses, creating a shared embedding space where relations from different frameworks can be compared via cosine similarity.
- Core assumption: Discourse relations across frameworks share semantic similarities that can be captured in a common embedding space, even when their surface forms differ significantly.
- Evidence anchors: [abstract] "These embeddings are then utilized to map discourse relations from different frameworks." [section] "Instead of using string matching to identify the closest PDTB arguments and RST EDUs with the aim of discovering potentially analogous relations, we try to learn label embeddings of the relation inventories and compare the label embeddings."
- Break condition: If discourse frameworks use fundamentally incompatible relation definitions or if there's insufficient training data to learn meaningful label embeddings.

### Mechanism 2
- Claim: The correlation matrix between learned label embeddings and class representation proxies provides a quantitative measure of embedding quality.
- Mechanism: After training, the model computes average representations of input sequences for each class and measures cosine similarity with learned label embeddings, creating a correlation matrix where diagonal values indicate alignment quality.
- Core assumption: Good label embeddings should correlate strongly with the average representations of their corresponding classes in the learned embedding space.
- Evidence anchors: [section] "we compute the correlation matrix M between thek learnt label embeddingsEyj and thek class representation proxiesHyi, where 0 ≤ j, i ≤ k − 1, with cosine similarity as the metric of correlation" [section] "the average of values at the main diagonal ofM is adopted as an overall measure of the quality of the learnt label embeddings"
- Break condition: If the correlation matrix shows low diagonal values or if off-diagonal values are similar to diagonal values, indicating poor separation.

### Mechanism 3
- Claim: Data augmentation through back-translation improves label embedding quality for frameworks with limited data.
- Mechanism: Translating RST-DU EDU segments to French and back introduces semantic variations while preserving core meaning, effectively expanding the training data and helping the model learn more robust label embeddings.
- Core assumption: Back-translation introduces useful semantic variations that help the model generalize better without fundamentally changing the discourse relations being expressed.
- Evidence anchors: [section] "we use back translation as a means of data augmentation... Data augmentation is not performed for Elaboration andJoint, which are the two largest classes in RST-DT, to achieve a more balanced data distribution." [section] "The F1 scores and label embedding scores are improved to a large margin" (after back-translation)
- Break condition: If back-translation introduces too many semantic distortions or if the augmented data creates distribution shifts that harm model performance.

## Foundational Learning

- Concept: Contrastive learning with label anchoring
  - Why needed here: Traditional contrastive learning works with instance pairs, but this task requires learning embeddings that represent abstract relation labels across different frameworks
  - Quick check question: How does label-anchored contrastive learning differ from standard instance-based contrastive learning?

- Concept: Multi-task learning with shared representations
  - Why needed here: The model needs to simultaneously learn input representations for classification and label embeddings for alignment, requiring careful balance between different loss functions
  - Quick check question: What happens if one loss component dominates training? How would you detect and correct this?

- Concept: Label embedding space as semantic mapping ground
  - Why needed here: The quality of discourse relation alignment depends on whether learned embeddings capture meaningful semantic relationships between relations from different frameworks
  - Quick check question: How would you verify that learned label embeddings actually capture semantic similarities rather than just classification convenience?

## Architecture Onboarding

- Component map: Input -> BERT encoder -> Instance representation -> Classification + Contrastive losses -> Label encoder -> Label embeddings -> Correlation evaluation
- Critical path: Input → Input encoder → Instance representation → Classification + Contrastive losses → Label encoder → Label embeddings → Correlation evaluation
- Design tradeoffs:
  - Label encoder choice vs. performance: RoBERTa generally outperforms BERT but increases computational cost
  - Data augmentation vs. noise: Back-translation helps with limited data but can introduce semantic distortions
  - Loss balance: Too much emphasis on contrastive losses may hurt classification accuracy, and vice versa
- Failure signatures:
  - Low diagonal values in correlation matrix indicate poor label embedding quality
  - High standard deviation across runs suggests instability in training
  - Performance gap between classification accuracy and label embedding quality suggests misalignment between tasks
- First 3 experiments:
  1. Train with only cross-entropy loss to establish baseline classification performance
  2. Add label-anchored contrastive learning with random label initialization to test embedding learning capability
  3. Compare different label encoder choices (BERT vs. RoBERTa vs. random) on the same dataset to identify optimal architecture

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the label-anchored contrastive learning method be extended to align discourse relations across more than two annotation frameworks simultaneously?
- Basis in paper: [explicit] The paper focuses on aligning RST and PDTB frameworks but mentions the method "may extend beyond labelling of discourse relations to alignment of any label sets."
- Why unresolved: The paper only demonstrates results on two frameworks and doesn't explore multi-framework alignment scenarios.
- What evidence would resolve it: Experimental results showing successful alignment of three or more discourse annotation frameworks using the same methodology.

### Open Question 2
- Question: How does the quality of label embeddings change when applied to discourse corpora from different domains (e.g., newswire vs. conversation)?
- Basis in paper: [inferred] The paper uses RST-DT and PDTB 3.0 which both use Wall Street Journal data, and acknowledges "domain shift" as a potential issue.
- Why unresolved: All experiments are conducted on news domain texts; no evaluation is performed on cross-domain alignment.
- What evidence would resolve it: Experiments comparing label embedding quality and alignment performance when applying the method to corpora from different domains.

### Open Question 3
- Question: What is the relationship between the amount of parallel data (same texts annotated in both frameworks) and the quality of automatically learned label embeddings?
- Basis in paper: [explicit] The authors note that "the label embeddings are trained together with input representations in a multi-class classification task and data imbalance poses a challenge."
- Why unresolved: While data augmentation is explored, the paper doesn't systematically investigate how varying amounts of parallel data affect alignment quality.
- What evidence would resolve it: Controlled experiments varying the proportion of parallel vs. non-parallel data while measuring label embedding quality and alignment accuracy.

## Limitations
- The paper doesn't provide detailed analysis of cross-framework relation mapping quality or expert linguistic evaluation of the learned mappings
- The preprocessing pipeline for mapping 78 RST relations to 16 classes is described but not detailed, making it difficult to assess potential biases
- The approach focuses on high-frequency relations and doesn't address how well it would work for low-frequency or rare discourse relations

## Confidence

**High confidence**: The experimental methodology is sound, the correlation between label embedding quality and classification performance is well-established, and the intrinsic evaluation metrics are appropriate for the task.

**Medium confidence**: The extrinsic evaluation results are promising but limited in scope - the 47.95 F1 score is achieved on relabeled PDTB data rather than on truly independent discourse relations.

**Medium confidence**: The claim that label-anchored contrastive learning is more effective than argument matching approaches is supported but could benefit from more direct comparison experiments.

## Next Checks

**Validation 1**: Conduct expert linguistic evaluation of the learned RST-PDTB mappings to verify that the automatic alignments correspond to meaningful semantic relationships rather than just numerical correlations.

**Validation 2**: Test the approach on additional discourse frameworks beyond RST and PDTB to assess generalizability, particularly frameworks with different annotation schemes like SDRT or eRST.

**Validation 3**: Perform ablation studies on the data augmentation strategy to determine whether back-translation improvements persist when controlling for vocabulary expansion and whether they transfer to truly unseen discourse patterns.