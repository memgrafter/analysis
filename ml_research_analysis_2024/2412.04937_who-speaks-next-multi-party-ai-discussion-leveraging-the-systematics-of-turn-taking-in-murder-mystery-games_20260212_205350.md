---
ver: rpa2
title: Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking
  in Murder Mystery Games
arxiv_id: '2412.04937'
source_url: https://arxiv.org/abs/2412.04937
tags:
- agents
- conversation
- information
- erika
- speaker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of achieving natural and coherent
  multi-party dialogue among AI agents by implementing turn-taking systematics inspired
  by conversation analysis. The proposed "Murder Mystery Agents" framework incorporates
  adjacency pairs and a self-selection mechanism that considers agents' internal states
  to determine the next speaker.
---

# Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games

## Quick Facts
- arXiv ID: 2412.04937
- Source URL: https://arxiv.org/abs/2412.04937
- Authors: Ryota Nonomura; Hiroki Mori
- Reference count: 40
- Multi-party AI dialogue system achieves 62% reduction in dialogue breakdowns through adjacency pair-based turn-taking

## Executive Summary
This study addresses the challenge of achieving natural and coherent multi-party dialogue among AI agents by implementing turn-taking systematics inspired by conversation analysis. The proposed "Murder Mystery Agents" framework incorporates adjacency pairs and a self-selection mechanism that considers agents' internal states to determine the next speaker. Experimental results demonstrate that this approach significantly reduces dialogue breakdowns (p < 0.001) and improves conversation quality, with higher scores in coherence, cooperativeness, and diversity compared to baseline conditions. The method particularly excels in information sharing and logical reasoning, essential for murder mystery game progression.

## Method Summary
The study implements a multi-agent dialogue system for Murder Mystery games that uses turn-taking systematics from conversation analysis. The system features a CSSN-or-SS mechanism where the current speaker either selects the next speaker or allows self-selection based on importance scores. Agents use detectDesignation() to identify adjacency pairs and determine response obligations, while think() generates importance scores (0-9) based on mission relevance and conversational context. A three-layer memory system (History, shortTermHistory, longTermHistory) enables context-aware reasoning and prevents repetitive information sharing.

## Key Results
- Dialogue breakdowns reduced by 62% (from 5.7 to 2.2 per session) when using CSSN-or-SS turn-taking (p < 0.001)
- CSSN-or-SS condition achieved higher scores in coherence (0.427 vs 0.339), cooperativeness (0.459 vs 0.344), and diversity (0.490 vs 0.453) compared to EQUAL condition
- Information sharing and logical reasoning were significantly enhanced, with higher scores in answering questions (1.40 vs 0.80) and confirming alibi information (0.80 vs 0.40)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adjacency pair detection enforces coherent turn-taking by creating response obligations
- Mechanism: When detectDesignation() identifies a first pair part (e.g., question), it explicitly tags the addressed agent to respond with the appropriate second pair part type, preventing topic drift and ignoring questions
- Core assumption: LLM can reliably classify adjacency pair types and identify addressees from conversational context
- Evidence anchors:
  - [abstract] "Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns"
  - [section 3.2.4] "When a first pair part is detected, it simultaneously classifies its type (Yes/No question, addressing, etc.) and estimates the agent addressed by the utterance"
  - [corpus] Weak - no direct evidence of adjacency pair detection accuracy in the corpus
- Break condition: LLM misclassifies adjacency pairs or fails to identify the correct addressee, leading to inappropriate response obligations

### Mechanism 2
- Claim: Self-selection mechanism allows agents to autonomously determine speaking urgency based on mission relevance and conversational context
- Mechanism: think() function generates "importance" scores (0-9) that reflect each agent's assessment of how crucial their utterance is for mission completion and conversation flow, with higher scores enabling turn-taking priority
- Core assumption: Agents can accurately evaluate their utterance's importance relative to others based on internal state and conversation history
- Evidence anchors:
  - [section 3.2.1] "This value is designed to reproduce the Self-Selection mechanism in conversation and is presumed to be determined based on factors such as relevance to the mission, consistency with current conversational context, urgency of the utterance content, and character personality"
  - [abstract] "The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account"
  - [corpus] Weak - corpus doesn't provide evidence of importance score effectiveness
- Break condition: Agents consistently overvalue their own utterances, leading to speech monopolization despite the Current Speaker Selects Next mechanism

### Mechanism 3
- Claim: Multi-layer memory system enables context-aware reasoning and prevents repetitive information sharing
- Mechanism: Three-tier memory (History for conversation flow, shortTermHistory for agent-specific thoughts, longTermHistory for normalized knowledge extraction) allows agents to recall relevant past information and maintain consistent character behavior
- Core assumption: Memory normalization and cosine similarity-based retrieval can effectively surface relevant information when needed
- Evidence anchors:
  - [section 3.1.2] "When generating new utterances, the previous utterance ut−1 is converted into an embedding vector E(ut−1), and the cosine similarity... is calculated with each vector E(ki) of the embedded knowledge stored in longTermHistory"
  - [abstract] "The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account"
  - [corpus] Weak - no direct evidence of memory system effectiveness from corpus
- Break condition: Memory retrieval fails to surface relevant information, causing agents to repeat previously stated facts or miss critical connections

## Foundational Learning

- Concept: Adjacency pairs in conversation analysis
  - Why needed here: Provides theoretical foundation for enforcing response obligations and maintaining conversational coherence
  - Quick check question: What are the two components of an adjacency pair, and why is the second part "conditionally relevant" to the first?

- Concept: Turn-taking systematics (Current Speaker Selects Next vs Self-Selection)
  - Why needed here: Enables natural multi-party dialogue flow by balancing designated responses with autonomous participation
  - Quick check question: How do the three rules of turn-taking described in Section 2.2 interact in the MMAgents implementation?

- Concept: LLM-as-a-Judge methodology
  - Why needed here: Provides scalable, consistent evaluation of conversational quality metrics (coherence, cooperativeness, diversity)
  - Quick check question: What are the three evaluation metrics used, and what does each measure in the context of Murder Mystery gameplay?

## Architecture Onboarding

- Component map: think() → selectMostImportant() → speak() → detectDesignation() → Memory layers (History, shortTermHistory, longTermHistory)
- Critical path: Current speaker generates utterance → detectDesignation() analyzes for adjacency pairs → assigns next speaker → selected agent's think() generates importance score → selectMostImportant() resolves turn-taking
- Design tradeoffs: Using GPT-4o for complex tasks (speak(), detectDesignation()) vs GPT-3.5-turbo for simpler tasks (think(), knowledge normalization) balances performance with computational cost
- Failure signatures: Dialogue breakdowns (ignoring questions, topic-change errors, repetition) indicate adjacency pair detection failures; low coherence scores suggest memory retrieval issues; speech monopolization reveals importance score miscalibration
- First 3 experiments:
  1. Compare adjacency pair detection accuracy with and without explicit addressing in utterances
  2. Test importance score distribution across different character personalities and mission types
  3. Evaluate memory retrieval effectiveness by measuring repetition rates in extended conversations (20+ turns)

## Open Questions the Paper Calls Out

None

## Limitations

- LLM accuracy dependency: The effectiveness of detectDesignation() and think() functions relies heavily on the underlying LLM's ability to correctly identify conversational structure and evaluate utterance importance
- Single scenario validation: Experimental results are based on one murder mystery scenario, limiting generalizability to other conversational domains
- Weak corpus evidence: The study lacks direct validation of adjacency pair detection accuracy and importance score calibration from the experimental corpus

## Confidence

- **High confidence**: The experimental methodology and statistical significance of results (p < 0.001 for dialogue breakdowns)
- **Medium confidence**: The theoretical framework of adjacency pairs and turn-taking systematics as applied to LLM agents
- **Medium confidence**: The effectiveness of the three-layer memory system in maintaining conversational context
- **Low confidence**: The calibration and reliability of importance scores in the self-selection mechanism

## Next Checks

1. **Adjacency pair detection validation**: Test the accuracy of detectDesignation() by having human annotators label adjacency pairs in agent conversations and compare against LLM classifications.

2. **Importance score calibration**: Conduct ablation studies varying the self-selection threshold to find the optimal balance between autonomous participation and preventing speech monopolization.

3. **Memory system comparison**: Compare the three-layer memory architecture against simpler alternatives (e.g., single conversation history) to quantify the contribution of the complex memory design to conversation quality.