---
ver: rpa2
title: 'When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures
  for Dental Caries Segmentation'
arxiv_id: '2511.14860'
source_url: https://arxiv.org/abs/2511.14860
tags:
- segmentation
- caries
- panoramic
- dental
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study benchmarks twelve deep learning architectures\u2014\
  CNNs, Vision Transformers, and Mamba-based models\u2014for dental caries segmentation\
  \ on panoramic radiographs using the DC1000 dataset. Despite the theoretical advantages\
  \ of attention and state-space models in global context modeling, the CNN-based\
  \ DoubleU-Net achieved the highest Dice coefficient of 0.7345, mIoU of 0.5978, and\
  \ precision of 0.8145, outperforming all transformer and Mamba variants."
---

# When CNNs Outperform Transformers and Mamba: Revisiting Deep Architectures for Dental Caries Segmentation

## Quick Facts
- arXiv ID: 2511.14860
- Source URL: https://arxiv.org/abs/2511.14860
- Reference count: 9
- CNNs outperformed transformers and Mambas in dental caries segmentation with highest Dice coefficient of 0.7345

## Executive Summary
This study benchmarks twelve deep learning architectures—CNNs, Vision Transformers, and Mamba-based models—for dental caries segmentation on panoramic radiographs using the DC1000 dataset. Despite the theoretical advantages of attention and state-space models in global context modeling, the CNN-based DoubleU-Net achieved the highest Dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145, outperforming all transformer and Mamba variants. The top three performers across all metrics were CNN architectures. Transformer and Mamba methods underperformed due to limited data and weaker spatial priors. Results emphasize that model complexity does not guarantee better performance in domain-specific medical imaging tasks, and spatial inductive biases remain critical. Computational analysis confirms CNNs offer the best trade-off between accuracy and efficiency for real-time clinical workflows.

## Method Summary
The study evaluated twelve deep learning architectures across three families: CNNs (UNet, DoubleUNet), Vision Transformers (ViT, DeiT, Swin), and Mamba-based models (Conv-Mamba, MambaUNet). All models were trained and tested on the DC1000 dataset of dental panoramic radiographs with caries annotations. Performance was measured using Dice coefficient, mIoU, and precision metrics. The dataset was split into training and validation sets, with hyperparameter tuning conducted for each architecture. Computational efficiency was assessed through inference time and parameter counts.

## Key Results
- CNN-based DoubleU-Net achieved highest performance: Dice coefficient of 0.7345, mIoU of 0.5978, precision of 0.8145
- Top three performers across all metrics were CNN architectures
- Transformer and Mamba variants underperformed due to limited dataset size and weaker spatial priors
- Computational analysis showed CNNs provide optimal accuracy-efficiency trade-off for clinical deployment

## Why This Works (Mechanism)
CNNs excel in dental caries segmentation due to their strong spatial inductive biases that capture local patterns critical for identifying carious lesions. The hierarchical feature extraction allows CNNs to progressively identify lesion boundaries and intensity variations characteristic of dental caries. In contrast, transformers and Mambas, while theoretically capable of global context modeling, require substantially more data to learn spatial relationships effectively. The limited DC1000 dataset prevents these architectures from fully realizing their attention or state-space advantages, while their computational overhead makes them less suitable for real-time clinical applications.

## Foundational Learning
- **Spatial inductive biases**: Why needed - Enable CNNs to capture local patterns without extensive training data; Quick check - Verify model learns edge detection in early layers
- **Hierarchical feature extraction**: Why needed - Progressively refine feature representations from coarse to fine details; Quick check - Examine feature maps at different network depths
- **Attention mechanisms**: Why needed - Enable global context modeling but require large datasets; Quick check - Measure attention weight distributions
- **State-space models**: Why needed - Efficient long-range dependency modeling but sensitive to data scale; Quick check - Compare performance on varying dataset sizes
- **Dice coefficient metric**: Why needed - Appropriate for imbalanced segmentation tasks with small lesion areas; Quick check - Calculate false positive/negative rates

## Architecture Onboarding

Component map: Input Image -> Backbone (CNN/Transformer/Mamba) -> Decoder -> Output Segmentation Map

Critical path: Image preprocessing -> Backbone feature extraction -> Decoder refinement -> Post-processing -> Segmentation output

Design tradeoffs:
- CNN: Strong spatial priors, efficient computation, but limited global context modeling
- Transformer: Global context capability, high parameter efficiency, but data-hungry and computationally intensive
- Mamba: State-space efficiency, good long-range modeling, but requires careful state dimension tuning

Failure signatures:
- Low Dice scores with high IoU indicate precision-recall imbalance
- Computational bottlenecks at attention layers suggest transformer scaling issues
- Poor boundary delineation indicates insufficient decoder refinement

First experiments:
1. Validate data preprocessing pipeline with visual inspection of augmented samples
2. Compare baseline UNet performance against random initialization
3. Measure inference latency across all architectures on target hardware

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Limited dataset size (DC1000) may not fully utilize transformer and Mamba capabilities
- Focus on panoramic radiographs limits generalizability to other dental imaging modalities
- No exploration of advanced training techniques like self-supervised pretraining or knowledge distillation

## Confidence

High confidence claims:
- CNN architectures outperform transformers and Mambas on DC1000 dataset for dental caries segmentation
- CNNs provide better computational efficiency for real-time clinical deployment

Medium confidence claims:
- CNN superiority generalizes to other small-to-medium medical imaging datasets
- Spatial inductive biases are universally more important than attention for medical segmentation

Low confidence claims:
- Computational efficiency rankings hold across all hardware configurations and batch sizes

## Next Checks

1. Test model performance on a larger, multi-center dental imaging dataset to assess scalability and generalizability
2. Implement self-supervised pretraining for transformer and Mamba architectures to evaluate whether increased data exposure alters performance rankings
3. Conduct ablation studies isolating the contribution of spatial inductive biases versus architectural complexity in the observed performance differences