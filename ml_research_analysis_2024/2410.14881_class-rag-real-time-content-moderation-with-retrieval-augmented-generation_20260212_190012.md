---
ver: rpa2
title: 'Class-RAG: Real-Time Content Moderation with Retrieval Augmented Generation'
arxiv_id: '2410.14881'
source_url: https://arxiv.org/abs/2410.14881
tags:
- library
- retrieval
- class-rag
- examples
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Class-RAG, a retrieval-augmented generation
  system for real-time content moderation that outperforms fine-tuning baselines in
  classification accuracy and robustness against adversarial attacks. The method retrieves
  similar safe and unsafe examples from a dynamic library to provide context to a
  fine-tuned LLM classifier, enabling semantic hotfixing without model retraining.
---

# Class-RAG: Real-Time Content Moderation with Retrieval Augmented Generation

## Quick Facts
- arXiv ID: 2410.14881
- Source URL: https://arxiv.org/abs/2410.14881
- Reference count: 13
- Primary result: Perfect classification (AUPRC=1.0) on clean data with high robustness (AUPRC=0.938 average) against adversarial attacks

## Executive Summary
Class-RAG introduces a retrieval-augmented generation system for real-time content moderation that outperforms fine-tuning baselines in both classification accuracy and robustness against adversarial attacks. The system retrieves similar safe and unsafe examples from a dynamic library to provide context to a fine-tuned LLM classifier, enabling semantic hotfixing without model retraining. Experiments show Class-RAG achieves perfect classification on clean data while maintaining high performance against common obfuscations, outperforming both a 4-layer transformer and Llama-3-8B baselines. The system's performance scales with retrieval library size, demonstrating that expanding the library is a low-cost approach to improving moderation accuracy.

## Method Summary
Class-RAG is a retrieval-augmented generation system that uses a fine-tuned Llama-3-8B model with a modified Chain-of-Thought prompting approach for content moderation. The system retrieves similar safe and unsafe examples from a dynamic library and provides them as context to the classifier. During training, the model learns to make classification decisions using retrieved examples. The retrieval library is constructed using DRAGON RoBERTa embeddings and Faiss similarity search, and can be dynamically updated for real-time content moderation without model retraining.

## Key Results
- Perfect classification performance (AUPRC=1.0) on clean data
- High robustness against adversarial attacks (AUPRC=0.938 average across 8 obfuscation techniques)
- Outperforms fine-tuned 4-layer transformer and Llama-3-8B baselines
- Performance scales with retrieval library size, showing cost-effective improvement potential

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Class-RAG enables real-time mitigation of harmful content through dynamically updatable retrieval library
- Mechanism: When a user input is received, Class-RAG retrieves similar safe and unsafe examples from the retrieval library and provides them as context to the fine-tuned LLM classifier. This allows the system to leverage previously seen examples to make classification decisions without requiring model retraining.
- Core assumption: The retrieval library contains relevant examples that can provide sufficient context for accurate classification
- Evidence anchors:
  - [abstract]: "Class-RAG extends the capability of its base LLM through access to a retrieval library which can be dynamically updated to enable semantic hotfixing for immediate, flexible risk mitigation"
  - [section 1]: "Class-RAG enables swift mitigation of generated content through its easily updated retrieval library, allowing changes to take effect within minutes to hours"
  - [corpus]: Weak evidence - no direct corpus citations support this specific mechanism
- Break condition: If the retrieval library lacks relevant examples for a given input, or if the examples provided are insufficient to distinguish between safe and unsafe content

### Mechanism 2
- Claim: Class-RAG improves classification performance by leveraging retrieved examples for few-shot learning
- Mechanism: By retrieving similar safe and unsafe examples and incorporating them into the classification prompt, Class-RAG effectively provides few-shot learning context that helps the LLM classifier make more accurate decisions, especially for subtle distinctions between safe and unsafe content.
- Core assumption: The LLM can effectively learn from and reason about the retrieved examples when making classification decisions
- Evidence anchors:
  - [abstract]: "Compared to model fine-tuning, Class-RAG demonstrates flexibility and transparency in decision-making, outperforms on classification"
  - [section 5.2]: "Class-RAG outperforms both baseline models. Notably, both LLAMA3 and Class-RAG achieved an AUPRC score of 1 on the test set"
  - [corpus]: Weak evidence - no direct corpus citations support this specific mechanism
- Break condition: If the LLM cannot effectively process or reason about the retrieved examples, or if the examples are too dissimilar from the input to be useful

### Mechanism 3
- Claim: Class-RAG scales performance with retrieval library size
- Mechanism: As the retrieval library grows larger, Class-RAG can retrieve more relevant examples for a given input, providing richer context for classification decisions. This allows the system to maintain or improve performance without model retraining.
- Core assumption: Larger retrieval libraries contain more diverse and relevant examples that improve classification accuracy
- Evidence anchors:
  - [abstract]: "Our findings also suggest that Class-RAG performance scales with retrieval library size, indicating that increasing the library size is a viable and low-cost approach to improve content moderation"
  - [section 5.5]: "Our results show that model performance consistently improves with increasing external retrieval library size" and "performance scales with the size of the retrieval library"
  - [corpus]: Weak evidence - no direct corpus citations support this specific mechanism
- Break condition: If increasing library size introduces noise or irrelevant examples, or if the retrieval mechanism becomes inefficient at finding relevant examples in very large libraries

## Foundational Learning

- Concept: Retrieval Augmented Generation (RAG)
  - Why needed here: Class-RAG is fundamentally built on RAG principles, using a retrieval mechanism to augment the LLM's generation capabilities for classification tasks
  - Quick check question: How does RAG differ from traditional fine-tuning approaches in terms of knowledge incorporation and adaptability?

- Concept: Dense retrieval and vector embeddings
  - Why needed here: Class-RAG uses an embedding model (DRAGON RoBERTa) to convert text into vector representations, which are then used for similarity search to find relevant examples in the retrieval library
  - Quick check question: What is the difference between dense retrieval (using vector embeddings) and sparse retrieval (like keyword matching)?

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: Class-RAG employs a modified CoT approach where the answer is placed before the reasoning process to minimize inference latency while still providing interpretability
  - Quick check question: How does placing the answer before the reasoning in CoT affect the model's generation process and latency?

## Architecture Onboarding

- Component map:
  Embedding model (DRAGON RoBERTa) -> Retrieval library -> Retrieval module (Faiss) -> LLM classifier (fine-tuned Llama-3-8B)

- Critical path:
  1. User input is embedded using the embedding model
  2. Faiss retrieves nearest safe and unsafe examples from the library
  3. Retrieved examples and input are sent to the fine-tuned LLM
  4. LLM outputs classification with reasoning

- Design tradeoffs:
  - Library size vs. retrieval efficiency: Larger libraries provide more examples but may slow down retrieval
  - Number of reference examples vs. input token limits: More examples provide better context but increase input length
  - Embedding model choice vs. retrieval quality: Different embedding models may capture different aspects of semantic similarity

- Failure signatures:
  - Poor classification accuracy when retrieval examples are irrelevant or insufficient
  - Increased latency with very large retrieval libraries
  - Inconsistent performance across different types of obfuscation attacks

- First 3 experiments:
  1. Test classification performance with varying numbers of reference examples (0, 2, 4, 6, 8) to find optimal balance
  2. Evaluate robustness against different obfuscation techniques to identify vulnerabilities
  3. Measure performance scaling with retrieval library size to validate the cost-effectiveness of library expansion

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Class-RAG performance scale with retrieval library size in multi-modal contexts?
- Basis in paper: [explicit] The paper states that performance scales with retrieval library size for text-only content moderation, but does not explore multi-modal applications.
- Why unresolved: The paper focuses exclusively on text-based moderation and does not test Class-RAG with image or video inputs, leaving open whether the retrieval-scaling benefits apply to multi-modal scenarios.
- What evidence would resolve it: Experiments comparing Class-RAG performance with increasing library sizes for multi-modal inputs (text+image, text+video) against baseline models.

### Open Question 2
- Question: What is the optimal balance between retrieval library size and reference example count for maximum performance?
- Basis in paper: [explicit] The paper shows performance improves with both larger libraries and more reference examples, but notes that adding references incurs higher computational costs.
- Why unresolved: The paper does not provide a cost-benefit analysis to determine the optimal combination of library size and reference count that maximizes performance while minimizing computational expense.
- What evidence would resolve it: Systematic experiments varying both library size and reference count to identify the point of diminishing returns and the most cost-effective configuration.

### Open Question 3
- Question: How does Class-RAG perform across different languages and cultural contexts?
- Basis in paper: [explicit] The paper acknowledges that the model's common sense knowledge is limited to its training data and may not perform well on non-English languages or out-of-scope knowledge.
- Why unresolved: All experiments and datasets used in the paper are English-only, with no evaluation of the model's performance or biases in multilingual or multicultural settings.
- What evidence would resolve it: Testing Class-RAG on multilingual datasets and culturally diverse content to assess performance variations and potential biases across different languages and cultural contexts.

## Limitations

- Perfect classification score (AUPRC=1.0) on clean data raises concerns about potential data leakage or overfitting
- Adversarial robustness evaluation limited to 8 specific obfuscation techniques, may not capture full attack space
- All experiments conducted on English-only datasets with no evaluation of multilingual or cultural performance

## Confidence

- Classification performance claims: Medium confidence - While the methodology appears sound, the perfect score on clean data raises concerns about potential data leakage or overfitting that could inflate performance metrics.
- Adversarial robustness claims: Medium-Low confidence - The study tests only 8 specific obfuscation techniques and may not capture the full space of potential adversarial attacks. Real-world adversaries could develop new evasion strategies not covered in the evaluation.
- Scalability claims: Medium confidence - The correlation between library size and performance is demonstrated, but the underlying mechanism (whether quality or quantity of examples drives improvement) is not fully explored.

## Next Checks

1. **Cross-dataset validation**: Evaluate Class-RAG on entirely separate datasets not used in training or library construction to verify that perfect classification scores on clean data are not artifacts of data leakage or overfitting to the CoPro dataset.

2. **Adversarial robustness stress test**: Implement a broader range of adversarial attack strategies including context-aware obfuscation, semantic-preserving transformations, and novel attack patterns to assess whether the claimed AUPRC=0.938 average holds against more sophisticated threats.

3. **Library quality vs. quantity analysis**: Conduct controlled experiments varying both the size and diversity of retrieval libraries while measuring classification performance to determine whether scaling benefits come from increased example quality, diversity, or simply probability of finding relevant examples.