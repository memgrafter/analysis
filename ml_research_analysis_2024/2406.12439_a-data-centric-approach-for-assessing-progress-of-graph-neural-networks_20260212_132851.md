---
ver: rpa2
title: A data-centric approach for assessing progress of Graph Neural Networks
arxiv_id: '2406.12439'
source_url: https://arxiv.org/abs/2406.12439
tags:
- multi-label
- datasets
- nodes
- graph
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates multi-label node classification in Graph
  Neural Networks (GNNs), an area often overshadowed by multi-class classification.
  The authors highlight data quality issues in existing datasets and propose a new
  multi-label graph generator with tunable properties to facilitate rigorous evaluation.
---

# A data-centric approach for assessing progress of Graph Neural Networks

## Quick Facts
- arXiv ID: 2406.12439
- Source URL: https://arxiv.org/abs/2406.12439
- Authors: Tianqi Zhao; Ngan Thi Dong; Alan Hanjalic; Megha Khosla
- Reference count: 3
- Key outcome: This paper investigates multi-label node classification in Graph Neural Networks (GNNs), an area often overshadowed by multi-class classification. The authors highlight data quality issues in existing datasets and propose a new multi-label graph generator with tunable properties to facilitate rigorous evaluation. They also introduce new biological datasets and redefine homophily and cross-class neighborhood similarity for multi-label scenarios. Through a large-scale study across nine datasets and eight methods, they reveal that simple baselines like DeepWalk often outperform more sophisticated GNNs. The findings indicate that current GNN techniques are insufficient for multi-label node classification, calling for further research and innovation in this domain.

## Executive Summary
This paper addresses the under-explored area of multi-label node classification in Graph Neural Networks (GNNs). The authors identify significant data quality issues in existing multi-label graph datasets and propose a new multi-label graph generator with tunable properties to enable rigorous evaluation. They also introduce new biological datasets and redefine homophily and cross-class neighborhood similarity for multi-label scenarios. Through a comprehensive study across nine datasets and eight methods, they reveal that simple baselines like DeepWalk often outperform more sophisticated GNNs, highlighting the need for further research and innovation in this domain.

## Method Summary
The authors investigate multi-label node classification on graph-structured data, focusing on data quality issues and evaluation practices. They propose a new multi-label graph generator with tunable properties (homophily parameter α, characteristic distance b) to create synthetic datasets. The study compares eight methods (MLP, DeepWalk, LANC, GCN, GAT, GraphSage, H2Gcn, GCN-LPA) on nine datasets (7 real-world + 2 synthetic). Evaluation uses Average Precision (AP) as the primary metric, highlighting the unreliability of AUROC in sparse label settings. The authors also introduce Cross-Class Neighborhood Similarity (CCNS) to better capture multi-label neighborhood relationships.

## Key Results
- AUROC scores can be misleading in sparse multi-label scenarios, as predicting "no label" for all nodes achieves high scores
- Simple baselines like DeepWalk often outperform more sophisticated GNNs in multi-label node classification
- The proposed multi-label graph generator enables controlled experiments with tunable homophily and feature quality properties

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Traditional homophily metrics fail for multi-label graphs because label sets can partially overlap without implying strong node similarity.
- Mechanism: The paper introduces Cross-Class Neighborhood Similarity (CCNS), which measures label distribution similarity across all class pairs, not just exact matches.
- Core assumption: Node labels are encoded as binary vectors, and cosine similarity over empirical label histograms captures meaningful neighborhood relationships.
- Evidence anchors:
  - [abstract] "Therefore, we define homophily and Cross-Class Neighborhood Similarity for multi-label classification"
  - [section] "Definition 2... the vector di∈RC corresponds to the empirical histogram (over|C|classes) of node i’s neighbors’ labels"
  - [corpus] Weak - related papers focus on multi-label GCNs but do not reference CCNS specifically
- Break condition: If label sets are extremely sparse or binary, cosine similarity over histograms collapses to Jaccard similarity, reducing CCNS to existing metrics.

### Mechanism 2
- Claim: AUROC scores can be misleading in sparse label scenarios because predicting "no label" for all nodes achieves high scores.
- Mechanism: AUROC treats each label as an independent binary classification; with many negatives, false positives have minimal impact on the curve.
- Core assumption: The dataset contains a high proportion of unlabeled nodes in test sets, and evaluation uses per-label binary classification metrics.
- Evidence anchors:
  - [abstract] "the use of the Area Under the ROC Curve (AUROC) metric leads to overly exaggerated performance scores"
  - [section] "a model that predicts 'No Label' for each node... achieves a high AUROC score"
  - [corpus] Weak - no direct mention of AUROC pitfalls in related works
- Break condition: If the label distribution is balanced or if evaluation switches to metrics like AP or F1 that penalize false negatives.

### Mechanism 3
- Claim: Multi-label datasets often have skewed label distributions, with most nodes having few labels, making standard GNNs less effective.
- Mechanism: Simple methods like DeepWalk, which do not rely on label homophily, can outperform GNNs when label overlap is low.
- Core assumption: Graph structure contains useful structural features even when label correlation is weak.
- Evidence anchors:
  - [abstract] "simple baselines like DeepWalk often outperform more sophisticated GNNs"
  - [section] "Table 1: Mean performance scores... DeepWalk 0.190 0.096 0.044 0.585..."
  - [corpus] Weak - related works mention DeepWalk as baseline but do not discuss its advantage in multi-label settings
- Break condition: If synthetic datasets are engineered for high homophily, GNNs should regain superiority.

## Foundational Learning

- Concept: Graph Neural Networks
  - Why needed here: Understanding how GNNs aggregate neighbor information is critical to grasping why they fail in low-homophily multi-label settings.
  - Quick check question: What happens to a GCN's hidden representation if all neighbors have disjoint label sets?

- Concept: Multi-label classification
  - Why needed here: Multi-label is fundamentally different from multi-class; each label is a separate binary task, and label correlation matters.
  - Quick check question: How does the label distribution skew (most nodes with few labels) affect the expected performance of a model trained with binary cross-entropy?

- Concept: Homophily and heterophily
  - Why needed here: These concepts underpin the paper's critique of applying single-label metrics to multi-label graphs.
  - Quick check question: Why does a high Jaccard similarity between neighbors' label sets not guarantee good GNN performance?

## Architecture Onboarding

- Component map: graph construction -> label set extraction -> neighborhood histogram computation -> model training and evaluation
- Critical path:
  1. Load graph and label matrix
  2. Compute CCNS matrix for analysis
  3. Train and evaluate each model on real and synthetic datasets
  4. Compare performance across homophily/feature quality settings
- Design tradeoffs:
  - AUROC vs AP/F1: AUROC insensitive to class imbalance; AP/F1 penalizes missing rare labels
  - DeepWalk vs GNNs: DeepWalk ignores labels during training; GNNs assume label correlation
  - Synthetic generator: tunable homophily vs realism; social distance model may not reflect all domains
- Failure signatures:
  - AUROC high, AP low → label sparsity issue
  - DeepWalk beats all GNNs → low homophily or poor feature quality
  - H2Gcn underperforms → synthetic homophily too low for its design assumptions
- First 3 experiments:
  1. Compute CCNS matrix for BlogCat and plot heatmap to confirm intra/inter-class similarity patterns
  2. Train MLP and DeepWalk on BlogCat, record AUROC and AP; verify DeepWalk superiority
  3. Generate synthetic dataset with rfeat=0.2, rhomo=0.8; train GCN and GAT; confirm homophily advantage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed homophily and Cross-Class Neighborhood Similarity (CCNS) measures perform on datasets with overlapping labels or hierarchical label structures?
- Basis in paper: [explicit] The paper introduces homophily and CCNS for multi-label scenarios but does not extensively evaluate these measures on datasets with complex label relationships.
- Why unresolved: The paper focuses on real-world datasets with relatively simple label structures and does not explore how these measures generalize to more complex scenarios.
- What evidence would resolve it: Experiments on datasets with overlapping labels or hierarchical structures, comparing the proposed measures to alternative similarity metrics, and analyzing their impact on model performance.

### Open Question 2
- Question: What is the impact of different graph construction models on the performance of multi-label node classification methods?
- Basis in paper: [inferred] The paper uses a specific social distance attachment model for graph construction but does not explore how different models affect classification performance.
- Why unresolved: The paper does not compare the performance of classification methods on graphs generated using different models or varying model parameters.
- What evidence would resolve it: Experiments comparing classification performance across multiple graph construction models, analyzing the sensitivity of methods to model parameters, and identifying optimal models for different types of multi-label datasets.

### Open Question 3
- Question: How do semi-supervised and active learning approaches perform in multi-label node classification compared to the transductive setting used in the paper?
- Basis in paper: [explicit] The paper focuses on the transductive setting, assuming labeled training nodes are completely labeled, but does not explore semi-supervised or active learning approaches.
- Why unresolved: The paper does not investigate how different learning paradigms, such as semi-supervised or active learning, affect the performance of multi-label node classification methods.
- What evidence would resolve it: Experiments comparing the performance of classification methods under different learning paradigms, analyzing the trade-offs between labeled data requirements and classification accuracy, and identifying optimal strategies for active learning in multi-label scenarios.

## Limitations

- The superiority of DeepWalk over GNNs may be specific to the datasets studied and the particular GNN implementations used
- The proposed CCNS metric, while theoretically sound, requires empirical validation across diverse graph structures
- The extent of AUROC's unreliability in sparse multi-label settings across different dataset sizes and label distributions remains unclear

## Confidence

- High: AUROC can be misleading in sparse multi-label classification; need for multi-label-specific evaluation metrics
- Medium: Cross-Class Neighborhood Similarity (CCNS) as a meaningful metric for multi-label graphs
- Medium: DeepWalk's effectiveness in low-homophily multi-label scenarios

## Next Checks

1. Generate synthetic datasets with varying label sparsity levels and verify that AUROC remains inflated while AP/F1 scores reflect true performance
2. Implement CCNS computation and validate its behavior on graphs with known homophily patterns (e.g., synthetic data with controlled label distributions)
3. Test additional GNN variants beyond those studied to determine if DeepWalk's advantage generalizes across the GNN spectrum