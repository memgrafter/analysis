---
ver: rpa2
title: 'MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory'
arxiv_id: '2411.06736'
source_url: https://arxiv.org/abs/2411.06736
tags:
- memory
- task
- agent
- place
- event
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of repeated failures in low-level
  controllers for embodied AI agents in Minecraft, caused by the absence of episodic
  memory. The authors introduce MrSteve, a novel low-level controller equipped with
  Place Event Memory (PEM), a form of episodic memory that captures what, where, and
  when information from episodes.
---

# MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory

## Quick Facts
- arXiv ID: 2411.06736
- Source URL: https://arxiv.org/abs/2411.06736
- Authors: Junyeong Park; Junmo Cho; Sungjin Ahn
- Reference count: 40
- One-line primary result: MrSteve outperforms existing methods in task-solving and exploration efficiency by incorporating episodic memory (PEM) to address repeated failures in low-level controllers.

## Executive Summary
This paper introduces MrSteve, a novel low-level controller for embodied AI agents in Minecraft that addresses repeated failures caused by the absence of episodic memory. The key innovation is Place Event Memory (PEM), which stores "what-where-when" information to enable efficient recall and navigation in long-horizon tasks. Unlike Steve-1 which relies on short-term memory, MrSteve can remember task-relevant resources and locations, allowing agents to revisit them directly rather than re-exploring. The authors also propose an Exploration Strategy with hierarchical exploration and a Memory-Augmented Task Solving Framework that alternates between exploration and task-solving based on recalled events. Results show significant improvements over existing methods in both task-solving and exploration efficiency.

## Method Summary
MrSteve extends the Steve-1 low-level controller by adding Place Event Memory (PEM) that hierarchically organizes spatial and event-based information. PEM uses MineCLIP embeddings to cluster visited locations into place clusters and subdivides them into event clusters based on visual similarity. The system employs a hierarchical exploration strategy where a high-level Count-Based goal selector divides the environment into grid cells and selects the least-visited cell as the goal, while VPT-Nav (a fine-tuned VPT model) handles low-level navigation. The Memory-Augmented Task Solving Framework includes a Mode Selector that queries PEM for task-relevant resources - if found, the agent navigates directly to execute the task, otherwise it explores and stores new experiences. Training involves PPO fine-tuning of VPT-Nav for goal-conditioned navigation.

## Key Results
- MrSteve achieves significantly higher success rates than Steve-1 in ABA-Sparse tasks by efficiently finding and revisiting task-relevant resources
- The Count-Based exploration strategy reduces revisits and improves map coverage compared to baseline exploration methods
- VPT-Nav successfully navigates to arbitrary goal locations using fine-tuned human demonstration data, enabling precise goal-directed behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Memory recall reduces repeated exploration failures by storing and retrieving "what-where-when" event data.
- Mechanism: Place Event Memory (PEM) clusters visited locations into place clusters and subdivides them into event clusters based on visual similarity. When a task is given, the agent queries PEM for event clusters matching the task and navigates directly to the relevant location instead of exploring anew.
- Core assumption: Visual embeddings from MineCLIP adequately capture semantic similarity for event clustering and retrieval.
- Evidence anchors:
  - [abstract] "PEM organizes spatial and event-based data, enabling efficient recall and navigation in long-horizon tasks."
  - [section] "PEM stores spatial and event-based information, allowing the agent to hierarchically organize and retrieve details about locations and events it has previously encountered."
  - [corpus] No direct corpus evidence; this is an assumption from the paper.
- Break condition: If visual embeddings fail to distinguish distinct events (e.g., two visually similar houses in different places), the agent may cluster them together and lose task-relevant frames.

### Mechanism 2
- Claim: Hierarchical episodic exploration reduces revisits by directing the agent to the least-visited locations.
- Mechanism: High-level Count-Based goal selector divides a visitation map into grid cells, selects the cell with the lowest visitation count as the goal, and VPT-Nav navigates to it. This ensures the agent explores new areas rather than repeating previous paths.
- Core assumption: The visitation map accurately tracks all visited locations and the agent can navigate to any selected goal.
- Evidence anchors:
  - [section] "This is achieved through a high-level goal selectorπH-Nav(gt|ℓ′t, Mt) and a low-level goal achiever πL-Nav(at|ht, gt), where ht = it−128:t, and ℓ′t, and gt are the agent's current location, and goal location in (coordx, coordy), respectively."
  - [section] "Specifically, L × L visitation grid map mt is used with the agent's starting location set as the center of the map."
  - [corpus] No direct corpus evidence; this is an assumption from the paper.
- Break condition: If the visitation map is too coarse or the agent cannot navigate complex terrain, it may get stuck or revisit areas.

### Mechanism 3
- Claim: Memory-augmented task solving improves success rate by allowing the agent to revisit previously found resources.
- Mechanism: When a task-relevant resource is found and stored in PEM, the agent can navigate back to it directly for subsequent tasks, avoiding the need to search again. This is demonstrated in ABA-Sparse tasks where the agent must find a resource twice.
- Core assumption: The agent can reliably navigate back to stored locations and the stored frames are still relevant when the task is repeated.
- Evidence anchors:
  - [section] "When a task-relevant resource exists in the memory, Execute mode is selected, then the agent navigates to the resource's position and executesπInst (i.e., Steve-1) to solve the task."
  - [section] "In Figure 5, it is clear that MrSteve outperforms Steve-1. This is because MrSteve can find task-relevant resources faster with efficient exploration and store the location of the taskA resource, allowing it to revisit the location and solve taskA again within a limited time."
  - [corpus] No direct corpus evidence; this is an assumption from the paper.
- Break condition: If the memory is limited and old frames are removed before the task is repeated, or if the environment changes and the stored location is no longer valid.

## Foundational Learning

- Concept: Episodic memory systems and their role in embodied AI.
  - Why needed here: Understanding how episodic memory differs from short-term memory and why it's crucial for long-horizon tasks in Minecraft.
  - Quick check question: What is the main limitation of Steve-1's memory system, and how does PEM address it?

- Concept: Hierarchical exploration strategies and their implementation.
  - Why needed here: Grasping how the high-level Count-Based goal selector and low-level VPT-Nav work together to efficiently explore the environment.
  - Quick check question: How does the Count-Based goal selector decide which location to explore next?

- Concept: Video pretraining (VPT) and its fine-tuning for goal-conditioned navigation.
  - Why needed here: Understanding how VPT-Nav is trained to navigate to specific goal locations using human demonstration data.
  - Quick check question: What are the key modifications made to VPT to create VPT-Nav for goal-conditioned navigation?

## Architecture Onboarding

- Component map:
  Memory Module (PEM with place and event clusters, write/read operations) -> Solver Module (Mode Selector, hierarchical exploration, task execution) -> Minecraft Environment

- Critical path:
  1. Receive task instruction
  2. Mode Selector queries PEM for task-relevant resources
  3. If found, navigate to location using VPT-Nav and execute task with Steve-1
  4. If not found, explore using Count-Based + VPT-Nav and store new experiences in PEM
  5. Repeat until task is completed or timeout

- Design tradeoffs:
  - Memory capacity vs. retrieval efficiency: Larger memory allows more storage but increases query time
  - Place cluster size vs. granularity: Larger clusters reduce memory usage but may lose location-specific details
  - Event cluster threshold vs. distinctiveness: Higher thresholds ensure distinct events but may create too many clusters

- Failure signatures:
  - Agent repeatedly visits the same locations: Issue with Count-Based exploration or visitation map tracking
  - Agent cannot find task-relevant resources: Issue with PEM clustering, retrieval, or MineCLIP embeddings
  - Agent gets stuck navigating complex terrain: Issue with VPT-Nav training or terrain handling

- First 3 experiments:
  1. Test exploration efficiency: Place agent in a 100x100 map, measure map coverage and revisit count with different exploration methods
  2. Test memory retrieval: Run ABA-Sparse tasks, measure success rate and task duration with different memory types
  3. Test navigation accuracy: Use VPT-Nav in diverse terrains, measure success rate and SPL for goal-conditioned navigation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the Place Event Memory (PEM) system be extended to access hierarchical planners for enhanced long-horizon task planning?
- Basis in paper: [explicit] The paper discusses the potential for PEM to improve low-level controller performance but notes that current limitations prevent high-level planners from accessing PEM, suggesting future work could explore this integration.
- Why unresolved: The paper does not explore the technical feasibility or implementation details of enabling PEM access for high-level planners, leaving open questions about how such integration would be achieved and its impact on planning accuracy.
- What evidence would resolve it: Experimental results demonstrating improved planning accuracy and task completion rates when PEM is accessible to high-level planners, along with a detailed technical framework for integration.

### Open Question 2
- Question: How can MrSteve be adapted to function effectively in environments with noisy positional data, such as real-world robotics applications?
- Basis in paper: [explicit] The paper notes that MrSteve uses exact position data in Minecraft, which may limit its adaptability to robotics tasks where positional information is often noisy, suggesting adaptation as a future direction.
- Why unresolved: The paper does not provide a methodology or experimental validation for adapting MrSteve to handle noisy positional data, leaving uncertainty about its robustness and performance in such scenarios.
- What evidence would resolve it: Empirical studies showing MrSteve's performance in simulated or real-world environments with varying levels of positional noise, along with modifications to the navigation and memory systems to handle such data.

### Open Question 3
- Question: What are the optimal parameters for the Place Event Memory (PEM) system to maximize efficiency and performance across diverse tasks?
- Basis in paper: [explicit] The paper presents ablation studies on top-k selection and cluster sizes, indicating that parameter tuning can affect performance, but does not explore the full parameter space or provide a comprehensive optimization strategy.
- Why unresolved: The paper does not investigate the impact of other parameters, such as the MineCLIP threshold or the update frequency, and does not provide a systematic approach to parameter optimization.
- What evidence would resolve it: A comprehensive study exploring the effects of various PEM parameters on performance metrics like success rate and task completion time, along with guidelines for parameter selection based on task characteristics.

## Limitations
- MineCLIP embedding quality is critical for PEM's event clustering performance but not validated across diverse environments
- Count-Based exploration assumes visitation map accurately tracks all reachable locations, which may fail in complex terrain
- Generalization to complex reasoning tasks beyond simple resource retrieval remains unproven

## Confidence
- **High confidence**: The fundamental architecture of PEM with hierarchical place and event clustering is sound and technically feasible
- **Medium confidence**: The claimed improvements in task-solving efficiency rely on specific implementation details not fully specified
- **Low confidence**: The generalization of MrSteve to complex instruction-following scenarios beyond ABA-Sparse tasks remains unproven

## Next Checks
1. **Embedding Quality Validation**: Run controlled experiments where visually similar but semantically distinct events are presented to MrSteve. Measure whether PEM correctly distinguishes these events using quantitative metrics like clustering purity and retrieval precision.

2. **Terrain Navigation Stress Test**: Deploy MrSteve in procedurally generated Minecraft worlds with complex terrain features (mountains, rivers, caves). Track navigation success rates and compare against flat terrain performance to identify potential VPT-Nav limitations.

3. **Memory Capacity Scaling**: Systematically vary the PEM memory capacity and measure the impact on task success rates and exploration efficiency. Determine whether there's a point of diminishing returns and identify the optimal memory size for different task types.