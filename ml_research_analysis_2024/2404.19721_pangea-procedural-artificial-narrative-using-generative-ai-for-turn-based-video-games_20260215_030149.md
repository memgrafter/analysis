---
ver: rpa2
title: 'PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based
  Video Games'
arxiv_id: '2404.19721'
source_url: https://arxiv.org/abs/2404.19721
tags:
- game
- narrative
- pangea
- player
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PANGeA, a system that uses LLMs to generate
  interactive narrative content for turn-based RPGs. Unlike prior work, PANGeA not
  only creates game assets but also enables dynamic, free-form dialogue between players
  and NPCs.
---

# PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games

## Quick Facts
- **arXiv ID**: 2404.19721
- **Source URL**: https://arxiv.org/abs/2404.19721
- **Reference count**: 40
- **Primary result**: Validation system improves narrative alignment from 30/90 to 89/90 irrelevant inputs in demo game.

## Executive Summary
PANGeA introduces a procedural narrative system for turn-based RPGs that leverages large language models (LLMs) to generate interactive content and enable free-form dialogue between players and NPCs. The system's key innovation is a validation framework using LLM self-reflection to evaluate and correct out-of-scope responses, ensuring narrative coherence. Supported by a custom memory system for context retention and a REST API for integration, PANGeA was evaluated in the Dark Shadows demo game, demonstrating significantly improved narrative alignment compared to a non-validated baseline.

## Method Summary
PANGeA uses a prompt schema to translate high-level game criteria into LLM instructions, enabling dynamic narrative generation and NPC dialogue. A validation system leverages LLM self-reflection to evaluate text inputs against game rules, either generating compliant responses or corrective logic. Context is maintained via a custom memory system combining short-term caching and long-term vector database retrieval with summarization. NPCs are assigned Big 5 personality traits encoded as percentages to bias LLM responses. The system is exposed via a REST API and integrates with game engines through a plugin that injects prompts and parses outputs. Evaluation compared narrative alignment with and without validation on 90 irrelevant inputs across three categories.

## Key Results
- PANGeA's validation system achieved 89/90 correct narrative-aligned responses versus 30/90 without validation.
- Custom memory system maintained context across interactions without exceeding LLM context limits.
- NPCs consistently expressed assigned Big 5 personality traits in generated dialogue.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PANGeA's validation system uses LLM-based self-reflection to evaluate and correct out-of-scope responses before they break narrative coherence.
- Mechanism: The LLM is prompted to first check whether text input violates game rules, then either generate a direct response or produce corrective logic that guides a compliant reply.
- Core assumption: LLMs can reliably interpret their own generated game rules and apply them to judge subsequent inputs.
- Evidence anchors:
  - [abstract] "A novel validation system that uses the LLM's intelligence evaluates text input and aligns generated responses with the unfolding narrative."
  - [section V] "To do this, the LLM is prompted using techniques from self-reflection [30]. First the LLM is prompted to evaluate whether the text input breaks a game play rule."
  - [corpus] Weak; no direct corpus evidence of self-reflection-based validation in game contexts.
- Break condition: If the LLM misinterprets game rules or hallucinates corrections, validation fails and narrative coherence degrades.

### Mechanism 2
- Claim: The custom memory system enables short-term and long-term context retention, preventing LLM hallucinations from exceeding context limits.
- Mechanism: Short-term memories cache recent interactions; long-term memories are stored in a vector database and retrieved via semantic search, then summarized for LLM injection.
- Core assumption: Summaries of retrieved context are sufficient to preserve narrative continuity without overwhelming the LLM's context window.
- Evidence anchors:
  - [abstract] "Making these interactions possible, PANGeA is supported by a server that hosts a custom memory system that supplies context for augmenting generated responses thus aligning them with the procedural narrative."
  - [section V] "The custom memory system enables content generation during game initialization by storing context from each prompt for injection into subsequent prompts."
  - [corpus] Weak; no corpus evidence of vector-db-based summarization for narrative continuity in games.
- Break condition: If summarization loses critical narrative details or semantic search retrieves irrelevant memories, context alignment fails.

### Mechanism 3
- Claim: Personality-biased NPCs are achieved by embedding Big 5 trait percentages into prompts, biasing LLM responses toward defined behavioral profiles.
- Mechanism: During NPC generation, the LLM is instructed to express specific Big 5 traits by percentage, which it then emulates in subsequent dialogue generation.
- Core assumption: LLMs can consistently interpret and express quantified personality traits in generated text.
- Evidence anchors:
  - [abstract] "The NPCs generated by PANGeA are personality-biased and express traits from the Big 5 Personality Model in their generated responses."
  - [section III] "The NPC is assigned a generated Big 5 personality profile, which, as has been shown possible by prior research, biases the LLM's responses by instructing it to emulate personality traits."
  - [corpus] Moderate; corpus neighbors cite research on personality trait emulation in LLMs but not in game NPC contexts.
- Break condition: If the LLM ignores or misinterprets trait percentages, NPC dialogue becomes inconsistent or generic.

## Foundational Learning

- Concept: Self-reflection techniques in LLMs
  - Why needed here: Enables the validation system to let the LLM critique its own outputs against game rules before generating final responses.
  - Quick check question: Can you describe how an LLM might be prompted to "reflect" on whether a text input violates a predefined rule?

- Concept: Vector database semantic search
  - Why needed here: Retrieves relevant long-term memories for NPCs without exceeding context limits, maintaining narrative continuity.
  - Quick check question: What is the difference between semantic search and keyword search in the context of memory retrieval?

- Concept: Personality trait bias in generative models
  - Why needed here: Ensures NPCs consistently express defined Big 5 personality profiles, creating believable and varied interactions.
  - Quick check question: How would you encode a "high agreeableness, low neuroticism" personality profile into an LLM prompt?

## Architecture Onboarding

- Component map:
  - REST API → Behavior Handler → LLM Interface → Validation System
  - Custom Memory System (Short-term cache + Long-term vector DB)
  - Game Engine Plug-in (JSON prompt injection + parsing)
  - Server (local/cloud hosting, OpenAI API compatible)

- Critical path:
  1. Game designer provides high-level criteria
  2. Prompt schema builds JSON instructions
  3. REST call sends to server
  4. Behavior handler routes to LLM
  5. Validation system checks input
  6. Memory system augments context
  7. LLM generates compliant response
  8. Plug-in parses and renders in-game

- Design tradeoffs:
  - Context summarization vs. narrative fidelity: summarization reduces hallucination risk but may lose nuance.
  - Prompt complexity vs. LLM compliance: richer prompts improve alignment but increase failure surface.
  - Memory granularity vs. performance: more detailed memories improve immersion but increase latency.

- Failure signatures:
  - Validation bypass: NPC responds to off-topic input without correction.
  - Context loss: NPC forgets prior events or repeats irrelevant information.
  - Trait drift: NPC personality shifts unexpectedly mid-conversation.

- First 3 experiments:
  1. Test validation with clearly off-topic inputs (e.g., "What's the weather like on Mars?") and verify corrective response.
  2. Test memory retrieval by replaying a prior conversation and checking for relevant context in NPC replies.
  3. Test personality bias by prompting NPCs with varied social stimuli and verifying trait-consistent responses.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the generated NPC personalities and interactions influence player immersion and emotional engagement over extended gameplay sessions?
- Basis in paper: [inferred] The paper mentions that NPCs are "personality-biased" and express Big 5 traits, but does not measure long-term player engagement or emotional response.
- Why unresolved: The study focuses on short-term narrative coherence and alignment, not on measuring player immersion, emotional impact, or sustained engagement over time.
- What evidence would resolve it: Longitudinal user studies tracking player engagement, emotional responses, and immersion levels across multiple gameplay sessions with PANGeA-generated NPCs.

### Open Question 2
- Question: Can PANGeA's validation system be extended to handle real-time collaborative storytelling between multiple players, and how would it manage conflicting narrative inputs?
- Basis in paper: [explicit] The paper describes validation for single-player free-form input but does not address multi-player scenarios or conflict resolution between players.
- Why unresolved: The current validation system is designed for single-player input and does not consider the complexity of multiple players contributing simultaneously to the narrative.
- What evidence would resolve it: Testing PANGeA in a multi-player environment to evaluate how the validation system manages conflicting inputs and maintains narrative coherence across multiple participants.

### Open Question 3
- Question: What are the computational and latency implications of PANGeA’s memory and validation systems when scaled to large, complex game worlds with many NPCs and dynamic events?
- Basis in paper: [inferred] While the paper describes the memory and validation systems, it does not provide performance metrics or discuss scalability challenges in large-scale game environments.
- Why unresolved: The paper demonstrates effectiveness in a demo game but does not explore the performance impact or scalability of the system in more complex, resource-intensive scenarios.
- What evidence would resolve it: Performance benchmarking of PANGeA in large-scale game environments, measuring latency, memory usage, and computational overhead as the number of NPCs and narrative complexity increases.

## Limitations

- Empirical validation limited to single demo game and small fixed input set, raising generalizability concerns.
- Evaluation relies on human judgment without inter-rater reliability reporting, introducing potential subjective bias.
- Validation mechanism depends on LLM self-reflection, which may fail if LLM misinterprets or hallucinates game rules.
- Memory summarization may lose critical narrative details over extended play sessions.
- Personality trait bias encoding is based on prior research not replicated in this work; trait stability over long dialogues is untested.
- REST API integration and plugin architecture details are underspecified, making real-world deployment feasibility uncertain.

## Confidence

- **High confidence**: The core technical contributions (validation system, custom memory, REST API) are clearly described and the ablation test design is sound.
- **Medium confidence**: The reported 89/90 alignment rate is internally consistent but not externally validated; mechanism effectiveness in diverse contexts is uncertain.
- **Low confidence**: Generalizability to other game genres, long-term narrative coherence, and personality trait stability are speculative.

## Next Checks

1. **Cross-game validation**: Deploy PANGeA in at least two additional game genres (e.g., mystery and sci-fi RPG) and evaluate narrative alignment on genre-specific irrelevant inputs to test generalizability.
2. **Long-term memory retention test**: Run a 2-hour continuous play session, logging NPC responses for memory coherence and trait consistency; analyze for context drift or personality instability.
3. **Inter-rater reliability assessment**: Re-run the 90-input evaluation with three independent human raters using a standardized rubric; report Fleiss' kappa to quantify agreement and reduce subjectivity.