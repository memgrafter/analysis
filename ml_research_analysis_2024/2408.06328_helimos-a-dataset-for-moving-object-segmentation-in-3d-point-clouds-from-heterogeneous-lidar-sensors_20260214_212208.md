---
ver: rpa2
title: 'HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From
  Heterogeneous LiDAR Sensors'
arxiv_id: '2408.06328'
source_url: https://arxiv.org/abs/2408.06328
tags:
- lidar
- dataset
- sensors
- points
- moving
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HeLiMOS addresses the lack of a dataset for moving object segmentation
  (MOS) in 3D point clouds captured by heterogeneous LiDAR sensors. The dataset provides
  point-wise MOS labels for sequences acquired by four diverse LiDAR sensors, including
  solid-state types with irregular scanning patterns.
---

# HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors

## Quick Facts
- arXiv ID: 2408.06328
- Source URL: https://arxiv.org/abs/2408.06328
- Authors: Hyungtae Lim; Seoyeon Jang; Benedikt Mersch; Jens Behley; Hyun Myung; Cyrill Stachniss
- Reference count: 36
- Primary result: HeLiMOS provides point-wise MOS labels for sequences from four diverse LiDAR sensors, enabling evaluation of MOS performance across heterogeneous setups.

## Executive Summary
HeLiMOS addresses the lack of a dataset for moving object segmentation (MOS) in 3D point clouds captured by heterogeneous LiDAR sensors. The dataset provides point-wise MOS labels for sequences acquired by four diverse LiDAR sensors, including solid-state types with irregular scanning patterns. The core method involves a novel instance-aware automatic labeling framework that combines topology-based trajectory clustering, instance-aware static map building (ERASOR2), and tracking-based false label filtering to reduce manual annotation effort. The dataset shows significantly higher dynamic point ratios than existing MOS datasets, with substantial variation across sensors and revisited scenes.

## Method Summary
The HeLiMOS dataset is built using an automatic labeling framework that combines topology-based trajectory clustering, instance-aware static map building (ERASOR2), and tracking-based false label filtering. The approach first segments trajectories into clusters prioritizing intersections and revisits, then corrects submap poses within each cluster via ICP to improve alignment before running ERASOR2. ERASOR2 treats each moving object as a single entity by segmenting point clouds into instances and removing dynamic points at the instance level. Tracking-based filtering augments missing detections by interpolating centroids between known frames when tracking is temporarily lost. The resulting dataset contains 12,188 labeled point clouds following SemanticKITTI format.

## Key Results
- MOS performance degrades significantly when models trained on standard datasets are applied to heterogeneous LiDAR setups, with IoU scores ranging from 4.69% to 82.87% depending on sensor type
- The automatic labeling framework achieves F1 scores up to 0.974 on crowded sequences, demonstrating effectiveness in reducing false positives and negatives
- HeLiMOS shows significantly higher dynamic point ratios than existing MOS datasets, with substantial variation across sensors and revisited scenes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The topology-based trajectory clustering reduces false positives in revisited scenes by aligning poses before MOS annotation.
- Mechanism: The approach first segments the trajectory into clusters prioritizing intersections and revisits, then corrects submap poses within each cluster via ICP, producing better alignment before running ERASOR2.
- Core assumption: Pose drift in revisited scenes is the dominant source of false positives; local ICP suffices to correct it.
- Evidence anchors:
  - [abstract] "topology-based trajectory clustering approach and tracking-based false label filtering"
  - [section] "we divide the trajectory with poses corresponding to Pt into multiple clusters and correct their poses to align their reference frames"
  - [corpus] Weak or missing
- Break condition: If ICP fails to converge due to sparse trajectories or large drifts, clustering may not improve alignment and false positives persist.

### Mechanism 2
- Claim: Instance-aware static map building (ERASOR2) reduces false positives by treating each moving object as a single entity.
- Mechanism: ERASOR2 first segments point clouds into instances, then removes dynamic points at the instance level by checking geometric discrepancies between scans and the static map.
- Core assumption: Dynamic points from the same object share coherent geometry, enabling instance-level detection.
- Evidence anchors:
  - [abstract] "our framework exploits an instance-aware static map building approach and tracking-based false label filtering"
  - [section] "ERASOR2 is a cluster-then-detect approach... dynamic point removal at the instance level"
  - [corpus] Weak or missing
- Break condition: If instance segmentation fails (e.g., heavily occluded or crowded scenes), the approach reverts to per-point decisions, increasing false positives.

### Mechanism 3
- Claim: Tracking-based false label filtering reduces both false positives and false negatives by augmenting missing detections.
- Mechanism: Multi-object tracking identifies lost tracks; augmented bounding boxes interpolate centroids between known frames to label missing dynamic points.
- Core assumption: Track continuity is mostly preserved except for brief occlusions or sensor dropouts.
- Evidence anchors:
  - [abstract] "tracking-based false label filtering to reduce false positives and negatives"
  - [section] "we augment additional bounding boxes in the frames where tracking is temporarily lost by interpolating the centroids of bounding boxes tracked in the previous frame and next frame"
  - [corpus] Weak or missing
- Break condition: If tracking fails for extended periods or in highly dynamic crowds, interpolation yields incorrect labels.

## Foundational Learning

- Concept: Point cloud synchronization across heterogeneous sensors
  - Why needed here: MOS must compare motion across different sensor scans; unsynchronized data yields false motion detection.
  - Quick check question: How do you transform point clouds from different sensors into a common reference frame at near-simultaneous timestamps?

- Concept: Instance segmentation in 3D point clouds
  - Why needed here: ERASOR2 relies on per-object clustering to distinguish dynamic from static points; without it, the static map includes dynamic objects.
  - Quick check question: What algorithm (e.g., Euclidean clustering) can segment points into distinct object instances in 3D space?

- Concept: Tracking-based interpolation of object centroids
  - Why needed here: To recover missing detections and reduce false negatives when tracking is temporarily lost.
  - Quick check question: How can you interpolate an object's position between two known frames to create a bounding box in an intermediate frame?

## Architecture Onboarding

- Component map: Data ingestion -> Synchronization -> Trajectory clustering -> Pose correction -> Instance-aware annotation (ERASOR2) -> Tracking-based filtering -> Human refinement -> Label back-propagation
- Critical path: Synchronization -> Trajectory clustering -> Pose correction -> ERASOR2 -> Tracking-based filtering -> Human refinement
- Design tradeoffs: Using ICP for pose correction is fast but may fail on sparse or highly drifted data; ERASOR2 is accurate but slower than point-wise approaches; human refinement ensures quality but adds latency.
- Failure signatures: High false positive rates in revisited scenes indicate poor pose correction; high false negative rates suggest tracking failures; persistent labeling errors after human refinement indicate algorithmic limits.
- First 3 experiments:
  1. Verify trajectory clustering correctly groups revisited segments by visualizing clusters in 2D/3D.
  2. Test ERASOR2 on a crowded sequence to confirm instance-aware dynamic point removal vs. per-point methods.
  3. Validate tracking-based filtering by injecting synthetic occlusions and measuring recovery rate.

## Open Questions the Paper Calls Out
None

## Limitations
- The framework's effectiveness depends heavily on accurate trajectory clustering and pose correction, which may fail in highly dynamic environments or with significant sensor drift.
- The reliance on instance segmentation quality introduces potential failure modes in crowded or occluded scenes where instance segmentation algorithms struggle.
- The dataset's relatively small size (12,188 labeled point clouds) compared to other 3D segmentation datasets may limit generalization to extremely diverse scenarios.

## Confidence

- **High Confidence**: The core dataset collection methodology and the observation that heterogeneous LiDAR sensors show varying dynamic point ratios. The quantitative evidence of MOS performance degradation when models trained on standard datasets are applied to heterogeneous LiDAR setups is well-supported.
- **Medium Confidence**: The effectiveness of the automatic labeling framework (F1 scores up to 0.974) is demonstrated but depends on specific implementation details not fully specified in the paper. The superiority of ERASOR2 over point-wise approaches is supported but may vary with scene complexity.
- **Low Confidence**: The generalizability of the framework to extremely challenging scenarios (e.g., dense crowds, severe occlusions, or extended tracking failures) is not thoroughly evaluated. The long-term stability of the automatic labeling process across diverse environmental conditions remains uncertain.

## Next Checks

1. **Tracking Robustness Test**: Evaluate the tracking-based filtering performance on sequences with extended occlusions and rapid object motion to quantify failure rates and interpolation accuracy under challenging conditions.

2. **Instance Segmentation Stress Test**: Assess ERASOR2's performance on extremely crowded scenes (e.g., busy intersections with 20+ dynamic objects) to identify breakdown points and quantify the impact of instance segmentation failures on overall MOS accuracy.

3. **Cross-Sensor Generalization**: Test the trained MOS models on unseen heterogeneous LiDAR sensor types not included in the training data to evaluate the framework's ability to generalize across sensor modalities and scanning patterns.