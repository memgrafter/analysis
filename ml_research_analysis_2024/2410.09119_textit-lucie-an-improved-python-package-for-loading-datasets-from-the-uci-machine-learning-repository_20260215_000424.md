---
ver: rpa2
title: '$\textit{lucie}$: An Improved Python Package for Loading Datasets from the
  UCI Machine Learning Repository'
arxiv_id: '2410.09119'
source_url: https://arxiv.org/abs/2410.09119
tags:
- datasets
- data
- lucie
- files
- ucimlrepo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: lucie addresses the problem that many UCI Machine Learning Repository
  datasets cannot be imported using the standard ucimlrepo Python package, particularly
  affecting 28.4% of the top 250 datasets due to nonstandard formats. The core method
  is a smart-import tool that automatically detects data formats and imports previously
  non-importable datasets while preserving tabular structure.
---

# $\textit{lucie}$: An Improved Python Package for Loading Datasets from the UCI Machine Learning Repository

## Quick Facts
- arXiv ID: 2410.09119
- Source URL: https://arxiv.org/abs/2410.09119
- Authors: Kenneth Ge; Phuc Nguyen; Ramy Arnaout
- Reference count: 29
- lucie successfully imports 95.4% of previously non-importable datasets vs. 73.1% for ucimlrepo

## Executive Summary
The UCI Machine Learning Repository contains hundreds of datasets, but many cannot be imported using standard Python packages due to nonstandard formats. lucie addresses this gap by automatically detecting data formats and importing previously non-importable datasets while preserving tabular structure. The package achieves a 95.4% success rate on benchmark datasets compared to 73.1% for the standard ucimlrepo package, successfully importing 124 out of 130 test datasets. lucie is available on PyPI with 98% code coverage and maintains compatibility with existing ucimlrepo interfaces.

## Method Summary
lucie is a Python package that uses pattern recognition and multi-strategy parsing to import datasets from the UCI Machine Learning Repository that fail with standard tools. The algorithm identifies common data format patterns from popular datasets and applies appropriate parsing strategies including checking for tabular file extensions, parsing text files with various delimiters, handling nested archives, and custom handling of irregular formats. The package was developed using the top 100 most popular datasets and benchmarked on the next 130, achieving significantly higher success rates than existing solutions.

## Key Results
- 95.4% success rate on datasets ranked 101-250 compared to 73.1% for ucimlrepo
- Successfully imports 124 out of 130 test datasets
- 98% code coverage with comprehensive test suite
- Addresses 28.4% of the top 250 datasets that were previously non-importable

## Why This Works (Mechanism)

### Mechanism 1
- Claim: lucie successfully imports 95.4% of previously non-importable datasets by automatically detecting data formats and handling nonstandard structures.
- Mechanism: The algorithm uses pattern recognition from popular datasets to identify various data formats, then applies appropriate parsing strategies (tabular file extensions, nested archives, text files, extensionless files) to convert them into pandas dataframes.
- Core assumption: Datasets that cannot be imported by ucimlrepo share common patterns that can be programmatically identified and processed.
- Evidence anchors:
  - [abstract] "lucie— load University California Irvine examples—a utility that automatically determines the data format and imports many of these previously non-importable datasets, while preserving as much of a tabular data structure as possible."
  - [section] "We concluded that if these patterns occurred at least once, there was a good chance they would occur again, i.e. in datasets beyond the top 100."
  - [corpus] Weak - only 2 corpus neighbors mention UCI-related datasets (lucie appears in one neighbor title)
- Break condition: If a dataset contains a completely novel format not encountered in the top 100 or test datasets, or if the dataset structure is too irregular to be coerced into tabular format.

### Mechanism 2
- Claim: lucie achieves high success rates by using a multi-strategy approach that progressively attempts more complex parsing methods.
- Mechanism: The algorithm follows a hierarchical approach: first tries built-in ucimlrepo import, then checks for manually cleaned datasets, looks for obvious tabular file extensions, searches for nested archives, attempts to parse text files with various delimiters, and finally tries to coerce irregular structures into tables or JSON format.
- Core assumption: By attempting multiple parsing strategies in order of increasing complexity, the algorithm can handle most dataset formats while minimizing false positives.
- Evidence anchors:
  - [section] "Step 3... we start by looking for any files with extensions that clearly identify them as tabular data... Step 4 If no such files are found, we then look for any nested archives... Step 5 If Step 2 is unsuccessful, we look through all '.txt' files..."
  - [abstract] "The algorithm uses pattern recognition from popular datasets and employs multiple strategies including checking for tabular file extensions, parsing text files, handling nested archives, and custom handling of irregular formats."
  - [corpus] Missing - no corpus evidence about multi-strategy approaches
- Break condition: If all parsing strategies fail or if the dataset is too large (over 100MB) causing timeouts, or if download links are invalid.

### Mechanism 3
- Claim: lucie's high success rate is achieved through extensive testing and coverage, with 98% code coverage and systematic evaluation on benchmark datasets.
- Mechanism: The development team created comprehensive test scripts covering all common dataset types, synthetic test datasets for rare types, and benchmarked the algorithm on datasets ranked 101-250 after development on top 100 datasets.
- Core assumption: Thorough testing and systematic benchmarking ensure reliability and identify edge cases before deployment.
- Evidence anchors:
  - [section] "We also wrote pytest tests scripts, which are included in both the GitHub repository and in the PyPI package... Our tests result in a code-coverage rate of 98%"
  - [section] "lucie's import function returns a dictionary... The flow chart in Fig. 2 provides a more comprehensive view of the logical structure."
  - [abstract] "lucie was designed using the top 100 most popular datasets and benchmarked on the next 130, where it resulted in a success rate of 95.4% vs. 73.1% for ucimlrepo."
- Break condition: If new dataset types are added to UCIMLR that weren't covered in testing, or if the API changes break the import functionality.

## Foundational Learning

- Concept: Pattern recognition in data formats
  - Why needed here: The algorithm relies on identifying common patterns across different dataset formats to determine appropriate parsing strategies
  - Quick check question: What are the four main patterns identified in the top 100 datasets that lucie was designed to handle?

- Concept: Hierarchical algorithm design
  - Why needed here: The multi-step approach ensures that simpler parsing methods are attempted first before moving to more complex ones
  - Quick check question: What is the order of parsing strategies attempted by lucie, from simplest to most complex?

- Concept: Error handling and fallback mechanisms
  - Why needed here: The algorithm needs to gracefully handle failures at each step and provide meaningful output or error messages
  - Quick check question: What does lucie return if it cannot coerce data into a pandas dataframe?

## Architecture Onboarding

- Component map:
  Main import function (lucie.load_uci) -> Pattern recognition module -> Multiple parser modules (tabular, nested archives, text files, extensionless files) -> Test suite (pytest-based with 98% coverage) -> API interface (compatible with ucimlrepo) -> Special case handlers (EEG, Diabetes, Movie, Reuters-21578)

- Critical path:
  1. Check if dataset can be imported via built-in ucimlrepo
  2. Download and extract .zip archive
  3. Identify format patterns and select appropriate parser
  4. Parse data and convert to pandas dataframe
  5. Return structured dictionary of results

- Design tradeoffs:
  - Prioritizes simplicity and compatibility over handling every possible edge case
  - Uses progressive parsing strategies to balance accuracy and performance
  - Focuses on tabular data preservation while maintaining flexibility for irregular formats
  - Trades some specificity for broader applicability across dataset types

- Failure signatures:
  - Returns empty dictionary or None value
  - Crashes during parsing attempts
  - Timeout errors for large datasets (>100MB)
  - Download errors for invalid links
  - False positives where non-data files are interpreted as tabular data

- First 3 experiments:
  1. Test import of a dataset known to fail with ucimlrepo but should succeed with lucie (e.g., UCIMLR ID #5)
  2. Test import of a dataset with nested archives to verify the recursive parsing works correctly
  3. Test import of a dataset with extensionless files to verify the delimiter detection and NaN filtering works as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does lucie's performance scale when applied to datasets beyond the top 250 in popularity?
- Basis in paper: [explicit] The paper states lucie was tested on datasets ranked 101-250 and achieved 95.4% success rate, but does not analyze performance on less popular datasets beyond this range.
- Why unresolved: The paper only provides performance data for the top 250 datasets, leaving open questions about how well the algorithm generalizes to the hundreds of other datasets in the repository that are less frequently accessed.
- What evidence would resolve it: Testing lucie on a representative sample of datasets ranked below 250 (e.g., 251-500 or 501-750) and comparing success rates would determine if performance degrades as dataset popularity decreases.

### Open Question 2
- Question: What is the false positive rate of lucie's data format detection algorithm?
- Basis in paper: [inferred] The paper mentions the algorithm tries to minimize false positives but does not provide quantitative data on how often it incorrectly identifies non-data files as tabular data.
- Why unresolved: While the paper describes the algorithm's approach to reducing false positives, it does not provide empirical data on the actual rate of incorrect identifications, which is critical for assessing reliability.
- What evidence would resolve it: Analyzing a diverse set of datasets to count instances where lucie incorrectly identified non-data files as data would provide a quantitative false positive rate.

### Open Question 3
- Question: How does lucie handle datasets that contain multiple distinct tables or data structures within a single .zip file?
- Basis in paper: [explicit] The paper describes how lucie returns a dictionary with keys representing file names and values being pandas dataframes, but does not discuss scenarios where multiple distinct tables exist.
- Why unresolved: The paper does not provide examples or analysis of how lucie handles complex datasets containing multiple related tables or data structures that might need to be processed together.
- What evidence would resolve it: Testing lucie on datasets known to contain multiple related tables (e.g., relational databases with multiple tables) and analyzing how it identifies and organizes these structures would demonstrate its handling of complex data relationships.

## Limitations
- Algorithm may struggle with completely novel formats not encountered during development
- Performance on datasets beyond the 101-250 range remains untested
- Custom handling of four specific repositories may not generalize to other complex datasets

## Confidence
- **High Confidence**: The reported success rates (95.4% vs 73.1%) are based on systematic benchmarking on a defined dataset range (101-250), and the methodology for calculating these rates is clearly specified.
- **Medium Confidence**: The pattern recognition approach and multi-strategy parsing algorithm are well-described, but their effectiveness on datasets outside the tested range remains unverified.
- **Medium Confidence**: The 98% code coverage claim is supported by test evidence, but coverage doesn't necessarily translate to functional correctness in all real-world scenarios.

## Next Checks
1. Test lucie's performance on UCI datasets ranked below 250 to assess generalization beyond the benchmarked range, particularly focusing on datasets with complex nested structures or unusual file formats.
2. Evaluate lucie's error handling and fallback mechanisms by intentionally providing corrupted or incomplete dataset archives to verify graceful failure modes and meaningful error messages.
3. Benchmark lucie against other UCI data loading tools (beyond ucimlrepo) on a diverse set of dataset types to establish comparative performance across different data formats and complexity levels.