---
ver: rpa2
title: Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot
arxiv_id: '2410.22767'
source_url: https://arxiv.org/abs/2410.22767
tags:
- dialogue
- state
- prompt
- tracking
- slot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an ontology-free dialogue state tracking
  (DST) approach for goal-oriented chatbots, addressing the limitations of fixed ontologies
  in open-domain dialogues. The method leverages instruction tuning and advanced prompt
  strategies, including Chain-of-Thought reasoning and anti-hallucination mechanisms,
  to enable Large Language Models (LLMs) to dynamically infer dialogue states without
  predefined slot values.
---

# Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot

## Quick Facts
- arXiv ID: 2410.22767
- Source URL: https://arxiv.org/abs/2410.22767
- Reference count: 40
- One-line primary result: Achieved 42.57% Joint Goal Accuracy on MultiWOZ2.0 without predefined ontologies

## Executive Summary
This paper introduces an ontology-free dialogue state tracking (DST) approach for goal-oriented chatbots, addressing the limitations of fixed ontologies in open-domain dialogues. The method leverages instruction tuning and advanced prompt strategies, including Chain-of-Thought reasoning and anti-hallucination mechanisms, to enable Large Language Models (LLMs) to dynamically infer dialogue states without predefined slot values. Additionally, a Variational Graph Auto-Encoder (VGAE) is employed to model and predict subsequent user intents by representing dialogue states as graphs. The approach achieved state-of-the-art performance with a Joint Goal Accuracy (JGA) of 42.57% on MultiWOZ2.0, outperforming existing ontology-less DST models. It also demonstrated strong adaptability to open-domain real-world conversations, validating its effectiveness in diverse dialogue contexts.

## Method Summary
The approach combines instruction-tuned LLMs with VGAE for ontology-free DST. First, LLaMA3-8B is fine-tuned using instruction tuning on MultiWOZ2.0, MultiWOZ2.4, and Schema-Guided Dialogue datasets. Advanced prompt strategies including Chain-of-Thought reasoning, persona assignment, and anti-hallucination mechanisms guide the LLM in extracting domains, slots, and values. The extracted dialogue states are then represented as graphs, with edges indicating relationships between slot-value pairs. A Variational Graph Auto-Encoder models these graphs to predict subsequent user intents through link prediction. The system achieves zero-shot inference without predefined ontologies, making it adaptable to open-domain conversations.

## Key Results
- Achieved 42.57% Joint Goal Accuracy on MultiWOZ2.0, surpassing existing ontology-less DST models
- Demonstrated strong performance on open-domain Persona-Chat dataset (30 dialogues)
- VGAE improved link prediction with AUC and AP metrics for subsequent intent prediction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large Language Models (LLMs) can infer dialogue states without predefined ontologies by using instruction tuning and advanced prompt strategies.
- Mechanism: The LLM is fine-tuned through instruction tuning, which provides explicit and precise instructions, enabling it to accurately extract domains, slots, and values across various contexts. This is complemented by prompt strategies like Chain-of-Thought (CoT) reasoning, which guides the LLM through intermediate reasoning steps, improving its ability to handle complex tasks and understand user intentions. Additionally, an anti-hallucination mechanism is incorporated to prevent the model from producing inappropriate slot values in cases where no valid ontology-free options exist.
- Core assumption: The LLM's pre-trained knowledge is sufficient to infer dialogue states dynamically without relying on predefined schemas, and that carefully designed prompts can effectively replace the role of ontologies.
- Evidence anchors:
  - [abstract]: "We propose a novel approach that leverages instruction tuning and advanced prompt strategies to enhance DST performance, without relying on any predefined ontologies."
  - [section]: "To improve LLM’s DST reasoning without relying on an ontology, we performed instruction tuning. Our approach provides the model with explicit and precise instructions, enabling it to accurately extract domains, slots, and values across various contexts."
  - [corpus]: Weak evidence; the corpus contains related work but no direct evidence of ontology-free DST using instruction tuning and prompt strategies.
- Break condition: If the LLM's pre-trained knowledge is insufficient for the specific domain or if the prompts fail to capture the necessary context for accurate dialogue state inference.

### Mechanism 2
- Claim: Variational Graph Auto-Encoder (VGAE) can model and predict subsequent user intents by representing dialogue states as graphs.
- Mechanism: After extracting dialogue states using the LLM, a graph is constructed from the domains and slot-value pairs, with edges indicating their relationships. The VGAE is then used to generate latent representations of these subgraphs, which are decoded to predict the most likely candidate dialogue states for the user's subsequent utterances. This approach allows for reasoning over subgraphs corresponding to user intents and predicting the next dialogue state based on the user's utterance.
- Core assumption: The dialogue states can be effectively represented as a graph structure, and that the VGAE can capture the latent relationships between nodes (i.e., slot-value pairs) to predict new slot-value relationships.
- Evidence anchors:
  - [abstract]: "Additionally, we employ a Variational Graph Auto-Encoder (VGAE) to model and predict subsequent user intent. Our approach achieved state-of-the-art with a JGA of 42.57%, surpassing existing ontology-less DST models, and performed well in open-domain real-world dialogue data."
  - [section]: "To further enhance dialogue state prediction, we employ a Variational Graph Auto-Encoder (VGAE) to represent dialogue states as graphs. This allows us to reason over subgraphs corresponding to user intents and predict the next dialogue state based on the user’s utterance."
  - [corpus]: Weak evidence; the corpus contains related work on GNNs but no direct evidence of VGAE being used for dialogue state prediction.
- Break condition: If the graph representation of dialogue states fails to capture the necessary relationships or if the VGAE cannot effectively learn from the graph structure to predict new slot-value relationships.

### Mechanism 3
- Claim: The combination of LLM-based prompting and VGAE allows for accurate dialogue state tracking in open-domain and real-world conversations without relying on predefined ontologies.
- Mechanism: The LLM-based approach, enhanced by instruction tuning and prompt strategies, dynamically infers dialogue states without predefined ontologies. The VGAE then models these inferred states as graphs, predicting subsequent user intents. This combination enables the system to adapt to diverse and dynamic dialogue contexts, making it suitable for open-domain and real-world conversations where topics are unpredictable and diverse.
- Core assumption: The LLM can effectively infer dialogue states in open-domain conversations, and the VGAE can accurately model and predict subsequent user intents based on these inferred states.
- Evidence anchors:
  - [abstract]: "Our approach achieved state-of-the-art with a JGA of 42.57%, surpassing existing ontology-less DST models, and performed well in open-domain real-world dialogue data."
  - [section]: "Our approach achieves state-of-the-art performance with a JGA of 42.57%, surpassing existing ontology-less DST models and demonstrating strong performance on open-domain real-world dialogue data."
  - [corpus]: Weak evidence; the corpus contains related work on open-domain dialogues but no direct evidence of combining LLM-based prompting with VGAE for dialogue state tracking.
- Break condition: If the LLM fails to infer dialogue states accurately in open-domain conversations or if the VGAE cannot effectively model and predict subsequent user intents based on these inferred states.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GNNs are used to model and predict subsequent user intents by representing dialogue states as graphs. They allow for reasoning over subgraphs corresponding to user intents and predicting the next dialogue state based on the user's utterance.
  - Quick check question: How do GNNs differ from traditional neural networks, and why are they particularly suited for modeling graph-structured data like dialogue states?

- Concept: Variational Auto-Encoders (VAEs)
  - Why needed here: VAEs are used to generate latent representations of the subgraphs corresponding to user intents, which are then decoded to predict the most likely candidate dialogue states for the user's subsequent utterances.
  - Quick check question: What is the role of the evidence lower bound (ELBO) in training VAEs, and how does it contribute to the model's ability to generate meaningful latent representations?

- Concept: Chain-of-Thought (CoT) Reasoning
  - Why needed here: CoT reasoning is used to guide the LLM through intermediate reasoning steps, improving its ability to handle complex tasks and understand user intentions. This is crucial for accurately inferring dialogue states without relying on predefined ontologies.
  - Quick check question: How does CoT reasoning enhance the LLM's ability to infer dialogue states, and what are some potential limitations of this approach?

## Architecture Onboarding

- Component map: Instruction Tuning -> Prompt Strategy -> Dialogue State Extraction -> Graph Construction -> VGAE

- Critical path:
  1. Instruction Tuning: Fine-tune the LLM to follow explicit instructions.
  2. Prompt Strategy: Design prompts using techniques like CoT reasoning and anti-hallucination mechanisms.
  3. Dialogue State Extraction: Use the fine-tuned LLM and designed prompts to infer dialogue states.
  4. Graph Construction: Represent the extracted dialogue states as a graph.
  5. VGAE: Model and predict subsequent user intents using the graph structure.

- Design tradeoffs:
  - Ontology-Free vs. Ontology-Based: The ontology-free approach offers flexibility and adaptability to open-domain conversations but may struggle with tracking non-existent values and synonym tracking.
  - LLM-Based vs. Traditional Methods: LLM-based methods offer higher performance and adaptability but require more computational resources and may be prone to hallucinations.
  - VGAE vs. Other GNNs: VGAE offers superior performance in predicting dialogue states but may be more complex to implement and train compared to other GNNs.

- Failure signatures:
  - Low JGA or slot F1 scores: Indicates that the LLM is not effectively inferring dialogue states or that the VGAE is not accurately modeling and predicting subsequent user intents.
  - High hallucination rate: Indicates that the anti-hallucination mechanism is not effectively preventing the LLM from producing inappropriate slot values.
  - Poor performance on open-domain conversations: Indicates that the model is not effectively adapting to diverse and dynamic dialogue contexts.

- First 3 experiments:
  1. Evaluate the impact of different prompt strategies (e.g., CoT, CoT with persona, SELF-DISCOVER, ToT) on dialogue state inference accuracy.
  2. Compare the performance of VGAE with other GNNs (e.g., GAT, GraphSAGE, GIN) in predicting subsequent user intents.
  3. Test the model's performance on open-domain conversations and real-world data to assess its adaptability and generalizability.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ontology-free DST compare to ontology-based approaches in domains with highly variable slot values?
- Basis in paper: [explicit] The paper states that their ontology-free approach achieved a JGA of 42.57% on MultiWOZ 2.0, outperforming existing ontology-less DST models. However, it does not provide a direct comparison to ontology-based models on the same dataset.
- Why unresolved: The paper focuses on comparing their approach to other ontology-less models and few-shot methods, but does not include a direct comparison to traditional ontology-based DST models.
- What evidence would resolve it: A direct comparison of JGA scores between the ontology-free approach and a state-of-the-art ontology-based DST model on the same dataset (e.g., MultiWOZ 2.0) would provide a clearer picture of the relative performance.

### Open Question 2
- Question: How does the anti-hallucination mechanism affect the model's ability to handle unseen domains or novel slot values?
- Basis in paper: [explicit] The paper introduces an anti-hallucination mechanism to prevent the model from producing inappropriate slot values when no valid ontology-free options exist. It mentions that this technique improved the F1 score by up to 20%.
- Why unresolved: While the paper demonstrates the effectiveness of the anti-hallucination mechanism in improving performance, it does not specifically test its impact on handling unseen domains or novel slot values.
- What evidence would resolve it: Evaluating the model's performance on a dataset with unseen domains or novel slot values, with and without the anti-hallucination mechanism, would quantify its impact on handling such scenarios.

### Open Question 3
- Question: What is the impact of the persona pattern on the model's performance across different dialogue domains?
- Basis in paper: [explicit] The paper finds that the CoT with persona pattern had the highest JGA value across all conditions and achieved the highest slot F1 score. It mentions that variations of the persona pattern can be found in Appendix A.
- Why unresolved: The paper does not provide a detailed analysis of how the persona pattern affects performance across different dialogue domains. It only presents overall performance metrics.
- What evidence would resolve it: Analyzing the model's performance on different dialogue domains (e.g., restaurant, hotel, attraction) with and without the persona pattern would reveal its domain-specific impact.

## Limitations
- Computational overhead and inference latency compared to traditional ontology-based systems
- Limited evaluation on Persona-Chat (only 30 dialogues) for real-world generalization
- VGAE component requires careful hyperparameter tuning and may struggle with scalability

## Confidence
- **High Confidence**: Core claim of LLM-based DST without ontologies is well-supported by 42.57% JGA on MultiWOZ2.0
- **Medium Confidence**: VGAE effectiveness is moderately supported but evaluation metrics don't directly measure DST performance
- **Low Confidence**: Anti-hallucination mechanism effectiveness is primarily theoretical with minimal quantitative evaluation

## Next Checks
1. **Ablation Study on Prompt Strategies**: Systematically test the contribution of each prompt component (CoT, persona, anti-hallucination) by removing them individually and measuring the impact on JGA and hallucination rates.

2. **Cross-Domain Generalization Test**: Evaluate the model on dialogue datasets from completely different domains (e.g., medical consultations, technical support) to assess whether the ontology-free approach truly generalizes beyond the training domains of MultiWOZ and SGD.

3. **Scalability Analysis**: Test the VGAE component on progressively larger dialogue graphs (synthetic scaling tests) to determine at what point the graph representation becomes computationally intractable or loses predictive accuracy.