---
ver: rpa2
title: What is Meant by AGI? On the Definition of Artificial General Intelligence
arxiv_id: '2404.10731'
source_url: https://arxiv.org/abs/2404.10731
tags:
- intelligence
- general
- nition
- cial
- arti
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper aims to clarify the definition of Artificial General
  Intelligence (AGI) by establishing a minimal consensus on its key aspects. The author
  proposes that general intelligence is the capability to adapt to open environments
  according to certain principles using limited resources, emphasizing that adaptation
  or learning is indispensable.
---

# What is Meant by AGI? On the Definition of Artificial General Intelligence

## Quick Facts
- arXiv ID: 2404.10731
- Source URL: https://arxiv.org/abs/2404.10731
- Authors: Bowen Xu
- Reference count: 17
- One-line primary result: Proposes a minimal consensus definition of AGI centered on adaptation to open environments under limited resources

## Executive Summary
This paper addresses the ambiguity surrounding the definition of Artificial General Intelligence (AGI) by proposing a minimal consensus framework. The author argues that general intelligence should be defined as the capability to adapt to open environments according to certain principles using limited resources, with adaptation being an indispensable property. The controversial aspects of AGI are placed within the principles of intelligence, which can be described from different perspectives (neuroscience, cognitive science, or computer science). The paper distinguishes between narrow AI systems that solve specific problems and true AGI systems that can adapt to novel, unforeseen environments.

## Method Summary
This is a theoretical and philosophical work that synthesizes existing ideas to propose a unified definition of AGI. The paper does not involve experimental methods or training procedures but instead reviews previous AI research, including Machine Learning methods, and draws on concepts from cognitive science, neuroscience, and computer science. The approach involves establishing a minimal consensus definition that separates adaptation (consensus) from principles (controversial), allowing researchers from different backgrounds to agree on core aspects while leaving room for debate on implementation details.

## Key Results
- Proposes three definitions: intelligence as adaptation with limited resources, general intelligence as adaptation to open environments with principles PG, and AGI as a computer satisfying these criteria
- Identifies adaptation to open environments as the indispensable property of intelligence, distinguishing it from problem-solving capability
- Places the controversial aspects within the set of principles PG, which can be described via different formal languages without invalidating the core definition
- Argues that current ML systems exhibit intelligence only in training stages, not in test stages, highlighting the gap between existing systems and true AGI

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The paper's definition of AGI centers on adaptation to open environments under limited resources, which distinguishes it from narrow AI and general algorithms.
- Mechanism: The definition combines two necessary conditions—open environment adaptability and resource limitation—to create a minimal consensus that excludes systems that solve specific problems without learning.
- Core assumption: Adaptation is an indispensable property of intelligence (Axiom 1), and any intelligent system must operate under resource constraints (Axiom 2).
- Evidence anchors:
  - [abstract] General intelligence refers to the adaptation to open environments according to certain principles using limited resources.
  - [section 3.3] Definition 3 From one perspective, intelligence is the capability for an information system to adapt to the open environment with limited computational resources.
  - [corpus] Average neighbor FMR=0.474, suggesting moderate relevance of surrounding papers.
- Break condition: If a system can solve a wide range of problems without demonstrating adaptation (e.g., a general-purpose solver that doesn't learn), the definition would exclude it, which may conflict with some operational definitions of AGI.

### Mechanism 2
- Claim: The controversial part of AGI is not adaptation or resource limitation, but the set of principles PG that describe how intelligence works.
- Mechanism: By separating adaptation (consensus) from principles (controversial), the paper allows researchers from different backgrounds to agree on a minimal definition while leaving room for debate on implementation details.
- Core assumption: Different perspectives (neuroscience, cognitive science, computer science) can describe intelligence principles using different formal languages without invalidating the core definition.
- Evidence anchors:
  - [abstract] It emphasizes that adaptation or learning is an indispensable property of intelligence, and places the controversial part within the principles of intelligence, which can be described from different perspectives.
  - [section 3.4] Researchers usually design their systems or methods in detail, however, some general principles should be finally extracted from their works, helping humanity to understand intelligence, especially how our mind works.
  - [corpus] No corpus evidence found for principle-based disagreements, indicating this may be a theoretical rather than empirical controversy.
- Break condition: If future consensus emerges on what principles constitute intelligence, the controversial aspect may dissolve, requiring the definition to evolve.

### Mechanism 3
- Claim: Current ML systems exhibit intelligence in training but not in test stages, highlighting the gap between existing systems and true AGI.
- Mechanism: The paper distinguishes between systems that learn during development versus systems that can adapt to new, unforeseen environments after deployment.
- Core assumption: True intelligence requires the ability to handle open environments where future situations may not match past experiences.
- Evidence anchors:
  - [section 3.1] Typical ML systems work in the second way, however, we can say that typical ML systems exhibit intelligence in the training stage but no intelligence in the test stage.
  - [section 3.3] With limited resources, faced with an open environment, the knowledge and resources of an intelligent agent are insufficient.
  - [corpus] Weak corpus evidence for this specific claim about ML systems.
- Break condition: If ML systems develop genuine adaptation capabilities that extend beyond their training data without human intervention, this mechanism would no longer hold.

## Foundational Learning

- Concept: Adaptation as a core property of intelligence
  - Why needed here: The paper explicitly makes adaptation a necessary condition for intelligence, distinguishing it from mere problem-solving capability.
  - Quick check question: Can a system that cannot adapt to environmental changes still be considered intelligent under this definition?

- Concept: Open environment versus closed environment
  - Why needed here: The definition specifies adaptation to open environments, which have unknown boundaries and changing conditions, not just predefined problem sets.
  - Quick check question: How does an open environment differ from a closed environment in terms of the challenges it presents to an intelligent system?

- Concept: Limited resources as a theoretical constraint
  - Why needed here: The paper argues that resource limitation is not just practical but theoretically necessary for intelligence, affecting how systems must prioritize and forget information.
  - Quick check question: Why might infinite resources undermine the development of truly intelligent systems?

## Architecture Onboarding

- Component map: Adaptation module -> Resource management module -> Principles implementation layer
- Critical path: System detects environmental changes -> Assesses resource availability -> Executes adaptation strategies while maintaining coherence with intelligence principles
- Design tradeoffs: Prioritizing adaptation speed may conflict with thorough learning, while strict resource limitations may prevent solving complex problems that require substantial computational power
- Failure signatures: Systems that perform well on training data but fail catastrophically on novel inputs, or systems that cannot operate within resource constraints
- First 3 experiments:
  1. Test system adaptation to gradually changing environments where past strategies become less effective over time
  2. Evaluate resource-constrained learning by progressively reducing available memory and observing adaptation quality
  3. Assess open environment handling by introducing completely novel problem types that were not represented in training data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the minimal set of principles PG that defines general intelligence?
- Basis in paper: [explicit] The paper states that the controversial part is on the set of principles PG, which can be described via neuroscience, cognitive science, or computer science languages.
- Why unresolved: Different researchers with various backgrounds describe PG with different scopes and formal languages, leading to disagreements on what principles should be included.
- What evidence would resolve it: A consensus reached by the AGI community through rigorous debates and empirical testing of proposed principles across different AGI systems.

### Open Question 2
- Question: How can we distinguish between "artificial" and "non-artificial" intelligence, especially in the context of biotechnology and biological computers?
- Basis in paper: [explicit] The paper discusses difficulties in defining "artificial" intelligence, especially when considering bio-computers and intelligent life produced in test tubes.
- Why unresolved: The concept of "artificial" becomes blurred when intelligence emerges from artificial neural networks or biotechnology, making it hard to distinguish from naturally occurring intelligence.
- What evidence would resolve it: A clear, universally accepted definition of "artificial" that can be applied consistently across different forms of intelligence, including those created through biotechnology.

### Open Question 3
- Question: What is the relationship between problem-solving capability and adaptation in defining intelligence?
- Basis in paper: [explicit] The paper argues that while problem-solving is a result of adaptation, stressing adaptation in the definition is more instructive than focusing solely on problem-solving.
- Why unresolved: There is ongoing debate about whether intelligence should be defined primarily by its problem-solving capability or by its adaptability to open environments.
- What evidence would resolve it: Empirical studies demonstrating that systems with strong adaptive capabilities consistently outperform those focused solely on problem-solving across a wide range of tasks and environments.

## Limitations

- The paper lacks operational criteria for measuring "open environments" and does not provide specific principles PG that would make the definition complete
- Claims about ML systems only exhibiting intelligence during training but not testing are based on theoretical reasoning rather than empirical validation
- The theoretical nature of the work means it lacks experimental validation or concrete implementation guidelines

## Confidence

- High: Adaptation as necessary property of intelligence
- Medium: Resource limitation as theoretical constraint
- Low: Claims about ML systems' intelligence limitations

## Next Checks

1. Operationalize "open environment" with measurable metrics and test existing AI systems against these criteria
2. Conduct experiments comparing system performance on training data versus novel test scenarios to empirically validate claims about ML limitations
3. Survey AGI researchers to identify which specific principles should be included in PG and assess agreement levels across different research communities