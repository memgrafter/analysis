---
ver: rpa2
title: Interactive Topic Models with Optimal Transport
arxiv_id: '2406.19928'
source_url: https://arxiv.org/abs/2406.19928
tags:
- topic
- edtm
- modeling
- topics
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents EDTM, an interactive topic modeling framework
  that leverages label names as a flexible form of supervision. EDTM frames topic
  modeling as an optimal transport assignment problem, using LM/LLM-based document-topic
  affinities and optimal transport for globally coherent assignments.
---

# Interactive Topic Models with Optimal Transport

## Quick Facts
- arXiv ID: 2406.19928
- Source URL: https://arxiv.org/abs/2406.19928
- Reference count: 16
- Primary result: EDTM uses optimal transport to improve topic modeling by leveraging LM/LLM document-topic affinities and global optimization

## Executive Summary
This paper introduces EDTM, an interactive topic modeling framework that leverages label names as supervision through an optimal transport assignment framework. EDTM treats topic modeling as an assignment problem where document-topic affinities are computed using LM/LLM models, and optimal transport algorithms find globally coherent topic assignments. The framework is robust to noisy analyst inputs and can incorporate various forms of feedback including label names, descriptions, and seed documents. Experiments on four diverse datasets show EDTM induces high-quality topics comparable to large-scale LLMs while using smaller, more efficient models.

## Method Summary
EDTM frames topic modeling as an optimal transport assignment problem where documents are assigned to topics based on computed affinities. The method uses LM/LLM models to score document-topic relationships, then applies optimal transport algorithms to find globally coherent assignments. Two variants are explored: complete assignment (all documents assigned) and partial assignment (only high-confidence assignments made). The framework supports both bi-encoder (faster, lower quality) and cross-encoder (slower, higher quality) architectures for computing affinities. Post-processing hardens soft assignments into discrete topic labels, with unassigned documents handled through batch processing or zero-weight topics.

## Key Results
- EDTM matches or exceeds performance of few-shot LLM classifiers, clustering, and LDA methods on P1 and MI metrics
- Cross-encoder EDTM approaches TopicGPT performance while using smaller models
- EDTM shows robustness to noisy analyst inputs through partial assignment mechanism
- The framework successfully incorporates various analyst feedback types including label names, descriptions, and seed documents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EDTM improves topic coherence by leveraging joint document-topic assignment through optimal transport rather than greedy nearest-neighbor matching.
- Mechanism: Optimal transport computes a globally coherent assignment matrix that minimizes the total cost of assigning documents to topics, considering all pairwise affinities simultaneously rather than making local greedy decisions.
- Core assumption: The document-topic affinities computed by the LM/LLM models are meaningful and capture semantic relationships that can be globally optimized.
- Evidence anchors:
  - [abstract] "EDTM models topic modeling as an assignment problem while leveraging LM/LLM based document-topic affinities and using optimal transport for making globally coherent topic-assignments"
  - [section 3.1] "optimal transport algorithms allow assignment decisions to be made in a globally coherent manner and naturally incorporate document-topic affinities from expressive LLM scoring functions"
- Break condition: If the document-topic affinities are noisy or don't capture meaningful semantic relationships, the global optimization will produce suboptimal assignments.

### Mechanism 2
- Claim: EDTM's use of partial assignments makes it robust to noisy or incomplete analyst inputs by allowing high-cost assignments to be excluded.
- Mechanism: The partial assignment formulation in optimal transport allows EDTM to exclude assignments where the cost is too high, effectively handling cases where analysts provide incorrect or incomplete topic labels.
- Core assumption: Some documents will have high affinity to provided topics while others won't, and the partial assignment can identify and exclude the latter group.
- Evidence anchors:
  - [abstract] "Further, we show EDTM’s ability to incorporate various forms of analyst feedback and while remaining robust to noisy analyst inputs"
  - [section 3.1] "Partial assignment requires only a fraction p < 1 of the source or target points to be assigned" and "points which don’t receive assignments represent high-cost topic assignments which are unlikely to receive accurate assignments"
- Break condition: If all document-topic affinities are moderate (neither clearly high nor clearly low), the partial assignment won't effectively distinguish between good and bad assignments.

### Mechanism 3
- Claim: EDTM achieves comparable performance to large-scale LLMs while using smaller, more efficient models by leveraging optimal transport's ability to make globally coherent assignments from local affinity scores.
- Mechanism: By computing document-topic affinities with smaller, efficient models and then globally optimizing assignments, EDTM can achieve performance similar to approaches using large, expensive LLMs for both affinity computation and assignment.
- Core assumption: The global optimization can compensate for the potentially lower quality of affinities computed by smaller models.
- Evidence anchors:
  - [abstract] "In experiments, we show the efficacy of our framework compared to few-shot LLM classifiers, and topic models based on clustering and LDA"
  - [section 4.2] "EDTMCE approaches the performance of TopicGPT in Bills, Bookgenome, and Twitter indicating its ability to induce high quality clusters at par with large scale LLMs while adhering to analyst provided topic labels"
- Break condition: If the smaller models' affinities are too poor, the global optimization cannot compensate, and performance will degrade significantly.

## Foundational Learning

- Concept: Optimal transport theory and its application to assignment problems
  - Why needed here: EDTM's core innovation relies on formulating topic modeling as an optimal transport problem, requiring understanding of how optimal transport algorithms work and how they can be applied to text data
  - Quick check question: How does the entropy-regularized optimal transport formulation differ from the original formulation, and why is it preferred for large-scale applications?

- Concept: Cross-encoder vs bi-encoder architectures for text similarity
  - Why needed here: EDTM uses both cross-encoders and bi-encoders to compute document-topic affinities, requiring understanding of when each architecture is appropriate and how they differ in computational cost and quality
  - Quick check question: What are the trade-offs between using a bi-encoder (faster but potentially lower quality) versus a cross-encoder (slower but higher quality) for computing document-topic affinities?

- Concept: Clustering evaluation metrics (P1, MI) and their interpretation
  - Why needed here: EDTM is evaluated using extrinsic clustering metrics, requiring understanding of what these metrics measure and how to interpret them in the context of topic modeling
  - Quick check question: Why does the paper choose P1 and MI over other metrics like NMI or ARI, and what specific aspects of clustering quality do these metrics capture?

## Architecture Onboarding

- Component map: Document preprocessing -> Affinity computation (bi-encoder/cross-encoder) -> Optimal transport assignment -> Hardening assignments -> Evaluation
- Critical path: Document-topic affinity computation → Optimal transport assignment → Hardening assignments → Evaluation
- Design tradeoffs:
  - Bi-encoder vs cross-encoder: speed vs quality trade-off
  - Complete vs partial assignment: ensuring all documents get assigned vs robustness to noise
  - Batch processing: scalability vs potential loss of global coherence across batches
  - Single vs multi-topic assignments: simplicity vs capturing document complexity
- Failure signatures:
  - Poor P1/MI scores despite reasonable affinity computation: suggests issues with optimal transport parameters or formulation
  - Extremely imbalanced assignments (most documents to one topic): suggests affinity computation issues or inappropriate regularization
  - Slow performance on large datasets: suggests need for better batching or approximation strategies
  - Inconsistent results across runs: suggests need for better initialization or deterministic processing
- First 3 experiments:
  1. Implement basic bi-encoder affinity computation and complete optimal transport assignment on a small dataset, verify P1/MI scores
  2. Add cross-encoder affinity computation and compare performance against bi-encoder baseline
  3. Implement partial assignment and test robustness by removing topic labels from the label set

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation framework relies entirely on extrinsic clustering metrics without qualitative analysis of topic quality
- The paper minimally tests robustness to noisy analyst inputs despite claiming robustness to various feedback types
- Computational complexity of cross-encoder approach is not thoroughly analyzed with detailed benchmarks

## Confidence
**High Confidence**: The core mechanism of using optimal transport for globally coherent topic assignments is well-supported by the theoretical framework and mathematical formulation. The partial assignment approach for handling noisy inputs is clearly articulated and supported by experimental evidence.

**Medium Confidence**: The claims about EDTM's ability to match or exceed large-scale LLM performance using smaller models are supported by the experimental results, but the evaluation is limited to specific datasets and metrics. The robustness claims to various feedback types need more extensive validation.

**Low Confidence**: The paper's claims about handling diverse analyst feedback types (beyond label names) are minimally supported by the experimental evidence. The scalability analysis for the cross-encoder approach lacks detailed benchmarks and approximation strategies.

## Next Checks
1. **Qualitative Analysis Validation**: Conduct a human evaluation study where domain experts assess the interpretability and quality of topics induced by EDTM compared to baseline methods, using both synthetic and real-world datasets.

2. **Robustness Testing**: Design a systematic experiment varying the noise level in analyst inputs (from 0% to 50% incorrect labels) and measure EDTM's performance degradation curve, comparing it against baseline methods' robustness.

3. **Scalability Benchmarking**: Implement and benchmark approximation strategies for the cross-encoder approach (e.g., using document embeddings instead of full cross-encodings for large datasets) and measure the trade-off between computational cost and clustering quality across datasets of increasing size.