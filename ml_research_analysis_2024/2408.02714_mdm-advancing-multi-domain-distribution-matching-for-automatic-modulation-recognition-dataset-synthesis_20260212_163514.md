---
ver: rpa2
title: 'MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation
  Recognition Dataset Synthesis'
arxiv_id: '2408.02714'
source_url: https://arxiv.org/abs/2408.02714
tags:
- dataset
- synthetic
- domain
- signal
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Automatic Modulation Recognition
  (AMR) in deep learning by introducing a novel dataset distillation method called
  Multi-domain Distribution Matching (MDM). MDM transforms time-domain signals into
  the frequency domain using Discrete Fourier Transform (DFT) and integrates information
  from both domains to distill synthetic datasets.
---

# MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis

## Quick Facts
- **arXiv ID**: 2408.02714
- **Source URL**: https://arxiv.org/abs/2408.02714
- **Authors**: Dongwei Xu; Jiajun Chen; Yao Lu; Tianhao Xia; Qi Xuan; Wei Wang; Yun Lin; Xiaoniu Yang
- **Reference count**: 21
- **Primary result**: Multi-domain Distribution Matching (MDM) achieves better classification accuracy on AMR datasets compared to baseline methods while maintaining strong cross-architecture generalization

## Executive Summary
This paper addresses the challenge of Automatic Modulation Recognition (AMR) in deep learning by introducing a novel dataset distillation method called Multi-domain Distribution Matching (MDM). MDM transforms time-domain signals into the frequency domain using Discrete Fourier Transform (DFT) and integrates information from both domains to distill synthetic datasets. The method combines distribution matching losses from time and frequency domains to update the synthetic dataset. Experiments on three AMR datasets show that MDM outperforms baseline methods, achieving better classification accuracy under similar compression ratios. Additionally, cross-architecture generalization experiments demonstrate that MDM's synthetic datasets generalize well on unseen model architectures.

## Method Summary
MDM is a dataset distillation method that compresses large AMR training datasets into smaller synthetic datasets while maintaining classification performance. The method uses Discrete Fourier Transform (DFT) to convert time-domain I/Q channel signals to frequency domain, then computes distribution matching losses in both domains using Maximum Mean Discrepancy (MMD). A tunable hyperparameter α balances the contribution of time and frequency domain losses. The synthetic dataset is updated via gradient descent to minimize the combined loss. After distillation, the synthetic dataset is used to train various AMR models, with experiments showing superior performance compared to baselines and strong cross-architecture generalization across five different neural network architectures.

## Key Results
- MDM outperforms baseline dataset distillation methods on three AMR datasets (RML2016.10a-high, RML2016.10a, and Sig2019-12-high) with better classification accuracy under similar compression ratios
- Cross-architecture generalization experiments show MDM's synthetic datasets perform well on unseen model architectures including AlexNet, 1D-ResNet, 2D-CNN, VGG16, and MCLDNN
- The synthetic datasets trained on AlexNet and VGG16 achieve best performance on AlexNet while maintaining strong results on other architectures, indicating robust cross-model generalization

## Why This Works (Mechanism)

### Mechanism 1
MDM captures complementary time-frequency domain information by integrating DFT-transformed signals with time-domain signals. MDM computes distribution matching losses in both time and frequency domains, then combines them to update synthetic dataset. The frequency domain representation exposes spectral features while time domain retains temporal dynamics. Core assumption: Signal modulation characteristics are sufficiently captured in both domains, and combining them yields better synthetic dataset than either domain alone.

### Mechanism 2
Distribution matching in MDM effectively preserves the statistical structure of the original dataset in synthetic samples. MDM uses Maximum Mean Discrepancy (MMD) to measure the distance between real and synthetic dataset distributions in embedded feature space. This ensures synthetic samples maintain the same distribution characteristics as real data. Core assumption: MMD provides a meaningful distance metric for signal distributions, and minimizing this distance preserves classification-relevant features.

### Mechanism 3
MDM achieves better cross-architecture generalization because the synthetic dataset captures fundamental signal characteristics rather than model-specific features. By focusing on distribution matching rather than model-specific training dynamics, MDM generates synthetic datasets that contain general signal properties useful across different architectures. Core assumption: Fundamental signal characteristics for modulation recognition are architecture-agnostic, and distribution matching captures these shared features.

## Foundational Learning

- **Concept**: Discrete Fourier Transform (DFT)
  - Why needed here: MDM requires transforming time-domain signals to frequency domain to capture spectral characteristics essential for modulation recognition.
  - Quick check question: What is the relationship between time-domain sampling rate and frequency-domain resolution in DFT?

- **Concept**: Maximum Mean Discrepancy (MMD)
  - Why needed here: MDM uses MMD to measure distribution distance between real and synthetic datasets in embedded feature space.
  - Quick check question: How does MMD compare to other distribution distance metrics like KL divergence for high-dimensional feature distributions?

- **Concept**: Dataset Distillation
  - Why needed here: MDM is a dataset distillation method that compresses large training datasets into smaller synthetic datasets while maintaining performance.
  - Quick check question: What are the key differences between dataset distillation and coreset selection approaches?

## Architecture Onboarding

- **Component map**: 
  DFT module -> Feature extractor (ψθ) -> MMD loss calculators (time & frequency) -> Loss combiner -> Synthetic dataset updater

- **Critical path**:
  1. Initialize synthetic dataset with random samples
  2. For each iteration: compute time-domain loss, frequency-domain loss, combine losses
  3. Backpropagate combined loss to update synthetic dataset
  4. After distillation, train final model on synthetic dataset

- **Design tradeoffs**:
  - Single vs. multiple feature extractors: Using one shared feature extractor reduces parameters but may limit domain-specific feature learning
  - Fixed vs. adaptive weighting (α): Fixed weights are simpler but adaptive weights could better balance domain contributions
  - DFT resolution: Higher resolution captures more spectral detail but increases computational cost

- **Failure signatures**:
  - Synthetic dataset shows poor performance across all architectures: Indicates fundamental distillation problem
  - Performance degrades significantly on test architectures: Suggests overfitting to training architecture
  - One domain consistently dominates loss: Imbalanced domain weighting

- **First 3 experiments**:
  1. Ablation study: Compare MDM with only time-domain or only frequency-domain losses to verify complementarity
  2. Sensitivity analysis: Test different values of α (domain weighting) to find optimal balance
  3. Cross-dataset generalization: Test synthetic datasets on different AMR datasets to verify robustness

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of MDM change with different hyperparameter α values across different datasets? The paper mentions that α is a tunable hyperparameter whose value depends on the dataset, but does not provide a detailed analysis of how different α values affect performance across various datasets. What evidence would resolve it: Experiments showing MDM performance with varying α values across different datasets, including visualizations or quantitative analysis of how α affects the trade-off between time and frequency domain contributions to the overall loss.

### Open Question 2
Can MDM be extended to other signal processing domains beyond AMR, such as biomedical signal processing or speech recognition? The paper demonstrates MDM's effectiveness on AMR datasets, but does not explore its applicability to other signal domains that might benefit from multi-domain analysis. What evidence would resolve it: Experiments applying MDM to other signal processing tasks like ECG classification, EEG analysis, or speech recognition, comparing its performance to domain-specific methods.

### Open Question 3
How does MDM's synthetic dataset compression ratio compare to other data distillation methods in terms of maintaining model performance? While the paper mentions that MDM performs well under similar compression ratios, it does not quantify or compare the actual compression ratios achieved by MDM versus other methods or explore the trade-off between compression ratio and model performance. What evidence would resolve it: A comprehensive analysis comparing the compression ratios achieved by MDM and other data distillation methods while maintaining similar or better model performance, including visualizations of the trade-off between compression ratio and accuracy.

## Limitations

- The paper's claims about cross-architecture generalization are supported by experiments but lack comparison to other dataset distillation methods' generalization capabilities.
- The computational overhead of MDM compared to simpler baselines is not quantified.
- The sensitivity analysis for the domain weighting hyperparameter α is incomplete, showing only one dataset example.

## Confidence

- **High confidence**: The core mechanism of MDM (DFT-based frequency domain transformation combined with MMD-based distribution matching) is technically sound and well-explained. The experimental setup and baseline comparisons are clearly defined.
- **Medium confidence**: Claims about MDM's superiority over baseline methods are supported by experiments but could benefit from more extensive ablation studies and comparison to additional dataset distillation approaches.
- **Medium confidence**: Cross-architecture generalization results are promising but limited to testing on architectures that weren't used during distillation. The paper doesn't test whether MDM-generated datasets generalize to architectures with fundamentally different architectures or to other AMR datasets.

## Next Checks

1. **Ablation study**: Compare MDM performance against versions using only time-domain losses, only frequency-domain losses, and different combinations of MMD metrics to quantify the contribution of each domain.

2. **Cross-dataset evaluation**: Test whether synthetic datasets generated from one AMR dataset (e.g., RML2016.10a) maintain performance when used to train models for different datasets (e.g., Sig2019-12-high) to assess true generalization capability.

3. **Hyperparameter sensitivity analysis**: Systematically vary the domain weighting hyperparameter α across all three datasets and measure the impact on both absolute performance and cross-architecture generalization to identify optimal settings.