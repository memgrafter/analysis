---
ver: rpa2
title: Improving Data Efficiency via Curating LLM-Driven Rating Systems
arxiv_id: '2410.10877'
source_url: https://arxiv.org/abs/2410.10877
tags:
- score
- data
- rating
- samples
- curation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Traditional instruction tuning methods focus on scaling up dataset
  size, but recent work shows that smaller, high-quality datasets can outperform larger
  ones. This paper introduces DS2, a Diversity-aware Score curation method for Data
  Selection, which addresses inaccuracies and biases in LLM-based rating systems by
  modeling error patterns through a score transition matrix.
---

# Improving Data Efficiency via Curating LLM-Driven Rating Systems

## Quick Facts
- **arXiv ID**: 2410.10877
- **Source URL**: https://arxiv.org/abs/2410.10877
- **Reference count**: 40
- **Key result**: Achieves superior instruction tuning performance using only 3.3% of dataset size (10k samples vs 300k) by correcting LLM rating errors through score transition matrices

## Executive Summary
This paper introduces DS2, a Diversity-aware Score curation method that addresses inaccuracies and biases in LLM-based rating systems for instruction tuning. Rather than scaling up dataset size, DS2 focuses on improving data quality by modeling error patterns through a score transition matrix and promoting diversity in selected samples. The method challenges conventional data scaling assumptions by demonstrating that smaller, high-quality datasets can outperform larger ones, achieving results that match or surpass human-curated datasets like LIMA using the same sample size (1k samples).

## Method Summary
DS2 operates by first having LLMs rate instruction samples, then correcting these ratings using a transition matrix estimated from k-NN agreement patterns in embedding space. The method computes long-tail diversity scores based on average cosine similarity between each sample and its neighbors, ensuring diverse coverage. Data selection combines curated quality scores with diversity scores through dual sorting (quality first, then diversity), enabling efficient selection of high-quality, diverse instruction examples that maximize downstream task performance while minimizing dataset size requirements.

## Key Results
- DS2 achieves superior results using only 3.3% of the original dataset (10k samples) compared to full-scale datasets (300k samples)
- Matches or surpasses human-curated datasets like LIMA with the same sample size (1k samples)
- Demonstrates significant improvements in downstream task performance across multiple benchmarks
- Challenges conventional data scaling assumptions by proving data quality matters more than quantity

## Why This Works (Mechanism)

### Mechanism 1: Score Transition Matrix Error Correction
- **Claim**: Score transition matrix modeling can identify and correct LLM rating errors without requiring ground truth labels
- **Mechanism**: Analyzes k-NN agreement patterns among embedding features to capture P(ŷ=j|y=i) probabilities, identifying misrated samples based on low cosine similarity between a sample's score and its neighbors' consensus
- **Core assumption**: k-NN clusterability holds - similar embedding features belong to the same ground-truth score class
- **Evidence anchors**: Abstract mentions systematic error pattern modeling through transition matrix; section 3.2 describes automatic estimation using LLM scores under clusterability condition
- **Break condition**: When embedding features do not cluster by true quality scores, making k-NN agreement unreliable for error detection

### Mechanism 2: Long-Tail Diversity Scoring
- **Claim**: Long-tail diversity scoring ensures selected samples represent diverse data distribution patterns
- **Mechanism**: Computes average cosine similarity between each sample embedding and its k-NN neighbors, creating a long-tail score where lower similarity indicates higher diversity
- **Core assumption**: Feature embeddings capture meaningful semantic diversity that correlates with instruction-following diversity
- **Evidence anchors**: Abstract states promotes diversity in selected data samples; section 4.2 describes scoring diversity by measuring distance between feature embeddings
- **Break condition**: When embedding space fails to capture true semantic diversity or when diversity conflicts with instruction quality

### Mechanism 3: Dual Sorting Quality-Diversity Trade-off
- **Claim**: Dual sorting (quality first, then diversity) creates optimal trade-off between instruction quality and coverage
- **Mechanism**: After curating scores to correct errors, samples are first sorted by curated quality scores, then within each quality group sorted by long-tail diversity scores
- **Core assumption**: Quality and diversity are complementary rather than conflicting objectives for instruction tuning
- **Evidence anchors**: Abstract mentions prioritizing data by first sorting based on curated scores and then by long-tail scores; section 4 describes dual sorting strategy for removing poor-quality outliers while ensuring diversity
- **Break condition**: When high-quality samples are inherently homogeneous, making diversity selection within quality groups redundant

## Foundational Learning

- **Concept**: Transition matrix estimation from k-NN agreement patterns
  - **Why needed**: Enables error correction without ground truth labels, crucial for scalable data curation
  - **Quick check**: If three neighboring samples have scores [5, 5, 5] but the center sample has score 3, what does this indicate about the transition matrix?

- **Concept**: Cosine similarity as diversity metric
  - **Why needed**: Provides normalized measure of embedding distance that works across different embedding scales
  - **Quick check**: If sample A has average k-NN cosine similarity of 0.95 and sample B has 0.45, which has higher long-tail diversity score?

- **Concept**: Dual-priority sorting algorithms
  - **Why needed**: Balances competing objectives (quality vs diversity) in multi-criteria selection
  - **Quick check**: When selecting 10K samples from 300K, should you sort by quality first then diversity, or vice versa? Why?

## Architecture Onboarding

- **Component map**: Data pool → LLM rating → Embedding generation → k-NN statistics → Transition matrix estimation → Score curation → Long-tail scoring → Dual sorting → Selected subset
- **Critical path**: LLM rating → Embedding generation → k-NN statistics → Transition matrix → Score curation → Final selection
- **Design tradeoffs**: Higher k-NN values improve clusterability but increase computation; larger embedding models improve quality but reduce efficiency
- **Failure signatures**: Poor performance indicates either embedding space doesn't capture quality diversity, or k-NN clusterability assumption fails
- **First 3 experiments**:
  1. Run DS2 pipeline with k=5 neighbors and verify score curation reduces rating variance across LLMs
  2. Compare selected subset diversity (long-tail score distribution) against random selection baseline
  3. Fine-tune base model on 10K DS2-selected samples vs 10K random samples and measure downstream performance delta

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation to English instruction tuning tasks, limiting generalizability to multilingual or specialized domains
- Computational overhead of k-NN statistics calculation and transition matrix estimation may become prohibitive at larger scales
- Effectiveness depends heavily on quality of embedding model and may vary across different types of instruction data

## Confidence

**High Confidence**: The core mechanism of using transition matrices to correct systematic rating errors is well-supported by mathematical formulation and empirical results. The claim that DS2 achieves superior results with 3.3% of the dataset is strongly supported by experimental comparisons.

**Medium Confidence**: The effectiveness of long-tail diversity scoring depends heavily on the quality of the embedding model and may vary across different types of instruction data. The dual sorting mechanism shows promise but lacks extensive ablation studies to confirm its necessity.

**Low Confidence**: The generalizability of DS2 to non-instruction-tuning scenarios and the scalability of the approach to much larger datasets (>1M samples) remain uncertain without additional experiments.

## Next Checks

1. **Embedding Space Validation**: Test DS2 with alternative embedding models (e.g., sentence-transformers, OpenAI embeddings) to verify that score transition matrix estimation is robust to embedding choice and that clusterability assumptions hold across different feature spaces.

2. **Scale-Up Experiment**: Evaluate DS2 on a 1M+ sample dataset to assess computational scalability and verify whether the 3.3% efficiency gains persist at larger scales, including measurement of runtime and memory requirements.

3. **Cross-Domain Transfer**: Apply DS2 to a different NLP task domain (e.g., summarization, question answering) with different quality metrics to test whether the transition matrix correction approach generalizes beyond instruction following.