---
ver: rpa2
title: Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport
arxiv_id: '2412.12569'
source_url: https://arxiv.org/abs/2412.12569
tags:
- change
- word
- usage
- semantic
- sense
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a novel approach to quantify lexical semantic
  change at the instance level by leveraging Unbalanced Optimal Transport (UOT) on
  contextualized word embeddings from diachronic corpora. The proposed Sense Usage
  Shift (SUS) metric captures changes in word sense usage frequency by measuring alignment
  discrepancies between usage instances in old and modern corpora.
---

# Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport

## Quick Facts
- arXiv ID: 2412.12569
- Source URL: https://arxiv.org/abs/2412.12569
- Reference count: 40
- Primary result: Introduced Sense Usage Shift (SUS) metric using UOT for instance-level semantic change detection, achieving Spearman correlation of up to 0.69 on word-level tasks

## Executive Summary
This paper proposes a novel approach to quantify lexical semantic change at the instance level by leveraging Unbalanced Optimal Transport (UOT) on contextualized word embeddings from diachronic corpora. The method introduces Sense Usage Shift (SUS) to capture changes in word sense usage frequency by measuring alignment discrepancies between usage instances across time periods. Evaluated on the DWUG dataset, the approach demonstrates competitive performance in detecting both word-level semantic change and semantic scope changes, while excelling in instance-level detection.

## Method Summary
The approach applies Unbalanced Optimal Transport to sets of contextualized word embeddings extracted from diachronic corpora, capturing semantic change through alignment discrepancies between usage instances. Sense Usage Shift (SUS) is calculated as the normalized difference between original instance weights and transported weights, quantifying frequency changes in each sense. The method aggregates SUS values to measure word-level change magnitude and semantic scope, addressing limitations of balanced Optimal Transport by allowing excess or deficit in alignments.

## Key Results
- Achieved Spearman correlation of 0.69 for word-level semantic change detection
- Demonstrated correlation of 0.55 for semantic scope changes (broadening/narrowing)
- Achieved instance-level semantic change detection with Spearman correlation of 0.46
- Outperformed balanced OT methods and showed competitive results against form-based baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unbalanced Optimal Transport (UOT) enables quantification of semantic change at the instance level by allowing excess or deficit in the alignment between usage instances across time periods.
- Mechanism: UOT relaxes the balanced alignment constraints of standard OT, permitting transportation matrices to capture semantic shifts as alignment discrepancies. This allows detection of emerging or disappearing senses without forcing artificial alignment.
- Core assumption: The contextualized embeddings for usage instances are sufficiently discriminative to reflect sense-level distinctions and changes.
- Evidence anchors:
  - [abstract] "apply Unbalanced Optimal Transport (UOT) to sets of contextualized word embeddings, capturing semantic change through the excess and deficit in the alignment between usage instances."
  - [section 3.3] "OT frequently conducts transportation between different senses... OT can capture overall semantic change at the word level, it may not fully capture semantic changes in individual usage instances."
  - [corpus] DWUG dataset provides usage instances with gold sense labels for evaluation, but does not provide sense boundaries or definitions.

### Mechanism 2
- Claim: Sense Usage Shift (SUS) quantifies the relative frequency change of word usage in each sense by normalizing the excess or deficit in UOT alignment.
- Mechanism: SUS calculates the normalized difference between original instance weights and the transported weight to/from modern corpus, indicating whether usage frequency in a particular sense has increased or decreased.
- Core assumption: The original instance weights (uniform in experiments) appropriately represent the relative importance of each usage instance for measuring frequency changes.
- Evidence anchors:
  - [abstract] "Sense Usage Shift (SUS), a measure that quantifies changes in the usage frequency of a word sense at each usage instance."
  - [section 4.2] "SUS represents the excess or deficit in the alignment normalized by the original weight."
  - [corpus] Gold sense frequency distributions (SFDs) from DWUG provide ground truth for evaluating SUS's ability to capture frequency changes.

### Mechanism 3
- Claim: Aggregating SUS across instances enables unified detection of both word-level semantic change magnitude and semantic scope changes.
- Mechanism: Word-level change is quantified by computing absolute differences in mean SUS values (magnitude) or variance ratios (scope), capturing both the degree and direction of semantic shift.
- Core assumption: The variance of SUS values across instances correlates with the semantic breadth of word usage.
- Evidence anchors:
  - [abstract] "By leveraging SUS, we demonstrate that several challenges in semantic change detection can be addressed in a unified manner, including quantifying instance-level semantic change and word-level tasks such as measuring the magnitude of semantic change and the broadening or narrowing of meaning."
  - [section 4.5] "If the SUS values are regarded as surrogate values for embeddings, a larger variance in SUS values indicates a broader semantic scope."
  - [corpus] DWUG provides word-level graded change scores and entropy-based scope measures for validation.

## Foundational Learning

- Concept: Optimal Transport (OT) and its balanced alignment constraints
  - Why needed here: Understanding why standard OT fails for semantic change detection is crucial for appreciating the need for UOT.
  - Quick check question: Why does balanced alignment in OT fail to capture semantic change when new senses emerge or existing ones disappear?

- Concept: Contextualized word embeddings and their distributional properties
  - Why needed here: The method relies on contextualized embeddings capturing sense distinctions, which requires understanding how embeddings encode semantic information.
  - Quick check question: How do contextualized embeddings for different usage instances of the same word typically differ when the word is used in different senses?

- Concept: Statistical distance measures and entropy
  - Why needed here: Aggregating SUS to quantify word-level change requires understanding metrics like Jensen-Shannon divergence and entropy differences.
  - Quick check question: What does a higher variance in SUS values across instances suggest about the semantic scope of a word's usage?

## Architecture Onboarding

- Component map: Embedding extraction -> UOT alignment -> SUS calculation -> Aggregation metrics
- Critical path: The most time-consuming step is UOT computation, which scales with the product of instance counts between time periods.
- Design tradeoffs: Using uniform instance weights simplifies SUS calculation but may not reflect true usage frequency importance.
- Failure signatures: Poor performance may indicate that embeddings fail to capture sense distinctions or that hyperparameter λ is poorly tuned.
- First 3 experiments:
  1. Visualize transportation matrices for OT vs UOT on a simple dataset with clear sense emergence/disappearance
  2. Test SUS sensitivity to different λ values on a validation set
  3. Compare SUS-based metrics against form-based baselines using word-level change scores

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal hyperparameter settings (λ and r) for SUS-based methods across different languages and domains, and how do they vary?
- Basis in paper: [explicit] The paper notes that the optimal λ value may vary depending on the data and that further investigations are needed to establish effective λ tuning strategies.
- Why unresolved: The study only used the DWUG dataset for English, limiting generalizability. The paper also mentions that tuning both λ and r was explored, but the results are not fully detailed.
- What evidence would resolve it: Experiments across multiple languages, domains, and datasets with systematic hyperparameter tuning and analysis of variance in optimal settings.

### Open Question 2
- Question: How does the performance of SUS-based methods compare to other advanced techniques for instance-level semantic change detection, such as those leveraging transformer-based models or graph-based approaches?
- Basis in paper: [inferred] The paper compares SUS to baseline methods like WiDiD and LDR but does not explore more advanced or recent techniques for instance-level semantic change detection.
- Why unresolved: The paper focuses on comparing SUS to traditional baselines but does not benchmark against state-of-the-art methods that might leverage newer architectures or methodologies.
- What evidence would resolve it: Comparative studies using modern techniques like transformer-based models or graph neural networks for instance-level semantic change detection.

### Open Question 3
- Question: How does SUS perform in capturing semantic changes for words with complex polysemy or homonymy, where senses may overlap or be ambiguous?
- Basis in paper: [inferred] The paper mentions that SUS can detect detailed changes in individual usage instances but does not explicitly address its performance on words with overlapping or ambiguous senses.
- Why unresolved: The study uses the DWUG dataset, which may not fully capture the complexity of polysemous or homonymous words, and the paper does not provide a detailed analysis of such cases.
- What evidence would resolve it: Experiments on datasets with annotated polysemous or homonymous words and qualitative analysis of SUS performance in distinguishing overlapping senses.

### Open Question 4
- Question: Can SUS be extended to handle semantic changes in multi-word expressions or phrases, and how would this affect its effectiveness?
- Basis in paper: [inferred] The paper focuses on SUS for individual words and does not explore its application to multi-word expressions or phrases.
- Why unresolved: The methodology is designed for single words, and extending it to phrases would require addressing challenges like phrase embedding and alignment.
- What evidence would resolve it: Development and evaluation of SUS-based methods for multi-word expressions, including experiments on phrase-level semantic change detection tasks.

### Open Question 5
- Question: How does the choice of language model (e.g., XL-LEXEME vs. other models like BERT or RoBERTa) impact the performance of SUS in detecting semantic changes?
- Basis in paper: [explicit] The paper uses XL-LEXEME for contextualized embeddings but does not compare its performance with other language models.
- Why unresolved: The study uses a single language model, and the impact of different models on SUS performance is not explored.
- What evidence would resolve it: Comparative experiments using different language models for embedding extraction and analysis of their impact on SUS-based semantic change detection.

## Limitations
- The method's effectiveness critically depends on the quality of contextualized embeddings for distinguishing word senses
- Computational complexity scales quadratically with instance counts, limiting scalability to larger corpora
- Evaluation on a single dataset (DWUG) raises concerns about generalizability across different domains and time periods
- Uniform weighting assumption for usage instances may not reflect true usage frequencies

## Confidence
- **High Confidence**: The core mechanism of using UOT to capture semantic change through alignment discrepancies is well-established and theoretically sound. The competitive performance against baselines on DWUG is demonstrated with statistical significance.
- **Medium Confidence**: The interpretation of SUS values as reliable indicators of sense frequency changes and the variance-based metric for semantic scope detection show promise but may be sensitive to embedding quality and dataset characteristics.
- **Low Confidence**: The assumption that SUS variance directly correlates with semantic scope changes requires further validation across diverse datasets and word types, as the relationship may not be universally applicable.

## Next Checks
1. **Embedding Quality Validation**: Evaluate the discriminability of XL-LEXEME embeddings for usage instances across different senses using intrinsic metrics like nearest neighbor consistency and sense clustering quality on a held-out portion of DWUG.

2. **Hyperparameter Robustness**: Conduct sensitivity analysis of SUS-based metrics to the UOT penalty parameter λ across multiple random train/validation splits, ensuring consistent performance and identifying potential overfitting.

3. **Cross-Dataset Generalization**: Test the approach on at least one additional diachronic corpus (e.g., COHA or Google Ngram) with different time periods and genres to assess robustness and generalizability beyond DWUG.