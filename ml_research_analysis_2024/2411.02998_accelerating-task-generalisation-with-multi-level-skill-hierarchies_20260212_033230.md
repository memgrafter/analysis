---
ver: rpa2
title: Accelerating Task Generalisation with Multi-Level Skill Hierarchies
arxiv_id: '2411.02998'
source_url: https://arxiv.org/abs/2411.02998
tags:
- fracture
- learning
- agent
- option
- fracos
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Fracture Cluster Options (FraCOs), a hierarchical
  reinforcement learning method that identifies patterns in agent behavior and converts
  them into temporally extended options based on their expected future usefulness.
  The method clusters agent trajectories to discover reusable behavioral patterns,
  evaluates their potential utility across tasks using a Bayesian-based usefulness
  metric, and forms options that enable rapid adaptation to new tasks.
---

# Accelerating Task Generalisation with Multi-Level Skill Hierarchies

## Quick Facts
- arXiv ID: 2411.02998
- Source URL: https://arxiv.org/abs/2411.02998
- Authors: Thomas P Cannon; Özgür Simsek
- Reference count: 40
- Primary result: FraCOs achieves higher in-distribution and out-of-distribution performance compared to state-of-the-art baselines across eight Procgen environments

## Executive Summary
This paper introduces Fracture Cluster Options (FraCOs), a hierarchical reinforcement learning method that identifies patterns in agent behavior and converts them into temporally extended options based on their expected future usefulness. The method clusters agent trajectories to discover reusable behavioral patterns, evaluates their potential utility across tasks using a Bayesian-based usefulness metric, and forms options that enable rapid adaptation to new tasks. In tabular settings, FraCOs demonstrates improved performance with deeper hierarchies. Across eight Procgen environments, FraCOs achieves higher in-distribution and out-of-distribution performance compared to state-of-the-art baselines including PPO, Option Critic with PPO, and Phasic Policy Gradient.

## Method Summary
FraCOs identifies behavioral patterns (fractures) from agent trajectories, clusters similar fractures, evaluates their expected future usefulness, and converts high-usefulness clusters into hierarchical options. The method operates by extracting action sequences from successful trajectories, grouping similar sequences through clustering, computing a usefulness metric based on appearance probability, relative frequency, and entropy, and forming options that capture these reusable behaviors. The process can be repeated to build multi-level skill hierarchies. In deep learning settings, FraCOs simplifies clustering by focusing on action patterns and uses neural networks for initiation prediction and policy learning.

## Key Results
- In tabular settings, FraCOs demonstrates improved performance as hierarchical depth increases
- Across eight Procgen environments, FraCOs achieves higher in-distribution and out-of-distribution performance
- Mean normalized interquartile returns show consistent gains over all competitors (PPO, OC-PPO, and PPG)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FraCOs identifies reusable behavioral patterns by clustering agent trajectories and converting them into temporally extended options
- Mechanism: The method clusters agent trajectories to discover reusable behavioral patterns, evaluates their potential utility across tasks using a Bayesian-based usefulness metric, and forms options that enable rapid adaptation to new tasks
- Core assumption: Similar action sequences across successful trajectories indicate transferable skills that will be useful in new tasks
- Evidence anchors:
  - [abstract] "FraCOs identifies patterns in agent behaviour and forms options based on the expected future usefulness of those patterns"
  - [section] "We hypothesise that identifying reoccurring patterns in an agent's behaviour across successfully completed tasks will improve performance on future tasks"
  - [corpus] Weak - only one related paper mentions skill discovery in reinforcement learning

### Mechanism 2
- Claim: FraCOs improves performance as hierarchical depth increases by creating multi-level skill hierarchies
- Mechanism: When learning a new task, the agent can now choose from both primitive actions and these higher-level behaviours. To build additional levels of the hierarchy, the process of identifying and clustering fractures is repeated
- Core assumption: Deeper hierarchies capture more complex and abstract behaviors that transfer better across tasks
- Evidence anchors:
  - [abstract] "In tabular settings, FraCOs demonstrates effective transfer and improves performance as it grows in hierarchical depth"
  - [section] "When learning a new task, the agent can now choose from both primitive actions and these higher-level behaviours"
  - [corpus] Weak - no direct evidence about hierarchical depth effects in related papers

### Mechanism 3
- Claim: FraCOs outperforms state-of-the-art methods by preventing option collapse through its option selection process
- Mechanism: FraCOs addresses option collapse by naturally preventing option collapse through its option selection process based on expected usefulness rather than simultaneous learning
- Core assumption: Option collapse occurs when all options converge to the same behavior or one particular option is chosen consistently
- Evidence anchors:
  - [section] "Both option-critic and HOC suffer from option collapse, where either all options converge to the same behaviour or one particular option is chosen consistently"
  - [section] "FraCOs addresses these limitations by naturally preventing option collapse through its option selection process"
  - [corpus] Weak - no specific evidence about option collapse in related papers

## Foundational Learning

- Concept: Markov Decision Processes (MDPs)
  - Why needed here: The entire framework operates on MDPs as the mathematical foundation for modeling decision-making
  - Quick check question: What are the five components of an MDP tuple and what does each represent?

- Concept: Hierarchical Reinforcement Learning and Options Framework
  - Why needed here: FraCOs builds on the options framework to create multi-level hierarchies of temporally extended actions
  - Quick check question: What are the three components of an option (I, π, β) and what does each represent?

- Concept: Generalization in Reinforcement Learning
  - Why needed here: The paper focuses on out-of-distribution generalization where state spaces and reward functions vary
  - Quick check question: What are the key differences between in-distribution and out-of-distribution generalization tasks?

## Architecture Onboarding

- Component map:
  - Fracture generation: Creates sequences of actions starting from specific states
  - Clustering module: Groups similar fractures using HDBSCAN (tabular) or neural networks (deep)
  - Usefulness metric: Evaluates fracture clusters based on appearance probability, relative frequency, and entropy
  - Option creation: Converts high-usefulness clusters into FraCOs with initiation sets, policies, and termination conditions
  - Hierarchical learning: Repeats the process to build multi-level skill hierarchies

- Critical path: Trajectory generation → Fracture formation → Clustering → Usefulness evaluation → Option creation → Hierarchical learning → Task execution

- Design tradeoffs:
  - Chain length vs. computational complexity: Longer chains capture more complex behaviors but increase factorial search complexity
  - Cluster granularity vs. generalization: Finer clusters may capture more specific behaviors but reduce transferability
  - Hierarchy depth vs. learning efficiency: Deeper hierarchies provide more abstraction but require more computational resources

- Failure signatures:
  - Poor clustering results in FraCOs that don't capture meaningful behavioral patterns
  - Low usefulness scores across all clusters indicate difficulty in identifying transferable skills
  - Option collapse manifests as redundant behaviors across different FraCOs
  - Computational bottlenecks during the discrete search over action permutations

- First 3 experiments:
  1. Implement FraCOs in a simple grid world (Four Rooms) to verify basic fracture clustering and option creation
  2. Test hierarchical depth effects by comparing single-level vs. multi-level FraCOs in the same environment
  3. Evaluate out-of-distribution performance by training on one set of tasks and testing on unseen reward locations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FraCOs scale with deeper hierarchies beyond 4 levels in complex environments?
- Basis in paper: [explicit] The paper states "we restricted the depth of the FraCOs hierarchy to 3 or 4 levels, depending on the complexity of the environment" and shows improved performance with deeper hierarchies in tabular settings
- Why unresolved: The experiments were limited to 3-4 hierarchy levels due to computational constraints, particularly the factorial growth of discrete search complexity
- What evidence would resolve it: Experimental results showing performance comparisons of FraCOs with 5+ hierarchy levels in various environments, particularly in deep learning settings

### Open Question 2
- Question: Can FraCOs be effectively extended to continuous action spaces?
- Basis in paper: [explicit] The paper explicitly states "this work focused on discrete action spaces; extending FraCOs to continuous action spaces remains as future work"
- Why unresolved: The current FraCOs implementation relies on discrete fracture matching and cluster selection, which becomes computationally expensive in continuous spaces
- What evidence would resolve it: A modified FraCOs implementation that successfully learns and applies options in continuous control environments, with performance comparisons to continuous HRL methods

### Open Question 3
- Question: How does the clustering method affect the quality and usefulness of discovered options in high-dimensional environments?
- Basis in paper: [explicit] The paper discusses switching from HDBSCAN to simpler clustering methods and neural networks due to HDBSCAN's limitations in high-dimensional Procgen environments
- Why unresolved: The paper only qualitatively demonstrates the effects of different clustering approaches but doesn't systematically compare their impact on option quality and task performance
- What evidence would resolve it: Controlled experiments comparing different clustering methods (HDBSCAN, neural network classifiers, other methods) on their ability to discover useful options and improve task performance in high-dimensional environments

## Limitations
- FraCOs relies heavily on the quality of fracture clustering, which may not generalize well to continuous high-dimensional state spaces
- Computational complexity grows factorially with chain length, potentially limiting scalability to deeper hierarchies
- The theoretical foundations for why hierarchical depth improves generalization remain underdeveloped

## Confidence

- Claims about FraCOs' mechanism and performance: **Medium** - Well-supported by experiments but with implementation-dependent variations
- Claims about hierarchical depth improvements: **Low-Medium** - Limited to tabular settings with unclear generalization to deep learning
- Claims about preventing option collapse: **Medium** - Demonstrated empirically but theoretical justification is minimal

## Next Checks

1. Implement FraCOs in a continuous control environment (e.g., MuJoCo tasks) to verify scalability beyond tabular settings
2. Conduct ablation studies removing the usefulness metric to quantify its impact on option quality and performance
3. Analyze option diversity metrics during training to empirically verify the prevention of option collapse across different hierarchical depths