---
ver: rpa2
title: What Do Self-Supervised Speech and Speaker Models Learn? New Findings From
  a Cross Model Layer-Wise Analysis
arxiv_id: '2401.17632'
source_url: https://arxiv.org/abs/2401.17632
tags:
- speaker
- speech
- layer
- layers
- wavlm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares how speech SSL models (e.g., WavLM), speaker
  SSL models (DINO-based), and supervised speaker models (ECAPA-TDNN) represent speech
  information using probing tasks and layer-wise similarity analysis. The authors
  find that (1) better non-speaker representation does not guarantee improved speaker
  representation, (2) both speaker models capture phoneme information early in their
  layers, unlike speech SSL models, and (3) speech SSL models show unique linguistic
  patterns in deeper layers absent in speaker models.
---

# What Do Self-Supervised Speech and Speaker Models Learn? New Findings From a Cross Model Layer-Wise Analysis

## Quick Facts
- arXiv ID: 2401.17632
- Source URL: https://arxiv.org/abs/2401.17632
- Reference count: 0
- Primary result: Speech SSL models capture linguistic information in deeper layers, while speaker models focus on speaker identity and capture phoneme information early.

## Executive Summary
This paper compares how speech SSL models (WavLM), speaker SSL models (DINO-based), and supervised speaker models (ECAPA-TDNN) represent speech information using probing tasks and layer-wise similarity analysis. The authors find that better non-speaker representation does not guarantee improved speaker representation, both speaker models capture phoneme information early unlike speech SSL models, and speech SSL models show unique linguistic patterns in deeper layers absent in speaker models. WavLM Large outperformed other models on most SUPERB tasks, while speaker models excelled at speaker-specific tasks.

## Method Summary
The study evaluates WavLM (speech SSL), DINO-based ECAPA-TDNN (speaker SSL), and supervised ECAPA-TDNN (speaker) models using SUPERB benchmark probing tasks with weighted layer summation. Layer representations are extracted and analyzed using LinCKA-based similarity to compare how information is distributed across layers within and across models. Models are trained on VoxCeleb2, with similarity analysis performed on VoxCeleb1 utterances.

## Key Results
- Better non-speaker representation does not guarantee improved speaker representation
- Speaker models capture phoneme information early in layers, unlike speech SSL models
- Speech SSL models exhibit unique linguistic patterns in deeper layers absent in speaker models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Better performance on non-speaker tasks does not imply better speaker representation
- Mechanism: Speaker SSL models are optimized for utterance-level speaker identity, prioritizing speaker cues over phoneme or linguistic content, while speech SSL models distribute information across layers for general-purpose representations
- Core assumption: Downstream task performance proxies representational capacity
- Evidence anchors: [abstract] "better non-speaker representation does not guarantee improved speaker representation"; [section] "both speaker models can solve the non-speaker tasks significantly better than the baseline model"
- Break condition: If downstream task weights prove unreliable indicators of representational capacity

### Mechanism 2
- Claim: Speaker models disentangle phoneme information early in layers
- Mechanism: Speaker models prioritize rapid extraction of stable, speaker-specific cues including phonetic patterns in early layers, while speech SSL models progressively disentangle speech variability with phoneme information emerging later
- Core assumption: Layer-wise information capture reflects training objectives
- Evidence anchors: [abstract] "both speaker models capture phoneme information early in their layers"; [section] "PR task focused on 1st frame-level block"
- Break condition: If phoneme information can be captured equally well in later layers of speaker models

### Mechanism 3
- Claim: Speech SSL models exhibit linguistic patterns in deeper layers
- Mechanism: Speech SSL models trained with masked prediction progressively refine linguistic abstractions in deeper layers, while speaker models focused on utterance-level identity do not develop such deep linguistic abstractions
- Core assumption: Linguistic patterns in deeper layers are necessary for high linguistic task performance
- Evidence anchors: [abstract] "speech SSL models show unique linguistic patterns in deeper layers"; [section] "Figs. 3B and C show distinctive representations around layer 11"
- Break condition: If speaker models are found to capture linguistic information in deeper layers

## Foundational Learning

- Concept: Layer-wise similarity analysis using LinCKA
  - Why needed here: To directly compare how different models distribute information across layers and identify unique representational patterns
  - Quick check question: What does high LinCKA similarity between two layers indicate about their representational content?

- Concept: Probing tasks with weighted layer summation
  - Why needed here: To indirectly measure which layers contribute most to solving specific speech tasks, revealing information types captured
  - Quick check question: How does the weight assigned to a layer in weighted sum relate to its importance for a given task?

- Concept: Self-supervised learning objectives (masked prediction vs. utterance-level contrastive learning)
  - Why needed here: To understand why speech SSL and speaker SSL models develop different representational hierarchies
  - Quick check question: How does the choice of pretext task influence information captured in early vs. late layers?

## Architecture Onboarding

- Component map: WavLM/ECAPA-TDNN (upstream models) -> Weighted sum of layers with learnable weights -> SUPERB probing tasks -> LinCKA similarity analysis

- Critical path: 1) Extract layer representations from upstream models, 2) Apply SUPERB probing tasks with weighted layer summation, 3) Analyze learnable weights to identify layer importance per task, 4) Compute LinCKA similarities within and across models, 5) Interpret results to understand representational differences

- Design tradeoffs:
  - Probing tasks vs. direct similarity: Probing tasks provide task-specific insights but are indirect; LinCKA is direct but may not reveal task-specific utility
  - Model capacity: Speech SSL models have higher capacity but may not optimize for speaker-specific tasks; speaker models are lighter but task-specialized
  - Training data: More data improves general representations but may not close performance gap on speaker-specific tasks

- Failure signatures:
  - If LinCKA shows high similarity across all layers, model may not disentangle information hierarchically
  - If probing task weights are uniform across layers, model may not specialize layers for specific information types
  - If speaker models perform poorly on non-speaker tasks, they may be over-specialized

- First 3 experiments:
  1. Compare layer-wise LinCKA similarity of WavLM BASE vs. WavLM LARGE to identify how model scale affects representational patterns
  2. Apply SUPERB probing tasks to DINO-based and supervised ECAPA-TDNN to measure impact of training objective on layer utilization
  3. Use subset of SUPERB tasks (PR, SID, IC) to perform focused comparison of early-layer specialization between speech SSL and speaker models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do intermediate layers (around layer 11 in BASE and layers 13-22 in LARGE) in WavLM models capture linguistic information, and what specific linguistic features are represented?
- Basis in paper: [explicit] The paper states WavLM models show distinctive representation in intermediate layers associated with linguistic information
- Why unresolved: The paper observes this but does not provide detailed breakdown of specific linguistic features captured
- What evidence would resolve it: Detailed linguistic feature analysis with probing tasks designed to identify word, semantic, and syntax features at each layer

### Open Question 2
- Question: What specific information is captured by the 4th layer in both supervised and DINO-based speaker models?
- Basis in paper: [explicit] The paper highlights the 4th layer shows distinct representation and crucial role in speaker identification
- Why unresolved: While the paper identifies its importance, it does not specify what type of information (e.g., channel, speaking style) is being captured
- What evidence would resolve it: Additional probing tasks focused on channel and speaking style classification

### Open Question 3
- Question: Why does supervised speaker model outperform DINO-based speaker model in speaker identification tasks?
- Basis in paper: [explicit] The paper observes supervised model achieves better performance but underlying reasons are not fully explored
- Why unresolved: The paper suggests supervised model might have more focused representation but does not delve into specific training aspects
- What evidence would resolve it: Comparative analysis of training objectives, data augmentation, and model architectures

## Limitations

- Findings rely heavily on probing tasks as proxies for representational content, which may not fully capture nuanced information
- LinCKA-based similarity analysis is limited to pairwise comparisons within mini-batches and may not generalize to full distributional differences
- Study does not explore impact of different input feature types on observed patterns

## Confidence

- High Confidence: Speaker SSL models capture phoneme information early in layers
- Medium Confidence: Speech SSL models show unique linguistic patterns in deeper layers absent in speaker models
- Medium Confidence: Better non-speaker representation does not guarantee improved speaker representation

## Next Checks

1. Validate linguistic patterns by applying dedicated linguistic probing tasks to confirm speech SSL models capture deeper linguistic abstractions in later layers

2. Probe cross-model transfer by training a single downstream model on weighted sum of layers from both speech SSL and speaker models to test if combining strengths yields superior performance

3. Analyze feature sensitivity by repeating layer-wise similarity analysis using different input features (MFCCs, raw waveforms) to determine if representational differences are robust to preprocessing choices