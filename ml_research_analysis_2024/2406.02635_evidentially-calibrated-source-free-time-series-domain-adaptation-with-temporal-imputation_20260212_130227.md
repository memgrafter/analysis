---
ver: rpa2
title: Evidentially Calibrated Source-Free Time-Series Domain Adaptation with Temporal
  Imputation
arxiv_id: '2406.02635'
source_url: https://arxiv.org/abs/2406.02635
tags:
- domain
- source
- adaptation
- evidential
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses source-free domain adaptation (SFDA) for time
  series data, where a model pre-trained on a labeled source domain needs to be adapted
  to an unlabeled target domain without access to the source data. Existing SFDA methods
  designed for visual data struggle to capture the inherent temporal dynamics of time
  series, hindering adaptation performance.
---

# Evidentially Calibrated Source-Free Time-Series Domain Adaptation with Temporal Imputation

## Quick Facts
- arXiv ID: 2406.02635
- Source URL: https://arxiv.org/abs/2406.02635
- Authors: Mohamed Ragab; Peiliang Gong; Emadeldeen Eldele; Wenyu Zhang; Min Wu; Chuan-Sheng Foo; Daoqiang Zhang; Xiaoli Li; Zhenghua Chen
- Reference count: 40
- Key outcome: Novel MAPU and E-MAPU methods achieve significant performance gains on five real-world time series datasets for source-free domain adaptation.

## Executive Summary
This paper addresses the challenge of source-free domain adaptation (SFDA) for time series data, where a pre-trained model must adapt to an unlabeled target domain without access to source data. Existing SFDA methods designed for visual data struggle with time series due to their inherent temporal dynamics. The authors propose MAPU, which introduces a temporal imputation task that masks time series signals and leverages a dedicated temporal imputer to recover the original signal within the learned embedding space. This approach ensures temporal consistency between source and target domains. Additionally, E-MAPU incorporates evidential uncertainty estimation to address overconfidence issues in softmax predictions, leading to better-calibrated models and improved adaptation performance.

## Method Summary
The method follows a two-stage approach: pre-training and adaptation. During pre-training on source data, the encoder and classifier are trained using cross-entropy loss while the temporal imputer is trained to reconstruct original signals from masked versions within the feature space. For adaptation, the pre-trained models are used with the encoder updated to generate target features that can be accurately reconstructed by the imputer. E-MAPU adds evidential uncertainty estimation, using Dirichlet distributions over class probabilities to obtain calibrated predictive uncertainty. The target encoder is then adapted to minimize evidential entropy of out-of-support target samples, mapping them closer to the source domain's support.

## Key Results
- MAPU achieves significant performance gains compared to existing SFDA methods across five real-world time series datasets
- E-MAPU further improves performance by incorporating evidential uncertainty estimation
- The temporal imputation approach effectively captures and adapts temporal dynamics in time series data
- Both methods demonstrate versatility and can be integrated with existing SFDA methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal imputation within the learned feature space ensures temporal consistency between source and target domains.
- Mechanism: MAPU trains an imputer network on the source domain by masking time series signals and reconstructing the original signal from its masked version within the feature space. During adaptation, this pre-trained imputer guides the target encoder to generate features that can be accurately reconstructed, thereby aligning the temporal dynamics of the target domain with the source domain.
- Core assumption: Temporal dependencies in time series data can be effectively captured and transferred through feature-level imputation, bypassing the complexities of noisy raw data.
- Evidence anchors:
  - [abstract] "This task involves randomly masking time series signals and leveraging a dedicated temporal imputer to recover the original signal within the learned embedding space, bypassing the complexities of noisy raw data."
  - [section] "This task involves reconstructing the original input signal X from a temporally masked version Xâ€² within the feature space."
  - [corpus] Weak - related papers discuss temporal restoration and imputation but do not explicitly validate the feature-space imputation mechanism described here.
- Break condition: If the temporal dynamics of the target domain are fundamentally different from the source domain, or if the masking ratio is too high, the imputer may fail to accurately reconstruct the target features, hindering adaptation.

### Mechanism 2
- Claim: Evidential uncertainty estimation addresses the overconfidence issue inherent in softmax predictions, leading to better-calibrated models and improved adaptation performance.
- Mechanism: E-MAPU incorporates evidential deep learning to replace softmax probabilities with a Dirichlet distribution over class probabilities. This approach infers a calibrated predictive uncertainty, enabling clearer distinctions in confidence levels between in-distribution (source) and out-of-distribution (target) data. During adaptation, the target encoder is trained to minimize the evidential entropy of out-of-support target samples, mapping them closer to the source domain's support.
- Core assumption: A better-calibrated model, achieved through evidential uncertainty estimation, leads to improved adaptability by more accurately identifying and aligning out-of-distribution target samples.
- Evidence anchors:
  - [abstract] "We further introduce E-MAPU, which incorporates evidential uncertainty estimation to address the overconfidence issue inherent in softmax predictions."
  - [section] "This approach fosters a better-calibrated pre-trained model and effectively tackles overconfidence by enabling clearer distinctions in confidence levels between in-distribution (source) and out-of-distribution (target) data."
  - [corpus] Weak - related papers mention uncertainty estimation but do not specifically validate the evidential uncertainty approach for source-free domain adaptation in time series data.
- Break condition: If the evidential uncertainty estimation fails to accurately distinguish between in-distribution and out-of-distribution samples, or if the target domain's distribution is too far from the source domain, the adaptation process may not effectively align the domains.

### Mechanism 3
- Claim: The proposed framework is versatile and can be integrated with existing SFDA methods, enhancing their temporal adaptation capabilities.
- Mechanism: The temporal imputation component of MAPU can be seamlessly integrated with other SFDA methods during both source pre-training and target adaptation stages. This integration allows existing SFDA methods, primarily designed for visual applications, to effectively capture and adapt temporal dynamics in time series data.
- Core assumption: Temporal consistency is a crucial factor in time series domain adaptation, and incorporating temporal imputation into existing SFDA methods can significantly improve their performance on time series data.
- Evidence anchors:
  - [abstract] "Additionally, it offers seamless integration with existing SFDA methods, providing greater