---
ver: rpa2
title: Towards Precise Scaling Laws for Video Diffusion Transformers
arxiv_id: '2411.17470'
source_url: https://arxiv.org/abs/2411.17470
tags:
- size
- optimal
- arxiv
- scaling
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes precise scaling laws for video diffusion
  transformers by showing that optimal batch size and learning rate depend on both
  model size and training tokens, contrary to prior approaches that used fixed hyperparameters.
  The authors propose new scaling equations that predict optimal hyperparameters for
  any model size and compute budget, enabling accurate performance predictions across
  different configurations.
---

# Towards Precise Scaling Laws for Video Diffusion Transformers

## Quick Facts
- arXiv ID: 2411.17470
- Source URL: https://arxiv.org/abs/2411.17470
- Reference count: 40
- One-line primary result: Established precise scaling laws for video diffusion transformers by showing optimal batch size and learning rate depend on both model size and training tokens, reducing inference costs by 40.1% while maintaining performance

## Executive Summary
This paper addresses a critical gap in video diffusion transformer scaling laws by demonstrating that optimal batch size and learning rate depend on both model size and training tokens, contrary to conventional approaches using fixed hyperparameters. The authors establish new power-law relationships for optimal hyperparameters and validation loss, enabling accurate performance predictions across different configurations. Their approach reduces inference costs by 40.1% while maintaining comparable performance to conventional methods within a compute budget of 10^10 TFlops.

## Method Summary
The authors systematically sweep batch sizes (64-1024) and learning rates (1e-5 to 1e-3) across models ranging from 0.017B to 1.07B parameters, training on 2B to 12B tokens from the Panda-70M dataset. They identify optimal hyperparameter combinations within 0.02% of minimum validation loss for each model size, then fit power-law relationships for optimal batch size (Bopt = αBT^βB N^γB) and learning rate (ηopt = αηT^βη N^γη). Validation loss is modeled as L(T,N) = (Tc/T)^αT + (Nc/N)^αN + L∞, with predictions validated through held-out configurations achieving MSE of 2.35×10^-7 for optimal hyperparameters versus 4.31×10^-7 for fixed hyperparameters.

## Key Results
- Optimal batch size and learning rate scale predictably with model size and training tokens, enabling precise hyperparameter selection
- Using optimal hyperparameters reduces inference costs by 40.1% compared to conventional fixed-parameter approaches while maintaining performance
- The proposed scaling laws predict validation loss with MSE of 2.35×10^-7 for optimal hyperparameters versus 4.31×10^-7 for fixed hyperparameters

## Why This Works (Mechanism)

### Mechanism 1
As model size increases, its complexity grows, leading to a corresponding increase in the Lipschitz constant L. This requires smaller learning rates and larger batch sizes for convergence. When the model's optimization landscape becomes non-smooth or exhibits pathological curvature, this relationship may break down.

### Mechanism 2
Batch size optimization balances gradient noise reduction against number of update steps under fixed compute budget. The trade-off between per-step improvement and total update steps follows a predictable power-law relationship. This breaks when compute budget constraints prevent achieving the optimal trade-off point.

### Mechanism 3
Fixed suboptimal hyperparameters introduce substantial uncertainty and result in less precise scaling laws because hyperparameters that work well for one model size do not necessarily work well for other model sizes. This effect is particularly pronounced at higher compute budgets where model size sensitivity is greatest.

## Foundational Learning

- Concept: Scaling laws in machine learning
  - Why needed here: The paper builds on established scaling law frameworks from language models to video diffusion transformers
  - Quick check question: What is the fundamental relationship described by scaling laws in neural networks?

- Concept: Hyperparameter optimization in large-scale training
  - Why needed here: The paper demonstrates that batch size and learning rate selection critically affects scaling law accuracy
  - Quick check question: How does the optimal learning rate typically scale with batch size in SGD?

- Concept: Power-law relationships in model performance
  - Why needed here: The paper establishes new power-law relationships for optimal hyperparameters and validation loss
  - Quick check question: What is the mathematical form of typical scaling laws relating model size, data size, and performance?

## Architecture Onboarding

- Component map: Cross-DiT architecture with cross-attention modules -> VAE encoding with PixArt-XL-2-512x512 initialization -> T5 text encoder -> 17-frame input sequences at 256x256 resolution -> Panda-70M dataset training

- Critical path: 1) Model initialization with pre-trained components, 2) Hyperparameter selection based on model size and compute budget, 3) Training with optimal batch size and learning rate, 4) Validation loss monitoring every 200 steps, 5) Performance prediction using established scaling laws

- Design tradeoffs: Fixed vs. adaptive hyperparameters (fixed suboptimal parameters lead to 39.9% parameter inefficiency), model size vs. training tokens (trade-off between model complexity and data quantity under fixed compute budget), resolution vs. computational cost (higher resolution requires more compute but may improve quality)

- Failure signatures: Validation loss plateaus early indicating suboptimal hyperparameters, training instability suggesting learning rate too high for model size, poor generalization suggesting insufficient training tokens

- First 3 experiments: 1) Train 0.02B model with varying batch sizes (64-1024) and learning rates (1e-5 to 1e-3) to establish baseline scaling behavior, 2) Train 0.06B model with same hyperparameter sweep to validate size-dependent optimal settings, 3) Train 0.13B model with optimal hyperparameters predicted from smaller models to test extrapolation accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How do video resolution and frame rate specifically impact the scaling laws for video diffusion transformers? The authors mention they did not explore this impact despite acknowledging higher computational demands. This remains unresolved because the study focused on low-resolution, smaller models and the authors explicitly state that higher-resolution models require new fitting approaches. What evidence would resolve it: Experimental results showing how scaling laws change with different resolutions and frame rates, along with corresponding hyperparameter adjustments.

### Open Question 2
What would be the effect of using a learning rate decay schedule instead of a constant learning rate on the scaling laws? The authors note they only fitted scaling laws with a constant learning rate and mention that investigating learning rate decay could yield different results but would require more computational resources. This remains unresolved because the authors chose a constant learning rate for simplicity and to control variables, but acknowledge this may not be optimal for all scenarios. What evidence would resolve it: Comparative experiments using different learning rate schedules (e.g., cosine decay, step decay) and their impact on validation loss and optimal hyperparameters.

### Open Question 3
How robust are the scaling laws across different video generation architectures beyond Cross-DiT? The study focuses on Cross-DiT architecture but the authors do not discuss how generalizable their findings are to other architectures like DiT or auto-regressive models. This remains unresolved because the authors do not provide comparative analysis with other architectures or discuss the architectural dependencies of their scaling laws. What evidence would resolve it: Experimental validation of scaling laws on multiple architectures, showing whether the same hyperparameter relationships and power-law formulations hold.

## Limitations
- The scaling laws are derived from a narrow range of model sizes (0.017B-1.07B parameters) and training tokens (2B-12B), potentially limiting extrapolation accuracy
- The 40.1% inference cost reduction claim is based on fixed compute budgets and may not reflect real-world deployment constraints
- The study uses validation loss as the primary metric, which may not fully capture perceptual quality improvements that users would experience

## Confidence

**High Confidence:** The observation that optimal batch size and learning rate depend on both model size and training tokens is strongly supported by experimental evidence across multiple model scales with sound theoretical foundation.

**Medium Confidence:** The power-law relationships derived for optimal hyperparameters show good fit within tested range but extrapolation beyond studied configurations carries moderate risk. The framework's ability to predict optimal settings for unseen model sizes is empirically validated but could face limitations at extreme scales.

**Medium Confidence:** The demonstration that fixed suboptimal hyperparameters lead to overestimation of optimal model size is well-established, but the specific magnitude of this effect (39.9% parameter inefficiency) may vary with different architectures or training objectives.

## Next Checks

1. **Cross-Architecture Validation:** Train a substantially different video generation architecture (e.g., pure Transformer-based approach without cross-attention modules) using the proposed scaling laws to verify if the same hyperparameter relationships hold. Compare prediction accuracy (MSE) with that achieved in Cross-DiT experiments.

2. **Extreme Scale Testing:** Evaluate the scaling laws at model sizes and training token counts beyond the studied range (e.g., 10B+ parameters, 100B+ training tokens). Test whether power-law relationships for optimal batch size and learning rate continue to hold or if new regimes emerge requiring different modeling approaches.

3. **Real-World Deployment Assessment:** Implement the proposed scaling laws in a production video generation system and measure actual inference latency, throughput, and quality metrics under realistic workloads. Compare these empirical results with theoretical inference cost reductions to identify gaps between theoretical optimization and practical deployment constraints.