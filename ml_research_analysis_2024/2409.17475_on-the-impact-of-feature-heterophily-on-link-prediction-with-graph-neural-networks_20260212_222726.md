---
ver: rpa2
title: On the Impact of Feature Heterophily on Link Prediction with Graph Neural Networks
arxiv_id: '2409.17475'
source_url: https://arxiv.org/abs/2409.17475
tags:
- link
- feature
- prediction
- similarity
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how feature heterophily impacts graph neural
  network (GNN) performance on link prediction tasks, where node labels are not available.
  It introduces formal definitions of homophilic and heterophilic link prediction
  based on the separation of feature similarity scores between edges and non-edges,
  showing that homophilic tasks require positive correlation while heterophilic tasks
  require negative correlation.
---

# On the Impact of Feature Heterophily on Link Prediction with Graph Neural Networks

## Quick Facts
- arXiv ID: 2409.17475
- Source URL: https://arxiv.org/abs/2409.17475
- Authors: Jiong Zhu; Gaotang Li; Yao-An Yang; Jing Zhu; Xuehao Cui; Danai Koutra
- Reference count: 40
- Key outcome: This paper studies how feature heterophily impacts graph neural network (GNN) performance on link prediction tasks, where node labels are not available. It introduces formal definitions of homophilic and heterophilic link prediction based on the separation of feature similarity scores between edges and non-edges, showing that homophilic tasks require positive correlation while heterophilic tasks require negative correlation. Theoretical analysis reveals that different link prediction tasks require distinct optimizations and that linear decoders (e.g., dot product, DistMult) are inadequate for gated tasks where non-linear separation is needed. Empirical results on synthetic and real-world datasets demonstrate that MLP and DistMult decoders outperform dot product decoders, and GNN encoders with ego- and neighbor-embedding separation (e.g., GraphSAGE, SIGN) are more robust to feature similarity variations than those without separation (e.g., GCN). These findings highlight the importance of selecting appropriate decoder and encoder designs for effective link prediction under varying feature homophily conditions.

## Executive Summary
This paper investigates how feature heterophily affects graph neural network performance on link prediction tasks. The authors formally define homophilic and heterophilic link prediction based on the separation of feature similarity scores between edges and non-edges. They demonstrate that different link prediction tasks require distinct optimizations and that linear decoders are inadequate for tasks requiring non-linear separation. Through extensive experiments on synthetic and real-world datasets, they show that MLP and DistMult decoders outperform dot product decoders, and GNN encoders with ego- and neighbor-embedding separation are more robust to feature similarity variations. The findings provide valuable insights for designing effective link prediction models under varying feature homophily conditions.

## Method Summary
The authors study link prediction by analyzing how feature similarity affects the relationship between predicted link probabilities and actual edges. They construct synthetic graphs by sampling node features and creating edges based on feature similarity quantiles. The link prediction models use an encoder-decoder framework with various GNN encoders (GCN, GraphSAGE, BUDDY variants) and decoders (Dot Product, MLP, DistMult). The models are trained using the standard encoder-decoder approach and evaluated using Mean Reciprocal Rank (MRR) and Hits@50 metrics. The experiments compare different encoder-decoder combinations across synthetic and real-world datasets with varying feature homophily levels.

## Key Results
- MLP and DistMult decoders outperform dot product decoders across all feature similarity levels
- GNN encoders with ego- and neighbor-embedding separation (GraphSAGE, SIGN) are more robust to feature similarity variations than those without separation (GCN)
- Performance drops significantly when feature similarity approaches zero, creating a U-shaped curve
- Linear decoders are inadequate for gated link prediction tasks requiring non-linear decision boundaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear decoders (DOT, DistMult) are inadequate for gated link prediction tasks where positive and negative feature similarity distributions cannot be separated by a single threshold
- Mechanism: Gated link prediction requires non-linear decision boundaries to separate edge and non-edge pairs, while linear decoders can only create single thresholds
- Core assumption: The feature similarity distributions for edges and non-edges in gated tasks are disjoint but require multiple separation thresholds
- Evidence anchors:
  - [abstract]: "linear decoders (e.g., dot product, DistMult) are inadequate for gated tasks where non-linear separation is needed"
  - [section]: "No parameter exists for a single linear decoder that perfectly separates link probability for edges and non-edges for gated link prediction"
  - [corpus]: No direct evidence found in corpus for this specific mechanism

### Mechanism 2
- Claim: Separating ego- and neighbor-embeddings in GNN message passing improves generalization under feature similarity variations
- Mechanism: By keeping ego and neighbor features separate during aggregation, the model learns representations that are less sensitive to local degree and similarity variations
- Core assumption: Real-world graphs have power-law degree distributions and large variation in feature similarity
- Evidence anchors:
  - [abstract]: "GNN encoders with ego- and neighbor-embedding separation (e.g., GraphSAGE, SIGN) are more robust to feature similarity variations"
  - [section]: "a GNN model that embeds ego- and neighbor-features together is less capable of generalizing under heterophilic settings"
  - [corpus]: No direct evidence found in corpus for this specific mechanism

### Mechanism 3
- Claim: Feature similarity affects link prediction performance differently across homophilic, heterophilic, and gated tasks
- Mechanism: The relationship between predicted link probability and feature similarity is positive for homophilic tasks, negative for heterophilic tasks, and non-linear for gated tasks
- Core assumption: Link prediction tasks can be categorized based on how edge and non-edge feature similarity distributions are separated
- Evidence anchors:
  - [abstract]: "homophilic tasks require positive correlation while heterophilic tasks require negative correlation"
  - [section]: "predicted link probability and feature similarity scores are positively correlated for homophilic tasks, while negatively correlated for heterophilic tasks"
  - [corpus]: No direct evidence found in corpus for this specific mechanism

## Foundational Learning

- Concept: Feature homophily vs class homophily
  - Why needed here: This paper distinguishes between feature similarity (used in link prediction) and class label similarity (used in node classification), which is crucial for understanding the different challenges in link prediction
  - Quick check question: What's the key difference between feature homophily and class homophily, and why does this distinction matter for link prediction?

- Concept: Graph neural network encoder-decoder framework
  - Why needed here: The paper analyzes link prediction performance through the lens of encoder-decoder architectures, requiring understanding of how GNNs encode node features and how decoders transform pairwise embeddings into link probabilities
  - Quick check question: In a GNN link prediction framework, what are the roles of the encoder and decoder components?

- Concept: Mean-centered cosine similarity
  - Why needed here: The paper uses mean-centered cosine similarity to measure feature similarity between nodes, which is crucial for their theoretical analysis and experimental setup
  - Quick check question: How does mean-centering affect cosine similarity calculations, and why might this be important for analyzing feature similarity in graphs?

## Architecture Onboarding

- Component map: Node features -> GNN encoder -> Node embeddings -> Decoder -> Link probability -> Loss -> Optimization
- Critical path: Node features → GNN encoder → Node embeddings → Decoder → Link probability → Loss → Optimization
- Design tradeoffs: Linear decoders (DOT, DistMult) offer faster inference but limited expressiveness for non-homophilic tasks; MLP decoders offer better performance but slower inference
- Failure signatures: Performance drop when feature similarity approaches zero (U-shaped curve); overfitting to specific similarity or degree buckets; poor generalization across heterogeneous graph regions
- First 3 experiments:
  1. Compare DOT vs MLP vs DistMult decoder performance across different feature similarity levels using synthetic graphs
  2. Test GCN vs GraphSAGE encoders with fixed MLP decoder to evaluate ego-neighbor separation impact
  3. Apply best-performing encoder-decoder combination to real-world datasets with varying feature homophily levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do link prediction performance trends change when using edge features or higher-order structural information instead of node features alone?
- Basis in paper: [explicit] The paper discusses the importance of node features but does not explore the impact of edge features or higher-order structural information on link prediction performance.
- Why unresolved: The paper focuses on node feature homophily and does not consider the potential benefits of incorporating edge features or higher-order structural information.
- What evidence would resolve it: Experiments comparing link prediction performance using node features alone, node and edge features, and node features with higher-order structural information.

### Open Question 2
- Question: How does the performance of link prediction models vary across different types of graphs, such as social networks, biological networks, and knowledge graphs?
- Basis in paper: [inferred] The paper primarily focuses on synthetic and real-world datasets but does not explicitly compare performance across different graph types.
- Why unresolved: The paper does not provide a comprehensive analysis of how link prediction performance varies across different graph domains.
- What evidence would resolve it: Experiments evaluating link prediction performance on diverse graph types, including social networks, biological networks, and knowledge graphs.

### Open Question 3
- Question: How do the findings of this paper generalize to dynamic graphs where the structure and features evolve over time?
- Basis in paper: [inferred] The paper focuses on static graphs and does not address the challenges of link prediction in dynamic graph settings.
- Why unresolved: The paper does not explore the impact of temporal dynamics on link prediction performance.
- What evidence would resolve it: Experiments evaluating link prediction performance on dynamic graphs with evolving structures and features.

### Open Question 4
- Question: How do the results of this paper change when using different similarity measures, such as Euclidean distance or Jaccard similarity, instead of cosine similarity?
- Basis in paper: [explicit] The paper uses cosine similarity to measure feature similarity but does not explore the impact of alternative similarity measures.
- Why unresolved: The paper does not investigate the sensitivity of link prediction performance to different similarity measures.
- What evidence would resolve it: Experiments comparing link prediction performance using different similarity measures, such as Euclidean distance or Jaccard similarity.

### Open Question 5
- Question: How do the findings of this paper apply to link prediction tasks in graphs with overlapping communities or multi-relational edges?
- Basis in paper: [inferred] The paper focuses on homogeneous graphs and does not address the challenges of link prediction in graphs with overlapping communities or multi-relational edges.
- Why unresolved: The paper does not explore the impact of community structure or edge types on link prediction performance.
- What evidence would resolve it: Experiments evaluating link prediction performance on graphs with overlapping communities or multi-relational edges.

## Limitations

- The theoretical analysis assumes feature similarity distributions are always disjoint for gated tasks, which may not hold in real-world graphs
- Experimental validation relies heavily on synthetic graphs constructed from a single real dataset, limiting generalizability
- The superiority of ego-neighbor embedding separation assumes power-law degree distributions are universal across all graph types

## Confidence

- **High confidence**: The formal definitions of homophilic and heterophilic link prediction based on feature similarity separation (90% confidence)
- **Medium confidence**: The empirical superiority of MLP and DistMult decoders over dot product in practice (75% confidence)
- **Low confidence**: The theoretical claim that ego-neighbor embedding separation always improves robustness to feature similarity variations (65% confidence)

## Next Checks

1. Test the hypothesis that linear decoders fail on gated tasks by creating synthetic datasets where feature similarity distributions for edges and non-edges are linearly separable, then measuring decoder performance.

2. Evaluate the ego-neighbor separation hypothesis on graphs with uniform degree distributions (e.g., regular graphs) to identify when the separation mechanism breaks down.

3. Validate the theoretical predictions by applying the framework to datasets from different domains (social networks, biological networks, recommendation systems) to assess generalizability beyond the current experimental scope.