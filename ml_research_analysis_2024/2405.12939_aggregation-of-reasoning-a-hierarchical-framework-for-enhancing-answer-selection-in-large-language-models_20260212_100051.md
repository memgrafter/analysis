---
ver: rpa2
title: 'Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection
  in Large Language Models'
arxiv_id: '2405.12939'
source_url: https://arxiv.org/abs/2405.12939
tags:
- reasoning
- chains
- answer
- evaluation
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a key limitation in current LLM reasoning:
  majority voting over multiple reasoning chains fails when correct answers are in
  the minority. To address this, the authors propose AoR, a hierarchical framework
  that first evaluates reasoning chains within answer groups (local-scoring), then
  compares top chains across answer groups (global-evaluation) to select the final
  answer.'
---

# Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models

## Quick Facts
- arXiv ID: 2405.12939
- Source URL: https://arxiv.org/abs/2405.12939
- Reference count: 0
- Primary result: AoR improves reasoning accuracy by 2.37-8.45% and reduces computational cost by 20% over baselines across multiple reasoning tasks

## Executive Summary
This paper identifies a key limitation in current LLM reasoning: majority voting over multiple reasoning chains fails when correct answers are in the minority. To address this, the authors propose AoR, a hierarchical framework that first evaluates reasoning chains within answer groups (local-scoring), then compares top chains across answer groups (global-evaluation) to select the final answer. AoR also uses dynamic sampling, adding reasoning chains only when the model is uncertain. Experiments show AoR improves accuracy by 2.37-8.45% over baselines across multiple reasoning tasks, while reducing computational cost by 20%. The method works well with various LLM architectures and is more robust than standard majority voting.

## Method Summary
The authors propose AoR, a hierarchical framework to enhance answer selection in LLM reasoning. AoR consists of two main stages: local-scoring, which evaluates reasoning chains within answer groups to identify high-quality chains, and global-evaluation, which compares top chains across answer groups to select the final answer. The framework also incorporates dynamic sampling, generating additional reasoning chains only when the model is uncertain about the current answer distribution. This approach addresses the limitation of majority voting, which fails when correct answers are underrepresented among generated reasoning chains.

## Key Results
- AoR improves reasoning accuracy by 2.37-8.45% over baselines across multiple reasoning tasks (GSM8K, MATH, Commonsense)
- Computational cost is reduced by 20% compared to baseline methods
- AoR is more robust than standard majority voting and works well with various LLM architectures

## Why This Works (Mechanism)
The proposed AoR framework addresses the fundamental limitation of majority voting in LLM reasoning: when correct answers are in the minority, majority voting will almost always select an incorrect answer. AoR's two-stage hierarchical approach first identifies high-quality reasoning chains within each answer group (local-scoring), then compares the best chains across groups to make a final selection (global-evaluation). This allows AoR to better handle cases where correct answers are underrepresented among generated reasoning chains, as it doesn't rely solely on the frequency of answers.

## Foundational Learning

- **Self-evaluation in LLMs**: Why needed - AoR relies on models to evaluate their own reasoning quality; quick check - assess reliability across domains
- **Dynamic sampling strategies**: Why needed - to balance computational cost and answer diversity; quick check - measure impact on accuracy vs. cost
- **Hierarchical reasoning evaluation**: Why needed - to handle cases where correct answers are in the minority; quick check - compare performance on imbalanced answer distributions

## Architecture Onboarding

**Component map**: Dynamic sampling -> Local-scoring -> Global-evaluation -> Final answer selection

**Critical path**: Dynamic sampling determines number of reasoning chains -> Local-scoring evaluates chains within answer groups -> Global-evaluation compares top chains -> Final answer selected

**Design tradeoffs**: Local-scoring relies on self-evaluation which may be biased, but enables efficient ranking within groups; global-evaluation requires more computation but better handles underrepresented correct answers

**Failure signatures**: When self-evaluation is unreliable, local-scoring may rank poor chains highly; when answer space is extremely large, global-evaluation may become computationally expensive

**First experiments**: 1) Ablation study comparing AoR with and without local-scoring stage 2) Test AoR with different dynamic sampling thresholds 3) Evaluate performance across diverse reasoning tasks with varying answer distributions

## Open Questions the Paper Calls Out
None

## Limitations
- Local-scoring relies on self-evaluation by the model, which may be biased or unreliable
- Experiments focus on three reasoning tasks, which are narrow in scope
- No detailed error analysis or examples of failure cases are provided

## Confidence
High: Improvement in accuracy (2.37-8.45%) and computational cost reduction (20%) are clearly demonstrated
Medium: Claims about robustness across different LLM architectures and reasoning tasks are supported but not extensively validated
Medium: The impact of self-evaluation reliability on local-scoring performance is not thoroughly investigated

## Next Checks
1. Test AoR on a wider range of reasoning tasks, especially those with more complex or ambiguous answer spaces
2. Conduct ablation studies to isolate the contribution of local-scoring versus global-evaluation, and assess the impact of self-evaluation reliability
3. Perform a detailed error analysis, including qualitative examples of where AoR succeeds and fails, to better understand its limitations and robustness