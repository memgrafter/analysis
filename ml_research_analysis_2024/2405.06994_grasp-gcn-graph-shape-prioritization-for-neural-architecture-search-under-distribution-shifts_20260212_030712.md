---
ver: rpa2
title: 'GRASP-GCN: Graph-Shape Prioritization for Neural Architecture Search under
  Distribution Shifts'
arxiv_id: '2405.06994'
source_url: https://arxiv.org/abs/2405.06994
tags:
- dataset
- architecture
- predictor
- architectures
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of Neural Architecture Search (NAS)
  under distribution shifts, where predictor-based algorithms struggle to generalize
  across different datasets. The core method, GRASP-GCN, is a ranking Graph Convolutional
  Network that takes as input the structure and vertex shapes of neural networks.
---

# GRASP-GCN: Graph-Shape Prioritization for Neural Architecture Search under Distribution Shifts

## Quick Facts
- arXiv ID: 2405.06994
- Source URL: https://arxiv.org/abs/2405.06994
- Reference count: 23
- The paper addresses NAS under distribution shifts, improving state-of-the-art performance by 3.3% for Cifar-10

## Executive Summary
This paper tackles the challenge of Neural Architecture Search (NAS) under distribution shifts, where predictor-based algorithms struggle to generalize across different datasets. The authors propose GRASP-GCN, a ranking Graph Convolutional Network that takes as additional input the shape of neural network layers. By training with not-at-convergence accuracies and incorporating vertex shape information, GRASP-GCN demonstrates improved generalization capabilities compared to state-of-the-art methods, particularly when transferring between different image datasets.

## Method Summary
GRASP-GCN is a ranking Graph Convolutional Network that encodes neural network structures along with vertex shape information (spatial dimensions of layers). The method uses a Kronecker-product-based search space generation to create scalable Resnet-like architectures while maintaining search efficiency. The GCN is trained using early-stopped accuracies rather than converged performance metrics to improve generalization across datasets. The model is evaluated on four datasets (Cifar-10, Cifar-100, Tiny-ImageNet, Fashion-MNIST) using NDCG, Precision@k, and Kendall's τ metrics.

## Key Results
- Improves state-of-the-art NAS performance by 3.3% for Cifar-10
- Demonstrates enhanced generalization under data distribution shifts
- Outperforms baseline methods when training on one dataset and evaluating on others

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GRASP-GCN improves NAS generalization by incorporating vertex shapes into the GCN input.
- Mechanism: Layer shape information provides context about how layer dimensions change across datasets, allowing the GCN to better predict architecture rankings under distribution shifts.
- Core assumption: Layer shape changes across datasets significantly affect architecture performance.
- Evidence anchors: [abstract]: "propose GRASP-GCN, a ranking Graph Convolutional Network that takes as additional input the shape of the layers"; [section]: "We therefore add the dimensions characterizing each DNN layer."

### Mechanism 2
- Claim: Training with not-at-convergence accuracies improves predictor generalization.
- Mechanism: Early-stopped accuracies represent more generalizable performance patterns that transfer better across datasets than converged accuracies.
- Core assumption: Early training dynamics capture more transferable architecture characteristics.
- Evidence anchors: [abstract]: "GRASP-GCN is trained with the not-at-convergence accuracies"; [section]: "Fig. 5 highlights a possible correlation between the change of rank and the epoch where the learning rate is dropped."

### Mechanism 3
- Claim: Kronecker-product-based search space generation creates scalable architectures while maintaining search efficiency.
- Mechanism: The Kronecker product repeats random matrix patterns to create Resnet-like structures that scale efficiently while avoiding computational costs of sampling large random matrices.
- Core assumption: Resnet-like architectures are sufficiently diverse to find good solutions while being computationally tractable.
- Evidence anchors: [section]: "We exploit the Kronecker product, a trick that allows us balancing flexibility and efficiency."

## Foundational Learning

- Concept: Graph Convolutional Networks
  - Why needed here: GCNs encode neural network structures and make ranking predictions
  - Quick check question: How does a GCN aggregate information from neighboring nodes in a graph?

- Concept: Distribution shift in machine learning
  - Why needed here: The paper addresses predictor generalization across different datasets with varying input distributions
  - Quick check question: What is the difference between covariate shift and concept shift in the context of dataset generalization?

- Concept: Neural Architecture Search fundamentals
  - Why needed here: Understanding NAS workflows is essential to grasp how GRASP-GCN fits into the broader NAS framework
  - Quick check question: What is the difference between predictor-based and one-shot NAS approaches?

## Architecture Onboarding

- Component map: Search space generation (Kronecker product + skeleton matrices) -> Architecture training pipeline (4 datasets × 2000 architectures) -> GRASP-GCN predictor (GCN + vertex shapes + early stopping) -> Evaluation metrics (NDCG, Precision@k, Kendall's τ)

- Critical path: Generate search space → Train architectures on all datasets → Extract vertex shapes and early accuracies → Train GRASP-GCN → Validate on held-out datasets

- Design tradeoffs:
  - Using vertex shapes increases input dimensionality but improves generalization
  - Early stopping reduces computation but may sacrifice final accuracy information
  - Kronecker product constrains search space but improves efficiency

- Failure signatures:
  - Poor NDCG scores indicate the predictor cannot rank architectures correctly
  - High variance across runs suggests instability in training
  - Performance drops when validation dataset differs from training dataset

- First 3 experiments:
  1. Reproduce baseline BRP-NAS results on Cifar-10 for comparison
  2. Train GRASP-GCN with and without vertex shapes on the same dataset
  3. Test predictor generalization by training on Cifar-10 and validating on Fashion-MNIST

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the vertex shape input be generalized to modalities beyond image datasets, such as video or text?
- Basis in paper: [explicit] The authors note that MetaD2A uses an encoder set limiting adaptation to video, while their approach with vertex shapes is more general
- Why unresolved: The paper only validates the vertex shape approach on image classification datasets
- What evidence would resolve it: Experiments applying GRASP-GCN to neural architecture search for video or text classification tasks

### Open Question 2
- Question: How does the performance of GRASP-GCN scale with larger and more diverse search spaces?
- Basis in paper: [inferred] The current search space uses a Kronecker-product-based approach with 2000 architectures
- Why unresolved: The paper's experiments are limited to a specific, relatively small search space
- What evidence would resolve it: Comparative experiments showing GRASP-GCN performance on larger search spaces (e.g., 10K+ architectures)

### Open Question 3
- Question: Would incorporating gradient information as additional input to the GCN further improve predictor performance?
- Basis in paper: [explicit] The authors mention in the limitations section that studying how gradient information inclusion could improve the method is an interesting future direction
- Why unresolved: The current GRASP-GCN only uses architecture structure, layer types, and vertex shapes as inputs
- What evidence would resolve it: Experiments comparing GRASP-GCN variants with and without gradient information inputs

## Limitations

- The vertex shape effectiveness assumption requires further validation on datasets with different image resolutions or channel structures
- Early stopping mechanism's benefits are plausible but the tradeoff between computational savings and potential loss of final accuracy information needs more analysis
- The Kronecker product constraint on search space may limit the diversity of discovered architectures compared to more flexible approaches

## Confidence

**High confidence**: The GCN-based ranking approach with graph convolution is well-established; the methodology for combining structure and shape features is technically sound.

**Medium confidence**: The specific claim of 3.3% improvement for Cifar-10 is supported but depends on implementation details and baseline comparisons that may vary across experimental conditions.

**Medium confidence**: The generalization claims under distribution shifts are promising but require more extensive validation across diverse dataset pairs and domain shifts.

## Next Checks

1. **Vertex shape ablation study**: Systematically test GRASP-GCN performance with and without vertex shapes across multiple dataset pairs to quantify the exact contribution of shape information to generalization.

2. **Early stopping vs. converged accuracy comparison**: Train the GCN with both early-stopped and converged accuracies on the same datasets to measure the actual performance tradeoff and verify that early dynamics capture more generalizable patterns.

3. **Search space diversity analysis**: Evaluate whether the Kronecker-product-constrained search space can discover architectures competitive with more flexible approaches by testing on additional diverse datasets beyond the four used in training.