---
ver: rpa2
title: The Solution for the ICCV 2023 1st Scientific Figure Captioning Challenge
arxiv_id: '2403.17342'
source_url: https://arxiv.org/abs/2403.17342
tags:
- information
- image
- text
- yang
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a solution for the ICCV 2023 Scientific Figure
  Captioning Challenge that combines improved OCR extraction, paragraph refinement
  using LLaMA, and the BRIO model to address exposure bias. The method extracts more
  accurate OCR information using PaddleOCR, refines paragraphs to remove noise from
  irrelevant images using LLaMA, and incorporates contrastive learning through BRIO
  to better align generation and evaluation.
---

# The Solution for the ICCV 2023 1st Scientific Figure Captioning Challenge

## Quick Facts
- **arXiv ID**: 2403.17342
- **Source URL**: https://arxiv.org/abs/2403.17342
- **Reference count**: 17
- **Primary result**: First place in ICCV 2023 Scientific Figure Captioning Challenge with test score of 4.49

## Executive Summary
This paper presents the winning solution for the ICCV 2023 1st Scientific Figure Captioning Challenge, achieving first place with a score of 4.49. The approach addresses the challenge of generating accurate captions for scientific figures by combining improved OCR extraction, paragraph refinement using LLaMA, and the BRIO model with contrastive learning. The solution tackles the exposure bias problem common in figure captioning tasks by better aligning the generation and evaluation processes.

## Method Summary
The proposed solution consists of three main components designed to improve scientific figure captioning. First, it employs PaddleOCR for enhanced OCR extraction to accurately capture textual elements within figures. Second, it uses LLaMA to refine paragraphs by removing noise from irrelevant images, improving the quality of input data. Third, it incorporates the BRIO model with contrastive learning to address the exposure bias problem, where the model generates captions differently than how they are evaluated. This multi-stage pipeline works together to produce more accurate and contextually appropriate captions for scientific figures.

## Key Results
- Achieved first place in ICCV 2023 Scientific Figure Captioning Challenge with test score of 4.49
- Demonstrated enhanced performance particularly on the ROUGE-2-normalized metric
- Successfully addressed exposure bias through contrastive learning integration in the BRIO model

## Why This Works (Mechanism)
The solution works by addressing three critical challenges in scientific figure captioning: accurate text extraction from figures, noise reduction in contextual information, and alignment between generation and evaluation processes. The improved OCR extraction ensures that textual elements within figures are accurately captured, providing essential information for caption generation. The LLaMA-based paragraph refinement removes irrelevant image information that could confuse the captioning model, resulting in cleaner input data. Finally, the BRIO model with contrastive learning directly tackles the exposure bias problem by ensuring the model generates captions in a way that better matches how they will be evaluated.

## Foundational Learning

**PaddleOCR**: A deep learning-based OCR tool that extracts text from images with high accuracy. Needed for accurately capturing textual elements within scientific figures that are crucial for generating informative captions. Quick check: Verify OCR accuracy on figures containing complex mathematical notation and scientific terminology.

**LLaMA**: A large language model used for paragraph refinement and noise reduction. Needed to filter out irrelevant image information and improve the quality of contextual data fed into the captioning model. Quick check: Measure noise reduction effectiveness by comparing input data quality before and after LLaMA refinement.

**BRIO Model**: A figure captioning model that incorporates contrastive learning. Needed to address exposure bias by aligning the generation process with evaluation metrics. Quick check: Validate that contrastive learning improves caption quality by comparing performance with and without this component.

## Architecture Onboarding

**Component Map**: PaddleOCR -> LLaMA Refinement -> BRIO Model with Contrastive Learning

**Critical Path**: The most critical path is PaddleOCR extraction → LLaMA refinement → BRIO generation, as errors at any stage propagate downstream. The OCR quality directly affects the refinement quality, which in turn impacts the final caption generation.

**Design Tradeoffs**: The solution trades computational complexity for accuracy by adding multiple processing stages. While this multi-stage pipeline likely increases computational cost and latency compared to simpler approaches, it achieves superior performance on the competition metrics. The use of LLaMA for refinement adds significant computational overhead but improves caption quality.

**Failure Signatures**: Potential failure modes include: (1) OCR errors leading to missing or incorrect textual information in captions, (2) over-aggressive noise removal by LLaMA that eliminates relevant context, (3) contrastive learning that overfits to specific evaluation metrics rather than producing genuinely better captions, and (4) computational bottlenecks at any stage of the pipeline.

**3 First Experiments**:
1. Test PaddleOCR accuracy on a diverse set of scientific figures with varying text densities and formats
2. Compare caption quality with and without LLaMA refinement to quantify its contribution
3. Evaluate the impact of contrastive learning in BRIO by comparing performance with standard BRIO implementation

## Open Questions the Paper Calls Out
None

## Limitations
- The solution's performance on datasets outside the competition framework is unknown
- The individual contribution of each component to overall improvement is not quantified through ablation studies
- Computational cost and efficiency of the multi-stage pipeline compared to simpler approaches is not discussed

## Confidence
- **High confidence**: Technical implementation details of the three-component pipeline are clearly described and appear reproducible
- **Medium confidence**: First place achievement is supported by competition results, though score context is limited
- **Medium confidence**: Reported performance improvements lack ablation studies showing individual component contributions

## Next Checks
1. Conduct ablation studies to quantify the individual contributions of PaddleOCR, LLaMA paragraph refinement, and BRIO contrastive learning to final performance
2. Test the complete pipeline on established scientific figure captioning benchmarks (FigureCap, SciCap datasets) to assess generalizability beyond competition data
3. Perform qualitative analysis of generated captions to evaluate whether improved ROUGE scores correspond to genuinely more informative and accurate scientific figure descriptions