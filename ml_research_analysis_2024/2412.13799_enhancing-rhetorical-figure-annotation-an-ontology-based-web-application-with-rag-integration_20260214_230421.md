---
ver: rpa2
title: 'Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application
  with RAG Integration'
arxiv_id: '2412.13799'
source_url: https://arxiv.org/abs/2412.13799
tags:
- rhetorical
- figures
- ontology
- figure
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper presents an ontology-based web application, \u201CFind\
  \ your Figure,\u201D for annotating German rhetorical figures, addressing the lack\
  \ of annotated data and qualified annotators in this domain. The application uses\
  \ the restructured GRhOOT ontology, simplifying relations and modeling figures as\
  \ classes for more intuitive querying."
---

# Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application with RAG Integration

## Quick Facts
- arXiv ID: 2412.13799
- Source URL: https://arxiv.org/abs/2412.13799
- Reference count: 14
- Primary result: Developed an ontology-based web application "Find your Figure" for German rhetorical figure annotation with integrated RAG pipeline

## Executive Summary
This paper presents an innovative approach to rhetorical figure annotation through an ontology-based web application that addresses the shortage of annotated data and qualified annotators in German rhetorical analysis. The authors restructured the GRhOOT ontology by reifying relations and converting figures to classes, enabling more intuitive querying and hierarchical annotation. A key contribution is the integration of Retrieval Augmented Generation (RAG) with an LLM, which provides domain-specific knowledge from the ontology and reduces hallucinations while enabling natural interaction with the system.

The application offers dual interaction modes - structured annotation and chatbot-like interaction - making it accessible to both experts and non-experts. Through systematic experimentation with different chunking methods, the authors identified basic chunking with chunk size 2048 as optimal for their RAG pipeline. The system also addresses important ethical considerations around intellectual property rights through verification steps, while planning future enhancements including gamification and user-submitted examples integration.

## Method Summary
The method involves restructuring the German GRhOOT ontology by reifying relations and modeling rhetorical figures as classes instead of individuals. A Flask-based web application called "Find your Figure" was developed with SQLite database integration. The system incorporates an LLM with RAG pipeline using basic chunking (chunk size 2048) to provide domain-specific knowledge. The RAG pipeline was evaluated using the Ragas framework with competency questions from the ontology. User interaction is facilitated through both structured annotation and chatbot interfaces, with plans to add gamification elements in future work.

## Key Results
- Basic chunking with chunk size 2048 achieved optimal performance for the RAG pipeline
- RAG integration successfully reduced LLM hallucinations and provided accurate domain-specific responses
- Dual interaction modes (structured and chat) improved accessibility for both expert and non-expert users
- Reified ontology structure enabled more intuitive querying and hierarchical figure recognition

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reification of ontology relations improves user query intuitiveness and filtering precision.
- **Mechanism:** By decomposing compound relations like `:isRepeatableElementOfSameForm` into simpler relations (`:hasOperation :Repetition`, `:affectedElement :Word`, `:operationalForm :SameForm`), users can filter by specific aspects of figure construction rather than complex string patterns.
- **Core assumption:** Users benefit more from explicit, fine-grained relation filtering than from complex pattern matching.
- **Evidence anchors:**
  - [section]: "We want to make the search more intuitive by breaking compound relations into smaller, fine-grained ones."
  - [abstract]: "The simplification of relations and properties is called reification in the context of ontologies."
  - [corpus]: Weak evidence. No related papers directly address reification benefits for rhetorical figure ontologies.
- **Break condition:** If the additional complexity of maintaining reified relations outweighs the filtering benefits for users.

### Mechanism 2
- **Claim:** RAG integration with ontological knowledge improves LLM performance on rhetorical figure tasks.
- **Mechanism:** By retrieving relevant chunks from the reified GRhOOT ontology and providing them as context to the LLM, RAG reduces hallucinations and grounds responses in domain-specific knowledge.
- **Core assumption:** Rhetorical figure definitions and examples in the ontology are sufficiently comprehensive to guide LLM responses.
- **Evidence anchors:**
  - [abstract]: "We integrate an LLM with RAG to ensure natural interaction with the ontology, and test different settings and chunking methods to find the most effective configuration for our needs."
  - [section]: "RAG reduces hallucinations and enables LLMs to obtain domain-specific knowledge, making it especially useful in areas where fine-tuning is constrained by limited data."
  - [corpus]: Weak evidence. Related papers mention RAG applications but none specifically for rhetorical figure ontologies.
- **Break condition:** If the ontology knowledge is insufficient or the retrieval quality is too low to meaningfully improve LLM responses.

### Mechanism 3
- **Claim:** Modeling rhetorical figures as classes instead of individuals enables hierarchical annotation and subclass recognition.
- **Mechanism:** By representing figures as classes, the ontology can capture that certain figures (e.g., antimetabole) are subclasses of more general figures (e.g., chiasmus), allowing both annotations to be valid.
- **Core assumption:** Hierarchical relationships between rhetorical figures are important for accurate annotation and understanding.
- **Evidence anchors:**
  - [section]: "We also decided to convert the rhetorical figures from individuals to classes to better align with established hierarchies in rhetorical theory."
  - [abstract]: "Another major change is the adaption of textual definitions and example sentences that are no longer modeled as property relations."
  - [corpus]: Weak evidence. No related papers discuss class-based modeling of rhetorical figures in ontologies.
- **Break condition:** If the hierarchical modeling adds unnecessary complexity without improving annotation quality or user understanding.

## Foundational Learning

- **Concept:** Ontological reification and its impact on query capabilities
  - Why needed here: Understanding how breaking down complex relations into simpler ones affects data retrieval and user interaction is crucial for the web application's design.
  - Quick check question: What is the primary benefit of reifying a compound relation like `:isRepeatableElementOfSameForm` in an ontology?

- **Concept:** Retrieval Augmented Generation (RAG) and its components
  - Why needed here: The web application integrates an LLM with RAG to provide domain-specific knowledge about rhetorical figures, requiring understanding of the RAG pipeline and its evaluation.
  - Quick check question: What are the key steps in a typical RAG pipeline, and what is the purpose of each step?

- **Concept:** Competency questions for ontology evaluation
  - Why needed here: The paper uses competency questions to evaluate the RAG pipeline's performance, requiring understanding of their purpose and how to formulate them.
  - Quick check question: What are competency questions, and how are they used to assess the adequacy of an ontology?

## Architecture Onboarding

- **Component map:** GRhOOT ontology -> Web application (Flask) -> SQLite database -> RAG pipeline (chunking, embedding, vector store, LLM) -> User interface
- **Critical path:** 1. User submits text or selects from database 2. Properties are extracted and translated into SPARQL query 3. Query executed on ontology to retrieve matching figures 4. Figures presented with definitions and examples 5. User selects figure(s) and submits annotation 6. Annotation stored in database
- **Design tradeoffs:** Using a file-based vector store instead of a database for simplicity vs. scalability; basic chunking with larger chunk size (2048) vs. advanced chunking techniques; structured annotation vs. chat-like interaction for user experience
- **Failure signatures:** Incorrect figure annotation due to ambiguous properties or user error; LLM hallucinations or incorrect responses despite RAG context; ontology retrieval failures due to SPARQL query issues or data inconsistencies
- **First 3 experiments:** 1. Test the SPARQL query generation and execution with various property combinations 2. Evaluate the RAG pipeline's performance with different chunking methods and settings using the competency questions 3. Assess the user experience and annotation quality with both structured and chat-based interaction modes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the RAG system change when incorporating user-submitted examples into the ontology?
- Basis in paper: [explicit] The paper mentions plans to add user-submitted examples to the ontology and update the vector store to improve RAG performance.
- Why unresolved: The paper does not present experimental results for this scenario, only outlines future work.
- What evidence would resolve it: Empirical results comparing RAG performance before and after integrating user-submitted examples.

### Open Question 2
- Question: What is the impact of intellectual property violations on the dataset quality and model training when using user-submitted text?
- Basis in paper: [explicit] The paper discusses challenges related to intellectual property rights and mentions verification steps.
- Why unresolved: The paper acknowledges the problem but does not provide data on how often violations occur or their impact.
- What evidence would resolve it: Analysis of user submissions showing frequency of potential IP violations and their effects on model performance.

### Open Question 3
- Question: How effective is the verification system in preventing harmful content from being displayed to users, particularly young children?
- Basis in paper: [inferred] The paper mentions implementing a flag for harmful content and planning a daily check, but doesn't evaluate its effectiveness.
- Why unresolved: The paper acknowledges the need for such a system but doesn't provide data on its success rate.
- What evidence would resolve it: Metrics showing the accuracy of harmful content detection and false positive/negative rates.

### Open Question 4
- Question: What is the optimal balance between structured annotation and chatbot interaction for different user groups?
- Basis in paper: [explicit] The paper presents both methods but doesn't compare their effectiveness for different user types.
- Why unresolved: User behavior and preference data is not presented in the paper.
- What evidence would resolve it: User study results comparing task completion rates, accuracy, and satisfaction across different interaction modes.

## Limitations

- The evaluation relies on internal metrics rather than direct comparison with human annotation quality
- The system's performance with ambiguous or borderline rhetorical figure cases is not addressed
- Claims about handling intellectual property concerns are stated but not empirically validated
- The optimal chunking configuration is based on internal metrics without human judgment validation

## Confidence

- **High Confidence:** The technical implementation of the Flask web application and ontology integration is well-described and follows standard practices. The RAG pipeline configuration and evaluation methodology using Ragas are clearly specified.
- **Medium Confidence:** The claim that reifying relations improves query intuitiveness is supported by logical reasoning but lacks empirical validation through user testing. The assertion that class-based modeling enables better hierarchical annotation is theoretically sound but not empirically verified.
- **Low Confidence:** The paper's claims about the system's ability to handle intellectual property concerns and prevent misuse are stated but not demonstrated through actual implementation or testing.

## Next Checks

1. **User Study Validation:** Conduct a controlled user study comparing annotation quality and user satisfaction between the structured annotation interface and traditional manual annotation methods, measuring both accuracy and time efficiency.

2. **Cross-linguistic Testing:** Test the system with texts from different German-speaking regions and varying complexity levels to assess its robustness and identify any language-specific limitations or biases in the ontology.

3. **Long-term Annotation Quality Assessment:** Implement a longitudinal study tracking annotation consistency over time and across multiple users to evaluate the system's effectiveness in maintaining annotation quality and identifying potential systematic biases.