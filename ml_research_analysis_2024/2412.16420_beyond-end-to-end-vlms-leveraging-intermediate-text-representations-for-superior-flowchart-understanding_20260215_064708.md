---
ver: rpa2
title: 'Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior
  Flowchart Understanding'
arxiv_id: '2412.16420'
source_url: https://arxiv.org/abs/2412.16420
tags:
- flowchart
- text
- flow
- node
- mermaid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TEXT FLOW, a two-stage framework for flowchart
  understanding that first converts flowchart images into structured text representations
  (Graphviz, Mermaid, or PlantUML) using a Vision Textualizer, then performs reasoning
  on the text representation using a Textual Reasoner. This approach addresses key
  limitations of end-to-end vision-language models, including limited controllability
  and poor explainability.
---

# Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding

## Quick Facts
- arXiv ID: 2412.16420
- Source URL: https://arxiv.org/abs/2412.16420
- Reference count: 15
- State-of-the-art performance on FlowVQA and FlowLearn benchmarks using TEXT FLOW framework

## Executive Summary
This paper introduces TEXT FLOW, a two-stage framework that converts flowchart images into structured text representations (Graphviz, Mermaid, or PlantUML) using a Vision Textualizer, then performs reasoning on the text representation using a Textual Reasoner. This modular approach addresses key limitations of end-to-end vision-language models, including limited controllability and poor explainability. The framework achieves state-of-the-art performance on FlowVQA and FlowLearn benchmarks, with Graphviz proving to be the most effective text representation format.

## Method Summary
TEXT FLOW decomposes flowchart understanding into two stages: (1) Vision Textualizer converts flowchart images to structured text representations using VLMs, and (2) Textual Reasoner performs question-answering on the text representations using LLMs. The framework explores three text representation formats - Graphviz, Mermaid, and PlantUML - allowing users to select the most appropriate format for their needs. The modular design enables integration of external tools and allows substitution of more capable LLMs when VLMs underperform, enhancing both performance and controllability.

## Key Results
- Achieves state-of-the-art performance on FlowVQA and FlowLearn benchmarks
- Graphviz text representation outperforms Mermaid and PlantUML formats
- Most errors originate from the Vision Textualizer stage, particularly with complex decision nodes
- Framework demonstrates robustness across different flowchart orientations and sizes
- Modular architecture enables better error attribution between visual and textual processing components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The modular decomposition of flowchart understanding into Vision Textualizer and Textual Reasoner stages reduces the complexity of the task by allowing specialized models to focus on their respective strengths.
- Mechanism: By separating visual encoding from reasoning, the framework enables each component to handle a more focused subtask, reducing the cognitive load on any single model and improving overall accuracy.
- Core assumption: That breaking down complex visual reasoning tasks into visual encoding and text-based reasoning stages leads to better performance than end-to-end processing.
- Evidence anchors:
  - [abstract]: "TEXT FLOW offers three key advantages: (i) users can select the type of text representations (e.g., GRAPHVIZ, MERMAID, PLANT UML), or further convert them into executable graph object to call tools, enhancing performance and controllability; (ii) it improves explainability by helping to attribute errors more clearly to visual or textual processing components"
  - [section]: "This dual-stage framework provides three distinct advantages: (i) Controllability—users can flexibly choose the type of text representation... (ii) Explainability—it improves error attribution by clarifying whether failures arise from visual or textual components; and (iii) Modularity—the framework allows for the use of more advanced LLMs in the REASONER stage when VLMs are inadequate"
  - [corpus]: Weak. Corpus contains related VLM work but lacks direct evidence of modular decomposition benefits for flowchart understanding specifically.
- Break condition: If the Vision Textualizer fails to produce accurate text representations, the reasoning stage cannot compensate regardless of its sophistication.

### Mechanism 2
- Claim: Using structured text representations (Graphviz, Mermaid, PlantUML) as intermediate outputs provides better controllability and interpretability than end-to-end VLM approaches.
- Mechanism: Structured text representations allow users to inspect, modify, and validate the intermediate output before reasoning, enabling better debugging and fine-tuning of the system.
- Core assumption: That structured text representations preserve the essential semantic and topological information of flowcharts in a format that LLMs can reason about effectively.
- Evidence anchors:
  - [abstract]: "users can select the type of text representations (e.g., GRAPHVIZ, MERMAID, PLANT UML), or further convert them into executable graph object to call tools, enhancing performance and controllability"
  - [section]: "We explore three flowchart textualization formats (examples can be found in Figure 1): MERMAID... GRAPHVIZ... PLANT UML..."
  - [corpus]: Weak. Corpus shows related VLM work but doesn't specifically address structured text representations for flowchart understanding.
- Break condition: If the chosen text representation format cannot adequately capture the complexity of the flowchart structure, reasoning accuracy will degrade.

### Mechanism 3
- Claim: The modular architecture enables substitution of more capable LLMs for the reasoning stage when VLMs are insufficient, providing flexibility and performance gains.
- Mechanism: By decoupling the reasoning stage from the visual encoding stage, the system can leverage the superior reasoning capabilities of LLMs without requiring those LLMs to also handle visual processing.
- Core assumption: That LLMs generally outperform VLMs on pure text-based reasoning tasks, making them better suited for the reasoning stage.
- Evidence anchors:
  - [abstract]: "it promotes the modularization of the solution, such as allowing advanced LLMs to be used in the REASONER stage when VLMs underperform in end-to-end fashion"
  - [section]: "the framework allows for the use of more advanced LLMs in the REASONER stage if VLMs are inadequate for end-to-end flowchart understanding, restricting the VLM to the TEXTUALIZER stage only"
  - [corpus]: Weak. While the corpus mentions various VLM and LLM approaches, it doesn't provide direct evidence of the benefits of modular substitution.
- Break condition: If the Vision Textualizer produces low-quality text representations, even the best LLM reasoner will struggle to provide accurate answers.

## Foundational Learning

- Concept: Visual encoding and reasoning as separate cognitive processes
  - Why needed here: Understanding why decomposition improves performance requires recognizing that visual perception and logical reasoning are distinct cognitive functions that may benefit from specialized processing
  - Quick check question: Why might separating visual processing from reasoning improve performance on complex visual tasks?

- Concept: Structured text representations for graph data
  - Why needed here: The effectiveness of Graphviz, Mermaid, and PlantUML formats depends on understanding how graph structures can be represented textually while preserving semantic relationships
  - Quick check question: What key information must a text representation preserve to enable accurate reasoning about flowchart topology?

- Concept: Error propagation in multi-stage systems
  - Why needed here: Understanding where errors occur in the pipeline (Vision Textualizer vs. Textual Reasoner) is crucial for debugging and improving the system
  - Quick check question: In a two-stage system, how does an error in the first stage affect the second stage's ability to produce correct outputs?

## Architecture Onboarding

- Component map: Image → Vision Textualizer → Structured Text → Textual Reasoner → Answer
- Critical path: Image → Vision Textualizer → Structured Text → Textual Reasoner → Answer
  The Vision Textualizer quality is the primary bottleneck; if it fails, the entire pipeline fails.
- Design tradeoffs:
  - End-to-end VLM vs. modular approach: Modularity provides better controllability and explainability but adds complexity
  - Text representation choice: Different formats (Graphviz, Mermaid, PlantUML) offer different tradeoffs between simplicity and expressiveness
  - Tool integration: Enhances reasoning accuracy but increases system complexity and potential failure points
- Failure signatures:
  - Vision Textualizer failures: Incorrect node/edge extraction, syntax errors in text output, missing decision nodes
  - Textual Reasoner failures: Misinterpretation of text structure, incorrect logical reasoning, failure to use provided tools
  - System-wide failures: Poor performance on complex flowcharts, degradation with increasing node count
- First 3 experiments:
  1. Test Vision Textualizer with simple flowcharts to establish baseline text extraction accuracy
  2. Evaluate Textual Reasoner performance using gold-standard text representations to isolate reasoning capability
  3. Compare different text representation formats (Graphviz vs. Mermaid vs. PlantUML) using the same Vision Textualizer and Textual Reasoner models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TextFlow's performance scale with more complex flowcharts that include nested decision structures or multiple layers of abstraction?
- Basis in paper: [inferred] The paper mentions that TextFlow struggles with complex flowcharts and that open-source models have difficulty handling syntax errors in PlantUML, particularly with nested loops and complex decision nodes.
- Why unresolved: While the paper demonstrates TextFlow's effectiveness on standard flowcharts, it does not provide extensive testing on highly complex flowcharts with nested structures. The limitations section also notes that TextFlow is not tested on dependency graphs or Gantt charts.
- What evidence would resolve it: Additional experiments testing TextFlow on flowcharts with increasing complexity, including nested decision structures, multiple abstraction layers, and comparison with other complex diagram types like dependency graphs.

### Open Question 2
- Question: What is the impact of integrating domain-specific knowledge bases or retrieval-augmented generation (RAG) techniques on TextFlow's reasoning performance?
- Basis in paper: [explicit] The limitations section mentions that TextFlow may need integration with RAG techniques or external knowledge bases when flowcharts require domain-specific knowledge or links to other documents.
- Why unresolved: The paper does not explore the integration of external knowledge sources with TextFlow, focusing instead on the core vision-to-text and text-to-reasoning pipeline.
- What evidence would resolve it: Experiments comparing TextFlow's performance with and without integration of domain-specific knowledge bases or RAG techniques on flowcharts that require external knowledge.

### Open Question 3
- Question: How does TextFlow perform on flowcharts with different visual styles, layouts, or orientations beyond the standard top-down and bottom-up configurations tested?
- Basis in paper: [inferred] The paper tests robustness across different orientations (top-down vs. bottom-up) and sizes, but does not explore other visual styles or layouts that might be present in real-world flowcharts.
- Why unresolved: While TextFlow shows robustness to orientation changes, the paper does not investigate how it handles alternative flowchart styles, such as circular layouts, horizontal flows, or flowcharts with varied visual elements like colors and shapes.
- What evidence would resolve it: Additional experiments testing TextFlow on flowcharts with various visual styles, layouts, and non-standard configurations to assess its generalization capabilities across diverse visual presentations.

## Limitations

- The framework's performance may degrade with extremely complex flowcharts containing nested decision structures or multiple abstraction layers
- Manual annotation of PlantUML ground truth introduces potential consistency issues and scalability challenges
- The approach is primarily evaluated on flowcharts and may not generalize well to other types of visual diagrams like dependency graphs or Gantt charts

## Confidence

- High: State-of-the-art performance on FlowVQA and FlowLearn benchmarks is well-supported by quantitative results
- Medium: Error attribution analysis between Vision Textualizer and Textual Reasoner components is clear but relies on manual inspection
- Low: Generalizability beyond flowcharts is not extensively tested, limiting confidence in broader applicability

## Next Checks

1. Test the framework on other graph-structured visual domains (such as organizational charts or mind maps) to assess generalizability beyond flowcharts
2. Conduct ablation studies isolating the contribution of the modular architecture from the LLM reasoning capabilities
3. Evaluate performance degradation with increasing flowchart complexity, particularly focusing on the Vision Textualizer's ability to handle complex decision nodes with multiple incoming/outgoing links