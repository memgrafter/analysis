---
ver: rpa2
title: 'Language models emulate certain cognitive profiles: An investigation of how
  predictability measures interact with individual differences'
arxiv_id: '2406.04988'
source_url: https://arxiv.org/abs/2406.04988
tags:
- surprisal
- reading
- entropy
- cognitive
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether incorporating information about
  individuals' cognitive capacities improves the predictive power of surprisal and
  entropy measures from language models on reading times. The authors use the Individual
  Differences Corpus, which includes eye-tracking reading data and psychometric scores
  for 61 native German speakers.
---

# Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences

## Quick Facts
- arXiv ID: 2406.04988
- Source URL: https://arxiv.org/abs/2406.04988
- Reference count: 27
- This work investigates whether incorporating information about individuals' cognitive capacities improves the predictive power of surprisal and entropy measures from language models on reading times.

## Executive Summary
This study investigates how individual differences in cognitive capacities interact with language model predictability measures to influence reading times. Using eye-tracking data from 61 German speakers and five different language models (GPT-2 variants, Llama 2, and Mixtral), the authors find that incorporating cognitive scores as interaction terms with surprisal and entropy significantly improves prediction accuracy. The results reveal that language models generally better predict reading times for individuals with lower verbal intelligence scores, suggesting systematic biases in how these models represent different cognitive profiles.

## Method Summary
The study uses the Individual Differences Corpus containing reading times and psychometric scores for 61 native German speakers. The authors extract surprisal and entropy estimates from five German language models and include them as predictors in linear-mixed models to predict reading times. They evaluate the predictive power of these models both with and without interaction terms between predictability measures and cognitive scores, using cross-validation and log-likelihood comparisons to assess improvements.

## Key Results
- Adding interaction terms between predictability measures (surprisal/entropy) and most cognitive scores significantly improves reading time prediction accuracy
- Individuals with higher cognitive capacities generally exhibit smaller predictability effects (lower sensitivity to surprisal and entropy)
- Language models better predict reading times for individuals with lower verbal intelligence scores, suggesting systematic biases toward certain cognitive profiles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating cognitive capacity scores as interaction terms with surprisal and entropy improves prediction accuracy of reading times.
- Mechanism: Cognitive capacities modulate the magnitude of predictability effects, with higher cognitive capacities generally associated with lower sensitivity to surprisal and entropy.
- Core assumption: Individual differences in cognitive capacities meaningfully influence language processing and predictive reading strategies.
- Evidence anchors:
  - [abstract] "adding interaction terms between predictability measures (surprisal and entropy) and most cognitive scores significantly improves the quality of reading time predictions"
  - [section 4.2] "we see that the interaction terms between surprisal/entropy and most psychometric scores lead to significant increases in PP, except for Stroop, non-verbal RIAS and spatial short-term memory"
- Break condition: If the interaction terms between cognitive scores and predictability measures do not lead to significant improvements in prediction accuracy.

### Mechanism 2
- Claim: Language models (LMs) exhibit systematic biases towards readers of certain cognitive profiles.
- Mechanism: LMs provide better predictability estimates (surprisal and entropy) for individuals with lower verbal intelligence scores, suggesting that LMs emulate readers with lower verbal intelligence.
- Core assumption: The way LMs process language is not uniformly representative of all cognitive profiles.
- Evidence anchors:
  - [abstract] "all tested models emulate the processing behaviour of individuals with low verbal intelligence"
  - [section 4.4] "we find that across all models, RT predictions are significantly better for the low-performing group in the operation span test as well as the vocabulary size test MWT"
- Break condition: If LMs provide equally accurate predictability estimates for individuals with both high and low verbal intelligence scores.

### Mechanism 3
- Claim: The predictive power of LM surprisal and entropy varies across different cognitive domains.
- Mechanism: Modulating surprisal and entropy with scores targeting specific cognitive domains (e.g., reading fluency, working-memory span) yields varying degrees of improvement in prediction accuracy.
- Core assumption: Different cognitive domains have distinct relationships with language processing and predictability effects.
- Evidence anchors:
  - [section 4.2] "Notably, PP is not significant (or extremely small) for these three scores across all models" (referring to Stroop, non-verbal RIAS and spatial short-term memory)
  - [section 4.2] "Scores targeting cognitive control show the lowest PP" (in comparison to reading fluency or working-memory span)
- Break condition: If the predictive power of surprisal and entropy does not vary significantly across different cognitive domains.

## Foundational Learning

- Concept: Linear Mixed Models (LMMs)
  - Why needed here: LMMs are used to predict reading times from a set of standardized word-level and subject-level predictors, including surprisal, entropy, and their interactions with cognitive scores.
  - Quick check question: What are the key components of a linear mixed model, and how do they differ from standard linear regression models?

- Concept: Surprisal and Contextual Entropy
  - Why needed here: Surprisal and contextual entropy are measures of predictability derived from language models, and their interaction with cognitive scores is central to the study's hypotheses.
  - Quick check question: How are surprisal and contextual entropy calculated, and what do they represent in the context of language processing?

- Concept: Cognitive Capacities and Psychometric Tests
  - Why needed here: The study uses scores from various psychometric tests targeting different cognitive domains to assess how individual differences in cognitive capacities influence predictability effects.
  - Quick check question: What are some common cognitive domains assessed in psychometric tests, and how might they relate to language processing?

## Architecture Onboarding

- Component map: InDiCo corpus -> Language models (GPT-2 base/large, Llama 2 7B/13B, Mixtral) -> Surprisal/entropy estimates -> Linear-mixed models with cognitive scores -> Reading time predictions

- Critical path:
  1. Extract surprisal and entropy estimates from LMs for each word in the corpus.
  2. Fit linear-mixed models to predict reading times, including baseline predictors and predictors of interest (surprisal, entropy, and their interactions with cognitive scores).
  3. Assess the predictive power of each model using cross-validation and compare the log-likelihoods of models with and without interaction terms.

- Design tradeoffs:
  - Model choice: Using auto-regressive LMs aligns with the incremental nature of human language comprehension but may not capture non-incremental processing strategies.
  - Token granularity: Summing sub-word token surprisal values provides a word-level measure but may introduce approximation errors, especially for entropy.

- Failure signatures:
  - Poor model fit: If the interaction terms between cognitive scores and predictability measures do not lead to significant improvements in prediction accuracy.
  - Inconsistent results: If the findings are not consistent within and across different LM families, as noted in the discussion section.

- First 3 experiments:
  1. Replicate the baseline analysis (H B) to establish the predictive power of surprisal and entropy without considering cognitive scores.
  2. Conduct the interaction analysis (H1) to assess whether modulating surprisal and entropy with cognitive scores improves prediction accuracy.
  3. Perform the group analysis (H3) to investigate whether LMs exhibit systematic biases towards readers of certain cognitive profiles.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do individuals with higher verbal intelligence scores show lower surprisal effects, contrary to expectations that more intelligent readers would be more sensitive to predictability?
- Basis in paper: [explicit] "We found that surprisal estimates across all tested models predicted RTs better for the group of individuals with low verbal intelligence scores"
- Why unresolved: The paper suggests language models might overestimate predictability effects for high-verbal-intelligence readers, but the underlying cognitive mechanisms remain unclear.
- What evidence would resolve it: Direct comparisons of predictability effects between individuals with high vs. low verbal intelligence across multiple linguistic contexts and languages.

### Open Question 2
- Question: What accounts for the divergent effects of verbal vs. non-verbal cognitive control measures on surprisal sensitivity?
- Basis in paper: [explicit] "individuals with higher FAIR-scores (attention and concentration) exhibit weaker surprisal effects" while "individuals performing well in the Simon test (inhibitory non-verbal cognitive control) exhibit stronger surprisal effects"
- Why unresolved: The paper notes this finding but does not explain the differential impact of verbal and non-verbal cognitive control on predictive processing.
- What evidence would resolve it: Experimental studies manipulating verbal and non-verbal cognitive control independently while measuring surprisal effects.

### Open Question 3
- Question: Why do different language models show varying biases toward specific cognitive profiles despite similar baseline predictive power?
- Basis in paper: [explicit] "entropy estimated from GPT-2 large showed the strongest increase in PP for the high reading-fluency word reading group" while "entropy estimated with GPT-2 base" showed different patterns
- Why unresolved: The paper notes these differences but doesn't explain the architectural or training factors causing them.
- What evidence would resolve it: Systematic comparisons of model architecture, training data, and tokenization strategies across different LM families.

## Limitations

- The extent to which observed interactions between cognitive scores and predictability measures reflect genuine cognitive mechanisms versus statistical artifacts remains uncertain
- While five language models provide some cross-validation, potential model-specific biases in predicting reading times for different cognitive profiles warrant further investigation
- The study's findings may not generalize to languages other than German or to populations with different demographic characteristics

## Confidence

- **High Confidence:** The core finding that incorporating cognitive capacity scores as interaction terms with surprisal and entropy improves prediction accuracy of reading times is well-supported by the statistical analysis and cross-validation results.
- **Medium Confidence:** The claim that language models exhibit systematic biases towards readers of certain cognitive profiles is supported by the group analysis, but the underlying reasons for these biases and their implications for language model design and application require further exploration.
- **Low Confidence:** The extent to which the observed interactions between cognitive scores and predictability measures reflect genuine cognitive mechanisms versus statistical artifacts is uncertain and requires additional validation.

## Next Checks

1. **Replication with Alternative Datasets:** Validate the findings using a different reading time corpus with diverse cognitive profiles to assess the generalizability of the observed interactions and biases.
2. **Mechanistic Investigation:** Conduct follow-up experiments to elucidate the cognitive mechanisms underlying the interactions between individual differences and predictability effects, potentially using neuroimaging or eye-tracking data.
3. **Model Comparison and Ablation:** Perform a more extensive comparison of language models, including models trained on specific cognitive profiles or with architectural modifications to better capture individual differences in language processing.