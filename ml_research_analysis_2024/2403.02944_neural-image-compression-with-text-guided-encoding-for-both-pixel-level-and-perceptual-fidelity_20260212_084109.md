---
ver: rpa2
title: Neural Image Compression with Text-guided Encoding for both Pixel-level and
  Perceptual Fidelity
arxiv_id: '2403.02944'
source_url: https://arxiv.org/abs/2403.02944
tags:
- image
- taco
- text
- compression
- text-guided
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving both high pixel-level
  fidelity (e.g., PSNR) and perceptual fidelity (e.g., LPIPS) in text-guided image
  compression. While recent text-guided approaches excel at perceptual quality, they
  often sacrifice pixel-level accuracy, limiting their practicality.
---

# Neural Image Compression with Text-guided Encoding for both Pixel-level and Perceptual Fidelity

## Quick Facts
- arXiv ID: 2403.02944
- Source URL: https://arxiv.org/abs/2403.02944
- Authors: Hagyeong Lee; Minkyu Kim; Jun-Hyuk Kim; Seungeon Kim; Dokwan Oh; Jaeho Lee
- Reference count: 35
- Key outcome: Proposes TACO, achieving state-of-the-art LPIPS while maintaining competitive PSNR in text-guided image compression

## Executive Summary
This paper addresses the fundamental challenge in image compression of balancing pixel-level fidelity (measured by PSNR) with perceptual quality (measured by LPIPS). While recent text-guided compression methods excel at perceptual quality, they often sacrifice pixel-level accuracy, limiting their practical utility. The authors propose TACO, a novel encoder-centric approach that injects text information through a text adapter module and joint image-text loss, enabling effective semantic enhancement without the generative diversity introduced by text-guided decoding.

## Method Summary
TACO introduces a novel encoder-centric approach to text-guided image compression that leverages a text adapter module and joint image-text loss. Unlike existing methods that use text-guided decoding (which can introduce excessive generative diversity), TACO achieves global semantic injection through the encoder. The method processes images through a standard encoder, then applies text information via the adapter before reconstruction. This architecture allows TACO to outperform existing baselines in LPIPS while maintaining competitive PSNR, FID, and CMMD scores across multiple datasets.

## Key Results
- Achieves best LPIPS performance among all evaluated methods
- Maintains PSNR within 1 dB of the best performing method
- Outperforms existing baselines in perceptual quality metrics while remaining competitive on pixel-level metrics
- Demonstrates effectiveness across multiple datasets including CLIC, Kodak, and CVPR-Compression-Hub

## Why This Works (Mechanism)
TACO works by injecting text information at the encoder level rather than the decoder, which prevents the excessive generative diversity that can occur with text-guided decoding approaches. The text adapter module allows for global semantic injection, meaning the compression process can leverage semantic understanding from the text description without being constrained to reconstruct specific pixel values. This enables the method to prioritize perceptual quality while maintaining sufficient pixel-level fidelity for practical applications.

## Foundational Learning
1. **Perceptual vs Pixel-level Fidelity**: Understanding the tradeoff between metrics like PSNR (pixel-level) and LPIPS (perceptual) is crucial. PSNR measures exact pixel reconstruction accuracy, while LPIPS measures human perceptual similarity, which are often in tension in compression systems.

2. **Text-guided Compression**: Recent advances use text descriptions to guide image compression, improving perceptual quality by leveraging semantic understanding. However, these methods often struggle to maintain pixel-level accuracy.

3. **Encoder-centric vs Decoder-centric Design**: The architectural choice of where to inject text information (encoder vs decoder) significantly impacts the compression outcome. Encoder-centric approaches like TACO can achieve semantic enhancement without the generative diversity issues of decoder-based methods.

4. **Global Semantic Injection**: The concept of incorporating semantic understanding across the entire image rather than local regions, which is essential for maintaining coherent perceptual quality while preserving important visual details.

5. **Compression Baselines**: Familiarity with traditional codecs (like BPG) and neural compression methods, including their strengths and limitations in balancing different fidelity metrics.

6. **Evaluation Metrics**: Understanding the roles of PSNR, LPIPS, FID, and CMMD in evaluating compression quality, where PSNR and LPIPS often show inverse relationships.

## Architecture Onboarding

**Component Map**: Input Image -> Encoder -> Text Adapter -> Decoder -> Output Image, with Text Description feeding into Text Adapter module

**Critical Path**: The core processing flow goes through the standard encoder, receives text information via the adapter, then passes to the decoder for reconstruction. The text adapter is the novel component that enables semantic enhancement.

**Design Tradeoffs**: The key tradeoff is between perceptual enhancement and pixel-level reconstruction accuracy. By choosing encoder-centric text injection rather than decoder-based guidance, TACO sacrifices some pixel-level precision to achieve superior perceptual quality, though it maintains PSNR within 1 dB of the best methods.

**Failure Signatures**: Methods that rely on text-guided decoding often exhibit excessive generative diversity, producing outputs that may be perceptually similar but significantly different at the pixel level. TACO's encoder-centric approach mitigates this by constraining the reconstruction process while still leveraging semantic information.

**3 First Experiments**:
1. Test TACO on a simple image compression task without text guidance to establish baseline performance
2. Evaluate the impact of removing the text adapter module to quantify its contribution
3. Compare encoding/decoding times with traditional codecs to understand computational overhead

## Open Questions the Paper Calls Out
None

## Limitations
- The method shows a fundamental tradeoff where absolute PSNR values remain below traditional codecs without text guidance
- Evaluation is limited to specific datasets (CLIC, Kodak, CVPR-Compression-Hub) and may not generalize to all image types
- Computational overhead from the text adapter and joint loss components is not thoroughly characterized

## Confidence
- High confidence: LPIPS performance improvements over baselines
- Medium confidence: The claim about bridging pixel-level and perceptual fidelity gaps
- Medium confidence: The superiority of encoder-centric text injection over decoder-based approaches

## Next Checks
1. Test TACO on additional diverse datasets beyond the three used in the paper to verify generalizability
2. Conduct ablation studies removing the text adapter and joint loss components to quantify their individual contributions
3. Measure and report the computational overhead (encoding/decoding time and model complexity) compared to baseline methods