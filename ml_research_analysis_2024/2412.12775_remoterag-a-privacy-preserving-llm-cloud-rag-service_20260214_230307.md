---
ver: rpa2
title: 'RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service'
arxiv_id: '2412.12775'
source_url: https://arxiv.org/abs/2412.12775
tags:
- documents
- embedding
- cloud
- privacy
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces RemoteRAG, a privacy-preserving cloud RAG\
  \ service that addresses the privacy concerns of sending user queries to cloud-based\
  \ RAG services. The core method introduces (n,\u03B5)-DistanceDP to characterize\
  \ privacy leakage and generates a perturbed embedding for the cloud while limiting\
  \ the search range to a small number of relevant documents."
---

# RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service

## Quick Facts
- arXiv ID: 2412.12775
- Source URL: https://arxiv.org/abs/2412.12775
- Authors: Yihang Cheng; Lan Zhang; Junyang Wang; Mu Yuan; Yunhao Yao
- Reference count: 40
- Primary result: Privacy-preserving cloud RAG service that achieves 100% retrieval accuracy while resisting embedding inversion attacks with minimal computation (0.67s) and communication (46.66KB) costs

## Executive Summary
RemoteRAG addresses privacy concerns in cloud-based RAG services by introducing a novel privacy-preserving mechanism that generates a perturbed embedding from user queries while maintaining retrieval accuracy. The system uses (n,ε)-DistanceDP to characterize privacy leakage, limits search range to relevant documents, and employs partially homomorphic encryption for secure distance calculations. Experimental results demonstrate that RemoteRAG can resist existing embedding inversion attacks while achieving no loss in retrieval performance, with dramatic efficiency improvements over non-optimized privacy-preserving approaches.

## Method Summary
RemoteRAG introduces a privacy-preserving cloud RAG service that generates a perturbed embedding using (n,ε)-DistanceDP mechanism, limiting search range to k' documents while ensuring the top k relevant documents are included. The system employs partially homomorphic encryption for secure cosine distance calculations between encrypted query embeddings and document embeddings. The method significantly reduces computation and communication costs while maintaining retrieval accuracy through theoretical analysis of the perturbation mechanism and search range optimization.

## Key Results
- Resists embedding inversion attacks while achieving 100% retrieval accuracy
- Reduces computation time from 2.72 hours to 0.67 seconds for 10^6 documents
- Reduces communication costs from 1.43 GB to 46.66 KB
- Maintains retrieval performance with privacy budget ε=10

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The (n,ε)-DistanceDP mechanism ensures bounded privacy leakage controlled by privacy budget ε
- **Mechanism**: Generates perturbed embedding by sampling radial component from Gamma(n, 1/ε) distribution and direction uniformly from n-dimensional unit sphere
- **Core assumption**: Embedding space is normalized and distance correlates with semantic similarity
- **Evidence anchors**:
  - [abstract]: "For privacy, we propose (n, ε)-DistanceDP inspired by differential privacy and an embedding perturbation mechanism"
  - [section 3.2.1]: "probability density function...D n, ε (x|x0) ∝ e^(-ε‖x - x0‖)"
- **Break condition**: If embedding space is not normalized or semantic similarity doesn't correlate with distance

### Mechanism 2
- **Claim**: Limiting search range to k' documents ensures top k relevant documents are included while reducing costs
- **Mechanism**: User calculates k' from Theorem 1 ensuring top k documents for query embedding are included in k' documents for perturbed embedding
- **Core assumption**: Perturbation is small compared to distance between query and document embeddings
- **Evidence anchors**:
  - [abstract]: "limit the search range from the total documents to a small number of selected documents"
  - [section 3.2.2]: "To ensure that top k documents...include top k documents related to the query embedding"
- **Break condition**: If perturbation is too large, top k relevant documents may not be included

### Mechanism 3
- **Claim**: PHE ensures cloud cannot reverse engineer query embedding while allowing cosine distance computation
- **Mechanism**: User encrypts query embedding using PHE, cloud calculates encrypted distances, user decrypts and sorts
- **Core assumption**: PHE supports operations needed for cosine distance calculation
- **Evidence anchors**:
  - [abstract]: "retrieve relevant documents within a minimum search range for efficiency"
  - [section 3.3.1]: "Considering that cosine distance involves only linear operations, we propose using PHE"
- **Break condition**: If PHE doesn't support necessary operations or cloud breaks encryption

## Foundational Learning

- **Concept**: Differential Privacy
  - **Why needed here**: Provides framework for quantifying and limiting privacy leakage for (n,ε)-DistanceDP mechanism
  - **Quick check question**: What is the main idea behind differential privacy and how does it relate to (n,ε)-DistanceDP?

- **Concept**: Embedding Space and Semantic Similarity
  - **Why needed here**: Mechanism relies on distance between embeddings correlating with semantic similarity in normalized space
  - **Quick check question**: How does distance between embeddings in normalized space relate to their semantic similarity?

- **Concept**: Partially Homomorphic Encryption (PHE)
  - **Why needed here**: Encrypts query embedding while allowing cosine distance computation for privacy during retrieval
  - **Quick check question**: What operations does PHE support and why is it suitable for cosine distances?

## Architecture Onboarding

- **Component map**: User -> (Perturbation Generation, Encryption) -> Cloud -> (Document Retrieval, Encrypted Distance Calculation) -> Vector Database
- **Critical path**: User generates perturbed embedding → User encrypts query embedding → Cloud retrieves k' documents → Cloud calculates encrypted distances → User decrypts distances → User sorts distances and retrieves top k documents
- **Design tradeoffs**:
  - Privacy vs. Efficiency: Higher ε improves privacy but may affect retrieval accuracy
  - Privacy vs. Communication: OT protocol increases communication but provides stronger privacy
  - Security vs. Performance: PHE ensures privacy but introduces computational overhead
- **Failure signatures**:
  - Retrieval accuracy drops: Perturbation too large or search range too small
  - Communication costs too high: OT protocol used unnecessarily
  - Privacy leakage detected: PHE vulnerability or (n,ε)-DistanceDP weakness
- **First 3 experiments**:
  1. Test privacy guarantees by measuring success rate of embedding inversion attacks with varying ε
  2. Evaluate retrieval accuracy comparing top k documents with and without perturbation
  3. Measure communication costs under different settings and compare to baseline approaches

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can RemoteRAG handle proprietary embedding models that user cannot access locally?
- **Basis in paper**: [explicit] Paper acknowledges limitation: "user cannot calculate query embedding locally and therefore cannot directly generate perturbation"
- **Why unresolved**: No solution provided for this scenario
- **What evidence would resolve it**: Method/protocol allowing user to generate perturbed embedding without accessing proprietary model

### Open Question 2
- **Question**: How does RemoteRAG perform under more realistic attack scenarios?
- **Basis in paper**: [inferred] Only evaluates against Vec2Text attack, not broader attack vectors
- **Why unresolved**: Paper focuses on specific attack method without comprehensive evaluation
- **What evidence would resolve it**: Results against various attack methods and complex query structures

### Open Question 3
- **Question**: What is impact of different distance metrics on performance and security?
- **Basis in paper**: [explicit] Mentions PHE supports only addition operation, restricting similarity distance variety
- **Why unresolved**: No exploration of implications of different distance metrics
- **What evidence would resolve it**: Comparative analysis using different distance metrics

## Limitations

- PHE implementation details and parameter choices are not fully specified
- Performance claims (0.67s for 10^6 documents) may be overly optimistic depending on PHE scheme
- Only tested against Vec2Text attack, not comprehensive suite of embedding inversion attacks
- Proprietary embedding model scenario not addressed

## Confidence

- **Privacy Preservation Claims**: Medium-High - Theoretical framework sound but real-world attack resistance needs broader testing
- **Retrieval Accuracy Claims**: Medium - 100% recall with privacy protection plausible but needs verification across models
- **Efficiency Claims**: Low-Medium - Specific numerical claims seem optimistic and implementation-dependent

## Next Checks

1. **PHE Scheme Validation**: Test implementation with varying dataset sizes (10^3, 10^4, 10^5, 10^6) to verify scaling behavior and measure actual encryption/decryption times

2. **Attack Resistance Testing**: Evaluate against broader suite of embedding inversion attacks beyond Vec2Text, including gradient-based and query reconstruction attacks across different embedding models

3. **Retrieval Robustness Testing**: Systematically vary privacy budget ε (1, 5, 10, 20) to measure tradeoff between privacy guarantees and retrieval accuracy across different query types