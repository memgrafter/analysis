---
ver: rpa2
title: 'Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding'
arxiv_id: '2409.03363'
source_url: https://arxiv.org/abs/2409.03363
tags:
- con-recall
- data
- member
- non-member
- min-k
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CON-RECALL, a novel contrastive decoding
  approach for detecting pre-training data in large language models. The method leverages
  asymmetric distributional shifts induced by member and non-member contexts to enhance
  membership inference.
---

# Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding

## Quick Facts
- arXiv ID: 2409.03363
- Source URL: https://arxiv.org/abs/2409.03363
- Authors: Cheng Wang; Yiwei Wang; Bryan Hooi; Yujun Cai; Nanyun Peng; Kai-Wei Chang
- Reference count: 24
- Primary result: Achieves state-of-the-art membership inference performance with 6.6% AUC and 30.8% TPR@5%FPR improvements over baselines

## Executive Summary
This paper introduces CON-RECALL, a novel contrastive decoding approach for detecting pre-training data in large language models. The method leverages asymmetric distributional shifts induced by member and non-member contexts to enhance membership inference. Through extensive experiments on the WikiMIA and MIMIR benchmarks across various model sizes, CON-RECALL achieves state-of-the-art performance, outperforming existing methods by 6.6% in AUC and 30.8% in TPR@5%FPR on WikiMIA. The approach demonstrates robustness against text manipulation techniques including random deletion, synonym substitution, and paraphrasing, maintaining superior performance even under these challenging conditions. Notably, CON-RECALL requires only gray-box access to models, using token probabilities without needing a reference model, making it practical for real-world applications.

## Method Summary
CON-RECALL exploits asymmetric distributional shifts between member and non-member contexts through contrastive decoding. The method computes a membership score by contrasting log-likelihoods under member and non-member prefixes (LL(x|Pnon-member) - γ · LL(x|Pmember)), where γ controls the contrastive strength. This normalized score amplifies subtle membership signals that would be lost in absolute probability comparisons. The approach requires only gray-box access to models, using token probabilities without needing a reference model, and demonstrates robustness to various text manipulation techniques while maintaining superior performance across different model sizes.

## Key Results
- Achieves 6.6% AUC improvement and 30.8% TPR@5%FPR improvement over state-of-the-art baselines on WikiMIA benchmark
- Maintains robust performance under text manipulation attacks including random deletion (10-20%), synonym substitution, and paraphrasing
- Demonstrates effectiveness across multiple model sizes from 1.4B to 30B parameters on both WikiMIA and MIMIR benchmarks
- Requires only gray-box access (token probabilities) without needing reference models or full model access

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Asymmetric distributional shifts between member and non-member contexts provide discriminative signals for membership inference
- Mechanism: When a target text is prefixed with member contexts, member data experiences minimal distributional shift while non-member data undergoes significant negative shift. The reverse occurs with non-member prefixes. This asymmetry creates a contrastive signal that can be exploited for inference.
- Core assumption: The model's learned representations maintain sufficient similarity between member data and their contexts to create this asymmetric shift pattern
- Evidence anchors:
  - [abstract] "our analysis reveals that these subtle shifts can be effectively leveraged when contrasted with non-member contexts"
  - [section] "Our analysis reveals that these subtle shifts in member contexts, though often dismissed, hold valuable information that has been underexploited"
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.493

### Mechanism 2
- Claim: Contrastive decoding amplifies subtle distributional differences that are not detectable through isolated analysis
- Mechanism: By computing the difference between log-likelihoods under member and non-member prefixes (LL(x|Pnon-member) - γ · LL(x|Pmember)), the method creates a normalized score that highlights membership information that would be lost in absolute probability comparisons
- Core assumption: The relative difference between member and non-member prefix effects contains more discriminative information than either prefix alone
- Evidence anchors:
  - [abstract] "leverages the asymmetric distributional shifts induced by member and non-member contexts through contrastive decoding, amplifying subtle differences"
  - [section] "Building on the insights from our analysis, we propose CON-RECALL, a method that exploits the contrastive information between member and non-member prefixes"
  - [corpus] Average neighbor FMR=0.493, average citations=0.0

### Mechanism 3
- Claim: Gray-box access requirement makes the method practical for real-world deployment
- Mechanism: By only requiring token probabilities rather than full model access or reference models, CON-RECALL can be applied to black-box scenarios where internal model parameters are not accessible
- Core assumption: Token probabilities contain sufficient information to compute the contrastive membership score
- Evidence anchors:
  - [abstract] "CON-RECALL requires only gray-box access to models, using token probabilities without needing a reference model"
  - [section] "Importantly, CON-RECALL requires only gray-box access to the model, utilizing solely token probabilities"
  - [corpus] Weak corpus evidence - most related work focuses on other aspects of membership inference

## Foundational Learning

- Concept: Wasserstein distance and signed distributional shifts
  - Why needed here: The paper uses signed Wasserstein distance to quantify and visualize the asymmetric distributional shifts between member and non-member data under different prefix conditions
  - Quick check question: How does signed Wasserstein distance differ from standard Wasserstein distance in capturing directional information about distributional shifts?

- Concept: Contrastive learning and its application to membership inference
  - Why needed here: The method adapts contrastive learning principles from text generation (where contrasting different model outputs improves quality) to the membership inference setting
  - Quick check question: What makes the contrastive approach in CON-RECALL different from traditional contrastive learning in representation learning?

- Concept: Membership inference attack metrics (AUC, TPR@FPR)
  - Why needed here: The evaluation framework uses standard MIA metrics to demonstrate performance improvements over baselines
  - Quick check question: Why might TPR@5%FPR be a more informative metric than overall AUC for practical membership inference applications?

## Architecture Onboarding

- Component map: Input text → Prefix selection (member/non-member contexts) → Token probability computation → Contrastive scoring function → Threshold application → Membership prediction
- Critical path: The contrastive scoring function (LL(x|Pnon-member) - γ · LL(x|Pmember)) / LL(x) is the core component that transforms raw probabilities into membership signals
- Design tradeoffs: Gray-box access enables practical deployment but limits the method's applicability to scenarios where token probabilities are available; the γ parameter requires tuning but enables flexibility
- Failure signatures: Poor performance on text manipulation tasks (random deletion, synonym substitution, paraphrasing) indicates the method is relying too heavily on exact token matches rather than semantic content
- First 3 experiments:
  1. Baseline comparison: Implement and compare against Loss (Yeom et al., 2018) and ReCall (Xie et al., 2024) on WikiMIA-32 to verify the 6.6% AUC improvement claim
  2. γ sensitivity analysis: Vary γ from 0.1 to 1.0 on WikiMIA to identify the optimal value and confirm the claim that performance fluctuates with γ
  3. Text manipulation robustness: Apply random deletion (10%, 15%, 20%) to WikiMIA-32 and measure AUC degradation compared to baselines to verify robustness claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal value of the hyperparameter γ in CON-RECALL, and how does it vary across different model sizes and datasets?
- Basis in paper: [explicit] The paper mentions that γ controls the contrastive strength between member and non-member prefixes, and that performance fluctuates as γ varies, suggesting an optimal value exists.
- Why unresolved: The paper does not provide a systematic study of how γ should be chosen or whether its optimal value depends on model characteristics or dataset properties.
- What evidence would resolve it: A comprehensive ablation study varying γ across different model sizes, datasets, and text lengths, with clear performance curves showing the relationship between γ and inference accuracy.

### Open Question 2
- Question: How robust is CON-RECALL against more sophisticated adversarial evasion techniques beyond the basic text manipulations tested (random deletion, synonym substitution, paraphrasing)?
- Basis in paper: [inferred] The paper demonstrates robustness against basic text manipulations but acknowledges this as a limitation, noting that "the method's robustness in the face of more sophisticated adversarial evasion techniques warrants further rigorous investigation."
- Why unresolved: The paper only tested three relatively simple manipulation techniques, leaving open the question of how the method would perform against more advanced adversarial strategies designed specifically to evade membership inference.
- What evidence would resolve it: Systematic testing of CON-RECALL against state-of-the-art adversarial attacks designed to defeat membership inference, including techniques like gradient-based word substitutions, sentence-level rephrasing, or more complex document transformations.

### Open Question 3
- Question: Can CON-RECALL be adapted for black-box scenarios where only API access is available, without token probabilities?
- Basis in paper: [explicit] The paper acknowledges that CON-RECALL requires gray-box access to models and notes this as a limitation, stating it "constrains its utility in black-box scenarios, such as API calls or online chat interfaces."
- Why unresolved: The paper does not propose or evaluate any modifications to CON-RECALL that would enable its use in black-box settings where only input-output pairs are observable.
- What evidence would resolve it: Development and evaluation of modified versions of CON-RECALL that work with API-only access, potentially using techniques like input perturbation analysis, output probability estimation, or transfer learning from gray-box to black-box settings.

## Limitations
- The paper demonstrates strong performance on specific benchmarks (WikiMIA, MIMIR) but the generalizability to other domains or model architectures remains untested
- The effectiveness of the contrastive approach relies heavily on finding appropriate member and non-member prefixes, which may be challenging in real-world scenarios
- While the method shows robustness to text manipulation techniques, the degree of manipulation studied may not represent the full spectrum of adversarial attacks

## Confidence
- High confidence in the core mechanism: The asymmetric distributional shift phenomenon appears well-documented through empirical evidence and the contrastive decoding approach is technically sound
- Medium confidence in performance claims: The 6.6% AUC and 30.8% TPR@5%FPR improvements are based on specific benchmarks and may not generalize across all scenarios
- Medium confidence in practical applicability: The gray-box access requirement is a strength, but the need for appropriate prefix selection may limit real-world deployment

## Next Checks
1. **Cross-domain validation**: Test CON-RECALL on a completely different dataset type (e.g., code, medical text, or scientific literature) to verify that the asymmetric distributional shift mechanism generalizes beyond Wikipedia-style text
2. **Architectural robustness analysis**: Evaluate the method on transformer variants (e.g., RWKV, Mamba, or other attention-free architectures) to determine if the distributional shift phenomenon holds across different model designs
3. **Adaptive attack resistance**: Design and test adaptive membership inference attacks that specifically target the contrastive mechanism, such as prefix-aware attacks or context poisoning strategies that could neutralize the asymmetric shift signal