---
ver: rpa2
title: Surrogate Modeling for Explainable Predictive Time Series Corrections
arxiv_id: '2412.19897'
source_url: https://arxiv.org/abs/2412.19897
tags:
- time
- correction
- series
- data
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Sequential Before and After Prediction Parameter
  Comparison (SBAPC), a method for explainable time series forecasting that combines
  interpretable base models with AI correction models. The approach uses a sliding
  window technique to generate sequential explanations by comparing base model parameters
  before and after applying a correction model.
---

# Surrogate Modeling for Explainable Predictive Time Series Corrections

## Quick Facts
- arXiv ID: 2412.19897
- Source URL: https://arxiv.org/abs/2412.19897
- Authors: Alfredo Lopez; Florian Sobieczky
- Reference count: 40
- One-line primary result: SBAPC provides explainable time series forecasting by comparing base model parameters before and after AI correction, with integrated gradients quantifying feature importance

## Executive Summary
This paper introduces Sequential Before and After Prediction Parameter Comparison (SBAPC), a method for explainable time series forecasting that combines interpretable base models with AI correction models. The approach uses a sliding window technique to generate sequential explanations by comparing base model parameters before and after applying a correction model. Experiments demonstrate effectiveness on synthetic and real-world datasets, showing interpretable patterns in polynomial trends and periodic components.

## Method Summary
The SBAPC method involves three steps: (1) fitting an interpretable base model to the time series data, (2) applying a correction model to predict residuals, and (3) fitting the base model again to corrected data to obtain parameter differences that explain the correction model's behavior. The authors extend this with Integrated Gradient Scores to quantify feature importance. The method provides automatic determination of local neighborhood size and physical interpretability through choice of base model, with the correction window size emerging as a key parameter.

## Key Results
- Effective explanation of change points in step, ramp, and sinusoidal patterns
- Application to complex frequency change point detection in sinusoidal data
- Identification of optimal correction window sizes through maximum surrogate correction strength
- Successful application to Air Passenger dataset showing interpretable patterns in polynomial trend and periodic components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SBAPC produces physically interpretable explanations by re-fitting a base model after subtracting the AI correction, yielding parameter differences that directly reflect the correction's impact.
- Mechanism: The base model is fitted twice: first to the raw data, then to the data with the AI correction removed. The difference in fitted parameters captures how the correction model alters the interpretable structure.
- Core assumption: The base model captures the dominant trend, so residuals represent correction-worthy deviations.
- Evidence anchors:
  - [abstract] "Explainability of the correction is provided by fitting the base model again to the data from which the error prediction is removed (subtracted), yielding a difference in the model parameters which can be interpreted."
  - [section 2] Step-3: "fit again the base model fθ to y′ leading to estimated parameter θr... the BAPC-explanation ∆θr = (∆θr1, . . . ,∆rq) := θ0 − θr ∈ Rq"
  - [corpus] Weak anchor: related work focuses on SHAP/LIME for time series but not on parameter-difference explanations.
- Break condition: If the base model is misspecified or the correction model captures trends instead of residuals, the parameter differences lose physical meaning.

### Mechanism 2
- Claim: The sequential sliding-window application enables per-timestep explainability while maintaining locality.
- Mechanism: At each time step, SBAPC is applied to the most recent n observations, using only the last r points for correction. This yields a sequence of explanations ∆θs_r that can be analyzed over time.
- Core assumption: Local corrections are sufficient to explain nonstationary behavior within each window.
- Evidence anchors:
  - [section 2] "sequential BAPC (SBAPC) as the process of consecutively applying BAPC to ys−n+1, . . . , ys, for every s = n, . . . , m"
  - [section 4] "IGk(fθ, s, t) := ∆θs_rk Z 1 0 ∂f/∂θk(t, γ(θs_r, θs_0, h)) dh" showing time-dependent gradients.
  - [corpus] Weak anchor: most related papers focus on feature importance rather than sequential parameter change.
- Break condition: If the time series exhibits abrupt changes larger than the window size, the locality assumption fails.

### Mechanism 3
- Claim: Integrated gradients over the parameter space quantify feature importance for each explanation component.
- Mechanism: IG computes the path integral of parameter gradients between corrected and uncorrected fits, producing a cumulative importance score per base model parameter.
- Core assumption: The parameter space is smooth enough for the gradient path integral to be meaningful.
- Evidence anchors:
  - [section 4] "The BAPC integrated gradient of the k-th explanation at t ∈ R is defined as IGk(fθ, t) := ∆θrk Z 1 0 ∂f/∂θk(t, γ(θr, θ0, h)) dh"
  - [section 5.1] Table 1 shows IG values alongside parameter differences, demonstrating their use for ranking.
  - [corpus] Weak anchor: corpus papers mention SHAP/IG but not IG applied to parameter-difference explanations.
- Break condition: If the base model is non-differentiable or the correction is discontinuous, the integral becomes ill-defined.

## Foundational Learning

- Concept: Parameter fitting in autoregressive (AR) models
  - Why needed here: SBAPC relies on fitting AR models as base models for certain experiments; understanding how φ1, φ2 relate to physical parameters is crucial.
  - Quick check question: In a stationary AR(2) process, what constraint must φ1 and φ2 satisfy for stability?

- Concept: Sliding window time series analysis
  - Why needed here: The sequential BAPC applies a fixed-size window that moves across the series; knowing how window size affects locality and bias is essential.
  - Quick check question: If you double the window size n while keeping r fixed, how does the temporal resolution of explanations change?

- Concept: Integrated gradients in explainability
  - Why needed here: SBAPC uses integrated gradients over parameter space, not input space; understanding the completeness axiom and path dependence matters.
  - Quick check question: For a linear base model fθ(t) = θ⊺g(t), what does the integrated gradient IGk reduce to?

## Architecture Onboarding

- Component map: Data pipeline -> Base model fitter (AR or physics-based) -> Correction model (LSTM/NN) -> Residual predictor -> Parameter-difference calculator -> Integrated gradient module -> Visualization/heatmap generator
- Critical path: Correction model prediction -> Residual subtraction -> Re-fitting base model -> Parameter difference -> IG computation -> Explanation output
- Design tradeoffs:
  - Window size n vs. temporal resolution: larger n smooths but may blur change points.
  - Correction window r vs. locality: smaller r gives sharper local explanations but risks overfitting.
  - Base model complexity vs. interpretability: simpler models yield clearer parameter changes but may miss structure.
- Failure signatures:
  - Large residuals after correction -> base model misspecification.
  - IG values near zero -> correction model not captured by base model.
  - Unstable parameter differences across windows -> change points near window boundaries.
- First 3 experiments:
  1. Synthetic step function with constant base model: verify ∆θr captures jump magnitude.
  2. Ramp function with linear base model: confirm ∆θr shows slope change at change point.
  3. Sinusoidal with frequency change: use AR base model, check if IG highlights frequency parameter shift.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal correction window size r for different types of change points in time series data?
- Basis in paper: [explicit] The paper discusses how the optimal window size depends on the type of change point and AI-correction framework, but does not provide a general method for determining it.
- Why unresolved: The paper shows that different window sizes yield different explanations and that there's a maximum in the strength of explanation at certain window sizes, but doesn't establish a systematic approach for selecting the optimal size.
- What evidence would resolve it: Empirical studies across diverse time series datasets showing consistent patterns in how window size relates to change point characteristics, and development of a principled method for determining optimal window size.

### Open Question 2
- Question: How does the SBAPC method perform compared to other XAI methods like LIME and SHAP for time series data?
- Basis in paper: [inferred] The paper mentions LIME as a comparison but only briefly, and suggests that BAPC and LIME could provide complementary insights, but doesn't conduct a comprehensive comparative evaluation.
- Why unresolved: While the paper demonstrates SBAPC's effectiveness on synthetic and real-world data, it doesn't benchmark against established XAI methods in terms of accuracy, stability, or interpretability.
- What evidence would resolve it: Systematic experiments comparing SBAPC to LIME, SHAP, and other XAI methods on benchmark time series datasets, measuring both explanation quality and computational efficiency.

### Open Question 3
- Question: Can the SBAPC framework be extended to multivariate time series with complex interdependencies?
- Basis in paper: [explicit] The paper focuses on univariate time series and mentions that extending to multivariate cases is a direction for future research.
- Why unresolved: The current SBAPC formulation relies on fitting interpretable base models to single time series, but real-world applications often involve multiple correlated time series.
- What evidence would resolve it: Successful application of SBAPC to multivariate time series datasets, demonstrating how to handle cross-series dependencies and maintain interpretability in the presence of complex interactions.

## Limitations
- The method assumes residuals are correction-worthy deviations, but correction models might capture trend components
- Sliding window approach introduces boundary effects that are not fully characterized
- Integrated gradient computation assumes differentiable base models, limiting applicability to non-smooth or discrete models

## Confidence
- High confidence: The core mechanism of parameter-difference explanations is well-supported by direct evidence from the paper's methodology section
- Medium confidence: The sequential application works as described for synthetic datasets but may degrade on real-world data with irregular change points
- Low confidence: The integrated gradient interpretation provides meaningful feature importance scores, as the paper doesn't validate these against ground truth feature importance

## Next Checks
1. Test SBAPC on a synthetic time series with multiple overlapping change points to evaluate window boundary effects and parameter stability across overlapping windows
2. Compare SBAPC explanations against ground truth feature importance using a synthetic dataset where the true underlying features are known
3. Apply SBAPC to a real-world dataset with known structural breaks and validate whether the method correctly identifies both the timing and nature of these breaks compared to established change point detection methods