---
ver: rpa2
title: 'Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical
  Reasoning'
arxiv_id: '2408.08640'
source_url: https://arxiv.org/abs/2408.08640
tags:
- data
- mllms
- mathematical
- visual
- stage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Math-PUMA tackles multimodal mathematical reasoning by progressively
  aligning text and vision modalities. It first trains an LLM on text-only math, then
  constructs 692K data pairs spanning four levels of multimodal complexity.
---

# Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning

## Quick Facts
- arXiv ID: 2408.08640
- Source URL: https://arxiv.org/abs/2408.08640
- Reference count: 15
- Primary result: State-of-the-art open-source performance on MATHVERSE, MATHVISTA, and WE-MATH benchmarks for multimodal mathematical reasoning

## Executive Summary
Math-PUMA addresses the challenge of multimodal mathematical reasoning by progressively aligning text and vision modalities through a three-stage training pipeline. The approach first strengthens language-only math reasoning, then uses KL divergence to align text-rich and vision-rich data pairs, and finally fine-tunes on high-quality multimodal instruction data. Experiments demonstrate significantly reduced modality gaps and state-of-the-art performance among open-source models on standard mathematical reasoning benchmarks.

## Method Summary
Math-PUMA employs a three-stage training pipeline: (1) text-only math reasoning fine-tuning on 200K problems, (2) Progressive Upward Multimodal Alignment (PUMA) using KL divergence to align 692K data pairs across four complexity levels, and (3) multimodal instruction tuning on 996K high-quality examples. The PUMA mechanism supervises weak-vision logits with strong-text logits using forward and reverse KL divergence, progressively aligning modalities from text-rich to vision-rich. The model is built on strong base LLMs like DeepSeek-Math-7B and Qwen2 variants with vision encoders.

## Key Results
- Achieves state-of-the-art open-source performance on MATHVERSE, MATHVISTA, and WE-MATH benchmarks
- Significantly reduces performance gaps between text-dominant and vision-dominant problem formats
- Demonstrates strong generalization across geometry, algebra, and reasoning tasks
- Maintains conversational abilities while enhancing multimodal reasoning capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Progressive Upward Multimodal Alignment (PUMA) improves multimodal reasoning by aligning weak-vision and strong-text modalities using KL divergence of next-token prediction distributions.
- Mechanism: The model first enhances language-only math reasoning (Stage 1), then aligns modalities by supervising weak logits with strong logits via forward and reverse KL divergence, finally fine-tunes with multimodal data (Stage 3). This hierarchical approach progressively aligns the modalities from text-rich to vision-rich.
- Core assumption: The alignment is effective because the strong-text logits provide reliable supervision for the weak-vision logits, and KL divergence converges to the same objective after sufficient epochs.
- Evidence anchors:
  - [abstract]: "By leveraging the Kullback-Leibler (KL) divergence of next-token prediction distributions to align visual and textual modalities, consistent problem-solving abilities are ensured."
  - [section]: "We observe that the multimodal mathematical reasoning ability of MLLMs resembles a pyramid, with performance declining from bottom to top as the information shifts from text to visual modalities... By leveraging the KL-divergence between next-token prediction distributions for text-rich and vision-rich problems, we achieve progressive bottom-up modal alignment across these hierarchical levels..."
  - [corpus]: Weak evidence - related work focuses on data augmentation and alignment methods, but none explicitly cite KL divergence alignment with hierarchical modality shifts.
- Break condition: If the strong-text logits are not reliable (e.g., LLM lacks sufficient math reasoning), the alignment supervision fails.

### Mechanism 2
- Claim: Training on a large corpus of text-only math problems first (Stage 1) provides a strong foundation for subsequent multimodal alignment and instruction tuning.
- Mechanism: The model is initialized with existing LLMs strong in math reasoning, then fine-tuned on 200K text-only math problems. This creates a robust base for aligning visual and textual modalities in Stage 2 and for handling multimodal instruction in Stage 3.
- Core assumption: A strong language-only math reasoning capability is necessary to provide reliable strong logits for alignment and to interpret multimodal instructions effectively.
- Evidence anchors:
  - [section]: "Stage 1: We train the LLM using a substantial dataset of text-based math problems to enhance its problem-solving capabilities... This phase significantly enhances the LLM’s mathematical reasoning abilities."
  - [section]: "Stage 2: ... the objective of PUMA is to facilitate the effective resolution of vision-rich mathematical problems by aligning the outputs of MLLMs with text-rich data, thereby enhancing their reasoning capabilities across different modalities."
  - [corpus]: Weak evidence - related work focuses on multimodal datasets but does not emphasize the foundational role of text-only math reasoning.
- Break condition: If the text-only math corpus is insufficient or of poor quality, the foundation for multimodal reasoning is weak.

### Mechanism 3
- Claim: Using multimodal instruction tuning with high-quality data (Stage 3) maintains and enhances the model's conversational and reasoning abilities across modalities.
- Mechanism: The model is fine-tuned on 996K high-quality multimodal problem-solving data, including detailed reasoning processes. This stage ensures the model can effectively leverage both textual and visual information and maintain conversational capabilities.
- Core assumption: High-quality multimodal data with detailed reasoning processes is necessary to teach the model how to integrate visual and textual information effectively.
- Evidence anchors:
  - [section]: "Stage 3: We select 996K high-quality multimodal problem-solving data to fine-tune the model, further enhancing its performance in multimodal mathematical problem-solving tasks."
  - [section]: "This multimodal instruction tuning not only bolsters the model’s reasoning and problem-solving abilities but also ensures that it can effectively leverage both textual and visual information for improved performance in mathematical problem-solving."
  - [corpus]: Weak evidence - related work focuses on data construction but does not explicitly discuss the importance of detailed reasoning processes in instruction tuning.
- Break condition: If the multimodal data is low quality or lacks detailed reasoning, the model's conversational and reasoning abilities may not improve.

## Foundational Learning

- Concept: KL Divergence
  - Why needed here: KL divergence is used to measure the difference between the probability distributions of next-token predictions for text-rich and vision-rich data, enabling the alignment of modalities.
  - Quick check question: What does KL divergence measure in the context of PUMA?
    - Answer: The difference between the probability distributions of next-token predictions for text-rich and vision-rich data.

- Concept: Multimodal Alignment
  - Why needed here: Multimodal alignment is the process of ensuring that the model can effectively integrate and reason with information from different modalities (text and vision) in a consistent manner.
  - Quick check question: What is the goal of multimodal alignment in Math-PUMA?
    - Answer: To ensure consistent problem-solving abilities across different modalities by aligning visual and textual information.

- Concept: Instruction Tuning
  - Why needed here: Instruction tuning is the process of fine-tuning a model on a dataset of instructions and corresponding responses to improve its ability to follow instructions and generate appropriate outputs.
  - Quick check question: What is the purpose of multimodal instruction tuning in Math-PUMA?
    - Answer: To enhance the model's reasoning and problem-solving abilities and ensure it can effectively leverage both textual and visual information.

## Architecture Onboarding

- Component map:
  - Base LLM (DeepSeek-Math-7B, Qwen2 variants) -> Vision Encoder (SigLIP, similar to LLaVA) -> Adapter -> PUMA Loss (KL divergence + hard loss) -> Datasets (text-only, alignment pairs, multimodal instruction)

- Critical path:
  1. Initialize LLM with strong math reasoning capabilities
  2. Fine-tune on text-only math problems to enhance reasoning
  3. Construct alignment data pairs with varying degrees of textual and visual information
  4. Apply PUMA loss to align modalities by supervising weak logits with strong logits
  5. Fine-tune on high-quality multimodal instruction tuning data to enhance reasoning and conversational abilities

- Design tradeoffs:
  - Text-only vs. Multimodal Training: Prioritizing text-only training first (Stage 1) ensures a strong foundation but may delay exposure to multimodal data
  - KL Divergence vs. Other Alignment Methods: KL divergence is chosen for its ability to measure distribution differences, but other methods (e.g., contrastive loss) could be explored
  - Data Quality vs. Quantity: Focusing on high-quality data (Stage 3) ensures better performance but may limit the amount of training data available

- Failure signatures:
  - Poor math reasoning: If the model struggles with basic math problems, the text-only training (Stage 1) may be insufficient
  - Inconsistent performance across modalities: If the model performs well on text but poorly on vision, the alignment (Stage 2) may be ineffective
  - Loss of conversational abilities: If the model's responses are less coherent or less contextually relevant, the multimodal instruction tuning (Stage 3) may be inadequate

- First 3 experiments:
  1. Evaluate the model's performance on text-only math problems to assess the effectiveness of Stage 1
  2. Test the model's ability to align text-rich and vision-rich data by measuring the KL divergence between their prediction distributions
  3. Assess the model's multimodal reasoning capabilities on a benchmark like MATHVERSE to evaluate the overall effectiveness of Math-PUMA

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Progressive Upward Multimodal Alignment (PUMA) approach perform on mathematical reasoning tasks beyond those evaluated in the paper (e.g., calculus, statistics, probability)?
- Basis in paper: [inferred] The paper evaluates Math-PUMA on geometry, algebra, and reasoning tasks, but does not explore its performance on other mathematical domains like calculus, statistics, or probability.
- Why unresolved: The paper focuses on geometry, algebra, and reasoning tasks, leaving the model's performance on other mathematical domains unexplored.
- What evidence would resolve it: Conducting experiments on additional mathematical domains such as calculus, statistics, or probability would provide insights into the model's generalization capabilities across different areas of mathematics.

### Open Question 2
- Question: What is the impact of using different types of visual data augmentation techniques (e.g., rotation, translation, shearing) on the performance of Math-PUMA in multimodal mathematical reasoning tasks?
- Basis in paper: [explicit] The paper mentions using image processing techniques like scaling, stretching, and gamma transformation for data augmentation, but does not explore the impact of other augmentation techniques.
- Why unresolved: The paper does not investigate the effects of different visual data augmentation techniques on the model's performance, leaving the optimal augmentation strategy unclear.
- What evidence would resolve it: Experimenting with various visual data augmentation techniques and evaluating their impact on Math-PUMA's performance would provide insights into the most effective augmentation strategies.

### Open Question 3
- Question: How does the performance of Math-PUMA compare to that of models using different vision encoders (e.g., CLIP, ConvNeXt) in multimodal mathematical reasoning tasks?
- Basis in paper: [explicit] The paper uses DeepSeek-VL and SigLIP-so400m-patch14-384 as vision encoders for Math-PUMA, but does not compare their performance with other vision encoders.
- Why unresolved: The paper does not explore the impact of using different vision encoders on the model's performance, leaving the optimal encoder choice unclear.
- What evidence would resolve it: Comparing the performance of Math-PUMA using different vision encoders (e.g., CLIP, ConvNeXt) would provide insights into the most effective encoder for multimodal mathematical reasoning tasks.

## Limitations

- The automatic data generation pipeline for creating 692K data pairs lacks detailed technical specifications, making reproducibility challenging
- The scalability of the approach to mathematical domains beyond geometry, algebra, and reasoning remains untested
- The long-term generalization to novel problem types not present in the training data is uncertain

## Confidence

- **High Confidence**: The three-stage training pipeline is clearly described and methodologically sound; KL divergence alignment is well-established; benchmark results are verifiable
- **Medium Confidence**: The claim that PUMA reduces modality gaps is supported but could benefit from more granular analysis; text-only training foundation is reasonable but not empirically validated against alternatives
- **Low Confidence**: Scalability to different mathematical domains is untested; long-term generalization to novel problem types is uncertain

## Next Checks

1. **Data Quality Analysis**: Conduct a detailed analysis of the automatically generated data pairs to verify their mathematical correctness, diversity, and alignment quality, including checking distribution of problem types and difficulty levels.

2. **Ablation Study on PUMA Components**: Perform an ablation study isolating the effects of forward KL, reverse KL, and the hard loss component to quantify their individual contributions to overall performance improvement.

3. **Cross-Domain Generalization Test**: Evaluate the model's performance on mathematical problems from domains not explicitly included in training data (e.g., real-world applied mathematics, interdisciplinary problems) to assess true generalization capabilities beyond benchmark datasets.