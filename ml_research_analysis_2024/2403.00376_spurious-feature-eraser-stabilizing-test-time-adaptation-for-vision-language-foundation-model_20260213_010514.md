---
ver: rpa2
title: 'Spurious Feature Eraser: Stabilizing Test-Time Adaptation for Vision-Language
  Foundation Model'
arxiv_id: '2403.00376'
source_url: https://arxiv.org/abs/2403.00376
tags:
- features
- clip
- images
- decision
- shortcuts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the issue of decision shortcuts in vision-language
  foundation models (VLFMs) like CLIP, where these models rely on spurious features
  rather than invariant causal features for classification tasks. The authors propose
  Spurious Feature Eraser (SEraser), a test-time prompt tuning method that optimizes
  learnable prompts to encourage the model to disregard decision shortcuts and focus
  on invariant features during inference.
---

# Spurious Feature Eraser: Stabilizing Test-Time Adaptation for Vision-Language Foundation Model

## Quick Facts
- arXiv ID: 2403.00376
- Source URL: https://arxiv.org/abs/2403.00376
- Authors: Huan Ma; Yan Zhu; Changqing Zhang; Peilin Zhao; Baoyuan Wu; Long-Kai Huang; Qinghua Hu; Bingzhe Wu
- Reference count: 10
- One-line primary result: SEraser achieves up to 52.67% improvement on worst-group performance for vision-language models by encouraging focus on invariant features during test-time adaptation

## Executive Summary
This paper addresses the critical issue of decision shortcuts in vision-language foundation models like CLIP, where models rely on spurious features rather than invariant causal features for classification. The authors propose Spurious Feature Eraser (SEraser), a test-time prompt tuning method that optimizes learnable prompts to encourage models to disregard decision shortcuts and focus on invariant features during inference. By regularizing the model to predict uniform distributions on auxiliary images representing spurious features, SEraser achieves significant improvements in zero-shot classification performance, particularly in worst-case scenarios across various datasets and model architectures.

## Method Summary
SEraser is a test-time adaptation method that addresses decision shortcuts in vision-language models by optimizing learnable prompts to encourage the model to focus on invariant features. The method works by constructing auxiliary images that represent spurious features (using annotations, patches, or reference images) and then optimizing the prompt to minimize the KL divergence between the model's predictions on these auxiliary images and a uniform distribution. This forces the model to predict equally across all classes for images containing spurious features, effectively "erasing" their influence. The optimized prompt is then used for zero-shot classification on test images. The approach is flexible and works across different model architectures including CLIP-ViT-L-14 and BLIP-2.

## Key Results
- SEraser achieves up to 52.67% improvement on worst-group performance in the SpiderCrab dataset
- The method shows 25.21% improvement on the Waterbirds dataset with challenging spurious correlations
- SEraser demonstrates effectiveness across different model architectures including CLIP-ViT-L-14 and BLIP-2
- The proposed S2E evaluation paradigm addresses limitations in existing VLFMs evaluation protocols

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CLIP's zero-shot failures stem from its use of decision shortcuts rather than invariant causal features during inference, even though it has already learned both types during pretraining.
- Mechanism: SEraser introduces a test-time prompt tuning paradigm that optimizes learnable prompts to force the model to predict uniform distributions on auxiliary images representing spurious features. This encourages the model to "erase" or disregard spurious features during inference.
- Core assumption: The model's poor performance is not due to missing features but rather to incorrect feature prioritization during inference.
- Evidence anchors:
  - [abstract]: "the underperformance of CLIP on downstream tasks originates from its inability to effectively utilize pre-trained features in accordance with specific task requirements"
  - [section]: "The experimental observations prompt us to contemplate how to compel foundational models to focus on and utilize causal features"
  - [corpus]: No direct evidence found in corpus neighbors. This appears to be a novel mechanism.

### Mechanism 2
- Claim: By minimizing the KL divergence between the prediction distribution on auxiliary images and a uniform distribution, SEraser can effectively "erase" spurious features.
- Mechanism: The loss function Le = KL(Pe(y|xe)||q) is used to optimize the prompt, where q is a uniform distribution. This forces the model to predict equally across all classes for images containing spurious features.
- Core assumption: Minimizing prediction entropy on auxiliary images representing spurious features will transfer to better feature selection on test images.
- Evidence anchors:
  - [section]: "we minimize the Kullback-Leibler divergence between the prediction distribution on the auxiliary image Pe and the uniform distribution q"
  - [corpus]: No direct evidence found in corpus neighbors. This appears to be a novel mechanism.

### Mechanism 3
- Claim: The flexibility in constructing auxiliary images allows SEraser to work across different scenarios without requiring exact annotations of spurious features.
- Mechanism: SEraser can use annotations, patches, or reference images as auxiliary images, with the method remaining effective even when these contain some invariant features due to its soft constraint nature.
- Core assumption: The method's effectiveness doesn't require perfectly pure spurious feature representations in auxiliary images.
- Evidence anchors:
  - [section]: "The flexibility enables the method to be more adaptable, and even when the auxiliary images contain partial invariant features, it is still effective since it prevents the model from making decisions based on partial features"
  - [corpus]: No direct evidence found in corpus neighbors. This appears to be a novel mechanism.

## Foundational Learning

- Concept: Decision shortcuts in machine learning
  - Why needed here: Understanding why models like CLIP fail on certain tasks despite strong pretraining requires grasping how models can learn spurious correlations during training
  - Quick check question: Can you explain the difference between a decision shortcut and an invariant causal feature in the context of image classification?

- Concept: Test-time adaptation and prompt tuning
  - Why needed here: SEraser operates entirely at test time without modifying model weights, using prompt tuning to adjust behavior for specific tasks
  - Quick check question: How does test-time prompt tuning differ from traditional fine-tuning, and what are its advantages and limitations?

- Concept: Kullback-Leibler divergence and entropy regularization
  - Why needed here: The core optimization objective uses KL divergence to minimize prediction entropy on auxiliary images
  - Quick check question: Why would minimizing the KL divergence between a model's predictions and a uniform distribution encourage the model to "ignore" certain features?

## Architecture Onboarding

- Component map:
  Visual encoder (CLIP ViT-B-32, ViT-L-14, or BLIP-2) -> Text encoder (CLIP text encoder) -> Learnable prompt vectors (M context vectors) -> Auxiliary image generator (annotations, patches, or reference images) -> Optimization loop (gradient descent on prompt vectors)

- Critical path:
  1. Generate auxiliary images representing spurious features
  2. Compute predictions on auxiliary images using current prompt
  3. Calculate KL divergence loss with uniform distribution
  4. Backpropagate loss to update learnable prompt vectors
  5. Use optimized prompt for zero-shot classification on test image

- Design tradeoffs:
  - Auxiliary image construction strategy vs. effectiveness
  - Number of learnable prompt parameters vs. overfitting risk
  - Number of optimization steps vs. computational cost
  - Choice of temperature parameter Ï„ in softmax function

- Failure signatures:
  - No improvement over vanilla CLIP baseline
  - Degradation in performance compared to baseline
  - Sensitivity to specific auxiliary image construction methods
  - Instability in optimization (exploding/vanishing gradients)

- First 3 experiments:
  1. Run SEraser with "Patches" strategy on Waterbirds dataset and compare worst-group accuracy to vanilla CLIP
  2. Test SEraser with different numbers of learnable prompt parameters (e.g., M=10, 50, 100) on SpiderCrab dataset
  3. Compare SEraser performance using different auxiliary image construction strategies (Patches, Images, Both) on Tiny-ImageNet

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SEraser vary when the auxiliary images contain varying degrees of invariant features, and what is the threshold at which the method's effectiveness begins to degrade?
- Basis in paper: [explicit] The paper mentions that SEraser remains effective even when auxiliary images contain partial invariant features, but does not specify the extent to which this is true or the threshold of invariant feature presence that would degrade performance.
- Why unresolved: The paper acknowledges the flexibility of SEraser in the presence of invariant features in auxiliary images but does not provide empirical evidence or a detailed analysis of how the method's performance changes as the proportion of invariant features in auxiliary images increases.
- What evidence would resolve it: Conducting experiments with auxiliary images containing controlled amounts of invariant features and measuring SEraser's performance across these varying levels would provide insights into the method's robustness and limitations.

### Open Question 2
- Question: What is the impact of SEraser on the interpretability of VLFMs, and does the method alter the attention patterns of the model in a way that could be exploited to understand its decision-making process better?
- Basis in paper: [inferred] While the paper discusses how SEraser encourages VLFMs to focus on invariant features, it does not explore the method's effects on the model's interpretability or the nature of its attention patterns.
- Why unresolved: The paper focuses on the performance improvements of SEraser but does not investigate how the method influences the model's internal mechanisms or its potential to enhance interpretability.
- What evidence would resolve it: Analyzing the attention maps and feature visualizations of VLFMs before and after applying SEraser could reveal changes in the model's decision-making process and provide insights into its interpretability.

### Open Question 3
- Question: How does the proposed "shortcut-to-evaluate" (S2E) paradigm compare to existing evaluation protocols in terms of detecting and measuring the impact of decision shortcuts in VLFMs across diverse real-world scenarios?
- Basis in paper: [explicit] The paper introduces S2E as a new evaluation paradigm for VLFMs, addressing limitations in current protocols, but does not provide a comprehensive comparison of S2E's effectiveness against existing methods.
- Why unresolved: While the paper highlights the shortcomings of current evaluation protocols and proposes S2E as a solution, it does not empirically compare S2E's ability to detect and measure decision shortcuts against other established methods.
- What evidence would resolve it: Conducting a comparative study using S2E and existing evaluation protocols on a wide range of real-world datasets would provide insights into the relative strengths and weaknesses of each approach in detecting and quantifying decision shortcuts.

## Limitations
- The method requires access to auxiliary images representing spurious features, which may not always be available in real-world scenarios
- The effectiveness of different auxiliary image construction strategies varies across datasets, requiring careful selection for optimal performance
- The theoretical foundation for why minimizing KL divergence to uniform distribution leads to better feature selection remains intuitive rather than rigorously proven

## Confidence

**High confidence:** The empirical methodology is sound and the experimental design is rigorous, with proper baselines and statistical significance testing

**Medium confidence:** The effectiveness of the three auxiliary image construction strategies is demonstrated but could benefit from deeper analysis of when each strategy works best

**Low confidence:** The theoretical explanation for why minimizing KL divergence to uniform distribution leads to better feature selection remains largely intuitive rather than rigorously proven

## Next Checks

1. Conduct ablation studies varying the number of optimization steps and learning rates to determine the sensitivity of SEraser to hyperparameter choices and identify optimal settings

2. Test SEraser on additional datasets with known spurious correlations (e.g., CelebA with gender/occupation biases) to verify generalizability beyond the reported benchmarks

3. Analyze feature representations before and after SEraser optimization using visualization techniques to provide empirical evidence of feature "erasure" and validate the proposed mechanism