---
ver: rpa2
title: Generating Robust Counterfactual Witnesses for Graph Neural Networks
arxiv_id: '2404.19519'
source_url: https://arxiv.org/abs/2404.19519
tags:
- node
- graph
- veri
- cation
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the need for robust, both counterfactual and
  factual explanations for graph neural networks (GNNs) that remain invariant under
  structural disturbances. The authors formalize the notion of robust counterfactual
  witnesses (RCWs) as subgraphs that preserve GNN classification results and are robust
  to a specified number of edge perturbations.
---

# Generating Robust Counterfactual Witnesses for Graph Neural Networks

## Quick Facts
- arXiv ID: 2404.19519
- Source URL: https://arxiv.org/abs/2404.19519
- Reference count: 40
- This paper addresses the need for robust, both counterfactual and factual explanations for graph neural networks (GNNs) that remain invariant under structural disturbances.

## Executive Summary
This paper addresses the need for robust, both counterfactual and factual explanations for graph neural networks (GNNs) that remain invariant under structural disturbances. The authors formalize the notion of robust counterfactual witnesses (RCWs) as subgraphs that preserve GNN classification results and are robust to a specified number of edge perturbations. They establish computational hardness results and develop efficient algorithms for verifying and generating RCWs, including a scalable parallel algorithm for large graphs. Experimental results on real-world datasets demonstrate that their method, RoboGExp, generates explanations that are more robust, have higher fidelity, and are more concise compared to state-of-the-art GNN explainers.

## Method Summary
The authors propose a framework for generating robust counterfactual witnesses (RCWs) for GNNs. The core approach involves expanding a witness subgraph by iteratively including edges that maximize the worst-case margin for each test node, thereby preemptively securing the subgraph against potential label changes from disturbances. They develop the RoboGExp algorithm with an expand-verify strategy and a parallel version (paraRoboGExp) for scalability. The verification algorithms (verifyRCW and verifyRCW-APPNP) efficiently check if a subgraph is a k-RCW under different disturbance models. The framework is evaluated on real-world datasets, showing significant improvements in robustness, fidelity, and generation time compared to existing methods.

## Key Results
- RoboGExp achieves up to 70.7% improvement in generation time with parallelization
- Produces explanations with 0.32 normalized graph edit distance, 0.79 fidelity+, and 0.05 fidelity- on the CiteSeer dataset
- Case studies showcase applications in drug discovery and cyber security, where RCWs identify invariant structures in molecular graphs and provenance graphs, respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RCWs remain invariant under structural disturbances up to k edge flips.
- Mechanism: The algorithm expands the witness subgraph by iteratively including edges that maximize the worst-case margin for each test node, thereby preemptively "securing" the subgraph against potential label changes from disturbances.
- Core assumption: The inference process of the GNN is deterministic and fixed.
- Evidence anchors:
  - [abstract] "remains so for any 'disturbed' G by flipping up to k of its node pairs"
  - [section] "Algorithm RoboGExp always terminates with either a non-trivial k-RCW, or trivial cases"
  - [corpus] Weak corpus evidence; only 1 related paper mentions "robustness" but in different context
- Break condition: If the GNN's inference process changes (non-deterministic) or if disturbances exceed k, the RCW may no longer be valid.

### Mechanism 2
- Claim: The verification algorithm can efficiently check if a subgraph is a k-RCW.
- Mechanism: For APPNPs under (k, b)-disturbance, the algorithm uses a greedy edge selection strategy to compute the optimal set of edges that would maximize the PageRank score, thereby minimizing the worst-case margin.
- Core assumption: The PageRank-based GNN (APPNP) can be verified in polynomial time under local budget constraints.
- Evidence anchors:
  - [section] "Algorithm verifyRCW-APPNP... ensures a PTIME process for APPNPs under (k, b)-disturbance"
  - [section] "Lemma 4: Given the configuration C that specifies APPNP M... Gs is a k-RCW of M (v, G)=l, if and only if M (v, G \ E*_k) = l"
  - [corpus] No direct corpus evidence supporting this specific mechanism
- Break condition: If the local budget b is not a small constant or if the GNN is not APPNP-based, the verification may become intractable.

### Mechanism 3
- Claim: The parallel algorithm scales efficiently for large graphs.
- Mechanism: The algorithm partitions the graph into fragments, performs parallel verification on each fragment, and synchronizes the results to avoid redundant verification.
- Core assumption: The graph can be partitioned such that local verification is sufficient and data exchange is minimized.
- Evidence anchors:
  - [section] "Algorithm paraRoboGExp... works with a coordinator site S0 and n workers {S1, . . . Sn}"
  - [section] "The algorithm paraRoboGExp scales well as more processors are used"
  - [corpus] Weak corpus evidence; only 1 related paper mentions parallel processing but not for this specific problem
- Break condition: If the graph partitioning is not effective or if the communication overhead between workers is high, the parallel algorithm may not scale as expected.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: Understanding how GNNs work is crucial for comprehending the explanation structures and algorithms presented in the paper.
  - Quick check question: Can you explain how a message-passing GNN updates node features?
- Concept: Counterfactual and Factual Explanations
  - Why needed here: The paper focuses on generating explanations that are both counterfactual (changing the prediction if removed) and factual (preserving the prediction).
  - Quick check question: What is the difference between a counterfactual and a factual witness?
- Concept: Robustness in Machine Learning
  - Why needed here: The paper introduces the concept of robust counterfactual witnesses, which remain valid under certain structural disturbances.
  - Quick check question: How does the concept of robustness apply to graph-structured data?

## Architecture Onboarding

- Component map: GNN classifier -> RoboGExp algorithm -> Parallel verification -> RCW output
- Critical path: The critical path is the generation of RCWs, which involves expanding the witness subgraph and verifying its robustness under disturbances.
- Design tradeoffs: The paper trades off between the quality of explanations (robustness and fidelity) and computational efficiency (time and scalability).
- Failure signatures: The algorithms may fail to generate non-trivial RCWs if the test nodes do not retain the same labels or if the disturbances exceed the specified budget.
- First 3 experiments:
  1. Verify the correctness of the verification algorithm on a small graph with known RCWs.
  2. Test the efficiency of RoboGExp on a medium-sized graph with varying numbers of test nodes and disturbances.
  3. Evaluate the scalability of paraRoboGExp on a large graph by increasing the number of workers and measuring the speedup.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can RoboGExp be extended to generate minimum explanations that are still robust and faithful to the GNN's predictions?
- Basis in paper: [explicit] The paper mentions "A future topic is to enhance our solution to generate minimum explanations" in the conclusion section.
- Why unresolved: The current RoboGExp algorithm focuses on generating robust counterfactual witnesses but does not explicitly optimize for the minimal size of these explanations. Finding the smallest possible explanation that maintains robustness and fidelity is an open research question.
- What evidence would resolve it: Experimental results comparing the size of explanations generated by an enhanced RoboGExp (optimized for minimality) against the current version, while maintaining similar levels of robustness and fidelity.

### Open Question 2
- Question: How does the performance of RoboGExp vary when applied to other GNN tasks beyond node classification, such as link prediction or graph classification?
- Basis in paper: [inferred] The paper primarily focuses on node classification tasks and mentions that the solutions are "model-agnostic and generalize to GNN specifications." However, it does not provide experimental results or analysis for other GNN tasks.
- Why unresolved: The paper's experiments and analysis are limited to node classification, leaving the effectiveness and efficiency of RoboGExp for other GNN tasks unexplored.
- What evidence would resolve it: Experimental results evaluating RoboGExp on link prediction and graph classification tasks, comparing its performance against existing explanation methods for these tasks.

### Open Question 3
- Question: How sensitive is RoboGExp to the choice of k (the number of allowed perturbations) in terms of explanation quality and computational efficiency?
- Basis in paper: [explicit] The paper discusses the impact of k on effectiveness and efficiency in the experimental section, but does not provide a comprehensive analysis of the sensitivity to k.
- Why unresolved: While the paper shows that RoboGExp's performance changes with different values of k, it does not explore the full range of k or provide insights into the optimal choice of k for various applications.
- What evidence would resolve it: A detailed sensitivity analysis of RoboGExp's performance (in terms of explanation quality and computational efficiency) across a wide range of k values, identifying the optimal k for different graph characteristics and GNN architectures.

## Limitations

- The theoretical framework assumes deterministic GNN inference, but many practical GNNs involve stochastic elements that could affect witness robustness
- The parallel algorithm's scalability claims depend heavily on effective graph partitioning, which may not generalize well to real-world graphs with heterogeneous structures
- The experimental validation focuses primarily on synthetic and moderately-sized real-world graphs, with limited testing on extremely large-scale graphs

## Confidence

- **High Confidence**: The computational hardness results (Theorem 2 and 3) are well-established and the algorithm correctness proofs are rigorous
- **Medium Confidence**: The empirical performance improvements (70.7% speedup, 0.32 GED, 0.79 fidelity+) are demonstrated but limited to specific datasets
- **Low Confidence**: The generalizability of the approach to non-GCN architectures and the practical utility of RCWs in complex real-world scenarios

## Next Checks

1. Test the parallel algorithm's scalability on graphs with 10M+ edges and measure actual vs. theoretical speedup
2. Evaluate RCW generation on non-GCN architectures (GAT, GraphSAGE) to assess framework generalizability
3. Conduct user studies with domain experts to validate whether the generated RCWs provide meaningful insights in practical applications like drug discovery and cybersecurity