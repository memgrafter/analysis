---
ver: rpa2
title: 'What is the Role of Small Models in the LLM Era: A Survey'
arxiv_id: '2409.06857'
source_url: https://arxiv.org/abs/2409.06857
tags:
- data
- language
- small
- arxiv
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey explores the relationship between large language models
  (LLMs) and small models (SMs) in the era of AI advancement. While LLMs have achieved
  remarkable performance, their high computational costs and resource demands make
  them impractical for many users.
---

# What is the Role of Small Models in the LLM Era: A Survey

## Quick Facts
- arXiv ID: 2409.06857
- Source URL: https://arxiv.org/abs/2409.06857
- Authors: Lihu Chen; Gaël Varoquaux
- Reference count: 33
- Primary result: Small models are strategic complements to LLMs, not just cost-effective alternatives

## Executive Summary
This survey systematically examines the relationship between small models (SMs) and large language models (LLMs) in the evolving AI landscape. While LLMs have achieved remarkable performance, their high computational costs and resource demands make them impractical for many users. The authors reveal that small models are not merely cost-effective alternatives but strategic complements that can enhance LLMs through data curation, efficient inference, augmented reasoning, and evaluation. Conversely, LLMs can improve SMs via knowledge distillation, data synthesis, and instruction tuning. The research highlights that small models offer distinct advantages in computation-constrained environments, task-specific domains, and interpretability-critical applications such as healthcare and finance.

## Method Summary
The survey synthesizes existing research on the collaboration and competition between small and large language models. The authors systematically categorize the relationships into two key perspectives: Collaboration and Competition/Complementarity. Through comprehensive literature review, they identify specific mechanisms where small models enhance LLMs and vice versa, covering areas such as data curation, knowledge distillation, and task-specific applications. The study provides actionable insights for practitioners and researchers, fostering a deeper understanding of the ecological niche of small models in the AI ecosystem.

## Key Results
- Small models serve as strategic complements to LLMs in resource-constrained and specialized domains
- Collaborative approaches optimize resource usage and expand reasoning capabilities across both model types
- Small models offer distinct advantages in computation-constrained environments, task-specific domains, and interpretability-critical applications

## Why This Works (Mechanism)
The collaboration between small and large models works through complementary strengths: LLMs provide broad knowledge and reasoning capabilities while small models offer efficiency, specialization, and interpretability. Small models can act as effective filters and curators for LLM training data, reducing noise and improving overall system performance. The knowledge distillation process transfers the reasoning patterns from LLMs to small models, enabling efficient deployment without sacrificing quality. This symbiotic relationship allows organizations to balance performance requirements with computational constraints.

## Foundational Learning

1. **Knowledge Distillation** - Transfer of knowledge from large models to small models through training procedures. Why needed: Enables small models to achieve performance close to LLMs while maintaining efficiency. Quick check: Compare perplexity scores between distilled small models and their teacher LLMs.

2. **Data Curation Pipeline** - Process of filtering and selecting high-quality data for model training. Why needed: Improves model performance by reducing noise in training data. Quick check: Measure data quality metrics before and after curation.

3. **Instruction Tuning** - Process of adapting models to follow specific instructions or tasks. Why needed: Enables models to perform specialized tasks more effectively. Quick check: Evaluate task completion rates on instruction-following benchmarks.

4. **Weak-to-Strong Alignment** - Training methodology where weaker models help align stronger models. Why needed: Improves the alignment and safety of large language models. Quick check: Compare alignment metrics between models trained with and without weak-to-strong supervision.

5. **Efficient Inference Techniques** - Methods to reduce computational cost during model deployment. Why needed: Enables practical deployment of models in resource-constrained environments. Quick check: Measure latency and memory usage during inference.

## Architecture Onboarding

**Component Map:** Data Curation -> Knowledge Distillation -> Instruction Tuning -> Efficient Inference

**Critical Path:** Small models act as data curators → distilled knowledge flows to small models → instruction tuning specializes capabilities → efficient inference enables deployment

**Design Tradeoffs:** Performance vs. efficiency, specialization vs. generalization, interpretability vs. capability

**Failure Signatures:** 
- Poor data curation leads to noisy training and degraded performance
- Ineffective distillation results in small models that don't capture LLM reasoning
- Insufficient instruction tuning causes task-specific failures
- Inefficient inference prevents practical deployment

**3 First Experiments:**
1. Compare data curation effectiveness by measuring training data quality metrics
2. Benchmark knowledge distillation success through perplexity and task performance
3. Evaluate instruction tuning impact on task-specific accuracy

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- The field is rapidly evolving, potentially affecting survey completeness
- Categorization of relationships may be oversimplified for complex real-world interactions
- Limited empirical validation of proposed collaborative frameworks

## Confidence
- High: Small models serve important roles in resource-constrained environments and specialized domains
- Medium: Proposed frameworks for collaboration between small and large models
- Low: Specific quantitative claims about performance and efficiency gains of collaborative approaches

## Next Checks
1. Empirical benchmarking studies comparing specific collaborative approaches across diverse task types and resource constraints
2. Analysis of real-world deployment cases where small models and LLMs are integrated, focusing on actual performance metrics and cost-benefit ratios
3. Investigation into the long-term sustainability of small models in the face of rapidly advancing LLM capabilities, particularly regarding model compression and distillation techniques