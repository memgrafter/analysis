---
ver: rpa2
title: A text-to-tabular approach to generate synthetic patient data using LLMs
arxiv_id: '2412.05153'
source_url: https://arxiv.org/abs/2412.05153
tags:
- data
- synthetic
- patient
- real
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a novel text-to-tabular approach for generating
  synthetic patient data using large language models (LLMs) without requiring access
  to original data. The method leverages in-context learning and medical domain knowledge
  embedded in LLMs to generate realistic synthetic patient data from textual descriptions
  of desired databases.
---

# A text-to-tabular approach to generate synthetic patient data using LLMs

## Quick Facts
- arXiv ID: 2412.05153
- Source URL: https://arxiv.org/abs/2412.05153
- Reference count: 29
- This study proposes a novel text-to-tabular approach for generating synthetic patient data using large language models without requiring access to original data.

## Executive Summary
This study introduces a novel text-to-tabular approach for generating synthetic patient data using large language models (LLMs) without requiring access to original data. The method leverages in-context learning and medical domain knowledge embedded in LLMs to generate realistic synthetic patient data from textual descriptions of desired databases. The approach was evaluated using Parkinson's Disease (PPMI) and Alzheimer's Disease (ADNI) datasets, comparing performance against state-of-the-art tabular-to-tabular synthetic data generation models. Results show that while the LLM-based approach achieved slightly lower fidelity scores than models trained on original data, it effectively preserved clinical correlations and achieved comparable utility in downstream tasks. Notably, the method demonstrated strong privacy preservation without using original patient-level data.

## Method Summary
The approach uses a prompt-based methodology where textual descriptions of desired health databases are used to generate synthetic patient data. The prompt includes medical knowledge, data specifications, instructions, and fictitious patient examples. GPT-3.5 or GPT-4 is called through their Python API with a temperature of 1 to generate synthetic data. The process involves simulating tables of rows using the prompt with random column permutations, iterating to obtain the desired output size. The synthetic data is then evaluated using fidelity, privacy preservation, and utility metrics, comparing against baseline SDG models like CTGAN, TV AE, and Gaussian Copula.

## Key Results
- The LLM-based approach achieved slightly lower fidelity scores than models trained on original data but effectively preserved clinical correlations
- The method demonstrated strong privacy preservation with the highest fifth percentile for DCR for PPMI and second-highest for NNDR
- Comparable utility was achieved in downstream ML tasks, with synthetic data performing competitively in classification tasks

## Why This Works (Mechanism)

### Mechanism 1
LLMs can generate realistic patient data without access to original data by leveraging their pre-trained medical knowledge. LLMs trained on biomedical literature databases extract meaningful relationships between diseases, clinical symptoms, and patient characteristics, which they use to generate realistic synthetic data from textual descriptions. Core assumption: LLMs contain sufficient embedded medical domain knowledge to understand relationships between clinical variables and generate plausible data distributions.

### Mechanism 2
The text-to-tabular approach preserves privacy by never accessing original patient-level data. By using only textual descriptions of desired databases rather than actual patient records, the approach eliminates the risk of exposing sensitive patient information. Core assumption: Privacy preservation is achieved solely through the absence of original data access, not through additional privacy-preserving techniques.

### Mechanism 3
The prompt design with medical definitions, data specifications, and fictitious examples enables high-quality synthetic data generation. The comprehensive prompt structure guides the LLM to generate data that matches the desired database characteristics, with examples providing additional context for realistic patient profiles. Core assumption: The LLM can effectively use few-shot learning from fictitious examples to understand the desired data distribution and characteristics.

## Foundational Learning

- **In-context learning**: Why needed here - The approach relies on the LLM's ability to learn from the prompt structure and examples without fine-tuning. Quick check - How does an LLM use few-shot examples in a prompt to guide its output generation?

- **Statistical fidelity metrics**: Why needed here - The evaluation framework uses multiple metrics (KSComplement, TVComplement, Column Shape Score, etc.) to assess how well the synthetic data matches the original data distributions. Quick check - What is the difference between KSComplement and TVComplement, and when would you use each?

- **Privacy metrics for synthetic data**: Why needed here - The approach claims strong privacy preservation, so understanding metrics like DCR, NNDR, and CAPCategorical is essential for proper evaluation. Quick check - How does the Distance to Closest Record (DCR) metric help assess the privacy of synthetic data?

## Architecture Onboarding

- **Component map**: Prompt generator -> LLM interface -> Data aggregator -> Evaluation pipeline -> Comparison module
- **Critical path**: 1) Create prompt with database description, data specifications, and fictitious examples. 2) Send prompt to LLM API and receive synthetic data. 3) Aggregate multiple LLM outputs into final dataset. 4) Compute evaluation metrics against real data. 5) Compare performance with baseline models.
- **Design tradeoffs**: Using GPT-4 vs GPT-3.5 (higher quality but increased cost), number of examples in prompt (more examples may improve quality but increase prompt size), dataset size (larger datasets provide better evaluation but increase computational cost).
- **Failure signatures**: Poor fidelity metrics (LLM not capturing correct data distributions), high privacy scores (synthetic data too dissimilar from real data), low utility metrics (synthetic data lacks patterns needed for downstream ML tasks).
- **First 3 experiments**: 1) Generate synthetic data using GPT-3.5 with basic prompt structure, then evaluate fidelity metrics. 2) Add fictitious examples to prompt and regenerate, comparing fidelity improvements. 3) Switch to GPT-4 and compare results against GPT-3.5 baseline.

## Open Questions the Paper Calls Out

### Open Question 1
How do LLM-based text-to-tabular approaches compare to traditional tabular-to-tabular methods when generating synthetic data for rare diseases or conditions with limited published literature? The current study focused on Parkinson's Disease and Alzheimer's Disease datasets with substantial published research, leaving uncertainty about LLM performance when medical knowledge is sparse. Testing the approach on rare diseases would resolve this question.

### Open Question 2
Can the text-to-tabular approach maintain synthetic data quality when applied to longitudinal patient data rather than cross-sectional datasets? The authors mention it would be valuable to assess performance on longitudinal data, but did not test this application. Applying the approach to longitudinal datasets and evaluating temporal consistency would resolve this question.

### Open Question 3
What is the optimal balance between providing specific examples in prompts versus allowing the LLM more freedom in synthetic data generation? While the study identified a trade-off, it didn't explore different types, numbers, or specificity levels of examples. Systematic testing of various prompt configurations would resolve this question.

## Limitations

- Fidelity scores were consistently lower than models trained on original data, suggesting potential information loss when generating from textual descriptions alone.
- The evaluation relied on public datasets which may not fully represent the complexity of proprietary or highly sensitive clinical data.
- The study's reliance on commercial LLM APIs introduces concerns about reproducibility, cost scalability, and potential data exposure through API calls.

## Confidence

- **High Confidence**: The core mechanism of using textual descriptions to guide LLM-based synthetic data generation is well-supported by experimental results. Privacy preservation claims are substantiated by strong performance across multiple privacy metrics.
- **Medium Confidence**: Utility claims for downstream ML tasks show promising but mixed results, with slight reduction in accuracy compared to models trained on original data.
- **Low Confidence**: Generalizability to other disease domains and long-term privacy guarantees require further validation, as the study focused on neurodegenerative diseases.

## Next Checks

1. Test the approach on a completely different medical domain (e.g., oncology or cardiovascular diseases) to assess generalizability beyond neurodegenerative conditions.

2. Conduct a time-series analysis of synthetic data privacy by evaluating how synthetic data generated today might be vulnerable to future inference attacks as LLMs and attack methodologies evolve.

3. Perform a detailed economic analysis comparing the approach's costs (API usage, computational resources) against the value created through privacy preservation and reduced data access barriers.