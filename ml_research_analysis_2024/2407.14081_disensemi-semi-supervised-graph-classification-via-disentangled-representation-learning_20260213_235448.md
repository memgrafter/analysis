---
ver: rpa2
title: 'DisenSemi: Semi-supervised Graph Classification via Disentangled Representation
  Learning'
arxiv_id: '2407.14081'
source_url: https://arxiv.org/abs/2407.14081
tags:
- graph
- factor
- representation
- learning
- supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of semi-supervised graph classification,
  where labeled graph data is limited. The proposed method, DisenSemi, introduces
  a novel disentangled representation learning framework that explicitly identifies
  and regularizes the rationale factors that align well between supervised and unsupervised
  learning models.
---

# DisenSemi: Semi-supervised Graph Classification via Disentangled Representation Learning

## Quick Facts
- arXiv ID: 2407.14081
- Source URL: https://arxiv.org/abs/2407.14081
- Reference count: 40
- Key outcome: Achieves 92.6% accuracy on MUTAG dataset, outperforming state-of-the-art methods in semi-supervised graph classification

## Executive Summary
This paper addresses semi-supervised graph classification where labeled data is limited. The proposed DisenSemi method introduces a disentangled representation learning framework that explicitly identifies and regularizes rationale factors aligning between supervised and unsupervised learning models. By factorizing graph representations and enforcing mutual information-based consistency regularization, DisenSemi transfers only relevant semantic aspects between tasks. Experimental results on multiple datasets demonstrate superior performance compared to existing methods, with significant accuracy improvements in low-label regimes.

## Method Summary
DisenSemi employs a disentangled graph encoder to generate factor-wise graph representations for both supervised and unsupervised models. The method trains two models using supervised objectives and mutual information-based constraints respectively, with a key innovation being MI-based disentangled consistency regularization between them. This ensures meaningful knowledge transfer by focusing on relevant semantic aspects bridging supervised and unsupervised tasks. The framework factorizes graphs into K factor graphs, applies message passing to extract representations, maximizes intra-factor MI for global content capture, minimizes inter-factor MI for disentanglement, and enforces consistency between supervised and unsupervised representations.

## Key Results
- Achieves 92.6% accuracy on MUTAG dataset, outperforming baseline methods
- Demonstrates consistent improvements across multiple benchmark datasets in semi-supervised settings
- Shows effectiveness particularly in low-label regimes where labeled data is scarce

## Why This Works (Mechanism)

### Mechanism 1
The model transfers only relevant semantic aspects between supervised and unsupervised tasks by disentangling graph representations into factor-wise components. The disentangled graph encoder decomposes the input graph into K factor graphs, each capturing a distinct latent factor, then maximizes mutual information between corresponding factor-wise representations to ensure only semantically aligned knowledge transfers.

### Mechanism 2
The intra-factor MI maximization ensures each factor graph representation captures the global content of that factor. For each factor graph, the model maximizes mutual information between the factor graph representation and local node embeddings, ensuring the representation captures the global structure of that factor.

### Mechanism 3
The inter-factor MI minimization enforces representation disentanglement by making different factor graph representations independent. The model minimizes mutual information between representations from different factor graphs, encouraging them to capture distinct aspects of the graph data.

## Foundational Learning

- Concept: Mutual Information Estimation
  - Why needed here: MI estimation is central to both the disentanglement process (intra-factor maximization and inter-factor minimization) and the consistency regularization between supervised and unsupervised models
  - Quick check question: What are the key differences between MINE, InfoNCE, and JS-based MI estimators, and when would each be most appropriate?

- Concept: Variational EM Algorithm
  - Why needed here: The consistency regularization can be formalized as a Variational EM problem, where the E-step infers the posterior over latent factors and the M-step optimizes the ELBO
  - Quick check question: How does the consistency regularization objective in DisenSemi map to the standard Variational EM framework, and what are the roles of the E and M steps?

- Concept: Graph Neural Networks and Message Passing
  - Why needed here: The GNN-based encoder is fundamental to extracting factor-wise graph representations through message passing on each factor graph
  - Quick check question: How does the choice of message passing layer (GraphConv vs GCN vs GAT) affect the quality of factor-wise representations, and what properties should an ideal message passing layer have for this application?

## Architecture Onboarding

- Component map: Input Graph → GNN-based Encoder → Supervised/Unsupervised Modules → Consistency Regularization → Output Labels
- Critical path: Input → GNN-based Encoder → Supervised/Unsupervised Modules → Consistency Regularization → Output
  The most critical components are the GNN-based encoder (for representation quality) and the consistency regularization (for knowledge transfer)
- Design tradeoffs:
  - Number of factor graphs (K): More factors allow finer-grained disentanglement but increase computational cost and risk of over-decomposition
  - Message passing depth (L): Deeper networks capture more complex structures but risk over-smoothing
  - MI estimation method: Different estimators (MINE, InfoNCE, JS-based) have different bias-variance tradeoffs and computational costs
- Failure signatures:
  - Poor performance despite good training loss: Likely indicates that the disentanglement is not meaningful or the consistency regularization is not effective
  - Disentangled factor graphs look similar: Suggests inter-factor MI minimization is not working properly
  - Supervised model performs well but unsupervised model does not improve: Indicates the consistency regularization may be one-sided
- First 3 experiments:
  1. Ablation study: Remove each component (GNN encoder, MI disentanglement, consistency regularization) to verify their individual contributions
  2. Sensitivity analysis: Vary the number of factor graphs (K) and message passing layers (L) to find optimal architecture
  3. Visualization study: Visualize factor graphs and representation correlations to verify meaningful disentanglement

## Open Questions the Paper Calls Out

### Open Question 1
How does the number of factor graphs (K) affect the performance of DisenSemi across different graph datasets, and what is the optimal value for each dataset? The paper explores K values from 20 to 24 but optimal values may vary depending on dataset characteristics and specific tasks.

### Open Question 2
How does the disentangled consistency regularization in DisenSemi compare to other consistency-based methods in terms of effectiveness and efficiency for semi-supervised graph classification? The paper introduces this method but hasn't thoroughly investigated its advantages and limitations compared to other consistency-based approaches.

### Open Question 3
How does the proposed MI-based representation disentanglement in DisenSemi compare to other disentanglement methods in terms of effectiveness and interpretability for semi-supervised graph classification? The paper introduces an MI-based approach but hasn't thoroughly investigated its advantages and limitations compared to other disentanglement methods.

## Limitations

- Limited interpretability analysis: The paper provides visualizations of learned factor graphs for small graphs but lacks comprehensive qualitative analysis across all datasets
- Core assumptions lack extensive validation: The assumption that MI-based disentanglement leads to better transfer learning lacks thorough ablation studies on the disentanglement process itself
- Computational complexity not thoroughly explored: The computational costs of MI estimation procedures and their sensitivity to hyperparameter choices are not fully examined

## Confidence

**High Confidence:** The overall framework architecture and mathematical formulation are well-specified. The experimental methodology (10-fold cross-validation, standard datasets) is rigorous and reproducible.

**Medium Confidence:** The claims about MI-based disentanglement leading to better knowledge transfer are supported by experimental results but lack deeper theoretical justification or extensive ablation studies on the disentanglement process itself.

**Low Confidence:** The paper's assertions about the semantic interpretability of learned factors are primarily supported by visual inspection of small graphs without quantitative measures of disentanglement quality or consistency across datasets.

## Next Checks

1. **Factor Stability Analysis:** Conduct experiments to assess how stable the learned factors are across different random seeds and whether the same factors consistently align with meaningful semantic aspects across different graph datasets.

2. **Ablation of MI Components:** Systematically remove the intra-factor MI maximization, inter-factor MI minimization, and consistency regularization components to quantify their individual contributions to performance gains.

3. **Factor Number Sensitivity:** Perform a comprehensive study varying the number of factors (K) from 2 to 10+ to determine the optimal number for different dataset characteristics and assess whether performance plateaus or degrades with over-decomposition.