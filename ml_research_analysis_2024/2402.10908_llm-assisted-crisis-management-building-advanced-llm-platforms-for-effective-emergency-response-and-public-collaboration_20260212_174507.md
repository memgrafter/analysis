---
ver: rpa2
title: 'LLM-Assisted Crisis Management: Building Advanced LLM Platforms for Effective
  Emergency Response and Public Collaboration'
arxiv_id: '2402.10908'
source_url: https://arxiv.org/abs/2402.10908
tags:
- emergency
- response
- language
- data
- management
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents two frameworks leveraging Large Language Models
  (LLMs) like LLAMA2 to enhance emergency response systems. The first framework integrates
  LLMs into 911 dispatch processes, enabling real-time transcription, classification,
  and analysis of emergency calls to assist dispatchers.
---

# LLM-Assisted Crisis Management: Building Advanced LLM Platforms for Effective Emergency Response and Public Collaboration

## Quick Facts
- arXiv ID: 2402.10908
- Source URL: https://arxiv.org/abs/2402.10908
- Reference count: 40
- Key result: LLAMA2-13B fine-tuned on emergency social media data achieves up to 0.85 F1-score in crisis classification

## Executive Summary
This paper presents two frameworks leveraging Large Language Models (LLMs) to enhance emergency response systems. The first framework integrates LLMs into 911 dispatch processes for real-time transcription, classification, and analysis of emergency calls. The second framework employs an LLM-enhanced mobile app to provide AI-driven guidance to the public during major crises. Through fine-tuning multiple LLMs on emergency-related social media datasets, the authors demonstrate that LLAMA2 models, particularly the 13B variant, achieve high accuracy in classifying emergency situations while balancing computational efficiency.

## Method Summary
The authors fine-tuned LLAMA2 and Mistral models (7B, 13B, 70B variants) on emergency-related social media datasets using Supervised Fine-Tuning with LoRA and QLoRA for efficient training. The Turkey Earthquake X Corp. Dataset (500 tweets) and the Emergency-Disaster Messages Dataset (25,000+ messages from various disasters) were used for training. Models were evaluated on classification performance using F1-score, ROC-AUC, and accuracy metrics. The fine-tuning process employed NVIDIA A100 GPUs with 80GB VRAM, noise injection (NEFTune), and Flash Attention 2 to prevent overfitting and improve efficiency.

## Key Results
- LLAMA2-70B achieved 0.85 F1-score, 0.93 ROC-AUC, and 0.69 accuracy on emergency message classification
- LLAMA2-13B provided the best balance between accuracy and computational efficiency among tested models
- The frameworks demonstrated potential for improving crisis management efficiency, inclusivity, and responsiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM fine-tuning on emergency-specific social media data improves classification accuracy for real-time crisis detection.
- Mechanism: The model learns to map varied linguistic patterns in disaster-related posts to structured emergency categories, enabling rapid identification of high-priority incidents.
- Core assumption: Emergency-related text follows distinguishable patterns that can be learned from labeled data.
- Evidence anchors:
  - [abstract] The authors fine-tuned multiple LLMs on datasets of emergency-related social media messages, achieving up to 0.85 F1-score in classifying emergency situations.
  - [section] The Turkey Earthquake X Corp. Dataset and the Emergency-Disaster Messages Dataset were used to fine-tune models, with LLAMA2-13B achieving the best balance of accuracy and efficiency.
  - [corpus] Weak evidence; related work on earthquake response mentions AI integration but not specific fine-tuning outcomes.
- Break condition: If the labeled data lacks diversity or is outdated, the model may fail to generalize to new crisis scenarios.

### Mechanism 2
- Claim: Integrating LLMs into 911 dispatch workflows enhances situational awareness and reduces dispatcher workload.
- Mechanism: Real-time transcription and classification of emergency calls provide structured, actionable information to dispatchers, improving response coordination.
- Core assumption: LLMs can reliably transcribe and interpret spoken emergency calls in real time.
- Evidence anchors:
  - [abstract] The first framework integrates LLMs into 911 dispatch processes, enabling real-time transcription, classification, and analysis of emergency calls.
  - [section] The proposed system includes real-time transcription and named entity recognition to identify emergency types, levels, and contact details, aiding dispatchers.
  - [corpus] No direct corpus evidence; related work focuses on visualization tools but not LLM-based dispatch support.
- Break condition: If transcription accuracy degrades in noisy or multilingual environments, the system's utility decreases.

### Mechanism 3
- Claim: LLM-enhanced mobile apps can provide AI-driven public guidance during crises, reducing strain on emergency services.
- Mechanism: By classifying incoming public messages and delivering targeted instructions, the system empowers individuals to take appropriate actions while informing authorities.
- Core assumption: The public will actively use and trust AI-generated guidance during emergencies.
- Evidence anchors:
  - [abstract] The second framework employs an LLM-enhanced mobile app to provide AI-driven guidance to the public during major crises.
  - [section] The app is designed to offer real-time, context-aware instructions based on user-reported situations and locations.
  - [corpus] Weak evidence; related work mentions social media use in disasters but not AI-driven public guidance systems.
- Break condition: If misinformation or mistrust in AI guidance spreads, public compliance and system effectiveness decline.

## Foundational Learning

- Concept: Text classification and named entity recognition
  - Why needed here: Essential for extracting structured information from unstructured emergency communications.
  - Quick check question: Can you explain how NER helps identify key entities like location and emergency type in a tweet?

- Concept: Supervised fine-tuning and LoRA
  - Why needed here: Enables efficient adaptation of large models to specialized emergency response tasks with limited labeled data.
  - Quick check question: What is the advantage of using LoRA over full fine-tuning for LLAMA2 in this context?

- Concept: Multilingual NLP and translation
  - Why needed here: Supports diverse populations in crisis situations where language barriers could delay response.
  - Quick check question: How does multilingual support in LLMs improve inclusivity in emergency management?

## Architecture Onboarding

- Component map: Real-time transcription → LLM classification → Dispatcher interface / Public app → Emergency agency notification
- Critical path: Incoming communication → Preprocessing → Model inference → Structured output delivery
- Design tradeoffs: Model size vs. latency (LLAMA2-13B balances accuracy and speed); fine-tuning data quality vs. generalization
- Failure signatures: High false negative rates in classification; transcription errors in noisy environments; app adoption barriers
- First 3 experiments:
  1. Fine-tune LLAMA2-13B on the Turkey Earthquake dataset and evaluate F1-score on a held-out test set.
  2. Integrate the model into a simulated 911 dispatch workflow and measure response time improvements.
  3. Deploy the public app in a controlled scenario and assess user comprehension of AI-generated instructions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between model size and real-time performance for emergency response applications?
- Basis in paper: [explicit] The paper discusses LLAMA2 variants (7B, 13B, 70B) and Mistral models (7B, 8x7B), noting that smaller models offer quick processing but limited understanding, while larger models provide better performance but require more computational resources.
- Why unresolved: The paper presents performance comparisons but doesn't determine the ideal model size that balances accuracy with real-time response requirements.
- What evidence would resolve it: Systematic evaluation of different model sizes under varying emergency scenarios, measuring both accuracy and response time.

### Open Question 2
- Question: How can data poisoning attacks be effectively prevented in emergency response AI systems?
- Basis in paper: [explicit] The paper discusses data poisoning as a threat where malicious entities introduce corrupted data into training datasets, potentially leading to inaccurate emergency responses.
- Why unresolved: While the paper mentions the threat, it doesn't provide specific solutions or protocols for preventing such attacks in real-world emergency response systems.
- What evidence would resolve it: Development and testing of robust data validation frameworks and adversarial training methods specifically designed for emergency response datasets.

### Open Question 3
- Question: What is the most effective approach for handling multilingual emergency communications while maintaining accuracy and response speed?
- Basis in paper: [explicit] The paper highlights the importance of multilingual support in emergency response systems, particularly for diverse urban areas, but doesn't specify the optimal implementation strategy.
- Why unresolved: The paper acknowledges the need for multilingual capabilities but doesn't provide specific metrics or methodologies for evaluating multilingual performance in emergency contexts.
- What evidence would resolve it: Comparative analysis of different multilingual implementation strategies, measuring both accuracy and response time across various language pairs.

## Limitations

- Small labeled datasets (500 tweets for Turkey Earthquake) may limit model generalizability across diverse emergency scenarios
- Evaluation focuses on classification metrics without testing actual system integration with 911 dispatch centers or real emergency response workflows
- Privacy and bias considerations are mentioned but not empirically validated in the proposed frameworks

## Confidence

- High confidence in: The technical feasibility of fine-tuning LLMs for emergency message classification, with LLAMA2-13B achieving strong F1-scores (0.78-0.85) on the tested datasets.
- Medium confidence in: The integration architecture connecting LLMs to 911 dispatch workflows and public mobile apps, as the paper provides conceptual frameworks but limited implementation details.
- Low confidence in: The real-world effectiveness of these systems in actual emergency scenarios, including public adoption rates, system reliability under stress, and impact on response times.

## Next Checks

1. Deploy the fine-tuned LLM in a simulated 911 dispatch environment with actual emergency call recordings (including background noise and multilingual content) to measure transcription accuracy and classification reliability under realistic conditions.

2. Conduct a controlled user study with 50+ participants testing the public mobile app during simulated crisis scenarios to evaluate comprehension of AI-generated guidance and willingness to follow instructions.

3. Perform cross-dataset validation by fine-tuning on the Turkey Earthquake data and testing on the Emergency-Disaster Messages Dataset (and vice versa) to assess model generalization across different disaster types and geographic regions.