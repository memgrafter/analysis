---
ver: rpa2
title: 'QASE Enhanced PLMs: Improved Control in Text Generation for MRC'
arxiv_id: '2403.04771'
source_url: https://arxiv.org/abs/2403.04771
tags:
- qase
- question
- answer
- plms
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of out-of-control generation
  in generative models for machine reading comprehension (MRC). The authors propose
  the Question-Attended Span Extraction (QASE) module, which is integrated during
  fine-tuning of pre-trained generative language models (PLMs).
---

# QASE Enhanced PLMs: Improved Control in Text Generation for MRC
## Quick Facts
- arXiv ID: 2403.04771
- Source URL: https://arxiv.org/abs/2403.04771
- Reference count: 26
- Primary result: QASE module integrated during PLM fine-tuning enables extractive MRC performance matching state-of-the-art methods and surpassing GPT-4

## Executive Summary
This work addresses the challenge of out-of-control generation in generative models for machine reading comprehension (MRC). The authors propose the Question-Attended Span Extraction (QASE) module, which is integrated during fine-tuning of pre-trained generative language models (PLMs). QASE enables these PLMs to match state-of-the-art extractive methods and outperform leading large language models like GPT-4 on MRC tasks, without significant increases in computational costs. Specifically, on SQuAD, QASE-enhanced models show up to 33.8% improvement in exact match and 8.4% in F1 score over vanilla fine-tuned models. On MultiSpanQA, improvements reach up to 1.6% in exact match F1 and 3.3% in overlap F1. Additionally, QASE improves factual consistency, as measured by Q2 scores, by 1.0% on SQuAD and 16.0% on MultiSpanQA. The best-performing model, Flan-T5-Large with QASE, surpasses GPT-4 by significant margins across all three MRC datasets.

## Method Summary
The proposed QASE module is designed to be integrated during the fine-tuning phase of pre-trained generative language models. It incorporates question-specific attention mechanisms to guide span extraction, effectively constraining the generation process to produce more accurate and factual answers. The module works by attending to relevant parts of the question while extracting answer spans from the context, thereby improving both precision and factual consistency compared to standard fine-tuning approaches.

## Key Results
- On SQuAD: up to 33.8% improvement in exact match and 8.4% in F1 score over vanilla fine-tuned models
- On MultiSpanQA: improvements reach up to 1.6% in exact match F1 and 3.3% in overlap F1
- Factual consistency (Q2 scores) improves by 1.0% on SQuAD and 16.0% on MultiSpanQA
- Flan-T5-Large with QASE surpasses GPT-4 by significant margins across all three MRC datasets

## Why This Works (Mechanism)
The QASE module introduces question-attended attention during span extraction, which constrains the generation process by focusing on relevant context based on the question. This targeted attention mechanism helps prevent the model from generating answers that are not supported by the context, addressing the common issue of out-of-control generation in PLMs. By aligning the answer extraction process more closely with the question semantics, QASE improves both the accuracy and factual consistency of generated answers.

## Foundational Learning
- **Question-Attended Span Extraction**: A technique that uses attention mechanisms to focus on relevant context portions based on the question. Needed to guide the model's answer extraction process. Quick check: Verify that the attention weights correlate with relevant context segments.
- **Fine-tuning of Pre-trained Generative Language Models**: The process of adapting PLMs to specific downstream tasks. Needed to leverage pre-trained knowledge for MRC tasks. Quick check: Confirm that fine-tuning converges and improves task-specific performance.
- **Factual Consistency Metrics (Q2 score)**: Evaluation metrics designed to measure the factual alignment between generated answers and the source context. Needed to quantify improvements in answer reliability. Quick check: Validate that Q2 scores align with human judgments of answer quality.

## Architecture Onboarding
- **Component Map**: Question -> QASE Module -> PLM -> Answer Span
- **Critical Path**: Input Question and Context -> QASE Attention Computation -> Span Extraction by PLM -> Output Answer
- **Design Tradeoffs**: The QASE module adds computational overhead during fine-tuning but claims minimal impact on inference time. Tradeoff between improved accuracy and potential latency increase.
- **Failure Signatures**: If QASE fails, models may revert to generating unsupported or factually inconsistent answers, similar to vanilla PLMs. Attention weights may become less focused on relevant context.
- **First 3 Experiments**: 1) Compare QASE-enhanced vs. vanilla fine-tuned models on SQuAD development set. 2) Measure Q2 scores for factual consistency across datasets. 3) Analyze attention weight distributions to verify question-context alignment.

## Open Questions the Paper Calls Out
None

## Limitations
- Model generalization remains untested across diverse MRC tasks, question types, and domains beyond SQuAD and MultiSpanQA
- Computational overhead claims lack quantitative comparison of training/inference times or memory requirements
- Factual consistency improvements rely solely on Q2 scores without comparison to alternative evaluation methods

## Confidence
- QASE matches state-of-the-art extractive methods: High
- QASE outperforms GPT-4 on tested datasets: Medium (dataset-specific)
- Minimal computational cost increase: Low
- Significant improvement in factual consistency: Medium

## Next Checks
1. Test QASE-enhanced models on additional MRC datasets (e.g., NewsQA, Natural Questions, RACE) to assess generalization across different question types and domains
2. Conduct ablation studies to quantify the exact computational overhead (training time, inference latency, memory usage) of QASE compared to vanilla fine-tuning
3. Compare Q2 scores with alternative factual consistency evaluation methods (e.g., factuality scoring models, human evaluation) to validate the claimed improvements