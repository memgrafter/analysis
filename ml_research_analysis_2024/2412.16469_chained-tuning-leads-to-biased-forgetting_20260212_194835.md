---
ver: rpa2
title: Chained Tuning Leads to Biased Forgetting
arxiv_id: '2412.16469'
source_url: https://arxiv.org/abs/2412.16469
tags:
- forgetting
- task
- safety
- toxigenqa
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates biased forgetting in large language models
  during chained fine-tuning. The authors systematically examine how task ordering
  affects forgetting, finding that safety tasks experience more forgetting when fine-tuned
  after capability tasks compared to the reverse order.
---

# Chained Tuning Leads to Biased Forgetting

## Quick Facts
- arXiv ID: 2412.16469
- Source URL: https://arxiv.org/abs/2412.16469
- Reference count: 40
- Primary result: Safety tasks experience more forgetting when fine-tuned after capability tasks compared to the reverse order

## Executive Summary
This paper investigates catastrophic forgetting in large language models during chained fine-tuning, revealing that task ordering significantly impacts forgetting severity. The authors find that safety tasks converge to sharper minima than capability tasks, making them more vulnerable to forgetting when trained second. They introduce a novel "biased forgetting" metric showing that certain demographic groups (Muslim, Jewish, Native American) experience disproportionately more forgetting than others. The study demonstrates that as little as 5% of original safety task data can nearly restore performance, providing practical guidelines for optimizing LLM fine-tuning sequences to reduce safety forgetting.

## Method Summary
The study uses LLaMa-v2 7B as the base model, fine-tuning it sequentially on capability and safety tasks in different orders. Capability tasks (ARC, CommonsenseQA, CommonsenseQA 2.0) and safety tasks (ToxiGenQA, BBQ, SaFeRDialogues) are all formatted as QA tasks and subsampled to 2261 examples each. The authors measure forgetting using accuracy differences between single-task and sequentially-trained models, introduce biased forgetting metrics to quantify demographic disparities, and analyze minima curvature using Hessian spectral radius. Mitigation strategies involve replaying portions of original safety task data during capability training.

## Key Results
- Safety tasks experience significantly more forgetting when fine-tuned after capability tasks compared to the reverse order
- Muslim, Jewish, and Native American demographic groups show the most severe biased forgetting across safety tasks
- Safety tasks converge to sharper minima than capability tasks, explaining differential forgetting rates
- As little as 5% of original safety task data can nearly restore performance during mitigation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task ordering affects forgetting severity
- Mechanism: Safety tasks converge to sharper minima than capability tasks, making them more vulnerable to forgetting when trained second
- Core assumption: The curvature of the loss landscape minima correlates with forgetting magnitude
- Evidence anchors:
  - [abstract] "safety tasks converge to sharper minima than capability tasks"
  - [section] "Given a model θ*AB trained sequentially on A followed by B... Equation (3) relies on the assumption that the first task model θ*A is at, or reasonably near to, a local minima"
  - [corpus] Weak - corpus papers discuss forgetting but not minima curvature differences
- Break condition: If first task doesn't converge to a local minimum, the curvature analysis becomes invalid

### Mechanism 2
- Claim: Biased forgetting disproportionately impacts certain demographic groups
- Mechanism: Forgetting patterns vary by demographic group, with Muslim, Jewish, and Native American groups showing most severe forgetting
- Core assumption: Demographic groups have different levels of representation or importance in the learned representations
- Evidence anchors:
  - [abstract] "Muslim, Jewish, and Native American groups showing the most severe forgetting"
  - [section] "We observe varying degrees of biased forgetting when comparing demographic groups in safety tasks"
  - [corpus] Weak - corpus papers discuss safety but not demographic-specific forgetting patterns
- Break condition: If demographic groups are not properly represented in the training data, the biased forgetting metric becomes unreliable

### Mechanism 3
- Claim: Small amounts of original task data can mitigate forgetting
- Mechanism: Replaying as little as 5% of original safety task data during capability training can nearly restore performance
- Core assumption: Partial rehearsal of original task examples maintains task-relevant representations
- Evidence anchors:
  - [abstract] "as little as 5% of the original safety task data can nearly restore performance"
  - [section] "Our findings show that as little as 5% of safety data can nearly restore performance to its original level"
  - [corpus] Weak - corpus papers discuss catastrophic forgetting but not specific data replay percentages
- Break condition: If the replayed data doesn't capture the essential task patterns, forgetting won't be mitigated

## Foundational Learning

- Concept: Catastrophic forgetting
  - Why needed here: This paper builds on catastrophic forgetting research to show task-specific and demographic-specific forgetting patterns
  - Quick check question: What distinguishes catastrophic forgetting from regular forgetting in neural networks?

- Concept: Minima curvature analysis
  - Why needed here: The paper uses Hessian spectral radius to explain why some tasks forget more than others
  - Quick check question: How does the spectral radius of the Hessian relate to the width of a minima?

- Concept: Demographic bias measurement
  - Why needed here: The paper introduces "biased forgetting" to quantify disproportionate forgetting across demographic groups
  - Quick check question: What statistical method does the paper use to assess the consistency of biased forgetting across different task pairs?

## Architecture Onboarding

- Component map:
  - LLaMa-v2 7B (pre-trained) -> Sequential fine-tuning pipeline -> Task-specific datasets -> Evaluation metrics

- Critical path:
  1. Load base model
  2. Fine-tune on first task
  3. Evaluate first task performance
  4. Fine-tune on second task
  5. Evaluate forgetting on both tasks
  6. Measure demographic-specific forgetting
  7. Apply mitigation if needed

- Design tradeoffs:
  - Data size vs. performance: Smaller datasets used for fair comparison
  - Task format consistency vs. realism: QA format chosen for comparability
  - Learning rate vs. forgetting: Higher rates may reduce forgetting but affect convergence

- Failure signatures:
  - High forgetting on safety tasks when trained second
  - Disproportionate forgetting on specific demographic groups
  - Poor minima curvature correlation with forgetting predictions

- First 3 experiments:
  1. Compare forgetting when safety task is first vs second (TQA→ARC vs ARC→TQA)
  2. Measure biased forgetting across demographic groups in ToxiGenQA
  3. Test mitigation by replaying 5% of safety data after capability training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed biased forgetting phenomenon generalize beyond QA tasks to other language modeling tasks like code generation or text classification?
- Basis in paper: [inferred] The paper notes that all experiments were conducted with QA tasks and suggests future work exploring other formats like code or traditional NLP classification tasks.
- Why unresolved: The current study's experimental scope is limited to QA tasks, leaving uncertainty about whether the task ordering effects and demographic disparities in forgetting would persist in different task domains.
- What evidence would resolve it: Conducting systematic experiments with non-QA tasks (e.g., code generation, sentiment analysis, named entity recognition) using similar chained fine-tuning setups would reveal whether biased forgetting is task-format dependent or a more general phenomenon.

### Open Question 2
- Question: What specific aspects of task similarity (domain, format, output space) contribute most to catastrophic forgetting, and can these be quantified?
- Basis in paper: [explicit] The authors observe that task similarity affects forgetting (e.g., maintaining consistent response style when both tasks use QA format) but don't systematically disentangle which similarity dimensions matter most.
- Why unresolved: While the paper suggests task similarity plays a role, it doesn't provide a principled analysis of which task characteristics (semantic domain, input/output format, label space) drive the forgetting effects.
- What evidence would resolve it: Controlled experiments varying one dimension of task similarity at a time (e.g., keeping domain constant but changing format, or vice versa) while measuring forgetting rates would help identify the most influential factors.

### Open Question 3
- Question: How does repeated chained fine-tuning (multiple rounds) affect biased forgetting compared to the single round studied here?
- Basis in paper: [explicit] The authors state that future work will explore multiple rounds of chained tuning to better match common practice, but this remains unexplored.
- Why unresolved: The current study examines only two-stage fine-tuning, but in practice models often undergo multiple subsequent fine-tuning rounds, which could compound or change the forgetting dynamics.
- What evidence would resolve it: Experiments with three or more sequential fine-tuning stages would reveal whether forgetting accumulates over multiple rounds and whether the demographic disparities observed in two-stage training persist or change.

### Open Question 4
- Question: What is the mechanism underlying why certain demographic groups experience more severe forgetting than others?
- Basis in paper: [explicit] The authors observe that groups like Muslim, Jewish, and Native American consistently suffer more forgetting, but the underlying reasons remain unclear.
- Why unresolved: While the paper quantifies the disparity, it doesn't investigate why specific groups are more vulnerable to forgetting or whether this relates to representation in the training data or other factors.
- What evidence would resolve it: Analyzing the training data distributions across demographic groups, examining feature representations before and after forgetting, and correlating forgetting severity with representation statistics would help identify the mechanisms driving the disparities.

## Limitations
- Limited to QA task format, leaving uncertainty about generalization to other task types
- Classifier-based evaluation of safety tasks introduces potential noise and unknown bias
- Small, balanced datasets used rather than realistic imbalanced distributions

## Confidence
- High confidence in core finding that safety tasks experience more forgetting when trained after capability tasks
- Medium confidence in mechanistic explanation linking minima curvature to forgetting severity
- Medium confidence in biased forgetting metric due to classifier-based evaluation method

## Next Checks
1. Verify that safety tasks indeed converge to sharper minima by comparing Hessian spectral radii between capability and safety tasks
2. Test the 5% data replay mitigation across different capability-safety task pairs to confirm generalizability
3. Check whether changing the task format (e.g., from QA to text classification) affects the magnitude of biased forgetting observed