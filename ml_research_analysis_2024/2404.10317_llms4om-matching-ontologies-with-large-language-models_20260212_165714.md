---
ver: rpa2
title: 'LLMs4OM: Matching Ontologies with Large Language Models'
arxiv_id: '2404.10317'
source_url: https://arxiv.org/abs/2404.10317
tags:
- ontology
- llms
- matching
- retrieval
- ontologies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents LLMs4OM, a novel framework for ontology matching
  using Large Language Models (LLMs). The framework addresses the challenge of aligning
  heterogeneous ontologies for data interoperability and knowledge sharing.
---

# LLMs4OM: Matching Ontologies with Large Language Models

## Quick Facts
- arXiv ID: 2404.10317
- Source URL: https://arxiv.org/abs/2404.10317
- Reference count: 40
- Primary result: Novel framework using LLMs for ontology matching that matches or surpasses traditional systems on OAEI benchmarks

## Executive Summary
LLMs4OM introduces a novel framework for ontology matching using Large Language Models (LLMs). The framework addresses the challenge of aligning heterogeneous ontologies for data interoperability and knowledge sharing. LLMs4OM employs a two-module strategy: a retrieval module using techniques like TFIDF and sentence-BERT, and an LLM-based matching module enhanced by zero-shot prompting across three ontology representations. Extensive evaluations on 20 datasets from various domains show that LLMs under the LLMs4OM framework can match or surpass traditional ontology matching systems, particularly in complex scenarios.

## Method Summary
LLMs4OM uses a dual-module approach combining retrieval and LLM-based matching. The retrieval module (using TFIDF, sentence-BERT, SPECTER2, or OpenAI text-embedding-ada) narrows down candidate matches from the target ontology. The LLM module then evaluates these pairs for equivalence using zero-shot prompting with three concept representations: concept-only, concept with parent, and concept with children. The framework processes ontologies to extract these representations, retrieves top-k candidates, verbalizes pairs into prompts, and uses label words to classify matches while deriving confidence scores.

## Key Results
- GPT-3.5 achieved 89.11% F1-score on the Anatomy track, outperforming the best OAEI 2023 system
- The framework demonstrated competitive performance across 20 datasets from various domains
- Different retrieval models performed best on different tracks, with OpenAI text-embedding-ada showing strong overall performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dual-module strategy (retrieval + LLM) overcomes context length and hallucination limitations of direct LLM prompting for ontology matching
- Mechanism: The retrieval module first narrows down candidate matches from the target ontology using techniques like TFIDF, sentence-BERT, or OpenAI text embeddings, producing a manageable set of candidate pairs. The LLM module then evaluates these pairs for equivalence, leveraging the focused input to reduce errors and improve accuracy
- Core assumption: Ontologies have sufficient structure and lexical similarity to enable effective candidate retrieval before LLM matching
- Evidence anchors:
  - [abstract] "LLMs4OM employs a two-module strategy: a retrieval module using techniques like TFIDF and sentence-BERT, and an LLM-based matching module enhanced by zero-shot prompting"
  - [section] "To address these, LLMs4OM employs a dual-module strategy: first, using the Retrieval-Augmented Generation (RAG) [26] for candidate selection for a given query Csource from a knowledge base of Ctarget, and then LLM-based matching, in a second module, for finer accuracy"

### Mechanism 2
- Claim: Different concept representations (concept, concept-parent, concept-children) improve LLM understanding and matching accuracy by providing hierarchical context
- Mechanism: The framework processes ontologies to extract three representations: the core concept, its parent concepts, and its child concepts. These are used as input variations to the LLM, allowing it to understand concepts in both isolation and within their hierarchical relationships, leading to better matching decisions
- Core assumption: Hierarchical relationships in ontologies provide meaningful context that LLMs can leverage to improve matching accuracy
- Evidence anchors:
  - [section] "These representations will be utilized to generate three distinct input representations: i) Concept (C), a foundational representation that encapsulates the core characteristics of a standalone concept within the ontology, ii) Concept-Parent (CP), extending beyond individual concepts, this representation establishes the hierarchical relationships by incorporating information about the parent concepts, and iii) Concept-Children (CC) complementing the CP representation which focuses on the descendants of a given concept"
  - [section] "We find LLMs perform better with additional contexts like parents or children, as seen in tasks across Biodiv, Phenotype, and Bio-ML tracks"

### Mechanism 3
- Claim: Zero-shot prompting with carefully designed templates enables LLMs to perform ontology matching without requiring task-specific fine-tuning
- Mechanism: The framework uses a prompt template that verbalizes concept pairs and asks the LLM to classify whether they refer to the same real-world entity, using label words like "yes/true/right" and "no/false/wrong" to categorize responses and derive confidence scores
- Core assumption: LLMs possess sufficient general knowledge and reasoning capabilities to understand ontology concepts and their relationships without domain-specific training
- Evidence anchors:
  - [section] "Using obtained {(Cs, Ct1), ...,(Cs, Ctk)} pairs from the retrieval model, each pair is verbalized as text and replaced in the prompt template to input LLMs. Subsequently, employing the LLM prompting technique [27], inputs are categorized into 'yes' and 'no' classes using label words such as yes/true/right for the 'yes' class and no/false/wrong for the 'no' class"
  - [abstract] "enhanced by zero-shot prompting across three ontology representations"

## Foundational Learning

- Concept: Ontology matching and alignment
  - Why needed here: The entire framework is designed to solve the problem of aligning concepts between different ontologies, so understanding what ontologies are and how matching works is fundamental
  - Quick check question: What is the formal definition of the ontology matching task as described in the paper?

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: The framework uses RAG as its core architectural approach, combining retrieval with LLM generation to overcome context limitations
  - Quick check question: How does the retrieval module in LLMs4OM differ from traditional RAG approaches in terms of candidate selection for ontology matching?

- Concept: Zero-shot prompting and label words
  - Why needed here: The LLM module uses zero-shot prompting with specific label words to classify concept pairs without fine-tuning
  - Quick check question: What are the label words used in the prompt template and how are they used to derive confidence scores?

## Architecture Onboarding

- Component map: Concept Representation -> Retriever Model -> LLM -> Post-processing
- Critical path: For each concept in the source ontology: 1) Generate C, CP, CC representations, 2) Use retriever to find top-k candidates from target ontology, 3) Format pairs into prompt template, 4) Send to LLM for classification, 5) Apply post-processing to finalize matches
- Design tradeoffs: The framework trades off between retrieval recall (higher top-k values) and computational efficiency, between different concept representations for accuracy vs. simplicity, and between using general vs. domain-specific LLMs for different ontology domains
- Failure signatures: Low recall in retrieval module (insufficient candidates for LLM to evaluate), LLM consistently outputting "no" (concept representations may be too sparse or retrieval candidates too poor), high variance in performance across different ontology tracks (architecture may not generalize well across domains)
- First 3 experiments:
  1. Run the framework with a simple ontology pair (like Anatomy track) using all three concept representations to verify basic functionality
  2. Compare performance of different retrievers (TFIDF vs. sentence-BERT vs. text-embedding-ada) on a medium-complexity dataset to identify the best retrieval approach
  3. Test the impact of top-k parameter on overall performance by running the same dataset with k=5, k=10, and k=20 to find the optimal tradeoff between recall and efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of retrieval model impact the overall performance of LLM-based ontology matching across different domains?
- Basis in paper: [explicit] The paper evaluates four retrieval models (TFIDF, sentence-BERT, SPECTER2, and OpenAI text-embedding-ada) and discusses their performance across different ontology matching tracks
- Why unresolved: The paper shows that the best retrieval model varies by track, but does not provide a comprehensive analysis of why certain models perform better in specific domains or how to select the optimal retrieval model for a given ontology matching task
- What evidence would resolve it: A detailed study comparing retrieval model performance across a wider range of ontology domains, along with an analysis of the characteristics of ontologies that make certain retrieval models more suitable

### Open Question 2
- Question: How do different concept representations (concept, concept-parent, concept-children) affect the performance of LLMs in ontology matching tasks?
- Basis in paper: [explicit] The paper evaluates three concept representations and finds that the best representation varies across tasks, with the concept representation generally performing best, but the inclusion of parent or children information sometimes improving results
- Why unresolved: The paper does not provide a clear explanation for why certain representations work better in specific scenarios or how to determine the optimal representation for a given ontology matching task
- What evidence would resolve it: A comprehensive analysis of the impact of concept representations on LLM performance across various ontology domains, along with guidelines for selecting the most appropriate representation based on the characteristics of the ontologies being matched

### Open Question 3
- Question: How can LLM-based ontology matching systems be improved to handle complex biomedical ontologies more effectively?
- Basis in paper: [explicit] The paper notes that the LLM-based system performed poorly on biomedical ontology matching tasks, even when using a domain-specific LLM (BioMistral-7B)
- Why unresolved: The paper does not provide insights into why the LLM-based system struggled with biomedical ontologies or propose potential solutions to improve performance in this domain
- What evidence would resolve it: A detailed investigation of the challenges specific to biomedical ontology matching, along with proposed methods or adaptations to LLM-based systems that could improve their performance in this domain

## Limitations

- The framework's performance heavily depends on the quality of the retrieval module, with an 82-87% recall rate that could leave significant gaps in matching coverage
- Zero-shot prompting approach may struggle with highly specialized ontology domains where general LLMs lack sufficient domain knowledge
- The framework assumes ontologies have sufficient lexical similarity and hierarchical structure to enable effective retrieval and context-based matching

## Confidence

- **High Confidence**: The dual-module architecture effectively addresses LLM context limitations and reduces hallucination (supported by consistent performance improvements over baseline systems)
- **Medium Confidence**: Different concept representations improve matching accuracy through hierarchical context (supported by experimental results across multiple tracks, but mechanism could vary by domain)
- **Medium Confidence**: Zero-shot prompting can match or surpass traditional ontology matching systems (supported by competitive results on OAEI benchmarks, but domain-specific adaptation may be needed)

## Next Checks

1. Test the framework on ontology pairs with minimal lexical overlap to evaluate retrieval module robustness under challenging conditions
2. Compare performance using domain-specific vs. general LLMs on technical ontology tracks to quantify the impact of domain knowledge
3. Analyze the correlation between ontology complexity metrics (number of concepts, depth of hierarchy) and matching accuracy to identify performance boundaries