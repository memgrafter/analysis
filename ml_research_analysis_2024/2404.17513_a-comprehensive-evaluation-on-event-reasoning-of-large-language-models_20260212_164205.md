---
ver: rpa2
title: A Comprehensive Evaluation on Event Reasoning of Large Language Models
arxiv_id: '2404.17513'
source_url: https://arxiv.org/abs/2404.17513
tags:
- event
- reasoning
- schema
- llms
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EV2, a benchmark for comprehensive evaluation
  of event reasoning in LLMs across schema and instance levels, covering diverse relations
  (causality, temporality, hierarchy) and reasoning paradigms (contextual event classification,
  relation reasoning). The benchmark is constructed via GPT-4 generation and human
  annotation, ensuring high quality.
---

# A Comprehensive Evaluation on Event Reasoning of Large Language Models

## Quick Facts
- arXiv ID: 2404.17513
- Source URL: https://arxiv.org/abs/2404.17513
- Authors: Zhengwei Tao; Zhi Jin; Yifan Zhang; Xiancai Chen; Haiyan Zhao; Jia Li; Bing Liang; Chongyang Tao; Qun Liu; Kam-Fai Wong
- Reference count: 23
- Primary result: EV2 benchmark reveals LLMs have basic event reasoning abilities but struggle with schema knowledge utilization and show varying performance across relation types

## Executive Summary
This paper introduces EV2, a comprehensive benchmark for evaluating event reasoning capabilities in large language models across schema and instance levels. The benchmark covers six relation types (causality, temporality, hierarchy) and two reasoning paradigms (contextual event classification, relation reasoning), constructed through GPT-4 generation and human annotation. Experiments on 11 LLMs reveal that while models possess basic event reasoning abilities, performance is far from satisfactory and varies significantly across relations and paradigms. The study also demonstrates that explicit guidance on using schema knowledge as memory can improve reasoning performance.

## Method Summary
The EV2 benchmark is constructed through a multi-stage pipeline involving GPT-4 prompt generation, manual filtering, human annotation, question adaptation, and quality inspection. The evaluation framework tests LLMs on both schema-level and instance-level reasoning tasks across six relation types using contextual event classification (CEC) and contextualized relation reasoning (CRR) paradigms. The study evaluates 11 LLMs including GPT-4 variants, open-source models (Mistral-7B, Qwen2-7B, etc.), and closed-source models via API, using direct evaluation without fine-tuning. Performance metrics include accuracy on multiple-choice tasks with human evaluation showing 91% correctness and 92% contextualization.

## Key Results
- LLMs demonstrate basic event reasoning abilities but performance is far from satisfactory across all relation types
- Models show uneven performance, performing better on causal reasoning compared to temporal reasoning
- LLMs possess event schema knowledge but struggle to leverage it effectively like humans do
- Explicit schema knowledge guidance significantly improves event reasoning performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Event reasoning requires both schema-level knowledge and instance-level processing to handle the diversity of inter-event relations and reasoning paradigms.
- Mechanism: The EV2 benchmark explicitly evaluates LLMs on two levels (schema and instance) across six relation types (Causality, Temporality, Hierarchy) and two reasoning paradigms (Contextual Event Classification, Contextualized Relation Reasoning). This comprehensive coverage reveals gaps in LLM abilities that single-dimension evaluations miss.
- Core assumption: Event reasoning performance varies significantly across relation types and reasoning paradigms, and this variation can only be detected through comprehensive multi-dimensional evaluation.
- Evidence anchors:
  - [abstract] "We introduce a novel benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of evaluation of schema and instance and is comprehensive in relations and reasoning paradigms."
  - [section 2] "EV2 consists of two event reasoning paradigms for both levels of schema and instance."
  - [corpus] Weak evidence - corpus shows related work on event reasoning but doesn't provide direct evidence for this specific multi-dimensional evaluation approach.
- Break condition: If LLM performance becomes uniformly high across all relations and paradigms, or if schema-level and instance-level performances become indistinguishable.

### Mechanism 2
- Claim: LLMs possess event schema knowledge but are not aligned with humans in how they leverage this knowledge for event reasoning.
- Mechanism: The evaluation methodology includes testing schema-level reasoning directly, then testing whether LLMs can generate required schema knowledge when prompted with instance-level questions. The gap between direct schema-level performance and schema knowledge generation reveals misalignment.
- Core assumption: Schema-level performance reflects stored knowledge, while schema knowledge generation reflects reasoning strategy alignment.
- Evidence anchors:
  - [abstract] "Besides, LLMs have event schema knowledge, however, they're not aligned with humans on how to utilize the knowledge."
  - [section 5.3] "However, we find rest models all fail to generate corresponding schema knowledge."
  - [corpus] Weak evidence - corpus mentions knowledge graph construction but doesn't provide direct evidence for schema knowledge generation alignment.
- Break condition: If LLMs consistently generate correct schema knowledge when prompted, or if direct schema-level performance becomes uniformly high.

### Mechanism 3
- Claim: Explicit guidance on using schema knowledge as memory improves event reasoning performance.
- Mechanism: By adding schema event types and relations directly into prompts for instance-level tasks, the evaluation shows performance improvements, suggesting that schema knowledge can serve as effective memory for reasoning tasks.
- Core assumption: Schema knowledge provides structural context that improves instance-level reasoning when explicitly provided.
- Evidence anchors:
  - [abstract] "Based on these findings, we guide the LLMs in utilizing the event schema knowledge as memory leading to improvements on event reasoning."
  - [section 5.4] "We demonstrate the performances of this guidance in Table 6 and 7. We find incorporating event schema knowledge significantly improves event reasoning."
  - [corpus] Weak evidence - corpus shows related work on knowledge graph construction but doesn't provide direct evidence for schema knowledge as memory.
- Break condition: If performance improvements from schema guidance become negligible, or if schema guidance introduces more errors than benefits.

## Foundational Learning

- Concept: Event schema knowledge
  - Why needed here: Schema knowledge provides the abstract framework (event types and their relations) that underlies specific event instances and enables global reasoning about event evolution.
  - Quick check question: What is the difference between an event type and an event instance in the context of schema knowledge?

- Concept: Inter-event relations (causality, temporality, hierarchy)
  - Why needed here: Different relation types require different reasoning strategies, and LLM performance varies significantly across these relation types, revealing strengths and weaknesses in reasoning capabilities.
  - Quick check question: How would you distinguish between a causal relation and a temporal relation between two events?

- Concept: Reasoning paradigms (classification vs. relation reasoning)
  - Why needed here: Different paradigms test different aspects of reasoning ability - classification tests understanding of event semantics and structure, while relation reasoning tests understanding of connections between events.
  - Quick check question: What's the fundamental difference between answering "Which event follows this one?" versus "What's the relationship between these two events?"

## Architecture Onboarding

- Component map: Prompt generation -> Manual filtering -> Annotation -> Question adaptation -> Quality inspection -> Schema-level CEC/CRR + Instance-level CEC/CRR across six relation types -> Performance analysis -> Insight generation
- Critical path: Prompt generation → Annotation → Question adaptation → Model evaluation → Performance analysis → Insight generation
- Design tradeoffs: Comprehensive evaluation vs. annotation cost, multiple relation types vs. dataset size, schema-level vs. instance-level balance
- Failure signatures: Poor performance across all relations indicates fundamental reasoning limitations; uneven performance suggests specific weaknesses; schema knowledge gaps indicate alignment issues
- First 3 experiments:
  1. Evaluate a baseline model on all EV2 tasks to establish performance baselines across relations and paradigms
  2. Test schema knowledge generation capability by prompting models to output required schema for instance-level questions
  3. Apply schema knowledge guidance to instance-level tasks and measure performance improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can explicit event schema knowledge guidance be further optimized to improve LLM performance on event reasoning tasks beyond the current implementation?
- Basis in paper: [explicit] The paper finds that LLMs improve when given explicit event schema knowledge guidance, suggesting potential for further enhancements.
- Why unresolved: The current study only tests a basic implementation of schema knowledge guidance. More sophisticated methods of integrating schema knowledge, such as dynamic retrieval or attention mechanisms, were not explored.
- What evidence would resolve it: Experiments comparing different schema knowledge integration techniques (e.g., retrieval-augmented generation, schema-based prompt engineering) and their impact on various event reasoning tasks and LLM models.

### Open Question 2
- Question: How does the imbalance in LLM performance across different event relations (e.g., causality vs. temporality) relate to the underlying training data distribution and what targeted interventions could address this?
- Basis in paper: [explicit] The paper observes that LLMs perform better on causal reasoning compared to temporal reasoning, indicating an imbalance in training.
- Why unresolved: The paper identifies the imbalance but does not investigate its root causes in training data or explore specific methods to balance performance across relations.
- What evidence would resolve it: Analysis of training datasets to quantify relation-specific representation, experiments with relation-balanced pretraining or fine-tuning, and ablation studies on relation-specific performance improvements.

### Open Question 3
- Question: To what extent does the performance gap between schema-level and instance-level event reasoning reflect fundamental limitations in LLM knowledge representation versus architectural constraints?
- Basis in paper: [inferred] The paper notes that LLMs' schema-level reasoning abilities lag behind instance-level, suggesting potential representational or architectural limitations.
- Why unresolved: The study identifies the gap but does not distinguish whether it stems from how LLMs represent abstract knowledge versus specific instances, or from architectural limitations in handling different abstraction levels.
- What evidence would resolve it: Comparative studies of LLM architectures on schema vs. instance tasks, analysis of internal representations using probing techniques, and experiments with models specifically designed to handle abstract knowledge.

## Limitations
- Benchmark construction relies on GPT-4 for initial question generation, potentially introducing bias toward more capable models
- Evaluation covers only 11 LLMs, which may not fully represent the current landscape of event reasoning capabilities
- Focus on English language events limits generalizability to other languages and cultures

## Confidence

- Comprehensive evaluation approach: High
- LLMs possess schema knowledge but misaligned utilization: Medium
- Schema knowledge guidance effectiveness: Medium

## Next Checks

1. Evaluate additional contemporary LLMs (especially newer versions of existing models and emerging competitors) to verify if performance patterns hold across a broader model spectrum.
2. Conduct ablation studies removing human annotations from the benchmark construction process to quantify their impact on evaluation quality and reliability.
3. Test cross-lingual generalization by adapting EV2 to other languages and evaluating whether the observed performance patterns and schema knowledge utilization issues persist across linguistic contexts.