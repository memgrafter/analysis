---
ver: rpa2
title: 'JaxLife: An Open-Ended Agentic Simulator'
arxiv_id: '2409.00853'
source_url: https://arxiv.org/abs/2409.00853
tags:
- agents
- robots
- terrain
- energy
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces JaxLife, a novel artificial life simulator
  designed to study the emergence of intelligent behavior through open-ended evolution.
  The key idea is to evolve agents capable of accumulating culture and technology
  across generations by interacting with programmable robots in a rich, expressive
  environment.
---

# JaxLife: An Open-Ended Agentic Simulator

## Quick Facts
- arXiv ID: 2409.00853
- Source URL: https://arxiv.org/abs/2409.00853
- Authors: Chris Lu; Michael Beukman; Michael Matthews; Jakob Foerster
- Reference count: 13
- One-line primary result: Novel artificial life simulator that evolves agents capable of accumulating culture and technology through interaction with programmable robots.

## Executive Summary
JaxLife is a new artificial life simulator designed to study the emergence of intelligent behavior through open-ended evolution. The system features embodied agents parameterized by deep neural networks, a programmable terrain, and Turing-complete robots that agents can control as tools. Through natural selection, agents evolve to perform increasingly complex behaviors including rudimentary agriculture, tool use, and communication. The simulation demonstrates how programmable robots enable open-ended tool use and how population size affects the emergence of complex collective dynamics.

## Method Summary
The simulation uses JAX to implement a multi-agent environment where neural network-controlled agents evolve through natural selection based on energy acquisition. Agents have LSTM-based neural networks with attention mechanisms to process environmental observations and communicate with other agents. The terrain is a 2D grid with energy, fertility, and information bits that agents can modify. Programmable robots provide Turing-complete computational capability through an instruction set including COPY, NOOP, PRODUCT, FMA, XOR, NAND, and LOOKUP operations. Agents reproduce asexually with weight perturbations, and evolution favors those who can acquire energy and terraform effectively.

## Key Results
- Evolved agents demonstrate rudimentary agriculture, tool use, and communication protocols
- Robots are shown to be Turing-complete by implementing Rule 110 cellular automaton
- Complexity metrics (energy usage, terraforming, communication saliency) scale with population size
- Agents can accumulate culture and technology across generations through robot interaction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Agents evolve to perform open-ended tool use because the programmable robots provide Turing-complete computational capability.
- Mechanism: Robots can be reprogrammed by agents via message passing, enabling agents to implement any desired function. This allows agents to leverage external computation to solve survival challenges.
- Core assumption: Agents have sufficient exploration and selection pressure to discover useful robot programs over evolutionary time.
- Evidence anchors:
  - [abstract] "agents can accumulate open-ended culture and technologies across generations by interacting with programmable robots"
  - [section] "we show that these robots can be programmed as useful tools and express meaningful Turing-complete dynamics"
  - [corpus] Weak evidence - no direct citations to related ALife work on programmable robots
- Break condition: If selection pressure is too weak or if robot programs are too complex for agents to discover through evolution.

### Mechanism 2
- Claim: Emergent communication arises because agents can send and receive messages that influence each other's actions.
- Mechanism: Agents have two message channels (self and other messages) that can be observed by nearby agents. The network architecture includes cross-attention over other agents' messages, creating pressure for communication to emerge as a useful strategy.
- Core assumption: The communication channels are integrated into the agent's decision-making process in a way that rewards coordination.
- Evidence anchors:
  - [abstract] "rudimentary communication protocols" emerge
  - [section] "agents can communicate with themselves and others" through self and other message types
  - [section] "we find that, over time, agent behaviors tend to be more sensitive to their communication channels"
  - [corpus] Weak evidence - no citations to communication emergence in ALife simulations
- Break condition: If the message encoding/decoding is too difficult for evolved agents to learn, or if the communication channels provide no survival advantage.

### Mechanism 3
- Claim: Complex emergent behaviors scale with population size because larger populations enable more sophisticated collective dynamics.
- Mechanism: The simulation shows that metrics like energy usage, terraforming complexity, and communication saliency increase with the number of agents, suggesting that larger populations enable more complex emergent behaviors.
- Core assumption: The environment provides sufficient resources and constraints to prevent collapse even as population grows.
- Evidence anchors:
  - [section] "we observe how these results change with scaling the number of agents in the environment"
  - [section] "In most cases, except if there are only 32 agents, the agents quickly learn to perform the eat action almost constantly"
  - [section] "we note that there are differences in behavior and metrics as we increase the number of agents"
  - [corpus] Weak evidence - no citations to scaling laws in ALife or agent-based models
- Break condition: If resource constraints prevent population growth, or if too many agents create chaotic dynamics that prevent coordination.

## Foundational Learning

- Concept: Turing completeness and computational universality
  - Why needed here: The paper claims the robots are Turing-complete and can implement Rule 110 cellular automaton, which is central to understanding the simulation's expressive power
  - Quick check question: What makes Rule 110 a suitable demonstration of Turing completeness?

- Concept: Agent-based modeling and evolutionary computation
  - Why needed here: The simulation uses natural selection to evolve agent behaviors, requiring understanding of how evolutionary pressure shapes emergent properties
  - Quick check question: How does the energy-based survival mechanism create selection pressure for specific agent behaviors?

- Concept: Neural network architectures for multi-agent systems
  - Why needed here: Agents use LSTMs with self-attention and cross-attention over other agents, requiring understanding of how these components enable communication and coordination
  - Quick check question: What role does the cross-attention mechanism play in enabling agent communication?

## Architecture Onboarding

- Component map:
  - Terrain grid with energy, fertility, and information bits
  - Neural network-controlled agents with LSTM memory and attention mechanisms
  - Programmable robots with instruction sets (COPY, NOOP, PRODUCT, FMA, XOR, NAND, LOOKUP)
  - Evolution system with asexual reproduction and weight perturbation
  - Energy-based survival and selection mechanism

- Critical path: Agents → Observe environment → Compute actions → Interact with terrain/robots → Receive energy → Reproduce or die → Evolution

- Design tradeoffs:
  - Higher terrain resolution enables more complex spatial patterns but increases computational cost
  - More robot instructions enable more complex tool use but make program discovery harder for agents
  - Larger population sizes enable more complex emergent behaviors but require more compute

- Failure signatures:
  - Agents fail to reproduce → Insufficient energy acquisition or terraforming capability
  - Robots never get programmed → Agents cannot discover useful programs or lack motivation to use robots
  - Population dies out → Selection pressure too strong or resource constraints too tight

- First 3 experiments:
  1. Run with minimal agents (32) and bots (8) to verify basic survival mechanics work
  2. Add robots with simple pre-programmed behaviors to test agent-robot interaction
  3. Scale to moderate population (128 agents, 32 bots) to observe initial emergence patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific features or hyperparameters of the simulation most strongly influence the emergence of complex behaviors like tool use and communication?
- Basis in paper: [explicit] The authors note that "simulation results can vary wildly when changing the initial conditions" and suggest investigating "effects of different initial settings" as future work.
- Why unresolved: The paper only provides initial scaling results with varying numbers of agents but doesn't systematically explore how different features (terrain parameters, robot instructions, etc.) affect emergent complexity.
- What evidence would resolve it: Systematic ablation studies varying different simulation parameters and measuring their effects on emergent behaviors and complexity metrics.

### Open Question 2
- Question: Can JaxLife evolve agents capable of mathematical reasoning or symbolic manipulation beyond simple Rule 110 computation?
- Basis in paper: [inferred] The authors suggest JaxLife could be used to explore "the evolution of mathematics" and note that robots can compute "arbitrary boolean functions," but current results only show rudimentary behaviors.
- Why unresolved: The current implementation shows basic emergent behaviors but hasn't demonstrated evolution of more advanced cognitive capabilities that would be needed for mathematical reasoning.
- What evidence would resolve it: Demonstrations of evolved agents performing symbolic operations, solving mathematical problems, or creating novel computational structures beyond Rule 110.

### Open Question 3
- Question: What is the relationship between population size, compute resources, and the emergence of increasingly complex cultural behaviors over extended time periods?
- Basis in paper: [explicit] The authors investigate "how complexity scales with the amount of compute used" and note differences in behavior as population size increases, but only run for 216 timesteps.
- Why unresolved: The scaling experiments are limited to a fixed, relatively short time horizon, making it unclear how behaviors would continue to evolve with more compute time or larger populations.
- What evidence would resolve it: Long-term experiments (thousands of timesteps) with varying population sizes showing whether complexity continues to increase or plateaus at certain thresholds.

## Limitations
- Evidence for Turing-completeness relies primarily on Rule 110 implementation without rigorous formal verification
- Emergent communication and agriculture claims lack statistical validation and control experiments
- No comparative analysis with existing ALife simulations or benchmarks

## Confidence

- High confidence in the simulator architecture and implementation details
- Medium confidence in the emergence of basic agent behaviors (energy acquisition, movement)
- Low confidence in claims about complex emergent phenomena (communication protocols, agriculture) without additional validation

## Next Checks

1. Run controlled experiments with varying robot instruction set complexity to measure impact on agent learning and tool use emergence
2. Implement statistical significance testing for scaling behavior claims by running multiple simulation instances with different random seeds
3. Compare emergent behavior metrics against baseline simulations without robots to quantify the contribution of programmable tools to cultural evolution