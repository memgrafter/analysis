---
ver: rpa2
title: Evidence-Enhanced Triplet Generation Framework for Hallucination Alleviation
  in Generative Question Answering
arxiv_id: '2408.15037'
source_url: https://arxiv.org/abs/2408.15037
tags:
- evidence
- question
- answer
- document
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of hallucination in generative
  question answering (GQA), where models generate answers inconsistent with the document.
  The proposed EATQA framework enhances the logical reasoning between question, evidence,
  and answer by predicting all combinations of the (Question, Evidence, Answer) triplet
  through flipping the source pair and target label.
---

# Evidence-Enhanced Triplet Generation Framework for Hallucination Alleviation in Generative Question Answering

## Quick Facts
- arXiv ID: 2408.15037
- Source URL: https://arxiv.org/abs/2408.15037
- Reference count: 9
- This paper addresses hallucination in generative question answering by proposing EATQA, a unified triplet generation framework that outperforms existing methods on MultiRC and QASPER benchmarks.

## Executive Summary
This paper addresses the critical problem of hallucination in generative question answering (GQA), where models generate answers inconsistent with source documents. The authors propose EATQA, a unified triplet generation framework that enhances logical reasoning between questions, evidence, and answers by training the model to predict all combinations of the (Question, Evidence, Answer) triplet through flipping source pairs and target labels. EATQA consists of three instruction tuning tasks: answer-aware evidence retrieval, evidence-enhanced query answering, and evidence-aware query restoration. Experiments on MultiRC and QASPER datasets show significant improvements over existing LLM-based methods and hallucination mitigation approaches, with EATQA achieving state-of-the-art results while preserving the LLM's prior knowledge.

## Method Summary
EATQA is a unified triplet generation framework that addresses hallucination in generative question answering through three instruction tuning tasks: answer-aware evidence generation (QA→E), evidence-enhanced question answering (QE→A), and evidence-aware question restoration (EA→Q). The framework trains the model to predict all combinations of the (Question, Evidence, Answer) triplet by flipping source pairs and target labels, forcing the model to understand logical relationships among the three components. A distribution bridging technique using KL divergence distills knowledge from evidence during inference when evidence sentences cannot be derived. The method uses LoRA adapters with only ~4.5M trainable parameters (0.06% of total) to preserve the LLM's prior knowledge while adding new capabilities. The three objectives are combined with weighted hyperparameters α1, α2, and α3 in the loss function LTriplet = α1LQAE + α2LQEA + α3LEAQ.

## Key Results
- EATQA achieves state-of-the-art performance on MultiRC and QASPER datasets, outperforming other LLM-based methods and hallucination mitigation approaches
- Significant improvements in Exact Match (EM) and F1 scores compared to baseline models including RAG, CAD, and RHO
- The framework effectively mitigates hallucination while generating faithful answers that are consistent with source documents
- EATQA preserves LLM's prior knowledge through efficient fine-tuning with adapter tokens, using only 0.06% of parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EATQA's unified triplet generation framework improves logical reasoning between question, evidence, and answer by training the model to predict all combinations of the triplet through flipping the source pair and target label.
- Mechanism: The framework includes three instruction tuning tasks: answer-aware evidence retrieval (QA->E), evidence-enhanced query answering (QE->A), and evidence-aware query restoration (EA->Q). This multi-task approach forces the model to understand the logical relationships among the three components, simultaneously improving evidence generation and query answering.
- Core assumption: The correct evidence contains sufficient information to reconstruct the original question, and the reconstruction accuracy reflects the correctness of the evidence.
- Evidence anchors:
  - [abstract]: "predicting all combinations of the (Question, Evidence, Answer) triplet by flipping the source pair and target label to understand their logical relationships"
  - [section]: "The evidence is utilized to reconstruct the question to ensure the model captures its logical relations to question and answer instead of superficial relevance"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism
- Break condition: If the evidence doesn't contain enough information to reconstruct the question, or if the model relies on superficial relevance rather than logical relationships, the framework would fail to improve reasoning.

### Mechanism 2
- Claim: The distribution bridging technique distills knowledge from evidence during inference when evidence sentences can't be derived.
- Mechanism: By minimizing the KL divergence between question answering with and without evidence (KL(P(a,q)||q(a|e,q))), the model learns to resort to the original document for answers when provided evidence is incomplete or misleading. This narrows the gap between training and inference.
- Core assumption: The distribution of answers with evidence should be similar to the distribution of answers without evidence when the evidence is correct.
- Evidence anchors:
  - [section]: "the second term KL(P (a, q)||q(a|e, q)), named as 'distribution bridging', narrows down the gap between training and inference"
  - [abstract]: "Furthermore, we bridge the distribution gap to distill the knowledge from evidence in inference stage"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism
- Break condition: If the evidence distribution is significantly different from the document distribution, or if the model over-relies on evidence even when it's misleading, the bridging technique would fail.

### Mechanism 3
- Claim: The unified framework preserves LLM's prior knowledge while mitigating hallucination and generating faithful answers.
- Mechanism: By using only a few additional trainable parameters (adapter tokens) and freezing the pretrained model weights, EATQA effectively preserves the LLM's prior knowledge and causal reasoning ability. The framework's multi-task approach ensures the model learns logical relationships without overfitting to specific evidence patterns.
- Core assumption: The LLM's prior knowledge is valuable for question answering and should be preserved while improving evidence reasoning.
- Evidence anchors:
  - [section]: "we additionally adopt several trainable adapter tokens... With such a few trainable parameters, EATQA effectively preserves LLMs' prior knowledge"
  - [abstract]: "Further analysis shows that our method not only keeps prior knowledge within LLM, but also mitigates hallucination and generates faithful answers"
  - [corpus]: Weak - no direct corpus evidence found for this specific mechanism
- Break condition: If the additional parameters are too large and cause catastrophic forgetting, or if the model's prior knowledge conflicts with evidence reasoning, the framework would fail to preserve knowledge while improving performance.

## Foundational Learning

- Concept: Bayesian formulation of probability relationships between question, evidence, and answer
  - Why needed here: Understanding that PM(a|q,e,d) is proportional to PM(e|a,d) and PM(q|e,a,d) explains why improving evidence generation and query restoration should improve question answering
  - Quick check question: Why does the paper assume PM(q|e,a) = PM(q|e,a,d) when showing the relationship between query restoration and question answering?

- Concept: Kullback-Leibler divergence and its role in distribution bridging
  - Why needed here: KL divergence measures the difference between the probability distributions of answers with and without evidence, which is crucial for understanding how the framework narrows the training-inference gap
  - Quick check question: How does minimizing KL(P(a,q)||q(a|e,q)) help the model handle incomplete or misleading evidence during inference?

- Concept: Adapter-based fine-tuning and parameter efficiency
  - Why needed here: Understanding why only 0.06% of parameters are trainable helps explain how EATQA preserves LLM's prior knowledge while adding new capabilities
  - Quick check question: Why does using adapter tokens instead of full fine-tuning help preserve the LLM's causal reasoning ability?

## Architecture Onboarding

- Component map: EATQA consists of three main components - Answer-aware Evidence Generation (QA->E), Evidence-Enhanced Question Answering (QE->A), and Evidence-Aware Question Restoration (EA->Q). Each component has its own instruction template and loss function, but they share the same LLM backbone with adapter tokens.
- Critical path: The critical path for question answering is QA->E followed by QE->A, as evidence must be generated before it can be used for answering. However, all three components are trained jointly, so the model learns to balance attention between evidence generation, query restoration, and answer generation.
- Design tradeoffs: Using a unified framework trades off some specialization for better generalization. The framework could potentially be less effective than a specialized evidence retriever, but it avoids the intrinsic discrepancy between retriever and LLM.
- Failure signatures: If the model generates irrelevant evidence, fails to reconstruct the question accurately, or produces answers inconsistent with the document, it indicates the framework isn't learning the logical relationships properly.
- First 3 experiments:
  1. Test the QA->E component in isolation by providing question-answer pairs and checking if the generated evidence supports the answer
  2. Test the EA->Q component by providing evidence-answer pairs and checking if the reconstructed question matches the original
  3. Test the complete pipeline on a small dataset to verify that improving evidence generation and query restoration leads to better question answering performance

## Open Questions the Paper Calls Out
None

## Limitations
- The paper lacks detailed specifications for critical hyperparameters, particularly the values of α1, α2, and α3 used in the weighted objective function LTriplet, making faithful reproduction challenging
- Evaluation primarily focuses on two datasets (MultiRC and QASPER), which may not fully represent the diversity of real-world question answering scenarios
- The claim that EATQA preserves LLM prior knowledge is based on qualitative observations rather than quantitative measurements

## Confidence
- **High confidence**: The core mechanism of unified triplet generation through flipping source pairs and target labels is well-explained and logically sound. The three-task framework (QA->E, QE->A, EA->Q) is clearly specified with defined instruction templates.
- **Medium confidence**: The distribution bridging technique using KL divergence is theoretically justified, but the paper provides limited empirical evidence of its effectiveness. The claim that this technique helps the model handle incomplete or misleading evidence needs further validation.
- **Medium confidence**: The claim of state-of-the-art performance is supported by experimental results, but the comparison with other methods could be more comprehensive. The paper doesn't explore the performance gap when removing the distribution bridging component.

## Next Checks
1. **Ablation study of distribution bridging**: Remove the KL divergence component and evaluate the model's performance on handling incomplete or misleading evidence. This would quantify the actual contribution of the distribution bridging technique to hallucination mitigation.

2. **Cross-dataset generalization test**: Evaluate EATQA on additional datasets with different characteristics (e.g., Natural Questions, HotpotQA) to assess its generalization capabilities beyond MultiRC and QASPER. This would reveal whether the framework's effectiveness is limited to specific dataset properties.

3. **Parameter sensitivity analysis**: Systematically vary the hyperparameters α1, α2, and α3 in the weighted objective function and evaluate the impact on performance. This would help understand the importance of each component and identify optimal configurations for different dataset characteristics.