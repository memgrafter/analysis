---
ver: rpa2
title: 'LoRA vs Full Fine-tuning: An Illusion of Equivalence'
arxiv_id: '2410.21228'
source_url: https://arxiv.org/abs/2410.21228
tags:
- intruder
- lora
- dimensions
- fine-tuning
- singular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper investigates whether Low-Rank Adaptation (LoRA) and\
  \ full fine-tuning of large language models produce equivalent solutions. Using\
  \ spectral analysis of weight matrices, the authors find that LoRA introduces \"\
  intruder dimensions\"\u2014high-ranking singular vectors dissimilar to pre-trained\
  \ weights\u2014while full fine-tuning preserves the original spectral structure."
---

# LoRA vs Full Fine-tuning: An Illusion of Equivalence

## Quick Facts
- **arXiv ID**: 2410.21228
- **Source URL**: https://arxiv.org/abs/2410.21228
- **Reference count**: 40
- **Primary result**: LoRA introduces "intruder dimensions" - high-ranking singular vectors dissimilar to pre-trained weights - that cause increased forgetting and worse continual learning performance compared to full fine-tuning

## Executive Summary
This paper investigates whether Low-Rank Adaptation (LoRA) and full fine-tuning of large language models produce equivalent solutions. Using spectral analysis of weight matrices, the authors find that LoRA introduces "intruder dimensions" - high-ranking singular vectors dissimilar to pre-trained weights - while full fine-tuning preserves the original spectral structure. These intruder dimensions strongly correlate with increased forgetting of pre-training data and accumulate during continual learning, leading to worse performance than full fine-tuning. Experiments across LLaMA2-7B and RoBERTa models on tasks like code, math, and classification confirm these findings.

## Method Summary
The study analyzes spectral properties of weight matrices from models fine-tuned using LoRA versus full fine-tuning. SVD decomposition is used to compare singular vectors and values between pre-trained and fine-tuned weights, identifying "intruder dimensions" as high-ranking singular vectors with low cosine similarity to any pre-trained singular vector. The researchers also perform intervention experiments by scaling down singular values of identified intruder dimensions and measure the impact on pre-training loss (forgetting) and test accuracy. Continual learning experiments involve sequential fine-tuning on multiple tasks to observe intruder dimension accumulation.

## Key Results
- LoRA introduces intruder dimensions - high-ranking singular vectors dissimilar to pre-trained weights - while full fine-tuning preserves pre-trained spectral structure
- Scaling down intruder dimensions significantly reduces forgetting with minimal impact on task performance
- LoRA accumulates intruder dimensions during continual learning, leading to worse performance than full fine-tuning on previously learned tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LoRA introduces high-ranking singular vectors ("intruder dimensions") that are dissimilar to pre-trained singular vectors, while full fine-tuning preserves pre-trained spectral structure.
- **Mechanism**: LoRA decomposes weight updates into low-rank matrices (BA) with rank r, where r ≪ min(m,n). This projection into a low-rank space amplifies differences in spectral properties, introducing new singular vectors not present in pre-trained weights.
- **Core assumption**: The low-rank decomposition in LoRA inherently alters the spectral structure of weight matrices in ways that full fine-tuning does not.
- **Evidence anchors**:
  - [abstract]: "LoRA and full fine-tuning yield weight matrices whose singular value decompositions exhibit very different structure: weight matrices trained with LoRA have new, high-ranking singular vectors, which we call intruder dimensions..."
  - [section 3]: "Singular vectors of models fine-tuned with LoRA appear to have, on average, much lower cosine similarity to pre-trained singular vectors in comparison to full fine-tuning. Interestingly, in LoRA fine-tuned models, we also observe the presence of high ranking singular vectors with very low cosine similarity to any pre-trained singular vector."
  - [corpus]: Weak evidence - no direct mention of intruder dimensions in related work.
- **Break condition**: If the LoRA rank approaches full rank (r ≈ min(m,n)), the spectral structure may converge to full fine-tuning, reducing intruder dimensions.

### Mechanism 2
- **Claim**: Intruder dimensions cause forgetting of pre-training data, while scaling them down improves pre-training performance with minimal impact on task performance.
- **Mechanism**: Intruder dimensions represent task-specific adaptations that interfere with pre-trained language modeling capabilities. Reducing their contribution (scaling down singular values) mitigates this interference.
- **Core assumption**: The scale (singular value) of intruder dimensions is not essential for fine-tuning task performance but is crucial for maintaining pre-training capabilities.
- **Evidence anchors**:
  - [abstract]: "Scaling them down significantly improves modeling of the pre-training distribution with a minimal drop in downstream task performance."
  - [section 5]: "When we scale down the top intruder dimension of each weight matrix, we measure a significant reduction in forgetting (pre-training loss) while incurring a minimal drop in test accuracy."
  - [corpus]: Weak evidence - no direct mention of causal relationship between intruder dimensions and forgetting.
- **Break condition**: If intruder dimensions are not task-specific or do not interfere with pre-training capabilities, scaling them down may not reduce forgetting.

### Mechanism 3
- **Claim**: LoRA accumulates intruder dimensions during continual learning, leading to worse performance than full fine-tuning on previously learned tasks.
- **Mechanism**: Sequential fine-tuning on multiple tasks introduces new intruder dimensions for each task, which accumulate and degrade performance on earlier tasks. Full fine-tuning preserves pre-trained structure better across tasks.
- **Core assumption**: Intruder dimensions are task-specific and their accumulation degrades multi-task performance.
- **Evidence anchors**:
  - [abstract]: "This will be amplified during continual learning because of sequentially fine-tuning, and we show that LoRA models do accumulate intruder dimensions here tend to perform worse in this setting."
  - [section 4]: "We observe that all ranks of LoRA degrade much more rapidly than full fine-tuning... We attribute this divergence from earlier results... to the accumulation of intruder dimensions during continual learning."
  - [corpus]: Weak evidence - no direct mention of intruder dimensions in continual learning context.
- **Break condition**: If LoRA variants can prevent intruder dimension accumulation or if tasks are sufficiently similar, continual learning performance may not degrade.

## Foundational Learning

- **Concept**: Singular Value Decomposition (SVD)
  - Why needed here: SVD is the primary tool for analyzing spectral properties of weight matrices and identifying intruder dimensions.
  - Quick check question: Can you explain how SVD decomposes a matrix into U, Σ, and V^T, and what each component represents?

- **Concept**: Low-Rank Matrix Decomposition
  - Why needed here: LoRA's effectiveness relies on representing weight updates as products of low-rank matrices, which directly relates to intruder dimensions.
  - Quick check question: How does the rank constraint in LoRA (r ≪ min(m,n)) affect the number of trainable parameters compared to full fine-tuning?

- **Concept**: Cosine Similarity in High-Dimensional Spaces
  - Why needed here: Measuring similarity between singular vectors requires understanding how cosine similarity behaves in high dimensions, especially for orthogonal vectors.
  - Quick check question: Why can a vector have low cosine similarity to a set of orthogonal vectors that span a space in high dimensions?

## Architecture Onboarding

- **Component map**: Pre-trained weights → SVD → Fine-tuned weights → SVD → Compare singular vectors and values → Identify intruder dimensions → Intervention (scaling)

- **Critical path**:
  1. Compute SVD of pre-trained and fine-tuned weight matrices
  2. Compare singular vectors using cosine similarity
  3. Identify intruder dimensions (singular vectors with low similarity to all pre-trained vectors)
  4. Analyze correlation between intruder dimensions and forgetting
  5. Intervene by scaling intruder dimension singular values and measure impact

- **Design tradeoffs**:
  - Rank selection (r): Higher rank increases expressivity but also increases computational cost and potential for intruder dimensions
  - Alpha scaling (α): Affects effective rank and convergence behavior, with α=2r generally preferred
  - Similarity threshold (ε): Balances false positives/negatives in intruder dimension detection

- **Failure signatures**:
  - No intruder dimensions detected when expected: May indicate rank is too low or similarity threshold is too high
  - High correlation between intruder dimensions and test accuracy: Suggests intruder dimensions may be beneficial rather than harmful
  - Scaling intruder dimensions has no effect: May indicate incorrect identification or model architecture differences

- **First 3 experiments**:
  1. Replicate SVD analysis on a simple LoRA fine-tuning task to verify intruder dimension detection
  2. Test scaling of identified intruder dimensions and measure impact on forgetting vs. task performance
  3. Compare spectral properties of LoRA variants (PiSSA, LoRA+, etc.) to understand differences in intruder dimension behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LoRA variants be designed to eliminate or minimize intruder dimensions while maintaining task performance?
- Basis in paper: [explicit] The paper shows that several LoRA variants (AdaLoRA, LoRA+, PiSSA, VeRA) still exhibit intruder dimensions, though with varying characteristics.
- Why unresolved: The paper only tests these variants with default hyperparameters and doesn't explore systematic design changes to eliminate intruder dimensions.
- What evidence would resolve it: Experiments showing a LoRA variant that either eliminates intruder dimensions or significantly reduces them while matching full fine-tuning performance on diverse tasks.

### Open Question 2
- Question: What is the causal relationship between intruder dimensions and catastrophic forgetting in continual learning settings?
- Basis in paper: [explicit] The paper demonstrates that LoRA models accumulate intruder dimensions during sequential fine-tuning and perform worse on previously learned tasks compared to full fine-tuning.
- Why unresolved: While the paper shows correlation and intervention experiments, it doesn't establish a complete causal chain from intruder dimensions to forgetting in sequential task learning.
- What evidence would resolve it: Controlled experiments where intruder dimensions are prevented from accumulating during continual learning, showing improved retention of previous tasks.

### Open Question 3
- Question: How does the selection of LoRA hyperparameters (rank, alpha, learning rate) affect the trade-off between task performance and forgetting through intruder dimensions?
- Basis in paper: [explicit] The paper shows that LoRA alpha impacts generalization and intruder dimensions, and that learning rate affects both intruder dimensions and forgetting.
- Why unresolved: The paper demonstrates these relationships exist but doesn't provide a comprehensive framework for optimizing these hyperparameters to balance performance and forgetting.
- What evidence would resolve it: A systematic study mapping hyperparameter combinations to both task performance and forgetting metrics, providing guidelines for practitioners.

## Limitations

- The analysis of intruder dimensions relies on SVD decomposition of specific weight matrices, but the paper does not establish whether these findings generalize across all layers or model architectures.
- The correlation between intruder dimensions and forgetting, while statistically significant, may be influenced by confounding factors such as task similarity or learning rate schedules.
- The intervention of scaling down singular values is post-hoc and may not reflect how models could be trained differently to avoid intruder dimensions in the first place.

## Confidence

**High confidence**: LoRA and full fine-tuning produce different spectral structures in weight matrices, supported by clear SVD analysis and cosine similarity measurements across multiple tasks and models.

**Medium confidence**: Intruder dimensions cause forgetting, as the evidence shows correlation but alternative explanations (e.g., capacity constraints, task interference) are not fully ruled out.

**Low confidence**: LoRA accumulates intruder dimensions during continual learning and performs worse than full fine-tuning, as the continual learning experiments appear limited in scope.

## Next Checks

1. **Layer-wise analysis**: Perform SVD decomposition and intruder dimension detection separately for each layer type (attention, MLP, etc.) to determine if the phenomenon is uniform across the model or concentrated in specific components.

2. **Alternative similarity metrics**: Replicate the analysis using different distance metrics (e.g., angular distance, Frobenius norm) and similarity thresholds to verify that intruder dimensions are not artifacts of the specific cosine similarity threshold chosen.

3. **Training intervention**: Instead of post-hoc scaling, implement LoRA training with explicit spectral regularization that penalizes divergence from pre-trained singular vectors, then compare forgetting and task performance to standard LoRA and full fine-tuning.