---
ver: rpa2
title: Multi-modal Causal Structure Learning and Root Cause Analysis
arxiv_id: '2402.02357'
source_url: https://arxiv.org/abs/2402.02357
tags:
- system
- causal
- root
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of root cause analysis (RCA) in
  complex systems by proposing a multi-modal causal structure learning method. The
  approach, MULAN, integrates system metrics and logs to learn a causal graph that
  identifies the top k system entities most relevant to system performance.
---

# Multi-modal Causal Structure Learning and Root Cause Analysis

## Quick Facts
- arXiv ID: 2402.02357
- Source URL: https://arxiv.org/abs/2402.02357
- Reference count: 40
- Key outcome: Multi-modal RCA method MULAN outperforms single-modal and multi-modal baselines on three real-world datasets, achieving MRR of 1.0 on one dataset.

## Executive Summary
This paper addresses root cause analysis in complex systems by proposing MULAN, a multi-modal causal structure learning method that integrates system metrics and unstructured logs. MULAN uses a log-tailored language model to convert logs into time-series data, employs contrastive learning to extract modality-invariant and modality-specific representations, and introduces a KPI-aware attention mechanism to fuse the final causal graph. The method demonstrates significant improvements over state-of-the-art approaches, particularly when one modality is of lower quality.

## Method Summary
MULAN is a multi-modal causal structure learning method that integrates system metrics and unstructured logs to identify the top k system entities most relevant to system performance. The method consists of four main modules: representation extraction via a log-tailored language model, contrastive multi-modal causal structure learning, causal graph fusion with KPI-aware attention, and network propagation-based root cause localization. MULAN converts unstructured log sequences into time-series data, extracts modality-invariant and modality-specific representations using contrastive learning, assesses modality reliability with KPI-aware attention, and fuses the final causal graph for root cause ranking.

## Key Results
- MULAN outperforms state-of-the-art single-modal and multi-modal RCA approaches on three real-world datasets
- MRR scores reach 1.0 on the Product Review dataset when both modalities are available
- When one modality is low-quality, MULAN's attention mechanism effectively shifts weight to the higher-quality modality, maintaining superior performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The log-tailored language model effectively converts unstructured log sequences into time-series data by treating each log template as a token and incorporating frequency information.
- Mechanism: Log parsing transforms raw logs into structured templates, which are then sequenced by first appearance timestamp. Frequency counts are appended to templates to encode anomaly signal strength. The language model is trained to predict anomaly scores using these sequences, yielding a [CLS] embedding per time window that represents the log's semantic and anomaly state.
- Core assumption: Log templates occurring more frequently within a time window carry higher anomaly signal, and that temporal ordering of first appearance preserves relevant causality.
- Evidence anchors:
  - [abstract] "leveraging a log-tailored language model to facilitate log representation learning, converting log sequences into time-series data"
  - [section] "we treat each event template as a token, and the log templates within a sequence are organized based on their first appearance timestamp in ascending order. This strategy...enables the encoding of semantic information into representations"
  - [corpus] Weak: No corpus papers directly validate the log-template-as-token + frequency approach, but the method aligns with DeepLog-style sequence modeling.
- Break condition: If logs lack clear templates (e.g., free-text logs), the parsing step fails and frequency signal becomes unreliable.

### Mechanism 2
- Claim: Contrastive learning extracts both modality-invariant and modality-specific representations, enabling richer causal structure learning than single-modality or naive multi-modal fusion.
- Mechanism: Two encoders (GraphSage-based) separately process metric and log data to produce invariant and specific representations. Node-level contrastive loss aligns invariant representations across modalities, orthogonal constraint prevents overlap, and edge-level loss ensures invariant representations encode causal topology.
- Core assumption: Modality-invariant features capture shared causal structure, while modality-specific features retain unique signals; mutual information maximization improves alignment without erasing modality-specific cues.
- Evidence anchors:
  - [abstract] "we propose a contrastive learning-based approach to extract modality-invariant and modality-specific representations within a shared latent space"
  - [section] "we propose maximizing the mutual information between these two representations using contrastive learning regularization"
  - [corpus] Weak: No direct corpus evidence; method is novel in RCA context but follows contrastive learning trends in vision/NLP.
- Break condition: If modalities are too dissimilar, contrastive alignment may force misleading invariant features.

### Mechanism 3
- Claim: KPI-aware attention reweights modalities based on their cross-correlation with the KPI, mitigating the impact of low-quality modalities.
- Mechanism: For each modality, compute max cross-correlation over time lags between each entity and the KPI. Sum over top-k entities to get modality importance score. Softmax over these scores yields attention weights that scale invariant representations and adjacency matrices before fusion.
- Core assumption: High-quality modalities show stronger and more consistent correlation between their top-k entities and the KPI; low-quality modalities yield weak correlation.
- Evidence anchors:
  - [abstract] "a novel key performance indicator-aware attention mechanism for assessing modality reliability and co-learning a final causal graph"
  - [section] "we employ ð’”ð’— to measure the importance of each modality" and "we can leverage the modality importance score ð’‚ð’— to replace the hyper-parameter ð›¼"
  - [corpus] Weak: Attention reweighting is common in multimodal learning but KPI-specific formulation is not evidenced in corpus.
- Break condition: If KPI and root causes are temporally misaligned or decorrelated, attention weights become noisy.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) for representation learning on structured data
  - Why needed here: The causal graph is naturally represented as a graph where nodes are system entities and edges encode causal influence; GNNs propagate information across this structure.
  - Quick check question: What is the difference between message passing in GNNs and simple feature concatenation for node embeddings?

- Concept: Vector Autoregression (VAR) models for temporal causal inference
  - Why needed here: VAR models capture lagged dependencies among time series, enabling identification of causal links between system metrics over time.
  - Quick check question: How does a VAR(p) model differ from a simple linear regression when modeling multivariate time series?

- Concept: Contrastive learning and mutual information maximization
  - Why needed here: Contrastive learning aligns representations across modalities without requiring labeled correspondences, improving generalization when modalities differ in format and signal quality.
  - Quick check question: What is the role of the temperature parameter in the InfoNCE contrastive loss?

## Architecture Onboarding

- Component map:
  Log parser (e.g., Drain) -> log templates -> log sequence builder (time windows + frequency tokens) -> Log-tailored language model -> [CLS] embeddings per window -> Two GNN encoders (metric, log) -> invariant + specific representations -> Contrastive + orthogonal + edge losses -> aligned representations -> VAR-based decoders -> future prediction loss -> KPI-aware attention -> modality importance weights -> Graph fusion -> final adjacency matrix -> Random walk with restart -> root cause ranking

- Critical path: Log -> embeddings -> contrastive alignment -> attention weighting -> fused graph -> ranking

- Design tradeoffs:
  - Log parsing vs. end-to-end token learning: Parsing ensures semantic structure but loses fine-grained tokens; end-to-end risks poor semantic capture.
  - Shared vs. separate encoders: Shared reduces parameters but may force modality-specific nuance loss; separate preserves modality traits but increases complexity.
  - Attention vs. equal weighting: Attention adapts to quality but adds hyperparameter tuning; equal weighting is simpler but brittle to noise.

- Failure signatures:
  - Poor log parsing -> empty or noisy sequences -> embeddings meaningless
  - Low mutual information between modalities -> contrastive loss dominates -> invariant features uninformative
  - KPI weakly correlated with root causes -> attention weights near uniform -> low-quality modality influence persists

- First 3 experiments:
  1. Run MULAN on Product Review dataset with both modalities enabled; verify MRR > baseline single-modality results.
  2. Replace high-quality metric with low-quality metric; check that attention weight shifts toward log modality and MRR degrades less than baselines.
  3. Disable contrastive loss (set Î»3=0); measure drop in MRR to quantify benefit of modality-invariant alignment.

## Open Questions the Paper Calls Out
- How does the performance of MULAN compare to other multi-modal methods when dealing with more than two modalities (e.g., system metrics, logs, and traces)?
- How sensitive is MULAN to the choice of log parsing tool (e.g., Drain) used in Phase 1 of the log-tailored language model?
- Can MULAN be effectively adapted for online RCA scenarios where data arrives in a streaming fashion, and how does its performance compare to offline RCA methods in such settings?

## Limitations
- The log-tailored language model's effectiveness depends heavily on the quality of log parsing and template extraction, which is not evaluated for noisy or unstructured logs
- Contrastive learning assumes meaningful overlap between metric and log modalities; in systems where these signals are truly independent, the invariant representations may be forced and misleading
- KPI-aware attention assumes the KPI is a reliable proxy for root cause relevance; if KPI and root causes are decorrelated (e.g., due to delayed effects), attention weights become noisy

## Confidence
- **High**: The overall multi-modal framework design and its superiority over single-modality baselines on benchmark datasets
- **Medium**: The contrastive learning approach for extracting modality-invariant features, as it follows established principles but lacks direct validation in the RCA context
- **Low**: The KPI-aware attention mechanism's ability to reliably assess modality quality, as it depends on strong cross-correlation between entities and KPI

## Next Checks
1. Perform ablation study by disabling KPI-aware attention (using uniform weights) and measure impact on MRR to isolate attention's contribution
2. Test on datasets where metric and log modalities are synthetically decorrelated to assess contrastive learning's robustness to modality independence
3. Evaluate log parsing quality separately by measuring template extraction accuracy and sequence representation coherence before feeding to the language model