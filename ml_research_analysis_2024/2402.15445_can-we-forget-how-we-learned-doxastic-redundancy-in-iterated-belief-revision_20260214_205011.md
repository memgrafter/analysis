---
ver: rpa2
title: Can we forget how we learned? Doxastic redundancy in iterated belief revision
arxiv_id: '2402.15445'
source_url: https://arxiv.org/abs/2402.15445
tags:
- formula
- equivalent
- same
- formulae
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies doxastic redundancy in iterated belief revision,
  specifically the problem of determining when a lexicographic revision can be removed
  from a sequence without changing the resulting doxastic state. The key contribution
  is a necessary and sufficient condition for the redundancy of the first lexicographic
  revision in a sequence, expressed as the equivalence of that revision to a disjunction
  of certain combinations of the other revisions.
---

# Can we forget how we learned? Doxastic redundancy in iterated belief revision

## Quick Facts
- arXiv ID: 2402.15445
- Source URL: https://arxiv.org/abs/2402.15445
- Authors: Paolo Liberatore
- Reference count: 19
- Key outcome: Characterizes when lexicographic revision can be removed from belief revision sequences while preserving the resulting doxastic state

## Executive Summary
This paper addresses the problem of doxastic redundancy in iterated belief revision, specifically when a lexicographic revision in a sequence can be eliminated without changing the resulting belief state. The author establishes necessary and sufficient conditions for redundancy, showing that the first lexicographic revision is redundant if and only if it is equivalent to a disjunction of certain combinations of the other revisions in the sequence. The work provides both theoretical complexity results and a practical SAT-based algorithm for checking redundancy.

## Method Summary
The paper presents a theoretical framework for analyzing doxastic redundancy in iterated belief revision systems. The author develops a characterization of when lexicographic revisions can be removed from revision sequences by expressing redundancy as equivalence to a disjunction of other revisions. The main technical contribution is an algorithm that reduces the redundancy checking problem to propositional satisfiability, leveraging modern SAT solvers. The approach involves constructing a propositional formula whose satisfiability determines whether the redundancy condition holds.

## Key Results
- Doxastic redundancy of the first lexicographic revision is characterized by equivalence to a disjunction of specific combinations of other revisions
- The general redundancy checking problem is proven coNP-complete
- For sequences of two Horn formulae, redundancy checking is solvable in polynomial time
- A SAT-based algorithm is provided that reduces redundancy checking to propositional satisfiability

## Why This Works (Mechanism)
The approach works by leveraging the algebraic structure of belief revision operations and their interaction properties. The redundancy condition captures when the effect of a particular revision can be simulated by the combination of subsequent revisions, allowing its elimination. By reducing this to propositional satisfiability, the method can exploit highly optimized SAT solvers to handle the computational complexity. The Horn restriction is tractable because it limits the search space to a polynomially-solvable subclass.

## Foundational Learning
- Iterated belief revision - Understanding how beliefs evolve through multiple revision steps; needed to model the sequential nature of doxastic updates; quick check: verify the sequence composition property holds
- Lexicographic revision - A specific belief revision operation that maintains priority orderings; needed as the target operation for redundancy analysis; quick check: confirm lexicographic revision satisfies success postulate
- Horn formulae - Conjunctive normal form with at most one positive literal per clause; needed for the tractable subclass; quick check: verify Horn clauses preserve Horn property under conjunction
- Propositional satisfiability - Determining if a logical formula can be satisfied; needed for the reduction approach; quick check: confirm SAT encoding preserves logical equivalence
- Computational complexity (coNP) - Class of problems whose complements are in NP; needed for hardness results; quick check: verify coNP-completeness reduction is sound
- Disjunction of revision combinations - Logical OR of different revision sequences; needed for the redundancy characterization; quick check: confirm disjunction correctly captures alternative paths

## Architecture Onboarding
Component map: Input sequence -> Redundancy check -> SAT encoding -> Solver -> Result
Critical path: Sequence parsing → redundancy condition construction → SAT encoding → solver invocation → result interpretation
Design tradeoffs: Theoretical completeness vs. practical solver efficiency; exact characterization vs. approximate methods
Failure signatures: SAT solver timeouts indicate computational intractability; incorrect results suggest encoding errors
First experiments:
1. Test the algorithm on a sequence of two simple Horn revisions to verify polynomial-time behavior
2. Construct a counterexample where the first revision is not redundant to validate the completeness of the condition
3. Run the SAT-based algorithm on a sequence where redundancy is known to hold to verify soundness

## Open Questions the Paper Calls Out
The paper identifies an open question regarding the boundary between tractability and intractability for Horn revisions. While the paper proves polynomial-time solvability for sequences of length two, it remains unknown whether this extends to sequences of three or more Horn formulae. This represents an interesting complexity gap that could be explored further.

## Limitations
- The tractability boundary for Horn revisions at sequence length two remains unproven for sequences of three or more formulae
- The SAT-based approach introduces implementation-dependent performance variations not fully characterized
- Theoretical complexity results are asymptotic and may not reflect practical performance on moderate-sized problems
- The framework is limited to lexicographic revision operations, excluding other revision types

## Confidence
- Complexity classification results: High
- Polynomial-time algorithm for two Horn formulae: Medium
- SAT-based equivalence checking approach: Medium
- Open questions about Horn tractability boundary: Low

## Next Checks
1. Implement and benchmark the SAT-based algorithm on synthetic Horn revision sequences of length 2-5 to empirically investigate the tractability boundary
2. Construct specific Horn formula examples that test edge cases of the redundancy condition to verify the algorithm's correctness
3. Compare the performance of the SAT-based approach against alternative methods for checking lexicographic revision redundancy on small-scale problems