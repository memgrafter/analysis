---
ver: rpa2
title: Understanding Language Model Circuits through Knowledge Editing
arxiv_id: '2406.17241'
source_url: https://arxiv.org/abs/2406.17241
tags: []
core_contribution: This paper introduces a novel approach to studying the functions
  of automatically-extracted circuits in large language models (LLMs) through the
  lens of knowledge editing. The authors conduct systematic knowledge editing experiments
  on the circuits of the GPT-2 language model, using diverse text classification datasets
  to extract circuits and hierarchical relations datasets for knowledge editing tasks.
---

# Understanding Language Model Circuits through Knowledge Editing

## Quick Facts
- arXiv ID: 2406.17241
- Source URL: https://arxiv.org/abs/2406.17241
- Authors: Huaizhi Ge; Frank Rudzicz; Zining Zhu
- Reference count: 11
- Primary result: Novel approach studying automatically-extracted circuits in LLMs through knowledge editing, revealing entity knowledge resistance and optimal circuit size range

## Executive Summary
This paper introduces a novel approach to studying the functions of automatically-extracted circuits in large language models (LLMs) through knowledge editing. The authors conduct systematic knowledge editing experiments on the circuits of the GPT-2 language model, using diverse text classification datasets to extract circuits and hierarchical relations datasets for knowledge editing tasks. The research reveals that these circuits contain entity knowledge but resist new knowledge more than complementary circuits during editing, and that an ideal "theoretical circuit" for essential knowledge is likely between 5-50% of model parameters.

## Method Summary
The method involves extracting circuits from GPT-2 XL using differentiable masking on diverse text classification datasets, then performing knowledge editing on these circuits using hierarchical relations datasets with fine-tuning. The study analyzes results by comparing pre-edit and post-edit probabilities, examining circuit size effects, measuring overlap between circuits from different datasets, and analyzing layer composition. Key techniques include differentiable masking for circuit extraction and fine-tuning for knowledge editing, with evaluation using negative log probability metrics.

## Key Results
- Circuits contain entity knowledge but resist new knowledge more than complementary circuits during editing
- An ideal "theoretical circuit" for essential knowledge incorporates more than 5% but less than 50% of model parameters
- LayerNorm modules constitute up to 60% of circuit parameters, challenging traditional views on knowledge storage

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Circuits containing entity knowledge resist new knowledge more than complementary circuits during editing.
- Mechanism: Knowledge-rich circuits develop stronger parameter dependencies that are harder to override through fine-tuning, while complementary circuits have fewer such dependencies.
- Core assumption: The "knowledge intensity" of a circuit correlates with the strength of parameter interactions that encode that knowledge.
- Evidence anchors: [abstract] "These findings indicate that these circuits contain entity knowledge but resist new knowledge more than complementary circuits during knowledge editing." [section 5.3] "the complementary 50% circuit consistently outperforms the 50% circuit in terms of editing for both the dna1 and h circuits" [corpus] "Average neighbor FMR=0.472" (moderate similarity suggesting circuits have distinct knowledge profiles)

### Mechanism 2
- Claim: An ideal "theoretical circuit" for essential knowledge is larger than 5% but smaller than 50% of parameters.
- Mechanism: Smaller circuits (<5%) may capture core knowledge but lack robustness, while larger circuits (>50%) include non-essential parameters that dilute editing effectiveness.
- Core assumption: There exists a size threshold where circuits balance knowledge density with functional robustness.
- Evidence anchors: [abstract] "we examine the impact of circuit size, discovering that an ideal 'theoretical circuit' where essential knowledge is concentrated likely incorporates more than 5% but less than 50% of the model's parameters." [section 6] "the 5% circuit, rather than the 50% circuit, may be closer to an idealized 'theoretical circuit' where essential knowledge is concentrated" [corpus] "max_neighbor_fmr": 0.6427 (high FMR for related work suggests this size question is actively researched)

### Mechanism 3
- Claim: LayerNorm modules constitute a disproportionately large share of knowledge-bearing circuits.
- Mechanism: LayerNorm layers provide stability and normalization that enables knowledge storage, while attention and MLP layers perform more dynamic computation.
- Core assumption: Knowledge storage requires stable, normalized representations rather than purely computational layers.
- Evidence anchors: [abstract] "we find that up to 60% of the circuits consist of layer normalization modules rather than attention or MLP modules" [section 8] "LayerNorm constitutes a disproportionately large percentage of the circuit's parameters, especially noticeable within the 5% circuit subset" [corpus] "Average neighbor citations=0.0" (limited direct evidence in corpus, need more research)

## Foundational Learning

- Concept: Circuit extraction through differentiable masking
  - Why needed here: This is the core method for identifying which parameters are critical for specific behaviors
  - Quick check question: What objective function combination encourages both faithfulness and sparsity in circuit extraction?

- Concept: Knowledge editing via fine-tuning
  - Why needed here: The editing experiments require modifying specific knowledge while preserving general capabilities
  - Quick check question: How does parameter masking during fine-tuning ensure only circuit parameters are updated?

- Concept: Negative log probability as edit performance metric
  - Why needed here: This quantifies how well the model adapts to new knowledge targets
  - Quick check question: Why does a lower negative log probability indicate better editing performance?

## Architecture Onboarding

- Component map: GPT-2 XL with 1.5B parameters, consisting of embedding layer, 48 transformer blocks (each with attention, MLP, and LayerNorm), and output projection
- Critical path: Circuit extraction → Model transformation (classification to generation) → Knowledge editing → Performance evaluation
- Design tradeoffs: Larger circuits capture more knowledge but include more noise; smaller circuits are cleaner but may lack robustness
- Failure signatures: Poor editing performance indicates knowledge is stored outside the targeted circuit; high variance across datasets suggests circuit overlap issues
- First 3 experiments:
  1. Extract 50% circuit from BLiMP dataset and verify it outperforms complementary circuit on pre-edit knowledge retrieval
  2. Apply knowledge editing to both 50% circuit and complementary circuit, measure edit performance differences
  3. Reduce circuit size to 5% and repeat editing experiments to observe size-performance relationship

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal size range for a "theoretical circuit" that concentrates essential knowledge?
- Basis in paper: [explicit] The authors find that an ideal "theoretical circuit" where essential knowledge is concentrated likely incorporates more than 5% but less than 50% of the model's parameters.
- Why unresolved: The study compares 5% and 50% circuits but does not pinpoint the exact optimal size within this range.
- What evidence would resolve it: Systematic experiments varying circuit sizes between 5% and 50% to identify the size that maximizes knowledge retention and editing performance.

### Open Question 2
- Question: How do LayerNorm layers contribute to knowledge storage and retrieval in neural networks?
- Basis in paper: [explicit] The study reveals that LayerNorm constitutes a disproportionately large share of the circuits, challenging traditional views on knowledge storage.
- Why unresolved: The specific role and mechanisms by which LayerNorm layers influence knowledge storage and network stability are not fully understood.
- What evidence would resolve it: Detailed analysis of LayerNorm's function in circuits, including ablation studies and comparisons with other layer types.

### Open Question 3
- Question: How can knowledge editing be performed on primary circuits without compromising model performance?
- Basis in paper: [explicit] The study suggests that complementary circuits are easier to edit than primary circuits, indicating potential for bias removal without affecting behavior.
- Why unresolved: The feasibility and methods for editing primary circuits while preserving model behavior are not explored.
- What evidence would resolve it: Experiments demonstrating successful editing of primary circuits using techniques like ROME or other targeted methods, ensuring minimal impact on model performance.

## Limitations

- Relatively small number of datasets used for circuit extraction (only two text classification datasets)
- Circuit extraction method relies on differentiable masking with unspecified implementation details and hyperparameters
- Knowledge editing experiments focus only on hierarchical relations datasets, potentially missing other knowledge types

## Confidence

**High confidence**: Circuits contain entity knowledge and resist editing more than complementary circuits (supported by consistent experimental evidence across multiple knowledge editing tasks)

**Medium confidence**: Optimal circuit size is between 5-50% (based on limited experimental data comparing only two circuit sizes)

**Medium confidence**: LayerNorm modules dominate knowledge-bearing circuits (percentage is directly measured but interpretation requires additional theoretical justification)

## Next Checks

1. **Cross-dataset circuit consistency test**: Extract circuits from three additional diverse text classification datasets and measure overlap between all circuit pairs to verify whether the moderate similarity pattern holds across a broader range of tasks and knowledge types.

2. **Layer-type ablation study**: Systematically remove LayerNorm, attention, and MLP components from the 5% circuit and measure the impact on knowledge editing performance to determine the actual functional contribution of each layer type rather than just their parameter share.

3. **Knowledge type specificity analysis**: Apply the same circuit extraction and editing methodology to knowledge types beyond hierarchical relations (such as factual knowledge, reasoning patterns, or linguistic rules) to test whether the resistance pattern and optimal size findings generalize across different knowledge domains.