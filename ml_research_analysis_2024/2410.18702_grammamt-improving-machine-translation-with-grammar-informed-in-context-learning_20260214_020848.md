---
ver: rpa2
title: 'GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning'
arxiv_id: '2410.18702'
source_url: https://arxiv.org/abs/2410.18702
tags:
- translation
- gloss
- sentence
- languages
- swahili
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "GRAMMA MT improves machine translation for low- and high-resource\
  \ languages by using Interlinear Glossed Text (IGT) annotations within prompting\
  \ strategies. It introduces three training-free approaches\u2014gloss-shot, chain-gloss,\
  \ and model-gloss\u2014that require minimal data collection and small numbers of\
  \ examples."
---

# GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning

## Quick Facts
- arXiv ID: 2410.18702
- Source URL: https://arxiv.org/abs/2410.18702
- Reference count: 20
- Improves machine translation for low- and high-resource languages using grammar-informed in-context learning with IGT annotations

## Executive Summary
GrammaMT introduces three training-free prompting strategies—gloss-shot, chain-gloss, and model-gloss—that leverage Interlinear Glossed Text (IGT) annotations to improve machine translation performance. By providing morphological and syntactic cues through IGT examples, the method achieves consistent BLEU score improvements across endangered, low-resource, and high-resource languages. The approach requires minimal data collection and works with various LLM architectures, demonstrating gains of over 17 BLEU points when accurate glosses are provided.

## Method Summary
GrammaMT uses Interlinear Glossed Text (IGT) annotations within prompting strategies to improve machine translation. The method introduces three training-free approaches: gloss-shot uses direct IGT examples in few-shot prompting, chain-gloss has the LLM first generate glosses before translation, and model-gloss leverages an external gloss generation model. These strategies require minimal data collection and small numbers of examples (21 per language), working effectively across different LLM architectures including Llama-3 and GPT-4o.

## Key Results
- Consistent BLEU improvements across endangered, low-resource, and high-resource languages
- Gains of over 17 BLEU points when accurate glosses are provided
- Three strategies (gloss-shot, chain-gloss, model-gloss) show varying effectiveness across different language families
- Generalizes across different LLM architectures and sizes
- Effective even without in-domain glosses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IGT annotations provide explicit morphological and syntactic cues that reduce ambiguity in translation.
- Mechanism: The gloss line breaks each source word into lemmata and grammatical morphemes, allowing the LLM to directly map morphological structure to target syntax without inferring it from raw text.
- Core assumption: The LLM can interpret and apply the morphological annotations provided in the gloss format.
- Evidence anchors:
  - [abstract]: "Interlinear Glossed Text (IGT), a common form of linguistic description providing morphological and lexical annotations for source sentences."
  - [section 3]: "The gloss consists of a sequence of target morphological annotations and (semantically full) lemmata for source words, indicating their grammatical morphemes and lexemes."
  - [corpus]: Weak; corpus mentions grammatical labels like "1SG" and "PST" but does not confirm LLM parsing success.
- Break condition: If glosses contain errors or are too ambiguous, the LLM may misinterpret morphology, degrading translation quality.

### Mechanism 2
- Claim: Model-gloss strategy leverages a specialized gloss generation model to produce accurate glosses, which improves translation performance compared to LLM-generated glosses.
- Mechanism: The external gloss model (GlossLM) is trained on large IGT corpora and produces higher-quality glosses, which are then fed into the LLM for translation.
- Core assumption: The external gloss model produces more accurate glosses than the LLM for unseen or low-resource languages.
- Evidence anchors:
  - [abstract]: "Moreover, ablation studies reveal that leveraging gloss resources could substantially boost MT performance (by over 17 BLEU points) if LLMs accurately generate or access input sentence glosses."
  - [section 5]: "Focusing on BLEU, this strategy shows a large improvement of 15.09, 14.65, and 12.03 BLEU points against zero-shot, zero-CoT and the few-shot approach on average, respectively."
  - [corpus]: Weak; corpus provides gloss accuracy metrics but not comparative performance between GlossLM and LLM-generated glosses.
- Break condition: If the external gloss model is unavailable or produces inaccurate glosses for the target language, the model-gloss strategy fails.

### Mechanism 3
- Claim: Chain-gloss prompting enables the LLM to first generate a gloss for the input sentence, then use that gloss to inform the translation, providing step-by-step reasoning.
- Mechanism: By explicitly generating the gloss before translation, the LLM decomposes the translation task into morphological analysis and semantic mapping, improving accuracy.
- Core assumption: The LLM can generate reasonable glosses for the input sentence when provided with in-context examples.
- Evidence anchors:
  - [abstract]: "In chain-gloss, the LLM first generates a gloss of the source sentence before translating."
  - [section 5]: "Focusing on BLEU, this strategy shows a large improvement of 15.09, 14.65, and 12.03 BLEU points against zero-shot, zero-CoT and the few-shot approach on average, respectively."
  - [corpus]: Weak; corpus does not directly measure gloss generation quality from LLM.
- Break condition: If the LLM cannot generate accurate glosses, the chain-gloss approach may produce misleading translations.

## Foundational Learning

- Concept: Interlinear Gloss Text (IGT) format
  - Why needed here: IGT provides the grammatical and morphological annotations that GRAMMA MT uses to guide translation.
  - Quick check question: What are the two main components of an IGT gloss line?
- Concept: In-context learning with few-shot examples
  - Why needed here: GRAMMA MT relies on providing a small number of IGT examples to the LLM to demonstrate the translation task.
  - Quick check question: How many examples are used in the optimal GRAMMA MT setup?
- Concept: BLEU and chrF++ evaluation metrics
  - Why needed here: These metrics are used to quantify translation quality improvements from GRAMMA MT.
  - Quick check question: Which metric is more sensitive to morphological accuracy?

## Architecture Onboarding

- Component map:
  - LLM (Llama-3 70B, 8B, Mixtral, GPT-4o) -> Gloss generation model (GlossLM for model-gloss) -> IGT example dataset -> Prompt templates (gloss-shot, chain-gloss, model-gloss)
- Critical path:
  1. Load LLM and (optionally) gloss generation model
  2. Prepare IGT examples for in-context learning
  3. Generate prompt based on chosen strategy
  4. Run inference and collect translation
- Design tradeoffs:
  - Using more examples improves performance but increases prompt length and cost
  - Chain-gloss provides interpretability but may introduce errors if gloss generation fails
  - Model-gloss requires external gloss model but yields most consistent improvements
- Failure signatures:
  - Poor translation quality with chain-gloss indicates gloss generation errors
  - No improvement over few-shot suggests IGT examples are not informative
  - High variance across languages indicates strategy sensitivity to language family
- First 3 experiments:
  1. Compare gloss-shot vs few-shot on Swahili with N=21
  2. Evaluate chain-gloss vs model-gloss on Lezgi to test gloss generation impact
  3. Test model-gloss on an unseen endangered language to verify robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of GRAMMA MT scale with increasing amounts of gloss resources available?
- Basis in paper: [explicit] The paper shows that performance improves with accurate glosses and mentions the potential of automatic gloss generation models like GlossLM, but doesn't explore scaling with varying amounts of gloss resources.
- Why unresolved: The study uses a fixed set of 21 examples and focuses on the impact of gloss accuracy rather than the quantity of gloss data. The relationship between gloss resource size and translation performance remains unclear.
- What evidence would resolve it: Experiments varying the number of gloss examples provided (e.g., 5, 10, 21, 50) across different language families and resource levels would show how performance scales with gloss availability.

### Open Question 2
- Question: How does GRAMMA MT perform when translating between non-English languages using interlinear glosses?
- Basis in paper: [inferred] The paper focuses on translation to English due to the availability of IGT datasets, but mentions attempting reverse translation (en →) with some success, suggesting potential for other language pairs.
- Why unresolved: The study's focus on English as the target language limits understanding of GRAMMA MT's applicability to other language pairs. The availability and quality of interlinear glosses for non-English pairs is a key factor.
- What evidence would resolve it: Testing GRAMMA MT on translation tasks between other language pairs (e.g., Spanish to French, Mandarin to Japanese) where interlinear gloss resources exist would demonstrate its cross-linguistic effectiveness.

### Open Question 3
- Question: What is the optimal balance between gloss-shot and chain-gloss strategies for different language types and resource levels?
- Basis in paper: [explicit] The paper shows that different strategies perform better for different languages (e.g., chain-gloss for low-resource languages, gloss-shot for out-of-domain settings), but doesn't provide a systematic framework for choosing between them.
- Why unresolved: The study presents individual results for each strategy but doesn't explore their relative effectiveness across different language families, morphological typologies, or resource levels. The optimal strategy likely depends on multiple factors.
- What evidence would resolve it: A comprehensive analysis comparing all GRAMMA MT strategies across diverse language families, morphological structures, and resource levels would identify when each strategy is most effective.

## Limitations
- Effectiveness depends on the quality and availability of IGT resources, which may be limited for many endangered or low-resource languages
- Performance is contingent on the accuracy of the gloss generation model (GlossLM), which may not generalize well to all target languages
- The approach relies on in-context learning, which may degrade for languages with complex morphological systems not well-represented in the example set
- The paper does not address potential biases introduced by linguistic assumptions embedded in IGT annotations

## Confidence
- High Confidence: The general improvement in BLEU scores across multiple languages and datasets is well-supported by the experimental results
- Medium Confidence: The claim that model-gloss provides the most consistent improvements is supported, but the reliance on an external gloss model introduces variability
- Low Confidence: The assertion that IGT annotations universally reduce ambiguity in translation is plausible but not empirically validated across all language families

## Next Checks
1. Conduct a manual evaluation of gloss accuracy across a diverse set of languages, particularly focusing on low-resource and endangered languages, to assess the reliability of the gloss generation model
2. Test the GRAMMA MT approach on a wider range of morphologically diverse languages, including those with non-concatenative morphology (e.g., Semitic languages), to evaluate robustness
3. Perform a detailed error analysis on translations where GRAMMA MT underperforms, identifying whether failures stem from gloss generation errors, LLM interpretation issues, or dataset limitations