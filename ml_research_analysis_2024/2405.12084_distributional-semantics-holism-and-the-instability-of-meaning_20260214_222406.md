---
ver: rpa2
title: Distributional Semantics, Holism, and the Instability of Meaning
arxiv_id: '2405.12084'
source_url: https://arxiv.org/abs/2405.12084
tags:
- meaning
- word
- words
- distributional
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors argue that the instability objection against holistic
  theories of meaning doesn't apply to distributional models of meaning. They show
  that meaning similarity is understood differentially in these models, and that changes
  in word meaning due to corpus expansion are constrained by the structure and scale
  of relationships between words.
---

# Distributional Semantics, Holism, and the Instability of Meaning

## Quick Facts
- arXiv ID: 2405.12084
- Source URL: https://arxiv.org/abs/2405.12084
- Reference count: 9
- Authors: Jumbly Grindrod; J. D. Porter; Nat Hansen
- Primary result: Instability objection against holism doesn't apply to distributional models because meaning is understood differentially, allowing productive change without undermining communication.

## Executive Summary
The paper argues that holistic theories of meaning, which claim word meanings depend on their relations to other words, face an "instability objection" that threatens communication. However, this objection doesn't apply to distributional semantic models because these models understand meaning similarity differentially rather than absolutely. Changes in word meaning due to corpus expansion are constrained by the structure and scale of relationships between words, with larger corpora providing more stability. This differential instability allows for productive meaning change while preserving enough stability for successful communication.

## Method Summary
The authors construct two types of distributional semantic models to test meaning stability: simple count-based models using co-occurrence vectors from short texts (Stein and Hemingway), and Word2vec models trained on Wikipedia plus philosophy texts. They compare nearest-neighbor lists and similarity relations before and after corpus expansion to examine how word meanings change. The analysis focuses on whether changes in corpora lead to substantial shifts in word meanings or whether the differential nature of similarity relations preserves stability across different corpus sizes and contexts.

## Key Results
- Differential instability allows for productive meaning change while not undermining communication
- Larger corpora dampen instability because relational networks become more densely connected and resistant to local perturbations
- Meaning similarity is understood relationally rather than absolutely, sidestepping the total change thesis

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Differential instability sidesteps the total change thesis because similarity is defined relationally, not absolutely
- **Mechanism:** Treating meaning as relative distances among words rather than fixed coordinates allows small corpus changes to shift word positions without altering relational neighborhoods
- **Core assumption:** Speakers rely on relative similarity rather than exact vector values when interpreting meaning
- **Evidence anchors:** [abstract] "Differential instability is variation in the relative distances between points in a space, rather than variation in the absolute position of those points"
- **Break condition:** Substantial nearest-neighbor list changes even with differential interpretation can disrupt perceived meaning

### Mechanism 2
- **Claim:** Larger corpora dampen instability through denser relational networks
- **Mechanism:** More examples anchor each word's position through stable relations, so new additions produce only minor adjustments
- **Core assumption:** Word-to-word relations form an interconnected network that constrains changes
- **Evidence anchors:** [abstract] "resistance to change for a word is roughly proportional to its frequent and consistent use"
- **Break condition:** Novel domains introducing large proportions of new context can still cause substantial shifts

### Mechanism 3
- **Claim:** Differential similarity enables stable-enough communication through overlapping network regions
- **Mechanism:** Personal models form networks; overlapping regions provide common ground where meaning is preserved despite peripheral differences
- **Core assumption:** Communication occurs within intersection of speakers' networks rather than requiring full model identity
- **Evidence anchors:** [abstract] "differential instability... allows for productive forms of meaning change while not leading to the problems raised by the instability objection"
- **Break condition:** Too small intersection (no shared vocabulary or context) prevents reliable meaning preservation

## Foundational Learning

- **Concept:** Vector space semantics
  - Why needed here: The entire argument rests on representing meaning as points in high-dimensional space
  - Quick check question: If two words are close in vector space, what does that imply about their distributional properties in the corpus?

- **Concept:** Cosine similarity vs Euclidean distance
  - Why needed here: The paper distinguishes these metrics and uses cosine similarity to define meaning proximity
  - Quick check question: Why might cosine similarity be preferred over Euclidean distance for comparing word vectors in distributional models?

- **Concept:** Semantic holism
  - Why needed here: The instability objection targets holism; understanding meaning determined by word-to-word relations is essential
  - Quick check question: What is the core claim of meaning holism, and why does it lead to the instability objection?

## Architecture Onboarding

- **Component map:** Count-based co-occurrence model → optional dimensionality reduction (SVD) → nearest-neighbor extraction → differential similarity comparison across corpora
- **Critical path:** Build model → expand corpus → recompute similarities → compare nearest-neighbor lists → evaluate differential stability
- **Design tradeoffs:** High dimensionality improves accuracy but increases computation; dimensionality reduction speeds processing but may lose interpretable dimensions
- **Failure signatures:** Nearest-neighbor lists change drastically after corpus expansion; cosine similarities between same word pairs diverge beyond acceptable thresholds
- **First 3 experiments:**
  1. Run toy model on Stein alone, then add Hemingway; verify "know" nearest neighbors remain unchanged while "glass" changes
  2. Vary corpus size incrementally; plot instability (nearest-neighbor change rate) vs corpus size to confirm scaling behavior
  3. Test on polysemous word (e.g., "bank"); compare how context window and preprocessing choices affect differential stability

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do large language models handle meaning change when encountering new contexts or corpora, and what specific mechanisms enable them to maintain stable communication despite potential instability in word meanings?
- **Basis in paper:** [explicit] The paper discusses how distributional models exhibit "differential instability" and argues that meaning similarity is understood differentially
- **Why unresolved:** The paper does not provide a detailed account of specific mechanisms by which large language models manage meaning change in new contexts
- **What evidence would resolve it:** Empirical studies examining large language model performance in handling new contexts and corpora, focusing on their ability to maintain stable communication

### Open Question 2
- **Question:** What is the precise threshold of similarity required for successful communication, and how does this threshold vary across different linguistic and cultural contexts?
- **Basis in paper:** [explicit] The paper acknowledges the need for a threshold of similarity between speaker and hearer meanings but does not specify this threshold
- **Why unresolved:** The paper does not provide a concrete threshold for similarity nor does it explore how this threshold might vary across contexts
- **What evidence would resolve it:** Empirical studies measuring the impact of varying degrees of meaning similarity on communicative success across different linguistic and cultural contexts

### Open Question 3
- **Question:** How do large language models account for polysemy and context-dependent meaning, and what are the limitations of current models in capturing these nuances?
- **Basis in paper:** [inferred] The paper mentions limitations of collocate-based models in handling polysemy and context-dependent meaning
- **Why unresolved:** The paper does not provide a detailed account of how large language models handle polysemy and context-dependent meaning
- **What evidence would resolve it:** Empirical studies comparing large language model performance in handling polysemy and context-dependent meaning, along with analyses of current model limitations

## Limitations

- The scaling claim about corpus size effects remains theoretically grounded but lacks direct empirical validation across diverse, large-scale datasets
- The relationship between polysemy handling and differential stability is not explored—multiple senses may exhibit different instability profiles
- The practical implications for real-world language change and cross-speaker alignment are not tested against actual diachronic shifts

## Confidence

- **High confidence** in the conceptual distinction between absolute and differential instability, and in the logical coherence of the defense against holism objections
- **Medium confidence** in the scaling claim about corpus size effects, as it follows from reasonable network theory but lacks empirical demonstration
- **Low confidence** in the practical implications for real-world language change and communication, since the paper does not test the model against actual diachronic shifts or cross-speaker alignment scenarios

## Next Checks

1. Construct count models and Word2vec models on progressively larger corpora (from 10K to 1M+ tokens), measuring nearest-neighbor stability across incremental expansions to empirically verify the scaling relationship between corpus size and instability

2. Test differential stability on polysemous words (e.g., "bank", "light", "run") versus monosemous words across the same corpus expansions, measuring whether multiple senses exhibit greater instability

3. Create two separate personal models from different text sources, then compute the intersection size of shared vocabulary and meaning relations after controlled communication scenarios, validating the claim that communication preserves meaning within overlapping network regions