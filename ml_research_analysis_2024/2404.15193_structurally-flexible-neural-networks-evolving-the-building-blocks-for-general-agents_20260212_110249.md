---
ver: rpa2
title: 'Structurally Flexible Neural Networks: Evolving the Building Blocks for General
  Agents'
arxiv_id: '2404.15193'
source_url: https://arxiv.org/abs/2404.15193
tags:
- neural
- parameters
- network
- sfnn
- neurons
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of creating neural networks
  that can adapt to multiple reinforcement learning environments with different input
  and output dimensions, overcoming what the authors call the "Symmetry Dilemma."
  The proposed Structurally Flexible Neural Networks (SFNNs) consist of sparsely connected
  parameterized neurons and plastic synapses, where the building blocks are GRUs that
  can adapt during an agent's lifetime. The key innovation is using multiple distinct
  sets of neuron and synapse types, with parameter-sharing within types but not across
  them.
---

# Structurally Flexible Neural Networks: Evolving the Building Blocks for General Agents

## Quick Facts
- arXiv ID: 2404.15193
- Source URL: https://arxiv.org/abs/2404.15193
- Reference count: 40
- Primary result: SFNNs achieve high scores across three different control tasks (CartPole-v1, Acrobot-v1, MountainCar-v0) simultaneously using a single set of evolved building blocks

## Executive Summary
This paper addresses the challenge of creating neural networks that can adapt to multiple reinforcement learning environments with different input and output dimensions. The authors propose Structurally Flexible Neural Networks (SFNNs) that use parameter-sharing across multiple distinct neuron and synapse types, with plastic synapses that can update their weights during an agent's lifetime. By evolving the building blocks rather than the entire network structure, SFNNs can solve three classic control tasks with different dimensionalities using the same evolved parameters.

## Method Summary
The approach uses GRUs as both neuron activation functions and synapse plasticity rules, with parameter-sharing within neuron/synapse types but not across them. Each lifetime starts with random sparse connectivity (50% dropout rate) and random initial synaptic weights. The evolved plasticity rules organize this random connectivity into functional networks through environmental interactions. CMA-ES optimization evolves the shared parameters across multiple environments simultaneously, with fitness calculated as the product of normalized scores from each task.

## Key Results
- SFNNs outperform Symmetric Learning Agents (SymLA) and ablated versions on all three environments
- The evolved building blocks successfully handle environments with different input/output dimensions (4, 6, and 2 inputs)
- Parameter-sharing with multiple distinct types enables adaptation without overfitting to specific permutations
- Sparse random connectivity combined with evolved plasticity rules enables self-organization into functional networks

## Why This Works (Mechanism)

### Mechanism 1
- Parameter-sharing across multiple distinct neuron and synapse types enables adaptation to varying input/output dimensions while maintaining functional diversity. The SFNN contains three distinct neuron types (input, hidden, output) and three synapse types, each with shared GRU parameters but unique hidden states. This allows synapses to develop different weight values despite sharing the same update rules, enabling adaptation to different environments.

### Mechanism 2
- Sparse random connectivity combined with evolved plastic synapses enables self-organization into functional networks across different environments. At each lifetime, a new random sparse adjacency matrix is sampled, and synapses with random initial weights are updated through interactions with the environment using evolved GRU plasticity rules. This allows the same evolved parameters to organize differently based on environmental feedback.

### Mechanism 3
- Permutation invariance is achieved through parameter-sharing and random initialization, allowing the network to handle different input/output orderings without retraining. All input neurons share parameters, and synapses from input to hidden layers share parameters. Random initialization of hidden states and sparse connectivity prevents overfitting to specific permutations or dimensions.

## Foundational Learning

- **Gated Recurrent Units (GRUs)**: GRUs serve as both neuron activation functions and synapse plasticity rules, providing memory and adaptive weight updates. *Quick check: What are the three gates in a GRU and how do they control information flow?*

- **Evolutionary optimization with CMA-ES**: CMA-ES optimizes the shared parameters of neuron and synapse types across multiple environments simultaneously. *Quick check: How does CMA-ES handle the trade-off between exploration and exploitation in high-dimensional parameter spaces?*

- **Permutation invariance in neural networks**: The network must function regardless of input/output element ordering or dimensionality changes across environments. *Quick check: What are the key architectural requirements for achieving permutation invariance in neural networks?*

## Architecture Onboarding

- **Component map**: Input neurons (linear + tanh) -> Synapses (GRU plasticity) -> Hidden neurons (linear + tanh) -> Synapses (GRU plasticity) -> Output neurons (linear + tanh)

- **Critical path**: Environment observation → input neuron activations → signal propagation through synapses → hidden neuron updates across micro-ticks → output neuron activation → action selection → synapse weight updates using GRU plasticity rules

- **Design tradeoffs**: Parameter-sharing vs. specialization (multiple neuron/synapse types provide balance), sparsity level (50% chosen empirically; higher sparsity reduces computation but may impair learning), GRU hidden size (4 chosen for balance between representational capacity and parameter efficiency)

- **Failure signatures**: No learning progress (likely issue with plasticity rule parameters or initialization), overfitting to specific environment (check if adjacency matrix randomness is properly implemented), converged synapse states (may indicate insufficient diversity in neuron/synapse types)

- **First 3 experiments**: Test basic functionality (run single environment with fixed adjacency matrix), test permutation invariance (run with different input/output orderings), test multi-environment capability (run all three environments simultaneously)

## Open Questions the Paper Calls Out

1. **Scalability with input dimensions**: How does increasing the number of neuron and synapse types affect performance on high-dimensional environments with many input elements? The paper tested only small input spaces (4, 6, and 2 inputs) and acknowledges this limitation.

2. **Task-switching during lifetime**: Can SFNNs maintain performance when switching tasks during a single lifetime, or do they need retraining on each new task? The experiments trained sequentially across separate lifetimes, not within a single lifetime.

3. **Structured vs. random connectivity**: How does random sparse connectivity compare to optimized structural development algorithms for SFNNs? The paper suggests combining with developmental algorithms but doesn't test this approach.

## Limitations
- The evolutionary optimization process may be computationally expensive and potentially overfit to the specific three control tasks
- The sparse connectivity pattern (50% dropout rate) was chosen empirically without systematic analysis of its impact
- The claim that parameter-sharing combined with random initialization provides sufficient permutation invariance lacks rigorous theoretical justification

## Confidence

**High Confidence**: The experimental results showing SFNN outperforming SymLA and ablated versions across all three environments. The mechanism of using parameter-sharing within neuron/synapse types while maintaining distinct hidden states is well-supported.

**Medium Confidence**: The claim that evolved plasticity rules can effectively organize random initial connectivity into functional networks across different environments. While results are positive, the underlying mechanism is not fully explained.

**Low Confidence**: The assertion that the approach generalizes to arbitrary permutations of input/output elements without retraining. The paper demonstrates invariance to fixed orderings but doesn't rigorously test arbitrary permutations or higher-dimensional environments.

## Next Checks

1. **Permutation Robustness Test**: Systematically test the evolved SFNN parameters on all possible permutations of input/output elements for each environment to verify true permutation invariance.

2. **Scalability Analysis**: Evaluate the approach on environments with significantly different dimensionalities (e.g., 10+ inputs/outputs) to assess whether the 50% sparsity level remains effective.

3. **Plasticity Rule Analysis**: Perform ablation studies on the GRU plasticity parameters to determine which components are essential for cross-environment generalization versus environment-specific adaptation.