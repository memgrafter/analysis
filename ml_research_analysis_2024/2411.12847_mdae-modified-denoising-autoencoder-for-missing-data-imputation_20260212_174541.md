---
ver: rpa2
title: 'mDAE : modified Denoising AutoEncoder for missing data imputation'
arxiv_id: '2411.12847'
source_url: https://arxiv.org/abs/2411.12847
tags:
- missing
- data
- values
- mdae
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes mDAE, a modified Denoising AutoEncoder (DAE)
  for missing data imputation. The key modification is to the loss function, which
  now ignores pre-imputed missing values, unlike standard DAE approaches.
---

# mDAE : modified Denoising AutoEncoder for missing data imputation

## Quick Facts
- arXiv ID: 2411.12847
- Source URL: https://arxiv.org/abs/2411.12847
- Authors: Mariette Dupuy; Marie Chavent; Remi Dubois
- Reference count: 7
- mDAE consistently ranks among top methods for missing data imputation

## Executive Summary
This paper proposes mDAE, a modified Denoising AutoEncoder (DAE) for missing data imputation that addresses a key limitation in standard DAE approaches. The core innovation is a modified loss function that ignores pre-imputed missing values during training, preventing the model from learning to reconstruct these placeholder values. Through ablation studies on UCI datasets, the authors demonstrate that this modified loss, combined with an overcomplete network structure, significantly improves imputation accuracy compared to standard DAE implementations.

## Method Summary
The mDAE method modifies the standard DAE approach by changing the loss function to ignore pre-imputed missing values during training. The method takes standardized data with missing values pre-imputed with zeros, applies masking noise with proportion μ, and trains using a modified L2 loss that only considers observed entries (PΩ(X) - PΩ(Z))²F. The architecture uses an overcomplete structure (q > p dimensions) with ReLU activation in the encoder and identity activation in the decoder. Hyperparameters are selected via cross-validation, though ablation studies show random μ selection performs nearly as well.

## Key Results
- mDAE ranks among top methods (with SoftImpute and missForest) based on proposed Mean Distance to Best (MDB) criterion
- Four recent deep learning/optimal transport methods (GAIN, MIWAE, SAUCIE, TDM) consistently ranked last
- Overcomplete structures outperform undercomplete ones, reducing RMSE by approximately 35% on tested datasets
- Modified loss function is essential - using standard DAE loss significantly degrades performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The modified loss function improves imputation by excluding pre-imputed zeros from reconstruction error
- **Mechanism**: Using PΩ(X) - PΩ(Z) in loss only penalizes reconstruction errors on observed values, preventing learning of zero reconstruction at missing positions
- **Core assumption**: Standard DAE loss trains model to reconstruct mean-imputed zeros, which is irrelevant for imputation quality
- **Evidence anchors**:
  - [abstract]: "The key modification is to the loss function, which now ignores pre-imputed missing values, unlike standard DAE approaches"
  - [section]: "Our proposal is then not only to apply a DAE to the pre-imputed data matrix as in previous works, but also to modify the reconstruction error (3) to skip these locations"
  - [corpus]: Weak - no direct validation of modified loss mechanism from corpus neighbor papers

### Mechanism 2
- **Claim**: Overcomplete structures consistently outperform undercomplete ones for missing data imputation
- **Mechanism**: Overcomplete layers allow DAE to learn richer latent representations without bottlenecking, improving reconstruction at missing positions
- **Core assumption**: DAEs benefit from overcomplete architectures when denoising, unlike standard autoencoders
- **Evidence anchors**:
  - [section]: "The fourth row shows that using an undercomplete structure rather than an overcomplete one clearly increases the RMSE to around 35% for two of the seven datasets"
  - [corpus]: Weak - no corpus neighbor papers explicitly discuss overcomplete DAE benefits for imputation

### Mechanism 3
- **Claim**: Randomly choosing μ in [0,1] is nearly as effective as optimizing via cross-validation
- **Mechanism**: Masking noise proportion μ has relatively flat performance curve, so random selection saves computation without significant quality loss
- **Core assumption**: Imputation quality is insensitive to exact value of μ within reasonable range
- **Evidence anchors**:
  - [section]: "The third row shows that using a random value of the hyper-parameter µ rather than an optimized one deteriorates the imputation quality for all datasets, but to a lesser extent (between 1 and 8% increase in RMSE)"
  - [corpus]: Weak - no corpus neighbor papers validate this claim

## Foundational Learning

- **Concept**: Denoising Autoencoders (DAEs)
  - Why needed here: mDAE builds directly on DAE principles, using noise masking to learn robust reconstructions
  - Quick check question: What is the primary difference between a standard autoencoder and a denoising autoencoder?

- **Concept**: Loss function modification for incomplete data
  - Why needed here: Standard reconstruction losses cannot handle missing entries; mDAE modifies loss to ignore them
  - Quick check question: How does modified loss PΩ(X) - PΩ(Z) differ from standard L2 loss in DAEs?

- **Concept**: Cross-validation for hyperparameter selection
  - Why needed here: mDAE uses cross-validation to choose μ and structure, though ablation shows random μ is nearly as good
  - Quick check question: Why might cross-validation be preferred over random selection for μ in some cases?

## Architecture Onboarding

- **Component map**: Input (standardized X) -> Encoder (fθ with ReLU) -> Latent space (y ∈ R^q, overcomplete) -> Decoder (gθ′ with identity) -> Output (Z) -> Modified L2 loss

- **Critical path**: 1) Pre-impute missing values with zeros, 2) Corrupt with masking noise (μ proportion), 3) Train with modified loss on observed entries only, 4) Predict missing values from final Z

- **Design tradeoffs**: Overcomplete vs undercomplete (overcomplete better but risks overfitting), Fixed μ vs optimized μ (optimized slightly better but random saves time), Modified vs standard loss (modified essential)

- **Failure signatures**: RMSE increases sharply with undercomplete structure, poor imputation with μ too low/high, biased reconstruction if data not standardized

- **First 3 experiments**: 1) Train mDAE with standard L2 loss vs modified loss, compare RMSE, 2) Test undercomplete vs overcomplete structures on small UCI dataset, 3) Compare random μ vs cross-validated μ on breast cancer dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does mDAE performance compare to other methods for block-wise missing data?
- Basis in paper: [explicit] Paper mentions mDAE should handle block-wise missing values by imposing block-wise structuring of masking noise, common in EHR, longitudinal studies, or time series
- Why unresolved: No experimental results or comparisons for block-wise missing data scenarios provided
- What evidence would resolve it: Experimental results comparing mDAE's performance on block-wise missing data against other imputation methods using datasets with block-wise missing patterns

### Open Question 2
- Question: How do optimal hyperparameters for mDAE vary across different dataset types and missing data mechanisms?
- Basis in paper: [inferred] Paper suggests cross-validation for μ optimization and mentions network structure choice significantly impacts performance, but lacks comprehensive analysis of hyperparameter selection based on dataset characteristics
- Why unresolved: Focuses on general methodology without exploring adaptation for different dataset types or missing data mechanisms
- What evidence would resolve it: Detailed study showing optimal hyperparameter configurations across various dataset types (high-dimensional vs low-dimensional, large vs small sample sizes) and missing data mechanisms (MCAR, MAR, MNAR)

### Open Question 3
- Question: Can mDAE methodology be extended to handle categorical or mixed-type data?
- Basis in paper: [explicit] Paper explicitly states mDAE is suited for numerical missing values only, all datasets used were numerical
- Why unresolved: Does not explore potential for extending mDAE to handle non-numerical data types common in real-world datasets
- What evidence would resolve it: Experiments demonstrating mDAE performance on categorical and mixed-type datasets, or theoretical framework for extending mDAE to handle non-numerical data

## Limitations
- Limited empirical validation of modified loss mechanism's impact, relying primarily on ablation studies
- Overcomplete structure claim supported by single-dataset experiments rather than systematic cross-validation across diverse data types
- Random μ selection claim based on limited comparisons may not generalize to datasets with complex missingness patterns

## Confidence
- Mechanism 1 (modified loss function): Medium confidence - theoretical justification sound but empirical validation limited to ablation studies
- Mechanism 2 (overcomplete structures): Low-Medium confidence - supported by single-dataset experiments but lacks systematic validation
- Mechanism 3 (random μ selection): Low-Medium confidence - based on limited comparisons; may not generalize to complex missingness patterns

## Next Checks
1. Conduct systematic cross-validation comparing overcomplete vs undercomplete structures across diverse dataset types to validate architecture claim
2. Test modified loss mechanism against alternative approaches (weighted loss, GAN-based imputation) to establish relative effectiveness
3. Evaluate random μ selection performance across datasets with varying missingness mechanisms (MCAR, MAR, MNAR) and different proportions of missing data to assess generalizability