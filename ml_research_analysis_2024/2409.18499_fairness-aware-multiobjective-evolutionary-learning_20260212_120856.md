---
ver: rpa2
title: Fairness-aware Multiobjective Evolutionary Learning
arxiv_id: '2409.18499'
source_url: https://arxiv.org/abs/2409.18499
tags:
- objectives
- fairness
- e-05
- measures
- e-04
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training fairer machine learning
  models when multiple fairness measures exist, each with complex and sometimes conflicting
  relationships. The authors propose a fairness-aware multiobjective evolutionary
  learning (FaMOEL) framework that dynamically and adaptively selects a representative
  subset of fairness measures as optimisation objectives during model training, rather
  than using a static predefined set.
---

# Fairness-aware Multiobjective Evolutionary Learning

## Quick Facts
- arXiv ID: 2409.18499
- Source URL: https://arxiv.org/abs/2409.18499
- Reference count: 40
- Primary result: FaMOEL achieves superior performance compared to state-of-the-art methods, both in terms of accuracy and 25 fairness measures, while only optimising a few dynamically selected objectives

## Executive Summary
This paper addresses the challenge of training fairer machine learning models when multiple fairness measures exist with complex and conflicting relationships. The authors propose a fairness-aware multiobjective evolutionary learning (FaMOEL) framework that dynamically and adaptively selects a representative subset of fairness measures as optimisation objectives during model training, rather than using a static predefined set. Experiments on 12 benchmark datasets demonstrate that FaMOEL achieves outstanding performance in terms of both accuracy and 25 fairness measures, despite only optimising a dynamically selected subset of objectives at each generation.

## Method Summary
The FaMOEL framework uses a fairness-aware strategy based on modified nonlinear correlation information entropy (mN-CIE) to online determine the most suitable subset of fairness measures as optimization objectives during training. The method employs a multiobjective evolutionary algorithm (Two Arch2) with partial training using stochastic gradient descent to evolve a population of models. At each generation, the framework calculates correlations among objective values and selects a representative subset of fairness measures to optimize, with the subset changing dynamically based on the current model training process. Three enhancement strategies are incorporated into the original ORNCIE method: using 10-generation moving averages for correlation capture, warm starting with all objectives, and using a static hyperparameter τ instead of classifying objectives.

## Key Results
- FaMOEL achieves superior performance compared to state-of-the-art methods on 12 benchmark datasets
- The framework maintains high accuracy while improving fairness across 25 different fairness measures
- Dynamic selection of objectives during training provides better results than static subset selection
- Only a few dynamically selected objectives are needed to improve all 25 fairness measures

## Why This Works (Mechanism)

### Mechanism 1
Dynamic selection of representative fairness measures during training improves model fairness compared to static selection. The FaMOEL framework employs a fairness-aware strategy based on modified nonlinear correlation information entropy (mNCIEE) to adaptively select a subset of fairness measures as optimization objectives at each generation. This subset changes over time based on the current model training process and correlation analysis of objective values. If the correlation structure among fairness measures remains static throughout training, dynamic selection would provide no benefit over static selection.

### Mechanism 2
The enhanced fairness-aware strategy with three novel improvements outperforms the original ORNCIE method. The paper introduces three enhancements: (1) using a 10-generation moving average of mNCIE matrices for more precise correlation capture, (2) warm starting with all objectives for the first 10 generations to enhance exploration, and (3) using a static hyperparameter τ instead of the "classifying objectives" strategy to avoid removing essential objectives. If the original ORNCIE method is already optimal for this application, or if the enhancements introduce new problems, performance could degrade.

### Mechanism 3
Optimizing a dynamically selected subset of fairness measures improves all 25 fairness measures, even those not selected as objectives. The positive correlations among fairness measures allow optimization of a representative subset to indirectly improve correlated measures not selected as objectives. The dynamic selection ensures the most relevant subset is optimized at each training stage. If fairness measures have complex, changing correlations that cannot be captured by the subset selection, or if the positive correlations are not strong enough to provide meaningful indirect improvement, this mechanism would fail.

## Foundational Learning

- Concept: Multiobjective optimization and Pareto optimality
  - Why needed here: The framework must maintain a diverse set of models representing different tradeoffs among accuracy and fairness measures, rather than converging to a single solution.
  - Quick check question: What is the difference between a Pareto optimal solution and a dominated solution in multiobjective optimization?

- Concept: Evolutionary algorithms and population-based optimization
  - Why needed here: The framework uses multiobjective evolutionary algorithms (MOEAs) to evolve a population of models, requiring understanding of genetic operators, selection mechanisms, and population dynamics.
  - Quick check question: How does tournament selection work in evolutionary algorithms, and why is it commonly used for mating selection?

- Concept: Fairness measures in machine learning
  - Why needed here: The framework must understand and calculate 25 different fairness measures to evaluate and optimize model fairness across multiple dimensions.
  - Quick check question: What is the difference between statistical parity and equal opportunity as fairness measures?

## Architecture Onboarding

- Component map:
  FaMOEL Framework -> Fairness-aware Strategy -> MOEA (Two Arch2) -> Partial Training -> Evaluation

- Critical path: Training data -> Partial training -> Objective evaluation -> Fairness-aware selection -> MOEA operations -> New population -> Repeat until termination

- Design tradeoffs:
  - Dynamic vs. static objective selection: Dynamic provides adaptability but adds computational overhead for correlation analysis
  - Subset size: Larger subsets provide better representation but reduce computational efficiency
  - Warm starting duration: Longer warm starting improves exploration but delays dynamic adaptation

- Failure signatures:
  - Poor HV values despite good GD/PD: Model set is converging to a local region, not exploring the full Pareto front
  - HV values plateau early: Subset selection is not adapting to changing correlations, or parameter τ is poorly chosen
  - High variance across trials: Random initialization or stochastic elements are dominating the optimization process

- First 3 experiments:
  1. Compare FaMOEL with static subset selection on a single dataset, measuring HV, GD, PD, and SP values across generations
  2. Analyze the dynamic subset selection process on a single dataset, visualizing which objectives are selected at each generation and their correlation structure
  3. Perform ablation study removing each of the three enhancements to quantify their individual contributions to performance improvement

## Open Questions the Paper Calls Out

### Open Question 1
How can the parameter τ in the fairness-aware strategy be automatically tuned across different datasets to optimize representative subset selection? The authors note that "the optimal parameter τ varies across different datasets" and suggest an adaptive mechanism for tuning τ would be valuable. This remains unresolved as the paper uses a fixed τ value (0.22) across all experiments without developing an automatic tuning method.

### Open Question 2
Can the FaMOEL framework be extended to handle more complex model architectures beyond single-hidden-layer ANNs while maintaining or improving fairness performance? The authors state they "plan to enhance the feasibility and interoperability of our framework when applied to more complex models, such as deep learning models." This remains unresolved as the current implementation uses only simple ANNs with one hidden layer.

### Open Question 3
How does the dynamically selected objective subset in FaMOEL compare to optimal static subsets that could be determined with unlimited computational resources? The authors note that determining "a suitable representative subset for a new dataset consumes significant computational cost" and their method eliminates this need. This remains unresolved as the paper compares against one static subset from literature but doesn't evaluate against computationally-derived optimal subsets for each dataset.

## Limitations

- The modified nonlinear correlation information entropy method is not fully detailed in the paper, making exact reproduction challenging
- The choice of 25 fairness measures, while comprehensive, may not capture all relevant fairness dimensions for different application domains
- The computational overhead of dynamic selection and correlation analysis is not quantified relative to static approaches

## Confidence

- High confidence: The fundamental claim that dynamic selection can improve fairness optimization compared to static selection
- Medium confidence: The specific three enhancement strategies provide meaningful improvements over the original ORNCIE method
- Medium confidence: Optimizing a subset of fairness measures can indirectly improve correlated measures not selected as objectives

## Next Checks

1. Perform sensitivity analysis on the selection threshold τ parameter across a range of values to determine its impact on convergence speed and final fairness performance
2. Compare FaMOEL's dynamic selection process against alternative subset selection methods (e.g., random selection, importance-based selection) to isolate the benefit of the mNCIE-based approach
3. Conduct a scalability study on larger datasets and with more than 25 fairness measures to evaluate how the framework's performance changes with problem size and objective dimensionality