---
ver: rpa2
title: Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences
arxiv_id: '2401.10472'
source_url: https://arxiv.org/abs/2401.10472
tags:
- trigger
- entity
- domain
- entities
- given
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of named entity recognition (NER)
  under domain shift between biomedical and chemical domains. A major problem is that
  standard transfer learning methods often mislabel source domain entities (e.g.,
  biomedical terms) as target domain entities (e.g., chemical terms) when these appear
  together in text.
---

# Named Entity Recognition Under Domain Shift via Metric Learning for Life Sciences

## Quick Facts
- **arXiv ID**: 2401.10472
- **Source URL**: https://arxiv.org/abs/2401.10472
- **Reference count**: 23
- **Primary result**: Up to 5% absolute F1 improvement over baselines for NER under domain shift

## Executive Summary
This paper tackles the problem of named entity recognition (NER) under domain shift between biomedical and chemical domains, where standard transfer learning often mislabels source domain entities as target domain entities when they co-occur. The authors propose a two-stage metric learning approach that first enriches entity representations using event annotations and groups similar entities via multi-similarity contrastive loss, then uses pseudo-labeling to detect out-of-domain entities and separate target entities from these source-like entities. Evaluated across three source and three target datasets, the method achieves significant improvements in F1 score, particularly in recall for target entities while reducing false positives from source entities.

## Method Summary
The proposed method addresses domain shift in NER through a two-stage approach. First, entity grouping in the source domain enriches entity representations using event annotations and groups similar entities via multi-similarity contrastive loss. Second, entity discrimination in the target domain employs pseudo-labeling to detect likely out-of-domain entities and uses multi-similarity loss to separate target entities from these pseudo-labeled source-like entities. This approach effectively projects source and target entities into separate regions of the feature space, improving domain-specific entity recognition under few-shot conditions.

## Key Results
- Achieved up to 5% absolute improvement in F1 score over baselines
- Particularly strong gains in recall for target entities while reducing false positives from source entities
- Effective feature space separation between source and target entities

## Why This Works (Mechanism)
The method works by leveraging metric learning to create distinct feature space regions for source and target domain entities. The two-stage approach first learns rich representations of source entities through event-based grouping, then uses these learned representations to identify and separate out-of-domain entities in the target domain. The multi-similarity contrastive loss ensures that similar entities are pulled together while dissimilar ones are pushed apart, creating clear boundaries between domain-specific entity types.

## Foundational Learning
- **Metric Learning**: Why needed - to create meaningful distance metrics between entity representations; Quick check - verify distance between same-type entities is smaller than cross-type
- **Contrastive Loss**: Why needed - to push apart dissimilar entities while pulling similar ones together; Quick check - ensure loss decreases during training
- **Pseudo-labeling**: Why needed - to identify likely out-of-domain entities without manual annotation; Quick check - validate pseudo-label accuracy against ground truth
- **Event Annotations**: Why needed - to enrich entity representations with contextual information; Quick check - confirm event features improve entity clustering
- **Domain Shift**: Why needed - to understand how entity distributions change between domains; Quick check - measure feature space overlap between domains

## Architecture Onboarding

### Component Map
Entity Representations -> Multi-similarity Contrastive Loss -> Entity Grouping -> Pseudo-labeling -> Entity Discrimination -> Final NER Model

### Critical Path
The critical path is: Entity Representations → Multi-similarity Contrastive Loss → Entity Grouping → Entity Discrimination → Final NER Model. This sequence is essential because the contrastive loss and grouping stages must complete before pseudo-labeling can effectively identify out-of-domain entities in the target domain.

### Design Tradeoffs
- Using event annotations improves entity representation quality but limits applicability to domains where such annotations exist
- Pseudo-labeling reduces manual annotation needs but introduces potential noise from incorrect labels
- Multi-similarity loss provides better separation than standard contrastive loss but increases computational complexity

### Failure Signatures
- If pseudo-labels are inaccurate, target entities may be incorrectly pushed away from their true cluster
- Insufficient event annotations lead to poor entity representation quality in the grouping stage
- Overly aggressive contrastive loss may create artificial boundaries that harm generalization

### First Experiments
1. Verify feature space separation improves after each stage using t-SNE visualization
2. Test pseudo-label accuracy on a validation set before applying to target domain
3. Measure impact of removing event annotations on final NER performance

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to biomedical and chemical domains with only three source and three target datasets
- Pseudo-labeling step could introduce noise if initial predictions are inaccurate
- Unclear performance with larger labeled datasets or in zero-shot scenarios

## Confidence
- **High**: Overall effectiveness in reducing false positives and improving recall (based on F1 score improvements and qualitative feature space analysis)
- **Medium**: Generalizability to other domains or tasks (limited scope of evaluation)
- **Low**: Robustness of pseudo-labeling step and its impact on overall performance (not thoroughly examined)

## Next Checks
1. Test the method on a broader range of domain pairs and NLP tasks to assess generalizability
2. Conduct ablation studies to quantify the contribution of each component and evaluate the impact of noisy pseudo-labels
3. Compare computational efficiency and resource requirements against standard transfer learning baselines