---
ver: rpa2
title: Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled Data
arxiv_id: '2405.18929'
source_url: https://arxiv.org/abs/2405.18929
tags:
- anomaly
- data
- detection
- anomalies
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses semi-supervised anomaly detection with contaminated
  unlabeled data, where existing methods degrade in performance due to the presence
  of anomalies in the unlabeled set. The authors propose PUAE, a novel framework based
  on positive-unlabeled learning that approximates normal data scores using both unlabeled
  and anomaly data.
---

# Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled Data

## Quick Facts
- arXiv ID: 2405.18929
- Source URL: https://arxiv.org/abs/2405.18929
- Reference count: 40
- Outperforms existing methods on MNIST, FashionMNIST, SVHN, CIFAR10 with up to 97.1% AUROC

## Executive Summary
This paper addresses semi-supervised anomaly detection where unlabeled training data contains both normal and anomalous samples. Traditional PU learning methods fail in this setting because they cannot properly handle contamination in the unlabeled set. The authors propose PUAE, a framework that approximates normal data scores using both unlabeled and anomaly data, enabling anomaly detector training without labeled normal data while minimizing scores for normal data and maximizing for anomalies.

## Method Summary
PUAE is built on positive-unlabeled learning principles and leverages two key components: an encoder-decoder architecture and a normal data approximation module. The method trains anomaly detectors like autoencoders and DeepSVDD without requiring labeled normal data by using both unlabeled and anomaly data to approximate normal data scores. This allows the model to minimize scores for normal data while maximizing them for anomalies, making it applicable to various anomaly detection frameworks.

## Key Results
- Achieves up to 97.1% AUROC on MNIST
- Outperforms existing methods (IF, AE, DeepSVDD, LOE, ABC, DeepSAD, SOEL, PU) in most cases
- Handles both seen and unseen anomalies effectively
- Shows consistent improvement across MNIST, FashionMNIST, SVHN, and CIFAR10 datasets

## Why This Works (Mechanism)
The method works by addressing the contamination problem in unlabeled data through positive-unlabeled learning principles. By approximating normal data scores using both unlabeled and anomaly data, PUAE can effectively train anomaly detectors without labeled normal data. The framework minimizes scores for normal data while maximizing them for anomalies, creating a robust separation between normal and anomalous patterns.

## Foundational Learning
- **Positive-Unlabeled Learning**: Needed because traditional PU learning fails with contaminated unlabeled data. Quick check: Verify that the method properly handles the unlabeled set containing both normal and anomalous samples.
- **Anomaly Detection with Contaminated Data**: Required to address the real-world scenario where unlabeled data contains anomalies. Quick check: Ensure the framework can distinguish between normal and anomalous patterns in mixed datasets.
- **Encoder-Decoder Architectures**: Essential for learning compressed representations of normal data. Quick check: Confirm the autoencoder component effectively reconstructs normal samples.
- **Score Approximation**: Needed to estimate normal data scores without labeled normal data. Quick check: Validate that the approximation module accurately estimates normal data characteristics.

## Architecture Onboarding
**Component Map**: Encoder -> Approximator -> Anomaly Detector -> Decoder

**Critical Path**: The encoder extracts features from input data, which are then processed by the normal data approximation module. These approximated scores are used to train the anomaly detector, with the decoder providing reconstruction feedback for autoencoder-based implementations.

**Design Tradeoffs**: The method trades computational complexity for robustness to contamination. By using both unlabeled and anomaly data for approximation, it gains resilience but requires careful hyperparameter tuning. The framework can be applied to various detectors but may need adaptation for different anomaly detection paradigms.

**Failure Signatures**: Poor performance on datasets with high contamination ratios or when anomalies are very similar to normal data. The method may also struggle with extreme class imbalance or when the approximation module fails to capture normal data characteristics.

**First Experiments**:
1. Test on MNIST with varying contamination ratios (1%, 5%, 10%) to assess sensitivity
2. Compare PUAE with standard autoencoder on contaminated vs. clean unlabeled data
3. Evaluate performance when anomalies are structurally similar to normal samples

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Limited evaluation to image datasets (MNIST, FashionMNIST, SVHN, CIFAR10) without testing on real-world tabular or time-series data
- Acknowledged hyperparameter sensitivity with limited analysis of parameter impact
- Unclear behavior with different contamination ratios and anomaly types in practical applications

## Confidence
- **High confidence** in the theoretical framework of PUAE and its ability to handle contaminated unlabeled data
- **Medium confidence** in the claimed superiority over existing methods, as results are primarily benchmark-based and may not generalize to real-world scenarios
- **Medium confidence** in the applicability to various anomaly detectors, though the experiments focus mainly on autoencoders and DeepSVDD

## Next Checks
1. Evaluate PUAE on real-world tabular and time-series datasets with varying contamination ratios to assess practical applicability
2. Conduct ablation studies to quantify the impact of each component of the PUAE framework and identify critical hyperparameters
3. Test the method's performance when anomalies and normal data come from significantly different distributions than the training data