---
ver: rpa2
title: Crafting Personalized Agents through Retrieval-Augmented Generation on Editable
  Memory Graphs
arxiv_id: '2409.19401'
source_url: https://arxiv.org/abs/2409.19401
tags:
- memory
- memories
- data
- user
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel task of crafting personalized agents
  powered by large language models (LLMs) that leverage users' smartphone memories
  to enhance downstream applications. To address this task, the authors propose EMG-RAG,
  which combines Retrieval-Augmented Generation (RAG) techniques with an Editable
  Memory Graph (EMG) optimized using Reinforcement Learning.
---

# Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs

## Quick Facts
- arXiv ID: 2409.19401
- Source URL: https://arxiv.org/abs/2409.19401
- Authors: Zheng Wang; Zhongyang Li; Zeren Jiang; Dandan Tu; Wei Shi
- Reference count: 39
- Primary result: EMG-RAG achieves approximately 10% improvement over the best existing approach for personalized agents using smartphone memories

## Executive Summary
This paper introduces a novel task of crafting personalized agents powered by large language models (LLMs) that leverage users' smartphone memories to enhance downstream applications. The authors propose EMG-RAG, which combines Retrieval-Augmented Generation (RAG) techniques with an Editable Memory Graph (EMG) optimized using Reinforcement Learning. The approach addresses three key challenges: data collection, editability, and selectability. Extensive experiments on a real-world dataset demonstrate significant improvements in performance across three downstream applications, and the personalized agents have been successfully transferred to a real smartphone AI assistant.

## Method Summary
The EMG-RAG solution combines RAG techniques with an Editable Memory Graph (EMG) optimized using Reinforcement Learning to craft personalized agents. The system collects smartphone memories (conversations and screenshots), processes them into a three-layer hierarchical graph structure, and uses an RL agent to adaptively select relevant memories for generating answers with a frozen LLM. The method involves data collection and cleaning, EMG construction with entity recognition and relation extraction, RL agent training through warm-start and policy gradient stages, and evaluation across downstream applications including question answering, autofill forms, and user services.

## Key Results
- Achieves approximately 10% improvement over the best existing approach across three downstream applications
- Successfully transferred to a real smartphone AI assistant with enhanced usability
- Demonstrates effective handling of data collection, editability, and selectability challenges

## Why This Works (Mechanism)

### Mechanism 1
The Editable Memory Graph (EMG) improves retrieval accuracy by using a graph structure to capture complex relationships between memories, enabling more effective selection of relevant memories for generation. The EMG organizes memories into a hierarchical tree structure combined with a graph structure that captures entity relationships, allowing the RL agent to traverse the graph and select relevant memories based on question context.

### Mechanism 2
Reinforcement Learning optimizes memory selection by maximizing the quality of generated answers through iterative refinement. An RL agent traverses the EMG using a Markov Decision Process (MDP), where states are defined by cosine similarities between question entities/relations and memory nodes, actions are binary decisions to include or exclude memories, and rewards are based on answer quality improvement.

### Mechanism 3
Editability through the EMG structure enables continuous updates to user memories while maintaining retrieval quality. The three-layer EMG structure supports insertion, deletion, and replacement operations by first locating the relevant memory subclass partition, then performing the edit operation based on relation comparison with the nearest memory.

## Foundational Learning

- **Retrieval-Augmented Generation (RAG)**: Combines retrieval-based methods (access to external knowledge) with generation-based methods (natural language output), enabling the system to answer questions using user-specific memories. *Quick check*: How does RAG differ from traditional retrieval-based QA systems that only return documents?

- **Reinforcement Learning (RL)**: Optimizes the memory selection process by learning a policy that maximizes answer quality through trial-and-error interactions with the environment. *Quick check*: What are the key components of a Markov Decision Process used in RL?

- **Graph Neural Networks (GNNs)**: Effectively process the EMG structure to capture complex relationships between memories and improve retrieval quality. *Quick check*: How do GNNs differ from traditional neural networks in processing graph-structured data?

## Architecture Onboarding

- **Component map**: Data Collection -> Memory extraction (GPT-4) -> QA pair generation (GPT-4) -> EMG Construction (MTL, MSL, MGL layers) -> RL Agent Training -> Inference with EMG-RAG -> Application-specific processing

- **Critical path**: Data Collection → EMG Construction → RL Agent Training → Inference with EMG-RAG → Application-specific processing

- **Design tradeoffs**: 
  - Graph structure vs flat storage: Graph provides better relationship capture but adds complexity
  - RL vs heuristic selection: RL can learn optimal policies but requires more training time
  - Frozen LLM vs fine-tuning: Frozen LLM preserves general capabilities but may limit task-specific optimization

- **Failure signatures**:
  - Poor retrieval quality: Graph traversal may not find relevant memories or may include too many irrelevant memories
  - Slow inference: Large EMG size or inefficient graph traversal algorithms
  - Unstable training: Noisy reward signals or poor exploration-exploitation balance in RL

- **First 3 experiments**:
  1. Compare RAG with and without EMG structure on a small dataset to validate graph benefits
  2. Test different RL algorithms (e.g., REINFORCE vs PPO) for memory selection optimization
  3. Evaluate editability operations on EMG by measuring retrieval quality before and after edits

## Open Questions the Paper Calls Out

### Open Question 1
How does the EMG-RAG system handle privacy concerns when multiple users share similar memory patterns? While the paper suggests sharing common subgraph patterns across users' EMGs to reduce storage costs, it doesn't provide details on how privacy is maintained in such scenarios or how user-specific data is protected.

### Open Question 2
What are the computational and storage trade-offs when increasing the number of activated nodes (K) in the EMG-RAG system? The paper only provides a limited range of K values (1 to 5) and doesn't explore the full spectrum of possible K values or their impact on computational and storage resources.

### Open Question 3
How does the EMG-RAG system adapt to new domains or memory types that were not part of the initial training data? While the paper suggests the system can be expanded to new categories, it doesn't provide details on how the system adapts to new domains or memory types, or how the RL agent is retrained or fine-tuned for these new domains.

## Limitations
- Lack of direct empirical comparisons between graph-based and non-graph-based memory representations
- Scalability of the EMG structure to extremely large memory sets remains untested
- Specific mechanisms by which graph structure and RL optimization improve performance lack direct empirical validation

## Confidence

- **High confidence**: The overall framework of combining RAG with EMG and RL is well-specified and technically sound
- **Medium confidence**: The claimed 10% improvement over existing approaches is supported by experimental results, though the specific comparison methodology could be more detailed
- **Low confidence**: The specific mechanisms by which the graph structure and RL optimization improve performance lack direct empirical validation

## Next Checks

1. Conduct ablation studies comparing EMG-RAG against a non-graph baseline (e.g., traditional RAG with flat memory storage) to quantify the exact contribution of the graph structure to performance gains
2. Perform stress tests on the EMG structure by gradually increasing memory volume to identify scalability limits and degradation points in retrieval quality
3. Implement and evaluate alternative memory selection strategies (e.g., heuristic-based vs RL-based) to isolate the contribution of the reinforcement learning component to overall performance