---
ver: rpa2
title: Integrating Large Language Models with Graph-based Reasoning for Conversational
  Question Answering
arxiv_id: '2407.09506'
source_url: https://arxiv.org/abs/2407.09506
tags:
- graph
- evidence
- question
- conversational
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of conversational question answering
  over multiple heterogeneous sources, including text, tables, knowledge graphs, and
  infoboxes. The proposed method leverages large language models (LLMs) by integrating
  them with graph-based reasoning.
---

# Integrating Large Language Models with Graph-based Reasoning for Conversational Question Answering

## Quick Facts
- arXiv ID: 2407.09506
- Source URL: https://arxiv.org/abs/2407.09506
- Reference count: 23
- Key outcome: Graph embeddings directly injected into LLM bypassing token layers achieve higher H@1 and H@5 on ConvMix conversational QA dataset

## Executive Summary
This paper addresses conversational question answering over multiple heterogeneous sources (text, tables, knowledge graphs, infoboxes) by integrating large language models with graph-based reasoning. The approach constructs dynamic evidence graphs from retrieved sources and injects graph embeddings directly into the LLM, bypassing token embedding layers. A memory module tracks and re-uses past evidence to improve retrieval quality and reduce topic drift. Experiments on the ConvMix benchmark show the graph-based approach outperforms baselines, with the memory module providing additional robustness against noise and retrieval errors.

## Method Summary
The method retrieves evidence from heterogeneous sources using CLOCQ for Wikidata and BM25 for Wikipedia, then constructs a dynamic graph by linearizing each evidence piece into a local subgraph and connecting them through common entities. Graph node embeddings are initialized using LLM token embeddings and processed through Graph Attention Networks to learn graph representations. These embeddings are injected into the LLM by concatenating with prompt embeddings, bypassing the token embedding layer entirely. A memory module maintains past evidence, which is re-ranked against current queries and can replace lower-ranked new evidence. The model is fine-tuned end-to-end with cross-entropy loss using parameter-efficient LoRA training on Mistral-7B.

## Key Results
- Model with graph embeddings and memory outperforms variants without either component on ConvMix dataset
- Higher precision at 1 (H@1) and precision at 5 (H@5) achieved compared to baseline approaches
- Memory module improves robustness against noise and retrieval errors, particularly in conversations with topic inertia
- Graph structure enhances reasoning ability across multiple heterogeneous sources compared to processing evidence independently

## Why This Works (Mechanism)

### Mechanism 1
Graph embeddings bypass the token embedding layer and are injected directly into the LLM, allowing the model to leverage structured evidence without retraining token representations. By skipping the token embedding layer, learned graph embeddings are concatenated with prompt embeddings and fed directly into the LLM. This avoids the need to retrain the entire model and preserves semantic alignment between the graph structure and LLM's learned representations. The core assumption is that token embeddings from the base LLM are sufficiently aligned with graph node embeddings so that direct concatenation preserves meaningful semantic relationships.

### Mechanism 2
The memory module reuses past evidence to improve retrieval quality and reduce topic drift during conversations. At each turn, the model maintains a memory of previously retrieved evidence. This memory is re-ranked against the current query, and a proportion of the lowest-ranked new evidence is replaced with top-ranked evidence from memory. This allows the model to leverage relevant past information and avoid topic drift. The core assumption is that past evidence is likely to be relevant to current queries, especially in conversations with topic inertia.

### Mechanism 3
Graph-based reasoning enhances the LLM's ability to reason over multiple heterogeneous sources compared to processing evidence independently. By organizing evidence into a graph, the model can capture global relationships between entities and evidence pieces. This allows for more effective reasoning and conflict resolution compared to processing each piece of evidence independently. The core assumption is that the relationships between entities and evidence pieces are crucial for effective reasoning and cannot be captured by processing evidence independently.

## Foundational Learning

- **Graph Neural Networks (GNNs)**: Used to learn graph embeddings representing structured evidence; crucial for capturing relationships between entities and evidence pieces. Quick check: How do GNNs differ from traditional neural networks in terms of their ability to handle graph-structured data?

- **Retrieval-Augmented Generation (RAG)**: The paradigm used in this work where LLM is conditioned on retrieved evidence; understanding RAG is crucial for understanding how graph-based evidence is integrated with the LLM. Quick check: What are the key components of a RAG system, and how do they interact?

- **Conversational Question Answering**: The task being addressed over multiple heterogeneous sources; understanding challenges and requirements is crucial for understanding design choices. Quick check: What are the key challenges in conversational question answering compared to traditional question answering?

## Architecture Onboarding

- **Component map**: Evidence Retrieval -> Graph Construction -> Graph Encoder -> LLM Integration -> Answer Generation
- **Critical path**: Evidence Retrieval uses CLOCQ and BM25 -> Graph Construction creates local subgraphs connected by entities -> Graph Encoder learns embeddings via GAT -> LLM Integration injects embeddings by bypassing token layers -> Answer Generation produces final response
- **Design tradeoffs**: Using memory module vs. retrieving new evidence at each turn (memory can improve quality but may introduce noise); bypassing token embeddings vs. retraining entire LLM (more efficient but may limit learning new relationships)
- **Failure signatures**: Poor retrieval quality (low H@1/H@5 scores for specific information); ineffective graph construction (low performance on questions requiring multi-evidence reasoning); memory module introducing noise (decreased performance on conversations with frequent topic shifts)
- **First 3 experiments**: 1) Evaluate memory module impact by comparing performance with/without it on conversations with different topic inertia levels; 2) Analyze graph structure effect by comparing with variant processing evidence independently; 3) Investigate impact of number of retrieved evidence instances on performance and graph construction efficiency

## Open Questions the Paper Calls Out

- **Multilingual Performance**: How would the proposed model perform on conversational QA datasets in languages other than English? The authors acknowledge only evaluating on English ConvMix dataset and express interest in examining multilingual or cross-lingual datasets. This remains unresolved as the paper provides no experiments or results on non-English datasets.

- **Prompting Techniques**: What is the impact of different prompting techniques on the proposed model's performance for conversational QA? The authors mention not conducting an in-depth study on prompts despite observing Mistral-7B outperformed Llama2-7B. This impact remains unmeasured as the paper does not explore various prompting strategies.

- **Pretrained Embeddings for Entity Linking**: How does the proposed model's performance on conversational QA tasks change when using pretrained embeddings for better entity linking? The authors suggest improving information retrieval by using pretrained embeddings for better entity linking as a potential future direction. This remains unresolved as the paper does not explore this approach.

## Limitations

- Architecture integration details for bypassing token embeddings are not fully specified, creating uncertainty about exact implementation
- Memory module effectiveness lacks ablation studies showing performance degradation when removed
- Graph construction scalability for large conversations with many evidence instances is not addressed

## Confidence

- **High Confidence**: Core experimental results showing improved H@1 and H@5 performance over baselines on ConvMix dataset
- **Medium Confidence**: Mechanism claims about bypassing token embeddings and specific integration approach
- **Medium Confidence**: Effectiveness of memory module in reducing topic drift and improving retrieval quality

## Next Checks

1. **Memory Module Ablation Study**: Run experiments with and without memory module across conversations with varying topic inertia levels to quantify when memory helps versus hurts performance, measuring both retrieval quality metrics and final answer accuracy.

2. **Graph Embedding Dimensionality Analysis**: Systematically vary dimensionality of graph embeddings (e.g., 64, 128, 256, 512) and measure impact on performance to determine if benefits are robust across different embedding sizes.

3. **Cross-Modality Performance Isolation**: Analyze performance separately for each evidence type (text, tables, knowledge graphs, infoboxes) to identify which modalities benefit most from graph-based approach and whether certain types introduce noise.