---
ver: rpa2
title: 'Multi-Sensor Object Anomaly Detection: Unifying Appearance, Geometry, and
  Internal Properties'
arxiv_id: '2412.14592'
source_url: https://arxiv.org/abs/2412.14592
tags:
- anomaly
- detection
- infrared
- dataset
- point
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MulSen-AD, the first multi-sensor anomaly
  detection dataset for industrial quality inspection, integrating RGB images, infrared
  thermography, and 3D point clouds. The dataset covers 15 industrial products with
  14 real-world anomaly types, enabling detection of surface, internal, and geometric
  defects.
---

# Multi-Sensor Object Anomaly Detection: Unifying Appearance, Geometry, and Internal Properties

## Quick Facts
- arXiv ID: 2412.14592
- Source URL: https://arxiv.org/abs/2412.14592
- Reference count: 40
- AUROC of 96.1% achieved for object-level anomaly detection using multi-sensor fusion

## Executive Summary
This paper introduces MulSen-AD, the first multi-sensor anomaly detection dataset for industrial quality inspection, integrating RGB images, infrared thermography, and 3D point clouds. The dataset covers 15 industrial products with 14 real-world anomaly types, enabling detection of surface, internal, and geometric defects. The authors propose MulSen-TripleAD, a decision-level fusion algorithm that combines these three modalities using memory banks and a gating unit. Experiments show that multi-sensor fusion achieves 96.1% AUROC in object-level anomaly detection, significantly outperforming single-sensor methods (91.1%-90.9%).

## Method Summary
The MulSen-TripleAD model uses pretrained feature extractors (DINO for RGB/IR, PointMAE for point clouds) to extract representations from each modality. These features are compared against memory banks of normal samples using a PatchCore-style scoring approach. A decision gating unit (OCSVM-inspired) then combines the three modality-specific anomaly scores into a final object-level prediction. The system operates in an unsupervised setting, learning only from normal samples to identify deviations that represent anomalies.

## Key Results
- Multi-sensor fusion achieves 96.1% AUROC in object-level anomaly detection
- Single-sensor performance: RGB (91.1%), infrared (90.9%), point cloud (66.8%)
- 9.4% of anomalies detected solely by RGB sensor, 9.2% by infrared, 4.3% by point cloud
- The dataset contains 15 industrial products with 14 real-world anomaly types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-sensor fusion captures a broader range of anomaly types than any single sensor can detect alone.
- Mechanism: Each sensor modality (RGB, infrared, point cloud) captures different defect characteristics—RGB for surface appearance, infrared for subsurface/internal defects, and point cloud for geometric deformations. By combining these complementary signals, the system can detect anomalies that would be invisible to any single sensor.
- Core assumption: The defect types present in industrial products are sufficiently diverse that no single sensor can capture all relevant information.
- Evidence anchors:
  - [abstract] "traditional single-sensor methods face critical limitations. They fail to capture the wide range of anomaly types, as single sensors are often constrained to either external appearance, geometric structure, or internal properties."
  - [section] "The Venn diagram in Figure 4 demonstrates the distribution of anomalies detected by the RGB, infrared, and point cloud sensors in the MulSen-AD dataset. Non-overlapping regions highlight each sensor's ability to capture specific anomalies independently, such as the 9.4% of anomalies detected solely by the RGB sensor, 9.2% by infrared, and 4.3% by point cloud."

### Mechanism 2
- Claim: Decision-level fusion with a gating unit effectively combines modality-specific anomaly scores to produce robust final predictions.
- Mechanism: Each sensor's memory bank computes anomaly scores based on deviation from normal data, then a learnable gating unit (OCSVM-inspired) combines these scores at the decision level. This allows the system to weigh each modality's contribution based on its reliability for the current object.
- Core assumption: The individual sensor modalities can be evaluated independently and their results meaningfully combined through a gating mechanism.
- Evidence anchors:
  - [section] "MulSen-TripleAD model, by leveraging complementary information from three distinct modalities—RGB, infrared, and point cloud—achieves significantly better overall performance than previous SOTA models, which rely on single-modality data."
  - [section] "Our experiments demonstrate that multi-sensor fusion substantially outperforms single-sensor approaches, achieving 96.1% AUROC in object-level detection accuracy."

### Mechanism 3
- Claim: Using pretrained feature extractors (DINO for RGB/IR, PointMAE for point clouds) provides strong representations for anomaly detection.
- Mechanism: The pretrained transformers have learned rich feature representations from large-scale pretraining, which can then be adapted to anomaly detection by comparing test samples to normal samples stored in memory banks.
- Core assumption: Features learned from large-scale pretraining on ImageNet (DINO) and ShapeNet (PointMAE) are transferable to the industrial anomaly detection domain.
- Evidence anchors:
  - [section] "For robust feature extraction, we leverage pretrained PointMAE [25] for point clouds and DINO [39] for RGB and infrared data."
  - [section] "The memory bank follows the Patchcore [26] setup, while the decision gating unit adopts the M3DM [34] configuration."

## Foundational Learning

- Concept: Anomaly detection in unsupervised settings
  - Why needed here: The system must identify defects without labeled examples of what constitutes an anomaly, requiring it to learn only from normal samples.
  - Quick check question: How does the system distinguish between normal variations and actual defects without any labeled anomaly examples?

- Concept: Memory-based anomaly detection (like PatchCore)
  - Why needed here: The system uses memory banks of normal samples to compare against test samples, enabling detection of deviations from normal patterns.
  - Quick check question: What is the role of the memory bank in computing anomaly scores, and how does it differ from traditional reconstruction-based methods?

- Concept: Decision-level vs. feature-level fusion
  - Why needed here: Understanding why decision-level fusion was chosen over feature-level fusion, and the tradeoffs involved in this architectural choice.
  - Quick check question: What are the advantages and disadvantages of decision-level fusion compared to feature-level fusion in multi-sensor systems?

## Architecture Onboarding

- Component map:
  - Input layer: RGB images, infrared images, point clouds
  - Feature extractors: DINO (RGB/IR), PointMAE (point clouds)
  - Memory banks: One per modality (Mrgb, Mir, Mpc)
  - Anomaly scoring: Patch-Core-style scoring per modality
  - Decision gating unit: OCSVM-inspired gating
  - Output: Object-level anomaly label

- Critical path: Sensor input → Feature extraction → Memory bank comparison → Individual anomaly scores → Decision gating → Final anomaly prediction

- Design tradeoffs:
  - Decision-level fusion vs. feature-level fusion: Decision-level is simpler and more robust to modality-specific preprocessing differences, but may miss cross-modal interactions.
  - Pretrained transformers vs. custom feature extractors: Pretrained models provide strong initial representations but may require adaptation to industrial domain.
  - Memory-based vs. generative approaches: Memory banks are efficient and don't require generative modeling, but may struggle with complex normal variations.

- Failure signatures:
  - Low performance on certain object categories: May indicate that one sensor modality is particularly weak for those objects.
  - Degraded performance when sensors are degraded: The gating unit may not handle missing or noisy sensor data well.
  - Poor generalization to new object types: The system may be overfit to the 15 object categories in the dataset.

- First 3 experiments:
  1. Evaluate single-sensor performance for each modality to understand individual strengths and weaknesses.
  2. Test dual-sensor combinations (RGB+IR, RGB+PC, IR+PC) to quantify the benefits of pairwise fusion.
  3. Test the impact of different memory bank sizes and sampling strategies on detection performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the inclusion of additional sensing modalities, such as X-ray or ultrasonic sensors, affect the performance of multi-sensor anomaly detection?
- Basis in paper: [explicit] The authors note that the dataset lacks deeper-sensing modalities like X-ray, which could enhance detection of internal anomalies, and suggest this as a limitation.
- Why unresolved: The paper does not explore the impact of adding X-ray or other modalities to the existing multi-sensor framework.
- What evidence would resolve it: Conducting experiments with the inclusion of X-ray or ultrasonic data in the MulSen-AD framework to measure changes in anomaly detection accuracy.

### Open Question 2
- Question: How can feature-level and modality-level fusion strategies be developed to improve the generalization and performance of multi-sensor anomaly detection systems?
- Basis in paper: [inferred] The authors suggest that decision-level fusion may miss important cross-modal interactions and propose exploring feature- and modality-level fusion as future work.
- Why unresolved: The current MulSen-TripleAD model relies on decision-level fusion, and the potential benefits of other fusion strategies are not tested.
- What evidence would resolve it: Implementing and comparing feature-level and modality-level fusion methods within the MulSen-AD framework to assess their impact on detection performance.

### Open Question 3
- Question: What are the potential benefits and challenges of extending the MulSen-AD dataset and methods to few-shot, zero-shot, and cross-domain anomaly detection scenarios?
- Basis in paper: [explicit] The authors identify the need to explore few-shot, zero-shot, and cross-domain settings as future research directions.
- Why unresolved: The current focus is on unsupervised anomaly detection, and the effectiveness of the dataset and methods in other learning paradigms is untested.
- What evidence would resolve it: Designing and evaluating experiments that apply the MulSen-AD dataset and methods to few-shot, zero-shot, and cross-domain anomaly detection tasks.

## Limitations

- The results are based on a single dataset of 15 industrial products, limiting generalizability to all industrial settings
- Decision-level fusion may not capture complex cross-modal interactions that feature-level fusion could potentially exploit
- The system may struggle with sensor degradation or missing modalities, as the gating unit's handling of such scenarios is not fully explored

## Confidence

- High confidence: The dataset creation methodology and basic performance improvements from multi-sensor fusion (AUROC of 96.1% vs 91.1%-90.9% for single sensors)
- Medium confidence: The specific contribution of each sensor modality and the effectiveness of the decision-level gating mechanism
- Medium confidence: The generalizability of the results to industrial settings beyond the 15 product categories in the dataset

## Next Checks

1. **Cross-dataset validation**: Test the MulSen-TripleAD model on external industrial datasets (such as Kaputt or other defect detection benchmarks) to verify generalization beyond the MulSen-AD dataset.

2. **Ablation study of fusion components**: Systematically evaluate the contribution of each component in the fusion pipeline (memory banks, gating unit, feature extractors) through controlled ablation experiments.

3. **Robustness to sensor degradation**: Evaluate system performance when individual sensors are degraded or noisy, testing the gating unit's ability to handle missing or unreliable modalities.