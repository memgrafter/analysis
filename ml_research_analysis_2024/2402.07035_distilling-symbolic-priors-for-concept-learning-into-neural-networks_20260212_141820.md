---
ver: rpa2
title: Distilling Symbolic Priors for Concept Learning into Neural Networks
arxiv_id: '2402.07035'
source_url: https://arxiv.org/abs/2402.07035
tags:
- learning
- neural
- network
- concept
- rules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Humans can learn new concepts from a few examples by using inductive
  biases, which have previously been captured using Bayesian models with symbolic
  representations. This work explores whether neural networks can display the same
  inductive biases.
---

# Distilling Symbolic Priors for Concept Learning into Neural Networks

## Quick Facts
- arXiv ID: 2402.07035
- Source URL: https://arxiv.org/abs/2402.07035
- Reference count: 6
- Humans can learn new concepts from few examples using inductive biases captured by Bayesian models; this work shows neural networks can develop similar biases through meta-learning.

## Executive Summary
This paper demonstrates that neural networks can develop human-like inductive biases for concept learning by meta-learning to internalize Bayesian priors. The authors use meta-learning (specifically MAML) to train a neural network on tasks where each task involves learning one sampled concept from a Rational Rules grammar. This approach allows the neural network to develop the same inductive biases as Bayesian models, enabling it to learn structured concepts from limited examples in ways that mirror human learning. The method is evaluated on several behavioral experiments where humans learned logical concepts, showing that the meta-trained neural network displays generalization behavior highly aligned with both humans and the Bayesian model, while a standard neural network does not.

## Method Summary
The core approach involves meta-training a neural network on a large set of concept learning tasks. Specifically, concepts are sampled from a Rational Rules grammar (DNF logical formulas), and for each concept, a training set of labeled examples (up to 20 examples) and a test set containing all possible objects are generated. The neural network is then meta-trained using MAML across these 10,000 sampled concepts, with 1 epoch per episode during training. The meta-training process uses learning rates of 0.0005 (outer) and 0.1 (inner), with an MLP architecture of 5 layers, hidden size 128/256, and dropout 0.1. The key innovation is that this meta-training allows the neural network to internalize the Bayesian prior distribution, enabling it to learn new concepts from few examples with human-like generalization patterns.

## Key Results
- The prior-trained network achieved an R² of 0.95 when compared to human performance on the Medin & Schaffer (1978) category structure experiment, versus an R² of 0 for a standard network
- The meta-trained neural network displayed generalization behavior highly aligned with both humans and the Rational Rules Bayesian model across multiple behavioral experiments
- Standard neural networks failed to capture human-like inductive biases and showed no correlation with human performance (R² ≈ 0) on these concept learning tasks

## Why This Works (Mechanism)
The meta-learning approach works by exposing the neural network to a diverse set of concept learning tasks during training, where each task involves learning a concept sampled from the Rational Rules grammar. Through this exposure, the network learns to generalize from few examples in ways that reflect the underlying structure of the concept space. The MAML algorithm specifically enables the network to adapt quickly to new concepts by learning good initial parameters that can be fine-tuned with minimal data. This process effectively distills the Bayesian prior distribution (which captures human inductive biases) into the neural network's parameters, allowing it to make similar generalization judgments as humans when learning new concepts.

## Foundational Learning
- **Rational Rules Grammar**: A context-free grammar that generates DNF logical formulas representing concepts; needed to sample structured concepts for meta-training, quick check: verify grammar generates diverse logical concepts
- **Meta-learning (MAML)**: A learning algorithm that enables fast adaptation to new tasks by learning good initialization parameters; needed to train on multiple concept learning tasks efficiently, quick check: confirm MAML updates both inner and outer loop parameters correctly
- **Bayesian Priors**: Probability distributions over hypotheses that encode inductive biases; needed as the target distribution to be distilled into the neural network, quick check: ensure sampled concepts reflect the Rational Rules prior distribution
- **DNF Formulas**: Disjunctive Normal Form logical expressions used to represent concepts; needed as the symbolic representation for concepts in the Rational Rules model, quick check: verify DNF evaluation produces correct truth values for all objects

## Architecture Onboarding
**Component Map**: Concept Sampler -> Data Generator -> MAML Trainer -> Evaluation Pipeline -> Human Data Comparison
**Critical Path**: The most important sequence is: sample concepts from Rational Rules grammar → generate training/test sets → meta-train neural network using MAML → evaluate on behavioral experiments → compare with human data
**Design Tradeoffs**: The approach trades computational expense (requiring meta-training on 10,000 concepts) for the ability to develop human-like inductive biases; an alternative would be to hard-code symbolic rules but this would lack flexibility
**Failure Signatures**: Standard network showing R² ≈ 0 on behavioral experiments indicates failure to capture inductive biases; poor performance on meta-training suggests issues with MAML implementation or concept sampling
**First Experiments**: 1) Verify baseline MLP matches human data performance when given full training sets; 2) Test meta-trained network on a simple concept not seen during training; 3) Compare predictions of prior-trained vs standard network on a held-out concept

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several implications arise from the work:
- How can the approach handle continuous feature spaces instead of just Boolean features?
- What are the computational limitations of the meta-learning approach for larger concept spaces?
- How can the method be adapted to handle noisy or ambiguous training data?

## Limitations
- The approach relies on specific Bayesian grammars (Rational Rules) that may not generalize to all concept domains
- Meta-training requires sampling and training on 10,000 concepts, which is computationally expensive
- Performance on some behavioral experiments showed only moderate correlations (R² values ranging from 0.4-0.8), not matching the strongest results

## Confidence
- **High confidence**: Prior-trained networks outperform standard networks on behavioral generalization tasks
- **Medium confidence**: The specific mechanisms by which meta-learning captures Bayesian priors are fully characterized
- **Medium confidence**: Results generalize beyond the specific experimental paradigms tested

## Next Checks
1. Replicate the full set of behavioral experiments with different random seeds to establish robustness of the R² correlations
2. Test whether the prior-trained network can transfer to novel concept structures not seen during meta-training
3. Compare computational efficiency against other approaches for integrating symbolic knowledge into neural networks (e.g., program synthesis methods)