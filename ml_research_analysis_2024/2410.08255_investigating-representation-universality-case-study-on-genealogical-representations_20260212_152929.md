---
ver: rpa2
title: 'Investigating Representation Universality: Case Study on Genealogical Representations'
arxiv_id: '2410.08255'
source_url: https://arxiv.org/abs/2410.08255
tags:
- arxiv
- representations
- llms
- preprint
- representation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models encode graph-structured
  knowledge in universal geometric patterns. The authors study genealogical (descendant-of)
  relationships through two complementary approaches.
---

# Investigating Representation Universality: Case Study on Genealogical Representations

## Quick Facts
- arXiv ID: 2410.08255
- Source URL: https://arxiv.org/abs/2410.08255
- Authors: David D. Baek; Yuxiao Li; Max Tegmark
- Reference count: 20
- Key outcome: LLMs exhibit universal geometric structures for genealogical relationships through tree-like cone embeddings across diverse architectures

## Executive Summary
This paper investigates whether large language models encode graph-structured knowledge in universal geometric patterns by studying genealogical (descendant-of) relationships. The authors identify tree-like "cone" subspaces in residual stream activations and verify their causal role through activation patching across five different models. They also conduct model stitching experiments across diverse architectures and sizes to quantify representational alignment through next-token prediction loss degradation. The key finding is that LLMs do exhibit universal geometric structures for graph representations - specifically, cone embeddings that mirror tree-like hierarchies emerge consistently across models, with early-to-mid layer representations showing better alignment than later layers.

## Method Summary
The authors generate synthetic genealogical data using binary trees with 15 nodes and create prompts with ordered family descriptions and descendant-of questions. They train a cone probe on residual stream activations at the target token, using PCA dimensionality reduction to 10D before fitting the probe. Activation patching experiments transfer representations between prompts while measuring logit changes to verify causal effects. Model stitching connects early layers of one model to later layers of another using trainable linear adapters, with stitching layers trained for 10,000 steps using AdamW optimizer with learning rate 10^-3 and weight decay 10^-4.

## Key Results
- Cone embeddings that mirror tree-like hierarchies emerge consistently across LLaMA-3.1-8B, LLaMA-3-8B, LLaMA-3.2-3B, Gemma-2-2B, and Gemma-2-9B models
- Activation patching confirms cone subspaces have strong causal effects on answering genealogical questions, comparable to or larger than top principal components
- Model stitching reveals better alignment in early-to-mid layers across different architectures, supporting the "stages of inference" hypothesis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cone embeddings represent genealogical relationships through geometric containment in a fixed cone space
- Mechanism: The model encodes descendant-of relationships by placing nodes in a tree-like subspace where child nodes lie within a cone emanating from parent nodes
- Core assumption: Tree-structured knowledge can be represented as geometric containment relationships in a fixed-dimensional space
- Evidence anchors:
  - [abstract] "identify tree-like 'cone' subspaces in residual stream activations using a cone probe"
  - [section] "cone embeddings that mirror tree-like hierarchies emerge consistently across models"
  - [corpus] Weak evidence - related works focus on representation universality but not specifically cone geometries
- Break condition: If genealogical relationships involve cycles or non-tree structures, the cone containment assumption breaks down

### Mechanism 2
- Claim: Model stitching reveals representational alignment through early-to-mid layer compatibility
- Mechanism: By connecting early layers of one model to later layers of another via trainable adapters, the experiment measures how well representations align across different architectures
- Core assumption: Equivalent processing stages across different models produce similar representations
- Evidence anchors:
  - [abstract] "model stitching experiments across diverse architectures and sizes"
  - [section] "representations from different models align more closely in early to mid layers than in later layers"
  - [corpus] Moderate evidence - related works on representation alignment exist but lack specific model stitching approaches
- Break condition: If models process information through fundamentally different mechanisms, early-to-mid layer alignment will be poor

### Mechanism 3
- Claim: Causal interventions confirm that cone subspaces have direct influence on question-answering performance
- Mechanism: Activation patching transfers representations between prompts while measuring logit changes
- Core assumption: Changes in specific subspaces will directly affect model outputs in predictable ways
- Evidence anchors:
  - [abstract] "activation patching to verify its causal effect"
  - [section] "patching the cone-probe subspace alone produces a logit shift that is comparable to or larger than patching the top two principal components"
  - [corpus] Weak evidence - causal analysis techniques exist but not specifically applied to genealogical representations
- Break condition: If the model uses distributed representations or if other subspaces compensate for missing cone information

## Foundational Learning

- Concept: Geometric representation learning
  - Why needed here: The paper relies on identifying tree-like geometric structures in activation spaces, requiring understanding of how discrete relationships map to continuous geometric embeddings
  - Quick check question: How would you represent a parent-child relationship using vector geometry?

- Concept: Activation patching and causal analysis
  - Why needed here: The paper uses intervention experiments to verify that identified subspaces have causal effects on model outputs
  - Quick check question: What does it mean if patching a subspace produces a large logit shift in the correct direction?

- Concept: Model stitching methodology
  - Why needed here: The paper compares representations across different models by connecting their layers, requiring understanding of how to measure representational alignment
  - Quick check question: Why would you expect early layers to align better than later layers across different models?

## Architecture Onboarding

- Component map:
  Cone probe -> Activation patching system -> Model stitching framework -> Evaluation pipeline

- Critical path:
  1. Generate genealogical tree data and format for in-context learning
  2. Run models on genealogical questions to collect activations
  3. Train cone probe on collected activations
  4. Perform activation patching experiments
  5. Set up model stitching across different architectures
  6. Analyze alignment patterns and causal effects

- Design tradeoffs:
  - PCA dimensionality reduction vs. full-space analysis (computational efficiency vs. information loss)
  - Linear adapters vs. nonlinear mapping in model stitching (simplicity vs. expressiveness)
  - Small trees vs. large genealogies (controllability vs. realism)

- Failure signatures:
  - Poor cone probe performance indicates either lack of geometric structure or insufficient dimensionality
  - High stitching loss suggests fundamental representational differences between models
  - Inconsistent activation patching results may indicate distributed representations

- First 3 experiments:
  1. Train cone probe on small genealogical tree and visualize resulting embeddings
  2. Perform activation patching between clean and corrupted genealogical prompts
  3. Stitch embedding layers of two similar-sized models and measure loss increase

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do LLM representations of genealogical relationships maintain tree-like geometric structures for larger trees beyond 15 nodes, or do these structures break down or transform as tree size increases?
- Basis in paper: [explicit] The authors note their current study is limited to relatively small trees (15 nodes) and state "it remains unclear whether similar causal, tree-like subspaces emerge in larger or more complex genealogies"
- Why unresolved: The paper only tests trees with 15 nodes, and the authors acknowledge that model performance degrades significantly with increasing graph size
- What evidence would resolve it: Testing cone probe emergence and causal effects on trees with 100+ nodes, and examining whether cone probe accuracy and causal effects scale with tree size

### Open Question 2
- Question: What is the relationship between the tree-like cone subspace identified by the cone probe and the actual mechanisms LLMs use to answer genealogical questions (circuit analysis)?
- Basis in paper: [explicit] The authors state "we focus solely on the internal geometry and universality of LLM representations – without examining how these subspaces are actually leveraged by the model for answering questions, more well known as circuit analysis"
- Why unresolved: The paper identifies the cone subspace and proves its causal effect, but doesn't investigate how the model actually uses this information to generate answers
- What evidence would resolve it: Mechanistic interpretability analysis tracing how information flows from the cone subspace through the network layers to produce final answers

### Open Question 3
- Question: How do LLMs represent more complex genealogical relationships beyond direct descendant-of (such as cousins, aunts, uncles) in terms of geometric structures?
- Basis in paper: [explicit] The authors state "One could systematically investigate the optimal representations of more complex genealogical relationships – such as cousins, aunts, and uncles"
- Why unresolved: The paper only examines the simple descendant-of relationship, but acknowledges that more complex relationships exist and may have different optimal representations
- What evidence would resolve it: Training probes for different genealogical relationships and comparing their geometric structures

### Open Question 4
- Question: How do LLMs represent uncertainty when answering genealogical questions, and can this uncertainty representation be interpreted mechanistically?
- Basis in paper: [explicit] The authors observe that "LLMs rarely express full confidence in their answers to descendant-of questions, even for relatively small trees" and suggest applying mechanistic interpretability techniques to study uncertainty representation
- Why unresolved: The paper notes the observation of LLMs' uncertainty but doesn't investigate how this uncertainty is represented internally
- What evidence would resolve it: Analyzing activation patterns, attention distributions, or other internal representations that correlate with uncertainty in genealogical question answering

## Limitations
- Limited to tree-structured genealogical relationships with only 15 nodes, representing a narrow subset of graph-structured knowledge
- Evidence for geometric universality relies heavily on synthetic data rather than naturally occurring graph representations in LLMs
- Sample size of five models is limited compared to the vast landscape of LLM architectures and training approaches

## Confidence
- Medium confidence: The identification of cone subspaces in residual activations and their causal effects on genealogical question-answering performance
- Low confidence: The broader claim of universal geometric patterns across all graph-structured knowledge representations in LLMs
- Medium confidence: The observation that early-to-mid layer representations align better across different models

## Next Checks
1. Test cone probe robustness on non-tree graphs by applying the methodology to genealogical data containing cycles or multiple relationship types
2. Expand model diversity and size range by conducting experiments across a wider range of architectures and scales from 100M to 70B parameters
3. Validate with naturally occurring graph data by analyzing activations from models processing real-world graph-structured text like knowledge base queries and network descriptions