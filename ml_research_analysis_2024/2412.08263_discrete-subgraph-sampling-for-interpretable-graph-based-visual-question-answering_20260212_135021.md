---
ver: rpa2
title: Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering
arxiv_id: '2412.08263'
source_url: https://arxiv.org/abs/2412.08263
tags:
- question
- answer
- methods
- sampling
- subgraph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces discrete subgraph sampling methods into graph-based
  visual question answering (GVQA) to generate interpretable explanations intrinsically.
  The authors integrate four methods - IMLE, AIMLE, SIMPLE, and GUMBEL SOFT SUB-ST
  - into a GVQA system and evaluate their effectiveness on the GQA dataset.
---

# Discrete Subgraph Sampling for Interpretable Graph based Visual Question Answering

## Quick Facts
- arXiv ID: 2412.08263
- Source URL: https://arxiv.org/abs/2412.08263
- Authors: Pascal Tilli; Ngoc Thang Vu
- Reference count: 40
- Key outcome: Discrete subgraph sampling methods achieve over 94% accuracy in GVQA while generating intrinsically interpretable explanations

## Executive Summary
This paper introduces discrete subgraph sampling methods into graph-based visual question answering (GVQA) systems to generate intrinsically interpretable explanations. The authors integrate four sampling methods—IMLE, AIMLE, SIMPLE, and GUMBEL SOFT SUB-ST—into a GVQA framework and evaluate their effectiveness on the GQA dataset. The results show that AIMLE achieves over 94% accuracy while producing explanations that strongly correlate with human preferences. The study demonstrates that discrete subgraph sampling can effectively balance interpretability and answer accuracy in GVQA systems.

## Method Summary
The paper integrates discrete subset sampling methods into a graph-based visual question answering system to generate interpretable explanations intrinsically. The approach uses CLIP text token embeddings for scene graph encoding and employs different discrete sampling methods (IMLE, AIMLE, SIMPLE, GUMBEL SOFT SUB-ST) to select relevant subgraphs during training and inference. The models are trained with various batch sizes and evaluated using answer accuracy, Answer Token Co-occurrence (AT-COO), and Question Token Co-occurrence (QT-COO) metrics. The methods work by computing prior scores between question representations and node embeddings, then sampling discrete subsets of nodes to form masked graphs for answer prediction.

## Key Results
- AIMLE achieves over 94% answer accuracy while generating highly interpretable explanations
- AIMLE and SIMPLE methods outperform IMLE and GUMBEL SOFT SUB-ST in both accuracy and co-occurrence metrics
- AT-COO and QT-COO metrics strongly correlate with human preferences in comparative evaluation
- AIMLE requires minimal hyperparameter tuning while SIMPLE needs more careful parameter selection

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Discrete subgraph sampling methods generate intrinsically interpretable explanations in GVQA.
- **Mechanism**: By sampling subgraphs directly during training and inference, the model learns to focus on the most relevant parts of the scene graph for answering questions, producing explanations that are inherently part of the prediction process rather than generated afterward.
- **Core assumption**: The sampled subgraph contains the necessary information to answer the question accurately while being interpretable to humans.
- **Evidence anchors**:
  - [abstract]: "We integrate different discrete subset sampling methods into a graph-based visual question answering system to compare their effectiveness in generating interpretable explanatory subgraphs intrinsically."
  - [section 2.1]: Describes the sampling process and how discrete subsets are selected from the scene graph based on question and node embeddings.
  - [corpus]: No direct evidence; the corpus papers focus on different aspects of GVQA interpretability but don't specifically address intrinsic subgraph sampling methods.
- **Break condition**: If the sampling process fails to capture relevant nodes, the explanations become uninformative and the answer accuracy drops significantly.

### Mechanism 2
- **Claim**: The AT-COO and QT-COO metrics effectively measure the quality of explanations generated by subgraph sampling methods.
- **Mechanism**: These metrics quantify how well the nodes in the sampled subgraph align with the answer tokens and question tokens, respectively, providing a quantitative measure of explanation quality that correlates with human preferences.
- **Core assumption**: High co-occurrence scores indicate that the explanation captures the relevant information for answering the question.
- **Evidence anchors**:
  - [abstract]: "We show that the integrated methods effectively mitigate the performance trade-off between interpretability and answer accuracy, while also achieving strong co-occurrences between answer and question tokens."
  - [section 3.2]: Reports strong correlations between AT-COO/QT-COO metrics and human preferences in the evaluation.
  - [corpus]: No direct evidence; the corpus papers don't discuss these specific co-occurrence metrics.
- **Break condition**: If the metrics don't correlate with human judgment, they fail to capture the aspects of explanation quality that matter to users.

### Mechanism 3
- **Claim**: Different discrete sampling methods (AIMLE, SIMPLE, GUMBEL SOFT SUB-ST) have varying effects on the balance between interpretability and answer accuracy.
- **Mechanism**: Each sampling method approximates the gradient of the discrete sampling process differently, affecting how well the model can learn to select relevant subgraphs while maintaining high answer accuracy.
- **Core assumption**: The sampling method's gradient approximation quality directly impacts the model's ability to balance explanation quality with answer accuracy.
- **Evidence anchors**:
  - [section 2.1]: Details the different sampling methods and their gradient computation approaches (e.g., AIMLE's adaptive perturbation, SIMPLE's marginal computation).
  - [section 3.1]: Shows that AIMLE and SIMPLE achieve higher answer accuracy and co-occurrence scores compared to IMLE and GUMBEL SOFT SUB-ST.
  - [corpus]: No direct evidence; the corpus papers don't compare these specific sampling methods in the GVQA context.
- **Break condition**: If a sampling method introduces too much bias or variance in the gradient estimates, it degrades both interpretability and answer accuracy.

## Foundational Learning

- **Concept**: Graph-based Visual Question Answering (GVQA)
  - **Why needed here**: Understanding how GVQA systems process scene graphs and generate answers is fundamental to implementing and evaluating the subgraph sampling methods.
  - **Quick check question**: What is the difference between using raw images and scene graphs as input in VQA systems?

- **Concept**: Discrete Subset Sampling Methods
  - **Why needed here**: The paper integrates several sampling methods (AIMLE, SIMPLE, GUMBEL SOFT SUB-ST) that approximate gradients for discrete sampling, which is crucial for training the model.
  - **Quick check question**: How does the GUMBEL SOFT SUB-ST method relax discrete sampling to make it differentiable?

- **Concept**: Co-occurrence Metrics (AT-COO and QT-COO)
  - **Why needed here**: These metrics are used to quantitatively evaluate the quality of the generated explanations by measuring alignment with answer and question tokens.
  - **Quick check question**: How is the Answer Token Co-occurrence (AT-COO) metric calculated from the subgraphs and answer tokens?

## Architecture Onboarding

- **Component map**: Question → Node Embeddings → Prior Scores → Sampling Module → Masked Graph → Answer Prediction
- **Critical path**: Question → Node Embeddings → Prior Scores → Sampling Module → Masked Graph → Answer Prediction
- **Design tradeoffs**:
  - Sampling method choice affects the balance between interpretability and accuracy
  - Fixed top-k vs. adaptive top-k sampling impacts explanation size and relevance
  - Batch size influences both accuracy and co-occurrence scores
- **Failure signatures**:
  - Low accuracy with high co-occurrence scores indicates explanations are good but not sufficient for accurate answers
  - High accuracy with low co-occurrence scores suggests the model is making correct predictions but explanations are uninformative
  - High variance in accuracy across runs indicates sensitivity to hyperparameters
- **First 3 experiments**:
  1. Implement the NONE baseline (no subgraph sampling) to establish the upper bound for accuracy.
  2. Implement AIMLE sampling with default hyperparameters to compare against the baseline.
  3. Implement SIMPLE sampling with varying batch sizes to observe the trade-off between accuracy and co-occurrence scores.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the discrete subgraph sampling methods perform on other multimodal datasets beyond GQA, such as CLEVR or Visual Genome?
- Basis in paper: [inferred] The paper only evaluates the methods on the GQA dataset using ground-truth scene graphs.
- Why unresolved: The authors did not test the methods on other datasets, leaving uncertainty about their generalizability.
- What evidence would resolve it: Running experiments on multiple datasets with varying scene graph qualities and question types would show how well the methods transfer across different visual question answering tasks.

### Open Question 2
- Question: What is the optimal dynamic top-k selection strategy that adapts to individual question complexity rather than using fixed top-k values?
- Basis in paper: [inferred] The paper mentions that fixed top-k sampling does not adapt to question complexity and could limit interpretability.
- Why unresolved: The authors did not propose or test any adaptive top-k selection mechanism, only comparing fixed values.
- What evidence would resolve it: Developing and evaluating an adaptive top-k mechanism that adjusts based on question length, complexity, or semantic content would demonstrate whether dynamic selection improves both accuracy and interpretability.

### Open Question 3
- Question: How do the subgraph sampling methods scale to larger scene graphs with hundreds of nodes, and what is the computational overhead?
- Basis in paper: [inferred] The paper does not discuss scalability to larger graphs or computational complexity analysis.
- Why unresolved: The authors only evaluated on GQA with relatively small scene graphs and did not analyze computational costs or scalability limits.
- What evidence would resolve it: Testing the methods on datasets with larger scene graphs and measuring training/inference time and memory usage would reveal scalability bottlenecks and practical limitations.

### Open Question 4
- Question: How do different subgraph sampling methods compare when using automatically generated scene graphs instead of ground-truth annotations?
- Basis in paper: [explicit] The paper acknowledges that ground-truth scene graphs contain errors and limit real-world applicability.
- Why unresolved: All experiments used ground-truth scene graphs, avoiding the challenge of working with noisy, automatically generated scene graphs.
- What evidence would resolve it: Evaluating the methods on automatically generated scene graphs from object detection and relationship prediction models would show how robust the sampling methods are to graph quality variations.

## Limitations
- The study focuses exclusively on the GQA dataset with scene graphs, limiting generalizability to other VQA settings
- The human evaluation used a relatively small participant pool and limited pairwise comparisons
- The comparison with other interpretable GVQA approaches was limited, making it difficult to position these methods within the broader landscape

## Confidence
**High Confidence Claims:**
- AIMLE and SIMPLE methods achieving higher answer accuracy and co-occurrence scores compared to IMLE and GUMBEL SOFT SUB-ST
- Strong correlation between AT-COO/QT-COO metrics and human preferences
- AIMLE requiring minimal hyperparameter tuning while SIMPLE needs careful parameter selection

**Medium Confidence Claims:**
- The claim that discrete subgraph sampling generates intrinsically interpretable explanations
- The effectiveness of fixed top-k sampling for better control over explanation subgraph size
- The superiority of AIMLE over other methods in terms of interpretability

**Low Confidence Claims:**
- The generalizability of results to other VQA datasets beyond GQA
- The long-term stability of the learned subgraph sampling mechanisms
- The comparison of these methods against all existing interpretable GVQA approaches

## Next Checks
1. **Cross-dataset validation**: Test the implemented methods on alternative VQA datasets (e.g., VQAv2, OK-VQA) that use raw images rather than scene graphs to assess generalizability beyond the GQA domain.

2. **Ablation study on sampling components**: Systematically remove or modify components of the sampling methods (e.g., test without fixed top-k, vary the CLIP embedding approach) to isolate which elements contribute most to performance improvements.

3. **Extended human evaluation**: Conduct a larger-scale human study with more participants and additional evaluation criteria (e.g., explanation completeness, relevance to specific question types) to strengthen the interpretability claims and validate the co-occurrence metrics across diverse question categories.