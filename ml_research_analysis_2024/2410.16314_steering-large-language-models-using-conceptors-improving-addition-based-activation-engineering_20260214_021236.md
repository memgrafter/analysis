---
ver: rpa2
title: 'Steering Large Language Models using Conceptors: Improving Addition-Based
  Activation Engineering'
arxiv_id: '2410.16314'
source_url: https://arxiv.org/abs/2410.16314
tags:
- steering
- layer
- activation
- conceptor
- beta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces conceptors as a novel method for steering
  large language models (LLMs) by projecting activation vectors using ellipsoidal
  regions instead of simple vector addition. Unlike traditional additive steering
  that translates activations with a fixed steering vector, conceptors capture complex
  activation patterns through soft projection matrices computed from sets of activation
  vectors.
---

# Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering

## Quick Facts
- arXiv ID: 2410.16314
- Source URL: https://arxiv.org/abs/2410.16314
- Authors: Joris Postmus; Steven Abreu
- Reference count: 40
- Key outcome: Conceptors outperform additive steering by capturing complex activation patterns through ellipsoidal projections, achieving higher accuracy on function tasks and superior composite function steering via Boolean operations.

## Executive Summary
This paper introduces conceptors as a novel method for steering large language models by projecting activation vectors using ellipsoidal regions instead of simple vector addition. Unlike traditional additive steering that translates activations with a fixed steering vector, conceptors capture complex activation patterns through soft projection matrices computed from sets of activation vectors. Experiments on GPT-J and GPT-NeoX models show that conceptor-based steering outperforms traditional additive methods across multiple function tasks (antonyms, capitalize, country-capital, english-french, present-past, singular-plural), achieving higher accuracy. Furthermore, combining conceptors using Boolean operations for composite functions outperforms additively combining steering vectors. These results demonstrate conceptors as a more precise and effective approach for activation engineering, offering improved control over LLM outputs without modifying model parameters.

## Method Summary
The paper proposes using conceptors for LLM steering by computing soft projection matrices from sets of activation vectors, which capture complex activation patterns better than simple steering vectors. The method involves extracting activations from in-context learning prompts, computing conceptors using the closed-form solution C = R(R + α^(-2)I)^(-1), and applying steering through matrix-vector multiplication. Mean-centering is employed to remove activation space bias by subtracting the mean activation vector from broader datasets. The approach is evaluated on GPT-J 6B and GPT-NeoX 20B models across six function tasks, with grid search over hyperparameters including layer selection, βadd, βc, and aperture parameter α. Boolean operations (AND, OR) on conceptors enable composite function steering, which is compared against additive vector combination.

## Key Results
- Conceptor-based steering outperforms additive steering on all six function tasks (antonyms, capitalize, country-capital, english-french, present-past, singular-plural) across GPT-J and GPT-NeoX models
- Mean-centering improves additive steering performance by up to 2x on the country-capital task
- Boolean operations on conceptors for composite functions outperform additively combining steering vectors
- Optimal performance occurs at different layers: layers 9-16 for GPT-J and layers 10-30 for GPT-NeoX

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conceptors outperform additive steering by capturing complex activation patterns through ellipsoidal projections rather than simple vector translation.
- Mechanism: Conceptors compute a soft projection matrix from sets of activation vectors, encoding correlations between activations. This matrix projects new activations toward the pattern represented by the principal directions of the original activation cloud, scaling components according to their importance in the pattern.
- Core assumption: The activation space of complex functions can be better represented as a region (ellipsoid) rather than a single point (steering vector).
- Evidence anchors:
  - [abstract] "Conceptors act as soft projection matrices and offer more precise control over complex activation patterns."
  - [section] "Conceptors can better capture the activation space of complex patterns compared to simple point representations, which discard information about correlations."
  - [corpus] Weak evidence - no directly comparable conceptor steering studies found.

### Mechanism 2
- Claim: Boolean operations on conceptors enable more effective composite function steering than arithmetic mean of steering vectors.
- Mechanism: The OR operation merges covariance matrices from different conceptors, creating a new conceptor that represents the union of activation patterns. The AND operation (via De Morgan's law) finds the intersection of activation patterns, allowing steering toward multiple functions simultaneously.
- Core assumption: Combining steering goals through Boolean operations on conceptors preserves the structural relationships between activation patterns better than simple vector addition.
- Evidence anchors:
  - [section] "We can combine multiple steering matrices using the conceptor Boolean operations... C1 ∧ C2 is computed using the correlation matrix (R−1 1 + R−1 2 )−1."
  - [abstract] "We further use Boolean operations on conceptors for combined steering goals that empirically outperform additively combining steering vectors on a set of tasks."
  - [corpus] Weak evidence - no comparable Boolean operation studies found in corpus.

### Mechanism 3
- Claim: Mean-centering improves steering effectiveness by removing activation space bias that dilutes task-specific signals.
- Mechanism: Subtracting the mean activation vector (computed over a broad dataset) from steering vectors/conceptors reduces the inherent anisotropy in LLM activation spaces, making the steering signal more focused on task-specific behavior.
- Core assumption: LLM activation vectors are systematically offset from the origin in a consistent direction that doesn't encode task-specific information.
- Evidence anchors:
  - [section] "Mean-centering attempts to mitigate this by subtracting the mean activation of a broader dataset that represents the general activation space of the model."
  - [section] "Mean-centering improves the performance of additive steering by as much as 2x (on the country-capital task)."
  - [corpus] Weak evidence - no directly comparable mean-centering studies found.

## Foundational Learning

- Concept: Matrix-vector multiplication as soft projection
  - Why needed here: Conceptor steering fundamentally operates through matrix-vector multiplication, which projects activations onto ellipsoidal regions rather than translating them.
  - Quick check question: Given a conceptor matrix C and activation vector x, what operation produces the steered activation?

- Concept: Eigenvalues and regularization in matrix inversion
  - Why needed here: The conceptor matrix computation involves eigenvalue decomposition and regularization through the aperture parameter α, which controls the trade-off between pattern representation and generalization.
  - Quick check question: How does the aperture parameter α affect the eigenvalues of the conceptor matrix?

- Concept: Boolean algebra on matrices
  - Why needed here: Combining conceptors for composite functions requires understanding Boolean operations (AND, OR, NOT) as defined on positive semi-definite matrices.
  - Quick check question: What matrix operation corresponds to the conceptor AND operation?

## Architecture Onboarding

- Component map: GPT-J/GPT-NeoX residual stream → conceptor computation (offline) → matrix-vector multiplication during inference → output generation
- Critical path: Activation caching → conceptor matrix computation → parameter tuning → inference-time steering
- Design tradeoffs: Conceptors provide better pattern capture but require O(n³) computation for n-dimensional activations; mean-centering adds preprocessing but improves accuracy
- Failure signatures: Steering degrades if aperture parameter is poorly chosen, if training data for mean-centering is unrepresentative, or if conceptor operations produce ill-conditioned matrices
- First 3 experiments:
  1. Implement basic conceptor steering on a single function (antonyms) without mean-centering to verify matrix computation and steering effectiveness
  2. Add mean-centering to the conceptor steering and compare performance gains
  3. Implement AND operation on two conceptors for a composite function and validate against baseline additive steering

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does conceptor steering scale to larger language models beyond 20 billion parameters, and does it maintain its performance advantage over additive steering?
- Basis in paper: [explicit] The paper concludes that "further research should be conducted to assess... the scalability to larger models."
- Why unresolved: The experiments only tested GPT-J (6B) and GPT-NeoX (20B) models, leaving the performance on larger models like GPT-3 (175B) or LLaMA-2 (70B) unknown.
- What evidence would resolve it: Conducting the same experiments on larger language models and comparing conceptor vs. additive steering performance across multiple model sizes.

### Open Question 2
- Question: What is the computational overhead of applying conceptor steering during inference, particularly when switching between multiple steering mechanisms?
- Basis in paper: [explicit] The paper mentions that "there may be an overhead cost for switching the conceptor steering on and off" but does not quantify this cost.
- Why unresolved: The paper acknowledges this as a potential limitation but does not provide empirical measurements of the switching overhead during auto-regressive generation.
- What evidence would resolve it: Measuring inference time and memory usage when applying conceptor steering with and without switching between different steering matrices.

### Open Question 3
- Question: How does the performance of conceptor-based steering on complex behaviors compare to its performance on simple function tasks?
- Basis in paper: [explicit] The paper states that "further research should be conducted to assess... the performance on more complex behaviors/tasks."
- Why unresolved: All experiments focused on simple function tasks (antonyms, capitalize, etc.), but the paper acknowledges that complex behaviors might behave differently.
- What evidence would resolve it: Testing conceptor steering on more complex tasks like summarization, translation, or multi-step reasoning problems and comparing results to additive methods.

## Limitations

- The paper lacks direct comparative studies in the corpus, making validation of claimed superiority over additive steering difficult
- Boolean operation claims for composite function steering lack empirical comparison with established vector combination methods
- Computational complexity of conceptor matrix operations (O(n³)) and practical scalability concerns are not discussed

## Confidence

**High Confidence**: The mathematical framework for conceptor computation using the closed-form solution C = R(R + α^(-2)I)^(-1) is well-established in the literature and the implementation details are clearly specified. The conceptor Boolean operations follow standard definitions for positive semi-definite matrices.

**Medium Confidence**: The empirical results showing conceptor superiority over additive steering on the tested function tasks appear methodologically sound, but the lack of comparable studies in the corpus makes it difficult to assess whether these results generalize to other domains or model architectures.

**Low Confidence**: The claims about Boolean operations for composite function steering outperforming additive vector combination lack comparative validation against alternative combination methods, and the theoretical justification for why conceptor operations preserve activation patterns better than vector addition is not provided.

## Next Checks

1. **External Benchmark Validation**: Test conceptor steering against at least three established activation engineering methods (e.g., feature-guided activation additions, contrastive activation engineering) on a held-out function task not used in the original experiments to verify generalization claims.

2. **Ablation Study on Mean-Centering**: Conduct controlled experiments removing mean-centering from both conceptor and additive steering methods across all six function tasks to quantify the specific contribution of this preprocessing step and determine whether improvements are consistent or task-dependent.

3. **Computational Complexity Analysis**: Measure wall-clock time and memory usage for conceptor computation and application across different activation dimensions (1024, 2048, 4096) and compare against additive steering to assess practical scalability for models larger than GPT-NeoX 20B.