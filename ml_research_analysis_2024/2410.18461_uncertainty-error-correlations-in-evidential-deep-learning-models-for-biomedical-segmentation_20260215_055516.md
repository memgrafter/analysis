---
ver: rpa2
title: Uncertainty-Error correlations in Evidential Deep Learning models for biomedical
  segmentation
arxiv_id: '2410.18461'
source_url: https://arxiv.org/abs/2410.18461
tags:
- uncertainty
- learning
- segmentation
- deep
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work evaluated Evidential Deep Learning (EDL) models for uncertainty
  quantification in biomedical image segmentation using cardiac and prostate MRI datasets.
  EDL models with U-Net backbones, which assign Dirichlet priors to segmentation labels,
  showed superior uncertainty-error correlations compared to conventional approaches
  like Shannon entropy, Monte-Carlo Dropout, and Deep Ensemble methods.
---

# Uncertainty-Error correlations in Evidential Deep Learning models for biomedical segmentation

## Quick Facts
- arXiv ID: 2410.18461
- Source URL: https://arxiv.org/abs/2410.18461
- Reference count: 32
- Primary result: EDL models with Dirichlet priors achieved superior uncertainty-error correlations (0.54-0.51) compared to baseline methods while maintaining similar Dice accuracy on cardiac and prostate MRI segmentation tasks.

## Executive Summary
This work evaluates Evidential Deep Learning (EDL) models for uncertainty quantification in biomedical image segmentation using cardiac and prostate MRI datasets. EDL models with U-Net backbones, which assign Dirichlet priors to segmentation labels, showed superior uncertainty-error correlations compared to conventional approaches like Shannon entropy, Monte-Carlo Dropout, and Deep Ensemble methods. Across both datasets, EDL achieved higher point-biserial uncertainty-error correlations while maintaining similar Dice coefficients to baseline models. Specifically, aleatoric uncertainty showed the strongest correlation for cardiac segmentation (0.54), while Dempster and epistemic uncertainties performed best for prostate (0.51). Uncertainty heatmaps generated by EDL models effectively identified potential regions of model errors. In active learning experiments, EDL-based uncertainty sampling achieved higher uncertainty-error correlations compared to Shannon entropy-based sampling while converging to similar Dice coefficients.

## Method Summary
The method employs a 2D U-Net backbone with a final layer producing two evidence variables (e1, e2) that parameterize Dirichlet distributions for segmentation outputs. The custom loss function combines Bayes risk, KL divergence regularization, and focal Dice loss terms with dataset-specific hyperparameters. Uncertainty is quantified through three measures: aleatoric (data uncertainty), epistemic (model uncertainty), and Dempster (scaled epistemic uncertainty). The model is trained for 800 epochs using Adam optimizer on NVIDIA A100 GPU, with uncertainty heatmaps computed from the evidence variables to identify potential segmentation errors.

## Key Results
- EDL achieved point-biserial uncertainty-error correlations of 0.54 (aleatoric) for cardiac and 0.51 (Dempster/epistemic) for prostate segmentation, outperforming Shannon entropy, MC Dropout, and Deep Ensemble baselines
- EDL models maintained Dice coefficients comparable to baseline models (0.94 cardiac, 0.81 prostate) while providing superior uncertainty quantification
- Uncertainty heatmaps effectively identified regions of model uncertainty that corresponded to segmentation errors
- In active learning experiments, EDL-based uncertainty sampling achieved higher uncertainty-error correlations than Shannon entropy sampling while converging to similar Dice coefficients

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Evidential Deep Learning (EDL) with Dirichlet priors improves uncertainty-error correlation by directly modeling the evidence for each class rather than relying on Monte Carlo sampling.
- Mechanism: EDL outputs non-negative evidence variables $e_i$ that are transformed into Dirichlet distribution parameters $\alpha_i = e_i + 1$. The model learns these parameters end-to-end, so the uncertainty (e.g., Dempster, epistemic, aleatoric) is intrinsically tied to the prediction confidence without requiring multiple stochastic forward passes.
- Core assumption: The Dirichlet distribution is a suitable higher-order prior for categorical segmentation outputs, and the learned evidence variables accurately reflect model uncertainty.
- Evidence anchors:
  - [abstract] "This class of models involves assigning Dirichlet distributions as priors for segmentation labels, and enables a few distinct definitions of model uncertainties."
  - [section 2] "In EDL, these parameters are incarnated as part of the model output which are thus naturally obtained when training is completed."
  - [corpus] Weak evidence—corpus neighbors do not directly address the Dirichlet prior mechanism.
- Break condition: If the Dirichlet prior poorly represents the true label distribution, the learned evidence will not correlate with actual errors.

### Mechanism 2
- Claim: EDL's Dempster uncertainty is effectively a scaled epistemic uncertainty, making it more interpretable for error detection.
- Mechanism: Dempster uncertainty $u_d$ is defined as $u_d = K \frac{\sum \alpha_i}{S}$ where $K$ is the number of classes. The paper shows this is proportional to epistemic uncertainty divided by aleatoric uncertainty, allowing clearer separation of model ignorance from data noise.
- Core assumption: The relationship $u_d = K \frac{u_e}{u_a}$ holds consistently across segmentation tasks and datasets.
- Evidence anchors:
  - [section 2] "Thus, up to an overall scaling factor K which is the number of class labels, the Dempster uncertainty ud is the epistemic uncertainty ue in units of the aleatoric uncertainty ua."
  - [abstract] "We found that the uncertainty heatmaps generated by EDL models can act as useful visual aids towards identifying potential regions of model errors."
  - [corpus] No direct evidence in corpus neighbors for this proportionality relationship.
- Break condition: If the scaling relationship does not hold for a given dataset, Dempster uncertainty will not be a reliable error indicator.

### Mechanism 3
- Claim: The custom loss function combining Bayes risk, KL divergence, and focal Dice loss optimizes both segmentation accuracy and uncertainty calibration.
- Mechanism: The total loss $L = L_{Bayes} + \lambda_{KL}L_{KL} + \lambda_{Dice}L_{Dice}$ balances mean-squared error over the Dirichlet distribution, regularization towards uniform distributions for incorrect labels, and a focal Dice term that emphasizes hard-to-segment regions.
- Core assumption: The hyperparameter values ($\lambda_{KL}=0.20, \lambda_{Dice}=0.15$ for cardiac; $\lambda_{KL}=0.20, \lambda_{Dice}=0.01$ for prostate) are optimal for both accuracy and uncertainty quality.
- Evidence anchors:
  - [section 3.1] "This deficiency was resolved after adding another focal Dice loss term defined as follows... The final form of our loss function is the sum..."
  - [abstract] "EDL achieved the same performance relative to all the other models for both datasets, indicating that segmentation accuracy was not compromised while having a more robust uncertainty quantification."
  - [corpus] No direct evidence in corpus neighbors for this specific multi-term loss design.
- Break condition: If the loss balance is incorrect, the model may sacrifice either accuracy or uncertainty calibration.

## Foundational Learning

- Concept: Dirichlet distribution as a conjugate prior for categorical/multinomial distributions
  - Why needed here: EDL models use Dirichlet priors to represent uncertainty over class probabilities, which is essential for computing evidential uncertainties.
  - Quick check question: What are the parameters of a Dirichlet distribution and how do they relate to the mean and variance of the categorical distribution?

- Concept: Point-biserial correlation coefficient
  - Why needed here: The paper uses point-biserial correlation to measure the relationship between binary error labels and continuous uncertainty values, which is critical for evaluating uncertainty quality.
  - Quick check question: How does the point-biserial correlation differ from Pearson correlation when one variable is dichotomous?

- Concept: Kolmogorov-Smirnov statistic
  - Why needed here: KS statistic is used to compare empirical cumulative distribution functions of uncertainties for correct vs. incorrect predictions, providing another measure of uncertainty-error correlation.
  - Quick check question: What does a large KS statistic indicate about the separation between two distributions?

## Architecture Onboarding

- Component map: Input image → U-Net feature extraction → Evidence variable output → Uncertainty computation → Loss calculation → Backpropagation
- Critical path: Input image → U-Net feature extraction → Evidence variable output → Uncertainty computation → Loss calculation → Backpropagation
- Design tradeoffs:
  - EDL vs MC Dropout: EDL provides uncertainty with single forward pass but requires custom loss; MC Dropout needs multiple forward passes but uses standard cross-entropy
  - Evidence variables vs softmax: Evidence variables can represent uncertainty directly but may be harder to interpret initially
  - Multi-term loss: Better calibration but more hyperparameters to tune
- Failure signatures:
  - Poor uncertainty-error correlation: Evidence variables not well-calibrated to actual errors
  - Overconfident predictions: KL regularization term may be too weak
  - Convergence issues: Focal Dice weight may be inappropriate for dataset difficulty
- First 3 experiments:
  1. Train baseline U-Net with standard cross-entropy loss and compare Dice coefficients to EDL
  2. Implement EDL with only Bayes risk loss (no KL or Dice terms) and measure uncertainty-error correlation
  3. Vary the focal Dice weight λDice systematically to find optimal balance between accuracy and uncertainty quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EDL-based uncertainty quantification compare to other methods for medical imaging tasks beyond segmentation, such as detection or classification?
- Basis in paper: [inferred] The paper focuses on segmentation tasks and notes that EDL models showed superior uncertainty-error correlations compared to baseline methods for this specific application.
- Why unresolved: The study only evaluated EDL models for segmentation tasks on cardiac and prostate MRI datasets. The effectiveness of EDL for other medical imaging tasks remains unexplored.
- What evidence would resolve it: Conducting experiments comparing EDL models to baseline methods for detection and classification tasks on various medical imaging datasets would provide evidence for the generalizability of EDL's superior uncertainty quantification.

### Open Question 2
- Question: Can the uncertainty heatmaps generated by EDL models be effectively used to guide human expert intervention in real-time clinical workflows?
- Basis in paper: [explicit] The paper suggests that uncertainty heatmaps can identify potential regions of model errors, enabling efficient human expert intervention.
- Why unresolved: While the paper demonstrates the correlation between uncertainties and errors, it does not provide direct evidence of the effectiveness of using these heatmaps in real-time clinical settings.
- What evidence would resolve it: Conducting user studies with medical professionals using EDL-generated uncertainty heatmaps to guide their decision-making in real-time clinical scenarios would provide evidence for their practical utility.

### Open Question 3
- Question: What are the optimal hyperparameter settings for the EDL model to achieve the best uncertainty-error correlation across different medical imaging tasks and datasets?
- Basis in paper: [explicit] The paper mentions that optimal values for hyperparameters λKL and λDice were found for the cardiac and prostate datasets.
- Why unresolved: The optimal hyperparameters may vary depending on the specific medical imaging task and dataset. The paper only explored a limited set of hyperparameters for two specific datasets.
- What evidence would resolve it: Performing a comprehensive hyperparameter search across a wide range of medical imaging tasks and datasets would provide insights into the optimal settings for achieving the best uncertainty-error correlation with EDL models.

## Limitations
- Limited to two biomedical datasets (cardiac and prostate MRI), which may not generalize to other anatomical structures or imaging modalities
- Hyperparameter selection for multi-term loss function appears dataset-specific and may require re-tuning for different applications
- Requires custom loss functions and infrastructure that may be less accessible than simpler uncertainty methods like MC Dropout

## Confidence
- **High confidence**: The superiority of EDL over Shannon entropy and MC Dropout for uncertainty-error correlation is well-supported by experimental results across both datasets
- **Medium confidence**: The claim that EDL maintains similar Dice accuracy while improving uncertainty quantification is supported, but exact numerical comparisons would benefit from additional baseline implementations
- **Medium confidence**: The effectiveness of EDL in active learning scenarios is demonstrated, but the study only examines one sampling strategy and could benefit from comparisons to other acquisition functions

## Next Checks
1. Test EDL models on additional biomedical segmentation datasets (e.g., liver, lung, brain) to verify generalization of uncertainty-error correlation improvements
2. Implement and compare alternative uncertainty quantification methods (Ensembles, Deep Ensembles) using identical U-Net backbones and training protocols
3. Conduct ablation studies on the multi-term loss function to quantify the individual contributions of Bayes risk, KL divergence, and focal Dice components to final performance