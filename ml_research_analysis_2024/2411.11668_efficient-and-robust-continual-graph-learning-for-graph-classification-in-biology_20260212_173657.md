---
ver: rpa2
title: Efficient and Robust Continual Graph Learning for Graph Classification in Biology
arxiv_id: '2411.11668'
source_url: https://arxiv.org/abs/2411.11668
tags:
- graph
- learning
- data
- tasks
- pscgl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of continual graph learning for
  graph classification in biology, where traditional GNNs suffer from catastrophic
  forgetting when adapting to new tasks. The authors propose Perturbed and Sparsified
  Continual Graph Learning (PSCGL), a framework that combines perturbed graph sampling,
  motif-based graph sparsification, and consistency training.
---

# Efficient and Robust Continual Graph Learning for Graph Classification in Biology

## Quick Facts
- arXiv ID: 2411.11668
- Source URL: https://arxiv.org/abs/2411.11668
- Reference count: 40
- Achieves 45.32% average performance on Enzymes dataset and 40.93% on Aromaticity dataset

## Executive Summary
This paper addresses catastrophic forgetting in continual graph learning for biological graph classification. The proposed Perturbed and Sparsified Continual Graph Learning (PSCGL) framework combines perturbed graph sampling, motif-based graph sparsification, and consistency training to maintain performance across sequential tasks while reducing computational overhead. The framework demonstrates significant improvements over baseline methods on two biological datasets and shows inherent robustness to graph backdoor attacks through its sparsification approach.

## Method Summary
PSCGL addresses continual graph learning by introducing three key mechanisms: perturbed graph sampling identifies critical data points through confidence averaging over perturbed graph versions, motif-based graph sparsification reduces storage by pruning nodes with low participation in key substructures, and consistency training stabilizes latent representations through MSE loss on augmented graphs. The framework uses a 2-layer GCN backbone and maintains a memory buffer of sparsified graphs from previous tasks, achieving both computational efficiency and robustness to backdoor attacks.

## Key Results
- PSCGL achieves 45.32% average performance on Enzymes dataset compared to 39.34% for next best method
- PSCGL achieves 40.93% average performance on Aromaticity dataset compared to 37.94% for next best method
- Sparsification reduces backdoor attack success rates by up to 70% on Enzymes dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Perturbed graph sampling with feature perturbations identifies more reliable and diverse replay samples than single-point confidence sampling.
- Mechanism: By averaging model confidence over multiple perturbed versions of each graph, PSCGL captures the stability of predictions in the neighborhood of the graph rather than relying on a single point estimate.
- Core assumption: Graph data with continuous or binary features can be meaningfully perturbed without destroying the underlying biological signal.
- Evidence anchors: [abstract] "We introduce a perturbed sampling strategy to identify critical data points that contribute to model learning..."
- Break condition: If perturbations destroy the core structural or chemical features that define the graph's class.

### Mechanism 2
- Claim: Motif-based graph sparsification removes backdoor triggers while preserving biologically meaningful substructures.
- Mechanism: By pruning nodes with low participation in key motifs, the sparsification process eliminates nodes that may contain injected triggers but don't contribute to essential biological patterns.
- Core assumption: Backdoor triggers are often added to peripheral nodes that don't participate in important motifs.
- Evidence anchors: [abstract] "Additionally, our PSCGL framework inherently defends against graph backdoor attacks..."
- Break condition: If backdoor triggers are embedded within or critical to important motifs.

### Mechanism 3
- Claim: Consistency training on augmented graphs stabilizes latent representations and improves cross-task discrimination.
- Mechanism: By adding an MSE loss between original and perturbed graph embeddings, the model learns representations that are invariant to small perturbations and more stable across tasks.
- Core assumption: The embedding space contains meaningful structure where small perturbations correspond to small changes in the representation.
- Evidence anchors: [section 3.5] "This consistency training helps the model to capture the inter-class variability..."
- Break condition: If the perturbation function creates representations that are too different from the original.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper addresses a core problem where GNNs lose performance on previous tasks when trained on new ones.
  - Quick check question: What happens to a neural network's performance on task A after it's trained on task B without any mitigation strategies?

- Concept: Graph neural networks and their message-passing mechanism
  - Why needed here: The framework builds on GNNs as the backbone model.
  - Quick check question: How does a 2-layer GCN compute node representations differently from a 1-layer GCN?

- Concept: Continual learning paradigms (replay-based, regularization-based, parameter-isolation)
  - Why needed here: The paper uses a memory-replay approach and compares against other paradigms.
  - Quick check question: What's the key difference between EWC (regularization-based) and GEM (memory-replay-based) in how they handle previous task knowledge?

## Architecture Onboarding

- Component map: Data → Perturbation sampling → Sparsification → Buffer storage → Training with consistency loss → Evaluation
- Critical path: Data flows through perturbation sampling to identify critical samples, undergoes sparsification for efficiency, gets stored in buffer, then training incorporates consistency loss for stable learning.
- Design tradeoffs:
  - Higher sparsification ratio reduces storage and computation but may hurt performance
  - More perturbations improve sampling reliability but increase computation time
  - Larger buffer budgets improve performance but increase memory requirements
  - Consistency training coefficient (α) balances original task loss vs. representation stability
- Failure signatures:
  - Performance degradation with high sparsification suggests triggers are in key motifs or legitimate features are being pruned
  - Low AP with perturbed sampling indicates perturbations are destroying meaningful features
  - High ASR despite sparsification suggests triggers are embedded in important motifs
  - Poor generalization across tasks may indicate consistency training is too restrictive
- First 3 experiments:
  1. Run PSCGL on Enzymes dataset with r=0.0 and b=10 to establish baseline performance
  2. Vary sparsification ratio (r=0.0, 0.3, 0.6) with fixed budget to find performance-storage tradeoff
  3. Test backdoor robustness by injecting triggers and measuring ASR across different sparsification levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the trade-off between graph sparsification ratio and model performance vary across different biological graph datasets with distinct structural characteristics?
- Basis in paper: [explicit] The paper discusses performance degradation as sparsity increases from r=0.0 to r=0.5 on Enzymes and Aromaticity datasets
- Why unresolved: The experiments only tested two biological datasets with relatively simple structures.
- What evidence would resolve it: Systematic experiments across diverse biological datasets measuring AP/AF at different sparsity levels.

### Open Question 2
- Question: What is the optimal balance between buffer budget size and sparsification ratio to maximize both storage efficiency and model robustness against backdoor attacks?
- Basis in paper: [explicit] Table III shows ASR decreases with higher sparsification but the interaction with buffer budget remains unclear
- Why unresolved: The paper shows individual effects of sparsification ratio and budget size on ASR, but doesn't explore their joint optimization.
- What evidence would resolve it: Multi-dimensional analysis varying both parameters simultaneously to identify Pareto-optimal combinations.

### Open Question 3
- Question: How does the perturbed graph sampling strategy perform when extended to structural perturbations in addition to feature perturbations?
- Basis in paper: [inferred] The paper explicitly chooses feature perturbation over structural perturbation due to concerns about maintaining biologically meaningful graph topology
- Why unresolved: The authors justify avoiding structural perturbation but don't empirically validate whether the performance gains would be preserved or enhanced.
- What evidence would resolve it: Controlled experiments comparing feature-only, structure-only, and combined perturbation strategies.

## Limitations
- Performance claims rely on sequential task setups that may not reflect realistic biological data distributions
- Perturbation parameters were optimized on 80% of the first task's data but the optimization procedure isn't detailed
- Backdoor defense mechanism assumes triggers are peripheral and non-motif-related, which may not hold for all attack strategies

## Confidence
- High confidence: The catastrophic forgetting problem in continual graph learning is well-established
- Medium confidence: The perturbed sampling mechanism's effectiveness depends on perturbation parameters that weren't fully detailed
- Low confidence: The backdoor defense claims assume specific attack patterns without testing diverse attack strategies

## Next Checks
1. Test PSCGL on datasets where backdoor triggers are embedded within important motifs to validate robustness under different attack scenarios
2. Conduct ablation studies varying perturbation parameters systematically to understand their impact on sampling quality
3. Evaluate the framework on biological datasets with more realistic task distributions rather than the artificial 2-class-per-task setup