---
ver: rpa2
title: Enhancing Counterfactual Explanation Search with Diffusion Distance and Directional
  Coherence
arxiv_id: '2404.12810'
source_url: https://arxiv.org/abs/2404.12810
tags:
- counterfactual
- distance
- diffusion
- coherence
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of generating more human-centric
  counterfactual explanations for AI model predictions. The authors propose CoDiCE,
  a framework that incorporates two novel biases: diffusion distance and directional
  coherence.'
---

# Enhancing Counterfactual Explanation Search with Diffusion Distance and Directional Coherence

## Quick Facts
- arXiv ID: 2404.12810
- Source URL: https://arxiv.org/abs/2404.12810
- Reference count: 40
- Key outcome: CoDiCE framework improves counterfactual explanation quality with diffusion distance and directional coherence biases, achieving 100% validity on Diabetes dataset

## Executive Summary
This paper introduces CoDiCE, a framework that enhances counterfactual explanations by incorporating two novel cognitive biases: diffusion distance and directional coherence. Diffusion distance improves feasibility by prioritizing transitions through interconnected data points along the data manifold, while directional coherence ensures joint feature changes align with expected marginal prediction changes. The framework is evaluated across multiple synthetic and real-world datasets, showing superior performance in validity, diffusion distance, and directional coherence compared to existing methods. The authors identify a fundamental trade-off between these two biases and propose balanced integration for optimal explanation quality.

## Method Summary
The CoDiCE framework uses genetic algorithm optimization to generate counterfactual explanations with an objective function combining validity, diffusion distance, sparsity, and directional coherence. The diffusion distance metric captures data manifold connectivity through transition probabilities, while directional coherence measures alignment between marginal and joint feature changes needed to flip model predictions. The method is evaluated on synthetic datasets (S-surface, Swiss roll) and real-world datasets (Diabetes, Breast Cancer, Adult, German, Compas, Energy consumption) with both continuous and mixed-type features.

## Key Results
- CoDiCE achieves 100% validity on the Diabetes dataset with a diffusion distance of 0.38
- The framework demonstrates improved performance across all evaluation metrics compared to baseline methods
- A fundamental trade-off exists between diffusion distance and directional coherence that requires balanced weight integration
- The approach shows robustness to data noise and high-dimensional settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion distance prioritizes transitions between data points that are interconnected through numerous short paths, improving counterfactual feasibility.
- Mechanism: Diffusion distance captures the connectivity and density of data points within the dataset by quantifying the ease of traversing the data landscape from one point to another, factoring in the multitude of potential paths and their associated probabilities. This approach identifies feasible counterfactuals through sequences of realistic transitions that favor in-distribution points.
- Core assumption: The data manifold has meaningful connectivity structure that reflects realistic transitions between points.
- Evidence anchors:
  - [abstract]: "diffusion distance effectively weights more those points that are more interconnected by numerous short-length paths"
  - [section]: "diffusion distance offers a nuanced understanding of the data manifold by prioritizing transitions between data points that are interconnected through numerous, short paths"
  - [corpus]: Weak - no corpus evidence found for diffusion distance specifically, but related work on manifold learning and graph-based methods supports the general concept
- Break condition: If the data manifold is highly disconnected or contains bottlenecks that separate clusters, diffusion distance may fail to find feasible paths between original points and counterfactuals.

### Mechanism 2
- Claim: Directional coherence ensures that joint feature changes align with expected marginal changes in model predictions, making explanations more intuitive.
- Mechanism: The directional coherence term quantifies the preference for alignment between joint and marginal directional changes in feature space necessary to achieve a counterfactual outcome. It counts the excess of features which have aligned marginal and joint directions to increase the model's prediction probability towards the desired outcome.
- Core assumption: Humans expect consistent relationships between individual feature changes and their collective impact on model predictions.
- Evidence anchors:
  - [abstract]: "directional coherence ensures that joint feature changes align with expected marginal changes in model predictions"
  - [section]: "Directional Coherence formulates a bias designed to maintain consistency between the marginal (one feature at a time) and joint (multiple features simultaneously) directions in feature space needed to flip the outcome"
  - [corpus]: Weak - no direct corpus evidence for directional coherence in counterfactual explanations, but related work on causal consistency supports the general principle
- Break condition: If the model exhibits complex non-linear interactions where marginal expectations don't align with joint effects, directional coherence may exclude valid counterfactuals.

### Mechanism 3
- Claim: The genetic algorithm optimization effectively balances multiple competing objectives (validity, diffusion distance, sparsity, directional coherence) in counterfactual search.
- Mechanism: The objective function combines loss, diffusion distance, sparsity, and directional coherence penalties weighted by hyperparameters. Genetic algorithm optimization explores the solution space to find counterfactuals that minimize this weighted sum while maintaining validity.
- Core assumption: The weighted combination of terms appropriately captures the relative importance of different explanation qualities.
- Evidence anchors:
  - [abstract]: "c = arg min {loss(f(x*), y) + λ1diffusion dist(x*, x) + λ2sparsity(x*, x) + λ3(1 - dcoherence(x*, x))}"
  - [section]: "The terms are weighted by hyperparameters λ1, λ2, and λ3, which can be adjusted or set to 0 if a particular constraint is not applicable"
  - [corpus]: Moderate - genetic algorithms are well-established for multi-objective optimization, though specific application to counterfactual explanations is novel
- Break condition: If the weight settings create conflicting objectives that cannot be simultaneously optimized, or if the genetic algorithm gets stuck in local optima.

## Foundational Learning

- Concept: Diffusion processes on graphs and random walks
  - Why needed here: The diffusion distance metric relies on understanding transition probabilities and stationary distributions in diffusion processes
  - Quick check question: What is the relationship between transition probability pt(x|z) and the number of paths between points x and z in t steps?

- Concept: Counterfactual explanation frameworks and evaluation metrics
  - Why needed here: The paper builds upon existing counterfactual methods and introduces novel evaluation metrics specific to the proposed approach
  - Quick check question: How does validity differ from other metrics like weighted L1 distance or directional coherence in evaluating counterfactual explanations?

- Concept: Genetic algorithm optimization for multi-objective problems
  - Why needed here: The counterfactual search is formulated as a multi-objective optimization problem solved using genetic algorithms
  - Quick check question: What are the key components of genetic algorithm optimization (selection, crossover, mutation) and how do they apply to counterfactual generation?

## Architecture Onboarding

- Component map: Data preprocessing (OneHotEncoding, standardization) -> Model training (logistic regression) -> Diffusion map construction -> Counterfactual search (genetic algorithm) -> Evaluation (multiple metrics)

- Critical path: Original instance → diffusion map construction → counterfactual search (genetic algorithm) → counterfactual generation → evaluation with multiple metrics

- Design tradeoffs:
  - Diffusion distance vs. traditional Lp distances: Better captures data manifold structure but computationally more expensive
  - Directional coherence vs. unconstrained search: Produces more intuitive explanations but may exclude valid counterfactuals in complex models
  - Genetic algorithm vs. gradient-based optimization: Better handles discrete changes and multiple objectives but slower convergence

- Failure signatures:
  - Low validity across all methods suggests issues with model training or data preprocessing
  - High variance in diffusion distance indicates highly skewed distributions or disconnected data manifolds
  - Low directional coherence suggests model non-linearities or inconsistent feature interactions

- First 3 experiments:
  1. Run on synthetic S-surface and Swiss roll datasets to visually verify diffusion distance captures manifold structure
  2. Compare CoDiCEdiff and CoDiCEL1 on Diabetes dataset to isolate effects of diffusion distance vs. directional coherence
  3. Perform ablation studies by varying λ weights to understand tradeoffs between diffusion distance and directional coherence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of diffusion distance in the counterfactual search objective function impact the robustness of explanations under varying conditions of data noise and model uncertainty?
- Basis in paper: [inferred] The paper mentions that diffusion distance is robust to noise, which is particularly valuable in high-dimensional settings, but does not explicitly explore its impact on the stability of counterfactual explanations under varying conditions of data noise and model uncertainty.
- Why unresolved: The paper does not provide empirical evidence or theoretical analysis on how diffusion distance affects the robustness of counterfactual explanations when faced with noisy data or uncertain models.
- What evidence would resolve it: Conducting experiments with synthetic datasets containing varying levels of noise and using different models with inherent uncertainties to evaluate the stability and robustness of counterfactual explanations generated using diffusion distance compared to other methods.

### Open Question 2
- Question: How does the trade-off between diffusion distance and directional coherence affect the diversity and applicability of counterfactual explanations across different user preferences and explanation modalities?
- Basis in paper: [explicit] The paper highlights a trade-off between diffusion distance and directional coherence, emphasizing the need for balanced integration to optimize explanation quality. However, it does not explore how this trade-off affects the diversity of explanations or their applicability to different user preferences and explanation modalities.
- Why unresolved: The paper does not provide empirical evidence or theoretical analysis on how the trade-off between diffusion distance and directional coherence influences the diversity of counterfactual explanations or their suitability for different user preferences and explanation modalities.
- What evidence would resolve it: Conducting user studies with different user groups to evaluate their preferences for counterfactual explanations generated with varying weights on diffusion distance and directional coherence. Additionally, exploring the impact of this trade-off on the applicability of explanations to different explanation modalities, such as textual, visual, or interactive explanations.

### Open Question 3
- Question: How can the proposed CoDiCE framework be extended to handle more complex data types, such as time-series or graph-structured data, while maintaining the benefits of diffusion distance and directional coherence?
- Basis in paper: [inferred] The paper focuses on tabular data with continuous and mixed-type features. However, it does not discuss how the CoDiCE framework can be adapted to handle more complex data types, such as time-series or graph-structured data.
- Why unresolved: The paper does not provide any insights or methodologies for extending the CoDiCE framework to handle data types beyond tabular data.
- What evidence would resolve it: Developing extensions of the CoDiCE framework to handle time-series data by incorporating temporal dependencies and graph-structured data by considering the graph topology. Evaluating the performance of these extensions on relevant datasets and comparing them to existing methods for counterfactual explanations on complex data types.

## Limitations

- The effectiveness heavily depends on proper tuning of λ weights for diffusion distance, sparsity, and directional coherence
- Diffusion distance assumptions may break down with highly disconnected data manifolds or complex decision boundaries
- Lack of user studies or psychological validation to confirm human-centricity of the proposed biases

## Confidence

**High confidence**: The core mathematical formulations for diffusion distance and directional coherence are clearly defined and theoretically sound. The evaluation metrics and experimental methodology follow established practices in explainable AI research.

**Medium confidence**: The empirical results demonstrate improved performance over baseline methods, but the improvements are dataset-dependent. The trade-off between diffusion distance and directional coherence suggests that optimal weight settings may vary significantly across different problem domains.

**Low confidence**: The paper claims human-centricity of the explanations, but lacks user studies or psychological validation to confirm that the proposed biases actually align with human reasoning patterns.

## Next Checks

1. **Ablation study on weight hyperparameters**: Systematically vary λ1, λ2, and λ3 across multiple orders of magnitude to understand sensitivity and identify robust weight configurations that work across diverse datasets.

2. **Stress test with complex decision boundaries**: Evaluate CoDiCE on datasets with non-linear, overlapping class boundaries (e.g., moons, circles) to assess performance when diffusion distance assumptions break down.

3. **User study validation**: Conduct a small-scale user study comparing CoDiCE explanations against baseline methods, measuring perceived interpretability and plausibility of counterfactuals by domain experts or target users.