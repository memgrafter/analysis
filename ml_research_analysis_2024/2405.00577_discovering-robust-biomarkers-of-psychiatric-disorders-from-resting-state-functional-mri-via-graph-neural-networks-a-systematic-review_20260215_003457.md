---
ver: rpa2
title: 'Discovering robust biomarkers of psychiatric disorders from resting-state
  functional MRI via graph neural networks: A systematic review'
arxiv_id: '2405.00577'
source_url: https://arxiv.org/abs/2405.00577
tags:
- graph
- features
- used
- studies
- they
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review synthesizes 65 studies applying graph neural
  networks (GNNs) to functional magnetic resonance imaging (fMRI) data for psychiatric
  disorder prediction. While GNNs show strong classification performance, the robustness
  of discovered biomarkers varies widely across studies.
---

# Discovering robust biomarkers of psychiatric disorders from resting-state functional MRI via graph neural networks: A systematic review

## Quick Facts
- arXiv ID: 2405.00577
- Source URL: https://arxiv.org/abs/2405.00577
- Reference count: 40
- Primary result: GNNs show strong classification performance for psychiatric disorders, but biomarker robustness varies widely with limited reproducibility across studies.

## Executive Summary
This systematic review synthesizes 65 studies applying graph neural networks (GNNs) to functional magnetic resonance imaging (fMRI) data for psychiatric disorder prediction. While GNNs demonstrate strong classification capabilities across disorders including ADHD, ASD, MDD, SZ, dementia, and PD, the robustness and reproducibility of discovered biomarkers remain major challenges. The review identifies key issues in prediction, attribution, and evaluation stages, highlighting that most identified biomarkers are disorder-specific rather than transdiagnostic. The authors propose a prediction-attribution-evaluation framework to guide future research toward discovering more robust and clinically meaningful biomarkers of neurological disorders.

## Method Summary
The review systematically analyzed 65 studies applying GNNs to fMRI data for psychiatric disorder classification. Studies were categorized by disorder type, GNN architecture (baseline vs. customized), graph construction method, explainability technique, and evaluation approach. The authors extracted key findings on classification performance, identified biomarkers, and reproducibility across studies. They synthesized patterns in methodological approaches, challenges encountered, and proposed a framework for future research to address limitations in biomarker discovery and validation.

## Key Results
- GNN models achieve strong classification performance across multiple psychiatric disorders but show limited biomarker reproducibility
- Reproducible biomarkers are restricted to a small subset of region-level features with few transdiagnostic biomarkers identified
- Lack of standardized reporting on salient features and objective robustness metrics hinders cross-study comparisons

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GNNs model functional connectivity (FC) matrices as graphs, enabling direct learning of brain network structure without hand-crafted features.
- Mechanism: Functional connectivity matrices are treated as adjacency matrices, with nodes representing brain regions and edges encoding correlation strength. GNNs apply message passing to propagate information through the network, capturing non-linear relationships.
- Core assumption: The underlying brain disorder manifests as changes in network topology or connection strength that are detectable by GNNs.
- Evidence anchors:
  - [abstract]: "Graph neural networks (GNN) have emerged as a popular tool for modelling functional magnetic resonance imaging (fMRI) datasets."
  - [section]: "fMRI datasets, especially FC matrices, are most naturally represented as graphs."
- Break condition: If disorder pathology is not network-based or changes are too subtle for GNNs to capture.

### Mechanism 2
- Claim: Feature attribution methods reveal which brain regions or connections contribute most to disorder classification, providing potential biomarkers.
- Mechanism: After training, explainability techniques (e.g., Integrated Gradients, attention scores, pooling weights) assign importance scores to features, highlighting regions/connections most influential in predictions.
- Core assumption: High attribution scores indicate biological relevance rather than model artifacts or noise.
- Evidence anchors:
  - [abstract]: "While GNNs show strong classification performance, the robustness of discovered biomarkers varies widely across studies."
  - [section]: "These explainers typically assign attribution scores to each feature, or identify important subgraphs that contribute most to the model's predictions."
- Break condition: If attribution scores reflect overfitting, noise, or dataset-specific artifacts rather than true disorder mechanisms.

### Mechanism 3
- Claim: Reproducible biomarkers across studies indicate robust disease mechanisms rather than methodological artifacts.
- Mechanism: When multiple independent studies identify the same brain regions or connections as important for a disorder, this suggests these features capture genuine disease-related changes.
- Core assumption: Different studies using different datasets, preprocessing pipelines, and GNN architectures can converge on the same biomarkers if they reflect true pathology.
- Evidence anchors:
  - [abstract]: "Reproducibility is limited to a small subset of region-level features, with few transdiagnostic biomarkers identified."
  - [section]: "Put together, future studies should consider evaluating the generalisability of these models to datasets other than ABIDE."
- Break condition: If lack of reproducibility stems from true biological heterogeneity rather than methodological issues.

## Foundational Learning

- Concept: Functional connectivity (FC) analysis
  - Why needed here: FC forms the basis of how brain networks are represented as graphs for GNN analysis.
  - Quick check question: How does Pearson correlation differ from partial correlation in measuring FC?

- Concept: Graph neural networks (GNNs) and message passing
  - Why needed here: GNNs are the primary modeling tool used to learn from brain network data.
  - Quick check question: What distinguishes spectral GNNs from spatial GNNs in their approach to convolution?

- Concept: Model explainability and feature attribution
  - Why needed here: Explainability methods are essential for extracting interpretable biomarkers from GNN predictions.
  - Quick check question: How do gradient-based attribution methods differ from perturbation-based methods?

## Architecture Onboarding

- Component map: fMRI data preprocessing -> Graph construction (FC matrix -> adjacency matrix) -> GNN architecture (graph convolution layers, pooling) -> Classification -> Explainability (attribution scores) -> Evaluation (robustness metrics)
- Critical path: Clean fMRI data -> Compute FC -> Build graph -> Train GNN -> Apply explainability -> Validate biomarkers
- Design tradeoffs: Balancing model complexity (more layers/parameters) with interpretability and robustness; choosing between spatial vs spectral GNNs; selecting appropriate explainability methods
- Failure signatures: Low reproducibility of biomarkers across studies; poor out-of-sample generalization; attribution scores that don't align with known neurobiology
- First 3 experiments:
  1. Reproduce classification performance using a standard GNN (Kipf & Welling) on a well-known dataset (e.g., ABIDE for ASD)
  2. Apply multiple explainability methods (Integrated Gradients, attention-based pooling) to the same trained model and compare biomarker consistency
  3. Test biomarker robustness by training on one site/dataset and evaluating on held-out sites to assess generalizability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal graph construction methods (beyond Pearson's correlation) for building functional connectomes in GNN-based biomarker discovery from fMRI data?
- Basis in paper: [explicit] The paper notes that while Pearson's correlation is widely used, alternatives like partial correlation and sparse representation have shown better performance in reducing noise and improving model outcomes.
- Why unresolved: The paper suggests that alternatives to Pearson's correlation could be less affected by noise, but it doesn't specify which methods are optimal or under what conditions.
- What evidence would resolve it: A comparative study evaluating different graph construction methods (e.g., partial correlation, sparse representation) across multiple disorders and datasets, with metrics on noise reduction and model performance.

### Open Question 2
- Question: How do different GNN architectures (baseline vs. customized) impact the robustness and reproducibility of discovered biomarkers in fMRI studies?
- Basis in paper: [explicit] The paper indicates that customized GNNs tailored for fMRI data (e.g., mix of BG/PG, adaptive graph construction) tend to outperform baseline GNNs, but the specific impact on biomarker robustness is not well-studied.
- Why unresolved: While performance improvements are noted, the direct link between GNN architecture choice and biomarker robustness is not established.
- What evidence would resolve it: Benchmarking studies comparing baseline and customized GNN architectures on the same datasets, focusing on both classification performance and the consistency of discovered biomarkers.

### Open Question 3
- Question: What are the most effective evaluation metrics for assessing the robustness of explanations produced by GNN-based models in fMRI studies?
- Basis in paper: [explicit] The paper highlights the need for objective evaluation metrics to determine the robustness of potential biomarkers, suggesting properties like Correctness, Completeness, Consistency, etc.
- Why unresolved: Existing metrics are often subjective and inconsistent, and the paper calls for new standards but doesn't specify which metrics are most effective.
- What evidence would resolve it: Development and validation of new evaluation metrics tailored to fMRI data, tested across multiple disorders and datasets to ensure their effectiveness in assessing explanation robustness.

## Limitations
- Limited reproducibility of identified biomarkers across independent studies
- Lack of standardized reporting on salient features and objective robustness metrics
- Most identified biomarkers are disorder-specific rather than transdiagnostic

## Confidence
- High confidence: GNNs can effectively model functional connectivity as graphs and achieve strong classification performance for psychiatric disorders
- Medium confidence: The identified biomarkers have limited reproducibility and robustness
- Low confidence: The clinical validity and biological significance of GNN-discovered biomarkers

## Next Checks
1. **Benchmark standardization**: Conduct a systematic evaluation using standardized datasets, preprocessing pipelines, and reporting metrics to assess GNN performance and biomarker reproducibility across multiple independent research groups.

2. **Transdiagnostic biomarker validation**: Test whether GNN-discovered biomarkers generalize across multiple psychiatric disorders by training on pooled datasets and evaluating cross-disorder classification performance and biomarker consistency.

3. **Biological validation**: Compare GNN-identified biomarkers against established neuroimaging findings from meta-analyses and histopathological studies to assess their biological plausibility and clinical relevance.