---
ver: rpa2
title: Do Large Language Models Speak All Languages Equally? A Comparative Study in
  Low-Resource Settings
arxiv_id: '2408.02237'
source_url: https://arxiv.org/abs/2408.02237
tags:
- languages
- task
- llms
- hate
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper evaluates large language models (LLMs) on zero-shot learning
  tasks in English and low-resource South Asian languages (Bangla, Hindi, Urdu). It
  addresses dataset scarcity by translating English sentiment and hate speech datasets
  into these languages.
---

# Do Large Language Models Speak All Languages Equally? A Comparative Study in Low-Resource Settings

## Quick Facts
- arXiv ID: 2408.02237
- Source URL: https://arxiv.org/abs/2408.02237
- Reference count: 18
- Primary result: GPT-4 outperforms Llama 2 and Gemini on zero-shot learning tasks, with English achieving highest accuracy across tasks

## Executive Summary
This study evaluates large language models (LLMs) on zero-shot learning tasks across English and three low-resource South Asian languages (Bangla, Hindi, Urdu). The authors address dataset scarcity by translating English sentiment and hate speech datasets into these languages. Three LLMs—GPT-4, Llama 2, and Gemini—are tested on natural language inference, sentiment analysis, and hate speech detection. Results show consistent performance gaps between English and low-resource languages, with GPT-4 demonstrating superior capabilities across all tasks and languages. The study highlights the need for improved LLM capabilities in low-resource languages and identifies translation quality as a key challenge.

## Method Summary
The study translates English datasets for sentiment analysis and hate speech detection into Bangla, Hindi, and Urdu using Google Translate. Three LLMs (GPT-4, Llama 2, Gemini) are evaluated on zero-shot learning tasks including natural language inference, sentiment analysis, and hate speech detection. Performance is measured using accuracy, precision, recall, and F1 scores. The authors analyze task-specific performance patterns and investigate the impact of translation quality on LLM outputs in low-resource languages.

## Key Results
- GPT-4 consistently outperforms Llama 2 and Gemini across all languages and tasks
- English achieves significantly higher accuracy than low-resource languages for all tasks
- Natural language inference tasks show the highest performance across all models and languages
- Translation quality significantly impacts LLM performance in low-resource languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs perform better in English due to higher representation in training data
- Mechanism: The majority of training data for large language models consists of English text, leading to stronger language understanding and task performance in English compared to low-resource languages
- Core assumption: Training data distribution directly correlates with downstream task performance
- Evidence anchors:
  - [abstract] "GPT-4 consistently outperforms Llama 2 and Gemini, with English consistently demonstrating superior performance across diverse tasks compared to low-resource languages"
  - [section] "One of the main reasons is that most of the LLMs are trained on a large amount (90%) of English data, whereas the amount of training data for low-resource languages is small compared with English"
  - [corpus] Weak evidence; corpus neighbors discuss low-resource language challenges but don't quantify training data distribution
- Break condition: If training data distribution becomes more balanced across languages or if model architectures are adapted for low-resource languages

### Mechanism 2
- Claim: Task structure affects LLM performance, with NLI performing better than sentiment/hate speech tasks
- Mechanism: NLI tasks have clearer rules and structured patterns compared to subjective, context-dependent sentiment and hate speech tasks, making them easier for LLMs to process
- Core assumption: Task structure directly impacts LLM performance
- Evidence anchors:
  - [abstract] "our analysis reveals that natural language inference (NLI) exhibits the highest performance among the evaluated tasks, with GPT-4 demonstrating superior capabilities"
  - [section] "The definition of an NLI task has clear rules and structured patterns, while sentiment and hate speech tasks are subjective and context-dependent"
  - [corpus] Weak evidence; corpus neighbors don't specifically address task structure differences
- Break condition: If task definitions become more standardized or if LLMs develop better contextual understanding

### Mechanism 3
- Claim: Translation quality impacts LLM performance on low-resource languages
- Mechanism: Poor translation quality from English to low-resource languages introduces errors and context loss, affecting LLM performance
- Core assumption: Translation quality directly impacts downstream task performance
- Evidence anchors:
  - [section] "The quality of the translation affects the performance of low-resource languages"
  - [section] "We analyzed the translations and found that most of the hashtags were not translated into the target language"
  - [corpus] Weak evidence; corpus neighbors don't discuss translation quality impacts
- Break condition: If translation quality improves or if models are trained directly on low-resource languages without translation

## Foundational Learning

- Concept: Zero-shot learning
  - Why needed here: The study evaluates LLM performance on tasks without any task-specific fine-tuning, relying solely on the model's pre-trained knowledge
  - Quick check question: What distinguishes zero-shot learning from few-shot or fine-tuned approaches?

- Concept: Cross-lingual evaluation
  - Why needed here: The study compares LLM performance across multiple languages (English, Bangla, Hindi, Urdu) to identify language-specific performance gaps
  - Quick check question: Why is it important to evaluate models across languages rather than just English?

- Concept: Prompt engineering
  - Why needed here: The study uses specific prompts to guide LLM responses, and prompt quality can significantly impact model performance
  - Quick check question: How might different prompt formulations affect LLM output quality?

## Architecture Onboarding

- Component map: English datasets -> Google Translate -> Translated datasets -> Prompt engineering -> LLMs (GPT-4, Llama 2, Gemini) -> Evaluation metrics
- Critical path: Data translation → Prompt formulation → Model inference → Evaluation metric calculation
- Design tradeoffs: Using translated datasets vs. native low-resource language data; zero-shot vs. fine-tuned approaches
- Failure signatures: Low performance on low-resource languages; inconsistent predictions across models; blocked content due to safety settings
- First 3 experiments:
  1. Compare model performance on translated vs. native low-resource language datasets
  2. Test different prompt formulations to improve low-resource language performance
  3. Evaluate the impact of data preprocessing (e.g., keeping vs. removing hashtags) on model performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of training LLMs on mixed-language datasets containing low-resource languages, rather than relying solely on translated data?
- Basis in paper: [inferred] The paper discusses the performance gap between English and low-resource languages like Bangla, Hindi, and Urdu, attributing it partly to the lack of training data for these languages.
- Why unresolved: The study focuses on zero-shot learning with translated datasets and does not explore the effects of training LLMs on datasets that include low-resource languages.
- What evidence would resolve it: Experimental results comparing LLM performance on tasks when trained on mixed-language datasets versus translated datasets.

### Open Question 2
- Question: How do different translation methods affect the performance of LLMs in low-resource language tasks?
- Basis in paper: [explicit] The authors mention using Google Translator and note that translation quality varies, with Hindi translations being better than Bangla and Urdu.
- Why unresolved: The study does not compare different translation methods or assess how translation quality impacts LLM performance.
- What evidence would resolve it: Comparative analysis of LLM performance using datasets translated by different methods or by human translators.

### Open Question 3
- Question: How does the inclusion of cultural context in prompts influence LLM performance on sentiment and hate speech detection in low-resource languages?
- Basis in paper: [inferred] The authors suggest that cultural differences affect LLM performance in sentiment and hate speech tasks.
- Why unresolved: The study does not experiment with culturally contextualized prompts or analyze their impact on performance.
- What evidence would resolve it: Results from experiments using culturally contextualized prompts compared to standard prompts in sentiment and hate speech tasks.

### Open Question 4
- Question: What is the effect of using few-shot learning or instruction fine-tuning on the performance of LLMs in low-resource languages?
- Basis in paper: [inferred] The authors focus on zero-shot learning and note the limitations of LLMs in low-resource languages, suggesting potential improvements.
- Why unresolved: The study does not explore few-shot learning or instruction fine-tuning techniques for low-resource languages.
- What evidence would resolve it: Performance metrics comparing zero-shot learning to few-shot learning or instruction fine-tuning in low-resource language tasks.

## Limitations
- Translation quality issues may artificially depress LLM performance in low-resource languages
- Limited scope to only three languages and three specific tasks
- Zero-shot evaluation doesn't explore potential improvements from fine-tuning or few-shot approaches

## Confidence

- **High confidence**: The finding that GPT-4 outperforms Llama 2 and Gemini across all tasks and languages is well-supported by the experimental results and consistent with broader LLM performance literature.

- **Medium confidence**: The conclusion about significant performance gaps between English and low-resource languages is robust for the specific languages and tasks studied, but may not generalize to other language families or task types.

- **Low confidence**: The attribution of performance differences primarily to training data imbalance is plausible but not definitively proven by this study alone, as other factors like translation quality and task structure may contribute significantly.

## Next Checks

1. **Translation quality validation**: Conduct human evaluation of translated datasets to quantify translation errors and their correlation with LLM performance drops, separating translation quality effects from genuine language understanding capabilities.

2. **Native data comparison**: Repeat the experiments using native low-resource language datasets (if available) or artificially balanced training data to isolate the effect of data quantity versus quality on LLM performance.

3. **Task structure variation**: Test the hypothesis that NLI tasks perform better than sentiment/hate speech by creating parallel task sets with varying levels of subjectivity and structure across all three languages, controlling for vocabulary and complexity.