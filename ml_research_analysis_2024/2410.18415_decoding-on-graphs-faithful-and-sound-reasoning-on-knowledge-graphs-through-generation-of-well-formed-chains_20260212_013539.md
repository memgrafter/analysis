---
ver: rpa2
title: 'Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through
  Generation of Well-Formed Chains'
arxiv_id: '2410.18415'
source_url: https://arxiv.org/abs/2410.18415
tags:
- reasoning
- llms
- location
- knowledge
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Decoding on Graphs (DOG), a training-free framework
  that enables large language models (LLMs) to perform faithful and sound reasoning
  on knowledge graphs (KGs) by generating well-formed chains of interrelated fact
  triplets. The core method, graph-aware constrained decoding, dynamically restricts
  the LLM's output vocabulary during decoding using a query-centric subgraph that
  expands progressively as reasoning proceeds, ensuring that each generated triplet
  exists on the KG and connects to previously visited entities.
---

# Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains

## Quick Facts
- **arXiv ID**: 2410.18415
- **Source URL**: https://arxiv.org/abs/2410.18415
- **Reference count**: 35
- **Key outcome**: Achieved 91.38% Hits@1 on WebQSP, 76.16% on CWQ, and 84.06% on 2Wikimultihop using Llama-3.1-8B with a training-free, graph-aware constrained decoding framework.

## Executive Summary
Decoding on Graphs (DOG) is a training-free framework enabling large language models to perform faithful and sound reasoning on knowledge graphs by generating well-formed chains of interrelated fact triplets. The core innovation is graph-aware constrained decoding, which dynamically restricts the LLM's output vocabulary during generation using a query-centric subgraph that expands as reasoning proceeds. This ensures each generated triplet exists on the KG and connects to previously visited entities. DOG integrates this with beam search to explore multiple reasoning paths in parallel, and demonstrates superior performance across three KGQA benchmarks with various open-source LLMs.

## Method Summary
DOG leverages a training-free approach to enable LLMs to reason over knowledge graphs by generating chains of interrelated fact triplets. The method employs graph-aware constrained decoding, which dynamically restricts the LLM's output vocabulary during decoding using a query-centric subgraph that progressively expands as reasoning proceeds. This ensures that each generated triplet exists on the KG and connects to previously visited entities. The framework integrates this constrained decoding with beam search execution to explore multiple reasoning paths in parallel, and includes an answer extraction module to derive final answers from generated chains. The approach is evaluated on WebQSP, CWQ, and 2Wikimultihop benchmarks with open-source LLMs, demonstrating robustness and effectiveness.

## Key Results
- Achieved 91.38% Hits@1 on WebQSP, 76.16% on CWQ, and 84.06% on 2Wikimultihop with Llama-3.1-8B
- Surpassed specialized retrievers and iterative prompting approaches on all benchmarks
- Demonstrated robustness across different KGs and general applicability to small LLMs

## Why This Works (Mechanism)
The framework's success hinges on constraining the LLM's output to only valid KG facts at each reasoning step, ensuring faithfulness by construction. The progressive subgraph expansion balances context richness with computational tractability, while beam search allows parallel exploration of multiple reasoning paths. The method's training-free nature enables direct application to any KG without additional model fine-tuning, and the integration of answer extraction from generated chains provides a clear end-to-end reasoning process.

## Foundational Learning
- **Knowledge Graph Structure**: Understanding how facts are represented as subject-predicate-object triplets and how entities and relations form a graph is essential for designing constrained decoding strategies.
  - *Why needed*: Enables the framework to enforce that generated chains correspond to actual KG paths.
  - *Quick check*: Can you identify all possible next steps from a given entity using its KG neighbors?

- **Constrained Decoding**: Restricting LLM output vocabulary based on context (here, valid KG triplets) ensures faithfulness but requires efficient implementation.
  - *Why needed*: Prevents the generation of hallucinated facts not present in the KG.
  - *Quick check*: Does the LLM's output at each step correspond to a valid KG triplet?

- **Beam Search in Generation**: Exploring multiple reasoning paths in parallel improves the chances of finding correct answers.
  - *Why needed*: Single-path decoding may miss correct reasoning chains due to early errors.
  - *Quick check*: Are multiple high-scoring reasoning chains being tracked and evaluated?

- **Progressive Subgraph Expansion**: Dynamically updating the set of valid next steps as reasoning proceeds keeps context manageable.
  - *Why needed*: Full KG context is computationally infeasible; selective expansion focuses on relevant facts.
  - *Quick check*: Does the subgraph grow logically with each reasoning step, reflecting newly visited entities?

- **Answer Extraction from Generated Chains**: Deriving final answers from the sequence of generated triplets is crucial for practical KGQA.
  - *Why needed*: Raw chains of facts must be translated into human-readable answers.
  - *Quick check*: Can you trace the final answer back to specific entities and relations in the KG?

## Architecture Onboarding

**Component Map**: Query -> Subgraph Extraction -> Graph-Aware Constrained Decoding -> Beam Search Execution -> Answer Extraction -> Final Answer

**Critical Path**: The critical reasoning loop involves extracting a query-centric subgraph, using constrained decoding to generate the next fact triplet, updating the subgraph with newly visited entities, and repeating until an answer is formed or a stopping criterion is met.

**Design Tradeoffs**: The framework trades computational efficiency for faithfulness by restricting decoding to valid KG facts, and balances context richness with tractability through progressive subgraph expansion. The training-free approach avoids fine-tuning costs but relies on the LLM's general reasoning ability.

**Failure Signatures**: Common failure modes include early generation of incorrect triplets (propagating errors through the chain), overly restrictive subgraph expansion (missing valid reasoning paths), and answer extraction errors when multiple entities could be correct. Performance may degrade on KGs with high noise or frequent updates.

**First Experiments**:
1. Verify that the LLM's output vocabulary is correctly restricted to valid KG triplets at each decoding step.
2. Measure the impact of subgraph expansion policy (e.g., breadth vs. depth) on reasoning accuracy and efficiency.
3. Test answer extraction accuracy on generated chains with known ground truth answers.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on static subgraph snapshots may limit robustness to KG updates or noise.
- Claims about the faithfulness and soundness of generated chains are largely qualitative, lacking formal verification or detailed error analysis.
- Performance comparisons are limited to specific benchmarks, and generalizability to broader KGQA scenarios remains uncertain.

## Confidence
- **High confidence**: The core mechanism of graph-aware constrained decoding and its integration with beam search is well-defined and reproducible. Ablation studies robustly support the necessity of both constrained decoding and global graph visibility.
- **Medium confidence**: Claims about robustness across diverse KGs and superiority over state-of-the-art retrievers are credible but depend on the quality and representativeness of the evaluation datasets (WebQSP, CWQ, 2Wikimultihop).
- **Low confidence**: Assertions that DOG's well-formed chains are inherently "faithful and sound" are qualitative and lack formal verification or error analysis beyond aggregate metrics.

## Next Checks
1. Compare DOG with alternative graph-aware generation baselines, such as iterative retrieval-augmented generation or other constrained decoding variants, to isolate its unique contributions.
2. Conduct ablation studies on beam search width and subgraph expansion policies to quantify their individual impacts on reasoning accuracy and computational efficiency.
3. Test DOG on KGs with frequent updates or noise to assess robustness in dynamic, real-world environments and identify failure modes.