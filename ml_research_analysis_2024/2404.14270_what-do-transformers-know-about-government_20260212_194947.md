---
ver: rpa2
title: What do Transformers Know about Government?
arxiv_id: '2404.14270'
source_url: https://arxiv.org/abs/2404.14270
tags:
- government
- probing
- heads
- finnish
- russian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates what insights about linguistic features
  and what knowledge about the structure of natural language can be obtained from
  the encodings in transformer language models. In particular, we explore how BERT
  encodes the government relation between constituents in a sentence.
---

# What do Transformers Know about Government?

## Quick Facts
- arXiv ID: 2404.14270
- Source URL: https://arxiv.org/abs/2404.14270
- Reference count: 19
- This paper investigates how BERT encodes government relations between constituents, finding information is encoded predominantly in early layers and can be captured by a small subset of attention heads.

## Executive Summary
This paper investigates what insights about linguistic features and knowledge about the structure of natural language can be obtained from transformer language models, specifically examining how BERT encodes government relations between constituents in sentences. The authors use probing classifiers trained on attention head weights to detect government relations in Finnish and Russian, finding that government information is encoded across all transformer layers but predominantly in the early layers. They demonstrate that a small number of attention heads contain sufficient information to predict government relations and discover new types of government never seen in training data.

## Method Summary
The authors use probing classifiers trained on attention head weights from BERT to detect government relations between governors (verbs) and governees (complements) in Finnish and Russian sentences. They extract positive and negative instances from parsed Universal Dependencies corpora, balance the data by distance and linguistic features, and evaluate classifier performance using logistic regression, MLP, and random forest models. The Government Bank dataset provides the government patterns for thousands of lemmas in both languages, and the authors release this dataset to support further research on grammatical constructions.

## Key Results
- Information about government relations is encoded across all transformer layers but predominantly in the early layers (1-4 for Finnish, 1-5-6 for Russian)
- A small subset of attention heads (3 for Finnish, 17-20 for Russian) can reliably predict government relations with performance comparable to using all heads
- Probing classifiers can discover new types of government relations never seen in training data
- Performance varies with the distance between governors and governees, with shorter distances being easier to classify

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer attention heads encode government relations even without explicit syntactic supervision.
- Mechanism: The probing classifier uses concatenated attention weights from all heads across transformer layers as input features. These weights reflect learned syntactic dependencies, enabling classification of government vs. non-government relations.
- Core assumption: Attention weights capture linguistic structure implicitly through self-supervised pretraining.
- Evidence anchors:
  - [abstract] "we explore how BERT encodes the government relation between constituents in a sentence"
  - [section] "We build the probing classifier based on the BERT model, specifically on the weights of its attention heads, from each transformer layer"
  - [corpus] Weak - corpus neighbors don't directly address attention-based syntactic encoding

### Mechanism 2
- Claim: Early transformer layers contain most government-relevant information.
- Mechanism: Performance plateaus after the first few layers (1-4 for Finnish, 1-5-6 for Russian), indicating government relations are primarily encoded in lower layers.
- Core assumption: Syntactic knowledge emerges early in transformer architectures before higher-level semantic processing.
- Evidence anchors:
  - [section] "crucially, all curves also indicate that the performance of classifiers increases rapidly for the early layers... and then the performance plateaus"
  - [abstract] "information about government is encoded across all transformer layers, but predominantly in the early layers of the model"
  - [corpus] Weak - corpus doesn't address layer-specific knowledge distribution

### Mechanism 3
- Claim: A small subset of attention heads can reliably predict government relations.
- Mechanism: Ablation studies show that using only the top 3 heads for Finnish or 17-20 heads for Russian achieves performance comparable to using all heads.
- Core assumption: Government relations are concentrated in specific attention heads rather than distributed uniformly.
- Evidence anchors:
  - [section] "The idea is that the learned coefficients serve as a good indication of the contribution of the corresponding heads... the most 'important' attention heads... are reliable indicators of government relations"
  - [abstract] "a small number of attention heads encode enough information about the government relations"
  - [corpus] Weak - corpus doesn't address head-specific information concentration

## Foundational Learning

- Concept: Government relations in linguistics
  - Why needed here: Understanding what government relations are and how they differ from general dependency relations is essential for interpreting probing results and designing experiments
  - Quick check question: What distinguishes a government relation from a general dependency relation in syntactic analysis?

- Concept: Transformer attention mechanisms
  - Why needed here: The entire probing approach relies on extracting and interpreting attention weights from BERT's transformer layers
  - Quick check question: How do attention weights in transformer layers capture syntactic relationships between words?

- Concept: Probing classifiers and their limitations
  - Why needed here: Understanding what probing classifiers can and cannot reveal about model internals is crucial for interpreting results and avoiding overclaiming
  - Quick check question: What is the key criticism of probing classifiers and how does the paper address it?

## Architecture Onboarding

- Component map:
  - Government Bank: Structured dataset of government patterns for Finnish and Russian
  - UD Corpus: Universal Dependencies treebanks providing parsed sentences
  - Morphological analyzers: TurkuNLP (Finnish) and DeepPavlov (Russian) for morphological analysis
  - Syntactic parsers: TurkuNLP (Finnish) and DeepPavlov (Russian) for dependency parsing
  - Probing classifier: Logistic regression, MLP, and Random Forest models trained on attention weights
  - BERT model: Pre-trained transformer providing attention head weights

- Critical path:
  1. Extract government patterns from Government Bank
  2. Identify positive/negative instances from parsed UD corpus
  3. Balance data by distance and linguistic features
  4. Extract attention weights from BERT for governor-argument pairs
  5. Train probing classifiers on attention weights
  6. Evaluate classifier performance and analyze layer/head contributions

- Design tradeoffs:
  - Using attention weights vs. token representations: Attention weights are more interpretable but may miss some information
  - Balanced vs. unbalanced data: Balancing prevents classifiers from learning superficial patterns but may reduce overall training data
  - Single vs. multiple probing tasks: Multiple tasks provide richer understanding but increase complexity

- Failure signatures:
  - Poor performance across all classifiers: Indicates government relations are not encoded in BERT or our probing approach is flawed
  - High performance only on near instances: Suggests classifier learned adjacency rather than government
  - No improvement with additional layers: May indicate all government information is in early layers or our probing method is insufficient
  - Random head ablation performs as well as targeted ablation: Suggests government information is uniformly distributed rather than concentrated

- First 3 experiments:
  1. Train a logistic regression classifier on attention weights from all layers and evaluate on the balanced test set to establish baseline performance
  2. Train probing classifiers using attention weights from only the first N layers (N=1,2,3,4) to identify where government information is concentrated
  3. Perform head ablation by training classifiers with only the top-ranked attention heads to determine the minimal set needed for reliable prediction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different transformer model architectures (e.g., BERT, RoBERTa, T5) encode government relations, and does the encoding pattern vary across architectures?
- Basis in paper: [inferred] The paper focuses on probing BERT specifically and mentions plans for future work to extend experiments to other models, but does not provide comparative results.
- Why unresolved: The current study is limited to BERT, preventing direct comparison with other transformer architectures.
- What evidence would resolve it: Probing experiments across multiple transformer models (BERT, RoBERTa, T5, etc.) using the same government probing methodology to compare encoding patterns and prediction performance.

### Open Question 2
- Question: How does the quality and completeness of the Government Bank impact the probing classifier's ability to detect government relations, and can improvements in the Bank lead to better performance?
- Basis in paper: [explicit] The paper acknowledges that the Government Bank is not "complete" and mentions errors in the data, such as inconsistencies between dependency relations and government instances, as well as noise from parser errors.
- Why unresolved: The current study uses an incomplete and imperfect Government Bank, which may limit the probing classifier's performance and generalization.
- What evidence would resolve it: Conducting probing experiments with progressively improved and more complete Government Banks, and analyzing the impact on classifier performance and error rates.

### Open Question 3
- Question: Can the probing methodology be extended to other types of grammatical constructions beyond government, such as coordination, subordination, or complex predicate-argument structures?
- Basis in paper: [explicit] The paper mentions plans to extend the work to government of other parts of speech (nouns, adjectives, etc.) and to more complex types of constructions than government in future work.
- Why unresolved: The current study focuses solely on verbal government, and the probing methodology's applicability to other constructions is yet to be explored.
- What evidence would resolve it: Applying the probing methodology to other grammatical constructions, such as coordination, subordination, or complex predicate-argument structures, and evaluating the classifiers' ability to detect and generalize these constructions.

## Limitations

- The study is limited to two morphologically rich languages (Finnish and Russian), making it unclear whether results generalize to other language types
- The probing approach cannot definitively establish whether attention heads actively encode government relations or merely reflect surface patterns
- The Government Bank dataset, while extensive, may not capture the full diversity of government patterns in natural language, particularly for less common or ambiguous cases

## Confidence

- **High confidence**: BERT encodes government relations in early layers (confirmed across multiple metrics and classifiers)
- **Medium confidence**: Attention heads can reliably predict government relations (supported by ablation studies but requires careful interpretation)
- **Low confidence**: Results generalize to other transformer architectures or languages (limited empirical validation beyond Finnish and Russian)

## Next Checks

1. **Cross-linguistic validation**: Replicate the probing experiments on additional languages spanning different morphological types (e.g., analytic languages like English or morphologically complex agglutinative languages) to assess whether layer-specific encoding patterns are universal or language-dependent.

2. **Architecture comparison**: Apply the same probing methodology to other transformer variants (e.g., RoBERTa, GPT, or smaller BERT variants) to determine whether government relation encoding is specific to BERT's pretraining objectives or a general property of transformer architectures.

3. **Temporal stability analysis**: Conduct experiments tracking how government relation encoding evolves during BERT's pretraining process, testing models at different checkpoints to determine whether this knowledge emerges early, late, or throughout training.