---
ver: rpa2
title: 'CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training
  of Language Models'
arxiv_id: '2407.17467'
source_url: https://arxiv.org/abs/2407.17467
tags:
- mixture
- loss
- general
- training
- ratio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the scaling behavior of large language
  models (LLMs) under continual pre-training (CPT) and proposes a principled method
  for determining the optimal mixture ratio of general and domain-specific data. The
  authors formalize the trade-off between maintaining general capabilities and achieving
  domain transfer, defining a Critical Mixture Ratio (CMR) as the maximum feasible
  ratio that satisfies both objectives.
---

# CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models

## Quick Facts
- arXiv ID: 2407.17467
- Source URL: https://arxiv.org/abs/2407.17467
- Authors: Jiawei Gu; Zacc Yang; Chuanghao Ding; Rui Zhao; Fei Tan
- Reference count: 40
- Key outcome: This paper proposes a principled method for determining optimal mixture ratios of general and domain-specific data during continual pre-training, predicting Critical Mixture Ratios with <0.05% error using power-law scaling relationships.

## Executive Summary
This paper investigates the scaling behavior of large language models (LLMs) under continual pre-training (CPT) and proposes a principled method for determining the optimal mixture ratio of general and domain-specific data. The authors formalize the trade-off between maintaining general capabilities and achieving domain transfer, defining a Critical Mixture Ratio (CMR) as the maximum feasible ratio that satisfies both objectives. Through extensive experiments, they discover a power-law relationship between loss, mixture ratio, and training tokens, enabling prediction of CMR using the proposed CMR scaling law.

The study finds that CMR values increase with model size (from 29.8% for 460M models to 34.9% for 940M models) and can be accurately predicted across different domains. The scaling law provides practical guidelines for optimizing LLM training in specialized domains while efficiently managing training resources, addressing the challenge of catastrophic forgetting during domain adaptation.

## Method Summary
The authors pre-train models from scratch on a 200B-token general dataset, then perform CPT on mixed datasets with varying mixture ratios (1/8, 1/4, 1/3, 1/2, etc.) for 20B tokens. They track losses during training and fit power-law models to predict losses for different mixture ratios and training tokens. The CMR is calculated by solving for the critical point where general loss tolerance is reached. The method uses Lagrangian optimization to balance domain and general losses, with power-law relationships forming the core of the prediction framework.

## Key Results
- CMR can be predicted with <0.05% error using power-law scaling relationships between loss, mixture ratio, and training tokens
- CMR increases with model size: from 29.8% for 460M models to 34.9% for 940M models
- The scaling law accurately predicts optimal mixture ratios across different domains, with CMR values of 29.8% for Finance and 36.7% for Academic Papers domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Critical Mixture Ratio (CMR) exists because there is a trade-off between maintaining general capabilities and achieving domain transfer during continual pre-training.
- Mechanism: As the proportion of domain-specific data increases, domain loss decreases while general loss initially increases and then decreases. This creates a window of feasible mixture ratios where both objectives can be satisfied.
- Core assumption: The relationship between loss, mixture ratio, and training tokens follows a predictable power-law form.
- Evidence anchors:
  - [abstract]: "We formalize the trade-off between general and domain-specific capabilities, leading to a well-defined Critical Mixture Ratio (CMR)"
  - [section]: "According to definition 3, the CMR is present across models of different scales, as shown in Figure 1"
  - [corpus]: Weak evidence - only two domains (Finance and Academic Papers) tested
- Break condition: If the power-law relationship doesn't hold or if the trade-off dynamics change significantly with larger models or different domains.

### Mechanism 2
- Claim: The CMR can be predicted using scaling laws that relate loss to mixture ratio and training token volume.
- Mechanism: By fitting power-law functions to the relationship between loss and mixture ratio, and between loss and training tokens, we can predict the critical point where general loss tolerance is reached.
- Core assumption: Loss follows a power-law relationship with both mixture ratio and training tokens, and this relationship is stable across different model sizes.
- Evidence anchors:
  - [abstract]: "Through extensive experiments, we identify a power-law relationship between loss, mixture ratio, and training tokens"
  - [section]: "We proposed the simplified expression L(R) as a power-law form of L(R) = α · Rs + β"
  - [corpus]: Weak evidence - only tested on model sizes up to 3.1B, which is relatively small
- Break condition: If the power-law fitting accuracy degrades significantly for larger models or if the relationship becomes non-linear.

### Mechanism 3
- Claim: Larger models can accommodate higher CMR values because they have greater capacity to learn domain knowledge without significant degradation of general capabilities.
- Mechanism: As model size increases, the feasible mixture ratio set expands, allowing for higher proportions of domain-specific data while still maintaining general performance within tolerance.
- Core assumption: Model capacity scales predictably with parameter count, allowing larger models to absorb more domain-specific knowledge.
- Evidence anchors:
  - [abstract]: "CMR goes up with increasing model scale: from 29.8% for the 460M model to 34.9% for the 940M model"
  - [section]: "Larger models tend to have bigger feasible mixture ratios set F (more curves with yellow dotted arrows)"
  - [corpus]: Weak evidence - only tested on model sizes up to 3.1B
- Break condition: If the relationship between model size and CMR doesn't hold for significantly larger models or if other factors (like architecture) become more important.

## Foundational Learning

- Concept: Power-law scaling relationships
  - Why needed here: The entire prediction method relies on identifying and fitting power-law relationships between loss, mixture ratio, and training tokens
  - Quick check question: What is the general form of a power-law relationship and why is it commonly observed in machine learning scaling phenomena?

- Concept: Lagrangian optimization and Lagrange multipliers
  - Why needed here: The objective function for CPT is formulated as a Lagrangian to balance the trade-off between domain and general losses
  - Quick check question: How does the Lagrange multiplier λ enforce the constraint on general loss while minimizing domain-specific loss?

- Concept: Catastrophic forgetting and continual learning
  - Why needed here: The motivation for CPT and the need to balance general and domain performance stems from the catastrophic forgetting problem
  - Quick check question: What is catastrophic forgetting and how does continual pre-training with general data replay help mitigate this issue?

## Architecture Onboarding

- Component map: Data preparation (general and domain-specific corpora) -> Model training (pre-training and CPT stages) -> Loss tracking and prediction (power-law fitting) -> CMR prediction (solving for critical points) -> Validation
- Critical path: The critical path for implementing this system is: prepare datasets -> pre-train base model -> perform CPT with varying mixture ratios -> track losses -> fit power-law relationships -> predict CMR -> validate predictions. The most time-consuming step is typically the extensive experimentation needed to gather sufficient data points for accurate fitting.
- Design tradeoffs: The main tradeoff is between prediction accuracy and computational cost. More extensive experimentation yields better fitting but requires more resources. Another tradeoff is between model size and CMR - larger models can handle higher CMR but are more expensive to train. The tolerance value (ϵ) is a key hyperparameter that balances general performance preservation against domain adaptation.
- Failure signatures: Common failure modes include poor power-law fitting (indicated by low R² values), prediction errors exceeding the stated 0.05% threshold, or infeasible mixture ratios that don't align with experimental observations. The system may also fail if the assumption about the trade-off dynamics breaks down for certain domains or model architectures.
- First 3 experiments:
  1. Reproduce the basic power-law fitting for a single model size and domain to verify the fundamental relationship holds
  2. Test the prediction accuracy by training models at predicted CMR values and measuring actual performance
  3. Validate the model size scaling by comparing predicted vs actual CMR across multiple model sizes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would CMR predictions change for domains with more extreme distribution gaps compared to the general corpus?
- Basis in paper: [inferred] The paper observes that CMR depends on the similarity between target and general domains, with smaller distribution gaps leading to larger CMR values.
- Why unresolved: The study only tested two domains (Finance and Academic Papers) with relatively similar distribution gaps to the general corpus. Testing with domains having more extreme distribution differences would provide a fuller understanding of this relationship.
- What evidence would resolve it: Experiments with a broader range of domains showing varying degrees of distribution similarity to the general corpus, measuring corresponding CMR values.

### Open Question 2
- Question: Does the power-law relationship between loss, mixture ratio, and training tokens hold across all model sizes, including frontier-scale LLMs?
- Basis in paper: [explicit] The authors note that computational constraints limited experiments to models ranging from 400M to 3.1B parameters, and acknowledge this may lead to inaccuracy in estimation of model size scaling.
- Why unresolved: The study's largest model is relatively small compared to contemporary LLMs, and the scaling behavior might differ at frontier scales.
- What evidence would resolve it: Experimental validation of the power-law relationship using larger models (e.g., 10B+ parameters) with similar mixture ratio and training token volume variations.

### Open Question 3
- Question: How would multi-domain CPT affect the Critical Mixture Ratio compared to single-domain CPT?
- Basis in paper: [explicit] The authors explicitly state they did not explore the more complex setting of training across multiple domains, focusing instead on single-domain CPT for clearer experimental observations.
- Why unresolved: The current study only examines single-domain scenarios, leaving open the question of how mixture ratios would need to be adjusted when multiple target domains are involved simultaneously.
- What evidence would resolve it: Experiments comparing CMR predictions and actual performance when performing CPT on multiple domains simultaneously versus sequentially.

## Limitations

- The study only tested on relatively small models (up to 3.1B parameters), limiting confidence in scaling law applicability to frontier-scale LLMs
- Only two domains (Finance and Academic Papers) were tested, raising questions about generalizability across diverse data types
- The power-law relationships were validated on limited experimental conditions and may not hold under different training regimes or architectures

## Confidence

- **High confidence**: The existence of a trade-off between general and domain-specific capabilities during CPT, and the basic methodology of using power-law fitting to predict losses
- **Medium confidence**: The accuracy of CMR predictions (reported <0.05% error) given the limited model size range tested
- **Low confidence**: The scaling law's applicability to models significantly larger than 3.1B parameters and to domains substantially different from Finance and Academic Papers

## Next Checks

1. **Cross-Domain Validation**: Test the CMR scaling law on at least three additional domains with fundamentally different characteristics (e.g., legal documents, medical literature, and software code) to assess the generality of the power-law relationships and prediction accuracy across diverse data types.

2. **Large Model Scaling**: Evaluate the scaling law's accuracy on models at least 10x larger than the current maximum (30B+ parameters) to determine whether the power-law relationships and CMR predictions hold at scales representative of state-of-the-art LLMs.

3. **Hyperparameter Interaction Study**: Systematically vary key training hyperparameters (learning rate, batch size, sequence length) while measuring their impact on the power-law fitting quality and CMR prediction accuracy to understand the robustness of the scaling law under different training conditions.