---
ver: rpa2
title: Asymptotic Unbiased Sample Sampling to Speed Up Sharpness-Aware Minimization
arxiv_id: '2406.08001'
source_url: https://arxiv.org/abs/2406.08001
tags:
- gradient
- ausam
- training
- samples
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes AUSAM, a method to accelerate Sharpness-Aware
  Minimization (SAM) by probabilistically sampling data points based on their gradient
  norms. The key idea is that samples with larger gradient norms are more important
  for preserving model generalization during SAM optimization.
---

# Asymptotic Unbiased Sample Sampling to Speed Up Sharpness-Aware Minimization

## Quick Facts
- arXiv ID: 2406.08001
- Source URL: https://arxiv.org/abs/2406.08001
- Authors: Jiaxin Deng; Junbiao Pang; Baochang Zhang
- Reference count: 40
- Key outcome: AUSAM accelerates SAM by over 70% while maintaining accuracy through gradient-norm-based sampling

## Executive Summary
This paper proposes AUSAM (Asymptotic Unbiased Sample Sampling), a method to accelerate Sharpness-Aware Minimization (SAM) by probabilistically sampling data points based on their gradient norms. The key insight is that samples with larger gradient norms are more important for preserving model generalization during SAM optimization. AUSAM approximates gradient norms using the difference in loss values before and after perturbation, enabling efficient sampling without extra computation. Theoretically, AUSAM achieves asymptotic unbiasedness as training progresses. Empirically, on CIFAR-10/100 and Tiny-ImageNet, AUSAM provides over 70% speedup compared to SAM while maintaining comparable accuracy.

## Method Summary
AUSAM accelerates SAM by sampling a subset of data points based on their importance for generalization, approximated by gradient norms. Instead of computing per-sample gradients (which is expensive), AUSAM uses the absolute difference in loss values before and after perturbation (DLP) as a proxy for gradient norm. During training, each sample maintains an average DLP (ADLP) over epochs, which determines its sampling probability. The method uses a hyperparameter α to control the sampling ratio. Theoretically, AUSAM achieves asymptotic unbiasedness, meaning that as training progresses, the sampling strategy converges to covering all important samples. Empirically, AUSAM achieves 70%+ speedup on image classification tasks while maintaining accuracy comparable to full-batch SAM.

## Key Results
- AUSAM achieves over 70% speedup compared to SAM on CIFAR-10/100 and Tiny-ImageNet while maintaining comparable accuracy
- With α=0.4, AUSAM matches SGD speed while significantly outperforming it on accuracy
- AUSAM demonstrates effectiveness beyond image classification on human pose estimation and network quantization tasks
- Theoretical analysis shows AUSAM achieves asymptotic unbiasedness as training progresses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Samples with larger gradient norms are more important for preserving model generalization during SAM optimization.
- Mechanism: The proposed method samples data points based on their gradient norms, approximating these norms using the difference in loss values before and after perturbation. This ensures that the most informative samples (those with larger gradient norms) are prioritized during training.
- Core assumption: Gradient norm magnitude is positively correlated with sample importance for generalization.
- Evidence anchors:
  - [abstract]: "samples with larger gradient norms are more important for preserving model generalization"
  - [section]: "Concretely, we probabilistically sample a subset of data points beneficial for SAM optimization based on a theoretically guaranteed criterion, i.e., the Gradient Norm of each Sample (GNS)"
  - [corpus]: Weak evidence - related work focuses on efficiency improvements but doesn't directly validate the gradient-norm importance claim
- Break condition: If gradient norms do not correlate with sample importance for generalization, or if the approximation of gradient norms using loss differences becomes inaccurate.

### Mechanism 2
- Claim: Approximating gradient norms using the difference in loss values before and after perturbation is computationally efficient.
- Mechanism: Instead of computing per-sample gradients directly (which is expensive), the method uses the absolute difference in loss values (DLP) before and after perturbation as a proxy for gradient norm.
- Core assumption: DLP is a good approximation of gradient norm.
- Evidence anchors:
  - [section]: "Lemma 1 shows that the gradient norm of sample xi can be approximated by the absolute values of Difference in Loss before and after Perturbation (hereinafter referred to as DLP)"
  - [abstract]: "We further approximate the GNS by the difference in loss values before and after perturbation in SAM"
  - [corpus]: No direct evidence in corpus - this appears to be a novel approximation strategy
- Break condition: If the DLP approximation becomes inaccurate for certain types of data or models, or if the computational savings are offset by other costs.

### Mechanism 3
- Claim: Probabilistic sampling with adaptive probabilities based on historical DLP achieves asymptotic unbiasedness.
- Mechanism: The method maintains an average DLP (ADLP) for each sample over training epochs and uses this to determine sampling probabilities, gradually prioritizing samples with larger gradient norms while ensuring all samples are eventually sampled.
- Core assumption: Averaging DLP over time provides a stable estimate of gradient norm importance.
- Evidence anchors:
  - [abstract]: "Our theoretical analysis indicates that samples with larger gradient norms are crucial for preserving the model's generalization"
  - [section]: "To ensure that samples with low gT xi values are not overlooked, we implement a probabilistic sampling mechanism"
  - [corpus]: Weak evidence - related work mentions unbiasedness but doesn't provide theoretical guarantees for this specific approach
- Break condition: If the averaging process doesn't converge to stable estimates, or if the probabilistic sampling doesn't adequately cover all samples over time.

## Foundational Learning

- Concept: Sharpness-Aware Minimization (SAM)
  - Why needed here: AUSAM is designed to accelerate SAM, so understanding SAM's core principles is essential
  - Quick check question: What is the key difference between SAM and standard SGD in terms of gradient computation?

- Concept: Gradient norm as importance measure
  - Why needed here: The method relies on gradient norms to determine sample importance for generalization
  - Quick check question: Why might samples with larger gradient norms be more important for generalization?

- Concept: Asymptotic unbiasedness
  - Why needed here: The method claims to achieve asymptotic unbiasedness, which is a key theoretical guarantee
  - Quick check question: What does it mean for a sampling strategy to be asymptotically unbiased?

## Architecture Onboarding

- Component map:
  - Data sampling module -> Loss computation module -> Gradient computation module -> Parameter update module -> ADLP tracking module

- Critical path:
  1. Forward pass on mini-batch to compute losses
  2. Compute DLP for each sample
  3. Update ADLP for each sample
  4. Compute sampling probabilities based on ADLP
  5. Sample subset of data
  6. Compute SAM perturbation on sampled subset
  7. Compute gradients after perturbation
  8. Update parameters

- Design tradeoffs:
  - Sampling ratio (α) vs. accuracy: Lower α gives more speedup but may hurt accuracy
  - DLP approximation accuracy vs. computational cost: More accurate approximations may require more computation
  - ADLP averaging window size vs. adaptiveness: Larger windows give more stable estimates but may adapt more slowly

- Failure signatures:
  - Accuracy degradation when α is too small
  - Training instability if DLP approximation becomes inaccurate
  - Convergence issues if sampling probabilities become too skewed

- First 3 experiments:
  1. Verify that DLP correlates with actual gradient norm on a small dataset
  2. Test the impact of different sampling ratios (α) on accuracy and speedup
  3. Validate that the method achieves asymptotic unbiasedness by tracking sample coverage over training

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- Theoretical analysis focuses on gradient norm importance and asymptotic unbiasedness but lacks rigorous proofs for DLP approximation accuracy across different model architectures
- Computational complexity analysis doesn't account for potential overhead in maintaining and updating ADLP statistics across training
- Experimental validation is primarily focused on image classification tasks, leaving questions about effectiveness on other domains

## Confidence
- **High Confidence**: The core mechanism of using DLP to approximate gradient norms and the asymptotic unbiasedness claim (supported by theoretical analysis and empirical convergence patterns)
- **Medium Confidence**: The computational speedup claims (70% faster than SAM) - these depend heavily on implementation details and hardware specifics
- **Medium Confidence**: The generalization preservation claims - while accuracy results are strong, ablation studies on the necessity of SAM's perturbation step are limited

## Next Checks
1. **DLP Approximation Validation**: Conduct controlled experiments comparing DLP-based gradient norm estimates against true per-sample gradient norms across diverse datasets and model architectures to quantify approximation error and identify failure modes.

2. **Ablation on SAM Perturbation**: Systematically test AUSAM without the perturbation step (effectively becoming a sampled-SGD variant) to isolate the contribution of SAM's sharpness-aware component versus the sampling efficiency.

3. **Cross-Domain Generalization**: Evaluate AUSAM on non-image tasks (NLP, speech, or tabular data) to assess whether the gradient-norm-based sampling remains effective when the underlying data distribution and model architectures differ significantly from the tested image classification scenarios.