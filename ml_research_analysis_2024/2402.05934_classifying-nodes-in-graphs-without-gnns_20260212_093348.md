---
ver: rpa2
title: Classifying Nodes in Graphs without GNNs
arxiv_id: '2402.05934'
source_url: https://arxiv.org/abs/2402.05934
tags:
- nodes
- training
- graph
- node
- gnns
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a GNN-free method for node classification that
  achieves competitive results with GNNs on popular datasets. The key insight is that
  GNNs' advantage lies in their inductive bias and sample efficiency rather than message
  passing.
---

# Classifying Nodes in Graphs without GNNs

## Quick Facts
- arXiv ID: 2402.05934
- Source URL: https://arxiv.org/abs/2402.05934
- Authors: Daniel Winter; Niv Cohen; Yedid Hoshen
- Reference count: 11
- Primary result: CoHOp achieves competitive or better results than GNNs and graph distillation methods on node classification tasks

## Executive Summary
This paper challenges the conventional wisdom that Graph Neural Networks (GNNs) are necessary for node classification tasks. The authors propose CoHOp, a GNN-free method that achieves state-of-the-art results on popular benchmark datasets. Their key insight is that GNNs' advantage stems from sample efficiency and inductive bias rather than message passing. By combining consistency loss, iterative pseudo-labeling, and neighborhood-label histograms, CoHOp matches or exceeds the performance of distillation methods without requiring any GNN training.

## Method Summary
CoHOp is a three-component approach for node classification without GNNs. First, it enforces consistency between neighboring nodes' predictions through a smoothness constraint. Second, it iteratively generates pseudo-labels for unlabeled nodes to artificially expand the training set. Third, it augments node features with histograms of neighboring nodes' labels. The method trains a simple MLP or linear model on this augmented data using cross-entropy loss combined with the consistency loss. This approach achieves competitive results without the computational overhead of training GNNs.

## Key Results
- CoHOp outperforms or matches state-of-the-art graph distillation methods across seven benchmark datasets
- The performance gap between MLPs and GNNs diminishes as training set size increases
- CoHOp is particularly effective on small training sets, achieving comparable results to GNNs with significantly less computational overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The advantage of GNNs lies in sample efficiency and inductive bias, not message passing.
- Mechanism: GNNs implicitly regularize the model through neighborhood aggregation, reducing overfitting on small training sets. Distillation methods achieve similar results by artificially expanding the training set with pseudo-labels.
- Core assumption: Standard node classification benchmarks have very small training sets, causing MLPs to overfit.
- Evidence anchors:
  - [abstract] "GNNs' advantage lies in their inductive bias and sample efficiency rather than message passing."
  - [section] "The observed trend indicates that with an increase in training size, the performance gap between node-level MLPs and GNNs diminishes."
  - [corpus] Weak evidence. No direct comparison of GNN vs. MLP sample efficiency in the corpus.
- Break condition: If training sets are large enough that MLPs don't overfit, GNNs' advantage disappears.

### Mechanism 2
- Claim: Consistency loss enforces homophilic priors to improve predictions.
- Mechanism: By encouraging neighboring nodes to have similar predictions, the model leverages the common graph property that connected nodes share labels.
- Core assumption: Many real-world graphs exhibit homophily (connected nodes tend to have the same label).
- Evidence anchors:
  - [abstract] "smoothness constraints" as a key component.
  - [section] "We incorporate a homophilic prior on the node predictions using a consistency loss."
  - [corpus] Weak evidence. No specific discussion of homophily in the corpus.
- Break condition: If the graph is heterophilic (neighbors tend to have different labels), consistency loss could harm performance.

### Mechanism 3
- Claim: Neighborhood-label histograms encode local context without message passing.
- Mechanism: By concatenating weighted label distributions from nearby nodes, the model gains information about local label patterns without computing hidden features for the entire neighborhood.
- Core assumption: Labels of nearby nodes are informative for classifying a given node.
- Evidence anchors:
  - [abstract] "neighborhood-label histograms" as a key component.
  - [section] "Our method only requires simple counting of the neighborhood labels which is a much weaker requirement than running a GNN over the entire neighborhood."
  - [corpus] Weak evidence. No specific discussion of neighborhood-label histograms in the corpus.
- Break condition: If nearby node labels are not informative or if the graph is too large to compute histograms efficiently.

## Foundational Learning

- Concept: Semi-supervised learning with pseudo-labeling
  - Why needed here: The training sets are very small (sometimes as little as 0.3% of nodes), so pseudo-labeling increases the effective training set size.
  - Quick check question: How does pseudo-labeling help when we don't have ground truth labels for the pseudo-labeled nodes?

- Concept: Regularization through consistency constraints
  - Why needed here: Without GNNs' implicit regularization, the model needs explicit constraints to prevent overfitting on small training sets.
  - Quick check question: What graph property does the consistency loss exploit to regularize the model?

- Concept: Feature engineering with neighborhood information
  - Why needed here: Node features alone may not capture local structural patterns that are important for classification.
  - Quick check question: How do neighborhood-label histograms differ from message passing in GNNs?

## Architecture Onboarding

- Component map: Predictor (MLP/linear) -> Consistency Loss Module -> Pseudo-labeling Loop -> Histogram Feature Augmentation

- Critical path: Train predictor → Compute consistency loss → Generate pseudo-labels → Update training set → Repeat

- Design tradeoffs:
  - Exact vs. approximate histogram computation (accuracy vs. speed)
  - Number of pseudo-labeling iterations (more iterations may improve accuracy but increase training time)
  - Consistency loss weight (balance between classification accuracy and smoothness)

- Failure signatures:
  - Poor performance on heterophilic graphs
  - Slow training if histograms are computed exactly on large graphs
  - Overfitting if consistency loss weight is too low

- First 3 experiments:
  1. Test the base MLP without any GNN-free components to establish baseline performance.
  2. Add consistency loss to see if it improves performance on homophilic graphs.
  3. Implement iterative pseudo-labeling to check if it helps with small training sets.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can CoHOp be adapted to work effectively on heterophilic graphs where neighboring nodes tend to have different labels?
- Basis in paper: [explicit] The paper acknowledges this limitation in the Discussion section, stating "Our method is focused on utilizing the homophilic prior. Yet, some graph datasets (Platonov et al., 2023) are heterophilic."
- Why unresolved: The authors only mention this as a limitation and suggest it's left for future work, without providing any concrete approach or preliminary results for adapting CoHOp to heterophilic graphs.
- What evidence would resolve it: Experimental results showing CoHOp's performance on heterophilic graph datasets, or a modified version of CoHOp specifically designed for heterophilic graphs with accompanying results.

### Open Question 2
- Question: What specific dataset characteristics cause NOSMOG to outperform CoHOp in some cases?
- Basis in paper: [explicit] The paper states "While our method outperformed NOSMOG on average, there are cases where NOSMOG achieves higher accuracy. This variation suggests that the different approaches might be influenced by dataset-specific characteristics."
- Why unresolved: The authors identify this as an open question but do not provide any analysis of which dataset features (e.g., graph structure, feature properties, label distribution) correlate with NOSMOG's superior performance.
- What evidence would resolve it: A detailed analysis of the datasets where NOSMOG outperforms CoHOp, identifying common characteristics, and potentially modifying CoHOp to handle these cases better.

### Open Question 3
- Question: How does CoHOp perform when the training set size is extremely small (e.g., less than 1% of nodes)?
- Basis in paper: [inferred] While the paper mentions that distillation methods overcome overfitting by increasing the training set size with pseudo-labels, it doesn't provide results for very small training sets where even this approach might struggle.
- Why unresolved: The paper focuses on standard benchmark datasets with training sizes around 0.3-0.5%, but doesn't explore the extreme case where the training set is even smaller.
- What evidence would resolve it: Experiments on datasets or synthetic graphs with extremely small training sets (<1% of nodes), comparing CoHOp's performance to GNNs and other methods in this regime.

## Limitations
- The method assumes homophily in graphs, limiting its effectiveness on heterophilic datasets
- Scalability to very large graphs remains untested
- Performance on graphs with non-IID label distributions is not evaluated

## Confidence

- **High Confidence**: The core methodology (consistency loss + pseudo-labeling + histogram features) is clearly described and experimentally validated
- **Medium Confidence**: Claims about GNNs' advantage being primarily sample efficiency rather than message passing effectiveness, based on the provided evidence
- **Low Confidence**: Generalization claims to all graph types and sizes, particularly for heterophilic graphs and very large-scale graphs

## Next Checks

1. Test CoHOp performance on heterophilic graphs (e.g., Chameleon, Squirrel datasets) to verify the homophily assumption
2. Compare training times and scalability with standard GNNs on graphs with 100K+ nodes to assess practical limitations
3. Validate the sample efficiency claims by systematically varying training set sizes across all datasets and comparing convergence rates with GNNs