---
ver: rpa2
title: 'LLMs as Research Tools: A Large Scale Survey of Researchers'' Usage and Perceptions'
arxiv_id: '2411.05025'
source_url: https://arxiv.org/abs/2411.05025
tags:
- llms
- research
- researchers
- usage
- more
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The survey of 816 verified research article authors reveals that
  81% of researchers have incorporated LLMs into their research workflows, with highest
  usage for information seeking and editing tasks. Non-White, junior, and non-native
  English speaking researchers report both higher LLM usage and perceived benefits,
  suggesting potential for improved research equity.
---

# LLMs as Research Tools: A Large Scale Survey of Researchers' Usage and Perceptions

## Quick Facts
- arXiv ID: 2411.05025
- Source URL: https://arxiv.org/abs/2411.05025
- Authors: Zhehui Liao; Maria Antoniak; Inyoung Cheong; Evie Yu-Yen Cheng; Ai-Heng Lee; Kyle Lo; Joseph Chee Chang; Amy X. Zhang
- Reference count: 40
- Primary result: Survey of 816 researchers reveals 81% LLM usage in research workflows with demographic differences in adoption and concerns

## Executive Summary
This large-scale survey of 816 verified research article authors reveals widespread adoption of large language models (LLMs) in research workflows, with 81% of researchers incorporating these tools into their work. The study finds that LLMs are primarily used for information seeking and editing tasks, while non-White, junior, and non-native English speaking researchers report both higher usage and perceived benefits. However, women, non-binary, and senior researchers express greater ethical concerns that may hinder adoption. The findings highlight both the growing integration of LLMs in research and the varying perceptions across demographic groups, underscoring the need for careful consideration of equity, ethics, and field-specific norms in LLM adoption.

The survey also reveals preferences for open-source and non-profit LLM platforms over commercial models due to transparency and ethical considerations. Computer science researchers show greater comfort with disclosure compared to other fields. These patterns suggest that while LLMs have significant potential to improve research equity by supporting underrepresented groups, they also raise important questions about ethical implementation and field-specific norms that must be addressed as the technology continues to evolve.

## Method Summary
The study conducted a comprehensive survey of 816 verified research article authors, focusing on their usage patterns, perceptions, and concerns regarding large language models in research workflows. Participants were recruited from various academic disciplines with an emphasis on AI/ML venues to ensure representation from researchers familiar with LLM technology. The survey collected data on demographic information, specific use cases, perceived benefits, ethical concerns, and disclosure practices. Researchers were asked to self-report their LLM usage, preferences for different platforms, and attitudes toward integration in academic research.

## Key Results
- 81% of surveyed researchers have incorporated LLMs into their research workflows
- Non-White, junior, and non-native English speaking researchers report both higher usage and perceived benefits
- Women, non-binary, and senior researchers express greater ethical concerns that may hinder adoption

## Why This Works (Mechanism)
The survey's findings reflect the growing normalization of LLMs in academic research workflows, particularly for tasks that align with the strengths of these models such as information synthesis and language refinement. The differential adoption patterns across demographic groups suggest that LLMs may be addressing existing inequities in research by providing support to groups that have historically faced barriers, such as non-native English speakers and early-career researchers. The preference for open-source platforms indicates researchers' desire for transparency and control over their tools, which aligns with academic values of reproducibility and ethical considerations.

## Foundational Learning

**Academic research workflows** - Understanding how researchers conduct their work is essential for contextualizing LLM integration. Quick check: Identify the main stages of research from ideation to publication.

**Demographic impact analysis** - Recognizing how different researcher groups interact with technology helps identify both opportunities and barriers. Quick check: Map demographic factors to potential technology adoption barriers.

**Ethical framework for AI in academia** - Establishing guidelines for responsible AI use is critical as adoption increases. Quick check: List key ethical considerations for AI tools in research contexts.

**Disclosure norms in academic publishing** - Understanding field-specific expectations around tool acknowledgment affects implementation strategies. Quick check: Compare disclosure requirements across different academic disciplines.

## Architecture Onboarding

**Component Map**: Researchers -> Survey Instrument -> Data Collection -> Analysis -> Findings
Critical path: Survey distribution and completion → demographic pattern analysis → usage behavior mapping → ethical concern assessment

**Design Tradeoffs**: The study prioritized breadth of researcher representation over depth of individual interviews, trading detailed qualitative insights for broader quantitative patterns. This approach enables identification of general trends but may miss nuanced contextual factors.

**Failure Signatures**: Sampling bias toward AI/ML venue authors could overrepresent LLM-familiar researchers. Self-reporting may introduce social desirability bias in disclosure practices. Field-specific limitations restrict generalizability to other disciplines.

**3 First Experiments**:
1. Test survey instrument with small pilot group to validate question clarity and response patterns
2. Compare self-reported usage with actual usage tracking in a controlled subset
3. Conduct demographic subgroup analysis to validate observed patterns across multiple variables

## Open Questions the Paper Calls Out
The paper highlights several open questions regarding the long-term impact of LLM integration on research quality, the evolution of field-specific norms around disclosure, and the potential for LLMs to either reduce or exacerbate existing inequities in academic publishing. The authors call for continued monitoring of how demographic groups' perceptions and usage patterns evolve over time, particularly as ethical concerns are addressed and disclosure practices become standardized.

## Limitations
- Sample overrepresents researchers from AI/ML venues, potentially biasing toward LLM-favorable perspectives
- Self-reported data may be subject to social desirability bias, particularly around disclosure practices
- Focus on computer science and related fields limits generalizability to disciplines with different research practices

## Confidence
**Key Findings: Medium Confidence**
- LLM adoption rate (81%) - Medium confidence due to self-reporting and field-specific sample
- Demographic pattern correlations - Medium confidence with noted limitations in sample representation
- Ethical concern disparities - Medium confidence based on self-reported perceptions

## Next Checks
1. Replicate the survey with a more diverse sample across multiple disciplines and publication venues to assess field-specific differences and reduce potential AI/ML bias.

2. Conduct follow-up interviews or focus groups to validate self-reported usage patterns and explore the nuanced reasons behind demographic differences in perceived benefits and concerns.

3. Implement a longitudinal study tracking actual LLM usage over time to verify the stability of current adoption patterns and assess how perceptions evolve as the technology matures.