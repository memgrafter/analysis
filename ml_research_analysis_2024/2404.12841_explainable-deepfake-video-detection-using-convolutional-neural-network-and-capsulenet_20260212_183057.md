---
ver: rpa2
title: Explainable Deepfake Video Detection using Convolutional Neural Network and
  CapsuleNet
arxiv_id: '2404.12841'
source_url: https://arxiv.org/abs/2404.12841
tags:
- deepfake
- videos
- video
- fake
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a hybrid deepfake video detection model combining
  Convolutional Neural Networks (CNN), Capsule Networks, and Long Short-Term Memory
  (LSTM) layers. The proposed approach addresses the limitations of traditional CNN-based
  methods in detecting deepfake videos by incorporating CapsuleNet to preserve spatial
  information and LSTM to capture temporal inconsistencies across video frames.
---

# Explainable Deepfake Video Detection using Convolutional Neural Network and CapsuleNet

## Quick Facts
- arXiv ID: 2404.12841
- Source URL: https://arxiv.org/abs/2404.12841
- Authors: Gazi Hasin Ishrak; Zalish Mahmud; MD. Zami Al Zunaed Farabe; Tahera Khanom Tinni; Tanzim Reza; Mohammad Zavid Parvez
- Reference count: 40
- Primary result: Hybrid CNN-CapsuleNet-LSTM model achieves 88% accuracy and 88.30% recall on Deepfake Detection Challenge (DFDC) dataset

## Executive Summary
This study presents a hybrid deepfake video detection model combining Convolutional Neural Networks (CNN), Capsule Networks, and Long Short-Term Memory (LSTM) layers. The proposed approach addresses the limitations of traditional CNN-based methods in detecting deepfake videos by incorporating CapsuleNet to preserve spatial information and LSTM to capture temporal inconsistencies across video frames. The model was trained and evaluated on the Deepfake Detection Challenge (DFDC) dataset, which contains over 124,000 videos with various face manipulation techniques. Experimental results demonstrate the effectiveness of the hybrid approach, achieving 88% accuracy and 88.30% recall on full-frame inputs, outperforming existing combined model approaches.

## Method Summary
The hybrid model uses ConvLSTM2D, Conv2D, CapsuleNet (Primary and Secondary Capsules), LSTM, and Dense layers. The architecture was trained on the DFDC dataset with videos resized to (5, 128, 128, 3) frames. Pre-trained Xception and InceptionV3 models were combined with the CapsuleNet model. Training was performed for 30 epochs using Adam optimizer and categorical crossentropy loss with a batch size of 4. The model was evaluated using accuracy, recall, and AUC metrics.

## Key Results
- Achieved 88% accuracy and 88.30% recall on full-frame inputs from DFDC dataset
- Outperformed existing combined model approaches by nearly 5% in accuracy
- Successfully implemented Grad-CAM for visual explanations of detection decisions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hybrid CNN-CapsuleNet-LSTM architecture detects deepfakes by leveraging spatial feature preservation from CapsuleNet and temporal inconsistency detection from LSTM.
- Mechanism: CNN layers extract initial spatial features, CapsuleNet preserves spatial relationships and orientation independence, and LSTM analyzes temporal inconsistencies across frames to detect deepfakes.
- Core assumption: Deepfakes introduce spatial and temporal artifacts that can be captured by this hybrid architecture.
- Evidence anchors:
  - [abstract] The model "addresses the limitations of traditional CNN-based methods in detecting deepfake videos by incorporating CapsuleNet to preserve spatial information and LSTM to capture temporal inconsistencies across video frames."
  - [section] "CNN lack in detecting fake videos when they are applied to inverse graphics. After every convolution layer the pooling layers of CNN cause loss of information and they are unable to identify a face if the features are not in correct order."
  - [corpus] Weak - no direct mention of this specific hybrid approach in related papers, but general concepts of CNN and LSTM for deepfake detection are present.
- Break condition: If the deepfake generation method does not introduce noticeable spatial or temporal inconsistencies, or if the model fails to learn these features during training.

### Mechanism 2
- Claim: Explainable AI using Grad-CAM provides visual explanations for the model's detection decisions, enhancing transparency and interpretability in deepfake detection.
- Mechanism: Grad-CAM highlights regions of the input frames that are most relevant for the model's classification decision, allowing humans to understand why a video was classified as real or fake.
- Core assumption: Visual explanations improve trust and understanding of the model's decisions.
- Evidence anchors:
  - [abstract] The study "implements Explainable AI (XAI) using Gradient-weighted Class Activation Mapping (Grad-CAM) to provide visual explanations for the model's detection decisions, enhancing transparency and interpretability in deepfake detection."
  - [section] "The purpose of Gradient-weighted Class Activation Mapping (Grad-CAM) is to make the convolutional neural networks more transparent by visualizing input regions which are relevant and important for predictions or for visual explanations."
  - [corpus] Weak - no direct mention of Grad-CAM in related papers, but general concepts of explainable AI for deepfake detection are present.
- Break condition: If Grad-CAM fails to highlight relevant regions or if the explanations are not understandable to humans.

### Mechanism 3
- Claim: The hybrid model outperforms existing combined model approaches in deepfake detection.
- Mechanism: The combination of CNN, CapsuleNet, and LSTM provides a more comprehensive feature extraction and analysis compared to using CNN or LSTM alone.
- Core assumption: Combining multiple architectures leads to better performance than using a single architecture.
- Evidence anchors:
  - [abstract] The proposed approach "achieves 88% accuracy and 88.30% recall on full-frame inputs, outperforming existing combined model approaches."
  - [section] "Our hybrid model has shown significantly improved results on the DFDC dataset compared to the above mentioned combined model approach. While considering full frame input sets our model shows nearly 5% more accuracy."
  - [corpus] Weak - no direct comparison of this specific hybrid model with existing approaches in related papers.
- Break condition: If the performance improvement is not significant or if the added complexity of the hybrid model does not justify the performance gain.

## Foundational Learning

- Concept: Convolutional Neural Networks (CNN)
  - Why needed here: CNN is used for initial spatial feature extraction from video frames.
  - Quick check question: What is the role of convolutional layers in a CNN?
- Concept: Capsule Networks
  - Why needed here: CapsuleNet preserves spatial relationships and orientation independence, which is crucial for detecting deepfakes.
  - Quick check question: How does CapsuleNet differ from traditional CNN in handling spatial information?
- Concept: Long Short-Term Memory (LSTM)
  - Why needed here: LSTM analyzes temporal inconsistencies across video frames to detect deepfakes.
  - Quick check question: What is the main advantage of using LSTM for sequence analysis in video frames?

## Architecture Onboarding

- Component map: Input → ConvLSTM2D → Conv2D → Primary Capsule → Secondary Capsule → LSTM → Dense Layers → Output
- Critical path: Input → ConvLSTM2D → Conv2D → Primary Capsule → Secondary Capsule → LSTM → Dense Layers → Output
- Design tradeoffs:
  - Using CapsuleNet instead of traditional CNN: Preserves spatial information but adds complexity
  - Using LSTM for temporal analysis: Captures inconsistencies but requires more computational resources
  - Using Grad-CAM for explainability: Provides transparency but adds overhead to the model
- Failure signatures:
  - Low accuracy: The model may not be learning the relevant features for deepfake detection
  - High loss: The model may be overfitting or underfitting the training data
  - Poor Grad-CAM explanations: The model may not be focusing on the correct regions of the input frames
- First 3 experiments:
  1. Train the model on a subset of the DFDC dataset and evaluate its performance on a validation set
  2. Visualize the Grad-CAM heatmaps for real and fake videos to ensure the model is focusing on relevant regions
  3. Compare the performance of the hybrid model with a baseline CNN-LSTM model to validate the improvement from using CapsuleNet

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different frame rates affect the accuracy of the hybrid model in detecting deepfake videos?
- Basis in paper: [explicit] The authors mention they would like to work on different frame rates as well, as increasing the frame rate could enlarge the dataset and improve the model's accuracy.
- Why unresolved: The study did not experiment with varying frame rates to assess their impact on model performance.
- What evidence would resolve it: Testing the model with datasets containing videos at different frame rates and comparing the accuracy and recall metrics.

### Open Question 2
- Question: What are the specific facial landmarks most commonly targeted in deepfake video creation, and how can this information be used to enhance detection methods?
- Basis in paper: [explicit] The authors aim to study the patterns generated by their model to identify primary approaches for making deepfake videos using face swapping and face warping technology, and to expose the basic facial landmarks being targeted.
- Why unresolved: The study mentions the intention to analyze patterns but does not provide specific results or insights into the facial landmarks.
- What evidence would resolve it: Detailed analysis of the activation heatmaps and Grad-CAM results to identify common facial landmarks manipulated in deepfake videos.

### Open Question 3
- Question: How does the proposed hybrid model perform when applied to datasets other than DFDC, such as those with different manipulation techniques or video qualities?
- Basis in paper: [explicit] The authors acknowledge the limitation of testing the model only on the DFDC dataset and express interest in applying the model to different datasets.
- Why unresolved: The study's performance evaluation is limited to the DFDC dataset, which may not represent all types of deepfake manipulations.
- What evidence would resolve it: Testing the model on multiple datasets with varying manipulation techniques and video qualities, and comparing performance metrics across these datasets.

## Limitations
- Limited evaluation to only the DFDC dataset, which may not represent all deepfake manipulation techniques
- Small batch size (4) may lead to overfitting and poor generalization
- Lack of extensive ablation studies to isolate the contribution of each architectural component

## Confidence
- Model effectiveness: Medium - strong DFDC performance but limited cross-dataset validation
- Explainability claims: Medium - Grad-CAM implemented but no user studies validating explanations
- Architectural claims: Low - limited analysis of feature maps and intermediate representations
- Performance comparisons: Medium - outperforms combined models but lacks comparison with current state-of-the-art

## Next Checks
1. Conduct extensive ablation studies to isolate the contribution of each component (CNN, CapsuleNet, LSTM)
2. Perform cross-dataset validation on multiple deepfake detection benchmarks
3. Implement user studies to evaluate the practical utility of Grad-CAM explanations in real-world deepfake detection scenarios