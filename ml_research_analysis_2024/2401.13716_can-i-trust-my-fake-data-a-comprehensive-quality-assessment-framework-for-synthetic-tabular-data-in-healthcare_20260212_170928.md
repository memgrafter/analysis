---
ver: rpa2
title: Can I trust my fake data -- A comprehensive quality assessment framework for
  synthetic tabular data in healthcare
arxiv_id: '2401.13716'
source_url: https://arxiv.org/abs/2401.13716
tags:
- data
- synthetic
- quality
- page
- metrics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study addresses the lack of a standardized framework for evaluating
  synthetic healthcare data quality for AI applications. A comprehensive literature
  review identified 616 metrics across five quality dimensions: similarity, usability,
  privacy, fairness, and carbon footprint.'
---

# Can I trust my fake data -- A comprehensive quality assessment framework for synthetic tabular data in healthcare

## Quick Facts
- arXiv ID: 2401.13716
- Source URL: https://arxiv.org/abs/2401.13716
- Reference count: 0
- Primary result: A comprehensive framework for evaluating synthetic healthcare data quality across five dimensions: similarity, usability, privacy, fairness, and carbon footprint

## Executive Summary
The study addresses the lack of a standardized framework for evaluating synthetic healthcare data quality for AI applications. Through a systematic literature review, the authors identified 616 metrics across five quality dimensions, revealing that most existing evaluations focus narrowly on similarity and usability. The proposed framework provides a stepwise approach aligned with EU medical device regulation, expanding existing frameworks to include fairness and carbon footprint. Benchmarking with the Dutch National Cancer Registry case demonstrated practical applicability while highlighting gaps in clinical validation and fairness assessment.

## Method Summary
The research combined a systematic literature review identifying 616 quality metrics for synthetic data with framework development and practical benchmarking. The review analyzed twelve existing frameworks, revealing diverging taxonomies and limited coverage of fairness and carbon footprint dimensions. The authors developed a hierarchical taxonomy organizing metrics across five dimensions and mapped them to six process stages from context definition through monitoring. Practical validation used a Dutch National Cancer Registry breast cancer cohort case study to test framework coverage and identify gaps in existing quality assurance practices.

## Key Results
- Literature review identified 616 metrics across five quality dimensions, with only 18% of articles evaluating all dimensions
- Proposed framework aligns with EU MDR and FDA AI/ML SaMD guidance while adding fairness and carbon footprint dimensions
- Benchmarking revealed practical applicability but highlighted lack of clinical validation and fairness metrics in current practices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework improves cross-disciplinary communication by unifying disparate taxonomies of synthetic data evaluation.
- Mechanism: By mapping and aligning divergent quality dimensions (similarity, usability, privacy, fairness, carbon footprint) into a single hierarchical taxonomy, the framework reduces semantic confusion and enables clearer shared understanding among technical and non-technical stakeholders.
- Core assumption: That conflicting terminology in prior literature is a primary barrier to practical adoption and trust-building.
- Evidence anchors:
  - [abstract] "Competing metrics with differing taxonomies for quality evaluation have been suggested, resulting in a complex landscape."
  - [section 3.1] "Our initial literature screening identified twelve frameworks for SD quality evaluation (details in chapter 2) with diverging taxonomy."
  - [corpus] Weak—no corpus neighbor explicitly addresses taxonomy unification.
- Break condition: If downstream users still interpret metrics differently due to domain-specific context.

### Mechanism 2
- Claim: Including fairness and carbon footprint expands the safety and sustainability assessment of synthetic data.
- Mechanism: By explicitly requiring fairness and carbon footprint metrics in evaluation, the framework surfaces risks (e.g., bias amplification, environmental cost) that are otherwise overlooked in traditional approaches focused on statistical similarity and utility.
- Core assumption: That omission of these dimensions in existing frameworks leads to incomplete risk assessment.
- Evidence anchors:
  - [abstract] "Despite the growing emphasis on algorithmic fairness and carbon footprint, these metrics were scarce in the literature review."
  - [section 3.2] "Our taxonomy comprises five dimensions for evaluating synthetic data: Similarity, Usability, Privacy, Fairness, and Carbon footprint..."
  - [corpus] Weak—no corpus neighbor directly addresses carbon footprint inclusion.
- Break condition: If fairness and carbon footprint metrics are not feasible or meaningful in certain healthcare contexts.

### Mechanism 3
- Claim: The stepwise approach aligns synthetic data evaluation with regulatory requirements (EU MDR, FDA AI/ML SaMD guidance).
- Mechanism: By structuring evaluation into six stages (priorities/context → training data → generation → synthetic data → analytical validation → clinical validation → monitoring), the framework ensures compliance with risk management and post-market surveillance expectations.
- Core assumption: That existing evaluation efforts are fragmented and do not map to clinical implementation pathways.
- Evidence anchors:
  - [abstract] "Our proposed framework provides a stepwise approach to assess synthetic data quality, aligning with EU medical device regulation (MDR) and FDA guidance..."
  - [section 3.4] "Our proposed framework provides a stepwise approach to assess synthetic data quality, aligning with EU medical device regulation (MDR) and FDA guidance..."
  - [corpus] Weak—no corpus neighbor explicitly maps stages to regulatory compliance.
- Break condition: If regulatory expectations evolve beyond the stages defined.

## Foundational Learning

- Concept: Deep generative models (GANs, autoencoders, diffusion models)
  - Why needed here: The framework specifically targets synthetic tabular healthcare data generated by these methods; understanding their behavior is essential to interpreting evaluation metrics.
  - Quick check question: What is the difference between mode collapse and mode invention in GANs, and why do both matter for synthetic data quality?

- Concept: Statistical similarity metrics (KS test, MMD, Wasserstein distance)
  - Why needed here: These metrics quantify how well synthetic data matches training data distributions, a core part of the "similarity" dimension.
  - Quick check question: When would you prefer Wasserstein distance over KL divergence for comparing synthetic vs. real data?

- Concept: Differential privacy and privacy risk metrics
  - Why needed here: Privacy preservation is a key dimension; understanding DP guarantees and post-hoc privacy risk assessment is necessary to evaluate synthetic data safely.
  - Quick check question: How does epsilon in differential privacy relate to the risk of membership inference attacks?

## Architecture Onboarding

- Component map: Quality dimension taxonomy (5 dimensions) -> Stage process pipeline (6 stages) -> Metric repository (616 metrics) -> Benchmark case (DNCR breast cancer cohort)
- Critical path: Stage 3 (synthetic data evaluation) -> Stage 4 (analytical validation) -> Stage 5 (clinical validation) for AI tool deployment
- Design tradeoffs:
  - Depth vs. breadth: Including fairness and carbon footprint increases comprehensiveness but adds evaluation complexity
  - Automation vs. expert judgment: Some metrics can be automated, but domain expertise is essential for clinical logic and fairness assessment
  - Privacy vs. utility: Stricter privacy guarantees (e.g., low epsilon DP) may reduce statistical similarity and usability
- Failure signatures:
  - Missing clinical logic evaluation -> unrealistic synthetic patients
  - Over-reliance on univariate metrics -> failure to capture multivariate dependencies
  - No fairness assessment -> biased downstream predictions
- First 3 experiments:
  1. Apply univariate similarity tests (KS, summary stats) to synthetic vs. real tabular healthcare data and visualize distribution differences
  2. Benchmark a classification model trained on synthetic data (TSTR) against one trained on real data (TRTR) using AUC and F1-score
  3. Run a membership inference attack simulation on synthetic data generated with differential privacy to estimate privacy loss

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective metrics for evaluating fairness in synthetic healthcare data across different demographic groups?
- Basis in paper: [explicit] The paper notes that despite growing emphasis on algorithmic fairness, integration of fairness perspectives in articles was limited, with only 6 articles found that applied fairness metrics.
- Why unresolved: The literature review found minimal research on fairness evaluation in synthetic healthcare data, with most studies focusing on similarity and usability metrics instead.
- What evidence would resolve it: Empirical studies comparing multiple fairness metrics across diverse healthcare datasets and demographic groups, demonstrating which metrics most effectively detect and prevent bias amplification in synthetic data generation.

### Open Question 2
- Question: How can carbon footprint be accurately measured and minimized in synthetic data generation processes without compromising data quality?
- Basis in paper: [explicit] The paper identifies that while 9 articles used computational resources as an evaluation metric, none quantified resource needs in terms of actual carbon footprint.
- Why unresolved: Current synthetic data evaluation frameworks lack standardized methods for measuring environmental impact, despite the substantial energy consumption of compute-intensive generative models.
- What evidence would resolve it: Development and validation of standardized carbon footprint measurement tools specifically for synthetic data generation, along with comparative studies showing trade-offs between environmental impact and data quality across different generation methods.

### Open Question 3
- Question: What is the optimal balance between privacy preservation and data utility in differentially private synthetic healthcare data?
- Basis in paper: [explicit] The paper notes that privacy was prioritized over realistic synthetic patients in the Dutch National Cancer Registry case, and only 6 articles evaluated privacy budget through differential privacy.
- Why unresolved: Limited research exists on the trade-offs between privacy guarantees and data utility in synthetic healthcare data, with most studies focusing on either extreme privacy or utility.
- What evidence would resolve it: Empirical studies quantifying the relationship between differential privacy parameters (epsilon values) and downstream model performance across various healthcare applications, establishing guidelines for optimal privacy-utility trade-offs.

## Limitations
- Coverage gaps exist in fairness and carbon footprint metrics, as these were scarce in the literature review
- Clinical validation was not included in the DNCR benchmark case, limiting real-world applicability evidence
- Specific regulatory requirements and how the framework addresses them are not detailed

## Confidence

- High Confidence: The systematic literature review methodology and identification of 616 quality metrics across five dimensions are well-supported
- Medium Confidence: The proposed framework's stepwise approach and alignment with regulatory requirements are plausible but require further validation
- Low Confidence: Practical applicability, particularly in clinical settings and for fairness and carbon footprint assessments, is uncertain due to limited evidence

## Next Checks

1. Clinical logic validation: Evaluate synthetic healthcare data for clinical realism and logic to ensure it captures meaningful medical relationships beyond statistical similarity
2. Fairness metric implementation: Develop and test fairness metrics specific to healthcare contexts to assess bias amplification in synthetic data
3. Carbon footprint assessment: Quantify the environmental impact of synthetic data generation methods to validate the framework's inclusion of carbon footprint as a quality dimension