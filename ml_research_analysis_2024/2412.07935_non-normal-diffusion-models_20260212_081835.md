---
ver: rpa2
title: Non-Normal Diffusion Models
arxiv_id: '2412.07935'
source_url: https://arxiv.org/abs/2412.07935
tags:
- diffusion
- where
- random
- distribution
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a generalization of diffusion models by relaxing
  the assumption that diffusion steps are normally distributed. The authors show that
  when step size goes to zero, the reversed process is invariant to the distribution
  of increments, revealing a previously unconsidered design parameter.
---

# Non-Normal Diffusion Models

## Quick Facts
- arXiv ID: 2412.07935
- Source URL: https://arxiv.org/abs/2412.07935
- Reference count: 40
- Primary result: Generalization of diffusion models by relaxing normality assumption on diffusion steps

## Executive Summary
This paper introduces a generalization of diffusion models by relaxing the assumption that diffusion steps are normally distributed. The authors demonstrate that when step size approaches zero, the reversed process becomes invariant to the distribution of increments, revealing a previously unconsidered design parameter. This framework enables explicit control over the distribution of diffusion steps and associated loss functions during training, with different choices producing qualitatively distinct generated samples. The proposed models achieve competitive performance on CIFAR10 in terms of negative log-likelihood and FID while offering unique sample characteristics.

## Method Summary
The method extends standard diffusion models by replacing Gaussian increments with arbitrary distributions while maintaining convergence to the same stochastic differential equation in the continuous limit. The framework introduces structured random walks where increments ∆xk can have any distribution, with the loss function becoming the KL divergence between the chosen forward and reverse distributions. Four model variants are implemented: Gaussian-Gaussian, Laplace-Laplace, Uniform-Gaussian, and Uniform-Laplace. Training follows established protocols from (Kingma et al., 2021) for log-likelihood and (Karras et al., 2022) for FID evaluation on CIFAR10 and downsampled ImageNet datasets.

## Key Results
- Non-normal diffusion models achieve competitive BPD (3.03) and FID (2.39) on CIFAR10
- Different increment distributions produce qualitatively distinct samples (e.g., less saturated images with Uniform-Gaussian)
- Structured invariance principle holds across various distribution choices while maintaining convergence
- Framework enables explicit control over loss functions through distribution selection

## Why This Works (Mechanism)

### Mechanism 1
Relaxing the normality assumption on diffusion step increments preserves the limiting distribution as step size approaches zero. The structured random walk formulation allows arbitrary distributions for increments ∆xk while still converging to the target SDE solution. Core assumption: drift and diffusion functions are Lipschitz continuous with linear growth conditions. Evidence anchors: [abstract] states invariance occurs as step size goes to zero, and [section] presents Theorem 3.2 proving convergence in distribution.

### Mechanism 2
Different choices of increment distributions enable explicit control over the training loss function. By selecting different distributions for q(∆xk|xk) and pθ(∆xk|xk), the KL divergence term Lk takes different forms, allowing control over whether the loss behaves like L2, L1, or hybrid norms. Core assumption: KL divergence between chosen distributions has a tractable closed form. Evidence anchors: [abstract] notes different distributions result in qualitatively different samples.

### Mechanism 3
The structural property of random walks allows decomposition into tractable auxiliary processes with the same limit. The structured random walk can be decomposed into auxiliary processes that converge to the same diffusion process, enabling proof of convergence without relying on independent increments. Core assumption: the structured random walk property holds for increments. Evidence anchors: [section] states convergence occurs with surprisingly few assumptions.

## Foundational Learning

- Concept: Donsker's Invariance Principle
  - Why needed here: Provides theoretical foundation for convergence of random walks to diffusion processes
  - Quick check question: What conditions must hold for a random walk to converge to a Brownian motion?

- Concept: Stochastic Differential Equations (SDEs)
  - Why needed here: Diffusion models are fundamentally based on solving SDEs in reverse time
  - Quick check question: How do drift and diffusion functions relate to the Fokker-Planck equation?

- Concept: Score Matching
  - Why needed here: Training objective minimizes difference between true and estimated score functions
  - Quick check question: What is the relationship between score matching and maximum likelihood estimation?

## Architecture Onboarding

- Component map:
  Score network ϵθ(x,t) -> Forward diffusion process with arbitrary increment distribution -> Reverse diffusion process using learned score function -> Loss function dependent on chosen increment distributions

- Critical path:
  1. Sample from forward diffusion with chosen increment distribution
  2. Compute score network output
  3. Calculate loss based on KL divergence between distributions
  4. Backpropagate through score network
  5. Generate samples using reverse diffusion

- Design tradeoffs:
  - Choice of increment distribution affects sample quality and training dynamics
  - More complex distributions may improve sample diversity but increase computational cost
  - Tradeoff between theoretical convergence guarantees and practical performance

- Failure signatures:
  - Mode collapse when training loss decreases but sample diversity is poor
  - Numerical instability when regularity conditions are violated
  - Training divergence when chosen distributions lead to intractable KL divergences

- First 3 experiments:
  1. Implement Gaussian-Gaussian model as baseline and verify BPD/FID matches literature
  2. Switch to Laplace-Laplace model and observe changes in sample saturation
  3. Implement Uniform-Gaussian model to test hybrid distribution effects on loss landscape

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical claims rely heavily on Lipschitz continuity and linear growth conditions that are stated rather than empirically validated
- Experimental validation limited to image datasets (CIFAR10, downsampled ImageNet) with standard architectures
- Lack of ablation studies examining impact of different increment distributions beyond the four demonstrated cases

## Confidence
- High Confidence: Convergence of structured random walks to SDEs under stated regularity conditions (Theorem 3.2)
- Medium Confidence: Different increment distributions produce qualitatively different samples (supported by FID scores)
- Low Confidence: Framework enables explicit control over training loss functions (theoretically sound but practical benefits not rigorously demonstrated)

## Next Checks
1. Implement additional increment distributions (e.g., t-distribution, exponential) and verify structured invariance principle holds across broader range of distributions
2. Systematically relax Lipschitz continuity and linear growth conditions to identify exact failure points, measuring both training stability and sample quality degradation
3. Apply framework to non-image domains (e.g., tabular data, audio) using appropriate architectures to validate general applicability beyond demonstrated image experiments