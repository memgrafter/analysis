---
ver: rpa2
title: Game Generation via Large Language Models
arxiv_id: '2404.08706'
source_url: https://arxiv.org/abs/2404.08706
tags:
- game
- goal
- avatar
- level
- vgdl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates game generation via large language models
  (LLMs) using video game description language (VGDL). The proposed LLM-based framework
  generates game rules and levels simultaneously through text-based prompts.
---

# Game Generation via Large Language Models

## Quick Facts
- arXiv ID: 2404.08706
- Source URL: https://arxiv.org/abs/2404.08706
- Authors: Chengpeng Hu; Yunlong Zhao; Jialin Liu
- Reference count: 38
- Key outcome: GPT-4 with complete context successfully generated correct games in all trials, while other models and incomplete prompts failed to produce both correct rules and levels.

## Executive Summary
This paper investigates game generation via large language models (LLMs) using video game description language (VGDL). The proposed LLM-based framework generates game rules and levels simultaneously through text-based prompts. Experiments with Maze games across different LLM models (GPT-3.5, GPT-4, Gemma 7B) and prompt variations show that including proper context in prompts is critical for generating correct games. GPT-4 with complete context successfully generated correct games in all trials, while other models and incomplete prompts failed to produce both correct rules and levels. The work highlights LLMs' potential for procedural content generation while revealing limitations in rule understanding and self-correction capabilities.

## Method Summary
The method employs a framework (LLMGG) that takes text-based prompts as input and generates VGDL representations of game rules and levels. The framework tests seven different prompt configurations with varying context elements (instruction, level, grammar, example, base, C1, C2) across three LLM models (GPT-3.5, GPT-4, Gemma 7B). Each prompt is tested for 10 trials, and the generated VGDL text is validated for parsability, logical consistency, and mappability. The validation process checks whether the generated games can be correctly interpreted and played using the GVGAI gym environment.

## Key Results
- GPT-4 with complete context successfully generated correct games in all trials
- Including proper context in prompts is critical for generating correct games
- LLMs struggle with understanding VGDL syntax rules correctly, especially regarding interaction order

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can generate syntactically valid VGDL representations when provided with explicit context about grammar, sprite classes, and interaction methods.
- Mechanism: In-context learning allows the LLM to adapt its output to match the structural requirements of VGDL by using examples and explicit syntax rules in the prompt.
- Core assumption: The LLM has sufficient pre-training exposure to structured text formats and can generalize from examples.
- Evidence anchors:
  - [abstract] Experiments show that prompts with proper context successfully generated correct games.
  - [section] Section III-B explains that context such as grammar and examples improve VGDL output quality.
  - [corpus] Related work shows LLMs are effective in PCG when fine-tuned or given explicit examples.

### Mechanism 2
- Claim: Including predefined character-to-sprite mappings in prompts prevents hallucinations and ensures consistent level design.
- Mechanism: Explicitly defining LevelMapping in prompts removes ambiguity in how characters translate to game objects, avoiding mismatches between rules and levels.
- Core assumption: LLMs tend to invent their own mappings when not given explicit instructions, leading to inconsistencies.
- Evidence anchors:
  - [section] Section IV-C shows that without predefined mappings, LLMs produced inconsistent mappings between rules and levels.
  - [abstract] Correct games were only generated when proper context (including mappings) was included.
  - [corpus] PCG research emphasizes the importance of structured input for reliable output.

### Mechanism 3
- Claim: LLMs struggle with understanding and applying VGDL syntax rules correctly, especially regarding interaction order.
- Mechanism: LLMs apply natural language intuition (subject-verb-object) to VGDL interactions, leading to incorrect interpretations of killSprite and removeSprite syntax.
- Core assumption: The syntax of VGDL interactions does not align with typical subject-verb-object order, causing misinterpretation.
- Evidence anchors:
  - [section] Section IV-D and IV-E describe how LLMs incorrectly explained killSprite interactions, believing the first sprite was removed when it was actually the second.
  - [abstract] Findings highlight limitations in rule understanding and self-correction capabilities.
  - [corpus] Survey papers note that LLMs often misinterpret structured syntax without explicit guidance.

## Foundational Learning

- Concept: Video Game Description Language (VGDL)
  - Why needed here: VGDL is the target representation format for both game rules and levels in this framework.
  - Quick check question: What are the four main components of a VGDL game description?
- Concept: In-context learning
  - Why needed here: LLMs rely on examples and explicit context in prompts to generate correct outputs without fine-tuning.
  - Quick check question: How does adding example VGDL games to a prompt improve generation quality?
- Concept: Procedural Content Generation (PCG)
  - Why needed here: The paper applies LLMs to PCG by generating both rules and levels simultaneously.
  - Quick check question: Why is generating both rules and levels together more challenging than generating levels alone?

## Architecture Onboarding

- Component map:
  - Prompt Construction → LLM Input
  - LLM Model (GPT-3.5/4, Gemma 7B) → Text Generation
  - VGDL Text Output → Syntax and Logic Validation
  - Validation Engine → Pass/Fail Decision
  - Game Engine (GVGAI Gym) → Interactive Game
- Critical path:
  1. Construct prompt with complete context (Instruction, Level, Grammar, Example).
  2. Send prompt to LLM.
  3. Validate generated text for parsability, logical consistency, and mappability.
  4. Convert valid VGDL to interactive game if all checks pass.
- Design tradeoffs:
  - Model choice: GPT-4 performs better but is more expensive; Gemma 7B is cheaper but less reliable.
  - Prompt verbosity: More context improves quality but increases prompt size and cost.
  - Validation strictness: Tighter validation ensures correctness but may reject borderline valid outputs.
- Failure signatures:
  - Unparsable: Syntax errors or missing required VGDL blocks.
  - Illogical: Incomplete interactions or wrong termination conditions.
  - Unmappable: Character-to-sprite mapping mismatches between rules and levels.
- First 3 experiments:
  1. Test each LLM with minimal context (P1) to establish baseline failure rate.
  2. Add grammar definitions (P2-P4) to evaluate improvement in parsability.
  3. Include complete context with examples (P7) to measure maximum success rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of different types of context in prompts affect the quality and correctness of generated games beyond the Maze game example?
- Basis in paper: [explicit] The paper investigates the effect of different combinations of context in prompts on the generation of Maze games.
- Why unresolved: The experiments are limited to Maze games, and it is unclear whether the findings generalize to other types of games or more complex game designs.
- What evidence would resolve it: Conducting experiments with a variety of game types and complexities, comparing the effectiveness of different context combinations across these games.

### Open Question 2
- Question: What are the underlying reasons for LLMs' inability to self-correct when provided with feedback about incorrect game logic?
- Basis in paper: [explicit] The paper discusses the difficulty of LLMs in self-correcting after being informed of incorrect game logic, such as the wrong interaction method "killSprite" instead of "removeSprite".
- Why unresolved: The paper identifies the problem but does not explore the reasons behind LLMs' limitations in understanding and applying corrections to their generated content.
- What evidence would resolve it: Analyzing the internal mechanisms of LLMs when processing corrections, potentially through controlled experiments that isolate specific aspects of understanding and correction.

### Open Question 3
- Question: How can the framework be extended to generate 3D games, and what additional challenges might arise in this context?
- Basis in paper: [explicit] The paper mentions future work to extend the framework to 3D game generation but does not elaborate on the specifics or challenges.
- Why unresolved: The transition from 2D to 3D game generation involves additional complexities in terms of spatial representation, interaction design, and level layout that are not addressed in the current framework.
- What evidence would resolve it: Developing a prototype extension of the framework for 3D games, identifying and addressing the specific challenges encountered in the process.

## Limitations

- The study relies entirely on controlled experiments with a single game genre (Maze), limiting generalizability to other game types or more complex mechanics
- Success rates are binary (correct/incorrect) without reporting intermediate metrics like partial success or quality scores for failed generations
- No analysis of generation speed or cost implications across different LLM models and prompt sizes

## Confidence

- High confidence: GPT-4 with complete context generates correct games consistently, as evidenced by direct experimental results
- Medium confidence: Context completeness directly impacts generation quality, though the specific contribution of each context element needs further isolation
- Low confidence: Claims about LLMs' general limitations in rule understanding, as these are based on a single syntax interpretation challenge rather than broader evaluation

## Next Checks

1. Test the framework across multiple game genres (platformers, puzzles, arcade) to assess generalizability beyond Maze games
2. Conduct ablation studies isolating the impact of each context element (grammar, examples, mappings) on generation success rates
3. Evaluate the cost-benefit tradeoff by measuring generation quality, speed, and API costs across different LLM models with varying prompt lengths