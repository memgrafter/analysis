---
ver: rpa2
title: Adapting Chat Language Models Using Only Target Unlabeled Language Data
arxiv_id: '2412.11704'
source_url: https://arxiv.org/abs/2412.11704
tags:
- chat
- language
- target
- elchat
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of adapting chat language models
  to new target languages when only unlabeled target data is available, without access
  to a base model or target chat data. The authors propose ElChat, a method that adapts
  a chat model directly using vocabulary expansion (VE) and then recovers chat abilities
  by merging the adapted model with the source chat model and copying special token
  weights.
---

# Adapting Chat Language Models Using Only Target Unlabeled Language Data

## Quick Facts
- arXiv ID: 2412.11704
- Source URL: https://arxiv.org/abs/2412.11704
- Reference count: 40
- Primary result: ElChat adapts chat models to new languages using only unlabeled target data, achieving superior chat and instruction-following performance compared to previous methods

## Executive Summary
This paper addresses the challenge of adapting chat language models to new target languages when only unlabeled target data is available, without access to a base model or target chat data. The authors propose ElChat, a method that adapts a chat model directly using vocabulary expansion (VE) and then recovers chat abilities by merging the adapted model with the source chat model and copying special token weights. ElChat achieves superior performance in chat and instruction-following tasks compared to the previous state-of-the-art method (Chat Vector), while being competitive and more robust in target language and safety tasks. The method also provides comparable inference speedups to standard VE approaches.

## Method Summary
ElChat adapts chat language models to new target languages using only unlabeled target data through a three-step process. First, vocabulary expansion (VE) is performed on the source chat model using an auxiliary tokenizer trained on target data, adding 10K new tokens and continuing pre-training on target data with only embedding, LM head, and top/bottom layers fine-tuned. Second, model merging using SLERP interpolation combines the source chat model's abilities with the target-adapted model's language knowledge. Third, special token weights are copied from the source model to the target model to preserve critical structural information. This approach achieves superior chat and instruction-following performance while maintaining target language capabilities.

## Key Results
- ElChat achieves superior chat and instruction-following performance compared to Chat Vector baseline
- The method provides comparable inference speedups to standard VE approaches
- ElChat demonstrates robustness across six target languages (French, German, Russian, Hindi, Korean, Japanese) while maintaining competitive performance in safety and target language tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Model merging restores chat and instruction-following abilities by combining source model's chat capabilities with target model's language proficiency
- Mechanism: SLERP interpolation between corresponding layers of source chat model (Ms) and target-adapted model (Mt), preserving distinct parametric knowledge from each
- Core assumption: Different layers encode separable representations for chat abilities vs target language knowledge
- Evidence anchors:
  - [abstract]: "model merging to integrate distinct parametric knowledge from the source and target models"
  - [section 3]: "Spherical linear interpolation (SLERP) to merge each layer of the source and adapted models"
  - [corpus]: Weak - neighbors discuss model merging but not specifically for chat model adaptation
- Break condition: If chat abilities and language knowledge are encoded in same parameters, merging cannot separate them

### Mechanism 2
- Claim: Copying special token weights transfers critical structural information needed for instruction-following
- Mechanism: Directly copy embedding vectors and language modeling head weights for special tokens (e.g., <im_start>) from source to target model
- Core assumption: Special tokens have stable, task-critical representations that don't need adaptation to target language
- Evidence anchors:
  - [abstract]: "reuse the weights of special tokens from the source model"
  - [section 3]: "copy all the special token weights from the source model to the adapted model"
  - [corpus]: Missing - no direct evidence about special token weight copying in adaptation
- Break condition: If special tokens require target language adaptation for proper function

### Mechanism 3
- Claim: VE on chat model improves target language performance while preserving chat abilities through targeted modifications
- Mechanism: Expand vocabulary and continue pre-training only top/bottom layers and embedding/LM head, leaving core chat capabilities intact
- Core assumption: Target language improvements localize to specific model components (embedding, LM head, outer layers)
- Evidence anchors:
  - [section 3]: "calibrate only the parts closely related to the encoding and decoding of the target language"
  - [section 4.3]: "train the embedding, LM head, and the top and bottom two layers"
  - [corpus]: Weak - neighbors discuss adaptation but not specific layer selection strategy
- Break condition: If target language improvements require deeper modifications affecting chat abilities

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: Explains why direct adaptation degrades chat abilities and why ElChat's recovery mechanisms are necessary
  - Quick check question: What happens to a model's original capabilities when trained on new data without protection mechanisms?

- Concept: Model merging via interpolation
  - Why needed here: Core technique for combining source chat abilities with target language knowledge
  - Quick check question: How does SLERP differ from simple linear interpolation when merging neural network weights?

- Concept: Vocabulary expansion and tokenization
  - Why needed here: Fundamental to understanding how VE works and why it causes overfragmentation in underrepresented languages
  - Quick check question: Why does adding new tokens require resizing embedding and language modeling head matrices?

## Architecture Onboarding

- Component map: Source chat model (Ms) -> Auxiliary tokenizer -> VE process -> Target-adapted model (Mt) -> Model merging (SLERP) -> Special token copying
- Critical path: VE → Merge → Copy (sequential dependencies)
- Design tradeoffs:
  - VE layer selection (top/bottom 2 + embedding/LM head) vs full fine-tuning
  - SLERP vs linear interpolation for model merging
  - Number of new tokens (k=10K) vs computational cost
  - Special token copying vs learning target-specific special tokens
- Failure signatures:
  - Chat abilities not recovered → Check merge interpolation and special token copying
  - Target language performance degraded → Verify VE layer selection and pre-training effectiveness
  - Inference speed not improved → Confirm vocabulary expansion was successful
- First 3 experiments:
  1. Apply VE to source chat model on target data, measure chat ability degradation
  2. Add model merging step, measure recovery of chat abilities
  3. Add special token copying, verify improved instruction-following performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal vocabulary size for language adaptation of chat models using vocabulary expansion?
- Basis in paper: [explicit] The paper discusses using an auxiliary tokenizer with a vocabulary size of 50K and adding 10K new tokens, following Tejaswi et al. (2024). However, it does not explore whether this is optimal for chat models.
- Why unresolved: The paper assumes standard VE parameters without investigating the impact of different vocabulary sizes on chat model performance.
- What evidence would resolve it: Systematic experiments varying vocabulary sizes (e.g., 20K, 50K, 100K new tokens) and measuring performance across safety, chat, instruction-following, and target language tasks.

### Open Question 2
- Question: How does the choice of model merging method affect the effectiveness of ElChat?
- Basis in paper: [explicit] The paper primarily uses SLERP for model merging but briefly mentions testing linear merging with similar results. It acknowledges that more recent methods like TIES and DARE-TIES might perform better but does not investigate them.
- Why unresolved: The paper only compares SLERP with linear merging and does not explore more advanced merging techniques that could potentially yield better results.
- What evidence would resolve it: Experiments comparing ElChat with different merging methods (SLERP, linear, TIES, DARE-TIES) on the same set of tasks to determine which yields the best performance.

### Open Question 3
- Question: What is the impact of iterative model merging on ElChat's performance in low-resource language settings?
- Basis in paper: [inferred] The qualitative analysis section mentions that improving target language abilities during VE while mitigating catastrophic forgetting could be addressed by making iterative model merging applicable to low-resource settings.
- Why unresolved: The paper does not explore iterative merging approaches, which could potentially enhance performance by allowing multiple rounds of adaptation and merging.
- What evidence would resolve it: Experiments applying iterative merging (as proposed by Alexandrov et al., 2024) to ElChat, comparing performance with single-step merging across various tasks and languages.

## Limitations
- Limited scope of evaluation: Experiments focus on six target languages but don't explore full diversity of language families or low-resource languages
- Dependency on source chat models: Method requires access to specific pre-trained chat models, effectiveness may vary with different architectures
- Trade-off between chat and language performance: Paper doesn't thoroughly analyze optimal balance between preserving source chat abilities versus improving target language capabilities

## Confidence
- High Confidence: Claims about overall effectiveness of ElChat's three-step process in achieving superior chat and instruction-following performance
- Medium Confidence: Claims about inference efficiency improvements and robustness across different target languages
- Low Confidence: Claims about general applicability to arbitrary source chat models and target languages beyond tested languages

## Next Checks
1. **Cross-linguistic generalization test**: Evaluate ElChat on a broader range of target languages including languages from different families (e.g., Arabic, Thai, Swahili) and scripts to verify that the method's effectiveness isn't limited to Indo-European or East Asian languages.

2. **Source model dependency analysis**: Systematically test ElChat with different types of source chat models (different architectures, sizes, and training objectives) to quantify how sensitive the method is to the characteristics of the source model.

3. **Special token adaptation study**: Conduct ablation studies comparing the special token copying approach against methods that learn target-specific special token representations, particularly for languages with significantly different tokenization requirements.