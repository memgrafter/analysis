---
ver: rpa2
title: Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?
arxiv_id: '2407.17730'
source_url: https://arxiv.org/abs/2407.17730
tags:
- text
- evaluation
- language
- conversations
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the feasibility of using large language models
  (LLMs) for Cognitive Behavioral Therapy (CBT). A comprehensive automatic evaluation
  framework is designed to assess the CBT counseling ability of LLMs, including evaluation
  of emotion tendency, structured dialogue pattern, and inquiry ability.
---

# Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?

## Quick Facts
- arXiv ID: 2407.17730
- Source URL: https://arxiv.org/abs/2407.17730
- Authors: Hao Shen; Zihan Li; Minqiang Yang; Minghui Ni; Yongfeng Tao; Zhengyang Yu; Weihao Zheng; Chen Xu; Bin Hu
- Reference count: 40
- Primary result: Large language models can perform CBT tasks with knowledge base integration, with ChatGPT-3.5-turbo showing superior performance

## Executive Summary
This paper investigates whether large language models can effectively conduct Cognitive Behavioral Therapy by designing a comprehensive automatic evaluation framework. The study evaluates four prominent LLMs across multiple dimensions including emotion tendency, structured dialogue patterns, and inquiry ability, both with and without CBT knowledge base integration. Results demonstrate that while general LLMs have limitations in therapeutic contexts, their performance significantly improves when equipped with domain-specific knowledge. ChatGPT-3.5-turbo emerges as the most capable model for CBT tasks among those tested, particularly after knowledge base integration.

## Method Summary
The researchers developed a multi-faceted evaluation framework to assess LLMs' CBT capabilities, focusing on three core aspects: emotion tendency analysis to measure positive vs negative emotional responses, structured dialogue pattern evaluation to assess adherence to CBT conversational flow, and inquiry ability measurement to evaluate question-asking effectiveness. Four LLMs (ChatGPT-3.5-turbo, ERNIE-3.5-8K, iFlytek Spark V3.0, and ChatGLM-3-turbo) were tested under both single-turn and multi-turn conversation scenarios, with and without integration of a comprehensive CBT knowledge base. The framework uses automated metrics rather than human expert validation, providing quantitative assessments of model performance across the CBT task dimensions.

## Key Results
- ChatGPT-3.5-turbo demonstrated the highest overall performance in CBT tasks among all evaluated models
- Knowledge base integration significantly improved all models' CBT counseling capabilities
- Multi-turn conversations showed better performance than single-turn interactions for CBT tasks
- General LLMs exhibited limitations in structured dialogue patterns and inquiry abilities without knowledge base support

## Why This Works (Mechanism)
None

## Foundational Learning
- **CBT Knowledge Base Integration**: Provides structured therapeutic frameworks and techniques that guide LLM responses toward evidence-based practices
  - Why needed: General LLMs lack specialized psychological training and therapeutic protocols
  - Quick check: Compare performance with and without knowledge base integration across all models

- **Structured Dialogue Patterns**: Ensures conversations follow CBT methodology with appropriate opening, exploration, and closing phases
  - Why needed: CBT requires specific conversational flow to achieve therapeutic goals
  - Quick check: Analyze dialogue structure adherence scores across different conversation lengths

- **Inquiry Ability Metrics**: Measures the quality and effectiveness of therapeutic questions in uncovering cognitive distortions
  - Why needed: Effective questioning is fundamental to CBT's cognitive restructuring approach
  - Quick check: Evaluate question types and their correlation with positive emotional outcomes

## Architecture Onboarding
- **Component Map**: User Input -> LLM Processing -> CBT Knowledge Base Integration -> Evaluation Metrics -> Performance Output
- **Critical Path**: Knowledge base integration is essential for achieving therapeutic effectiveness, particularly in structured dialogue and inquiry tasks
- **Design Tradeoffs**: Automated evaluation vs. human expert validation - automation enables scalability but may miss nuanced therapeutic effectiveness
- **Failure Signatures**: Without knowledge base integration, models show poor structured dialogue adherence and limited inquiry capabilities
- **First Experiments**:
  1. Test knowledge base integration impact on emotion tendency scores
  2. Compare single-turn vs multi-turn performance across all models
  3. Evaluate inquiry ability improvement with structured CBT guidance

## Open Questions the Paper Calls Out
### Open Question 1
- Question: What are the long-term therapeutic outcomes of using LLM-based CBT compared to traditional in-person CBT?
- Basis in paper: [inferred] The paper discusses the potential of LLMs in psychological counseling but does not provide data on long-term outcomes or efficacy compared to traditional methods.
- Why unresolved: The study focuses on evaluating the CBT counseling ability of LLMs through automatic metrics and does not extend to longitudinal studies or clinical trials.
- What evidence would resolve it: Long-term clinical studies comparing patient outcomes, symptom reduction, and relapse rates between LLM-based CBT and traditional CBT.

### Open Question 2
- Question: How do different cultural contexts affect the effectiveness of LLM-based CBT?
- Basis in paper: [explicit] The paper mentions collecting CBT dialogues from both Chinese and English sources, indicating an awareness of cultural differences, but does not explore how these differences impact LLM effectiveness.
- Why unresolved: The study does not address cultural variations in therapy or how LLMs might need to be adapted for different cultural contexts.
- What evidence would resolve it: Comparative studies of LLM-based CBT effectiveness across diverse cultural groups, including adaptations and modifications for cultural sensitivity.

### Open Question 3
- Question: What are the privacy and security risks associated with using LLMs for CBT, and how can they be mitigated?
- Basis in paper: [explicit] The paper acknowledges privacy concerns related to the use of LLMs in CBT, noting that models require access to conversation history and personal information.
- Why unresolved: The study does not delve into specific privacy risks or propose detailed mitigation strategies.
- What evidence would resolve it: Research on data security measures, encryption methods, and privacy-preserving techniques specifically tailored for LLM-based mental health applications.

## Limitations
- Evaluation relies entirely on automated metrics rather than human expert validation of therapeutic effectiveness
- Does not address safety concerns or ethical implications for vulnerable populations
- Limited to Chinese language models, potentially limiting generalizability
- Focuses on structured dialogues without capturing full complexity of real-world therapeutic relationships

## Confidence
- **High Confidence**: ChatGPT-3.5-turbo outperforms other models in CBT tasks with knowledge base integration
- **Medium Confidence**: Framework comprehensiveness for CBT assessment without clinical validation
- **Low Confidence**: Claims about clinical deployment readiness or replacing human therapists

## Next Checks
1. Conduct human expert evaluation comparing LLM-generated responses to trained CBT therapists across multiple clinical scenarios
2. Test model performance across diverse demographic populations and cultural contexts
3. Implement longitudinal studies examining how LLMs handle complex cases requiring safety assessment and crisis intervention over extended therapeutic engagements