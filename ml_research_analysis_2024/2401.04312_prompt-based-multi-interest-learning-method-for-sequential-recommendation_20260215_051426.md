---
ver: rpa2
title: Prompt-based Multi-interest Learning Method for Sequential Recommendation
arxiv_id: '2401.04312'
source_url: https://arxiv.org/abs/2401.04312
tags:
- user
- multi-interest
- embeddings
- learning
- interactions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a prompt-based multi-interest learning method
  (PoMRec) for sequential recommendation. Existing methods directly feed user interactions
  into multi-interest extraction and aggregation modules without considering their
  different learning objectives or user interaction dispersion.
---

# Prompt-based Multi-interest Learning Method for Sequential Recommendation

## Quick Facts
- **arXiv ID**: 2401.04312
- **Source URL**: https://arxiv.org/abs/2401.04312
- **Reference count**: 39
- **Key outcome**: PoMRec outperforms state-of-the-art multi-interest learning methods, achieving up to 9.62% improvement in Recall@5 and 10.77% improvement in NDCG@5

## Executive Summary
This paper introduces PoMRec, a prompt-based multi-interest learning method for sequential recommendation that addresses limitations in existing approaches. Traditional methods feed user interactions directly into multi-interest extraction and aggregation modules without considering their different learning objectives or user interaction dispersion. PoMRec overcomes these limitations by inserting specific learnable prompts into user interactions to adapt them to different learning objectives, and by using both mean and variance embeddings to comprehensively capture user interests. The method achieves state-of-the-art performance on three public datasets while using significantly fewer parameters than competing approaches.

## Method Summary
PoMRec uses learnable prompt embeddings (PF for multi-interest extraction, PG for multi-interest weight prediction) inserted at the beginning of user interaction sequences to condition representations differently for each module's objective. The method employs self-attention to cluster user interactions into interest groups, then calculates both mean (centrality) and variance (dispersion) embeddings for each cluster. A trade-off parameter λ balances these components. Multi-interest weights are predicted using attention-based aggregation with an MLP, and final user embeddings are created through weighted summation of interest embeddings. The model is trained using pairwise BPR loss optimization.

## Key Results
- Achieves up to 9.62% improvement in Recall@5 and 10.77% improvement in NDCG@5 compared to state-of-the-art methods
- Uses significantly fewer parameters than competing approaches by using one item embedding instead of two
- Outperforms baselines across three public datasets (ML-1M, Movies & TV, and one unnamed dataset)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompt embeddings make user interaction embeddings adaptive to the learning objectives of different modules
- Mechanism: By inserting learnable prompt embeddings at the beginning of the user interaction sequence, the model can condition the representations differently for each module's objective
- Core assumption: The same user interaction sequence can benefit from different conditioning depending on whether it's being used to extract interests or predict interest weights
- Evidence anchors: [abstract] "specific prompts are inserted into user interactions to make them adaptive to the extractor and aggregator"
- Break condition: If the prompts become too large relative to the interaction embeddings, they may overshadow the actual user behavior signal

### Mechanism 2
- Claim: Using both mean and variance embeddings captures both centrality and dispersion of user interests
- Mechanism: The model calculates both the mean (centrality) and variance (dispersion) of user interactions within each interest cluster, combining them with a trade-off parameter λ
- Core assumption: User interests are better represented by both where interactions cluster (centrality) and how spread out they are (dispersion)
- Evidence anchors: [abstract] "we utilize both the mean and variance embeddings of user interactions to embed the user multiple interests for the comprehensively user interest learning"
- Break condition: If λ is set too high, variance may dominate and make the model overly sensitive to outliers in user behavior

### Mechanism 3
- Claim: Self-attention mechanism effectively clusters user interactions into interest groups
- Mechanism: The model uses self-attention to compute attention weights that softly cluster user interactions, then derives interest embeddings from these clusters
- Core assumption: Self-attention can identify meaningful groupings of user interactions that correspond to different interests
- Evidence anchors: [abstract] "we adopt the self-attention mechanism to softly cluster the prompt-augmented user interactions"
- Break condition: If the number of interests K is set incorrectly relative to actual user diversity, the clustering may be meaningless

## Foundational Learning

- Concept: Self-attention mechanism
  - Why needed here: Used to compute attention weights for clustering user interactions into interest groups and aggregating prompt-augmented embeddings
  - Quick check question: How does the softmax operation in self-attention ensure that attention weights sum to 1 across all user interactions for each interest?

- Concept: Variational Autoencoder principles
  - Why needed here: The paper's approach of using both mean and variance embeddings is conceptually similar to VAE's use of both parameters to represent distributions
  - Quick check question: Why might representing user interests as distributions (rather than point estimates) be more robust than traditional methods?

- Concept: Bayesian personalized ranking
  - Why needed here: The optimization objective uses pairwise ranking to ensure positive items are ranked higher than negative items
  - Quick check question: What's the intuition behind using sigmoid(yi - yj) in the loss function rather than just maximizing yi directly?

## Architecture Onboarding

- Component map:
  Input layer: User interaction sequence → Item embeddings + Positional embeddings
  Prompt layer: Learnable prompt embeddings (PF, PG) inserted at sequence start
  Multi-interest extraction: Self-attention → Mean/variance calculation → K interest embeddings
  Multi-interest weight prediction: Self-attention → MLP → K interest weights
  Aggregation: Weighted sum of interest embeddings → User embedding
  Output layer: Dot product with item embeddings → Predicted ratings

- Critical path: User interaction sequence → Prompt insertion → Multi-interest extraction → Multi-interest weight prediction → Weighted aggregation → Rating prediction

- Design tradeoffs:
  - Number of interests K vs. model complexity: More interests capture diversity better but increase parameters and may overfit
  - Prompt embeddings vs. item embeddings: Prompts adapt inputs but add parameters; the paper uses fewer parameters than baselines by using one item embedding instead of two
  - Mean vs. variance weighting (λ): Higher λ captures dispersion better but may make model unstable

- Failure signatures:
  - If K is too small: All interests will be similar, variance embeddings will be nearly identical
  - If K is too large: Interests will fragment, model may memorize rather than generalize
  - If λ is too high: Variance will dominate, making predictions sensitive to outlier interactions
  - If prompt embeddings are too large: They may overshadow actual user behavior signal

- First 3 experiments:
  1. Baseline test: Run with K=1 (single interest) to verify the multi-interest framework adds value
  2. Prompt ablation: Compare with and without prompt embeddings to measure their contribution
  3. λ sensitivity: Test different λ values (0, 1, 3, 5) to find optimal balance between centrality and dispersion

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of the number of user interests (K) impact the performance of PoMRec on different types of datasets (e.g., datasets with highly concentrated vs. diverse user interests)?
- Basis in paper: [explicit] The paper mentions that the most suitable K for the ML-1M dataset is 2, while that for the Movies & TV dataset is 3, and suggests this may be because user interests in ML-1M are more concentrated while those in Movies & TV are more diverse.
- Why unresolved: The paper does not provide a detailed analysis of how K affects performance across different dataset characteristics or provide guidelines for choosing K based on dataset properties.
- What evidence would resolve it: A systematic study varying K across multiple datasets with different characteristics (concentration of interests, dataset size, sparsity) and correlating performance with dataset properties.

### Open Question 2
- Question: How do the prompt embeddings affect the training dynamics and convergence of PoMRec compared to non-prompt-based multi-interest learning methods?
- Basis in paper: [explicit] The paper mentions that PoMRec achieves better performance with fewer parameters than baseline methods like TiMiRec, which assigns two embeddings per item, but does not provide detailed analysis of training dynamics or convergence behavior.
- Why unresolved: The paper does not provide experimental evidence comparing training curves, convergence speed, or stability between PoMRec and baseline methods.
- What evidence would resolve it: Training curve comparisons showing loss/metrics over epochs for PoMRec vs. baselines, analysis of sensitivity to learning rate and other hyperparameters, and convergence speed measurements.

### Open Question 3
- Question: How does PoMRec's performance change when incorporating item multimodal features (e.g., text, images) compared to using only interaction data?
- Basis in paper: [explicit] The paper acknowledges in the conclusion that PoMRec currently only uses user interaction data and overlooks valuable information in item multimodal features, suggesting this as future work.
- Why unresolved: The paper does not conduct any experiments or provide theoretical analysis of how multimodal features could enhance PoMRec's performance.
- What evidence would resolve it: Experimental results comparing PoMRec's performance with and without multimodal features, ablation studies showing the contribution of different modalities, and analysis of which modalities provide the most benefit for different types of recommendations.

## Limitations

- The mechanism by which prompt embeddings adapt user interactions to different learning objectives is not rigorously analyzed - it's unclear whether prompts are learning semantic distinctions or simply acting as additional trainable parameters
- The choice of λ=3 as the trade-off parameter between mean and variance embeddings appears somewhat arbitrary, with insufficient analysis of sensitivity to this parameter across different datasets
- The claim about using "significantly fewer parameters" than competing approaches is not fully substantiated with detailed parameter counts or ablation studies

## Confidence

- **High Confidence**: The experimental methodology and general multi-interest learning framework are well-established in the field
- **Medium Confidence**: The specific contributions of prompt embeddings versus the underlying multi-interest learning architecture are difficult to disentangle
- **Low Confidence**: The paper's claim about using "significantly fewer parameters" than competing approaches is not fully substantiated

## Next Checks

1. **Parameter Sensitivity Analysis**: Conduct experiments varying λ across a wider range (0 to 5) and analyze how performance changes, particularly focusing on whether the mean or variance component dominates at different values

2. **Prompt Ablation Study**: Compare PoMRec performance with and without prompt embeddings while keeping all other components constant to isolate the contribution of prompts to overall performance improvements

3. **Component-wise Parameter Analysis**: Provide detailed parameter counts for each baseline method and PoMRec, breaking down contributions from embeddings, attention mechanisms, MLPs, and prompts to verify the "significantly fewer parameters" claim