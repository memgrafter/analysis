---
ver: rpa2
title: Using Shapley interactions to understand how models use structure
arxiv_id: '2403.13106'
source_url: https://arxiv.org/abs/2403.13106
tags:
- interactions
- distance
- shapley
- language
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how Shapley interaction indices can reveal
  structural information encoded in language and speech models. The authors compute
  pairwise Shapley interactions to measure how features influence each other beyond
  their independent effects, then correlate these interactions with linguistic structures
  like syntax, non-compositional semantics, and phonetic coarticulation.
---

# Using Shapley interactions to understand how models use structure

## Quick Facts
- arXiv ID: 2403.13106
- Source URL: https://arxiv.org/abs/2403.13106
- Reference count: 12
- Key outcome: Shapley interaction indices reveal how models encode linguistic structure through non-linear dependencies, with autoregressive models showing stronger syntax correlations and both text model types exhibiting higher interactions in idiomatic phrases

## Executive Summary
This paper demonstrates how Shapley interaction indices can reveal structural information encoded in language and speech models by measuring non-linear feature dependencies. The authors compute pairwise Shapley interactions to quantify how feature pairs influence model outputs beyond their independent effects, then correlate these interactions with linguistic structures like syntax, non-compositional semantics, and phonetic coarticulation. For text models, autoregressive architectures show stronger interactions between syntactically close tokens, while both autoregressive and masked models exhibit higher interactions in idiomatic phrases. In speech models, interactions are stronger between consonants and vowels than between consonants, with more sonorant consonants showing vowel-like interaction patterns. These findings show that Shapley interactions provide insights into how models encode linguistic structure, particularly non-linear dependencies that linear attribution methods miss.

## Method Summary
The paper uses Shapley Taylor Interaction Indices (STII) to measure pairwise feature interactions in language and speech models. For text models, the authors compute interactions on GPT-2 (autoregressive) and BERT-base (masked) using Wikitext-2 corpus with spaCy tokenization and dependency parsing. For speech models, they analyze wav2vec2-base-960h on Common Voice dataset with MFA phoneme alignment. STII values are calculated using Monte Carlo permutation sampling, then correlated with linguistic structures including syntactic proximity (dependency tree distance), multiword expressions (MWEs), and phonetic coarticulation (consonant-vowel relationships). The analysis stratifies interactions by interacting pair distance and prediction distance to control for positional effects.

## Key Results
- Autoregressive text models show negative correlations between STII values and syntactic distance, indicating stronger interactions between syntactically closer tokens
- Both autoregressive and masked text models exhibit significantly higher STII values for tokens in idiomatic phrases compared to random pairs
- Speech models show significantly higher interactions between consonants and vowels than between consonants, with more sonorant consonants displaying vowel-like interaction patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shapley interaction indices measure non-linear feature dependencies that linear attribution methods miss
- Mechanism: The Shapley Taylor Interaction Index (STII) computes second-order derivatives between feature sets, capturing how pairs of inputs influence outputs beyond their independent effects. This provides a view into how models encode structural interactions between inputs.
- Core assumption: Neural networks process inputs through non-linear transformations where features interact in complex ways, making linear attribution methods insufficient for understanding model behavior.
- Evidence anchors:
  - [abstract] "Pairwise Shapley interactions measure how much two inputs work together to influence model outputs beyond if we linearly added their independent influences"
  - [section 2.1] "Shapley values do not account for interacting effects between sets" and STII calculates "second-order interactions using the discrete second-order derivative"
  - [corpus] Weak evidence - only 1 citation found in related papers
- Break condition: If the model's processing were purely linear, Shapley interactions would provide no additional information beyond standard feature attribution methods.

### Mechanism 2
- Claim: Models encode linguistic structure through non-linear interactions between related features
- Mechanism: The strength of Shapley interactions correlates with structural relationships in the input data - syntactic proximity in text models and consonant-vowel relationships in speech models. This shows models learn to prioritize structurally related features through non-linear processing.
- Core assumption: Linguistic structures (syntax, semantics, phonetics) create non-linear dependencies that models must learn to process effectively for accurate predictions.
- Evidence anchors:
  - [abstract] "We find that autoregressive text models encode interactions that correlate with the syntactic proximity of inputs"
  - [section 3.2] "autoregressive language models, all statistically significant correlations are negative" between syntactic distance and STII
  - [section 4.1] "interactions are significantly higher in the consonant-vowel case" compared to consonant-consonant boundaries
- Break condition: If models processed all features independently or only used linear combinations, these correlations between interactions and linguistic structure would not exist.

### Mechanism 3
- Claim: Different model architectures encode structural information through distinct interaction patterns
- Mechanism: Autoregressive models show stronger correlations between interactions and syntax compared to masked language models, while both show increased interactions for idiomatic phrases. This demonstrates architecture-specific ways of encoding structure.
- Core assumption: The training objective and architecture determine how models represent and prioritize different types of structural information through non-linear interactions.
- Evidence anchors:
  - [abstract] "autoregressive text models encode interactions that correlate with the syntactic proximity of inputs, and that both autoregressive and masked models encode nonlinear interactions in idiomatic phrases"
  - [section 3.2] "In contrast, non-autoregressive language models exhibit both positive and negative correlations" for syntax
  - [section 3.3] "For both the autoregressive models and masked models, STII is higher when the interacting pair is in a MWE"
- Break condition: If all architectures processed structural information identically, we would not observe these systematic differences in interaction patterns.

## Foundational Learning

- Concept: Shapley values and cooperative game theory
  - Why needed here: The paper uses Shapley values as the foundation for measuring feature contributions and interactions, treating features as players in a cooperative game where the model output is the value function.
  - Quick check question: What does a Shapley value represent in terms of feature contributions to model predictions?

- Concept: Multiword expressions and compositionality
  - Why needed here: The paper examines how models handle non-compositional phrases where meaning cannot be derived from individual words, using MWEs as test cases for non-linear semantic processing.
  - Quick check question: What distinguishes strong MWEs from weak MWEs in terms of semantic compositionality?

- Concept: Phonetic features and coarticulation
  - Why needed here: The speech model experiments rely on understanding how consonant-vowel interactions work in human speech perception and how these phonetic relationships manifest as non-linear interactions in model processing.
  - Quick check question: Why are vowels more influenced by surrounding consonants than consonants are by vowels in phonetic realization?

## Architecture Onboarding

- Component map:
  - Input processing: Tokenization (text) or MFCC extraction (speech)
  - Model selection: GPT-2 (autoregressive), BERT-base (masked), Wav2Vec 2.0 (speech)
  - Interaction computation: STII calculation using Monte Carlo permutation sampling
  - Analysis pipeline: Correlation between interactions and linguistic structures
  - Evaluation: Statistical significance testing of correlation patterns

- Critical path:
  1. Preprocess input data and align with linguistic annotations
  2. Run model inference to get output logits
  3. Compute STII values between feature pairs using Monte Carlo sampling
  4. Calculate correlations between interaction strength and structural metrics
  5. Test statistical significance of observed correlations

- Design tradeoffs:
  - Computational cost vs. accuracy: Exact STII computation is O(2^N) but Monte Carlo sampling provides approximation with manageable resources
  - Positional distance vs. linguistic distance: Need to control for position effects when measuring structural correlations
  - Model selection: Different architectures capture structure differently, requiring multiple model types for comprehensive analysis

- Failure signatures:
  - No correlation between interactions and structure suggests models don't encode that structural information
  - Inconsistent correlation patterns across architectures may indicate model-specific processing differences
  - High computational variance in STII estimates suggests insufficient sampling for stable measurements

- First 3 experiments:
  1. Verify position effects: Measure STII correlation with interacting pair distance and prediction distance across all models
  2. Test syntactic encoding: Calculate STII correlation with dependency tree distance for autoregressive vs masked models
  3. Examine semantic compositionality: Compare STII values for tokens in strong vs weak MWEs versus random pairs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do higher-order Shapley interactions beyond pairwise relate to hierarchical linguistic structures like syntax trees or phoneme hierarchies?
- Basis in paper: [explicit] The authors state "This work focuses on pairwise interactions" and suggest "Higher order Shapley interactions (Sundararajan et al., 2020) provide a method of hierarchical clustering on features" in the Future Work section.
- Why unresolved: The paper only examines pairwise interactions, leaving unexplored whether multi-feature interactions reveal more nuanced structural patterns or hierarchical relationships in linguistic representations.
- What evidence would resolve it: Experimental comparison of higher-order Shapley interactions with linguistic hierarchies, measuring whether multi-way interactions correlate more strongly with tree-structured syntactic relationships or multi-level phonological organization than pairwise interactions.

### Open Question 2
- Question: Do Shapley interactions capture meaningful differences between language model architectures trained on the same objective (e.g., different transformer variants trained with autoregressive objectives)?
- Basis in paper: [explicit] The authors note they "do not compare any models that are trained on the same objective with different architectures" and suggest this comparison "can provide many insights into how specific models are similar and different."
- Why unresolved: The paper only compares masked versus autoregressive objectives, not different architectural implementations of the same training objective, leaving unclear whether interaction patterns are objective-dependent or architecture-dependent.
- What evidence would resolve it: Comparative analysis of Shapley interactions across multiple autoregressive models with varying architectures (RNNs, transformers, different attention mechanisms) trained on identical datasets and objectives.

### Open Question 3
- Question: Can Shapley interactions serve as predictive tools for model behavior rather than just descriptive correlations with linguistic structure?
- Basis in paper: [inferred] The authors acknowledge "we do not forsee significant risks" but note they only examine "correlational analyses" and suggest "the second way in which this analysis could be made stronger would be to go beyond looking at correlations, and investigate the causal predictive power of Shapley interactions."
- Why unresolved: Current analysis establishes correlations between interactions and structure but doesn't demonstrate whether interaction patterns can predict model behavior changes, failure modes, or transfer learning outcomes.
- What evidence would resolve it: Experimental validation showing that Shapley interaction patterns predict specific behavioral changes when models are fine-tuned, encounter distribution shifts, or exhibit particular types of errors.

## Limitations
- The findings rely on the assumption that Shapley interaction indices accurately capture non-linear dependencies without validation through controlled experiments with known ground truth interactions
- The Monte Carlo approximation method introduces sampling variance that could affect the stability of observed correlations, particularly for less frequent linguistic structures
- The study uses only one dataset per modality (Wikitext-2 for text, Common Voice for speech), limiting generalizability across different linguistic domains and language varieties

## Confidence
- High Confidence: The observation that autoregressive models show stronger negative correlations between interactions and syntactic distance compared to masked models is well-supported by the data and aligns with these architectures' different processing mechanisms
- Medium Confidence: The finding that both autoregressive and masked models show higher interactions in idiomatic phrases is consistent across analyses but could be influenced by the specific MWE detection method used
- Medium Confidence: The speech model results showing stronger interactions between consonants and vowels are statistically significant but may be affected by the specific phonetic features and model architecture chosen

## Next Checks
1. **Cross-dataset validation**: Test the syntactic interaction patterns on multiple text corpora (e.g., news, literature, social media) to verify that observed correlations are not dataset-specific artifacts
2. **Controlled interaction experiments**: Design synthetic inputs where known non-linear interactions exist between features, then verify that STII correctly identifies these interactions while linear attribution methods fail
3. **Sampling variance analysis**: Systematically vary the number of Monte Carlo samples used for STII computation and measure how this affects the stability and significance of observed correlations across different linguistic structures