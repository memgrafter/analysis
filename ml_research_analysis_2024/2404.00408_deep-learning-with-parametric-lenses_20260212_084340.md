---
ver: rpa2
title: Deep Learning with Parametric Lenses
arxiv_id: '2404.00408'
source_url: https://arxiv.org/abs/2404.00408
tags:
- learning
- parametric
- lens
- lenses
- example
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a categorical framework for gradient-based
  machine learning using parametric lenses, reverse derivatives, and lens composition.
  The approach models learning components (models, loss functions, optimizers) as
  parametric lenses in a Cartesian reverse differential category, enabling a unified,
  compositional description of various learning algorithms.
---

# Deep Learning with Parametric Lenses

## Quick Facts
- arXiv ID: 2404.00408
- Source URL: https://arxiv.org/abs/2404.00408
- Reference count: 40
- Key outcome: Introduces a categorical framework for gradient-based machine learning using parametric lenses, reverse derivatives, and lens composition, demonstrated through a Python implementation achieving accuracy comparable to mainstream frameworks on standard benchmarks.

## Executive Summary
This paper proposes a categorical semantics for machine learning algorithms using parametric lenses and reverse derivatives. The framework models learning components—models, loss functions, and optimizers—as morphisms in a Cartesian reverse differential category, providing a unified, compositional description of various learning algorithms. The approach supports both continuous (e.g., neural networks) and discrete (e.g., Boolean circuits) learning settings, with a Python implementation demonstrating practical viability and achieving accuracy comparable to mainstream frameworks on standard benchmarks.

## Method Summary
The authors construct a categorical framework where machine learning algorithms are expressed as parametric lenses in a Cartesian reverse differential category. They build Para(C) for parametric maps, apply Lens to get bidirectional maps, and compose Para(Lens(C)) for parametric lenses with reverse derivative R[f] providing the backward pass. The framework unifies models, loss functions, and optimizers into a single compositional structure. A Python implementation demonstrates the approach on standard benchmarks, showing comparable accuracy to mainstream frameworks.

## Key Results
- Parametric lenses provide a unified categorical framework for gradient-based learning algorithms
- Framework supports both continuous (neural networks) and discrete (Boolean circuits) learning settings
- Python implementation achieves accuracy comparable to mainstream frameworks on standard benchmarks

## Why This Works (Mechanism)

### Mechanism 1
Parametric lenses unify models, loss functions, and optimizers into a single categorical framework. The Para construction turns a category C into Para(C) of parametric maps, then the Lens construction turns Para(C) into Para(Lens(C)) where maps have forward/backward parts. This composite captures all learning components as morphisms.

Core assumption: The base category C is a Cartesian reverse differential category (CRDC), so it has a reverse derivative operation R[f] that acts as the backward pass.

Break Condition: If C is not a CRDC, R[f] does not exist and the backward pass (gradient computation) fails.

### Mechanism 2
Learning rate and optimizer are implemented as reparameterizations of the model's parameter space. A learning rate lens from L to 1 applies a constant scaling to the backward gradient. An optimizer lens from S×P to P transforms the gradient into a parameter update (e.g., adding momentum or scaling by accumulated gradients).

Core assumption: The parameter space P is a commutative monoid (or group for descent) so that addition/subtraction of gradients is defined.

Break Condition: If P lacks monoid/group structure, the optimizer lens cannot be defined.

### Mechanism 3
Deep dreaming is modeled by reparameterizing the input port instead of the parameter port. Instead of applying an optimizer lens to P, apply it to A (the input space). The backward pass R[f] now updates the input image rather than the model weights.

Core assumption: The input space A has a suitable structure (e.g., a vector space) so that gradient updates make sense.

Break Condition: If A lacks the required structure, gradient updates to the input cannot be performed.

## Foundational Learning

- Concept: Cartesian reverse differential categories (CRDCs)
  - Why needed here: CRDCs provide the reverse derivative operation R[f] that serves as the backward pass in learning algorithms.
  - Quick check question: Can you explain what R[f]: A×B→A represents in terms of gradients?

- Concept: Parametric categories via the Para construction
  - Why needed here: Para(C) allows modeling neural networks and other models as parametric maps (P, f): P×A→B where P is the parameter space.
  - Quick check question: How does a parametric map in Para(Smooth) differ from a plain smooth map?

- Concept: Lenses as bidirectional maps
  - Why needed here: Lenses model the forward computation and backward gradient propagation in a single structure.
  - Quick check question: What are the get and put parts of a lens in the context of learning?

## Architecture Onboarding

- Component map: Base category C (e.g., Smooth or POLYZ2) → Para(C): parametric maps (P, f): P×A→B → Lens(C): bidirectional maps (f, f*): A×B'→A' → Para(Lens(C)): parametric lenses with parameter space and bidirectional interfaces → CRDC structure: reverse derivative R[f] providing backward pass

- Critical path:
  1. Define base CRDC C
  2. Build Para(C) for parametric maps
  3. Apply Lens to get bidirectional maps
  4. Compose Para(Lens(C)) for parametric lenses
  5. Use R[f] to define backward pass
  6. Compose with loss, learning rate, optimizer lenses

- Design tradeoffs:
  - Choosing Smooth vs POLYZ2: continuous vs discrete learning settings
  - Monoid vs group structure on parameters: ascent vs descent
  - Trivial vs stateful optimizers: memory/compute vs performance

- Failure signatures:
  - Missing R[f]: gradients cannot be computed
  - Non-additive backward pass: composition fails
  - Non-Cartesian base: products/projections undefined

- First 3 experiments:
  1. Implement linear regression in Smooth with quadratic loss and basic gradient descent
  2. Implement boolean circuit learning in POLYZ2 with XOR loss
  3. Implement deep dreaming on a simple image with dot product loss

## Open Questions the Paper Calls Out

### Open Question 1
How can the parametric lens framework be extended to model probabilistic and non-gradient-based learning algorithms? The authors mention that future work includes "using the full power of CRDC axioms" and extending the framework to "probabilistic, non-gradient based, and other forms of non-supervised learning." This remains unresolved because the paper focuses on gradient-based learning and does not explore how the parametric lens framework can accommodate learning algorithms that do not rely on gradients. A formal extension incorporating probability distributions and alternative optimization methods would resolve this.

### Open Question 2
Can the parametric lens framework be used to develop a verified or formally correct-by-construction machine learning system? The authors suggest using "fibrations/dependent types to model the use of tangent bundles" to "foster the extension of the correct by construction paradigm to machine learning." While the authors hint at the potential for verification, they do not provide a concrete approach or implementation. A formal verification methodology for machine learning systems built on the parametric lens framework would resolve this.

### Open Question 3
How can the parametric lens framework be used to model and analyze the dynamics of Generative Adversarial Networks (GANs) and other adversarial learning systems? The authors provide a detailed example of modeling GANs using parametric lenses and discuss how the framework can capture the complex dynamics of these systems. While the authors demonstrate the feasibility of modeling GANs, they do not explore the potential for analyzing convergence, stability, or other properties. A comprehensive analysis of GAN dynamics using the parametric lens framework would resolve this.

## Limitations
- Framework's practical applicability is limited by requirement for base categories to be Cartesian reverse differential categories
- Theoretical construction relies on specific categorical properties that may not hold for all learning scenarios
- Computational efficiency compared to mainstream frameworks remains unclear due to lack of runtime and memory usage benchmarks

## Confidence
- Framework validity: High (mathematically sound constructions demonstrated through Python implementation)
- Universal applicability: Low (restriction to CRDCs may limit modeling of all learning algorithms)
- Performance claims: Medium (accuracy reported but lack of runtime and memory comparisons makes claims uncertain)

## Next Checks
1. Test the framework's ability to handle non-differentiable components or discrete optimization problems that fall outside the CRDC class
2. Implement a larger neural network (e.g., ResNet-18) and benchmark both accuracy and training time against PyTorch/TensorFlow equivalents
3. Evaluate the framework's performance on a non-image domain (e.g., natural language processing or graph neural networks) to test its generality