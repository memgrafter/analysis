---
ver: rpa2
title: Extrapolability Improvement of Machine Learning-Based Evapotranspiration Models
  via Domain-Adversarial Neural Networks
arxiv_id: '2406.00805'
source_url: https://arxiv.org/abs/2406.00805
tags:
- data
- sites
- dann
- domain
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of improving the extrapolation
  capability of machine learning-based evapotranspiration (ET) models across diverse
  geographical regions with uneven data distribution. The core method introduces Domain-Adversarial
  Neural Networks (DANN) to mitigate distributional discrepancies between different
  sites by leveraging adversarial training to learn domain-invariant features.
---

# Extrapolability Improvement of Machine Learning-Based Evapotranspiration Models via Domain-Adversarial Neural Networks

## Quick Facts
- arXiv ID: 2406.00805
- Source URL: https://arxiv.org/abs/2406.00805
- Authors: Haiyang Shi
- Reference count: 12
- Primary result: DANN achieves 0.2-0.3 KGE improvement over traditional LOO methods

## Executive Summary
This study addresses the challenge of improving the extrapolation capability of machine learning-based evapotranspiration (ET) models across diverse geographical regions with uneven data distribution. The core method introduces Domain-Adversarial Neural Networks (DANN) to mitigate distributional discrepancies between different sites by leveraging adversarial training to learn domain-invariant features. Results show that DANN significantly enhances ET prediction accuracy, achieving an average increase in Kling-Gupta Efficiency (KGE) of 0.2 to 0.3 compared to traditional Leave-One-Out (LOO) methods. DANN is particularly effective for isolated sites and transition zones between biomes, reducing data distribution discrepancies and avoiding low-accuracy predictions.

## Method Summary
The method employs Domain-Adversarial Neural Networks (DANN) with three main components: a feature extractor, an ET predictor, and a domain classifier. The model is trained using FLUXNET2015 flux station data, satellite remote sensing data, and site-scale dataset, with Kling-Gupta Efficiency (KGE) as the primary evaluation metric. The training procedure involves 50 epochs using the Adam optimizer with a learning rate of 0.001, and a dynamically adjusted weight parameter λ to balance regression and domain losses. The model aims to achieve an average KGE improvement of 0.2 to 0.3 compared to traditional Leave-One-Out (LOO) methods.

## Key Results
- DANN achieves an average KGE improvement of 0.2 to 0.3 compared to traditional LOO methods
- DANN is particularly effective for isolated sites and transition zones between biomes
- DANN reduces data distribution discrepancies and avoids low-accuracy predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-Adversarial Neural Networks (DANN) improve ET prediction accuracy by learning domain-invariant features that reduce distributional discrepancies between sites.
- Mechanism: DANN uses adversarial training between a feature extractor and a domain classifier. The feature extractor tries to create features that fool the domain classifier, forcing it to learn features that are indistinguishable across different geographical domains. This reduces overfitting to source domain characteristics and improves generalization to target domains.
- Core assumption: The distributional differences between sites (domains) are the primary cause of poor extrapolation performance, and these differences can be reduced by learning domain-invariant features.
- Evidence anchors:
  - [abstract]: "DANN significantly enhances ET prediction accuracy, achieving an average increase in Kling-Gupta Efficiency (KGE) of 0.2 to 0.3 compared to traditional Leave-One-Out (LOO) methods"
  - [section]: "DANN can reduce data distribution discrepancies between domains through adversarial interaction between the domain classifier and the feature extractor"
  - [corpus]: Weak evidence - no direct mention of DANN or similar domain adaptation techniques in related papers, though one paper mentions "Approaches for enhancing extrapolability in process-based and data-driven models in hydrology"
- Break condition: If the distributional differences between sites are not the primary cause of poor extrapolation, or if the adversarial training fails to create truly domain-invariant features.

### Mechanism 2
- Claim: DANN improves model performance at isolated sites by leveraging information from data-rich areas through transfer learning.
- Mechanism: By learning domain-invariant features from data-rich source domains, DANN can transfer this knowledge to data-scarce target domains (isolated sites). This is particularly effective when the source and target domains share underlying patterns but differ in data distribution.
- Core assumption: Knowledge can be effectively transferred from data-rich to data-scarce domains when the underlying patterns are similar but the data distributions differ.
- Evidence anchors:
  - [abstract]: "By leveraging information from data-rich areas, DANN enhances the reliability of global-scale ET products, especially in ungauged regions"
  - [section]: "DANN can enhance model performance by learning domain-invariant features, which is particularly useful in scenarios with limited or sparse training data. Isolated sites benefit from DANN's transfer learning capabilities"
  - [corpus]: Weak evidence - no direct mention of transfer learning from data-rich to data-scarce domains in related papers
- Break condition: If the underlying patterns between data-rich and data-scarce domains are too different, or if the adversarial training fails to capture the relevant transferable knowledge.

### Mechanism 3
- Claim: DANN improves performance at transition zones between biomes by reducing data distribution discrepancies between different plant functional types (PFTs) or biomes.
- Mechanism: Transition zones often have mixed characteristics from different biomes, making them challenging for traditional models. DANN reduces the distributional discrepancies between these biomes, allowing the model to better handle the mixed characteristics of transition zones.
- Core assumption: The mixed characteristics of transition zones are primarily due to distributional differences between biomes, which can be reduced through domain adaptation.
- Evidence anchors:
  - [abstract]: "DANN is particularly effective for isolated sites and transition zones between biomes, reducing data distribution discrepancies and avoiding low-accuracy predictions"
  - [section]: "In transition zones, DANN's DA mechanism proves effective. By reducing data distribution discrepancies between different PFTs, DANN can enhance model performance at sites in these transition zones"
  - [corpus]: Weak evidence - no direct mention of transition zones or biome mixing in related papers
- Break condition: If the mixed characteristics of transition zones are not primarily due to distributional differences, or if the adversarial training fails to capture the relevant biome-specific patterns.

## Foundational Learning

- Concept: Domain Adaptation (DA)
  - Why needed here: DA techniques are needed to address the challenge of uneven data distribution across geographical regions, which limits the extrapolation capabilities of machine learning models in hydrology.
  - Quick check question: What is the main goal of domain adaptation techniques in machine learning?

- Concept: Adversarial Training
  - Why needed here: Adversarial training is a key component of DANN, used to encourage the feature extractor to learn domain-invariant features by making it compete against the domain classifier.
  - Quick check question: How does adversarial training work in the context of DANN?

- Concept: Kling-Gupta Efficiency (KGE)
  - Why needed here: KGE is used as the model performance metric to measure the consistency between simulated and observed ET values, providing a more comprehensive evaluation than traditional metrics like NSE.
  - Quick check question: What are the three components of the Kling-Gupta Efficiency metric?

## Architecture Onboarding

- Component map:
  - Input data -> Feature Extractor -> ET Predictor -> ET prediction
  - Input data -> Feature Extractor -> Domain Classifier -> Domain classification
  - ET Predictor -> Regression Loss (MSE)
  - Domain Classifier -> Domain Loss (Cross-Entropy Loss)
  - Regression Loss + Domain Loss -> Total Loss -> Adam Optimizer

- Critical path:
  1. Input data flows through feature extractor
  2. Extracted features are used by ET predictor to make predictions
  3. Same features are used by domain classifier to determine domain origin
  4. Losses are calculated and combined
  5. Model is updated using Adam optimizer

- Design tradeoffs:
  - Number of trees in RF vs. DANN complexity: RF uses simpler ensemble method, DANN uses more complex neural network architecture
  - Static vs. dynamic λ: Dynamic adjustment allows better balance between regression and domain losses during training
  - Training epochs: 50 epochs chosen for DANN, may need adjustment based on dataset size and complexity

- Failure signatures:
  - Low KGE values despite training (model fails to learn useful features)
  - High domain classification accuracy (feature extractor not learning domain-invariant features)
  - Overfitting to source domain (high accuracy on source, low on target)

- First 3 experiments:
  1. Compare DANN performance with varying λ schedules to find optimal balance between regression and domain losses
  2. Test DANN with different feature extractor architectures (more/less layers, different activation functions)
  3. Evaluate DANN performance on synthetic data with known domain shifts to validate mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we establish a robust mapping relationship between model accuracy and sets of catchment attributes in machine learning-based hydrological models?
- Basis in paper: [explicit] The paper states that while catchment properties are correlated with model performance, an accurate mapping relationship between model accuracy and sets of catchment attributes has yet to be established (Nearing et al., 2024).
- Why unresolved: The paper acknowledges the correlation but does not provide a method or framework for establishing this mapping relationship.
- What evidence would resolve it: Developing and validating a method that accurately maps catchment attributes to model accuracy, demonstrating its effectiveness in improving model performance across diverse hydrological settings.

### Open Question 2
- Question: What is the optimal strategy for selecting input data subsets in machine learning models for hydrological predictions, beyond using all available data or data based on hydrological similarity?
- Basis in paper: [explicit] The paper suggests that data-driven models built using all available data are not always superior to those built using data subsets based on specific plant functional types (PFTs), but whether the similarity obtained from empirical knowledge or hydrological and ecological characteristics matches well with model transferability remains uncertain.
- Why unresolved: The paper indicates that the current strategies for selecting input data subsets are not optimal and that the relationship between data similarity and model transferability is unclear.
- What evidence would resolve it: Conducting experiments to compare the performance of models trained on various data selection strategies and identifying the most effective approach for different hydrological and ecological contexts.

### Open Question 3
- Question: How can domain adaptation techniques be extended to other machine learning models in hydrology and ecology to improve their extrapolation and generalization capabilities?
- Basis in paper: [inferred] The paper concludes that domain adaptation techniques, such as DANN, can significantly improve the extrapolation capability of machine learning models in hydrology, and suggests that other models in hydrology and ecology should consider using DA techniques to enhance their extrapolation and generalization capabilities in large-scale applications.
- Why unresolved: While the paper demonstrates the effectiveness of DANN for ET prediction, it does not provide a framework for applying domain adaptation techniques to other hydrological and ecological models.
- What evidence would resolve it: Developing and validating domain adaptation techniques for various machine learning models in hydrology and ecology, demonstrating their effectiveness in improving model performance across different scales and applications.

## Limitations
- The study focuses on specific FLUXNET sites and ET prediction, limiting generalizability to other hydrological variables and regions
- The impact of temporal variations is not fully captured in the analysis
- The study uses a single performance metric (KGE), which may not capture all aspects of model behavior

## Confidence
- High confidence in DANN's effectiveness for reducing distributional discrepancies between domains
- Medium confidence in the transferability of results to different climate regimes or with different input variables
- Medium confidence in the generalizability of the adversarial training approach to other hydrological variables beyond ET

## Next Checks
1. Test DANN performance on synthetic datasets with known domain shifts to validate the mechanism of domain-invariant feature learning
2. Conduct ablation studies to isolate the contribution of each component (feature extractor, domain classifier) to overall performance
3. Evaluate model performance across different temporal scales (seasonal vs. annual) to assess robustness to temporal variations