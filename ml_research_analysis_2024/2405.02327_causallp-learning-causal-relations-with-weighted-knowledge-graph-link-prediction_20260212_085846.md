---
ver: rpa2
title: 'CausalLP: Learning causal relations with weighted knowledge graph link prediction'
arxiv_id: '2405.02327'
source_url: https://arxiv.org/abs/2405.02327
tags:
- causal
- prediction
- links
- link
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CausalLP addresses the problem of finding missing causal relations
  in incomplete causal networks by framing it as a knowledge graph link prediction
  task. The approach encodes causal relations and weights into a causal knowledge
  graph, learns embeddings using knowledge graph embedding algorithms (e.g., TransE,
  DistMult, ComplEx, HolE), and applies link prediction for causal explanation and
  prediction tasks.
---

# CausalLP: Learning causal relations with weighted knowledge graph link prediction

## Quick Facts
- arXiv ID: 2405.02327
- Source URL: https://arxiv.org/abs/2405.02327
- Reference count: 16
- Primary result: Weighted causal relations improve link prediction accuracy, with 43.26%-115.05% higher MRR for causal explanation and 38.96%-79.26% higher MRR for causal prediction.

## Executive Summary
CausalLP addresses the challenge of finding missing causal relations in incomplete causal networks by framing it as a knowledge graph link prediction task. The approach encodes causal relations and weights into a causal knowledge graph, learns embeddings using knowledge graph embedding algorithms (e.g., TransE, DistMult, ComplEx, HolE), and applies link prediction for causal explanation and prediction tasks. CausalLP incorporates causal weights into embeddings using the FocusE method and introduces a novel Markov-based data splitting approach to reduce model bias. Evaluated on the CLEVRER-Humans dataset, CausalLP with weighted causal relations significantly outperforms baseline methods without weights, achieving 43.26%-115.05% higher MRR for causal explanation and 38.96%-79.26% higher MRR for causal prediction. Adding external knowledge further improves performance, and CausalLP effectively handles sparse causal knowledge graphs.

## Method Summary
CausalLP preprocesses CLEVRER-Humans CEGs by removing low-weight edges and cycles, then constructs CausalKG in RDF format with causal ontology. The approach uses FocusE to incorporate causal weights into KGE models (TransE, DistMult, ComplEx, HolE) trained on different KG structures (C, CT, CTP). A novel Markov-based data splitting approach is used to reduce model bias. The framework evaluates causal explanation (predicting cause-entity types) and causal prediction (predicting effect-entity types) using link prediction metrics like MRR and Hits@k.

## Key Results
- Weighted causal relations improve link prediction accuracy over unweighted baselines
- Markov-based data splitting reduces model bias compared to random splitting
- Adding external knowledge (types, properties) to CausalKG further improves performance
- CausalLP handles sparse causal knowledge graphs effectively

## Why This Works (Mechanism)

### Mechanism 1
Incorporating causal weights into KG embeddings improves link prediction accuracy by modulating link scores based on causal influence. Higher causal weights indicate stronger causal associations, so embedding models should prioritize them. If causal weights are unreliable or noisy, the modulation could degrade embedding quality.

### Mechanism 2
Markov-based data splitting reduces model bias by ensuring that links spanning across the Markov boundary are excluded from training to avoid leakage. The approach assumes causal links at time t are independent of links at t+1 given links at t-1. If the Markov assumption is violated in the data, the split could omit relevant training links.

### Mechanism 3
Reifying causal relations (causesType, causedByType) enables type-level causal prediction by adding links between entity instances and their types. This allows KG link prediction models to infer causal links at the type level rather than instance level. If type abstraction loses critical causal detail, predictions may be less accurate.

## Foundational Learning

- **Knowledge Graph Embedding (KGE)**: Provides continuous vector representation of entities and relations for link prediction via similarity scoring. Quick check: How does a KGE model score a triple (h, r, t)?
- **Causal Bayesian Networks**: Guide how the KG is split and how causal weights are interpreted through causal structure and Markov property. Quick check: What is the local Markov property in causal networks?
- **Link Prediction Evaluation Metrics (MRR, Hits@k)**: Quantify ranking quality of predicted links in test set. Quick check: How is MRR calculated for a set of ranked predictions?

## Architecture Onboarding

- **Component map**: CausalKG (RDF graph) → FocusE-weighted KGE (TransE/DistMult/ComplEx/HolE) → Link prediction (causal explanation/prediction) → Evaluation (MRR/Hits@k)
- **Critical path**: Data preprocessing → CausalKG construction → KGE training → Link prediction → Evaluation
- **Design tradeoffs**: Weighted vs unweighted embeddings (better accuracy but requires reliable causal weights), Markov vs random split (less bias but potentially less training data)
- **Failure signatures**: Low MRR despite high training performance may indicate overfitting or data leakage; poor performance with weights may indicate noisy causal weights
- **First 3 experiments**:
  1. Train CausalKGE-Base and CausalKGE-W on the same data split; compare MRR to verify weight impact
  2. Apply Markov-based split and random split separately; compare causal prediction performance to detect bias
  3. Vary KG structures (C, CT, CTP) to assess the effect of additional knowledge on link prediction accuracy

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of CausalLP vary across different KGE algorithms (e.g., TransE, DistMult, ComplEx, HolE) when using weighted causal relations? The paper provides overall performance metrics but does not break down results by individual KGE algorithms, making it difficult to determine which algorithm performs best with weighted causal relations.

### Open Question 2
How does the Markov-based data splitting approach impact the generalizability of CausalLP to real-world causal networks with varying structures? The evaluation is limited to CLEVRER-Humans dataset, and the impact of the Markov-based split on different types of causal networks is not investigated.

### Open Question 3
What are the potential limitations of using causal weights in knowledge graph embeddings, and how can they be addressed? The paper focuses on benefits of incorporating causal weights but does not explore issues such as accuracy of weight estimation or impact of incorrect weights on model performance.

## Limitations

- Performance gains based on single dataset (CLEVRER-Humans) with limited external validation
- FocusE method integration with KGE models not fully explained
- Markov-based split assumes specific causal structure that may not hold in all networks

## Confidence

- **High**: CausalLP framework correctly formulates causal link prediction as a KG link prediction problem
- **Medium**: Weighted causal relations improve link prediction accuracy compared to unweighted baselines
- **Low**: The Markov-based split significantly reduces model bias compared to random splitting

## Next Checks

1. Evaluate CausalLP on additional causal datasets (e.g., COPA, CausalBank) to verify performance gains generalize beyond CLEVRER-Humans
2. Conduct ablation studies to isolate the impact of FocusE on embedding quality and link prediction accuracy
3. Test CausalLP with alternative data splitting strategies (e.g., time-based splits) to assess the robustness of the Markov-based approach