---
ver: rpa2
title: 'Balancing the Scales: Enhancing Fairness in Facial Expression Recognition
  with Latent Alignment'
arxiv_id: '2410.19444'
source_url: https://arxiv.org/abs/2410.19444
tags:
- bias
- learning
- fairness
- latent
- expression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses bias mitigation in facial expression recognition
  (FER) systems by proposing a novel latent alignment technique. The method uses a
  Variational Autoencoder (VAE) with shared weights across protected attributes, combined
  with an adversarial discriminator to minimize inter-latent domain gaps.
---

# Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment

## Quick Facts
- arXiv ID: 2410.19444
- Source URL: https://arxiv.org/abs/2410.19444
- Reference count: 40
- Primary result: State-of-the-art fairness and accuracy in facial expression recognition through latent alignment

## Executive Summary
This paper addresses bias mitigation in facial expression recognition (FER) systems by proposing a novel latent alignment technique using a Variational Autoencoder (VAE) with shared weights across protected attributes. The method combines an adversarial discriminator to minimize inter-latent domain gaps, generating improved latent representations that mitigate bias while maintaining classification accuracy. Extensive evaluation on RAF-DB and CelebA datasets demonstrates significant improvements in both fairness metrics and overall accuracy.

## Method Summary
The proposed method uses a two-part model architecture: a VAE with shared weights across protected attributes and an MBConv-based CNN classifier. The VAE generates aligned latent representations through a custom loss function incorporating KL-divergence for denser representations, discriminator loss for adversarial training to remove protected attribute information, and style-reconstruction loss to preserve semantic emotion features. The model is trained on RAF-DB and CelebA datasets with explicit protected attribute labels (gender, race, age), using SGD optimization and a symmetric cross-entropy loss for the final classification.

## Key Results
- Achieves mean class-wise accuracies of 76.1% on RAF-DB and 93.85% on CelebA
- Significantly reduces bias across gender, race, and age attributes
- Demonstrates state-of-the-art performance in both fairness metrics and overall accuracy
- Maintains expression classification performance while improving demographic fairness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Variational Autoencoder with shared weights across protected attributes generates latent representations that encode expression-relevant features while minimizing protected attribute information
- Mechanism: The shared-weight VAE architecture forces different demographic groups to map into a common latent space, while the adversarial discriminator actively penalizes the ability to predict protected attributes from the latent representation
- Core assumption: Protected attributes and expression features can be sufficiently disentangled in the latent space, allowing the model to learn expression features that are invariant to protected attributes
- Evidence anchors:
  - [abstract] "uses a Variational Autoencoder (VAE) with shared weights across protected attributes, combined with an adversarial discriminator to minimize inter-latent domain gaps"
  - [section 3] "Our goal is to minimize the distance between these latent spaces so that each latent encodes only the information relevant to expression classification"
  - [corpus] Weak - corpus contains no papers specifically addressing VAE-based latent alignment for bias mitigation
- Break condition: If expression features are inherently correlated with protected attributes (e.g., certain expressions are culturally specific to particular demographic groups), the disentanglement process may remove important discriminative features along with protected attribute information

### Mechanism 2
- Claim: The KL-divergence component of the loss function creates denser latent representations that improve both accuracy and fairness
- Mechanism: By penalizing deviation from a Gaussian distribution in the latent space, the KL-divergence loss forces the VAE to create more compact and regular latent representations that capture the essential features needed for expression classification while discarding irrelevant variations
- Core assumption: A Gaussian prior in the latent space will naturally encourage the model to learn representations that are more focused on task-relevant features rather than demographic-specific variations
- Evidence anchors:
  - [section 3] "The first part is the KL Divergence between the latent and a sample from a Gaussian distribution with mean 0 and variance 1 according to [24]. This is used to provide denser representations in the latent space, improving accuracy and mitigating bias"
  - [abstract] "The model is trained using a custom loss function incorporating KL-divergence"
  - [corpus] Missing - no corpus evidence directly supporting KL-divergence's role in bias mitigation
- Break condition: If the expression classification task requires complex, multi-modal latent distributions, forcing a Gaussian prior may oversimplify the representation and harm both accuracy and fairness

### Mechanism 3
- Claim: Style-reconstruction loss preserves semantic emotion-level features during the reconstruction process, preventing information loss that could harm classification accuracy
- Mechanism: Unlike pixel-wise reconstruction loss, the style-reconstruction loss focuses on preserving the high-level semantic content of expressions by matching feature maps between input and reconstructed images, ensuring that expression-relevant information is maintained even as protected attribute information is removed
- Core assumption: Semantic consistency in expressions is better preserved through feature-level matching than pixel-level reconstruction, and this preservation is crucial for maintaining classification performance
- Evidence anchors:
  - [section 3] "The final component is the Style-Reconstruction Loss from [21], which is added to ensure that the semantic emotion-level features are not lost on the Generator's reconstruction of the image"
  - [abstract] "custom loss function incorporating... style-reconstruction loss"
  - [corpus] Weak - corpus lacks papers discussing style-reconstruction loss in the context of bias mitigation
- Break condition: If the semantic features of expressions are strongly correlated with protected attributes, preserving semantic features may inadvertently preserve bias, creating a conflict between fairness and accuracy

## Foundational Learning

- Concept: Variational Autoencoders and their probabilistic formulation
  - Why needed here: The VAE forms the core architecture for generating aligned latent representations across protected attributes
  - Quick check question: How does the VAE's encoder-decoder structure with a probabilistic latent space enable the disentanglement of protected attributes from expression features?

- Concept: Adversarial training and min-max optimization
  - Why needed here: The discriminator-adversary relationship is essential for the bias mitigation mechanism
  - Quick check question: What role does the adversarial discriminator play in ensuring that the VAE's latent representations are independent of protected attributes?

- Concept: Loss function design and multi-objective optimization
  - Why needed here: The custom loss function balances three competing objectives: reconstruction quality, latent space alignment, and protected attribute independence
  - Quick check question: How do the three components of the loss function (KL-divergence, discriminator loss, and style-reconstruction loss) work together to achieve both fairness and accuracy?

## Architecture Onboarding

- Component map:
  Input images → Shared-weight VAE (Encoder E + Generator G) → Aligned latent space → MBConv-based CNN classifier → Expression predictions
  Aligned latents → Discriminator → Protected attribute predictions (adversarial training)

- Critical path: Image → Encoder E → Aligned latent → Classifier → Expression prediction
  (The discriminator operates in parallel during training but is not used during inference)

- Design tradeoffs:
  - VAE vs standard autoencoder: VAE provides probabilistic regularization but adds complexity
  - MBConv vs ResNet: MBConv blocks offer better efficiency and slightly higher accuracy in this application
  - Discriminator vs direct constraint: Adversarial approach is more flexible but can be harder to train stably

- Failure signatures:
  - High discriminator accuracy: Indicates protected attributes are still encoded in latents
  - Low reconstruction quality: May indicate excessive information removal, harming accuracy
  - Poor expression classification accuracy: Could indicate insufficient preservation of expression features

- First 3 experiments:
  1. Train with VAE+discriminator but no style-reconstruction loss to assess impact on accuracy
  2. Replace VAE with standard autoencoder to evaluate the importance of probabilistic regularization
  3. Remove the discriminator to test whether latent alignment occurs without adversarial training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed latent alignment technique perform on other image classification tasks beyond facial expression recognition?
- Basis in paper: [explicit] The authors mention that their method "can be extended to other image classification tasks" and suggest it paves the way for "a more extensive exploration of latent space manipulation for bias reduction in a wider range of image classification scenarios."
- Why unresolved: The paper only evaluates the method on two FER datasets (RAF-DB and CelebA), leaving its generalizability to other classification tasks untested.
- What evidence would resolve it: Experimental results showing the technique's effectiveness on diverse image classification tasks such as object recognition, medical imaging, or document classification.

### Open Question 2
- Question: What is the computational overhead of the proposed method compared to standard FER models?
- Basis in paper: [inferred] The paper describes a complex two-part model with a VAE, discriminator, and custom classification backbone, but does not provide runtime or memory usage comparisons with baseline methods.
- Why unresolved: While the paper demonstrates improved fairness and accuracy, it lacks information on the practical deployment costs of the approach.
- What evidence would resolve it: Benchmarking results showing inference time, training time, and memory requirements compared to standard FER models on the same hardware.

### Open Question 3
- Question: How does the method handle protected attributes that are not explicitly labeled in the dataset?
- Basis in paper: [inferred] The methodology assumes explicit knowledge of protected attributes (gender, race, age), but many real-world datasets lack comprehensive attribute annotations.
- Why unresolved: The paper does not address scenarios where protected attributes are unknown or only partially labeled.
- What evidence would resolve it: Experimental results demonstrating the method's performance when protected attributes are inferred or partially available, or a modification to handle unlabeled attributes.

## Limitations

- The effectiveness of disentanglement between expression features and protected attributes is assumed but not empirically verified through latent space analysis
- The paper lacks ablation studies to validate the individual contributions of each loss function component to the overall performance
- The method requires explicit knowledge of protected attributes, limiting its applicability to datasets without comprehensive attribute annotations

## Confidence

- **High confidence**: The overall experimental setup and dataset descriptions are clear and reproducible
- **Medium confidence**: The fairness improvements are demonstrated on two datasets, but the ablation studies are insufficient to validate individual components
- **Low confidence**: The theoretical claims about disentanglement and semantic preservation lack rigorous empirical support

## Next Checks

1. **Latent space analysis**: Visualize and quantitatively analyze the VAE's latent representations to verify that protected attributes are actually removed while expression features are preserved
2. **Component ablation study**: Systematically disable each component of the loss function (KL-divergence, discriminator loss, style-reconstruction loss) to quantify their individual contributions to fairness and accuracy
3. **Cross-dataset generalization**: Test the trained model on a third dataset (e.g., FER-2013) to evaluate whether the bias mitigation generalizes beyond the training distributions