---
ver: rpa2
title: On the Generalization of Handwritten Text Recognition Models
arxiv_id: '2411.17332'
source_url: https://arxiv.org/abs/2411.17332
tags:
- recognition
- text
- data
- divergence
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts the first large-scale analysis of out-of-distribution
  (OOD) generalization in Handwritten Text Recognition (HTR) models, addressing the
  significant performance gap between in-distribution and OOD scenarios. The authors
  evaluate 336 OOD cases across eight state-of-the-art HTR models on seven datasets
  spanning five languages, and introduce novel proxy metrics to quantify visual and
  textual divergence between domains.
---

# On the Generalization of Handwritten Text Recognition Models

## Quick Facts
- arXiv ID: 2411.17332
- Source URL: https://arxiv.org/abs/2411.17332
- Reference count: 40
- This paper conducts the first large-scale analysis of out-of-distribution (OOD) generalization in Handwritten Text Recognition (HTR) models, addressing the significant performance gap between in-distribution and OOD scenarios.

## Executive Summary
This paper presents the first comprehensive analysis of out-of-distribution generalization in HTR models, evaluating 336 OOD cases across eight state-of-the-art architectures on seven diverse datasets spanning five languages. The authors introduce novel proxy metrics to quantify visual and textual divergence between domains and employ factor analysis to identify the key drivers of OOD performance. Their findings reveal that textual divergence between source and target domains is the primary factor affecting OOD error, followed by visual divergence, while model selection and capacity have negligible impact on generalization.

## Method Summary
The study trains eight HTR architectures (CRNN, V AN, C-SAN, HTR-VT, Kang, Michael, LT, VLT) from scratch for 500 epochs with extensive data augmentation. Synthetic data is generated from the WIT dataset using 4,000 handwritten-style fonts across five languages. Visual divergence is measured using reconstruction error from a convolutional autoencoder, while textual divergence is quantified using averaged KL-divergence across n-grams (1-5). Factor analysis with oblimax rotation identifies four latent factors explaining the variance in OOD performance. The framework estimates OOD error from proxy metrics with a target accuracy of within 10 points in 70% of cases.

## Key Results
- Textual divergence between source and target domains is the primary factor affecting OOD error, with Factor 1 showing strong correlation (0.92) with ground-truth textual metrics
- Visual divergence has a modest negative correlation with OOD error (-0.3), making it the second most significant factor
- Model selection strategies and increased model capacity show negligible impact on OOD performance
- OOD CER values range from 37.4% to 53.9% across models, with CTC-based architectures showing marginally better generalization
- Proxy metrics can estimate OOD error with discrepancies below 10 points in 70% of cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Textual divergence between source and target domains is the primary driver of OOD error in HTR models.
- Mechanism: Factor analysis revealed that Factor 1, which strongly correlates with textual divergence metrics (ground truth ∆GT at 0.92 and generic ∆L at 0.84), accounts for the largest share of variance in OOD error. Higher textual misalignment leads to increased difficulty in generalizing.
- Core assumption: The textual content distribution shift is more impactful than visual or model complexity factors in determining OOD generalization performance.
- Evidence anchors:
  - [abstract]: "We reveal that the most significant factor for generalization lies in the textual divergence between domains, followed by visual divergence."
  - [section]: "Factor 1: Textual divergence explains most of the OOD error. Factor 1 shows a strong positive correlation with textual metrics for both ground-truth ∆GT (YS, YT) (0.92) and generic texts ∆L(YS, YT) (0.84)."
  - [corpus]: Weak evidence. The corpus papers focus on SSL, low-resource HTR, and Arabic text recognition, but do not directly address textual divergence as a primary factor.
- Break condition: If the textual divergence metric does not capture the actual linguistic differences between domains, or if visual divergence becomes dominant in specific HTR scenarios.

### Mechanism 2
- Claim: Visual divergence between domains has a modest negative correlation with OOD error.
- Mechanism: Factor 2 in the factor analysis shows high positive correlation with reconstruction errors (∆S and ∆T), indicating it captures visual differences. It also shows a weak to moderate negative correlation with OOD error (-0.3), suggesting that greater visual divergence leads to slight performance degradation.
- Core assumption: While textual divergence is dominant, visual features still contribute to OOD generalization, albeit to a lesser extent.
- Evidence anchors:
  - [abstract]: "We reveal that the most significant factor for generalization lies in the textual divergence between domains, followed by visual divergence."
  - [section]: "Factor 2: Visual similarity has a modest influence on OOD Error: Factor 2 has a high positive correlation with ID reconstruction error ∆S(XS, XT) (0.8) and OOD reconstruction error ∆T (XS, XT) (0.92) indicating that this factor predominantly reflects visual divergence between domains. Interestingly, Factor 2 also shows a weak to moderate negative correlation with OOD error (-0.3)."
  - [corpus]: Weak evidence. The corpus includes papers on SSL for HTR and optimal transport for low-resource HTR, but lacks direct evidence on visual divergence's impact.
- Break condition: If visual features are not effectively captured by the reconstruction-based metric, or if other factors (e.g., model architecture) overshadow visual divergence.

### Mechanism 3
- Claim: Model selection and capacity have negligible impact on OOD performance in HTR.
- Mechanism: Experiments comparing three model selection strategies (no-selection, held-out, oracle) showed no substantial differences in OOD performance. Additionally, increasing model capacity did not correlate with improved OOD generalization.
- Core assumption: In the DG setting, model selection heuristics and model size do not provide a significant advantage for OOD generalization in HTR.
- Evidence anchors:
  - [abstract]: "We reveal that the most significant factor for generalization lies in the textual divergence between domains, followed by visual divergence."
  - [section]: "Model selection has no impact. Fig. 5 demonstrates that the choice of selection method has a negligible impact on OOD performance in the HTR models, with the results across the various selection strategies being practically identical."
  - [corpus]: Weak evidence. The corpus papers do not discuss model selection or capacity effects in the context of HTR generalization.
- Break condition: If specific model architectures or selection strategies prove more robust in other HTR studies, or if capacity becomes relevant in larger-scale or different HTR tasks.

## Foundational Learning

- Concept: Factor Analysis
  - Why needed here: To identify the underlying latent factors that most influence OOD generalization in HTR models, beyond the observable metrics.
  - Quick check question: How do you determine the number of factors to retain in a factor analysis, and what criteria justify this choice?
- Concept: KL Divergence for Textual Distributions
  - Why needed here: To quantify the divergence between textual distributions across domains using n-grams, capturing linguistic differences.
  - Quick check question: Why is averaging KL divergence across n-grams (1-5) a suitable way to measure textual divergence, and what are its limitations?
- Concept: Reconstruction Error as Anomaly Detection
  - Why needed here: To measure visual divergence between domains by training an autoencoder on the source and evaluating reconstruction error on the target.
  - Quick check question: How does reconstruction error reflect domain shift, and what assumptions underlie this approach?

## Architecture Onboarding

- Component map: Datasets -> Data Augmentation -> HTR Models (CRNN, V AN, C-SAN, HTR-VT, Kang, Michael, LT, VLT) -> Evaluation -> Divergence Metrics (Visual via Reconstruction Error, Textual via KL Divergence) -> Factor Analysis -> OOD Error Estimation
- Critical path: For OOD analysis: (1) Train HTR models on source domains, (2) Evaluate on target domains, (3) Compute divergence metrics, (4) Perform factor analysis to identify key factors, (5) Estimate OOD error from proxy metrics
- Design tradeoffs: Choosing between CTC, Seq2Seq, and hybrid alignment affects generalization; using synthetic data can improve OOD performance but introduces language mismatch; factor analysis simplifies complex interactions but may miss nuances
- Failure signatures: High OOD CER with low textual/visual divergence may indicate model capacity or architecture issues; low OOD CER with high divergence suggests metric limitations; inconsistent factor loadings across runs may indicate instability
- First 3 experiments:
  1. Train and evaluate all 8 HTR models on IAM (source) and Rimes (target) to replicate core OOD findings.
  2. Generate synthetic data in English and French, train models on each, and evaluate on Rimes to test synthetic data benefits.
  3. Compute visual and textual divergences between IAM and Rimes, then perform factor analysis to confirm Factor 1 dominance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can visual divergence between domains be more accurately quantified using alternative anomaly detection methods beyond reconstruction error?
- Basis in paper: [inferred] The paper uses reconstruction error from an autoencoder to measure visual divergence, but acknowledges this is a simple approach and that "more research studying this last factor has to be done."
- Why unresolved: The paper uses a basic convolutional autoencoder and doesn't explore more sophisticated methods like adversarial training, contrastive learning, or domain-specific feature extraction that might better capture visual differences relevant to HTR performance.
- What evidence would resolve it: Comparative experiments testing multiple anomaly detection approaches (e.g., contrastive autoencoders, GAN-based methods, feature extractor-based metrics) against the reconstruction error method, measuring their correlation with actual OOD performance.

### Open Question 2
- Question: Does increasing model capacity beyond the tested range improve OOD generalization performance in HTR models?
- Basis in paper: [explicit] The paper finds that "an increase in model capacity does not correspond to an improvement in the generalization capabilities in OOD scenarios" but only tests models up to 90M parameters.
- Why unresolved: The tested parameter range may be insufficient to reach the point where capacity benefits OOD performance, especially given the extreme visual and textual differences between domains studied.
- What evidence would resolve it: Experiments with significantly larger models (hundreds of millions to billions of parameters) trained on the same datasets, comparing OOD performance curves to determine if a capacity threshold exists.

### Open Question 3
- Question: How do different types of synthetic data generation (e.g., HTG methods vs random text generation) impact the effectiveness of synthetic data for OOD generalization?
- Basis in paper: [explicit] The paper excludes HTG methods "as they rely on labeled data targeting ID performance, limiting their applicability to DG" but doesn't test whether they might be more effective for OOD scenarios.
- Why unresolved: The paper only tests random text generation from Wikipedia, which may not capture the same linguistic patterns or visual characteristics as more sophisticated HTG approaches that could better prepare models for domain shifts.
- What evidence would resolve it: Direct comparison between HTG-generated synthetic data and random text generation, measuring both ID and OOD performance across multiple architectures and domain pairs.

### Open Question 4
- Question: What is the relative contribution of visual vs. textual divergence when both factors are present simultaneously in a domain shift?
- Basis in paper: [explicit] Factor analysis shows textual divergence explains most OOD error (Factor 1) while visual divergence has "a modest influence" (Factor 2), but the interaction between these factors isn't explicitly tested.
- Why unresolved: The factor analysis identifies independent contributions but doesn't establish how these factors interact or which dominates in different types of domain shifts (e.g., same language/different script vs different language/same script).
- What evidence would resolve it: Controlled experiments isolating visual and textual divergence components, such as testing cross-language shifts with matched visual styles versus same-language shifts with different visual styles, to determine their relative importance.

## Limitations
- The study relies on proxy metrics (KL-divergence) for textual divergence rather than direct linguistic analysis, which may not fully capture semantic differences
- Factor analysis assumes linear relationships between observed metrics and latent factors, potentially missing non-linear interactions
- The relatively small sample size of 336 OOD cases across 8 models may limit generalizability to other HTR architectures

## Confidence
- **High Confidence**: The observation that model selection strategies and model capacity have negligible impact on OOD performance
- **Medium Confidence**: The identification of textual divergence as the primary factor affecting OOD error
- **Medium Confidence**: The effectiveness of proxy metrics in estimating OOD error within 10 points in 70% of cases

## Next Checks
1. Conduct ablation studies on the textual divergence metric by comparing KL-divergence against alternative linguistic distance measures (e.g., BLEU, ROUGE) to verify robustness of Factor 1 identification
2. Perform leave-one-model-out cross-validation on the factor analysis to assess stability of latent factors across different model subsets
3. Test the proxy metric estimation framework on a new, held-out dataset pair (e.g., IAM to Bentham) to validate the 10-point error estimation claim independently