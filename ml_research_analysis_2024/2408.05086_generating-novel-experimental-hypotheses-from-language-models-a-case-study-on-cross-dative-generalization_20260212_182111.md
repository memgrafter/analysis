---
ver: rpa2
title: 'Generating novel experimental hypotheses from language models: A case study
  on cross-dative generalization'
arxiv_id: '2408.05086'
source_url: https://arxiv.org/abs/2408.05086
tags:
- generalization
- verb
- novel
- exposure
- theme
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method to use language models (LMs) as simulated
  learners to derive novel experimental hypotheses for human language acquisition
  studies. The authors focus on cross-dative generalization (CDG), where learners
  generalize novel verbs across dative constructions (e.g., she pilked me the ball/she
  pilked the ball to me).
---

# Generating novel experimental hypotheses from language models: A case study on cross-dative generalization

## Quick Facts
- arXiv ID: 2408.05086
- Source URL: https://arxiv.org/abs/2408.05086
- Reference count: 40
- This paper presents a method to use language models (LMs) as simulated learners to derive novel experimental hypotheses for human language acquisition studies, focusing on cross-dative generalization (CDG).

## Executive Summary
This paper introduces a novel approach to deriving experimental hypotheses for human language acquisition by using language models (LMs) as simulated learners. The authors focus on cross-dative generalization (CDG), where learners generalize novel verbs across dative constructions. They train LMs on child-directed speech and systematically vary the features of theme and recipient in exposure contexts. The study first validates that LMs replicate known patterns of children's CDG, then uses these models to explore novel hypotheses about how contextual features influence generalization. The results suggest that CDG is facilitated when the first postverbal argument is pronominal, definite, short, and harmonically aligned with discourse prominence expectations.

## Method Summary
The study uses autoregressive decoder-only Transformer LMs (OPT architecture) trained from scratch on the AO-CHILDES corpus of child-directed speech. The models have 8.4M parameters and are trained for 10 epochs. Novel verb learning trials involve adding a randomly initialized novel verb token to the vocabulary, updating its embedding on exposure stimuli, and validating verbhood. Generalization behavior is measured by comparing log probabilities of novel verbs in modeled versus unmodeled dative constructions. Linear mixed-effects models predict generalization based on exposure features including pronominality, animacy, definiteness, and length of theme and recipient arguments.

## Key Results
- LMs replicate known patterns of children's cross-dative generalization, showing asymmetric generalization from double object (DO) to prepositional phrase (PP) constructions
- Cross-dative generalization is facilitated when the first postverbal argument is pronominal, definite, short, and harmonically aligned with discourse prominence expectations
- The proposed harmonic alignment hypothesis suggests that CDG is enhanced when exposure context features align with positional prominence scales

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Language models trained on child-directed speech replicate known patterns of cross-dative generalization in children.
- **Mechanism**: The LM learns distributional patterns of dative constructions from exposure, enabling it to generalize novel verbs to unmodeled dative forms analogously to children.
- **Core assumption**: The linguistic input from child-directed speech contains sufficient distributional cues for LMs to mimic human generalization patterns.
- **Evidence anchors**:
  - [abstract] "We find LMs to replicate known patterns of children's CDG, as a precondition to exploring novel hypotheses."
  - [section 4.1] "LM learners exhibited relatively greater tendency to generalize from DO to PP than from PP to DO, for both types of our generalization set sentences (p < .001 using a linear mixed-effects model)."
- **Break condition**: If the LM is trained on a corpus lacking sufficient dative construction examples or distributional cues, it will not replicate human patterns.

### Mechanism 2
- **Claim**: Harmonic alignment of discourse and positional prominence scales in exposure contexts facilitates cross-dative generalization.
- **Mechanism**: Features of the first postverbal argument that align with positional prominence (e.g., pronominal, definite, short) promote generalization by creating favorable distributional cues.
- **Core assumption**: LMs encode and utilize discourse prominence hierarchies similar to humans when processing dative constructions.
- **Evidence anchors**:
  - [abstract] "These patterns are characteristic of harmonic alignment in datives, where the argument with features ranking higher on the discourse prominence scale tends to precede the other."
  - [section 5.2] "Our results suggest a potential role of harmonically aligned first postverbal argument features in LM learners' cross-dative generalization."
- **Break condition**: If the LM does not encode discourse prominence hierarchies, harmonic alignment will not facilitate generalization.

### Mechanism 3
- **Claim**: Preemption via exposure cues explains the role of feature configurations in cross-dative generalization.
- **Mechanism**: Exposure to a novel verb in a construction with features associated with the alternate construction (e.g., PP-associated features in DO exposure) preempts generalization by providing indirect negative evidence.
- **Core assumption**: LMs can infer counterfactual usage patterns from distributional cues, similar to human learners.
- **Evidence anchors**:
  - [section 5.4] "The usage of a novel verb in the DO construction is preempted if it is observed in a PP construction in contexts where a DO construction is expected."
- **Break condition**: If the LM does not encode counterfactual inference mechanisms, preemption will not explain generalization patterns.

## Foundational Learning

- **Concept**: Dative alternation in English (DO vs. PP constructions)
  - **Why needed here**: Understanding the dative alternation is crucial for interpreting the experimental setup and results, as the study focuses on cross-dative generalization.
  - **Quick check question**: What is the primary difference between the double object (DO) and prepositional phrase (PP) dative constructions in English?

- **Concept**: Child-directed speech and its role in language acquisition
  - **Why needed here**: The study uses LMs trained on child-directed speech to simulate human language acquisition, so understanding the characteristics of this input is essential.
  - **Quick check question**: Why is child-directed speech considered a developmentally plausible corpus for training LMs in language acquisition studies?

- **Concept**: Statistical preemption and entrenchment in language learning
  - **Why needed here**: The study discusses preemption as a mechanism for explaining the role of exposure cues in generalization, so understanding these concepts is crucial for interpreting the results.
  - **Quick check question**: How does statistical preemption differ from entrenchment in explaining the avoidance of overgeneralization errors in language learning?

## Architecture Onboarding

- **Component map**: OPT model architecture (8.4M parameters) -> Training on AO-CHILDES corpus -> Novel verb learning trials with exposure stimuli -> Generalization evaluation on held-out sets
- **Critical path**: Train LMs on child-directed speech → Systematically vary exposure context features → Evaluate novel verb generalization → Analyze patterns to derive hypotheses
- **Design tradeoffs**: The choice of a smaller LM architecture (8.4M parameters) and a developmentally plausible corpus (AO-CHILDES) prioritizes ecological validity over raw performance, potentially limiting the LM's ability to capture complex linguistic patterns
- **Failure signatures**: If the LM fails to replicate known patterns of cross-dative generalization or does not show sensitivity to exposure cues, it may indicate issues with the training data, model architecture, or experimental design
- **First 3 experiments**:
  1. Test the LM's ability to generalize novel verbs from DO to PP and vice versa, replicating Conwell and Demuth (2007)'s findings on asymmetric generalization
  2. Investigate the role of theme animacy and cross-structure training in generalization, replicating Arunachalam (2017)'s findings
  3. Conduct an exhaustive exploration of theme and recipient feature configurations to characterize their effects on cross-dative generalization, as described in the main simulation study (section 4.3)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Do distributional cues from a broader set of exposures, beyond the controlled stimuli used in the experiments, significantly modulate the cross-dative generalization patterns observed in language models?
- **Basis in paper**: [inferred] The paper acknowledges the potential impact of a broader set of distributional cues, such as transitive uses of ditransitive verbs, on the learning of novel dative verbs in natural settings.
- **Why unresolved**: The experiments were conducted using controlled stimuli with single exposure contexts, limiting the exploration of the effects of indirect evidence and a wider range of linguistic experiences on generalization.
- **What evidence would resolve it**: Conducting experiments with language models exposed to a more diverse and naturalistic set of linguistic inputs, including transitive uses of ditransitive verbs and other indirect evidence, and analyzing the resulting cross-dative generalization patterns.

### Open Question 2
- **Question**: Does the semantic signal of possession transfer, beyond the canonical animacy features of event participants, further facilitate cross-dative generalization in language models, particularly from prepositional phrase (PP) to double object (DO) constructions?
- **Basis in paper**: [explicit] The paper mentions a preliminary experiment that found no significant difference in generalization when additional context indicating possession transfer was provided in PP exposures, suggesting that LMs might not capture the semantic nuances of possession transfer.
- **Why unresolved**: The preliminary experiment was limited in scope and did not explore the potential interaction between semantic signals and other contextual features in modulating generalization.
- **What evidence would resolve it**: Conducting more comprehensive experiments with language models exposed to PP contexts with varying degrees of semantic clarity regarding possession transfer, and analyzing the resulting generalization patterns in relation to other contextual features.

### Open Question 3
- **Question**: Are there mechanistic similarities between how language models and human learners carry out cross-dative generalization, or are the observed patterns subject to multiple realizability, where different processing mechanisms lead to similar input-output behaviors?
- **Basis in paper**: [explicit] The paper acknowledges the possibility of multiple realizability and emphasizes the need for further investigations to determine whether the observed patterns of generalization in language models reflect similar underlying processes in human learners.
- **Why unresolved**: The paper focuses on the behavioral alignment between language models and human learners, but does not delve into the potential differences in their processing mechanisms or cognitive architectures.
- **What evidence would resolve it**: Conducting comparative studies that examine the processing mechanisms and neural activations involved in cross-dative generalization in both language models and human learners, and analyzing the similarities and differences in their underlying cognitive processes.

## Limitations

- The ecological validity of using language models to simulate human language acquisition remains uncertain, despite training on developmentally plausible child-directed speech
- The proposed mechanisms (harmonic alignment, preemption) are inferred from model behavior rather than directly validated through human experiments
- The OPT architecture used (8.4M parameters) may lack the representational capacity to capture all relevant linguistic patterns, potentially limiting generalizability to larger or more complex models

## Confidence

- **High confidence**: The finding that language models replicate known patterns of cross-dative generalization in children, as this is supported by direct empirical comparisons with established human studies (Conwell & Demuth, 2007; Arunachalam, 2017)
- **Medium confidence**: The proposed mechanism of harmonic alignment facilitating generalization, as it is supported by systematic simulations but requires direct human validation to confirm its applicability to child language acquisition
- **Medium confidence**: The preemption mechanism explaining feature-based generalization patterns, as it provides a plausible account but lacks direct empirical support from human studies

## Next Checks

1. **Human replication study**: Conduct a behavioral experiment with children to test whether harmonic alignment of discourse prominence features in exposure contexts facilitates cross-dative generalization, directly validating the novel hypothesis derived from LM simulations

2. **Model architecture scaling**: Repeat the simulations with larger language models (e.g., GPT-2, BERT) to assess whether the observed patterns of cross-dative generalization and the proposed mechanisms (harmonic alignment, preemption) are consistent across different model architectures and scales

3. **Cross-linguistic validation**: Extend the LM simulations to languages with different dative alternation patterns (e.g., German, Japanese) to evaluate the cross-linguistic applicability of the harmonic alignment hypothesis and identify language-specific vs. universal mechanisms in dative acquisition