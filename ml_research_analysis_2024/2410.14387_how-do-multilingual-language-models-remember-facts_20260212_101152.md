---
ver: rpa2
title: How Do Multilingual Language Models Remember Facts?
arxiv_id: '2410.14387'
source_url: https://arxiv.org/abs/2410.14387
tags:
- subj
- last
- after
- language
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how multilingual language models (LLMs)
  store and retrieve factual knowledge across different languages, focusing on three
  models: XGLM, EUROLLM, and mT5. The authors analyze how these models recall facts
  using causal tracing to identify key layers for subject token processing and attention
  mechanisms.'
---

# How Do Multilingual Language Models Remember Facts?

## Quick Facts
- arXiv ID: 2410.14387
- Source URL: https://arxiv.org/abs/2410.14387
- Reference count: 40
- Primary result: Multilingual LLMs show both shared and distinct mechanisms for factual recall compared to English models, with language-specific extraction phases and model architecture-dependent encoding timing

## Executive Summary
This paper investigates how multilingual language models (LLMs) store and retrieve factual knowledge across different languages, focusing on three models: XGLM, EUROLLM, and mT5. The authors analyze how these models recall facts using causal tracing to identify key layers for subject token processing and attention mechanisms. They also use attention knockout to study information flow to the final token and measure extraction events to understand how predicted objects are generated. The primary results show that while some mechanisms from English LLMs generalize to multilingual models, key differences exist: multilingual models use both MLPs and attention layers during extraction, unlike English models which rely mainly on attention. Additionally, the authors use activation patching to study language encoding during recall, finding that in decoder-only models, relation information flows to the last token before language encoding, whereas in mT5, both flow simultaneously. The findings reveal that subject and relation representations are largely language-independent, but the extraction phase is language-specific, providing new insights into cross-lingual knowledge transfer and the need for tailored methodologies for multilingual LLMs.

## Method Summary
The authors employ causal tracing to identify key layers for subject token processing and attention mechanisms in multilingual LLMs. They use attention knockout to study information flow to the final token and measure extraction events to understand how predicted objects are generated. Activation patching is applied to study language encoding during recall, comparing decoder-only models (XGLM, EUROLLM) with encoder-decoder models (mT5). The analysis focuses on three multilingual models: XGLM, EUROLLM, and mT5, examining their factual recall mechanisms across different languages.

## Key Results
- Multilingual models use both MLPs and attention layers during extraction, unlike English models which rely mainly on attention
- In decoder-only models, relation information flows to the last token before language encoding; in mT5, both flow simultaneously
- Subject and relation representations are largely language-independent, but the extraction phase is language-specific

## Why This Works (Mechanism)
The paper demonstrates that multilingual LLMs employ a combination of attention and MLP mechanisms for factual recall, with the extraction phase being particularly language-specific. The timing of relation and language encoding differs between decoder-only and encoder-decoder architectures, suggesting that model architecture influences how multilingual knowledge is processed and retrieved.

## Foundational Learning
- **Causal tracing**: Why needed - to identify which layers and components are critical for processing subject tokens during factual recall; Quick check - verify that traced layers align with expected processing stages in the model architecture
- **Attention knockout**: Why needed - to measure the impact of attention mechanisms on information flow to the final token; Quick check - confirm that knockout results show differential effects across model components
- **Activation patching**: Why needed - to study when and how language information is encoded during the recall process; Quick check - ensure that patching reveals distinct timing patterns between decoder-only and encoder-decoder models
- **Extraction event measurement**: Why needed - to quantify how predicted objects are generated during factual recall; Quick check - validate that extraction events correlate with correct object predictions
- **Cross-lingual comparison**: Why needed - to identify language-specific vs. language-independent mechanisms in factual recall; Quick check - verify that findings hold across diverse language pairs
- **MLP vs. attention analysis**: Why needed - to understand the relative contributions of different neural mechanisms in multilingual models; Quick check - confirm that MLP usage differs significantly between multilingual and English-only models

## Architecture Onboarding

**Component map**: Input tokens -> Embedding layer -> Encoder/Decoder layers (with attention and MLP subcomponents) -> Extraction phase -> Output layer

**Critical path**: Subject token processing -> Attention/MLP computation -> Relation encoding -> Language encoding -> Object extraction

**Design tradeoffs**: The paper highlights that multilingual models must balance language-specific and language-independent representations, with encoder-decoder models (mT5) showing different timing patterns compared to decoder-only models (XGLM, EUROLLM). The use of both MLPs and attention during extraction suggests a more complex knowledge retrieval mechanism than in English-only models.

**Failure signatures**: If the extraction phase is disrupted, factual recall accuracy drops significantly. If language encoding timing is misaligned, cross-lingual transfer may fail. If MLP components are ablated, multilingual models show reduced performance compared to attention-only ablations.

**First experiments**:
1. Replicate causal tracing on an additional multilingual model to verify the generalizability of identified key layers
2. Perform attention knockout experiments focusing specifically on MLP components during extraction
3. Conduct activation patching across more diverse language pairs to test the robustness of language-independent subject/relation representations

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis is confined to three specific multilingual models (XGLM, EUROLLM, mT5), limiting generalizability
- Experimental setup relies heavily on controlled factual recall tasks, which may not capture real-world complexity
- Techniques like causal tracing and attention knockout may not capture all relevant pathways for knowledge retrieval
- The claim that extraction is "language-specific" requires further validation across more diverse linguistic contexts

## Confidence
- Mechanisms of fact recall in multilingual models: High
- Differences between multilingual and English-only models: High
- Language encoding timing differences between decoder-only and encoder-decoder models: Medium
- Language-independence of subject/relation representations: Medium

## Next Checks
1. Replicate the causal tracing analysis on additional multilingual models (e.g., BLOOM, mBERT) to test generalizability of the identified mechanisms
2. Extend the language encoding experiments to include more diverse language pairs, particularly low-resource languages, to confirm the robustness of the subject/relation language-independence claim
3. Conduct ablation studies on the MLP and attention components during extraction to quantify their relative contributions across different linguistic contexts and model architectures