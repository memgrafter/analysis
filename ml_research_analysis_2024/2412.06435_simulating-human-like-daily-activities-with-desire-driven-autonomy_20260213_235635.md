---
ver: rpa2
title: Simulating Human-like Daily Activities with Desire-driven Autonomy
arxiv_id: '2412.06435'
source_url: https://arxiv.org/abs/2412.06435
tags:
- alice
- agent
- action
- value
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a desire-driven autonomy framework that enables
  LLM-based agents to autonomously generate and select activities aligned with intrinsic
  motivations, inspired by the Theory of Needs. The Desire-driven Autonomous Agent
  (D2A) uses a dynamic Value System to track multi-dimensional desires (e.g., hunger,
  social connectivity) and selects activities that best satisfy these desires.
---

# Simulating Human-like Daily Activities with Desire-driven Autonomy

## Quick Facts
- arXiv ID: 2412.06435
- Source URL: https://arxiv.org/abs/2412.06435
- Authors: Yiding Wang; Yuxuan Chen; Fangwei Zhong; Long Ma; Yizhou Wang
- Reference count: 40
- Key outcome: Introduces desire-driven autonomy framework enabling LLM-based agents to autonomously generate and select activities aligned with intrinsic motivations, showing superior human-likeness in text-based simulations compared to baseline agents

## Executive Summary
This paper presents a desire-driven autonomy framework that enables LLM-based agents to generate human-like daily activities by autonomously selecting actions aligned with intrinsic motivations. The framework, called D2A (Desire-driven Autonomous Agent), uses a dynamic Value System to track multi-dimensional desires and selects activities that best satisfy these desires at each time step. Experiments on a text-based simulator show that D2A produces more natural, coherent, and plausible daily activities compared to baseline approaches like ReAct, BabyAGI, and LLMob, both in indoor and outdoor environments.

The core insight is that human-like behavior can be simulated by modeling intrinsic desires and allowing agents to autonomously select activities to fulfill them. D2A demonstrates adaptability to social interactions, generalizes across environments and LLM backbones, and shows the importance of qualitative value descriptions and planner width parameters in performance. The framework effectively satisfies desires in a manner similar to humans while maintaining coherence in activity sequences.

## Method Summary
The D2A framework consists of two main components: a Value System that tracks multi-dimensional desire states (hunger, thirst, sleepiness, etc.) and a Desire-driven Planner that generates, evaluates, and selects activities to satisfy these desires. At each time step, the agent evaluates its current desire states, proposes candidate activities, and selects the one that best reduces dissatisfaction between current and expected desire values. The framework uses qualitative value descriptions to improve LLM interpretability and employs a planner width parameter to optimize exploration of the activity space. Experiments were conducted in the Concordia text-based simulator with 15 trials per configuration, using GPT-4o for evaluation and calculating dissatisfaction metrics.

## Key Results
- D2A generates more natural, coherent, and plausible daily activities compared to baseline agents (ReAct, BabyAGI, LLMob) across indoor and outdoor environments
- Human evaluations and GPT-4o assessments confirm D2A's superior human-likeness in activity generation
- The framework effectively satisfies desires like humans and demonstrates adaptability to social interactions
- Ablation studies highlight the importance of qualitative value descriptions and planner width in performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The desire-driven autonomy framework enables more human-like activity generation by aligning agent actions with intrinsic motivations modeled through a dynamic Value System.
- **Mechanism:** At each step, the agent evaluates its current desire states (e.g., hunger, social connectivity), proposes candidate activities, and selects the one that best reduces dissatisfaction between current and expected desire values. This mimics human decision-making driven by needs.
- **Core assumption:** Human-like behaviors can be simulated by modeling intrinsic desires and allowing agents to autonomously select activities to fulfill them.
- **Evidence anchors:**
  - [abstract] "Our Desire-driven Autonomous Agent (D2A) follows the 'Act to Satisfy Intrinsic Desires' principle"
  - [section 5.1] "The theory of needs suggests that individual behavior is motivated by meeting the individual's needs or wants"
  - [corpus] Weak – no direct citations on desire-driven frameworks in agent literature found.
- **Break condition:** If the Value System fails to accurately represent human needs or if activity selection becomes overly biased toward short-term satisfaction at the expense of long-term coherence.

### Mechanism 2
- **Claim:** Qualitative value descriptions improve agent understanding of desire states, leading to more appropriate activity selection.
- **Mechanism:** Numerical desire values are translated into descriptive sentences (e.g., "nearly starved, feeling weak and unable to concentrate due to a lack of food"), enabling the agent to better recognize shortfalls and select actions that address them.
- **Core assumption:** Large language models interpret qualitative, descriptive information more effectively than raw numerical values when reasoning about states and actions.
- **Evidence anchors:**
  - [section 5.2] "Since many studies have shown that large language models often struggle with interpreting numerical values, we designed the Qualitative Value Description procedure"
  - [section 6.4] "Ablation study shows that when the qualitative description component is removed, the agent struggles to accurately interpret its current desire states"
  - [corpus] Weak – limited direct evidence on LLM interpretability of numerical vs. descriptive states.
- **Break condition:** If qualitative descriptions become too verbose or ambiguous, potentially confusing the agent rather than aiding decision-making.

### Mechanism 3
- **Claim:** The planner width parameter optimizes the exploration of the activity space, improving the selection of desire-satisfying actions.
- **Mechanism:** The Desire-driven Planner generates multiple candidate activities (width N), evaluates their impact on desire states, and selects the best one. A larger width provides more options, increasing the likelihood of finding optimal actions.
- **Core assumption:** A broader set of candidate activities increases the probability of selecting actions that effectively reduce dissatisfaction across multiple desire dimensions.
- **Evidence anchors:**
  - [section 5.3] "Inspired by the work of Tree of Thoughts, we argue that the paradigm of presenting multiple candidate activities and evaluating them enables the agent to select the best action"
  - [section 6.4] "Ablation study shows that D2A(W-1) encounters difficulties in selecting the optimal activity to reduce dissatisfaction, while D2A(W-5) is more effective at selecting activities that minimize dissatisfaction"
  - [corpus] Weak – no direct citations on planner width effects in LLM-based agents found.
- **Break condition:** If the planner width becomes too large, computational costs increase without proportional gains in activity quality, or if evaluation becomes superficial due to volume.

## Foundational Learning

- **Concept:** Dynamic Value System for tracking multi-dimensional desires
  - **Why needed here:** To model the fluctuating nature of human needs and motivations, enabling agents to generate contextually relevant activities that address current shortfalls.
  - **Quick check question:** How does the Value System update desire values after an action is executed, and what factors influence the magnitude of change?

- **Concept:** Qualitative state description for LLM interpretability
  - **Why needed here:** To bridge the gap between numerical desire metrics and LLM reasoning, ensuring agents can effectively interpret their current states and make informed decisions.
  - **Quick check question:** What is the process for converting numerical desire values into descriptive sentences, and why is this step critical for activity selection?

- **Concept:** Multi-candidate activity evaluation (planner width)
  - **Why needed here:** To enable systematic exploration of the activity space, allowing agents to compare potential actions and select those that best satisfy their intrinsic motivations.
  - **Quick check question:** How does the Desire-driven Planner generate and evaluate candidate activities, and what criteria determine the "best" action?

## Architecture Onboarding

- **Component map:** Value System → Desire-driven Planner → Environment → Value System (iterative loop per time step)
- **Critical path:** Value System → Desire-driven Planner → Environment → Value System (iterative loop per time step)
- **Design tradeoffs:**
  - Qualitative vs. numerical desire representation: improved interpretability vs. increased generation overhead
  - Planner width: broader exploration vs. computational cost
  - Multi-step planning: long-term coherence vs. responsiveness to immediate desires
- **Failure signatures:**
  - Agent selects repetitive or irrelevant activities (planner evaluation failure)
  - Desire values diverge from expected states (Value System update failure)
  - Generated activities violate environmental constraints (consistency enforcement failure)
- **First 3 experiments:**
  1. Run D2A with width=1 vs. width=3 to observe impact on dissatisfaction reduction
  2. Enable/disable qualitative descriptions to measure effect on activity appropriateness
  3. Test D2A in indoor environment with randomized items to validate robustness across configurations

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do agents handle conflicting desires when multiple desires are equally urgent or in direct opposition?
- **Basis in paper:** [inferred] The paper mentions agents evaluate and select activities based on current desire states, but does not specify how conflicts between equally urgent or opposing desires are resolved.
- **Why unresolved:** The paper does not describe a prioritization mechanism or decision-making process for handling conflicting desires, which is crucial for realistic human-like behavior.
- **What evidence would resolve it:** Experiments showing agent behavior when desires are in direct conflict (e.g., hunger vs. social connectivity) and whether they show consistent decision-making patterns or require additional rules for conflict resolution.

### Open Question 2
- **Question:** How does the framework handle long-term planning versus immediate desire satisfaction?
- **Basis in paper:** [explicit] The ablation study shows that adding a multi-step planning component actually decreased performance, suggesting tension between short-term and long-term planning.
- **Why unresolved:** The paper does not explore whether the framework can balance immediate desires with longer-term goals or how it might handle scenarios requiring sustained effort over time.
- **What evidence would resolve it:** Comparative experiments testing agent performance in scenarios requiring both immediate satisfaction and long-term planning (e.g., maintaining health over weeks while also meeting daily social needs).

### Open Question 3
- **Question:** How does the framework generalize to environments with more complex social dynamics and power structures?
- **Basis in paper:** [explicit] The paper mentions extending to outdoor party environments with higher-level desires like "recognition" and "sense of superiority," but does not test environments with formal hierarchies or power dynamics.
- **Why unresolved:** The paper does not explore whether the framework can handle environments with formal social hierarchies, competition for resources, or complex group dynamics beyond casual social interactions.
- **What evidence would resolve it:** Experiments in environments with explicit social hierarchies (e.g., workplace settings, political simulations) showing whether agents can navigate power structures and adapt their behavior accordingly.

## Limitations

- The approach's generalizability beyond the Concordia text-based simulator remains uncertain, with unclear performance in more complex, real-world environments or with different types of desires
- Reliance on GPT-4o for evaluation introduces potential circularity, as the same model type is used both as a judge and in the system design
- Human evaluation sample size (20 participants) may be insufficient for robust statistical conclusions about human-likeness

## Confidence

- **High confidence**: The core mechanism of desire-driven activity selection through a dynamic Value System is well-supported by both theoretical framing and experimental results. The claim that D2A generates more natural and coherent daily activities compared to baselines is strongly supported by both human and GPT-4o evaluations.
- **Medium confidence**: The effectiveness of qualitative value descriptions for improving LLM interpretability is plausible based on the ablation study, but would benefit from additional experiments comparing different description formats or direct LLM interpretability measurements.
- **Low confidence**: The specific parameter choices (planner width=3, 11 desire dimensions) are presented as optimal but lack systematic sensitivity analysis. Claims about generalizability across environments and LLM backbones are based on limited comparisons rather than comprehensive testing.

## Next Checks

1. **Cross-environment validation**: Test D2A in a different simulator or real-world environment (e.g., robotics platform or different text-based world) to assess generalizability of desire-driven activity generation beyond Concordia.
2. **Independent evaluation**: Conduct blind human evaluations where raters don't know which agent generated which activities, and include alternative evaluation metrics beyond human-likeness (e.g., task completion, efficiency).
3. **Parameter sensitivity analysis**: Systematically vary planner width (1-10) and number of desire dimensions (5-15) to identify optimal configurations and understand the impact of these hyperparameters on performance across different scenarios.