---
ver: rpa2
title: 'FairDiffusion: Enhancing Equity in Latent Diffusion Models via Fair Bayesian
  Perturbation'
arxiv_id: '2412.20374'
source_url: https://arxiv.org/abs/2412.20374
tags:
- stable
- fairness
- diffusion
- image
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates fairness in medical text-to-image diffusion
  models, revealing significant disparities across gender, race, and ethnicity subgroups
  in both image generation quality and semantic correlation of clinical features.
  The authors propose FairDiffusion, an equity-aware latent diffusion model that employs
  Bayesian optimization to adaptively perturb the learning process for each demographic
  group.
---

# FairDiffusion: Enhancing Equity in Latent Diffusion Models via Fair Bayesian Perturbation

## Quick Facts
- arXiv ID: 2412.20374
- Source URL: https://arxiv.org/abs/2412.20374
- Reference count: 0
- Key outcome: This study investigates fairness in medical text-to-image diffusion models, revealing significant disparities across gender, race, and ethnicity subgroups in both image generation quality and semantic correlation of clinical features. The authors propose FairDiffusion, an equity-aware latent diffusion model that employs Bayesian optimization to adaptively perturb the learning process for each demographic group. Trained on a newly curated FairGenMed dataset, FairDiffusion demonstrates substantial improvements over standard Stable Diffusion, reducing FID by 7.84 for Black and 11.79 for Hispanic subgroups while improving semantic correlation with AUC gains of 10.03 for Asian and 7.58 for Male subgroups on glaucoma classification. The approach generalizes across medical imaging modalities, showing consistent fairness improvements on HAM10000 and CheXpert datasets.

## Executive Summary
This paper addresses fairness disparities in medical text-to-image diffusion models across demographic groups. The authors identify significant gaps in image generation quality and semantic correlation of clinical features between different gender, race, and ethnicity subgroups when using standard Stable Diffusion. To address these issues, they propose FairDiffusion, a novel method that uses Bayesian optimization to adaptively perturb the learning process based on demographic attributes. The approach is evaluated on a newly curated FairGenMed dataset and demonstrates substantial improvements in both generation quality and semantic correlation across all demographic groups while maintaining overall performance.

## Method Summary
FairDiffusion builds upon Stable Diffusion by incorporating a Fair Bayesian Perturbation module that applies demographic-conditioned perturbations during training. The method uses Bayesian optimization with an upper confidence bound acquisition function to learn optimal perturbation parameters for each demographic group. During training, the model computes perturbations based on group-specific characteristics and applies them to the denoising score matching loss. This adaptive perturbation process aims to reduce distribution mismatches between generated and real images for underrepresented groups while maintaining overall generation quality. The approach is evaluated using equity-scaled metrics (ES-FID, ES-IS, ES-AUC) on the FairGenMed dataset and demonstrates generalizability across medical imaging modalities including dermatology and chest radiography.

## Key Results
- FairDiffusion reduces Fr√©chet Inception Distance (FID) by 7.84 for Black and 11.79 for Hispanic subgroups compared to standard Stable Diffusion
- Semantic correlation improvements show AUC gains of 10.03 for Asian and 7.58 for Male subgroups on glaucoma classification
- The method generalizes across medical imaging modalities, showing consistent fairness improvements on HAM10000 and CheXpert datasets

## Why This Works (Mechanism)

###