---
ver: rpa2
title: 'From Models to Systems: A Comprehensive Fairness Framework for Compositional
  Recommender Systems'
arxiv_id: '2412.04655'
source_url: https://arxiv.org/abs/2412.04655
tags:
- fairness
- utility
- user
- item
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of fairness in compositional recommender
  systems, where multiple ML models work together to provide recommendations. The
  authors argue that traditional fairness notions focused on individual models are
  insufficient, as real-world systems involve complex interactions between retrieval,
  scoring, and serving components.
---

# From Models to Systems: A Comprehensive Fairness Framework for Compositional Recommender Systems

## Quick Facts
- arXiv ID: 2412.04655
- Source URL: https://arxiv.org/abs/2412.04655
- Authors: Brian Hsu; Cyrus DiCiccio; Natesh Sivasubramoniapillai; Hongseok Namkoong
- Reference count: 40
- Key outcome: Fair EHVI method consistently identifies better tradeoffs between utility and DER compared to random search and pure utility optimization, achieving statistically significant improvements in DER across all tested datasets

## Executive Summary
This paper addresses the problem of fairness in compositional recommender systems, where multiple ML models work together to provide recommendations. The authors argue that traditional fairness notions focused on individual models are insufficient, as real-world systems involve complex interactions between retrieval, scoring, and serving components. The core contribution is formulating system-level fairness as a multi-objective optimization problem balancing overall utility and equity across user groups, with Bayesian Optimization adapted to jointly optimize these objectives.

## Method Summary
The authors formulate system-level fairness in compositional recommender systems as a multi-objective optimization problem balancing utility and equity across user groups. They adapt Bayesian Optimization using Expected Hypervolume Improvement (EHVI) to jointly optimize these objectives, introducing a novel fairness metric called Deviation from Equal Representation (DER). The approach is tested on synthetic and real datasets (MovieLens, ModCloth, Electronics) to demonstrate effective tradeoffs between utility and fairness.

## Key Results
- Fair EHVI method consistently identifies better tradeoffs between utility and DER compared to random search and pure utility optimization
- Statistically significant improvements in DER achieved across all tested datasets
- The framework demonstrates effectiveness on both synthetic data and real-world recommendation datasets

## Why This Works (Mechanism)

### Mechanism 1
Traditional model-level fairness metrics fail to ensure equitable outcomes in compositional systems because utility depends on interactions across multiple components. Utility in compositional systems is determined by the weighted sum of multiple model outputs, retrieval success, and user preferences. Disparities in any component can amplify downstream unfairness even if individual models are fair. The system can be decomposed into retrieval, scoring, and serving layers, each contributing additively to user utility.

### Mechanism 2
Preference heterogeneity across demographic groups can cause global utility optimization to favor majority groups. When true user preferences α*(g) differ across groups, a single global weight vector α will inevitably misalign with minority group preferences, creating systematic utility gaps. User preferences are heterogeneous across groups but individual models are calibrated across all feature space.

### Mechanism 3
Retrieval model quality bottleneck can propagate fairness gaps downstream even if scoring and serving are optimized. If the retrieval model under-samples high-quality items for a particular group, no amount of optimal scoring or serving can recover the lost utility for that group. Retrieval model quality is defined by expected maximum γ-good item retrievable, and retrieval is separate from downstream optimization.

## Foundational Learning

- Concept: Gaussian Process (GP) modeling of black-box objectives
  - Why needed here: Bayesian Optimization treats the utility-DER objective as a black-box function, requiring flexible surrogate models like GPs
  - Quick check question: What is the role of the kernel function in a GP, and how does it affect the smoothness of the surrogate model?

- Concept: Multi-objective optimization and Pareto frontiers
  - Why needed here: The system-level fairness problem is framed as balancing utility and DER simultaneously, requiring identification of Pareto-optimal solutions
  - Quick check question: Why is the hypervolume indicator used in Expected Hypervolume Improvement (EHVI), and what does it measure?

- Concept: Distribution shift and shared feature space
  - Why needed here: The fairness analysis conditions on a "shared space" where both demographic groups are present, requiring understanding of how distributions shift across groups
  - Quick check question: How does the SX measure in Equation (3) ensure that comparisons are made over co-observed features across groups?

## Architecture Onboarding

- Component map:
  Retrieval layer -> Scoring layer -> Serving layer -> Utility evaluation -> Optimization layer

- Critical path:
  1. Batch of users enters system
  2. Retrieval selects m items per user
  3. Scoring models fk generate predictions
  4. Serving layer applies weights α to produce ranked list
  5. Top item selected and utility computed based on true outcomes
  6. BO updates GP surrogate models and suggests new α

- Design tradeoffs:
  - Global vs. personalized weights: Personalization avoids majority bias but raises disparate treatment concerns
  - Model complexity vs. interpretability: Weighted sum is simple but may not capture complex user preferences
  - Online vs. offline optimization: BO requires online feedback but can adapt to changing user behavior

- Failure signatures:
  - If DER does not improve despite BO iterations, the surrogate model may be poorly calibrated or the objective landscape may be flat
  - If utility drops sharply when prioritizing fairness, the DER-utility tradeoff may be too steep in the current design space
  - If one group consistently receives low utility, the retrieval model may be undersampling quality items for that group

- First 3 experiments:
  1. Run BO with random search baseline on synthetic data to verify DER improvement and utility preservation
  2. Test EHVI vs. constrained EI variants to compare fairness-utility tradeoffs on Movielens dataset
  3. Simulate retrieval failure by undersampling items for one group and observe downstream utility degradation

## Open Questions the Paper Calls Out

### Open Question 1
How do fairness interventions at the system level impact long-term user retention and engagement beyond single-session utility? The paper acknowledges that realistic user behavior involves multiple interactions, where high utility in one session begets further usage and low utility begets drop-off, but does not explicitly model this temporal dimension.

### Open Question 2
How does the framework generalize to handle fairness between viewer-side and candidate-side in recommendation systems? The paper focuses on viewer-side fairness and acknowledges the analogous problem for systems that rank candidates, suggesting this as a direction for future research.

### Open Question 3
What are the implications of relaxing the assumption that user features X are rich enough to make {Y^k_j | X} invariant across demographic groups? The paper assumes that user features X are rich enough to make {Y^k_j | X} invariant across demographic groups, but acknowledges this as a limitation and suggests this as a topic for future study.

## Limitations
- Focuses on global weight vectors rather than personalized recommendations, which may be suboptimal for heterogeneous user preferences
- Theoretical analysis assumes additive utility across components, which may not hold in all real-world systems
- DER metric may not capture all aspects of fairness in multi-stakeholder recommendation scenarios

## Confidence
- System-level fairness formulation: High
- DER metric effectiveness: Medium
- Bayesian Optimization implementation: High

## Next Checks
1. Test the approach on a live production system to validate real-world performance and identify potential deployment challenges
2. Compare DER with alternative fairness metrics (e.g., statistical parity, equal opportunity) to assess robustness across different fairness definitions
3. Evaluate the sensitivity of results to different kernel choices in the Gaussian Process surrogate model to ensure findings are not artifact of specific hyperparameters