---
ver: rpa2
title: 'Agentic-HLS: An agentic reasoning based high-level synthesis system using
  large language models (AI for EDA workshop 2024)'
arxiv_id: '2412.01604'
source_url: https://arxiv.org/abs/2412.01604
tags:
- design
- reasoning
- harp
- language
- utilization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors addressed the challenge of predicting HLS design performance
  metrics (validity, latency, BRAM, LUT, FF, and DSP utilization) in FPGA synthesis
  by integrating large language models with graph neural networks. Their core method
  combined fine-tuned HARP graph embeddings with GPT-4o's reasoning capabilities through
  an iterative agentic evaluation framework.
---

# Agentic-HLS: An agentic reasoning based high-level synthesis system using large language models (AI for EDA workshop 2024)

## Quick Facts
- arXiv ID: 2412.01604
- Source URL: https://arxiv.org/abs/2412.01604
- Reference count: 8
- One-line primary result: Agentic-HLS achieved a RMSE score of 4.21, outperforming fine-tuned HARP alone (2.82) and GPT-4o with HARP (6.60) for HLS design performance prediction.

## Executive Summary
This paper presents Agentic-HLS, an innovative approach to predicting HLS design performance metrics by integrating large language models with graph neural networks. The system combines fine-tuned HARP graph embeddings with GPT-4o's reasoning capabilities through an iterative agentic evaluation framework that includes source code analysis, pragma impact reasoning, and self-reflective prediction refinement. The method demonstrates superior prediction accuracy compared to traditional approaches, achieving a RMSE score of 4.21 across six key performance metrics.

## Method Summary
Agentic-HLS combines fine-tuned HARP graph neural network embeddings with GPT-4o's reasoning capabilities through an iterative agentic evaluation framework. The system generates graph embeddings that capture program structure and pragma transformations, then uses GPT-4o to analyze source code, reason about pragma impacts, and iteratively refine predictions through three cycles of self-reflection and criticizer feedback. The approach employs Chain-of-Thought prompting to enable multi-step reasoning, with the predictor agent generating initial predictions and the criticizer agent providing feedback for refinement.

## Key Results
- Achieved RMSE score of 4.21 for HLS performance prediction
- Outperformed fine-tuned HARP alone (RMSE 2.82) and GPT-4o with HARP (RMSE 6.60)
- Demonstrated effective integration of structured graph embeddings with LLM reasoning capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The iterative agentic evaluation process with self-reflection and criticizer feedback improves prediction reliability through three cycles of refinement.
- Mechanism: The predictor agent generates initial predictions based on graph embeddings and source code analysis, then the criticizer agent evaluates these predictions against training data, providing feedback that enables the predictor to refine its analysis in subsequent iterations.
- Core assumption: The training data contains sufficient representative samples to enable meaningful self-correction through comparison.
- Evidence anchors:
  - [section] "An iterative evaluation process is employed, wherein the predictor agent performs self-reflection based on available training data batches. This process runs for three cycles due to its computational expense but is crucial for enabling the predictor to rationalize its performance predictions."
  - [section] "The predictor-agent iteratively refines its analysis by providing justifications for specific optimizations and then reflecting on feedback from the criticiser agent, enhancing overall prediction reliability."
- Break condition: The iterative process breaks down when training data is insufficient or unrepresentative, preventing meaningful self-correction.

### Mechanism 2
- Claim: The integration of HARP graph embeddings with GPT-4o's reasoning capabilities provides superior prediction accuracy compared to either approach alone.
- Mechanism: HARP generates structured graph embeddings that capture program structure and pragma transformations, while GPT-4o applies chain-of-thought reasoning to interpret these embeddings in the context of source code analysis, combining structural and semantic understanding.
- Core assumption: The hierarchical graph representation from HARP contains sufficient information about critical paths and pragma impacts for accurate prediction.
- Evidence anchors:
  - [section] "We utilized the HARP encoder to create comprehensive graph embeddings that encapsulate critical design features. The graph embeddings provide a representation from which reasoning about the critical path and latency measurements can be derived."
  - [section] "Graph embeddings carry specific control/data flow information that enables the LLM to attend to node-edge relationships and enhances their overall reasoning."
- Break condition: The mechanism fails when the graph embeddings miss critical information or when GPT-4o cannot effectively interpret the structural data.

### Mechanism 3
- Claim: Chain-of-thought prompting significantly improves reasoning quality for large models but shows diminishing returns for smaller models below 100B parameters.
- Mechanism: Larger language models can perform multi-step reasoning when prompted with chain-of-thought techniques, enabling them to break down complex prediction tasks into manageable subtasks and justify their decisions.
- Core assumption: Model size correlates with reasoning capability, and the benefits of CoT prompting scale with model capacity.
- Evidence anchors:
  - [section] "We plan to use models such LLAMA3 to conduct this experiment however we were short of tie. Tat why we chose GPT4o. With emerge of larger models, we predict that agents will become more effective in reasoning and predicting design performances."
  - [section] "Limitation of CoT prompting: The technique is less effective with smaller models. To achieve meaningful gains, it's best to apply CoT in proportion to the model's size, as smaller models (less than 100B parameter) may produce less coherent reasoning with CoT prompting."
- Break condition: The mechanism fails when using models with insufficient parameter counts, where CoT prompting cannot elicit meaningful reasoning.

## Foundational Learning

- Concept: High-Level Synthesis (HLS) fundamentals and pragma impact on FPGA design
  - Why needed here: Understanding how HLS transforms C/C++ code into hardware and how pragmas affect resource utilization and latency is essential for interpreting the problem domain and evaluation metrics.
  - Quick check question: How do different pragma directives like PARALLEL, PIPE, and TILE affect FPGA resource utilization and latency in HLS?

- Concept: Graph Neural Networks (GNNs) and hierarchical graph representations
  - Why needed here: HARP uses GNNs to create hierarchical graph embeddings that capture program structure and pragma transformations, which form the foundation for the prediction model.
  - Quick check question: What advantages do hierarchical graph representations offer over flat representations for modeling HLS designs?

- Concept: Chain-of-Thought (CoT) prompting and agentic reasoning
  - Why needed here: The methodology relies on LLMs performing multi-step reasoning through CoT prompting and iterative self-reflection to improve prediction accuracy.
  - Quick check question: How does chain-of-thought prompting enable large language models to perform complex reasoning tasks compared to direct prompting?

## Architecture Onboarding

- Component map: HARP encoder -> GPT-4o source code analysis -> Pragma impact reasoning -> Predictor agent -> Criticizer agent -> Refined predictor (3 cycles)
- Critical path: Graph embedding generation → Source code analysis → Pragma impact reasoning → Initial prediction → Iterative evaluation (3 cycles) → Final prediction
- Design tradeoffs: The system trades computational expense for improved accuracy through three iterative cycles, while balancing between the structured approach of HARP and the flexible reasoning of GPT-4o.
- Failure signatures: Poor predictions occur when training data is insufficient, when HARP embeddings miss critical information, or when GPT-4o cannot effectively interpret the graph structures; classification accuracy particularly affects overall RMSE scores.
- First 3 experiments:
  1. Test HARP graph embedding generation on a simple HLS design to verify the hierarchical structure captures pragma impacts correctly
  2. Evaluate GPT-4o's source code analysis capability on basic C/C++ kernels to ensure it can identify control flow and loops accurately
  3. Run the full iterative evaluation process on a small dataset to observe the improvement from predictor→criticizer→refined predictor cycles

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Agentic-HLS scale with the number of reasoning iterations, and is there a point of diminishing returns?
- Basis in paper: [explicit] The paper mentions an iterative evaluation process that runs for three cycles due to computational expense, but doesn't explore whether more or fewer iterations would be optimal
- Why unresolved: The paper only tested 3 iterations without exploring the trade-off between computational cost and prediction accuracy
- What evidence would resolve it: Experiments testing Agentic-HLS with 1, 2, 3, 5, and 10 reasoning iterations, measuring both prediction accuracy (RMSE) and computational cost for each

### Open Question 2
- Question: How does Agentic-HLS perform on HLS design datasets from different application domains or with different characteristics than the contest dataset?
- Basis in paper: [inferred] The paper only reports results on the specific contest dataset without testing generalization to other HLS benchmarks or application domains
- Why unresolved: The evaluation is limited to a single dataset, making it unclear whether the approach generalizes to other HLS scenarios
- What evidence would resolve it: Testing Agentic-HLS on multiple HLS benchmark suites from different domains (signal processing, cryptography, scientific computing) and measuring performance consistency

### Open Question 3
- Question: What is the contribution of each individual component (HARP embeddings, source code analysis, agentic evaluation) to the overall performance improvement?
- Basis in paper: [inferred] The paper presents a combined system but doesn't perform ablation studies to isolate the contribution of each component to the final RMSE score
- Why unresolved: Without component-level analysis, it's unclear which aspects of the system are most critical for performance gains
- What evidence would resolve it: Ablation experiments testing variants with: only HARP, only source code analysis, only agentic evaluation, and various combinations, with corresponding RMSE measurements

### Open Question 4
- Question: How does the performance of Agentic-HLS change when using smaller language models versus the 100+ billion parameter models?
- Basis in paper: [explicit] The paper states that "CoT prompting is less effective with smaller models" and mentions using GPT-4o specifically, but doesn't test the performance trade-off systematically
- Why unresolved: The paper only tests with GPT-4o without comparing to smaller models or exploring the relationship between model size and prediction accuracy
- What evidence would resolve it: Comparative experiments using different sized language models (e.g., GPT-4o, LLaMA2 70B, LLaMA3 8B) with the same Agentic-HLS framework, measuring RMSE for each

## Limitations

- The paper lacks complete implementation details including specific HARP fine-tuning configurations and GPT-4o prompt templates
- Statistical significance of the RMSE improvements over baseline methods is not established
- The approach's performance on HLS datasets from different application domains or with different characteristics is unknown

## Confidence

- **High confidence**: The core mechanism of combining HARP embeddings with GPT-4o reasoning is well-supported by the described methodology and evidence anchors.
- **Medium confidence**: The iterative agentic evaluation process and its three-cycle refinement structure appears sound, though the computational expense tradeoff is noted.
- **Medium confidence**: The claimed RMSE improvement over baseline methods, while reported, lacks statistical validation details.

## Next Checks

1. Replicate the HARP graph embedding generation on a small benchmark HLS design to verify pragma impact capture accuracy.
2. Implement and test the GPT-4o source code analysis module on basic C++ kernels to validate control flow identification.
3. Conduct ablation studies comparing RMSE scores with different numbers of iterative refinement cycles (1, 2, and 3) to quantify the benefit of the agentic evaluation process.