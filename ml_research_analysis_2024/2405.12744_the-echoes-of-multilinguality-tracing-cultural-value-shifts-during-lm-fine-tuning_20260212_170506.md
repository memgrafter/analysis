---
ver: rpa2
title: 'The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM Fine-tuning'
arxiv_id: '2405.12744'
source_url: https://arxiv.org/abs/2405.12744
tags:
- language
- fine-tuning
- cultural
- languages
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how multilingual language models encode
  and revise cultural values during fine-tuning across different languages and data
  sources. Using cloze-style prompts derived from the World Values Survey, the authors
  probe for cultural values in mT5 models fine-tuned on multi-parallel data from Wikipedia,
  religious texts, and news sources in four fine-tuning languages across 13 test languages.
---

# The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM Fine-tuning

## Quick Facts
- **arXiv ID**: 2405.12744
- **Source URL**: https://arxiv.org/abs/2405.12744
- **Reference count**: 40
- **Primary result**: Fine-tuning language and domain source have minor impact on cultural value shifts compared to fine-tuning data size, though multilingual fine-tuning better preserves cultural similarities between languages

## Executive Summary
This study investigates how multilingual language models encode and revise cultural values during fine-tuning across different languages and data sources. Using cloze-style prompts derived from the World Values Survey, the authors probe for cultural values in mT5 models fine-tuned on multi-parallel data from Wikipedia, religious texts, and news sources in four fine-tuning languages across 13 test languages. Results show that fine-tuning language and domain source have a minor role in value shifts compared to fine-tuning data size, though they can steer cultural profiles in different directions. Multilingual fine-tuning better preserves cultural similarities between languages. Training data attribution reveals that the semantic content of fine-tuning data may not be the main driver of value shifts, with the model instead relying on language-specific training examples. Overall, results indicate complex cross-language cultural interactions and suggest language-specific adaptation approaches are needed for value alignment.

## Method Summary
The study uses mT5 models (small, base, large) fine-tuned on multi-parallel data from Wikipedia (Flores-101), religious texts (Bible, Quran), and news articles. Four fine-tuning languages (Farsi, Korean, Hindi, Russian) are used with 13 test languages. The World Values Survey questions serve as cloze-style prompts to probe cultural values. Models are fine-tuned using both monolingual (separate per language) and multilingual (joint training) strategies with 2K or 10K sentences. Training data attribution analysis is performed using TRAK to trace value shifts back to specific training examples.

## Key Results
- Fine-tuning data size has a larger impact on cultural value shifts than fine-tuning language or domain source
- Multilingual fine-tuning better preserves cultural similarities between test languages compared to monolingual fine-tuning
- The semantic content of fine-tuning data may not be the main driver of value shifts; the model tends to rely on language-specific training examples
- Fine-tuning language and domain source can steer cultural profiles in different directions, though their overall impact is minor

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Cross-lingual sharing during multilingual fine-tuning better preserves cultural similarities between test languages.
- **Mechanism:** Multilingual fine-tuning jointly exposes the model to multiple fine-tuning languages, allowing it to retain distinct cultural profiles for each language rather than biasing all towards a single direction.
- **Core assumption:** Cultural information is separately encoded per language in the model and can be preserved when exposed to multiple languages simultaneously.
- **Evidence anchors:**
  - [abstract]: "Multilingual fine-tuning better preserves cultural similarities between languages."
  - [section]: "We suspect that the results for multilingual fine-tuning are similar because the fine-tuning languages in any case tend to behave similarly. Thus, when using them interchangeably it has a limited further effect on the predictions."
  - [corpus]: Weak/no direct evidence for this mechanism in the corpus.

### Mechanism 2
- **Claim:** The semantic content of fine-tuning data might not be the main reason for value shifts; the model tends to rely on language-specific training examples.
- **Mechanism:** The model relies on parallel training examples within each fine-tuning language, rather than the actual semantic content, to instigate value shifts across test languages.
- **Core assumption:** The model's value shifts are more influenced by the structure and language of the training data rather than the specific cultural content.
- **Evidence anchors:**
  - [abstract]: "Yet, when looking at the values that shift across test languages given the same fine-tuning language, we observe more consistency."
  - [section]: "We find that from the most influential examples in each fine-tuning language that instigate the same value shift, only < 5% are parallel sentences."
  - [corpus]: Weak/no direct evidence for this mechanism in the corpus.

### Mechanism 3
- **Claim:** Fine-tuning language and domain source play a minor, but visible, role in the amount of value shifts compared to the size of the fine-tuning dataset.
- **Mechanism:** Increasing the amount of fine-tuning data has a larger impact on value shifts than the specific fine-tuning language or domain source used.
- **Core assumption:** The model's cultural values are more influenced by the quantity of fine-tuning data than the specific linguistic or domain characteristics.
- **Evidence anchors:**
  - [abstract]: "Results show that fine-tuning language and domain source have a minor role in value shifts compared to fine-tuning data size."
  - [section]: "A natural follow up question is whether language or domain bias becomes more prevalent when using a larger corpus during fine-tuning. We find that increasing our training size from 2K to 10K samples does tend to further increase the amount of value shifts."
  - [corpus]: Weak/no direct evidence for this mechanism in the corpus.

## Foundational Learning

- **Concept:** Cultural values are descriptive ethics, not prescriptive.
  - **Why needed here:** Understanding that the study focuses on how values are actually encoded, not how they should be, is crucial for interpreting the results.
  - **Quick check question:** Are the cultural values studied in this paper based on how people actually behave or how they should behave according to some standard?

- **Concept:** Cross-lingual sharing in multilingual models.
  - **Why needed here:** Understanding how information is shared across languages in multilingual models is key to interpreting the results on cultural value shifts.
  - **Quick check question:** In a multilingual model, are cultural values encoded separately for each language or are they shared across languages?

- **Concept:** Training data attribution methods.
  - **Why needed here:** Understanding how to trace model predictions back to specific training examples is crucial for interpreting the results on which training examples influence value shifts.
  - **Quick check question:** What is the purpose of training data attribution methods in the context of this study?

## Architecture Onboarding

- **Component map:** mT5 model -> Fine-tuning (Flores-101, PBC, Tanzil, news) -> Probing (WVS questions) -> Analysis (correlation, TDA)
- **Critical path:** Fine-tune mT5 models on multi-parallel data -> Probe for cultural values using WVS questions -> Analyze shifts in cultural profiles and alignment to human values
- **Design tradeoffs:** Using multi-parallel data allows for controlled experiments but limits the choice of fine-tuning languages and domain sources. Using cloze-style questions derived from surveys allows for quantitative analysis but may not capture all nuances of cultural values.
- **Failure signatures:** If the fine-tuning languages are too culturally similar, multilingual fine-tuning may not preserve distinct cultural profiles. If the fine-tuning data is extremely biased or unrepresentative, the specific language or domain may have a larger impact than expected.
- **First 3 experiments:**
  1. Fine-tune mT5-small on 2K sentences from Flores-101 in Farsi and test on German, analyzing the shifts in cultural profiles.
  2. Fine-tune mT5-small on 10K sentences from PBC in Korean and test on Indonesian, analyzing the alignment to human values.
  3. Use TRAK to trace the top 100 most influential training examples for value shifts when fine-tuning mT5-small on Tanzil in Hindi and testing on Vietnamese.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the semantic contents of fine-tuning data drive value shifts, or do language-specific training examples play a larger role?
- Basis in paper: [explicit] The paper states: "This suggests that the semantic content of fine-tuning data might not be the main reason for the shifts. Instead, the model tends to rely on the same training examples within a fine-tuning language, and these examples have different effects on the manifestation of cultural values across test languages."
- Why unresolved: While the paper shows that the semantic content of fine-tuning data might not be the main reason for value shifts, it does not definitively conclude whether the language-specific training examples play a larger role. Further investigation is needed to determine the exact influence of each factor.
- What evidence would resolve it: A detailed analysis comparing the influence of semantic content versus language-specific examples on value shifts would provide clarity. This could involve controlled experiments where the semantic content is held constant while varying the language, and vice versa.

### Open Question 2
- Question: How do cultural value shifts during fine-tuning affect the alignment of multilingual language models (MLMs) to human values across different languages?
- Basis in paper: [explicit] The paper notes: "We now test whether the changes we observed led the model to be steered into a direction that is better aligned to real human values."
- Why unresolved: While the paper explores the alignment of MLMs to human values, it does not provide a comprehensive analysis of how cultural value shifts during fine-tuning affect this alignment across different languages. Further research is needed to understand the nuances of this relationship.
- What evidence would resolve it: A comparative study of MLM alignment to human values before and after fine-tuning across multiple languages would shed light on the impact of cultural value shifts. This could involve evaluating the models on a diverse set of human value datasets in different languages.

### Open Question 3
- Question: What is the impact of multilingual fine-tuning on preserving cultural similarities between languages within a model?
- Basis in paper: [explicit] The paper states: "Interestingly, multilingual fine-tuning results in the highest correlation with human data."
- Why unresolved: While the paper highlights the positive impact of multilingual fine-tuning on cultural similarity, it does not provide a detailed analysis of the extent to which this preservation occurs. Further investigation is needed to understand the nuances of cultural similarity preservation in multilingual models.
- What evidence would resolve it: A comprehensive analysis comparing the cultural similarity preservation in monolingual versus multilingual fine-tuning would provide insights into the impact of multilingual training. This could involve evaluating the models on cross-cultural similarity tasks and analyzing the preservation of cultural profiles across languages.

## Limitations

- The fine-tuning languages (Farsi, Korean, Hindi, Russian) may be too culturally similar to properly test whether cross-lingual sharing can maintain distinct cultural profiles
- The reliance on TRAK for training data attribution introduces uncertainty, as the method's reliability for this specific task hasn't been thoroughly validated
- The finding that semantic content plays a minimal role is based on only 1.3% of influential examples being parallel sentences, which may not capture the full complexity

## Confidence

**High Confidence:** The finding that fine-tuning data size has a stronger impact on value shifts than fine-tuning language or domain source. This conclusion is well-supported by the experimental results showing clear differences between 2K and 10K fine-tuning samples.

**Medium Confidence:** The claim that multilingual fine-tuning better preserves cultural similarities between test languages. While the data shows this pattern, the underlying mechanism is not fully explained, and the cultural similarity of fine-tuning languages limits the strength of this conclusion.

**Low Confidence:** The assertion that semantic content of fine-tuning data is not the main driver of value shifts. This conclusion is based on limited training data attribution analysis and requires more robust validation.

## Next Checks

1. **Cross-cultural similarity analysis**: Conduct a systematic analysis of cultural distance between the fine-tuning languages using external cultural dimension metrics to determine whether they are indeed sufficiently diverse to test the cross-lingual sharing hypothesis.

2. **Parallel content verification**: Manually examine a larger sample of the top 100 influential training examples identified by TRAK to verify whether parallel content is indeed underrepresented and to better understand what types of content drive value shifts.

3. **Alternative attribution methods**: Replicate the training data attribution analysis using simpler influence methods as a sanity check, given concerns about TRAK's reliability for this specific task.