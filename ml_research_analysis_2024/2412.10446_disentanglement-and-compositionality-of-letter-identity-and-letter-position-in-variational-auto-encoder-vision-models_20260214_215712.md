---
ver: rpa2
title: Disentanglement and Compositionality of Letter Identity and Letter Position
  in Variational Auto-Encoder Vision Models
arxiv_id: '2412.10446'
source_url: https://arxiv.org/abs/2412.10446
tags:
- letter
- neural
- words
- comporth
- position
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether modern deep neural models can disentangle
  letter identity and position when processing images of written words, a key ability
  for human-like compositional generalization. The authors created CompOrth, a benchmark
  designed to test generalization to unseen combinations of letter identities and
  positions, as well as unseen word lengths and retinal locations.
---

# Disentanglement and Compositionality of Letter Identity and Letter Position in Variational Auto-Encoder Vision Models

## Quick Facts
- arXiv ID: 2412.10446
- Source URL: https://arxiv.org/abs/2412.10446
- Reference count: 15
- Key outcome: β-VAE models fail to disentangle letter identity and position, showing poor compositional generalization to unseen word lengths and novel letter-position combinations on the CompOrth benchmark

## Executive Summary
This study investigates whether modern deep neural models can disentangle letter identity and position when processing images of written words - a key ability for human-like compositional generalization. The authors created CompOrth, a benchmark designed to test generalization to unseen combinations of letter identities and positions, as well as unseen word lengths and retinal locations. They trained β-VAE models on images of letter strings and evaluated their performance using CompOrth. While the models successfully disentangled surface features like retinal position, they dramatically failed to disentangle letter identity and position, showing poor generalization to unseen word lengths and novel letter-position combinations. Neural perturbation analyses revealed no strong neural disentanglement of these features in the models. The study highlights the limitations of current β-VAE models in achieving human-like compositional abilities and proposes CompOrth as a challenging benchmark for future models.

## Method Summary
The authors created CompOrth, a synthetic benchmark consisting of images of letter strings varying in word length (1-5 letters), retinal position (horizontal/vertical shifts), and letter identity (A/B only). They trained β-VAE models with 4 convolutional layers + 2 fully connected encoder and mirrored decoder architecture, optimizing hyperparameters (β parameter, latent size, learning rate) using nested cross-validation. Models were evaluated on reconstruction accuracy (using a separate CNN evaluator), reconstruction loss, and Mutual Information Ratio (MIR) for neural disentanglement. The study tested generalization through three CompOrth tests: Spatial (horizontal/vertical shifts), Length (word length generalization), and Compositional Generalization (unseen letter-position combinations).

## Key Results
- β-VAE models successfully disentangle surface spatial features like retinal position but fail to disentangle letter identity and position
- Models show poor compositional generalization to unseen word lengths and novel letter-position combinations
- Neural perturbation analyses reveal no strong neural disentanglement of letter identity and position in the models
- The models demonstrate limited ability to learn compositional rules, instead relying on memorization of training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: β-VAE models successfully disentangle surface features like retinal position but fail to disentangle letter identity and position.
- Mechanism: The models learn to represent spatial features (horizontal and vertical word displacement) independently from the letter content, but lack the ability to encode letter identity and position as separate, composable features.
- Core assumption: Neural disentanglement of features is necessary for compositional generalization to unseen letter-position combinations.
- Evidence anchors:
  - [abstract] "While the models successfully disentangled surface features like retinal position, they dramatically failed to disentangle letter identity and position"
  - [section] "β-V AEs can be optimized to achieve neural disentanglement, which encourages the activity of single units in the latent layer to encode different generative factors of the training data, such as letter identity and letter position"
  - [corpus] Weak evidence - no corpus neighbors directly address this specific disentanglement failure in β-VAEs
- Break condition: If models achieve neural disentanglement of identity and position (e.g., through alternative architectures or training objectives), they should pass the Compositional Generalization test in CompOrth.

### Mechanism 2
- Claim: Poor compositional generalization in β-VAEs is due to limited neural disentanglement of letter identity and position.
- Mechanism: When letter identity and position are not neurally disentangled, the model cannot compose them flexibly for unseen combinations, leading to memorization-based failures rather than rule-based generalization.
- Core assumption: Neural disentanglement is a prerequisite for compositional generalization.
- Evidence anchors:
  - [abstract] "They dramatically fail to disentangle letter position and letter identity and lack any notion of word length"
  - [section] "We found that β-V AEs learn to disentangle surface properties of written words, such as 'retinal' horizontal and vertical position. However, beta-V AEs dramatically fail to disentangle identity and positional information of letters"
  - [corpus] Weak evidence - corpus contains related work on compositionality but not specific to β-VAE failure modes
- Break condition: If a model achieves compositional generalization without strong neural disentanglement, this mechanism would be falsified.

### Mechanism 3
- Claim: The information bottleneck in β-VAEs creates a tradeoff between reconstruction accuracy and compositionality.
- Mechanism: Excessive constraint of the bottleneck can compromise reconstruction performance and prevent learning of compositional rules, while insufficient constraint leads to memorization of training data.
- Core assumption: There exists an optimal information bottleneck strength that balances reconstruction and compositionality.
- Evidence anchors:
  - [section] "Theoretically, the information bottleneck principle in auto-encoders could encourage models to learn underlying patterns in the data by forming abstract representations and relying on rule-based encoding rather than memorization. However, there's a trade-off with reconstruction accuracy"
  - [section] "We first optimized for the hyperparameters of theβ-V AE models, using nested cross-validation"
  - [corpus] Weak evidence - no corpus neighbors directly address this specific information bottleneck tradeoff in β-VAEs
- Break condition: If models achieve both high reconstruction accuracy and compositionality with the same information bottleneck settings, this mechanism would be falsified.

## Foundational Learning

- Concept: Variational Autoencoders and β-VAE extension
  - Why needed here: Understanding the core architecture and how β-VAE modifies the standard VAE to encourage disentanglement
  - Quick check question: What is the key difference between VAE and β-VAE in terms of the objective function?

- Concept: Neural disentanglement metrics (MIG and MIR)
  - Why needed here: Evaluating whether models achieve the required disentanglement for compositional generalization
  - Quick check question: How does MIR differ from MIG in terms of what it measures about neural disentanglement?

- Concept: Compositional generalization and its importance for human-like language processing
  - Why needed here: Understanding why the failure to disentangle letter identity and position is a critical limitation
  - Quick check question: Why is the ability to generalize to unseen letter-position combinations considered a hallmark of human language processing?

## Architecture Onboarding

- Component map:
  Input layer (28x28 grayscale images) -> 4 convolutional layers -> 2 fully connected layers -> Latent layer -> 2 fully connected layers -> 4 convolutional layers -> Output layer

- Critical path:
  1. Generate synthetic word images with controlled variations
  2. Train β-VAE on training splits
  3. Evaluate reconstruction loss and MIR
  4. Test generalization using CompOrth benchmark
  5. Analyze failure modes through perturbation experiments

- Design tradeoffs:
  - Latent layer size vs. reconstruction accuracy: Larger layers improve reconstruction but may reduce disentanglement
  - β parameter vs. compositionality: Higher β encourages disentanglement but may harm reconstruction
  - Synthetic vs. real data: Synthetic data provides control but may miss real-world complexities

- Failure signatures:
  - High reconstruction accuracy but poor compositional generalization
  - Successful disentanglement of spatial features but failure on letter identity/position
  - "Hallucination" of letters in positions where they were not present during training

- First 3 experiments:
  1. Vary β parameter systematically (0.1, 1, 10, 100) to find optimal tradeoff between reconstruction and disentanglement
  2. Test different latent layer sizes (16, 32, 64, 128) to find optimal capacity
  3. Implement alternative disentanglement methods (e.g., FactorVAE, DIP-VAE) to compare with β-VAE performance

## Open Questions the Paper Calls Out
The paper suggests several directions for future research, including exploring whether other disentanglement architectures (such as adversarial autoencoders or information bottleneck methods) could achieve better compositional generalization than β-VAEs on CompOrth. The authors also note the need to investigate what specific neural mechanisms in human readers enable robust disentanglement of letter identity and position, and whether these can be reverse-engineered for neural network models. Additionally, they propose examining whether different training data structures or curricula could enable neural models to learn compositional generalization for letter identity and position.

## Limitations
- Findings are based on synthetic data with only two letters (A and B) and simplified font variations, limiting generalizability to naturalistic writing systems
- Only β-VAE models were tested without exploring alternative disentanglement approaches like FactorVAE or DIP-VAE
- Lack of neural recordings or behavioral data from human subjects prevents direct comparison between model and human performance

## Confidence
- **High confidence**: Models successfully disentangle surface spatial features while failing to disentangle letter identity and position
- **Medium confidence**: Poor compositional generalization stems specifically from lack of neural disentanglement
- **Low confidence**: The information bottleneck tradeoff between reconstruction accuracy and compositionality

## Next Checks
1. Test alternative disentanglement architectures (FactorVAE, DIP-VAE) on the same CompOrth benchmark to determine whether compositional generalization failure is specific to β-VAE
2. Scale up to naturalistic data with larger character sets (26 letters) and variable fonts to evaluate whether observed patterns hold
3. Conduct behavioral experiments with human subjects on the same CompOrth tasks to establish whether model failure patterns mirror human limitations