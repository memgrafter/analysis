---
ver: rpa2
title: 'PQ-GCN: Enhancing Text Graph Question Classification with Phrase Features'
arxiv_id: '2409.02481'
source_url: https://arxiv.org/abs/2409.02481
tags:
- graph
- question
- classification
- text
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PQ-GCN improves question classification by incorporating phrase-based
  features into a graph convolutional network. The method extracts word-level, phrase-level,
  and entity-level features from questions and constructs multiple feature graphs.
---

# PQ-GCN: Enhancing Text Graph Question Classification with Phrase Features

## Quick Facts
- arXiv ID: 2409.02481
- Source URL: https://arxiv.org/abs/2409.02481
- Reference count: 40
- Primary result: Phrase-based GCN achieves 0.724, 0.712, 0.751 macro-F1 on three question classification datasets

## Executive Summary
PQ-GCN introduces a graph convolutional network architecture that incorporates phrase-level features alongside word and entity features for improved question classification. The method constructs multiple feature graphs (word PMI, POS, phrases, phrase POS, and entities) and processes each through individual GCNs before combining them for final classification. The approach demonstrates competitive performance with BERT while using significantly fewer parameters, particularly excelling in low-resource settings where labeled data is limited.

## Method Summary
PQ-GCN extracts word-level, phrase-level, and entity-level features from questions, constructing multiple feature graphs that are processed through individual GCNs. Phrase features are obtained via POS regex patterns and embedded using PhraseBERT, then combined with word and entity embeddings in separate graphs. Each graph type (word PMI, word POS, phrase PMI, phrase POS, named entities) is processed by its own 2-layer GCN, with outputs concatenated and passed through a final GCN and linear layer for classification. The method achieves strong performance across three datasets while maintaining parameter efficiency compared to transformer-based approaches.

## Key Results
- Achieves macro-averaged F1 scores of 0.724, 0.712, and 0.751 on NU, ARC, and LREC datasets respectively
- Outperforms baseline graph-based methods in low-resource settings
- Matches BERT's performance with significantly fewer parameters (approximately 1.7M vs 109M)

## Why This Works (Mechanism)

### Mechanism 1
Phrase features capture contextual chunks that single words miss, improving classification accuracy. Noun and verb phrases are extracted using POS regex patterns, then embedded via PhraseBERT. These phrase-level embeddings are added to the graph alongside word-level features, allowing GCNs to learn from richer semantic units.

### Mechanism 2
Multi-graph construction preserves distinct linguistic relationships and prevents feature dilution. Separate graphs are built for word PMI, POS tags, phrases, phrase POS tags, and named entities. Each graph is processed by its own GCN, then outputs are concatenated before a final classification layer.

### Mechanism 3
Phrase features improve performance in low-resource settings by reducing reliance on large labeled datasets. Phrase-based semantic units provide additional context that compensates for limited training examples, allowing the model to generalize better.

## Foundational Learning

- Concept: Graph Convolutional Networks (GCNs)
  - Why needed here: GCNs naturally model relationships between text features (words, phrases, entities) as nodes in a graph, enabling structure-aware classification.
  - Quick check question: What operation does a GCN layer perform on a node's features using its neighbors?

- Concept: Phrase extraction with POS tagging
  - Why needed here: Extracting noun and verb phrases provides semantically richer units than individual words, improving feature representation.
  - Quick check question: How do POS regex patterns identify noun phrases in spaCy?

- Concept: Embedding concatenation for multi-modal features
  - Why needed here: Combining embeddings from different linguistic levels (word, phrase, entity) enriches the final representation before classification.
  - Quick check question: Why concatenate rather than average embeddings from different feature graphs?

## Architecture Onboarding

- Component map: Text preprocessing → Tokenization & phrase extraction → Graph construction (5 graphs) → 5 individual GCNs → Concatenation → Final GCN + Linear layer → Classification
- Critical path: Graph construction → Individual GCN propagation → Feature concatenation → Final GCN → Classification
- Design tradeoffs:
  - Multi-graph approach increases parameter count but preserves feature specificity
  - Using pre-trained PhraseBERT avoids training phrase embeddings but adds dependency
  - Concatenation vs. attention for combining GCN outputs: concatenation is simpler but may not weigh features optimally
- Failure signatures:
  - Low performance across all datasets → Check graph construction and embedding quality
  - Good on one dataset, poor on others → Investigate dataset-specific phrase extraction or class imbalance
  - Overfitting on small datasets → Reduce GCN depth or apply stronger dropout
- First 3 experiments:
  1. Train with only word PMI graph vs. full multi-graph to measure feature contribution
  2. Remove phrase features to confirm their impact in low-resource settings
  3. Swap PhraseBERT with static embeddings to test phrase embedding quality

## Open Questions the Paper Calls Out

### Open Question 1
How do phrase-based features perform across languages with different syntactic structures, particularly non-configurational languages with free word order? The paper notes that applying the proposed method to other languages would require adapting feature extraction methods to syntactic rules of the target language, and that extracting regex-based noun or verb phrases may be challenging for non-configurational languages with free word order.

### Open Question 2
How would incorporating phrase-based features into inductive graph methods compare to the current transductive approach in terms of online inference capability and performance? The paper explicitly states that PQ-GCN adopts a transductive approach and is not suited for online inference, while expressing hope to inspire future work in incorporating phrase-based features into inductive methods.

### Open Question 3
How does the performance of PQ-GCN scale with increasing dataset size, particularly in comparison to pre-trained language models like BERT? The paper notes that PQ-GCN performs competitively with BERT on NU, ARC, and LREC datasets, but BERT outperforms PQ-GCN on Bloom and TREC, without exploring how performance changes as dataset size increases beyond these ranges.

## Limitations

- The approach relies heavily on POS regex patterns that may not generalize across different domains or languages
- Multi-graph architecture introduces significant complexity and computational overhead not fully addressed
- Performance claims are based on relatively small datasets (under 600 questions each), limiting generalizability
- Phrase extraction mechanism's robustness across different writing styles and question types remains untested

## Confidence

**High Confidence**: The claim that phrase features improve classification performance in low-resource settings is well-supported by experimental results and ablation study.

**Medium Confidence**: The assertion that PQ-GCN matches BERT's performance with fewer parameters is reasonable but limited by comparison on only three datasets.

**Low Confidence**: The paper does not adequately address potential failure modes or computational overhead of the multi-graph approach.

## Next Checks

1. **Cross-domain validation**: Test PQ-GCN on questions from different domains (e.g., technical support, customer service, educational content) to verify phrase feature generalization beyond the three reported datasets.

2. **Ablation study with different phrase types**: Systematically evaluate the contribution of noun phrases, verb phrases, and named entities individually and in combination to identify which phrase features drive the most performance gains.

3. **Parameter efficiency analysis**: Conduct controlled experiments comparing PQ-GCN against BERT and other transformer models across various dataset sizes to quantify the trade-off between parameter count and classification accuracy in different resource settings.