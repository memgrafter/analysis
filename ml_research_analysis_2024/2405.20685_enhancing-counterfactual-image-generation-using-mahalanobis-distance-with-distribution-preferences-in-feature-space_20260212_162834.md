---
ver: rpa2
title: Enhancing Counterfactual Image Generation Using Mahalanobis Distance with Distribution
  Preferences in Feature Space
arxiv_id: '2405.20685'
source_url: https://arxiv.org/abs/2405.20685
tags:
- counterfactual
- feature
- image
- space
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of generating interpretable counterfactual
  explanations for black-box image classification models. The authors propose a novel
  method, DPMDCE, that computes feature importance in the feature space of the black-box
  model using information fusion techniques.
---

# Enhancing Counterfactual Image Generation Using Mahalanobis Distance with Distribution Preferences in Feature Space

## Quick Facts
- arXiv ID: 2405.20685
- Source URL: https://arxiv.org/abs/2405.20685
- Authors: Yukai Zhang; Ao Xu; Zihao Li; Tieru Wu
- Reference count: 21
- Key outcome: DPMDCE achieves smaller feature space distances while maintaining similar pixel space distances compared to baselines

## Executive Summary
This paper proposes DPMDCE, a novel method for generating interpretable counterfactual explanations for black-box image classification models. The approach computes feature importance in the feature space of the black-box model using information fusion techniques, then finds counterfactual explanations using Distribution Preference Mahalanobis Distance (DPMD). These feature space counterfactuals are transformed into image counterfactuals using a generator model. The method is evaluated on the MNIST dataset with three different black-box models, demonstrating superior performance compared to established baselines.

## Method Summary
DPMDCE generates counterfactual explanations by first identifying important feature layers in the black-box model using Wasserstein distance and Passing Rate metrics. The selected layers are then fused using three merging strategies (balanced, weakening, strengthening) to create feature importance vectors. The Distribution Preference Mahalanobis Distance (DPMD) incorporates these feature importance weights to compute counterfactual explanations in feature space. Finally, a GAN generator transforms these feature space counterfactuals into image counterfactuals. The method includes automatic strategies for selecting optimal counterfactual classes based on distribution similarity or prototype proximity.

## Key Results
- DPMDCE achieves smaller feature space distances (Fe-Dist) compared to baselines while maintaining similar pixel space distances (Pixel-Dist)
- The method demonstrates high success rates (Suc-Rate) in generating valid counterfactual explanations
- Results show that distributions in feature space can be well-fitted using Kolmogorov-Smirnov tests
- DPMDCE outperforms established baselines on MNIST dataset with three different black-box models

## Why This Works (Mechanism)

### Mechanism 1
DPMDCE achieves smaller feature space distances while maintaining similar pixel space distances compared to baselines by using distribution preference Mahalanobis distance (DPMD) with feature importance weighting. The method finds counterfactual explanations that are closer in the model's learned feature space while still being visually similar in pixel space. This works because the feature space learned by the black-box model contains semantically meaningful representations where distance corresponds to meaningful differences.

### Mechanism 2
Distribution Preference Mahalanobis Distance (DPMD) better captures feature importance than standard Mahalanobis distance by computing feature importance vectors based on distributional distances between classes in the feature space. These are then incorporated into the Mahalanobis distance calculation to weight features differently. Features with larger distributional distances between classes are considered more important for changing the model's prediction.

### Mechanism 3
Automatic category selection strategies improve counterfactual generation efficiency and quality by providing two strategies (distribution similarity and prototype-based) to automatically determine the optimal counterfactual class without requiring user specification. The most appropriate counterfactual class can be determined by either distributional similarity or proximity to class prototypes in feature space.

## Foundational Learning

- Concept: Feature space vs pixel space in deep learning models
  - Why needed here: The method operates in the feature space of the black-box model rather than pixel space, requiring understanding of how neural networks transform inputs through layers.
  - Quick check question: What is the key difference between generating counterfactuals in feature space versus pixel space, and why does the paper claim feature space is preferable?

- Concept: Mahalanobis distance and its extensions
  - Why needed here: The core distance metric combines Mahalanobis distance with feature importance weighting, requiring understanding of multivariate distance metrics.
  - Quick check question: How does the Distribution Preference Mahalanobis Distance (DPMD) differ from standard Mahalanobis distance, and what role does the feature importance vector play?

- Concept: Wasserstein distance for distribution comparison
  - Why needed here: The paper uses Wasserstein distance to compute the Passing Rate metric for selecting feature layers, requiring understanding of optimal transport metrics.
  - Quick check question: What property of Wasserstein distance makes it suitable for comparing distributions of neural network activations across different classes?

## Architecture Onboarding

- Component map: Black-box model (feature extractor) → Feature layer selection module → Feature importance computation → DPMD-based counterfactual solver → Generator (GAN) → Image counterfactual output
- Critical path: Input image → Black-box feature extraction → Selected feature layers → Distribution fitting → Feature importance computation → DPMD optimization → Generator → Final counterfactual image
- Design tradeoffs: Feature space operations provide semantic relevance but require accurate distribution fitting; pixel space operations are more direct but may produce out-of-distribution images
- Failure signatures: Poor counterfactual quality (high Fe-Dist or Pixel-Dist), failure to change class prediction (low Suc-Rate), or generation of unrealistic images
- First 3 experiments:
  1. Implement feature layer selection with Passing Rate metric on a simple fully-connected model
  2. Test DPMD optimization with synthetic feature importance vectors on MNIST
  3. Integrate generator with feature space counterfactual solver and evaluate Fe-Dist/Pixel-Dist tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
How well would DPMDCE perform on multi-channel image datasets beyond MNIST, particularly with convolutional neural networks? The authors note their method is currently limited to single-channel datasets and fully connected neural networks, and they plan future work to address this limitation. This remains unresolved because the paper only tested DPMDCE on the MNIST dataset using fully connected black-box models, leaving performance on multi-channel images and CNNs unknown. Experimental results comparing DPMDCE performance on datasets like CIFAR-10 or ImageNet using CNNs would provide clear evidence of generalizability.

### Open Question 2
How sensitive is the Distribution Preference Mahalanobis Distance (DPMD) to the choice of β parameter and the number of feature layers selected for fusion? The authors introduce β as a balance parameter in the DPM distance formula and use a heuristic approach to select feature layers, but don't explore sensitivity to these choices. This remains unresolved because the paper doesn't provide ablation studies or sensitivity analysis for these key hyperparameters. Comprehensive experiments varying β and the number of feature layers while measuring impact on counterfactual quality metrics would clarify parameter sensitivity.

### Open Question 3
Can the feature importance calculation be made more efficient for high-dimensional feature spaces? The authors compute feature importance for each neuron across all selected layers, which could become computationally expensive for high-dimensional feature spaces. This remains unresolved because the paper doesn't discuss computational complexity or potential optimization strategies for the feature importance calculation. Analysis of computational time scaling with feature dimensionality and proposed optimizations with their performance impact would address this question.

## Limitations

- The method requires access to feature representations from the black-box model, which may not always be available
- Evaluation is limited to the MNIST dataset with simple fully-connected networks, limiting generalizability to more complex architectures and real-world images
- The quality of counterfactual explanations depends heavily on the performance of the GAN generator, which can introduce artifacts or produce unrealistic images

## Confidence

- **High Confidence**: The core claim that DPMDCE achieves smaller feature space distances while maintaining similar pixel space distances compared to baselines is well-supported by the experimental results presented in the paper.
- **Medium Confidence**: The claim that DPMD better captures feature importance than standard Mahalanobis distance is supported by the methodology but lacks direct comparative experiments with standard approaches.
- **Low Confidence**: The claim that automatic category selection strategies consistently improve counterfactual generation quality is based on limited experimental validation and would benefit from more extensive testing.

## Next Checks

1. **Distribution Fitting Validation**: Conduct more rigorous validation of the Kolmogorov-Smirnov tests used to confirm distribution fitting in feature space, including tests on out-of-distribution samples and comparison with alternative distribution fitting methods.

2. **Generalization Testing**: Evaluate the DPMDCE method on more complex datasets (e.g., CIFAR-10, ImageNet) and different model architectures (CNNs, transformers) to assess scalability and robustness across diverse scenarios.

3. **Ablation Study**: Perform a comprehensive ablation study to quantify the contribution of each component (feature importance weighting, automatic category selection, distribution preferences) to overall performance, helping identify which elements are most critical for success.