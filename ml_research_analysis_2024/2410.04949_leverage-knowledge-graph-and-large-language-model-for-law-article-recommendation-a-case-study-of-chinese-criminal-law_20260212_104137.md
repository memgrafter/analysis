---
ver: rpa2
title: 'Leverage Knowledge Graph and Large Language Model for Law Article Recommendation:
  A Case Study of Chinese Criminal Law'
arxiv_id: '2410.04949'
source_url: https://arxiv.org/abs/2410.04949
tags:
- article
- case
- information
- graph
- articles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of improving court efficiency
  by enhancing law article recommendation in Chinese criminal law. The authors propose
  a novel approach that integrates a Case-Enhanced Law Article Knowledge Graph (CLAKG)
  with a Large Language Model (LLM) to overcome limitations of traditional methods,
  such as data dependency, label imbalance, and hallucinations in LLM outputs.
---

# Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law

## Quick Facts
- arXiv ID: 2410.04949
- Source URL: https://arxiv.org/abs/2410.04949
- Authors: Yongming Chen; Miner Chen; Ye Zhu; Juan Pei; Siyu Chen; Yu Zhou; Yi Wang; Yifan Zhou; Hao Li; Songan Zhang
- Reference count: 40
- Primary result: Accuracy improves from 0.549 to 0.694 using CLAKG+LLM approach

## Executive Summary
This study addresses the challenge of improving court efficiency by enhancing law article recommendation in Chinese criminal law. The authors propose a novel approach that integrates a Case-Enhanced Law Article Knowledge Graph (CLAKG) with a Large Language Model (LLM) to overcome limitations of traditional methods, such as data dependency, label imbalance, and hallucinations in LLM outputs. CLAKG stores law articles, case data, and their relationships, while an automated construction method leverages LLMs for scalability. Experiments using Chinese criminal law judgments show that the proposed method improves recommendation accuracy from 0.549 to 0.694, significantly outperforming baseline models like BERT, GRU, DPCNN, and RAG-based approaches. An ablation study confirms the robustness of the approach across different LLMs, including GPT-4 and Llama-3.1-405b-chat. The findings demonstrate the effectiveness of combining structured knowledge graphs with LLMs to enhance legal decision-making and reduce errors in law article recommendations.

## Method Summary
The proposed method constructs a Case-Enhanced Law Article Knowledge Graph (CLAKG) that integrates law articles, historical case information, and their relationships. An automated LLM-based approach extracts entities and relationships from legal documents to build the graph. RGCN is applied to create node embeddings that capture semantic relationships. For recommendations, the system retrieves candidate law articles and relevant case precedents from CLAKG, then uses an LLM to generate recommendations grounded in these retrieved sources. The approach combines the semantic richness of knowledge graphs with the reasoning capabilities of LLMs while mitigating hallucinations through retrieval-augmented generation.

## Key Results
- Accuracy improves from 0.549 to 0.694, outperforming baseline models (BERT, GRU, DPCNN, TFIDF-RAG, Graph-RAG, Light-RAG)
- Consistent performance across different LLMs (GPT-4 and Llama-3.1-405b-chat) in ablation study
- Successfully addresses label imbalance issues that cause baseline models to classify all cases under a single article

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CLAKG structure enables semantic law article matching beyond keyword overlap
- Mechanism: By embedding law articles and key information nodes in a unified graph space via RGCN, cosine similarity can capture conceptual relationships (e.g., "bribery" to relevant statutes) that lexical methods miss
- Core assumption: The topological structure of the KG preserves meaningful legal semantics when projected into vector space
- Evidence anchors:
  - [section] "Utilizing the historical case information and the candidate law articles retrieval algorithm specified in Section 3.2.3, the system identifies the candidate law articles"
  - [abstract] "we propose a Case-Enhanced Law Article Knowledge Graph (CLAKG) as a database to store current law statutes, historical case information, and correspondence between law articles and historical cases"
  - [corpus] Weak - no direct corpus evidence that semantic matching works better than lexical methods
- Break condition: If graph embedding fails to preserve legal semantics (e.g., cosine similarity doesn't correlate with legal relevance)

### Mechanism 2
- Claim: LLM grounding via CLAKG reduces hallucinations in law article recommendations
- Mechanism: By retrieving candidate law articles and relevant case precedents from CLAKG before LLM generation, the model's output is constrained to verifiable legal sources rather than fabricating citations
- Core assumption: LLMs can effectively use retrieved legal content as context without ignoring it
- Evidence anchors:
  - [section] "Our method intends to incorporate reference case information and the original text of candidate law articles to eliminate the hallucinations of LLMs"
  - [abstract] "By using a large LLM, users can not only retrieve the law article in numeric and textual form, but also investigate the rationale behind its applicability to the case"
  - [corpus] Moderate - related work on RAG for legal applications shows reduced hallucinations
- Break condition: If LLM ignores retrieved context or the retrieved content is insufficient/incorrect

### Mechanism 3
- Claim: Graph embedding captures macro-semantic relationships between cases and law articles
- Mechanism: RGCN training on CLAKG creates embeddings where nodes representing related legal concepts (cases, statutes, key information) have similar vector representations, enabling semantic retrieval beyond exact text matches
- Core assumption: The link prediction objective during RGCN training aligns with legal semantic similarity
- Evidence anchors:
  - [section] "Based on the reference law articles written in the judgment documents, it is possible to link the name of a case node with law article id nodes"
  - [section] "we analyze the correlation between case information and the corresponding key information of applicable law articles using a LLM"
  - [corpus] Weak - no corpus evidence that RGCN embeddings capture legal semantics better than other methods
- Break condition: If link prediction accuracy doesn't translate to semantic retrieval quality

## Foundational Learning

- Concept: Knowledge Graph construction and schema design
  - Why needed here: CLAKG's effectiveness depends on proper entity/relationship definitions that capture legal domain semantics
  - Quick check question: Can you explain the difference between LAKG and ACKG components in the CLAKG schema?

- Concept: Graph neural networks and embedding techniques
  - Why needed here: RGCN is used to create vector representations that preserve both local and global graph structure for semantic retrieval
  - Quick check question: What distinguishes RGCN from standard GCN in handling multi-relational graphs?

- Concept: Retrieval-Augmented Generation (RAG) architecture
  - Why needed here: The method combines traditional retrieval (from CLAKG) with LLM generation to ground outputs in verifiable legal content
  - Quick check question: How does the retrieval component in this approach differ from standard text-based RAG methods?

## Architecture Onboarding

- Component map:
  - Case input -> Keyword matching -> Graph embedding similarity -> Candidate retrieval -> Prompt construction -> LLM generation -> User validation

- Critical path: Case input → Keyword matching → Graph embedding similarity → Candidate retrieval → Prompt construction → LLM generation → User validation

- Design tradeoffs:
  - Accuracy vs. latency: Graph embedding similarity calculation adds computational overhead but improves semantic matching
  - Completeness vs. noise: Including more case data enriches CLAKG but may introduce irrelevant connections
  - LLM choice vs. cost: GPT-4 provides better grounding but at higher operational cost than open-source alternatives

- Failure signatures:
  - Low recommendation accuracy despite high graph embedding quality: suggests semantic mismatch between graph structure and legal relevance
  - LLM consistently ignores retrieved content: indicates retrieval quality or prompt engineering issues
  - Performance degrades with more data: suggests scalability issues in graph embedding or retrieval algorithms

- First 3 experiments:
  1. Compare retrieval accuracy using graph embeddings vs. TF-IDF on a held-out test set
  2. Measure hallucination rates with vs. without CLAKG retrieval using a legal factuality benchmark
  3. Ablation study: measure accuracy impact of removing case information vs. law article information from CLAKG

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of law article recommendation change when scaling the CLAKG to include more diverse legal domains beyond Chinese criminal law?
- Basis in paper: [inferred] The paper demonstrates effectiveness on Chinese criminal law but explicitly states the method can be applied to "any type of law articles in any country."
- Why unresolved: The study only evaluates the proposed approach on Chinese criminal law judgments, limiting generalizability to other legal systems and domains.
- What evidence would resolve it: Testing the method on diverse legal domains (e.g., civil law, international law, or legal systems from different countries) and comparing accuracy metrics across domains.

### Open Question 2
- Question: What is the impact of incorporating additional case metadata (e.g., judge profiles, court levels, or geographic regions) into the CLAKG on recommendation accuracy?
- Basis in paper: [inferred] The paper uses basic case metadata (case name, time, prosecution reason) but doesn't explore richer metadata integration.
- Why unresolved: The study focuses on a limited set of case features, leaving the potential benefits of richer metadata unexplored.
- What evidence would resolve it: Experimenting with enhanced CLAKG schemas that include additional case metadata and measuring improvements in recommendation accuracy.

### Open Question 3
- Question: How does the proposed method perform in real-time legal assistance scenarios where cases arrive continuously and the CLAKG needs dynamic updates?
- Basis in paper: [explicit] The paper mentions "future work" involving expanding CLAKG data volume and exploring dynamic updates but doesn't evaluate real-time performance.
- Why unresolved: The study evaluates static performance on historical data without addressing operational challenges of continuous case streams and knowledge graph updates.
- What evidence would resolve it: Implementing a real-time system that processes incoming cases, updates CLAKG dynamically, and measures recommendation accuracy and system latency under continuous operation.

## Limitations

- The approach's effectiveness is limited to the specific legal domain and language (Chinese criminal law) tested, with unclear generalizability to other legal systems
- The CLAKG construction relies heavily on LLM-based automation, which may introduce biases or errors if the LLM's legal understanding is incomplete
- Performance depends on the quality and completeness of historical case data, potentially limiting effectiveness in jurisdictions with less digitized legal records

## Confidence

**High Confidence**: The experimental results showing improved accuracy from 0.549 to 0.694 are well-supported by the methodology and dataset description. The ablation study demonstrating consistent performance across different LLMs (GPT-4 and Llama-3.1-405b-chat) provides strong evidence for the approach's robustness.

**Medium Confidence**: The claim that CLAKG structure enables semantic law article matching beyond keyword overlap is plausible but not directly validated against lexical baselines in the corpus. The mechanism depends on assumptions about RGCN's ability to preserve legal semantics that require further empirical verification.

**Low Confidence**: The assertion that LLM grounding via CLAKG significantly reduces hallucinations is supported by related work on RAG but lacks direct measurements of hallucination rates with and without the proposed approach.

## Next Checks

1. **Semantic Retrieval Validation**: Compare retrieval accuracy using graph embeddings versus traditional TF-IDF methods on a held-out test set to empirically validate whether semantic matching outperforms lexical methods.

2. **Hallucination Rate Measurement**: Implement a legal factuality benchmark to measure hallucination rates in LLM outputs with and without CLAKG retrieval, quantifying the actual reduction in hallucinated citations.

3. **Cross-Domain Generalizability Test**: Apply the CLAKG+LLM approach to a different legal domain (e.g., civil law) or language to assess whether the method generalizes beyond Chinese criminal law.