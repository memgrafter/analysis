---
ver: rpa2
title: Handling Numeric Expressions in Automatic Speech Recognition
arxiv_id: '2408.00004'
source_url: https://arxiv.org/abs/2408.00004
tags:
- numeric
- expressions
- data
- test
- expression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of correctly formatting numeric
  expressions in automatic speech recognition (ASR) transcripts. The challenge is
  that the expected transcript format depends on the context, e.g., 1945 (year) vs.
---

# Handling Numeric Expressions in Automatic Speech Recognition

## Quick Facts
- arXiv ID: 2408.00004
- Source URL: https://arxiv.org/abs/2408.00004
- Reference count: 0
- Primary result: Adapted end-to-end ASR model achieved 92.9% accuracy on numeric expressions, outperforming cascaded approaches in latency and cost

## Executive Summary
This paper addresses the challenge of correctly formatting numeric expressions in ASR transcripts, where context determines whether numbers should be interpreted as years, timestamps, currency, or quantities. The authors compare cascaded (ASR + LLM) and end-to-end approaches for numeric expression recognition and formatting. Using a data generation strategy with LLMs and TTS to create adaptation data, they evaluate these approaches on a proprietary test dataset, finding that while LLM-based approaches perform well, adapted end-to-end models offer competitive accuracy with significant advantages in latency and inference cost.

## Method Summary
The authors employ two main approaches for numeric expression formatting in ASR: cascaded and end-to-end. For the cascaded approach, they use ASR output as input to LLMs (gpt-3.5-turbo, gpt-4-turbo, and gpt-4o) for formatting. For the end-to-end approach, they generate adaptation data using an LLM to create text prompts with various numeric expressions, then use a TTS model to convert these to speech, creating a training dataset. The adapted end-to-end model is fine-tuned on this synthetic data to directly output formatted numeric expressions.

## Key Results
- Adapted end-to-end model achieved 92.9% accuracy on numeric expressions test data
- Outperformed cascaded ASR + LLM approaches in terms of latency and inference cost
- Showed competitive performance compared to LLM-based approaches (only slightly worse than ASR + gpt-4o)
- LLM-based approaches still performed well in recognizing formatted numeric expressions

## Why This Works (Mechanism)
The success of the adapted end-to-end approach stems from its ability to learn direct mappings from acoustic features to formatted numeric expressions during training. By generating synthetic training data that captures the variability in how numeric expressions are spoken and should be formatted, the model learns context-aware formatting rules without the overhead of a separate LLM component. This integration allows for faster inference and lower costs while maintaining high accuracy.

## Foundational Learning

**Automatic Speech Recognition (ASR)**: Converts spoken language into text; needed as the base technology for all approaches; quick check: model outputs raw transcriptions before formatting.

**Large Language Models (LLMs)**: Generate formatted text based on prompts; needed for the cascaded approach to format numeric expressions; quick check: can correctly format "nineteen forty five" as "1945" or "19:45" based on context.

**Text-to-Speech (TTS)**: Converts text to speech; needed to create synthetic training data for the end-to-end approach; quick check: produces natural-sounding speech from generated prompts.

**Data Augmentation**: Technique to increase training data diversity; needed to create sufficient examples for numeric expression formatting; quick check: generates multiple pronunciations and contexts for each numeric expression.

## Architecture Onboarding

**Component Map**: Speech input -> ASR module -> (LLM formatting OR End-to-end formatting) -> Formatted numeric expressions

**Critical Path**: Speech input -> End-to-end ASR model -> Formatted numeric expressions (for the adapted end-to-end approach)

**Design Tradeoffs**: Cascaded approach offers flexibility and potentially better formatting through LLM reasoning, but at higher latency and cost; end-to-end approach provides faster, cheaper inference with competitive accuracy but requires adaptation data generation.

**Failure Signatures**: Cascaded approach may fail due to ASR errors propagating to LLM, or LLM misinterpreting context; end-to-end approach may struggle with out-of-distribution numeric expressions not seen in training data.

**First Experiments**:
1. Test the adapted end-to-end model on a small set of common numeric expressions to verify basic functionality
2. Compare inference latency between cascaded and end-to-end approaches on identical inputs
3. Evaluate model performance on numeric expressions with ambiguous context to test contextual understanding

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation conducted on proprietary test dataset, limiting external validation
- Study focuses specifically on numeric expressions, not addressing other formatting challenges
- Accuracy is the primary metric, with limited analysis of error types or recovery mechanisms

## Confidence
- **High confidence**: Comparative performance between cascaded and end-to-end approaches, latency and cost advantages of end-to-end models, overall methodology
- **Medium confidence**: Superiority of adapted end-to-end model over LLM-based approaches due to proprietary test data
- **Medium confidence**: Effectiveness of LLM+TTS data generation strategy without detailed analysis of generated data quality

## Next Checks
1. Evaluate the adapted end-to-end model on publicly available ASR datasets with annotated numeric expressions to verify generalizability
2. Conduct ablation studies to quantify the contribution of the LLM+TTS data generation strategy versus other adaptation methods
3. Test the models on out-of-domain data (e.g., different accents, recording conditions, or numeric expression types) to assess robustness beyond the test set