---
ver: rpa2
title: Task Arithmetic Through The Lens Of One-Shot Federated Learning
arxiv_id: '2411.18607'
source_url: https://arxiv.org/abs/2411.18607
tags:
- task
- learning
- arithmetic
- federated
- heterogeneity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work establishes a theoretical connection between Task Arithmetic
  and one-shot Federated Averaging (FedAvg), revealing that Task Arithmetic inherits
  both the benefits and challenges of federated learning. Through this lens, two key
  factors impacting Task Arithmetic are identified: data heterogeneity, which slows
  convergence, and training heterogeneity, which causes objective inconsistency.'
---

# Task Arithmetic Through The Lens Of One-Shot Federated Learning

## Quick Facts
- arXiv ID: 2411.18607
- Source URL: https://arxiv.org/abs/2411.18607
- Reference count: 31
- One-line primary result: Task Arithmetic is mathematically equivalent to one-shot Federated Averaging, inheriting both its benefits and challenges from data and training heterogeneity.

## Executive Summary
This paper establishes a theoretical connection between Task Arithmetic and one-shot Federated Averaging (FedAvg), revealing that Task Arithmetic inherits both the benefits and challenges of federated learning. Through this lens, two key factors impacting Task Arithmetic are identified: data heterogeneity, which slows convergence, and training heterogeneity, which causes objective inconsistency. The study adapts several federated learning algorithms—FedNova, FedGMA, Median, and CCLIP—to address these challenges in model merging. Experimental results on vision-language models (CLIP) and large language models (LLMs) demonstrate that these adaptations often significantly improve performance over standard Task Arithmetic, particularly when training heterogeneity is present. This work provides new theoretical insights and practical methodologies for more effective model merging.

## Method Summary
The paper establishes that Task Arithmetic is mathematically equivalent to one-shot Federated Averaging (FedAvg). In Task Arithmetic, task vectors are computed by subtracting pre-trained model parameters from fine-tuned ones, then aggregated and added back to the pre-trained model. The paper adapts federated learning algorithms (FedNova, FedGMA, Median, CCLIP) to address data heterogeneity and training heterogeneity in Task Arithmetic. Experiments evaluate these adaptations on CLIP and LLM models using normalized accuracy, win rate, zero-shot accuracy, and pass@1 metrics.

## Key Results
- Task Arithmetic is mathematically equivalent to one-shot FedAvg, with both performing single aggregation steps without fine-tuning.
- Data heterogeneity slows convergence in Task Arithmetic, with performance degrading as the diversity of task gradients increases.
- Training heterogeneity causes objective inconsistency in Task Arithmetic, creating a discrepancy between the actual and intended multi-task objectives.
- Adapted federated algorithms (FedNova, FedGMA, Median, CCLIP) often significantly improve Task Arithmetic performance, especially when training heterogeneity is present.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Task Arithmetic is mathematically equivalent to one-shot Federated Averaging (FedAvg), which explains its empirical success.
- **Mechanism**: Both Task Arithmetic and one-shot FedAvg perform a single aggregation step of model updates (task vectors) without additional fine-tuning. In FedAvg, devices compute local updates and send them to a server which averages them. In Task Arithmetic, each task produces a task vector by subtracting the pre-trained model parameters from the fine-tuned model parameters, and these vectors are summed and added back to the pre-trained model. The mathematical equivalence is shown by comparing the update rules: Task Arithmetic update θTA = θ0 - λ/T ∑t Kt-1∑k=0 η(k)t gt(θ(k)t ) matches the one-shot FedAvg update θOS = θ0 + β/T ∑t (θ(Kt)t - θ0).
- **Core assumption**: The learning rates and number of iterations can be normalized to make the equivalence exact.
- **Evidence anchors**:
  - [abstract] "We demonstrate that Task Arithmetic is mathematically equivalent to the commonly used algorithm in Federated Learning, called Federated Averaging (FedAvg)."
  - [section 3] "By comparing equations (3) and (4), we see that performing Task Arithmetic is equivalent to one-shot FedAvg with outer step size β=λT."
  - [corpus] Found 25 related papers with average FMR=0.57, suggesting moderate related work but limited direct citations.
- **Break condition**: If the learning rates or number of iterations vary significantly across tasks, the equivalence breaks down as the effective aggregation weights change.

### Mechanism 2
- **Claim**: Data heterogeneity in Task Arithmetic slows convergence and degrades performance, similar to Federated Learning.
- **Mechanism**: When each task is trained on different data distributions, the task vectors point in different directions in weight space. The aggregation of these heterogeneous vectors results in a suboptimal direction that doesn't effectively optimize any individual task. The paper shows that the convergence error contains a non-vanishing term (Hζ2*B4)1/3 that depends on data heterogeneity ζ2*, meaning the more heterogeneous the data, the worse the performance.
- **Core assumption**: Data heterogeneity can be quantified by the diversity of gradients at optimal points across tasks.
- **Evidence anchors**:
  - [section 4.1] "The quantity ζ2* measures the diversity among the set of functions {Lt}T t=1 at the optima of the averaged multi-task objective function L(θ)."
  - [section 4.1] "The term (Hζ2*B4)1/3 is a non-vanishing error term introduced by ζ2*, highlighting the negative impact of data heterogeneity."
  - [corpus] Moderate related work with FMR=0.57 suggests some community interest in this connection.
- **Break condition**: If all tasks share identical or very similar data distributions, data heterogeneity approaches zero and this mechanism's negative impact disappears.

### Mechanism 3
- **Claim**: Training heterogeneity (different learning rates and iterations across tasks) causes objective inconsistency in Task Arithmetic, degrading performance.
- **Mechanism**: When tasks use different training hyperparameters, the effective contribution of each task vector to the final model is weighted differently than the uniform weighting assumed in the multi-task objective. This creates a discrepancy between the actual objective being optimized and the intended multi-task objective. The paper shows this causes a persistent error term χ2p||wζ2 that only vanishes when training is homogeneous.
- **Core assumption**: Different training processes create different "effective" numbers of updates that should be weighted differently in aggregation.
- **Evidence anchors**:
  - [section 4.2] "This discrepancy is caused by training heterogeneity, and leads FedAvg with multiple communication rounds to converge to the stationary point of a different objective function ˜L(θ) :=∑T t=1wtLt(θ) which is inconsistent with the original objective function L."
  - [section 4.2] "When all task objective functions are optimized with the same number of iterations K and a consistent learning rate schedule {η(0),...,η(K-1)}, we have wt = 1/T. This yields χ2p||w = 0 and L = ˜L, aligning the actual objective function ˜L being optimized with the original objective function L."
  - [corpus] FMR=0.57 indicates some related work but limited direct evidence for this specific mechanism.
- **Break condition**: If all tasks use identical training procedures (same learning rate schedule and number of iterations), training heterogeneity vanishes and objective inconsistency is eliminated.

## Foundational Learning

- **Concept**: Federated Learning fundamentals (FedAvg algorithm, data heterogeneity, and training heterogeneity)
  - Why needed here: The paper's core contribution is establishing Task Arithmetic as one-shot FedAvg and using federated learning theory to analyze its performance. Understanding FedAvg's behavior with heterogeneous data and training is essential to grasp why Task Arithmetic works or fails.
  - Quick check question: In FedAvg, what happens to the convergence rate when devices have non-i.i.d. data distributions?

- **Concept**: Multi-task learning objective formulation
  - Why needed here: Task Arithmetic aims to optimize a multi-task objective L(θ) = 1/T ∑Tt=1 Lt(θ) by combining task vectors. Understanding how this differs from single-task learning and how it relates to distributed optimization is crucial.
  - Quick check question: How does the multi-task objective L(θ) differ from optimizing a single task objective Lt(θ)?

- **Concept**: Model merging techniques and task vectors
  - Why needed here: Task Arithmetic is a specific model merging technique that uses task vectors. Understanding the concept of task vectors and how they capture task-specific modifications is fundamental to understanding the method.
  - Quick check question: What is a task vector in Task Arithmetic, and how is it computed from a pre-trained and fine-tuned model?

## Architecture Onboarding

- **Component map**: Pre-trained model (θpre) -> Fine-tune on individual tasks -> Compute task vectors (τt = θt - θpre) -> Aggregate task vectors -> Final model (θpre + aggregated task vectors)

- **Critical path**: Pre-trained model → Fine-tune on individual tasks → Compute task vectors → Aggregate task vectors → Generate multi-task model

- **Design tradeoffs**:
  - One-shot vs. multi-round aggregation: Task Arithmetic uses one-shot aggregation for efficiency but sacrifices the convergence benefits of multiple rounds
  - Uniform weighting vs. adaptive weighting: Simple summation assumes equal importance of all tasks, while adaptive methods could weight tasks differently based on performance or other criteria
  - Full model vs. parameter-efficient merging: Task Arithmetic merges entire models while methods like LoRA merge only small adapters, trading completeness for efficiency

- **Failure signatures**:
  - Performance degradation when merging heterogeneous task vectors (data or training heterogeneity)
  - Overfitting to specific tasks when λ is too large
  - Underfitting or loss of task-specific capabilities when λ is too small
  - Sign interference when task vectors have conflicting directions

- **First 3 experiments**:
  1. Replicate the basic Task Arithmetic experiment: Fine-tune a pre-trained model on 2-3 different tasks, compute task vectors, and merge them with different λ values to observe the trade-off between task performance.
  2. Test the impact of data heterogeneity: Merge task vectors from tasks with similar vs. dissimilar data distributions to quantify the performance degradation.
  3. Test the impact of training heterogeneity: Merge task vectors generated with identical vs. different learning rates/iterations to demonstrate objective inconsistency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the size of the pre-trained model influence the impact of data heterogeneity on Task Arithmetic performance?
- Basis in paper: [inferred] The paper mentions that a good pre-trained model with a smaller B can mitigate the adverse effects of high data heterogeneity, but doesn't explore why large pre-trained models can also alleviate data heterogeneity.
- Why unresolved: The paper focuses on the role of the pre-trained model's quality in mitigating heterogeneity effects but does not investigate how model size itself affects this relationship.
- What evidence would resolve it: Experiments comparing Task Arithmetic performance across models of varying sizes (e.g., CLIP-ViT-B-32 vs larger CLIP variants) while controlling for pre-training quality could reveal whether larger models inherently handle heterogeneity better.

### Open Question 2
- Question: What are the optimal aggregation methods for merging task vectors generated by different fine-tuning approaches (e.g., standard fine-tuning vs parameter-efficient fine-tuning)?
- Basis in paper: [explicit] The paper identifies that task vectors from parameter-efficient fine-tuning (e.g., QLoRA) have smaller norms compared to those from standard fine-tuning, which complicates aggregation.
- Why unresolved: Current aggregation methods like Median and CCLIP are designed for robust aggregation but may not optimally handle the specific challenges posed by combining task vectors with significantly different norms.
- What evidence would resolve it: Developing and testing new aggregation methods that account for norm differences between task vectors, followed by empirical evaluation on merged model performance, could identify more effective strategies.

### Open Question 3
- Question: How does training heterogeneity affect Task Arithmetic when the fine-tuning methods differ but the hyperparameter settings are the same?
- Basis in paper: [explicit] The paper distinguishes between training heterogeneity from hyperparameter differences and from fine-tuning method differences, noting that the latter exacerbates heterogeneity.
- Why unresolved: While the paper analyzes the impact of hyperparameter differences, it does not fully explore how different fine-tuning methods (e.g., standard vs parameter-efficient) contribute to training heterogeneity.
- What evidence would resolve it: Controlled experiments where models are fine-tuned with identical hyperparameters but different methods, followed by Task Arithmetic merging, could quantify the additional heterogeneity introduced by method differences.

## Limitations
- The theoretical equivalence between Task Arithmetic and one-shot FedAvg relies on normalized learning rates and iteration counts across tasks, becoming approximate when tasks use heterogeneous training procedures.
- The convergence analysis assumes smooth, strongly-convex objectives, which may not hold for modern deep learning tasks, particularly in the vision-language and LLM domains studied.
- The experimental validation is limited to specific model architectures (CLIP and LLMs) and task types, leaving uncertainty about generalizability to other domains.

## Confidence
- **High confidence**: The mathematical derivation showing Task Arithmetic's equivalence to one-shot FedAvg (Mechanism 1) is rigorous and well-established. The identification of data heterogeneity as a performance bottleneck has strong theoretical and empirical support.
- **Medium confidence**: The analysis of training heterogeneity causing objective inconsistency is theoretically sound but relies on assumptions about gradient diversity that may not fully capture real-world behavior. The effectiveness of adapted federated algorithms for Task Arithmetic shows promising but not uniformly consistent results.
- **Low confidence**: The convergence bounds and error terms are derived under idealized assumptions that may not hold for practical deep learning scenarios, particularly regarding smoothness and convexity assumptions.

## Next Checks
1. **Test convergence under controlled heterogeneity**: Systematically vary data heterogeneity (using controlled data splits) and training heterogeneity (using different learning rates/epochs) to validate the theoretical predictions about their impact on Task Arithmetic performance.

2. **Validate across diverse architectures**: Reproduce the experiments on additional model families beyond CLIP and LLMs (e.g., vision transformers, diffusion models) to assess the generalizability of the findings.

3. **Compare with state-of-the-art merging methods**: Benchmark the federated learning adaptations against recent model merging approaches like ATM or routing methods to establish relative performance and identify scenarios where each approach excels.