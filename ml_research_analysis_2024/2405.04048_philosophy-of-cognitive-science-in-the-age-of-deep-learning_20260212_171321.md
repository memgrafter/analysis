---
ver: rpa2
title: Philosophy of Cognitive Science in the Age of Deep Learning
arxiv_id: '2405.04048'
source_url: https://arxiv.org/abs/2405.04048
tags:
- learning
- cognitive
- deep
- language
- science
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Modern deep neural networks have overcome many limitations of older
  connectionist models, enabling them to match or exceed human performance on a broad
  range of cognitive tasks. This progress has important implications for the philosophy
  of cognitive science, as it challenges classical symbolic approaches to cognition
  and suggests that neural networks can account for structure-sensitive properties
  of cognition without merely implementing a language of thought architecture.
---

# Philosophy of Cognitive Science in the Age of Deep Learning

## Quick Facts
- arXiv ID: 2405.04048
- Source URL: https://arxiv.org/abs/2405.04048
- Reference count: 14
- Primary result: Modern DNNs overcome limitations of older connectionist models, enabling human-level performance on cognitive tasks

## Executive Summary
Modern deep neural networks have overcome many limitations of older connectionist models, enabling them to match or exceed human performance on a broad range of cognitive tasks. This progress has important implications for the philosophy of cognitive science, as it challenges classical symbolic approaches to cognition and suggests that neural networks can account for structure-sensitive properties of cognition without merely implementing a language of thought architecture. The convergence of DNNs with human performance on tasks like compositional generalization, reasoning, and language understanding highlights the need for robust methods to evaluate and compare them with humans.

## Method Summary
The paper synthesizes findings from multiple studies comparing deep neural networks with human cognitive performance across various benchmarks. It analyzes architectural innovations in modern DNNs that enable systematic compositional generalization and non-content-specific computations. The methodological discussion draws on practices from cognitive science to propose improved evaluation protocols, including controlled training data, novel stimuli, and multiple tasks testing the same capacity.

## Key Results
- DNNs achieve systematic compositional generalization through architectural innovations without explicit symbolic rules
- Modern DNNs implement non-content-specific computations like induction heads that apply the same algorithm across diverse contents
- Cognitive science methodologies can significantly improve DNN evaluation and human-machine comparisons

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modern DNNs can account for structure-sensitive cognitive properties without merely implementing a language of thought architecture
- Mechanism: Deep learning models achieve systematic compositional generalization through architectural innovations (like Transformers with self-attention) and training regimes that induce tree-structured computations without built-in symbolic rules
- Core assumption: The constituent structure of representations in DNNs, while real, need not be discrete or functionally equivalent to classical symbolic binding to account for systematic cognitive properties
- Evidence anchors:
  - [abstract] "neural networks can account for structure-sensitive properties of cognition without merely implementing a language of thought architecture"
  - [section] "Lake and Baroni (2023) show that a standard Transformer-based neural network trained with meta-learning can achieve human-like systematic generalization... without the need for explicit compositional rules"
  - [corpus] Weak corpus evidence - neighboring papers discuss compositionality but don't directly address the mechanism of avoiding language of thought implementation
- Break condition: If role-filler independence in DNNs were shown to require discrete symbolic binding, the mechanism would collapse

### Mechanism 2
- Claim: DNNs can perform both content-specific and non-content-specific computations, unlike classical architectures that strictly separate them
- Mechanism: DNNs implement non-content-specific computations through mechanisms like "induction heads" in Transformers that apply the same similarity algorithm across stored memories regardless of their specific contents
- Core assumption: The content-specificity of DNN computations exists on a continuum rather than as a strict binary distinction
- Evidence anchors:
  - [abstract] "DNNs... demonstrate an unprecedented convergence with human performance on many long-standing challenges"
  - [section] "Transformer-based LLMs also induce a broad repertoire of non-content-specific computations, including domain-general 'induction head' mechanisms"
  - [corpus] Moderate corpus evidence - neighboring papers discuss neurosymbolic approaches that bridge symbolic and neural representations
- Break condition: If DNNs were shown to be fundamentally incapable of general-purpose computations across different content types, this mechanism would fail

### Mechanism 3
- Claim: Methodological insights from cognitive science can significantly improve the evaluation of DNNs and human-machine comparisons
- Mechanism: Cognitive science provides best practices like using novel stimuli to avoid data contamination, controlled training data analogous to developmental experiments, and multiple tasks to test the same capacity
- Core assumption: The connection between theoretical constructs and operational variables in benchmarks is often implicit and poorly supported, requiring more rigorous experimental design
- Evidence anchors:
  - [abstract] "ongoing methodological challenges related to the comparative evaluation of deep neural networks stand to benefit greatly from interdisciplinary collaboration with philosophy and cognitive science"
  - [section] "researchers can use novel stimuli to avoid data contamination; use minimal stimuli...; control the training data...; use multiple tasks to test the same capacity"
  - [corpus] Weak corpus evidence - neighboring papers focus more on philosophical frameworks than specific methodological practices
- Break condition: If benchmarking practices were shown to be fundamentally adequate without cognitive science input, this mechanism would be unnecessary

## Foundational Learning

- Concept: Compositional generalization
  - Why needed here: Understanding how DNNs recombine learned elements to produce novel outputs is central to evaluating whether they can capture structure-sensitive cognitive properties
  - Quick check question: Can a model trained on "red square" and "blue circle" correctly identify "red circle" without seeing this exact combination during training?

- Concept: Multiple realizability
  - Why needed here: The paper argues that DNNs provide concrete examples of sophisticated cognitive functions being implemented in physical systems, challenging classical architecture assumptions
  - Quick check question: Does the ability of DNNs to match human performance on cognitive tasks provide evidence for multiple realizability?

- Concept: Content-specific vs. non-content-specific computation
  - Why needed here: Understanding this distinction is crucial for evaluating whether DNNs implement classical symbolic systems or represent a genuinely different computational approach
  - Quick check question: Would a computation that applies the same similarity algorithm to all stored memories regardless of their content be content-specific or non-content-specific?

## Architecture Onboarding

- Component map: Input layer -> Hidden layers (with convolutional filters, self-attention layers) -> Output layer -> Backpropagation algorithm -> Regularization techniques
- Critical path: 1. Data input and preprocessing 2. Forward pass through hidden layers with feature extraction 3. Computation of loss function 4. Backpropagation to update weights 5. Application of regularization to prevent overfitting
- Design tradeoffs:
  - Depth vs. computational efficiency: Deeper networks can learn more abstract representations but require more resources
  - Specialized vs. general architectures: Task-specific components improve performance but reduce flexibility
  - Training data size vs. generalization: Larger datasets improve performance but increase risk of data contamination
- Failure signatures:
  - Poor compositional generalization despite good overall accuracy
  - Overfitting despite regularization techniques
  - Failure on minimal stimulus variations that humans handle easily
  - Sensitivity to benchmark contamination
- First 3 experiments:
  1. Test compositional generalization on held-out test samples with carefully designed train-test splits
  2. Evaluate non-content-specific computation by testing similarity algorithms across diverse memory contents
  3. Compare performance on controlled minimal pairs with and without context analogous to human training

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can DNNs truly account for structure-sensitive properties of cognition without merely implementing a language of thought architecture?
- Basis in paper: [explicit] The paper discusses this as a key question in relation to the classicist dilemma and the progress of DNNs in compositional generalization tasks
- Why unresolved: There is ongoing debate about what constitutes genuine implementation versus mere implementation of a language of thought. The mechanisms by which DNNs achieve compositional generalization are still being investigated
- What evidence would resolve it: More detailed mechanistic studies of DNNs' internal representations and computations, particularly around variable binding and role-filler independence. Comparative studies with human cognition to determine if DNNs use similar mechanisms

### Open Question 2
- Question: How can we best evaluate DNNs and compare them to humans on linguistic and cognitive tasks?
- Basis in paper: [explicit] The paper highlights methodological challenges with benchmarks and the need for more robust, hypothesis-driven experiments inspired by cognitive science
- Why unresolved: Standard benchmarks are often saturated, prone to data contamination, and may not adequately capture the theoretical constructs they aim to measure. There is a need for better evaluation practices
- What evidence would resolve it: Development and validation of new evaluation methods that use novel stimuli, controlled training data, multiple tasks, and appropriate controls. Comparative studies that ensure adequately matched testing conditions for humans and DNNs

### Open Question 3
- Question: What is the relevance of DNNs to theoretical linguistics and theories of language acquisition?
- Basis in paper: [explicit] The paper discusses how DNNs challenge core tenets of generative linguistics and calls for an examination of their potential to inform linguistic theory and language acquisition models
- Why unresolved: There is ongoing debate about whether statistical approaches like DNNs can account for the hierarchical structure dependence of syntactic competence. Most DNNs are exposed to vastly more data than children during learning
- What evidence would resolve it: Studies that train DNNs in more developmentally plausible learning scenarios and compare their acquisition trajectories to those of children. More targeted experiments probing the nature and extent of syntactic knowledge acquired by DNNs

## Limitations
- Limited empirical results from the paper itself, relying heavily on synthesis of external studies
- Weak corpus evidence supporting some proposed mechanisms and methodological recommendations
- Unclear implementation details for key experimental approaches mentioned

## Confidence

**High confidence:** Limited - the analysis relies on synthesizing findings from multiple external studies with varying methodological rigor

**Medium confidence:** The characterization of DNN capabilities for compositional generalization and the proposed mechanisms for avoiding language-of-thought implementation

**Low confidence:** Specific methodological recommendations due to limited supporting evidence and implementation details

## Next Checks
1. Replicate the compositional generalization experiments on controlled synthetic datasets with carefully designed train-test splits
2. Test whether DNNs can perform the same similarity algorithm across diverse memory contents without content-specific adaptations
3. Implement and evaluate the proposed methodological improvements (novel stimuli, controlled training data, multiple tasks) on a standard cognitive benchmark