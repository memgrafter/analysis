---
ver: rpa2
title: Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on
  English-Korean Code-Switching
arxiv_id: '2410.18436'
source_url: https://arxiv.org/abs/2410.18436
tags:
- knowledge
- korean
- english
- language
- code-switching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether code-switching can activate language-specific
  knowledge in multilingual large language models (LLMs), particularly for low-resource
  languages. To facilitate this research, the authors construct ENKOQA, a synthetic
  English-Korean code-switching question-answering dataset based on two Korean-centric
  datasets.
---

# Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching

## Quick Facts
- **arXiv ID**: 2410.18436
- **Source URL**: https://arxiv.org/abs/2410.18436
- **Reference count**: 40
- **Primary result**: Code-switching outperforms English and translated Korean baselines in activating language-specific knowledge in multilingual LLMs, especially for low-resource language domains.

## Executive Summary
This study investigates whether code-switching can activate language-specific knowledge in multilingual large language models (LLMs), particularly for low-resource languages. To facilitate this research, the authors construct ENKOQA, a synthetic English-Korean code-switching question-answering dataset based on two Korean-centric datasets. The knowledge activation process is divided into two tasks: Knowledge Identification, which evaluates the quality and relevance of identified knowledge, and Knowledge Leveraging, which assesses whether the model can correctly answer questions using the identified knowledge. Experiments on various multilingual LLMs show that code-switching outperforms both English and translated Korean baselines, especially in language-specific domains such as History and Tradition. Human and LLM-based evaluations confirm that code-switched questions elicit more faithful and helpful knowledge. The results suggest that code-switching can effectively activate low-resource language knowledge within LLMs, offering a promising approach for addressing data scarcity in multilingual tasks.

## Method Summary
The study constructs ENKOQA, a synthetic English-Korean code-switching QA dataset generated from two Korean-centric datasets using the Matrix Language Frame model. The knowledge activation process is evaluated through two tasks: Knowledge Identification (measuring faithfulness and helpfulness of identified knowledge) and Knowledge Leveraging (QA accuracy). Experiments compare code-switching against English and translated Korean baselines across multiple multilingual LLMs including GPT-4o, GPT-3.5, Claude 3.5, Solar, Llama3, and Gemma2. Both human evaluation and LLM-as-a-judge methods are employed to assess knowledge quality.

## Key Results
- Code-switching significantly outperforms English baselines in knowledge identification, particularly in History and Tradition domains
- Code-switched questions elicit more faithful and helpful knowledge according to both human and LLM-based evaluations
- Code-switching reduces hallucinations compared to English-only prompts across all tested LLMs
- The effectiveness varies by domain and model family, with more advanced models showing stronger benefits

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Code-switching activates knowledge in multilingual LLMs by preserving semantic and cultural cues that are lost in translation.
- **Mechanism:** The Matrix Language Frame (MLF) model suggests that code-switching retains the matrix language's grammatical structure while embedding semantically important content from the embedded language. This preserves culturally specific terminology and concepts, which are more likely to be encoded in the original language within the LLM's memory.
- **Core assumption:** LLMs encode knowledge more robustly in the original language of the concept, and code-switching can retrieve this knowledge more effectively than pure translation.
- **Evidence anchors:**
  - [abstract] "Code-switching (CS), a phenomenon where multilingual speakers alternate between languages in a discourse, can convey subtle cultural and linguistic nuances that can be otherwise lost in translation and elicits language-specific knowledge in human communications."
  - [section 3.1] "Following Matrix Language Frame Model (Myers-Scotton, 1997), we synthesize Korean QA datasets (Kim et al., 2024b; Son et al., 2024) that encompass various aspects of Korea into English-Korean code-switched questions."
- **Break condition:** If the LLM does not encode language-specific knowledge in a language-dependent manner, or if the embedded language content is not semantically important, code-switching will not provide an advantage.

### Mechanism 2
- **Claim:** Code-switching improves knowledge identification by making the LLM's knowledge retrieval process more aligned with human cognitive patterns for bilingual speakers.
- **Mechanism:** Bilingual humans recall language-specific knowledge more effectively when prompted in a mixed-language format. LLMs, when prompted in code-switched text, may simulate this human-like retrieval process, leading to more faithful and helpful knowledge identification.
- **Core assumption:** LLMs can simulate human cognitive processes related to language and knowledge retrieval, and these processes are enhanced by code-switching.
- **Evidence anchors:**
  - [abstract] "When a human English-Korean bilingual is given a question about Korean culture, they will first try to identify what specific knowledge is required to answer the question, and then apply the knowledge to find the correct answer. Depending on which language the question is written in, the quantity and quality of the knowledge may vary..."
  - [section 5.1] "We observe a significant gap in faithfulness scores between CS and English in both History and Tradition. The discrepancy is more salient in Tradition where cultural nuances is much important..."
- **Break condition:** If the LLM does not simulate human-like cognitive processes, or if the knowledge retrieval process is not influenced by the language of the prompt, code-switching will not improve knowledge identification.

### Mechanism 3
- **Claim:** Code-switching reduces hallucinations in LLM responses by grounding the model in more accurate and contextually relevant knowledge.
- **Mechanism:** When prompted in code-switched text, the LLM retrieves knowledge that is more closely aligned with the original language of the concept, reducing the likelihood of generating incorrect or hallucinated information. This is particularly important for domains that require domain-specific expertise, such as History and Tradition.
- **Core assumption:** Hallucinations in LLM responses are often caused by the model's inability to accurately retrieve relevant knowledge, and code-switching can mitigate this by providing more precise prompts.
- **Evidence anchors:**
  - [abstract] "We observe that answering English questions results in more errors compared to CS across all LLMs, and most of them were hallucinations. This indicates that models hallucinate much frequently when English questions are given..."
  - [section 6] "In the case of Gemma2 9B on Law domain, hallucinations are observed in the knowledge generated from CS question. According to the Civil Act of the Republic of Korea, individuals under the age of 14 can only enter into binding contracts with the consent of their legal guardians..."
- **Break condition:** If the LLM's hallucinations are not primarily caused by knowledge retrieval issues, or if code-switching does not improve the accuracy of knowledge retrieval, it will not reduce hallucinations.

## Foundational Learning

- **Concept:** Matrix Language Frame (MLF) model
  - **Why needed here:** The MLF model provides the theoretical foundation for understanding how code-switching works and how it can be applied to activate knowledge in LLMs. It explains the grammatical structure of code-switched text and how semantically important content from the embedded language is integrated into the matrix language.
  - **Quick check question:** What is the difference between the matrix language and the embedded language in the MLF model?

- **Concept:** Knowledge identification and leveraging
  - **Why needed here:** The study subdivides the knowledge activation process into two tasks: knowledge identification (evaluating the quality and relevance of identified knowledge) and knowledge leveraging (assessing whether the model can correctly answer questions using the identified knowledge). Understanding these concepts is crucial for evaluating the effectiveness of code-switching in activating knowledge.
  - **Quick check question:** What is the difference between knowledge identification and knowledge leveraging in the context of this study?

- **Concept:** Low-resource language tasks
  - **Why needed here:** The study focuses on the effectiveness of code-switching in activating knowledge for low-resource language tasks, where data scarcity is a significant challenge. Understanding the challenges and characteristics of low-resource language tasks is essential for appreciating the potential benefits of code-switching.
  - **Quick check question:** What are the main challenges in low-resource language tasks, and how can code-switching help address these challenges?

## Architecture Onboarding

- **Component map:** ENKOQA dataset (synthetic English-Korean code-switching QA) -> Multilingual LLMs (GPT-4o, GPT-3.5, Claude 3.5, Solar, Llama3, Gemma2) -> Knowledge Identification Task (faithfulness and helpfulness evaluation) -> Knowledge Leveraging Task (QA accuracy evaluation)
- **Critical path:** Synthesize ENKOQA dataset using MLF model → Prompt LLMs with code-switched questions → Evaluate knowledge identification (human and LLM-as-judge) → Assess knowledge leveraging (QA accuracy) → Compare against English and translated Korean baselines
- **Design tradeoffs:** The main design tradeoff is between the quality and naturalness of the code-switching dataset and the computational cost of generating and evaluating it. Using a high-quality translation model (gpt-3.5-turbo) and manual supervision can ensure the quality of the dataset, but it also increases the cost and time required for dataset construction.
- **Failure signatures:** Failure signatures include: (1) the LLM performs worse on code-switched questions compared to English or translated Korean questions, (2) the identified knowledge is not faithful or helpful, (3) the LLM fails to answer questions correctly even when given relevant knowledge, and (4) the code-switching dataset is not natural or grammatically correct.
- **First 3 experiments:**
  1. Evaluate the LLM's performance on code-switched questions versus English and translated Korean questions in a simple QA task.
  2. Conduct human evaluation of the quality of the identified knowledge from code-switched and English questions.
  3. Assess the LLM's ability to answer questions correctly using the identified knowledge from code-switched and English questions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does code-switching activation generalize across language pairs beyond English-Korean, and what linguistic factors influence its effectiveness?
- Basis in paper: [inferred] The paper focuses specifically on English-Korean code-switching but suggests the methodology could be "generalizable to all languages" and calls for research on "other language settings."
- Why unresolved: The study only examines one language pair, leaving unclear whether the observed knowledge activation effects are specific to English-Korean or represent a broader phenomenon. Different language pairs have varying syntactic distances, cultural proximity, and resource availability that could affect outcomes.
- What evidence would resolve it: Systematic experiments comparing code-switching effectiveness across multiple language pairs (e.g., English-Spanish, English-Chinese, English-Arabic) while controlling for cultural proximity, syntactic similarity, and resource availability.

### Open Question 2
- How does the timing and method of code-switching implementation (pre-training vs. instruction-tuning vs. prompting) affect knowledge activation in LLMs?
- Basis in paper: [explicit] The paper mentions future directions including "its role in pretraining and instruction-tuning" and focuses on prompting with code-switched text.
- Why unresolved: The current study only examines prompting with pre-existing code-switched text. The paper acknowledges that "augmenting low-resource datasets into code-switching text can amplify resource and mitigate data scarcity" but doesn't explore when during the LLM development cycle code-switching is most effective.
- What evidence would resolve it: Controlled experiments comparing knowledge activation when code-switching is incorporated during pre-training, fine-tuning, and only at inference time, measuring both performance and computational efficiency.

### Open Question 3
- What is the relationship between code-switching effectiveness and the linguistic competence level of LLMs in the target language?
- Basis in paper: [inferred] The paper assumes LLMs are "fairly competent in Korean" and shows varying effectiveness across different model families (GPT-4o/Claude perform better than Llama3/Gemma2), suggesting competence may play a role.
- Why unresolved: While the paper shows that more advanced models (GPT-4o, Claude) demonstrate stronger code-switching benefits, it doesn't systematically analyze how baseline language competence correlates with code-switching effectiveness or whether there's a threshold effect.
- What evidence would resolve it: Detailed analysis correlating models' baseline performance on monolingual tasks in the target language with their relative improvement when using code-switched prompts, potentially revealing competence thresholds or saturation points.

## Limitations
- The study relies on synthetic data generation using translation models, which may not capture authentic code-switching patterns found in natural bilingual communication
- The evaluation framework depends on both human judgments and LLM-as-a-judge methods, where human evaluation criteria are not fully specified
- The effectiveness varies significantly across domains and model families, suggesting context-dependent benefits rather than universal improvements

## Confidence
- **High Confidence**: The observation that code-switching outperforms English baselines in knowledge identification tasks, particularly in History and Tradition domains, is well-supported by both human and LLM-based evaluations with clear statistical significance.
- **Medium Confidence**: The claim that code-switching reduces hallucinations is supported by observed error patterns but could be influenced by the specific datasets and models used. The mechanism linking code-switching to reduced hallucinations needs further validation.
- **Medium Confidence**: The general superiority of code-switching over translated Korean baselines is demonstrated, but the effect size varies significantly across domains and models, suggesting context-dependent effectiveness.

## Next Checks
1. **Natural Code-Switching Validation**: Collect and evaluate a dataset of naturally occurring English-Korean code-switched questions from bilingual speakers to compare against the synthetic ENKOQA dataset, validating whether the synthetic approach captures authentic code-switching patterns.
2. **Cross-Lingual Generalization Test**: Replicate the experiments with code-switching between English and other low-resource languages (e.g., English-Vietnamese or English-Hindi) to determine if the observed benefits generalize beyond the English-Korean pair.
3. **Hallucination Mechanism Analysis**: Conduct controlled experiments isolating knowledge retrieval from generation phases to determine whether code-switching specifically improves knowledge retrieval accuracy or if the observed hallucination reduction stems from other factors in the generation process.