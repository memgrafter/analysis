---
ver: rpa2
title: 'RAM: Replace Attention with MLP for Efficient Multivariate Time Series Forecasting'
arxiv_id: '2410.24023'
source_url: https://arxiv.org/abs/2410.24023
tags:
- attention
- forecasting
- time
- performance
- spatial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes RAM (Replace Attention with MLP), a method to
  replace attention mechanisms in multivariate time series forecasting models with
  simpler MLPs containing feedforward layers, residual connections, and layer normalization.
  This approach aims to reduce computational complexity while maintaining performance.
---

# RAM: Replace Attention with MLP for Efficient Multivariate Time Series Forecasting

## Quick Facts
- arXiv ID: 2410.24023
- Source URL: https://arxiv.org/abs/2410.24023
- Reference count: 38
- Replaces attention with MLPs to reduce computational complexity while maintaining forecasting performance

## Executive Summary
RAM (Replace Attention with MLP) proposes replacing attention mechanisms in multivariate time series forecasting models with simpler MLPs containing feedforward layers, residual connections, and layer normalization. This approach achieves significant reductions in FLOPs (62.579% for spatio-temporal and 42.233% for long-term forecasting) with minimal performance drops (less than 2.5% and 2% respectively). The method demonstrates that attention mechanisms are not essential for effective forecasting in these tasks, with the core components being the MLP structure rather than attention.

## Method Summary
The RAM approach replaces attention modules in multivariate time series forecasting models with MLPs containing feedforward layers, residual connections, and layer normalization. This is applied to both spatio-temporal and long-term forecasting models, replacing attention mechanisms in both encoder and decoder structures. The method is tested on various models including ASTGNN, STAEFormer, PatchTST, and iTransformer across multiple datasets including METR-LA, PEMS-BAY, Weather, Traffic, and Electricity. The key insight is that attention matrices are not essential for effective forecasting, and the embedding of input features and linear transformations are more critical than explicitly modeling temporal and channel dependencies.

## Key Results
- Achieves 62.579% FLOPs reduction for spatio-temporal forecasting with less than 2.5% performance drop
- Achieves 42.233% FLOPs reduction for long-term forecasting with less than 2% performance drop
- Demonstrates attention mechanisms can be replaced with MLPs while maintaining strong inference performance

## Why This Works (Mechanism)

### Mechanism 1
The attention mechanism in multivariate time series forecasting models can be approximated by MLP components without significant performance degradation. Attention mechanisms compute pairwise interactions between elements, leading to O(nÂ²) complexity. The RAM approach replaces these computations with MLP layers (feedforward, residual connections, layer normalization), reducing complexity to O(dmodel). The empirical results show that for STF models, this replacement leads to a 62.579% reduction in FLOPs with less than 2.5% performance drop, and for LTSF models, a 42.233% FLOPs reduction with less than 2% performance drop.

### Mechanism 2
The core components for effective forecasting are the MLP structure rather than the attention mechanism. The RAM approach demonstrates that attention matrices in both temporal and spatial modules are not essential for effective forecasting. By replacing attention with MLP components, the model maintains strong inference performance without requiring pre-training or fine-tuning. This suggests that the embedding of input features and linear transformations are more critical than explicitly modeling temporal and channel dependencies through scaled dot-product attention.

### Mechanism 3
Attention mechanisms in both encoder and decoder structures can be safely removed without degrading performance. The RAM approach shows that attention in the decoder is the same as the attention in the encoder and can be safely removed. Replacing the attention mechanism with MLP without modifying the encoder structure will cause a performance drop, but removing the attention mechanism in both the encoder and decoder will cause a major performance drop. This indicates that the attention mechanism is not essential for effective forecasting.

## Foundational Learning

- **Concept**: Attention mechanisms in transformer models
  - Why needed here: Understanding how attention mechanisms work is crucial for grasping why their replacement with MLPs can be effective in certain scenarios
  - Quick check question: What is the computational complexity of the standard attention mechanism, and how does it compare to the complexity of an MLP?

- **Concept**: Graph Convolutional Networks (GCNs) and their relation to attention mechanisms
  - Why needed here: The paper demonstrates that GCN modules used for spatial correlations are essentially modified attention mechanisms, so understanding this relationship is key to understanding the RAM approach
  - Quick check question: How does a GCN layer implementation relate to a single-head attention mechanism applied along the node dimension?

- **Concept**: Time series forecasting and the specific challenges of multivariate time series
  - Why needed here: The RAM approach is specifically designed for multivariate time series forecasting, so understanding the unique challenges of this domain is essential for appreciating the approach's significance
  - Quick check question: What are the key differences between univariate and multivariate time series forecasting, and why do these differences matter for model design?

## Architecture Onboarding

- **Component map**: Input embedding layer -> Encoder (MLP modules) -> Decoder (linear projection) -> Output layer
- **Critical path**:
  1. Input data passes through the embedding layer
  2. Embedded data is processed by the encoder, which uses MLP components to model spatial and temporal associations
  3. Encoded data is passed to the decoder, which is simplified to a linear projection or convolutional layer
  4. Decoded data is output as the final forecast

- **Design tradeoffs**:
  - Complexity vs. performance: Replacing attention with MLP significantly reduces computational complexity but may lead to minor performance drops
  - Model size vs. accuracy: The RAM approach reduces model size, which can be beneficial for deployment on resource-constrained devices but may impact accuracy
  - Interpretability vs. performance: MLPs may be more interpretable than attention mechanisms, but the specific tradeoffs depend on the implementation

- **Failure signatures**:
  - Significant performance degradation compared to attention-based models
  - Inability to capture complex multivariate dependencies in the data
  - Overfitting on smaller datasets due to reduced model complexity

- **First 3 experiments**:
  1. Implement the RAM approach on a simple multivariate time series forecasting dataset and compare performance to a baseline attention-based model
  2. Gradually increase the complexity of the dataset and observe how the RAM approach performs compared to attention-based models
  3. Experiment with different MLP architectures (e.g., varying the number of layers, hidden dimensions) to find the optimal configuration for the RAM approach

## Open Questions the Paper Calls Out

- **Open Question 1**: What are the fundamental limitations of attention mechanisms in multivariate time series forecasting, and under what specific conditions do they become redundant? While the paper shows attention replacement works well in tested scenarios, it doesn't fully characterize the boundary conditions where attention mechanisms remain necessary versus where they become redundant.

- **Open Question 2**: How does the effectiveness of attention mechanisms vary with the number of variables/nodes in multivariate time series data? The paper observes that performance drops are more pronounced for datasets with more nodes, suggesting attention mechanisms play a more important role in capturing spatial dependencies when the number of variables increases.

- **Open Question 3**: Can the insights from attention-MLP replacement in time series forecasting be generalized to other domains like computer vision and natural language processing? The paper explicitly suggests this as a direction for future research, noting that similar questions could be asked about the effectiveness of attention mechanisms in other domains.

## Limitations

- The effectiveness of RAM may vary depending on the specific characteristics of multivariate time series datasets
- The paper does not explore whether certain types of attention mechanisms (e.g., sparse attention patterns) might be more effective to retain while replacing others
- Computational efficiency gains are measured in terms of FLOPs reduction, but real-world runtime performance may vary depending on hardware and implementation specifics

## Confidence

- **High confidence**: The core finding that attention mechanisms can be replaced with MLPs for multivariate time series forecasting with minimal performance degradation is well-supported by the experimental results
- **Medium confidence**: The generalizability of these findings to other time series domains and the potential for further optimization of the MLP architecture
- **Low confidence**: The paper's claim that "attention is not essential" for all multivariate time series forecasting tasks without acknowledging potential domain-specific exceptions

## Next Checks

1. Test RAM on datasets with known strong multivariate dependencies (e.g., financial time series with complex cross-asset correlations) to verify the approach's effectiveness in scenarios where attention mechanisms might be more critical
2. Compare RAM's performance against state-of-the-art linear models like vLinear on the same datasets to establish whether the MLP approach offers advantages over simpler alternatives
3. Conduct ablation studies to determine which components of the MLP architecture (feedforward layers, residual connections, layer normalization) are most critical for maintaining performance after attention removal