---
ver: rpa2
title: 'Confabulation: The Surprising Value of Large Language Model Hallucinations'
arxiv_id: '2406.04175'
source_url: https://arxiv.org/abs/2406.04175
tags:
- arxiv
- hallucination
- narrative
- narrativity
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the phenomenon of hallucinations in large
  language models (LLMs), reframing them as "confabulations" with potential value
  rather than categorically negative flaws. The authors argue that confabulations,
  like human confabulations, arise from a narrative impulse to generate coherent and
  substantive outputs, even when factual information is lacking.
---

# Confabulation: The Surprising Value of Large Language Model Hallucinations

## Quick Facts
- arXiv ID: 2406.04175
- Source URL: https://arxiv.org/abs/2406.04175
- Reference count: 24
- Primary result: LLM hallucinations exhibit significantly higher narrativity and coherence than veridical outputs

## Executive Summary
This paper challenges the conventional view of LLM hallucinations as purely negative errors by reframing them as "confabulations" with potential value. The authors argue that confabulations arise from a narrative impulse similar to human storytelling, generating coherent and substantive outputs even when factual information is lacking. Through empirical analysis of three hallucination benchmarks, they demonstrate that hallucinated responses consistently show higher narrativity scores than factual responses, with a significant positive correlation between narrativity and semantic coherence. This suggests that the tendency to confabulate may be intrinsically linked to an LLM's capacity for coherent narrative generation.

## Method Summary
The study analyzes three popular hallucination benchmarks (FaithDial, BEGIN, and HaluEval) to compare narrativity and coherence between hallucinated and veridical responses. Narrativity is measured using an ELECTRA-large model fine-tuned on Reddit narrative detection, while coherence is evaluated using the DEAM metric (RoBERTa-large fine-tuned on semantic perturbations). The authors compute narrativity and coherence scores for all responses, then perform statistical analysis including beta regression and logistic regression to examine correlations. Results are visualized through distribution plots showing narrativity scores across different hallucination categories.

## Key Results
- Hallucinated responses show consistently higher narrativity scores (0.620-0.658) than partial and non-hallucination categories across all three datasets
- A significant positive correlation exists between narrativity and coherence scores across all benchmark datasets
- The tendency to confabulate appears intrinsically linked to the capacity for coherent narrative generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hallucinations are reframed as confabulations, which are inherently tied to narrative generation and coherence
- Mechanism: The LLM's tendency to confabulate is rooted in a narrative impulse that drives coherent text generation, even when factual information is lacking
- Core assumption: Confabulations mirror human storytelling tendencies, which are cognitive resources for sense-making and communication
- Evidence anchors:
  - [abstract] The authors argue that confabulations arise from a narrative impulse to generate coherent and substantive outputs
  - [section 2.2] Confabulation is defined as a narrative impulse to schematize information into self-consistent stories, even when details are insufficient
- Break condition: If the narrative-rich outputs are not found to be more coherent or persuasive than factual outputs, the reframing loses its value

### Mechanism 2
- Claim: Higher narrativity in confabulated outputs correlates with higher coherence in dialogue
- Mechanism: The internal consistency and persuasiveness of narratives make them effective tools for maintaining coherence in communication, which LLMs leverage when generating confabulations
- Core assumption: Narratives provide beneficial cognitive and social effects, making confabulated outputs more engaging and coherent
- Evidence anchors:
  - [section 4.0.1] Empirical results show a significant positive correlation between narrativity and coherence across all three benchmark datasets
  - [section 4.1.1] Narrative theory suggests that storytelling is pivotal in maintaining discourse-level coherence
- Break condition: If coherence metrics do not align with narrativity scores, the narrative coherence hypothesis is weakened

### Mechanism 3
- Claim: Reframing hallucinations as confabulations opens new research avenues for leveraging LLM outputs constructively
- Mechanism: By viewing confabulations as narrative-rich behaviors, researchers can explore their utility in creative, educational, and exploratory applications
- Core assumption: Confabulations, when bounded and understood, can serve as cognitive resources for sense-making and innovation
- Evidence anchors:
  - [section 1] The paper outlines potential applications where confabulations could be valuable, such as creative writing and legal analogies
  - [section 5] Future research directions include human evaluations and exploring utility in domains like journalism and advertising
- Break condition: If human evaluations do not validate the benefits of narrative engagement, the constructive reframing loses practical relevance

## Foundational Learning

- Concept: Narrative theory and its role in communication
  - Why needed here: Understanding how narratives maintain coherence and persuade is key to interpreting why confabulations might be valuable
  - Quick check question: How does narrative coherence differ from factual accuracy in communication effectiveness?

- Concept: Cognitive narratology and mental models
  - Why needed here: The paper links confabulations to human cognitive processes, requiring knowledge of how stories shape thought and experience
  - Quick check question: What role do counterfactual scenarios play in enhancing the robustness of mental models?

- Concept: Evaluation metrics for narrativity and coherence
  - Why needed here: The empirical analysis relies on measuring narrativity and coherence, necessitating familiarity with these metrics
  - Quick check question: How does the ELECTRA-based narrativity model generalize to dialogue contexts?

## Architecture Onboarding

- Component map: FaithDial/BEGIN/HaluEval datasets -> ELECTRA narrativity model -> DEAM coherence model -> Beta/logistic regression analysis -> Visualization

- Critical path:
  1. Load and preprocess dialogue datasets
  2. Compute narrativity scores using the fine-tuned ELECTRA model
  3. Compute coherence scores using the DEAM model
  4. Aggregate and analyze results with regression models
  5. Visualize distributions and correlations

- Design tradeoffs:
  - Using ELECTRA vs. other models for narrativity detection
  - Aggregating partial hallucinations with full hallucinations for analysis
  - Balancing computational cost vs. model performance in fine-tuning

- Failure signatures:
  - Low correlation between narrativity and coherence scores
  - Inconsistent narrativity scores across different dialogue datasets
  - Overfitting in the fine-tuned models during evaluation

- First 3 experiments:
  1. Validate narrativity model on a held-out Reddit dataset to ensure generalization
  2. Test coherence model on synthetic incoherent dialogues to confirm sensitivity
  3. Compare narrativity-coherence correlation across different aggregation strategies for partial hallucinations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different types of confabulations (e.g., creative vs. deceptive) vary in their narrativity and semantic coherence?
- Basis in paper: [inferred] The paper distinguishes between different types of hallucinations/confabulations but does not explicitly analyze how their narrativity and coherence differ
- Why unresolved: The paper provides a general finding that confabulated texts have higher narrativity and coherence, but does not delve into specific subtypes of confabulations
- What evidence would resolve it: Empirical studies comparing narrativity and coherence scores across different types of confabulations (e.g., creative, deceptive, or factual confabulations) would provide insights into their varying characteristics

### Open Question 2
- Question: What are the cognitive mechanisms underlying the generation of narratively rich confabulations in LLMs?
- Basis in paper: [inferred] The paper draws parallels between human confabulation and LLM confabulation but does not explore the underlying cognitive processes
- Why unresolved: The paper focuses on the outcomes of confabulation (narrativity and coherence) rather than the processes that lead to their generation
- What evidence would resolve it: Neuroscientific studies or computational models that investigate the neural or algorithmic processes involved in generating narratively rich confabulations in LLMs would shed light on the cognitive mechanisms

### Open Question 3
- Question: How does the narrativity of confabulations affect user perception and trust in LLM outputs?
- Basis in paper: [explicit] The paper mentions that higher narrativity is associated with higher coherence, but does not explore its impact on user perception and trust
- Why unresolved: The paper acknowledges the potential benefits of narrativity but does not empirically investigate its effects on user experience
- What evidence would resolve it: User studies comparing the perceived trustworthiness and usefulness of high-narrativity confabulations versus low-narrativity but factual outputs would provide insights into the impact of narrativity on user perception

## Limitations
- The correlation between narrativity and coherence does not establish causation and may mask other underlying model behaviors
- Partial and full hallucinations are aggregated together, potentially obscuring important distinctions
- The study relies solely on automatic evaluation metrics without human validation of perceived coherence or value

## Confidence

- **High Confidence**: The empirical finding that hallucinated responses exhibit significantly higher narrativity scores than veridical responses across all three benchmark datasets is well-supported by the data and statistical analysis
- **Medium Confidence**: The positive correlation between narrativity and coherence scores is supported by the regression analysis, but the practical significance and causal relationship remain uncertain
- **Medium Confidence**: The reframing of hallucinations as confabulations with potential value is conceptually interesting and supported by theoretical arguments, but lacks comprehensive human evaluation to validate its practical utility

## Next Checks
1. **Human Evaluation Study**: Conduct a human study comparing human perception of coherence and narrative quality between hallucinated and veridical responses, controlling for factual accuracy to isolate the effects of narrativity

2. **Partial vs. Full Hallucination Analysis**: Re-analyze the datasets separately for partial and full hallucinations to determine if the narrativity-coherence relationship differs between these categories, potentially revealing distinct mechanisms

3. **Cross-Dataset Validation**: Test whether the narrativity-coherence correlation holds across additional datasets beyond the three examined (FaithDial, BEGIN, HaluEval) to assess generalizability of the findings