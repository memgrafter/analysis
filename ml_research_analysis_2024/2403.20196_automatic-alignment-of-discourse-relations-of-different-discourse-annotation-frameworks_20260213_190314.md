---
ver: rpa2
title: Automatic Alignment of Discourse Relations of Different Discourse Annotation
  Frameworks
arxiv_id: '2403.20196'
source_url: https://arxiv.org/abs/2403.20196
tags:
- label
- relations
- discourse
- pdtb
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a fully automatic approach for aligning discourse
  relations from different annotation frameworks (RST and PDTB) without requiring
  manual matching of arguments. The core idea is to learn label embeddings during
  discourse relation classification using label-anchored contrastive learning, then
  compare these embeddings to discover correlations between relations across frameworks.
---

# Automatic Alignment of Discourse Relations of Different Discourse Annotation Frameworks

## Quick Facts
- arXiv ID: 2403.20196
- Source URL: https://arxiv.org/abs/2403.20196
- Authors: Yingxue Fu
- Reference count: 0
- Achieves 63.13% accuracy and 47.95 F1 score on discourse relation classification by combining aligned RST and PDTB data

## Executive Summary
This paper presents a fully automatic approach for aligning discourse relations from different annotation frameworks (RST and PDTB) without requiring manual matching of arguments. The core innovation is using label-anchored contrastive learning to learn label embeddings during discourse relation classification, then comparing these embeddings to discover correlations between relations across frameworks. The method handles segmentation differences between frameworks by focusing on relation labels rather than argument spans, enabling cross-framework mapping through semantic similarity in a shared embedding space.

## Method Summary
The method extends label-anchored contrastive learning to learn label embeddings during discourse relation classification. It uses a combination of instance-centered contrastive loss, label-centered contrastive loss, and cross-entropy losses during training. After training, the average input representations for each class serve as class representation proxies, and the correlation between these proxies and the learned label embeddings (measured by cosine similarity) indicates how well the embeddings capture class semantics. The approach is evaluated intrinsically by measuring the quality of learned label embeddings and extrinsically by showing that relabeling PDTB data using the learned alignments and combining it with RST data improves discourse relation classification performance.

## Key Results
- Learns label embeddings that correlate well with class representation proxies (mean cosine similarity of 0.47)
- Achieves 63.13% accuracy and 47.95 F1 score on discourse relation classification
- Handles segmentation differences between frameworks without requiring manual argument matching
- Shows improvement over baseline methods when combining aligned RST and PDTB data

## Why This Works (Mechanism)

### Mechanism 1
The method learns label embeddings that capture semantic correlations between discourse relations across different frameworks without requiring manual argument matching. Label-anchored contrastive learning is applied during discourse relation classification, with losses that pull instances of the same class together and push different classes apart in embedding space. This assumes discourse relations across frameworks share semantic similarities that can be captured in a shared embedding space, even when segmentation criteria differ.

### Mechanism 2
The learned label embeddings serve as proxies for relation classes, enabling automatic mapping between different annotation frameworks. After training, the average input representations for each class serve as class representation proxies. The correlation between these proxies and the learned label embeddings (measured by cosine similarity) indicates how well the embeddings capture class semantics, assuming the embeddings should be more correlated with their own class representation proxies than with other classes' proxies.

### Mechanism 3
The method handles segmentation differences between frameworks by focusing on relation labels rather than argument spans. By learning label embeddings directly during classification and comparing them, the method bypasses the need to match arguments/EDUs across frameworks, which is complicated by different segmentation criteria. This assumes the relation labels themselves contain enough semantic information to enable cross-framework alignment, regardless of how arguments are segmented.

## Foundational Learning

- Concept: Contrastive learning and embedding spaces
  - Why needed here: The method relies on learning label embeddings in a shared space where semantically similar relations are close together, enabling cross-framework mapping
  - Quick check question: Can you explain how contrastive loss functions work to pull similar instances together and push dissimilar ones apart in embedding space?

- Concept: Multi-task learning with classification and representation learning
  - Why needed here: The method trains both a classifier and learns label embeddings simultaneously, requiring understanding of how different loss functions interact
  - Quick check question: How do you balance multiple loss functions during training, and what happens if one dominates the others?

- Concept: Correlation metrics and their interpretation
  - Why needed here: The quality of learned label embeddings is evaluated using correlation matrices, requiring understanding of how to interpret these metrics
  - Quick check question: What does it mean if the diagonal values in a correlation matrix are high but the off-diagonal values are also high?

## Architecture Onboarding

- Component map: Input encoder (BERT-based) -> Label encoder (BERT/RoBERTa/Random) -> Loss functions (Instance-centered contrastive, Label-centered contrastive, Cross-entropy) -> Correlation computation

- Critical path: 1) Preprocess data to extract argument pairs and relation labels; 2) Initialize models and optimizers; 3) Train with combined loss functions; 4) Generate class representation proxies from test set; 5) Compute correlation matrix to evaluate label embeddings; 6) Use cosine similarity between label embeddings for cross-framework mapping

- Design tradeoffs: Using pre-trained language models provides good initialization but increases computational cost; Random label initialization works well for classification but may not produce meaningful embeddings; Adding more loss functions can improve performance but may lead to overfitting with limited data; Data augmentation helps with data sparsity but introduces potential noise

- Failure signatures: Low correlation between label embeddings and class proxies (diagonal values in correlation matrix); High standard deviation across multiple runs indicating instability; Significant performance drop when combining data from different frameworks; Label embeddings clustering together in visualization, indicating lack of discrimination

- First 3 experiments: 1) Train with all loss functions on PDTB explicit relations only, evaluate correlation matrix quality; 2) Compare different label encoder options (BERT, RoBERTa, Random) on the same data; 3) Apply the best-performing configuration to RST data with and without data augmentation, compare results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed method handle more than two annotation frameworks simultaneously?
- Basis in paper: The paper focuses on aligning RST and PDTB frameworks, but mentions "enabling interoperability of discourse corpora annotated under different frameworks" in the abstract.
- Why unresolved: The method is evaluated only on two frameworks, and it's unclear whether the label embedding approach can scale to multiple frameworks with different relation inventories and structural constraints.
- What evidence would resolve it: Experiments applying the method to three or more annotation frameworks (e.g., RST, PDTB, and SDRT) with evaluation of the quality of learned embeddings and alignment accuracy.

### Open Question 2
- Question: How does the performance of the proposed method compare to expert knowledge-based approaches for discourse relation alignment?
- Basis in paper: The paper claims to eliminate the need for expert knowledge and manual examination, but doesn't directly compare its results to expert-annotated alignments.
- Why unresolved: While the method is fully automatic, it's unclear if the alignments it produces are as accurate or meaningful as those created by domain experts who understand the nuances of different frameworks.
- What evidence would resolve it: A comparison of the proposed method's alignments with gold-standard alignments created by expert annotators, measuring both accuracy and agreement with expert judgments.

### Open Question 3
- Question: What is the impact of discourse relation alignment on downstream tasks beyond classification?
- Basis in paper: The paper mentions benefits of incorporating discourse relations in downstream tasks like sentiment analysis, text summarization, and machine comprehension, but only evaluates the alignment method on discourse relation classification.
- Why unresolved: The paper doesn't investigate whether the aligned discourse relations improve performance on other NLP tasks that benefit from discourse understanding.
- What evidence would resolve it: Experiments showing improvements in downstream tasks (e.g., summarization quality, sentiment analysis accuracy) when using aligned discourse relations from multiple frameworks versus using a single framework's relations.

## Limitations
- The method relies on manually defined subsets of relations (16 from each framework with >100 instances), potentially missing nuanced alignments for less frequent relations
- Performance is sensitive to hyperparameter choices and initialization, with results reported as averages over multiple runs but with considerable variance
- The approach assumes semantic similarity between relations across frameworks can be captured in a shared embedding space, which may not hold for fundamentally different annotation philosophies

## Confidence
The approach demonstrates Medium confidence for cross-framework alignment quality, as the correlation matrices show reasonable diagonal dominance (mean cosine similarity of 0.47 between label embeddings and their class proxies) but with notable off-diagonal values indicating some ambiguity in relation mappings. The extrinsic evaluation shows modest improvement (63.13% accuracy, 47.95 F1) over baseline methods, suggesting the learned alignments are useful but not perfect.

## Next Checks
1. Evaluate the method on a gold-standard parallel corpus (if available) to measure alignment accuracy against ground truth mappings between RST and PDTB relations
2. Perform ablation studies removing each loss component to quantify their individual contributions to label embedding quality and alignment performance
3. Test the transferability of learnt alignments to other discourse frameworks (e.g., Segmented Discourse Representation Theory) to assess generalizability beyond RST-PDTB mapping