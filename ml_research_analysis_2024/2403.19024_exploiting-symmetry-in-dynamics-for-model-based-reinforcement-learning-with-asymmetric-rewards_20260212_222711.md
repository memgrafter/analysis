---
ver: rpa2
title: Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with
  Asymmetric Rewards
arxiv_id: '2403.19024'
source_url: https://arxiv.org/abs/2403.19024
tags:
- symmetry
- learning
- dynamics
- symmetries
- group
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for learning dynamical models that
  are, by construction, invariant under specified continuous symmetries using Cartan's
  moving frame method. The key idea is to transform states and actions to their canonical
  forms corresponding to elements of the symmetry group, and then learn a function
  operating on these lower-dimensional canonical forms.
---

# Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards

## Quick Facts
- arXiv ID: 2403.19024
- Source URL: https://arxiv.org/abs/2403.19024
- Authors: Yasin Sonmez; Neelay Junnarkar; Murat Arcak
- Reference count: 23
- Key outcome: Method learns dynamics models invariant to specified symmetries using Cartan's moving frame method, achieving lower observation error especially with fewer neural network parameters.

## Executive Summary
This paper proposes a method for learning dynamical models that are invariant under specified continuous symmetries using Cartan's moving frame method. The approach transforms states and actions to canonical forms corresponding to elements of the symmetry group, then learns a function operating on these lower-dimensional canonical forms. The method is evaluated on two environments - "Parking" and "Reacher" - showing that it achieves lower observation error compared to baseline methods without symmetry, particularly when neural networks have fewer parameters. The work extends the applicability of symmetry techniques to problems where dynamics exhibit symmetries but rewards do not.

## Method Summary
The method uses Cartan's moving frame to learn dynamics models that are, by construction, invariant to specified symmetries. It transforms states and actions to their canonical forms in a lower-dimensional space, then learns a function operating on these canonical forms. This approach reduces the input dimension of the neural network, improving sample efficiency. The method is particularly effective when dynamics and rewards exhibit different symmetries, broadening the scope of problems where symmetry techniques can be applied. The authors evaluate their approach on two environments with known continuous symmetries and compare performance against baseline methods.

## Key Results
- Method with symmetry achieves lower observation error compared to baseline without symmetry, especially with fewer neural network parameters
- For Parking environment, method outperforms baseline at lower parameter counts and learns faster with two hidden layers
- For Reacher environment, method achieves slightly better performance in all cases, most notably with one hidden layer

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proposed method learns dynamics models invariant to specified symmetries by transforming states and actions to canonical forms.
- Mechanism: The method uses Cartan's moving frame to map states to canonical forms in a lower-dimensional space, then learns a function operating on these canonical forms. This ensures the learned dynamics are, by construction, invariant to the specified symmetries.
- Core assumption: The state space can be split into complementary subspaces X_a and X_b, where X_a is acted upon by the symmetry group and X_b contains the canonical forms.
- Evidence anchors:
  - [abstract] "We use Cartan's moving frame method to introduce a technique for learning dynamics that, by construction, exhibit specified symmetries."
  - [section] "The premise of our method is to transform (x, u) to its canonical form, corresponding to an element of {(ϕg(x), ψg(u)) | g ∈ G}. When F in (1) is G-invariant, we parameterize it by a function that operates on these canonical forms, which reside in a lower-dimensional space."
- Break condition: The method fails if the moving frame map γ does not exist globally over the entire state space X, which can happen if the cross-section C is not well-defined or if the implicit function theorem cannot be applied.

### Mechanism 2
- Claim: Learning dynamics in the lower-dimensional canonical form space reduces the input dimension of the neural network, improving sample efficiency.
- Mechanism: By transforming the state and action to their canonical forms using the moving frame, the method effectively reduces the dimensionality of the input space to the neural network. This reduction in input dimension means fewer parameters are needed to achieve the same level of accuracy.
- Core assumption: The reduction in input dimension leads to a proportional reduction in the number of parameters needed for the neural network to achieve the same level of accuracy.
- Evidence anchors:
  - [abstract] "Numerical experiments demonstrate that the proposed method learns a more accurate dynamical model."
  - [section] "A side-benefit is that training is done with a lower dimensional input space (X^b × U instead of X × U)."
- Break condition: The method fails to improve sample efficiency if the reduction in input dimension does not lead to a significant reduction in the number of parameters needed, or if the complexity of the transformation offsets the benefits of dimensionality reduction.

### Mechanism 3
- Claim: The method is effective even when dynamics and reward exhibit different symmetries, broadening the scope of problems where symmetry can be applied.
- Mechanism: By focusing on symmetries in the dynamics independent of the reward function, the method can be applied to a wider range of problems where the dynamics exhibit symmetries but the reward function does not. This is particularly useful in multi-task learning scenarios where the same dynamical symmetries exist across tasks but the reward models change.
- Core assumption: The dynamics exhibit symmetries that are independent of the reward function, and these symmetries can be exploited to improve the learning of the dynamics model.
- Evidence anchors:
  - [abstract] "In this paper, we assume only the dynamics exhibit symmetry, extending the scope of problems in reinforcement learning and learning in control theory to which symmetry techniques can be applied."
  - [section] "A common assumption when using symmetry in RL and optimal control is that both the dynamics and reward (or cost) function exhibit the same symmetries... In many scenarios, however, symmetries in the dynamical model are not necessarily applicable to the reward model."
- Break condition: The method fails to broaden the scope of problems if the dynamics do not exhibit symmetries that are independent of the reward function, or if exploiting these symmetries does not lead to improved learning of the dynamics model.

## Foundational Learning

- Concept: Lie groups and their actions on manifolds
  - Why needed here: The method relies on Lie groups to represent the symmetries of the dynamical system. Understanding Lie groups and their actions on manifolds is crucial for applying Cartan's moving frame method.
  - Quick check question: Can you explain what a Lie group is and how it acts on a manifold?

- Concept: Cartan's moving frame method
  - Why needed here: The method uses Cartan's moving frame to construct a map from elements in the state space to their canonical forms. This is the key technique for enforcing symmetries in the learned dynamics model.
  - Quick check question: Can you describe the steps involved in applying Cartan's moving frame method to a given Lie group and state space?

- Concept: Neural network architecture and training
  - Why needed here: The method involves learning a function operating on the lower-dimensional canonical forms using a neural network. Understanding neural network architecture and training is necessary for implementing the method.
  - Quick check question: Can you explain how the input and output dimensions of the neural network are determined in the proposed method?

## Architecture Onboarding

- Component map: Cartan's moving frame method -> Lower-dimensional function -> Transformation back to original space

- Critical path:
  1. Define the Lie group representing the symmetries of the dynamical system.
  2. Apply Cartan's moving frame method to construct the map γ.
  3. Transform states and actions to their canonical forms using γ.
  4. Learn a function operating on the canonical forms using a neural network.
  5. Transform the learned dynamics back to the original state space using γ.

- Design tradeoffs:
  - Symmetry exploitation vs. model complexity: The method reduces model complexity by exploiting symmetries, but the complexity of the transformation using the moving frame must be considered.
  - Dimensionality reduction vs. information loss: The method reduces the input dimension of the neural network, but this may lead to some information loss if the canonical forms do not capture all relevant dynamics.

- Failure signatures:
  - Poor performance: If the learned dynamics model does not accurately capture the true dynamics, it may be due to an incorrect choice of Lie group or an error in applying Cartan's moving frame method.
  - High computational cost: If the method is computationally expensive, it may be due to a high-dimensional state space or a complex transformation using the moving frame.

- First 3 experiments:
  1. Implement the method on a simple dynamical system with known symmetries (e.g., a pendulum or a cart-pole system) and compare the learned dynamics model with a baseline method that does not exploit symmetries.
  2. Vary the number of parameters in the neural network and evaluate the impact on the accuracy of the learned dynamics model.
  3. Apply the method to a multi-task learning scenario where the same dynamical symmetries exist across tasks but the reward models change, and compare the performance with a baseline method that does not exploit symmetries.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical bound on the performance improvement when leveraging symmetries in model learning?
- Basis in paper: [inferred] The paper shows empirical improvements in observation error, especially with fewer parameters, but does not provide a theoretical analysis of the performance gains.
- Why unresolved: The authors demonstrate empirical benefits but do not provide a theoretical framework to quantify the extent of these benefits.
- What evidence would resolve it: A mathematical proof or analysis showing the expected performance improvement in terms of sample efficiency or convergence rate when using symmetry-based methods compared to standard methods.

### Open Question 2
- Question: How do discrete symmetries impact the effectiveness of the proposed method compared to continuous symmetries?
- Basis in paper: [explicit] The authors mention that future work could involve developing a theoretical framework that includes discrete symmetries.
- Why unresolved: The paper focuses on continuous symmetries using Cartan's moving frame method, but does not explore the potential benefits or challenges of incorporating discrete symmetries.
- What evidence would resolve it: Experimental results comparing the performance of the method with both discrete and continuous symmetries, and a theoretical analysis of how discrete symmetries can be integrated into the framework.

### Open Question 3
- Question: What is the impact of the proposed method on policy performance when used in conjunction with model-based reinforcement learning?
- Basis in paper: [inferred] The paper evaluates the method on dynamics learning but does not train policies using the learned models or assess their performance.
- Why unresolved: The authors focus on improving model accuracy but do not investigate whether these improvements translate to better policy performance in model-based RL.
- What evidence would resolve it: Experimental results showing the performance of policies trained using the proposed symmetry-enhanced models compared to policies trained with standard models, including metrics such as reward and sample efficiency.

## Limitations

- The method relies on the existence of a global moving frame map, which may not be possible for all Lie groups and state spaces
- The reduction in input dimensionality may lead to information loss if the canonical forms do not capture all relevant dynamics
- The method is only evaluated on two environments, and its performance on more complex tasks is unknown

## Confidence

- **High confidence** in the mechanism of using Cartan's moving frame method to enforce symmetries in the learned dynamics model
- **Medium confidence** in the effectiveness of the method in reducing observation error, as the results are only shown for two specific environments
- **Low confidence** in the generalizability of the method to more complex tasks and environments with different types of symmetries

## Next Checks

1. Evaluate the method on a more complex environment with a higher-dimensional state space and multiple types of symmetries
2. Investigate the impact of the reduction in input dimensionality on the learned dynamics model's ability to capture all relevant dynamics
3. Compare the method's performance with other state-of-the-art techniques for learning dynamical models with symmetries, such as those based on Lie algebra or equivariant neural networks