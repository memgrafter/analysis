---
ver: rpa2
title: 'NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise'
arxiv_id: '2406.04299'
source_url: https://arxiv.org/abs/2406.04299
tags:
- noise
- label
- pair
- graph
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NoisyGL, the first comprehensive benchmark
  for graph neural networks under label noise (GLN). The benchmark addresses the challenge
  of evaluating GLN methods due to variations in datasets, noise types, rates, and
  preprocessing techniques across existing studies.
---

# NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise

## Quick Facts
- arXiv ID: 2406.04299
- Source URL: https://arxiv.org/abs/2406.04299
- Reference count: 40
- Introduces NoisyGL, the first comprehensive benchmark for Graph Neural Networks under Label Noise (GLN)

## Executive Summary
NoisyGL addresses the challenge of evaluating Graph Neural Networks (GNNs) under label noise by providing a standardized benchmark. The benchmark includes 17 representative methods - 10 GLN methods to assess effectiveness on noisy labeled graph data, and 7 LLN methods to evaluate applicability in graph learning tasks. Through extensive experiments on 8 datasets with various noise types and rates, NoisyGL reveals that simply applying LLN methods cannot significantly improve GNN robustness, while existing GLN methods can alleviate label noise in specific scenarios. The benchmark also shows that negative effects of label noise can spread through graph structure, especially in sparse graphs, and that graph structure augmentation effectively mitigates this spread.

## Method Summary
NoisyGL introduces a comprehensive benchmark for evaluating Graph Neural Networks under Label Noise (GLN). The benchmark includes 8 datasets (Cora, Citeseer, Pubmed, DBLP, Amazon-Computers, Amazon-Photos, BlogCatalog, Flickr) with standardized backbones, APIs, data splitting, and processing strategies for fair comparisons. It evaluates 17 methods - 10 GLN methods and 7 LLN methods - under various noise types (pair and uniform) and rates (0% to 50%). The benchmark provides standardized experimental settings, hyperparameters, and evaluation metrics to enable reproducible and comparable results across studies.

## Key Results
- Simply applying LLN methods cannot significantly improve GNN robustness to label noise
- Existing GLN methods can alleviate label noise in their own applicable scenarios, with pair noise being the most harmful due to its misleading effects
- Negative effects of label noise can spread through graph structure, especially in sparse graphs, and graph structure augmentation effectively mitigates this spread

## Why This Works (Mechanism)
None provided

## Foundational Learning
- Graph Neural Networks (GNNs): Neural networks designed to operate on graph-structured data, aggregating information from neighboring nodes to make predictions. Needed because graphs represent complex relationships that traditional neural networks cannot capture.
- Label Noise: Incorrect or noisy labels in training data that can degrade model performance. Critical because real-world datasets often contain mislabeled instances.
- Graph Structure Augmentation: Techniques to enhance graph connectivity or node features to improve model robustness. Important for mitigating the negative effects of label noise spread through graph structure.
- Pair Noise: A type of label noise where a fraction of labels are flipped to another class, creating misleading training examples. Significant because it can severely impact model performance.
- Uniform Noise: A type of label noise where labels are randomly assigned to any class with equal probability. Relevant as it represents random corruption of labels.

## Architecture Onboarding

Component Map: Datasets (Cora, Citeseer, Pubmed, DBLP, Amazon-Computers, Amazon-Photos, BlogCatalog, Flickr) -> Preprocessing -> Noise Injection -> GNN Models -> Evaluation

Critical Path: Data loading and preprocessing -> Noise injection and data splitting -> Model training and validation -> Performance evaluation and comparison

Design Tradeoffs: The benchmark prioritizes standardization and reproducibility over flexibility, using fixed hyperparameters and experimental settings to enable fair comparisons across methods.

Failure Signatures: Out-of-memory errors on large datasets like PubMed, numerical instability in loss calculations with high noise rates, and inconsistent results due to unspecified random seeds.

First Experiments:
1. Run experiments for a specific GLN method (e.g., GraphSMOTE) on the Cora dataset with 20% pair noise
2. Compare the performance of a GLN method and an LLN method (e.g., Co-teaching) on the Citeseer dataset with 30% uniform noise
3. Evaluate the impact of graph structure augmentation on a GNN model's robustness to label noise on the Pubmed dataset

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How do GLN methods perform on heterogeneous graphs with varying node types and edge types?
- Basis in paper: The authors note that most GLN methods struggle with heterogeneous graphs like Flickr, and the benchmark primarily uses homogeneous graphs.
- Why unresolved: The current benchmark lacks a diverse set of heterogeneous graph datasets to thoroughly evaluate GLN methods in this context.
- What evidence would resolve it: Extending the benchmark to include more heterogeneous graph datasets and evaluating the performance of GLN methods on these datasets would provide insights into their effectiveness on heterogeneous graphs.

### Open Question 2
- Question: What is the impact of different label noise types, such as instance-dependent label noise, on the performance of GLN methods?
- Basis in paper: The authors mention that most GLN studies focus on pair noise and uniform noise, but there is limited research on instance-dependent label noise.
- Why unresolved: The benchmark primarily focuses on pair noise and uniform noise, leaving the impact of other noise types unexplored.
- What evidence would resolve it: Incorporating different types of label noise, such as instance-dependent noise, into the benchmark and evaluating the performance of GLN methods under these conditions would shed light on their robustness to various noise types.

### Open Question 3
- Question: How do GLN methods perform on graph learning tasks beyond node classification, such as link prediction or graph classification?
- Basis in paper: The authors note that most GLN studies focus on node classification tasks, with limited research on other graph learning tasks.
- Why unresolved: The benchmark primarily focuses on node classification, leaving the performance of GLN methods on other tasks unexplored.
- What evidence would resolve it: Extending the benchmark to include other graph learning tasks, such as link prediction or graph classification, and evaluating the performance of GLN methods on these tasks would provide insights into their applicability to a broader range of graph learning problems.

## Limitations
- Exact hyperparameter values used in the original experiments are not specified
- Random seeds for data splitting and noise generation are not provided
- Lack of statistical significance tests or confidence intervals for reported performance differences

## Confidence
- Reproducibility: Medium (due to unspecified hyperparameters and random seeds)
- Methodology: High (well-designed benchmark with standardized experimental settings)
- Claims: Medium (lack of statistical validation for reported findings)

## Next Checks
1. Verify the exact hyperparameter values used in the original experiments by checking the source code or contacting the authors
2. Run the experiments with multiple random seeds to assess the variability in the results
3. Perform statistical significance tests (e.g., t-tests) to validate the reported differences in performance between methods