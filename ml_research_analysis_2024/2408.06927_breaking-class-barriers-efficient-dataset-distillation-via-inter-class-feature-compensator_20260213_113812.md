---
ver: rpa2
title: 'Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature
  Compensator'
arxiv_id: '2408.06927'
source_url: https://arxiv.org/abs/2408.06927
tags:
- dataset
- distillation
- infer
- synthetic
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses dataset distillation by rethinking the prevailing
  "one label per instance" paradigm. This paradigm creates inefficiencies and overlooks
  inter-class features.
---

# Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator

## Quick Facts
- arXiv ID: 2408.06927
- Source URL: https://arxiv.org/abs/2408.06927
- Authors: Xin Zhang; Jiawei Du; Ping Liu; Joey Tianyi Zhou
- Reference count: 37
- Primary result: Achieves state-of-the-art dataset distillation performance with 34.5% improvement over SRe2L on ImageNet-1k using ResNet18

## Executive Summary
This paper addresses dataset distillation by challenging the conventional "one label per instance" paradigm that creates inefficiencies in synthetic data generation. The proposed INFER method introduces a Universal Feature Compensator (UFC) that integrates inter-class features, enabling multiple synthetic instances to be generated from a single UFC input. This approach significantly improves distillation budget efficiency while maintaining or enhancing model performance across benchmark datasets.

## Method Summary
The INFER method generates synthetic datasets by integrating natural instances with Universal Feature Compensators (UFC) that capture inter-class features. For each class, one natural instance is selected and combined with UFCs to create synthetic data. Multiple neural network architectures are used to generate UFCs and relabel the synthetic data through averaging. MixUp augmentation is applied using static soft labels, and the synthetic dataset is used to train target models. The approach achieves state-of-the-art performance across CIFAR-10/100, Tiny-ImageNet, and ImageNet-1k.

## Key Results
- Achieves 34.5% improvement over SRe2L on ImageNet-1k with same compression level using ResNet18
- Demonstrates significant compression ratio improvements across all benchmark datasets
- Maintains high classification accuracy while substantially reducing synthetic dataset size
- Shows effectiveness of inter-class feature integration through UFC mechanism

## Why This Works (Mechanism)

### Mechanism 1: Inter-Class Feature Integration via UFC
The Universal Feature Compensator (UFC) integrates inter-class features by being added to natural instances from different classes. UFC carries features that span multiple classes, and when added to one instance from each class, the resulting synthetic instance gains enriched features that bridge class boundaries. This works because features that span classes are learnable and beneficial for decision boundary clarity.

### Mechanism 2: Static Soft Labels with MixUp
MixUp works on synthetic data without dynamic soft labels when static soft labels are used, thanks to the UFC's design. UFC and natural instances together create synthetic instances whose linear interpolation of labels matches natural datasets. Static soft labels (averaged over M architectures) suffice for training with MixUp because the linear label interpolation property of natural data carries over when UFC is combined with diverse-class natural instances.

### Mechanism 3: Multi-Architecture UFC Generation
Using multiple architectures to generate UFCs improves diversity and generalization. Each architecture contributes a different view of inter-class features; averaging their UFCs yields richer, more robust synthetic data. This works because diverse model architectures capture complementary aspects of inter-class features.

## Foundational Learning

- **Inter-class feature distribution**: Understanding how features overlap or separate across classes is key to why UFC improves generalization. Quick check: If two classes have highly overlapping features, what kind of decision boundary will a model likely form without inter-class compensation?

- **Dataset distillation optimization**: The method reframes distillation from "one label per instance" to a joint optimization involving natural instances and UFCs. Quick check: How does the loss function change when UFC is introduced compared to traditional distillation?

- **MixUp data augmentation**: MixUp is used to further enhance inter-class feature mixing, but only works effectively because of UFC design. Quick check: Why does MixUp require soft labels, and how does UFC enable static soft labels to work?

## Architecture Onboarding

- **Component map**: Natural dataset T -> Universal Feature Compensator (UFC) set U_k -> Natural instances set P_k -> Synthetic dataset S_k -> Multiple architectures -> Training pipeline with MixUp

- **Critical path**:
  1. Randomly select P_k with one instance per class from T
  2. Initialize UFCs U_k as zero vectors
  3. Optimize UFCs via loss including gradient matching and BN regularization
  4. Generate static soft labels by averaging logits from M architectures
  5. Train with MixUp using static soft labels
  6. Repeat for K subsets to form full synthetic dataset

- **Design tradeoffs**:
  - More architectures (M) → richer UFCs but higher computation
  - Larger K (more subsets) → better coverage but more storage
  - Static vs dynamic soft labels → lower storage but potential supervision loss
  - UFC size (same as data dim) → memory cost but flexible integration

- **Failure signatures**:
  - Synthetic data collapses to near-zero variance (UFC too dominant)
  - Performance degrades with more architectures (conflicting UFCs)
  - MixUp causes training instability (static labels insufficient)
  - Decision boundaries remain chaotic despite UFC (inter-class features not captured)

- **First 3 experiments**:
  1. Ablation: Run with M=1 architecture vs M=4; measure performance and storage
  2. Label study: Compare static vs dynamic soft labels on CIFAR-100; check compression ratio
  3. Feature duplication: Measure cosine similarity between synthetic instances within same class; compare to SRe2L baseline

## Open Questions the Paper Calls Out

- **Scaling to extremely large datasets**: How does UFC scale to datasets like WebImage-10M or beyond? The paper only evaluates on ImageNet-1k and mentions future work on scaling without providing theoretical analysis or empirical evidence for 10-100x larger datasets.

- **Optimal number of architectures**: What is the optimal number of architectures (M) for UFC generation across different dataset complexities? The paper uses M=4 for CIFAR and M=3 for ImageNet-1k but doesn't identify where returns diminish or how to select M optimally.

- **Extreme compression comparison**: How does INFER compare to coreset selection methods at extremely small compression ratios (ipc=1 or CR < 1%)? The paper demonstrates advantages at moderate compression but doesn't test extreme compression regimes where coreset methods might be competitive.

## Limitations

- The inter-class feature integration mechanism lacks direct corpus evidence validating that UFC effectively captures and leverages features spanning multiple classes.
- The efficacy of static soft labels in MixUp for synthetic data, enabled by UFC design, lacks explicit experimental or theoretical justification in the literature.
- Multi-architecture UFC generation may have diminishing returns or feature conflicts that are not empirically validated across diverse model families.

## Confidence

- **High Confidence**: CIFAR-100 and Tiny-ImageNet results; ImageNet-1k compression claims; MixUp's role in enhancing synthetic data generalization
- **Medium Confidence**: Generalizability of inter-class feature compensation across datasets; scalability to larger architectures; static label MixUp stability
- **Low Confidence**: Core claim that UFC effectively captures and integrates inter-class features; robustness of static soft labels under MixUp; multi-architecture UFC synergy

## Next Checks

1. **Inter-Class Feature Validation**: Compute pairwise cosine similarity between synthetic instances from different classes; compare distribution to SRe2L baseline to confirm enriched inter-class features.

2. **Static Label MixUp Robustness**: Systematically vary M (number of architectures) and measure training stability and final accuracy; test if static labels maintain performance as M grows.

3. **UFC Ablation on ImageNet-1k**: Remove UFC entirely and train with standard distillation; measure drop in accuracy to quantify UFC's contribution beyond data augmentation.