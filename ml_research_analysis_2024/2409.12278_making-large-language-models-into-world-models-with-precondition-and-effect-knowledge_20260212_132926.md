---
ver: rpa2
title: Making Large Language Models into World Models with Precondition and Effect
  Knowledge
arxiv_id: '2409.12278'
source_url: https://arxiv.org/abs/2409.12278
tags:
- action
- world
- preconditions
- effects
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work explores whether large language models (LLMs) can function
  as world models by learning to predict valid actions and state transitions. The
  authors propose a two-part approach: fine-tuning separate LLMs for precondition
  inference and effect inference, then connecting these models with semantic matching
  modules.'
---

# Making Large Language Models into World Models with Precondition and Effect Knowledge

## Quick Facts
- arXiv ID: 2409.12278
- Source URL: https://arxiv.org/abs/2409.12278
- Authors: Kaige Xie; Ian Yang; John Gunerli; Mark Riedl
- Reference count: 23
- One-line primary result: Fine-tuned LLMs with synthetic data can infer action preconditions/effects and predict valid actions/state transitions in dish cooking domain

## Executive Summary
This paper explores whether large language models (LLMs) can function as world models by learning to predict valid actions and state transitions through precondition and effect knowledge. The authors propose a two-part approach: fine-tuning separate LLMs for precondition inference and effect inference, then connecting these models with semantic matching modules. To train these models, they develop a global-local prompting technique using GPT-4 to generate a high-quality action precondition/effect corpus from synthetic data. The approach is evaluated on the dish cooking domain, showing that the precondition/effect inference modules achieve high accuracy (F1 scores around 65%, BLEU-2 scores around 70%) and the full world model successfully predicts valid actions and state transitions.

## Method Summary
The authors fine-tune two separate FLAN-T5-large models - one for precondition inference and one for effect inference - using a synthetic corpus generated through a global-local prompting technique with GPT-4. This technique iteratively refines action plans to maximize action chaining, creating a high-quality dataset of action preconditions and effects. The fine-tuned models are then integrated with two GPT-4-based semantic matching modules that check preconditions against world states (for valid action prediction) and apply effects to update world states (for state transition prediction). The full world model orchestrates these components to predict valid actions and state transitions in the dish cooking domain.

## Key Results
- Precondition/effect inference modules achieve F1 scores around 65% and BLEU-2 scores around 70%
- The world model successfully predicts valid actions and state transitions in the dish cooking domain
- Human evaluations confirm the model-generated knowledge aligns with human understanding
- The model supports creative planning trajectories, satisfying 83.5% of never-before-seen actions in an average of 9.7 different ways

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can be fine-tuned to reliably infer action preconditions and effects when provided with synthetic training data
- Mechanism: The global-local prompting technique generates a high-quality precondition/effect corpus by iteratively refining action plans to maximize action chaining. This corpus is then used to fine-tune separate LLMs for precondition and effect inference, leveraging the LLMs' inherent knowledge of real-world dynamics learned from pre-training
- Core assumption: GPT-4 possesses sufficient intrinsic knowledge about real-world action preconditions and effects to generate accurate synthetic data when properly prompted
- Evidence anchors:
  - [abstract]: "We fine-tune two separate LLMs—one for precondition prediction and another for effect prediction—while leveraging synthetic data generation techniques"
  - [section]: "Through preliminary prompting experiments, we find that GPT-4 possesses the intrinsic knowledge about action precondition/effect but does not necessarily apply that knowledge when generating plan action sequences"
  - [corpus]: Weak - The corpus evidence shows high FMR scores for related papers but doesn't directly validate GPT-4's knowledge of preconditions/effects
- Break condition: If GPT-4 lacks sufficient real-world knowledge or if the prompting technique fails to properly induce this knowledge, the synthetic corpus will be unreliable and the fine-tuned models will perform poorly

### Mechanism 2
- Claim: Semantic matching modules can bridge the gap between natural language preconditions/effects and world states
- Mechanism: Two GPT-4-based modules are designed to semantically match inferred preconditions with current world states (for valid action prediction) and to update world states based on inferred effects (for state transition prediction). These modules handle the complexity of natural language matching and state updates
- Core assumption: GPT-4 can reliably perform semantic matching between natural language descriptions of preconditions/effects and world states
- Evidence anchors:
  - [abstract]: "We provide a means for these two models to work together, along with procedures for checking preconditions against a world state and applying effects to alter the world state"
  - [section]: "Since world states are natural language descriptions, as are preconditions and effects, we require a means of semantically matching preconditions to states and updating states based on effects"
  - [corpus]: Weak - No direct evidence in the corpus about semantic matching capabilities
- Break condition: If GPT-4 cannot reliably perform the required semantic matching or if the natural language descriptions are too ambiguous, the world model will fail to make accurate predictions

### Mechanism 3
- Claim: The world model can support creative planning trajectories beyond memorizing examples
- Mechanism: By learning from a diverse corpus of action preconditions and effects, the model develops a search space that allows for multiple ways to satisfy preconditions for never-before-seen actions. This is evidenced by the ability to satisfy 83.5% of never-before-seen actions in an average of 9.7 different ways
- Core assumption: The diversity of the training corpus and the effectiveness of the inference modules create a search space with sufficient coverage and flexibility
- Evidence anchors:
  - [abstract]: "We also analyze the extent to which the world model trained on our synthetic data results in an inferred state space that supports the creation of action chains"
  - [section]: "It can also be inferred that the system is not simply memorizing dish recipes"
  - [corpus]: Weak - The corpus doesn't directly measure the diversity of the resulting search space
- Break condition: If the training corpus is too narrow or the inference modules fail to capture the full complexity of action dependencies, the search space will be limited and the model will only be able to reproduce memorized plans

## Foundational Learning

- Concept: Fine-tuning large language models on task-specific data
  - Why needed here: Standard LLMs are not designed for world modeling tasks and need to be adapted to perform precondition and effect inference
  - Quick check question: What are the key differences between prompt engineering and fine-tuning for adapting LLMs to new tasks?

- Concept: Semantic matching in natural language processing
  - Why needed here: The world model needs to match preconditions/effects (natural language) with world states (also natural language) and perform state updates
  - Quick check question: How does semantic matching differ from exact string matching when comparing natural language descriptions?

- Concept: Synthetic data generation for training ML models
  - Why needed here: There is no existing high-quality corpus of action preconditions and effects for domains with significant action chaining, so synthetic data must be generated
  - Quick check question: What are the advantages and disadvantages of using synthetic data versus human-annotated data for training ML models?

## Architecture Onboarding

- Component map:
  - Data generation pipeline (global-local prompting with GPT-4)
  - Precondition inference module (fine-tuned LLM)
  - Effect inference module (fine-tuned LLM)
  - Semantic matching module for valid action prediction (GPT-4)
  - Semantic matching module for state transition prediction (GPT-4)
  - World model orchestrator (coordinates all components)

- Critical path:
  1. Generate synthetic data using global-local prompting
  2. Fine-tune precondition and effect inference modules
  3. For valid action prediction: infer preconditions → semantic matching → output validity
  4. For state transition prediction: infer effects → semantic matching → output new state

- Design tradeoffs:
  - Using separate LLMs for precondition and effect inference vs. a single multi-task model
  - Fine-tuning smaller models vs. using larger models with prompt engineering
  - Generating synthetic data vs. collecting human-annotated data
  - Using GPT-4 for semantic matching vs. training specialized matching models

- Failure signatures:
  - Low F1/BLEU scores on precondition/effect inference indicate poor fine-tuning or inadequate synthetic data
  - High accuracy on valid action prediction but low accuracy on state transition prediction suggests semantic matching issues
  - Inability to handle never-before-seen actions indicates insufficient diversity in the training corpus

- First 3 experiments:
  1. Test the global-local prompting technique by generating a small corpus and manually inspecting the quality of preconditions/effects
  2. Fine-tune the precondition inference module on a subset of the corpus and evaluate on a held-out test set
  3. Integrate the full world model pipeline and test on a simple planning task to verify end-to-end functionality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the world model scale with increasing complexity and diversity of the dish cooking domain?
- Basis in paper: [inferred] The paper evaluates the model on dish cooking, a representative real-world domain with significant action chaining. However, it doesn't explore how the model performs on more complex or diverse domains within cooking or other real-world domains.
- Why unresolved: The paper focuses on a single domain (dish cooking) and doesn't provide evidence of the model's generalization to more complex or diverse scenarios within that domain or to other real-world domains.
- What evidence would resolve it: Testing the model on a wider range of cooking tasks with varying levels of complexity and diversity, or evaluating its performance on other real-world domains with significant action chaining, such as assembly tasks or repair procedures.

### Open Question 2
- Question: What is the impact of the quality and diversity of the synthetic data generated by GPT-4 on the final performance of the world model?
- Basis in paper: [explicit] The paper acknowledges that the performance of the model is dependent on the quality and diversity of the training data, and performs ablation studies to investigate the impact of key steps in creating the corpus.
- Why unresolved: While the paper demonstrates the effectiveness of the global-local prompting technique in creating a high-quality corpus, it doesn't explore the upper limits of data quality and diversity or how much improvement can be achieved by further refining the data generation process.
- What evidence would resolve it: Conducting experiments with different data generation strategies, varying the amount and diversity of synthetic data, and measuring the corresponding impact on the world model's performance.

### Open Question 3
- Question: How does the world model handle situations where the preconditions and effects inferred by the LLMs are incorrect or incomplete?
- Basis in paper: [inferred] The paper evaluates the accuracy of the precondition and effect inference modules using automatic metrics and human evaluations, but doesn't explicitly address how the world model handles errors in these inferences.
- Why unresolved: The paper focuses on the accuracy of the inference modules but doesn't discuss how the world model's predictions are affected when these inferences are incorrect or incomplete.
- What evidence would resolve it: Introducing controlled errors or omissions in the precondition and effect data and observing how the world model's predictions are affected, or developing techniques to identify and mitigate the impact of such errors on the model's performance.

## Limitations
- The synthetic data generation pipeline's reliability depends heavily on GPT-4's intrinsic knowledge about real-world action dynamics, which was not directly validated
- The evaluation is limited to a single domain (dish cooking) with predefined action chains, leaving unclear how well the approach generalizes to other domains
- The human evaluation methodology lacks detailed statistical analysis and sample sizes for each evaluation dimension

## Confidence
**High Confidence:** The fine-tuning of precondition/effect inference modules shows consistent performance across multiple automatic metrics (F1 ~65%, BLEU-2 ~70%) and the semantic matching modules successfully connect these inferences with world states for both valid action prediction and state transitions.

**Medium Confidence:** The claim that the model supports creative planning trajectories beyond memorization is supported by the finding that never-before-seen actions can be satisfied in multiple ways, but the analysis lacks quantitative measures of plan diversity and coverage across the full action space.

**Low Confidence:** The global-local prompting technique's effectiveness is inferred from downstream performance rather than direct validation of the synthetic corpus quality, and the human evaluation results, while positive, lack statistical significance measures and detailed breakdowns.

## Next Checks
1. **Ablation Study on Data Sources:** Train the world model using only human-annotated precondition/effect data (if available) versus the synthetic corpus to quantify the impact of the global-local prompting technique on model performance.

2. **Cross-Domain Transferability Test:** Evaluate the fine-tuned precondition/effect inference modules on a different domain (e.g., home cleaning or craft-making) to assess generalization beyond the dish cooking domain.

3. **Plan Diversity Analysis:** Systematically measure the variety of valid action chains generated for common planning tasks, comparing the ratio of unique plans to total plans and analyzing whether the model consistently discovers novel solution paths or relies on a limited set of strategies.