---
ver: rpa2
title: Parallel Unlearning in Inherited Model Networks
arxiv_id: '2408.08493'
source_url: https://arxiv.org/abs/2408.08493
tags:
- unlearning
- learning
- data
- nodes
- inheritance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of parallel unlearning in model
  inheritance networks, where models exhibit complex dependencies. The proposed Fisher
  Inheritance Unlearning (FIUn) method uses the Fisher Information Matrix (FIM) to
  quantify parameter significance and enable efficient parallel unlearning across
  inherited models.
---

# Parallel Unlearning in Inherited Model Networks

## Quick Facts
- arXiv ID: 2408.08493
- Source URL: https://arxiv.org/abs/2408.08493
- Authors: Xiao Liu; Mingyuan Li; Guangsheng Yu; Lixiang Li; Haipeng Peng; Ren Ping Liu
- Reference count: 40
- Primary result: FIUn achieves complete unlearning for single-class tasks (0% accuracy for unlearned labels, 94.53% for retained labels) and strong performance for multi-class tasks (1.07% accuracy for unlearned labels, 84.77% for retained labels), while accelerating unlearning by 99% compared to alternative methods

## Executive Summary
This paper addresses the challenge of parallel unlearning in model inheritance networks, where models exhibit complex dependencies across federated learning, distributed data parallel learning, incremental learning, and transfer learning frameworks. The proposed Fisher Inheritance Unlearning (FIUn) method uses the Fisher Information Matrix (FIM) to quantify parameter significance and enable efficient parallel unlearning across inherited models. A key innovation is the Merging-FIM (MFIM) function, which consolidates multiple FIMs to support one-shot unlearning of inherited knowledge.

The method achieves complete unlearning (near-zero accuracy on removed classes) while preserving accuracy on retained classes and dramatically reducing unlearning time compared to retraining baselines. Experiments demonstrate FIUn's effectiveness across four learning frameworks using CIFAR-100 and TinyImageNet datasets with various model architectures including ResNet18 and DenseNet161.

## Method Summary
FIUn leverages Fisher Information Matrix (FIM) calculations to identify parameter significance for unlearning tasks across model inheritance networks. The method operates on a DAG representation of model inheritance relationships, using breadth-first search to identify discovery nodes and unlearning subgraphs. For each model, unlearning FIMs are calculated using the unlearning dataset, while model FIMs are computed from the model's training data. The Merging-FIM function consolidates multiple upstream FIMs through element-wise maximum operations, enabling one-shot unlearning across multi-root scenarios. Model parameters are then updated based on the consolidated FIMs, allowing parallel unlearning regardless of inheritance depth or path structure.

## Key Results
- Single-class unlearning: 0% accuracy on unlearned labels, 94.53% on retained labels
- Multi-class unlearning (4 classes): 1.07% accuracy on unlearned labels, 84.77% on retained labels
- Cumulative unlearning time reduction: 99% compared to retraining benchmarks
- Performance preserved across four learning frameworks (FL, DDPL, IL, TL) with varying inheritance depths

## Why This Works (Mechanism)

### Mechanism 1
Fisher Information Matrix (FIM) provides stable localization of parameter importance across model inheritance paths. FIM diagonal approximation quantifies parameter sensitivity to unlearning data, allowing targeted parameter scaling without full retraining. Core assumption: parameter importance remains localized at fixed positions in parameter space across inheritance. Break condition: if parameter importance shifts due to model fine-tuning or architectural changes.

### Mechanism 2
Merging-FIM function consolidates multiple unlearning requests into single parameter update operation. Element-wise maximum operation across multiple upstream FIMs identifies parameters needing updates for complete unlearning across multi-root scenarios. Core assumption: most impactful parameter adjustments across different unlearning sources determine necessary update. Break condition: if parameter interactions are non-linear or if different unlearning sources require contradictory updates.

### Mechanism 3
Hyper-Distance property enables parallel unlearning regardless of inheritance depth or path structure. Class-wise inheritance approach allows each model to incorporate union of label sets from predecessors while focusing on label differences for unlearning. Core assumption: each model effectively incorporates union of label sets from predecessors, making inheritance depth irrelevant to unlearning. Break condition: if model inheritance structure changes fundamentally or if label dependencies are non-sequential.

## Foundational Learning

- Concept: Fisher Information Matrix (FIM) and its diagonal approximation
  - Why needed here: Provides mathematical foundation for quantifying parameter importance in unlearning tasks
  - Quick check question: Can you explain why the diagonal of FIM is used instead of full matrix for computational efficiency?

- Concept: Directed Acyclic Graph (DAG) representation of model inheritance
  - Why needed here: Captures topological structure of model dependencies across learning frameworks
  - Quick check question: How would you represent a federated learning topology using a DAG structure?

- Concept: Class-wise vs sample-wise unlearning
  - Why needed here: Determines granularity of unlearning operations and affects FIM calculation approach
  - Quick check question: What are computational differences between class-level and sample-level unlearning?

## Architecture Onboarding

- Component map: UMIG (DAG-based topology) -> FIUn (core algorithm) -> Merging-FIM (consolidation) -> Parameter update
- Critical path: Breadth-first search → FIM calculation → Merging-FIM → Parameter update
- Design tradeoffs:
  - Accuracy vs speed: Using only last layer FIM reduces computation but may miss deeper parameter dependencies
  - Parallelization vs consistency: Fully parallel approach may introduce slight accuracy variations
  - Complexity vs generality: Generic DAG representation works across frameworks but may miss framework-specific optimizations

- Failure signatures:
  - Accuracy degradation on retained labels indicates over-aggressive parameter scaling
  - Incomplete unlearning (high accuracy on unlearned labels) suggests insufficient parameter adjustment
  - Computational bottlenecks indicate suboptimal FIM calculation or merging strategy

- First 3 experiments:
  1. Single-class unlearning on CIFAR-100 with ResNet18 to verify basic functionality
  2. Multi-class unlearning with overlapping label sets to test Merging-FIM function
  3. Inheritance depth analysis to verify Hyper-Distance property across varying DAG depths

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several critical areas require further investigation:

### Open Question 1
How does FIUn scale when applied to extremely large model networks with thousands of interconnected models? While the method is claimed to be scalable, no experiments were conducted on large-scale networks to verify this claim.

### Open Question 2
What happens to FIUn's unlearning effectiveness when the to-be-unlearned data distribution differs significantly from the original training data distribution? All experiments used unlearning data drawn from the same distribution as training data.

### Open Question 3
How robust is FIUn to adversarial attacks specifically designed to manipulate the Fisher Information Matrix calculations? The paper relies heavily on FIM calculations for parameter significance assessment but does not address potential vulnerabilities to adversarial manipulation.

## Limitations

- Scalability concerns for extremely large model networks with thousands of interconnected models
- Limited validation of FIM localization stability across diverse model architectures and inheritance paths
- Focus on computer vision tasks constrains generalizability to other domains like NLP or tabular data

## Confidence

- High confidence in core claims about FIM-based unlearning effectiveness and experimental results
- Medium confidence in claims about generalizability across arbitrary inheritance structures and Hyper-Distance property
- Limited validation of theoretical properties under stress conditions and across diverse model families

## Next Checks

1. **Stress Test Inheritance Structures**: Evaluate FIUn on inheritance DAGs with varying depths, branching factors, and topological complexities to verify Hyper-Distance property under extreme conditions.

2. **Cross-Domain Generalization**: Test the method on non-vision tasks (NLP, tabular data) with fundamentally different model architectures to assess generalizability beyond computer vision focus.

3. **Parameter Interaction Analysis**: Conduct ablation studies examining how parameter interactions evolve through inheritance paths, particularly for models with significant architectural differences or non-linear dependencies.