---
ver: rpa2
title: 'Work Smarter Not Harder: Simple Imitation Learning with CS-PIBT Outperforms
  Large Scale Imitation Learning for MAPF'
arxiv_id: '2409.14491'
source_url: https://arxiv.org/abs/2409.14491
tags:
- mapf
- learning
- agents
- search
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether simple large-scale imitation learning
  can produce state-of-the-art ML MAPF performance. The authors collected 700k+ examples
  using a strong heuristic search solver (EECBS) across diverse maps and trained a
  simple GNN model.
---

# Work Smarter Not Harder: Simple Imitation Learning with CS-PIBT Outperforms Large Scale Imitation Learning for MAPF

## Quick Facts
- arXiv ID: 2409.14491
- Source URL: https://arxiv.org/abs/2409.14491
- Authors: Rishi Veerapaneni; Arthur Jakobsson; Kevin Ren; Samuel Kim; Jiaoyang Li; Maxim Likhachev
- Reference count: 40
- Primary result: CS-PIBT with simple imitation learning outperforms large-scale IL methods for MAPF

## Executive Summary
This paper investigates whether large-scale imitation learning can produce state-of-the-art MAPF performance. Surprisingly, simple imitation learning with naive collision shielding failed to yield impressive results despite using 700k+ examples from a strong heuristic solver. Instead, the authors discovered that CS-PIBT, a smart 1-step collision resolution technique, enabled training a state-of-the-art ML MAPF model in minutes with minimal data. The resulting model achieved high success rates (>40%) across diverse maps and agent densities, significantly outperforming existing ML MAPF methods.

## Method Summary
The authors collected demonstrations using ECBBS, a strong heuristic search solver, across diverse maps and agent densities. They trained a simple GNN model using these demonstrations with two different collision handling approaches: naive collision shielding and CS-PIBT. CS-PIBT (Coordinated Single-Step Policy Improvement by Teaching) is a 1-step collision resolution technique that resolves conflicts efficiently during training. The model was evaluated on its ability to generalize to unseen maps and higher agent densities compared to existing ML MAPF approaches including MAPF-GPT.

## Key Results
- CS-PIBT with minimal data (minutes of training) outperforms large-scale IL methods trained on 700k+ examples
- The CS-PIBT model achieves success rates >40% across diverse maps and agent densities
- Naive collision shielding with large-scale IL failed to produce competitive results
- The model struggles with target conflicts and bottlenecks, indicating need for longer-horizon reasoning

## Why This Works (Mechanism)
CS-PIBT works by intelligently resolving 1-step collisions during training rather than ignoring them or requiring the model to learn collision avoidance from scratch. This allows the model to focus on higher-level path planning while CS-PIBT handles local conflict resolution. By separating these concerns, the model can learn more effectively from fewer examples and generalize better to unseen scenarios. The approach essentially teaches the model to think longer-term while delegating immediate collision resolution to a specialized mechanism.

## Foundational Learning
- Graph Neural Networks (GNNs): Used to represent the MAPF problem as a graph where agents and their relationships are encoded as nodes and edges. Why needed: MAPF naturally maps to graph structures where agents interact locally with their environment and each other. Quick check: Verify node/edge features capture essential spatial and temporal information.

- Imitation Learning: The model learns from expert demonstrations (solutions from ECBBS) rather than through trial-and-error reinforcement learning. Why needed: Expert demonstrations provide high-quality trajectories that would be expensive to discover through exploration. Quick check: Ensure demonstration quality by validating against multiple expert solutions.

- Collision Resolution: CS-PIBT provides a mechanism to handle immediate conflicts while training. Why needed: Without intelligent collision handling, the model must learn both path planning and collision avoidance simultaneously, which is challenging. Quick check: Measure collision resolution success rate during training.

## Architecture Onboarding

Component Map:
Input Map/Agents -> GNN Encoder -> Policy Head -> Action Prediction -> CS-PIBT Collision Resolver -> Final Action

Critical Path:
The critical path flows from map representation through the GNN encoder to action prediction, with CS-PIBT providing a parallel path for collision resolution that can override or modify the predicted actions when conflicts are detected.

Design Tradeoffs:
The key tradeoff is between model complexity and training efficiency. By using CS-PIBT to handle collisions, the model can be simpler and trained faster, but it becomes dependent on the collision resolver. This contrasts with approaches that require the model to learn all behaviors, which need more data and training time but are more self-contained.

Failure Signatures:
Poor performance on maps with bottlenecks and target conflicts indicates the model's limitations in long-horizon reasoning. High collision rates during evaluation suggest CS-PIBT may not be resolving all conflicts or the model's predictions are too far from solvable states.

First Experiments:
1. Evaluate CS-PIBT's collision resolution rate on validation set to ensure it's effectively handling conflicts
2. Test model performance with and without CS-PIBT to quantify its contribution
3. Analyze failure cases to identify whether issues stem from GNN representation or CS-PIBT limitations

## Open Questions the Paper Calls Out
The paper identifies that the model's poor performance on target conflicts and bottlenecks indicates the need for longer-horizon reasoning mechanisms. This suggests that while CS-PIBT handles local conflicts well, the underlying model still needs mechanisms to reason about future states and plan accordingly.

## Limitations
- Results are based on specific map types and agent densities, limiting generalizability to real-world scenarios
- Reliance on ECBBS for data collection may introduce biases favoring the learned policy
- Comparison with large-scale approaches could be strengthened with more comprehensive ablation studies
- The CS-PIBT dependency means the approach isn't fully self-contained

## Confidence

High confidence: CS-PIBT significantly improves ML MAPF performance with minimal data and training time
Medium confidence: Simple imitation learning cannot match CS-PIBT results based on limited comparison with one approach
Medium confidence: Model struggles with target conflicts/bottlenecks indicate need for longer-horizon reasoning, assessment may depend on evaluation metrics

## Next Checks

1. Evaluate CS-PIBT approach on wider range of map types including complex obstacles and varying topologies to assess robustness and generalizability
2. Conduct comprehensive comparison with other large-scale imitation learning methods using transformer architectures or diverse pretraining datasets to verify performance advantage
3. Investigate incorporating longer-horizon reasoning mechanisms into CS-PIBT framework to address weaknesses in handling target conflicts and bottlenecks