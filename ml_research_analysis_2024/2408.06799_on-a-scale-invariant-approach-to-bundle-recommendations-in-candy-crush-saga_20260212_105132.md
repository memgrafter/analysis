---
ver: rpa2
title: On a Scale-Invariant Approach to Bundle Recommendations in Candy Crush Saga
arxiv_id: '2408.06799'
source_url: https://arxiv.org/abs/2408.06799
tags:
- recommendation
- bundle
- data
- system
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a scale-invariant approach for bundle recommendations
  in Candy Crush Saga, combining supervised and unsupervised learning methods. A TabNet
  model predicts item quantities per user, followed by k-means clustering to define
  preference clusters and bundle composition.
---

# On a Scale-Invariant Approach to Bundle Recommendations in Candy Crush Saga

## Quick Facts
- **arXiv ID**: 2408.06799
- **Source URL**: https://arxiv.org/abs/2408.06799
- **Reference count**: 40
- **Primary result**: Scale-invariant bundle recommendation system deployed in production serving millions of users, achieving 30% increase in click rate and 40% increase in take rate versus heuristics

## Executive Summary
This paper presents a production-ready bundle recommendation system for Candy Crush Saga that combines supervised learning (TabNet) with unsupervised clustering (k-means) to deliver personalized in-game item bundles at scale. The system uses a scale-invariant cosine distance metric to evaluate recommendation quality, addressing the sparsity problem inherent in bundle recommendations where each user can have unique combinations of items. The approach has been deployed in production serving millions of users and demonstrates significant improvements in engagement metrics compared to heuristic-based methods.

## Method Summary
The system predicts quantities of in-game items per user using a TabNet model trained on user behavior data aggregated over 15-30 days, then applies k-means clustering to define preference clusters and create discrete bundle compositions. The pipeline includes data extraction, feature transformation, TabNet training/inference, clustering, bundle mapping, game system delivery, and monitoring components. The scale-invariant cosine distance metric enables evaluation of recommendation quality regardless of absolute quantity scales, while the clustering approach discretizes the continuous predictions to create practical bundles.

## Key Results
- TabNet achieves 0.103 mean cosine distance versus 0.234 for XGBoost in offline evaluation
- Online A/B experiments show 30% increase in click rate and over 40% increase in take rate versus heuristics
- Recommendation diversity deteriorates gradually over time but stabilizes after 20 days
- System is deployed in production serving millions of users with monitoring and technical debt mitigation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TabNet's attention-based feature selection improves personalized bundle recommendations by focusing on relevant features for each user.
- Mechanism: The model dynamically identifies and prioritizes important features during each decision step using a structured attention mechanism, allowing it to handle sparse and diverse user data effectively.
- Core assumption: User behavior patterns are sufficiently distinct that instance-wise feature attention will capture meaningful differences in preferences.
- Evidence anchors:
  - [abstract] "TabNet uses a structured attention mechanism to highlight important features during each decision step, which enables transparency and interpretability of the model's predictions, as well as efficient handling of sparse features."
  - [section] "TabNet's capability to handle sparsity and operate on an instance-wise basis is advantageous for our use case, as it allows the model to independently determine the features to pay attention to for each example."
- Break condition: If user behavior patterns are too homogeneous or feature relevance is static across users, the attention mechanism's benefits diminish.

### Mechanism 2
- Claim: The scale-invariant cosine distance metric effectively measures recommendation quality by focusing on item proportion relationships rather than absolute quantities.
- Mechanism: By normalizing target vectors and using cosine similarity, the system evaluates how well the predicted item proportions match actual user purchases, regardless of scale differences.
- Core assumption: The relative proportions of items in a bundle are more important than absolute quantities for user satisfaction.
- Evidence anchors:
  - [section] "Given that the targets are normalised, we use cosine similarity as our evaluation metrics as it ignores the overall scale of the predicted vectors, which is beneficial if the magnitude of the model predictions is not directly comparable to the targets."
  - [section] "The cosine distance metric enables a scale-invariant comparison of the proportions of the different items present in the predicted vector and the actual label vector."
- Break condition: If users care more about absolute quantities than proportions, or if normalization obscures meaningful scale differences.

### Mechanism 3
- Claim: The combination of supervised learning (TabNet) and unsupervised clustering (k-means) effectively handles the data sparsity problem in bundle recommendations.
- Mechanism: TabNet predicts continuous item quantities per user, then k-means clustering discretizes these predictions into meaningful preference clusters, reducing the combinatorial explosion of possible bundles.
- Core assumption: Similar user preference patterns exist that can be grouped into clusters, and the clustering process won't lose too much individual preference information.
- Evidence anchors:
  - [section] "We expect to find many similar combinations of in-game item proportions in the predictions yielded from the model in Step 1, so in this step we employ an unsupervised clustering approach to define a discrete preference space."
  - [section] "Since the quantities of the items in a bundle are discrete, the clustering approach serves the double purpose of discretizing the problem and resolving the data sparsity."
- Break condition: If user preferences are too unique to cluster meaningfully, or if clustering creates artificial groupings that don't reflect actual user behavior.

## Foundational Learning

- **Cosine similarity and distance metrics**: Why needed here - The system uses cosine distance as its primary evaluation metric to measure recommendation quality in a scale-invariant way. Quick check question: Why would cosine distance be preferred over Euclidean distance for measuring bundle recommendation quality?
- **Supervised vs unsupervised learning**: Why needed here - The system combines TabNet (supervised) for predicting item quantities with k-means clustering (unsupervised) for grouping preferences. Quick check question: What is the advantage of using k-means clustering after the supervised TabNet predictions?
- **Feature importance and attention mechanisms**: Why needed here - TabNet's attention mechanism dynamically identifies relevant features for each user, which is crucial for handling diverse player behavior. Quick check question: How does TabNet's attention mechanism differ from traditional feature importance methods in tree-based models?

## Architecture Onboarding

- **Component map**: Data pipeline → Training pipeline (TabNet) → Inference pipeline → Managed notebook pipeline (clustering) → Game system → Monitoring pipeline → External monitoring platform
- **Critical path**: Data extraction → Feature transformation → TabNet training/inference → Clustering → Bundle mapping → Game system delivery → Monitoring
- **Design tradeoffs**: Batch prediction vs real-time inference (chosen for scalability), single model vs separate models for different item types (single model chosen for simplicity)
- **Failure signatures**: Training/serving skew, feature distribution drift, recommendation diversity deterioration, feedback loop effects
- **First 3 experiments**:
  1. Test TabNet vs XGBoost on offline data using cosine distance metric
  2. Validate clustering quality by comparing cluster centroids to rounded bundle values
  3. Run A/B test with random recommendation as baseline to measure novelty effects

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the recommendation diversity change over longer periods beyond 140 days? The paper mentions novelty effects stabilize after 20 days and diversity deteriorates gradually over time, with effects lasting up to 100 days. Long-term tracking of recommendation diversity metrics over multiple years would resolve this.
- **Open Question 2**: What is the optimal aggregation period for balancing short-term and long-term user behavior patterns? The paper mentions exploring shorter aggregation periods could enhance model performance compared to the 30-day baseline. Systematic comparison of model performance across multiple aggregation window lengths would resolve this.
- **Open Question 3**: How does the model performance change when applied to other game genres or non-gaming applications? The paper mentions the scale-invariant system is efficient for generalization to other tasks. Performance metrics from applying the same methodology to different game genres or other recommendation domains would resolve this.
- **Open Question 4**: What is the impact of different imbalance weighting strategies for the 13 target items? The paper mentions the current solution doesn't account for weight differences between items and suggests target-specific weighting could help. Comparative results using different weighting schemes for target items would resolve this.
- **Open Question 5**: How does the cold start problem affect recommendation quality for completely new users? The paper acknowledges the cold start problem where at least one purchase is needed before model-based recommendations can be generated. Performance comparison between the current approach and proposed solutions for new users without purchase history would resolve this.

## Limitations

- External validity concerns: The approach was validated specifically on Candy Crush Saga data, limiting generalizability to other game contexts or domains
- Offline metric limitations: While cosine distance shows TabNet outperforms XGBoost, offline metrics may not fully capture online user behavior and engagement
- Long-term effects unknown: The paper demonstrates short-term engagement improvements but doesn't address long-term player retention or potential novelty effects wearing off

## Confidence

- **High confidence**: The scale-invariant approach using cosine distance is technically sound and well-justified for bundle recommendations
- **Medium confidence**: The combination of TabNet and k-means clustering effectively addresses the sparsity problem, though specific parameter choices may vary by context
- **Low confidence**: The fairness and privacy safeguards are adequately addressed, as implementation details are limited

## Next Checks

1. **Cross-domain validation**: Test the scale-invariant approach on a different game or e-commerce context to assess generalizability
2. **Longitudinal A/B testing**: Run extended experiments (3-6 months) to measure long-term engagement effects and potential novelty decay
3. **Feedback loop analysis**: Implement systematic monitoring to detect and quantify feedback loops where recommendations influence future behavior in unintended ways