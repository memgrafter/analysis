---
ver: rpa2
title: 'HUMOS: Human Motion Model Conditioned on Body Shape'
arxiv_id: '2409.03944'
source_url: https://arxiv.org/abs/2409.03944
tags:
- motion
- body
- human
- shape
- motions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating realistic human
  motion that accounts for body shape and size differences. Most existing motion models
  ignore these differences, resulting in uniform motion across different body types.
---

# HUMOS: Human Motion Model Conditioned on Body Shape

## Quick Facts
- **arXiv ID**: 2409.03944
- **Source URL**: https://arxiv.org/abs/2409.03944
- **Reference count**: 40
- **Primary result**: HUMOS generates diverse, physically plausible, and dynamically stable human motions conditioned on body shape, outperforming state-of-the-art methods in physics-based metrics and perceptual studies.

## Executive Summary
This paper introduces HUMOS, a generative motion model that conditions human motion on body shape and size. Existing motion models typically ignore body shape variations, resulting in uniform motion across different body types. HUMOS addresses this by using a conditional Variational Auto-Encoder (c-VAE) trained with cycle consistency, intuitive physics, and stability constraints. The model effectively learns how people with different body shapes perform the same motion, enabling realistic motion retargeting between characters with different identities. HUMOS generates motions that are both physically plausible and dynamically stable, achieving significant improvements over existing methods in both quantitative metrics and perceptual evaluations.

## Method Summary
HUMOS is a conditional VAE that generates motion conditioned on body shape using a Transformer-based encoder-decoder architecture. The encoder maps motion and identity to a latent space, while the decoder generates motion conditioned on target identity. The model is trained on the AMASS dataset (480 unique identities) using cycle consistency to learn identity-agnostic motion representations without paired data. Key components include intuitive physics terms (penetration, float, foot sliding) and dynamic stability constraints based on Zero Moment Point (ZMP) theory. The training procedure uses specific loss weights: λcycle=1, λphysics=1, λdyn=0.0001, λKL=10^-5, λE=10^-2, optimized with AdamW over 1300 epochs.

## Key Results
- HUMOS achieves a 71.9% dynamic stability rate compared to 55.92% for the closest baseline
- Generated motions show significant improvements in physics-based metrics (penetration, float, skate)
- Perceptual study indicates HUMOS-generated motions are rated as more realistic than those from other methods
- The model successfully learns how people with different body shapes perform the same motion

## Why This Works (Mechanism)

### Mechanism 1
Cycle consistency allows training a shape-conditioned motion model without paired data by leveraging unpaired motion and identity samples. The model encodes a source motion into a latent representation that is identity-agnostic. It then decodes this latent code conditioned on a target identity to generate a retargeted motion. By reversing this process and ensuring the reconstructed motion matches the original, the model learns to disentangle motion style from identity. Core assumption: The latent space captures motion style independently of identity, and the cycle consistency loss forces the model to preserve motion semantics across identity transformations. Evidence: [abstract] "We demonstrate that it is possible to train this model from unpaired training data using cycle consistency, intuitive physics, and stability constraints" and [section 3.2] "we employ cycle-consistency by reversing the forward step, this time using ˆMA→B as the source motion andA as the target identity". Break condition: If the latent space fails to disentangle motion style from identity, cycle consistency cannot enforce meaningful retargeting.

### Mechanism 2
Dynamic stability terms ensure generated motions are biomechanically plausible by enforcing ZMP-CoP alignment. The model computes the Zero Moment Point (ZMP) from the center of mass dynamics and minimizes its distance to the Center of Pressure (CoP), ensuring the motion remains dynamically stable during locomotion. Core assumption: Human motions in the dataset are dynamically stable, and enforcing ZMP-CoP alignment during training will produce realistic, balanced motions. Evidence: [abstract] "We propose differentiable physics terms that improve the realism of generated motions by addressing common issues like foot sliding, ground penetration, and unrealistic floating effects" and [section 3.4] "We follow the concept of zero-moment-point (ZMP)... If this point lies within the base of support, the ZMP is equivalent to the center of pressure and the motion is considered dynamically stable". Break condition: If the dataset contains many unstable motions or the ZMP computation is inaccurate, the stability term may enforce unrealistic constraints.

### Mechanism 3
Intuitive physics losses prevent trivial solutions by penalizing physically implausible artifacts like foot sliding and ground penetration. Additional loss terms are applied to the generated target motion to minimize ground penetration, floating, and foot sliding, encouraging the model to adjust the motion appropriately for the target body shape. Core assumption: Without these physics constraints, the model could trivially copy the source motion to the target body, resulting in physically implausible artifacts. Evidence: [abstract] "To prevent this, our key insight is to incorporate our IP and dynamic stability terms as training losses on the generated target body motions" and [section 3.3] "We design IP terms to address penetration, float, and foot sliding individually... We collate them together as Lphysics = Lpenetrate + Lfloat + Lslide". Break condition: If the physics terms are too weak or the motion space is too constrained, the model may still produce implausible motions despite these losses.

## Foundational Learning

- **Concept**: Variational Autoencoder (VAE) and conditional VAE (c-VAE)
  - Why needed here: HUMOS uses a c-VAE architecture to learn a latent representation of motion conditioned on body shape, enabling generation of diverse, realistic motions for different identities.
  - Quick check question: How does a c-VAE differ from a standard VAE in terms of input and output?

- **Concept**: Zero Moment Point (ZMP) and dynamic stability in biomechanics
  - Why needed here: The dynamic stability term in HUMOS is based on ZMP theory, ensuring generated motions are biomechanically plausible by enforcing balance during locomotion.
  - Quick check question: What is the physical interpretation of the ZMP, and why is it important for dynamic stability?

- **Concept**: Cycle consistency in unpaired image-to-image translation
  - Why needed here: HUMOS leverages cycle consistency to train the shape-conditioned motion model without paired data, inspired by successful applications in unpaired image translation.
  - Quick check question: How does cycle consistency help enforce that the retargeted motion preserves the original motion style?

## Architecture Onboarding

- **Component map**: Encoder (Transformer) -> Latent space (μ, Σ) -> Decoder (Transformer) -> Physics & stability losses -> Retargeted motion
- **Critical path**: Encoder → Latent space → Decoder → Physics & stability losses → Retargeted motion
- **Design tradeoffs**:
  - Non-autoregressive vs. autoregressive generation: Chosen for better motion diversity but may sacrifice fine-grained temporal coherence
  - Mesh-based representation (SMPL) vs. skeleton-based: Chosen for accurate surface contact modeling but increases computational complexity
  - Transformer architecture vs. other sequence models: Chosen for strong spatial-temporal modeling but requires more data and compute
- **Failure signatures**:
  - Poor disentanglement of motion style and identity: Retargeted motions look similar regardless of target body shape
  - Inaccurate ZMP computation: Generated motions exhibit unrealistic floating or imbalance
  - Weak physics terms: Generated motions have ground penetration, foot sliding, or other physical artifacts
  - Mode collapse in latent space: Generated motions lack diversity and appear repetitive
- **First 3 experiments**:
  1. Train with only cycle consistency loss (Lcycle) and evaluate on physics metrics to confirm it learns basic retargeting
  2. Add physics losses (Lphysics) and measure improvement in penetration, float, and skate metrics
  3. Add dynamic stability term (Ldyn) and verify improvement in dynamic stability percentage and BoS distance

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the diversity of body shapes in the training data affect the generalization capabilities of HUMOS?
  - Basis in paper: [explicit] The paper mentions that HUMOS is trained on the AMASS dataset, which contains 480 unique gender identities with diverse body shapes and sizes. It also notes that the differences in motion style produced by characters of very different body shapes remain subtle, possibly due to the limited shape diversity in the training set.
  - Why unresolved: The paper does not provide a detailed analysis of how varying the diversity of body shapes in the training data impacts the model's performance and generalization.
  - What evidence would resolve it: Conducting experiments with datasets of varying body shape diversity and comparing HUMOS's performance on each would provide insights into the impact of training data diversity on the model's generalization capabilities.

- **Open Question 2**: How does HUMOS handle self-penetrations that may arise during shape-conditioned motion generation?
  - Basis in paper: [inferred] The paper mentions that HUMOS generates physically plausible and dynamically stable human motions but does not explicitly address self-penetrations.
  - Why unresolved: The paper does not discuss any mechanisms or losses in HUMOS specifically designed to prevent self-penetrations.
  - What evidence would resolve it: Implementing and evaluating additional loss terms or constraints in HUMOS to prevent self-penetrations, and comparing the results with and without these additions, would clarify the model's handling of self-penetrations.

- **Open Question 3**: How would incorporating motion style as an additional conditioning signal affect HUMOS's performance?
  - Basis in paper: [explicit] The paper acknowledges that human motion is influenced by both body shape and individual motion style, but only considers body shape as a conditioning signal. It suggests that with style-specific annotations, it would be useful to extend HUMOS to include style attributes as additional conditioning signals.
  - Why unresolved: The paper does not explore the impact of including motion style as a conditioning signal on HUMOS's performance.
  - What evidence would resolve it: Extending HUMOS to include motion style as an additional conditioning signal and evaluating its performance on motion generation tasks would provide insights into the benefits of incorporating motion style.

## Limitations

- The reliance on unpaired data via cycle consistency assumes clean disentanglement of motion style from identity, which is not rigorously validated
- Physics terms depend heavily on accurate contact detection and ZMP computation, potentially limiting generalization to motions outside the AMASS dataset
- The perceptual study involved only 25 participants per video and focused on a narrow set of scenarios
- The paper does not explore how well HUMOS generalizes to extreme body shapes or highly dynamic motions like sports

## Confidence

- **High Confidence**: The core idea of using a c-VAE with cycle consistency to learn identity-agnostic motion representations is well-founded and supported by the experimental results. The physics and stability terms are clearly defined and show measurable improvements in quantitative metrics.
- **Medium Confidence**: The perceptual study indicates HUMOS-generated motions are rated as more realistic, but the small sample size and limited scenarios reduce confidence in broader applicability. The claim that HUMOS "significantly outperforms" baselines is supported quantitatively but may not hold for all motion types or body shapes.
- **Low Confidence**: The paper does not address potential failure modes for extreme body shapes or highly dynamic motions. The computational efficiency and scalability of the approach are not evaluated, which limits confidence in real-world deployment.

## Next Checks

1. **Latent Space Disentanglement**: Visualize and quantify the separation between motion style and identity in the latent space. Use techniques like latent traversal or style-content separation metrics to verify that the c-VAE truly learns an identity-agnostic motion representation.

2. **Generalization to Extreme Body Shapes**: Test HUMOS on AMASS sequences with highly atypical body shapes (e.g., very tall/short, obese/extremely muscular) and evaluate whether the generated motions remain physically plausible and realistic. Compare against baselines to quantify any degradation in performance.

3. **Real-time Performance and Scalability**: Measure the computational cost of training and inference for HUMOS, including memory usage and latency. Benchmark against simpler architectures (e.g., LSTM-based models) to assess the trade-off between motion quality and efficiency. Explore potential optimizations (e.g., model pruning, quantization) to improve real-time applicability.