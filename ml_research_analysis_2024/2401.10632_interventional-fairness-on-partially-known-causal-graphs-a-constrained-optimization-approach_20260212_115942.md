---
ver: rpa2
title: 'Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization
  Approach'
arxiv_id: '2401.10632'
source_url: https://arxiv.org/abs/2401.10632
tags:
- causal
- mpdag
- fairness
- data
- ifair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses causal fairness in partially known causal
  graphs, specifically MPDAGs. It proposes a modeling technique where predictions
  are treated as the effect of all observational variables, leading to another MPDAG
  that facilitates causal inference.
---

# Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach

## Quick Facts
- arXiv ID: 2401.10632
- Source URL: https://arxiv.org/abs/2401.10632
- Authors: Aoqi Zuo; Yiqing Li; Susan Wei; Mingming Gong
- Reference count: 40
- One-line primary result: The method achieves a trade-off between RMSE and unfairness on synthetic and real-world datasets, with RMSE of 1.1 and unfairness of 0.03 on 10-node graphs when tuned appropriately.

## Executive Summary
This paper addresses causal fairness in partially known causal graphs, specifically Markov Perfect Directed Acyclic Graphs (MPDAGs). The proposed approach involves modeling fair prediction using a Partially Directed Acyclic Graph (PDAG) and formulating a constrained optimization problem to balance fairness and accuracy. By treating predictions as the effect of all observational variables, the method creates an augmented MPDAG that facilitates causal inference. The work analyzes the identification condition for interventional fairness on MPDAGs and demonstrates effectiveness through experiments on synthetic and real-world datasets.

## Method Summary
The method addresses interventional fairness by modeling predictions as the effect of all observational variables (X, A) on outcome Y, creating an augmented MPDAG G* that extends the original DAG D. This new graph allows identification of interventional fairness criteria using standard causal inference tools. The approach formulates a constrained optimization problem that minimizes prediction loss while adding a fairness penalty term measured by the difference between interventional distributions, controlled by a tunable parameter λ. The method analyzes the identification condition for interventional fairness on MPDAGs and uses Monte Carlo sampling with Maximum Mean Discrepancy (MMD) to approximate the fairness penalty.

## Key Results
- The proposed method achieves a trade-off between RMSE and unfairness on synthetic data compared to baselines
- On synthetic data with 10 nodes and 20 edges, achieves RMSE of 1.1 and unfairness of 0.03 when tuned appropriately
- Demonstrates effectiveness on real-world datasets with varying amounts of background knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The augmented-G with Y creates a new MPDAG where causal inference can be formally performed
- Mechanism: By modeling the predictor Y as a function of all observational variables (X, A), the approach implicitly constructs a new causal graph D* that extends the original DAG D with edges from all V ∈ V to Y. This new graph's MPDAG representation G* allows identification of interventional fairness criteria using standard causal inference tools.
- Core assumption: The density f(v, ŷ) = f(ŷ|v)f(v) is consistent with G*, and G* is itself an MPDAG
- Evidence anchors:
  - [abstract] "The proposed approach involves modeling fair prediction using a Partially Directed Acyclic Graph (PDAG)"
  - [section 4.1] "Theorem 4.1 implies that f(v, ŷ) is consistent with the MPDAG augmented-G with ŷ, denoted as G*"
  - [corpus] Weak - no direct citations supporting this specific augmentation technique
- Break condition: If the augmentation violates Meek's rules or creates cycles in the resulting graph

### Mechanism 2
- Claim: Identification of interventional fairness is possible when no undirected edge exists between intervened variables and other variables
- Mechanism: Proposition 4.1 establishes that the causal effect P(Ŷ = y|do(A=a), do(Xad=xad)) is identifiable if and only if there is no pair of nodes X ∈ A ∪ Xad and V ∈ V\(A ∪ Xad) such that X − V in G. This condition ensures the post-interventional distribution can be expressed as an integral over observational densities.
- Core assumption: The partial causal ordering (PCO) decomposition of V\(A ∪ Xad) can be computed
- Evidence anchors:
  - [section 4.2] "Proposition 4.1 implies that the causal effect of A ∪ Xad on Ŷ is identifiable... if and only if there is no pair of nodes X ∈ A ∪ Xad and V ∈ V\(A ∪ Xad) such that X − V is in G"
  - [section 4.2] "In such case, f(ŷ|do(a), do(xad)) = ∫f(ŷ|v)∏Vi⊆V f(vi|pa(vi, G))dv′"
  - [corpus] Moderate - Perkovic (2020) provides the foundational PCO algorithm
- Break condition: When the MPDAG contains undirected edges between intervened and non-intervened variables

### Mechanism 3
- Claim: The constrained optimization problem balances fairness and accuracy through a tunable parameter
- Mechanism: The objective function minimizes prediction loss while adding a fairness penalty term measured by the difference between interventional distributions. The parameter λ controls the trade-off, allowing the model to find a Pareto-optimal solution between RMSE and unfairness.
- Core assumption: The unfairness term can be approximated using Monte Carlo sampling and MMD
- Evidence anchors:
  - [section 3.2] "min_θ 1/n ∑i=1^n ℓ(ŷi, yi) + λ|P(ŶA←a,Xad←xad) − P(ŶA←a′,Xad←xad)|"
  - [section 4.3] "we employ Maximum Mean Discrepancy (MMD)... but other measures can also be utilized"
  - [corpus] Strong - MMD is a well-established method for distribution comparison
- Break condition: When the MMD approximation becomes computationally intractable or the fairness penalty overwhelms the prediction loss

## Foundational Learning

- Concept: Causal graphs and d-separation
  - Why needed here: The entire framework relies on understanding causal relationships and conditional independence encoded in the MPDAG
  - Quick check question: Given an MPDAG, can you determine if two variables are d-separated given a conditioning set?

- Concept: Interventions and do-calculus
  - Why needed here: Interventional fairness is defined using do(A=a) operators, and the identification formula uses post-interventional densities
  - Quick check question: What is the difference between P(Y=y|do(A=a)) and P(Y=y|A=a) in terms of causal interpretation?

- Concept: Markov equivalence classes and MPDAGs
  - Why needed here: The paper works with MPDAGs as representations of Markov equivalence classes, and the augmentation technique relies on properties of these graphs
  - Quick check question: How does an MPDAG differ from a CPDAG, and when would you use one versus the other?

## Architecture Onboarding

- Component map: Data preprocessing -> Learn MPDAG from observational data + background knowledge -> Graph augmentation -> Conditional density estimation -> Interventional data generation -> Model training -> Evaluation

- Critical path:
  1. Learn MPDAG G from data
  2. Generate background knowledge and refine to MPDAG G'
  3. Augment G' to G* with Ŷ
  4. Estimate conditional densities f(vi|pa(vi, G))
  5. Generate interventional training data
  6. Train model with fairness-constrained optimization
  7. Evaluate on test interventional data

- Design tradeoffs:
  - Computational cost vs accuracy: Exact MMD computation vs Monte Carlo approximation
  - Model complexity vs fairness: Including all descendants vs only non-descendants of sensitive attribute
  - Background knowledge quality vs model performance: More accurate background knowledge leads to better MPDAG but may be harder to obtain

- Failure signatures:
  - High unfairness despite optimization: Identification condition not satisfied (undirected edges between intervened and non-intervened variables)
  - Poor RMSE despite tuning λ: Conditional density estimation errors or model misspecification
  - Unstable results across runs: Insufficient interventional data or poor MMD approximation

- First 3 experiments:
  1. Synthetic data with known DAG → derive MPDAG → test identification condition satisfaction
  2. Real data with varying background knowledge amounts → measure impact on fairness-accuracy tradeoff
  3. Unidentifiable cases → implement averaging over multiple MPDAGs → compare to identifiable case performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed framework be extended to handle scenarios with selection bias or latent confounders?
- Basis in paper: [explicit] The authors acknowledge that their framework assumes the absence of selection bias and latent confounders, but note that this is a limitation of the work.
- Why unresolved: Addressing selection bias and latent confounders is a significant challenge in causal inference and fair machine learning. The authors do not provide any suggestions or preliminary work on how their framework could be adapted to handle these issues.
- What evidence would resolve it: Demonstrating the effectiveness of the framework on real-world datasets that exhibit selection bias or latent confounders, or proposing and validating modifications to the framework to account for these factors.

### Open Question 2
- Question: How does the choice of kernel function and bandwidth in the MMD calculation impact the fairness-accuracy trade-off?
- Basis in paper: [explicit] The authors mention that they use the Gaussian RBF kernel for MMD, but note that other kernel functions can be utilized.
- Why unresolved: The choice of kernel function and bandwidth can significantly impact the performance of MMD-based methods. The authors do not provide any analysis or justification for their choice of kernel function and bandwidth.
- What evidence would resolve it: Conducting experiments with different kernel functions and bandwidths to evaluate their impact on the fairness-accuracy trade-off and model performance.

### Open Question 3
- Question: How does the proposed framework compare to other fairness-aware learning methods that do not rely on causal inference?
- Basis in paper: [inferred] The authors do not provide any direct comparisons with non-causal fairness-aware learning methods.
- Why unresolved: The proposed framework is based on causal inference, which may introduce additional assumptions and complexity compared to other fairness-aware learning methods. It is unclear how the framework's performance and trade-offs compare to these alternative approaches.
- What evidence would resolve it: Conducting experiments comparing the proposed framework to state-of-the-art fairness-aware learning methods that do not rely on causal inference, evaluating their performance and trade-offs on various datasets and fairness metrics.

## Limitations

- Graph augmentation validity is asserted but not rigorously proven for all MPDAG structures
- Computational scalability becomes problematic for real-world graphs with hundreds of nodes
- Method assumes access to reliable background knowledge, which may be limited or noisy in practice

## Confidence

- High: The constrained optimization formulation and its implementation using MMD for fairness measurement
- Medium: The identification condition for interventional fairness on MPDAGs
- Low: The graph augmentation technique that creates augmented-G with Ŷ

## Next Checks

1. **Empirical validation of graph augmentation**: Create a comprehensive test suite of MPDAGs and verify that augmented-G with Ŷ satisfies Meek's rules in all cases. Identify any graph structures where the augmentation fails.

2. **Scalability analysis**: Benchmark the approach on progressively larger synthetic graphs (50, 100, 200 nodes) to determine computational limits. Measure runtime and memory usage for each component: conditional density estimation, MMD computation, and optimization.

3. **Robustness to background knowledge noise**: Systematically vary the accuracy of background knowledge (0% to 100% correct edges) and measure the impact on fairness-accuracy tradeoffs. Determine the minimum accuracy threshold required for the approach to outperform unconstrained methods.