---
ver: rpa2
title: Improved Forward-Forward Contrastive Learning
arxiv_id: '2405.03432'
source_url: https://arxiv.org/abs/2405.03432
tags:
- learning
- algorithm
- layer
- ffcl
- backpropagation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the computational inefficiency and biological
  implausibility of the Forward-Forward Contrastive Learning (FFCL) algorithm, which
  uses a three-stage training process with backpropagation. The proposed method eliminates
  the final two stages of FFCL and relies solely on local updates using two separate
  instances of the same model.
---

# Improved Forward-Forward Contrastive Learning

## Quick Facts
- arXiv ID: 2405.03432
- Source URL: https://arxiv.org/abs/2405.03432
- Reference count: 13
- Primary result: Achieves up to 63% test accuracy on MNIST after 30 epochs using only local updates

## Executive Summary
This paper proposes a simplified version of Forward-Forward Contrastive Learning (FFCL) that eliminates backpropagation by using only local updates between two synchronized models. The method replaces FFCL's three-stage training process with a single-stage approach where each model processes the same positive data independently, and corresponding layers use cosine embedding loss to pull representations closer. The approach aims to be more biologically plausible by mimicking mirror neuron behavior, where outputs from one model's layers guide learning in the corresponding layers of the second model.

## Method Summary
The method uses two identical neural networks trained simultaneously on MNIST data, each with architecture 784→64→64→10. Both models process the same input images in parallel, and for each corresponding layer pair, cosine embedding loss is computed between layer outputs to drive local weight updates using Adam optimizer. The final classification layer uses binary cross-entropy loss instead of representation loss. This eliminates the need for global backpropagation by relying solely on layer-wise contrastive updates between the two models, with each model's layer outputs serving as guidance signals for the corresponding layer in the other model.

## Key Results
- Test accuracy reaches up to 63% on MNIST after 30 epochs
- Training and testing losses show exponential decay indicative of successful training
- Initial test accuracy starts near 37% and improves during training
- Demonstrates viability of local contrastive updates as an alternative to backpropagation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method removes backpropagation entirely by using local contrastive updates between two synchronized models.
- Mechanism: Each model processes the same positive data independently. Corresponding layers use cosine embedding loss to pull their representations closer, enabling local weight updates without global error propagation.
- Core assumption: Shared representations across models provide sufficient gradient-like signals for each layer to update meaningfully.
- Evidence anchors:
  - [abstract] "we rely solely on local updates, offering a more biologically plausible alternative."
  - [section] "For local updates we have used Representation Loss (RL) for all trainable layers except last output layer were Classification Loss (CL) has been used."

### Mechanism 2
- Claim: The output from one model's layer serves as a guiding signal for the corresponding layer in the other model.
- Mechanism: After forward propagation, each layer's output from model A is used as a target for the corresponding layer in model B, mimicking mirror neuron-like imitation.
- Core assumption: Layer-wise representations from one model are sufficiently informative to guide learning in the other without a global loss.
- Evidence anchors:
  - [abstract] "leveraging outputs from one model's layers to guide learning in the corresponding layer of the second model, akin to the role of mirror neurons in the brain."
  - [section] "we employed the output from one model's layer as a guiding tool to train the corresponding layer in the second model."

### Mechanism 3
- Claim: Two independent models trained on the same data can reach comparable performance to FFCL's three-stage pipeline.
- Mechanism: Parallel training with layer-wise contrastive loss substitutes for global backpropagation, while the classification layer uses binary cross-entropy to maintain task performance.
- Core assumption: Layer-wise contrastive learning is sufficient to approximate the global gradient flow normally provided by backpropagation.
- Evidence anchors:
  - [section] "Both training and testing phases exhibited an exponential decay in losses, indicative of successful ANN training. Initially, the testing accuracy for both models started near 37% and eventually reached as high as 63% during training."

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: Enables similarity maximization between two views of the same data without labeled pairs beyond positive sampling.
  - Quick check question: What loss function is used to compare outputs between corresponding layers in the two models?

- Concept: Local versus global learning updates
  - Why needed here: Removes the need for global error backpropagation, replacing it with independent layer-level optimization.
  - Quick check question: Which layer in the architecture uses classification loss instead of representation loss?

- Concept: Mirror neuron hypothesis
  - Why needed here: Provides a biological analogy for why using one model's outputs to guide another's learning is plausible.
  - Quick check question: What biological system does the paper reference to justify layer-wise cross-model guidance?

## Architecture Onboarding

- Component map:
  - Input layer: 784 nodes (MNIST flattened)
  - Hidden layers: Two layers of 64 ReLU units each
  - Output layer: 10 softmax units (classification)
  - Loss functions: Cosine embedding loss for hidden layers, binary cross-entropy for output
  - Optimizers: Adam with learning rate 0.0001 for both models

- Critical path: Forward pass through both models → layer-wise contrastive loss computation → Adam updates on each model independently

- Design tradeoffs:
  - Single-stage training vs. FFCL's three-stage: Faster but potentially lower accuracy ceiling
  - Local updates vs. global gradients: Biologically plausible but may limit deep network coordination
  - Dual model necessity: Doubles memory and computation, but enables layer-wise supervision

- Failure signatures:
  - Training loss plateaus early with no accuracy gain
  - Models diverge in representation space (loss stops decreasing)
  - Output accuracy remains near random chance after multiple epochs

- First 3 experiments:
  1. Run a single epoch with one model frozen and the other trained; verify that representation loss decreases.
  2. Enable both models training in parallel; monitor layer-wise loss curves for convergence.
  3. Evaluate classification accuracy after each epoch; confirm that accuracy improves beyond random chance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed single-stage Forward-Forward Contrastive Learning (FFCL) algorithm compare in performance to the original three-stage FFCL algorithm and backpropagation-based methods on more complex datasets?
- Basis in paper: [explicit] The paper mentions that the proposed method achieves a test accuracy of up to 63% on MNIST after 30 epochs, which is lower than what is typically achieved by backpropagation-based methods. The paper also mentions that the original FFCL algorithm uses a three-stage training process, with the final stage relying on backpropagation.
- Why unresolved: The paper only presents results on the MNIST dataset and does not compare the proposed method to the original FFCL algorithm or backpropagation-based methods on more complex datasets.
- What evidence would resolve it: Conducting experiments on more complex datasets, such as CIFAR-10 or ImageNet, and comparing the performance of the proposed method to the original FFCL algorithm and backpropagation-based methods.

### Open Question 2
- Question: Can the proposed method be extended to deeper neural networks with more layers and achieve better performance?
- Basis in paper: [inferred] The paper presents a model with four linear layers, including two hidden layers with 64 nodes each. It is not clear if the proposed method can be extended to deeper neural networks with more layers.
- Why unresolved: The paper does not explore the scalability of the proposed method to deeper neural networks.
- What evidence would resolve it: Conducting experiments with deeper neural networks, such as those with more hidden layers or a larger number of nodes per layer, and evaluating the performance of the proposed method.

### Open Question 3
- Question: How does the proposed method's performance scale with the size of the training dataset?
- Basis in paper: [inferred] The paper uses the entire MNIST training dataset for training the model. It is not clear how the proposed method's performance scales with the size of the training dataset.
- Why unresolved: The paper does not investigate the impact of the training dataset size on the proposed method's performance.
- What evidence would resolve it: Conducting experiments with different sizes of the training dataset, such as using only a fraction of the MNIST training data, and evaluating the performance of the proposed method.

## Limitations

- The method achieves only 63% accuracy on MNIST, significantly below backpropagation-based methods
- No comparison provided with original FFCL algorithm or other state-of-the-art approaches
- Limited evaluation only on MNIST dataset without testing scalability to more complex tasks
- Biological plausibility claims are asserted but not empirically validated

## Confidence

- Accuracy claims: Low - limited evaluation scope (single dataset, single architecture)
- Conceptual contribution: Medium - method is clearly described but results are sparse
- Biological plausibility: Low - mirror neuron analogy is asserted without empirical testing

## Next Checks

1. Implement the layer-wise contrastive loss between corresponding layers and verify it decreases during training.
2. Test whether using outputs from one model to guide the other's layer training actually improves accuracy versus independent training.
3. Evaluate model divergence over training epochs to confirm the two models maintain distinct but coordinated representations.