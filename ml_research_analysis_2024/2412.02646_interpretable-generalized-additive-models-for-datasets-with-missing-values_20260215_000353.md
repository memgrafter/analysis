---
ver: rpa2
title: Interpretable Generalized Additive Models for Datasets with Missing Values
arxiv_id: '2412.02646'
source_url: https://arxiv.org/abs/2412.02646
tags:
- missing
- data
- missingness
- m-gam
- imputation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces M-GAM, a sparse generalized additive modeling\
  \ approach that handles missing data without imputation by incorporating missingness\
  \ indicators and interaction terms. The method uses \u21130 regularization to maintain\
  \ sparsity, enabling interpretable models even when modeling interactions with missing\
  \ data."
---

# Interpretable Generalized Additive Models for Datasets with Missing Values

## Quick Facts
- arXiv ID: 2412.02646
- Source URL: https://arxiv.org/abs/2412.02646
- Reference count: 40
- This paper introduces M-GAM, a sparse generalized additive modeling approach that handles missing data without imputation by incorporating missingness indicators and interaction terms.

## Executive Summary
This paper introduces M-GAM, a sparse generalized additive modeling approach that handles missing data without imputation by incorporating missingness indicators and interaction terms. The method uses ℓ0 regularization to maintain sparsity, enabling interpretable models even when modeling interactions with missing data. Experiments show that M-GAM achieves comparable or superior accuracy to impute-then-predict methods while producing significantly sparser models.

## Method Summary
M-GAM extends GAMs to handle missing data by adding missingness indicators and interaction terms to the feature set, then applying ℓ0 regularization to maintain sparsity. For each feature, M-GAM creates boolean indicators for whether that feature is missing and uses interaction terms to capture how missingness in one feature affects the relationship between others and the outcome. The model is trained using FastSparse optimization to minimize exponential loss while directly optimizing for sparse models with ℓ0 regularization.

## Key Results
- M-GAM matches the accuracy of multiple imputation approaches on real datasets
- On semi-synthetic data with informative missingness, M-GAM substantially outperforms imputation methods
- M-GAM produces significantly sparser models than competing methods while maintaining comparable accuracy

## Why This Works (Mechanism)

### Mechanism 1
M-GAM preserves interpretability in the presence of missing data by maintaining a sum of univariate shape functions, even when incorporating missingness indicators and their interactions. The key idea is to augment each original shape function with missingness adjustment terms that modify its behavior when certain features are missing. Instead of imputing missing values and creating multivariate features, M-GAM uses simple boolean adjustments to existing univariate shape curves.

### Mechanism 2
ℓ0 regularization enables M-GAM to handle the explosion of missingness indicators and interaction terms while maintaining sparsity and interpretability. By using ℓ0 regularization (rather than ℓ1), M-GAM directly optimizes for models with fewer non-zero coefficients. This allows inclusion of all missingness indicators and interactions without overfitting, as the regularization encourages many coefficients to be exactly zero.

### Mechanism 3
M-GAM can achieve comparable or superior accuracy to impute-then-predict methods, especially when missingness contains information about the outcome (informative missingness). By incorporating missingness indicators and interactions directly into the model, M-GAM can capture information about the outcome that would be lost through imputation. Proposition 3.1 shows that using missingness as a value can be more informative than imputation when missingness depends on the outcome.

## Foundational Learning

- Concept: Generalized Additive Models (GAMs) and their interpretability properties
  - Why needed here: M-GAM builds directly on GAMs by extending them to handle missing data while preserving the interpretability that comes from the sum of univariate shape functions
  - Quick check question: What makes GAMs interpretable compared to other model classes like random forests or neural networks?

- Concept: Missing data mechanisms (MCAR, MAR, MNAR)
  - Why needed here: Understanding different missing data mechanisms is crucial for evaluating when M-GAM will be most effective and how it compares to imputation-based approaches
  - Quick check question: How does the M-GAM approach differ when handling MCAR versus MNAR missingness patterns?

- Concept: ℓ0 regularization and sparse optimization
  - Why needed here: M-GAM uses ℓ0 regularization to maintain sparsity despite the explosion of missingness indicators and interaction terms, which is central to its ability to produce interpretable models
  - Quick check question: What are the computational challenges of ℓ0 regularization compared to ℓ1, and how does the paper address them?

## Architecture Onboarding

- Component map:
  - Input layer: Original features with missing values (xi ∈ (R ∪ {NA})d)
  - Missingness encoding: Boolean indicators for each type of missingness and interaction terms
  - Shape functions: Univariate functions fj for each feature, augmented with missingness adjustments hj
  - Missingness interaction terms: hj,j' functions that modify shape functions when other features are missing
  - ℓ0 regularization layer: Directly optimizes for sparse models by encouraging zero coefficients
  - Output layer: Binary classification via exponential loss minimization

- Critical path:
  1. Encode missingness as boolean indicators and interaction terms
  2. Construct augmented feature matrix with all thresholds, missingness indicators, and interactions
  3. Apply ℓ0 regularization during optimization to encourage sparsity
  4. Train model to minimize exponential loss while maintaining sparsity
  5. Evaluate model performance and sparsity on held-out data

- Design tradeoffs:
  - M-GAM vs. imputation: M-GAM preserves interpretability but may miss some complex multivariate relationships that imputation could capture; imputation preserves some relationships but creates uninterpretable multivariate features
  - ℓ0 vs. ℓ1 regularization: ℓ0 directly optimizes for sparsity but is computationally more expensive; ℓ1 is computationally efficient but may not produce truly sparse models
  - Number of thresholds: More thresholds increase model flexibility but also increase dimensionality and computational cost

- Failure signatures:
  - Poor performance on datasets where missingness is truly random and contains no predictive information
  - Computational intractability when the number of features (including missingness terms) becomes extremely large
  - Over-regularization leading to underfitting when important interaction terms are excluded
  - Difficulty handling missingness patterns that cannot be captured by simple boolean adjustments

- First 3 experiments:
  1. Run M-GAM on a simple dataset with artificially added missingness to verify that it maintains interpretability while achieving reasonable accuracy
  2. Compare M-GAM to GAM with multiple imputation on a real-world dataset to verify comparable accuracy claims
  3. Test M-GAM's sparsity by varying the ℓ0 regularization strength and measuring the number of non-zero coefficients retained

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does M-GAM's performance change when the missingness rate exceeds 50%?
- Basis in paper: [explicit] The paper tests M-GAM with up to 50% synthetic MAR missingness
- Why unresolved: The paper does not test missingness rates above 50%, which could reveal performance limits
- What evidence would resolve it: Experimental results showing M-GAM performance on datasets with 60-90% missingness rates

### Open Question 2
- Question: Does M-GAM maintain its interpretability advantage when applied to high-dimensional datasets with hundreds of features?
- Basis in paper: [inferred] The paper mentions ℓ0 regularization for sparsity but doesn't test M-GAM on very high-dimensional data
- Why unresolved: All tested datasets have relatively low feature counts (23-49 features), leaving scalability questions unanswered
- What evidence would resolve it: Experiments comparing M-GAM interpretability and performance on datasets with 100+ features

### Open Question 3
- Question: How sensitive is M-GAM's performance to the choice of binning strategy (number of quantiles) in the shape functions?
- Basis in paper: [explicit] The paper tests 4, 8, 16, and 32 quantiles but only on one dataset
- Why unresolved: Results show different quantile numbers affect performance, but the paper doesn't systematically explore this sensitivity across datasets
- What evidence would resolve it: Comprehensive sensitivity analysis showing M-GAM performance across different binning strategies on all tested datasets

## Limitations

- The computational scalability of ℓ0 regularization for very high-dimensional problems with extensive missingness patterns remains untested
- While strong performance is demonstrated on benchmark datasets, results on semi-synthetic data with informative missingness are less extensively validated
- The method's performance when missingness rates exceed 50% has not been evaluated

## Confidence

- **High Confidence**: Claims about M-GAM's ability to achieve comparable accuracy to imputation methods on real datasets, and its superior performance on semi-synthetic data with informative missingness
- **Medium Confidence**: Claims about the interpretability preservation mechanism and the computational advantages of ℓ0 regularization
- **Low Confidence**: Claims about scalability to very high-dimensional problems with extensive missingness patterns

## Next Checks

1. Test M-GAM on datasets with varying missingness mechanisms (MCAR, MAR, MNAR) to verify the robustness of the boolean indicator approach across different scenarios
2. Benchmark M-GAM against state-of-the-art imputation methods on a wider range of real-world datasets with known missingness patterns
3. Evaluate the computational scalability of M-GAM by testing on synthetic datasets with increasing numbers of features and missingness patterns to identify performance limits