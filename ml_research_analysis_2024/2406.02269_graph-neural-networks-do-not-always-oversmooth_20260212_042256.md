---
ver: rpa2
title: Graph Neural Networks Do Not Always Oversmooth
arxiv_id: '2406.02269'
source_url: https://arxiv.org/abs/2406.02269
tags:
- phase
- networks
- gcns
- graph
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper shows that graph neural networks (GCNs) can avoid oversmoothing\u2014\
  a common problem where node features converge to the same values\u2014by initializing\
  \ with a sufficiently large weight variance. Using the Gaussian process (GP) equivalence\
  \ of infinitely wide GCNs, the authors analyze the linearized dynamics around equilibrium\
  \ and find that an eigenvalue condition determines whether a network is in the oversmoothing\
  \ or non-oversmoothing phase."
---

# Graph Neural Networks Do Not Always Oversmooth

## Quick Facts
- arXiv ID: 2406.02269
- Source URL: https://arxiv.org/abs/2406.02269
- Authors: Bastian Epping; Alexandre René; Moritz Helias; Michael T. Schaub
- Reference count: 40
- Key outcome: GCNs can avoid oversmoothing by initializing with sufficiently large weight variance

## Executive Summary
Graph neural networks typically suffer from oversmoothing, where node features converge to the same values over many layers. This paper shows that by initializing with a sufficiently large weight variance, GCNs can avoid oversmoothing and maintain distinct features even at large depths. The authors analyze infinitely wide GCNs using Gaussian process (GP) equivalence and linearize the covariance dynamics around a constant-covariance fixed point. They find that when weight variance exceeds a critical threshold, the fixed point becomes unstable, preventing oversmoothing and enabling deep, expressive networks.

## Method Summary
The paper analyzes infinitely wide GCNs using GP equivalence, where hidden features at each layer are jointly Gaussian distributed. The authors derive recursive equations for the covariance between node features and linearize these dynamics around the constant-covariance fixed point. By computing eigenvalues of the linearized system, they determine whether the network is in the oversmoothing or non-oversmoothing phase. Experiments on synthetic CSBM data and the Cora citation network confirm that GCNs initialized near the transition point achieve high performance even with over 100 layers, matching state-of-the-art results while avoiding typical oversmoothing degradation.

## Key Results
- GCNs initialized with large weight variance avoid oversmoothing and maintain distinct node features at large depths
- The transition between oversmoothing and non-oversmoothing phases is determined by an eigenvalue condition in the linearized covariance dynamics
- GCNs near the transition point achieve high classification accuracy on Cora with over 100 layers, matching state-of-the-art performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large weight variance at initialization prevents oversmoothing by destabilizing the fixed point where all node features converge to the same vector.
- Mechanism: In the GP limit, the covariance matrix dynamics are linearized around the "constant covariance" fixed point. If the weight variance is large enough, the eigenvalues of the linearized system exceed 1 in magnitude, making that fixed point unstable. This instability forces node features to remain distinguishable at large depth.
- Core assumption: The linearization around the constant-covariance fixed point accurately predicts finite-size GCN behavior, and the GP equivalence holds well for large hidden feature dimensions.
- Evidence anchors:
  - [abstract] "if the initial weights of the network have sufficiently large variance, GCNs do not oversmooth"
  - [section] "The chaotic, non-oversmoothing phase of a GCN is determined by the condition that this point of constant covariance becomes unstable"
  - [corpus] Weak evidence: related papers discuss oversmoothing mitigation but do not analyze the eigenvalue instability condition.
- Break condition: If the linearization approximation fails (e.g., very small hidden feature dimensions) or if the shift operator does not preserve the constant-covariance fixed point.

### Mechanism 2
- Claim: The propagation depth in GCNs is determined by eigendirections of the linearized covariance dynamics, generalizing the DNN case to a multidimensional setting.
- Mechanism: Instead of a single propagation depth, each eigendirection of the linearized covariance update has its own depth. Near the transition to non-oversmoothing, at least one eigendirection has an infinite propagation depth (eigenvalue approaching 1), allowing information to propagate arbitrarily deep.
- Core assumption: The linearized dynamics capture the true information propagation properties of the full nonlinear GCN.
- Evidence anchors:
  - [abstract] "we generalize the concept of propagation depth of information from DNNs to GCNs"
  - [section] "we find that a given GCN architecture comes with a set of potentially different information propagation depths, each corresponding to one eigendirection"
  - [corpus] Weak evidence: related work mentions oversmoothing but does not analyze eigendirections of linearized dynamics.
- Break condition: If the nonlinear effects dominate early, or if the shift operator couples eigendirections strongly, breaking the independent evolution assumption.

### Mechanism 3
- Claim: Near the transition to non-oversmoothing, GCNs balance feature information and graph structure information, achieving good performance at large depth.
- Mechanism: In the chaotic phase, the equilibrium state retains information about graph topology even when input features are washed out. This topology information is sufficient for tasks like node classification, especially when the graph structure correlates with labels.
- Core assumption: The equilibrium covariance contains discriminative information about node roles or communities, and the readout can extract it effectively.
- Evidence anchors:
  - [abstract] "Near the transition point, GCNs at large depth offer a trade-off between feature information and information contained in the neighborhood relation of the graph"
  - [section] "At point B ... one can recognize the community structure of the CSBM: the lower left and upper right quadrants are lighter than the diagonal ones"
  - [corpus] Weak evidence: related papers discuss heuristics for deep GNNs but not the topology-information trade-off near the transition.
- Break condition: If the graph structure is not informative of the task, or if the readout cannot leverage the equilibrium covariance effectively.

## Foundational Learning

- Concept: Gaussian Process equivalence of infinitely wide neural networks
  - Why needed here: The paper's theoretical analysis relies on replacing the finite GCN with its GP limit to obtain tractable dynamics of the covariance matrix over layers.
  - Quick check question: What does the GP equivalence tell us about the distribution of hidden features in a deep GCN?

- Concept: Linearization of nonlinear dynamics around a fixed point
  - Why needed here: To analyze stability and propagation depth, the GCN's covariance update rule is linearized around the constant-covariance fixed point, reducing the problem to eigenvalue analysis.
  - Quick check question: How does the eigenvalue magnitude relative to 1 determine stability in the linearized system?

- Concept: Eigendecomposition of coupled dynamical systems
  - Why needed here: The shift operator in GCNs couples node features, so the linearized system is a large matrix acting on vectorized covariances; eigendecomposition decouples the evolution along independent directions.
  - Quick check question: Why does the GCN case require solving for N² eigenvalues instead of a single scalar as in standard DNNs?

## Architecture Onboarding

- Component map:
  - Input features X^(0) ∈ R^(N×d₀) -> Row-stochastic shift operator A ∈ R^(N×N) -> Message passing with weight matrices W^(l) -> Activation φ -> Output readout

- Critical path:
  1. Initialize weights from N(0, σ²_w/d_l) for each layer
  2. Propagate features via X^(l) = φ(A X^(l-1) W^(l)⊤ + 1b^(l)⊤)
  3. Compute equilibrium covariance via GP recursion
  4. Linearize around constant-covariance fixed point
  5. Compute eigenvalues; check if max|λ| > 1 to detect non-oversmoothing phase
  6. If in non-oversmoothing phase, train readout or use equilibrium features for classification

- Design tradeoffs:
  - Larger σ²_w → more non-oversmoothing but potentially higher variance in equilibrium features
  - Row-stochastic shift operator → guarantees constant-covariance fixed point, simplifying analysis
  - Activation choice → erf allows analytic C(l)γδ; other choices require numerical integration
  - Infinite width assumption → good approximation for large d_l, breaks down for small d_l

- Failure signatures:
  - All pairwise feature distances → 0 as depth increases (oversmoothing)
  - Equilibrium covariance has zero entries for all nodes (no information retained)
  - Eigenvalue condition max|λ| < 1 (stable fixed point, oversmoothing persists)
  - Performance degrades rapidly with depth in oversmoothing regime

- First 3 experiments:
  1. Implement GCN GP recursion for a small complete graph; verify constant-covariance fixed point and compute transition σ²_w,crit
  2. Apply eigenvalue analysis to linearized dynamics for a stochastic block model; confirm non-oversmoothing above σ²_w,crit
  3. Train readout layer on equilibrium features from a GCN in non-oversmoothing phase; measure classification accuracy on Cora dataset at large depth

## Open Questions the Paper Calls Out

- Can the non-oversmoothing phase be achieved with other graph neural network architectures beyond GCNs?
- What is the exact relationship between the critical weight variance and graph properties like diameter, spectral gap, or community structure?
- How do finite feature dimensions affect the critical weight variance and the transition between phases?

## Limitations

- The theoretical analysis relies on Gaussian process equivalence and linearization approximations that may not fully capture finite-width GCN behavior
- The eigenvalue condition for non-oversmoothing assumes perfect stability analysis of the constant-covariance fixed point, which may not hold for all real-world graphs
- Practical applicability depends on finding the critical weight variance for each architecture, which requires full eigenvalue analysis

## Confidence

- **High confidence**: The experimental demonstration that increasing weight variance prevents oversmoothing on both synthetic and real datasets
- **Medium confidence**: The theoretical analysis using GP equivalence and linearization, as it depends on infinite-width assumptions and approximate stability calculations
- **Medium confidence**: The claim about eigendirections of linearized dynamics determining propagation depth, as this extends previous DNN results to the coupled GCN setting

## Next Checks

1. Test on graphs with high degree variance to verify the theory holds for graphs where the row-stochastic shift operator assumption is less accurate
2. Compare GP predictions with finite-width GCNs of varying hidden dimension to quantify the infinite-width approximation error
3. Test whether the non-oversmoothing transition occurs similarly for different activation functions beyond erf, or if it's specific to the analytical tractability of the GP recursion