---
ver: rpa2
title: A Novel LLM-based Two-stage Summarization Approach for Long Dialogues
arxiv_id: '2410.06520'
source_url: https://arxiv.org/abs/2410.06520
tags:
- summarization
- input
- document
- data
- summary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a hierarchical two-stage framework for summarizing
  long dialogues. The approach first segments the input text using an unsupervised
  topic segmentation method based on BERT embeddings, then condenses each segment
  via zero-shot prompting with ChatGPT (v3.5).
---

# A Novel LLM-based Two-stage Summarization Approach for Long Dialogues

## Quick Facts
- arXiv ID: 2410.06520
- Source URL: https://arxiv.org/abs/2410.06520
- Authors: Yuan-Jhe Yin; Bo-Yu Chen; Berlin Chen
- Reference count: 29
- One-line primary result: Proposed two-stage summarization framework achieves ROUGE-1 score of 29.15 on ForeverDreaming dataset, outperforming baseline models.

## Executive Summary
This paper introduces a hierarchical two-stage framework for summarizing long dialogues that exceed typical model input lengths. The approach first segments input text using unsupervised topic segmentation based on BERT embeddings, then condenses each segment via zero-shot prompting with ChatGPT (v3.5). The condensed summaries and event lists are concatenated with lead-k utterances and used to fine-tune a BART model for final abstractive summarization. Experimental results on the ForeverDreaming dataset demonstrate superior performance compared to baseline models, achieving a ROUGE-1 score of 29.15.

## Method Summary
The framework employs a two-stage architecture: first, unsupervised topic segmentation using BERT embeddings identifies semantic breakpoints to split long dialogues into manageable segments. Second, zero-shot ChatGPT condensation generates first-stage summaries and event lists for each segment. These are combined with lead-k utterances from the original text and used to fine-tune a BART model for final summarization. This approach addresses the challenge of processing long documents while minimizing computational resources and avoiding extensive training requirements.

## Key Results
- Achieves ROUGE-1 score of 29.15 on ForeverDreaming dataset
- Outperforms baseline models: BART (19.35), LongFormer (15.39), and T5 (18.57)
- Demonstrates that lead-k utterance injection improves summarization quality by restoring critical context
- Shows that event list generation combined with first-stage summaries produces better results than single-stage approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unsupervised topic segmentation with BERT embeddings reduces semantic drift across segments.
- Mechanism: BERT embeddings provide semantic sentence representations; cosine similarity between consecutive embeddings identifies breakpoints where topical coherence drops, enabling meaningful splits.
- Core assumption: BERT embeddings capture sufficient semantic similarity to distinguish topic boundaries without labeled data.
- Evidence anchors: Referenced approach from [9] with sliding window method for BERT embedding calculation.
- Break condition: If cosine similarity variance is too low, greedy segmentation may create too many fragments, losing context.

### Mechanism 2
- Claim: Zero-shot prompting with ChatGPT condenses segments into coherent first-stage summaries without training labels.
- Mechanism: ChatGPT receives prompt-guided instructions to summarize or list events per segment; outputs are concatenated to form a condensed document suitable for downstream summarization.
- Core assumption: ChatGPT's generation capabilities are sufficient to capture essential information from short segments in zero-shot mode.
- Evidence anchors: ChatGPT (v3.5) generates first-stage summaries ensuring length meets BART input requirements.
- Break condition: If segments are too long or too short, ChatGPT may produce summaries that are either too vague or too detailed.

### Mechanism 3
- Claim: Lead-k utterance injection restores critical context lost during segmentation and condensation.
- Mechanism: The first k utterances of the original text are prepended to the condensed data before BART fine-tuning, providing explicit anchors to the original document structure.
- Core assumption: Early utterances contain key contextual cues that help BART maintain fidelity to the original document's meaning.
- Evidence anchors: Lead-k injection enriches input text, resulting in better ROUGE scores.
- Break condition: Excessive k may overwhelm the condensed content, reducing summarization focus.

## Foundational Learning

- Concept: Text segmentation based on semantic similarity
  - Why needed here: Prevents loss of topical coherence when splitting long documents into manageable chunks for summarization.
  - Quick check question: How does cosine similarity between BERT embeddings indicate a topic boundary?

- Concept: Zero-shot prompting for data condensation
  - Why needed here: Enables transformation of long segments into concise summaries without requiring labeled training data for the condensation stage.
  - Quick check question: What are the risks of relying on zero-shot prompting for summarization quality?

- Concept: Fine-tuning abstractive summarization models
  - Why needed here: Trains a downstream model (BART) on condensed data to produce final summaries that reflect both condensed and original content.
  - Quick check question: Why is fine-tuning on condensed data more efficient than training on full long documents?

## Architecture Onboarding

- Component map: Input document → BERT-based unsupervised segmentation → Segment-wise ChatGPT condensation → Lead-k injection → BART fine-tuning → Final summary
- Critical path: Segmentation → Condensation → Fine-tuning
- Design tradeoffs:
  - Trade memory efficiency for potential information loss; segmentation reduces input length but may fragment context.
  - Zero-shot prompting avoids training costs but may produce variable quality summaries.
  - Lead-k injection balances context restoration against input length constraints.
- Failure signatures:
  - ROUGE scores drop sharply if segmentation is too aggressive.
  - Summarization quality degrades if ChatGPT produces overly vague first-stage summaries.
  - Model overfitting or underfitting if lead-k injection is too large or too small.
- First 3 experiments:
  1. Vary segmentation granularity (number of segments) and measure ROUGE impact.
  2. Compare zero-shot prompting with event list generation vs. direct summarization prompts.
  3. Test different k values for lead-k injection and analyze trade-off between context and coherence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different topic segmentation algorithms (e.g., TextTiling vs. BERT-based) compare in terms of ROUGE scores and computational efficiency for long dialogue summarization?
- Basis in paper: [explicit] The paper uses BERT-based segmentation and references TextTiling algorithm as a baseline method.
- Why unresolved: The paper only implements and tests one segmentation method without comparing alternatives.
- What evidence would resolve it: Comparative experiments testing multiple segmentation algorithms on the same dataset and evaluating both ROUGE scores and computational costs.

### Open Question 2
- Question: What is the optimal balance between event list generation and first-stage summary length for maximizing summarization quality?
- Basis in paper: [explicit] The paper mentions that combining event lists with first-stage summaries improves results but doesn't explore the optimal ratio.
- Why unresolved: The paper uses a fixed approach but doesn't systematically investigate how varying the proportion affects outcomes.
- What evidence would resolve it: Ablation studies varying the relative lengths of event lists and first-stage summaries while measuring ROUGE scores.

### Open Question 3
- Question: How does the proposed two-stage approach scale to document lengths beyond those tested in the ForeverDreaming dataset?
- Basis in paper: [inferred] The paper demonstrates effectiveness on a specific dataset but doesn't test extreme document lengths.
- Why unresolved: The paper validates the method on a single dataset without exploring performance boundaries.
- What evidence would resolve it: Testing the framework on progressively longer documents and analyzing performance degradation points.

## Limitations

- Unsupervised segmentation may create semantic drift between segments, potentially fragmenting crucial context for coherent summarization.
- Zero-shot ChatGPT condensation introduces variability in summary quality that depends heavily on prompt engineering choices not fully specified in the paper.
- Lead-k injection assumes early utterances contain sufficient representative information, which may not hold for all dialogue structures.

## Confidence

- **High confidence**: The hierarchical architecture design and overall effectiveness of the two-stage approach are well-supported by ROUGE-1 improvements over baseline models.
- **Medium confidence**: The specific contribution of each component (segmentation, ChatGPT condensation, lead-k injection) is demonstrated through ablation studies, but the exact impact of individual hyperparameters remains unclear.
- **Medium confidence**: The use of ROUGE metrics for evaluation is standard practice, though these metrics may not fully capture semantic fidelity and coherence in dialogue summarization.

## Next Checks

1. **Ablation study with varying segmentation parameters**: Systematically test different numbers of segments and sliding window sizes to quantify the impact of segmentation granularity on final summarization quality.
2. **Prompt engineering analysis**: Compare different ChatGPT prompt templates (summary vs. event list generation) to determine optimal zero-shot condensation strategies.
3. **Context restoration validation**: Experiment with varying k values for lead-k injection and measure the trade-off between context preservation and summary coherence.