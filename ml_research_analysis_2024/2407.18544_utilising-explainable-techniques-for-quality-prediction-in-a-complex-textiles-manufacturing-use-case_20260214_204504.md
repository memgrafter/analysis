---
ver: rpa2
title: Utilising Explainable Techniques for Quality Prediction in a Complex Textiles
  Manufacturing Use Case
arxiv_id: '2407.18544'
source_url: https://arxiv.org/abs/2407.18544
tags:
- features
- were
- feature
- data
- manufacturing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses quality prediction in a complex textiles manufacturing
  environment using explainable machine learning techniques. The research focuses
  on predicting product failure due to color deviations in woollen carpet manufacturing,
  using a dataset from a New Zealand manufacturer containing 300 instances with 372
  features across multiple processing stages.
---

# Utilising Explainable Techniques for Quality Prediction in a Complex Textiles Manufacturing Use Case

## Quick Facts
- arXiv ID: 2407.18544
- Source URL: https://arxiv.org/abs/2407.18544
- Reference count: 27
- Primary result: Random Forest with Boruta feature selection achieved precision 0.81 and F1 0.76 for color deviation prediction in woollen carpet manufacturing

## Executive Summary
This study addresses quality prediction in complex textiles manufacturing by developing explainable machine learning models to predict product failure due to color deviations. Using a dataset from a New Zealand carpet manufacturer containing 300 instances with 372 features across multiple processing stages, the research evaluates three tree-based classification algorithms and three feature selection methods. The work demonstrates that combining opaque models with post-hoc explainability techniques can achieve superior performance while maintaining interpretability, providing actionable insights for manufacturing quality control decisions.

## Method Summary
The research employed a three-pronged approach: first, three classification algorithms (Decision Tree, Random Forest, XGBoost) were trained and evaluated on the dataset; second, three feature selection techniques (SelectKBest, Pearson Correlation Coefficient, Boruta) were applied to identify the most predictive features; third, post-hoc rule extraction using TE2Rules was performed to maintain model interpretability. The methodology focused on predicting color deviation failures in woollen carpet manufacturing, with performance metrics including precision, recall, F1-score, and AUC-ROC. Feature engineering incorporated domain-specific statistical and calculated features to enhance model performance.

## Key Results
- Random Forest with Boruta feature selection achieved the best overall performance (precision 0.81, F1 0.76)
- Post-hoc rule extraction revealed that additional statistical and calculated features significantly improved model performance
- The approach successfully demonstrates that opaque models with post-hoc explainability techniques can outperform transparent models while maintaining interpretability

## Why This Works (Mechanism)
The success of this approach stems from combining the predictive power of ensemble methods with sophisticated feature selection and post-hoc explainability. Random Forest's ability to capture complex non-linear relationships in manufacturing data, combined with Boruta's comprehensive feature selection that considers both direct and interaction effects, enables accurate failure prediction. The post-hoc rule extraction through TE2Rules translates the model's decisions into interpretable patterns that manufacturing engineers can understand and act upon, bridging the gap between model complexity and practical usability.

## Foundational Learning
- **Tree-based classification algorithms**: Decision trees, Random Forest, and XGBoost provide hierarchical decision-making structures suitable for complex manufacturing data with mixed feature types
- **Feature selection methods**: SelectKBest uses statistical tests, Pearson Correlation identifies linear relationships, and Boruta uses random forest-based importance ranking to identify truly predictive features
- **Post-hoc explainability**: TE2Rules extracts interpretable decision rules from complex models, enabling domain experts to understand model decisions without sacrificing predictive performance
- **Manufacturing quality prediction**: Predicting color deviations requires understanding multiple processing stages and their cumulative effects on final product quality
- **Feature engineering in manufacturing**: Domain-specific statistical and calculated features can capture complex relationships between processing parameters and quality outcomes

## Architecture Onboarding
- **Component map**: Raw manufacturing data -> Preprocessing -> Feature selection (Boruta) -> Random Forest classification -> TE2Rules post-hoc explainability
- **Critical path**: Data preprocessing and feature selection constitute the most critical path, as poor feature engineering directly impacts model performance and interpretability
- **Design tradeoffs**: The study prioritizes predictive accuracy over model simplicity, accepting more complex models with post-hoc explainability rather than simpler transparent models
- **Failure signatures**: Model underperformance likely indicates insufficient feature engineering or inappropriate feature selection, while poor interpretability suggests inadequate post-hoc rule extraction
- **First experiments**: 1) Validate feature selection results by comparing model performance with and without selected features; 2) Test different tree-based algorithms to establish baseline performance; 3) Apply TE2Rules to different model configurations to optimize interpretability

## Open Questions the Paper Calls Out
None

## Limitations
- The dataset contains only 300 instances, which may not capture full production variability
- The research focuses exclusively on color deviation failures in woollen carpet manufacturing
- Feature engineering relies heavily on domain-specific statistical features that may not generalize to other manufacturing contexts

## Confidence
- Random Forest with Boruta performance claims: Medium
- Opaque models outperforming transparent models: Medium
- Generalizability to other manufacturing contexts: Low

## Next Checks
1. Test model performance on a larger, more diverse dataset from the same manufacturer to assess scalability and robustness
2. Apply the methodology to predict different types of quality failures (e.g., texture, dimensional accuracy) within the same manufacturing process
3. Conduct time-series validation by testing the model on data from different production periods to ensure temporal stability and prevent data leakage issues