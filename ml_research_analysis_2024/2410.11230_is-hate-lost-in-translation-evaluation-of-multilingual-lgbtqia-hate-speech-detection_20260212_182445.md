---
ver: rpa2
title: '"Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech
  Detection'
arxiv_id: '2410.11230'
source_url: https://arxiv.org/abs/2410.11230
tags:
- hate
- speech
- detection
- translation
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines how well large language models detect LGBTQIA+
  hate speech across multiple languages, focusing on English, Italian, Chinese, and
  code-switched English-Tamil. It compares zero-shot and fine-tuned GPT models on
  original text versus machine-translated text.
---

# "Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection

## Quick Facts
- arXiv ID: 2410.11230
- Source URL: https://arxiv.org/abs/2410.11230
- Authors: Fai Leui Chan; Duke Nguyen; Aditya Joshi
- Reference count: 10
- Primary result: Translation degrades hate speech detection accuracy, especially for Chinese (F1 drop: 0.062)

## Executive Summary
This paper examines how well large language models detect LGBTQIA+ hate speech across multiple languages, comparing zero-shot and fine-tuned GPT models on original text versus machine-translated text. The study finds that English shows the highest performance (F1: 0.795), while code-switched English-Tamil performs the lowest (F1: 0.362). Fine-tuning consistently improves performance across all languages, but translation often degrades detection accuracy, particularly for Chinese and Italian. Qualitative analysis reveals that slang, cultural expressions, and LGBTQIA+-specific terminology are often mistranslated, highlighting the limitations of current translation models in capturing hate speech nuances. The study concludes that translation alone is insufficient for robust multilingual hate speech detection.

## Method Summary
The study uses GPT-3.5-turbo to perform zero-shot classification on four datasets (English, Italian, Chinese, English-Tamil code-switched) with homotransphobic and non-homotransphobic labels (total: 15,261 samples). Non-English text is translated to English using GPT-3.5-turbo, then classified again. The authors then fine-tune GPT on selected datasets. Performance is evaluated using F1-score, precision, recall, and Cohen's Kappa agreement with a 60:20:20 train-validation-test split. The study compares performance between original and translated text, and between zero-shot and fine-tuned models.

## Key Results
- English yields the highest F1-score (0.795), followed by Chinese (0.746), Italian (0.599), and English-Tamil code-switched (0.362)
- Fine-tuning improves performance consistently across languages, with the most substantial gains in Italian (ΔF1: +0.2385) and English-Tamil (ΔF1: +0.1772)
- Translation degrades detection accuracy for Chinese (F1 drop: 0.062) and Italian, but shows mixed results for other languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Translating text before hate speech detection often degrades model performance, especially for Chinese.
- Mechanism: Machine translation fails to preserve nuanced linguistic features, slang, and cultural expressions essential for accurate hate speech detection.
- Core assumption: Hate speech relies on specific cultural and linguistic context that is lost during translation.
- Evidence anchors:
  - [abstract] "translation often degrades detection accuracy, especially for Chinese (F1 drop: 0.062)"
  - [section] "Our findings indicate that: (1) English has the highest performance and the code-switching scenario of English-Tamil being the lowest, (2) fine-tuning improves performance consistently across languages whilst translation yields mixed results."
  - [corpus] Weak - corpus neighbors discuss translation-based approaches but don't directly address degradation in hate speech detection performance.

### Mechanism 2
- Claim: Fine-tuning improves hate speech detection performance across all languages.
- Mechanism: Adapting the model to the specific characteristics of each language dataset enhances its ability to recognize patterns associated with hate speech.
- Core assumption: The model can learn language-specific patterns that are indicative of hate speech through fine-tuning.
- Evidence anchors:
  - [abstract] "Fine-tuning consistently improves performance across all languages"
  - [section] "Fine-tuning consistently improves performance across all languages, with the most substantial gains in Italian (∆F1: +0.2385, ∆Kappa: +0.5878) and English-Tamil (∆F1: +0.1772)."
  - [corpus] Weak - corpus neighbors don't directly address fine-tuning for hate speech detection.

### Mechanism 3
- Claim: Code-switching presents unique challenges for hate speech detection.
- Mechanism: The mixing of languages within a single text introduces ambiguity and complexity that standard detection models struggle to interpret.
- Core assumption: Code-switched text contains elements that are not well-represented in monolingual training data.
- Evidence anchors:
  - [abstract] "English-Tamil performs the lowest (F1: 0.362)"
  - [section] "English yields the highest F1-score (0.7952), followed by Chinese (0.7464), Italian (0.5990), and English-Tamil (0.3619). The strong performance in Chinese suggests good generalisation to non-Latin scripts after translation, while the low score for English-Tamil highlights challenges with code-mixed content."
  - [corpus] Weak - corpus neighbors mention code-mixing but don't specifically address its impact on hate speech detection.

## Foundational Learning

- Concept: Hate speech detection in multilingual contexts
  - Why needed here: Understanding how hate speech manifests across different languages and cultures is crucial for building effective detection systems.
  - Quick check question: What are some examples of culturally specific hate speech expressions that might be mistranslated?

- Concept: Machine translation limitations
  - Why needed here: Recognizing the constraints of current translation models helps in designing appropriate detection strategies.
  - Quick check question: Why might machine translation struggle with slang and culturally specific references?

- Concept: Fine-tuning techniques for LLMs
  - Why needed here: Knowing how to adapt pre-trained models to specific tasks is essential for optimizing performance.
  - Quick check question: What are the benefits and potential risks of fine-tuning a large language model?

## Architecture Onboarding

- Component map: Translation layer → LLM for classification → Fine-tuning module
- Critical path: Original text → LLM classification → Evaluation metrics
- Design tradeoffs: Translation accuracy vs. direct multilingual detection
- Failure signatures: Significant performance drop after translation, poor performance on code-switched text
- First 3 experiments:
  1. Compare performance of original vs. translated text for each language.
  2. Evaluate the impact of fine-tuning on both original and translated text.
  3. Conduct qualitative error analysis to identify specific types of mistranslations affecting hate speech detection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the correlation between translation quality and downstream hate speech detection performance across different languages?
- Basis in paper: [inferred] The paper mentions that translation degrades hate speech detection performance, especially for Chinese, but does not analyze the correlation between translation quality and task performance.
- Why unresolved: The authors did not conduct a systematic analysis of how translation quality metrics (e.g., BLEU score, human evaluation) relate to hate speech detection accuracy.
- What evidence would resolve it: A study measuring translation quality using standardized metrics and correlating these scores with hate speech detection F1 scores across all tested languages.

### Open Question 2
- Question: How do other large language models compare to GPT-3.5-turbo in multilingual LGBTQIA+ hate speech detection?
- Basis in paper: [explicit] The authors acknowledge this as a limitation, stating "it would be highly beneficial to compare gpt3.5-turbo with other large language models and specialised hate speech detection systems."
- Why unresolved: The study only used GPT-3.5-turbo and did not benchmark against other models like GPT-4, Claude, or specialized hate speech detection systems.
- What evidence would resolve it: Comparative experiments using multiple LLMs and specialized hate speech detection systems on the same datasets with identical evaluation protocols.

### Open Question 3
- Question: How does context beyond single sentences affect the accuracy of multilingual hate speech detection?
- Basis in paper: [explicit] The authors note as a limitation that "there is a lack of context beyond single sentences in our analysis."
- Why unresolved: The study only analyzed single sentences, which may miss contextual cues important for hate speech detection, especially in code-switched or culturally nuanced cases.
- What evidence would resolve it: Experiments using longer text segments, conversation threads, or document-level context to evaluate whether additional context improves detection accuracy, particularly for code-switched English-Tamil data.

## Limitations

- The study relies on machine translation, which may not preserve the full nuance of hate speech across languages, particularly for slang and culturally specific expressions.
- The code-switched English-Tamil dataset is relatively small (926 samples) and imbalanced, which could affect the reliability of performance metrics.
- The fine-tuning procedure details are not fully specified, including hyperparameters and training duration, which may impact reproducibility.

## Confidence

- **High Confidence**: The finding that fine-tuning consistently improves hate speech detection performance across languages is well-supported by the data, with clear quantitative improvements in F1-score and Cohen's Kappa.
- **Medium Confidence**: The claim that translation often degrades detection accuracy, especially for Chinese, is supported by F1-score drops but may vary depending on the specific translation model and language pair.
- **Low Confidence**: The assertion that code-switching presents unique challenges is based on limited data (English-Tamil only) and may not fully capture the complexity of all code-switched scenarios.

## Next Checks

1. **Replication with Diverse Languages**: Validate the findings by testing the approach on additional language pairs, including those with different scripts and linguistic structures, to assess generalizability.
2. **Human Translation Comparison**: Conduct a qualitative comparison between machine translations and human translations to identify specific types of mistranslations that affect hate speech detection accuracy.
3. **Fine-tuning Procedure Specification**: Obtain and document the exact fine-tuning hyperparameters and procedures to ensure reproducibility and allow for systematic comparison with other fine-tuning approaches.