---
ver: rpa2
title: Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation
arxiv_id: '2412.14905'
source_url: https://arxiv.org/abs/2412.14905
tags:
- depac
- context
- arxiv
- fact
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes DePaC to address hallucination issues in parallel
  context extension (PCE) for retrieval-augmented generation (RAG). DePaC introduces
  two key components: context-aware negative training to guide the model to refuse
  answering when contexts are unrelated to questions, and information-calibrated aggregation
  to prioritize context windows with higher information value.'
---

# Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2412.14905
- Source URL: https://arxiv.org/abs/2412.14905
- Reference count: 16
- Primary result: DePaC significantly reduces hallucinations in RAG while maintaining performance across 9 tasks

## Executive Summary
This paper addresses hallucination issues in retrieval-augmented generation (RAG) through parallel context extension (PCE). The proposed DePaC method introduces two key components: context-aware negative training that enables models to refuse answering when contexts are unrelated to questions, and information-calibrated aggregation that prioritizes context windows with higher information value. Experimental results on nine RAG tasks demonstrate that DePaC significantly reduces both fact fabrication and fact omission hallucinations while maintaining strong performance on information seeking and document-based question answering tasks.

## Method Summary
DePaC tackles RAG hallucinations through two mechanisms. First, context-aware negative training fine-tunes LLMs with negative supervision, teaching them to refuse answering when provided contexts are unrelated to questions. Second, information-calibrated aggregation uses KL divergence to measure information increment, prioritizing context windows that provide more relevant information. The method is evaluated on 9 RAG tasks using Mistral-7B as the backbone model, with training on 19K context-aware negative samples constructed from the C4 corpus.

## Key Results
- DePaC achieves better accuracy than existing PCE approaches across information seeking and DocQA tasks
- The method significantly reduces both fact fabrication and fact omission hallucinations
- DePaC maintains performance advantages even as the number of candidate documents increases
- Information-calibrated aggregation provides better performance than existing aggregation methods

## Why This Works (Mechanism)

### Mechanism 1
Context-aware negative training enables the model to refuse to answer when contexts are unrelated to questions, thereby mitigating fact fabrication. The model is fine-tuned with two types of training data - one with useful documents and questions as input, and another with irrelevant documents and questions as input, with a rejection token as output.

### Mechanism 2
Information-calibrated aggregation prioritizes context windows with higher information increment, preventing fact omission. Kullback-Leibler (KL) divergence is used to measure the information increment of with-document compared to non-document, enhancing the model's capability to identify useful information within parallel windows.

### Mechanism 3
The simplified form of DePaC ensures that irrelevant context windows are directly filtered out. The product of two terms is used to inject into Equation 6, with the constraint that γ ≫ C(pi,j, pi,c) to directly filter out irrelevant context windows.

## Foundational Learning

- Concept: Retrieval-augmented generation (RAG)
  - Why needed here: RAG is the foundation for the task, as it involves retrieving documents and incorporating them into the language model's prompt.
  - Quick check question: What is the primary purpose of RAG in the context of this paper?

- Concept: Parallel context extension (PCE)
  - Why needed here: PCE is the method used to effectively integrate parallel contexts in RAG scenarios.
  - Quick check question: How does PCE differ from traditional context extension methods?

- Concept: Kullback-Leibler (KL) divergence
  - Why needed here: KL divergence is used to measure the information increment provided by a document, which is crucial for the information-calibrated aggregation mechanism.
  - Quick check question: What is the role of KL divergence in the context of this paper?

## Architecture Onboarding

- Component map:
  Retrieval-augmented generation (RAG) -> Parallel context extension (PCE) -> Context-aware negative training -> Information-calibrated aggregation

- Critical path:
  1. Retrieve documents using RAG
  2. Apply PCE to integrate parallel contexts
  3. Use context-aware negative training to mitigate fact fabrication
  4. Use information-calibrated aggregation to prevent fact omission

- Design tradeoffs:
  - Tradeoff between computational complexity and accuracy
  - Tradeoff between the number of context windows and the model's ability to identify useful information

- Failure signatures:
  - Fact fabrication: The model generates claims that are not supported by the contexts
  - Fact omission: The model fails to present claims that are supported by the contexts

- First 3 experiments:
  1. Evaluate the model's performance on information seeking tasks with varying numbers of context windows
  2. Analyze the proportion of hallucinations produced by the model on different tasks
  3. Conduct an ablation study to identify the essential components of DePaC's performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of DePaC change when using different backbone models beyond Mistral-7B and Llama3-8B? The paper only evaluates DePaC with Mistral-7B and Llama3-8B, leaving the performance on other backbone models unexplored.

### Open Question 2
What is the impact of varying the hyperparameters β and γ on DePaC's performance and hallucination reduction? The paper only mentions setting β = 0.2 and does not explore the effects of different values of β and γ on performance and hallucination reduction.

### Open Question 3
How does DePaC perform on tasks with highly ambiguous or subjective questions where the ground truth may not be definitive? The paper focuses on tasks with clear answers, leaving the model's ability to handle ambiguous or subjective questions untested.

### Open Question 4
Can DePaC be extended to handle multimodal inputs, such as text and images, in retrieval-augmented generation tasks? The paper focuses on text-based RAG tasks and does not explore the potential for multimodal inputs.

### Open Question 5
How does DePaC handle cases where the retrieved documents are noisy or contain conflicting information? The paper does not explicitly address the model's behavior when dealing with noisy or conflicting information in retrieved documents.

## Limitations

- The evaluation relies heavily on automatic metrics and simulated retrieval scenarios, with limited human evaluation of actual hallucination quality
- The computational cost analysis is limited to inference complexity without addressing the full training pipeline costs
- The study focuses on a single backbone model (Mistral-7B), leaving questions about generalizability to other architectures

## Confidence

**High Confidence** (Mechanism 1, Context-aware negative training): The core approach of using negative supervision to train refusal behavior is well-established and the implementation details are clearly specified.

**Medium Confidence** (Mechanism 2, Information-calibrated aggregation): While the KL divergence approach is theoretically sound, its practical effectiveness depends on implementation details not fully specified in the paper.

**Medium Confidence** (Overall performance claims): The results show consistent improvements across multiple tasks, but the evaluation methodology has limitations including reliance on pattern matching for hallucination detection.

## Next Checks

1. **Human evaluation of hallucination quality**: Conduct a blinded human evaluation where annotators assess whether the model's refusals are appropriate and whether the remaining outputs contain hallucinations, comparing DePaC against baseline approaches on the same examples.

2. **Cross-architecture validation**: Implement DePaC on at least two additional backbone models (e.g., Llama-2 and GPT-2 variants) and evaluate whether the performance gains and hallucination reduction generalize beyond Mistral-7B.

3. **Real-world retrieval testing**: Replace the simulated retrieval with actual retrieval from production-scale document collections (minimum 1M documents) and measure both performance degradation and hallucination rates under realistic conditions with varying document quality and relevance distributions.