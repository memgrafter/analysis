---
ver: rpa2
title: 'TeleOracle: Fine-Tuned Retrieval-Augmented Generation with Long-Context Support
  for Network'
arxiv_id: '2411.02617'
source_url: https://arxiv.org/abs/2411.02617
tags:
- context
- telecom
- language
- performance
- phi-2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TeleOracle, a specialized RAG system built
  on the Phi-2 SLM to address telecom-specific challenges. The system uses semantic
  chunking, a two-stage retrieval process (hybrid keyword/semantic search plus reranking),
  and context window extension via SelfExtend.
---

# TeleOracle: Fine-Tuned Retrieval-Augmented Generation with Long-Context Support for Network

## Quick Facts
- arXiv ID: 2411.02617
- Source URL: https://arxiv.org/abs/2411.02617
- Reference count: 40
- Outperforms baseline Phi-2 and larger LLMs on telecom QnA tasks with 81.20% accuracy and 78.80% faithfulness

## Executive Summary
TeleOracle is a specialized RAG system built on the Phi-2 small language model to address telecom-specific challenges in processing complex 3GPP documentation. The system combines semantic chunking, a two-stage retrieval process (hybrid keyword/semantic search plus reranking), and context window extension via SelfExtend. Fine-tuning is performed efficiently with LoRA, and prompt engineering guides Phi-2 to produce consistent, context-driven answers. Evaluated on telecom QnA tasks, TeleOracle achieves 81.20% accuracy and a faithfulness score of 78.80%, outperforming both baseline Phi-2 and larger LLMs, and showing higher adherence to retrieved context.

## Method Summary
TeleOracle processes telecom documents through semantic chunking using Chroma DB with bge-small-en-v1.5 embeddings, setting a breakpoint percentile threshold of 90 and buffer size of 3. The two-stage retrieval process first uses hybrid search (BM25 + vector search) to retrieve top 150 chunks, then applies a cross-encoder reranker to select the top 15 chunks. Phi-2 is fine-tuned with LoRA using learning rate 10^-4, batch size 32, dropout 0.05, weight decay 0.01, rank 32, alpha 64 on the TeleQnA dataset, then the context window is extended to 8192 tokens using SelfExtend. The system is evaluated on 2000 telecom questions with accuracy and faithfulness metrics.

## Key Results
- Achieves 81.20% accuracy on telecom QnA tasks, outperforming baseline Phi-2 and larger LLMs
- Maintains 78.80% faithfulness score, demonstrating strong adherence to retrieved context
- Semantic chunking preserves contextual integrity better than fixed-size chunking for telecom documentation

## Why This Works (Mechanism)

### Mechanism 1
- Semantic chunking outperforms fixed-size chunking for telecom documentation by preserving context integrity and capturing nuanced terminology
- Mechanism: Semantic chunking uses dissimilarity thresholds to split text only when context changes significantly, ensuring coherent chunks that maintain technical relationships between terms
- Core assumption: Telecom documents contain complex, non-uniform structures where fixed-size chunks would break logical relationships between related concepts
- Evidence anchors:
  - [abstract] "We implement an optimized document processing pipeline that combines semantic chunking with a two-stage retrieval process"
  - [section III-B] "In this work, we utilize semantic chunking to enhance the relevance and accuracy of the retrieved information. This technique involves splitting the text whenever a set dissimilarity threshold is exceeded."
  - [corpus] "Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards" - weak evidence for chunking approach
- Break condition: If the dissimilarity threshold is set too high, chunks become too long and lose focus; if too low, related concepts get separated.

### Mechanism 2
- The two-stage retrieval process (hybrid search + reranking) improves both efficiency and accuracy compared to single-stage approaches
- Mechanism: First stage uses fast BM25 keyword search and vector similarity to retrieve candidate chunks, then a cross-encoder reranker refines results by evaluating query-chunk pairs with higher computational cost
- Core assumption: BM25 captures telecom-specific terminology while vector search captures semantic meaning, and reranking can correct first-stage limitations
- Evidence anchors:
  - [abstract] "To improve context retrieval, TeleOracle employs a two-stage retriever that incorporates semantic chunking and hybrid keyword and semantic search"
  - [section III-D.2] "Cross encoders, illustrated in Fig. 4, evaluate the similarity between each query and document pair and then output a classification score between between 0 and 1"
  - [corpus] "In Defense of RAG in the Era of Long-Context Language Models" - weak evidence for two-stage approach
- Break condition: If the reranker's computational cost exceeds benefits, or if first-stage retrieval is already highly accurate.

### Mechanism 3
- SelfExtend enables small language models to handle longer contexts without fine-tuning by modifying positional encoding through grouped attention
- Mechanism: SelfExtend alters how positional information is processed in self-attention, using floor operations to map distant positions to seen training positions while maintaining neighbor accuracy
- Core assumption: Language models can generalize to longer sequences if positional encoding is adjusted, as the relative position of tokens matters more than absolute positions
- Evidence anchors:
  - [abstract] "Additionally, we expand the context window during inference to enhance the model's performance on open-ended queries"
  - [section III-E] "SelfExtend builds on the idea that relative positions do not have to be unique, and uses the floor operation resulting in position indices up to the maximum position index seen during training"
  - [corpus] "RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding" - weak evidence for SelfExtend approach
- Break condition: If grouped attention causes too much information loss for distant tokens, or if the neighbor window size is inappropriate.

## Foundational Learning

- Concept: Vector embeddings and cosine similarity
  - Why needed here: Understanding how documents and queries are represented as vectors in high-dimensional space for similarity matching
  - Quick check question: What does a cosine similarity of 0.8 between two vectors indicate about their semantic relationship?

- Concept: Transformer self-attention and positional encoding
  - Why needed here: Essential for understanding how models process sequences and why positional information matters for longer contexts
  - Quick check question: Why do transformers need positional encoding when processing sequential data?

- Concept: BM25 ranking algorithm
  - Why needed here: Understanding the keyword-based retrieval component and how it differs from semantic search
  - Quick check question: What role do the parameters k and b play in the BM25 scoring formula?

## Architecture Onboarding

- Component map: Query → Hybrid Retriever (BM25 + Vector Search) → Reranker → ChromaDB → SelfExtend → Phi-2 (fine-tuned with LoRA) → Answer
- Critical path: Document retrieval and processing must happen before context window extension, which must complete before Phi-2 generation
- Design tradeoffs: Semantic chunking vs fixed-size (accuracy vs simplicity), two-stage retrieval vs single-stage (accuracy vs speed), SelfExtend vs fine-tuning (efficiency vs potential accuracy)
- Failure signatures: Poor retrieval accuracy suggests hybrid retriever issues, context window problems suggest SelfExtend configuration errors, format compliance issues suggest prompt engineering problems
- First 3 experiments:
  1. Test hybrid retriever with known telecom queries to verify BM25 captures terminology and vector search captures semantics
  2. Validate SelfExtend extends context window correctly by testing with sequences longer than 2048 tokens
  3. Verify LoRA fine-tuning improves telecom-specific accuracy by comparing with base Phi-2 on benchmark questions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TeleOracle compare when integrating structured data types like tables and network graphs into the retrieved context?
- Basis in paper: [inferred] The paper notes that RAG models struggle with incorporating tables, figures, and network graphs, and future work should explore integrating these elements.
- Why unresolved: The current TeleOracle implementation does not include structured data types in its context retrieval, and no experiments were conducted to evaluate their impact.
- What evidence would resolve it: Comparative experiments measuring TeleOracle's accuracy and faithfulness with and without structured data types in the retrieved context.

### Open Question 2
- Question: What is the optimal balance between semantic chunking and fixed-size chunking for different types of telecom documents?
- Basis in paper: [explicit] The paper compares semantic chunking with fixed-size chunking and notes that semantic chunking maintains contextual integrity but can produce longer chunks.
- Why unresolved: The paper does not provide a systematic analysis of when each chunking method is preferable or how to optimize the balance between them.
- What evidence would resolve it: Experiments testing TeleOracle's performance with various chunking strategies across different document types and content structures.

### Open Question 3
- Question: How does SelfExtend's grouped attention mechanism affect the model's ability to maintain coherence in extremely long contexts?
- Basis in paper: [explicit] The paper describes SelfExtend's use of grouped attention for handling longer sequences but notes that it may affect coherence in certain cases.
- Why unresolved: The paper does not provide detailed analysis of coherence degradation at various context lengths or how the neighbor window size affects performance.
- What evidence would resolve it: Systematic evaluation of TeleOracle's output coherence at different context lengths with varying neighbor window sizes.

## Limitations
- Cross-encoder reranker implementation details are not specified, including model architecture and training configuration
- Prompt engineering approach for Phi-2 is described only at a high level without providing actual templates or instructions
- Faithfulness evaluation methodology lacks clarity on how the 78.80% score is calculated and what it measures

## Confidence
- High Confidence: Semantic chunking mechanism and its implementation details are well-specified with clear parameters and rationale
- Medium Confidence: LoRA fine-tuning procedure is reasonably detailed, though exact hyperparameters beyond learning rate are not fully specified
- Low Confidence: Faithfulness evaluation methodology and comparison with unspecified larger LLMs have significant gaps that prevent independent verification

## Next Checks
1. **Cross-Encoder Reranker Validation**: Implement and test the cross-encoder reranker independently using a standard telecom dataset to verify it improves retrieval accuracy by at least 5-10% compared to single-stage retrieval.

2. **Faithfulness Metric Verification**: Replicate the faithfulness scoring methodology on a subset of questions to confirm the 78.80% score and understand what specific aspects of context adherence are being measured.

3. **Long-Context Performance Test**: Systematically test TeleOracle with queries requiring context lengths beyond 2048 tokens to empirically validate that SelfExtend maintains or improves answer quality compared to base Phi-2 without context extension.