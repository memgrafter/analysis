---
ver: rpa2
title: Knowledge graph enhanced retrieval-augmented generation for failure mode and
  effects analysis
arxiv_id: '2406.18114'
source_url: https://arxiv.org/abs/2406.18114
tags:
- fmea
- data
- failure
- information
- vector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a knowledge graph (KG)-enhanced retrieval-augmented
  generation (RAG) framework for failure mode and effects analysis (FMEA). The approach
  addresses the challenge of limited reasoning capabilities in traditional tabular
  FMEA tools by integrating a KG with RAG to enable analytical and semantic question-answering
  capabilities.
---

# Knowledge graph enhanced retrieval-augmented generation for failure mode and effects analysis

## Quick Facts
- arXiv ID: 2406.18114
- Source URL: https://arxiv.org/abs/2406.18114
- Authors: Lukas Bahr; Christoph Wehner; Judith Wewerka; José Bittencourt; Ute Schmid; Rüdiger Daub
- Reference count: 20
- Primary result: KG-RAG framework outperforms traditional Excel-based FMEA with improved correctness, usability, relevance, and completeness

## Executive Summary
This paper presents a knowledge graph (KG)-enhanced retrieval-augmented generation (RAG) framework for failure mode and effects analysis (FMEA) that addresses the limitations of traditional tabular FMEA tools. The approach integrates a knowledge graph with RAG to enable analytical and semantic question-answering capabilities, combining graph query language for precise symbolic reasoning with vector search for handling vague queries. The framework is validated through a user experience design study with 10 participants, demonstrating superior performance compared to traditional Excel-based FMEA in terms of correctness, usability, relevance, and completeness. Additionally, context precision and recall metrics show that the KG-RAG framework outperforms baseline RAG implementations, highlighting its potential for AI-enhanced risk management in manufacturing.

## Method Summary
The study employs a KG-RAG framework that combines symbolic reasoning through graph queries with semantic reasoning via vector search to enable analytical and semantic question-answering on FMEA data. The approach uses a knowledge graph with 3,107 nodes and 4,576 relations, created from FMEA data using a depth-first search algorithm to generate vector embeddings. These embeddings are stored as literals in Neo4j and associated with FailureMode nodes. The framework leverages LLM (OpenAI GPT-4) for graph query generation and text generation, while text-embedding-ada-002 handles vector embedding computation. Validation includes a user experience design study with 10 participants evaluating correctness, usability, relevance, and completeness, plus automated context precision and recall metrics to assess retrieval performance.

## Key Results
- KG-RAG framework demonstrates superior performance compared to traditional Excel-based FMEA in user studies
- Context precision and recall metrics show the KG-RAG approach outperforms baseline RAG implementations
- Framework successfully handles both analytical queries (requiring symbolic reasoning) and semantic queries (requiring vector similarity)
- RPN calculation accuracy for failure modes validated through user experience study

## Why This Works (Mechanism)
The KG-RAG framework works by combining the strengths of symbolic reasoning (graph queries) with semantic reasoning (vector search) to overcome the limitations of both approaches individually. Graph queries provide precise, interpretable results for analytical questions that require exact relationships between FMEA concepts, while vector search handles vague, open-ended queries by finding semantically similar information. This hybrid approach enables the system to handle the full spectrum of FMEA queries, from structured numerical analysis to exploratory risk assessment, while maintaining both accuracy and flexibility in information retrieval.

## Foundational Learning
**Knowledge Graph Schema Definition**: Understanding the FMEA-KG schema with nodes (FailureMode, FailureEffect, FailureCause, FailureMeasure, ProcessStep) and relations (occursAtProcessStep, resultsInFailureEffect, isDueToFailureCause, isImprovedByFailureMeasure). *Why needed*: Provides the semantic structure for representing FMEA concepts and their relationships. *Quick check*: Verify all required node types and relations are correctly implemented in Neo4j.

**Vector Embedding Generation**: Depth-first search algorithm for creating vector embeddings from graph paths, storing them as literals in Neo4j. *Why needed*: Enables semantic search capabilities while preserving the underlying FMEA-KG structure. *Quick check*: Ensure DFS traversal captures meaningful paths between related FMEA concepts.

**Graph Query Generation**: LLM-based generation of Cypher queries from natural language questions about FMEA data. *Why needed*: Bridges the gap between user queries and the structured knowledge graph. *Quick check*: Validate that generated queries correctly map to the FMEA-KG schema and return expected results.

**Fallback Mechanism**: Intelligent switching between symbolic (graph query) and semantic (vector search) reasoning based on query type. *Why needed*: Optimizes retrieval accuracy by using the most appropriate reasoning approach for each query. *Quick check*: Test that analytical queries use graph queries while vague queries use vector search.

## Architecture Onboarding

**Component Map:**
User Interface -> LLM (Graph Query Generator) -> Neo4j (Knowledge Graph) -> LLM (Text Generator) -> User Interface
Vector Search Engine -> LLM (Text Generator) -> User Interface

**Critical Path:**
1. User submits FMEA query
2. LLM generates graph query or determines semantic search needed
3. If graph query: Execute Cypher query on Neo4j
4. If semantic search: Perform vector similarity search on embeddings
5. LLM generates natural language response from retrieved data
6. Return response to user

**Design Tradeoffs:**
- Symbolic reasoning provides precision but lacks flexibility for vague queries
- Semantic reasoning handles ambiguity but may miss exact relationships
- Hybrid approach balances precision and recall but adds complexity
- Graph database choice affects query performance and scalability

**Failure Signatures:**
- Incorrect graph queries: LLM generates malformed Cypher or wrong relationships
- Poor vector embeddings: Similar FMEA concepts have low cosine similarity
- Fallback failures: System chooses wrong reasoning approach for query type
- LLM generation issues: Output doesn't address user query or contains hallucinations

**First Experiments:**
1. Test graph query generation with simple FMEA relationships (e.g., "Which failure causes result in effect X?")
2. Validate vector search by comparing cosine distances between known similar and dissimilar FMEA concepts
3. Verify fallback mechanism by testing both analytical and vague queries to ensure correct reasoning approach selection

## Open Questions the Paper Calls Out
**Open Question 1:** How does the performance of the KG-RAG framework vary across different LLM models for text generation and vector embedding computation? The paper mentions that access to other online language models is restricted by data protection regulations, preventing testing with alternative LLMs. Comparative experiments using multiple LLM models for both text generation and vector embedding computation, measuring performance metrics like context recall, precision, and user satisfaction across different model families would resolve this.

**Open Question 2:** What is the optimal chunking strategy for converting the FMEA-KG into vector embeddings beyond the depth-first search approach? While we employ DFS to capture the underlying information of the FMEA-KG, other potentially more efficient path algorithms, such as breadth-first search or iterative deepening, are worth evaluating. Systematic comparison of different graph traversal algorithms and path-finding strategies, measuring the quality of vector embeddings through context recall/precision metrics and computational efficiency would resolve this.

**Open Question 3:** How can the KG-RAG framework be extended to support guided user input that improves the data quality of the FMEA database? The framework can be extended to support guided user input, which could significantly improve the data quality of the FMEA database. Implementation and evaluation of guided input mechanisms (e.g., structured prompts, validation rules, suggestion systems) measuring their impact on data completeness, consistency, and overall FMEA quality metrics would resolve this.

## Limitations
- Missing implementation details for LLM-based graph query generation and fallback mechanism between symbolic and semantic reasoning
- Lack of specifics on chunking strategy and path traversal algorithm for vector embedding generation
- High-level description of user study methodology without details on task design, participant selection, or evaluation rubric
- Only tested with OpenAI GPT-4 model, limiting generalizability to other LLM architectures

## Confidence
- **High confidence**: Conceptual framework of KG-RAG for FMEA and overall evaluation approach (user study + context precision/recall metrics)
- **Medium confidence**: Knowledge graph schema definition and basic integration of Neo4j with vector embeddings
- **Low confidence**: Specific implementation details of depth-first search for embedding generation, graph query generation mechanism, and fallback logic between symbolic and semantic reasoning

## Next Checks
1. Implement a simplified version of the KG-RAG framework using a small synthetic FMEA dataset to validate the graph query generation and vector search fallback mechanism works as intended.

2. Create a controlled experiment comparing context precision/recall of the KG-RAG approach against pure vector search and pure graph query approaches on a validation dataset to verify the claimed performance improvements.

3. Reconstruct the user study protocol by defining specific FMEA-related tasks, evaluation rubrics for correctness/usability/relevance/completeness metrics, and conduct a pilot study with 3-5 participants to validate the measurement approach before scaling to larger studies.