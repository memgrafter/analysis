---
ver: rpa2
title: Representing Web Applications As Knowledge Graphs
arxiv_id: '2410.17258'
source_url: https://arxiv.org/abs/2410.17258
tags:
- actions
- state
- application
- user
- dynamic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a method for representing web applications as
  knowledge graphs, where nodes correspond to unique application states and edges
  represent user-initiated actions. Unlike traditional web crawlers that follow hyperlinks,
  this approach captures dynamic, interactive behaviors inherent to modern web applications.
---

# Representing Web Applications As Knowledge Graphs

## Quick Facts
- arXiv ID: 2410.17258
- Source URL: https://arxiv.org/abs/2410.17258
- Authors: Yogesh Chandrasekharuni
- Reference count: 19
- Primary result: Proposed method achieves 95 states vs. 24 for traditional crawler on Dentomart.com

## Executive Summary
This work introduces a novel approach to representing web applications as knowledge graphs, where nodes represent unique application states and edges represent user-initiated actions. Unlike traditional web crawlers that follow hyperlinks, this method captures dynamic, interactive behaviors inherent to modern web applications. The system uses a multi-modal LLM to infer possible actions, execute them, and prioritize meaningful state transitions through a reward/penalty model.

The experimental evaluation on Dentomart.com demonstrates significant improvements over traditional parsing methods, achieving higher state coverage (95 vs. 24 states) and edge complexity (94 vs. 86 edges). The resulting knowledge graph supports downstream tasks like automated testing, enabling the generation of 51 unique test cases. This approach addresses the limitations of hyperlink-based crawling by modeling the rich, interactive nature of modern web applications.

## Method Summary
The method represents web applications as directed graphs where nodes correspond to unique application states, defined by their screenshot, page source, and metadata. The system consists of three main components: a Functionality Inferring Module that uses a multi-modal LLM to predict possible actions based on current state and history, an Action Executor that performs actions and validates state transitions, and a Reward/Penalty Model that scores actions between -1 and +1 to prioritize meaningful transitions. The system explores the application through this guided process, building a comprehensive graph of states and transitions that captures the application's interactive behavior beyond simple hyperlink navigation.

## Key Results
- Achieved 95 unique states compared to 24 states using traditional Scrapy-based parsing
- Captured 94 edges versus 86 edges in traditional approach, demonstrating richer interaction modeling
- Generated 51 unique test cases from graph traversal, demonstrating practical utility
- System completed in 5500 seconds while achieving significantly higher coverage

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representing states as structured nodes with screenshot, page source, and metadata allows the system to differentiate between dynamic states at the same URL.
- Mechanism: By capturing both the visual and structural representation of the application, the system can distinguish between states that differ due to user context or dynamically rendered content.
- Core assumption: Different states can be uniquely identified by their combination of visual and structural properties, not just URL.
- Evidence anchors:
  - [abstract] "In contrast, the proposed method models each node as a structured representation of the application's current state"
  - [section] "A state is defined by the following key components: Screenshot, Page Source, Metadata"
- Break condition: If the combination of screenshot, page source, and metadata is insufficient to differentiate states, the model will conflate distinct states.

### Mechanism 2
- Claim: Action prioritization through the Reward/Penalty Model enables efficient exploration of meaningful state transitions.
- Mechanism: Actions leading to new states or unexplored functionalities receive positive rewards, while redundant or trivial actions receive penalties, guiding the exploration process.
- Core assumption: Reward-based prioritization can effectively distinguish between meaningful and trivial state transitions.
- Evidence anchors:
  - [section] "Positive scores reflect significant progress, while negative scores highlight trivial or redundant actions"
  - [section] "Actions that lead to new state transitions or the discovery of unexplored functionalities receive positive rewards"
- Break condition: If the reward model fails to accurately assess the significance of state transitions, exploration may focus on irrelevant or redundant states.

### Mechanism 3
- Claim: The Functionality Inferring Module can predict potential actions by synthesizing current observations, explored functionalities, and state-action history.
- Mechanism: The module uses a multi-modal LLM to understand the current state and a database interface to avoid redundant actions, generating a prioritized list of possible actions.
- Core assumption: The multi-modal LLM can accurately interpret the current state from page source, screenshots, and metadata to predict relevant actions.
- Evidence anchors:
  - [section] "The Reasoning Agent employs a multi-modal LLM to comprehensively understand the current state"
  - [section] "Based on the current state and the record of explored functionalities, the Reasoning Agent outputs a list of plausible actions"
- Break condition: If the multi-modal LLM fails to accurately interpret the current state or predict relevant actions, the system will miss important state transitions.

## Foundational Learning

- Concept: Knowledge Graph Representation
  - Why needed here: The entire approach relies on representing web applications as knowledge graphs with states as nodes and actions as edges
  - Quick check question: What are the three components that define a state in this knowledge graph representation?

- Concept: State Abstraction and State-Flow Graphs
  - Why needed here: The system builds upon techniques like Crawljax's state abstraction to handle AJAX-based applications
  - Quick check question: How does state abstraction differ from traditional hyperlink-based crawling?

- Concept: Multi-modal Understanding
  - Why needed here: The Reasoning Agent uses multi-modal LLM to interpret page source, screenshots, and metadata simultaneously
  - Quick check question: Why is multi-modal understanding necessary for accurately predicting user actions?

## Architecture Onboarding

- Component map: Functionality Inferring Module -> Action Executor -> State Validation -> Reward/Penalty Model -> Knowledge Graph Database

- Critical path: Observation → Functionality Inferring Module → Action Executor → State Validation → Reward/Penalty Model → Graph Update

- Design tradeoffs:
  - High state coverage vs. exploration time (95 states vs. 5500 seconds)
  - Detailed state representation vs. computational overhead
  - Multi-modal understanding vs. model complexity

- Failure signatures:
  - Low state coverage despite high exploration time
  - Reward model consistently penalizing meaningful actions
  - Action Executor failing to execute or validate state transitions
  - Multi-modal LLM misinterpreting page source or screenshots

- First 3 experiments:
  1. Run traditional Scrapy parser on Dentomart.com with 3 levels depth, compare state coverage
  2. Execute Functionality Inferring Module on static page to validate action prediction accuracy
  3. Test Action Executor with simulated user actions to verify state transition and validation

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Single-site evaluation limits generalizability across different web application types and architectures
- Multi-modal LLM implementation unspecified, creating reproducibility challenges and uncertainty about model performance
- Computational overhead of detailed state representation and multi-modal processing may not scale to large applications

## Confidence
- Knowledge graph representation effectiveness: High
- State coverage improvement over traditional methods: High
- Multi-modal LLM interpretation accuracy: Low
- Reward model effectiveness: Medium
- Generalizability to other web applications: Low

## Next Checks
1. Test the system on multiple web application types (e-commerce, social media, productivity tools) to assess generalizability and identify application-specific failure modes.

2. Conduct ablation studies removing the multi-modal LLM component to quantify its contribution to state identification and action prediction accuracy.

3. Implement the system with different LLM models (GPT-4, Claude, open-source alternatives) to evaluate how model choice impacts performance and resource requirements.