---
ver: rpa2
title: 'CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models'
arxiv_id: '2406.08070'
source_url: https://arxiv.org/abs/2406.08070
tags:
- diffusion
- guidance
- sampling
- inversion
- ddim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies that the off-manifold phenomenon in classifier-free
  guidance (CFG) arises from the use of a high guidance scale and the renoising process,
  rather than being an inherent limitation of diffusion models. The authors propose
  CFG++, a simple yet effective modification that reformulates text guidance as an
  inverse problem with a text-conditioned score matching loss.
---

# CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models

## Quick Facts
- arXiv ID: 2406.08070
- Source URL: https://arxiv.org/abs/2406.08070
- Reference count: 35
- Authors: Hyungjin Chung, Jeongsol Kim, Geon Yeong Park, Hyelin Nam, Jong Chul Ye
- Key outcome: Identifies off-manifold phenomenon in CFG as stemming from high guidance scales and renoising process, proposes CFG++ modification using unconditional noise and smaller guidance scales (λ ∈ [0,1]) that improves sample quality, DDIM inversion, and inverse problem solving

## Executive Summary
This paper addresses the off-manifold phenomenon in classifier-free guidance (CFG) for diffusion models, which manifests as mode collapse, out-of-distribution artifacts, and poor inversion capabilities. Contrary to the belief that these are inherent limitations of diffusion models, the authors demonstrate that the issues stem from using guidance scales ω > 1.0 and the renoising step. They propose CFG++, a simple yet effective modification that reformulates text guidance as an inverse problem with text-conditioned score matching loss, using unconditional noise instead of conditional noise in the renoising step and employing smaller guidance scales λ ∈ [0,1]. The method achieves consistently better sample quality in text-to-image generation, significantly improves DDIM inversion and editing capabilities, and enables the incorporation of text guidance into diffusion inverse solvers.

## Method Summary
CFG++ modifies the standard CFG algorithm by using unconditional noise instead of conditional noise in the renoising step and employing smaller guidance scales λ ∈ [0,1] instead of ω > 1. The key insight is that this reformulation enables interpolation between unconditional and conditional sampling rather than extrapolation, keeping the generated samples on the piecewise linear manifold between these two estimates. The method also improves DDIM inversion by making it approximately invertible up to discretization error, and can be extended to diffusion inverse solvers for tasks like super-resolution and deblurring.

## Key Results
- CFG++ consistently outperforms standard CFG across all guidance scales in text-to-image generation, improving FID scores and CLIP similarity
- The method significantly improves DDIM inversion quality, enabling precise and high-fidelity image editing
- CFG++ enables incorporation of text guidance into diffusion inverse solvers, achieving superior performance in solving inverse problems compared to standard CFG
- Quantitative evaluations show CFG++ maintains better sample quality while using guidance scales that are 10x smaller than standard CFG

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Off-manifold phenomenon in CFG arises from using guidance scales ω > 1.0 and the renoising step, not from diffusion models themselves.
- **Mechanism**: CFG++ reformulates text guidance as an inverse problem with text-conditioned score matching loss. It uses unconditional noise instead of conditional noise in the renoising step and employs smaller guidance scales λ ∈ [0,1].
- **Core assumption**: The clean data manifold is piecewise linear, and staying within interpolation bounds between unconditional and conditional estimates prevents falling off the manifold.
- **Evidence anchors**:
  - [abstract]: "Contrary to the widespread belief that these are inherent limitations of diffusion models, this paper reveals that the problems actually stem from the off-manifold phenomenon associated with CFG, rather than the diffusion models themselves."
  - [section 3.2]: "CFG++ extrapolates beyond the unconditional and conditional estimates... the conditional posterior mean estimates from CFG obtained with a guidance scale outside the range of [0, 1], can easily extend beyond the piecewise linear manifold."
  - [corpus]: Weak - no direct evidence in corpus papers about piecewise linear manifold assumption specifically.
- **Break condition**: If the piecewise linear manifold assumption fails, or if the unconditional noise is not representative of the true manifold, CFG++ could still produce off-manifold samples.

### Mechanism 2
- **Claim**: CFG++ enables seamless interpolation between unconditional and conditional sampling at lower guidance scales.
- **Mechanism**: By setting λ ∈ [0,1], CFG++ interpolates between unconditional (λ=0) and conditional (λ=1) sampling, where λ=1.0 has similar effect to ω ~ 12.5 at 50 NFE.
- **Core assumption**: Interpolation between unconditional and conditional estimates provides sufficient guidance strength for high-quality generation.
- **Evidence anchors**:
  - [abstract]: "CFG++ enables seamless interpolation between unconditional and conditional sampling at lower guidance scales, consistently outperforming traditional CFG at all scales."
  - [section 3.2]: "λ, ω ∈ [0, 1] facilitates an interpolation. However, with ω > 1.0, CFG extrapolates beyond the unconditional and conditional estimates."
  - [corpus]: Weak - corpus papers discuss guidance scales but don't specifically validate interpolation effectiveness.
- **Break condition**: If interpolation between unconditional and conditional estimates is insufficient for strong text-image alignment, CFG++ may underperform CFG at high guidance requirements.

### Mechanism 3
- **Claim**: CFG++ improves DDIM inversion and editing capabilities by reducing accumulated error.
- **Mechanism**: CFG++ uses unconditional noise in the renoising step, making the inversion approximately invertible up to discretization error, unlike CFG which accumulates significant errors.
- **Core assumption**: The error term εcf g++ = λ∥δˆϵc(xt) − δˆϵc(xt−1)∥ < ∥εcf g∥ for λ < ω ensures smaller accumulated errors during inversion.
- **Evidence anchors**:
  - [abstract]: "DDIM with CFG lacks invertibility, complicating image editing; furthermore, high guidance scales... frequently result in issues like mode collapse."
  - [section 3.2]: "CFG++ significantly improves the DDIM inversion... CFG++ delivers precise and high-fidelity edits."
  - [corpus]: Weak - corpus papers discuss CFG but don't specifically validate CFG++'s inversion improvements.
- **Break condition**: If the step size is too large or the approximation ˆϵλc(xt) ≃ ˆϵλc(xt−1) breaks down, CFG++ inversion could still accumulate errors.

## Foundational Learning

- **Concept**: Tweedie's formula for conditional expectations in diffusion models
  - Why needed here: CFG++ relies on Tweedie's formula E[x0|xt] = (xt - √(1-αt)ˆϵ(xt))/√αt for denoising estimates
  - Quick check question: How does Tweedie's formula relate the noisy observation xt to the clean estimate E[x0|xt] in the variance preserving framework?

- **Concept**: Classifier-free guidance (CFG) mechanism
  - Why needed here: Understanding standard CFG is essential to grasp why CFG++ modifies the renoising step and uses smaller guidance scales
  - Quick check question: What is the mathematical difference between CFG sampling (using ˆϵωc) and standard unconditional sampling (using ˆϵ∅)?

- **Concept**: Diffusion posterior sampling (DIS) and manifold constraints
  - Why needed here: CFG++ reformulates text guidance as an inverse problem, similar to DIS approaches that navigate manifolds
  - Quick check question: How does manifold-constrained gradient (MCG) ensure the updated estimate stays on the correct noisy manifold in DIS?

## Architecture Onboarding

- **Component map**: Base diffusion model (conditional and unconditional) -> Text conditioning mechanism (cross-attention) -> Guidance scale selection (λ for CFG++, ω for CFG) -> Renoisng step (modified in CFG++) -> Sampling solver (DDIM, Euler, DPM-solver, etc.)

- **Critical path**:
  1. Initialize xt ~ N(0,I) at time T
  2. Compute conditional score ˆϵc(xt) and unconditional score ˆϵ∅(xt)
  3. Apply guidance: ˆϵλc(xt) = ˆϵ∅(xt) + λ[ˆϵc(xt) - ˆϵ∅(xt)]
  4. Denoise: ˆxλc(xt) = (xt - √(1-αt)ˆϵλc(xt))/√αt
  5. Renoise: xt-1 = √αt-1ˆxλc(xt) + √(1-αt-1)ˆϵ∅(xt)
  6. Repeat until t=0

- **Design tradeoffs**:
  - Smaller guidance scales (λ ∈ [0,1]) vs. potential loss of guidance strength
  - Using unconditional noise in renoising vs. potentially slower convergence
  - Interpolation vs. extrapolation in guidance direction
  - Computational overhead (minimal) vs. implementation complexity

- **Failure signatures**:
  - Mode collapse or insufficient text-image alignment
  - Off-manifold artifacts in generated samples
  - Poor DDIM inversion/reconstruction quality
  - Sensitivity to guidance scale selection

- **First 3 experiments**:
  1. Generate images with CFG++ at λ=0.2, 0.4, 0.6, 0.8, 1.0 and compare FID/CLIP scores to CFG at corresponding ω values
  2. Perform DDIM inversion on real images with CFG++ and evaluate PSNR/RMSE vs CFG
  3. Apply CFG++ to PSLD inverse solver and compare reconstruction quality across super-resolution, deblurring, and inpainting tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between the time-varying guidance scale schedule ωt = −γt/ξt and the proposed CFG++ algorithm in terms of sample quality and computational efficiency?
- Basis in paper: [explicit] The paper mentions that CFG++ sampling can be achieved by setting a time-varying schedule ωt = −γt/ξt, where γt and ξt are specific functions of the time step.
- Why unresolved: The paper states that this specific choice of time-varying guidance scale has not been reported in the literature and does not provide empirical evidence comparing this schedule to the standard CFG++ implementation.
- What evidence would resolve it: Experiments comparing sample quality (FID, CLIP scores) and computational efficiency (NFE, runtime) between CFG++ with fixed λ and CFG++ with the time-varying schedule ωt = −γt/ξt across various datasets and guidance scales.

### Open Question 2
- Question: How does the proposed CFG++ algorithm perform in text-to-video generation tasks compared to standard CFG, and what are the potential challenges or limitations?
- Basis in paper: [inferred] The paper focuses on text-to-image generation and mentions potential applications in various fields that utilize text guidance, but does not explicitly discuss video generation.
- Why unresolved: Text-to-video generation introduces additional complexities such as temporal consistency and increased computational requirements, which may affect the performance of CFG++.
- What evidence would resolve it: Experiments comparing CFG++ and standard CFG on text-to-video generation tasks, evaluating metrics such as temporal consistency, visual quality, and computational efficiency.

### Open Question 3
- Question: Can the principles of CFG++ be extended to other conditional generation tasks beyond text guidance, such as image-to-image translation or style transfer, and what modifications would be necessary?
- Basis in paper: [inferred] The paper discusses the reformulation of text guidance as an inverse problem and proposes CFG++ as a solution, suggesting potential applicability to other conditional generation tasks.
- Why unresolved: While the reformulation as an inverse problem is general, the specific implementation of CFG++ relies on text-conditioned score matching loss, which may not directly translate to other conditional generation tasks.
- What evidence would resolve it: Experiments applying CFG++ principles to other conditional generation tasks, such as image-to-image translation or style transfer, and evaluating the performance compared to existing methods.

## Limitations

- The piecewise linear manifold assumption underlying CFG++ may not hold for all diffusion model architectures and datasets, limiting generalizability
- While CFG++ shows improvements for guidance scales in [0,1], it's unclear how the method performs at extreme guidance requirements where standard CFG might still be superior
- The theoretical foundation connecting unconditional noise choice to manifold adherence is not fully established, with improvements primarily demonstrated empirically rather than mathematically proven

## Confidence

- **Medium Confidence**: The claim that piecewise linear manifold assumption holds for all diffusion models remains largely theoretical, with limited empirical validation across different model architectures and datasets.
- **Medium Confidence**: While CFG++ shows improved DDIM inversion and editing capabilities, the extent to which these improvements generalize to other inversion techniques and editing applications requires further investigation.
- **Low Confidence**: The theoretical foundation for why unconditional noise in the renoising step specifically prevents off-manifold phenomena is not fully established.

## Next Checks

1. **Cross-architecture validation**: Test CFG++ on diffusion models with different architectures (e.g., latent diffusion vs. pixel-space) and varying numbers of parameters to verify the piecewise linear manifold assumption holds universally.

2. **Guidance scale sensitivity analysis**: Conduct a systematic study of CFG++ performance across a wider range of guidance scales (extending beyond [0,1]) to determine if there are scenarios where traditional CFG might still outperform CFG++ at extreme guidance requirements.

3. **Alternative inversion technique comparison**: Evaluate CFG++'s inversion improvements against other inversion methods beyond DDIM, such as consistent reconstruction or geometric accumulation inversion, to establish whether the improvements are specific to DDIM or generalize to the broader class of diffusion inversion techniques.