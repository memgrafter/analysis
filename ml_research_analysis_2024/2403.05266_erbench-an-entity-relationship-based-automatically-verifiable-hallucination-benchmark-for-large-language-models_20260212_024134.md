---
ver: rpa2
title: 'ERBench: An Entity-Relationship based Automatically Verifiable Hallucination
  Benchmark for Large Language Models'
arxiv_id: '2403.05266'
source_url: https://arxiv.org/abs/2403.05266
tags:
- movie
- questions
- option
- director
- soccer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ERBench is a new benchmark for evaluating hallucination in large
  language models using relational databases. It constructs questions from database
  schemas, records, and integrity constraints like functional dependencies and foreign
  key constraints to enable automatic verification of both answers and rationales.
---

# ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models

## Quick Facts
- arXiv ID: 2403.05266
- Source URL: https://arxiv.org/abs/2403.05266
- Reference count: 40
- Primary result: ERBench effectively evaluates LLM reasoning by checking for critical keywords in rationales, with high manual verification accuracy (>95%) and better performance than existing hallucination benchmarks

## Executive Summary
ERBench is a novel benchmark for evaluating hallucination in large language models (LLMs) using relational databases and integrity constraints. It automatically generates questions from database schemas, records, and constraints like functional dependencies and foreign key constraints, enabling automatic verification of both answers and rationales. The benchmark supports single-hop, multi-hop, and multimodal questions, and can be continuously updated as underlying databases change.

## Method Summary
ERBench converts databases into LLM benchmarks by leveraging functional dependencies (FDs) and foreign key constraints (FKCs) to generate questions and automatically verify responses. FDs are used to identify critical keywords that must appear in correct rationales, while FKCs enable construction of multi-hop questions by joining relations. The system generates single-hop, multi-hop, and multimodal questions from ER diagrams and automatically verifies both answers and rationales by checking for specific values derived from FDs.

## Key Results
- ERBench achieves over 95% manual verification accuracy across 5 datasets
- LLMs show significant performance drops on multi-hop questions compared to single-hop questions
- The benchmark effectively evaluates reasoning capabilities by checking for critical keywords in rationales rather than requiring full semantic understanding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Functional dependencies (FDs) can pinpoint critical keywords that an LLM must know to properly answer a given question containing certain attribute values.
- Mechanism: By defining FDs over database relations, the system can automatically extract the specific values that should appear in a correct rationale. When verifying an LLM response, it checks for the presence of these values rather than requiring full semantic understanding.
- Core assumption: The FDs accurately represent the true dependencies in the data, and the LLM's knowledge of these values is necessary for correct reasoning.
- Evidence anchors:
  - [abstract]: "functional dependencies can be used to pinpoint critical keywords that an LLM must know to properly answer a given question containing certain attribute values"
  - [section 3.1]: "When verifying an LLM response, ERBench checks if both the answer and rationale are correct. The answer checking is straightforward where we check if the LLM selected the right binary or multiple-choice option. To check the rationale, we look for the inferred values of the FD applied on the current record."
  - [corpus]: Weak evidence - no direct corpus support for FD-based keyword extraction
- Break condition: If FDs are incorrectly defined or if the LLM can answer without knowing the specific keyword values, this mechanism fails.

### Mechanism 2
- Claim: Foreign key constraints (FKCs) enable construction of arbitrarily long multi-hop questions that can debug intermediate answers.
- Mechanism: By joining relations through FKCs, ERBench can construct questions that require the LLM to reason across multiple steps. Each hop adds another relation, and the verification process checks for correctness at each step.
- Core assumption: FKCs correctly identify relationships between entities, and the LLM can follow these relationships through multiple hops.
- Evidence anchors:
  - [abstract]: "foreign key constraints can be used to join relations and construct multi-hop questions, which can be arbitrarily long and used to debug intermediate answers"
  - [section 3.3]: "Using a foreign key, we can also join two relations and construct FDs that span them. In Fig. 1, the FD title, year → birth year is a result of joining the Movie and Director relations and combining the first two Movie and Director FDs."
  - [corpus]: Weak evidence - limited corpus support for multi-hop construction
- Break condition: If the LLM cannot maintain reasoning accuracy across multiple hops or if FKCs don't represent true relationships.

### Mechanism 3
- Claim: The combination of FDs and FKCs enables automatic verification of both answers and rationales without human annotation.
- Mechanism: FDs provide the specific values to check in rationales, while FKCs enable construction of complex questions with clear correct answers. This combination allows fully automated evaluation.
- Core assumption: The database schema and integrity constraints are complete and accurate enough to generate meaningful questions with unambiguous answers.
- Evidence anchors:
  - [abstract]: "We thus propose ERBench, which uses these integrity constraints to convert any database into an LLM benchmark. ERBench supports continuous evaluation as databases change, multimodal questions, and various prompt engineering techniques."
  - [section 3.2]: "When verifying an LLM response, ERBench checks if both the answer and rationale are correct. The answer checking is straightforward where we check if the LLM selected the right binary or multiple-choice option."
  - [corpus]: Moderate evidence - related work on automatic verification exists but ERBench's specific approach is novel
- Break condition: If the database lacks sufficient integrity constraints or if questions cannot be constructed with clear verification criteria.

## Foundational Learning

- Concept: Functional Dependencies
  - Why needed here: FDs are the core mechanism for identifying critical keywords in rationales
  - Quick check question: Given a relation Movie(title, year, director, length) and the fact that a movie's title and year determine its director and length, how would you express this as a functional dependency?

- Concept: Foreign Key Constraints
  - Why needed here: FKCs enable multi-hop question construction by joining relations
  - Quick check question: If a Movie relation has a director attribute that refers to the name attribute of a Director relation, what is the foreign key constraint?

- Concept: Entity-Relationship Model
  - Why needed here: The ER model provides the framework for understanding how databases are structured
  - Quick check question: What are the three main components of an ER diagram?

## Architecture Onboarding

- Component map: Database schema → FD/FKC extraction → Question generation → LLM prompting → Response verification → Performance metrics
- Critical path: The flow from database schema through question generation to response verification and metric calculation
- Design tradeoffs: Automatic generation vs. manual curation (ERBench chooses automatic for scalability), single-hop vs. multi-hop complexity (ERBench supports both), text-only vs. multimodal (ERBench supports both)
- Failure signatures: Incorrect FD/FKC definitions leading to wrong verification criteria, insufficient entity knowledge in LLMs leading to poor performance, database changes not properly reflected in questions
- First 3 experiments:
  1. Test single-hop binary questions on a simple Movie database with FDs like title,year → director,length
  2. Test multi-hop questions by joining Movie with Director relations using FKCs
  3. Test multimodal questions by replacing text attributes with images and measuring performance changes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ERBench handle cases where the database schema or integrity constraints are incomplete or contain errors?
- Basis in paper: Inferred from the discussion of ERBench's reliance on database schema and integrity constraints for question generation and answer verification
- Why unresolved: The paper assumes that the database schema and integrity constraints are accurate and complete, but in practice, these can be flawed or incomplete, potentially leading to incorrect question generation or answer verification
- What evidence would resolve it: Experiments or analysis demonstrating ERBench's performance when applied to databases with known schema or constraint errors, or a proposed method for handling such cases

### Open Question 2
- Question: Can ERBench be extended to handle more complex types of integrity constraints beyond functional dependencies and foreign key constraints?
- Basis in paper: Inferred from the discussion of ERBench's use of functional dependencies and foreign key constraints, suggesting a potential for handling other constraint types
- Why unresolved: The paper focuses on functional dependencies and foreign key constraints, but there are other types of integrity constraints (e.g., check constraints, unique constraints) that could potentially be leveraged for question generation and answer verification
- What evidence would resolve it: A theoretical framework or experimental results demonstrating how ERBench could be extended to handle additional constraint types, along with an analysis of the potential benefits and challenges

### Open Question 3
- Question: How does ERBench perform when applied to databases with a high degree of semantic ambiguity or multiple valid interpretations of the same data?
- Basis in paper: Inferred from the discussion of ERBench's reliance on the database schema and data for question generation and answer verification, which may be challenging when dealing with ambiguous or semantically complex data
- Why unresolved: The paper does not address how ERBench handles cases where the database data or schema can be interpreted in multiple ways, potentially leading to ambiguity in question generation or answer verification
- What evidence would resolve it: Experiments or analysis demonstrating ERBench's performance on databases known to have high semantic ambiguity, or a proposed method for handling such cases

## Limitations

- The benchmark's effectiveness depends heavily on the quality and completeness of functional dependencies and foreign key constraints in source databases
- Multimodal evaluation uses a limited set of images and may not fully represent the challenges of visual reasoning
- High manual verification accuracy (>95%) was conducted on a subset of questions, raising potential sampling bias concerns

## Confidence

- High Confidence: The core mechanism of using functional dependencies to extract critical keywords for rationale verification is well-supported by the paper's experiments and theoretical framework
- Medium Confidence: The multi-hop question construction using foreign key constraints is supported by examples, but the scalability and effectiveness across diverse domains need further validation
- Low Confidence: The multimodal question generation approach, while promising, lacks detailed methodology and comprehensive evaluation across different types of visual data

## Next Checks

1. Conduct a comprehensive manual review of 100 randomly selected questions across all five datasets to verify the accuracy of automatically generated verification criteria based on functional dependencies
2. Test the multi-hop question generation mechanism on a new, unseen database with complex relationships to evaluate its scalability and robustness beyond the current datasets
3. Expand the multimodal evaluation to include diverse visual data types (e.g., charts, diagrams, real-world photos) and compare performance across different visual reasoning tasks