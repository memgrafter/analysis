---
ver: rpa2
title: Towards Quantifying The Privacy Of Redacted Text
arxiv_id: '2410.07772'
source_url: https://arxiv.org/abs/2410.07772
tags:
- text
- redacted
- privacy
- bart
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a k-anonymity-like approach for evaluating
  privacy of redacted text using transformer-based neural networks. The method generates
  multiple grammatical text reconstructions consistent with the redacted text, representing
  each as an embedding vector.
---

# Towards Quantifying The Privacy Of Redacted Text

## Quick Facts
- arXiv ID: 2410.07772
- Source URL: https://arxiv.org/abs/2410.07772
- Authors: Vaibhav Gusain; Douglas Leith
- Reference count: 11
- Primary result: Transformer-based reconstruction attacks can be quantified using k-anonymity-like metrics based on the diversity and quality of generated text reconstructions

## Executive Summary
This paper proposes a method for evaluating the privacy of redacted text by generating multiple grammatical reconstructions using a transformer-based neural network (BART) and analyzing their diversity and quality. The approach is inspired by k-anonymity, where privacy is achieved when many plausible reconstructions exist. By measuring how many grammatical sentences BART can generate from redacted text, the method estimates the level of privacy provided. Experiments across five datasets show that when less than 20% of words are redacted, BART produces grammatical reconstructions with high attack accuracy, while redaction above 80% provides strong privacy protection.

## Method Summary
The method uses BART, a transformer-based encoder-decoder architecture, to generate up to 100 grammatical reconstructions of redacted text. A gibberish detection algorithm (combining Nostrill with word overlap analysis) filters out non-grammatical predictions. The privacy metric is calculated as the mean gibberish classification score across predictions. For evaluation, a TFIDF vectorizer and logistic regression classifier are trained on non-redacted text to measure attack accuracy on redacted versions. The approach is tested across five datasets (BBCnews, Amazon-Fine-food, AGnews, IMDB, Medal) with varying redaction levels from 0% to 100%.

## Key Results
- When <20% of words are redacted, BART consistently produces grammatical reconstructions with high attack accuracy
- When >80% of words are redacted, privacy metrics approach 100% and attack accuracy drops to near-random guessing
- Between 20-80% redaction, increasing redaction level increases privacy and decreases attack effectiveness
- Selecting a redaction level ensuring privacy metrics exceed ~70% provides good resistance against text reconstruction attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BART's transformer architecture generates grammatical reconstructions by leveraging contextual word embeddings learned during pre-training.
- Mechanism: BART uses a bidirectional encoder-decoder structure where the encoder learns bidirectional context for each token, and the decoder generates output tokens left-to-right while attending to encoder outputs. This allows BART to predict masked words based on surrounding context.
- Core assumption: The surrounding context in redacted text provides sufficient information for BART to generate plausible reconstructions, even if not perfectly accurate.
- Evidence anchors:
  - [abstract] "transformer-based deep learning network to reconstruct the original text"
  - [section] "BART is a transformer-based neural net that targets reconstruction of text damaged by spelling mistakes, missing words etc"
  - [corpus] Weak - no direct corpus evidence provided
- Break condition: When redaction exceeds ~80%, the context becomes too sparse for BART to generate grammatical output, causing quality to drop sharply.

### Mechanism 2
- Claim: The gibberish detection algorithm effectively separates grammatical from non-grammatical BART predictions based on word overlap and character patterns.
- Mechanism: Algorithm 1 combines a standard gibberish detector (Nostrill) with a custom measure that calculates the fraction of original words overlapping with predictions. Sentences with low overlap and gibberish patterns are classified as non-grammatical.
- Core assumption: BART predictions are either clearly grammatical or clearly gibberish, with few ambiguous cases.
- Evidence anchors:
  - [section] "Algorithm 1 combines a standard gibberish detector Nostrill [4] with a measure of the fraction of words from the original (non-redacted) sentence that overlap with the predicted sentence"
  - [section] "BART predictions tend to either be fairly grammatical or else are grossly non-grammatical"
  - [corpus] Weak - algorithm specifics not fully detailed in corpus
- Break condition: When redaction level is moderate (20-80%), some grammatical sentences may be incorrectly classified as gibberish due to reduced context.

### Mechanism 3
- Claim: The privacy metric correlates with attack resistance because when BART cannot generate grammatical reconstructions, the contextual information needed for category classification is lost.
- Mechanism: As redaction increases and BART's reconstruction quality drops, the attack classifier (TFIDF + logistic regression) also loses accuracy because the remaining text provides insufficient information for category discrimination.
- Core assumption: The same contextual information that BART uses for reconstruction is also what the attack classifier needs for accurate categorization.
- Evidence anchors:
  - [section] "we find that the drop in BART prediction quality strongly correlates with a decrease in attack effectiveness"
  - [section] "as the percentage of masked words is increased the classification accuracy decreases while the privacy metric increases"
  - [corpus] Weak - correlation mentioned but causation not explicitly established
- Break condition: When redaction is too low (<20%) or too high (>80%), the correlation between BART quality and attack accuracy breaks down.

## Foundational Learning

- Concept: Transformer architecture and attention mechanisms
  - Why needed here: Understanding how BART's encoder-decoder structure processes context is crucial for grasping why the method works
  - Quick check question: How does the bidirectional encoder in BART differ from the left-to-right generation in the decoder, and why is this combination important for text reconstruction?

- Concept: Text embedding and similarity metrics
  - Why needed here: The method relies on representing sentences as embedding vectors to measure diversity and clustering of reconstructions
  - Quick check question: What properties should a good sentence embedding have to effectively capture semantic similarity for this privacy evaluation?

- Concept: k-anonymity privacy framework
  - Why needed here: The paper's approach is inspired by k-anonymity, using the number of plausible reconstructions as a privacy measure
  - Quick check question: How does the concept of "hiding in the crowd" apply to text reconstruction, and what does it mean for privacy when multiple reconstructions are possible?

## Architecture Onboarding

- Component map:
  - Data preprocessing: TFIDF vectorization and word frequency filtering
  - BART model: Transformer-based encoder-decoder for text reconstruction
  - Gibberish detection: Nostrill + custom overlap algorithm
  - Privacy metric: Mean gibberish classification score across top 100 predictions
  - Attack classifier: TFIDF vectorizer + logistic regression for category prediction
  - Evaluation pipeline: Redaction simulation, reconstruction generation, privacy measurement, attack accuracy calculation

- Critical path:
  1. Preprocess dataset with TFIDF and create train/test splits
  2. For each redacted sentence, generate top 100 BART reconstructions
  3. Apply gibberish detection algorithm to classify reconstructions
  4. Calculate privacy metric as mean gibberish score
  5. Train attack classifier on training data
  6. Measure attack accuracy on redacted test data
  7. Correlate privacy metric with attack accuracy across redaction levels

- Design tradeoffs:
  - Using top 100 predictions balances computational cost with coverage of reconstruction space
  - TFIDF-based redaction ensures informative words are masked but may miss domain-specific patterns
  - Simple gibberish detection may miss nuanced grammatical errors
  - Logistic regression classifier is interpretable but may underperform compared to more complex models

- Failure signatures:
  - Privacy metric near 0% even with high redaction indicates gibberish detection failure
  - Attack accuracy remains high despite high privacy metric suggests classifier overfitting or metric-correlate breakdown
  - Inconsistent results across datasets may indicate dataset-specific characteristics affecting BART's performance

- First 3 experiments:
  1. Run BART on fully intact sentences to establish baseline reconstruction quality
  2. Test gibberish detection algorithm on a small sample of BART outputs with varying redaction levels
  3. Measure privacy metric and attack accuracy for a single dataset at 0%, 50%, and 100% redaction levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the embedding vectors of BART predictions be clustered to estimate a k-anonymity-like metric that better reflects semantic diversity?
- Basis in paper: [explicit] The paper mentions that initial results indicate it may be possible to estimate a k-anonymity-like metric by clustering the embedding vectors of BART predictions and counting the number of distinct clusters, but proper analysis is left to future work.
- Why unresolved: The paper only provides initial results suggesting this approach might work, without presenting a detailed methodology or experimental validation.
- What evidence would resolve it: A complete methodology for clustering the embedding vectors, experimental results showing the effectiveness of this approach across multiple datasets, and comparison with traditional k-anonymity metrics would resolve this question.

### Open Question 2
- Question: How does the level of redaction needed to protect privacy vary depending on the granularity of the privacy threat (e.g., broad aspects like sentiment vs. fine-grained aspects)?
- Basis in paper: [explicit] The paper mentions that initial results suggest the nature of the privacy threat is relevant to the level of redaction needed, with broad textual aspects requiring higher levels of redaction than more fine-grained aspects.
- Why unresolved: The paper only provides initial results and mentions that further study of this aspect is left to future work.
- What evidence would resolve it: Detailed experiments comparing the level of redaction needed to protect different types of privacy threats (broad vs. fine-grained) across multiple datasets, and analysis of the relationship between threat granularity and required redaction level.

### Open Question 3
- Question: How does the proposed privacy metric correlate with utility measures such as next word prediction performance?
- Basis in paper: [explicit] The paper mentions that they evaluated next word prediction performance for the Medal dataset vs privacy and found that utility remains high even when redaction achieves a high level of resistance against estimation of medical condition, but does not provide detailed results.
- Why unresolved: The paper only briefly mentions this evaluation without presenting detailed results or discussing the relationship between privacy and utility.
- What evidence would resolve it: Comprehensive experiments measuring the correlation between the proposed privacy metric and various utility measures (e.g., next word prediction, text classification accuracy) across multiple datasets, and analysis of the trade-off between privacy and utility.

## Limitations

- The approach assumes that multiple grammatical reconstructions indicate insufficient privacy, but this may not account for cases where all reconstructions reveal the same sensitive information
- The evaluation focuses primarily on category classification accuracy as a proxy for privacy risk, which may not capture all privacy threats in real-world scenarios
- The study uses relatively standard datasets that may not represent the complexity and sensitivity of real-world redacted text

## Confidence

**High confidence**: The technical implementation of BART for text reconstruction and the basic methodology for measuring reconstruction quality are well-established. The correlation between reconstruction quality and attack accuracy across multiple datasets provides strong evidence for the core mechanism.

**Medium confidence**: The gibberish detection algorithm's effectiveness and the privacy metric's reliability across diverse text domains. While the paper shows consistent results across five datasets, the algorithm's performance on highly technical or domain-specific language remains uncertain.

**Low confidence**: The generalizability of results to real-world redaction scenarios and the sufficiency of category classification accuracy as a privacy metric. The paper doesn't address potential adversarial scenarios beyond category prediction or explore the method's effectiveness against more sophisticated privacy attacks.

## Next Checks

1. **Cross-dataset consistency test**: Apply the privacy evaluation method to a dataset with significantly different characteristics (e.g., medical records or legal documents) and compare the redaction-privacy relationship curves to the existing datasets. This would validate whether the observed patterns hold across diverse text domains.

2. **Adversarial attack robustness**: Design and implement an attack that targets the semantic content of redacted text rather than category classification. Test whether the privacy metric still correlates with attack success when the attack goal shifts from category prediction to extracting specific sensitive information.

3. **Human evaluation study**: Conduct a study where human participants attempt to reconstruct redacted text and identify sensitive information. Compare human success rates with the automated privacy metric to validate whether the computational measure accurately reflects real privacy risk.