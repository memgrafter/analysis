---
ver: rpa2
title: Large Language Models are Geographically Biased
arxiv_id: '2402.02680'
source_url: https://arxiv.org/abs/2402.02680
tags:
- bias
- topics
- ratings
- llms
- average
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to quantify geographic bias in LLMs
  by measuring systematic errors in their geospatial predictions. The method uses
  modified prompts to elicit ratings for locations across various topics, then compares
  these ratings against ground truth or socioeconomic proxies using Spearman's correlation
  and mean absolute deviation.
---

# Large Language Models are Geographically Biased

## Quick Facts
- arXiv ID: 2402.02680
- Source URL: https://arxiv.org/abs/2402.02680
- Authors: Rohin Manvi; Samar Khanna; Marshall Burke; David Lobell; Stefano Ermon
- Reference count: 40
- Key outcome: LLMs exhibit geographic bias on subjective topics, with correlation coefficients up to 0.70 with socioeconomic indicators

## Executive Summary
This paper introduces a method to quantify geographic bias in large language models by measuring systematic errors in their geospatial predictions. The authors demonstrate that LLMs can make accurate zero-shot geospatial predictions on objective topics (Spearman's ρ up to 0.89) but show clear socioeconomic bias on subjective topics like attractiveness and intelligence. They introduce a comprehensive bias score that incorporates correlation with socioeconomic indicators, rating consistency, and answer rates. Experiments across multiple models reveal significant variation in bias levels, with GPT-4 Turbo and Llama 2 70B showing the least bias.

## Method Summary
The method uses modified prompts to elicit ratings from LLMs for locations across various topics, then compares these ratings against ground truth or socioeconomic proxies using Spearman's correlation and mean absolute deviation. The prompts include task context and GeoLLM spatial information to enable zero-shot geospatial predictions. A bias score is calculated that combines correlation with socioeconomic indicators, mean absolute deviation, and answer rate to quantify geographic bias. The approach is validated across multiple LLM architectures including GPT-4 Turbo, Llama 2 70B, and GPT-3.5.

## Key Results
- LLMs show strong monotonic correlation with ground truth for objective topics (Spearman's ρ up to 0.89)
- Clear socioeconomic bias observed on subjective topics like attractiveness and intelligence (correlation coefficients up to 0.70)
- GPT-4 Turbo and Llama 2 70B exhibit the least bias among tested models
- Bias score effectively captures variation in geographic bias across models and topics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method successfully elicits geospatial knowledge from LLMs by modifying GeoLLM prompts to include task context.
- Mechanism: Adding a prefix that clarifies the task (rating relative to all human-populated locations) and maintains the GeoLLM spatial context enables zero-shot geospatial predictions without fine-tuning.
- Core assumption: LLMs have embedded geospatial knowledge that can be accessed through well-designed prompts.
- Evidence anchors: [abstract] "Initially, we demonstrate that LLMs are capable of making accurate zero-shot geospatial predictions in the form of ratings that show strong monotonic correlation with ground truth (Spearman's ρ of up to 0.89)."

### Mechanism 2
- Claim: Spearman's rank correlation is an appropriate metric for evaluating geospatial predictions in this context.
- Mechanism: Since LLM ratings are not uniformly distributed and may be skewed, ranking the ratings and comparing them to ground truth ranks provides a more accurate measure of monotonic correlation than Pearson's r.
- Core assumption: We care about the relative ordering of predictions, not the absolute values, when evaluating geospatial knowledge.
- Evidence anchors: [section] "We use Spearman's ρ (eq. 1) (Spearman, 1961), which is equivalent to Pearson's r with the respective ranks instead of the ratings."

### Mechanism 3
- Claim: The bias score effectively quantifies geographic bias in LLMs by combining correlation with an anchoring bias distribution, mean absolute deviation, and answer rate.
- Mechanism: The bias score penalizes LLMs for correlations with socioeconomic indicators, large deviations in ratings on sensitive topics, and high answer rates on controversial topics.
- Core assumption: A truly unbiased model would either give constant ratings, random ratings, or refuse to answer on sensitive subjective topics.
- Evidence anchors: [abstract] "We introduce a bias score that incorporates both correlation with socioeconomic indicators and rating consistency, finding significant variation across models, with GPT-4 Turbo and Llama 2 70B showing the least bias."

## Foundational Learning

- Concept: Geospatial datasets and their use in evaluating model knowledge
  - Why needed here: The method relies on comparing LLM predictions to ground truth geospatial data to measure accuracy and bias
  - Quick check question: What are some examples of geospatial datasets that could be used to evaluate LLM knowledge of population density or temperature?

- Concept: Prompt engineering for eliciting specific responses from LLMs
  - Why needed here: The method requires modifying prompts to extract geospatial knowledge without fine-tuning
  - Quick check question: How might the inclusion of task context in a prompt influence an LLM's response compared to a prompt without that context?

- Concept: Statistical measures of correlation and deviation
  - Why needed here: The method uses Spearman's rank correlation and mean absolute deviation to quantify model performance and bias
  - Quick check question: Why might Spearman's rank correlation be more appropriate than Pearson's r for evaluating LLM geospatial predictions?

## Architecture Onboarding

- Component map: Prompt generator -> LLM interface -> Ground truth data -> Evaluation module
- Critical path: 1. Generate prompts for geographic coordinates 2. Send prompts to LLM and collect ratings 3. Compare ratings to ground truth using Spearman's correlation 4. Calculate MAD and bias score 5. Analyze results and visualize on maps
- Design tradeoffs: Using logprobs for more precise ratings vs. discrete ratings for simplicity; choosing an anchoring bias distribution that may not capture all forms of bias; balancing granularity of coordinates with computational efficiency
- Failure signatures: Low answer rate from LLM indicating reluctance to engage; low Spearman's correlation suggesting poor geospatial knowledge extraction; high bias score indicating strong correlation with socioeconomic indicators
- First 3 experiments: 1. Test prompt modifications on small coordinate set to verify zero-shot performance 2. Compare Spearman's correlation with and without logprobs for rating precision 3. Analyze bias score components separately to understand their contributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can geographic bias be quantified in a single, comprehensive metric that captures all relevant dimensions of bias?
- Basis in paper: explicit
- Why unresolved: The authors acknowledge that geographic bias can be evaluated along multiple axes and that their current bias score only captures correlation with one anchoring bias distribution. A single comprehensive metric would need to account for all possible forms of geographic bias.
- What evidence would resolve it: A validated, multi-dimensional geographic bias metric that can effectively compare models across all relevant geographic dimensions and correlates with real-world outcomes.

### Open Question 2
- Question: What is the optimal prompt structure for eliciting zero-shot geospatial predictions that balances accuracy with bias minimization?
- Basis in paper: explicit
- Why unresolved: The authors demonstrate that prompt structure significantly affects both prediction accuracy and bias levels, but haven't explored the full space of prompt designs or identified optimal trade-offs.
- What evidence would resolve it: Systematic experiments comparing different prompt structures while measuring both prediction accuracy and bias levels across multiple models.

### Open Question 3
- Question: How do geographic biases in LLMs manifest in real-world applications beyond the direct rating tasks tested?
- Basis in paper: explicit
- Why unresolved: While the authors provide preliminary evidence of bias in travel recommendations, the full extent and impact of geographic biases in practical applications remains unknown.
- What evidence would resolve it: Comprehensive studies examining how geographic biases affect various real-world LLM applications and their downstream impacts on different populations.

## Limitations

- Ground truth quality and representativeness uncertainty, particularly for subjective topics where anchoring bias distribution may not fully capture socioeconomic factors
- Prompt engineering variability that could significantly impact results but isn't systematically explored
- Model-specific behavior differences that make it difficult to distinguish between true bias and architectural differences

## Confidence

- High Confidence: LLMs exhibit geographic bias on subjective topics, demonstrated through strong correlations with socioeconomic indicators
- Medium Confidence: GPT-4 Turbo and Llama 2 70B show the least bias among tested models
- Low Confidence: The method can effectively elicit zero-shot geospatial predictions from any LLM without model-specific tuning

## Next Checks

1. Cross-validate bias detection using multiple socioeconomic indicators (GDP, education levels, urbanization rates) to verify robustness of observed correlations
2. Conduct systematic prompt ablation study to determine essential components for accurate geospatial knowledge elicitation
3. Evaluate model versions over time to distinguish between inherent architectural biases and training data artifacts