---
ver: rpa2
title: Evaluation of Geographical Distortions in Language Models
arxiv_id: '2404.17401'
source_url: https://arxiv.org/abs/2404.17401
tags:
- arxiv
- cities
- geographical
- page
- geographic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates geographic biases in language models by introducing
  four indicators to assess spatial information coverage, geographic knowledge disparities,
  and distortions in semantic versus geographic distances. Experiments on ten widely
  used models reveal systematic overrepresentation of Western countries and underrepresentation
  of African, Eastern European, and Middle Eastern regions.
---

# Evaluation of Geographical Distortions in Language Models

## Quick Facts
- arXiv ID: 2404.17401
- Source URL: https://arxiv.org/abs/2404.17401
- Reference count: 25
- Key outcome: Language models systematically overrepresent Western countries while underrepresenting African, Eastern European, and Middle Eastern regions, with geographic knowledge quality not scaling with model size.

## Executive Summary
This study evaluates geographic biases in language models by introducing four indicators to assess spatial information coverage, geographic knowledge disparities, and distortions in semantic versus geographic distances. Experiments on ten widely used models reveal systematic overrepresentation of Western countries and underrepresentation of African, Eastern European, and Middle Eastern regions. Geographic knowledge quality does not scale with model size, and multilingual models partially mitigate bias at the expense of English task performance. Semantic and geographic distances show low correlation, with Western and Oceanian countries appearing unnaturally close while African cities are abnormally distant. These biases impact downstream NLP tasks, particularly in crisis response, where underrepresented regions face higher vulnerability but poorer model coverage.

## Method Summary
The study evaluates ten widely used language models (BERT, m-BERT, GeoLM, RoBERTa, XLM-RoBERTa, LLaMa 2, LLaMa 3, Mistral v0.1, Mistral v0.3, ChatGPT, OpenAI/Ada) using four indicators: vocabulary coverage analysis of city names, geo-guessing tasks for geographic knowledge, correlation analysis between geographic and semantic distances, and geographic distortion index calculation. The analysis uses GeoNames gazetteer data of cities with population >100,000 and examines whether spatial information coverage, knowledge disparities, and semantic-geographic distance correlations reveal systematic geographic biases across models.

## Key Results
- Western countries are systematically overrepresented while African, Eastern European, and Middle Eastern regions are underrepresented across all tested language models
- Geographic knowledge quality does not improve with model size, contradicting typical scaling trends in other domains
- Semantic and geographic distances show low correlation, with Western and Oceanian countries appearing unnaturally close while African cities show abnormal distances
- Multilingual models partially mitigate geographic bias but at the cost of reduced English task performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Token vocabulary coverage of city names in training data predicts geographic knowledge quality in masked language models.
- Mechanism: The tokenizer's vocabulary is built from most frequent tokens in pretraining data. If a city name appears frequently enough to be included, it indicates strong representation of that region in training corpora, leading to better geographic knowledge in downstream tasks.
- Core assumption: City name frequency in training data directly correlates with overall regional representation and model's ability to answer geographic queries.
- Evidence anchors: [abstract] "Experiments are conducted from these four indicators with ten widely used language models. Results underscore the critical necessity of inspecting and rectifying spatial biases in language models to ensure accurate and equitable representations." [section] "We investigate the inclusion or exclusion of cities (using their English names) with a population of more than 100,000, totalling 4,916 cities, in the predefined vocabularies of the models." [corpus] Weak - no direct corpus evidence about token frequency patterns.
- Break condition: If tokenizer uses subword tokenization (like SentencePiece), this mechanism breaks since city names appear as decomposed subword units rather than full tokens.

### Mechanism 2
- Claim: Semantic distance between city embeddings correlates with geographic distance when training data provides balanced regional co-occurrences.
- Mechanism: When cities from different regions appear together in training text, their embeddings capture spatial relationships. Balanced co-occurrence patterns lead to embeddings where semantic distance mirrors geographic distance.
- Core assumption: Training data contains sufficient co-occurrences of geographically proximate cities to learn spatial relationships through context.
- Evidence anchors: [abstract] "Geographic knowledge quality does not scale with model size, and multilingual models partially mitigate bias at the expense of English task performance." [section] "According to Tobler (1970), on page 236, the first law of geography states that Everything is related to everything else, but near things are more related than distant things. This implies that the embeddings of geographically close cities should also be close to the semantic space of the models." [corpus] Moderate - corpus shows some papers on embedding quality metrics and spatial information, but limited direct evidence about geographic co-occurrence patterns.
- Break condition: If training data is sparse for certain regions, embeddings will not capture accurate geographic relationships regardless of model architecture.

### Mechanism 3
- Claim: Geographic knowledge disparities impact downstream NLP task performance, particularly for crisis response applications.
- Mechanism: Models with poor geographic knowledge for certain regions will generate less accurate responses when asked about those locations, leading to ineffective crisis management support where it's most needed.
- Core assumption: Geographic knowledge directly affects model performance on location-based reasoning tasks.
- Evidence anchors: [abstract] "These biases impact downstream NLP tasks, particularly in crisis response, where underrepresented regions face higher vulnerability but poorer model coverage." [section] "We also assess the impact of these geographical biases on downstream NLP tasks, with a particular focus on using LMs for crisis management." [corpus] Weak - corpus shows some papers on NLP task performance and geographic information, but limited evidence specifically about crisis response impact.
- Break condition: If models can retrieve external geographic information (via RAG or similar), this mechanism may not hold as strongly.

## Foundational Learning

- Concept: Vector embeddings and cosine similarity
  - Why needed here: The study uses semantic distances between city embeddings to measure geographic distortion, requiring understanding of how embeddings represent meaning and how cosine similarity measures semantic relatedness.
  - Quick check question: What does a cosine similarity of 0.8 between two city embeddings indicate about their semantic relationship?

- Concept: Tokenization and vocabulary construction
  - Why needed here: The first indicator examines which city names appear in model vocabularies, requiring understanding of how tokenizers build vocabularies from training data frequency.
  - Quick check question: How does a tokenizer decide which words to include in its fixed vocabulary during pretraining?

- Concept: Correlation analysis and linear regression
  - Why needed here: The study measures correlation between geographic and semantic distances using R² values from linear regression, requiring understanding of statistical correlation metrics.
  - Quick check question: What does an R² value of 0.25 indicate about the relationship between geographic and semantic distances?

## Architecture Onboarding

- Component map: The system consists of four evaluation indicators: (1) vocabulary coverage analysis, (2) geo-guessing task for geographic knowledge, (3) correlation analysis between geographic and semantic distances, (4) geographic distortion index calculation. Data flows from raw model embeddings through distance calculations to statistical analysis.
- Critical path: For each model: extract embeddings → compute pairwise distances → calculate correlation coefficients → identify outliers → aggregate by region. The geo-guessing task runs in parallel for geographic knowledge assessment.
- Design tradeoffs: Using city names as geographic entities provides granularity but suffers from homonyms. Focusing on population thresholds balances coverage with data quality. The GDI metric corrects for geographical isolation but adds complexity to interpretation.
- Failure signatures: Low correlation between distances indicates poor spatial encoding. Zero scores on geo-guessing suggest complete lack of geographic knowledge. High GDI values for certain regions indicate semantic isolation or overrepresentation.
- First 3 experiments:
  1. Run vocabulary coverage check on a small set of city names to verify tokenizer behavior before full analysis
  2. Test geo-guessing task with a single model and a few capital cities to validate prompt effectiveness
  3. Compute pairwise distances for a small region (e.g., Europe) to verify distance calculation pipeline before scaling up

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms or training data characteristics cause language models to capture geographic distances less accurately in underrepresented regions?
- Basis in paper: [inferred] The paper identifies that geographic knowledge quality is not evenly distributed globally and that regions like Africa, Eastern Europe, and Southeast Asia are semantically isolated, but does not specify the exact mechanisms causing this.
- Why unresolved: The study observes correlations between geographic and semantic distances but cannot definitively attribute the low correlations to specific training data patterns or model architecture limitations.
- What evidence would resolve it: Detailed analysis of co-occurrence patterns in training datasets, or controlled experiments varying geographic data representation during training, could identify whether underrepresentation in co-occurrences or other factors drives the observed disparities.

### Open Question 2
- Question: How can language models be improved to better represent geographic distances in underrepresented regions without degrading performance on other tasks?
- Basis in paper: [explicit] The paper discusses several strategies (e.g., retrieval-augmented generation, multilingual fine-tuning, model merging) but notes that approaches like GeoLM fine-tuning led to loss of language understanding capabilities.
- Why unresolved: While the paper proposes multiple approaches, it does not evaluate their effectiveness in practice or determine which balance geographic accuracy with general task performance.
- What evidence would resolve it: Systematic comparison of these approaches using standardized geographic benchmark datasets would show which methods best improve geographic accuracy without compromising other capabilities.

### Open Question 3
- Question: To what extent do geographic biases in language models impact the effectiveness of downstream NLP tasks in crisis management for underrepresented regions?
- Basis in paper: [explicit] The paper highlights that regions most vulnerable to natural disasters often have poorer language model coverage and discusses implications for crisis response tasks like event detection and deduplication.
- Why unresolved: While the paper identifies geographic disparities and suggests potential impacts, it lacks empirical data showing how these biases directly affect crisis management task performance in underrepresented regions.
- What evidence would resolve it: Empirical studies comparing model performance on crisis management tasks across regions with varying geographic representation in training data would quantify the real-world impact of these biases.

## Limitations
- Tokenization-dependent validity: The first indicator's reliance on city name inclusion in tokenizer vocabularies introduces significant uncertainty, as this breaks down with subword tokenization systems.
- Training data opacity: The study cannot verify whether low vocabulary coverage actually indicates underrepresentation in training data, as pretraining corpora are typically proprietary.
- Crisis response impact verification: While geographic biases are claimed to impact crisis response applications, there is minimal direct evidence connecting measured indicators to actual task performance.

## Confidence
- Geographic knowledge disparities exist: High
- Semantic distance distortions are real: High
- Multilingual models mitigate bias at performance cost: Medium

## Next Checks
1. Subword tokenization validation: For each model, verify whether high-population city names appear as complete tokens versus decomposed subwords in the tokenizer vocabulary.
2. Geographic co-occurrence analysis: Analyze actual training data (where accessible) to measure co-occurrence frequencies of geographically proximate cities.
3. Downstream task benchmarking: Design and execute controlled experiments measuring actual performance differences on location-based reasoning tasks across models with varying geographic knowledge quality.