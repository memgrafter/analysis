---
ver: rpa2
title: Towards Better Benchmark Datasets for Inductive Knowledge Graph Completion
arxiv_id: '2406.11898'
source_url: https://arxiv.org/abs/2406.11898
tags:
- datasets
- inductive
- graph
- performance
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Existing inductive KGC datasets exhibit a shortcut where Personalized
  PageRank (PPR) achieves near-SOTA performance, undermining their validity. The root
  cause is that the dataset construction procedure creates graphs with significantly
  lower shortest path distances (SPD) between entities in positive test samples compared
  to negatives.
---

# Towards Better Benchmark Datasets for Inductive Knowledge Graph Completion

## Quick Facts
- arXiv ID: 2406.11898
- Source URL: https://arxiv.org/abs/2406.11898
- Reference count: 40
- Primary result: Existing inductive KGC datasets exhibit a shortcut where Personalized PageRank achieves near-SOTA performance due to low SPD between positive test entities

## Executive Summary
This paper identifies a critical flaw in existing inductive knowledge graph completion (KGC) benchmarks: Personalized PageRank (PPR) can achieve near-state-of-the-art performance not by learning meaningful relational patterns, but by exploiting structural shortcuts in the dataset construction process. The root cause is that positive test samples have significantly shorter shortest path distances (SPD) compared to negative samples, allowing PPR to distinguish them without using relational information. The authors propose using graph partitioning to construct better benchmarks that preserve the original graph's properties while eliminating this shortcut mechanism.

## Method Summary
The authors analyze existing inductive KGC datasets and discover that their construction procedure creates graphs with artificially low SPD between entities in positive test samples compared to negatives. This structural bias allows simple heuristics like PPR to perform well without learning relational patterns. To address this, they propose a graph partitioning approach that samples train and inference subgraphs while better preserving the original graph's SPD distribution. The method involves partitioning the graph and carefully selecting entities for training and testing to maintain similar SPD characteristics between positive and negative samples.

## Key Results
- PPR performance drops dramatically on newly constructed datasets (e.g., from 66.0% to 45.1% Hits@10 on WN18RR)
- The performance gap between PPR and supervised methods increases from ~25% to ~101%
- The proposed graph partitioning approach effectively mitigates the shortcut mechanism while preserving dataset utility

## Why This Works (Mechanism)
The shortcut works because existing dataset construction procedures create positive test samples with entities that are closer in the graph (lower SPD) compared to negative samples. PPR, which favors shorter walks, can exploit this structural bias to achieve high performance without learning meaningful relational patterns. The graph partitioning approach works by sampling subgraphs that better preserve the original graph's SPD distribution, making it harder for simple heuristics to distinguish positive from negative samples based solely on graph structure.

## Foundational Learning
- **Knowledge Graph Completion**: Predicting missing links in a knowledge graph; needed to understand the core task being benchmarked
- **Inductive Learning**: Training on one graph and evaluating on unseen entities; quick check: verify if model can generalize to new entities
- **Personalized PageRank**: A link prediction method that scores nodes based on random walks; quick check: examine how PPR performs on different graph structures
- **Shortest Path Distance (SPD)**: The minimum number of edges between two nodes; quick check: calculate SPD distributions for positive vs negative samples
- **Graph Partitioning**: Dividing a graph into disjoint subsets; quick check: verify partition quality using standard metrics

## Architecture Onboarding
- **Component Map**: Original Graph -> Graph Partitioning -> Train/Inference Subgraphs -> Benchmark Dataset
- **Critical Path**: Dataset Construction → SPD Analysis → Shortcut Detection → Graph Partitioning → New Benchmark Creation
- **Design Tradeoffs**: Balanced partitions vs. preserving original graph properties; larger partitions may preserve more properties but reduce the inductive setting's challenge
- **Failure Signatures**: PPR achieving near-SOTA performance; large SPD gaps between positive and negative test samples
- **First Experiments**: 1) Compare SPD distributions between positive and negative samples in existing datasets, 2) Measure PPR performance on current vs. newly constructed benchmarks, 3) Test whether other simple heuristics can exploit remaining structural biases

## Open Questions the Paper Calls Out
The paper does not explicitly call out additional open questions beyond the primary findings.

## Limitations
- Does not systematically explore alternative shortcut features that could persist in proposed datasets
- Effectiveness of graph partitioning as a universal solution requires validation across diverse KGC scenarios
- The completeness of shortcut identification is uncertain, as other structural biases may exist

## Confidence
- High confidence in the empirical observation that PPR exploits SPD shortcuts in existing datasets
- Medium confidence in the graph partitioning methodology as a general solution
- Low confidence in the completeness of shortcut identification

## Next Checks
1. Test the graph partitioning approach on additional KGC datasets beyond WN18RR and NELL-995 to verify generalizability
2. Conduct ablation studies to isolate the impact of specific graph partitioning parameters on shortcut elimination
3. Investigate whether other simple heuristics beyond PPR can exploit remaining structural biases in newly constructed datasets