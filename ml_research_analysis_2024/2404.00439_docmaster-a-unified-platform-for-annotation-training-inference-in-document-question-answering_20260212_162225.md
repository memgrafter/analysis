---
ver: rpa2
title: 'DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document
  Question-Answering'
arxiv_id: '2404.00439'
source_url: https://arxiv.org/abs/2404.00439
tags:
- document
- docmaster
- training
- text
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DOCMASTER, a unified platform for annotating,
  training, and performing inference for document question-answering tasks. The platform
  addresses challenges in training NLP models on PDF documents, including the complexity
  of PDF formats and the lack of privacy-preserving annotation tools.
---

# DOCMASTER: A Unified Platform for Annotation, Training, & Inference in Document Question-Answering

## Quick Facts
- arXiv ID: 2404.00439
- Source URL: https://arxiv.org/abs/2404.00439
- Authors: Alex Nguyen; Zilong Wang; Jingbo Shang; Dheeraj Mekala
- Reference count: 9
- One-line primary result: Seven-fold increase in document processing throughput through AI-assisted QA for PDF documents

## Executive Summary
DOCMASTER is a unified platform for annotating, training, and performing inference on document question-answering tasks. It addresses challenges in training NLP models on PDF documents, including complex PDF formats and privacy concerns. The platform enables users to upload PDFs, input questions, and highlight text spans as answers while saving layout information. DOCMASTER has been deployed at UCSD's ISEO, reducing document processing time from 15 to 100 documents per hour and achieving 94% correctness and 93.56% accuracy for RoBERTa-base on a test set of 128 applications.

## Method Summary
The platform integrates PDF.js for frontend rendering and PyMuPDF for backend text extraction, solving layout-aware annotation challenges.