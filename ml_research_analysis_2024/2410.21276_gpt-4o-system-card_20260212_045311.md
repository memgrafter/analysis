---
ver: rpa2
title: GPT-4o System Card
arxiv_id: '2410.21276'
source_url: https://arxiv.org/abs/2410.21276
tags:
- gpt-4o
- audio
- text
- voice
- evaluations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GPT-4o is a multimodal model capable of processing text, audio,
  image, and video inputs to generate corresponding outputs. The model was evaluated
  for safety, including risks related to voice generation, speaker identification,
  and content moderation.
---

# GPT-4o System Card

## Quick Facts
- arXiv ID: 2410.21276
- Source URL: https://arxiv.org/abs/2410.21276
- Authors: OpenAI and 230+ contributors
- Reference count: 40
- Key outcome: GPT-4o is a multimodal model capable of processing text, audio, image, and video inputs to generate corresponding outputs with improved performance in underrepresented languages and strong medical knowledge benchmarks.

## Executive Summary
GPT-4o is OpenAI's latest multimodal model capable of processing text, audio, image, and video inputs to generate corresponding outputs. The model was developed with a focus on safety, including risks related to voice generation, speaker identification, and content moderation. Safety measures include restricting voice outputs to preset voices, refusing to identify speakers from audio inputs, and blocking disallowed content. The model demonstrates improved performance in underrepresented languages compared to GPT-4 and outperforms existing specialized models on medical knowledge benchmarks. Evaluations showed GPT-4o performs comparably to prior models in English while showing no significant increase in autonomous capabilities.

## Method Summary
GPT-4o was developed through end-to-end training across text, vision, and audio modalities using a diverse dataset including web data, code/math, and multimodal data up to October 2023. The model underwent post-training alignment to human preferences for safety, followed by extensive red teaming and third-party assessments. Safety mitigations were implemented for voice generation risks (restricting to preset voices), speaker identification (refusing to identify speakers), and content moderation (using text transcription classifiers). Performance was evaluated across multiple benchmarks including medical knowledge, general capabilities, and safety-specific tests.

## Key Results
- GPT-4o demonstrates low latency speech responses (232-320ms) through end-to-end training of all modalities
- The model shows improved performance in underrepresented languages while maintaining comparable English performance to GPT-4
- GPT-4o outperforms existing specialized models on medical knowledge benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4o achieves low latency speech responses by processing all modalities through a single end-to-end trained neural network.
- Mechanism: End-to-end training allows the model to directly map audio inputs to audio outputs without intermediate modality-specific bottlenecks, enabling faster response times.
- Core assumption: The model's architecture can effectively handle all input/output combinations without significant degradation in quality.
- Evidence anchors:
  - [abstract] "It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network."
  - [section] "GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation."
- Break condition: If the model encounters inputs that significantly differ from its training distribution, the end-to-end approach may struggle to maintain low latency and high quality.

### Mechanism 2
- Claim: GPT-4o maintains safety across modalities by transferring text-based moderation policies to audio outputs through transcription.
- Mechanism: The model's post-training includes alignment to human preferences for safety, and existing text moderation classifiers are applied to transcriptions of audio inputs and outputs.
- Core assumption: Text-based safety policies and classifiers are sufficiently effective when applied to audio through transcription.
- Evidence anchors:
  - [section] "We found high text to audio transference of refusals for previously disallowed content."
  - [section] "Additionally, we run our existing moderation model over a text transcription of both audio input and audio output to detect if either contains potentially harmful language, and will block a generation if so."
- Break condition: If the transcription process introduces errors or if audio-specific nuances are not captured by text classifiers, safety may be compromised.

### Mechanism 3
- Claim: GPT-4o reduces unauthorized voice generation by restricting output to pre-selected voices and using an output classifier.
- Mechanism: During post-training, the model is supervised with ideal completions using the selected voice as the base, and a standalone classifier detects deviations from approved voices.
- Core assumption: The classifier can reliably distinguish between approved and unapproved voices in real-time.
- Evidence anchors:
  - [section] "We addressed voice generation related-risks by allowing only the preset voices we created in collaboration with voice actors to be used."
  - [section] "Additionally, we built a standalone output classifier to detect if the GPT-4o output is using a voice that's different from our approved list."
- Break condition: If the classifier's precision degrades over time or with new voice samples, unauthorized voice generation could increase.

## Foundational Learning

- Concept: Multimodal model architecture
  - Why needed here: Understanding how GPT-4o processes different input/output combinations is crucial for grasping its capabilities and limitations.
  - Quick check question: How does end-to-end training differ from training separate models for each modality?

- Concept: Safety evaluation methodologies
  - Why needed here: The paper describes various safety measures and their effectiveness, which is essential for understanding the model's deployment readiness.
  - Quick check question: What are the advantages and disadvantages of using text transcriptions for audio moderation?

- Concept: Red teaming and external evaluation
  - Why needed here: The paper emphasizes the importance of external testing in identifying potential risks and improving safety measures.
  - Quick check question: Why is it important to have diverse red teamers representing different languages and geographic backgrounds?

## Architecture Onboarding

- Component map: Input processors for text, audio, image, and video -> Unified neural network for end-to-end processing -> Output generators for text, audio, and image -> Safety classifiers (moderation, voice output, speaker identification) -> Post-training alignment modules

- Critical path: 1. Input reception and preprocessing 2. Neural network inference 3. Safety checks and filtering 4. Output generation and streaming

- Design tradeoffs: End-to-end training vs. modular approach: End-to-end allows for faster processing but may be less flexible in handling edge cases. Real-time safety checks vs. post-generation filtering: Real-time checks ensure immediate safety but may introduce latency.

- Failure signatures: Increased latency or timeouts during inference, inconsistent safety behavior across modalities, degradation in output quality for underrepresented languages or accents

- First 3 experiments: 1. Test end-to-end inference latency with different input combinations and compare to modular approach. 2. Evaluate safety classifier performance on transcribed audio vs. original text inputs. 3. Assess voice output classifier precision and recall on a diverse set of voice samples.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific safety measures were implemented to prevent unauthorized voice generation in GPT-4o, and how effective are these measures?
- Basis in paper: [explicit] The paper discusses that unauthorized voice generation risks were mitigated by allowing only preset voices and using an output classifier to detect deviations.
- Why unresolved: While the paper mentions the implementation of these measures, it does not provide detailed information on the specific techniques used or the comprehensive effectiveness of these measures.
- What evidence would resolve it: Detailed descriptions of the techniques used for voice verification and comprehensive test results showing the effectiveness of these measures against various attempts at unauthorized voice generation.

### Open Question 2
- Question: How does GPT-4o handle voice inputs with different accents and dialects, and what impact does this have on model performance and fairness?
- Basis in paper: [explicit] The paper mentions evaluations on disparate performance on voice inputs across different accents but does not detail the impact on performance and fairness.
- Why unresolved: The paper notes that performance is marginally worse for diverse human voices but does not explore the broader implications for fairness and inclusivity.
- What evidence would resolve it: Comprehensive analysis of model performance across a wider range of accents and dialects, including user studies on perceived fairness and inclusivity.

### Open Question 3
- Question: What are the potential long-term societal impacts of anthropomorphization and emotional reliance on GPT-4o, and how can these impacts be mitigated?
- Basis in paper: [inferred] The paper discusses anthropomorphization and emotional reliance as potential risks, suggesting a need for further study into their long-term societal impacts.
- Why unresolved: The paper identifies these risks but does not explore their long-term societal impacts or propose specific mitigation strategies.
- What evidence would resolve it: Longitudinal studies on user interactions with GPT-4o, exploring changes in social behavior and emotional reliance, along with proposed mitigation strategies based on findings.

### Open Question 4
- Question: What are the potential risks and benefits of using GPT-4o for scientific research, particularly in accelerating mundane and transformative scientific tasks?
- Basis in paper: [inferred] The paper mentions the potential for GPT-4o to accelerate scientific research but does not explore the associated risks and benefits in detail.
- Why unresolved: The paper highlights the capabilities of GPT-4o in scientific contexts but lacks a thorough discussion of the risks and benefits.
- What evidence would resolve it: Detailed studies on the use of GPT-4o in scientific research, including case studies on both mundane and transformative tasks, with analysis of risks, benefits, and ethical considerations.

### Open Question 5
- Question: How does GPT-4o's performance in medical knowledge benchmarks compare to existing specialized models, and what are the implications for healthcare applications?
- Basis in paper: [explicit] The paper states that GPT-4o outperforms existing specialized models on medical knowledge benchmarks but does not explore the implications for healthcare applications.
- Why unresolved: While the paper provides performance data, it does not discuss the practical implications for healthcare applications or the potential benefits and risks.
- What evidence would resolve it: Case studies or pilot programs demonstrating the use of GPT-4o in real-world healthcare settings, along with analysis of benefits, risks, and areas for improvement.

## Limitations

- The safety evaluations, particularly for audio outputs and voice generation, rely on proprietary testing methodologies that are not fully disclosed
- Performance improvements in underrepresented languages lack detailed breakdown across different language families and proficiency levels
- The effectiveness of text-based moderation for audio content depends on transcription accuracy, which may introduce errors

## Confidence

**High Confidence:** Claims about the model's end-to-end training architecture and basic multimodal processing capabilities are well-supported by the technical descriptions and performance benchmarks provided.

**Medium Confidence:** The safety measures and their effectiveness ratings are based on reported evaluations, but the specific methodologies and success rates for detecting subtle safety violations are not fully detailed.

**Low Confidence:** Assertions about the model's performance in underrepresented languages and its ability to handle diverse accents and dialects lack granular data to support these claims.

## Next Checks

1. Conduct independent evaluations of the voice output classifier using a diverse set of voice samples, including both approved and unapproved voices, to verify the reported precision and recall rates.

2. Perform systematic testing of the model's performance across different language families and proficiency levels to validate the claimed improvements in underrepresented languages.

3. Implement a controlled study comparing the model's safety behavior when processing audio inputs directly versus through transcribed text to assess the effectiveness of the text-based moderation approach.