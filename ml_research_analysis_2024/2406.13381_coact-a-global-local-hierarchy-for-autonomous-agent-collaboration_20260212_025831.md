---
ver: rpa2
title: 'CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration'
arxiv_id: '2406.13381'
source_url: https://arxiv.org/abs/2406.13381
tags:
- coact
- global
- agent
- plan
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoAct introduces a hierarchical multi-agent framework where a global
  planning agent formulates high-level plans and assigns subtasks to a local execution
  agent, which focuses on detailed task implementation. This structure enables better
  task comprehension and more accurate execution compared to single-agent approaches.
---

# CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration

## Quick Facts
- arXiv ID: 2406.13381
- Source URL: https://arxiv.org/abs/2406.13381
- Authors: Xinming Hou; Mingming Yang; Wenxiang Jiao; Xing Wang; Zhaopeng Tu; Wayne Xin Zhao
- Reference count: 18
- Primary result: 13.8% success rate on WebArena benchmark, 40% improvement over ReAct baseline

## Executive Summary
CoAct introduces a hierarchical multi-agent framework for autonomous web task execution that divides responsibilities between a global planning agent and a local execution agent. The global agent formulates high-level plans and assigns subtasks, while the local agent focuses on detailed implementation and execution. This hierarchical approach addresses the limitations of single-agent systems by enabling better context management, dynamic re-planning when failures occur, and improved task comprehension. Tested on the WebArena benchmark across five diverse web tasks, CoAct achieved a 13.8% success rate compared to 9.4% for the baseline ReAct method, representing over 40% improvement.

## Method Summary
CoAct implements a two-agent hierarchical framework where a global planning agent creates macro-level plans and assigns subtasks to a local execution agent. The global agent handles task comprehension and creates high-level plans, while the local agent executes detailed subtasks, navigates web interfaces, and collects feedback. When execution failures occur, the local agent can request re-planning from the global agent, enabling dynamic adaptation. The framework uses gpt-3.5-turbo-16K-0613 as the backbone LLM with temperature=1, and was evaluated on the WebArena benchmark with 5 tasks (Shop, CMS, Reddit, Gitlab, Map) using 100 examples per task.

## Key Results
- Achieved 13.8% success rate on WebArena benchmark across 5 tasks
- 40% improvement over ReAct baseline (9.4% success rate)
- Identified 40% of failures stem from planning inadequacies, 60% from iterative/repetitive actions
- Particularly effective for long-horizon web tasks through dynamic re-planning capability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical task decomposition enables better context management and reduces cognitive load on individual agents
- Mechanism: The global planning agent handles high-level task understanding and creates macro-level plans, while the local execution agent focuses on detailed implementation of specific subtasks. This division allows each agent to operate within its optimal scope of attention and memory capacity
- Core assumption: Large language models have limited context windows and attention mechanisms that constrain their ability to handle complex, long-horizon tasks in a single stream
- Evidence anchors:
  - [abstract] "Current explorations predominantly focus on a single LLM and a single memory stream. Recent studies (Wang et al., 2023) indicate that the performance of a single LLM is constrained by the finite nature of the attention mechanism and hierarchical capacity"
  - [section 3.2] "ReAct will struggle to address them as the agent accumulates excessive context information during category-seeking, preventing the model from recognizing the need to break out of the category search process after a failure"

### Mechanism 2
- Claim: Explicit re-planning capability allows dynamic adaptation to execution failures
- Mechanism: When the local execution agent encounters failures, it can request re-planning from the global planning agent, which can revise the global plan based on new information and context from the execution phase
- Core assumption: Task execution often encounters unforeseen obstacles that require adaptive planning rather than rigid adherence to initial plans
- Evidence anchors:
  - [abstract] "CoAct can re-arrange the process trajectory when facing failures"
  - [section 3.2] "Local execution agents can request adjustments to the global plan, enabling macro-level re-planning"

### Mechanism 3
- Claim: Context partitioning through hierarchical planning improves attention allocation and memory management
- Mechanism: By dividing the task into distinct phases with clear outcomes, CoAct creates natural boundaries for context switching, allowing agents to maintain focused attention on relevant information for each subtask
- Core assumption: Large language models perform better when operating on focused, relevant context rather than accumulated, potentially contradictory information
- Evidence anchors:
  - [section 3.2] "The core difference between CoAct and ReAct lies in context partitioning, attention allocation, and memory management"
  - [section 4] "About 60% of CoAct's failures involve iterative and repetitive actions, surpassing the maximum round limit for interaction between the global planning agent and the local execution agent"

## Foundational Learning

- Concept: Hierarchical planning and decomposition
  - Why needed here: CoAct relies on breaking down complex tasks into manageable subtasks that can be handled by different agents at different levels of abstraction
  - Quick check question: How does hierarchical planning differ from flat planning approaches in terms of cognitive load distribution?

- Concept: Multi-agent coordination and communication protocols
  - Why needed here: The framework requires effective communication between global planning and local execution agents, including request-response patterns for re-planning
  - Quick check question: What are the key communication patterns needed between planning and execution agents in a hierarchical system?

- Concept: Error recovery and adaptive planning
  - Why needed here: CoAct must handle execution failures gracefully by requesting and implementing revised plans from the global agent
  - Quick check question: How does the re-planning mechanism in CoAct differ from simple error correction or retry mechanisms?

## Architecture Onboarding

- Component map:
  Global Planning Agent -> Local Execution Agent -> Environment Interface -> Feedback Loop -> Global Planning Agent

- Critical path:
  1. Task input → Global Planning Agent
  2. Global plan creation → Local Execution Agent assignment
  3. Subtask execution → Environment interaction
  4. Execution feedback → Progress evaluation
  5. Success or failure → Continue or request re-planning
  6. Re-planning if needed → Updated global plan
  7. Task completion validation → Output generation

- Design tradeoffs:
  - Granularity of task decomposition vs. communication overhead
  - Re-planning frequency vs. execution efficiency
  - Agent specialization depth vs. system flexibility
  - Context retention vs. memory constraints

- Failure signatures:
  - Planning inadequacies: 40% of failures indicate insufficient task understanding at global level
  - Iterative/repetitive actions: 60% of failures suggest local execution getting stuck in loops
  - Communication breakdowns: Failed re-planning requests or misinterpreted feedback
  - Context mismatch: Subtasks that don't align with global objectives

- First 3 experiments:
  1. Baseline comparison: Run CoAct vs. ReAct on identical tasks to measure improvement in success rate
  2. Failure analysis: Categorize failures in CoAct to identify whether they stem from planning or execution issues
  3. Memory optimization: Test different context retention strategies for the local execution agent to reduce repetitive actions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CoAct vary when different LLMs are used as the backbone model?
- Basis in paper: [inferred] The paper uses gpt-3.5-turbo-16K-0613 as the backbone LLM but does not explore other models.
- Why unresolved: The paper only tests CoAct with a single LLM model, leaving the impact of different model architectures unexplored.
- What evidence would resolve it: Experiments comparing CoAct's performance using various LLM models (e.g., GPT-4, Claude, LLaMA) on the same benchmark tasks.

### Open Question 2
- Question: What is the optimal number of phases for global planning in CoAct across different task complexities?
- Basis in paper: [explicit] The paper mentions global planning agent decomposes tasks into "Phase 1, Phase 2...Phase N" but doesn't investigate optimal phase granularity.
- Why unresolved: The paper uses a variable number of phases without systematic analysis of how phase granularity affects performance.
- What evidence would resolve it: Controlled experiments varying the number of phases for the same tasks and measuring success rates and efficiency metrics.

### Open Question 3
- Question: How does CoAct's hierarchical approach compare to flat multi-agent approaches without global-local distinction?
- Basis in paper: [inferred] The paper focuses on the hierarchical global-local structure but doesn't compare to alternative multi-agent architectures.
- Why unresolved: The paper only benchmarks against single-agent ReAct, not against other multi-agent approaches.
- What evidence would resolve it: Experiments comparing CoAct to flat multi-agent systems where agents collaborate without hierarchical structure.

### Open Question 4
- Question: What specific knowledge integration methods would most effectively reduce the 40% planning inadequacies in CoAct?
- Basis in paper: [explicit] The paper identifies "Planning Inadequacies" as affecting ~40% of failures and suggests web page-specific knowledge integration.
- Why unresolved: The paper mentions the problem and general direction but doesn't test specific knowledge integration approaches.
- What evidence would resolve it: Experiments testing different knowledge integration methods (e.g., fine-tuning, retrieval augmentation, tool use) and measuring their impact on planning success rates.

## Limitations
- The framework's generalizability beyond WebArena benchmark remains uncertain
- Optimal granularity for task decomposition is not empirically validated
- Communication protocol details between agents are not fully specified
- The "force stop intervention" mechanism lacks detailed implementation explanation

## Confidence

**High confidence**: The overall hierarchical framework design and its basic premise of dividing global planning from local execution is well-supported by the empirical results showing 13.8% success rate vs 9.4% baseline. The mechanism of context partitioning through hierarchical planning is clearly articulated and demonstrates measurable improvement.

**Medium confidence**: The specific failure mode analysis (40% planning inadequacies, 60% iterative actions) is based on observed data but the methodology for categorization isn't fully detailed. The effectiveness of the re-planning mechanism when execution failures occur is demonstrated but the frequency and quality of re-planning decisions could benefit from more granular analysis.

**Low confidence**: The generalizability of the framework beyond the WebArena benchmark remains uncertain, as does the scalability to more complex, real-world web tasks. The performance impact of different agent communication patterns and the optimal granularity for task decomposition are not empirically validated across multiple task types.

## Next Checks

1. **Communication Protocol Validation**: Implement and test multiple communication pattern variations between global planning and local execution agents (e.g., synchronous vs asynchronous messaging, different granularity of feedback) to identify optimal communication protocols for various task types.

2. **Failure Mode Resolution Testing**: Design specific experiments to address the identified failure modes - implement enhanced memory mechanisms to reduce repetitive actions and test improved global planning strategies to reduce planning inadequacies, measuring the impact on overall success rates.

3. **Cross-Benchmark Generalization**: Evaluate CoAct on additional web task benchmarks beyond WebArena to assess the framework's generalizability and identify whether the 40/60 failure split remains consistent across different task domains and complexity levels.