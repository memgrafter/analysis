---
ver: rpa2
title: The twin peaks of learning neural networks
arxiv_id: '2401.12610'
source_url: https://arxiv.org/abs/2401.12610
tags:
- error
- mean
- dimension
- peak
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between the double descent
  phenomenon in neural networks and the Boolean Mean Dimension (BMD), a metric that
  measures the complexity and sensitivity of functions represented by neural networks.
  The authors derive an analytical expression for the BMD in the Random Feature Model
  (RFM) using the replica method, showing that the BMD exhibits a peak at the interpolation
  threshold, coinciding with the peak in generalization error.
---

# The twin peaks of learning neural networks

## Quick Facts
- arXiv ID: 2401.12610
- Source URL: https://arxiv.org/abs/2401.12610
- Authors: Elizaveta Demyanenko; Christoph Feinauer; Enrico M. Malatesta; Luca Saglietti
- Reference count: 40
- Key outcome: This paper investigates the relationship between the double descent phenomenon in neural networks and the Boolean Mean Dimension (BMD), a metric that measures the complexity and sensitivity of functions represented by neural networks.

## Executive Summary
This paper establishes a connection between the double descent phenomenon in neural networks and the Boolean Mean Dimension (BMD), a measure of function complexity and sensitivity. The authors derive an analytical expression for BMD in the Random Feature Model using the replica method, showing that BMD peaks at the interpolation threshold, coinciding with the peak in generalization error. Through extensive numerical experiments with various model architectures (RFM, MLP, ResNet) and datasets (MNIST, CIFAR10), they demonstrate that BMD can serve as a black-box test for assessing overfitting without requiring task-specific data.

## Method Summary
The authors use a combination of theoretical analysis and numerical experiments to study the relationship between BMD and the double descent phenomenon. They derive analytical expressions for BMD in the Random Feature Model using the replica method, and estimate BMD for other models using Monte Carlo methods. Models are trained with cross-entropy loss and L2 regularization using the Adam optimizer with batch size 128. They experiment with different levels of label noise and input distributions, including binary, Gaussian, and uniform inputs. The BMD is computed for various model architectures (RFM, MLP, ResNet) and datasets (MNIST, CIFAR10) to observe its behavior across different settings.

## Key Results
- The Boolean Mean Dimension (BMD) exhibits a peak at the interpolation threshold, coinciding with the peak in generalization error
- BMD values are higher for adversarially initialized models and correlate with model robustness to adversarial attacks
- The location of the BMD peak is robust to the choice of input statistics used for its measurement, even in non-i.i.d. settings
- BMD can serve as a black-box test for assessing the proximity to the separability threshold and signaling potential overfitting, without requiring task-specific data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Boolean Mean Dimension (BMD) peaks at the interpolation threshold because the function represented by the neural network becomes maximally sensitive to input perturbations as overfitting begins.
- Mechanism: As the model capacity increases past the interpolation threshold, it starts fitting noise in the training data. This increased sensitivity manifests as higher variance in the function's response to small input changes, which directly raises the BMD.
- Core assumption: The BMD accurately measures sensitivity to input perturbations under the assumed binary input distribution.
- Evidence anchors:
  - [abstract] "we find that, as the degree of overparameterization of the network is increased, the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak"
  - [section 4.3] "the BMD reaches an evident peak at the interpolation threshold, in correspondence with the generalization error peak"
  - [corpus] Weak evidence - no direct mention of BMD or double descent in neighboring papers
- Break condition: If the model's sensitivity to input changes doesn't correlate with its overfitting behavior, or if the input distribution assumption is violated.

### Mechanism 2
- Claim: Adversarial initialization increases BMD because it forces the network to implement a more complex, sensitive function that overfits the noisy pretraining data.
- Mechanism: Training on 100% label noise creates a function that is highly sensitive to input variations. When this model is then trained on clean data, it retains this sensitivity, resulting in higher BMD.
- Core assumption: The sensitivity induced by adversarial pretraining persists through subsequent training on clean data.
- Evidence anchors:
  - [section 5.3] "we observe a significant increase in the BMD of the adversarially initialized model"
  - [section 5.4] "higher values of the BMD correspond to lower robustness of the model and vice versa"
  - [corpus] Weak evidence - no direct mention of adversarial initialization or BMD
- Break condition: If the model's architecture or training procedure can effectively reduce sensitivity despite adversarial initialization.

### Mechanism 3
- Claim: The location of the BMD peak is robust to input distribution choice because it depends primarily on the first two moments of the input distribution.
- Mechanism: The BMD calculation involves expectations over input perturbations. As long as different input distributions share the same first two moments, these expectations produce similar results, making the BMD peak location stable.
- Core assumption: The function's sensitivity to input changes depends primarily on the first two moments of the input distribution.
- Evidence anchors:
  - [section 5.6] "distributions, which first two moments coincide (e.g. binary uniform Unif{-1, 1} and Gaussian N(0, 1)) yield the same MD pattern"
  - [section B.2.1] "we would have obtained the same result if we had chosen a probability distribution on the inputs with the same first two moments"
  - [corpus] Weak evidence - no direct mention of input distribution robustness
- Break condition: If higher-order moments of the input distribution significantly affect the function's sensitivity, or if the function's behavior is highly non-local.

## Foundational Learning

- Concept: Boolean Mean Dimension (BMD)
  - Why needed here: BMD is the central metric used to measure function sensitivity and complexity in this work. Understanding its definition and properties is crucial for interpreting all results.
  - Quick check question: What does a high BMD value indicate about a function's behavior?

- Concept: Double descent phenomenon
  - Why needed here: The paper connects BMD behavior to the double descent phenomenon in generalization error. Understanding double descent is essential for interpreting the main results.
  - Quick check question: What happens to generalization error as model capacity increases past the interpolation threshold?

- Concept: Replica method
  - Why needed here: The analytical results for BMD in the Random Feature Model rely on the replica method from statistical physics. Understanding this method is necessary to follow the theoretical derivations.
  - Quick check question: What type of problems is the replica method typically used to solve?

## Architecture Onboarding

- Component map:
  - Random Feature Model (RFM): Fixed first layer weights, trainable second layer
  - Two-layer MLP: Trainable weights in both layers
  - ResNet-18: Convolutional architecture with residual connections
  - All models: Cross-entropy loss with optional L2 regularization

- Critical path:
  1. Initialize model (Xavier initialization)
  2. Train on dataset (Adam optimizer, batch size 128)
  3. Compute BMD using Monte Carlo estimation or analytical formula (for RFM)
  4. Analyze BMD behavior as function of model capacity

- Design tradeoffs:
  - RFM vs. MLP: RFM has analytical tractability but limited expressivity; MLP has more parameters but harder to analyze theoretically
  - Regularization strength: Higher regularization reduces both generalization and BMD peaks but may hurt performance
  - Label noise: Increases both peaks but makes them more pronounced and easier to detect

- Failure signatures:
  - BMD peak not aligned with generalization peak: Model sensitivity not properly capturing overfitting behavior
  - BMD always close to 1: Model implementing very simple function regardless of capacity
  - No self-averaging in BMD: Insufficient sample size or unstable training procedure

- First 3 experiments:
  1. Reproduce RFM BMD calculation on MNIST with varying width to verify peak at interpolation threshold
  2. Compare BMD of adversarially initialized vs normally initialized RFM to confirm sensitivity increase
  3. Test BMD robustness to input distribution by computing with binary, Gaussian, and uniform inputs for a trained MLP

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Boolean Mean Dimension (BMD) behave in neural networks with architectures beyond those studied in this paper (e.g., recurrent networks, transformers, or networks with non-standard activation functions)?
- Basis in paper: [inferred] The paper primarily investigates the BMD in the Random Feature Model (RFM), two-layer fully connected networks, and ResNet architectures. It does not explore more complex architectures.
- Why unresolved: The paper's scope is limited to a specific set of architectures, and the theoretical framework may not directly extend to other architectures.
- What evidence would resolve it: Empirical studies measuring the BMD in a variety of network architectures and comparing the results to the findings in this paper.

### Open Question 2
- Question: Can the BMD be used as a reliable indicator of overfitting in scenarios where the training data distribution is significantly different from the test data distribution?
- Basis in paper: [explicit] The paper mentions that the BMD is estimated using i.i.d. binary inputs, which are different from the training data distribution. However, it shows that the BMD peak still correlates with the generalization error peak.
- Why unresolved: The paper does not investigate scenarios where the training and test data distributions are vastly different, such as domain adaptation or out-of-distribution generalization.
- What evidence would resolve it: Empirical studies measuring the BMD in scenarios with different training and test data distributions and analyzing its correlation with generalization performance.

### Open Question 3
- Question: How does the choice of the input distribution for estimating the BMD affect its value and its ability to predict generalization performance?
- Basis in paper: [explicit] The paper explores the effect of using different input distributions for estimating the BMD, including binary, Gaussian, uniform, and empirical distributions. It shows that the location of the BMD peak is robust to the choice of input distribution, but the absolute values may vary.
- Why unresolved: The paper does not investigate the optimal choice of input distribution for estimating the BMD or provide a theoretical justification for the observed robustness.
- What evidence would resolve it: Theoretical analysis of the relationship between the input distribution and the BMD, as well as empirical studies comparing the performance of different input distributions in predicting generalization.

## Limitations

- The theoretical foundation linking BMD to double descent relies heavily on assumptions about input distributions and model behavior in the high-dimensional limit
- The analytical expressions for BMD are derived specifically for the Random Feature Model, and generalization to deeper networks remains empirical
- The robustness of BMD to input distribution choice, while demonstrated, requires further theoretical justification

## Confidence

- **High Confidence:** The empirical observation that BMD peaks at the interpolation threshold across multiple model architectures and datasets
- **Medium Confidence:** The theoretical connection between BMD peaks and function sensitivity to input perturbations
- **Medium Confidence:** The relationship between adversarial initialization and increased BMD values

## Next Checks

1. Test BMD behavior on architectures not examined in the paper (e.g., Vision Transformers, recurrent networks) to assess the universality of the phenomenon
2. Conduct ablation studies varying the perturbation magnitude in BMD calculation to determine its impact on peak location and magnitude
3. Investigate whether alternative complexity measures (e.g., Fisher-Rao norm, path norm) exhibit similar phenomenology to BMD at the interpolation threshold