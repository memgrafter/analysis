---
ver: rpa2
title: 'AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma
  Patient Support'
arxiv_id: '2409.15815'
source_url: https://arxiv.org/abs/2409.15815
tags:
- language
- asthmabot
- asthma
- text
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AsthmaBot, a multi-lingual, multi-modal retrieval-augmented
  generation system for asthma patient support. AsthmaBot addresses the challenge
  of limited access to medical care, especially in developing countries, by providing
  automated, accurate, and interactive support.
---

# AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support

## Quick Facts
- arXiv ID: 2409.15815
- Source URL: https://arxiv.org/abs/2409.15815
- Reference count: 1
- Primary result: AsthmaBot improves asthma patient support via multi-modal, multi-lingual RAG, reducing hallucinations and language bias

## Executive Summary
AsthmaBot is a multi-modal, multi-lingual retrieval-augmented generation system designed to support asthma patients, particularly in regions with limited access to medical care. It integrates text, images, and videos, leveraging RAG to ground responses in curated sources and reduce hallucinations. The system addresses LLM language bias by translating queries to English for retrieval and generation, then translating answers back. Evaluated on an asthma FAQ dataset, AsthmaBot shows significant performance improvements over a no-RAG baseline across languages and modalities, with a user-friendly online interface for accessibility.

## Method Summary
AsthmaBot is a multi-modal, multi-lingual RAG system that supports asthma patients by retrieving context from curated text, images, and videos before generating answers. The system detects the language of user queries, translates them to English, retrieves relevant content from separate vector databases per modality, and prompts an LLM (Google Gemini) with this context. Answers are translated back to the original language and delivered via a chatbot interface. Evaluation uses ROUGE and BLEU metrics on an asthma FAQ dataset, comparing performance against a no-RAG baseline.

## Key Results
- AsthmaBot significantly outperforms a no-RAG baseline on an asthma FAQ dataset using ROUGE and BLEU metrics.
- The system successfully mitigates LLM language bias by translating queries to English and back.
- Multimodal retrieval (text, images, videos) improves answer quality and comprehensiveness.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AsthmaBot reduces hallucinations by retrieving context from curated multimodal sources before generating answers.
- Mechanism: The RAG architecture supplies the LLM with semantically relevant text, image, and video descriptions retrieved via vector similarity, grounding generation in factual sources rather than relying solely on parametric memory.
- Core assumption: Retrieved context is sufficiently relevant and accurate to correct or constrain the LLM's output.
- Evidence anchors:
  - [abstract] "Retrieval-augmented generation systems, integrating curated documents, can improve large language models' performance and reduce the incidence of hallucination."
  - [section] "To address these challenges new works... supply LLMs with pertinent documents sourced from current and reliable collections... called retrieval augmented generation (RAG)."
- Break condition: If retrieved passages are irrelevant or noisy, the model may still hallucinate or misinterpret context.

### Mechanism 2
- Claim: AsthmaBot mitigates language bias by translating non-English queries to English before retrieval and generation, then translating answers back.
- Mechanism: The system uses a language detection module, translates queries to English, retrieves from English-only vector stores, prompts the LLM in English, and translates responses to the original language.
- Core assumption: The LLM performs better in English due to richer training data, and translation quality is high enough to preserve meaning.
- Evidence anchors:
  - [abstract] "LLMs suffer from language biases, which limits the quality of information that they generate in languages other than English."
  - [section] "We noticed that LLMs (Gemini and ChatGPT) have biases towards the English language and can produce significantly richer responses in English than in Arabic or French."
- Break condition: If translation introduces errors or the LLM's English bias is not strong enough, performance in non-English languages may degrade.

### Mechanism 3
- Claim: AsthmaBot's multimodal retrieval improves performance over unimodal approaches by integrating text, images, and videos.
- Mechanism: Separate vector databases for each modality allow targeted retrieval, and the system aggregates evidence from multiple sources to provide comprehensive answers.
- Core assumption: Different modalities contain complementary information that enhances answer quality when combined.
- Evidence anchors:
  - [abstract] "AsthmaBot has an added interactive and intuitive interface that integrates different data modalities (text, images, videos) to make it accessible to the larger public."
  - [section] "Evaluation of an asthma-related frequently asked questions dataset shows AsthmaBot's efficacy."
  - [corpus] Weak: No direct citation or comparison to unimodal baselines in neighbor papers, but implied by design.
- Break condition: If modality integration is not properly weighted or synchronized, it may introduce noise or inconsistency.

## Foundational Learning

- Concept: Vector database indexing and semantic search
  - Why needed here: Enables fast, relevant retrieval of multimodal content for RAG
  - Quick check question: How does cosine similarity between vector embeddings determine retrieval relevance?

- Concept: Retrieval-augmented generation (RAG) pipeline
  - Why needed here: Core mechanism for reducing hallucinations and grounding responses
  - Quick check question: What are the three main components of a RAG system and how do they interact?

- Concept: Cross-lingual model bias and translation effects
  - Why needed here: Explains why query translation to English improves LLM output quality
  - Quick check question: Why might an LLM produce richer responses in English compared to other languages?

## Architecture Onboarding

- Component map:
  Frontend -> Chatbot interface -> Backend -> Query -> Language detection -> Translation -> Vector store selection -> Retrieval -> Prompt assembly -> LLM inference -> Translation -> Response -> Frontend display

- Critical path:
  Query → Language detection → Query translation → Retriever → Prompt assembly → LLM → Answer translation → Frontend display

- Design tradeoffs:
  - Multiple vector stores increase parallelism but add complexity
  - Translation step reduces language bias but adds latency and potential errors
  - Separate modality stores enable specialization but require careful aggregation

- Failure signatures:
  - Irrelevant or missing retrieval results → vague or incorrect answers
  - Translation errors → nonsensical or off-topic responses
  - Vector store misconfiguration → empty or mismatched context

- First 3 experiments:
  1. Test end-to-end with a single English query and text-only retrieval to verify basic RAG pipeline
  2. Add non-English query with translation to confirm language bias mitigation works
  3. Enable all modalities and verify multimodal context aggregation and response formatting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the data curation process be improved for the video and image modules in AsthmaBot?
- Basis in paper: [explicit] The paper mentions that the RAG video and image modules are less curated than the text module, which was taken from educational resources.
- Why unresolved: The paper suggests that improving the curation of videos and images could enhance the trustworthiness of AsthmaBot, but it does not provide specific methods or strategies for achieving this improvement.
- What evidence would resolve it: A detailed study comparing the performance of AsthmaBot with expert-curated videos and images versus the current automated curation process, showing significant improvements in trustworthiness and accuracy.

### Open Question 2
- Question: How can automatic prompting be implemented to improve AsthmaBot's performance?
- Basis in paper: [explicit] The paper suggests that AsthmaBot could benefit from new research in learnable prompts, which could be particularly important for fine-tuning prompts to FAQs.
- Why unresolved: The paper does not provide specific methods or examples of how automatic prompting could be implemented or how it would improve AsthmaBot's performance.
- What evidence would resolve it: A study demonstrating the implementation of automatic prompting in AsthmaBot, with measurable improvements in the quality and relevance of responses compared to the current prompting approach.

### Open Question 3
- Question: What are the limitations of the current evaluation protocol for AsthmaBot, and how can they be addressed?
- Basis in paper: [explicit] The paper mentions that the current evaluation protocol is fully automated and may not convey the full extent of evaluation, such as factuality and adherence to contextual information.
- Why unresolved: The paper acknowledges the limitations of the current evaluation protocol but does not propose specific methods for addressing these limitations or improving the evaluation process.
- What evidence would resolve it: A comprehensive evaluation study that includes both automated and manual evaluation methods, demonstrating improvements in the assessment of factuality, contextual adherence, and overall performance of AsthmaBot.

## Limitations
- Evaluation is based on a small asthma FAQ dataset, limiting generalizability to real-world queries.
- Reliance on translation introduces potential for meaning loss or mistranslation, especially for complex medical terms.
- The claim of "significant" performance improvements lacks detailed statistical validation (e.g., p-values, effect sizes).

## Confidence
- **High confidence**: The core RAG mechanism (retrieval + generation) is well-established and the translation-to-English approach is a documented solution for LLM language bias.
- **Medium confidence**: The multimodal retrieval approach and the claim of improved performance over a no-RAG baseline, as these are supported by the evaluation but lack detailed statistical validation.
- **Low confidence**: The scalability and robustness of the system in real-world, diverse patient interactions, given the limited evaluation scope and lack of error analysis.

## Next Checks
1. Conduct statistical significance testing (e.g., paired t-tests) on ROUGE/BLEU scores across languages and modalities to confirm that improvements over the no-RAG baseline are not due to chance.
2. Perform a detailed error analysis on a sample of failed queries to identify failure modes (e.g., translation errors, irrelevant retrieval, modality integration issues) and quantify their impact on performance.
3. Test the system on an expanded, more diverse set of asthma-related queries and out-of-domain medical questions to assess robustness, generalizability, and sensitivity to data curation quality.