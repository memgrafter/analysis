---
ver: rpa2
title: Untrained neural networks can demonstrate memorization-independent abstract
  reasoning
arxiv_id: '2407.17791'
source_url: https://arxiv.org/abs/2407.17791
tags:
- features
- predictive
- feature
- problems
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether abstract reasoning can be achieved
  by neural networks without prior training, addressing concerns that existing models
  rely on memorization. The authors developed a novel approach using untrained Relation
  Networks (RNs) that optimize their weights during problem-solving using the data
  itself.
---

# Untrained neural networks can demonstrate memorization-independent abstract reasoning

## Quick Facts
- arXiv ID: 2407.17791
- Source URL: https://arxiv.org/abs/2407.17791
- Authors: Tomer Barak; Yonatan Loewenstein
- Reference count: 40
- Primary result: Untrained Relation Networks achieved 58% accuracy on abstract reasoning tasks, significantly above chance level of 25%

## Executive Summary
This study challenges the prevailing view that neural networks must be trained on similar problems to solve abstract reasoning tasks. The authors demonstrate that untrained Relation Networks can successfully identify predictive features and their relationships in visual reasoning problems by optimizing their weights during test time using the problem data itself. The approach achieves an average accuracy of 58% across varying difficulty levels, suggesting that abstract reasoning capabilities can emerge from test-time optimization without requiring extensive prior training data.

## Method Summary
The study used untrained Relation Networks to solve visual reasoning problems consisting of sequences of 5 images with 4 choice images. The network architecture includes 3 random convolutional layers followed by 5 fully connected layers in the encoder, with a simple relation module measuring consistency between consecutive latent representations. During test time, the network optimizes its weights using RMSprop (learning rate 1e-5) for 10 steps per problem, treating each problem as a small optimization task to minimize inconsistency between consecutive images.

## Key Results
- Untrained networks achieved 58% average accuracy across all test conditions, significantly outperforming chance level (25%)
- Performance critically depends on optimizing fully connected layers while random convolutional layers act as frozen feature extractors
- Training on specific predictive features improves performance on those features through knowledge crystallization, but doesn't generalize to other features
- Interleaving training on multiple features was more effective than block training, showing parallels to human learning patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The untrained network can solve abstract reasoning problems without prior training because it optimizes its weights during the test phase using the problem data itself.
- Mechanism: During test time, the network treats each problem as a small optimization task. The loss function encourages the network to find representations and relations that minimize inconsistency between consecutive images in the sequence. This allows the network to discover the predictive feature and its rule on the fly.
- Core assumption: The optimization process can converge to useful representations even when starting from random weights.
- Evidence anchors:
  - [abstract]: "untrained Relation Networks (RNs) that optimize their weights during problem-solving using the data itself"
  - [section]: "the model does not need to learn the features and their relation in the generative sense to solve a test successfully. Instead, it is enough to find image representations and rules that are sufficiently correlated with a problem's predictive feature"
  - [corpus]: No direct evidence found in neighbors about untrained networks solving reasoning tasks.
- Break condition: If the optimization process fails to converge or gets stuck in poor local minima, the network would not identify the predictive feature correctly.

### Mechanism 2
- Claim: The convolutional layers act as frozen feature extractors that are already sufficiently good at capturing features correlated with the predictive features.
- Mechanism: Random initialization of convolutional layers happens to create filters that, by chance, respond to patterns in the data that correlate with the underlying predictive features. These layers don't need training because they already provide useful feature representations.
- Core assumption: Random convolutional filters can capture useful patterns without training.
- Evidence anchors:
  - [section]: "The random convolutional layers extract features that are correlated with relevant latent features... optimization of the convolutional layers was not necessary for achieving the performance"
  - [section]: "the parameters of the convolutional layers are optimized in the direction of minimizing the loss function... However, it turns out that the optimization of the parameters of the convolutional layers does not contribute to the performance"
  - [corpus]: No direct evidence in neighbors about random convolutional filters capturing relevant features.
- Break condition: If the random filters happen not to capture any patterns related to the predictive features, the network would fail.

### Mechanism 3
- Claim: The fully connected layers and relation module learn to amplify the representation of features that vary monotonically with the sequence order.
- Mechanism: During optimization, the loss function "seeks" representations that vary predictably with the sequence. The gradient updates cause the network to amplify connections from neurons that correlate with the sequence order, effectively highlighting the predictive feature.
- Core assumption: The optimization process can distinguish between features that vary with the sequence and those that don't.
- Evidence anchors:
  - [section]: "the optimization process makes larger changes to the synaptic weights from those neurons that co-vary strongly with the sequence order"
  - [section]: "the neurons in the encoder's FC layer become strongly correlated with the sequence order... the encoder amplifies the representation of those features that co-vary with the sequence order"
  - [corpus]: No direct evidence in neighbors about sequence-based feature amplification.
- Break condition: If multiple features co-vary with the sequence order equally, the network may amplify irrelevant features.

## Foundational Learning

- Concept: Optimization-based problem solving
  - Why needed here: The entire approach relies on using gradient descent to optimize network weights during test time rather than relying on pre-trained weights.
  - Quick check question: Can you explain why the network needs to optimize during test time rather than using pre-trained weights?

- Concept: Feature extraction and representation learning
  - Why needed here: Understanding how the network identifies which features are predictive requires knowledge of how neural networks learn to represent and extract features from raw data.
  - Quick check question: How do convolutional layers typically extract features from images?

- Concept: Catastrophic forgetting and interleaving effects
  - Why needed here: The paper discusses how networks forget previously learned features when trained on new ones, and how interleaving training helps mitigate this.
  - Quick check question: What is catastrophic forgetting and why does interleaving training help prevent it?

## Architecture Onboarding

- Component map:
  Image → Encoder (3 conv layers + 5 FC layers) → Latent representation → Relation module → Consistency score → Choice selection

- Critical path: Image → Encoder → Latent representation → Relation module → Consistency score → Choice selection

- Design tradeoffs:
  - Random convolutional layers vs. trained: Random layers work because they already capture useful features, saving computation
  - Simple relation module vs. complex: Simple module works if encoder provides good representations; complex module can compensate for weaker encoder
  - Optimization during test vs. pre-training: Test-time optimization allows solving novel problems but may be slower per problem

- Failure signatures:
  - Poor performance on problems with many distractors
  - Failure when predictive feature is non-monotonic
  - Complete chance-level performance when convolutional layers are removed

- First 3 experiments:
  1. Test performance on problems with 0, 1, 2, 3, 4 distractors to verify difficulty scaling
  2. Freeze convolutional layers and test if performance drops to confirm their role
  3. Freeze fully connected layers and test if performance drops to confirm their role

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the untrained neural network approach generalize to more complex abstract reasoning tasks beyond sequential visual reasoning, such as Raven's Progressive Matrices or analogical reasoning?
- Basis in paper: [inferred] The paper demonstrates success on sequential visual reasoning tasks but acknowledges limitations in solving problems that require breaking down into sub-components or generating new images that follow identified regularities.
- Why unresolved: The current framework is specifically designed for sequential reasoning and lacks components for more complex reasoning types like working memory or analogical mapping.
- What evidence would resolve it: Demonstrating the same untrained network approach on established abstract reasoning benchmarks like Raven's matrices, or showing success on analogical reasoning tasks would establish generalizability.

### Open Question 2
- Question: What is the theoretical limit of the types of regularities that can be identified by untrained networks using this optimization approach?
- Basis in paper: [explicit] The authors note that while monotonic relationships can be captured by simple relation modules, non-monotonic rules (like alternating patterns) remain at chance level performance.
- Why unresolved: The paper only explores a limited set of regularity types (linear, exponential, square root, alternating) and does not establish the boundary conditions for what can be learned through optimization.
- What evidence would resolve it: Systematic testing across a spectrum of regularity types, including piecewise functions, periodic patterns, and hierarchical structures, would reveal the fundamental limitations of this approach.

### Open Question 3
- Question: How does the performance of untrained networks on abstract reasoning tasks compare to that of humans solving the same problems without prior exposure?
- Basis in paper: [inferred] The paper focuses on demonstrating that networks can perform abstract reasoning without training, but does not compare their performance to human baselines on equivalent tasks.
- Why unresolved: While the paper establishes that networks can achieve above-chance performance, it does not contextualize this within human cognitive capabilities or limitations.
- What evidence would resolve it: Direct experimental comparison of untrained networks and human participants on identical abstract reasoning problems, controlling for problem difficulty and complexity, would establish the relative capabilities of each approach.

## Limitations
- Limited to synthetically generated visual reasoning problems with controlled features and distractors
- Cannot handle non-monotonic patterns (e.g., alternating patterns) that require more complex reasoning
- Performance degrades significantly with increasing number of distractors

## Confidence
- High confidence: Core empirical finding of 58% vs 25% accuracy
- Medium confidence: Proposed mechanisms for untrained network success
- Medium confidence: Conclusions about knowledge crystallization and interleaving effects

## Next Checks
1. Test the untrained network on real-world abstract reasoning datasets (e.g., Raven's Progressive Matrices) to verify generalization beyond synthetic problems.

2. Conduct ablation studies that systematically vary the number of convolutional filters and their initialization to quantify how much random feature extraction contributes to performance.

3. Implement visualization techniques to directly observe whether the network is actually identifying the predictive feature or finding alternative patterns that correlate with the correct answer.