---
ver: rpa2
title: Compositional Hardness of Code in Large Language Models -- A Probabilistic
  Perspective
arxiv_id: '2409.18028'
source_url: https://arxiv.org/abs/2409.18028
tags:
- problems
- problem
- generation
- composition
- solution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the difficulty large language models (LLMs)
  face when solving multiple analytical tasks within the same context window, such
  as generating code for complex problems. The authors introduce the concept of "in-context
  compositional hardness," where composing multiple sub-tasks within one context window
  leads to exponentially worse performance compared to solving them in separate contexts.
---

# Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective

## Quick Facts
- arXiv ID: 2409.18028
- Source URL: https://arxiv.org/abs/2409.18028
- Reference count: 40
- Primary result: Composing multiple coding tasks in the same context window exponentially increases generation complexity compared to solving them in parallel contexts

## Executive Summary
This paper investigates why large language models struggle with composing multiple analytical tasks within the same context window, particularly for code generation. The authors introduce "in-context compositional hardness," showing that mixing semantically different sub-tasks introduces noise into hidden representations that exponentially degrades generation quality. They propose a generation complexity metric and demonstrate through theoretical analysis and experiments on Llama 3 and Mistral models that multi-agent approaches (solving sub-tasks in parallel contexts) avoid this exponential degradation.

## Method Summary
The authors construct composite coding problems by pairing subproblems from Human Eval and Code Contests datasets, then measure generation complexity - the number of generations needed to obtain at least one correct solution. They use nucleus sampling (p=0.95, T=1) with Llama-3-8B-Instruct to generate solutions, evaluating correctness via test cases. The core methodology compares generation complexity ratios between compositional approaches (single context) and parallel approaches (multi-agent), validating theoretical bounds on noise injection and probability degradation during autoregressive decoding.

## Key Results
- Generation complexity for composite problems scales exponentially with total solution length due to accumulated noise effects
- Multi-agent systems outperform single-context approaches for compositional coding tasks, with generation complexity becoming the product of sub-problem complexities
- Larger models (70B vs 8B) show reduced but still present compositional hardness
- The noise mechanism is attributed to semantically different sub-tasks mixing in hidden representations during autoregressive generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Composing two coding problems in the same context window exponentially increases generation complexity compared to solving them in parallel contexts.
- Mechanism: The model's autoregressive nature causes hidden representations to mix semantically different sub-tasks, injecting noise into the logits during decoding. This noise symmetrically degrades the probability of correct continuations while occasionally boosting incorrect ones.
- Core assumption: Noise on logits is continuous, symmetric, and bounded within [-M, +M] when mixing semantically different but grammatically similar tasks.
- Evidence anchors:
  - [abstract] "The hardness of composition is quantified by a generation complexity metric... that increases exponentially with the solution's length."
  - [section 3.2] "When combining two problems whose solutions are grammatically similar but semantically different... we assume this combination injects noise into the model's representations during solution generation."
  - [corpus] Weak - related papers discuss compositional adapters and formal verification but don't directly address autoregressive noise mechanisms.
- Break condition: If the noise distribution is not symmetric or bounded, or if sub-tasks are semantically similar enough that representations don't conflict.

### Mechanism 2
- Claim: Generation complexity for composite problems scales exponentially with total solution length due to accumulated noise effects.
- Mechanism: Each decoding step introduces multiplicative probability degradation from noise, accumulating over sequence length. The renormalization term's mean (∆) and variance determine exponential growth rate.
- Core assumption: Probability of correct token at each step stays bounded away from 0 and 1 (ϵ ≤ P(correct) ≤ 1-ϵ).
- Evidence anchors:
  - [section 3.3] "On average, the noise decreases the probability of a correct continuation... by a factor exp(-∆(ϵ, X))"
  - [section 4] "We see that longer problems become harder to solve within the same context relative to solving them in parallel due to the noise injected into the decoding steps"
  - [corpus] Weak - no direct corpus evidence for length-dependent noise accumulation in LLMs.
- Break condition: When the model can perfectly isolate sub-tasks in the same context, or when solution length is below the noise threshold.

### Mechanism 3
- Claim: Multi-agent systems outperform single-context approaches for compositional coding tasks due to parallel sampling avoiding accumulated noise.
- Mechanism: Parallel contexts allow independent sampling from each sub-problem distribution, avoiding the exponential degradation from noise mixing. Generation complexity becomes product of sub-problem complexities instead of exponential growth.
- Core assumption: Solutions to sub-problems can be independently verified or their combination can be verified end-to-end.
- Evidence anchors:
  - [abstract] "the product of generation complexities of the sub-problems, corresponding to sampling independently a correct solution to each"
  - [section 4] "it is more beneficial to sample y1...yk in parallel. This defines a compositional hardness of coding problems"
  - [corpus] Moderate - related papers on multi-agent frameworks for complex code tasks support this direction.
- Break condition: When sub-problems have strong dependencies that require shared context, or when verification is only possible end-to-end.

## Foundational Learning

- Concept: Autoregressive generation and token-by-token decoding
  - Why needed here: The entire hardness of composition mechanism depends on how tokens are generated sequentially based on previous tokens
  - Quick check question: If a model generates tokens one at a time based on previous tokens, what happens to the hidden state when semantically different sub-tasks are mixed in the same context?

- Concept: Hidden layer representations and their interaction with vocabulary embeddings
  - Why needed here: The noise mechanism specifically operates on how representations project onto the vocabulary space during decoding
  - Quick check question: How does the dot product between hidden representations and embedding matrix create logits, and how can noise in representations affect this?

- Concept: Probability distributions and softmax normalization
  - Why needed here: The core mechanism involves how noise redistributes probability mass across tokens via softmax
  - Quick check question: When noise is added to logits, how does the softmax function redistribute probability mass among tokens?

## Architecture Onboarding

- Component map: Problem Decomposition → Context Formation → Autoregressive Decoder → Solution Verification
- Critical path: Problem → Decomposition → Context Formation → Autoregressive Generation → Solution Verification. The bottleneck is typically in the context formation stage where noise is introduced.
- Design tradeoffs: Single-context approaches have lower communication overhead but suffer from exponential complexity growth. Multi-agent approaches avoid this but introduce coordination complexity and potential coherence issues between agents.
- Failure signatures: Exponential growth in required generations for composite problems, particularly as solution length increases. High variance in generation complexity across different problem pairs suggests context mixing issues.
- First 3 experiments:
  1. Measure generation complexity ratio (composite vs parallel) for varying solution lengths to validate exponential relationship
  2. Analyze logit noise distribution by comparing correct vs incorrect token projections in composite vs non-composite contexts
  3. Test multi-agent approach on the same composite problems to verify practical advantage over single-context generation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the compositional hardness scale with more than two sub-problems? Does the exponential increase in generation complexity continue to hold when composing three or more problems?
- Basis in paper: [explicit] The paper presents theoretical results for composing two problems but notes that the proof can be inductively extended to any number of problems.
- Why unresolved: The experiments only tested compositions of two problems. Testing compositions of three or more problems would require significantly more computational resources due to the exponential growth in sampling needed.
- What evidence would resolve it: Empirical measurements of generation complexity ratios for compositions of three, four, or more sub-problems, comparing single-context vs multi-agent approaches.

### Open Question 2
- Question: What is the exact functional form of the noise distribution in the model's latent representations when composing semantically different sub-tasks? Is it truly Gaussian or does it have different characteristics?
- Basis in paper: [explicit] The paper assumes the noise is continuous, symmetric, and bounded within [-M, +M], and approximates it as Gaussian for estimation purposes.
- Why unresolved: The experimental measurements only show that the noise is symmetric and bounded, but do not determine its exact distribution. The Gaussian approximation may not capture all characteristics of the true noise.
- What evidence would resolve it: Detailed statistical analysis of the noise distribution from multiple model layers and decoding steps, comparing against various candidate distributions.

### Open Question 3
- Question: How does the compositional hardness vary across different model architectures and sizes? Is the exponential dependence on solution length universal or architecture-dependent?
- Basis in paper: [explicit] The paper tests Llama 3 8B/70B and Mistral 7B, showing that larger models have reduced but still present compositional hardness.
- Why unresolved: The experiments only cover a limited range of model sizes and architectures. It's unclear whether the effect is fundamental to transformer architectures or if different architectures might show different scaling behaviors.
- What evidence would resolve it: Systematic comparison of compositional hardness across multiple model families (GPT, Claude, Gemini, etc.) and sizes, measuring generation complexity ratios for each.

### Open Question 4
- Question: Can fine-tuning or specialized training methods mitigate the compositional hardness effect? Would models trained on composite problem solving show reduced exponential growth in generation complexity?
- Basis in paper: [inferred] The paper demonstrates that models suffer from compositional hardness even on simple composite problems they haven't been explicitly trained on, suggesting this might be addressable through training.
- Why unresolved: The paper only tests baseline models without any special training for composition. It's unknown whether the effect is inherent or can be reduced through appropriate training regimes.
- What evidence would resolve it: Comparative experiments measuring generation complexity ratios for models trained with and without composite problem datasets, showing whether training reduces the exponential scaling.

## Limitations
- Weak empirical validation of theoretical noise model - core mechanism relies on theoretical bounds but lacks direct measurement of noise distribution properties
- Dataset and problem construction specificity - results depend heavily on specific composite problem constructions using HumanEval and Code Contests datasets
- Multi-agent implementation details - theoretical advantages assume perfect isolation and verification that may not hold in practice

## Confidence
- **High Confidence**: The observation that compositional problems in the same context exhibit higher generation complexity than parallel approaches is well-supported by empirical data. The generation complexity metric itself is clearly defined and measured.
- **Medium Confidence**: The theoretical analysis connecting solution length to exponential complexity growth through accumulated noise is internally consistent but relies on assumptions about noise properties that aren't fully validated empirically.
- **Low Confidence**: The exact noise distribution characteristics (symmetry, boundedness, variance) and their impact on decoding are assumed rather than measured.

## Next Checks
1. Direct noise distribution analysis: Measure the actual logit noise distribution when semantically different sub-tasks are composed in the same context versus separate contexts, comparing against theoretical assumptions.
2. Cross-domain generalization test: Apply the same generation complexity analysis to non-coding compositional tasks to verify whether the exponential length dependence and multi-agent advantage generalize beyond coding problems.
3. Noise threshold characterization: Systematically vary solution lengths and measure the generation complexity ratio to identify at what length scales the exponential degradation becomes significant.