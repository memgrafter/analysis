---
ver: rpa2
title: Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical
  Documents
arxiv_id: '2409.16934'
source_url: https://arxiv.org/abs/2409.16934
tags:
- neurons
- layers
- https
- language
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates OCR-sensitive neurons in transformer models
  and their impact on named entity recognition (NER) performance in historical documents.
  By analyzing neuron activation patterns in response to clean and noisy text inputs,
  the authors identify and neutralize OCR-sensitive neurons to improve model performance.
---

# Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents

## Quick Facts
- **arXiv ID**: 2409.16934
- **Source URL**: https://arxiv.org/abs/2409.16934
- **Reference count**: 40
- **Primary result**: Neuron neutralization technique improves NER performance on noisy historical documents by identifying and neutralizing OCR-sensitive neurons in transformer models.

## Executive Summary
This paper investigates how transformer models process noisy text from historical documents with OCR errors. By analyzing neuron activation patterns in response to clean and noisy inputs, the authors identify "OCR-sensitive neurons" that show distinct activation patterns when processing OCR-corrupted text. Through a neuron neutralization technique that scales down activations of these identified neurons during inference, the study demonstrates improved named entity recognition performance on historical newspapers and classical commentaries. The research reveals that middle layers of transformer models are most sensitive to OCR noise and that targeted neuron modulation can enhance robustness to text degradation.

## Method Summary
The authors fine-tune Llama2 and Mistral models on French historical datasets (HIPE-2020 and Ajax Multi-Commentary) using LoRA adaptation. They generate synthetic OCR noise at three levels using the NLPAug library and analyze neuron activation differences between clean and noisy token pairs to identify OCR-sensitive neurons. These neurons are then neutralized during inference by scaling down their activations using factors of 0.1, 0.5, and 0.9. Performance is measured using F1-scores on NER tasks, with additional analysis using CKA similarity to identify layers most affected by OCR noise.

## Key Results
- OCR-sensitive neurons exist in both Llama2 and Mistral models, with middle layers (2-11, 13-23, 27-31) showing highest sensitivity to OCR noise
- Neutralizing 100-11,000 neurons per layer improves NER performance on historical documents with OCR errors
- CKA similarity analysis reveals that activation values between clean and noisy inputs diverge significantly in specific layers
- The neuron neutralization approach shows particular effectiveness on datasets with higher OCR noise levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: OCR-sensitive neurons show distinct activation patterns when processing noisy vs clean text.
- Mechanism: By comparing neuron activation differences between correct and OCR-corrupted tokens, neurons that consistently deviate more than others are identified as OCR-sensitive.
- Core assumption: Neuron activation differences can reliably indicate sensitivity to OCR noise.
- Evidence anchors: "A neuron n in an MLP up-projection layer is considered activated if its activation values Ïƒ(x) exceed zero [40,50]. Then, it is defined as OCR-sensitive if the difference between its activations in response to correct tokens and its activations in response to altered tokens is significantly higher than that of other neurons in the same layer..."

### Mechanism 2
- Claim: Neutralizing OCR-sensitive neurons can improve NER performance on noisy historical documents.
- Mechanism: By scaling down activations of identified OCR-sensitive neurons during inference, the model's reliance on these noise-reactive features is reduced, improving robustness.
- Core assumption: OCR-sensitive neurons negatively impact NER performance when processing noisy text.
- Evidence anchors: "We neutralise between 100 to 11,000 neurons per layer in steps of 100 during the forward pass on the test data, using 0.1, 0.5, and 0.9 as neutralising factor values..."

### Mechanism 3
- Claim: Different layers exhibit varying sensitivity to OCR noise, with middle layers showing the highest sensitivity.
- Mechanism: Using CKA similarity to compare layer activations between clean and noisy inputs reveals which layers are most affected by OCR noise.
- Core assumption: CKA similarity is an effective measure for identifying OCR-sensitive regions in neural networks.
- Evidence anchors: "For both models, the CKA values between correct-altered tokens are low for layers 2-11, 13-23 and 27-31, indicating that their activation values are far apart."

## Foundational Learning

- **Neuron probing and activation analysis**: Understanding how individual neurons respond to different inputs is fundamental to identifying OCR-sensitive neurons. *Quick check*: What is the primary difference between analyzing layer representations vs individual neuron activations?

- **CKA (Centered Kernel Alignment) similarity**: CKA is used to measure how similarly layers respond to clean vs noisy inputs. *Quick check*: What does a low CKA value between two layer activations indicate about their similarity?

- **Neuron ablation/neutralization techniques**: The study's core approach involves systematically disabling identified OCR-sensitive neurons. *Quick check*: How does neuron neutralization differ from neuron ablation in terms of implementation?

## Architecture Onboarding

- **Component map**: Tokenized text (clean/noisy) -> Llama2/Mistral decoder-only Transformer with 32 decoder blocks -> MLP up-projection layers -> NER performance metrics (F1 scores)

- **Critical path**: 1. Generate clean/noisy token pairs 2. Analyze layer activations using CKA similarity 3. Identify OCR-sensitive neurons through activation difference analysis 4. Neutralize identified neurons during inference 5. Measure impact on NER performance

- **Design tradeoffs**: Synthetic vs real OCR noise (controlled experiments vs real-world representation), neuron neutralization vs full ablation (preserving functionality vs complete removal), layer-level vs neuron-level analysis (precision vs computational cost)

- **Failure signatures**: No improvement or degradation in NER performance after neuron neutralization, inconsistent results across different datasets or noise levels, difficulty distinguishing OCR-sensitive neurons from neurons sensitive to other input variations

- **First 3 experiments**: 1. Generate small dataset of clean/noisy token pairs and verify CKA similarity patterns 2. Implement neuron sensitivity analysis on single layer and manually verify identified neurons 3. Test neuron neutralization on small subset of neurons and measure impact on simple downstream task

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Does the observed sensitivity to OCR noise vary systematically with specific types of character-level distortions (substitutions, deletions, insertions) rather than noise levels alone?
- **Basis in paper**: The paper introduces a method for generating OCR noise at different levels but does not analyze whether certain distortion types affect neuron sensitivity differently.
- **Why unresolved**: The study focuses on noise levels but does not categorize or analyze the impact of specific distortion types on neuron behavior.
- **What evidence would resolve it**: Conducting experiments that isolate and compare the effects of different OCR distortion types (e.g., substitutions, deletions, insertions) on neuron activation patterns and model performance.

### Open Question 2
- **Question**: Are the OCR-sensitive neurons identified in this study transferable across different OCR systems or datasets with varying noise distributions?
- **Basis in paper**: The paper acknowledges that the identification of OCR-sensitive neurons is highly dependent on the specific datasets and noise levels used in the experiments.
- **Why unresolved**: The study uses only two French datasets with controlled noise generation, limiting the generalizability of the findings to other OCR systems or languages.
- **What evidence would resolve it**: Testing the identified OCR-sensitive neurons on multiple datasets from different OCR systems, languages, and noise distributions to assess their transferability and robustness.

### Open Question 3
- **Question**: How do OCR-sensitive neurons interact with other model components during the forward pass, and what compensatory mechanisms might occur when these neurons are neutralized?
- **Basis in paper**: The study neutralizes OCR-sensitive neurons by scaling down their activations but does not explore the broader impact on neuron interactions or potential compensatory mechanisms within the model.
- **Why unresolved**: The neuron ablation approach used in the study simplifies the complex dynamics of neuron interactions, leaving questions about compensatory mechanisms unanswered.
- **What evidence would resolve it**: Investigating the model's internal dynamics using techniques like neuron interaction analysis or network pruning to understand how the model compensates for the neutralization of OCR-sensitive neurons.

## Limitations
- Synthetic OCR noise generation may not fully capture real-world OCR error patterns in historical documents
- Lack of comparison with alternative robustness techniques such as adversarial training or data augmentation
- Focus on only two specific models (Llama2 and Mistral) limits generalizability across different architectures
- No analysis of potential trade-offs between noise robustness and performance on clean text

## Confidence
**High Confidence**: The identification of OCR-sensitive neurons through activation difference analysis is well-supported by the methodology and aligns with established neuron probing techniques. The improvement in F1-scores after neuron neutralization provides direct evidence for the effectiveness of the approach.

**Medium Confidence**: The layer-wise sensitivity patterns identified through CKA analysis are plausible given the architectural understanding of transformers, but the specific patterns may vary with different noise types or model architectures.

**Low Confidence**: The broader claim that targeted neuron modulation is a superior approach to improving NER on noisy historical documents lacks comparative analysis with other robustness methods.

## Next Checks
1. **Cross-architecture validation**: Apply the same neuron analysis methodology to different transformer architectures (e.g., BERT, RoBERTa) to determine whether OCR-sensitive patterns are consistent across model families.

2. **Real-world OCR error testing**: Replace synthetic noise with actual OCR outputs from historical document scans to verify that identified neurons remain sensitive to real OCR errors.

3. **Performance trade-off analysis**: Systematically measure the impact of neuron neutralization on both noisy and clean text performance across multiple tasks to quantify any potential degradation in clean-text accuracy.