---
ver: rpa2
title: Is Multiple Object Tracking a Matter of Specialization?
arxiv_id: '2411.00553'
source_url: https://arxiv.org/abs/2411.00553
tags:
- modules
- tracking
- conference
- each
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PASTA, a modular framework that improves domain
  generalization for transformer-based multiple object tracking by combining Parameter-Efficient
  Fine-Tuning (PEFT) with attribute-specific expert modules. Instead of fine-tuning
  entire models, PASTA learns lightweight modules for attributes like lighting, viewpoint,
  and occupancy, then composes them to adapt to new scenarios without increasing inference
  time.
---

# Is Multiple Object Tracking a Matter of Specialization?

## Quick Facts
- arXiv ID: 2411.00553
- Source URL: https://arxiv.org/abs/2411.00553
- Reference count: 40
- One-line primary result: PASTA improves domain generalization for MOT transformers using attribute-specific expert modules without inference overhead

## Executive Summary
This paper proposes PASTA, a modular framework that improves domain generalization for transformer-based multiple object tracking by combining Parameter-Efficient Fine-Tuning (PEFT) with attribute-specific expert modules. Instead of fine-tuning entire models, PASTA learns lightweight modules for attributes like lighting, viewpoint, and occupancy, then composes them to adapt to new scenarios without increasing inference time. Experiments show that PASTA reduces negative interference, improves tracking performance on both source and target domains, and outperforms monolithic fine-tuning in zero-shot settings. The modular design enables efficient storage, faster training, and better adaptability to domain shifts.

## Method Summary
PASTA extends transformer-based MOT trackers (like MOTRv2-MS) by learning small, attribute-specific PEFT modules instead of full fine-tuning. Each module is a lightweight adaptation (LoRA matrices for encoder/decoder layers, scale/shift vectors for conv layers) trained independently on specific attribute values (e.g., lighting conditions, camera viewpoints). During inference, a Domain Expert selects relevant modules based on scene attributes, which are then combined in parameter space using weighted summation. This allows systematic generalization to new domains without increasing inference time or memory overhead.

## Key Results
- PASTA reduces negative interference by training attribute-specific modules independently
- Zero-shot transfer performance improves significantly on real-world datasets (MOT17, PersonPath22)
- No inference overhead: module composition occurs in parameter space, not output space

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PASTA prevents negative interference by training attribute-specific PEFT modules independently, isolating parameter updates per attribute.
- Mechanism: During training, the model freezes the backbone and only updates the LoRA matrices or scale/shift parameters for one randomly selected attribute per iteration. This confines gradient updates to a single module, avoiding cross-attribute parameter conflicts.
- Core assumption: Attribute-specific modules do not require interaction during training; each module's specialization is sufficient to capture the relevant attribute without interference.
- Evidence anchors:
  - [abstract]: "These expert modules are combined in parameter space, enabling systematic generalization to new domains without increasing inference time."
  - [section]: "To prevent negative interference, we optimize each module independently, randomly sampling one attribute at a time and updating only the corresponding module at each training iteration."
- Break condition: If attributes are correlated or non-disjoint, isolating them may lose shared representational capacity, hurting performance.

### Mechanism 2
- Claim: PASTA improves domain generalization by leveraging attribute-level specialization, enabling effective adaptation to unseen domains via soft routing.
- Mechanism: At inference, the Domain Expert selects modules based on scene attributes. For zero-shot transfer, soft routing aggregates all modules for an attribute with a higher weight (ρ=0.8) on the selected module and lower weights on others, enriching the representation.
- Core assumption: Combining multiple attribute-specific modules yields a more robust representation than relying on a single module, especially under domain shift.
- Evidence anchors:
  - [abstract]: "These expert modules are combined in parameter space, enabling systematic generalization to new domains without increasing inference time."
  - [section]: "we adopt a soft strategy that considers all the modules in the inventory associated with the relevant attribute."
- Break condition: If attribute modules are too specialized or incompatible, their combination could produce conflicting signals, degrading performance.

### Mechanism 3
- Claim: PASTA avoids computational overhead at inference by composing modules in parameter space, not output space.
- Mechanism: Modules are combined by adding their task vectors (displacement from base parameters) to the pre-trained backbone, resulting in a single forward pass with no extra FLOPs beyond the base tracker.
- Core assumption: The linear combination of task vectors accurately approximates the effect of sequential application of individual modules.
- Evidence anchors:
  - [abstract]: "These expert modules are combined in parameter space, enabling systematic generalization to new domains without increasing inference time."
  - [section]: "To minimize inference costs, this process is usually performed in the parameter space rather than the output space, an activity often referred to as model merging [54]."
- Break condition: If task vectors are large or non-linear, their linear combination may poorly approximate the true composite function.

## Foundational Learning

- Concept: Parameter-Efficient Fine-Tuning (PEFT)
  - Why needed here: Full fine-tuning of large transformer trackers is computationally expensive and memory-intensive. PEFT (e.g., LoRA) allows efficient adaptation by updating only small low-rank matrices.
  - Quick check question: What is the shape of the LoRA update matrices relative to the original weight matrix, and why does this reduce trainable parameters?

- Concept: Modular Deep Learning (MDL)
  - Why needed here: MDL enables specialization by learning lightweight expert modules for different attributes, which can be selectively combined for different scenarios without retraining the full model.
  - Quick check question: How does MDL differ from traditional multi-task learning in terms of parameter sharing and specialization?

- Concept: Domain Generalization
  - Why needed here: The goal is to adapt a tracker trained on synthetic data (MOTSynth) to real-world domains (MOT17, PersonPath22) without further training. This requires leveraging attribute-level knowledge transfer.
  - Quick check question: Why is zero-shot transfer harder than in-domain transfer, and how does attribute specialization help mitigate this?

## Architecture Onboarding

- Component map:
  - Backbone: Pre-trained ResNet + Deformable DETR (frozen during module training)
  - Attribute modules: LoRA matrices (for encoder/decoder linear layers) and scale/shift vectors (for conv layers)
  - Domain Expert: Router that selects modules based on scene attributes
  - Composition: Weighted sum of task vectors in parameter space

- Critical path:
  1. Training: Sample attribute → update corresponding module → repeat until convergence
  2. Inference: Domain Expert selects modules → soft routing combines task vectors → apply to backbone → run tracker

- Design tradeoffs:
  - Pros: Reduced negative interference, improved domain generalization, no inference overhead, efficient storage
  - Cons: Requires manual attribute annotation, limited to discrete attribute values, potential incompatibility in module combinations

- Failure signatures:
  - Poor performance on source domain → overfitting to modules or insufficient diversity in training attributes
  - Poor zero-shot transfer → modules too specialized or incompatible, or attribute selection mismatch
  - Increased inference time → incorrect module composition (e.g., output-space fusion instead of parameter-space)

- First 3 experiments:
  1. Train PASTA on MOTSynth with only lighting and viewpoint modules; evaluate on validation set to check in-domain improvement.
  2. Test zero-shot transfer from MOTSynth to MOT17 with Domain Expert selection; compare HOTA/IDF1 vs MOTRv2-MS.
  3. Evaluate effect of soft routing (ρ=0.8) vs hard routing (ρ=1.0) on MOT17 to confirm benefit of richer representations.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal routing strategy for selecting modules in dynamic, real-time scenarios where attributes may change rapidly?
- Basis in paper: [inferred] The paper mentions that manual annotation or domain expert intervention is required for routing, but suggests exploring automatic routing techniques for scalability.
- Why unresolved: The current reliance on manual annotation or expert input may not be practical for large-scale or real-time applications where attributes change frequently.
- What evidence would resolve it: Comparative studies evaluating the performance of automatic routing strategies versus manual annotation in dynamic scenarios, demonstrating improvements in scalability and real-time adaptability.

### Open Question 2
- Question: How does the modular approach impact the model's ability to generalize to entirely new attributes not seen during training?
- Basis in paper: [inferred] The paper discusses the effectiveness of the modular approach in zero-shot scenarios but does not address the model's performance with entirely new attributes.
- Why unresolved: The experiments focus on known attributes, leaving uncertainty about how the model would handle novel attributes that were not part of the training process.
- What evidence would resolve it: Experiments testing the model's performance on datasets with new, unseen attributes, measuring its ability to adapt and maintain accuracy without additional training.

### Open Question 3
- Question: What are the long-term effects of using the modular approach on model performance, particularly in terms of catastrophic forgetting and knowledge retention?
- Basis in paper: [explicit] The paper mentions that the modular approach mitigates catastrophic forgetting compared to full fine-tuning, but does not explore long-term effects.
- Why unresolved: While short-term improvements are noted, the paper does not investigate how the model's performance evolves over time with continuous updates or exposure to new data.
- What evidence would resolve it: Longitudinal studies tracking model performance over extended periods, assessing the impact of ongoing updates on knowledge retention and the emergence of new forms of forgetting or interference.

## Limitations
- Requires manual annotation of attributes like lighting, viewpoint, and occupancy, which may not be feasible in all domains
- Assumes attribute independence, which may not hold in complex real-world scenarios with correlated attributes
- Scalability to very large module inventories (50+ modules) is not empirically validated

## Confidence
- **High confidence**: The mechanism preventing negative interference through independent module training is well-supported by the described experimental results and aligns with established PEFT principles.
- **Medium confidence**: The zero-shot transfer improvements are demonstrated on specific datasets (MOT17, PersonPath22) but may not generalize to all domain shifts, particularly when attribute distributions differ significantly from training data.
- **Low confidence**: The scalability claim for large-scale applications lacks empirical validation, and the performance impact of increased module inventory size is not thoroughly investigated.

## Next Checks
1. **Ablation study on attribute correlation**: Systematically evaluate PASTA performance when training modules for correlated vs. independent attributes to quantify the impact of the independence assumption.
2. **Cross-dataset attribute consistency**: Test whether attribute annotations transfer meaningfully between datasets (e.g., MOTSynth lighting annotations applied to MOT17) to validate the manual annotation requirement.
3. **Large-scale scalability test**: Evaluate PASTA with 50+ attribute modules to identify performance degradation thresholds and confirm the claimed linear scalability with module count.