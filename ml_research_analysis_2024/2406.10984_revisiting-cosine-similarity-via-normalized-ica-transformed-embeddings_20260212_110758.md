---
ver: rpa2
title: Revisiting Cosine Similarity via Normalized ICA-transformed Embeddings
arxiv_id: '2406.10984'
source_url: https://arxiv.org/abs/2406.10984
tags:
- embeddings
- axes
- normalized
- values
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a new interpretation of cosine similarity
  using Independent Component Analysis (ICA)-transformed embeddings. By normalizing
  ICA-transformed embeddings, the authors demonstrate that each axis becomes more
  interpretable and exhibits sparsity, allowing cosine similarity to be viewed as
  the sum of semantic similarities across axes.
---

# Revisiting Cosine Similarity via Normalized ICA-transformed Embeddings

## Quick Facts
- arXiv ID: 2406.10984
- Source URL: https://arxiv.org/abs/2406.10984
- Reference count: 40
- Primary result: ICA-transformed embeddings with normalization provide interpretable, sparse representations where cosine similarity decomposes into semantic similarities across axes

## Executive Summary
This paper proposes a novel interpretation of cosine similarity by applying Independent Component Analysis (ICA) to word embeddings and normalizing the results. The normalized ICA-transformed embeddings exhibit sparsity, enhancing the interpretability of each axis. The authors demonstrate that cosine similarity can be decomposed into the sum of semantic similarities across axes, with each axis representing an independent semantic aspect. They also derive probability distributions governing component values and their products, enabling statistical selection of significant axes. Experiments show that ICA provides better interpretability than PCA, with normalization further enhancing interpretability and resulting in greater sparsity of semantic similarities.

## Method Summary
The method involves applying FastICA to pre-trained word embeddings (such as GloVe or contextualized embeddings) to obtain independent components. The ICA-transformed embeddings are then normalized to unit length, creating sparse representations where each axis represents an independent semantic aspect. The cosine similarity between two normalized ICA-transformed embeddings is interpreted as the sum of component-wise products, each representing semantic similarity on a particular axis. The authors derive probability distributions for these component values and their products, allowing for statistical significance testing and axis selection using Bonferroni correction.

## Key Results
- ICA-transformed embeddings exhibit sparsity and enhanced interpretability compared to PCA-transformed embeddings
- Cosine similarity can be decomposed into a sum of semantic similarities across independent axes
- Statistical distributions enable principled selection of significant axes through p-value calculation and Bonferroni correction
- Normalization further enhances interpretability and sparsity of semantic similarities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Normalizing ICA-transformed embeddings produces sparse representations, making each axis more interpretable.
- Mechanism: Normalization to unit length amplifies differences in component magnitudes, causing only a few axes to have large values while others shrink toward zero.
- Core assumption: The ICA transformation already produces axes with distinct semantic meanings, and normalization accentuates these differences.
- Evidence anchors:
  - [abstract]: "The normalized ICA-transformed embeddings exhibit sparsity, enhancing the interpretability of each axis"
  - [section 1]: "the normalized ICA-transformed embeddings exhibit sparsity, enhancing the interpretability of each axis"
  - [corpus]: Weak - no direct corpus evidence provided; relies on controlled experiments.

### Mechanism 2
- Claim: Cosine similarity between ICA-transformed embeddings can be decomposed into a sum of semantic similarities across axes.
- Mechanism: Each component of the normalized embeddings represents a semantic aspect; their product between two embeddings quantifies shared meaning on that axis, and summing these products gives the cosine similarity.
- Core assumption: The ICA transformation yields independent semantic axes, and normalization preserves these independence properties.
- Evidence anchors:
  - [section 3.1]: "the cosine similarity can be interpreted as the sum of the semantic similarities over all axes"
  - [abstract]: "propose a novel interpretation of cosine similarity as the sum of semantic similarities over axes"
  - [corpus]: Moderate - supported by numerical examples and experiments but not directly tested on diverse datasets.

### Mechanism 3
- Claim: Statistical distributions for component values and their products enable principled axis selection.
- Mechanism: Component values follow a normal distribution with variance 1/d; their products follow a Bessel function distribution, allowing p-value calculation for significance testing.
- Core assumption: The normalized ICA-transformed embeddings have component values that asymptotically follow the specified distributions.
- Evidence anchors:
  - [section 4.1]: "the probability distribution that ˆs(ℓ) follows is a normal distribution with mean 0 and variance 1/d"
  - [section 4.2]: "the probability density function of ˆs(ℓ)ˆs(ℓ) is (d/π)K0(d|ˆs(ℓ)ˆs(ℓ)|)"
  - [corpus]: Moderate - theoretical derivations provided, but experimental validation limited to specific cases.

## Foundational Learning

- Concept: Independent Component Analysis (ICA) and its difference from PCA.
  - Why needed here: Understanding ICA is crucial because the paper's interpretation relies on ICA's ability to produce independent semantic axes, unlike PCA which only ensures uncorrelated axes.
  - Quick check question: What is the key difference between ICA and PCA in terms of the properties of the transformed components?

- Concept: Statistical hypothesis testing and Bonferroni correction.
  - Why needed here: The paper proposes selecting significant axes using p-values and Bonferroni correction to control for multiple comparisons.
  - Quick check question: Why is Bonferroni correction necessary when selecting significant axes from multiple dimensions?

- Concept: Sparse representations and their interpretability.
  - Why needed here: The paper argues that sparsity enhances interpretability by focusing attention on a few meaningful axes rather than diluting it across many.
  - Quick check question: How does sparsity in embedding representations contribute to interpretability?

## Architecture Onboarding

- Component map: GloVe embeddings -> FastICA transformation -> Normalization -> Component-wise product computation -> Statistical significance testing
- Critical path:
  1. ICA transformation of embeddings
  2. Normalization of ICA-transformed embeddings
  3. Component-wise product computation for cosine similarity
  4. Statistical significance testing of components and products
- Design tradeoffs:
  - Computational cost: ICA is more expensive than PCA due to iterative optimization
  - Interpretability vs. performance: Normalization improves interpretability but may slightly affect downstream task performance
  - Statistical rigor: Bonferroni correction is conservative, potentially missing some significant axes
- Failure signatures:
  - Lack of sparsity after normalization indicates ICA transformation did not produce meaningful axes
  - Inconsistent results across different embedding models suggest the approach may not generalize
  - High computational cost for large vocabularies or high-dimensional embeddings
- First 3 experiments:
  1. Apply ICA and normalization to a small GloVe embedding set and visualize the sparsity pattern
  2. Compute cosine similarities using both original and ICA-transformed embeddings to verify decomposition
  3. Perform statistical significance testing on a subset of axes to validate the distribution assumptions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the distributions of component-wise products differ between PCA and ICA embeddings, and what are the implications for semantic sparsity?
- Basis in paper: [inferred] The paper states that ICA-transformed embeddings exhibit greater sparsity in component-wise products compared to PCA, but does not provide a detailed comparison of the distributions.
- Why unresolved: The paper focuses on the probability distribution of component-wise products for ICA-transformed embeddings, but does not explore the differences in distribution for PCA-transformed embeddings.
- What evidence would resolve it: A detailed comparison of the distributions of component-wise products for both PCA and ICA-transformed embeddings, including statistical tests to quantify the differences in sparsity.

### Open Question 2
- Question: How does the choice of the number of independent components in ICA affect the interpretability and sparsity of the transformed embeddings?
- Basis in paper: [explicit] The paper uses FastICA with a fixed number of iterations and convergence tolerance, but does not explore the impact of varying the number of independent components.
- Why unresolved: The paper does not investigate how the number of independent components influences the interpretability and sparsity of the ICA-transformed embeddings.
- What evidence would resolve it: Experiments comparing the interpretability and sparsity of ICA-transformed embeddings with different numbers of independent components, including quantitative metrics and qualitative assessments.

### Open Question 3
- Question: How does the ICA transformation perform on embeddings with different dimensionalities and vocabulary sizes?
- Basis in paper: [inferred] The paper uses GloVe embeddings with 300 dimensions and 400,000 vocabulary size, and contextualized embeddings with varying dimensions, but does not explore the impact of different dimensionalities and vocabulary sizes on the ICA transformation.
- Why unresolved: The paper does not investigate how the performance of the ICA transformation varies with different embedding dimensionalities and vocabulary sizes.
- What evidence would resolve it: Experiments comparing the interpretability and sparsity of ICA-transformed embeddings with different dimensionalities and vocabulary sizes, including statistical tests to quantify the impact of these factors.

## Limitations

- The assumption that ICA consistently produces meaningful independent semantic axes across different embedding models and domains remains unverified
- The impact of normalization on downstream task performance beyond interpretability is not explored
- The derived statistical distributions may not accurately model component behavior in all real-world scenarios

## Confidence

- Mechanism 1: Medium
- Mechanism 2: Medium
- Mechanism 3: High

## Next Checks

1. Test ICA normalization across multiple embedding architectures (word2vec, fastText, contextualized models) to assess generalizability of the interpretability improvements
2. Conduct ablation studies measuring task performance trade-offs between original embeddings, PCA-transformed, and ICA-transformed representations
3. Validate the statistical significance framework by measuring false positive and false negative rates across different vocabulary sizes and embedding dimensions