---
ver: rpa2
title: 'Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication
  in Codenames'
arxiv_id: '2408.04900'
source_url: https://arxiv.org/abs/2408.04900
tags:
- clue
- words
- target
- giver
- guesser
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Rational Speech Acts for Cross-Cultural Communication
  (RSA+C3), a method that enables AI agents to adapt to cultural differences in shared
  knowledge during communication. The authors evaluate their approach using Codenames
  Duet, a collaborative reference game where players must convey meaning despite cultural
  gaps in common ground.
---

# Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication in Codenames

## Quick Facts
- **arXiv ID:** 2408.04900
- **Source URL:** https://arxiv.org/abs/2408.04900
- **Reference count:** 34
- **One-line primary result:** RSA+C3 achieves significantly higher win rates in cross-cultural Codenames Duet gameplay compared to literal and standard RSA approaches

## Executive Summary
This paper presents RSA+C3, a method that enables AI agents to adapt to cultural differences in shared knowledge during communication. The approach works by maintaining multiple models of literal listeners representing different cultures, estimating the probability that an interlocutor shares each cultural background based on interaction history, and then selecting utterances optimized for the inferred cultural context. The authors evaluate their method using Codenames Duet, a collaborative reference game where players must convey meaning despite cultural gaps in common ground. Experimental results show that RSA+C3 significantly improves win rates in cross-cultural gameplay compared to baselines, demonstrating its ability to infer and adapt to sociocultural context through live interaction.

## Method Summary
RSA+C3 extends the Rational Speech Acts framework by maintaining multiple culture-specific listener models and dynamically estimating which cultural context applies during gameplay. The system trains word embeddings using contrastive learning on demographic subsets of gameplay data, creating culture-specific semantic spaces. During interaction, it maintains a belief distribution over possible cultural identities of the interlocutor and updates these beliefs based on observed behavior. The method uses either trained word embeddings or LLM prompting with demographic context to generate culturally appropriate clues, selecting utterances that optimize expected utility given the inferred cultural alignment.

## Key Results
- RSA+C3 achieves higher win rates than literal and standard RSA approaches when players have different education levels (high school vs. graduate)
- Culture-specific word embeddings capture meaningful semantic differences across demographic groups
- LLM prompting with cultural context improves alignment with human gameplay patterns
- The system can infer cultural context from interaction history and adapt communication accordingly

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** RSA+C3 improves win rates by dynamically estimating cultural alignment through interaction history.
- **Mechanism:** The system maintains multiple literal listener models for different cultures, estimates the probability that the interlocutor shares each cultural background using interaction history, and selects utterances optimized for the inferred cultural context.
- **Core assumption:** Cultural differences in common ground can be captured by training separate word embedding models on demographic subsets of gameplay data.
- **Evidence anchors:**
  - [abstract] "RSA+C3 can ease cross-cultural communication in gameplay by inferring sociocultural context from interaction"
  - [section 3.2] "We estimate the probability P(wi) by calculating the probability that utterance g would have been chosen if the interlocutor shares the same culture"
  - [corpus] Weak evidence - no directly relevant corpus papers found
- **Break condition:** If cultural patterns in gameplay are too subtle to capture with current training methods, or if interaction history doesn't provide sufficient signal for cultural inference.

### Mechanism 2
- **Claim:** Training word embeddings on cultural subsets captures domain-specific semantic associations that differ across cultures.
- **Mechanism:** Contrastive learning increases similarity between clues and words selected by humans from the same cultural background while decreasing similarity with other words, creating culture-specific embedding spaces.
- **Core assumption:** Different cultural groups use systematically different word associations in Codenames gameplay that can be learned from interaction data.
- **Evidence anchors:**
  - [section 6.1] "We contrastively train embeddings using the technique in Section 5.1 on subsets of the Cultural Codes dataset"
  - [section 6.1] "There are similar large differences in accuracy between GloVe trained on split and GloVe trained on the other split in the cultural splits on country and politics"
  - [corpus] Weak evidence - related work focuses on politeness and general cultural awareness but not game-specific cultural semantics
- **Break condition:** If cultural differences are primarily in strategic preferences rather than word associations, or if training data is too limited to capture meaningful patterns.

### Mechanism 3
- **Claim:** Including cultural context in LLM prompting improves alignment with human gameplay patterns.
- **Mechanism:** Few-shot prompting with demographic information guides the model to generate clues and select targets that better match the cultural background of the human players in the dataset.
- **Core assumption:** LLMs can leverage cultural priors when provided with demographic context, even without explicit fine-tuning on cultural data.
- **Evidence anchors:**
  - [section 6.2] "inclusion of cultural context in clue generation, we find that inclusion of all demographics increased performance in the 13B model while 'leaning' (the political leaning and personality scores of the human players) increased performance for the 7B model"
  - [section 6.2] "including any demographic information improved alignment with the human guesser for the Llama-2-7B-Text model"
  - [corpus] Weak evidence - no directly relevant corpus papers found
- **Break condition:** If cultural context leads to stereotypical associations rather than genuine cultural patterns, or if model performance degrades with certain demographic combinations.

## Foundational Learning

- **Concept: Rational Speech Acts (RSA) framework**
  - Why needed here: Provides the theoretical foundation for modeling pragmatic reasoning in communication games
  - Quick check question: In RSA, what is the relationship between the pragmatic speaker's utility function and the literal listener's interpretation probabilities?

- **Concept: Contrastive learning for embedding spaces**
  - Why needed here: Enables creation of culture-specific semantic spaces that capture different word association patterns
  - Quick check question: How does the contrastive loss function encourage embeddings to distinguish between words selected by humans versus unselected words?

- **Concept: Pragmatic failure and common ground**
  - Why needed here: Explains why cultural differences cause communication breakdowns and motivates the need for cross-cultural adaptation
  - Quick check question: What is the difference between "norms and values" versus "common ground" in the context of cross-cultural communication?

## Architecture Onboarding

- **Component map:** Data processing pipeline -> Word embedding trainer -> LLM prompt generator -> RSA+C3 inference engine -> Evaluation framework
- **Critical path:** Training embeddings → creating culture-specific models → interactive gameplay evaluation → win rate comparison
- **Design tradeoffs:**
  - Word embeddings vs. LLMs: Embeddings are more consistent and interpretable; LLMs can capture more complex patterns but are less reliable
  - Number of culture models: More cultures allow finer-grained adaptation but increase computational cost and data requirements
  - Interaction history length: Longer histories provide better cultural inference but may include outdated information
- **Failure signatures:**
  - Win rates plateau at baseline levels despite RSA+C3 adaptation
  - Cultural inference probabilities become uniform across all cultures
  - Embedding training fails to converge or produces degenerate vectors
- **First 3 experiments:**
  1. Train embeddings on high school vs. graduate education subsets and measure guess accuracy differences
  2. Implement RSA+C3 with two culture models and test on fixed set of 100 boards
  3. Compare win rates of RSA+C3 versus literal and standard RSA approaches across different cultural splits

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but raises several implicit ones about the generalizability of the approach beyond Codenames Duet and how to handle players with multiple intersecting cultural identities.

## Limitations
- The Cultural Codes dataset may be too limited (794 games, 153 players) to capture complex cultural patterns
- The approach assumes cultural differences manifest primarily in word associations rather than strategic preferences
- The system's performance depends heavily on interaction history length and quality

## Confidence

- **High Confidence:** The RSA+C3 framework's theoretical soundness and the general observation that cultural differences affect communication in reference games. The win rate improvements over literal baselines are robust.
- **Medium Confidence:** The effectiveness of contrastive learning for capturing cultural word associations, and the specific implementation details of culture probability estimation from interaction history.
- **Low Confidence:** The scalability of the approach to more fine-grained cultural distinctions, and whether improvements generalize beyond the specific demographic splits tested (high school vs graduate education).

## Next Checks

1. **Dataset Adequacy Test:** Conduct ablation studies by training on increasingly smaller subsets of the Cultural Codes dataset to determine the minimum sample size needed for meaningful cultural adaptation, and identify which demographic splits provide the strongest signals.

2. **Cultural Pattern Verification:** Analyze the learned embedding spaces to verify that cultural differences reflect genuine semantic associations rather than superficial patterns. This could involve qualitative analysis of nearest neighbors for culture-specific words and comparison with external cultural knowledge sources.

3. **Real-World Transfer:** Test RSA+C3 on a different reference game or communication task with cross-cultural participants to assess whether the learned cultural models transfer beyond Codenames Duet, and identify which aspects of the approach are game-specific versus generally applicable.