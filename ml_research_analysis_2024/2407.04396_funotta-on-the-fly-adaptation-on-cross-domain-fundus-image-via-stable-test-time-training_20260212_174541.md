---
ver: rpa2
title: 'FunOTTA: On-the-Fly Adaptation on Cross-Domain Fundus Image via Stable Test-time
  Training'
arxiv_id: '2407.04396'
source_url: https://arxiv.org/abs/2407.04396
tags:
- domain
- fundus
- adaptation
- image
- glaucoma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a test-time adaptation (TTA) framework, FunOTTA,
  designed for fundus image classification under cross-domain scenarios. The method
  addresses the challenge of domain shifts in fundus images from different imaging
  devices or locations, which hinder the deployment of pre-trained diagnostic models
  in real-world applications.
---

# FunOTTA: On-the-Fly Adaptation on Cross-Domain Fundus Image via Stable Test-time Training

## Quick Facts
- arXiv ID: 2407.04396
- Source URL: https://arxiv.org/abs/2407.04396
- Authors: Qian Zeng; Le Zhang; Yipeng Liu; Ce Zhu; Fan Zhang
- Reference count: 40
- Primary result: Achieves consistent AUC and F1 score improvements over state-of-the-art TTA methods for cross-domain fundus image classification.

## Executive Summary
This paper introduces FunOTTA, a test-time adaptation framework designed to address domain shifts in fundus image classification across different imaging devices and locations. The method tackles the challenge of deploying pre-trained diagnostic models in real-world settings where data distributions differ from training conditions. FunOTTA achieves this through several innovations: dynamic filtering of memory bank updates based on feature disambiguation, a trainable prototypical classifier with ensemble learners, confidence-guided contrastive loss, and dual-level alignment strategy. Experimental results on large-scale benchmarks for diabetic retinopathy and glaucoma demonstrate significant improvements over existing TTA methods, with consistent gains in both AUC and F1 score across multiple target domains.

## Method Summary
FunOTTA is a test-time adaptation framework that operates without access to source data during adaptation. It uses a frozen source feature extractor to process incoming target domain images, maintaining a dynamic memory bank that selectively updates based on feature disambiguation rather than entropy. The framework employs an ensemble of learners to generate class prototypes, which are used with neighbor search to compute robust pseudo-labels for target samples. A confidence-guided contrastive loss enhances feature separation while mitigating uncertainty, and a dual-level alignment strategy reduces reliance on harmful source-domain bias. The method trains only the classifier weights in an online manner using unlabeled target data, making it suitable for real-time medical imaging applications.

## Key Results
- Outperforms state-of-the-art TTA methods on cross-domain fundus image classification for both diabetic retinopathy and glaucoma diagnosis
- Achieves consistent improvements in AUC and F1 score across multiple target domains and dataset combinations
- Demonstrates stability and effectiveness particularly in challenging medical imaging contexts with subtle inter-class differences
- Shows superior performance compared to entropy-based filtering approaches and traditional source-biased adaptation methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic filtering based on feature disambiguation reduces harmful prior knowledge bias.
- Mechanism: At each time step, the memory bank updates by eliminating features far from updated class centroids, computed from low-dimensional embeddings. This focuses adaptation on informative instances rather than entropy-based filtering.
- Core assumption: The source-trained feature extractor preserves relative distances in the embedding space, enabling reliable disambiguation of ambiguous features.
- Evidence anchors:
  - [abstract] "dynamic filtering mechanism that selectively updates a memory bank based on feature disambiguation rather than entropy"
  - [section] "our dynamic filtering mechanism updates the centroids by learning a clearer decision boundary to eliminate ambiguous features"
  - [corpus] No direct evidence; corpus contains related medical imaging works but not this specific filtering approach.
- Break condition: If the source feature extractor does not preserve meaningful distances, the filtering will misidentify reliable features as ambiguous, degrading adaptation.

### Mechanism 2
- Claim: Trainable prototypical classifier with ensemble learners improves class conditional estimation and reduces source bias.
- Mechanism: An ensemble learner generates hidden prototypes per class, and neighbor search aggregates information from memory bank embeddings to compute robust pseudo-labels. This avoids reliance on frozen source classifier outputs.
- Core assumption: Ensemble learners can produce stable prototypes that adapt to target feature space shifts.
- Evidence anchors:
  - [abstract] "trainable prototypical classifier with ensemble learners for improved class conditional estimation"
  - [section] "we estimate the class conditionals of unlabeled target data using the prototypical network, rather than simply relying on the classifier's output as pseudo labels"
  - [corpus] No direct evidence; corpus lacks mention of prototypical classifiers or ensemble learners for medical imaging.
- Break condition: If prototypes become unstable or collapse due to noisy memory bank updates, class conditional estimation will degrade.

### Mechanism 3
- Claim: Confidence-guided contrastive loss improves feature separation and mitigates uncertainty in target domain.
- Mechanism: Constructs positive/negative pairs using prototypes and guides learning by prediction confidence, penalizing uncertain samples to avoid incorrect associations.
- Core assumption: Confidence scores reliably indicate sample quality for guiding contrastive learning.
- Evidence anchors:
  - [abstract] "confidence-guided contrastive loss to enhance feature separation"
  - [section] "we introduce a confidence-based restriction that penalizes samples with uncertain predictions"
  - [corpus] No direct evidence; corpus lacks mention of confidence-guided contrastive losses in medical imaging.
- Break condition: If confidence estimates are unreliable, contrastive learning may focus on noisy samples, harming adaptation.

## Foundational Learning

- Concept: Domain adaptation vs. domain generalization vs. test-time adaptation.
  - Why needed here: FunOTTA operates in a test-time adaptation setting, requiring understanding of how it differs from other domain transfer paradigms.
  - Quick check question: In test-time adaptation, can the model access source data during adaptation? (Answer: No)

- Concept: Memory bank with dynamic filtering.
  - Why needed here: Central to FunOTTA's stability; understanding how it selectively updates features is key to implementing the method.
  - Quick check question: What criterion does FunOTTA use to filter memory bank entries? (Answer: Distance to updated class centroids in embedding space)

- Concept: Prototypical networks and ensemble learners.
  - Why needed here: Used to estimate class conditionals without relying on source classifier outputs.
  - Quick check question: How does FunOTTA compute pseudo-labels for target samples? (Answer: Using neighbor search aggregated with ensemble learner prototypes)

## Architecture Onboarding

- Component map: Frozen source feature extractor -> Dynamic memory bank with filtering -> Ensemble learner -> Non-parametric classifier -> Dual-level alignment losses
- Critical path: Feature extractor -> Memory bank updates -> Ensemble prototype generation -> Neighbor-based pseudo-label computation -> Contrastive and alignment losses -> Classifier parameter updates
- Design tradeoffs:
  - Using frozen feature extractor reduces parameter tuning but risks missing target domain nuances.
  - Dynamic filtering avoids entropy noise but depends on distance preservation quality.
  - Ensemble learners improve robustness but increase computational cost.
- Failure signatures:
  - Memory bank becomes noisy or collapses -> ambiguous feature filtering fails.
  - Prototypes unstable -> class conditional estimation degrades.
  - Confidence estimates unreliable -> contrastive loss misguides training.
- First 3 experiments:
  1. Validate dynamic filtering by comparing memory bank content before/after filtering on a small target batch.
  2. Test ensemble learner stability by varying the number of learners and measuring prototype variance.
  3. Assess confidence-guided contrastive loss impact by toggling confidence weighting and observing adaptation curves.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FunOTTA perform in scenarios involving label space expansion, such as detecting rare diseases not present in the source domain?
- Basis in paper: [explicit] The paper discusses the close-world assumption in the label space and mentions potential future work on datasets involving rare diseases to enhance generalization under open-set scenarios.
- Why unresolved: The current framework is evaluated within the close-world assumption, and its performance in open-set or rare disease detection scenarios is not tested.
- What evidence would resolve it: Experimental results on datasets with rare diseases or open-set scenarios, demonstrating FunOTTA's ability to detect or classify unseen disease categories.

### Open Question 2
- Question: What are the effects of hyperparameter selection on FunOTTA's performance in real-world medical applications where exhaustive tuning is infeasible?
- Basis in paper: [explicit] The paper discusses the stability of performance improvements with different hyperparameters and suggests future work on adaptive strategies like attention mechanisms for automatic neighbor selection.
- Why unresolved: While the paper explores hyperparameter stability, it does not provide solutions for automatic hyperparameter tuning in practical settings.
- What evidence would resolve it: Implementation of adaptive hyperparameter selection strategies and their evaluation in real-world medical imaging applications.

### Open Question 3
- Question: How does FunOTTA handle more extreme domain shifts, such as those involving unseen classes or significant label distribution shifts?
- Basis in paper: [explicit] The paper mentions the potential for FunOTTA to handle more extreme domain shifts involving unseen classes, aligning with universal domain adaptation principles.
- Why unresolved: The current evaluation focuses on covariate and label shifts within known classes, not extreme shifts with unseen classes.
- What evidence would resolve it: Experimental results on datasets with significant label distribution shifts or unseen classes, demonstrating FunOTTA's robustness and adaptability.

## Limitations
- Core innovations lack direct validation through ablation studies, making it difficult to isolate individual mechanism contributions
- Assumption that frozen source feature extractors preserve meaningful distance relationships in embedding space is unverified
- Stability of ensemble learners under varying memory bank conditions is not thoroughly examined

## Confidence
- Claims about FunOTTA's overall effectiveness: High (supported by consistent performance gains across multiple datasets and metrics)
- Claims about individual mechanism contributions: Medium (mechanisms are described but not independently validated)
- Claims about stability and robustness: Medium (qualitative observations without systematic stress testing)

## Next Checks
1. Conduct ablation studies removing each mechanism (dynamic filtering, ensemble prototypical classifier, confidence-guided contrastive loss) to quantify their individual contributions to performance gains.
2. Test the stability of ensemble learners by measuring prototype variance across different memory bank sizes and update frequencies, and examine sensitivity to hyperparameter choices (M, R, N).
3. Validate the assumption about distance preservation by comparing intra-class and inter-class distances in the source feature space before and after adaptation, and assess whether filtering decisions remain meaningful under domain shift.